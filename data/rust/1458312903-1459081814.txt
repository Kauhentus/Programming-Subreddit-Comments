The link should be fixed now - I renamed to `MatrixSlice` per /u/addmoreice's suggestion. I believe I understand now but I am not sure how to implement this. Wouldn't this require (at least one of) the inputs to be mutable? For example this [playground code](http://is.gd/ZRP67T). Edit: I just realised I can do [this](https://play.rust-lang.org/?gist=9723c41defd6a9142143&amp;version=stable). Is this what you mean? I suppose then I would need to implement these operation for when both inputs are references and one is not. I will actually need to do this same in my core matrix module :)
&gt; A really common practice in C is being able to interpret a piece of memory, say a header to a file, as a structure (libelf, for example, does this) Ok. But it does that because the language / compiler vendor makes some guarantees about memory layout and the ABI. This type of header struct only contains "stupid raw data". You could do the same in Rust. That's what `Copy` and `repr(C)` are for. use std::mem; use std::slice; fn non_portable_raw_access&lt;T: Copy&gt;(thing: &amp;T) -&gt; &amp;[u8] { unsafe { slice::from_raw_parts(thing as *const T as *const u8, mem::size_of::&lt;T&gt;()) } } fn non_portable_raw_access_mut&lt;T: Copy&gt;(thing: &amp;mut T) -&gt; &amp;mut [u8] { unsafe { slice::from_raw_parts_mut(thing as *mut T as *mut u8, mem::size_of::&lt;T&gt;()) } } fn main() { let mut n = 0u32; non_portable_raw_access_mut(&amp;mut n)[1] += 1; println!("{}", n); } Depending on what you want to do with this, your `T` should perhaps be declared with `#[repr(C)]`. On the other hand, if you go that route, you're basically not interested in portability. The fact that reliance on struct layout is so common among C programmers (according to you) is rather sad, in my humble opinion. &gt; I can't do this in Rust with anything that implements the Drop trait And why is that a problem? Why would you want to twiddle with a piece of memory on a bit/byte level that represents a nontrivial object that tries to uphold certain invariants? It doesn't seem sensible at all. The way I see it is Rust supports what you want and adds an additional kind of data type on top, the kind you don't have in C: Types that are not copyable via memcpy, types whose author is interested in upholding certain invariants where nobody else is supposed to mess with that. Since Rust allows you to write generic code that detects this (`Copy` bound) at compile-time, you should be fine.
Actually you can disallow implementing `Drop` on types that are `#[repr(C)]` using `#![forbid(drop_with_repr_extern)]`. By default it is warning: http://is.gd/ti63kb So this would not be that much issue as you think.
You could also say `mut a: Vec&lt;f64&gt;` in the function signature, no need for `let mut d = a`
Yup, that's what I meant. That's the beauty of move semantics! Small nitpick about the playground code: if you change your loop too for (a, &amp;b) in a.iter_mut().zip(b.iter()) { *a = &amp;b; } The compiler would be able to optimize out the bound checks, producing whole lot simpler code. [Playground](http://is.gd/7kN5q5). Unfortunately, both versions are not vectorized :( 
It's been the same for me, except I have to deal with PHP instead of C#. I've no irrational hatred for PHP (quite the contrary, in fact ^^^^my ^^^^hatred ^^^^is ^^^^entirely ^^^^rational ), but the Rust syntax felt so clear and natural (lifetimes excepted, I guess, and even that made sense pretty quickly) that it immediately fit into a kind of hole in my brain and I cannot simply get it out again. It really is just that good.
Thanks for your help! I'll start working on these changes. As you pointed out vectorization could prove to be some work but hopefully I can adapt some of the existing code for that. Going back to the discussion of reusing the implementation for `Matrix&lt;T&gt; op MatrixView&lt;T&gt;` - do you agree that it would be better to implement `MatrixView&lt;T&gt; op MatrixView&lt;T&gt;` in the same vein that we don't allocate new data? Or is there a nuance I'm missing?
If you really care to make this quick you might need to optimize versions of the system when the matrix size are small through vectorization which should be significantly easier to pull off then trying to vectorize the system with generic sizes. Though i can see some of what would be needed, I am not nearly good enough at rust to help with that (hence why my help has been remarkably shallow: "make it slice!" =P hehe).
Since I always use the braces quasi-mandatory, I haven't thought of that. What you say makes perfect sense.
SO also has a fair proportion of outdated (thus useless) responses for Rust (more than for older languages). This is a recurring problem on SO, and I think Rust is just more sensitive because of its "turbulent" recent past (pre 1.0).
How do you figure? `let bar: Baz;` is perfectly valid in a function definition; it simply means that you're declaring a variable called `bar` of type `Baz` and are not initializing it. This code compiles fn main() { let bar: u32; bar = 5; println!("{}", bar); } 
I think this is largely a solved problem. Check out the [serde](https://crates.io/crates/serde) and [rustc-serialize](https://crates.io/crates/rustc-serialize) crates. Note that some of the features only work on nightly.
Because of the domain (machine learning) - I'm only really worried about large matrices. For small matrices I think there's already some strong libraries ([nalgebra](https://github.com/sebcrozet/nalgebra)) which I don't think I could compete with even if I tried! Any input is very welcome! And naming things is half (if not more) of the battle.
For a small lib, I have found rustc-serialize to be a neat drop-in. Otherwise, serde is my de facto option for lower level parsing.
Fair enough. Vectorization of large structures would still be in your favor though. GPU work as well (have fun!) i look forward to seeing where you get to go with this. I wouldn't mind pairing your work with my FDTD work.
If I understand correctly, `alloc_jemalloc` is an `#![allocator]` crate, and `liballoc` is a `#![needs_allocator]` crate. So your custom allocator can depend on `alloc_jemalloc` but not on `liballoc`.
&gt; This isn't exactly an edge case either (`Vec` does this), it's quite practical for large structures instead of initializing with static data every time you build a new instance You mean the space `Vec` allocates on the heap? You can't safely get access to that space, which is different than what you're doing. Working with uninitialized memory is unsafe in Rust, and `mem::uninitialized` is mainly used for calling C functions that initialize a struct via a pointer. &gt; Unless there's some version of `mem::uninitialized()` that will emit another instruction to initialize the piece of memory relevant to the drop flag Yes, there is, in the same module, [`mem::dropped()`](https://doc.rust-lang.org/std/mem/fn.dropped.html).
I'm an embedded developer who works out in the field. A lot of my code falls into this category. Just because I *can* get away with using bad patterns/practices doesn't mean I *should*. The real issues is the Game Industry is always in deadline hell mode and changing style/architecture is a long process that nobody has time for. 
It would be hard in something that is not Rust, but Rust has things like enums to represent multiple plausible structures which can solve this problem fairly easily, while Serde solves this slightly with `serde::Value` it doesn't fully solve this problem yet. You can't deserialize to multiple structs in enums easily, you only get the choice of representing it has `Value` which does not solve the problem, `Value` is not a fully statically checked structure, so everyone that interacts with it is going to have to fail at run time making it error prone to work with, you'd need to walk into it to convert it to your own types which is also very inefficient, the largest problem would be to have to figure out the enum type at compile time, for example: *in the reddit API, you have `"kind":` that has a key string that needs to be things like `: "t1"` or `: "t2"`, you need to determine this "kind", before serializing to a `"data":` type*. Iv tried figuring out if i could do anything about this when using Serde, but there doesn't seem to be any way to solve this properly yet.
Rust favors explicitness in almost all things. `mat[1, 2]` could be row 1 column 2 or it could be column 1 row 2. There is precedent for both column-major and row-major matrices, so I would very much avoid using the Index operator.
Most languages that do make braced blocks optional have style guides saying to always use them.
What about using a boolean to choose between the two? Or if you have more than two, storing them in an array or other container and using an index? Then you don't have to swap references around at all.
Are these literally the two passes, or are you grouping multiple passes into type checking? I'm wondering if build time is roughly type checking + translation in the context of these charts.
I will also put in the standard plea for a plot that has the y axis starting at zero.
I appreciate the positive feedback. Just a heads up, I did add a warning section at the bottom of the post because this approach is not perfectly generalizable.
Good to know that I can skip some arguments to `configure`. I'll try building it again without --build and --target. :) GDB indicates the illegal instruction is in llvm::sys::MemoryFence: Program received signal SIGILL, Illegal instruction. 0xb4db18f0 in llvm::sys::MemoryFence() () from /usr/lib/librustc_llvm-9026086f.so (gdb) disassemble Dump of assembler code for function _ZN4llvm3sys11MemoryFenceEv: =&gt; 0xb4db18f0 &lt;+0&gt;: mfence 0xb4db18f3 &lt;+3&gt;: ret End of assembler dump. (gdb) `mfence` is an SSE2 instruction.
Holy crap. How have I never seen this before. Definitely checking it out!
While I like the existing Cargo logo, especially the notion of shipping packages, I wanted to see something a little more "Rust-y". Here's the first concept I came up with just for fun :) If you have any Rust-related concept art, I'd love to see it!
Thanks for the suggestions. Looking at those, though, I feel completely lost. I guess I need a good "starter project" where I can get beyond the basic syntax stuff but not head-on into trying to dissect a large project. :(
I have a question about Graphene. Is this conceptually the same thing as an [Electron (Atom)](http://electron.atom.io/)? Can we build some cross-platform native apps using Graphene, (e.g. a billionth programmers' IDE, other apps)? Thanks!
The announced alpha release is in June, not now. For now, it's source builds only. At the time of the alpha, I expect the servo project will start releasing pre-built binaries. I don't know if it will be packaged for Debian/Ubuntu at that point; while Rust and Cargo are now packaged for Debian, there are still some issues to work out about packaging crates and so on. It may take some time before Servo actually gets packaged up.
Ah, interesting. My glyph cache has a slightly different scope. Yours looks good for when the glyph set is small and known ahead of time, and runtime cost should be minimised. Using skyline also produces good packing. Mine is aiming to be a system for dynamically caching recently used glyphs in GPU memory. Due to its dynamic nature (insertion/removal), the packing scheme is not as efficient in space, and there's a (hopefully small) runtime CPU overhead for cache management. You can actually see the current state of it (and example usage) on master in the RustType repo. It's not published to crates.io yet.
For `rustc`, there's a codegen option called `target_cpu`. I'm not sure on how to pass it to ./configure correctly, but I've used it like this successfully: `rustc -C target_cpu=i586 something.rs` Perhaps try `./configure --target_cpu=i586 ...`
Nope, I hadn't found that in my searches, as is typical unfortunately. Information on cross-bootstrapping (and bootstrapping in general) is spread all over the place in little bits and fragments (and sometimes just commit messages) and it's hard to get a good understanding of things. Thanks for linking me to it. I've got a few questions about your post, if you don't mind: 1. Why does the i686 target spec need to be modified when you're using the i586 one in the argument to `configure`? 2. Why `--target` instead of `--host` or `--build`? I'm having a hard time understanding what exactly the differences between these flags are. 3. re: "Just be careful about CFLAGS present in your environment." What should these be set to? `-m32 -mcpu=pentium`? Nice to see someone else working on this problem. Thanks!
`--target_cpu` isn't a valid `configure` flag. In any case, it looks like the problem isn't with rust-generated code, but the outputs from GCC and LLVM that are used in the rustc build.
&gt; rustc -C target_cpu=i586 ... It's `-C target-cpu` and that would only work for the rust part via: `RUSTFLAGS='-C target-cpu=i586'` but the rust part is completely fine. 
That's good to know. I hadn't realized it wasn't even alpha yet. With all the various installs I've got, I really should start rolling my own packages for source builds anyway.
One thing you can do in order to get the alignment padding right is something like: #[repr(C)] pub struct Foo { x: u16, _y_align: [c_int; 0], y: [u8; 4], } or perhaps something like #[repr(C)] pub struct Align&lt;A, T&gt; { alignment: [A; 0], value: T, } #[repr(C)] pub struct Foo { x: u16, y: Align&lt;c_int, [u8; 4]&gt;, }
As a Uni student who alternates writing Rust (I chose the language for use in my honours project), Java, and C# for one of my units. This is the issue I identify with the most.
The Nomicon is quite clear that transmuting `&amp;T` to an `&amp;mut T` [is taboo](https://doc.rust-lang.org/nomicon/transmutes.html). I don't actually see what on the [list of UBs](https://doc.rust-lang.org/reference.html#behavior-considered-undefined) it's violating on its own though. That list is pretty clear that *mutating* the value would be UB, but maybe accessing it is fine? I'm wondering about this because going from `*const T` to `*mut T` can be done with just an `as`. (`&amp;T as *mut T` doesn't work, but `&amp;T as *const T as *mut T` does! No transitivity for you!) Since going from `&amp;` to `*mut` is considered safe, I'm assuming the UB only comes into play when the value is actually mutated, which would have to be in an `unsafe {}`. The reason I'm asking this is that the Rust SDL bindings [actually do this](https://github.com/AngryLawyer/rust-sdl2/blob/master/src/sdl2/surface.rs#L192), although it does it unsafely with a direct transmute instead of using a "safe" `as` chain like I describe. Still, it's creating a `*mut` from `&amp;` and, I'm guessing, just trusting the other side of the FFI not to mutate it even though the C API doesn't declare it const. Is this a thing I should be freaking out about, or is this all playing by the rules? (Fun side note: you can get an `&amp;mut T` through something evil like `&amp;mut unsafe {* (&amp;x as *const u8 as *mut u8) }` which is unsafe but doesn't `transmute`, so perhaps the Nomicon's warning, dire though it is, is still insufficient!)
OK, I'll give that a try. I didn't mess with CFLAGS at all, so it was probably just inheriting what I had in there by default, which was `-march=x86_64 -mtune=generic ...`. Configure obviously overrode the `-march` flag, but I suppose `-mtune=generic` snuck through and maybe caused it to generate SSE2 instructions? Anyway, I'll try using more appropriate CFLAGS, and I'll try teaching configure to use them also. And you're right, `--host=i586...` is definitely wrong. I just tried it, and 2.5 hours later I have a nice shiny new.... x86_64 rustc. :) Thanks for the help.
This is more or less exactly the logo I envisioned for Cargo years ago, except unlike me you actually have artistic talent. :P
Too bad it isn't open source :(
 larger_struct foo; /* there will always be sizeof(larger_struct) space here */ /* create pointer to base struct, cast to a larger structure, and dereference. the data after sizeof(base_struct) will be whatever data that was after base_struct in the stack or heap */ foo = *(larger_struct*) &amp;base_struct; Generally it's the other way around, but this code isn't unsafe (although the data after `base_struct`, if the memory location for it did not point to an allocation of data large enough, would be undefined garbage). Typically you wouldn't be copying structures around anyway, and just casting the structure pointers to their larger counterparts if there's some indicator/flag that the original structure is only of a portion (base) of the relevant data. Strict aliasing rules start to interfere with your code if you use _multiple pointers_ to `base_struct` as different types interchangeably in your code. This example actually copies `base_struct` into foo, with some extra garbage (or maybe not -- the programmer could have known the data after `&amp;base_struct`). And if I were casting pointers around instead, all I have to do is make sure the following operations make use of only one pointer to the same memory location, or carefully make use of both (within the same memory barrier, one should be used), to make sure pointer aliasing rules don't screw up my code due to compiler reordering.
I don't know about other people, but when I see a shipping create I usually associate it with docker.
https://doc.rust-lang.org/book/enums.html has some more explanations about `enum` where variants have data associated to them.
This is awesome! I'd love to see this as a footer logo on crates.io.
Nice! About your 8-point plan: - nos. 1&amp;2 are not necessary; your x86_64 host should be downloading the corresponding x86_64 snapshot that includes the i586 target. - you can speed up #5 even further (getting slightly less optimized code) by going: `RUSTFLAGS='-C codegen-units=&lt;num_cpus&gt;' make -j...` And finally, here are my generic i686 stage0 [snapshots]( https://www.dropbox.com/sh/9ga4a7df1nafuc2/AABSiVQwwpyXa2Ellm0Ihgwxa?dl=0) in case you wanted to try bootstrapping Rust natively.
Great idea. I will play around with this.
Thanks for the heads up, should be fixed now. Yeah I think I know what you mean re: integration with bindings. I considered using it with our `rust-portaudio` and `coreaudio-rs` crates too, however I think bindings have the burden of having to remain at least a bit familiar to the original libraries. I found this to be tricky as `sample` is quite heavily type/trait-oriented, while most audio IO libs re written in C (not sure if this is the same thing you ran into though!). I've been thinking that perhaps it would be more suitable as a nice starting point for developing a purely Rust portable audio IO lib from the ground-up - something that has no strings attached. This would require an epic effort though, at least to reach something as useful and portable as ALSA or PortAudio (I think even CPAL is barely scratching the surface here yet).
Nice! `sample` doesn't have an implementation of anything like PSOLA built in, but yes, it should make a nice starting point for implementing it yourself.
&gt; /r/playrust jesus christ i am a fucking idiot. thank you for letting me know. 
This subreddit should just copy the logo of Rust the game, to make the poor gamers that accidentally end up here even more confused.
I like Servo, but can we *please* stop trying to crowbar a browser into *absolutely everything*, irrespective of whether or not it makes any damn sense?
You can get pass timing with `-Z time-passes`. In the graph, type checking corresponds to "item-bodies checking" and translation to "translation". So type checking does not include borrow checking, for example. Distributions of build time differ from crate to crate. For docopt (which takes longest to build here), of total ~16 seconds, ~8 seconds(~50%) are in LLVM, ~6 seconds(~40%) are in type checking and translation, ~2 seconds(~10%) are in other passes.
Thanks :)
awesome, glad to see I'm heading in the right direction :)
perfect! thanks.
Is there a way to use Rust enums with C unions? 
Crossbeam is intended to be a low-level library that higher level abstractions are built on. As such, it doesn't do any kind of management of the number of threads spawned. I'd recommend using one of those higher-level libraries that either builds on crossbeam, or implements slightly different abstractions. Two good examples would be [rayon](https://github.com/nikomatsakis/rayon) or [scoped-pool](https://github.com/reem/rust-scoped-pool).
AFAIK there are some attributes that rustc hands to LLVM related to the potential aliasability of &amp;-references, so it can make code like fn a_thing(a: &amp;mut i32, b: &amp;mut i32) { *a += *b; *a += *b; } compile down to fn a_thing(a: &amp;mut i32, b: &amp;mut i32) { *a += 2 * *b; } , even though those give different results for `a_thing(&amp;mut x, &amp;mut x)`.
This looks like exactly what I was looking for. Thank you!
You've pretty much described a threadpool, which there are already crates for (linked in other posts here).
Its relative to the initial value, so the earliest compilation for each crate is 100% and every other one is a percentage of that.
Thank you :)
To be fair, a browser has solved a lot of the "text layout and presentation" problems that people face, so it's a place people immediately think of when they need to do those things. Not that it's the right choice, but shipping a "bad idea" working product is a lot better than building your ivory tower for ten years and getting left behind.
naaah. I'm very aware of the limitations in the above system. I'm just wondering if the reduced problem space would confer a higher accuracy.
I see. Really cool to have these long term performance graphs.
I'm not familiar with ?, can you give me an example and explanation of what it is?
Whilst I am generally curmudgeonly about using browsers in everything, in this specific case it makes sense. Graphene is supposed to be Servo's version of Electron, and Atom was one of the first use cases for Electron (IIRC). It's an explicit goal to support application development in Graphene. I wasn't very happy with Atom when it came out. I expected that an editor using browser technology would be slow, and I was right. It's gotten much better now (still, I'm not leaving Sublime/Vim anytime soon) though. Specifically for editors, a browser backend isn't that bad an idea. You want it to be scriptable anyway, so it's nice if it's written in the same scripting language. The diversity of control over layout in HTML is not something you can find in most (any?) UI toolkits either (which is why lots of folks are using webviews for browser dev these days).
I can speak to that. We used to use `;` in structs, just like C, but the inconsistency with `enums` felt very annoying, and we switched to commas. Meanwhile traits had only `fn` items and so they used `;`. Basically, the content of traits generally maps to modules, and hence `;` and `{`...`}` are used to terminate them, whereas the contents of structs/enums uses `,`. But of course this RFC straddles the line between them. Perhaps in retrospect it would have been better to use `;` everything (even in `enums`)? I think `,` everywhere would not feel "C-like". Anyway, water under the bridge at this point. 
If you are willing to use nightly, you can use the `Fn` traits to express allocating use cases. Basically you would use `x(3)` instead of `x[3]`. I actually see this as preferable, since it tells your reader what is happening -- in other words, `x[3]` remains an "lvalue" -- that is, an expression that references some pre-existing memory, which can then be assigned to etc. (Consider that e.g. `x[3] = foo` makes no sense if you are allocating a fresh location to return.) That said, as others have commented, I do expect we'll make some progress here, even if it is only to make the `Fn` traits stable to implement (eventually).
I think it would be very fitting logo for [this Docker rust builder project](https://www.reddit.com/r/rust/comments/4aq5bm/a_container_to_generate_static_rust_executables/) 
I added an issue to [clippy](https://github.com/Manishearth/rust-clippy), we can develop a lint against this there and perhaps move it into rustc later if the team wants it.
Does this mean all those things that are blocked on MIR might start to see some forward progress?
I don't think so. The boolean target function stays the same: tests pass successfully or not. Rust detects many errors at compile time that would only occur at run time in a C++ program. That doesn't make it easier to generate correct code, but it could speed up each run and the code that correctly passed the tests will probably have less bugs.
How does that API look?
That stuff has had work going on for a while now. It's just slow going, this is a cool step, but won't affect any "blocked on MIR" work. 
Yeah that is unfortunate. Neither serde or rustc-serialize really handle arbitrary precision numbers, but they do at least support also serializing to u64 and i64 to avoid Some loss of precision. 
Also relevant: https://github.com/rust-lang/rust/pull/32345 and https://github.com/rust-lang/rust-buildbot/issues/82. You can start trying out `cargo rustc -- -Z orbit` in a few hours, when a new nightly finishes building. Not sure if `RUSTFLAGS="-Z orbit"` works yet in nightly cargo, but it should soon anyway. Please report any LLVM assertions you stumble upon (the known issues only involve runtime behavior, as far as I'm aware, everything should still compile). You *might* get some speedups from turning MIR trans on, but it's not significantly faster when bootstrapping, and LLVM takes longer there, because statically scheduled drops and stack flags are not implemented at all for MIR (/u/pnkfelix is actively working on that).
thanks for the info, I've literally been working with rust for a week I think? I still have a lot to pick up :)
thanks for the info!
Just bear in mind that it won't be in stable for a couple months. 
Cool, as I clean up vox_box and implement a few new things I'll look into it. It'd be great to get a tutorial going on writing a SuperCollider UGen using Sample. I think that's the missing library that will make things really easy, especially now with no_std and no dynamic allocations.
IIRC graphene is supposed to be electron-compatible. I'm not sure of the details though.
Thanks, your solution works. 
This is a big refactor of the internals of the Rust compiler. On its own, it doesn't mean that much; it's mostly an internal detail of how the compiler is organized. However, this particular refactor is seen as being quite helpful in implementing several highly desired features. So once it's done, and the compiler can switch over to this model completely, it should unblock several other features. I don't know everything that is waiting on MIR, but I believe that a few things that are waiting for it are [removal of drop flags from objects](https://github.com/rust-lang/rfcs/blob/master/text/0320-nonzeroing-dynamic-drop.md), [non-lexical borrows](https://github.com/rust-lang/rfcs/issues/811), and [higher kinded types](https://github.com/rust-lang/rfcs/issues/324). I think those things are ordered by how soon they are likely to happen; removal of drop flags already has an accepted RFC, it's just the implementation waiting on MIR landing before going in. Non-lexical borrows are, I believe, a relatively easy to specify feature, but would be hard to implement without MIR, so while they don't yet have an RFC, I don't think it would be a very big project to write one up. Higher kinded types are something that lots of people want and would allow a lot of new abstractions, but it will take some serious design work to fit them into Rust's type system, so may still be a good ways off. Of course, I'm not on the language or compiler teams so I may be wrong about the exact order and difficulty of the above mentioned features, but the main point is that a lot of desired new features will be easier to implement once MIR is fully production ready.
I have made good experience with both RustDT (Eclipse-based) and Atom.
Seconded. This is hugely valuable work, major thanks!
I was under the impression that MIR was one of the most important potentially-reusable workproducts, according to https://github.com/rust-lang/rfcs/blob/master/text/1298-incremental-compilation.md#high-level-design .
[**@jperkin**](https://twitter.com/jperkin): &gt;[2016-03-08 09:15:26 UTC](https://twitter.com/jperkin/status/707132609969725441) &gt;Ok, rust\-1.8.0pre1 package now available in SmartOS 2015Q4/x86\_64 repository for people to play with. Let me know of any issues! Enjoy. ---- [^[Mistake?]](/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=/4b4ds7%0A%0APlease leave above link unaltered.) [^[Suggestion]](/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/joealcorn/TweetPoster) [^[Issues]](https://github.com/joealcorn/TweetPoster/issues) 
Thanks for correcting me, that was my understanding.
Right. While I'm skeptical that high performance statics are necessary (why? because they are memory mapped from the data segement?) anything with overhead isn't a universal replacement.
SIMD to C++ level isn't a very high bar I have to say. All I've seen has been intrinsics and libraries. 
&gt; P.S. Writing in Rust is hard. Either that or spending too much time in high-level/VM/Interpreter languages has spoiled me. Learning a language that's significantly different than you're used to is certainly tough at first, but it's a great way to expand your horizons a bit.
May I ask what sort of problems you were running into? Also I plan to improve the layout and commenting of the `gpu_cache` example to make it a bit clearer. For anyone else reading I'd like to note that the GPU cache isn't exclusive to glium, it's backend-agnostic, so gfx or anything else with support for 2D textures should work fine.
Thanks to both you and /u/erickt for answering that question. I'm really excited for MIR in general.
&gt; Now with dynamic GPU font caching! That's for rendering the glyphs into a rasterized font atlas, right? Would RustType be an appropriate code base for implementing font rendering with signed distance fields (like Valve's), or an SDF font rendering implementation would instead be a separate library that depends on your library? edit: do you use vector texture maps on RustType?
I literally spent all day Friday playing around with `freetype-rs`with a pet gpu project of mine, I'll definitely be giving this a try.
It dynamically manages a packed font atlas, yes, adding and removing glyphs as it sees fit (typically removing least recently used glyphs to make room for new glyphs). I think an SDF implementation would be better off in a separate library, especially if it ends up depending on specific graphics APIs. I figured that a dynamic cache for GUI purposes is such a fundamental use case for a font library that it should stay in-tree, at least for now. GPU rendering with RustType is just drawing texture content uploaded from the CPU. Nothing more complicated than that. Very simple and fast for many use cases. Anything more than that that depends on particular shader implementations should stay out of the RustType library. Another note about SDF - be aware of its limitations, particularly its tendency to cut off corners. A more robust (but more complicated) method is used in [Glyphy](https://github.com/behdad/glyphy).
part of the idea of the paper i mentioned is that while there are an huge number of ways to lay down some code, many of those chunks of code are invalid from a compiler point of view, restricting the space to search, test space, restricting it further, security space, and most importantly, a human usefulness space, that last one is what the probabilistic model works with. If you restrict any of those spaces further you should improve the model generation. Rust does exactly that.
I haven't seen this mentioned in this thread. Does this mean that a stable plugin API is now possible?
Clojure has taught me this.
Currently for me it is cross-platform compilation, in the sense of cross compiling for another platform. Setting up the tooling is not yet made easy, but I am under the impression that there is a reasonably long chain of dependencies waiting to make this happen (I recall multirust is/was waiting on some upstream changes to cargo, which was waiting on some other changes, etc.). Finding out about the status of certain things that Rust as a language supports yet is done kind of humorously through the registration of http://arewe[thing]yet.com domains ([example](https://areweideyet.com/)]). Is there a meta-place to find all of these domains in one place? 
1. The cognitive load. More is More philosophy. But this would be less of a problem but for.. 2. Compile time. I still find it interesting, though.
No coroutine-like async I/O abstraction.
&gt; type erasure So I should have done this with Traits? Any good resources to grok Traits? I have worked with them minimally, but most Rust code I have seen with traits confuses me. 
Would this library be appropriate for changing parameters of the graph in real time? Things like changing the volume and changing the playback speed using interpolation?
`use` takes an absolute path (whyyy?). edit: On a more serious note, though the standard library is excellently documented, the language documentation is spread out over a great many different places. Basic information is in the reference. But if you want to know even eg. what `as` does, that's in the Rustinomicon. And if you want to know about borrowck, you should look at `librustc_borrowck/borrowck/README.md`. And for the rest, perhaps you can find it in an RFC or a comment on an RFC or a blogpost. I grant, of course, that Rust is probably still moving too fast to start setting everything in stone, so perhaps nothing _should_ be done about this yet, but its a pain-point nonetheless.
There's an RFC for this, definitely on the way.
Please use arewewebyet.org/, arewewebyet.com is no longer maintained and contains massively outdated information.
As much as I like rust, there are parts that just suck: 1. Stdlib poor design. Combination of lowest-common-denominator and shielding developers from underlying os API makes it broken for many purposes: there is no wait_with_timeout on lock primitives, no connect_with_timeout on sockets, and there are already hundreds of libraries who don't provide features who require those, because library authors are not always up to the task to fix stdlib issues - nor should they be. This is fixable issue if you want to write something simple, but systemic problem if you want to write an app that uses multiple crates. Many libraries for rust suffer a lot because of that. 2. Presenting errors to users sucks. FileNotFound error ... does not inform WHICH file was not found. Got this info from a cronjob in non-trivial app? Happy debugging suckers. Again, if you would like to handle displaying this yourself - you can't "cause that would be platform-dependant". IO error is "the error" in the most of ecosystem, but most field are private, and public api provides almost nothing usable. It tries to build platform-agnostic layer on top(kind), but does it poorly. Those and some other issues come from the fact that rust authors don't write rust applications. Mostly they write libraries, (servo, rust flagship project is months if not years away from being deployed to actual users), so those issues tend to be ignored. 
For me, the most irritating thing about Rust is the fact that it is not currently possible to build a copy of the stable standard library using a stable compiler, because the standard library uses unstable features. The official reason is that the stable compiler *cannot* use unstable features, but this is strictly false; during bootstrapping, the standard library is in fact built with the very same binary that will become the final compiler. This is accomplished by providing a magic environment variable, which is detected by the compiler, which then allows unstable features. The magic value is fairly trivial to discover for a determined user (interested parties should refer to my dotfiles). This makes it very frustrating to build standard libraries for other platforms using strictly stable Rust. It also makes it impossible (without knowing the magic value) to bootstrap stable Rust with a stable stage0. I would like to see an obscure flag in the compiler that allows using unstable features needed by the standard library. It might even be an implementation detail known only to the Rust Build System, but the important thing is that it would not require any spelunking for users who want to use stable Rust to do toolchain work. Please correct me if any of the above is inaccurate; I'd be interested to know how things have progressed in this area.
Not precisely, because it doesn't work if the current scope isn't a module. But I dislike it more because it seems flagrantly arbitrary than because it causes a serious problem. (This was also a round about way of saying there isn't much I dislike about Rust; most obvious deficiencies are corrected by this-or-that RFC in progress.)
My biggest annoyance is the inability to (reasonably) return an Iterator from a function. I believe we'll see significantly more functional-oriented techniques and libraries when abstract return types land even without HKTs. For Rust mass adoption, I believe the main barrier is IDE support. Racer helps me out a lot but better autocomplete, templating out impls, automatic imports, graphical display of lifetimes, refactoring (e.g between moves and borrows), and support for playing type tetris would significantly lower the cognitive load and barrier to entry. It'll never be an easy language but I think it can compete effectively with Java/Go for general adoption.
It might be an oversight; it would certainly make sense to me that `use self::whatever` in a function would use the current module as `self`. Have you seen decisions one way or the other?
Wrong sub. You want /r/playrust.
I see Rust as becoming a new C++. Complex and expert-friendly. It has already adopted several of C++'s design philosophies.
On the `use` thing, I must admit I was first a little confused when I first started learning Rust. As for documentation, I guess it's just really, really hard to get a good balance of moving fast, community accessibility, temporal relevance (one should never be able to accidentally find out of date documentation) and quality. The Rust Book is apparently getting rewritten, but I have not checked on its status in some time. /u/steveklabnik1?
You should use generics.
If this language lives as long as C++ has, it will certainly pick up some of the legacy cruft that makes C++ have such a large list of useless features. That's not really avoidable except through extremely forward-thinking language designers (you guys are good, but not magical), or a deprecation strategy that would be hostile to many corporate or other long-lived projects. Otherwise, providing ways to opt out of language features that add complexity is good. We already have some of that in the form of `Rc` and `RefCell`.
Python is also quite far from there being only one obvious way to do something...
What kinds of things do you have in mind? We do try to stick to this principle, but of course, "thing" can be hard to pin down sometimes...
That's good to hear. What's the proposed solution? (If you have a link to the discussion, that would be great.)
Yeah, you ran straight into higher-rank trait bounds. That is definitely quite a complex thing to work on first! HRTBs are definitely one of the dark corners of Rust at the moment. They are actually heavily used everywhere (for closures), but are mostly elided due to inference. Where they tend to crop up explicitly is when you have traits with lifetime parameters, which is the case for the [`Owned`](https://github.com/dwrensha/capnproto-rust/blob/87fb27f69dc17f5818252382cb0bf097cbef06af/src/traits.rs#L52) trait you were impl'ing. Because of this, I consciously avoid parameterizing traits by lifetime parameters, but they are necessary on occasion.
There are examples like https://github.com/dpc/mioco on crates.io. A lot of this is still in development, but certainly moving in the right direction.
If anyone is curious what HRTBs are and why they're useful, I'd recommend reading either the [Rustonomicon](https://doc.rust-lang.org/nomicon/hrtb.html) or [Vladimir's excellent answer](http://stackoverflow.com/a/35595491/1830736) to a question I asked on StackOverflow.
It's mostly orthogonal, as they interact with different parts of the compiler: plugins (at least, syntax extensions) manipulate the AST (i.e. they transform AST -&gt; AST), while MIR is part of the pipeline that takes AST -&gt; machine code. The difficulties with making plugins stable are things like ensuring that we're still able to make changes to language syntax (e.g. add `impl Trait` as valid syntax for a type)/refactor the compiler/not tie alternate Rust compilers to specific implementation details, which aren't things MIR helps with at all.
Aha! Thanks for the info, having a name for the concept is great. I think the motivation and design from the [RFC](https://github.com/rust-lang/rfcs/blob/master/text/0387-higher-ranked-trait-bounds.md) may help me understand them better.
Oh, that makes sense! For some reason I thought that there was something on tracks to allow compiler plugins to work on post MIR stage, but now I see that's not how it works because MIR doesn't carry syntax information.
&gt;servo, rust flagship project is months if not years away from being deployed to actual users Scarily (or perhaps hilariously), an alpha build of Servo + Browser.html is supposed to be shipping [at the start of June](https://groups.google.com/forum/#!topic/mozilla.dev.servo/dcrNW6389g4). It'll definitely be interesting to see how Rust development changes as it gains traction in actual applications that face actual users.
At least the "wrong way" issue should disappear once specialization lands. On a related note, I find the naming of `String` and `str` pretty odd, both the fact that one is just an abbreviation of the other, and the capitalization. I guess `str` is lowercase because it's a built-in type, but there's nothing about it that actually requires this other than string literals (which ought to be extensible anyway). `StrBuf`/`Str` would have been more consistent.
That we, as a video game community, always tend to get mixed up with some weird programming language...
I don't think Rust will ever compete with Go for general adoption. Less is more really is more for the vast majority of software which is less than 10k LOC. But Go, like Rust, is not perfect and because great programmers will do great, important things with Rust it should do well in large, reliable software. With Go, you can get going so fast but I think that could lead to a fair bit of sloppy code. Rust seems like it could develop a culture of well designed code. A big downside of Go is its retention of null pointers and values, which has prompted me to take a close look at Rust and Pony.
Yes, this is possible by having the parameters that you'd like to control be `Signal`s themselves, where the value that is yielded is always the current value of the parameter. For example, a `Volume` parameter could be implemented as an `Iterator` that yields the current volume. If you wanted to scale some `signal` by some `volume` instance, you could do so via `signal.mul_amp(volume)`. The same might be done for playback speed, i.e. `signal.mul_hz(playback_speed_hz)`. I actually wrote a draft for a generic `ControlSender`/`ControlReceiver` pair the night before posting this. The `ControlReceiver` acted as a `Signal` that always yielded the latest value that was sent from the `ControlSender` (which may or may not be on a different thread). This is just like a `channel` pair, however the `ControlReceiver` always only produces the last value that was sent, rather than all values. This allows for fast, non-blocking control of parameters in the audio thread from other threads (like the GUI thread). I ended up discarding it in favour of keeping the crate minimal as there are many ways this could be implemented, so I thought it best to leave it to the user or another crate. Perhaps I should consider adding it anyway, maybe under a feature flag? Anyway, hope this helps.
I think you should slowly go through The Book ( https://doc.rust-lang.org/book/ ) making sure that you groked the basics of Rust. A pet project of some kind will help a lot, just make sure it doesn't depend on writing unsafe code. Promises (at least multithreaded version) require writing unsafe code, meaning you will need good understanding of memory management and Rust specifics (like drop semantics, Unique/Shared ptrs etc). Writing something like this as a first project is probably not a good idea. Once you've groked the basics you can proceed with The Rustonomicon ( https://doc.rust-lang.org/nomicon/ ) and learn a proper way of writing unsafe code in rust.
I don't really speak "type" parlance but what are Higher Kinded Types? Are they just monads/functors etc? They just allow stuff that goes from Stuff&lt;A&gt; =&gt; Stuff&lt;B&gt; right? How are they different from a map().collect() or similar? Everyone seems to love them, why?
`&amp;str` is a reference type, which means it's a borrow. This is generally the type you want to use for APIs (it doesn't force a heap allocation and `String`s can be cheaply converted to `&amp;str`). `&amp;str` simply points to some UTF-8 encoded buffer (this could be a `String` or a stack-allocated buffer). `String` is a heap-allocated, owned structure. These are generally easier to keep around for a long time (no need for lifetimes). However, going from a `&amp;str` to `String` has a cost of a new heap allocation. `Strings` are also more flexible as they can be mutated and resized freely. Converting from `String` to `&amp;str` can be done with let foobar: String = "Foobar".to_string(); let foo: &amp;str = &amp;*foobar; Because `&amp;str` is a reference, you would need a lifetime to keep it around: struct Sub&lt;'a&gt; { name: &amp;'a str } This is because it's ambiguous on how long the reference is actually going to live for. You could have a stack-allocated string or it could be a reference to some `String` that's heap allocated. Where as a `String` is much easier to manage because you completely own it: struct Sub { name: String }
The way I see it is that Rust has some really new, exciting concepts. It has a compelling purpose. Go, on the hand, isn't really anything new. It's just slightly better in terms of tooling and environment (AOT compiled, static binary) than dynamic languages and much lighter than the JVM. If you're writing APIs or other server software, you either hop on the JVM train, the Go train, or one of the many dynamic languages train. Right now, Go is the choice many people are making. Not because it's that much better than anything out there, it just has the right-enough combination. I think once Rust has gained some more ecosystem, it might be a compelling tool for more use cases or more people. I think it has pretty strong tooling already (one of the best package managers and dependency story, testing, documentation, benchmarking are all top notch) but the one limitation is the number of libraries out there. If you start a project in Go, you'll likely have libraries for everything you're doing. Probably not the case with Rust thus far.
The module system is complex, which increases the cognitive load for using libraries. Want to use a method? Better remember every trait the type implements and which modules they're defined in. The worst parts are `pub mod` and `pub use` tangles.
Yep, once you start treating dsp graph parameters as `Signal`s (i.e. some iterator yielding `Frame`s), you should be able to plug any `Signal` into any other `Signal`. I.e. you could modulate the modulator of a modulator modulating some other signal, etc. The only time you need to be careful is when modulating the playback rate of some `Output` created from a `Bus`. If one `Output` requests frames from a `Bus` at a totally different rate to another `Output`, the pending frame buffer will grow endlessly large (with all the frames requested by the first signal which haven't yet been collected by the second) consuming more memory over time. There is a note about this in [the docs](http://rustaudio.github.io/sample/sample/signal/trait.Signal.html#method.bus). You almost definitely wouldn't use `Bus` for FM though - I imagine `Bus` would almost exclusively be used for "send"s and "side-chaining". I'll likely need something like the control pair soon, when the time comes I'll consider adding it to the crate under a feature gate.
I look at your example there and say “of course it moves the `T`; the LHS of each argument is purely a pattern defining how it is bound inside the function, the only externally relevant part is the type which on the RHS”.
How is the module system complex? `mod` declares a module, `use` uses a type from a given path. This means that you can declare a module before using it, this means you can use a module that uses you clearly without having to deal with recursing imports problems, this means that a `use` statement cannot be creating any new information, like `mod` is. `mod` and `use` are clear distinctions between exports and declarations of modules and other types. It would not make much sense to make `use module;` create a module exactly like it would not make much sense to have `let module;` create a module. *`mod` is to `use` what `struct` or `enum` or `trait` are to `let` or `use` or `const` or `static`.* It separates creation from usage. *Note, the only other language i known is Python and only for little over a year*
One more thing, what would you think of having feature-gated adaptors that turn audio sources and sinks from other libraries (such as simplemad and cpal) into the appropriate types for use with signal? Or should those get libraries of their own?
I'd find it *more* surprising to run across a function with signature `fn(T)` that somehow magically auto-borrows its argument. The `ref` is not part of the type; it's part of how the body of the function binds to said argument.
&gt; How is the module system complex? Whether or not it is fundamentally complex, there's substantial empirical evidence that it confuses people. There's a few possible explanations, e.g.: - the module system is different to other languages in awkward ways, matching some expectations but breaking others, - the docs and the compiler errors aren't as helpful as they could be, - the module system is fundamentally complicated. I personally suspect it is some combination of the first two, since it seems that once it "clicks" for people, they no longer have troubles with it.
I think this should already be possible with very little effort. Almost all current audio IO APIs work with slices/Vecs of samples. If not, they at least provide some way of producing or consuming `Iterator`s yielding samples: The [`signal::from_interleaved_samples`](http://rustaudio.github.io/sample/sample/signal/fn.from_interleaved_samples.html) function converts an iterator yielding `Sample`s into an iterator yielding `Frame`s (aka a `Signal`). The [`slice::to_frame_slice`](http://rustaudio.github.io/sample/sample/slice/fn.to_frame_slice.html) and [`slice::to_frame_slice_mut`](http://rustaudio.github.io/sample/sample/slice/fn.to_frame_slice_mut.html) functions can cast a slice of samples (i.e. `&amp;[f32]`) to a slice of frames (i.e. `&amp;[[f32; 2]]`). This may also be done using the `conv` traits like `conv::ToFrameSlice`, etc. Also, for every function/method that convert *to* `Frame`s, there are matching functions/methods that convert back to `Sample`s.
`fn f(ref t: T) {...}` and `fn f(t: &amp;T) {...}` are two very, *very* different things. Most of the time, you don't want to use the former, but the latter.
That it feel back to the C/C++ mess of integer types. So right now you need to choose your type based on bit-width (since /u/isize is discouraged, more on this in a second) and if you need negative numbers, both of these things are problematic. Regarding bit-width, it can be very platform dependent on what provides good performance. You could be using a library that thought it was being clever in choosing i16 or i8, but on certain architectures this can really badly affect performance. So for anything that is performance critical and dependent on memory size you use i/usize. Also, the whole bit-width focused discussion breaks apart at various edge cases, such as the multiple amounts of fail in this code: let c: Vec&lt;u8&gt; = (0..0x100).collect(); Except now you have .. as i/usize littered throughout your code with no proper overflow checking, since sometimes it can be useless and sometimes it isn't, good luck easily spotting those problems. And selection based on what you might think regarding negation usually ends badly, which is why many organisations developing C/C++ usually just say to use the signed variant for most cases and not overthink it so you have flexibility. You might think choosing unsigned is the right choice, but then you want to do something like: cmp::max(x-y, y-x) and suddenly it explodes in your face. Also the whole discussion is ridiculous, as if negation is some very important property of your numerical properties. I really wish we had a simpler integer type, something like Ada's integers or maybe a bit-slower integer that does the right thing all the time and with an easier flow for casting at the boundaries (such as memory access and places where bit-width is important). I sadly think, that if rust ends up being popular, vast amounts of the security vulnerabilities in rust programs are going to be centered across this issue. It's not a simple issue, but the tooling here is not great.
It's harder to do early returns compared to other languages, resulting in lots of indentation. And, personally, [I really dislike code with too much indentation](https://i.imgur.com/BtjZedW.jpg). For example, here's an eta reduction function I wrote many moons ago [in C++](https://gist.github.com/anonymous/dac975d94e3da25acf56) and its equivalent [in Rust](https://gist.github.com/anonymous/c48070824952cf65fc22) (apart from the eta reduction counter).
The `drop(self)` function is automatically called whenever a value is dropped.
I agree, but I've found the [quick-error](https://github.com/tailhook/quick-error) crate to alleviate this pain considerably. I now use it on pretty much all my projects, it makes writing custom error types with all the bells and whistles very easy.
1. As oddly as it may sound, some aspects of the rust community: The rust community seems to suffer having a relatively large number of people whom are willing to give incorrect or inaccurate answers to questions, and do without mentioning the possibility that those answers might be incorrect. In some instances, a question will have nothing but incorrect answers that are given in an authoritative tone . I've first noticed this phenomenon on SO, but it seems that it occurs here in this sub as well. I don't know if it's a negative side effect of the rust community being too friendly and encouraging, but I've never experienced this with other languages or smaller projects. Being more harsh and strict on those who answer recklessly might be a solution to this problem, but I don't see this community adopting it given it's core values. 2. Non-authenticated packages. Transport security is not a substitute for proper cryptographic authentication. TLS was and still is not designed as robust authentication mechanism. 3. Threads can't be killed by their parents. This makes some tasks such as running a foreign function that loops in the background (or any function that does not yield intermediately and is not aware of the way it's executed) impossible using the std API. Using channels as a means to facilitate thread termination is nothing but workaround and a band-aid around the real issue. All that said, for every single sore point rust has many, many great points. I still prefer to use it whenever the situation allows.
Indeed. Like the other [Zen of Python lines](https://www.python.org/dev/peps/pep-0020/), this one is tongue-in-cheek and wide open to interpretation. (Look at the punctuation for bonus irony.)
None of these is the *worst* thing, but they are all annoying IMO: * The module system. Having to `use` ten different module items before writing code in a new module; having to write `::my_module` if `my_module` is at the root scope unless I `use` it explicitly. * Having to build all crates a project depends on when doing a clean build. Not being able to cache compiled dependencies greatly lengthens compile times. * The combination of a slim stdlib and too few 'official' crates that are guaranteed to be supported in the future. The lack of coordination makes it harder to compose small crates. * Lack of a **composable** way to do asynchronous I/O (HTTP servers are nice, but what about HTTP clients, file I/O, mixing and matching different libraries...?). No async I/O in the stdlib. * Attributes and coherence. These go hand in hand. Attributes feel bolted-on. If my struct can automatically implement Debug, then let it implement Debug! Same goes for Clone, Copy, RustcEncodable/RustcDecodable... IMO, if a trait is going to be implemented **automatically** then it should be, as needed. Coherence makes it harder/impossible to implement needed traits on a foreign type, and increases complexity by having to resort to newtypes. I think there is a better way, maybe through simpler, more powerful compile-time metaprogramming. I can see a few drawbacks to on-demand derivation: * easier to break backwards compatibility by accident. A possible solution would be to let library authors optionally derive traits explicitly, maybe add a warning if they fail to do so on types that are part of a public interface. * higher compiler complexity. This is inevitable, but if Rust's primary goal was to minimize the compiler's complexity, we wouldn't have the borrowck, would we? I find compile times OK, though. Once the dependencies are built, they aren't as bad as one may think. I have a few other gripes (regarding closures, and overall rigidity of some parts of the language), but that's all for now :)
&gt; use takes an absolute path (whyyy?). Back in the day the import paths were relative, but that caused cyclic imports to make rustc go insane. That's why they're now absolute. I agree that it feels weird though.
Yeh you make a good point. I still think Rust has (way) too much complexity but the counter to that is libraries that will encapsulate a fair amount of that complexity. I agree it will make a huge diff.
What keywords are you thinking of? I know C added "_Bool" then typedefed it in an optional header to "bool". C++ biggest offense is the "contextual keywords" that mean one thing in one place, and can be a variable in another, but that is *because* it lets them use the word they want to AND not break backwards compat.
The wrong way issue could disappear now by people just not bothering to point it out unless it truly is a bottleneck.
Why do we need to derive both Copy and Clone? What's the difference, and would you ever need to derive only one of them?
different use cases.. Rust is suitable for niches where Go doesn't work; Rust is a viable alternative to C++, Go is not.
I'm at that fresh learning stage, and this really resonates with me. I felt like I could just read "the book" linearly, but I found I had to jump around through it just to grok and earlier concept in the context of the language.
In no particular order: * Lifetime syntax, I really hate that it uses a single quote * String vs str is just really confusing/annoying at times * Compile times * Compiler errors involving macros can be really hard to debug
`Copy` types and their magic behaviour. **Certain** programs are made shorter and me readable, but a beginner can't take that program and replace a number with a more complex type, without suddenly having to deal with a different class of errors. I would prefer a little more verbosity so that copy and move semantics are clearly expressed in syntax, rather than magically applied based on type. I'll admit that I don't run into these problems very much now. But this one thing significantly held up my learning of **other, unrelated** concepts.
I don't think so. Composition is so painless in Rust that inheritance will look clumsy in contrast.
When killing a thread, how do you ensure that destructors run? At the very least I would expect such a kill to leak memory and resources such as file handles. What you suggest can be done in a garbage collected language (and even there I expect it to be problematic) but I suspect it will never be even remotely safe in rust. 
You're obviously not Dutch. :-P
Way back moving and copying used to be explicit. It wasn't nice at all :-)
Having mostly lurked around Rust since I stumbled upon it 2-3 years ago, my concerns are less detailed than some of the other responses here. First of all, I feel the lack of tooling is making it hard to justify a switch to Rust for someone who's used to that kind of stuff, and it worries me when I don't see a more focused effort on this from the community, or Mozilla for that matter. I would absolutely love to see some first-class support from some established IDE like Visual Studio, IntelliJ or Eclipse, or at least get some corporate backing going for some of the plugins for those IDEs. Secondly, and I realize this might be petty and controversial (and absolutely not something that can be fixed at this point), but I am not a fan of some of the naming conventions that Rust went with. C++ has a long tradition of being a patchwork of naming conventions, and every other library you run into will be using anything but the snake_casing that the standard library uses. Why this is I'm not entirely sure, but I personally find snake_casing noisy and at times almost unreadable compared to CamelCasing. Swift, D, Go, Nim ~~and Vala~~ are fairly recent system programming languages that all chose to use CamelCasing, and I do find them a lot more visually pleasing to look at.
Cpmplexity. Rust is a relatively complex language, especially compared to dynamic languages (e.g. Python, PHP) or GC-based languages (e.g. Java, C#). Its complexity is comparable to C++, which has similar goals as Rust. Now note that this complexity is there for good reasons. It was *necessary* to accomplish Rust's objectives: memory safety without garbage collection (which means it's super fast), or data-race freedom (which means good concurrency). So it was kinda inevitable. But still, complexity is complexity. There are many values to pursue in software engineering. If you can afford less-memory-safe programs or less-strict code, paying a high learning curve of Rust may not be the best choice for you. Especially for a company, letting its employees learn a complex new language or hiring a new developers who know a relatively obscure language is a *cost*. Keeping a deadline is much more important than writing a super fast program, for example.
Posting the new [Are we web yet?](http://www.arewewebyet.org/) as a link, in the hopes that it bumps up its rank on google (no idea how SEO works anymore).
Compile times are probably number one. Quick feedback helps a good development flow get started, and this can be hard to achieve when working with a large application that needs to be run in release mode to be usable. I expect incremental compilation can help here. Relatedly, the debug builds being crazy slow instead of a little bit slower is a bit unusual. It's hard to fit the language in your head. I need to scramble for the APIs for the different string types and the various containers. Any time I need to write a signature for something that involves closures, it's documentation time. Working with the borrow checker generally involves some trial and error. Implementing a trait for a generic type that implements some other trait might work brilliantly or run into some weird typing morass, hard to say beforehand. Annoyances: That it makes sense to write something like `let two: T = One::one() + One::one()`. That macros that produce const arrays from their variadic arguments need to generate the number for the element count for the type signature of the const array value. You can write neat iterator expression chains in-place, but you can't really throw them around and start building the sort of composability and abstractability you might get in something like Haskell, because the return type signatures would get horrible and because you probably run into some ownership horror sooner or later.
Is it possible to use it with blocking I/O interfaces such as `std::fs::File` or `hyper::Client`?
&gt; When killing a thread, how do you ensure that destructors run? ... I suspect it will never be even remotely safe in rust It's not remotely safe in any language, but because of the risk of invalidating invariants: running destructors (or not) is not a memory safety issue (e.g. [`mem::forget` is safe](https://github.com/rust-lang/rfcs/blob/master/text/1066-safe-mem-forget.md)). 
[This thread](https://www.reddit.com/r/rust/comments/4b5rfi/what_in_your_opinion_is_the_worst_thing_about_rust/), which was posted a few hours ago, contains a very good list of disadvantages of Rust.
If you're talking about lexical borrows, this is [in the process of being fixed](https://github.com/rust-lang/rfcs/issues/811), once MIR lands that is.
Not to get too deep in the weeds... &gt; You go and look at the docs and see that map returns a Map and then you go to figure out how to get an actual thing out of the map. http://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map `.map`'s docs show both common ways of "getting things out of the map": `.next()` and `.collect()`. Is there somehow I can make this more clear in the docs itself? Or rather, I'm confused why you went to http://doc.rust-lang.org/std/iter/struct.Map.html, rather than the docs that are already right there.
Very nice to know that this bug is fixed soon! =) The MIR translations sound very promising.
&gt; If my struct can automatically implement Debug, then let it implement Debug! So we actually did used to do things like this. It had problems: if you automatically implement things, you need to have some kind of opt-out syntax as well. Only having opt-in is both simpler and more straightforward: you can look at the list of things derived and you know them all. This was very apparent with `Copy`, for example. &gt; if Rust's primary goal was to minimize the compiler's complexity, we wouldn't have the borrowck, would we? There are two kinds of complexity: inherent complexity and accidental complexity. Borrowck is very much inherent complexity, but we can still try to minimize accidental complexity, and do.
This! Who cares about the performance of "Hello, World!" or FizzBuzz?
&gt; it worries me when I don't see a more focused effort on this from the community, or Mozilla for that matter. We actually have been doing a lot of work here. Maybe we need to make that more public somehow...
&gt; a deprecation strategy that would be hostile to many corporate or other long-lived projects. If deprecation becomes necessary, I am hoping that the fact that the compiler libraries can be embedded in other programs can be leveraged to create migration tools, much like Go does.
&gt; Being more harsh and strict on those who answer recklessly might be a solution to this problem, but I don't see this community adopting it given it's core values. There's no need to be harsh or strict, however I certainly hope that incorrect answers will be pointed out as incorrect by anyone realizing it!
It's never been a problem for me yet, however your experience worries me. I wonder how many beginners stumble on this and give up and what we could do to help you (and them) overcome this obstacle.
The most misunderstood point of Rust. It's been heavily communicated, but years of habits are not so easily overcome.
&gt; If my struct can automatically implement Debug, then let it implement Debug! You are forgetting the "explicit is better than implicit" and "you don't pay for what you don't use" core tenets of Rust. That being said, I agree that I wish it was possible to "break" the coherence rules sometimes; and I do think I remember /u/nikomatsakis writing about this recently so there may be hope here. Creating a type wrapper certainly is a solution, but it is annoying.
Personally, I like the absolute path. I find that it makes refactoring easy: - I can move a `use` directive from one file to another, at a different depth/path, without issue - I can "fix" the `use` directives after moving their target with a simple `sed`
It's not even Rust-specific! Oh well...
All things that are Copy are Clone, but not all things that are Clone are Copy. Copy: "a memcpy can copy this" Clone: "arbitrary code must run to duplicate this."
&gt; Or rather, I'm confused why you went to http://doc.rust-lang.org/std/iter/struct.Map.html Well, it's the first result when you type `map` in the search field in the docs, whereas "std::iter::Iterator::map" is only the 6th (the `Map` struct is also better referenced on google). Now, there's a link to the `.map` method in the description, but maybe it could be said more explicitly "If you just want to use .map(), go there". (Maybe in bold with big flashing lights.)
Yeah! Or [k-nucleotide](http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=knucleotide)? [regex-dna](http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=regexdna)? (btw. what about that error?) [fasta](http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=fasta)? Btw. sorry this is a bit trollish, but one person's benchmark is another person's antipattern.
That's not an RFC. I can only find this one: https://github.com/rust-lang/rfcs/pull/884
I'm curious what kind of work that is. Any specific GitHub issues I should maybe be keeping an eye on? I should probably emphasize the "I don't see" part more, since I'm not really actively engaged in the community, just lurking until the tooling reaches a point where I feel I wouldn't lose any of the productivity I currently have with C++.
I see a lot of comments here saying complexity, and I agree that complexity is probably the hardest thing about Rust for me as well, but I also just want to say that I would never get rid of a part of the language just because it is complex. Static analysis is not a simple topic (of course simplicity is relative to the programmer, but in general...) and I don't think Rust should be expected to be simple. I don't think it should even be a primary goal.
As Mandack correctly inferred I was talking about lexical borrows and I don't know if it is useful for the hard-working Rust-Team to issue bugs that are already known since ages. But please educate me if I am wrong! ;)
Yes, that's one of them that we're aware of. Thanks!
https://www.rust-lang.org/ides.html Is the broad overview. There's an RFC for the oracle, I don't think it's been merged just yet.
Yes, but the more features like that there are, the less likely it is to Just Work.
&gt; NaN's are horrible that's why their behavior is so weird ... At least I can add it to my list of reasons why IEEE754 is holding back mankind. Kinda offtopic, but, eh, IEEE754 has done pretty amazing things. It's not perfect, but, for one, it has resulted in fairly consistent behaviour across most devices, and I'd be willing to bet that that alone has pushed humanity much further forward than the whole rest of the standard has held it back. Also, whenever I've dug into it, I've found that all the alternatives for various edge-cases have their own special set of drawbacks... but it's definitely easy to focus on the drawbacks of the choice we use in practice since those are the ones programmers have to fight each day, not the hypothetical alternatives.
But really, if you need a language where you control when and where your memory is allocated, you can't avoid this complexity. This is first kind of complexity that is not avoidable. However, I would want to emphasize that C++ has a whole bag of different complexity, that exists because of historical reasons and the needs to keep the language backwards-compatible. In that regard, I think it is unfair to say that Rust is as complex as C++.
Copy means "can be memcopied safely". Clone means "can call `.clone()` on to make a copy of", and only happens if you actually call `.clone()`, whereas Copy is a marker trait for the compiler.
I think there are 3 categories that are often confused: 1. It is possible to do more low-level things in Rust than on other languages, therefore it is definitely more complex. 2. The different way to solve problems, mainly the resource management using ownership and the trait system makes it less familiar at the start. Does that make Rust more complex? I would argue that these sings are simply different solutions to the same problems. 3. Rust is actually _less_ complex now, because it is a minimal version of what Rust can be. You will likely miss some features which are not stabilized yet.
I dislike the rampant use of unwrap() everywhere. IMO unwrap should at least be a compiler warning, and maybe something you have to use a special compiler directive to allow. Code that can crash the program isn't safe. I think unwrap is so prevalent because error handling is kind of awkward and unintuitive, and proper error handling is rare in examples. 
That's kind of a weird thing to say. If a lot of people find a tool too complex to use, then people are going to find reasons to avoid using said tool. It seems like that'd be a bad thing for Rust, so finding ways to reduce increases in complexity as time goes on seems like a worthy cause to me. Not just worthy, but *necessary*.
Using `unwrap` is fine, it's just not a substitute for robust error handling. Elevating `unwrap` to a compiler warning on the grounds that it can crash your program would be no different than elevating indexing a `&amp;[T]` into a compiler warning (since `&amp;slice[i]` is like `slice.get(i).unwrap()`).
&gt; It is possible to do more low-level things in Rust than on other languages, therefore it is definitely more complex. From one perspective, I suppose. I find lower level code a lot easier to reason about. As I said, I write Python every day, and trying to reason about memory usage and performance is a real pain. &gt; I would argue that these sings are simply different solutions to the same problems. I would agree. I don't find lifetimes particularly complicated at all. I guess this is the closest thing I can see to 'complexity' but I mean... is it more complex than a GC? From the developer perspective, there's potentially more cognitive overhead, I suppose. But there's also a lot of cognitive overhead when trying to reason about a garbage collector, if you're in a position where you must. It always seems like one complexity is substituted for another. I think, from my perspective, the complexity of the borrow checker is really negligible compared to the complexity of higher level languages abstracting things away from me, because, when I have written rust/ python versions of projects, I've found the rust code to be much easier to write.
How is using unwrap ok? If you make a mistake it crashes your program. Re array bounds, if it was possible for the compiler to prove that my array accesses were all in bounds and safe, I'd want it to do that, especially if it was zero cost and happened at compile time. But proving array accesses are valid at compile time is kind of hard, while proving that unwrap() is not called is pretty easy. Why not enforce it? 
IIRC there are tricks with `repr(C)` and zero-length arrays to align values within structs, but I haven't tried them yet.
1. Having to type types the compiler already knows, particularly with return types. This makes it impossible to return complicated iterators without boxing, as an example. Could easily (from my perspective) be solved by allowing a `?` mark return type or something that tells the compiler to just figure it out. Alternatively this could be solved with good tooling that can infer types, combined with a slight rework so it's possible to specify all types (closures!). 2. Unecessary lifetimes must be written into structures, if I want to have a `&amp;str` in a structure it needs I need to annotate it and every structure containing it with a `&lt;'a&gt;` lifetime bound. We should do the same as we do with functions and elide them. 3. Unecessary derives, I more or less have to spam #[derive(Clone, Copy, Debug)] on 90% of structures for 'correct' behaviour, in many cases I'm lazy and don't until I need it causing future pain. These should be automatic unless opted out of (or impossible) instead of the reverse. 4. Use statements are a pain to add, we need tools like those that exist for Java that make it trivial to add use statements you need with a `ctrl-enter` or something. 5. `std` should be in the prelude, so I don't have to `use std` if I am going to need some random type in it. Also, crates should be able to add things to the prelude (mainly for traits).
The heavy syntax. Type inference helps, but there are too many braces.
I think he just means that reducing complexity for simplicity is not good if it reduces utility.
I started writing a reply about how I don't feel python is as complex as rust, but then I remembered about generators and the new async features added in 3.5 .
Yep, pretty much nailed it.
Okay, great I'll have to check it out; that solves half the problem. Still need a way to allocate a la posix_memalign() in C to reap the full benefits of the optimization. The idea for this would be that in multithreaded code you wouldn't have to needlessly dirty shared cache lines in core-private L1 and L2.
No namespace hierarchy for crates.io.
1. It's coming as Anonymised Return Types (`-&gt; impl Trait) 2. My view is that that helps in telling when a type contains a borrow, simplfying both the programmer's and the compiler's job. 3. Once upon a time `Copy` was automatically provided, but it lead to unexpected behavior, and not being able to opt out of it. 4. IDE support is slowly improving, not really a fault of the language, it's just bad because it's relatively new. 4. `::std::item::from::std` works everywhere.
1. Awesome, haven't been keeping up with RFCs 2. You're not wrong, I just don't think it's worth it. 3. I am aware, the only reason I don't think that was a huge mistake is it is backwards compatible to reimplement the old behaviour, but not the reverse. Being able to opt out of it is easy with negative trait impls. 4. Yes... the question posed did explicitly include tooling problems though... 5. Fair point, but it still is inconsistent behaviour between the main module of a crate and the other ones.
In my opinion String (for String) and StringView (for str) would be more intuitive names for this. 
Rust "feels" dramatically more complicated than C++ to me, but that's influenced by what I view as "cludgy as fuck" syntax. Rust's syntax drives me nuts, everything seems just a step too complicated.
Everything I hate about Rust qualifies as a "little issue", in the interplay between complex features. Except for one thing. The difficulty of getting a clear mental image of the semantics, guarantees, etc. For example, I still have no idea what's the deal with "object safety". Also, I *really* miss type-level integers.
I have to say that your second point touches on my biggest gripe with C++: so many things are opt-out. Like copy constructors. I think rust got it right to have things like Copy and Clone be opt-in. Instead of unexpected behavior at runtime, you get a compiler error, which is a huge win in my book. 
I'm really coaching from the benchers here, but I'd much prefer the symbol approach. Portability first!
&gt; No if you want optimal performance for your architecture, you have to select the optimal size yourself. isize is just the size of a pointer, not the optimal type for all operations. For instance, on x86_64, isize is 64 bits, but arithmetics on u32 are usually faster. If u32 was chosen for inference fallback, it is because it is the most effective type for most processors. Yeah, I know it's more complicated than that, but I didn't want to get into that. It is more complicated which makes it even less possible to "do the right thing". &gt; IMO, the rust size is really a great thing about Rust. The size of every types is obvious and you know it will not break, while porting from one architecture to another. It is most definitely better than the mess in C/C++, I just feel like it could be better. 
Nice article I enjoyed your writing style. The example let a = 1; /* immutable */ let b = &amp;mut a; /* impossible, as `a` is immutable */ let b2 = &amp;a; /* immutable variable binding to immutable borrow */ let mut c = 2; /* mutable variable binding */ let d = &amp;mut c; /* immutable variable binding to mutable borrow */ let mut e = &amp;mut c; /* mutable variable binding to mutable borrow */ may be easier to follow if you give the respective types for a, b etc. 
&gt; I'm just missing a cargo command to also download source code of dependencies. Cargo already does this automatically, you just have to look for them in ~/.cargo/registry/src/ or ~/.multirust/toolchains/&lt;toolchain&gt;/cargo/registry/src if you use multirust
Just curios, is there something about rust that you find worse in terms of rightward drift than, say c++?
Actually, `&amp;str`s (or even `Cow&lt;'a, str&gt;`s) are underused in most Rust code, especially by beginners. People think that they need a `String` when they don't. For Java programmers, I usually explain that `&amp;str` is comparable to Java's `String`, and Rust's `String` to Java's `StringBuilder`. Also string interpolation is not a good fit in a systems language, IMHO.
&gt; an "initialized byte counter", whose destructor increases the object's buffer length Rust doesn't promise anything beyond a best-effort that destructors are run, even in purely safe code.
&gt; in C++ the impossibility to use std::string is stiffling... Shouldn't we use something like `&amp;'static str` in Rust for compile time parameters?
Only serious GUI support right now seems to be gtk
Not a huge C++ programmer so not the best person to make the comparison, but `match` vs `switch` stands out - they drift about the same distance but `match` seems much more prevalent in and integral to Rust than `switch` to C++, given its emphasis on enums and patterns. Other languages w/ such a heavy emphasis on pattern matching seem to put more effort into making its use more concise.
Just to make this more clear: I like when smart stuff is about being added, but sometimes I have the feeling people just want it because other languages have it. Like the inheritance discussion. For me it should never-ever be in the core. Examples of RFCs: https://github.com/rust-lang/rfcs/pull/142 https://github.com/rust-lang/rfcs/pull/223 Thanks God it was decided against it for now: https://github.com/rust-lang/meeting-minutes/blob/master/Meeting-inheritance-2014-09-23.md
Rust definitely does not have a More Is More philosophy. The features that it has are those that are necessary for safe systems programming, and I'm struggling to think of any that could be gotten rid of without compromising that goal.
Not a complete beginner, and the documentation structure is painful and difficult. Rust really needs better API documentation and much of this is just finding a better way to lay out the information. The poor Java Doc clone doesn't fit well with how Rust is a a language.
On the subject of static binaries, it's now possible to build static rust binaries with multirust (if you're on linux). personally i'm pretty excited by this, for all the reasons people like static binaries in go. 
MIO is too high level at times and forces certain requirement on you concerning the event loop and such.
&gt; &gt; &gt; I really wish we had a simpler integer type, something like Ada's integers or maybe a bit-slower integer that does the right thing all the time Problem is, "a bit" translates to "a lot" most of the time, and that's not acceptable for languages on Rust's level. The possibility of allocation (complete with a chance of panicking) on every integer operation is enough to kill this proposal stone dead.
Unfortunately, you could not write Rust functions that concatenate two `&amp;str` together; so it would be rather limited.
A "kind" is the type of a type constructor. A basic type that takes no parameters is said to have a kind of `*`. This would include things like `i32`, `str`, or a struct type like `struct MyStruct { a: i32, b: Vec&lt;f64&gt; }`. You can use them as a type on their own. A type that takes parameters is known as a type constructor. An example would be `Vec`. On it's own, `Vec` is not a type that an object can have; to construct a concrete type, you need to supply a parameter, which is itself a type of kind `*`. For example, `Vec&lt;i32&gt;` or `Vec&lt;String&gt;`. Its kind would be written `* -&gt; *`; that is, it takes a concrete type as a parameter, and produces a concrete type as output. You can also have types that take more than one type parameter, such as `Result`; its kind would be written `(*, *) -&gt; *` (note for those coming from Haskell or reading sources based on Haskell, you might expect to see `* -&gt; * -&gt; *`, but that's because Haskell uses curried type constructors just like it uses curried functions, while Rust treats multiple arguments to functions and type constructors as tuples rather than by currying). A higher kinded type is a type constructor which can take a type constructor as an argument. Rust does not have that. With a higher kinded types, you could have a type like `Directory&lt;M: Map&gt;`, which could be applied to various types which implement a hypothetical `Map` trait; for instance, you could have `Directory&lt;HashMap&gt;` or `Directory&lt;BTreeMap&gt;`, or construct a directory from any type constructor that implements the `Map` trait. `Directory` then would have the kind `((*, *) -&gt; *) -&gt; *`; that is, it takes a type constructor that takes two arguments which are themselves concrete types and produces a concrete type, and from that `Directory` produces a concrete type. This would allow you to have types that are generic over things like collection types; where your type supplies the argument to the collection, but is able to be parameterized over the collection type itself. Another common use case for this in Rust would be being generic over pointer types. For instance, we have `Rc&lt;T&gt;` for single-threaded reference counted pointers, and `Arc&lt;T&gt;` for atomically reference counted pointers which can be shared between threads. Because `Rc&lt;T&gt;` just uses ordinary, non-atomic operations, it is more efficient in the single threaded case, while `Arc&lt;T&gt;` is necessary if you need to share objects between threads. Now let's say you have some type that will be using reference-counted pointers to manage a data structure, such as a DOM object for representing XML or HTML. You might want to allow the user to make the tradeoff between `Rc&lt;T&gt;` and `Arc&lt;T&gt;` depending on whether they would be using this in a single-threaded context or multithreaded. So you'd want a type that could be written as something like `Dom&lt;R: RefCount&gt;` where `RefCount` is a trait expressing the interface of a reference counted pointer, and then be able to construct a `Dom&lt;Rc&gt;`, `Dom&lt;Arc&gt;`, or maybe even in the future `Dom&lt;Gc&gt;` if we manage to figure out how to effectively integrate a garbage collector into Rust (in that case, the trait may need to be called something like `SharedPointer` or `SharedBox` rather than `RefCount`, but you get the idea). This can also be used for some of the very abstract type stuff that are commonly used in Haskell, like monads and functors like you refer to. But I think it's helpful to recognize that it doesn't just apply to this kind of very abstract stuff, but also fairly concrete and easy to conceptualize needs like being generic over types of containers or types of smart pointers.
Sure, but that can be its own kind of pain. Breaking out a fn for every 2-3 line match arm clutters the rest of the file, results in more total verbosity, and breaks the reader's flow by making them chase down the definition.
Yep. The formatting norms that are being adopted don't go out of their way to help here.
1- numeric type parameters (on the way, I know) 2- better macro functionality and syntax - e.g., there is no byte slice equivalent of stringify!() anymore 3- no structural inheritance (also on the way, but seems to be far off) &lt;-- very big 4- over aggressive borrow checker that fails on simple, safe code 5- confusing API documentation (slightly better than javadoc, but what isn't) 6- no good IDE - with all the info in the rlib files, should be able to do amazing things 7- inconsistent APIs - the most tripped on seems to be that pattern searching is really a mess depending on the type searched over. 8- Can't have enums of enums of ... and it do the right thing. (Useful for interfacing with open systems) 9- ASCII strings are painful and slow to deal with since you can't use str/Str unless you want to keep paying the unnecessary Unicode costs and byte slices don't make many of the ops you want 10- constants and statics are very limited in how you can initialize them 11- no way to initialize variables, such as a allocate a hash or array. Having to explicitly initialize a library gets painful when you have a dozen of them. 12- tests basically have to be in the same files or directory as the code they test making a huge mess of everything 13- strange idioms for system programming, such as calling map on Option to simply bind the value and do something to it or return null if it doesn't exist. When this is part of a chain of calls (e.g., Vec::get::map ...) it just seems wrong 14- poor networking library. MIO is to high level and forced a few design decision on you that aren't appropriate. Can't we just have Java NIO for rust? It manages to string a good balance. 15- lifetime infection. Once you need a lifetime on one struct, you need them everywhere 16- enums - really tagged unions, not enums. they can't have common fields, so I should use a struct, but really I can only have a couple kinds and some fields would be constant and... oh wait, let's try a tuple struct. Wait, maybe just a plain tuple.. 17- too much playing with types - Sometimes half my code is a serious of type conversion calls as_X.()to_Y().into_Z(). For rust having type inference, I seem to hassle with types more than any other language. If there is a zero cost path from X to Z, rust should just do it. 18- difficult error handling - can't return an error from a lamda and have it do the write thing in the enclosing function, and when you have to mix Result and Option, it gets wordy (try_unwrap!(opt, Error) or something should exist that is similar to try!, but unwraps the option or returns Err(Error) if option is None) I know I'm missing a few, but this is my current list. But Rust is still fav new language, I just see a lot of unused potential and the complexity budget getting a little out of whack.
That's fair. I mainly use C++, so to me there's not too much of a difference, though I'll agree that match is used a bit more in rust than switch is C++ (I think though in most of the cases where you have a match in rust but not a switch C++ you'd have some other construct such as a try catch etc, causing the same amount of drift)
Thank you that makes a lot of sense. I am interested to see what people would do with something like that :)
That sneaky bastard! I expected this to be cached in the dependencies folder of the current crate build. Thanks for the hint!
Yes, I agree, Java's and Rust's strings are very similar. But anyway Java's strings are easier to understand, not due to lack of borrow checker\lifetimes and explicit creating `StringBuilder`, but because there is just one string type, and *helper* for operating with strings - everything on its place. Rust has *two string types incompatible with each other*, and this is very confusing, when you try to write something more complex than "hello world". Which disadvantages with string interpolation?
Even though it is a more "complex" language than something like JavaScript or Python, I feel that development is still smooth and fast, since I spend less time worrying about nulls and guessing the parameter type of a function argument. The one thing that is a disadvantage compared to older languages is the lack of advanced IDE support, but that will come with time. When it comes, it will be a huge productivity helper.
If you have concrete thoughts here, I'd love to hear them. I'm sure it can be better but I'm not a UX person and so I don't know how.
Well supposing it is a bad thing, like I'm writing replacement software for the [Therac-25](https://en.wikipedia.org/wiki/Therac-25). In that scenario making sure that sudden program termination never happens would be a top design goal. I'd want sections of the software that could cause termination flagged just like unsafe sections are flagged in rust today, and just like with unsafe code I'd want to minimize the amount of it, and exhaustively test what can't be eliminated. I just think that most use of unwrap is plain lazy, and not a carefully considered choice. I count myself in the group that's often getting lazy and writing unwrap because I just want to get things done. Then I have to go back and rewrite my code later, or I forget about it. For the most part I guess its no big deal, but rust is a language that purports to enforce correctness. I don't see what's so radical about having to handle errors, just like I'm expected to handle all the possibilities in a match clause. 
At some point I figured out why just having `"+foo+"` be the string interpolation syntax isn't *quite* the same thing, but I can't remember what it was...
So much this. I spend so much time on documents than actually coding. Even reading the documents, I am still confused on how to implement such thing. 
Java's Strings are a lot of things, but *easy* isn't one of them. Did you know that until version 1.7b43, substrings (those created with `.substring(..)` or `.split(..)`) shared the underlying `char[]` array of the original String (can I get a "memory leak"!?)? Then there's the fact that Strings are stored as UTF-16 (at least for now, /u/shipilev recently talked about further optimizations that will probably land in Java 9), and converted on the fly during output to System.out *encoded according to some System property* that you'll hope is correct lest you get garbled output. Oh, input, too. Don't even get me started on `+` vs. `StringBuffer` vs. `StringBuilder`...
&gt;Inflexibility. Want to initialize globals before main starts? Too bad, use lazy_static! and take a big performance hit the first time you access it, and a small performance hit every time after. Wait, can't you use mutable statics if you really want?
GHC hasn't regretted it or discouraged it, interestingly, but their [experience](https://www.reddit.com/r/rust/comments/4b5rfi/what_in_your_opinion_is_the_worst_thing_about_rust/d16wm46) definitely hasn't made me want to adopt it for any language I might design myself. I wonder what makes it at least tolerable for them, and not for other languages -- it's *probably* something to do with the relatively restrained use of shared mutable state.
&gt; http://arewe[thing]yet.com domains. Is there a meta-place to find all of these domains in one place? Here: https://wiki.mozilla.org/Areweyet , though most of them are not Rust-related.
Thank you! I was able to find the documentation on my system. Excellent forethought to install it with the compiler.
I don't share this feeling -- at all -- and I'm paying my bills by programming in C++ most of the time.
Thanks! Yeah, that section was sort of done rather quickly, I'll relabel everything at some point later.
I totally agree with the "wrong" return type of map. I've been trying to implement a c# RX like lib in rust and I must admit it's really painful and hard. Things such as implementing a custom method over an iterator that reuse map for instance is not easy because the return type cannot be infered, we must deduce the correct type. If we use dynamic dispatch instead, we sacrifice the performance.
Missing line numbers. I have to jump through a lot of hoops to implement a simple "GOTO 10". And while we're at it, would it have been so hard for Rust to require a '$' after variable names referring strings? There's a reason why it's the gold standard.
&gt; Or rather, I'm confused why you went to _ This happens to me. Used to happen a lot, actually. I'd end up on a doc page that seemed relevant but was missing X or Y information. I've had at least a few of my IRC questions answered simply by pointing me to the right docs.
Yeah, I mean, I still have a ton of work to do on parts of the API docs, for sure. But these ones in particular are ones I've already spent a ton of time on.
`nullptr`, `reinterpret_cast`, `static_assert`, `thread_local`, etc... The `reinterpret_cast` is particularly irritating, because it's just a C-style cast. You could make an argument that its length is good because its use is a code smell, but you can still just do the C-style cast and circumvent all of that.
Destructors run if the program runs normally, if the user tries to interfere with these destructors running, it will only mean that less bytes are marked as initialized. I think that's safe.
Before Rust, all of the languages and frameworks I had been using were CamelCase (Qt and Haskell), and I initially found Rust's mixed usage of `CamelCaseType`s and `snake_case_function`s to be faintly bizarre... but it didn't *strongly* bother me, and I got used to it very quickly. I only mention this because it wouldn't surprise me if this were, in fact, *most* peoples' reaction upon first encountering Rust, both those coming from camel case, and those from snake case languages. I kinda suspect Rust's choice to use camel case for type-level things and snake case for value-level things might have actually been subtly brilliant. There has been a *conspicuous* absence of people expressing discontent with it, from either camp. In over two years I'm not sure if this hasn't been the first actual complaint about it I've seen! (It probably hasn't, but I also can't remember any others.) My hypothesis is that this is because CamelCase people feel most strongly about it being inappropriate to use snake_case for types, and snake_case people feel most strongly about it being inappropriate to use camelCase for functions, so Rust's chimera case adeptly avoids triggering *both* of their potential strongest negative reactions.
I actually like `extern` but I don't see it as meaning 'external' per se, but instead consider it to be its own word in programming jargon.
http://github.com/mystor/slag
&gt; Rust's lack of support for C++ makes this hit a lot harder. There's a huge chunk of game devs who I can't imagine will ever switch to rust, because they can't keep using the libraries they know so well (and because they have to wait for replacements to come to rust!) If someone puts in the work, they can make or use a C binding to the C++ library, and build a Rust binding off of that. Many of the language concepts are 1-to-1 correspondences, like replacing `~Class` with `impl Drop for Class`. &gt; The lack of labeled/optional arguments really makes me sad. The main argument I hear against this is that it makes the names of parameters part of the public interface, so renaming them becomes a breaking change. So at the very least, I'd like named parameters to be something that the library designer has to opt-in to.
&gt; let words = s.split_whitespace().map(String::from).collect::&lt;Vec&lt;_&gt;&gt;(); It is still as "verbose" but I find it more readable to write it like this: let words: Vec&lt;_&gt; = s.split_whitespace().map(String::from).collect(); Wrapping it on multiple lines helps for readability too. I don't necessarily agree with you that this verbosity is a big pain-point of Rust. Rust without type inference would be unnecessarily verbose, but having to write a couple of extra function calls to get full control of what is happening behind the curtains is an advantage IMO not a drawback. It seems people really care about their keystrokes as if their keyboard had a maximum number of key-presses before it died.. I personally spend way more time thinking about what to code and how to code it well, than the actual typing part, a few more function calls are not going to make that big of a difference. Their purpose is clear, the code is readable and I have full control if I need it. I do agree though that it could be more intimidating for beginners and that they could get lost more easily. 
Anyone has any idea about this? ~ http://stackoverflow.com/questions/36105579/exposing-a-c-symbol-containing-an-array-of-strings-from-rust-to-c
&gt; Why do we need to derive both Copy and Clone? What's the difference `Clone` is a generalization of `Copy`. `Copy` is about a special kind of duplicating things. A type that is `Copy` basically promises to be OK with copying its raw bits and bytes. If this applies to your type, you should mark it as such because then you get to use it in places that require this property, for example `Cell&lt;T&gt;`. For other types, copying the raw bits and bytes is not an option. It would break their invariants. For example, a `Vec&lt;T&gt;` maintains that it's the sole owner of the elements it internally points to. Copying the raw bytes of the Vec to another memory location would break this. Still, it makes sense to make a logical copy of a vector. The "copy" just needs to get its own memory block. This is what `Clone` is for. Types that are `Clone` support the creation of duplicates as well. But it's not necessarily as cheap as `Copy`. Some user-defined code is executed to "do a correct copy". So, in a sense, `Clone` is a similar constraint but much weaker than `Copy` in that it allows arbitrary code to run to create the duplicate. If a value of some type can be duplicated by copying the raw bytes it sure as hell can be duplicated by running user-defined code: fn clone(&amp;self) -&gt; Self { *self } // clone by copy :-) So, it makes a lot of sense to derive both, Copy and Clone in such cases because then you get to use your type in places that require `Clone`. &gt; and would you ever need to derive only one of them? From what I can tell, it makes little sense to only derive `Copy`. If `Copy` is applicable, you should derive `Clone` as well. `Copy` and `Clone` should form a subset relation with all `Copy` types being a subset of all `Clone` types. This means, there are types that are only `Clone`. Example: #[derive(Clone)] struct Foo { x: Vec&lt;i32&gt;, } In this case, only `#derive(Clone)` works because `Vec&lt;i32&gt;` is not `Copy` but for `Foo` to be `Copy` you need all members to be `Copy`.
There are also other languages which share our conventions. Ruby, for example, puts class names in CamelCase but methods in snake_case, and constants in SCREAMING_SNAKE_CASE. IIRC Python is similar?
Actually, my point about Java's `ConcurrentModificationException` is that you can have "data races" even in a single thread :) It's a really easy mistake to make, especially in an imbroglio of `Observer` and other abstract callbacks.
These sentences seem to contradict each other... the standard library is big, but you haven't had this problem with other massive ones?
Using complicated, hard-to-predict algorithms to infer types, instead of the language-level Hungarian notation. (I, J, K at the beginning mean integer, everything else is real, is the common rule) Also, Rust's return and assignment syntaxes are different. Why is it so inconsistent?
Cheeky bastard. Have a +1. 
If you're coming from GHC, think of object safety as whether you can use the trait together with `data Object trait = forall object. trait object =&gt; Object object` (using `ConstraintKinds` and `ExistentialQuantification`), write `instance MyTrait (Object MyTrait)` in the obvious way, and have all of the methods type-check. (It has nothing to do with type- or memory safety, in particular. Rust tends to avoid using the word "safety" for other things besides that, but for some reason this is an exception.)
I don't think I could choose a single "worst" thing, but the two which come to mind at the moment, which I run into often and *most bother* me are: 1. Panics with unwinding. I totally understand why we have them and what they're important for (Servo, Ruby, robust concurrent applications in general). At the same time, the number of places where they cause major complexity or find us saying "ah, that'd be nice to have, but we can't because unwinding" is amazing. I'm not sure most people really appreciate the costs in terms of language design, because there's not one big drawback, but many smaller and medium-sized ones all over the place. The costs are diffuse, but huge in the aggregate. 2. `unwrap()`. It should've been called `assert()`! It's such a better name! It was such an inspired idea and I will mourn it forever.
Oh... That sounds awful. Good old Java... 
I don't disagree! Just wanted to point the finger at the most likely culprit for their confusion.
Well, let's be fair. You're actually lucky in Java. In C++, you can get anything from an infinite loop to a crash or memory corruption when modifying a collection you're iterating upon :/
Other than the big pain points to which other people have already referred (abstract return types, etc), my biggest gripe right now is how unstable library features are handled. As an example, I was recently trying to use Any, was running into some issues, and ran into a case where I needed to specify Reflect as a type constraint while trying to track it down. (Because I am trying to keep rust development instability separate from my own unfamiliarity with the language, I am using the stable build.) This means that I can't even *test* whether or not I was going down a dead end with that implementation, or whether or not this is due to my own inexperience, since using Reflect would require switching to a nightly build. In my view, this would be roughly similar to saying that you need to switch to a different operating system to diagnose whether or not your network card is failing due to a hardware problem or a driver issue. I understand the motivation for making it an error, but making the user of your compiler completely unable to explore the problem space because of a **staging** issue instead of a technical problem is infuriating. It's like you're saying "Come back and try to use our language again in 6 months. Maybe we will have figured it out by then. Unless you want to use FnBox or something else we don't have a good roadmap for stabilizing." Ultimately, I had to re-implement Any, Reflect, **and** implement an unsafe representation of fat pointers in order to get what I wanted, leaving me with a bad impression of the attitude toward run-time type handling. To add insult to injury, the results are much worse. My version of Reflect can't be auto-implemented, for example. I am now unable to use a *stable* portion of the standard library &amp; compiler because of the unstable portion being behind a feature gate. Please, please, please reconsider your position on not allowing the use of unstable features on stable rust. The standard library has too many features that are unstable, and have continued to be unstable for a long time. There *must* be a way for users to opt-in to unstable library features without also opting in to an unstable compiler.
Performance (particularly latency) vs GC'd languages. Obviously performant GC'd languages would be more interesting (like F# or C# running on .NET). And benchmarks with more emphasis on allocation and collection would be more interesting. For example, there are a bunch of benchmarks by Kostya [here](https://github.com/kostya/benchmarks). Brainfuck is just dispatch on bytes with no real memory management (just a stack), no optimisation passes and no compilation so it is quite dull. Base64 is the same but with no opportunity for compilation. Json is perhaps the most interesting benchmark. Matmul is a naive cache-unaware matrix-matrix multiply with no memory management to speak of and nothing interesting like recursive subdivision, genericity over element type or even parallelism. Havlak is Google's "loop recognition" benchmark which has a badly flawed methodology and there is no Rust solution (and the F# solution that beat all others isn't there either). There are a few other Rust benchmarks out there but that's the best I've found. 
You probably meant to post to /r/playrust, /r/rust is about a programming language :)
&gt; Is this nonlexical borrows or something else? That and the reborrow problem, I think it what it is called. I've just had problems where things like a x.f(x.g()) causes issues and I had to introduce temporaries to get it to compile.. &gt; inconsistent APIs This was recently when I was trying to parse some data from the wire where methods on str weren't also there for byte slices so I basically had to reimplement them (e.g., find) &gt; Can't have enums of enums of About six months ago I made an interface to another language and database. The language had atomic types (a lot of them) and derived types (such as list, dictionary, table -- dict of dicts -- etc...). Some of these derived types were generic (can hold anything) and some where each element had the same atomic type (like a list of anything versus a list of ints). I wanted to have an enum of enum of enum... to model this, but the enum tag at each level would take up extra space even though the tags were disjoint. It was mostly to be able to use the same enum in different contexts. It would have been possible for rust to only use a single tag to represent the tags for everything. I can dig up the code to give you a better understanding actually. I went over the possibilities on #rust and we really couldn't come up with a good way of doing it. &gt; MIO is to high level It is in some ways and isn't in other ways. It basically forces you to use its event loop when you use its non-blocking sockets. I write a lot of high performance networking code and its event loop isn't very good for what I want to do (e.g, I want to handle timers differently, I want call backs from the event loop thread that aren't time based, I need finer granularity on the timers, I have some specific threading requirements for sharing work, etc...). Exposing the non-blocking sockets and the selector/multiplexing mechanism separately and allowing me to build my own event loop, similar to how Java NIO lets you, would be much more preferable. I basically rewrote part of it myself for what I wanted. This was almost a year ago though, so it might have changed by now. &gt; difficult error handling A few days ago I was bitten by having to sanity check some structures and return an Err to the calling function is something isn't right. I had to write a bunch of hand coded traversals that would properly short circuit the check when it found a problem. I coudn't just use map/for_each or whatever since I can't "return" from them and have that Err propagated up like an exception will. I don't mind the lack of exceptions, but my code was filled with try! and a lot of very similar traversal loops . I guess what I really needed was some sort of short circuiting iterator that mapped or folded as I needed, but bailed and returned an Err when it hit an issue. I didn't want to have the sanity checks their own loops but wanted to do it as I processed the buffer for performance reasons (it cut about 30% of my time off). These are probably really small cases and often because I'm dealing in nanos here (my routine to parse a FIX protocol message is a little over a micro now, but I would like to cut it in half. 
Ah yeah that's a pretty important exception.
Its been a couple of months since I last played with rust, does ref mean that T needs to be a reference type and the second example takes a type T as an immutable reference?
So if I define a recursive type using Box or Cell or what have you, I can forego defining a Drop instance for that type and not worry about memory leaks?
Almost. If you get cycles, you must break them with weak references.
Consider we have something like this: let x: String = `interpolation {variable}`; // ^ sugar for format!("interpolation {}", variable) what disadvantages?
&gt;Huh, I've never heard this criticism of Rust's numerics before... only praise for removing the confusion/pain of short/int/long and their lack of definite sizes in C and C++. Let me preface by saying that I love rust, and the think what we have in rust is an improvement from the mess we had in C/C++. I wrote the previous post as a bit of a rant while on jet-lag, so it may have come off too hard and incoherent. I'll try to elaborate on the points. BTW, I realized that used clamp to mean saturate in this post. &gt;Hmm, this sentence seems like a good guideline with or without "performance critical", but it sounds like you're phrasing it as a bad thing? That is, if you have an integer that is someway dependent on memory size, _size is the right choice. Well, from what I felt from the community, the discussion was pretty much that _size is discouraged as a generic integer and was specifically called that to make sure people used the more specific integral type and used _size purely for memory access. &gt; This seems hyperbolic? Well, there is also the fact that you can't get the iterator to iterate over those values, the fact that it will panic on debug but not on release. I understand the decisions that led here, and I am not trying to be overly harsh, but trying to have a simple iterator that will allow me to have all ascii values and I am dealing with low-level silly bit-width issues. If this was in a performance critical code, I would agree, but here *I don't care* I just want it to work. &gt; What do you mean no proper overflow checking? It's not like the overflow checking of usize is any different to the other types? I am sorry, wasn't clear. I mean that now on the glue between your i8 or i32 and usize you have a bunch of `x as usize` casts littered throughout the code. No easy way to specify what to do in case the cast overflows (wrap, clamp, panic, etc...), so for most code-bases that won't be defined well, with behaviors differing between debug and release. The worst is that just by browsing the code it is not obvious which are "dangerous" and which aren't. After all, an innocent looking `x[j as usize]` can or can't be dangerous in a non-obvious way. &gt; I don't understand, could you rephrase this? I mean that I think the main focus in what a high-level rust developer would want to choose in his "work-horse" integers (obvioussly not talking about integers in protocols, file-formats, etc...) is not about the possibility of negation or the bit-width, but about wrapping, clamping, asserting, behavior (or is this a number that is performance sensitive, security sensitive, or don't know so be extra careful). And while there are solutions and libraries to help with this, they are not built in as nicely to the language and as such aren't used in the bulk of code. &gt; Do you mean the static range checking? Yeah, though I care less about the implementation and more about language ergonomics on this. &gt; What is the right thing all the time? It seems to me that the correct behavior is entirely dependent on what the integer represents, something the compiler can't determine. Well, we obviously will need _size for memory access and the specified bit-width for protocols and file-formats. As /u/UtherII mentions in a reply to me, we really don't have access to the "best-performance" integral type, so we may need that as well. but for the general case, and I am just spit balling, but having something like static range checking, wouldn't make better sense? Or maybe having a 128bit signed integer, that will panic on overflow, and everything can be cast to it (so no danger there), but when cast to specific integral types you will need to be more specific, such as: `x[new_int.cast_clamp::&lt;usize&gt;(0, x.len())]` (obvious bike-shedding, and nicer syntax aside). It would be slower but when you care use a different type, for most cases it should perform well enough. Again, I am not enough of a language guy to know what the solution should be, but rust is a language where you can use high-level constructs and their cost is upfront, this doesn't really seem to exist in the numeric side. I can't say that I don't care about performance but make sure that the right thing is done (in a user defined way) regarding complicated calculations. How any people are actually using wrapping_* or saturating_* when they should be? I am working on a medium sized project in rust in my spare time, and I have a lot of integral as casts sprinkled around my code, and I feel like the burden of choosing the correct integral type used over parts of the code is completely non-obvious. Going over the casts to figure out which are OK and which can be dangerous is also non-obvious. Now in C\C++ I would just use int, and check stuff in really specific boundaries, and keep needing to remember where things can break. I don't feel like rust is helpful enough in alleviating this problem (though it is better!). It needs to be something that is deeply integrated in the language and has great ergonomics. I am not saying I know how to design this solution :) (sorry for the length).
&gt; (A lot of the Rust libs team regard this as a mistake, but there's not that much that can be done about it now, due to backwards compatibility.) Could you give more info on this? I am interested in what the problems they have with this are. Thanks
They similar in idea, that there is *immutable array of chars*, and *instrument for permutations among these arrays*. Implementation is different. Explanation (type names, sugar etc.) of idea also different. Java loses in implementation. Rust in explanation
Using `unwrap` is *only* lazy if you're using it as a proxy for error handling. It doesn't make sense to generalize all uses of `unwrap`. Most use of `unwrap` outside of code examples and error handling is not lazy at all, and typically just represents an invariant that wasn't moved into the type system. (Because moving *all* invariants into types is, umm, *really hard*.) &gt; I'd want sections of the software that could cause termination flagged just like unsafe sections are flagged in rust today Most or all code would end up flagged. For example, every index operation could result in a panic.
Either ways you should not be putting this monster on a single line: let words = s .split_whitespace() .map(String::from) .collect::&lt;Vec&lt;_&gt;&gt;(); That's still much better then using Python like this: words = list(map(string.split("\n"), func)) Has you can see we just made Rust more readable then equivalent Python. Also about turbofish `::&lt;Vec&lt;_&gt;&gt;`, its useful to use it when you want to collect and keep chaining, so doing something like: let words = s .split_whitespace() // ... parse to i32 .. somehow .collect::&lt;Vec&lt;i32&gt;&gt;() // sums the vector .fold(0, |acc, i| acc += 1); *Again, i don't see how this is unreadable.* Every method has its line, every method is only inside of its line, the order is extremely visible, the format leaves space for comments. *This would be my definition of readable if i where to have one.*
That would mean a new format for strings (which I personally dislike, but ah well), and then you'd need to either a) extend the grammar to match valid expressions within `{..}` in strings, and do correct error checking (oh, btw. you'll also want to take those variables by immutable reference, just to make it more magic...) or b) leave strings as they are and just desugar whatever is in those curlies to arguments of a format! invocation, which means more work for error checking and possibly worse reporting (with some more duplication). All for the privilege to write the variables within the curlies. That said, someone could write an i!("..") macro to do exactly this. No need for changing the grammar.
Maybe I should do more with strings, but so far I found them perfectly workable in both Java and Rust. The fact that you must have an owner for your `String` (unless it is `'static`) is by construction in Rust, and is the prime reason for additional complexity.
I think this is true. The error messages could probably be improved here also, if you try `use foo;` when you mean `mod foo;`, I'm pretty sure the error you get suggests you try adding `extern crate foo;` to your root module. For someone who doesn't understand crates and modules enough to know that this is definitely wrong, this will just send them down a totally wrong course.
It may help to understand the situation to think about the fact that under the hood`String` is just a `Vec&lt;u8&gt;` and `str` is just a `[u8]`. The compiler doesn't cast an `&amp;'static str` to a `String` for the same reason it doesn't cast an `&amp;'static [T]` to a `Vec&lt;T&gt;`. And all this complication is really because `[T]` and `str` are dynamically sized types, unlike number primitives, so they can't trivially be stack allocated. This doesn't mean it can't happen someday, as the sibling comment says.
In my experience the docs work like the rest of the language: they're fantastic but have a learning curve. You have to know how the pieces (traits, types, etc ... ) fit together in the language before knowing where to look to come up with answers to specific questions via the documentation. It's not that the docs are incomplete, it's a question of discoverability. Unless you know to check each trait for a function, you're going to be confused why certain methods don't exist on certain pages. I don't think this is a problem with the docs at all. It's just necessary given the complexity of the language and heavy reliance on the type system. That's one of the reasons it's so good to go through the rust book first...it gives you the information necessary to progress when confronted with "this should be here...why isn't this here?" scenario that seems to come up quite a bit when first learning. *Enter whimsical idea without any thought behind it:* I wonder how hard it would be to create an error explorer? When an error happens have something able to pull up the relevant type and relevant impl'd traits so you have starting point. Tooling probably isn't the way to solve this, but it's sort of the way I interact with the docs using the search feature anyway, just manually.
Can you give me step by step instructions on how to use vcvars? I ran it in the command prompt before compiling but I still get the error. Thanks.
the point of reinterpret_cast is twofold 1. make dangerous code ugly 2. make it easily greppable.
Oh, I have another one now - `format_args!`. Its beautiful to make string interpolation a contained DSL (and my hope is someday `format_args!` will actually be a procedural macro imported with `std` instead of a compiler built-in). But it means that `println!` is a macro, which means hello world.rs has a mysterious `!` in it, and now a new user has to wonder "What's that bang for?" and then "Why does println! need to be a macro?" and very probably "What even _is_ a hygienic AST macro?"
And how does copying during initialization solve any of these problems? The problems just move to the memory where the temporary objects were constructed. --EDIT-- BTW, none of these problems occur for many simple types, but Rust doesn't offer any economies for the simple cases here.
http://i.imgur.com/9KCIeJi.gif
I'd assume it's a mix of: 1. Leave the namespace as free as possible (There's more than one `Result` and more than one `Error` in the standard library, for example) 2. Special-case as little of the standard library as possible
While i agree, making GitHub a second class citizen is not a good idea. I looked at a lot of open source projects out there that merely publish on GitHub to call them selves open source. If Rust where to have an interface between multiple services (private or not to Rust) i would have to wrap all of them has equal class citizens somehow. This creates another problem, known has subscription hell, so i don't think it could be done to more then 1 - 2 services. If you don't do this then you need to treat all services has second class citizens, and mirror the issues out of them, further segregating the community, which is even worst then subscription hell. *Sure laying all eggs in a single basket is not good, but if you lay your eggs in 2 baskets how are you supposed to keep both of them equally cozy hot?*
Suppose a type `X` implements two traits providing a method `read()`. What happens when you write `x.read` if having traits in scope is not necessary? There are two main possibilities: 1) some disambiguation rule is applied, the code compiles and uses one of the two implementations 2) compiler rejects this code and reports an ambiguity error. Rust chooses the second variant. Now suppose your project uses `read()` on `x`s and you add a new crate to it and that crate implement some trait (maybe even private!) with a method `read()` on `X`. Whoops, all your code is broken due to ambiguity errors and you have to rewrite everything with UFCS. The general principle behind scoped traits and some other features, like coherence, is to provide the ability to freely combine crates without fear of breaking the code unpredictably.
Also see https://github.com/carols10cents/cargo-open ;)
Couldn't you have compile-time concatenation of `&amp;'static str`?
Ok, new format, but actually it replaces old formats. All that not only for writing variables between curlies, but also for better readability and prettier code - critical part for large number of programmers, especially for newcomers. Personally I hate writing a lot of syntaxic garbage for simple and common things. Macro "`i!("..")` should be an `interpolate!("..")` like `format!("..")` and `concat!("..")`, so I dislike this.
Makes perfect sense, thanks!
Which is the closest experience to Eclipse+Java? Do you feel like you are as productive in rust as in java, or if there are particular things missing from the rust ide/rooling? In particular I'm looking at building a toy project in scala or rust (having no experience in either), and think that the jvm/scala tooling would make scala the easier language to learn and be productive in.
Rust strings aren't incompatible with each other. For instance, you can trivially convert String to &amp;str with `&amp;`, you can use `Cow` in data types to allow users to store either of them, you can use `Into` to make functions take either, etc. Low-level concerns prevent there from being "one type to rule them all", but that doesn't mean we haven't gone to a lot of effort to make them play nicely with each other where we can.
Compilation times.
Want to add onto this: not just adding a new crate, but a new update to an existing dependency could do this as well. This can already happen with traits in scope, it'd be even worse with all traits of all dependencies.
While not formally specified, the current in-memory representation of enums is something like `(usize, T)`, where the first argument is referred to as the tag. Rust does not squash down the tag bit of enums-of-enums-of-enums... because the the variant arguments need to be stand alone values. The compiler reserves the right to change the enum representation. This allows a type like `Option&lt;Box&lt;T&gt;&gt;` to be implemented as `*T`, where the `None` value is represented by a null pointer. Theoretically the compiler could squash all of /u/jnordwick's variants together to cut down on their memory usage. This is being tracked in this [RFC issue](https://github.com/rust-lang/rfcs/issues/1230). /u/jnordwick: It might also be possible that one of the virtual inheritance RFCs might also solve this problem for you. 
This is just maintainer's choice. Cargo uses the directory `tests` and compiles all files below it as test runners, if they exist.
The Rust authors have absolutely been writing Rust applications. I'm not sure why you're excluding Servo, which has enormously informed Rust development (the Rust development team used to be half Servo developers!), but the Rust devs use Rust all the time: Cargo, crates.io, Crossbeam, LALRPOP... and furthermore, the Rust team is perpetually soliciting feedback from Rust users on RFCs, so everyone using Rust has a say. It's simply entirely incorrect to say that Rust has ignored the needs of real-world code.
There's work on eliminating these copies. First, you should check out the [arrayvec](https://github.com/bluss/arrayvec) crate, which provides a safe `Vec`-like abstraction around initializing fixed size arrays while retaining drop safety. I think there could be an argument getting this in the standard library some day, but a cargo dependency isn't *that* bad. Second, on avoiding an unnecessary copy, I believe llvm is pretty good at optimizing away moves, and hopefully when MIR is finished, we can do an even better job of removing them. Third, there's an [accepted RFC](https://github.com/rust-lang/rfcs/pull/0809) that's implementing in-place boxing, which enables Rust to initialize a value directly in allocated memory, rather than on the stack and copied in. Each of these should help optimize away your issues.
A lot could be done to improve this aspect by creating better documentation. The book isn't very new user friendly in most places. The order doesn't make a lot of sense and as it stands now there is no way to have it make sense by just moving pages around. There are often concepts placed in example sections for other concepts before the former is introduced or documented in any way. Also, despite sections like the guessing game being very beginner friendly, complicated sections like ownership and borrowing don't seem to have been as well thought out for the new user.
Something like this? let mut cmd = Command::new("ls"); let mut cmd = cmd.arg("-la"); // stuff let _ = cmd.output(); Take this with a grain of salt as I've only been doing Rust for a couple months, but I believe the trouble is that the `Command` returned by `Command::new` lives only to the end of the current expression. Calling `arg` borrows that value, but that value is going to die at the end of the expression, which would leave you with a dangling reference. Therefore you have to bind the original value to a variable in order to guarantee it lives long enough. You don't have to bind the result of `Command::new` when you call `output` inline because it already lives to the end of the expression; long enough for `output` to do its job and give you its own result.
I think it's possible to regret the Ord/PartialOrd split without regarding it as a mistake. There's just no universal solution to this problem, at least as far as I'm aware. Well, other than omitting floating point math from your language entirely, maybe. :P
Note that life-before-main is a massive problem in large C++ projects. Sure, your couple of initialisers are fine, but remember that every single library linked in *also* gets to put stuff in there. In a large project with many dependencies, you may end up waiting for a library to initialize that never gets used. You also can't move the initialization off to another thread or otherwise hide the delay, since it happens before you can do anything.
Yes. But in the name of backward compatibility, those goals are subverted by the existence of C-style casts, which are neither of those things.
&gt;So at the very least, I'd like named parameters to be something that the library designer has to opt-in to. Yeah, I could easily imagine something like this: pub fn my_function(positional: i32, pub named: i32); This would make it clear that the parameter is public and part of the API :)
IMHO the same as with new `?` operator which are: - new lang item, which is even worse than `?` as this one depends on `alloc` which is no go in embedded - "invisibility" it is much harder to spot `format!` than `\``
The worst thing about Rust for me is the lack of feature X. My opinion about it, is that while new features can be added, features cannot be removed. I'd rather not have feature X for a while than have a dangerously broken feature X right now.
Allowing unstable features to be used on the stable compiler would make the stable/unstable division meaningless. The utter, catastrophic failure of CSS prefixes in web browsers has proven that developers can't be trusted to not introduce unstable features into production code, thereby de facto stabilizing features well before they're ready and damaging the platform due to permanent implementation incompatibility and increased maintenance burden. Unstable features are stabilized with every Rust release, and if there's a feature that's still unstable then there's likely a good reason for that. If you have unstable features that you would like to see prioritized for stabilization, then please leave feedback on the corresponding issue or RFC, or file an issue yourself.
&gt; you add a new crate to it and that crate implement some trait Might be worth emphasizing: You can implement new traits for other people's types! If all the trait implementations for a type had to be in the crate that defined that type, Rust might not have needed traits to be explicitly imported.
I use 2 space indentation and 80 char limit and am happy with it.
I wish I had a good answer to this. I think a lot of small incremental changes would be beneficial. Starting by a slightly more readable layout for each doc page would go a long way. Maybe I just find the table layout in JavaDoc and clear delineation of section much more readable because I'm used to it.
Thanks for the detailed info. In-place boxing sounds good.
Personal preference I guess. I hate &gt; 80 char columns and most Rust code uses &gt;100. Every time I need to do a 3-way merge on a &gt;100 char column project I want to kill myself. It feels like I should get a 40'' monitor just for these situations.
Lifetimes are both one of the worst things in the language as well as the best thing in the language. I also hate the tendency to have types that end up with chains such as this Box&lt;A&lt;B&lt;C&gt;&gt;&gt;. It can end up quite large sometimes. Type inference helps, but sometimes you want to store this stuff in a struct.
&gt; BTW, none of these problems occur for many simple types, but Rust doesn't offer any economies for the simple cases here. It does offer at least one: `[x; 100]` works fine for `Copy` types like integers, but yes, fixed sized arrays are definitely annoying. &gt; a pointless copy sending many electrons to their death &gt; &gt; And how does copying during initialization solve any of these problems? Which copy are you referring to?
Thanks, that was interesting and informative. 
It's totally fine, these things are subjective. (As for the caps thing, types are in SnakeCase and function names are in snake_case, that's the major bit.)
To be clear, we haven't actually hashed out what rustfmt's defaults should be yet. It's still just being generally worked on at this point.
I do fundamentally think some unifying abstraction should live in the stdlib to avoid fragmentation. I'm concerned that this is against the Rust ethos and we'll end up with a bunch of libraries that can't coordinate their async I/O in a composable way.
They compatible through some "glue" between them, and that brings a new level of complexity, adds some exceptional cases you must figure out and remember. It's ok by ideas behind Rust, I understand, I accept. But naming and conventions, makes them totally confusing, especially when you think about `two strings` each with his own exceptions, not about `string` and `buffer`.
- It's very squished and finding all methods a struct/trait implement can be difficult. The information is there, but is visually hard for me to follow. It might just be because I become used to the JavaDoc layout. Not that is perfect (it sort of hides the inherited methods), but I find it easier to glance and get a good idea of what I'm looking for. - The first thing I do on EVERY page is immediately collapse the items. A signature overview is very useful, especially since entries can be very long. Either adding one (like JavaDoc), or just defaulting to collapsed (or just let me set it to that). Maybe just show the first sentence of the doc comments with the signature? This one liner would be especially helpful for the trait implementation funcs shown on a struct so I don't need to click over to the trait page to get the idea. - alphabetize, or if there where table columns, a way to sort on name (columns would allow be to sort on return type even), - Columns/alignment make it easier to scan for what I'm looking for, such as I know I'm looking for a method that returns Iter or a slice, it is easier to look down vertically if the return types are aligned somehow. - keybindings. mostly I really want to be able to jump to sections and collapse all with a key. I find myself scrolling a lot to read the docs. Of and enter a search from anywhere on the page. These are all really small things, and maybe one day I'll actually learn enough HTML/JavaScript to tackle one of them :)
Thanks, you are too kind :)
I spend easily 1/3 of my dev time googling for how to convert between the 5 different stringy types (String, str, [u8], Vec&lt;u8&gt;, probably more). I don't think they should be unified because there are good reasons for them, but I really wish the conversion syntax was more uniform
Perhaps I should have said "no more suitable than C or C++", because I believe we can be doing so much better in this area than these languages do. Error handling in C is a big pain (`goto` being the state of the art) and ignoring errors by accident is trivially easy. Meanwhile, C++ was *supposed* to coalesce around exceptions as the dominant model for reasonable error handling, except poor implementations for most of its life caused people to advocate against them and disable them entirely, causing a schism which lingers to this day (and aside from the "poor early implementations" aspect, the reasons for wanting to disable unwinding in Rust still apply to C++, so you'd still have this situation regardless). Meanwhile, Rust strikes a great balance between capacity for handling expected errors (`Result`) and capacity for "handling" oh-shit-everything-is-broken-better-burn-down-the-house errors (panics), except with the useful nuance that if you're a guest in someone *else's* house then they can politely ask you to leave before you strike the match. In a language with nothing but aborts, you have to either shove the oh-shit-etc errors in with the expected errors (thereby making strongly-typed error handling like Rust's too much of a burden to bear), or else you embrace your irrepressible penchant for arson (and get used to people no longer inviting you over for dinner).
Multirust is available on Windows now? That's new. (v.0.0.5 new, in fact..) Thanks for the heads up, I'll check that out when I get a chance.
The real tragedy here is that we didn't bite the bullet and retire the stupid "string" terminology that has plagued programming languages since forever. :P I'll take `&amp;Text` and `TextBuf` any day.
I'm kind of "coming from GHC", in that I've read about a thousand pages of Haskell documentation but written about thirty lines of code. I'm not sure what "the obvious way" is, but if you unpack that I'll probably get it. :P
Thanks! That would be pretty radical. . .
Dear Rust folks: PLEASE MAKE AN INTELLIJ PLUGIN D:
Can you give some examples of your first point? As someone who's interested by language design it seems like a very important thing to consider. Totally agree with your second point.
I know this is personal preference stuff but I strongly disagree. Putting the tests physically close to the code being tested means that I'm more likely to write them
This works in eg C++ but it would be less useful in Rust. It's very useful to see how an argument is borrowed (immutably, mutably) or moved because this affects how it can used later on in the same scope (unlike c++). Dereferencing is much more than just removing any number of unnecessary &amp; references since it allows types like Arc&lt;T&gt; and Box&lt;T&gt;, etc to work as if they were of type T. I'm not sure there is a symmetry in what auto-dereferencing does and what auto-referencing would do. When you say closures take automatic references, that's true I think, but really they are borrowing the variable (or moving it). Ultimately, it was a design choice that I think makes more sense because borrowing is a much more important concept in Rust.
For me, the driving use case is calling Vulkan api functions from Rust. This [thread](https://forums.khronos.org/showthread.php/9649-Official-Vulkan-Feedback-API-for-High-efficiency-Graphics-and-Compute-on-GPUs?p=38243&amp;viewfull=1#post38243) is a bit outdated (with respect to both Vulkan and Rust), but outlines the problem fairly well.
IMHO - this could be efficiently solved by `Copy` and non-`Copy` types being highlighted a different colour in an IDE, or the `Copy` thing featuring preeminently in term [hints](https://en.wikipedia.org/wiki/Tooltip). At the very least, the relevant error messages need to mention `Copy`.
Yeah, multirust-rs (the one I linked to) is a Rust reimplementation/the next generation of the original multirust shell scripts. One of the goals of the new version is Windows support.
&gt;the only interesting aspect of Rust is memory safety without garbage collection Also the absence of "use after free" bugs in managed resources (file system handles, network handles, etc.), the absence of data races, the 21st century competitor to C for kernel and driver code... :)
Maybe the phrasing issues? I can't understand what he's saying.
&gt; In some instances, a question will have nothing but incorrect answers that are given in an authoritative tone . I've first noticed this phenomenon on SO, but it seems that it occurs here in this sub as well. As a prevalent answerer on Rust questions on StackOverflow, I certainly hope that I'm not guilty of this. However, you should *definitely* feel completely justified to downvote incorrect answers there! I'd encourage you to comment explaining to others why the answer is wrong, but that's up to you. Feel free to drop into the [Rust SO chatroom](http://chat.stackoverflow.com/rooms/62927/rust) to discuss any questions with some of us as well.
How does it compare to some other compiled languages?
Some descriptions and snippets (possibly tweaked for clarity) from rustc's codebase or the stdlib for each. It'd be nice if the libs team can chime in as well, and yes, I need to actually elaborate on all the docs for these: (Maybe I'll turn this comment into them tomorrow...) &gt; to_owned This trait is intended to be a trait bound for a function that's going to convert some kind of generic borrowed value into its associated owned value. If you're not writing generic code, then you shouldn't be using this. Note also that `ToOwned` and `Clone` are very similar; and in fact, for any `T` that is `Clone`, there's a blanket `ToOwned` impl that calls `clone()`. pub fn into_owned(self) -&gt; &lt;B as ToOwned&gt;::Owned { match self { Borrowed(borrowed) =&gt; borrowed.to_owned(), Owned(owned) =&gt; owned, } } &gt; to_string This function converts some type into a `String`. So if your end goal is to get a `String`, this is the method you want. archive.iter() .filter_map(|child| child.ok()) .filter_map(|child| child.name()) .map(|child| child.to_string()) .collect() Most of std uses `.to_string()` to convert literals. There's a minority style (that I personally subscribe to) that uses it for variable bindings and `String::from` for literal strings. &gt; into `Into` is generally a trait bound on a type parameter that's going to be converted into a value of some other kind of type. In other words, it's used when you want to convert from a value of some generic type into some other value of some generic type. pub fn span_warn&lt;S: Into&lt;MultiSpan&gt;&gt;(&amp;mut self, sp: S, msg: &amp;str) -&gt; &amp;mut DiagnosticBuilder&lt;'a&gt; { self.sub(Level::Warning, msg, Some(sp.into()), None); self } pub fn new&lt;T: Into&lt;Vec&lt;u8&gt;&gt;&gt;(t: T) -&gt; Result&lt;CString, NulError&gt; { // I cut out some safety checks because they distract here CString::from_vec_unchecked(t.into()) } &gt; from From is generally used to convert to a value of some known, concrete type, from a value of some other type. String::from("hello"); PathBuf::from(filename); OsString::from("bar"); u32::from(a); Ipv4Addr::from(2130706433); The type, before the `::`, is a concrete type, but the argument can vary.
Have you found https://github.com/intellij-rust/intellij-rust lacking?
While this is true, the official guidelines are "unit tests in tree, integration tests in `tests`", due to privacy rules.
Cool, I don't use IntelliJ myself, so I'd be interested in what you have to say!
This is a question about how Rust works in general that I can't seem to wrap my head around. I'm trying to use RwLocks inside of a thread when it's defined outside of the thread. If RwLocks implements Send and Sync why does it need to be inside of Arc and then cloned for me to use it within a thread? let data_lock = Arc::new(RwLock::new(0)); //launch threads for i in 0 .. threads { //clone for local use in the thread let ldata_lock = data_lock.clone(); thread::spawn(move || { let data = data_lock.write().unwrap(); data += 1; }); 
* It's young. * It's complex. * It has a lot of syntactic overhead.
Half the C++ compilers I've used love to dump pages and pages of text when you've got compilation errors, especially when you're using templates. That alone makes C++ significantly more frustrating to deal with.
&gt; Was there any drawback of making NaN == NaN, apart from portability and expectations issues between languages? I think this is possibly the weakest decision (i.e. fewest tradeoffs for `NaN == NaN`), [I understand](http://stackoverflow.com/a/1573715/1256624) that considerations about existing implementations (at the time the first version was published) was a major factor in this decision. However, it does seem a little more sensible/controlled to me that, say, `∞ - ∞ != sqrt(-1)`. &gt; Was there any non-obvious drawback to making all NaNs signalling, i.e. trigger something like a panic, just like division by zero does? The standard is designed so that inconsequential/irrelevant errors don't necessarily cause catastrophic program failure, but yeah, it seems like it's a bit of a "worse is better" decision. There's a IEEE754 FAQ answer covering this too: http://grouper.ieee.org/groups/754/faq.html#exceptions (The standard does offer various ways to tweak how nans/exceptions are handled.) &gt; Do you know of any other source of, or reason to have types with strange non-Eq/Ord-abiding behavior apart from IEEE754? Not really in practice, other than the obvious ones of types built from IEEE754 types (`Vec&lt;f64&gt;` etc.). I believe this is mathematically called a ["partial equivalence relation"](https://en.wikipedia.org/wiki/Partial_equivalence_relation) (and that page gives some examples in mathematics).
I mean, what qualifies as major? The exception handling RFC is a major feature in my book. Same with type annotations. Not that it's any more complex than the status quo, but they're still big features.
Links on Reddit get `rel="nofollow"` on them which negates any possible SEO.
Why is the copy truly necessary? What safety benefit did it bring?
As I said, I don't understand how the "copy" (or something similar/identical) can be avoided: the memory storing each element has to be set to an initializing value. This discussion would be much clearer if you post the `unsafe` version that you have in mind that doesn't have the "copy", please.
&gt; By "exception handling" do you mean std::panic? Probably `?` (its title is the slightly-misleading "trait based exception handling").
In the large, you're seeing the magnitude of difference between a compiler that basically doesn't optimize at all, and a compiler that does. I doubt the debug version is doing much inlining, let alone anything fancy like autovectorizing loops.
By exception handling I meant `?`. Don't get me wrong, I personally like, a lot, both features I mentioned. But I think accepted RFC's are fair game when discussing feature creep.
IMO, Rust's chain-everything style makes a lot of code hard to format reasonably. It results in a lot of, well, this Python's usually not only a lot terser, but much simpler to format. I personally think words = list(map(func, string.split("\n"))) is significantly more readable than let words = string.split_whitespace().map(String::from).collect::&lt;Vec&lt;_&gt;&gt;(); and that words = string.split() words = map(str, words) words = list(words) is significantly more readable than let words = string .split_whitespace() .map(String::from) .collect::&lt;Vec&lt;_&gt;&gt;(); or however it ends up formatted. Especially as in Python the last two lines just cancel each other out. Just like you can extend to let word_count = string .split_whitespace() // ... parse to i32 .. somehow .collect::&lt;Vec&lt;i32&gt;&gt;() // counts the vector length .fold(0, |acc, i| acc += 1); in Rust, you can extend to words = string.split() # ... parse to int .. somehow words = list(words) # counts the vector length word_count = sum(1 for _ in words) in Python. Especially as the Python code actually works.
The "how" of avoiding the copy is to perform the initialization directly on the destination. The memcpy is pure overhead. Here is the unsafe version. This is not my code, it's a cut and paste from Stackoverflow on this topic. let array = unsafe { // Create an uninitialized array. let mut array: [Foo; 10] = mem::uninitialized(); for (i, element) in array.iter_mut().enumerate() { let foo = Foo { a: i as u32, b: 0 }; // Overwrite `element` without running the destructor of the old value. // Since Foo does not implement Copy, it is moved. ptr::write(element, foo) } array }; 
&gt; Well, from what I felt from the community, the discussion was pretty much that _size is discouraged as a generic integer and was specifically called that to make sure people used the more specific integral type and used _size purely for memory access. It's discouraged as a general purpose integer: not the right choice for, say, the amount of money in a bank account, or the health of a monster. But it is the right choice when interacting with memory, e.g. the length of an array, or the index of the next item to retrieve from a vector. &gt; the fact that it will panic on debug but not on release An overflowing literal actually doesn't panic in either mode, it just gets a compiler warning. &gt; trying to have a simple iterator that will allow me to have all ascii values and I am dealing with low-level silly bit-width issues. If this was in a performance critical code, I would agree, but here I don't care I just want it to work Yeah, it can be annoying, but this is part of the cost of a systems programming language: more control over memory layout/performance for the programmer means more knobs to tweak and more things to think about. Also, cases like this are exactly why [inclusive ranges](https://github.com/rust-lang/rust/issues/28237) are proposed: you can write `0...0xFF` instead. &gt; No easy way to specify what to do in case the cast overflows (wrap, clamp, panic, etc...), so for most code-bases that won't be defined well Yeah, inability to chose panicking/clamping is a hole, e.g. https://github.com/rust-lang/rfcs/pull/1218 &gt; with behaviors differing between debug and release Hm, you seem to regard this as a very bad thing, but I personally see this specific situation as a very good one. Maybe we come from different backgrounds, but Rust takes a step up from the raw behaviour of C by adding a few extra checks (to detect possible overflow bugs), but still doesn't lose speed when you need it. (Also, for better or worse, overflowing casts do not panic in debug mode.) &gt; I mean that I think the main focus in what a high-level rust developer would want to choose in his "work-horse" integers (obvioussly not talking about integers in protocols, file-formats, etc...) is not about the possibility of negation or the bit-width, but about wrapping, clamping, asserting, behavior (or is this a number that is performance sensitive, security sensitive, or don't know so be extra careful). And while there are solutions and libraries to help with this, they are not built in as nicely to the language and as such aren't used in the bulk of code. I'm sorry, I still don't understand this. Are you saying that developers aren't choosing the integer type based on whether they use `-`, or what the bitwidth is? I definitely disagree with the latter: people chose the integer type based on what range of values they need, which is *directly* related to the bitwidth. In any case, I agree that it can be annoying to get unexpected behaviour due to unsigned overflow, which is exactly why Rust chose to panic in debug builds, so that people's testing flags these problems early. &gt; for most cases it should perform well enough I'm not sure about this: it seems like it could easily induce a "death by a thousand cuts" scenario, e.g. It would add code (i.e. larger binaries, more cache pressure) all across an application. That is to say, microbenchmarks might say that it is only 2&amp;times; slower (which is still a lot!), but they only capture one facet of performance. &gt; where you can use high-level constructs and their cost is upfront, this doesn't really seem to exist in the numeric side Defaulting to an expensive integer type like a 128-bit one would be exactly the opposite of making their costs up-front. Rust tries to default to not implicitly adding costs, but still giving the tools for higher level constructs (some of which are expensive, but a lot of which are not). &gt; How any people are actually using wrapping* or saturating* when they should be? The fact that overflow panics in debug mode means that I'm sure that most "real" libraries are using them where they need to (i.e. libraries that have tests and aren't total experiments). &gt; I am working on a medium sized project in rust in my spare time, and I have a lot of integral as casts sprinkled around my code, and I feel like the burden of choosing the correct integral type used over parts of the code is completely non-obvious. Going over the casts to figure out which are OK and which can be dangerous is also non-obvious. Yeah, choosing the right integer type can be tricky, but defaulting to `i32` (or `i64`) and only looking for smaller types when you know memory usage matters (e.g. being stored in a vector) is a good one. And, you're definitely not alone in being concerned about the noise of OK casts, e.g. https://internals.rust-lang.org/t/implicit-widening-polymorphic-indexing-and-similar-ideas/1141
Where is the useless copy in `let foo = [1,2,3];`?
&gt; having to write a couple of extra function calls to get full control of what is happening behind the curtains is an advantage IMO not a drawback Why not both? For the target Rust's aimed at, it certainly makes a lot more sense to do it that way. But I think Python's power comes a lot precisely from the fact it is so concise; that I can do v = {a: b, x: y}.get(k, d) in one line in Python is a great tool for *thinking* about a problem. A place this comes up particularly strongly for me is with iteration; `yield` is a blessing in Python and the duck typing makes reasoning about iterators very simple. In Rust, a lot more time is spent on making and organizing types and their state. I get why this is, and I think it's the right choice for Rust, but it's very much a trade.
Because you could have other things inside that `Arc` that need no locks, e.g. atomics.
I hate to be that guy (especially since I am jumping on the Rust train now), but I found the Go documentation/layout to be much friendlier. The combination of the index at the top of the page (for quick scanning) and detailed examples of every function really make them easier to navigate. I have been using Dash to navigate the Rust docs but I am not on my Mac 100% of the time. I am aware I can collapse the examples but that only gets you so far in terms of layout.
You have to specifically execute it using `call "C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\amd64\vcvars64.bat"` (or whatever vcvars bat file you want to use). You cannot simply run the bat file in your command prompt, because that will give it a new cmd context to execute in and the changes it does to the environment variables won't be shared with the original context.
I think Rust would go `2.x` to clean the legacy cruft, when it starts to weight, a strategy C++ always avoided.
Not sure how I feel about this. My first thought when encountering `PathBuf` was "that sounds like passing a Java `StringBuilder`; who in their right mind would do that?".
Don't worry about being that guy: specific complaints are very useful. Thanks.
I think I've been through this, but it may be because I started fiddling with Rust before 1.0, maybe around 0.10 or 0.11, so at some point I had old code I wanted to revive.
&gt; Immature community (not like "lol 8=D") I would say immature ecosystem. I think Rust community is a really strong point of the Rust language.
[That RFC](https://github.com/rust-lang/rfcs/pull/1317) was merged last month. =)
That and also you can't use privates outside a module, which I find very useful for some forms of unit testing.
You know, when I use C++, the most surprising thing I come across is automatic copying. It is very hard to know at a glance when things are being moved and when things are being copied. In Rust, that's far more explicit, and I value that. But in the 9 months I've used Rust, it's really felt like more of a burden to have to take borrows to things that are unfortunate enough to be arguments instead of being on the receiving end of a method call.
As a resident of the c++ subs I've met the immature side of the rust community too. 
Amazing! So do you run it in Dolphin? If not how are you running it on your Gamecube?
There's also the whole specialization story (and anything else "inheritance-y" that may come. Most would say it's necessary (I agree), but it's not a simple addition to the language.
This is why we've spent years working on the design of this feature, to make sure it integrates nicely with the language rather than feeling tacked-on or vestigial. Every piece needs to play nicely with all the existing parts of the language, and all the pieces should be independently useful. And given that there are no RFCs in this area accepted yet, let alone implemented, it's still way too early to talk about its impact on language complexity. :P
Oh, I have no doubt it will be designed and implemented extremely well. I don't think the complexity will come from the design decisions around its implementation in Rust, more just that it's not a conceptually simple addition.
And then what happens? :D It involves `__getattribute__`, `__getattr__`, descriptors, special cases for which attributes are only looked up on the type and not on the instance and so on..
It would be horrible usability, as you should use `str` by default and `String` only when necessary. Making the type name twice as long does not help its usage (even less so as you need borrow/lifetime info on top)
&gt; I've always been fuzzy on why string literals are the former and can't be automatically inferred as the latter. Because Rust is very careful about ownership, "inferring" a string literal as a `String` would mean *an implicit string allocation* as it would have to copy all the static `str` data into a newly allocated `String`, which is the kind of things Rust avoids. &gt; My vague understanding is that string literals are &amp;'static strs and live "somewhere" They live in the `data` segment of the binary, which gets mapped into memory at load. &gt; And why do numeric literals not require similar gymnastics? Is it just heap vs stack allocation? Kinda. Numeric types live entirely in/as their value, whereas the part you directly manipulate of a string type (the string value which lives in your function and is passed around) is just (pointer, length) for `&amp;str` and (pointer, length, capacity) for `String`. So when you move a numeric value around you move the whole thing, when you move a string value around you only move some metadata to memory which is elsewhere (on the heap, in an other section of the stack, in the bss or data segments of the binary, in an mmap'ed region, etc…)
Note that in nightly, both the TCP und UDP socket types have a ```set_nonblocking``` method now, so having to spin up a thread for network IO isn't necessary anymore. Although a ```select``` function would be nice too.
When you say panics with unwinding, you mean as opposed to aborting?
Cargo question: Is there any way to install the dependencies of a project without having to declare any target, even without having any source code on folder other than Cargo.toml/Cargo.lock? This is very docker-related use case. Right now I'm doing this hack in order to caching dependencies compilation, but its not so nice: FROM scorpil/rust:1.7 WORKDIR /app ADD Cargo.toml /app/Cargo.toml RUN mkdir src &amp;&amp; echo "fn main() {}" &gt; src/main.rs RUN cargo build ADD . /app RUN cargo build CMD ./target/debug/hello_world If you don't know much about docker, here is an explanation about how the build cache works: https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/#build-cache . If you build your environment isolating files that rarely change (like Cargo.toml), you will boost the build speed by a huge lot.
Awesome references, thanks! I think weakening the guarantees of `Eq` and `Ord` for all types just because of the existence of floating point (or saying the guarantees should hold but making floating-point types implement them anyways, which is actually the same thing, you'd just be lying) is the worst possible resolution. People will intuitively assume the guarantees anyways, and end up with broken code. But I'm open to the possibility that separating `Partial`{`Eq`,`Ord`} from {`Eq`,`Ord`} is the *second* worst solution. There is something to be said for keeping it simple, after all. If `NaN` is really the sole reason for this entire mess then I think I might lean toward making `NaN == NaN` and providing a separate `float_eq` function with the IEEE754 semantics for people who need it, or something like that.
IIRC you can't do that from an inline tests module either. I've had some success with this though (ignoring syntax errors): fn my_private() { # do a thing } #[cfg(test)] fn _my_private() { my_private() }
Yeah, basically.
Type inference question. I have a type `Id`, for which I implemented `Into&lt;usize&gt;`. I want to use it to index into a vector: `my_vector[my_id.into()]`. However the compiler says it cannot infer enough information. Shouldn't it be able to understand that though, since `usize` is the only type I implemented `Into` for, and a vector can only be indexed by that or a range?
You *can't possibly* not care unless one of two things is true: 1. You are intentionally irresponsible about edge conditions, e.g. a quick &amp; dirty demo, which begs the question, who is the code communicating to? 2. You know `int` suffices on a specific platform, e.g. `int` is 32-bit, in which case, you should've used `int32_t` / `uint32_t` or even something smaller. Using `int` instead of `int32_t` is a very common mistake and it's mostly due to the fact that `int` is shorter than `int32_t`. I believe that Rust has made the right tradeoff: `i32` / `u32` are as short as they could be, whereas the `c_int` from the `libc` crate is less convenient to reach for, but not too painful for FFI.
&gt;Python's power comes a lot precisely from the fact it is so concise I agree with that, the fact that you can make a "useful" working program with 20-ish lines of Python is incredible. But I wouldn't want Rust to become like Python. Because as much as I enjoy Python's conciseness, it is pretty hard to maintain or understand code when this property is (ab)used (at least for me). If Rust aims to be used in large Projects, I think it's verbosity and explicitness becomes a strength. It's a lot easier to maintain a code-base where almost all lines are self-explanatory because rust is verbose, explicit and is not afraid to make use of longer names for clarity. Both verbosity and conciseness have their advantages and drawbacks in different situations. I think Rust made a good choice for their targeted audience and use cases.
&gt; Also the absence of "use after free" bugs in managed resources (file system handles, network handles, etc.) Just curious but when was the last time such a bug bit you? I cannot think of any time that has ever caused a problem for me. &gt; the absence of data races Yeah, I had a data race once. Not something I'm going to change languages about. &gt; the 21st century competitor to C for kernel and driver code Are more kernels being written in Rust than, say, OCaml (Mirage)? So, yeah, those are all theoretically valid points to some degree but they are all about Rust solving problems that I don't have. So it is of purely academic interest to me. Now if Rust really can deliver on performance then I am all ears but I have yet to see any compelling evidence. 
I've got the new and improved [rusty-cheddar](https://gitlab.com/rusty-binder/rusty-cheddar) (C header generator) working with [rusty-binder](https://gitlab.com/rusty-binder/rusty-binder) (generic language bindings generator, SWIG for Rust if you will) which has been about 4 months in the making, so that's a bit of a load off. Before I do a proper release though I want to make a proof-of-concept Python bindings generator to show that it actually works (plus I think it may throw up a few issues with the API), and I want to significantly improve documentation since I don't think it's very easy to figure out at the moment (unfortunately I'm about as far from a documentation guru as you can get so...).
&gt; IIRC Python is similar? Exactly. :-)
Often because one use case of Rust is replacing performance-sensitive code in higher level languages. Replacing C++ code with Rust is a thing too, but you won't do it for better performance. So everyone replacing python-with-rust will actually measure the performance gain, the folks doing C++-with-Rust won't. And the point of these performance measurements is to show _how much faster_ Rust gets, which is a rather useful thing to know. Comparisons between Rust and C++ in benchmarks are uninteresting, usually since they turn up more or less the same and are more prone to optimization tricks swaying the result.
C++ is an amazing language, with a lot of power and flexibility, and its own set of not-so-good things too. I think it's fairly non-controversial that the latter class includes the integer types that were inherited from C, inherited with their (lack of) guarantees: one just knows `sizeof(long) &gt;= sizeof(int) &gt;= sizeof(short) &gt;= sizeof(char)` plus some minimal bitcounts, with non-trivial variation in sizes across platforms. It is definitely true that the newer standards include types that give more guarantees, but the old, messier C types are still in widespread use. Just like it's not a good criticism of C++ to ignore the newer standards, it's also not good *advocacy* for C++ to ignore widely-used existing features and habits. To be clear, the complaint isn't that C++ allows you to do something in some other way (Rust itself certainly has multiple places with multiple choices), it's that the other way is still a typical default choice and is messy. &gt; when someone reaches for int it means they don't care, that communicates something too. It can also mean that they haven't thought about/haven't been reminded to think about it. While `int` isn't the worst default (on common platforms one can be fairly sure it is 32-bits), this... isn't as good a choice as one might hope: `int` has downsides like overflow being undefined, so an inappropriate use (e.g. it's not unimaginable to have arrays with more than 2 billion elements) can lead to a fundamentally broken program. The various implicit promotion rules also have their benefits, but they can disguise problems with such choices.
That has the same meaning as `use Foo`. Afaik that syntax only parses because its needed for the current way macros can refer to other code, which is `use $crate::Foo` and which expands as either `use ::Foo` or `use name_of_crate::Foo` depending on where the macro is expanded.
Note that `Result` is not a trait, but an enum.
...wow. When I write my language it sure as hell won't have any of that D:&lt;
Interesting question! The Rust compiler doesn't check if only one `Into` trait is implemented when doing type inference. This is (probably) intended, since it would lead to weird errors when adding another `Into` impl. It doesn't have to do with the `Index` trait. You see the same behavior with `fn foo&lt;T&gt;(t: T)` and `foo(Id.into())`. ---- Just as a side note, this **would** be awesome to do in your case: impl&lt;T, O&gt; Index&lt;Id&gt; for T where T: Index&lt;usize, Output=O&gt; { type Output = O; fn index(&amp;self, index: Id) -&gt; &amp;Self::Output { self[index.into::&lt;usize&gt;()] } } Sadly, it's not possible to implement foreign traits for foreign types...
This weekend I updated the API and merged Windows support to [ruster_unsafe](https://github.com/goertzenator/ruster_unsafe), an interface between Erlang and Rust. Also working on a usbfs crate with mio support so I can talk to the USB devices I work with. And I'm also thinking about what it would take to make something like libusb in pure Rust.
From what I understand, we did something similar with [SharedTensor](http://autumnai.github.io/collenchyma/collenchyma/tensor/struct.SharedTensor.html). A n-dimensional array, that can hold its data on the CPU, GPU, wherever. With Collenchyma we have the operations (e.g. BLAS), that can than be executed on CPUs, GPUs, wherever for any SharedTensor. You might be able to use Collenchyma-BLAS or the other operation plugins, but then it is already working with SharedTensor. What we are lacking a bit (and where we are going towards ndarray) is Views, Slices and such. We are happy to help you contribute, if you are up to that. You can reach us at the [Gitter chat](https://gitter.im/autumnai/collenchyma).
&gt; What are you comparing with? C++? I think it's been pretty conclusively proven that Rust can be as fast as C++. You won't see much evidence that it's faster, since any discrepancy here will be due to the different kinds of optimization tricks used. But Rust does do as well as C++ on the benchmark game; and in Servo and other applications we've not noticed any significant differences. Rust vs F# or even C# would be much more interesting for me. I don't consider C++ to be fast any more. Sure, if you're doing a trivial tight numerical loop it can compete with Fortran but IRL the problems I solve are anything from trivial and deadlines are tight. I'd be lucky to get *any* working C++ solution written in time, much less an optimised solution. Metaprogramming is a nightmare in C++. There's no memory-safe IR you can target, e.g. for regexs. The tools for lexing and parsing suck. Async is horrific in C++. Lack of automatic memory management means people end up reference counting by default which is slow and still leaks cycles. &gt; What about the type system? It's pretty easy to build your own safe abstractions using it. Sure but I've already been down that route with FPLs. You're quickly into diminishing returns. If anything, it is the main thing that concerns me about Rust because, IRL, young developers run riot trying to embed everything in their types, resulting in a completely unmaintainable mess. I prefer to KIS. Now, I haven't tried Rust myself (only just installed it yesterday and cannot get the Havlak benchmark to compile) but I spoke to a friend who said there are bad interactions between the borrow checker and generics that make generics harder to use in Rust. I've also noticed that most Rust programs appear to be much longer than the equivalent, say, F#. Granted that is at least partly because Rust handles errors explicitly but I still find it off putting. &gt; To me, the type system is a huge part in my liking of Rust. Yeah, not something I am personally excited about. I've only ever seen advanced type systems cause trouble in the real world. 
Hm, I should join some of these IRC channels. Coming form a C/C++ background, I find rust really exciting, but it's difficult to move past the initial learning cure to feel proficient in the language. I read a bunch of stuff, write a few simple things, then I get burned out at work, become a zombie, and forget everything I learned. Then I repeat the whole thing.
It does not. Sending build context to Docker daemon 5.632 kB Step 1 : FROM scorpil/rust:1.7 ---&gt; 1c1705caf03f Step 2 : WORKDIR /app ---&gt; Using cache ---&gt; 359515da308b Step 3 : ADD Cargo.toml /app/Cargo.toml ---&gt; Using cache ---&gt; a6f0db198d73 Step 4 : RUN cargo fetch ---&gt; Running in 02370a42a457 failed to parse manifest at `/app/Cargo.toml` Caused by: no targets specified in the manifest either src/lib.rs, src/main.rs, a [lib] section, or [[bin]] section must be present The command '/bin/sh -c cargo fetch' returned a non-zero code: 101 
Ownership tracking. This means taking care that your value gets dropped when no longer needed (and not before or after).
Saw d3d and gfx stuff, for a second thought I'd have to come say /r/playrust Glad this one's right.
Cross API? Noo! Don't be angry! Be nice! Happy API!
Besides what others have said, a sync_channel can help address this problem.
The reason for not having this is that borrow errors can be confusing as it is without having autoref in the mix. (Autoref for the left hand side of `.` is kind of a necessary evil.)
I don't think Rust (as released at 1.0 anyway) has any more complexity than that which is needed to make memory safe systems programming work. Lifetimes, the borrow checker, generics, etc.—they're all necessary.
IMO, the more correct way of looking at it is that everything is *synchronous* and *blocking* in Go. The thread scheduler just happens to be a userland M:N scheduler instead of a 1:1 kernel scheduler, but that's an implementation detail and not one that's without tradeoffs (as Rust's past attests to). I'd sum up Go's philosophy as "Go optimizes the implementation of blocking synchronous programming in an effort to make asynchronous I/O not needed." (How much Go succeeds in this is a matter of debate.) It's actually the exact opposite of "async everywhere", in my view…
Edit: A workaround for this has been found [here](https://users.rust-lang.org/t/cannot-infer-an-appropriate-lifetime-error-borrowing-from-a-mutable-field/5103)! Reposting from last week since there was barely a day before the thread went away. I am getting a "cannot infer an appropriate lifetime due to conflicting requirements" error. [Here](http://is.gd/mIFVnM) is an example. It may not be minimal but it mirrors the structure of my actual code pretty closely. I only sort of see the conflict and unfortunately this particular message doesn't provide more specific information. I know it has something to do with using `Vec`/slices in `Ex::mutate` since if I remove all the slices and change the `Vec` to just a reference, everything compiles fine. I think it has to do with how `BorrowMut` works too, since if I use `get` instead of `get_mut`, everything compiles fine. Given the error message, my working theory is that the compiler is trying to assign the lifetime of the references in the `Vec` to the references in the `s` parameter of `Ex::mutate`. But I don't see why it should assign those, nor why the lifetimes must be the same (if indeed they should). My intuition says they should be allowed to be unrelated since I only need to hash the input and nothing else. If I make the compiler-suggested change and annotate `fn mutate(&amp;mut self, &amp;[&amp;'a str])`, the error moves up a level to `Container::mutate` where it again wants me to annotate the parameter. Making that changes pushes the error another level to `Library::func`, which in my actual code is third-party and cannot be changed. It is the library which actually owns the "root" `&amp;str` from which all further slices are taken. I can't change the library code, and I'd like my `Ex::mutate` signature to look basically the same (slices with references in parameters. I have tried adding various explicit lifetimes and bounds but have yet to find a version that works. So my questions are: 1. What exactly is going on with the lifetimes? 2. Is there any way to express to the compiler that there is no conflict? 3. If not, is there an alternate construction that can support the same basic API? I haven't been able to find one.
Thank you! I’ve wanted this for a while &lt;3
Suppose you have multiprocess shared memory (like ipc-channel) in Rust, but panic causes process abort. What do you do with mutexes (for example) when one of the processes dies? I think these questions aren't nearly as simple as "unwinding is evil". In fact, the way I see it, unwinding is kind of a red herring. The issue is with robustness relating to shared resources in the presence of multiple threads of control accessing that resource. Kill in-process unwinding and the problem will still exist.
Definitely, it adds another thing we can cache. But we can have most of incremental compilation without MIR.
The idea that uint32_t is difficult to reach for is laughable. https://en.wikipedia.org/wiki/False_dilemma
`Char8` variants of `ByteString` of course!
Good question. I'm not aware of any. The (public) cross-API systems I've seen before are all fairly high-level - basically graphics engines.
Oh yes, I do know that much... I was just wondering whether complexity (of implementation and maintenance) was the only reason for avoiding it, or was there any theoretical issues preventing completeness.
using int means you don't care. using uint8_t means you do care. using uint_least8_t means you care about portability. uint_fast8_t means you care about portability and speed. size\_t is used to represent the sizes of things, including a __vector__ with 2 billion elements that has a vector with a size() method that returns a size_t that will cause compiler warnings if you do something silly. &gt; It is definitely true that the newer standards include types that give more guarantees, but the old, messier C types are still in widespread use. Just like it's not a good criticism of C++ to ignore the newer standards, it's also not good advocacy for C++ to ignore widely-used existing features and habits. Strawman. I said you don't care. using int means the developer doesn't care. When the developer starts caring about the bit length they'll start being explicit about the bit length. --- I don't know why I didn't expect ideology, I've been around software development for enough years. But I do find it disappointing. This is a complete __non-issue__ in C++. Stop attacking phantoms C++: "oh god, what if someone introduces a bug by using int instead int64_t or size_t and then cast to size_t to stop compiler complaints"!? Rust: "oh god, what if someone introduces a bug by using i32 instead of i64 then cast it to usize to stop the compilation from failing!?!". Atleast in C++ there's a chance the developer will avoid casting since it's also considered good practice to avoid squelching compiler warnings unless you're __damned sure__ it's not an issue. I know I know, you're going to argue the rust story is somehow less bad, I get it. I understand your motivation. But this is a complete non-issue amongst C++ developers. This is one of those things where a C++ developer kind of laughs nervously when they realize the rust folks think they fret over this shit, or that it's an actual source of serious problems. meanwhile, rust doesn't have a good way of letting the developer specify the fastest integer type that's atleast 16 bits wide without maintaining it themselves or pulling in external dependencies.
At the moment, there is no type inference, just dynamical types. I am considering adding a type system because of it would be useful for error handling, but also because first class functions are not safe.
Is this the wrong place to ask this question? Should I have went to [Rust Internals forum](http://internals.rust-lang.org/)? (Should I repost it there?)
You can write a C library wrapper, even though I only did this for Idris once. I do not know what you need for window, but should be possible.
&gt; Going back a few comments: &gt; &gt; &gt; The only interesting aspect of Rust is memory safety without garbage collection &gt; &gt; If that were the case, people wouldn't be asking for an optional garbage collector. You mis-quoted me. What I actually wrote was: "...**in my mind** is that the only interesting the only interesting aspect of Rust is memory safety without garbage collection..." I am not asking for an optional GC. I was not claiming to know what other people want. I was stating my own perspective. &gt; Interesting. What approach to concurrency are you using that seems to completely exclude data races? Communicating sequential processes that can use mutable state internally but don't share it with the outside world. &gt; Redox is particularly cool. I'll check it out. &gt; I'm surprised that you insist on your non-academic-ness yet bring up Mirage in casual conversation. Rust being on par with any every other language being used to write "toy" kernels is of no interest to me. If someone is trying to write a proper kernel then that is more interesting. &gt; The reason I bring up lines of C in Mirage is to point out that Rust has low-level development capabilities on par with C and C++, which is a) not particularly niche (see embedded systems, driver development) and b) unheard of in languages less than thirty years old. Sure but that isn't present in modern languages because the vast majority of developers don't want it. &gt; Because it's clear that you'd made up your opinion on Rust's merit before you even read a word of this thread. It's academic, useless, and needs to get real. No, that is not what I think at all. Lots of people are toying with it. The jury is out regarding performance, waiting for someone to make some decent benchmarks. &gt; And they don't have to be one of you - just because you're not interested in Rust doesn't mean you're justified in spraying your contempt all over the place like so much skunk piss. If I wasn't interested in Rust I wouldn't be here. 
&gt; I'm interested in fast high-level languages like F#, OCaml, Scala and so on. Sure. And others are not. I was just explaining why you tend to see more performance comparisons between slow languages and Rust. I suspect that folks are pretty happy with faster high level languages and the activation energy required to switch to rust is too much. Rust may be faster, but not so much faster to justify a switch. At the same time, these languages have awesome type systems and Rust has less to offer when compared with them. &gt; implied that Rust shares all of the performance problems that C++ has I didn't. When I say C++, I mean C/C++/etc. Languages of that kind, which don't introduce a GC or a VM or whatever. What problems are you talking about? Rust can optimize more than C++ based on aliasing info (since that's baked into the language). Generics do lead to larger binaries, but that's rarely an issue.
&gt; I don't consider C++ to be fast any more. Most of the problems you list in C++ aren't (or shouldn't be) issues in Rust as far as I can tell. As I mentioned in the other comment, Rust's type system might not be so interesting if you're from an F# background. &gt; I spoke to a friend who said there are bad interactions between the borrow checker and generics that make generics harder to use in Rust Could you give some details? I'm not sure what the issue is here. There are some fiddly things but they only come up if you try to do some compilcating abstraction-ing. 
It was [previously discussed](https://internals.rust-lang.org/t/more-robust-lifetime-inference/692) over there... Sorry for the noise... (Updated the description to include the link.)
The enum discussion is interesting. It seems they are missing the low hanging fruit though (at least in that RFC) where the enum is a C-style enum and the tags are assigned by hand. Then is becomes much easier since the compiler can know immediately on definition of both enums it can compact them without loss of performance.
I really like the look of the `?` work, nice. Though I don't think that we want to get rid of *all* the `try!`s in the rust-lang repo, we still want regression tests on both `?` and `try!` for as long as the latter is supported.
Thanks! Also, please hop into [#rust-community](https://client00.chat.mibbit.com/?server=irc.mozilla.org&amp;channel=%23rust-community) if you want to chat. Ill update more after work. 
`in_range` make more sense in the opposite order : `num.in_range(1..100)` The range contains a number, the number is in a range. 
The MIR bootstrapping isn't in notable changes? 
Sure, I never said (or even meant to imply) that unwinding is evil. Just that it really bothers me that it gets in the way of things like `&amp;out`. In either case (multi-thread or multi-process robustness) the question is what other complexity you're willing to incur and capabilities you're willing to sacrifice on that altar -- what opportunity costs you're willing to pay. Saying "if your program has a bug, it will fall down" is also a defensible choice, which most other languages have made. Again, priorities and judgment call.
I'd like to take the min or max of 2 float values (f32 or f64). The standard has `std::cmp::{min, max}` however they require `Ord` which f32 and f64 are not. You can emulate this easy enough with this: pub fn min&lt;T: PartialOrd&gt;(a: T, b: T) -&gt; T { if a &lt; b { a } else { b } } pub fn max&lt;T: PartialOrd&gt;(a: T, b: T) -&gt; T { if a &lt; b { b } else { a } } But this has a subtle bug: while the min and max of two arbitrary float values is very clearly defined (NaN if either of the arguments is NaN) in Debug builds the above code will naively compile to a compare (`ucomiss` for f32 on my target) and select one of the arguments which will handle NaNs incorrectly. This is not a problem in release builds as it gets replaced with simple `minss` or `maxss` (f32) `minsd` or `maxsd` (f64) which DOES correctly handle NaN. So my question is, how do I get correct min/max behaviour for floating point types? One that preferably works generically over any numeric type (like the code snippet above).
I think the reason why people consider rust more complex, is because to get basic things working takes significantly more learning. However, once you start working on real-world problems in rust. Everything you learned for the basics transitions directly to your more complex problem. Which actually greatly reduces the complexity you have to deal with at that point. This is the tricky part with python and languages like it, it's like a wolf in sheep's clothing. Simple to start, but the features needed are exponential as you get deeper.
That's exactly what I mean. /u/kibwen: your language is better than mine, want to update the readme with your wording?
Right, I think I get it - It's because `output()` will return a result that is not bound by the current expression, where `Command::new` will no longer be needed... I don't think I actually get it - `let cmd = Command::new(...).arg(...);` seems like it should make sense as it is the same expression and I am binding it to a variable.
&lt;3
Thanks! I asked because I plan to do a talk at my university in Belgium (in French) to *promote* Rust. I have already written a draft and slides for half of the presentation. I will probably need some proofreading to make sure I am not stating incorrect things and or maybe improve the content. I am not sure if this falls under the scope of that repo :)
Great work folks! It was a crazy idea in the first place to create a cross API graphics lib, and it's impressive to see it finally coming to fruition! Bring on the Metal support!
Re: C++ I think Rust could implement a [D-like approach](https://dlang.org/spec/cpp_interface.html) with extern "C++" where it supports name mangling, function call conventions, and vtable for simple classes. This seems like a good 80% solution that solves a lot of problems. It would perhaps be more complicated for Rust than D since it has a significantly different object model than C++ but many things map 1:1. I have doubts as to whether this would ever get implemented, but it seems possible.
python really isn’t. its levels of complexity are well-separated, and idiomatic python is about only using complex, hard-to-grasp things if they’re really necessary (so you won’t usually see modules tampering with the import system) R would be a good example, though. its lazy evaluation and use of things like `deparse` and `substitute` can result in real head scratchers, while being used in popular APIs (e.g. [`ggplot2`](http://docs.ggplot2.org/current/vignettes/ggplot2-specs.html) and the [`subset`](http://www.inside-r.org/r-doc/base/subset) function).
Seeing more stuff built with Racer is fantastic! The more people using it, hopefully the more issues that get filed and PRs submitted!
I didn't expect my call to participation for `multipart` to be on there this week. Does it stay up until the tracking issue is closed then? 
I agree with this 100%. In fact, I still find this to be problematic even after using Rust on and off since a little before the 1.0 release. I tend to come back to the language every couple months, and the thing I have the most trouble with is modules and imports. Way harder for me to figure out what I'm doing wrong than any of the borrow checker issues others seem to run into.
You are binding the result of `arg` to a variable, yes. But that result is a borrow of the `Command` returned by `Command::new`. It is the `Command`'s lifetime that ends with the expression, not the borrow's. Put another way, the borrow from `arg` does not implicitly extend the `Command`'s lifetime to that of the borrow, and that would leave you with a dangling reference when the `Command` is dropped.
Go ahead and file it, you can be our trial run. :P
Oh, we just forgot to take it out. Or do you want us to leave it there?
Sorry, my mistake, I somehow overlooked it. Silly me! Edit: Pushed a PR to add it.
Well I'm not averse to extra publicity, and I do still need help on that issue so I guess it's fine if you guys don't mind. 
Clearly you should have started with an ed clone rather than a vi clone, then you wouldn't have needed to put any work into UI at all. :)
&gt; What problems are you talking about? Can you write a fast generic hash table implementation, for example? 
Could you be more specific? What performance issues are there in this? I don't see why a generic hashtable would be slow in Rust or C++.
Or, if type inference allows, `"".into()`.
Not quite new, and possibly not the easiest question, but: how far is stdlib from stability? What parts are still unstable, and what needs to be done to change that?
Okay, I got what you mean under `?`. The same problem and solution might be here. Personally I hate `try` expressions in any form: Java-like, Rust-like, `?`-like. Over all of them I prefer more "lightweight" `match`, like following: get_Result() : Some(res) { print!(res); } _ {} get_Error() : Err(e) { panic!(e); } Ok(r) { print!(r); } 
Look at https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AB-unstable for an overview.
Welcome! Please let us know any pain points you're having, we care a lot about production use.
Do you know of a comparison between the performance of it and a .NET `Dictionary`, for example? 
For all the talk of ideology, I do kinda feel like you're getting the most worked up about this. Please keep in mind that just because there's a part of C++ that a few people here aren't fond of doesn't mean they're attacking C++ as a whole. Where Rust's features differ from another language's, it's to be expected that some people will prefer it the way Rust does it, and some people will prefer it the way the other language does it.
To clarify, the previous APNs protocol was not HTTP/1.1, it was a custom TCP protocol which let you multiplex "requests" on a single connection. If a notification were delivered successfully, no response was returned, just assume it's delivered. If a notification errored, you would usually get an error response indicating the last successfully sent notification, and then you had to retry all notifications sent after the error. fwiw, monitoring CPU usage seems to suggest the Rust based system spends far less time in user-space code.
You can use private items in any of its submodules, so if the inline tests are defined in the same module, or in a submodule (often `mod tests { ... }` at the end of a file) things should work OK.
You should put that link into the README. I'd also use an Endianness enum instead of `little_endian: bool`. Apart from that, I fail to see the "distributed" part, perhaps some docs would help. The code looks pretty rustic to me, btw.
No idea off the top of my head, I've never personally worked with .NET (I rarely end up using Windows at all), but Rust uses an aggressive algorithm (Robin-hood hashing, allowing high load factors, and also not forcing separate chaining for collisions like C++'s `unordered_map`) and of course exploits Rust's control over memory to get good cache behaviour. If you've got a set-up you want tested and access to the environment you're interested in, you're free to write your own benchmarks. You'll want to be aware that Rust's hashmap defaults to a relatively secure but expensive hash function to defend against hashdos, but this can be controlled.
Nice. Pretty impressive binary size as well. We have a Java jar that we distribute that is roughly 50mb in size and a server app that runs with 100 threads and consumes 20gb when running full bore. So really it is pretty impressive how little memory is consumed by so many threads.
`f32` and `f64` do define [min and max methods](https://doc.rust-lang.org/std/primitive.f32.html#method.max), so you shouldn't need to reimplement these yourself. Genericity over numeric types in general is not possible right now AFAIK.
Is there a reason why the Rust docs site doesn't have a search? (Go has one on the top-right) If you're trying to keep the site static html, I could help you implement lunr.js or a custom trie-based js search if you want.
The "distributed" part comes from how you'd use it - in a large(ish) distributed system you might have hundreds or thousands of actors creating new objects in your database. A flake implementation gives you unique, ordered object-level identifiers. In an RDBMS you might use an `AUTOINCREMENT`, `SEQUENCE`, or `IDENTITY`, but that generator can eventually become a bottleneck. A flake generator is run at the point where you create that object identifier itself. It's a distributed system, but it's a nice little helper for one. Thanks for the suggestion - I'll add the link and more information to the `README`. And thanks for the compliment! This is the first chunk of rust I've written, and hopefully not the last.
Great! Basically, the official book should be able to guide you along your way. Some main differences between java and rust are things like stack/heap difference and value vs. reference semantics. Some other things you don't have in Java are rust's `enum`s and pattern matching, rust's error handling, and traits (although they are *somewhat* similar to interface, but used in a different manner). If you're familiar with java 8's streams and lambdas, that should also help you get comfortable with the iterator api rather quickly. All in all, I would say the book is a great starting point. Also, if you get stuck, don't hesitate to ask questions, for example in one of the official rust channels! #rust and #rust-beginners on mozilla's irc are two were you can always find help. Good luck! :)
Oh, interesting, had no idea about that. Thanks. Very much looking forward to the write ups.
We use glutin as one of the GL context providers. The PR doesn't have anything to do with it.
I hadn't heard of this project before, so I figured it could use some advertisment. But just now I looked at its crates.io stats to see that it has almost 200,000 downloads, so I may just be out of the loop here. :) https://crates.io/crates/solicit 
This is like using raw `match` and `try!` is just wrapper around that. I do not see any magic in that solution, it is just using power of the language to simplify common task. On the other hand `?` is making language more complex just for sake one simple task that can be accomplished with macros. 
Sorry, yeah I just mean searching for "Rust Docs" returns https://doc.rust-lang.org/ and the first link is https://doc.rust-lang.org/book/ and the second is https://doc.rust-lang.org/reference.html both of which lack searches. Arguably the second link doesn't need a search because it's one big page but browser in-page searches lack stemming (etc)
It's not quite what you are looking for, but maybe /u/pcwalton's [gaol](https://github.com/pcwalton/gaol/) might also helpful for this?
So yes, the only reason the book doesn't have one is that nobody's built it. Such a thing would be awesome, and it would need to work as static HTML.
Here's a [Rust/Java](https://www.reddit.com/r/rust/comments/486fdz/blog_comparing_rust_and_java/) comparison if you missed it.
This is great to see! I'm excited about more companies using rust in production. Sort of offtopic, but can you clarify what you mean by: &gt; This remains true even for implementations where Ruby threads map directly to operating system threads. Do you mean that code implementations using, (e.g. `Thread.new`) are still subject to the GIL? Because I thought other _ruby_ implementations (e.g. JRuby) could have true concurrency.
You're totally right about JRuby - I forgot about it completely! I'll update the article accordingly. Thanks for mentioning it!
cc /u/llogiq
How did developers feel about the rust tooling, compared to longer lived Ruby and such?
I can't speak for anyone else, but personally, I'm mostly happy with Rust tooling. Big heavy IDEs were never my thing. All of my editing was done in vim. My vim installation includes rust.vim for highlighting and syntax errors, and YouCompleteMe w/ Rust support for auto-completion and go-to. My main complaints are some bugs with `racer`. Completing `cmd::` where the module `cmd` has a function named `cmd` will recurse indefinitely until it crashes. There's also an issue resolving ~50% of crate paths, so completions aren't provided for those. There's also a bug with racerd where the file cache is not updated in some cases resulting in stale completions, but that one is on me XD. Disclaimer: I wrote the racerd wrapper for racer and integrated racerd with YCM. You can read more about YCM + Rust in the [announcement post](http://blog.jwilm.io/youcompleteme-rust). Edit: Forgot to mention standard compile time complaint.
I recently got faust (a DSP language) working with rust. This week I'm trying to get my [faust-rust audio program](https://github.com/bburdette/fraust-echo/) to work on ARM, either with portaudio or with alsa. 
Nope. I remember hearing noise about this being worked on, but there's nothing in-tree yet.
I built the example with Rust 1.7 and disassembled the output. The compiler did an in-place initialization. Memcpy was not needed, or at least not literally used -- the compiler just stuffed the constant values into memory via a register. So, that's respectable. I still wonder if copies don't sneak in when initialization is more complex that just integer constants.
Definitely an index of all the method names at the top.
There are a number of things to unlearn from Java, but let me just suggest you install a nightly plus [clippy](https://github.com/Manishearth/rust-clippy), it will (besides other things) warn about some Java-isms. Apart from that, try to go as much borrowed and as immutable as possible. You may also read my [blog](https://llogiq.github.io) for further information.
I want to calculate the difference between two u32. I casted both to i64, subtracted them from each other and called abs() on that. 1. Does this work? Is there some danger of an overflow or something? 2. How expensive is this way of dooing this. (just curious, it probably doesn't really matter) 3. Is there a better way to do this? 
Yeah, data movement is only semantically a call to `memcpy` (i.e. a byte copy), the compiler is free to optimise it to something more efficient than literally calling the function. &gt; I still wonder if copies don't sneak in when initialization is more complex that just integer constants. I still don't know what you think "copy" means, but nothing fancy happens: moves are always byte copies, "copies" of `Copy` types are always byte copies.
I'm trying to use [`GlyphCache` from the `opengl_graphics` crate](https://github.com/PistonDevelopers/opengl_graphics/blob/master/src/glyph_cache.rs) to render some text via `piston_window::Text` (which is a [re-export of `graphics::Text`](https://github.com/PistonDevelopers/piston_window/blob/master/src/lib.rs#L77)). The problem I have is that the compiler complains: &gt; the trait `graphics::character::CharacterCache` is not implemented for the type `opengl_graphics::glyph_cache::GlyphCache&lt;'_&gt;` I can see the implementation of the trait at [the bottom of `GlyphCache`'s definition](https://github.com/PistonDevelopers/opengl_graphics/blob/master/src/glyph_cache.rs#L120-L134) so I guess I'm missing something obvious. Here's a relevant part of the code if anyone wants to dig in: https://gist.github.com/vrinek/0ffc516733e293aacd9d
and my point is that you don’t need to learn all of python to be productive and to understand 99.999% of al code you’ll ever see.
In brief, from Jonathan's bio: &gt; I led the TypeScript team from its initial release to its use in major frameworks. I also helped design parts of Clang/LLVM, Chapel, and ChaiScript. I've never heard of ChaiScript, but TypeScript is a great project and Chapel (a massively-parallel programming language for supercomputers) is quite relevant to Rust's domain. And of course it's always great to have another LLVM expert on hand. :) This looks like a great hire!
IPv6 is disabled on my server and `make check` always fails at IPv6 tests. How can I **conveniently** make sure any other tests are not failing? Currently I use GNU Screen and manually search for "failures:" in the transcript to make sure the failed items are all about TCP/IP. My major concern is if I might be skipping a whole section of tests following them. failures: net::tcp::tests::clone_accept_concurrent net::tcp::tests::clone_accept_smoke net::tcp::tests::clone_while_reading net::tcp::tests::close_read_wakes_up net::tcp::tests::close_readwrite_smoke net::tcp::tests::connect_loopback net::tcp::tests::double_bind net::tcp::tests::fast_rebind net::tcp::tests::multiple_connect_interleaved_greedy_schedule net::tcp::tests::multiple_connect_interleaved_lazy_schedule net::tcp::tests::multiple_connect_serial net::tcp::tests::partial_read net::tcp::tests::read_eof net::tcp::tests::shutdown_smoke net::tcp::tests::smoke_test net::tcp::tests::socket_and_peer_name net::tcp::tests::tcp_clone_smoke net::tcp::tests::tcp_clone_two_read net::tcp::tests::tcp_clone_two_write net::tcp::tests::write_close net::udp::tests::socket_name_ip4 net::udp::tests::socket_smoke_test_ip4 net::udp::tests::udp_clone_smoke net::udp::tests::udp_clone_two_read net::udp::tests::udp_clone_two_write
It's a good start that you're here on /r/rust. There's arguably no better place to fast improve your Rust skills.
Alas, my existence finally has meaning! https://github.com/cybergeek94/multipart Enjoy. If you're using Hyper 0.8, by the way, I'm working on an upgrade to that. Edit: I've published the upgrade as `0.6.0-alpha` to make it easier to try out. 
I'm certainly not opposed to the idea, but I think it's just slightly too far outside the scope of Rust as a language.
What confused me most about this is uninformative error messages ("xyz was not found") and the fact that "use" needs to phrased differently in different places (e.g. `use x::y::z;` externally from library `x`, `use z;` from within module `y`, except when its in a test case in which case it's `use y::z;`).
What are the chances of using D3D12 and /or Vulkan as well? They're pretty different as I'm aware, so this might be a trouble. 
I actually have a mentored project for creating samples, as tracked [here](https://github.com/cybergeek94/multipart/issues/29). It's slow going, but they're only volunteers so I should probably be grateful that they're giving any time at all. The best sample I have currently would be in [this integration test](https://github.com/cybergeek94/multipart/blob/master/src/local_test.rs) which submits a request through a mock API, reads it out on the other end, and compares the two. I've also put a lot of work into [the documentation](http://cybergeek94.github.io/multipart/doc/multipart/index.html). 
Vulkan is our most important target at the moment, and the chances we get it this year are pretty high. There is also a little chance for the Metal backend from /u/fkaaaa, and D3D12 is not a priority because the only platform that really needs it is Xbox One. All these next-gen APIs are very possible with GFX. They are different from last-gen, but we've been preparing to get them on-board. The biggest thing was getting the architecture centered around [PSO](https://www.reddit.com/r/rust/comments/425muq/repost_from_rust_gamedev_gfx_adopts_the_pipeline/).
Very cool! This is the first time I see someone instantiating a Rust parser outside of rustc.
EDIT: This is incorrect, see replies. I have a serious problem with this solution. Something as simple as 'find the signed difference between 2 unsigned integers' should not involve a branch. Would this work: `b.wrapping_sub(a) as i32`? Playpen http://is.gd/XRa8yA suggests that yes it is correct (works in Debug mode). disclaimer: I base my view of correctness based on what the compiler and debug output say, if it is incorrect I assume that debug assertions should have caught it.
It's easily the most controversial feature I've seen implemented. 
Any reasons? I kinda like it. It does not complicate the language and makes code "easier to read". However, it depends. In code where error handling is rather uninteresting, `?` takes those way larger `try!`s out of sight so that one can better focus on what is actually about to be done. And in code where the side effects of error handling might cause rather surprising control flows, `try!` is not as easy to overlook as `?` is. And, of course, `?` beautifies chained `try!`s a lot. However, most `try!`s aren't chained up.
`//!` comments refer to the enclosing item, usually used to document the contents of a file by adding it at the top of it. `cargo doc` also by default only documents the public API, at the moment I do not recall any switch to make it document private items. So change `//!` to `///` for `main` and then declare `add_one` as `pub` and it should hopefully generate some HTML for you. Edit: `cargo rustdoc -- --no-defaults --passes "collapse-docs" --passes "unindent-comments"` will also produce documentation for private items.
`//!` documents the containing module. It should look like this: //! This module does stuff. //! //! It does this really well. /// Just a function in this awesome stuff-doing module. pub fn do_stuff() { println!("Stuff!"); } And documentation is - as far as I know - only generated for public modules and function. This is not a Rust-binary-instead-of-library issue, as documentation for the binary I'm working on works just fine.
Because `?` is lang-item (not operator), and cannot be made operator in current Rust state. I truly believe that event with HKT `?` would be impossible to implement as an operator. Actually `?` complicate language a lot as it now needs to know about `Result` type or about `try!` macro to expand it at compile time. Instead I would rather see fixed `and_then` implementation that allow returning changed error type and maybe we should abuse `&gt;&gt;` operator for `Result`s to make it work like `Result::and_then`. It would allow us then to write code like: may_fail() &gt;&gt; process_data &gt;&gt; more_process but this would require sometimes things like: may_fail() &gt;&gt; |r| { do_stuff(r, 1, 2, 3) } &gt;&gt; do_more_stuff Also `?` is so easy to be overlooked that I consider it harmful. **EDIT:** Oh and when we will have HKT then it will be possible to have `do`-like notation so `?` will be de facto unneeded. **EDIT2:** Chaining `Result`s is bad idea. I consider more than 3 `try`s in a function a code smell (it became almost untestable).
I can understand as I am strongly against it and I really hope that this will never land in stable.
I'm not sure if this is the issue, but you're adding a doc comment to a private (not `pub`) function, which don't get rendered by rustdoc.
As a new user, I found this to be particularly frustrating. I also couldn't tell you exactly why my current mod / use setup works, although it does for the moment. It's not necessarily the part of rust that takes the most time to learn, but I think it's more frustrating than usual, since it's something that feels like it should be very easy.
I haven't seen much code with nested `Result`s. Also, it's a new operator that's just saving 3 characters compared to `try!`.
Those are quite some really good points against `?`. I am convinced.
Recursive parsing can be annoying if you have to keep state outside of the parser, like line numbers. As [/u/TouchingBrain](/u/TouchingBrain) said, you can avoid using `named!` as it is just a convenience macro. That way, you could have a parser written like this: fn block(input: &amp;[u8], level: u8) -&gt; IResult&lt;&amp;[u8], &amp;[u8]&gt; { alt!(input, apply!(start_config) =&gt; terminated!( stuff, apply!(end_config)), apply!(start_external_ref) =&gt; terminated!( stuff, apply!(end_external_ref)), tag!("{") =&gt; terminated!( apply!(block, level + 1), tag!("}")) ) } `alt!` or `switch!` are commonly used when there are multiple alternatives, and you can use `call!` or `apply!` to pass arguments to sub parsers.
As usual controversy is inversely proportional to significance.
I don't like this syntax. Try tells me that it could fail, but ? seems a bit too much magic.
It's a simple decision: use an algorithm that is fast in many cases but breaks down catastrophically in some or use one that is slower in most cases but works well enough in all cases. If you choose the former, you'll open your code to HashDoS attacks, which are hard to debug (because you'll be using more than one HashMap). In the latter case, you can easily profile first to see whether a more optimized hash is worth it.
Are not rustdoc, rustfmt and racer doing this?
&gt; I would rather see fixed and_then implementation that allow returning changed error type How would that work? How does `and_then` change the error type that isn't covered by invoking `map_err` first?
It seems you missed the int apocalypse 
I'd like to add that `?` being a suffix means that it can be missed when not reading _far enough_, making it possible to miss hidden early returns. `try!( )` clearly marks scope and the danger of that.
&gt; `get_mut` also uses just `Borrow` and not `BorrowMut` (since it's the key that's borrowed, but the `get_mut` applies to the value in the map) Oh, of course, lol. I even looked it up during my troubleshooting and somehow still typed it wrong. Oops! Maybe I merged Borrow and &amp;mut in my head and out came BorrowMut. Anyway, thanks for the correction. &gt; since the error messages is quite devoid of any details (no information on what conflicting requirements, which is usually available in these kinds of messages) I'm wondering if it's a bug with lifetime checking, a bug with the error messages, or both. I was starting to wonder about that too. I was able to coerce a similarly not useful message about inferring an "autoref" lifetime by explicitly annotating the result of get_mut. Maybe that has something to do with it? &gt; It might make sense to post this to [the users discourse forum](https://users.rust-lang.org/) to get more exposure on it. Thanks, I will try that when I'm not mobile anymore.
But try is inside brackets, so it should be able to figure out how it ends with regular expressions. I am just not too good in them to do it myself. You could even create a regular expression to find out whether something is valid rust code syntax. Its just very complex.
No, you can't match arbitrarily nested balanced parentheses with a regular expression. (One wonders whether `rustc` does has a fixed depth limit...)
Not by a long shot. :) I think that this is one of those areas where users of Rust and prospective users of Rust disagree. Look at HN threads, where you have more of a cross-section of the wider programming community. I see a good deal of people complaining about Rust's error handling story, mainly due to the verbosity of `try!`. When using the language for a while, you get used to it, but I think it's also worth considering the impressions of people coming to the language for the first time. Edit: As a matter of fact, here's a comment just today by someone who wants the `?` syntax (although they don't know it): https://news.ycombinator.com/item?id=11338406
* It's a *significant* cognitive load to someone who's reading code. Suddenly, every function that returns a `Result` may contain a `?`, which you have to actively look out for. And there's *no* way I'm going to rely on my brain to keep track of lots of things at once. * `?` is really easy to overlook, especially if you're debugging code at 4 AM. Your eyes are sore, you yawn all the time and the code in front of you looks like an alphabet/symbol soup. I'm pretty sure that playing hide and seek with question marks is *not* going to be fun. EDIT: To put it in another way, `?` is a "small" construct with big consequences wrt control flow execution, which I personally don't like.
This may be relevant: https://github.com/das-labor/panopticon (I'm not affiliated in any way) We also have bindings for capstone for decoding instructions: https://github.com/richo/capstone-rs/ I'm not very experienced so I don't know what you need and what Radare does, but I hope these give some ideas.
Its a good example actually of the advantage of this syntax over try. You can remove the temporary without hurting readability: for file in fs::read_dir(dir)? { if file?.file_name() == *"compiletest-ignore-dir" { return Ok(()); } }
Yeah I can't think of a reason this syntax would ever be necessary in a function signatures. But it's necessary in the case you mentioned, or in `match` statements, when you're working with a value that you're not allowed to move. I guess it made sense to define a general piece of syntax that's valid everywhere?
There is a radare-based decompiler written entirely by Rust. You should see it. https://github.com/radare/radeco-lib
I am not sure if this is possible, but something like that: impl Result&lt;T, E&gt; { fn and_then&lt;K, E1: From&lt;E&gt;, F: Fn(T) -&gt; K&gt;(self, f: F) -&gt; Result&lt;K, E1&gt; { match self { Ok(v) =&gt; Ok(f(v)), Err(err) =&gt; Err(err.into()), } } }
GitHub is highlighting `?` and doesn't highlight `try!` and I still find it easier to look out for `try!`. Also I do not see nested `Result`s often. Also I do not think that chaining `?`s is a good idea. I do not often see more than 3 `try`s in one function and I think it is good idea as more than that make testing your function almost impossible.
Yeah `cargo fetch` without any targets is a legitimate use case. You can file a ticket at Github.
Adding more lints for pointer math checks for instance would be handy ("hey you clearly are addressing beyond the size of the object, are you sure you meant to do that?").
That's a nice sum-up of the situation. Unfortunately, as much as compile-time reflection would open new possibilities, it does bring one issue: it exposes the *internals* of a `struct`, which is a violation of privacy and might introduce unsuspected dependencies on said internals in the downstream crates.
It will probably look better on new code that intends to use it. /u/Quxxy implicitly brings up a good point. `try!` has a chilling effect on writing code with `Result` because it can be unwieldy. It a) encourages less code to use `Result` at all, though the rust community is fairly panic averse so I don't think there will be a huge leap in the number of `Result`s you see. And b) `try!` often forces you to use more temporaries because it adds so many characters and because chaining is so unwieldy. I suspect the 2nd reason will see a lot of improvement to new code written. One of the examples in the RFC that was convincing to me was builders that return `Result`. You can have either: let foo = try!(try!(try!(FooBuilder::new().set_a(1)).set_b(2)).set_c(4)).build() or: let foo = try!(FooBuilder::new().set_a(1).and_then(|b| b.set_b(2)).and_then(|c| c.set_c(3))).build(); or: let foo = FooBuilder::new().set_a(1)?.set_b(2)?.set_c(4)?.build() When designing interfaces I'm extremely adverse to anything like the first or the second because they are so unwieldy.
More to the point, unlike Haskell Rust code *is already in a monad*. (This is why it gets to have control flow, as well as side effects.) Recreating the whole monadic infrastructure in parallel within the existing monadic language would just be overengineering. Better to make the ambient monad we're already in more capable. How would people feel about continuations? :P
Isn't the point of `unsafe` that it's for when the compiler gets in the way by trying to help? E.g. for pointer math, the compiler can't tell if you're using the pointer as an array intentionally or not. If you want that check, use a reference.
I wouldn't r+ any of your code fragments, due to all of them being illegible. Try this: let foo = FooBuilder::new(); let foo = try!(foo.set_a(1)); let foo = try!(foo.set_b(2)); let foo = try!(foo.set_b(3)); let foo = try!(foo.set_c(4)); let foo = try!(foo.build()); 
Self-referencing is usually quite hard to get right, because when an object contains a reference into itself it can no longer move. Having a reference into a `Vec` means you can't do stuff like pushing additional elements to that `Vec` because it might resize and invalidate the reference. [Using `Rc` instead of `Box` fixes your problem](https://play.rust-lang.org/?gist=3f92c7fa6e3c3b00f425&amp;version=nightly).
Because it has to run on stable?
I still think there are useful techniques to learn, even if sometimes very specific. Once you ask yourself: How did they come up with that? you're on the way to new knowledge. I for one have got quite a few % of speedup by doing similar bit twiddling. Regarding Java: The JVM pulls an obscene amount of tricks to make the code run fast despite pointer chasing &amp; suboptimal memory model. Truly an engineering marvel. And yes, value types *are* the better solution (which is why Java will get them), but IME not required for high performance code under many workloads. Of course YMMV. I don't see the big benefits of run time code generation though.
It's generally a nasty to track source of bugs and surprising behavior. Maybe I'm just picky there, but I'd generally like to see where things happen very clearly.
It is well known that Java apps can be quite memory hungry. Though at 20G heaps, you still can use `-XX:+UseCompressedOops`. I have batch jobs running here that take 90G heaps...
It may not be tricky, but it would definitely require changes to cargo to send some extra metadata about why it wants a certain crate, so it would take a while before those stats could show up.
I don't like try, because i can't use it in method chaining `obj.thing().maybe_thing()?.thing();`, nesting function calls become horribly hard to read, so macros are not flexible enough for this. The idea of symbols is that people use it often enough that it can be remembered and that specialized syntax is worth it. `?` would be used more then `..` the range syntax. Personally i would like the range syntax gone more then the question mark, ranges could really be macros while try could really be syntax.
Beautiful. Thank you very much! What you said about self-referencing makes sense too. Is there a reason this code requires the nightly version of Rust? Switching it to stable gives a playpen error instead of a rustc error. Maybe they're just having issues right now?
I think that `?` wins the most in your last example, in the more artificial ones try looks half decent because everything lines up, there not so much. let foo = FooBuilder::new() .set_algorithm( ALGORITHM_NAME, 16, 4 )? .set_message_length( 4 * 1024 )? .set_encryption_key( enc_key )? .set_mac_key( mac_key )? .build()?; This would look even better with syntax highlighting for `?` instead of attempting to get slightly fancy with unicode.
Why would you be running it if you only had stable rust installed? I don't see that being a restriction.
Also most of the Rust patterns around composition are a result of borrow paths, and will thus come quite easily.
A Result-oriented builder like that definitely benefits from `?`, but wouldn't/shouldn't most builders return a Result from `build` rather than the individual builder methods? Unless you're doing arg validation along the way, I suppose.
This is my top complaint too. Error handling is generally a complicated affair, and I think rust's `Result` type is a solid solution, but it can be cumbersome to use. I haven't quite figured out the best way to manage composed error types just yet.
Coming from C++, I fall into the too many features camp. I don't want to see Rust become huge like C++.
I prefer your first indent style and that's what I use in my rust code. Beyond vim fighting me sometimes, I don't see any restrictions on this.
EDIT: Turns out xmm min/max don't work how I thought they did, see replies Yes I consider my generic version to be incorrect in the face of NaN, hence why I asked here. My `RustMeUpmin` however is correct in release builds (there's some argument to be made that optimized builds should not change observable behaviour which this most certainly does but I'm not versed too well in compiler theory). Do you have a reference for your assertion about min? I found this [Wolfram](http://mathworld.wolfram.com/Minimum.html) article but both properties `min(x, x) = x` and `min(x, y) = min(y, x)` hold in the face of NaN. Even still there is a function that returns the smallest of two floating point numbers and NaN if either of the arguments is NaN. It doesn't matter what this function is called. This function is implemented in hardware and I'd like to access this hardware instruction from rust code. Furthermore I'd like the ability call this generically over integers and floats, this is not possible right now but I guess this ability will come with specialization. There's an argument to be made about "correct min/max" and I'm sure it's an interesting problem but I come from a more practical angle. There exists a hardware instruction for min/max and that's good enough for me.
&gt; Suddenly, every function that returns a Result may contain a ?, which you have to actively look out for. Why would you have to look out for it? You've already established that the function returns a Result, the presence or absence of `?` does nothing to change the type signature of the function or change the contract that the type signature represents. &gt; ? is really easy to overlook, especially if you're debugging code at 4 AM. Again, I don't see how overlooking `?` could possibly be a problem. The compiler will tell you if you get the type signature wrong, and if the type signature is right then the compiler is already forcing you to handle all the proper cases.
 OK, just tried it by making my functions public and it worked! So I guess, what do you do for documentation generation for private functions and modules? doxygen or something similar? 
It seems to work fine on stable for me. Did you reintroduce `Any`? Because I think that trait is not stable yet, so it would work only on nightly. Instead of a reference you can also keep track of an index, and use the index to get a reference only when you need it.
Why would you want to document functions no one is able to use? If you document for yourself, having normal comments in the code should suffice.
It turns out I interpreted the OP's post incorrectly and concede that llogiq's answer is correct. My mistake was that due to my display's width it wrapped the _abs()_ requirement to the next line and I didn't notice. This makes llogiq's answer correct and mine incorrect.
isize used be called int, and usize used to be called uint. There was a lot of argument about what these types should be called.
That is mostly just a scaling thing. We've decided to go out instead of up. We have a small cluster of 6 12 core boxes which each consume around 20gb a piece when they run full bore.
I did one you might be interested in. It's kinda poorly made, doesn't compile anymore and I don't have time to update it at the moment. There's a huge list of things I want to change. It uses some old LLVM bindings that are no longer maintained - at some point I plan to update it to use iron-llvm. https://github.com/nwoeanhinnogaehr/synthizer
While I'm somewhat indifferent to the `try!` v. `?` debate, minus a healthy dose of conservative skepticism, the only thing I do have strong feelings about is that I dislike the `?` being at the *end* of the line as others have said as well. I find it very easy to miss. I'm assuming placing it as a prefix would have made chaining difficult, but I'm curious if something like this will become a code smell or not: let foo = FooBuilder::new() .set_algorithm( ALGORITHM_NAME, 16, 4 ) ?.set_message_length( 4 * 1024 ) ?.set_encryption_key( enc_key ) ?.set_mac_key( mac_key ) ?.build()?; Obviously not perfect, but at least to me calls attention to early returns. EDIT: I even have mixed feelings about the above, because it calls attention to the presence of early returns better, but then also takes more cognitive load to process which line is actually returning.... sad face
Thank you, this is a very good observation. I think I now follow a similar line of thought - I don't know about continuations but I would like to see something like the proposed C++17 generalized co-routines in Rust.
That example looks horrible.
In my experience, a Rust implementation of a thing is roughly twice as fast as your run-of-the-mill CLR implementation. I write C#, not F#, but I reckon they're fairly comparable. You can add or subtract a bit for jitting depending on what you're doing. Please note that I'm comparing only *my* implementations of things--and I don't tend to go out of my way to optimize anything that isn't painfully slow.
&gt; try! always returns, which might not be what I want, instead ? lets me have a way to handle errors prematurely. `?` currently does exactly what `try!` does. `?` with the planned `catch` statement will let you catch the early return and handle it like your examples sugges. (As will `try!` part of the RFC included making try use `?` under the hood).
`try!` is not good enough to do everything `?` would, its an improvement. We need to stream line error handling one way or another, `try!` is not enough, its way to restrictive due to it being a macro.
Rustdoc is something the users of a library read, and they should not know about private functions – after all, the library author reserves the right to remove or change private items of their library. Having comments in the code to explain or motivate design decisions is a good thing, but those concern people working on the code, which usually read the code directly, no the rustdoc-rendered output.
Then try to do this: `file.try!(file_name())`, it doesn't work for obvious reasons. This is what i want `?` to fix.
Just got my GBA emulator to run some code, so I decided to push the first progress onto a [public GitHub repo](https://github.com/Evrey/GBArs). This is, however, not my working repository.
&gt; Even still there is a function that returns the smallest of two floating point numbers and NaN if either of the arguments is NaN. Note x86 `MINSS` / `MINSD` don't work in that way. - http://www.tptp.cc/mirrors/siyobik.info/instruction/MINSS.html &gt; If only one value is a NaN (SNaN or QNaN) for this instruction, the second operand (source operand), either a NaN or a valid floating-point value, is written to the result. 
I don't. Private functions and modules are private because they are of no interest to the outside world. Therefore, they aren't documented.
&gt; Why would you have to look out for it? You've already established that the function returns a Result, the presence or absence of ? does nothing to change the type signature of the function or change the contract that the type signature represents. I'm not talking about the function signature. I'm talking about the fact that it breaks the control flow of the function in a way that it's not instantly attention-catching to me. And this makes it harder for me to reason about whether or not the execution state is consistent if a function returns with a failure (If this function fails, will that 100 MB temporary file it created be deleted?). &gt; Again, I don't see how overlooking ? could possibly be a problem. The compiler will tell you if you get the type signature wrong, and if the type signature is right then the compiler is already forcing you to handle all the proper cases. I'm not talking about compilation errors here. I'm talking specifically about debugging. If Debbie wants to debug (pun intended) a function because of a `?`, I'm pretty sure there will be times where she will accidentally skip it over and over again. If humans [can't see things right in front of them](https://blogs.msdn.microsoft.com/oldnewthing/20080101-00/?p=23963), I'm positive they will skip over a teeny `?`.
 try!(file.and_then(File::file_name)) or even that: for file in try!(fs::read_dir(dir)).filter_map(Result::ok) { if file.file_name() == "compiletest-ignore-dir" { return Ok(()) } } Or similar. There is a lot other ways to solve that.
So one of the more important issues is that you can't actually serialize arbitrary fields in a meaningful way. This is why trying to compare Go and Rust tends to fall down. Lets take Ramp for example, since it's my crate. The Int type contains three fields: a length, which also doubles as an indication of the sign, a capacity, and a pointer to the actual data. Serialization of this can't be done automatically, since it needs to understand how to interpret the data behind the pointer. Cross-crate metaprogramming *sounds* nice, but as mentioned, it exposes type internals. This means that basically any structural change somebody might do is potentially a breaking change for someone.
But that make language per se much more complicated as now language needs to know about `Result`. There is no other way to use that than introducing new lang item, which we should reduce, not introduce new. Also, Rust chose to use return values instead of exceptions and now people want to use language as it had exceptions. Why? Why you people want to do so? You had quite nice and quite simple language for system programming and now you want to make it new mix Java and Go for web development. Just why? Use Go/Java and jump tu Rust when needed.
`impl&lt;T, U&gt; Into&lt;U&gt; for T where U: From&lt;T&gt;` and `impl&lt;T&gt; From&lt;T&gt; for T` together mean `impl&lt;T&gt; Into&lt;T&gt; for T`. You can do this regardless you want or not: let id = Id; let id2 : Id = id.into(); This causes the conflict.
Even so, I would rather welcome `|&gt;` (or would abuse `&gt;&gt;`) operator than `?` for that.
Let's say I'm prototyping some code and I want to leave concerns about error handling for later. This is exactly the use case for unwrap: blah(foo.bar().qux(baz).unwrap()); But of course, once you're ready to commit to something beyond a prototype, unwraps should be excised from your code. We want to propagate this error instead, but it doesn't suffice to just make edits where the unwrap is: we also have to seek back to the start of the expression and make an edit there as well: blah(try!(foo.bar().qux(baz))); This is what I mean when I say that `try!` requires non-local edits. Alternatively, with `?`, all that needs to be done is to swap out the unwrap, which is a trivial find-and-replace: blah(foo.bar().qux(baz)?);
But when you compose you do not store `Result` but simple value. So where is need for long chain? We need real world examples or we end like JS with `with` statement.
OsString/OsStr should work in this case. 
Yeah, I just don't know if the argparse libraries produce them or not.
As /u/CrumblingStatue states, `clap` supports values which aren't valid UTF-8 for exactly the reasons you state. If you have any questions, or need any help with it don't hesitate to ask! 
I never said i wanted exceptions, i never claimed that you did. I never said we had to use `Result` neither, `try!` all ready uses result and looks awful doing it. The `?` syntax should probably have a trait, just like `+`, `-`, `*` and all other operators have, `Result` can implement that trait making it ready to use, while if you have other types of errors, then you would just go ahead and implement it. So yes i agree, fixing this to `Result` would be a terrible idea, but its exactly what we're doing now, we wrap `Result` in something and reuse it everywhere.
Ah, I understand. Thanks for the explanation! I'm still not entirely sold on `?`, but the "local" edits thing seems nice
`Result`s chain is one of the reason why I am against this syntax as it will encourage people to write untestable code.
It looks like the `std::env` module [duplicates most of its interfaces](https://doc.rust-lang.org/std/env/index.html) so that you can choose between `String`s and `OsString`s. That seems like kind of a shame. If it's too inconvenient to have only the `OsString` functions, does that mean the `OsString` methods are lacking, or maybe that some other interfaces need to add support for it? We might unintentionally be encouraging people to write buggy code. (Admittedly it took me a long time to figure out how `OsStr` and `OsString` are supposed to be used, so maybe forcing beginners to confront that type just to read their args is sadistic?)
In theory, some kind of trait could have been made, yeah, so that you could pass either. Or maybe `Into` or something. I'm not sure about `std::env`'s design history, I guess.
Sure, it's not an issue if you've got a great IDE customized with plugins. :P And yet it's still strictly more difficult. &gt; searching for ? isn't that easy as searching for try! This makes no sense. I'm also a vim user, let me show you how I'd do this (note that this one *doesn't* require any plugins): /? Done! :)
Perhaps the author used its own source as a testcase, like a self-hosting compiler.
I call it that in Rust (any other language that I am aware of does not have such operator).
Except when you are using very magic, or using Ag, or grep, or `sed`, or AWK, or Perl regex, or Ruby regex, or Rust regex, etc. But IDE is created for plugins. So there can be plugin for both, of course changing into `try!` will be longer than single `sed`, but not impossible in any current IDE that I am aware of.
`clap` has the option of [`&amp;str`](http://kbknapp.github.io/clap-rs/clap/struct.ArgMatches.html#method.value_of) or [`OsStr`](http://kbknapp.github.io/clap-rs/clap/struct.ArgMatches.html#method.value_of_os)
&gt; making memory live for longer than expected I was thinking more in terms of files. Something akin to "you're creating a big file but you want to unlink it if something goes wrong, so that you don't waste unnecessary space on the user's disk". &gt; It stands out immensely. Unfortunately, I'm going to agree with what /u/thiez said in the sibling comment. 
This is very good news, I happen to be giving a presentation at my job tomorrow to attempt to convince them to switch a service from Node.js to Rust based on a rewrite I did, and this is just one more argument that I can use in my favor.
Awesome!
Great news.
Isn't the main difference between trait vs generics dynamic dispatch vs static dispatch? Also, don't the rust generics use traits with bound generics? And isn't the main trait faster compile times, slower code, smaller binaries with traits only and longer compile times, larger binaries, and faster code with generics?
Would you switch now though? Given that rust and it's libraries are still under heavy development.
There are many reasons why the individual builder may want to return Results. For example, here's a design document for an improved `std::net`, which was one of the strong motivations for the `?` operator: https://github.com/alexcrichton/rfcs/blob/net2.1/text/0000-io-net-2.1.md Note that it creates APIs that look like this today: try!(try!(try!(try!(TcpBuilder::new_v6()) .nodelay(true)) .keepalive(Some(Duration::new(0, 500)))) .read_timeout(None)) ...which would look like this with `?`: TcpBuilder::new_v6()? .nodelay(true)? .keepalive(Some(Duration::new(0, 500))? .read_timeout(None);
I'm much happier with the relevant operator being postfix rather than prefix. Error handling is important, and it's good to be explicit, but it's not so important that it needs to steal attention from the operations that my code is trying to perform on the happy path.
All three of those examples are equally hard to test. I would argue that if you are using the `?` it is unnecessary to test every error condition through the error chain because the function doesn't care about the errors either. The testing would be better served at the level of the `From` impls or functions that have to handle the errors your function returns.
Sure, sometimes fallible builder steps make sense, but it really isn't *that* common. The RFC you linked itself says "the builder-style API of {Tcp,Udp}Builder is not following the conventional builder guidelines due to the ability that each intermediate step being able to fail". 
In what specific way are you concerned about testing?
&gt; chose to use return values instead of exceptions and now people want to use language as it had exceptions. There are both upsides and downsides to exceptions. It's entirely possible that we can trend toward an error handling story that approaches the convenience of exceptions without being *completely implicit* like exceptions are (which IMO is their worst property). &gt; now language needs to know about Result Error handling is such a fundamental aspect of programming languages that this is hardly a high cost to pay. Rust also knows about iterators (specifically the IntoIterator trait), because iterators are also fundamental.
Again, please give an example of how chained operations result in untestable code. I just don't see how that follows.
ndarray slides: http://bluss.github.io/rust-ndarray/talk1/ rendered &amp; tested by rustdoc, based on an old slide deck by kmc. Maybe we can clean up the general parts of that after the talk is done.
Ahh, I see the discussion now, found here if anyone wants a quick link: https://github.com/hyperium/hyper/issues/395 Still just taking my first cursory looks at the language for a pet project so not as up on things as I ought to be. 
Instead of extending a class, you have an instance of that class as a field of the new class. Then, simply delegate to it as needed. 
And part of the reason that it's not common is that `try!` is so unergonomic for fallible intermediate steps. But the causes of errors don't just go away if your language doesn't have a nice way of handling them, all that happens is that those errors are shunted somewhere else. We didn't invent the aforementioned `std::net` RFC because we wanted to justify the existence of `?`, we invented it because that was the API that felt most usable, but for the existence of `try!`.
Given: http://seanmonstar.com/post/141495445652/async-hyper Even though its not quite ready, if someone is investing time into testing/benching something. It might make most sense to test against Hyper(internally Mio + Rotor + HTTP parsing). 
&gt; This video is currently being transcoded Can't wait!
What do you mean by "correctly" handle NaN? The (secret) spec says any comparisons involving NaN should evaluate to false, as far as I know. Inconsistent behavior of compiled code in debug vs release builds is a bug that should be reported.
Just got approval from my employer to release snowpatch, a CI tool for open source projects with mailing-list-based code review workflows. We're going to spend another week polishing it up, but should be released soon. edit: if anyone's interested in following along, we've got a mailing list at https://lists.ozlabs.org/listinfo/snowpatch and we'll announce when we're up on GitHub
I am on mobile so this may be off... but you need to pull the trait in to scope before any types will be considered to implement it. That means in your `card_interface.rs` you will need `use opengl_graphics::character::CharacterCache;`. This brings the trait into scope and `GlyphCache` will be considered to be implementing it. (Note actual path to trait may not be correct... hopefully you get the idea).
No. At least insofar as it relates to the skills you have expressed interest in. After you have a firm grasp on C, x86 Assembly, C++ with STL and/or Boost, IDC and OCaml, DIMACS/SMTLIB2 **then** Rust could be a profitable use of your time if your interest is reverse engineering. 
What's ironic about the punctuation? I feel like I'm missing something here :(
&gt; It's reasonable to want error handling to pop a bit more when reading the code. May be instead of `?`, it should have been `???` :D let foo = FooBuilder::new().set_a(1)???.set_b(2)???.build(); !!
`f32` and `f64` have their own `min` and `max`. I am not sure that it is best solution, but you can implement your own trait like this: http://is.gd/qIMNT3
Just tried this out, and it worked! Many thanks for this. 
Original author of solicit here... Thanks for using the crate and I'm glad you found the async example helpful! I have an mio-based client somewhere in a nearly finished state, but I stopped to wait and see where the dust settles on the hyper mio work. The base `solicit` API didn't need to change to facilitate this, which is exactly what I was going for. I'll have a look where the hyper implementation landed, as a few months ago I posted some requirements in the GitHub issue if we were to make full use of all HTTP/2 features from hyper. Feel free to open any issues on github and contributions are always welcome :)
I'm the original author of this crate, thanks for posting this. The `hyper` downloads do skew the numbers on crates.io, but my initial hope with this project was that it could be used as a basis by higher-level clients libs anyway. That said, the current hyper adapter ends up losing a lot of the http/2 benefits, starting from the most basic one, which is multiplexing multiple requests/responses over the same TCP connection. This is not a limitation of `solicit`, though. The main idea of the library is that it can support clients on multiple levels: - The framing layer: serializing/deserializing HTTP/2 frames, deflating/inflating headers (I busted out the hpack implementation into a [separate crate](https://github.com/mlalic/hpack-rs)), and connection-level flow control. On this level, it doesn't matter whether the client is implementing the server or the client end of the HTTP/2 communication. - The session layer: interpreting the received frames into semantic events, such as "new headers received" or "new data chunk for stream x" - the stream level: only worry about events for each HTTP/2 stream; the library already handles (de)multiplexing and stream-level flow control. Here, clients and servers do differ (e.g. servers are not allowed to receive push promise frames). - a rudimentary client and server - more of a sanity check for the API and a demo than something that should be really relied on. On the other hand, if all you want is to fire some HTTP/2 requests and get back some raw responses (fully uninterpreted bytes for both the response body and headers), then feel free :) The two things that are explicitly out of scope are the transport layer and a high-level client/server. The former means that as long as bytes representing an http/2 connection are somehow obtained, this library can be used to make sense of them. This has both upsides and downsides -- it's possible to build on top of any IO provider, but then you need to worry about the specifics of doing the IO itself, before passing off the result to `solicit`. I'd say this is the correct separation of concerns, though. A basic transport layer implementation on top of the std TcpStream is included, but this is not meant to be the only way. I'm not sure how clear that is from the docs. As for the high-level client, it includes things like strongly typed header representations, various convenience helpers for building requests, etc.; it should be possible to build this (efficiently) on top and if it's not, then I'd consider that a bug. All this said, there's still work to be done for a fully compliant HTTP/2 implementation. There's two major things: finishing the flow control bits (window update frames are currently ignored, but all other window updates are accounted for; this is fairly straightforward) and the server push mechanism. I was actually planning to get to some of these things this Easter weekend when I got some more time on my hands, so this comes at a perfect time to nudge me a bit :) Of course, contributions are more than welcome!
Hi! I really like the writing style, and also the examples given, a really good article! C# isn't really something I have used, but I like that you started explaining lifetimes through the problem they solve, and showed that this problem exists even in a more "high-level" language like C#, and that they aren't some weird thing Rust invented just to scare people! My only complain really is that the post is too short, as I would like a comparison between Rust's iterators and C#'s LINQ syntax, about which I've heard great things. Also, `enum`s are definitely a thing that warrant a mention in my opinion, but I guess you tried to keep the post brief ;) Do you plan to write more of the same kind, turning this into a (short) series on Rust for C#, or was this a one-shot kind of thing? Really awesome article! 
Well someone's got to be the first, and there's absolutely no way you can build high quality libraries without someone trialling them in production. 
Don't you have to escape `?` as well, because it is a glob?
Thanks :-) ... I did have both of those things in mind when I started out - if I have a chance to follow it up with another post I'll make sure to get those in.
Perhaps each field should be required to implement the same trait such as fmt::Display or json:ToJson. Here is an idea that might work // Provides Inspect&lt;fmt::Display&gt; requiring each field to implement fmt::Display #[inspect(fmt::Display)] struct Point {x: u32, y: u32, z: u32 }; let p = Point {x: 7, y: 9, z: 12 }; // Force the compiler to unroll the loop (assuming this is necesary) #[unroll] for (name, value): (&amp;str, &amp;fmt::Display) in &amp;p.inspect() { println!("{:} {:}", *name, *value); } 
It's very similar (though more generic) to the current situation: - using `derive(xxx)` will auto-implement the trait by using the internals - implementing the trait manually allows one to use fake internals and most importantly, it shares the issue that the OP is complaining about: it requires the *creator* of the `enum` or `struct` to implement this trait, the user cannot "retroactively" implement it on a 3rd party piece of data.
TIL Piston has its own parsing library :)
Cool! Is iron-llvm the LLVM bindings project to look at these days?
[Cyclomatic complexity](https://en.wikipedia.org/wiki/Cyclomatic_complexity), each `?` adds new possible branch. Using `try` isn't better but due "ugliness" of `try` almost no one is using more than 3 `try`s in function. With `?` it will encourage people to build complicated and, due to that, hard to test functions.
`try!` is much rarer combination of characters than `?`. It hasn't occur in strings a lot in contrast to `?` which you cannot filter in easy way. Also `?` has special meaning in most of regexp engines.
But you can't just decide to have APIs stop returning Results. Errors can happen, and they have to be handled. Are you advocating using unwraps everywhere instead?
In context of subprogram (aka. function) `?` is diverging execution of current flow. I am not aware of any operator, in any language, that works that way.
It is worth mentioning that the 50% number still includes quite a bit of IO as both services need to make quite a few REST calls. Regardless, it is impressive how fast JavaScript runs as an interpreted language. As a developer who has to maintain the service, the things I like most about Rust compared to JavaScript are the lack of null/undefined errors and the type system. The performance to me is less important, although it definitely is worth noting since it provides "business value".
Probably could be. But I don't see simple way to define such trait. Everything that I can came with looks really strange.
[Context](https://stackoverflow.com/questions/7825055/what-does-the-c-operator-do) `??!??!` = `||` :)
http://doc.crates.io/crates-io.html#cargo-yank Yanked crates are still available, just not listed. You can't break existing builds by yanking one, so the npm-style unpublishing would not affect rust. The law/claim issues though... Someone running the service will have to explain.
I pasted your code in the rust playground and after adding ´thread::sleep_ms(500);´ as the last line in the main fn everything seems to work. So the problem is that your main thread terminates and takes all spawned child threads with it.
Cool stuff! Has it been considered building something like `hypersync`on top of corroutines, like mioco does for mio?
&gt; JavaScript are the lack of null/undefined errors and the type system If you're working in JS and are running your code through Babel (or any other way to strip off types), I encourage you to check out [Flow](http://flowtype.org/). It doesn't have the community support that Typescript has but it runs faster, the inference/flow analysis is much better, types are not nullable, and the support for object literals is better. I've applied both to several codebases and I find that Flow mostly just needs its comment pragma and annotations on the function signatures while TS needs additional annotations on object literals and rearranging code to be happy. Good luck with pitching the rewrite.
This is somewhat tangential, but I hope this incident builds more awareness that when you build a package that has a dependency, _you_ are responsible for making the dependency work. Rust has somewhat unique problems here because of strong typing: if bigpackage 1.0.0 depends on, say, smallpackage 0.1.x which depends on libc 0.1.x, and also directly on libc 0.1.x, and smallpackage upgrades to libc 0.2.x, a bunch of types are no longer compatible because you suddenly have e.g. two different `libc::c_void` structs, one from each version of libc. There's no malice / intention to create disruption: you _should_ be upgrading libc versions! If smallpackage disappears entirely for legal reasons, it is largepackage's responsibility to either upload smallpackage under a different name (if it's a trademark issue) or find another way to solve the problem (if it's, e.g., a copyright issue). Unless crates.io is hosted in international waters or something, there will certainly be cases where someone includes code that's copyrighted by someone else without permission, and the copyright owner asks crates.io to take it down.
Have you consider migration to Erlang/OTP?
I agree. The cool thing about monads in Haskell is that they allow the monad author to control exactly what side effects are permitted. In Rust, as you say, all code can do anything anyway, so you have no guarantees and no additional tools for reasoning about what code does or how it composes.
pretty much, though you don't even need to have it as a field in the class. It could be a parameter a method. And with java 8 supporting lambdas, it is much more concise than it was before.
Not quite as simple as it could be (yet). I'm sorry to answer by link to tweet, but: https://twitter.com/Argorak/status/712571589972402176
This is what I learned as I am learning Rust. I come from an embedded system program, programming in C. Feedback is most welcome.
Sure, but you can then just publish a new major version instead of a new semiminor version. The issue you refer to is about not following semver, which is orthogonal. The issue here was that an unpublish broke everyone's builds. Crates.io doesn't allow this, and is an append-only registry. Yanking only blocks future crates from depending on it.
Hmm, would the [schannel](https://crates.io/crates/schannel) crate remove the need for OpenSSL? 
I've been coding C# for 13 years now and absolutely love rust. I agree this article does an excellent job at explaining lifetimes in a way that C# developers can clearly understand.
You should run your text through a spell checker, as there are numerous errors like 'rational' instead of 'rationale', 'checkign'.
Here's a thing: I remain unconvinced that the claim by `kik` was fraudulent or excessive. I also remain unconvinced that they were trolling, in fact, they took the nice route. Kik is a software company and - whether they are doing it currently or not - could have a vested interest in using that name at some point. In fact, kik offers an API. Now, the reaction of the author is up to him, but I don't see how NPM should have stood up to the legal request in that case. It is also unknown how Kik approached NPM. There are cases, e.g. DMCA requests in copyright, where there's not much of a way around such actions. _it is not a platforms job to oppose DMCAs on behalf of the publisher_. I'm not sure about the legalities around Trademark in the US, but it might be similar. I suspect crates to react in a similar way, especially after the original author indicated that they are not open to a solution _outside of court_ (because that is basically what he said to Kik by refusing). On the technicalities: I know that crates can be deleted, but only by contacting the admins. Automatically, you can only yank. That's similar to Rubygems. There are many cases where deletions can make sense, but I find self-serving deletions harmful - especially as the names can be squatted afterwards. FWIW: I'm not a fan of trademarks in general, but I see their usefulness (e.g. for Firefox and Rust).
&gt; it is not a platforms job to oppose DMCAs on behalf of the publisher. Eh. What if a real attorney sent a real notice to the crates.io owners that the `libc` crate was in violation? It's patently ridiculous, but it does seem like it would be the job of the crates.io owners to resist complying with such a request. I do think there's some level of resistance that something like crates.io should show, but it's hard to say exactly how much since it's probably dependent on how "legitimate" the request from the attorney receives. Certainly, a takedown notice for `libc` seems more ridiculous than `kik`, but who's to say? It's a tough place to have a rigid policy, unfortunately... I'll just steer completely clear of actually commenting on the laws that allow this type of nonsense to happen. Grrr.
Link to the song on Soundcloud for the lazy: https://soundcloud.com/mdkofficial/mdk-ft-nick-sadler-phoenix-orchestral-mix
Do you think namespacing would resolve this issue? As in /john/kik is fine where as /kik/kik is obviously the official kik repo. Someone brought this up in discussion for npm on hackernews, and I know namespacing has been considered in the past for crates.io (I'm for it)
1. Yes, ideally. 2. Big deal bugs can be released as patch versions to 0.8. However, as we shift to async, there will likely be less people using 0.8, and thus noticing bugs... -------------- The connection will be reused in the pool as long as all keep-alive requirements are met. There isn't a way to take the socket and use it for other purposes though. This is a flaw I've fixed in async hyper. 
Cost and effort. And now imagine what would have happened if NPM said: "then sue the person" and Kik would have responded with "to ensure the takedown, we sue you both". This is not an improbable scenario.
In addition to /u/fgilcher's link, there is https://github.com/rust-lang/cargo/pull/2361
As a c# coder at work but rust follower, thank you for the article. You text got me the idea ( although i have used lifetimes before and got the basics ) I will now make always two lifetimes inside functions: &lt;'hero_of_the_world_must_live_for_sure, 'ugly_can_die_for_all_i_care&gt; Please do blog more, Thanks! :)
AFAICT it's considered good courtesy on Reddit to link to the original source. Besides, now people won't have to spend 2 minutes searching for the original source. Never underestimate the power of laziness ;-)
In addition to the other comments, Java 8 interfaces support default methods which can be used for composition.
I'd say the main thing there is that C#'s iterators are *much* more limited, which is kind of annoying on the one hand (they're less efficient for certain things--think `.Reverse()` in C# vs. a reversible iterator in Rust), but which, on the other hand, seems to make them somewhat more composable in certain cases. So far, anyway.
Stack overflow while running. On 64-bit Windows 7 Ultimate. Rust 1.7.0. 
https://github.com/rust-lang/crates.io/issues/67 For those that can't be arsed to go to twitter. 
Great! Let us know what they think! We are all very interested in engaging the data science community. 
Ideed. Thanks!
 &gt;&gt; they took the nice route. &gt;"take this down or else" is not "the nice route". It is. "We sue immediately" is the non-nice one. &gt;DMCA only applies to copyright claim. Using DMCA for trademark disputes is fraudulent. Furthermore changing ownership of content is not a normal response to a DMCA notice as the DMCA process can end up with the restauration of the content. Please reread how I specifically phrased the sentence to make clear that DMCA is the way of action in copyright and we don't know how they approached NPM. &gt; That's a strange way to assert that you should bend down unquestioningly to legal threats. I don't say "unquestioningly".
I wanted to write up some more information on the linear algebra module within rusty-machine. It seems that other similar libraries have dependencies on BLAS/LAPACK, which is smart, but for [rusty-machine](https://github.com/AtheMathmo/rusty-machine) I've opted to focus first on a pure rust linear algebra library. I do plan to add optional dependencies using BLAS/LAPACK later (because it will take monumental effort to match their performance) but I also want to enable new users to jump in without getting all tangled up in dependencies.
I wanted to write up some more information on the linear algebra module within rusty-machine. It seems that other similar libraries have dependencies on BLAS/LAPACK, which is smart, but for [rusty-machine](https://github.com/AtheMathmo/rusty-machine) I've opted to focus first on a pure rust linear algebra library. I do plan to add optional dependencies using BLAS/LAPACK later (because it will take monumental effort to match their performance) but I also want to enable new users to jump in without getting all tangled up in dependencies.
When structures in `libc` have private fields, they are supposed to be initialized with `std::mem::zeroed` or `std::mem::uninitialized`. Private fields in `libc` are usually implementation details of a specific C library, they should not be exposed.
Yeah, court is its own form of punishment. I certainly have a few open source projects (not Rust related) that are a simple request from an attorney away from disappearing off the Internet, even if I think the request is unreasonable. The threat of legal action is enough to make me comply.
I agree in general, but this structure doesn't have an api for setting fields, so there is no alternative, and it is not documented as an opaque struct.
doc: http://praxis.edoceo.com/man/3/mq_getattr
IMHO - the `kik` stuff is small fries, the real issue here is that one guy pulling his packages broke half of the ecosystem. What personal factors led to that isn't the focus here.
&gt; Is there something like phpDoc's @api tag? An uninterrupted chain of `pub` from the crate root. By default, items (submodules, traits, enums and structs, struct fields, functions and methods) are only visible from their direct containing module. Marking them as `pub` makes them visible *through* their containing module (and thus to whoever can see it module). The crate's top-level (`lib.rs`) defines the "external" visibility, if something is either directly exposed by it (possibly through re-publication e.g. `pub use foo::bar::Baz` will make `Baz` visible from outside the crate even though `foo` and `foo::bar` may not be) or if it's transitively visible (e.g. `pub foo { pub bar { pub Baz } }` makes `Baz` visible as `$crate::foo::bar::Baz`). &gt; Is there a way to document a public API for a crate? http://smallcultfollowing.com/rust-int-variations/isize-usize/rustdoc.html seems to be a pretty good overview. [The book](https://doc.rust-lang.org/book/documentation.html) also has a page on the subject but it seems significantly less complete.
Here is my implementation: http://src.rampantmonkey.com/mazes/tree/src/lib.rs#n71 My main focus was trying to separate the data structure for storing, manipulating, and displaying walls from the maze generation algorithm.
Hah I realised pretty quickly that I did that! I deleted it and reposted with the correct link. Thanks though.
Sorry for confusing the blas bindings, I've updated the post now :). blas-sys looks really good. Thank you! It certainly is a huge end goal but for now I'm aiming fairly small. In the *near* future I'll add blas bindings to my current linear algebra stuff. After that I'll try to make the core linear algebra stuff a little more agnostic so it can be used on top of whatever data structures rusty-machine ends up using (probably ndarray). There's a lot to think about and I guess I'll have to wait and see how it shapes up. Oh, and thanks for the paper. It will certainly help!
&gt; Apple Computers and Apple Music both have trademarks on the word "Apple", as an easy example. ... and this was fine until Apple Computers got into the music business, at which case, they got sued over trademark by Apple Music and settled.
Probably not.. But at the same time rusty-machine isn't aiming to be a production library (yet). I started it to learn rust and along the way have some fun implementing things I don't usually get/have to. I completely acknowledge that in the future I will need to introduce BLAS bindings - but I want to maintain a pure rust library too. This is something that exists for example in numpy as well - you don't NEED blas to use numpy but it does provide significant performance gains. 
Since unix `fork` does not exist on Windows, I don't think there is an elegant cross-compatible way to do that, and that may explain why it is not on `std`. Even Python's solution is somewhat buggy (like inits running again because the program is literally reopened with some parameters to make it continue where you "forked") on Windows because of the lack of fork.
Looks great, somehow this was not on my radar! If it's of any value, I started and stopped a similar project (hex grids in 3d for an adventure game I was designing): https://github.com/viperscape/thule and relevant post: https://www.reddit.com/r/rust_gamedev/comments/40xea2/open_sourced_some_game_code/
That the spacing around the dashes is irregular and in two ways.
Namespacing could be desirable for other reasons, but it wouldn't solve this problem any more than e.g. a social network trying to escape litigation by naming itself johnfacebook.com.
Yeah, it sounds crazy at first, but I learned it in 2003 after graduating high school. Hard to believe that much time has passed, some times.
&gt; even though my Cargo.toml explicitly lists clippy 0.0.55. Are you saying clippy = "0.0.55" or clippy = "=0.0.55" ?
I have a public enum that I want to add new variants to in the future. How do I force users to have a wildcard match to ensure exhaustive matches won't break?
While I agree that testing hyper is valuable and should be done, IMO testing: mio + rotor + http is blurring the measurement for each component. If it's slow, which part is at fault? Without measuring all the pieces from bottom up, it's hard to tell. Especially http performance depends on parser, features used etc. Eg. see [mioco handling 10 million http requests per second](https://github.com/dpc/mioco/blob/master/BENCHMARKS.md#http-server) on my desktop without a sweat. We could coordinate the effort and do measurement of all interesting scalability related Rust pieces.
I am writing a [compiler/vm](https://github.com/Marwes/embed_lang) designed to fill the same role as Lua so I can't speak towards LLVM or other ways of creating assembly. For this particular brand of compiler I don't think you can do any better than Rust, compared to C and C++, Rust enums alone helps a lot when writing a compiler. If the kind of control Rust gives is not of particular importance however, I think Rust is less suited towards writing a compiler than a traditional functional language such as OCaml or Haskell. As an example I found it more annoying to write my typechecking code in Rust than I would expect from a garbage collected language. While it is possible to use `Rc&lt;T&gt;` or `&amp;T` to write sharing heavy code it is either slower or more complicated than the equivalent code with garbage collection. For other useful crates I should mention my parser combinators library [combine](https://github.com/Marwes/combine) which I am dogfooding. It has some problem with compile times due to some missing caching in rustc but is otherwise quite nice.
Mio is single threaded. You spawn multiple mio instances: each for each thread you want. You don't have to use mio timers, but you need to use something that can wake mio up: meaning it's supported by it.
Cargo defaults to ^ not = btw, so if you want an exact version make sure to use =.
Does the cargo team have a policy about how to react to a lawsuit? IMO the 10min breakage of `npm` ecosystem was unfortunate, but the real damage has been: 1. completely lost the trust of all `npm` users 2. lost an active community member IIUC they "just took the package down". That's the worst possible reaction ever. Their community seems very empathic with the author that decided to kill all his packages and leave for feeling betrayed and sold out. Such a community would have definetly understood the need to take a package down for the greater good (like keeping `npm` running). Had they discussed the situation _in the open_ (e.g. by writing a blog post about it) and waited 1 or 2 days before reacting, letting everybody in the community speak, probably would have solved the issue. The author would have voluntarily either renamed the package or added a disclaimer about its name. Even if he told them to "fuck off" privately, I doubt somebody would do that infront of a community one is a valuable member of. Hell `kik` might have changed their mind and left them alone for bad PR. Even if nothing works, and they have to forcefully take the package down, at least they heard everybody. Nobody would feel betrayed. Even if the author rages out, they might only loose an active community member, but not the trust of the whole community. When someone threatens to sue you for a gallizion dollars is easy to react "hot headed". The cargo team should have a policy for how to react under lawsuits. Even if it is just: write a forum/reddit post explaining what's about and give everybody 2 days to express their opinion before any kind of reaction at all.
Your formatting is off. You meant `clippy ="^0.0.55" ` but forgot the backticks.
I started a basic straight Rust matrix library for fun, some of my methods look similar, so it's good to know I'm on the right track :)
Look's like it's failing on the new `?` syntax (as if I needed more reasons to dislike it :p), perhaps it's not building with unstable features enabled?
Wait, why does this matter? `^0.0.55` still does not allow `0.0.56`.
It's because that's what you want, 99% of the time. So that's the default.
No, in my opinion BSD are second class systems for Rust mainline developers: https://wiki.freebsd.org/Rust Generally, port /lang/rust works, but cargo doesn't so developing anything is close to impossible: http://portsmon.freebsd.org/portoverview.py?category=lang&amp;portname=rust
I always forget how carat works with `0.0.z` versions... it was just the first thing I thought of.
&gt; Do you have any info how long before I will be able to install rust and cargo from ports? Do you mean being able to build the compiler from its source? - We are already producing rustc binaries for freebsd via cross compilation. (Look for the rustc-*-freebsd tarball [here](https://static.rust-lang.org/dist/2016-03-23/index.html)) - Cargo binaries for freebsd should be [coming out in the next days](https://github.com/rust-lang/cargo/pull/2510). - After rustc and cargo are available on freebsd and [this file](https://github.com/rust-lang/rust/blob/master/src/nightlies.txt) gets updated to use newer nightlies, you should be able to compile rustc on freebsd using `configure --enable-rustbuild &amp;&amp; make`. This is for 64-bit freebsd 64 but 32-bit freebsd should be similar. I'll inform the tools team that there is interest in rustc and cargo binaries for 32-bit freebsd.
The reasoning behind that is to allow all compatible versions as per Semantic Versioning which as long as the dependency sticks to that should be in your best interest.
Hmmm. Maybe you have a wrong system library somewhere that gets picked up; but I cannot help there, as I have no Windows to check. Perhaps if you build with -g (you can change the `[profile.release]` profile with `debug = true`), then you should be able to get debugging info if you wish to pinpoint the problem further.
Got it, TIL! I don't hugely like or trust SemVer, so I'll just prepend the `=` to everything that isn't `*`.
Viable option but it does add some development overhead since a non breaking change can still be really important.
I'm not really concerned about cross-platform but anyways I think I'm going to use and modify rust-uwsgi to my needs
&gt; No, in my opinion BSD are second class systems for Rust mainline developers: It's actually third class: https://doc.rust-lang.org/book/getting-started.html#platform-support That doesn't mean we don't want it to move up, just currently, that's where it's at.
ISTR recall Windows has smaller stack so it possibly legit too. I'll check out the debug info, thanks.
Wow, nice work thanks! :-) Perhaps it is time I resurrected that project... 
Essentially in my current code I have three types of timer events: I have time outs that I rarely expect to happen and are often far away, like 30 seconds at minimum, I have timers that I do expect to always calls and they are often much shorter in duration, and I have callbacks which are to be called immediate on the event loop thread (this is to modify event loop structures, do something that needs to prioritized after I run through the current events, etc.. -- mostly it is used to do things to the event loop like add and remove sockets or timers so I don't need to make those structs thread-proof). I want these run on the mio event loop without having to run another thread for them, but I can't figure if that is possible. 
Rust^TM is only applicable as a proper noun in computer software. The ferrous oxidation reaction is fine, as is calling someone Rusty
Yeah, he should have. He was informed of imminent trademark squatting, which is illegal. He can move or be moved. Kik is under obligation to move him in order to keep their trademark on their name. He elected to be uncooperative, so Kik moved forward as the law empowers and requires them to do Kik the company owns "Kik" the word in the software marketplace. Once they decided to publish on NPM, another `kik` project is trademark violation. They can contest it, or lose their ownership of their trademark.
The law means whichever one filed first. I don't know offhand if either have, but, a collision will be awkward. Rust the lang was released in 2010, Rust the game in 2013. I'll be sure to bring popcorn if they ever play chicken.
Thanks, I have fixed up the spelling mistakes and made a couple of points clearer. Cheers. 
Look through your `Cargo.lock`. You can even edit it manually if necessary but be careful.
Couldn't you effectively unpublish a crate by pushing an empty crate as a semver-compatible version and yanking all the other versions?
You can point cargo at any host, yeah. But then they're missing all the packages.
&gt; I have the sense that, generally, F# is slightly slower than C# where things like the F# immutable collections are concerned. Immutable collections on .NET should have the same performance whether you call them from C# or F#. If you mean purely functional data structures are slower than mutable data structures then yes, absolutely, a purely functional `Map` is typically 10x slower than `Dictionary` (regardless of the language). There are only really three times when purely functional data structures can have good performance characteristics: 1. Collections are almost always either empty or very small, e.g. argument lists when writing an interpreter or compiler. 2. Old versions are aggressively reused (e.g. backtracking in logic programming). 3. There is a lot of sharing (e.g. an undo buffer). &gt; An interesting point: Rust generally doesn't have overhead for immutability. For fixed-size values, yes. For general immutable collections I expect Rust to be many times slower than a GC'd language because Rust programs will have to resort to reference counting (which is really slow) in order to handle shared ownership. 
I'm there in IRC a couple times a week, but on Eastern time. Look for one of jas{,0,1,2}. And I have tried to use gitter and was never able to figure out how to join a room (no joke).
It's always good to have native-language implementations, if only because it saves headaches when porting things. Then, this could actually be *interesting*: In the sense that rust has aliasing information that could enable it to be at least equally fast as Fortran, here, that is, faster than (standard) C. A Rust implementation of BLAS could actually be competitive once all that info is actually used in optimisation. 
I guess it may be possible to have a tool to check the crates updates, and notify the users if some crate uses a wrong versionning scheme?
Should be as easy as going to https://gitter.im/dpc/mioco, but who knows what's going on. :)
So, AFAIK, trademarks on software dependencies have not played out in court. So how this would turn out is pretty out there. However, trademarks for domain names have played out in court. And in those case, it almost always favors the defendant. The only case where the defendant isn't favored is when they are squatting or masquerading is the company whose trademark is in question. In this case, I would be surprised if the courts favored kik. Azer wasn't masquerading as them, his project was significantly different, and he wasn't trying to fool anyone into thinking he was kik. If they were to follow Domain Name trademark rulings, it would be cut and dry that Azer wasn't in the wrong (in the US). Further, the fact that Kik threatened legal action and then proceeded to seize his assets via npm WITHOUT executing said legal actions may be a basis for a lawsuit by Azer under [section 21 of the 1994 trademark act](http://www.legislation.gov.uk/ukpga/1994/26/section/21). Azer would have an even stronger case with the fact that Kik did not seek out legal action against him for the github page which also bore the name kik. To me, kik is totally in the wrong here in more ways that one. Further, npm's actions have shown they really can't be trusted as a package maintainer.
That will fail if you happen to have a one character file in the current directory. That is, globs are passed through verbatim only when they match nothing, at least in bash.
Do you support matrix masks the way JAI does?
I hadn't heard of JAI (Java Advanced Imaging?) before you asked this but a quick google revealed the answer is probably no. It looks like the masks you mentioned are for operations like convolutions etc.? I plan to add these (for convolutions) at some point in the future but they're not really on the radar right now. If I've misunderstood the question please clarify and I'll try to answer properly!
Don't forget cgmath for game dev! Still lots of rough edges, but I'm slowly working on improving it...
I put the code in lib.rs because it was originally intended to be a library to embed in other projects. I ended up writing a main function later to provide a demo. I do not know if that is a normal rust practice or not.
Meanwhile, people wait for the native-language implementation to even be as fast as the standard C. Sorry, I'm not a fan of language-mercantilism, but I do see the benefits that you mentioned.
Well to get a feel for the language you'd need to watch several. I mostly watch them because I have my own internal language and like stealing ideas. In fact, I just keep one big list of 'good ideas' to draw from. You are correct about this being a similar idea to sparse matrices. Having a mask to customize matrix behavior is pretty cool though. Similarly, say you've got a covariance matrix (symmetric): being able to determine it a such would save you 50% (have not verified) of operations because M[x,y] = M[y,x]. Personally, my take on linear algebra was to bake matrices into my language. I haven't got to masks yet but I essentially went with MATLAB-style approach plus some magic hackery. I cross-compile into Eigen, though, which is already SIMD-optimized and whatnot.
There are multiple reasons for that. The biggest one is that we don't want to wait 15-20 minutes for a compile. Also we have some lints that simply don't belong in a compiler. That said, clippy *is* a perfect testbed for lints and I think we have some that would fit perfectly into rustc and could probably be moved sooner or later.
Release a new minor version (if below 1.0) or major version (if above 1.0) when you add variants.
Is it just me, or does it feel like the meetings are *always* cancelled, for one reason or another? (I am quietly amused.)
&gt; Would you switch now though? Given that rust and it's libraries are still under heavy development. Have you seen the JS world lately?
Hyper doesn't support pipelining. Many servers don't support it either, so there isn't much gain in trying to add it. Best to use HTTP2 to do that. The Client does support multiple concurrent connections to the same server. With blocking IO, you'd need to use the Client over several threads, but it definitely works. 
This is the subject of a potential language feature which is currently still in limbo. See https://github.com/rust-lang/rfcs/pull/757
So excited for a fully-featured rustup, this is something that Rust needs before I can be comfortable calling the language complete. How far is easy cross-compilation on the radar?
No worries - your library tackles a very different domain to mine. But seeing as nalgebra and euclid are on there.... ;)
It would be nice if the size of the matrix could be encoded in the type. Rust has fixed size arrays, but I'm not sure there's a way to abstract over the size.
This could have something to do with different crates using conflicting versions of the `CharacterCache` trait. I notice that you have both `piston_window` and `opengl_graphics`. It is likely that you don't need the `opengl_graphics` crate, as `opengl_graphics` is a `Graphics` backend, however `piston_window` already provides a `Graphics` backend to work with (the `piston_window::G2d` implements `Graphics`, and `piston_window::Glyphs` implements `CharacterCache`).
You are looking for /r/playrust. This subreddit is about the Rust *programming language*, not the Rust *game*.
Hey and thanks! The lack of u64 and i64 is, as you've said, due to JS limitations, and some other platforms might have issues as well - Java for that matter has 64 bit integers, but only signed. That said, I could represent u64 as BigNumber in JavaScript, extra dependency but I'd rather be correct than converting a precise (u)int to a float of the same scope but losing precision. In the end, if you want a big number and precision isn't an issue, that's what floats are for :). And with that in mind, expanding size to allow 64 bits also makes sense, guess I know what I'm doing with my free time during Easter.
If you care about simplicity, there is http://cbor.io - json compatible subset is really easy to implement.
Mostly having a library with the same API on another platform than Rust to be able to read that data (and vice versa), and the convenience of not having to prefix non-number data with size manually, and dealing with the tax on that. You could prefix all strings with manually with u32, but if your string just reads `"Foo"`, but then you are using 7 bytes to send a message that's 3 bytes long, that's what the `size` in BitSparrow is for. I'll most likely switch over to using byteorder with the cursor internally though, as per suggestion above.
&gt; Rust has fixed size arrays, but I'm not sure there's a way to abstract over the size. There is a hack for that: https://crates.io/crates/generic-array (Disclaimer: I'm the author)
According to recent statements of kik, they did neither of those. :/ Which brings me back to one of my original points: we didn't know what NPM and Kik actually communicated and had no indication for fraudulent behavior.
Whoever has taken their agenda please give it back so they can hold a meeting again! ;-P
Very nice, Thanks. At times it seems very few people in the Rust community use Windows which is a shame. So this is refreshing to see.
The problem is that if you do typed packing, you can still end up producing messages that any other serializer would fail to read, it's fairly easy to do in Jackson when writing down plain JSON, and I fear it would be much worse in MessagePack since now you have a whole new class of potential bugs related to putting wrong number of elements on an array or a map. At this point if something goes wrong, the debugging effort isn't really any smaller than if you didn't have types at all. Also with manually typing values, you can technically send `10` as `uint 64`, and while I reckon most implementations should handle that quite gracefully, it seems to defeat the main point of MessagePack. I will have a look at CBOR though.
Yes, but if I developed software on it, I would only rely on LTS releases (there are some in nodejs AFAIK) and avoid third party libraries altogether.
&gt; What I meant there is that I thought it was considered idiomatic to use them in F#, where it would be really strange to use them in C#. Idiomatic in high-level APIs perhaps but purely functional collections like `list`, `Set` and `Map` are not idiomatic inside functions. In F# you have an easy choice and mutable collections are ubiquitous too. In C# you can also choose the [BCL Immutable collections](https://www.nuget.org/packages/Microsoft.Bcl.Immutable/). They make sense in situations like those above (especially an undo buffer where they make life so much easier) but, as you say, are generally really slow. Graph algorithms are perhaps the exact opposite end of the spectrum: purely functional data structures rarely help at all, partly because the vast majority of existing algorithms are inherently imperative. &gt; As to the point regarding immutability in Rust, what I have found is that the problem solved by immutability in .NET languages is simply not present in Rust; an immutable thing in Rust is simply a thing you are not allowed to change. :) I see. You mean Rust tracks mutability in the type system? One thing that jumps out at me in this context is laziness because it is the difference between immutable and purely functional. When the result of a lazy thunk is required it is mutated in place from an unevaluated expression to an evaluated value. Subsequent attempts to force the evaluation then return the previous result immediately. The semantics are unchanged so this is purely functional but it requires mutation. So I assume Rust would not permit this? Does Rust provide a `lazy` thing? In F# I use `lazy` most when I want to write initialization code (often globally) but I want that code to run in a particular place, most often on the UI thread for WPF. That's how I got [F# for Visualization](http://fsharpnews.blogspot.co.uk/2013/09/f-for-visualization-07-released.html) to run inside F# Interactive, for example. 
I'm sure I'm from a different culture then you are (actually running a business and having a very short line to my lawyer), but yes, pointing to the way of legislation is fair. I would have probably phrased that in a different fashion and the tone is really bad, but hey, Azuls response wasn't nice either.
What's the difference between hyper and rotor-http though ? Hyper uses rotor for async so the differences are from an API point of view?
BLIS looks really interesting, but it is also new, it's harder to integrate with as a library. It requires to be built against a particular configuration, and it has a mantatory `bli_init` function. It would be nice to create a good blis-sys for this in Rust, do you have a clue how to solve those issues nicely?
Thanks! Yes it is ambitious, though Rust saves me from doing bs all the time and makes me _very_ productive. It really looks promising so far and one very basic module is already implemented and another is almost get ready. I guess I will work on taskwarrior integration (for the "todo-tracking"-part of PIM) this or maybe next weekend.
It's [in the pipeline](https://github.com/rust-lang/rfcs/issues/1038).
&gt; Kik the company owns "Kik" the word in the software marketplace. Once they decided to publish on NPM, another kik project is trademark violation. They can contest it, or lose their ownership of their trademark. That's silly, if there was a company named Pepsi selling bicycles, they would not be violating soft-drinks-Pepsi's trademark because they are in a different market and people would not be confused (I'm assuming that the bike-company does not use a similar logo, colorscheme, etc.). If soft-drinks-Pepsi decides that tomorrow it wants to start selling cars in addition to soft drinks, then it's not bike-Pepsi's fault that people looking for transportation might be confused, nor does it mean that bike-Pepsi was in trademark violation all along: soft-drinks-Pepsi never owned a trademark that applied to transportation, nor does the confusion *they* caused entitle them to one. Kik does not 'own' the "Kik" word in the software marketplace at all, you can read where it applies [right here](https://trademarks.justia.com/858/93/kik-85893307.html). The relevant goods and services are: &gt; Computer software for use with mobile devices, namely, computers, personal digital assistants (PDAs) and mobile phones for downloading, displaying, transmitting, receiving, editing, extracting, encoding, decoding, playing, storing and organizing text, sound, images, audio files and video files &gt; &gt; Wireless messaging services; transmission, delivery and reception of text, sound, images, audio files and video files between computers, personal digital assistants (PDAs) and mobile phones &gt; &gt; Providing an interactive website featuring online non-downloadable software that enables users to download, display, transmit, receive, edit, extract, encode, decode, play, store and organize text, sound, images, audio files and video files One can see clearly that these goods and services do *not* include the software that Acer intended to publish. Kik was not in the right, it was simply trying to bully someone into giving them something they were not entitled to.
Kiks trademark did not apply, so they would have lost and it would have been a PR disaster for them.
How is it squatting when azer had a legitimate project hosted? Squatting is when you take the name with no intention of using it for yourself but rather just to sell it. It was common at one time to see "the site is for sale" on random domains.
Sounds nice.
I will be taking the word of reddit on that in the future. Thanks.
That seemed.. too insane for me to do it right. I updated my rustc instead xD.
You can do ad-hoc namespacing with hyphens. For example https://crates.io/crates/servo-skia
What problems would that solve? A vendors name could still clash with that of a company. For example, one could actually have been named Kik by ones parents, or have chosen to use that name as a nickname. Or you could be [Mike Rowe](https://en.wikipedia.org/wiki/Microsoft_vs._MikeRoweSoft).
Ok thanks, good point. But there is still a reading "problem" (not really a problem in fact) with long names: my-name-simple-error
Hello! Let me start off by re-capping the situation, because it's complex. I will then discuss what would happen if the same situation occurred, and also if a variant of it occurred. I will largely be summarizing what others have said, but wanted you to hear it from me. What happened: 1. someone made an npm package named `kik`. 2. A company named kik wanted to make an npm package using their stuff. 3. The emailed said author, asking if he'd be willing to give them the package. 4. The author said no, in a very standoff-ish way. 5. kik emailed npm support, asking if they could maybe assist in resolving this amicably. 6. npm's ceo decides to give kik the package. 7. the original maintainer gets upset, and deletes all of his packages 8. one of his packages, `left-pad`, was depended on by a LOT of people. 9. As the names are now open, new maintainers take over these packages. 10. new maintainers can't publish old versions, but npm makes an exception in the case of `left-pad`, and reinstates the old version with the new maintainer. As a thought experiment, let's decide that this exact chain of events happens in the Crates.io ecosystem. Everything could be the same up until point 7. You can't hard delete packages, only yank them. With yanking, it's just like it was vendored: if you have a `Cargo.lock` with the version in it, you're good to go, but new packages can't depend on the yanked versions. So the whole ecosystem breakage wouldn't happen. So first of all, there's that. But this is also because there's two different packages in question here: `kik` and `left-pad`. What if the company was LeftPad, instead? This is a trickier question, which also leads into my further comments. If this situation were to happen in the crates.io ecosystem, step 6 would also be different. We've previously commented on this: https://internals.rust-lang.org/t/crates-io-package-policies/1041 &gt; For issues such as DMCA violations, trademark and copyright infringement, Crates.io will respect Mozilla Legal's decisions with regards to content that is hosted. I would like a more elaborate, clear policy here, however, and so we'll be working on one. But the core of it is still true: we cannot defy the law. In the npm case, no legal action actually happened, but if we were sued in court, we would have to follow the rulings of said court. That ultimately overrides any kind of policy that we do make.
a question: with rust advocating the use of i32 when sufficient, is there really any benefit in running rust on a 32 bit OS?
No memes please.
No, but they could do wonders for my ocd. :)
"I recommend using the left-pad library" suddenly becomes an ambiguous statement. Github introduced that problem to the Ruby community a couple of years ago by automatically building gems of the form `username-lib`. Suddenly, there were many versions of that lib around, all with small changes.
Broken link
I have a vector that simulates a heap. It owns a bunch of `Option&lt;T&gt;`, where `None` means a null pointer and `Some` is an allocated value. I want to "move" data out of it, transferring ownership, and without copying or shifting any indices, since each index represents a pointer. So far I've got: let mut heap: Vec&lt;Option&lt;Object&gt;&gt; = ...; let pointer = 5; // or whatever other index heap.push(None); let object = heap.swap_remove(pointer); Is this a good way to "move out" of the vector? It feels a bit weird to push `None` first before removing something, but I guess it works. 
Yes: https://medium.com/@mproberts/a-discussion-about-the-breaking-of-the-internet-3d4d2a83aa4d#.9rjwkq868 A lot of people are reading them in a lot of ways, to be honest. If you look at the programming reddit thread, it's the full spectrum.
I meant [rotor-http](https://github.com/tailhook/rotor-http) which can be used for http servers afaik (https://github.com/brson/basic-http-server)
If you put wrong number of elements on an array, they will appear after array end. If you pack `10` as `uint64` it still will be unpacked as 10. By debugging I don't mean debugging message format (but hey, it is still easier when generic unpacker exists). I mean debugging application logic, when you take some message bytes and unpack them in node/ruby/python console. I often even able to read CBOR from screen with little help of jump table from spec. Sure, MessagePack is also "readable".
you mean this: [crates.io/left-pad](https://crates.io/crates/left-pad) lol
I don't know if you got this figured out, but I ran into the same issue and was only able to solve it by using the libc::open and passing O_NONBLOCK which is intended for opening fifos like this. Rust does not have any other way to do non-blocking I/O and its basically just required for interacting with fifos.
Right, just read the rules on the sidebar. Won't do!
don’t forget to provide your barrow checker with a [barrow checklist](http://g01.s.alicdn.com/kf/HTB1UHXTGpXXXXXKaXXXq6xXFXXX5/206025245/HTB1UHXTGpXXXXXKaXXXq6xXFXXX5.jpg)
Oh, I see. The `Handler` is constructed once per request. That makes a lot more sense. Thanks for answering my questions!
Or if you want something else to happen when you set the variable, e g: impl Foo { pub fn set_bar(&amp;mut self, v: bool) { self.bar = v; if (!v) { self.close_bar(); self.go_home(); } } } Btw, am I correct in that the Rust convention is that setters are `set_xxx` whereas getters are just `xxx`, unless it's a builder-style method - that's when it's the other way around (setters are `xxx`, getters are `get_xxx`)?
Is left-pad becoming some kind of meme in the programming world?
That's a totally different argument :)
https://github.com/tyc/Aldous-Broder/blob/master/README.md
how is this a meme? it’s simply a joke targetting the fact that his/her misspelling of “borrow” matches “(wheel)barrow”. “meme” means it is used by multiple people. if more people happen to adopt my joke (thus making it into a meme), it’s not my fault since i can’t foresee that happening.
No one is pretending anything, and no one is required to pretend anything. Having a particular name on crates.io does not confer any definitiveness, authority, quality guarantees, or officialness on a crate, and you should not assume it does.
I'll let it stand anyway. But don't reuse it, lest it become a meme.
No, you mean https://crates.io/crates/left-pad And it hasn't been yanked yet.
Meh.
Will do 😋 Out of curiosity, though: any reason you say that instead of “oops, I thought it was one, sorry”? I neither aim to be obtuse nor stubborn, I just pride myself to be able to admit mistakes, and (as fellow mod) think this is a good quality for any person with power.
Yes... but he did it wrong... He should have depended on ~3 other crates for this simple function.
Then `mem::zeroed` was pointed out as a way to initialize the struct before setting whatever fields you want. So how is `transmute` better
I don't fully understand the angle of your blog post. Are you arguing that Rust is very rigid and hard to mutate?
I imagine those projects would appreciate bug reports in their issue tracker.
Yay! This is one thing I had in mind when writing `RegexSet`, so I'm happy to see it used for this case. A couple comments: 1. There must be another router crate out there? How does the performance compare? 2. You might consider having a `RouterBuilder` and a `Router`. e.g., That would let you get around the `RegexSet::new(&amp;["", ""])` awkwardness. (You could use an `Option&lt;RegexSet&gt;` instead, but at that point, there's a clear delineation between "building a router" and "a router used for matching.") 3. I think if you add only one route, your `finalize` method will return an error because `RegexSet` demands at least 2 regexes. I was being conservative. Now that I see it actually used, that seems like a stupid error condition. [Filed an issue.](https://github.com/rust-lang-nursery/regex/issues/189) Oh, and how does a user access components of a URL? (Nevermind, the `README` says it is a TODO. :-))
Compare the value of self as a raw pointer. http://is.gd/fkSKz1
Given how easily unsafe code can cause issues, you'd probably want something more in the vein of "Robot approved" than "Safe". (ie. There's a limit to what static checks can do and the unsafe keyword constrains them, but, when the computer is looking over your shoulder at your code, it'll never miss something because it got bored or distracted.)
In response to the comments: 1. I know of a few tied to certain frameworks like conduit, iron, and nickel. I haven't searched thoroughly for one that hyper can use. 2. That's true, I debated wrapping the RegexSet in an Option. If that would make more sense as an API, then I can switch that up. So a follow up question to this is, do you mean have a `RouterBuilder` that can add routes and then pass that to a `Router::new()` for example? 3. I check to see if the length of the `routes_list` is &gt;= 2 and if it's not I return an error. So I left it to the user to catch that. But if that functionality lands where it needs only one, then I can pull that logic out :). And since you're an author of the regex crate, I thought about opening an issue to provide capture groups to the RegexSet. What are your thoughts on that?
I had a look at that, but it's outdated and just the beginning of a mutator.
Nic Cage is mysteriously missing.
All our `deny` lints (with exception of `invalid_regex`). Also `drop_ref` and perhaps `unused_label`.
Totally, that's just the only previous work I'm aware of.
This happens more than people care to admit (and I certainly don't exclude myself, everyone commits bugs). Having an easy way to turn on ASAN and TSAN during tests would go a long way towards fixing the situation.
Did you change to pipes because a problem with the implementation of the mq? Or just because they are easier to use in Rust?
Yeah, I mentioned it at the beginning of the post. I had a look at it after you gave me a hint on IRC.
Because I realized that I could simplify my software model; I'm compiling and working in a custom kernel environment, so adding message queues meant another compile time feature to put into the kernel, which isn't really desirable.
http://stackoverflow.com/questions/36207839/how-can-i-convert-an-optionstr-to-bson
I really like this as an example of raw pointer usage that doesn't require any unsafe code.
It fails on a release build, thanks to LLVM's pointer region rules. Comparing pointers that aren't part of the same "thing" is undefined behavior in C, and it looks like LLVM inherits this limitation.
It fails for Zero-sized structs anyways, it works just fine if you add data to them.
That must be what broke it, then. It looks like [equality is defined, but ordering is not](http://stackoverflow.com/questions/4909766/is-it-unspecified-behavior-to-compare-pointers-to-different-arrays-for-equality), so this isn't running into that UB.
Doesn't safe Rust still have undefined behavior with some floating point shenanigans?
I assume that duplicating statements is easy with this approach, which means that you should also be able to *relocate* statements easily (which isn't something that you mention at all in your bulleted list).
I would actually love if my `Cargo.toml` could have: [dependencies] abcd = { unsafe: true, version = "0.5.0" } Such that only whitelisted dependencies could use `unsafe` internally or depend on `unsafe` packages. Or since that restriction will make every package `unsafe`, and that low level `unsafe` dependencies may be common across crates, potentially whitelist deep dependencies. [dependencies] iron = "1.0.0" [dependencies.unsafe] mio = "1.0.0" # rotor = "1.0.0" # There doesn't seem to be `unsafe` in `rotor` hyper = "1.0.0" # iron = "1.0.0 # There doesn't seem to be `unsafe in `iron` left-pad = "0.0.3" 
Well, I hope so. I just thought it is worth mentioning, because most safe interfaces will be trivial to crash if there is undefined behavior in safe Rust.
If nothing else it would help make it transparent to people just how many of their dependencies rely on unsafe code, which would hopefully cut down on instances of frivolous unsafe code in the library ecosystem. It might also encourage library authors to use Cargo features to allow users to opt into a version of their crate that uses unsafe code.
Just because something is written in Rust doesn't mean you can trust it. I'm certain it's easy to write malware in 100% safe Rust. This sort of thing can *only* backfire, long-term. Plus, as a programmer, I find these kinds of things *deeply* suspicious. Branding campaigns immediately make me wonder if the people behind them have so little in the way of solid, unambiguous *technical* benefits to talk about that they have to compensate with shiny landing pages and a lists of vague, impossible-to-empirically-measure benefits like an ad for some herbal supplement that probably makes you turn green and cry echinacea. Programming languages are like hammers; putting a bow on it doesn't make it less of a hammer, and isn't going to stop the head constantly flying off. Likely, it won't make a good hammer any better; it'll just get in the way when I'm trying to put a nail in. ... sorry, I think I kinda lost my train of thought there.
&gt; is there really any benefit in running rust on a 32 bit OS? If the choice is between using rust on 32-bit or not using rust at all, I'd definitely go with using rust.
[removed]
So this representation is meant for human eyes, and they should use the better naming scheme.
Why is it using `Cow` when it already has to allocate, might as well just return a `String` at that point.
I don't think you understand how marketing works. It's effective on developers too. People will believe it if you repeat it enough times with confidence. It's why Go is _suuuuch_ an awesome systems language.
There are two libraries I have in mind whose authors told me that it's not worth fixing the issues I raised to them. Other than that, in the past I already reviewed several (maybe 5-10) wrappers around C libraries written by other people, and found big safety problems with all of them. I obviously can't review everything, but based on that sample I think that most if not almost all wrappers have safety problems. I'm also guilty because glutin (53.7k downloads and used by Servo) and hlua (1.1k downloads) are easy to make crash as well.
No, it's not. I needed the Cargo.lock from when you were trying to use `multipart`.
It now builds with multipart! So I guess the cargo update must have fixed it. [Here](http://pastebin.com/mbpMkXyM) is my Cargo.lock anyway..
Wouldn't duplicating statements be a problem due to the possibility of double-borrows? Reordering and removing statements would only require basic data flow analysis, which may be feasible. Edit: No, wait, switching statements can also make borrowck unhappy.
Couldn't you wrap the PhantomData in a newtype that also has the `Io` bound? That way, including it will make the compiler check the bounds.
Yes, I am worried about performance. Because if we need to hit the Rust compiler for each mutation, we'll get roughly 0.1 to 60 mutations compiled per minute (depending on the code size) and we still need to run the tests over every single one. Even limited to single mutations, large code bases can easily get tens of thousands of mutations, especially if we increase the variety of mutations.
A path has to exist to canonicalize it, because `/a/b/c/../d` will not be `/a/b/d` if a segment of `/a/b/c` is a symlink. For instance, if `/a/b/c` is a symlink to a directory `/f/g`, the canonical version of `/a/b/c/../d` will be `/f/d`. You cannot check for that situation if the path doesn't exist. However: URI paths behave differently. A URI `scheme:/a/b/c/../d` is defined to be equivalent to `scheme:/a/b/d`. In fact, if you want to be safe from security exploits of situations like the above, you *must* normalize the URI before resolving.
Couldn't there be such a thing as removing a feature (valid -&gt; deprecates -&gt; hard error -&gt; not in the compiler) provided that a tool exists to quickly upgrade the codebase? Maybe even in rustc itself. You wait, and then, you check through crates.io whether anyone uses said feature anymore. If not, you just remove it. Obviously, it can't work for everything, but it might help remove `try!` if that's ever a thing that we want to do.
&gt; "Software you can trust" Such arrogance.
I'll update the title and clarify the intro a bit because these are the steps you'd need to take to ensure you could build anything you can pull down from crates.io. the Rust compiler is enough for many of them, but anything implemented in C, or that users a linker to system libraries, will need a linker kn a local platform. Hopefully this blog post can become obsolete one day as we're able to replace C libraries with Rust ones, but right now there's still some work.
Thanks, that was fast.
I think that authors not caring about issues is a valid position for them to take (only conclusion from taking "no guarantees" clauses seriously), but I also think that community infrastructure should absolutely help users know what they are relying on. Our crate ecosystem will much stronger if cargo makes it easier to... and crates.io tells us which: - Use unsafe - Use CI - Have test coverage - Their CI runs tests - Their CI runs various sanitizers (as /u/udanburkert suggests) - Their CI runs fuzzers - ... etc
If a library lets me crash it, for example, by panicking when I pass an out of bounds index, I think that is (at least in some cases) reasonable design. I worry a lot more about crates that expose memory unsafe interfaces, but don't know of a good way to test for that. 
I am curious about these situations, can you elaborate how these happen, at least in your libraries? for example in glutin is it because the C libraries you call are easy to make crash despite any feasible input checks by glutin? is it because of problems in glutin itself that are hard to fix? is the whole mental model of wrapping C code by Rust code to increase safety essentially wrong?
I don't see how you've gone from rust -&gt; JavaScript over dependencies. Seems like a big leap. Why don't you want to use external dependencies? There's a crate for everything you've mentioned.
You are talking about Rust, not Java or C#. It's a systems programming language with a minimal standard library, for everything else you have `cargo` and [crates.io](https://crates.io/). There you'll find the packages you need, developed by other Rustaceans. Instead of having a huge and bloated runtime with loads of stuff noöne needs, like Java and C#, Rust prefers having a minimal library that is flexible and perfect in what it does.
That was always pretty annoying throughout the later part of the pre-1.0 development, especially since the language was so volatile at that point. I picked up Rust shortly after the removal of the ~ sigil, and my google searches would continually bring up MIT docs which still used them. I first tried Rust shortly after @ was removed, and had the same issue then. I seem to remember that the Rust developers requested that MIT take down the outdated docs, but were refused.
I thought it wouldn't be a small endeavor to get capture groups for a set. I also had the idea to compile the pattern into an individual Regex and then use captures there. That may be the best option now. Thanks for your feedback, I have some things to work on this weekend :)
You cherry-picked one of the less worrisome problems. [This issue](https://github.com/rust-lang/rust/issues/10184) is much easier to exploit. Any safe function that takes an int can be trivially made to crash using just `1e100f64 as int`. 
I wonder what it would mean for two values of a ZST to not be identical. ZSTs are semantically singletons.
You forgot [maidsafe.](https://github.com/maidsafe) They went rust last July. 
It is a system language which means it is designed to be small library, so it can work on embedded devices, raspberry pi, and other means. If one were to put everything in rust, reduxOS would never exist.
Libcore is for people building an OS or running on embedded devices. Adding more stuff to libstd would not affect this. 
My complaint was not regarding the canonicalize function requiring the path to exist. I just mentioned it to show that it is not very helpful to compensate for the behaviors of other functions in the module.
I don't understand how that would improve things, the type parameter with its bounds would still need to be added to the type which owns the wrapper type. Maybe I've misunderstood, can you show me exactly what the wrapper type would look like?
So I'm going to put this on crates.io and start using it where I needed it, but I'm really not sure if this actually a good idea to do. I think a better solution would be to create a new "platform" for `std` which mocks all io (not just stdio) and exposes some new functions for setting/testing io handles, and to be able to link to that platform during testing. That way, you wouldn't need to do anything special in your production code, only in your testing code.
To get a dynamically linked executable you'll need `-C prefer-dynamic`.
But the other functions can't assume that components of the path are not symlinks either.
In order to full disambiguate, people will need to say 'my-company/left-pad', whereas right now, they just need to say the name of the crate. Having a single namespace avoids more frequent disambiguation errors. There is only one `html5ever` crate, so whenever we talk about `html5ever` we know which crate we're talking about.
Linking to it only raises its search results :p
It doesn't look like there's built-in support to represent optional values in the bson crate. This is untested and uncompiled but I believe you can add that with a newtype and implementing it yourself. To give you an idea of what I'm thinking: use bson::Bson; use std::convert::From struct OptBson&lt;T&gt;(Option&lt;T&gt;) impl&lt;T&gt; From&lt;OptBson&lt;T&gt;&gt; for Bson where T: From&lt;T&gt; for Bson { fn from(ob: OptBson&lt;T&gt;) -&gt; Bson { if let OptBson(Some(t)) = ob { From::from(t) } else { Bson::Null } } } And to use it let doc = doc!{"value" =&gt; OptBson(title)}; 
I see. Discoverability is the only difference, though - the compiler will require the bound if you try to perform io through the type regardless (I suppose the error message will be clearer). I'm not sure honestly that discover is _better_ with a new type, it obscures what is going on. Also I would definitely call it `PhantomIo` so I could still call the marker field `_spoopy`.
AFAIU, the `move` for the closure in this case would only act on the value in `clone`. The error says you can't take the `Vec&lt;u32&gt;` in `field` out of the `TestStruct`. If you change `test_fn` to take `&amp;Vec&lt;u32&gt;` instead, and pass in `&amp;clone.field` it compiles.
I've done the minimal basics to access its dgemm from Rust: https://github.com/bluss/blis-sys
And also Redox is worth checking. 
Thanks!
Your crate, your choice. :-)
Is this something that could be built into rustdoc? I don't know if that fits in the scope of rustdoc but it would be great if all Rust developers got this functionality out of the box.
So historically bugs in Rustdoc led to a lot of 404s, so it wasn't really helpful. However, the new build system checks links, so it seems reasonable... So, one problem with making this an error rather than a warning is that it can make services un-deployable. Once, Rust By Example went down, and I fixed the bug, tried to deploy... And it failed, because it checked the links, which were now 404-ing. So I had to turn it down from a failure to a warning.
That's correct. (The MIT bit)
I agree entirely but to play devils advocate, I think what the OP is speaking to is that external deps arent held to *any* quality or maintenance standards. Plus there's the burden of sorting through all the offerings to determine which one meets your needs (which in and of itself is no small task considering it can require you learn at least the basics of each API, etc.). Im not saying whats in the stdlib is best (*cough* Python), but at least it can be held to a minimal quality standard and not be expected to suddenly disappear. Edit: to clarify I'm just playing devils advocate and take no real issue with Rust's stancw on stdlib size :)
[Google would prefer](https://support.google.com/webmasters/answer/93710?hl=en) if you would add a `&lt;meta name="robots" content="noindex"&gt;` in the `&lt;head&gt;` tag of each page to remove from being indexed.
japaric actually wrote such a tool and used it to generate the above PR. But even then I think it would be irresponsible to not have a sizeable period of deprecation. A breaking change is a breaking change, and transitions such as this always take time to filter through an ecosystem. (Though I suppose it's also worth noting that this breaking change would be minimal to mitigate for end-users, since it's literally just a macro that works on stable and you can take the definition and put it in your own code without any problems.)
&gt; I was talking about checking, not fully compiling the code. Then I'm confused, since earlier you said that you wanted to run tests on every single mutation, and that would necessarily demand running the full compiler. I think I need a more detailed breakdown of your intent and proposed pipeline.
Yes, this is entirely my point.
Security is about the weakest link, so I think cherry-picking the most worrisome problem is legitimate. While my statement would have been more accurate when replacing "make crash" with "trigger undefined behavior", I don't think it makes that much of a difference. BTW, I'm really happy that UB is considered a bug and I'm having a lot of fun playing with Rust for a few years now. How do you know that the floating point soundness hole will be fixed this year? In the issue it seems like there is no consensus how to fix it yet.
I know you use google but just a tip for those who use ddg, there is a !rust bang that searches doc.rust-lang.org and it's super helpful. There's also !crates for crates.io
I don't know what the original reasoning was, but here are a couple of benefits of the current design: - If `set_file_name` guaranteed that the parent dir never changed, then either it would need something like a `Result` return type, or it would need to panic. That would be extra complexity for callers that don't care about the guarantee. - Doing it this way is more flexible. Callers that do care can still check `file_name.parent()` before the call, or something like that. But if `set_file_name` was strict, callers that wanted the current behavior wouldn't be able to use it.
It did indeed get reverted, sadly. Fingers crossed that by 2017 distros will have their act in order such that they don't choke on it. Toes crossed that LLD will descend from the heavens by then to deliver us to an eternity of paradise and elation.
Yes, it's probably presumptuous of me to say that it's going to be fixed this year for sure. All I have is a confident feeling, so take that for what it's worth. :) My reasoning is that the remaining soundness bugs are going to get a larger focus once MIR lands (which I've been assured will be this year), and that the bug in question that you're referencing is one of the oldest P-medium bugs. Servo also seems to be ramping up for wider public releases sometime this year or next, and closing soundness holes is going to be an important component of Servo's reliability story. Finally, the bug isn't fundamentally intractable, it's just annoying, and the discussion so far is how we *ought* to fix the bug, rather than whether it's *possible* to fix the bug (which it undoubtedly is).
How does it compare to existing LOC-counting tools?
I can't remember exactly why, since I only heard about the incident in passing. I imagine that it was not necessarily a matter of them *wanting* to host outdated docs as much as not wanting to update them constantly (the language was very unstable) as well as wanting to host docs in general. From what I can remember of that time period, the MIT people would get around to updating about once every couple months (not necessarily coinciding with releases), but that was nowhere near fast enough to pin down such a fast-moving target.
This is it compared to cloc.pl, comparing the torvalds/linux repo, with hot cache. Tokei first, cloc second. TL;DR Tokei: 3 minutes. CLOC 19 minutes ------------------------------------------------------------------------------- Language Files Total Blanks Comments Code ------------------------------------------------------------------------------- BASH 151 12724 1620 2799 8305 C 22761 15399578 2192602 2032838 11175768 C++ 1 1870 231 58 1581 Device Tree 1918 452023 51972 41362 358695 LISP 1 281 63 0 218 C Header 17580 3872869 422095 732003 2723410 HTML 3 3333 398 2 2933 LD Script 19 571 57 58 456 Makefile 59 3395 663 740 1992 Markdown 1 1297 220 1077 0 Objective C++ 1 244 55 0 189 Perl 43 31550 4433 26983 7475 Python 39 10009 1262 1249 7499 Assembly 1418 398522 47215 4145 347162 TeX 1 1022 108 3 911 Plain Text 3379 414335 87811 326524 0 XML 181 54220 3464 252 50512 ------------------------------------------------------------------------------- Total 47557 20657843 2814269 3170093 14687106 ------------------------------------------------------------------------------- 0.00user 0.01system 3:36.92elapsed 0%CPU (0avgtext+0avgdata 361472maxresident)k 0inputs+0outputs (5670major+0minor)pagefaults 0swaps 53583 text files. 53134 unique files. 12968 files ignored. https://github.com/AlDanial/cloc v 1.66 T=1168.65 s (37.8 files/s, 17001.2 lines/s) --------------------------------------------------------------------------------------- Language files blank comment code --------------------------------------------------------------------------------------- C 22732 2194053 2026817 11198066 C/C++ Header 17377 421605 723149 2725730 Assembly 1417 47163 110196 241250 XML 181 3464 243 50513 make 2163 8180 7838 34425 Perl 47 4567 3604 23971 Bourne Shell 175 1800 3250 9835 Python 42 1312 1461 7560 yacc 8 655 355 4327 HTML 3 398 2 2933 lex 8 299 288 1891 Bourne Again Shell 48 390 261 1612 C++ 1 231 58 1581 awk 10 132 129 1130 NAnt script 2 127 0 476 Pascal 3 49 0 231 Lisp 1 63 0 218 Objective C++ 1 55 0 189 m4 1 15 1 95 XSLT 6 13 27 71 vim script 1 3 12 27 Windows Module Definition 1 0 0 8 --------------------------------------------------------------------------------------- SUM: 44228 2684574 2877691 14306139 --------------------------------------------------------------------------------------- 143.81user 53.20system 19:30.58elapsed 16%CPU (0avgtext+0avgdata 7660800maxresident)k 0inputs+0outputs (135038major+0minor)pagefaults 0swaps 
Define safety.
&gt;If set_file_name guaranteed that the parent dir never changed, then either it would need something like a Result return type, or it would need to panic. But look at the set_extension function, which returns a Bool to indicate success. How is set_file_name different? &gt; Callers that do care can still check file_name.parent()... It seems to me that anyone using this specific function cares about that. Or else they would have used the push function. Right? So I think this function is causing extra complexity for its common and intended use case. 
It looks like they each have different interpretations of when a file should be considered a certain file type, and maybe one also supports more/different file types than the other? E.g. for XML, they seem to agree on what constitutes an XML file, and what's a blank inside one. They're almost agreeing on code, but not on comments (but really only with a slightly over 3% disagreement). In Assembly, there's a huge difference in opinion how comments should be counted, probably because most characteristically for Assembly, comments are often on the same line as code. The number for Code also differs fairly significantly. I don't think it's apples and oranges, but the apples appear to have slightly different flavors. 
Why don't you want to provide platform-specific `Ext` traits and so on like `std` does?
It is really difficult to debug this. For example if you look the number of perl files, tokei, cloc, and github's repo all report a different stat. But as /u/ende76 mentioned tokei has a very strict definition of what a file is. It is mostly through file extensions, and now with a certain sets of shebangs(If you know a lot that commonly used, that arent included feel free to make a PR!). I know that CLOC is based on regular expressions, which I've found to be inaccurate. Tokei only count comments if they are the starting piece. See example below. Also certain files that arent part of Tokei, are part of CLOC and vice versa, so right now i don't have awk, and cloc doesn't have Device trees, or LD scripts. // Counted as comment x = y; // Counted as Code. /* Counted as comment * comment * comment */ x = y * 2; /* Counted as code * counted as comment */ 1+2; // code
Reddit puts `rel="nofollow"` on all links, so it won't raise its SEO.
You've used "runtime" and "standard library" interchangeably here... 
Not a rust user but I recall reading that they're planning to add third-party libraries to the standard library for some things that there isn't currently standard library support for once winners emerge and APIs stabilize.
Now that you mention it, this is frightening :| let mut p = Path::new("myfile").to_owned(); p.set_extension("txt/doc"); println!("{:?}", p); // "myfile.txt/doc" Python's similar `pathlib` methods (like `with_suffix`) tend to validate their inputs and throw exceptions in these cases. I just filed https://github.com/rust-lang/rust/issues/32497 about this.
&gt; there could be a special kind of syntax to link to a language item that leverages the type information rustdoc has. See https://github.com/rust-lang/rfcs/issues/792 Also see https://internals.rust-lang.org/t/rustdoc-restructuredtext-vs-markdown/356
Mathematically speaking, a single grain is a heap (and even no grain would be an empty heap), but that's splitting hairs. I already have apologized to flying-sheep. I was wrong to call his comment a meme. Now please let us get back on topic.
Note that clippy can obviously only lint constant out-of-bounds values/ranges. We don't do whole-program verification.
There's no way that GCC is doing whole-program verification to detect this issue on C code, so for the author's purpose I think this should suffice. :P
Agreed. Also C++'s loop syntax has more room for errors, e.g. mismatching `.start()` and `.end()`. I've been looking at other static analysis packages for multiple languages, and I found a lot of lints for problems that don't exist in Rust by design.
&gt; This does not seem very safe to me, and especially a major selling point of Rust is that it prevents some of the problems that C would seem to have, such as out of bounds access. Wrong! What Rust prevents is [Undefined Behavior](https://en.wikipedia.org/wiki/Undefined_behavior) (esp. those concerning safety). Out of bounds access is properly defined in Rust: it'll panic. In C, out-of-bounds access is undefined behavior. Which means, in the best case scenario, you'll get a Segfault; otherwise your program will continue to run -- which can be really really bad -- in the worst case exposing a security hole...
Question back. Why include MD5? Only reason why MD5 is still around are legacy systems. Everything new use SHA-1, but since SHAppening even that is rather discouraged for new applications. There are a lot of great alternatives for various use cases that including MD5 into anything new would be waste of time (unless this is needed for some reason). 
[Not all links](https://www.reddit.com/r/SEO/comments/2kg0mn/do_reddit_links_count_as_backlinks_or_are_they/), at least two years ago.
Just one thing: Rustc does static linking and link-time optimization by default, so a larger stdlib doesn't mean that binaries get larger (unless you use those functions).
&gt; This does not seem very safe to me, and especially a major selling point of Rust is that it prevents some of the problems that C would seem to have, such as out of bounds access. Rust actually does bounds checking on arrays and vectors. It panics (crashes) on out-of-bounds access rather than having undefined behavior. &gt; Other than the prevention of memory leaks, what safety features does the Rust language have? Rust doesn't prevent memory leaks (consider you can have a circular [reference-counted smart pointer](https://doc.rust-lang.org/std/rc/)) and doesn't consider memory leaks a safety issue. And even though it's considered an "advanced" book, I think the first few chapters of the [Rustonomicon](https://doc.rust-lang.org/nomicon/) is the best introduction for Rust's notion of safety. In special [Meet Safe and Unsafe](https://doc.rust-lang.org/nomicon/meet-safe-and-unsafe.html): &gt; Unlike C, Undefined Behavior is pretty limited in scope in Rust. All the core language cares about is preventing the following things: &gt; * Dereferencing null or dangling pointers &gt; * Reading uninitialized memory &gt; * Breaking the pointer aliasing rules &gt; * Producing invalid primitive values: &gt; * * dangling/null references &gt; * * a bool that isn't 0 or 1 &gt; * * an undefined enum discriminant &gt; * * a char outside the ranges [0x0, 0xD7FF] and [0xE000, 0x10FFFF] &gt; * * A non-utf8 str &gt; * Unwinding into another language &gt; * Causing a data race &gt; That's it. That's all the causes of Undefined Behavior baked into Rust. Of course, unsafe functions and traits are free to declare arbitrary other constraints that a program must maintain to avoid Undefined Behavior. However, generally violations of these constraints will just transitively lead to one of the above problems. Some additional constraints may also derive from compiler intrinsics that make special assumptions about how code can be optimized. &gt; Rust is otherwise quite permissive with respect to other dubious operations. Rust considers it "safe" to: &gt; * Deadlock &gt; * Have a race condition &gt; * Leak memory &gt; * Fail to call destructors &gt; * Overflow integers &gt; * Abort the program &gt; * Delete the production database
Exactly. These functions should be safe by default. Or else one could have just used string manipulation/comparision functions.
How many times in your professional work have your written k-nucleotide or regex-dna outside of a microbench requirement ?
You can't replace language design decisions with a lint. And it's not a good idea to choose arbitrarily what to put inside a lint and what to put inside the compiler. A lint can't contain everything. This important kind of analysis is better kept inside the Rustc compiler.
I totally agree that it's surprising behavior. I remember being very disappointed when it first happened to me, but this isn't a matter of safety. In fact, by choosing to deterministically panic rather than have undefined behavior, rustc does enforce safety. Allowing an out of bounds access is the root of buffer overflow vulnerabilities in C. Now they're gone. That being said, the other choice for Rust could have been to have array access return Option&lt;T&gt; rather than panic on an out of bounds access. This is what `HashMap::get` does. I think this would have been my vote for the API because it won't crash the executing thread. But then, some people believe in crashing ASAP (ahem, Erlang). Tradeoffs everywhere. 
This is something that would be possible, but is not implemented yet. Given the speed of MIR development, and the fact that it's a pain point to many people, I'd be expecting a solution within the next 12 months. Anyway, you can put the for loop into a `{ block }` as a workaround in the meantime.
[Here it is](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.get) You're totally right. See, Rust is safe! :)
What trickiness is involved in counting other than memchr?
Thank you for reply! I've tried that, it doesn't [work either](https://play.rust-lang.org/?gist=052c73109084fa7488af&amp;version=stable) . I've also tried to move loop in it's own function returning `Option&lt;&amp;str&gt;`, but the problem is mostly same.
.begin() and .end() aren't used often in modern C++ anyway, since there are now foreach-style loops. 
Couldn't they have added a `robots.txt` file and be done with it? I mean I understand their point, but there is no reason for their students to use google to find their docs since they already have a link to the course site. That would seem to me like a solution that would make everybody happy (except for whoever has to add the `robots.txt` but that is a "minor" discomfort).
typo, right, thanks! &gt; it cannot be enforced at compile-time. Not even in idris. You can always read an index from stdin and use it to index a vector, there is no way the compiler can tell which index you are going to type after compilation. ultimately this is the same situation as "you could read in an address from stdin and dereference it" really. You will have some operations that would have to be `unsafe`. And with the stdin situation, it can be enforced at compile time. It would be explicitly disallowed, since the set of things that can come in from stdin is a superset of the set of allowed values. I bet Idris doesn't do this, but a hypothetical language could. Keep track of the domain and range of each operation and you should be able to get something out of it. But yes, there still might be false positives; since finding the range of an arbitrary algorithm may not be statically decidable. Ultimately I like Rust's solution. 
The reason why Rust doesn't do bounds checking at compile time is that it's impossible in the general case. The best we could do would be to define a set of special cases in which we can do it (like D does, it seems), and bake those rules into the language specification. That would make those rules immutable for all time--we could never improve them in new versions of the language since we can't break code. Besides being brittle and of little value since bounds check violations are rarely so obvious in the real world, this would massively complicate the language. In the small number of cases in which it is valuable to do this kind of thing, it's better to let those users who need the functionality get a third-party crate from crates.io to do it. That's precisely what Rust does: the clippy crate provides a form of this feature. In short, if it's impossible to do it right (and in this case it is, short of full-on dependent typing) then Rust would rather not do it at all. By the way, similar reasoning applies to why Rust doesn't do Nim-style "disjointness analysis" for data race prevention. &gt; Other than the prevention of memory leaks, what safety features does the Rust language have? Memory safety, which is *not* the "prevention of memory leaks". &gt; This does not seem very safe to me, and especially a major selling point of Rust is that it prevents some of the problems that C would seem to have, such as out of bounds access. It's totally safe. In C that is undefined behavior, so the compiler can do whatever it wants. Out-of-bounds reads are in fact regularly security vulnerabilities, whereas they cannot be in Rust.
Useful and nicely done. Keep going =)
While an extreme case, its possible for a crate owner to simply pull public repos and yank versions from crates.io for one reason or another. Granted a more likely scenario is one where a lib simply gets abandoned. Regardless, both are equally detrimental to getting buy-in for Rust in production when the project is 90% external crates. To be fair this is partially due to the relative newness of Rust and should begin to iron out over the next few years. Edit: I know yanking doesn't affect those alreadying pulling said version, but the point remains. Edit 2: this wasnt intended to have any sort of correlation to the `kik`/`left-pad` debacle as I wasn't even aware of it until just a few minutes ago....but yeah - strange things like that happen and is exactly my point.
In the immortal words of Homer H. Simpson: D'oh!
Do I understand correctly that a project compile requires fully compiling all dependent crates? I looked for any docs on linking and that only really touches on FFI linking.
Do you mean the dependencies? If so, only if they aren't already compiled and have not changed in the meantime. So if you clone a project that has 30 deps, you'll usually compile all of them the first time you build the project. Afterwards, only those that changed.
My project produces an executable, does it also *need* to produce a library to be visible for testing under ./tests? It seems awkward to have a lib.rs and make lots of things `pub`, and just as awkward to have integration tests under /src. I feel I must be doing something wrong :) 
Yes, the integration tests in that directory can only import your stuff as an extern crate. If you don't want to do that you can just put tests in the library itself -- you can put them in a submodule `#[cfg(test)] mod tests;` (and then write the tests in `tests.rs`) if you don't want to clutter up the files.
Can I do this without having a library at all? ie. just main.rs Edit: Yes. ./src/ |-- tests | |-- mod.rs | `-- simple.rs ` main.rs main.rs #[cfg(test)] mod tests; ... fn print_thing() { ... } simple.rs #[test] pub fn test() { super::super::print_thing(); } ---- On a slight tangent, what is the absolute reference to main.rs::print_thing? 
Hm, looks like I mucked up something earlier when I was running into this -- not running into this now. Do you know if failed builds don't cache having built dependencies, or if tests depend on a different set of artifacts? 
What's the problem with this? I can have a `mytext.txt\/doc` file alright. (Edit: Given a broken filesystem)
I don't follow cryptocurrencies really, but ISTM that they're deliberately trying to avoid the situation that Bitcoin has found itself in where the protocol is so ill-documented that people believe it would be irresponsible to produce any alternative implementations (and possibly even minor tweaks to the existing implementation) for fear of accidentally hard-forking the blockchain.
Thanks for the explanation! That seems like a decent enough reason.
I was under the impression that slashes in filenames were genuinely impossible on Linux, short of finding a bug that lets you create them. Part of the problem is, if you manage to create a file whose name really contains a slash, I don't think there's any way to refer to that file using the regular `rm` or `cat` commands (including trying to use `rm *`). Maybe other OS's do this differently? Either way, I think the result of using set_extension with a slash on a Rust path, is indistinguishable from a path that really means to treat `mytext.txt\` as a directory, even if in theory the OS supported putting slashes in filenames somehow. Which is almost certainly not what the user wanted.
That depends very much on the file system. While it *should* be an error to have a slash within a filename under POSIX (IIRC), there is nothing in the kernel that keeps file systems from doing the most evil things under the sun.
In cases where you have a fixed length, a tuple is often more appropriate anyway.
That's fair. I guess my worry is that kernels usually (always? or maybe I'm way off base?) pass around filepaths as a raw string, with components defined only by the slash character. So even if slashes can slip into a directory entry somewhere, there are all sorts of functions in POSIX that can't represent that path. AFAICT Rust treats paths the same way; functions like `is_separator` take a single char, and `Path::file_name()` can never return a string containing a slash for any possible `Path` value. If there was an OS that needed us to represent slashes in filenames for real, Rust's `path` module would need to change its internal representation, and maybe a bunch of interfaces. The result is that what actually happens when you pass a slash to `set_extension`, is that you turn what was a file into a directory with a slightly different name. Even if `set_extension` wanted to support a hypothetical slashes-everywhere OS, the `Path` representation it's working with isn't capable of representing that, and I think that sort-of-implementation-detail leaks through in a lot of places. [50% confidence at most on all the above. This is my first time thinking about a lot of this.]
You might want to look at dependently-typed languages like Idris (also ATS, Agda, Coq, etc). They do provide the kind of type checking that you want, at the cost of Turing-completeness and (my impression is) a lot of manual proof-writing.
Compile time bounds checking is very much possible, see idris for example. But maybe there is something I'm missing?
But the yank would affect all those *not* using `"=ver"`, no? (Assuming the "new" version was `~` or `^` compatible) ...i.e. most crates
While Azer's response was that of a 16 year old, KIK's request wasnt at all polite and was passive agressive extortion style bullying. The fact that `npm` managers acted *without a court ruling* is extremely unfortunate, and in my opinion blatantly wrong. I'd hope the crates.io managers wouldn't do the same.
Well, it won't affect anyone with a lockfile, since yanks just prevent you from changing or adding that version to the lockfile. Though IMO we should allow building over yanks, but disallow _publishing_ with yanked versions pinned in the toml.
So why don't you `cfg` those restrictions according to `target_os`? You can let Windows-only folks have their fun while still doing what you can to keep general use safe.
Too many muts. :) Build your data structures completely and avoid passing mutable references around. For instance: 1. Create a function to convert the word list to a set and return the set, so you don't have to make it mutable. 2. Convert all the words from the set to dvorak. Adding them to another set. 3. Use set intersection to find the words that are in both sets.
- Since you don't need to store any values, use `HashSet` (or `BTreeSet`). - EDIT: I've changed my mind about reading the file, let's use `read_to_string` after all: dict_file.read_to_string(&amp;mut s).unwrap(); let words: HashSet&lt;&amp;str&gt; = s.lines().map(|line| line.trim_right()).collect(); - Filtering for valid words can happen at the time of conversion thanks to `FromIterator` being implemented for `Option&lt;String&gt;`: for word in words.iter() { // if any `get(&amp;c)` lookup fails `converted` is set to None let converted: Option&lt;String&gt; = word.chars().map(|c| qd_map.get(&amp;c).cloned()).collect(); if let Some(converted) = converted { if words.contains(&amp;converted[..]) { println!("{} -&gt; {}", word, converted); } } } EDIT: apparently this is slower than doing the filtering earlier.
How so? Arrays coerce to slices and get all their utility. I don't even think a constant tuple makes sense in most cases. Why not have separate consts for each element in the tuple? Or put them in a struct?
&gt; I know yanking doesn't affect those alreadying pulling said version, but the point remains. Can you clarify this? I thought the point you were making is that depending on a crate is risky since it can be removed and rendered unusable. But this is not true with crates.io, as you pointed out. I'm just wondering what the remaining issue is.
&gt; On a slight tangent, what is the absolute reference to main.rs::print_thing? `::print_thing()` or `use print_thing; print_thing()`
Man, I like the idea of this. It's much cleaner. Unfortunately the ways I've tried implementing this end up being a little slower. Obviously there's nothing performance critical about this problem, so this would be a nicer way to write it. On another note, I love set operations :) EDIT: On another another note, I also agree about muts. I also love default immutability (as well as a ton of Rust's other design decisions).
&gt; let converted: Option&lt;String&gt; = word.chars().map(|c| qd_map.get(&amp;c).cloned()).collect(); Can you explain what's going on here? This looks cool. In this particular case, pruning the whole dictionary for only valid words ends up being faster because "e" is one of the invalid letters since it's a "." in Dvorak. And the majority of English words have an e in them somewhere, so it demolishes the set of words that need to be converted and checked. But I think I would use this pattern all over the place. But I don't understand why the `.cloned()` is in this line. 
I'm not quite sure how to get to the rendered docs for the relevant impl, but here's [a source link](http://doc.rust-lang.org/src/core/option.rs.html#867). That implementation lets us `collect` an iterator of `Option&lt;char&gt;` into `Option&lt;String&gt;`. The moment it encounters `None` collecting is short-circuited and `None` is returned, but some temporary string has likely already been allocated at this point, hence the slowdown. `qd_map.get(&amp;c)` returns almost what we want to feed to `collect`: a `Option&lt;&amp;char&gt;` so we use `cloned` to turn it into `Option&lt;char&gt;`.
Since the filtering bit proves beneficial, it is done slightly wasteful: you search each string up to 8 times. I'd prefer one of the following: !word.chars().any(|&amp;c| c == 'q' || c == 'Q' || c == 'w' /*etc*/) !word.chars().any(|c| "qQwWeEzZ".contains(c)) !word.contains(&amp;['q', 'Q', 'w', 'W', 'e', 'E', 'z', 'Z'][..]) 
I am not sure. It seems that I cannot do it in linux. [This SO thread also says it is not possible] (http://stackoverflow.com/questions/9847288/is-it-possible-to-use-in-a-filename). The problem with this is the same as things like sql injection. You expect a file name, or extension. But allows the input to include data that will be interpreted as something else. In this case and the case of set_file_name, it becomes possible to include a directory segment. So the programmer has to take extra precaution to makes sure this does not happen. But being a path manipulation library, one expects this library to protect the user from this, to a possible extent. 
Cool! As a Dvorak typist, I am amused by this. I decided to go to silly lengths to optimize it, and you can see the results in my [`array` branch](https://github.com/mbrubeck/qwerty_dvorak.rs/blob/array/src/main.rs). Here are the main changes I made: * Use a static array instead of a HashMap for character lookups. * Map all non-alpha characters to nul bytes. * Operate on `[u8]` instead of `str`, to avoid UTF-8 validation. * Pre-allocate vectors and maps, to avoid re-allocations. On my computer, the `array` branch runs more than twice as fast as the`master` branch (20ms compared to 50ms, as measured by `time ./target/release/qwerty_dvorak`).
&gt; I don't think the policy is clear on how the crates.io maintainers would deal with such an action. ...because The Law cannot be clear-cut? &gt; ### The Law &gt; &gt; For issues such as DMCA violations, trademark and copyright infringement, Crates.io will respect Mozilla Legal's decisions with regards to content that is hosted. &gt; &gt; \- [Crates.io package policies](https://internals.rust-lang.org/t/crates-io-package-policies/1041) You can't expect it to be a mathematical equation... ;)
As soon as the Cargo Yanks Act becomes an actual law, sure.
still new to rust here, but that seems like it would be counterproductive to me. If you are trying to debug an issue, wouldn't you want it to execute the same as your release version?
I don't know what your real goal is, if you are trying to store different type of data in the same variable I suggest using enums instead of generics.
The templates are expanded at compile time, so that everything is inlined, right? Or does this have a run time cost?
How much support time would npm need to allocate to handle cases like 'I accidentally published my keys' if unpublishing required manual intervention? crates.io has far fewer users than npm.
Oh! Good to know... Right now xml-rs does not allow emitting partial-content (you simply have to accept a complete document, whether you like it or not!). I don't know if there's a reason behind that design because I really have no idea about the specifications, namespaces and all that...
If your secret credentials are published, ever, unpublishing is emphatically not the solution to the problem. Any such credentials must be assumed to be compromised and must be revoked without delay.
I think your main issue is that you are conflating values and types, possibly even what happens at compile time with what happens at run time. Everything at compile time must resolve to a single type. An enum is a single type at compile type with a set of possible values at run time. However you are trying to use the enum's run time values (`Integer`/`String`) in a way where they resolve to different types at compile time (`MergeFile&lt;i32&gt;`/`MergeFile&lt;String&gt;`) which is simply not possible. In short, you need to pick one because Rust does not (yet) have support for using constant values to specialize types. If you want to stick with an enum's values to choose the value of the key, you'll need to do so in a way where the `MergeFile` only uses the values of the enum at run time and maybe isn't generic at compile time - [example](http://is.gd/5j93M2). If you want to specify values at compile time and be generic then you can "just do it" and not worry about an enum at all since those values have their own types - [example](http://is.gd/BHnUQF).
Sure. That isn't really relevant though. The point is this: how many valid and totally harmless requests to unpublish would npm receive if they didn't have unpublish? How much of an investment would that be to resolve? Will crates.io be able to afford to only offer yank without manual intervention when it has that many users? Substitute 'my secret keys' with 'proprietary code' or 'unfished code,' or 'pornography' or anything else. Fielding unpublish requests requires resources that become unwieldy at a certain number of downloads per day.
Old one continues to work because of already generated Cargo.lock. New one doesn't, because Cargo consults crates.io to generate new Cargo.lock. This assumes you copy/paste a dependency in Cargo.toml, but do not copy Cargo.lock. In general, the assumption is that Cargo.lock is solely managed by Cargo.
Thanks, it's not a big deal, was just hoping there was a more concise way to do it.
No, that is an incorrect formulation and is definitely *not* the same. ```step_by(c)``` means "skip ```c``` elements each iteration" and not add ```c``` to ```i```. Your example is misleading and wrong and you have disregarded my alternative example altogether.
rust-lang-nursery already has a bunch of random stuff, like a regex crate and rustfmt. clippy might join them at some point too. So I'd say that a bindings generator (a pretty useful tool and necessary to have) would probably have a chance. rust-lang isn't just for "Rust as a language" stuff
The Rust "const V: &amp;'static [u8]" is more like the D "enum ubyte[3]". And D gives the same error even if you remove the "const": void main() { import std.stdio; int[3] v = [1, 2, 3]; writeln(v[3]); } test.d(4,13): Error: array index 3 is out of bounds v[0 .. 3] General rule to keep in mind to avoid troubles: Rust is not always necessarily a better language than D.
Can you iterate a tuple in Rust (as in D)? Can you access its items with an index with a uniform [i] syntax (as in D)?
Actually, given that sounds like a fairly typical SAX-style API, it's probably that you're expected to roll your own fragment support and then only feed the completed document to the `EventWriter`. (I've done that sort of thing before in Python. Each function returns an iterator which is responsible for flattening in the contents of any child iterators.)
&gt; The thing about Lua is that it's both (a) very simple and (b) very flexible and expressive. A static type system will have a really hard time satisfying both of those at the same time. (That, essentially, is I think why we don't yet have such a thing as "a statically typed language like Lua". It's not as easy as it sounds.) The simpler the type system is, the more awkwardness, syntactic overhead, and rigid structure is imposed upon user programs. Conversely, the simpler, more direct, and more malleable user programs are, the more powerful the type system has to be. I agree! I do think we are going about the type system in two different ways though. I am trying to make a type system which is as simple as possible (both semantically and implementation wise) without being awkward to use. There will always be some programs a typed language will be unable to write (easily at least) so I am going for a "good enough" type system (which is still quite powerful I think). On the other hand, as I am understanding it, you want to anticipate as much as possible of what I use may want to write and then have type system that accommodates this. Essentially trying to have a type system that is flexible enough to not be noticed unless absolutely necessary (which makes it dynamic in some sense). I can't say which approach is the best but I know that this is a really large project regardless so going for an easier type system to start with seems sensible. I would rather have a type system which covers all bases of course, but as I also have to be implement it I prefer to go with a potentially inadequate system and then extend or change it if it gets to that point even that means it is more problematic to change at that point (as you wrote). &gt; (Or you can go the Go way and be OK with runtime casts, data races, and copy-pasting as the price of specification/implementation simplicity.) Sort of on the same note as above. I think Go shows to some extent that at least for applications it is possible for most people to live with a weaker type system. Personally I dislike Go's simplistic type system but for the type of programs it wants to be useful for I can still see it as acceptable.
How does the llvm autovectorizer handle the bounds checking on loops, does it mess with it (as in cannot vectorize)?
&gt; Actually the hashing algorithm is independent of the type of hashed data (which is really clever if you ask me), and you can switch out Hashers per map, so if you have one map in hot code that you know will only have short (≤64b) keys, plug FNVHasher for a nice speedup. Or you can write your own more specialized hashers for possibly more performance gain. But you'll know when doing so you give up HashDoS safety, so you better not let an attacker control the keys. So Rust's default hash is structural and, therefore, will break when applied to any value where structural equality and semantic equality are not the same, like a balanced tree? 
A match is going to be the most efficient thing and in this case it's easy to do as all the matching -- including `qd_map` -- is static. Especially `qd_map` can be compiled to a computed jump. Someone somewhere might already have written a macro like `hash!` for that, if not, it's easy enough to implement with `macro_rules!`. ...it should also be able to handle lower and upper case uniformly by flipping a single bit first, as the thing is matching against an ASCII subset of UTF-8.
Not quite. First of all, there is no XHTML form of HTML5, which kind of makes the thing rather odd - you'd be generating something XHTML-like with no schema, so the chances of generating which is _somewhat_ XHTML-like (following the general syntax, but not following any set rules) are quite high. Also, XHTML is _odd_ when it comes to attributes. (`selected="selected"`) and stuff like that. There's a reason why HTML5 has no XHTML form anymore. In addition to that, content is often mixed together with third parties, so it is quite possible that you well-crafted XHTML-compatible HTML stops being that quite quickly.
I particularly don't like an aspect about it: [the design](http://tafia.github.io/quick-xml/src/quick_xml/lib.rs.html#404-406) of representing everything in one single vector. It is not friendly, because when a user needs a tiny feature, s/he may not want to wait for the original author to implement it. But if the design is opaque/complex, we'll have to invest considerable amount of time to achieve it (unjustifiable w.r.t the complexity of the problem). So I'll distance myself from it if I can.
If you `#[derive(Hash, PartialEq, Eq)]`, you'll get structural equality and hashing, yes. You are of course free to implement those traits by hand. For example look at the [Hash](https://doc.rust-lang.org/std/hash/trait.Hash.html) trait. The methods get a [Hasher](https://doc.rust-lang.org/std/hash/trait.Hasher.html) instance which encapsulates any hash algorithm we may choose. It is the responsibility of the `Hash` impementation to align the hashing with semantic equality. This design works quite well in practice but makes it *very* hard to do things like hashing unordered sets.
I'm well aware that there's no "XHTML5". It's not because it's dead... it's because they explicitly decided to merge it into HTML5 by ensuring that the well-formed XML serialization was a subset of valid HTML5. (Which means that there IS a schema... the same schema you'd use to validate HTML5 that *isn't* well-formed XML.) The "reason why HTML5 has no XHTML form anymore" is because experience taught them that having it as a second set of doctypes with their own semi-separate spec was wasteful. In fact, until maintenance was stopped in September 2015, there was a full-blown [spec for "polyglot markup"](https://www.w3.org/TR/html-polyglot/). As for mixing it with 3rd-party content, I'm well aware that all bets are off in that case unless you parse the 3rd-party content and re-serialize it. I don't see what bearing that has on the validity of generating HTML5 that's also well-formed XML.
I just wrote my own benchmark that uses a `HashSet` to find neighbor shells in a potentially-infinite graph: type [&lt;Struct&gt;] P = val i : int val j : int new(i, j) = {i=i; j=j} let cmp = { new System.Collections.Generic.IEqualityComparer&lt;P&gt; with member __.Equals(this, that) = this.i = that.i &amp;&amp; this.j = that.j member __.GetHashCode this = this.i + 4000 * this.j } let inline iterNeighbors f (p: P) = let i, j = p.i, p.j f(P(i-1, j)) f(P(i+1, j)) f(P(i, j-1)) f(P(i, j+1)) let rec nthLoop n (s1: HashSet&lt;_&gt;) (s2: HashSet&lt;_&gt;) = match n with | 0 -&gt; s1 | n -&gt; let s0 = HashSet(cmp) let add p = if not(s1.Contains p || s2.Contains p) then ignore(s0.Add p) Seq.iter (fun p -&gt; iterNeighbors add p) s1 nthLoop (n-1) s0 s1 let nth n p = nthLoop n (HashSet([p], cmp)) (HashSet(cmp)) (nth 2000 (P(0, 0))).Count That F# takes 2.037s to run (in F# Interactive, I didn't try batch compiled). Here's the fastest Rust I've got so far: use std::collections::HashSet; use std::hash::BuildHasherDefault; use std::default::Default; use std::hash::Hasher; pub struct FnvHasher(u64); impl Default for FnvHasher { #[inline] fn default() -&gt; FnvHasher { FnvHasher(0xcbf29ce484222325) } } impl Hasher for FnvHasher { #[inline] fn finish(&amp;self) -&gt; u64 { self.0 } #[inline] fn write(&amp;mut self, bytes: &amp;[u8]) { let FnvHasher(mut hash) = *self; for byte in bytes.iter() { hash = hash ^ (*byte as u64); hash = hash.wrapping_mul(0x100000001b3); } *self = FnvHasher(hash); } } type Set = HashSet&lt;(i32, i32), BuildHasherDefault&lt;FnvHasher&gt;&gt;; fn Empty() -&gt; Set { let fnv = BuildHasherDefault::&lt;FnvHasher&gt;::default(); HashSet::with_hasher(fnv) } fn iterNeighbors&lt;F&gt;(mut f: F, (i, j): (i32, i32)) -&gt; () where F: FnMut((i32, i32)) -&gt; () { f((i-1, j)); f((i+1, j)); f((i, j-1)); f((i, j+1)); } fn nthLoop(n: i32, s1: Set, s2: Set) -&gt; Set { if n == 0 { return s1; } else { let mut s0 = Empty(); for &amp;p in &amp;s1 { let add = |p| { if !(s1.contains(&amp;p) || s2.contains(&amp;p)) { s0.insert(p); } }; iterNeighbors(add, p); } drop(s2); return nthLoop(n-1, s0, s1); } } fn nth(n: i32, p: (i32, i32)) -&gt; Set { let mut s1 = Empty(); s1.insert(p); let s2 = Empty(); nthLoop(n, s1, s2) } fn main() { let s = nth(2000, (0, 0)); println!("{}", s.len()); } That takes 2.66s. Can you make the Rust faster? 
[nom](https://github.com/Geal/nom) is a really nice parser combinator library for binary data (I wrote a quake 3 level parser with it and it was extremely ergonomic, if a little sigil-heavy). I've heard good things about [combine](https://github.com/Marwes/combine) also, although I haven't used it.