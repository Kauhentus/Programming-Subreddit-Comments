The changes in the \`Future\` trait are these: \- Take \`Pin&lt;&amp;mut Self&gt;\` rather than \`&amp;mut self\`. This is a no-op if you set any \`T: Future\` to \`T: Future + Unpin\`, but without that bound (if you want to support unboxed \`async fn\` inside your custom future) you have to use the pin\_utils macros or careful unsafe code to ensure that no values are accidentally moved. \- Take \`&amp;LocalWaker\` explicitly rather than implicitly requiring that a wakeup handle be passed down through thread-local storage. \- Returns \`type Output;\` rather than \`Result&lt;Item, Error&gt;\`. This means that futures don't all necessarily have to have an \`Error\` value. &amp;#x200B; The first of these changes is necessary in order to support async/await, and is largely ignorable through the mechanical addition of \`Unpin\` bounds. The second makes a parameter that was always present explicit, and will require mechanical addition of the parameter to many functions. The third change means that some, but not all futures will have an error type, so APIs may change as a result: this was done in order to support things like \`async fn foo() -&gt; i32\` without strange compiler magik. &amp;#x200B; I don't personally think that any of these things make for an inferior experience, but the introduction of \`Pin\` means that implementing manual futures will take more work \*if\* you want to support unboxed \`async\`/\`await!\` code. Of course, the current futures 0.1 model doesn't support unboxed \`async\`/\`await!\` code, so it's strictly better for \`async\`/\`await!\` users to be consistently using the new trait even if they need to continue to box their futures.
The library API is, I'd say, one of the most (if not the most) currently used unstable library components in \`std\`. It's used in futures-rs, Fuchsia, and has been used alongside the existing Tokio ecosystem using the futures-0.1 compatibility functionality. Tokio and the rest of the ecosystem cannot migrate to an unstable API (given that they currently work on stable).
Last Rust job I interviewed for was porting Python stuff to Rust, or doing new stuff in Rust. I don't agree that you need to know C, but anyone using Rust right now is likely doing something relatively ambitious, and are looking for people with pretty deep skills, either deep skills at Rust, at Math, and low level systems programming, something. Mostly senior level roles probably. 
Maybe not what you're looking for but I've completely moved away from using [lib] [[bin]] to get the separation where core logic is a lib and unit testable and the main function is somewhere else. Now I pretty much exclusively use cargo workspaces where I have a bin crate and a lib crate and use a relative path to include the lib as a dependency for the bin in Cargo.toml.
I thought you wrote a book and wondered how I missed to pre-order it!
I read the book :D 
Not necessarily. It is true that Rust's roots are in systems programming spaces where C/++ traditionally dominates, but I think Rust has a broad enough appeal that we'll eventually see the industry moving to it from many different domains. But also, if you're trying to decide which language to learn, I would start with thinking about which problem domain you're more interested in. If you want to do low level systems software, like embedded, kernel work, drivers, etc, learn C/++. If you want to write applications, web servers, big data analytics and pipelines, etc, learn Java or Go. If you don't really know, I'd recommend defaulting to Java.
I'm sorry I don't know if I wasn't clear, but that's not my point. This code is just an example of me trying to pass the function pointer from C. There are a lot more things, I just want to be able to pass the pointer to `free`. Can you explain why I shouldn't rely on `Arc::strong_count`? Does it actually cause problems? Because I do need the inner `Arc`... It's a good suggestion to define the drop function when constructing the data-structure, but that doesn't actually solve the problem: **How can I pass the pointer to the C function to call from Rust** Btw that still causes problems if some elements are static and some are allocated, but I don't think there is a way to solve that (besides passing the pointer to `free` for each element). 
Gotcha. I appreciate the response. The idea of porting Python code to rust code is pretty encouraging, because those are my two favorite languages atm. But maybe I'll save Rust for after I have an entry level job, and try to work my way up with it. Thanks again!
Nit: the \`poll\_unpin\` gets you some of the extra way here, and for a wrapper like the one here it's not necessary to use \`TryFuture\`. The way I'd write this today would be &amp;#x200B; impl&lt;T: Future + Unpin&gt; Future for MyFuture&lt;T&gt; { type Output = T::Output; fn poll(self: Pin&lt;&amp;mut Self&gt;, lw: &amp;LocalWaker) -&gt; Poll&lt;Self::Output&gt; { self.poll\_unpin(lw) } } &amp;#x200B; i'm not sure how fair this is, since obviously the complexity of the different examples will vary based on the specific case in question, but I don't think most \`poll\` impls (for \`Unpin\` futures) look significantly more complicated. To the contrary, many of them actually get more ergonomic as a result of the \`std::ops::Try\` implementations for the \`std::task::Poll\` type.
You can definitely write your own - it's a different syntax, but not inherently harder.
The new futures API is different from the old API exposed in 0.1 and has a busier API as a result of changing from `&amp;mut self` to `Pin&lt;&amp;mut Self&gt;` and some other miscellaneous bits I've outlined above. These were important changes which allowed for more ergonomic and performant async/await code. As I've explained above, opting into `Unpin` will largely get you the similar ergonomics to 0.1, but without the built-in error type in the default trait (use `TryFuture` instead for the `Result`-y version).
&gt; Can you explain why I shouldn't rely on Arc::strong_count? Because the way you're using it is going to cause memory leaks. Two threads are going to hit that `is_last` check before either has has a chance to drop their `Arc`, and then no one is going to be responsible for freeing all of the list elements because no one saw themselves as "last" &gt; How can I pass the pointer to the C function to call from Rust It wasn't clear at all that this was your real question. It sounded like you were asking about the overall strategy. Without more concrete code from both the C and Rust side that reproduces your issue, I'm not sure how much help anyone can be, since I don't see anything conceptually wrong with passing a C function pointer to Rust.
What if I wanted to do something with AI? I have a degree in Psychology with a focus in Neuroscience/cognitive science. I've considered picking up a language like R and doing a machine learning project with that and Python.
&gt;Two threads are going to hit that is_last check before either has has a chance to drop their Arc That makes a lot of sense, thanks! But what is the solution if the data-structure I'm writing the FFI for actually has a interior Arc that's needed? &gt;It sounded like you were asking about the overall strategy. I see, it was part of that, but the (former) example code doesn't actually work, it segfaults. My main problem is exactly that FnFree is probably the wrong type. But I have no clue which is the correct one. &gt;I don't see anything conceptually wrong with passing a C function pointer to Rust. So this code should actually not cause UB?
I think this is better. With the short-circuit evaluation, it should be same between both when execute. I'm not familiar with boyer-moore, so I haven't figured out where's the problem yet.
I think you could; I haven't done a ton of research of the state of machine learning in Rust, but I think some libs exist. But it is unlikely at this point that you'll find a job where you're doing AI/ML in Rust. For a job, I think that space is dominated by Python.
How about using the lazy_static crate to make something roughly like this: ```struct TestDb { con: DbConnection, } impl TestDb { fn new(url) -&gt; Self { let mut con = DbConnection::to(url); con.execute(cleanup_queries); TestDb { con } } fn get_con(&amp;self) -&gt; DbConnection { self.con.clone() } } lazy_static! { static ref TEST_DB : TestDb = TestDb::new("some_url"); }``` And then the tests do this: ```#[test] fn db_foo() { let mut con = TEST_DB.get_con(); con.execute(create_schema_query); con.execute(more_queries); }``` That way, the first test that is run and needs the Db will call the setup code. All the others can just use the Db normally. If you want to clean up after the tests instead of before, you could impl Drop for TestDb. However, be aware that destructors will not run always be run, for example if your program is terminated ungracefully.
Try the `diesel_migrations` crate for running SQL migrations programmatically from Rust. If you want a temporary database (in this case PostgreSQL) specifically designed for testing, install `pg_tmp`. It's incredibly fast, with startup times of less than a second, and performs its own locking and database isolation, making it perfectly safe for use with concurrent tests. In short, from within your test, spawn a database with `pg_tmp`, get the connection string, connect to it and initialize it using `diesel_migrations`, and run your inserts/queries.
Diesel works really well, it could use a lot more guides though.
Thanks for the encouragement! I'd really hate to abandon Rust altogether, so hearing that really helps. But you're right, I think I'll shift my focus to something more practical, and make learning Rust a side project.
I have used Rocket and Actix-web. In Actix you have to define messages and actors, and implement traits for those actors. This is probably more performant and robust but you end up with a lot more boilerplate and indirection. So I think that Rocket is simpler to use.
So I tried this out after your suggestion and got some...interesting...results. so it's: s3dconverter/ Cargo.toml src/ main.rs src/ lib.rs Cargo.toml the s3dconverter has the name = 's3dconverter' as you would expect, but here is where it gets interesting... if I put no [[bin]] in the root Cargo.toml then I can't cargo run, I have to go to the s3dconverter folder before I can run it. But if I add a [[bin]] section in the root Cargo.toml then I can cargo run it...but then it depends on if I'm in the root or the s3dconverter directory which determines if I get s3d or s3dconverter as the info passed into cargo on build! So, does this seem to be a bug to anyone else? I would have expected this to just work the right way from either directory, root *or* workspace.
I suggest: * find a tiny project to do in Rust, maybe porting something small and self-contained that you wrote in another language. * if you are having trouble figuring out the smart pointer types, [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) is great, and gets you very comfortable with the compiler errors! * [Programming Rust](http://shop.oreilly.com/product/0636920040385.do) is wonderful for clarifying all sorts of topics that might still be a bit hazy. I just skimmed through stuff I was already confident with and went slow with the stuff I found tricky, and now it serves as a great reference when I need it. * You probably don't need to worry about the Rustonomicon. I still haven't dug into it and I don't expect I will until I actually have a real need to write unsafe Rust. Similar story with macros, I've barely spent any time learning how to write them because I haven't found the need to write any yet. * just start using Rust to build cool things and learn the various topics as you need them :)
Oh, I indeed did. Thanks, I'm going to add a note about that. Btw. it's a pure coincidence but that Niko's blog series treads quite similar grounds, so there's likely to be more cases that aren't accounted in my post!
I'm working on learning Gfx-hal!!! First graphics API so wish me luck. Think I'm gonna be on this for a while lol
good times on rust 
Sorry this isn’t a direct response to your question OP, but I just started learning Rust and am not looking for a development job but I just wanted to mention that the replies in this thread were extremely helpful for my understanding of current practical applications for the language. I know a handful of languages including C, Python, and Java but I have been struggling to figure out where it makes sense to use Rust instead of the current popular languages, and several Redditors offered really clear explanations with lots of examples to help answer this question. Thanks OP for bringing up this discussion!
It's good to know there are others in this sub who are just starting out with the language and have the same questions I do. I'm glad my post helped you, even if it was in a roundabout sorta way. Good luck!
Remember there is always an exception in all the rules.
Gotcha. Just to clarify, what do you mean by "distributed systems?" I'm still in the process of learning all the software developer lingo.
Very true!
&gt; write out "I will check the subreddit topic before posting" 1000 times I think you should accept a short rust program that would do it as an alternative to writing on paper.
that directory structure doesnt look like a cargo workspace, heres an example im working with right now ``` dev|stashed $ ls docs game-core game-main target texture Cargo.lock Cargo.toml COPYING README.md tags dev|stashed $ cat Cargo.toml [workspace] members = [ "game-main", "game-core", ] # [profile.release] # lto = true dev|stashed $ cat game-main/Cargo.toml [package] name = "gameoff" version = "0.1.0" authors = [] [dependencies] amethyst = "0.9.0" game-core = { path = "../game-core" } # [profile.release] # lto = true ```
yup, that's how I eventually changed it to. virtual root, two workspaces. Everything just works right then. I just find it *very* odd that a root with a workspace results in different values being sent through cargo build depending on if you do it from the root or the workspace, that seems like a bug to me. 
(Sorry for my English, not my main language) Pattern matching can be implemented more easily if your programming language is statically typed you just need to use structure like this: ```rust struct Value { pub ty: Type, pub value: ValueEnum, } ``` And for something like `match value` you need to know `value` type and then check that type of all values type that you matching,something like that: ``` for val in match_values.iter() { val.ty.is(value.ty); // should return err if val.ty != value.ty } ``` And then match all values: ```rust ///Just pseudo code let mut case_index = None; for (index,val) in match_values.iter().enumerate() { if val.value == value { case_index = Some(index); break; } else { continue; } } if case_index.is_none() { cases[0].eval(); // 0 it's a index of default case, like that: `_ =&gt; {}` } else { cases[case_index.unwrap()].eval(); } ``` 
Dump question, but does the usage of the system allocator really change the binary size? I though that was only changing the amount of memory allocated.
A [distributed system](https://en.wikipedia.org/wiki/Distributed_computing) is one that's split up over multiple independent, concurrent subsystems connected via some communications scheme, typically assumed to be "a network". In truth, basically all modern software is a distributed system in some light, simply because of the internet's pervasiveness. But I put the term "distributed systems" on my resume to mean that I've studied how to design explicitly distributed systems and the infrastructure they need, as opposed to using an existing infrastructure.
Roughly speaking, "distributed systems" refer to applications where the code runs in different machines that are communicating with one another. As a motivating example, Google's databases are replicated and partitioned, so that there are multiple copies of each piece of data, and no single computer has all the data. This is done for many reasons - reliability (what if a computer loses power, it fails some other way?), scalability (what if a user queries for data that's on a particular server, but that server's already busy?), etc. This all sounds great so far. But the problem is, databases can change; their data can be modified. And we want to be able to make guarantees about how the data changed, so we want the database to support transactions (i.e. either a change is made, or it isn't; but it's never "half done, half not"). Do this means, all the machines that represent the database need to agree on what the data should be; they have to communicate with each other (based on how the clients are interacting with them), and come to a consensus about what's happening. That's a distributed system: a service or application where work happens on multiple computers that are communicating with each other. I hope that made sense! For more info: https://en.wikipedia.org/wiki/Distributed_computing
Plot twist. The bots being used to ddos were being controlled via rust.
https://github.com/rust-lang/rust/issues/55910
Awesome! Wow, thanks for publishing this. Can't wait to work on this over the winter! I assume there's no lecture video material?
I just successfully tested my [Suriza solver](https://github.com/butzsch/Suriza-solver) for the first time. Now I'm working on improving it so it's able to solve some more inputs it currently doesn't know how to deal with. Also I'm preparing a talk about Rust for my colleagues, explaining the basic concepts and features of the language.
With dynamically typed programming language you need to implement PartialEq to your `Scalar` enum and make something like there https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2015&amp;gist=518fb2e9ea5ebc47cc09952acf886026
`(0..1000).map(|_| println!("I will check the subreddit topic before posting")`
Rust has `break`? It doesn't even have for loops
If only you could use a `println` fn, I'd b write it as iter::repeat("I will check the subreddit topic before posting).take(1000).for_each(println)
Alas no, university policy is to keep videos internally (partially due to the [Berkeley lawsuit](https://www.washingtonpost.com/local/education/why-uc-berkeley-is-restricting-access-to-thousands-of-online-lecture-videos/2017/03/15/074e382a-08c0-11e7-a15f-a58d4a988474_story.html?utm_term=.1fc8305870e4) I believe?). However, I worked hard to make the lecture notes accessible, so they should still suffice in lieu of a video.
I think that would be too complicated. I want to make a command line app that would take data from stdin, perform some operations on it and then send the changed data to the websockets. I also need some logic to respond to http requests and host my static files. I'm sorry I didn't specify it earlier.
&gt; What if I wanted to do something with AI? Python. Probably with TensorFlow. I don't like Python personally, but it's a rather large community for machine learning, statistics(R is also good at that), fintech, VFX, etc. Things like computer vision and machine learning might use C/C++ under the hood but provide Python wrappers to utilize in python instead of C/C++. From what I understand(not a C/C++ dev), while many languages support FFI that works well with C, integrating with C++ is less smooth of a process or something, otherwise I wouldn't bother with Python which has the large community/ecosystem that supports many of those kind of bindings. 
Thanks!
&gt; I notice that there isn’t any symmetric crypto. And type of ETA? I’m really curious on how you’d build an API for AE. It's on the roadmap! I haven't filed an issue for it yet, but I plan to add AEAD support at some point. I haven't considered other forms of AE. &gt; your password API accepts a &amp;[u8]. While perfectly normal, we’ve seen a couple times lately how improperly handled passwords get added to logs. Have you thought about exposing a wrapper that locks down Debug/Display, and possibly auto-zeroing and other possible mlock shaninigans like SecStr does? That's an interesting thought. So far I've been allowing types which can really be expressed as byte slices (in other words, any given sequence of bytes is a valid instance of the type) just be plain byte slices, but I do see the argument in favor of doing otherwise. If you're curious about the general philosophy around types, check out the [DESIGN.md](https://github.com/google/mundane/blob/master/DESIGN.md) file.
&gt;consider using [Actix](https://github.com/actix/actix) and its ecosystem. +1 to this. An important benefit of using Actix-web is the ability to build your application with actors.
Thanks! Too bad though that this binary uses jemalloc, so that's not a helpfull thing to look out for. Going for the strings in the binary seems like the best bet.
Thank you!
[Custom test frameworks](https://doc.rust-lang.org/unstable-book/language-features/custom-test-frameworks.html) were implemented recently. We are now able define our own test runners, enabling set-up and clean-up while using ``cargo test``.
Sorry I don’t have a direct answer, it’s been quite a while since I’ve done any Rocket stuff, but I’d wager you might want to lean on MIME types here (ex use the `Content-Type` header) to let you know what type of data is coming in.
Which binary ?
Is it only a syntactic check? Or does it check that the binaries do not contain anything from standard? (like symbols, etc.). 
Ahh I'm already flying in to Russia via St Petersburg the day after this and will miss out on the great opportunity! Considering changing my tickets haha, would love to meet some more developers in your part of the world. 
You can! One can even experiment with it on the [playground](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=262ef15b92e19e52d9af6d2f07dc6f46) :)
`*const extern fn` is a double-reference in rust. `unsafe extern fn(ptr: *mut c_void` is already a function pointer, so `*const unsafe extern fn...` is a pointer to a pointer, which I imagine is why you're getting a segfault. See https://doc.rust-lang.org/nomicon/ffi.html#targeting-callbacks-to-rust-object. Let me know if that helps?
One of the basic mistakes when using `verify` is to discard the return value. What about either annotating the verify function with #[must_use] or wrapping the return value in a #[must_use] type?
Diesel is not really an ORM but more of a query builder. This is important to note because if you go into it expecting something like Django's ORM, like I did, you will be disappointed. It is fully capable but doesn't try to hide the underlying SQL as much as an ORM generally does.
Syntactic check only (plus a lot of logic that goes into evaluating if conditional no_std support will be triggered) as of now. There is a [issue regarding checking for std symbols](https://github.com/hobofan/cargo-nono/issues/2)
I didn't know that, thanks for the tip. I'll look into it and update the post 😉
If you know the structure of the data you're deserializing, it's probably the easiest to write a Rust struct to de-serialize into. You can annotate the fields that need to be BigDecimal with #\[serde(deserialize\_with=...)\], see [https://serde.rs/field-attrs.html#serdedeserializewith--path](https://serde.rs/field-attrs.html#serdedeserializewith--path) If you need a more flexible structure, you might have to write your own deserializer, it's not as hard as it first looks. Basically, it's a Trait with functions that get called when the data encounters an integer, a string, a map starts etc. You can the take it from there. Good Luck! :)
&gt; Which binary ? The one I linked the ldd output from. `strings` + `grep` for jemalloc worked as well.
Do you have that code somewhere? I'd be interested in checking it out to see if there's anything that could be done to improve the experience
Thanks for the info, I'll check it out!
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rustjerk] [Thank you for your amazing support](https://www.reddit.com/r/rustjerk/comments/9wnfec/thank_you_for_your_amazing_support/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I actually see "isn't async" as a positive- maybe I'm just being crotchety, but I've long been on a campaign against making everything asynchronous because the benefits are nebulous and drawbacks in code complexity are concrete. I've [given talks on this topic](https://docs.google.com/presentation/d/e/2PACX-1vTKxMqZcqN6h5Kng7EwnHIATm1GwTfFsWw1rgWk419sHpmAwBsluUHJlRVjWrWLrC_zHjU8eNropLzr/pub?start=false&amp;loop=false&amp;delayms=3000)
Goddamnit when was this announced? I'm in Moscow next week but could easily have booked it another week in December.
... why? What's wrong?
I liked the look of it, too, but requiring nightly is an absolute no for me at the moment. Maybe one day.
The Content-Disposition Header may have a field called filename. I don't really know much about Rocket but I think it lets you access the HTTP Headers and with that you will be able to grab filename.
&gt; There are a host of fantastic cryptography crates in Rust, each with its own focus and design tradeoffs. Mundane has its focus - to be misuse-resistant at all costs - and it makes design tradeoffs with that focus in mind. If that’s not what you’re looking for, then one of the other cryptography crates might be a better fit for your use case. You make it sound like other cryptography crates aren't trying to be misuse-resistant. In fact, `ring` goes even further in this regard. For example its signature verification function returns `Result` instead of bool, so you will get a warning if you forget to check the return value (yes, I've seen production code that called verify on digital signature but didn't check the result). Also it's [error type](https://briansmith.org/rustdoc/ring/error/struct.Unspecified.html) contains absolutely no information because "providing more details about a failure might provide a dangerous side channel".
What happens when you `mem::forget` a `RefMut` (from a `RefCell`)? It will prevent all other access to the `RefCell`, which could cause a thread to permanently block or else panic. To me, if a user calls `mem::forget` then any resulting strange behaviour is on them. A panic is reasonable, but it shouldn't be able to trigger UB. For example, if you are dereferencing a computed pointer in unsafe code, you definitely cannot rely on range checks having occurred in `drop`. You need to perform the assertions at the time that those pointers are computed or else risk UB.
It could be annotated with `#[must_use]`, I think?
Thank you and u/staticassert for your replies. You forced me to give my intuitions a second thought and express them more clearly (I hope). I don't think we disagree on hard facts, only on weights and priorities. Panics are the most benign manifestation of programming errors (other possibilities include incorrect results, inefficiencies, and vulnerabilities). Other effects are bad not only because of their impact, they are also more likely to stay undetected and unfixed. `catch_unwind` isolates panics and does not help with other problems at all. I'm not saying that it's completely useless. It's of limited utility, and it's not free. I'm also not saying that it's definitely not worth it, but it's a question worth asking. Overall it's desirable for programming errors to result in panics as opposed to other outcomes. Let's say that by pushing defensive programming to its practical limits we get 75% chance that a programming error manifests in a panic (arbitrary number with no justification, but we can at least agree that it's not 99.5% or anything like that). Amunsingly, testing and QA drag this number down (precisely because panics are easier to detect), but it's not a bad thing because they reduce overall defect frequency. When you and u/staticassert say that dropping unrelated connections is unacceptable, you are basically saying that it's unacceptable that mildly inconvenient thing happens with probability `0.75 * X`, while quietly tolerating an `0.25 * X` chance that terrible things will happen (because you can only avoid these terrible things by pushing for defensive programming or by reducing `X`, and hopefully we already did the former). This sounds disingenuous in general, though of course it could be true in your particular circumstances for very specific values of "X", "mildly inconvenient", and "25". &gt; If you don't need to launch a process per request, how are you going to isolate them from each other's faults when you're suggesting every panic should abort the entire process? Process pool, one process per concurrent request, reuse for subsequent requests, restart as needed. &gt; Do you have much real world experience with high volume production systems? For what it's worth, I have some limited experience with robust large scale high complexity systems, though not at the very low level. Random takeaways: things could appear robust from the outside while being total garbage fire internally; large scale causes complexity by making it economically justified; when one thing in a datacenter talks to another thing in a datacenter it should never assume that there won't be a connection error or some other error. The overall design philosophy in that particular project was that at certain scale and complexity levels failures of various nature, including abrupt failures, are inevitable and perhaps not even uncommon, so deal with them. This influences my perspective for sure. But... maybe evaluate my arguments and not my credentials? 
seems for practical machine learning 'practitioners', it's all about C++ (really CUDA etc GPU code..) libraries, with high level (python etc) interfaces to organise data. I dont think Rust would be good at the latter at all.
If you call `mem::replace` then the old value will be dropped, so you'd still get your validation. The more worrying case is when `drop` is bypassed entirely. See [these comments below](https://www.reddit.com/r/rust/comments/9wcujb/mutguard_run_code_every_time_data_is_mutably/e9k8w65)
&gt; Are there many instances of unsafe code using panic catching? It's irrelevant. When writing _any_ `unsafe` block you have to keep in mind the possibility that a panic will occur inside it and will be caught outside.
I see it has having more merit as a practical argument against the effort to create a framework like this... His point about value in innovation coming from solving problems makes sense... Rocket doesn't seem to do this since there are a number of existing mature, high-quality frameworks. The guys behind rocket have already done the initial steps, and are committed to continue supporting it; good for them. They've taken a risk with their own time. Learning to use the framework they built isn't a big investment... if I want to pick it over existing tech, no big deal for me. In other words, I think the guy in that video is placing the burden of doing something not-very-innovative in the wrong place.
Using unstable is not an option for me and a poor choice in general in my opinion - you may not be able to compile it few month from now (or even tomorrow), and if the project will stop to be supported, you'd be left in the dark. Actix works just fine for me.
I can't comment on the job prospects but.. "rust will make you a better C++ programmer" Coming from C++ I also found Rust was a bridge which made Haskell more comprehensible. .. so perhaps it is still of indirect value r.e. employable skills even if there aren't many *rust jobs* out there. 
I agree that it's mostly about calling destructors on unwind, though it's not exclusively that. For instance, if you leave a vector element in an uninitialized state, it would be bad even if the lifetime of the vector is larger than the scope of `catch_unwind`, because almost any operation on this vector is now dangerous. &gt; And without destructors that run on unwind, you can kind of forget the whole RAII thing. Strongly disagree. First of all, even with unwinding, you don't have a guarantee that for every constructor call there will be a matching destructor call. Infinite loops still happen, sometimes intentionally even. And sometimes processes get killed by the OS. And by the hardware. Second, the real value of RAII is in non-pathological code paths. It's very convenient that the file is closed and the lock is released when you `break` from any point in the loop body. But how does it matter if the file is closed right before the process terminates abnormally. Can you give an example of an application where running destructors is important even for abnormal termination with unknown cause?
with \`mem::forget\`, the guard will not be called. I consider it a bit like \`unwrap()\`, ie a thing that can result in a lot of issues, but that I can grep for easily. If there's a panic when there's an active guard, the first panic will take over. It would mean we're already in a weird state. But if you have suggestions to make mutguard safer, I'm interested :)
Because I know that someday I'll forget to add the invariant check. Or make public the members of a struct and forget about it. With this I can force the invariant check in every case.
that would be cool :D
An alternative design would just set a `bool` when the data is mutably accessed. At the point of depending on the invariant, you can call a method which only performs the assertions if the flag has been set. This has the upside of guaranteeing that you perform validation at most once. The downside is that a panic backtrace will be less local to the source of the problem.
It's funny how peoples' perspectives differ. I love ORMs because they can save a lot of time / fiddling with SQL strings, but the first thing I like for is that it's relatively close to SQL! (I'm a big fan of laravel's Eloquent).
Fuchsia? So this is from Google?
Yeah, that's what I'm figuring out. Still, that's what triggered my interest.
Have you considered working in design, as in the design that focuses on user experience (UX) rather than graphic design? You can help organizations create more engaging, useful services by applying what you learned (but mostly what you will learn) about human behavior, motivation, etc. You'll do lots of data science related work, where Python would serve you well in this role. 
The situation with early Rust is similar to what Pony is experiencing now: a neat language with an interesting type system optimized for concurrent systems but not enough libraries nor a vocal community to increase its adoption.
Great article! Keep going!
&gt; An important benefit of using Actix-web is the ability to build your application with actors. Why not delve into this a bit more? 
If you create a \`Box\`, call \`Box::into\_raw\`, use the pointer, use \`Box::from\_raw\`, and let it drop, then it all works. Those last two steps are what the implementation of \`free\_my\_thing\` would be.
What about Rocket made you fall in love with it?
Thank you. It’s a real shame that the ada is being used in that way. I remember managing a web site for an academic institution in college and the ada really limited the content we could publish since we had to compatibility test with screen readers as well as multiple browsers. 
That's exactly what happened to me. I moved from JS to Rust and fucking love it.
I assumed he was trying to derefence the function pointer to call it, which would be equally unsuccessful. There could even be layout differences between `extern fn()` and `*const extern in()` though that could cause a crash on calling `destroy` without it ever doing anything too, though. If I read correctly, the idea was to use `free` to free heap allocated stuff allocated by C and stored somewhere within `Datastructure`. It sounds like a sane thing to do, as long as `free` is passed in correctly?
`Result` is a #[must_use] type already, and honestly I think a cryptographic library should provide more feedback on whether or not something is verified than a yes/no answer.
It's been at the Rust site for free for years 
I have a String/&amp;str problem I just don't understand. I use gtk-rs and this is the problem: let headerbar_clone = headerbar.clone(); test_button.connect_clicked(move |_| { println!("Test"); headerbar_clone.set_title("Title was changed"); This of course works without a problem. But now I want to make it a bit more dynamic and pass a String into the set\_title() function so it looks like this: let message = String::from("new title"); headerbar_clone.set_title(&amp;message); This is not working, because set\_title expects a &amp;str and not a String. The compiler error thus is: | 188 | headerbar_clone.set_title(&amp;message); | ^^^^^^^^^ the trait `std::convert::From&lt;&amp;std::string::String&gt;` is not implemented for `std::option::Option&lt;&amp;str&gt;` | And of course I know that I could just change it to: let message = "new title"; headerbar_clone.set_title(message); and it would work. But I want to use this with some actual input I'm getting from the user or an API for example. So now my questions: 1. How do I convert a String to a &amp;str? I understand that the content of a String is heap allocated, so once the String goes out of scope the &amp;str is a problem. But there needs to be a way around it? 2. Why is the compiler talking about Options here? Neither the String "message" nor the parameter of set\_title is an Option. What am I overlooking here? Thanks for your help!
Rust does not have the mass market exposure yet, it does pose a particular problem if you need to interop with other teams who know other more popular legacy languages. IMO Rust is still too new to be a door opener for employment but once you are employed then Rust can shine because you can use it on the job for products that you own end to end at that point it is not a matter or what language you use but how productive and how polished the product is.
Thanks for the suggestion, but that's not really where my interests lie. My focus in college was less on social behavior and more on neurobiology and philosophy of mind.
So why not ring? It appears better than mundane at every single trade off mentioned. If something is missing, why can’t ring he improved?
&gt; Rust has a much more involved community around it--we've even got an operating system in Rust. ahem... There is an operating system *being developed* in Rust. It ain't exactly a daily-driver.
I think what are missing some of the advices is asking is in what category/market you want to work, maybe backed, game development, desktop apps, mobile apps, etc. Because every category/market has their preferred languages. But as you mentioned Go I think is backed most probably, in that market you may find Go, Ruby, Python and Java more valuable to learn and eventually master them.
1. It must be some problem with the set_title() function then. Because otherwise how do you explain the error? 2. I would say so. Otherwise how would my initial example work? I'm just passing it a `&amp;str` as the parameter and not `Some("somestring")`.
There is local Rust community meetup in St Petersburg every two weeks. You can attend if interested. [https://www.meetup.com/spbrust/events/](https://www.meetup.com/spbrust/events/)
Oh my god how could I forget about `as_str()` ??? Thanks so much! And yes it works just fine now! However I need to ask a folloup question, because I really need to understand this: 1. So as_str() copies the heap part of the String? Or how exactly does it solve the problem of the String going out of scope? 2. What is this `Into`? Why would I want to return a String into an Option? Isn't the point of an Option that the function decides what to return. If something is returned it's wrapped insode of `Some()`, otherwise it's none. So if I already have something (like the String here) why "convert" it to an option? Can `Into` auto-detect if a String is empty/None/nil and then "fix" this by putting it in an Option? Or what is the exact point here? Is there a ELI5 way to explain this? Thanks so much in advance!
Yes. Fuchsia has a sizeable Rust component.
This is great! Thank you. I've done most of the assignments from the other stanford class that uses rust as well (cs140e) and it was lots of fun
1. `as_str` doesn't solve the problem with the `String` going out of scope, it gives you a reference to the string slice that cannot outlive the owning `String`. `set_title` probably clones the string internally. 2. `set_title` accepts either a `Some(&amp;str)` as the title, or a `None` for no title (as opposed to the empty string). However, the API authors don't want to require the caller to wrap every title with a `Some()`, so they used `Into` which "converts" a `T` into a `Some(T)`. A quick Google search brought up [this article](http://www.suspectsemantics.com/blog/2016/11/29/the-into-trick/), calling it "The Into Trick".
You can still use actors underneath the hood even with Rocket! :) It might not be as streamlined as with Actix, but there's no fundamental reason that actors couldn't be used when requests are being processed. I agree, though, that actors are architecturally a nice way to build async codebases.
Rust relied on the old jemalloc version which was suboptimal for recent systems and bloated output binaries. Not to mention issues with debugging. It's a nice change for most users and others can switch to newer version of jemalloc with \`jemallocator\` crate as shown in the docs: [https://doc.rust-lang.org/std/alloc/index.html](https://doc.rust-lang.org/std/alloc/index.html)
Thanks so much for your answer. I will read the blog post this evening. I think I understand what's going on. But we'll see tonight :-) Thanks!
I'm not so sure about that. Exposing this data (e.g. why it wasn't verified - maybe because the padding is wrong?) to the user can sometimes open up additional vulnerabilities like the Bleichenbacher attack. While additional (error) information is generally good, it might not be in this case.
Thanks for your help. Very much appreciated. I'll have to look at it in-depth this evening so I fully understand everything 100%!
If you're making a web service, I would strongly recommend using the tower web implementation from rust-aws-lambda and then choosing whether to run it in lambda mode or regular web server mode at startup. Easier to implement and far faster development times. 
I didn't know that, thanks for the suggestion!
Indeed. Attempts to surface more information, e.g. invalid padding versus invalid MAC in MAC-then-encrypt constructions are exactly how vulnerabilities like padding oracles arise. IMO unless you're dealing with a cryptographic hardware device /HSM and need to surface error information about some sort of I/O error talking to that, verification errors should be otherwise completely opaque.
This isn't fixed by NLL, this is due to the order the borrows are taken by desugaring (the mutable borrow for the slice first, then the immutable borrow for the length call). See the post in this sibling's comment for more info. 
You're right, sorry. My test was completely wrong.
I would not use hyper directly. Actix or Rocket should probably be what you use unless you intend to go lower level. Also, it is my personal opinion, but I think C macros are actually easier (there isn't nearly as much to learn), but not as good or useful. That may depend on your definition of easy though.
\#beginner-question but my google-fu is not sufficient to find an answer. The following works: (e.g. at this point, compiles anyway ;) ) impl ::fmt::Display for Board { fn fmt(&amp;self, f: &amp;mut ::fmt::Formatter) -&gt; ::fmt::Result { //let mut r = std::option::Option&lt;Ok&gt;; for p in self.peg.iter() { write!(f, "{:3}", p); } //r write!(f, "") } } I don't like adding the final do-nothing I/O operation just to provide a return address. `for {}` returns `()`. I think I should capture the return value of the `write!()` within the loop and return that. I need to declare it before the loop and assign a value so the return value is guaranteed to be initialized but cannot figure out the form of the assignment. The following does not work: impl ::fmt::Display for Board { fn fmt(&amp;self, f: &amp;mut ::fmt::Formatter) -&gt; ::fmt::Result { let mut r = std::option::Option&lt;Ok&gt;; for p in self.peg.iter() { r = write!(f, "{:3}", p); } r //write!(f, "") } Compiler flags it: error: chained comparison operators require parentheses --&gt; src/stack.rs:92:44 | 92 | let mut r = std::option::Option&lt;Ok&gt;; | ^^^^^ | = help: use `::&lt;...&gt;` instead of `&lt;...&gt;` if you meant to specify type arguments = help: or use `(...)` if you meant to specify fn arguments error: expected expression, found `;` --&gt; src/stack.rs:92:48 | 92 | let mut r = std::option::Option&lt;Ok&gt;; | ^ expected expression Clearly I'm way off on how to declare a Result and give it a default value if the compiler can't even figure out what I'm trying to accomplish. maybe I've got that detail wrong or maybe there's a better pattern to do this. If you want the entire code (w/out this Display trait) see [https://gitlab.com/HankB/Tower-of-Hanoi-from-scratch/tree/master/rust](https://gitlab.com/HankB/Tower-of-Hanoi-from-scratch/tree/master/rust) (Note to self - fix the README!) &amp;#x200B; Thanks!
Having the capability to be async if desired should be useful though because you can take a targeted approach after benchmarking and otherwise not use async.
The nomicon is mostly for unsafe code. Ideally, you don't want to write any unsafe code if at all possible. Of course, in some situations it's unavoidable but for most use cases you don't need to write a single line of unsafe code. Instead, you can often find existing crates that encapsulate the unsafe things you want to do in a nice, safe interface. So I wouldn't consider the nomicon to be the next thing to read after reading the Rust book. Only if you actually want to or need to write unsafe code. Instead, like James said, just find a project to work on and choose your material to read based on that.
why do people use lambda or serverless architectures? I'm asking because I don't understand the appeal, but I'm sure there is one.
As a fairly inexperienced Rust user / programmer generally, I'm a little confused by one of the examples. use std::thread; struct Bank { cash: i32 } fn deposit(the_bank: &amp;mut Bank, n: i32) { the_bank.cash += n; } fn withdraw(the_bank: &amp;mut Bank, n: i32) { the_bank.cash -= n; } fn customer(the_bank: &amp;mut Bank) { deposit(the_bank, 2); } fn main() { let mut the_bank = Bank { cash: 0 }; thread::spawn(|| { customer(&amp;mut the_bank) }).join().unwrap(); println!("Total: {}", the_bank.cash); } --- error[E0373]: closure may outlive the current function, but it borrows `the_bank`, which is owned by the current function --&gt; bank4.rs:26:19 | 26 | thread::spawn(|| { | ^^ may outlive borrowed value `the_bank` 27 | customer(&amp;mut the_bank) | -------- `the_bank` is borrowed here help: to force the closure to take ownership of `the_bank` (and any other referenced variables), use the `move` keyword | 26 | thread::spawn(move || { | ^^^^^^^ &gt;Let’s take a moment to carefully walk through the rationale for this error. Let’s think about the lifetime of the function passed to thread::spawn. A thread may outlive the function that spawned it, so it would be illegal to hold a pointer to anything inside the main function, as the value it points to could be deallocated before the thread exits. This logical issue materializes as the error: “closure may outlive the current function”, referring to the thing passed to thread::spawn as the closure, and main as the function. If the threads get join()'d, how is it possible for them to outlast the main function? Am I misunderstanding something or is it just a case where the compiler isn't quite smart enough?
There are multiple advantages (and disadvantages) in using a serverless architecture. Usually, they are used in specific use cases. One example would be scaling according to demand: this allows an organization to pay for only what they use. It's useful when the service is used sporadically or has peaks of usage. The "traditional" way would mean having to buy enough servers to support the usage peaks, but when the service would be under normal load, some servers may not be used, which is considered wasteful. You can learn more [here](https://serverless.com/learn/use-cases/)
Can a drop implementation zero out memory?
Ok, this give the matching, but how represent unions and products?
The program authors need to know that something went wrong. Maybe the users of the program should not know. Looks like the needs of users and the needs of developers can't really be reconciled by simply applying the type system to the problem.
I was trying to outsmart Rust, but as it turns out, I am not smart enough! :-( I'm using gtk-rs and it works wonderfully. I made a test-app with a few buttons that do different things: Println, call other functions, etc. However I'm now at a point where I need to work with threads, because some functions take some time to finish and if I don't put those tasks in another thread, my gui will freeze up until the task is finished. Gtk objects aren't thread-safe. But I thought that I can just work around this by just passing a message back to the closure. First the code: let headerbar_clone = headerbar.clone(); button2.connect_clicked(move |_| { println!("Starting a new thread"); let (tx, rx) = mpsc::channel(); thread::spawn(|| { println!("This message is coming out of a thread"); let val = String::from("This is coming through the channel"); tx.send(val).unwrap(); thread::sleep(Duration::from_secs(2)); println!("2 Seconds are over!"); }); let received = rx.recv().unwrap(); println!("The message is: {}", received); headerbar_clone.set_title(received.as_str()); }); Explanation: If I press \`button2\` a new thread is started and a message is returned via a channel. That message (a String) is then used to change the title of the Gtk headerbar. I thought that this way I can work around the missing thread-safety and just assign the headerbar a new title within the scope of the closure. Which is exactly how it works when not using threads. Just to be clear, this is a working example of a button changing the headerbar: let headerbar_clone = headerbar.clone(); button2.connect_clicked(move |_| { println!("Doing stuff"); thread::sleep(Duration::from_secs(2)); println!("Finished"); }); This works without a problem, but freezes my GUI for 2 seconds. So when I run the threaded and channel-ed code I get this error: error[E0277]: `std::sync::mpsc::Sender&lt;std::string::String&gt;` cannot be shared between threads safely --&gt; src/gui.rs:46:9 | 46 | thread::spawn(|| { | ^^^^^^^^^^^^^ `std::sync::mpsc::Sender&lt;std::string::String&gt;` cannot be shared between threads safely | = help: the trait `std::marker::Sync` is not implemented for `std::sync::mpsc::Sender&lt;std::string::String&gt;` = note: required because of the requirements on the impl of `std::marker::Send`for `&amp;std::sync::mpsc::Sender&lt;std::string::String&gt;` = note: required because it appears within the type `[closure@src/gui.rs:46:23:52:10 tx:&amp;std::sync::mpsc::Sender&lt;std::string::String&gt;]` = note: required by `std::thread::spawn` error: aborting due to previous error However I do not at all understand this error. A channel (which sole purpose is to be used in threads) cannot be shared between threads? I suspect this has something to do with the closure in which the spawn is being executed/run? But even then I don't see how it is a problem? I can execute GTK functions (like set\_title() without a problem. What is the easiest and ELI5-iest solution to this problem? I would like to fix it myself, but I'm totally confused by this. How can something that was made to be used in threads not be thread-safe? What am I misunderstanding?
&gt; I don't think I have any good material for the hallway track right RustFest is all around coming up with that during the hallway track ;) &gt; So I guess I will tune in for the livestream instead. Just to be clear: livestream isn't confirmed, as this is incredibly venue sensitive. We will try to have one, though.
It can zero out the object's final location, but not previous locations if the object has been moved.
Hi, you're probably looking for r/playrust. This subreddit is for a programming language called "Rust"
No worries. It helped me figure out what i needed with the assistance of another /r/rust member. Plus, it's still a useful and interesting thing to be able to do so thanks =D
The thread does not have to be joined, so if we choose not to, it will continue living past the function that spawned it. Here, the compiler makes a conservative analysis: even though the thread definitely is joined in this example, the compiler opts for consistency, disallowing the reference regardless of whether you use join or not.
This is off topic even for /r/playrust, they want /r/playrustservers
Interesting: I wanted to see whether this changes with `feature(nll)` enabled, and saw that non-lexical lifetimes actually produce an additional error. Running https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=6b02a12b9669655ca2b50e931eb1a4a2 outputs: error[E0373]: closure may outlive the current function, but it borrows `the_bank`, which is owned by the current function --&gt; src/main.rs:24:19 | 24 | thread::spawn(|| { | ^^ may outlive borrowed value `the_bank` 25 | customer(&amp;mut the_bank) | -------- `the_bank` is borrowed here | note: function requires argument type to outlive `'static` --&gt; src/main.rs:24:5 | 24 | / thread::spawn(|| { 25 | | customer(&amp;mut the_bank) 26 | | }).join().unwrap(); | |______^ help: to force the closure to take ownership of `the_bank` (and any other referenced variables), use the `move` keyword | 24 | thread::spawn(move || { | ^^^^^^^ error[E0502]: cannot borrow `the_bank.cash` as immutable because it is also borrowed as mutable --&gt; src/main.rs:28:27 | 24 | thread::spawn(|| { | - -- mutable borrow occurs here | _____| | | 25 | | customer(&amp;mut the_bank) | | -------- first borrow occurs due to use of `the_bank` in closure 26 | | }).join().unwrap(); | |______- argument requires that `the_bank` is borrowed for `'static` 27 | 28 | println!("Total: {}", the_bank.cash); | ^^^^^^^^^^^^^ immutable borrow occurs here error: aborting due to 2 previous errors Some errors occurred: E0373, E0502. I thought `nll` might help, but it seems that `thread::spawn()` actually requires [`'static' lifetime guarantees](https://doc.rust-lang.org/std/thread/fn.spawn.html) for the given closure. Could this maybe be changed with `nll`? Or a destructors still the blocking problem here?
The sender side of a channel can't be *shared* between threads, but it can be *moved*. You just need to use a `move` closure: `thread::spawn(move || {`...
Tbh, it's hard to understand what you're asking for. I'll try to respond to what I can: &gt; is common to just have a enum of the possible values. This mean to box it and need dynamic dispatch. If you have an `enum`, why are you boxing/using dynamic dispatch? &gt; I think maybe a macro could do this, but in runtime? Macros operate at compile time only. They don't exist at runtime. &gt; compilation on the fly or the ability to do stagged interpretation, but that is not possible, right? It's probably *technically* possible but it would be extremely complicated to do correctly. What's the actual problem you're trying to solve? 
&gt; So now native systems languages are typically only used on projects where the tradeoff in development time makes sense because low-level access, maximum performance, or compatibility with legacy native code is needed to solve the problem. Note that when performance is required, you'd be trading off development time for performance by *using* a high-level language and desperately try to get it to perform to satisfaction ;) 
Why would truncating a sha-512 hash to 256 bits reduce security compared to using sha-256?
You never know what someone knows until you talk to them. We treat experience and education the same. We hire as many devs as we can find so long as they know what they're doing; there's no either/or.
&gt;If you have an enum, why are you boxing/using dynamic dispatch? Because i need to match for each value to select the proper operations (here, boxing is not Box&lt;_&gt;, is the fact I need to put everything into a Enum): pub fn math_add(x:&amp;Scalar, y:&amp;Scalar) -&gt; Scalar { match (x, y) { (Scalar::I32(a), Scalar::I32(b)) =&gt; bin_op::&lt;i32, _&gt;( Add::add, *a, *b), (Scalar::I64(a), Scalar::I64(b)) =&gt; bin_op::&lt;i64, _&gt;( Add::add, *a, *b), (a, b) =&gt; panic!("Argument {:?} &lt;&gt; {:?}", a, b ) } } &gt; What's the actual problem you're trying to solve? Is to reduce the friction between the host &amp; target (ie: The ffi). Because everything is inside a Enum I need to reimplement a lot of functionality instead of reuse directly rust functions. So If I need to call a rust function: fn sum(a:i32, b:i32) I need to wrap it into the Enum. This alone is not hard, but make complicate to grow the capabilities of the lang. But If I could just use the rust types directly, I can have a lot for free. Of course, this is the thing that will be easier with a compiler, but exploring how far is possible to push this into a interpreter (because the language is for data exploration I need dynamic capabilities)
Ohhhh yes. That is awesome!!! God I was sure the answer to this is gonna be some super complicated RefCel/Smartpointer/Mutex mess! But I'm very glad it isn't! I just tried it and it works beautifully. Just as I wanted it to. So just to make sure I understood this 100%: This is basically the same thing as with the other closure. I need to "move" it so that it is fully owned by the closure. Which in turn means that it no longer needs to share anything across thread, because it is owned by the thread instead. is that correct?
Rust's [`Send`](https://doc.rust-lang.org/stable/std/marker/trait.Send.html) and [`Sync`](https://doc.rust-lang.org/stable/std/marker/trait.Sync.html) traits (which are related to thread-safety checking) have no methods on them at all. In Go, an interface with no methods on it is implicitly implemented by everything.
Hmmm, ring's approach to error handling does seem really interesting. We intentionally don't provide any structured information - all you can do with errors is print them - but it's certainly true that programmers have tried to gain information from error strings before, so maybe we're not going far enough.
I mentioned in the blog post that we're interested in improvements to our build system. One such improvement would be the ability to rename symbols *in an object file* so that we can just compile as normal and then modify the symbol names after the fact. Right now, we have a very ugly and complicated two-phase build process that I would very much like to get rid of.
It doesn't; it reduces its security compared to what you would get if you didn't truncate the SHA-512 output. The concern is that somebody would say, "we need SHA-512's security guarantees, so we'll use ECDSA-SHA512-P256," which would silently give them a weaker security guarantee than they were expecting.
Without an error message this is a little bit tricky to debug, but I think the issue has to do with this line: `else if let Some(Token::Id(parent_id)) = symbol_table.get("$$PARENT$$") {` parent id is a reference to the value inside the `symbol_table` argument and so this isn't safe. IDK if you're using NLL, but either way the following approach should work: - Make a single-level-lookup function that takes `(table: &amp;'a mut ScopeTable, id: Uuid, symbol: &amp;'b str)` and returns one of `Found(Uuid)`, `CheckParent(Uuid)` or `NotFound`. - Implement your recursion (or looping) in terms of that. It's not the only solution, but it's the easiest way to make sure you don't accidentally have lifetimes from the one-level lookup extend beyond the call.
So your point is that even ECDSA-SHA256-P256 should be disallowed because SHA256 gives 256 bits of security, while ECDSA-P256 only gives 128, and so reduces the effective entropy of the SHA256 output even though it's not truncated? That's an interesting point; I will consult my crypto gurus about it :)
I've got this setup in my project now, where the runner will drop all the schemas at the top of a test run, however cargo's output when I invoke `test` says that 0 tests were run. I can see that the runner is running tests, but do you know why it isn't telling me the result of the tests?
Have a look at https://github.com/MaikKlein/pyro, `SoaStorage` is what you are looking for.
No, I wouldn’t disallow ecdsa-sha256-p256, since sha256 is a much better hash function than any of the well known that have shorter digests. But I probably wouldn’t disallow ecdsa-sha512-p256 either, since it’s still as secure as with sha256. Here is a case where documentation is king, any algorithm that uses p256 will have ~128 bits of security. Take a look at something like curve25519xsalsa20poly1305 where the elliptic curve has approximately 128 bits of security, but the authenticator have higher security margins. That doesn’t mean that it’s a weak construction.
Well, not very concise but here's the github issue https://github.com/rust-lang/rust/issues/50547
Your "other alternative" is exactly what I tried, and it didn't work, mentioned as point #1 under "Now here's what I've tried". As for the error you requested: `Cannot borrow *table as mutable more than once at a time` This is the same error I get regardless of it being your alternative or my original. It says the table is borrowed the first time on the `let symbol_table = table.get_mut(&amp;id)` line, and that the borrow ends at the end of the function (regardless of version)
Amazing work. Thank you very much.
Ok, I have a semi-tested solution (Made some assumptions about how your types are defined, but it should be fine)? https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=7a1eb5596b9cc14d095f836d1c06882a I think the issue is the borrow checker can't tell that the outer scope only executes if the data is no longer borrowed (seems to happen regardless of NLL).
In practice, you want to be able to move secret things. For example, when implementing a state machine for TLS, you want to be able to move an encryption state from one state to another state.
The old color was a lighter red, with a bit of an orange tint to it. I thought it more closely matched the color used throughout the Rust community. Now it's a dark red color, almost identical to Ruby's coloring on GitHub! Clearly, this is an emergency situation! We need to unite the Rustaceans! kidding... but it is interesting.
Gotta say, you pretty much nailed my data structures exactly! I think mine failed was because I didn't let the single-level lookup deal with the issue of handling the `symbol_table` resolution; I did this: fn lookup(symbol_table: &amp;SymbolTable, id: Uuid, symbol: &amp;str) -&gt; Lookup { if symbol_table.get(symbol).is_some() { Lookup::Found(id) } else if let Some(Token::Id(parent_id)) = symbol_table.get("$$PARENT$$") { Lookup::CheckParent(*parent_id) } else { Lookup::NotFound } } fn find_symbol&lt;'a, 'b&gt;(table: &amp;'a mut ScopeTable, id: Uuid, symbol: &amp;'b str) -&gt; Result&lt;&amp;'a mut SymbolTable&gt; { let symbol_table = table.get_mut(&amp;id).expect(&amp;format!("Scope ID {} not present in scope table. This should not happen.", id)); match lookup(symbol_table, id, symbol) { Lookup::Found(_) =&gt; Ok(symbol_table), Lookup::CheckParent(id) =&gt; find_symbol(table, id, symbol), Lookup::NotFound =&gt; Err(Error::UnknownIdentifier), } } But thank you so much! It finally compiled! I can finally get back to implementing the interpreter.
It's like dried blood. I like it.
Ring is obviously a fantastic crate with a ton of users. We just have different tradeoffs than they do. For example, they're trying to move more towards pure-Rust implementations, while we're opting to be more conservative and stick with BoringSSL's existing implementations.
Or Rust...
The last week three dependencies for async/await! have been proposed for stabilization: - [Pin APIs](https://github.com/rust-lang/rust/issues/55766) - [Stablize using some arbitrary self types defined in std](https://github.com/rust-lang/rust/issues/55786) - [`std::task` and `std::future::Future`](https://github.com/rust-lang/rfcs/pull/2592) If those all get stabilized you will be able to write the what your async function would desugar to yourself, on stable that is. (That's my understanding at least.) [async functions are available on nightly](https://github.com/alexcrichton/futures-await/issues/111#issuecomment-432653673), but I don't expect them to be stabilized until the above three are available on stable.
Too close to Ruby, and too close to D. I liked the old colour :(
Right. It was an example of what I said two sentences prior, about Rust having a broader application than Go. Writing an OS in Rust sounds fun; writing it in Go sounds masochistic.
Color of rusting iron? 
The lame change, everyone already used to old colour
That could still be done by implementing a moveTo(target: impl Pin&lt;&amp;mut SecretThing&gt;) method on the type, right? Pins don't deny you access to the bits, so as long as your secret doesn't contain self-references it could still do a copy of the contents to the new (also pinned) location, but it would then remember to zero the original afterwards.
It looks like you could do #[post("/", format = "image/tiff", data = "&lt;paste&gt;")] fn upload_tiff(paste: Data) -&gt; io::Result&lt;String&gt; { ... } #[post("/", format = "image/jpeg", data = "&lt;paste&gt;")] fn upload_jpeg(paste: Data) -&gt; io::Result&lt;String&gt; { ... } Alternatively, you can always examine the file for known magic-numbers, and apply the correct extension yourself. This will be a bit more involved, but won't rely on the file type and mediatype to actually match 
The build dependencies [because of BoringSSL] include perl, c++ and *golang* o_0 (goodbye platforms golang is not ported to yet) I like the [ring](https://github.com/briansmith/ring) approach of only taking C/asm code from BoringSSL but not depending on *building* BoringSSL much more :P And it should be possible to build full (ish?) BoringSSL without its build system I think? Mono does that
What are your views on how Libsodium is shaping up for Rust?
I miss the old color. This one looks way too similar to Java/Ruby imo.
Yeah I though the old peach / orange colour was great. Current one totally looks like Ruby.
A few of you might be a bit color-blind, not so close to Ruby :D I like it anyway! loving the language so far
A quick question. I have a function that reads and returns a Settings struct. If there's a config file it reads the content, serdes it and then returns an Option&lt;Settings&gt;. I want to declare a variable depending on if there is a Some or a None returned. But how do I get this variable into the main scope? Here's an example code. This is obviously not working, but I want you to understand what i want to have. match read_user_settings() { // returns a Some(and the content). I tested this by println-ing it. Some(us) =&gt; { let user_settings = us; // This variable goes out of scope, but I want it back in the main scope. } None =&gt; (), }; println!("{:?}", user_settings); I can't do it like this: let user_settings = match settings::read_user_settings() { Some(us) =&gt; us, None =&gt; (), }; Because if None is returned the variable is not of type Setting. What is the most Rustacean way of solving this? Sorry if this is a noob question
This is a good band-aid fix that can at least have my API up and running by the end of the day, but the finished product must have only one post request and be able to dynamically determine the file extension before saving the streamed file to disk. I've been reading about MIME types per **turboladen**'s recommendation and suspect that's the right direction to move in, but I don't even know where to begin with viewing `Content-Type` headers from a Data Struct.
Currently, custom tests might need their own output. [Standardizing the output](https://github.com/rust-lang/rfcs/blob/master/text/2318-custom-test-frameworks.md#standardizing-the-output-1) with a crate is an open question on the rfc. Optionally hooking into the stanard test formatting easily would be great. One option is to base your output off [libtest's pretty printer](https://github.com/rust-lang/rust/blob/master/src/libtest/formatters/pretty.rs) and/or tweak it to represent the schema results with more detail.
Also very close to Scala.
What do you mean by "declare a variable depending on if there is a Some"? You cannot have the variable either declared or undeclared - Rust is statically typed language, so the compiler just won't allow that. Maybe you wanted the function to return if settings is `None`? You can do that: let user_settings = match settings::read_user_settings() { Some(us) =&gt; us, None =&gt; return, }; 
Ahhh ok. I tried every thing: (), None, etc... But a simple return is all I needed. So the "let" statement basically knows to just cancel the declaration of the variable "user_settings" when match returns "return"?! Understood. Thanks for your help!
I hope GitLab keeps the more orange color since it's a similar tone to C, since the newer one is closer to that of more dynamic languages that have more vibrant colors.
This week I'm continuing work on my [integration for the SpatialOS SDK](https://github.com/jamiebrynes7/spatialos-sdk-rs). Lots of fun C FFI problems to solve and looking forward to doing some code generation and serialization macro magic in the near future!
What is correct type for a slice? Right now I'm completely confused, because: 1) I can use slice as left part of sentence without &amp;, e.g. ``` let mut a: [u8; 5] = [0; 5]; a[1..2].copy_from_slice(some_other_slice) ``` 2) When I'm trying to detect it's type via ``` let z: () = a[1..2] ``` rust says `^^^^^^^^^^^ expected (), found slice` 3) But if I'm trying to use [u8] as type, it also shows an error `doesn't have a size known at compile-time` 4) I cannot use [u8; 5], because it's a signature of array `a`, not it's slice. My main question is that if slice is a &amp;[T], then why I can use syntax from 1) (`a[1..2].copy...`) instead of `&amp;a[1..2].copy...`? 
So, after using this for a week now, I'm pretty much sold. Buying it now haha. I'm so impressed. I wish I had the chops and focus to create such a unique product.
Recruiters occasionally send me job openings for rust. Most of the time they are blockchain related. Some of them are remote.
I don't know enough about it to have an opinion.
Is there a way to avoid box? I've been looking at the `zip` code: https://doc.rust-lang.org/src/core/iter/mod.rs.html#1073 ..it seems like they just accept two iterators there, no?
If I'm not looking to have any kind of custom output for now, is there a way to hook into the regular test result output, where I can just see pass / fail numbers? After looking at it, I'm not really sure how I can use that pretty printer. Would I have the test runner call this pretty printer with the results of each test, essentially? If you have an example of a custom output using a test runner that would be really helpful!
Actually that doesn't work either. I just tried it in a simple example and it stops my entire programm. This is my example code: #![allow(dead_code, unused_variables, unused_imports)] #[derive(Debug)] struct Settings { name: String, } fn main() { let user_settings = match give() { Some(us) =&gt; us, None =&gt; return, // The "return" seems to end my entire program }; println!("{:?}", user_settings); println!("This is the last line"); // This isn't printed if "return" is returned. } fn give() -&gt; Option&lt;Settings&gt; { let one = Settings { name: String::from("setting1"), }; if 4 &lt; 3 { Some(one) } else { None } } Is there another way to do this that doesn't stop my entire program?
You need to use generics, not trait objects: struct MathZipper&lt;A: Iterator, B: Iterator&lt;Item=A::Item&gt;&gt; { first: A, second: B }
I'd consider looking into itertools's zip_longest, which should also meet your needs.
Another new feature of Rust 2018, yess! JK.
Seeing what C++ has I feel like I have no right to complain.
The method syntax decides whether it should take ownership of `self`, a shared reference to `self`, an exclusive reference to it or how many times it needs to dereference `self` to call the specified function. That's quite a lot. `a[1..2].copy_from_slice(src)` desugars to `&lt;[u8]&gt;::copy_from_slice(&amp;mut a[1..2], src);` that means it automatically takes `a[1..2]` by exclusive reference because of the signature of `copy_from_slice` whose first argument is `&amp;mut self`.
I believe the 3rd one isn't actually a dependency of async/await.
You shouldn't be passing a function pointer to free. Either call the free function from the C stdlib: https://docs.rs/libc/0.2.43/libc/fn.free.html (Recommended way to do so) Or write your own C function to free the memory, and link it in Rust this way: https://doc.rust-lang.org/1.9.0/book/ffi.html 
`a[1..2]` is secretly `*Index::index(&amp;a, 1..2)`. `index` returns an `&amp;[u8]`. Deref'ing a `&amp;[u8]` gives `[u8]`, so `a[1..2]` is of type `[u8]`. However, this is kind-of a lie. Internally, the compiler knows that this `[u8]` is *actually* behind a pointer (since it just deref'ed it), so when you call `copy_from_slice` (which takes a borrow of the subject), it knows it can just "undo" the deref to get a pointer again. As such, it's as though the deref never happened in the first place. This is important because `[T]` is a dynamically sized type, and dynamically sized types cannot be stored in variables or moved around; they can *only* be used behind pointers. The example works because from the compiler's point of view, it never has to actually move the result of `a[1..2]` anywhere. In any case, there is no single type for slices. A slice can be `&amp;[u8]`, `Box&lt;[u8]&gt;`, `Rc&lt;[u8]&gt;`, *etc.* The type you *want* for `a` is probably `&amp;[u8]`. Also, `z` would need to be: `let z: &amp;[u8] = &amp;a[1..2];`. Here you *do* need to re-borrow `a[1..2]` because you're trying to store it. Again, all this is *really* doing is undoing the implicit deref that using indexing inserts. As for why it does all this: so that using `a[i]` gives you a `u8` rather than a `&amp;u8` that you then need to explicitly deref yourself, combined with slicing being regular indexing but in disguise. Aside: if you *did* have to explicitly borrow `a[1..2]`, it would be `(&amp;a[1..2]).copy...`.
How do I use the new macro importing style? I have a module called `bitwise_derive` that contains a macro called `derive_or`. The macro is annotated with #[macro_export]. I try to import the macro with `use bitwise_derive::derive_or` but attempting to compiles results in &gt;no `derive_or` in `bitwise_derive` Right above this line I have `use lazy_static::lazy_static`, which is a macro import from an extern crate and that works with no issue. I've copied and pasted the name to make sure that I haven't mistyped it.
The best argument for using SHA-512 over SHA-256 is that it's generally faster on 64-bit CPUs. (There is of course also SHA-512/256—uses SHA-512 internals but truncates output to 256 bits—but nobody really uses it.)
Well, you need to ask yourself what should happen in the rest of the body of `main` if `give()` returns `None` (a failure): * Want to provide a default value? `unwrap_or` * It will never be `None`? `unwrap` * Assuming we move the code from `main` into a new function `f`. Return early because it's clearly an errornous state? Try operator `?`. If `f` shouldn't return an option but a result `Result&lt;(), MyError&gt;`, use `ok_or(MyError::Variant)?`
https://github.com/github/linguist/pull/4319
A better link to this change is [this](https://github.com/github/linguist/pull/4319); Github uses linguist for associating a language and color.
Implementing a big change in the collector API of tantivy (a search engine) and adding multithreaded search for 0.8
Thank you! It looks over-complicated for Rust's pretty clear and wisely chosen syntax... How can one find these secrets behind looks-simple-but-really-not types?
I tried to find a PR for this on linguist, but somehow didn't! thanks!
It might be a bit outside the scope of the question but similar to the standard library it's more ideomatic to have a generic struct like: ``` struct MathZipper&lt;A, B&gt; { first: A, second: B, } ``` And the rather have bounds on those generics in the implementation block like: ``` impl&lt;A, B&gt; Iterator for MathZipper&lt;A, B&gt; where A: Iterator, B: Iterator, { /*... */ } ``` There are some advantages to this: - Less verbose for complex type bounds - Easy to add new impls without breaking backwards compatibility - Individual bounds for different impls as not all impls will require the same bounds, which makes it more generic and easy to use in many different situations 
you both [posted at almost the same time...](https://www.reddit.com/r/rust/comments/9wsas2/github_changed_the_language_color_for_rust/e9n8wxz/?context=3) alt accounts out in force?
My Rust/Clojure repo looks downright angry
&gt; It looks over-complicated for Rust's pretty clear and wisely chosen syntax... Every step in the chain is there for good reason. - Indexing returns a value because it returns a value in pretty much every other language, and it's what people expect. - People also expect to be able to extract a pointer from an indexed container. So it must return a pointer. - So the *implementation* must return a pointer that is automatically dereferenced for convenience. - The thing about slicing is just a consequence of trying to unify concepts. Slicing isn't a distinct operation from indexing, it's just indexing where the index itself represents a range of positions to access, rather than just one. &gt; How can one find these secrets behind looks-simple-but-really-not types? It's not that they're not types. It's that there's additional information about the expressions that's not contained in the type. I don't know that there's anything about this specifically; it's just a consequence of how pointers work.
&gt; God I was sure the answer to this is gonna be some super complicated RefCel/Smartpointer/Mutex mess! But I'm very glad it isn't! Thanks so much, you're the man! Or woman. Whatever it is :-) Please, I prefer "dog". Humans are smelly. &gt; So just to make sure I understood this 100%: This is basically the same thing as with the other closure. I need to "move" it so that it is fully owned by the closure. Which in turn means that it no longer needs to share anything across thread, because it is owned by the thread instead. is that correct? Yep. Closures that might be stored, or sent to another thread (where pretty much anything could happen as far as the compiler knows) usually need to be `move` so they be separated from where they were created.
You are assuming the user allocated the memory through the system allocator. The entire problem is that the user can obtain that `*const c_void` in many ways, from the system allocator, to static data, to jemalloc or w/e. I want to free that data when I free the memory. How can I do that? The C community said passing a pointer to free was the appropriate solution. Do you have a better way? &gt;Or write your own C function to free the memory What if the user user a arena allocator? Or static data?
`impl Future&lt;...&gt;` is stable since 1.26. Or is it another feature?
&gt; Aside: if you *did* have to explicitly borrow `a[1..2]`, it would be `(&amp;a[1..2]).copy...`. I think we talk about `&lt;[T]&gt;::copy_from_slice` which takes `&amp;mut self`, so the explicit form is (&amp;mut a[1..2]).copy…`. Your version does not compile. /u/SuperbYesterday 
I sent a message to https://github.com/contact asking them to change it back
OK - noted and understood. Thanks so much!!
There's a PR to revert it: https://github.com/github/linguist/pull/4326
I'm taking another look at Rust. It has been a few years since I tried it last. Back then, not much made sense to me. I am now (re)reading the online books/docs and everything is going well so far. I think it's because I'm approaching it with a different mindset, the community has matured a lot, and I'm a bit more experienced.
7PM PST happens when this comment is 3 hours and 44 minutes old. You can find the live countdown here: https://countle.com/BwUZLGL_X --- I'm a bot, if you want to send feedback, please comment below or send a PM.
There is `std::any::Any::get_type_id: fn(&amp;self) -&gt; std::any::TypeId` which does the same as your helper function. You should be able to just write `my_fn.get_type_id()` and be done with it :D
This is the livestream link for https://www.meetup.com/Rust-Bay-Area/events/255058428/, with talks: * _Bringing FlatBuffers Zero-Copy Serialization to Rust_ by Robert Winslow * _Fearless Low-Latency Music Synthesis_, by /u/raphlinus (sadly it needs you to log in with github to proceed, but it should be publicly accessible)
I suspect the header change was to unify GitHub enterprise with regular GitHub. See discussion here for issues having two code ASR’s/headers caused: https://www.heavybit.com/library/podcasts/enterpriseready/ep-2-the-early-days-of-github-with-tom-preston-werner/
That's one of my favorites. ❤
I'm guessing that this doesn't include async methods, as that requires traits returning `impl Trait`, which itself requires Chalk landing? (Unless async methods allocate on return, I don't recall...)
https://crates.io/crates/byteorder
Wow, ok. I'd looked in that crate before, played around with it, then decided to just use the built-in `to_be()` method to transform my data into big-endian. But your comment prompted me to take another closer look at it, and it does indeed provide exactly what I need. &amp;#x200B; Cheers!
the new color is way way better. the old one was washed out and almost sickly looking
I think it's okay, these are mostly design decisions, just worth documenting that: 1) there is no poisoning (like RefCell but unlike Mutex) and 2) that you cannot rely on the guard being run, e g if the user calls mem::forget (which in itself is perfectly safe).
I think you've missed my point. Yes, you have to be aware of panics. But that doesn't mean that panicking in unsafe code *is actually a common issue in reality*, even if you must consider it when writing unsafe.
&gt; 0.75 * X &gt; , while quietly tolerating an &gt; 0.25 * X My contention is that I do not believe it is '0.25' * X and actually is considerably, radically smaller than that. And it's something that is only a problem in the presence of unsafe - something that should be extremely rare. &gt; Process pool, one process per concurrent request, reuse for subsequent requests, restart as needed. Considering *why* people use rust - extremely low overhead - that seems like a solution that wouldn't be easily accepted by the community. Consider that people already choose async frameworks over frameworks with threads, and the perf difference there is way less significant than with processes. You could just work to validate that your unsafe code doesn't panic? Like, there's even a crate that will prevent compilation if a function panics - just use that?
Shouldn't they be called the Rust Usage Strike Team :)
Secure the Pink!
Came here to say this haha
I wonder how much more likely folks will be to confuse "Rust" and "Ruby" now...
[Actually...](https://en.wikipedia.org/wiki/Rust_(fungus\))
I'm unable to find a way to hook into the regular output. There are discussions on further cargo integration in the tracking issue. A test runner managing calling to a proper printer makes sense. The following is a naive [example](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2015&amp;gist=309ea8b4b06d3efd749d1a2ee7af1424), but it emulates the output format.. slightly. Macros ([something like the ones described here)](https://github.com/rust-lang/rust/issues/50297#issuecomment-420100606)) would reduce boilerplate and replace the manually written names. The example also doesn't buffer output or handle any results (or panics; a case for `std::panic::catch_unwind` maybe?).
Do you have anything against Libsodium?
In the meantime here's a userstyle: span.language-color[aria-label*="Rust"], a[href*="search?l=rust"] &gt; .color-block { background-color: #dea584 !important; }
I tried using that code too, but I ran into an issue in the match, when setting the values `Some((x_val, 0_u8))`, that 0_u8 was not the iterator item, and I didn't know how to fix that. 
All hands on deck! Who's gonna make the browser plugin to revert the change!?
Wrong subreddit, you're looking for /r/playrust.
Looks like pure rust
Try to put everyone into a closure and find wherever they accept at least a FnOnce. Better yet find where they accept a Fn and call it repeatedly. Will capture their variables in no time. 
I think I get the idea, but still is something else (doing what a enum do but more raw). Now, if you are telling me that I could store all as Vec&lt;u8&gt; and somehow this allow to make the interpreter simpler without much loss on performance, I'm ears. --- What I'm looking is how reuse the rust types allowing to operate inside the host as close as regular rust without much indirection (even if this restrict me to some fundamental types). Or in other words, how reduce the the work in extend the language taking advantage of what the host provide. ---- &gt; Structs are just a way to name and describe bytes. Their actual representation is lost once the code has been compiled, as such asking for dynamic structs is an oxymoron, BTW, exist a way to see how turn a struct into bytes and back?
I started out seeing how both sides have arguments and grew more and more disappointed as I continued to read...
Thanks for this. I am not experienced enough with Rust to make a relevant witty response, and I am glad to see you did it for me.
Thanks for sharing. Can you explain what you mean by `panic may be deferred slightly by an implementation to allow overflow checks to be coalesced for better codegen`?
This is really cool. Were you expecting that level of performance improvement before you saw the benchmark results? 
&gt; The page you have tried to view (Debian, Rust, and librsvg) is currently available to LWN subscribers only. Maybe resubmit this link in two weeks when it's publically viewable?
I'm too lazy to look up the exact wording, but basically: let a = x + y + z + w; Naively if you just say overflow panics, we would need to emit this as: let a = x.checked_add(y) .unwrap() .checked_add(z) .unwrap() .checked_add(w) .unwrap(); Which is really branchy and bad code. But the RFC that defined this stuff gave us latitude to do something like: let mut overflowed = false; let a = x + y; overflowed |= cpu_overflow_flag; a += z; overflowed |= cpu_overflow_flag; a += w; overflowed |= cpu_overflow_flag; assert!(!overflowed); Which is a lot better
Downvoting because the link is a subscribers-only link which won't become available generally for another two weeks.
I would do it something like \[this\]([https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=fbb7c91298539d5e42b4f65096137102](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=fbb7c91298539d5e42b4f65096137102)) by using \`chain\` and \`iter::repeat\`.
Thanks! &gt;Were you expecting that level of performance improvement before you saw the benchmark results? Are you referring to the improvement offered by [the switch to `ManuallyDrop`](https://github.com/zslayton/lifeguard/issues/18) or the improvement from using a `Pool` at all?
Does anybody have a link to get over the paywall here? I don't subscribe to LWN myself...
Very cute name.
They added the bounds `A::Item: Default` and `B::Item: Default` for exactly this reason. You can't use 0_u8 there since the items are generic and `u8` is a concrete type. So you have to use `A::Item::default()` / `B::Item::default()` instead. 
What's the difference to lazy_static? Both prevent you from recomputing things.
I think you need `edition = 2018` in your Cargo.toml.
I'm having a difficult time trying to puzzle through a problem with borrows (mutable and immutable at same time) and need advice on how to solve. I have a an idea but it doesn't seem very appealing to me. I'm writing a binary format parser in which the first chunk of metadata is encoded the same way, then the main payload of data is encoded based on specific metadata fields - specifically the metadata defines endianness as well as character encoding of string values. I decided to change my implementation to use an iterator as both the metadata and the payload are effectively key/value pairs, and structured it so the iterator parses through pair-by-pair. I then wanted to make a separate utility structure which could use this iterator to read through entries and cache them and the values parsed as types. The main implementation of this looks like: let iter: MyIterator&lt;&gt; = MyIterator::new(file, ...); for entry in iter.by_ref() { parse_entry_value(entry, iter.endian, iter.charset); } In `MyIterator` the `endian` and `charset` values start as a default and then in `next()` if the entry parsed is the one that specifies I update those fields to the appropriate value. The problem is in the for loop above. The iteration is a mutable borrow and because of that inside the loop I'm unable to retrieve any previously parsed endian/charset value. I understand why the borrow-checker is disallowing what I want, as if the iteration was parallelized then the mutable access becomes a data race. The only ideas I cam up with are either using `RwLock` or having the iterator return a tuple of entry/endian/charset however that seems excessive since once those values are read from the metadata they won't change again so for the entire payload - it will be the same endian/charset passed in each call to iterator. Are there other options for working around this problem?
Create a library that looks really useful for metal mining or turret programming, but under the hood uses ‘unsafe’ to introduce subtle bugs. With clever enough under-handed use of unsafe, you might even be able to pwn their entire operation remotely. 
Wait it did?! I have handwritten vectorized overflow-checked adds that rely on deferred overflow panics. But I thought we didn't allow the implementation do that.
And who are you? It's weird that everyone in Reddit assumes I know them.
Which you can compile into pure WASM
What's the downside to this?
Not certain that saying "I'm not allowed to do something" in the same sentence as "but I'll do it anyway" is a good idea without marking it `unsafe`, but a link to the book would have been nice.
Yeah, OP might want to rephrase that. Part of our code of conduct is not attacking other languages in non technical ways. A lot of us are frustrated with C++, but calling it horrible can be seen as zealotry.
Yes, it is more Rusty. Now I will look at Rust repos and think they are D repos!
Of course the "correct" (tm) colo(u)r should only be visible in Servo.
Someone really wanted to call themselves a github contributor on their CV I guess...
So far I've only needed it for using some library written in c.
Yeah finding the functionality that is right in front of you is a very hard problem in programming and I don't mean it in a sarcastic way. I often find myself implementing things that I thought is "unavailable" and while I was researching a specific detail I stumble across a ready to use solution to my original problem and often realize I was REVISITING that crate or Blogpost from the author of that crate. Discoverability can not be valued hight enough.
Using Rust for nearly 5 months now I never really found a situation where I had to use unsafe. I do think that the point of unsafe is that you never really should have to use it in a normal application, but rather when you want to make some specialized abstraction. Especially when you are new to the language I think you should not use unsafe at all. I do think that it might feel really easy to use unsafe if you're coming from another language where you frequently use pointers in a unsafe way. That way you're kinda using unsafe to be able to solve a problem similarly in both languages. One of the benefits of rust is that it makes you aware of the situations where pointer problems can arise, and that is a nudge saying that you should probably redesign your solution. I think it would be great if you could explain/link the code you made and why you felt like you had to use unsafe. I do think there is probably a way to solve your problem using purely safe Rust. Overall it's very cool that you started to learn Rust, and I would be happy to help you reason about your problem in perhaps a different way to be able to solve it without unsafe. Welcome to the community! 
it is, though I personally prefer Haskell's purple-grey tint ! 💜 … I had no idea so much thinking went into the language colors TBH they could have been computing them using a hash function of the language name for all I knew.
Yeah, imagine a Rust IDE that graphically shows lifetime workflows.
I've used Rust (on and off) for over 2 years. I've never had to use unsafe. That probably tells more about the types of projects I've built rather than the language itself, but in general you shouldn't need to use unsafe unless you're building new collections or concurrency primitives, or interfacing with native C libraries.
Thanks for the awesome reply! I would love to share it with you but I want to submit the assignment first before making my repository public. My graduate professor was awesome enough to let me use Rust since I have a lot of experience in C/C++. Anyway, the situation arose when I was sharing containers such as Vectors between several different threads. However, each thread would be accessing a unique set of indexes and modifying the elements in place so there any data races. However, I am forced to either lock the Vector behind a Mutex or RwLock to do anything with it. I decided to use raw pointers instead and using pointer arithmetics to dereference and change the values in those addresses. I am guessing it's because of my immaturity of the tools available in the language that I am struggling with this. If you have any insights, let me know. :) Overall, I am loving Rust, the syntax, and the environment just feels so good and seamless!
Merged!
&gt;the situation arose when I was sharing containers such as Vectors between several different threads. However, each thread would be accessing a unique set of indexes and modifying the elements in place For this you should either use [Rayon](https://docs.rs/rayon/1.0.3/rayon/) for parallel iteration, or Vector's [mutable splits](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.split_at_mut) if you need manual control
It has been reverted! https://github.com/github/linguist/pull/4326#issuecomment-438572601
The only time i had to is when building a language vm with garbage collection
I see. I really wanted to stay with the pure standard library, but doing research and with this reply as well, it looks like I'll have to use them as well.
[Ok ok ok. I hear you. I hear you. I'll revert and get a new release out and up on GitHub before GitLab has a chance to update Linguist there, yup they use it too 😉, and you all head over that way to request the same change. Locking any further comments.](https://github.com/github/linguist/pull/4319#issuecomment-438572160)
never
Could you explain what it is we're looking at here?
this one allows to calculate stuffs at runtime
"I want to satisfy my own necessaries and improve the world. Help appreciated."
I am havign a play with async/await by using tokio with the async-await-preview feature enabled like so in my Cargo.toml: tokio = { version = "0.1.11", features = ["async-await-preview"] } Unfortunately I've run into an error I don't understand, which is reproduced in this minimal example: #![feature(await_macro, async_await, futures_api)] use tokio::prelude::*; pub fn main() { tokio::run_async(async { let s: Option&lt;Box&lt;dyn Sink&lt;SinkItem=u8, SinkError=()&gt; + Send + Sync + 'static&gt;&gt; = None; if let Some(sink) = s { await!(sink.send_async(100)); } }); } The error is: the trait `for&lt;'r&gt; futures::sink::Sink` is not implemented for `dyn futures::sink::Sink&lt;SinkItem=u8, SinkError=()&gt; + std::marker::Send + std::marker::Sync` and it goes away if I remove the line beginning "await!". Can anybody help me to figure out how to get around this?
Once, to call a libc function with no safe binding. ...but then I normally code in scripting languages like Python and JavaScript and, aside from DOS retro-computing projects, I avoid C and C++. (In my current hobby project, I'm actually going farther and using inline assembly to write maximally compact bindings for DOS and PC BIOS calls.)
I am not sure about this but I would say that Rust, in a sense, follows the [Unix philosophy](https://en.m.wikipedia.org/wiki/Unix_philosophy). The standard library doesn't try to do everything well, it rather wants to provide a solid base to build ontop of. This means that the standard library does not contain a lot of things. One thing that surprised me is that the standard libraries don't include regexes. However from a different perspective this means that you could just include the crates you want, and you don't always have to rely on a single implementation for a certain construct.
And the fungi is named because it looks like rust...
Yeah, it's technically *correct*, but it makes no sense. Would you say all Rust/C/C++ programs are in pure assembly just because thats what they compile to? You talk about code in terms of what you wrote it in, not what it compiles to.
I already miss the new one. I liked it.
async methods are not yet being proposed for sabilization. About 10 hours ago Aturon made explicit that he wants to "[pave the way for stabilizing core async/await *within the next release cycle or two*](https://github.com/rust-lang/rfcs/pull/2592#issuecomment-438482219)". (cc /u/Programmurr)
I'm just surprised that [the changing-color PR](https://github.com/github/linguist/pull/4319) was merged without a discussion. I like the old one, although I guess it's just a matter of getting used to it.
Lmao we can't win
Setting aside FFI (where it's unavoidable): twice. Once in a crate that implemented seeking cursors over strings (to avoid constantly having to re-validate the strings; I had about 10x as much test code as unsafe code), and once in my current project to get around a borrow checker limitation.
You could rewrite the for loop to a while let loop: let mut iter = MyIterator::new(file, ...); while let Some(entry) = iter.next() { // now you can access iter inside the loop parse_entry_value(entry, iter.endian, iter.charset); }
Imagine a Rust IDE that lets you change the program as it's running
Oh, it actually **did** change, I thought I had some screen or lighting issue yesterday!
Looks like they’re going to revert?
But you knew that before, right?
How come it hasn't changed for me yet?
&gt; is Moscow a safe place for LGBT folks to attend a conference? Sorry for the long delay with the reply, we've been researching to give you the best advice. We have an experience of organising several conferences in a various places in Russia, they were pretty diverse, and there were no issues for folks attending them. Leonid Kalneus, who is on our team, previously organized DevFest Siberia in Novosibirsk, and there were to problems for LGBT people coming to the conference. And of course we as organisers will guarantee that the conference stays harassment-free. It’s about technology and people, there’s no place for discrimination. As a general note to a visitor of a foreign country with different culture we advise to keep your guard up in the city. If you feel unsafe, please contact organizers or police. You shouldn't have any troubles as far as we can tell. So, answering your question: yes, Russia might be not the safest place in the world, but Moscow is a modern, safe, and pretty diverse and multicultural city. You’d be welcomed and we’d happy to see you there :)
Thx
The commit has been added to [release 7.1.1](https://github.com/github/linguist/commits/release-v7.1.1), but the release isn't out yet ([the last one is 7.1.0](https://github.com/github/linguist/releases))
Thank you.
Only twice in a couple of years: once for C FFI interaction, and another one for SIMD optimizations.
My code is written in pure binary friendo
I hope the borrow checker'd be perfect one day, so that we don't need `unsafe` except for FFI. How much does NLL take us?
I haven't listened, but why not to change the enterprise GitHub header instead? Less people use it so less people will be affected. Also, why introduce different headers in the first place? Perhaps it's all explained in the audio, though.
Cool project, thanks! Are there any plans to support multithreading? IMO, even the simplest pool per thread without balancing would be interesting.
So I haven't really been paying too much attention to WASM but I thought that until very recently a JS bridge was required for DOM access since WASM had no DOM access? So "pure WASM" would make sense in the meaning of "only wasm no more JS at all".
This is just a small step toward victory. Now let's rewrite Github in Rust!
Expected to see rfcbot's "final commitment period" checkboxes at the bottom.
WASM still can’t access the DOM directly.
NLL doesn't help. To make this work, the compiler would have to understand that after `join()` returns, the borrows of things in `thread::spawn()` end. Rust doesn't even have a way of annotating such complex systems. Finding out automatically would require interprocedural analysis, which Rust doesn't do. And all of that is assuming that none of these things panic and don't do what they're supposed to.
It's a typed HTML dom/vdom procedural macro, a few tweets lower you can see the compiler's error messages when tags are not properly closed, non-existent variables are used or invalid attributes are used (it looks like the macro allows arbitrary `data-` attributes but only the specified set of non-data attributes).
You should only be using unsafe when the fundamental core of what you are doing demands it, and there is no library to do it for you. When you _do_ use unsafe, you abstract it away such that you can call on it in a safe way.
The future !
The comments on that PR don't reflect very well on the rust community
Resuming work on HDF5 project (http://github.com/aldanor/hdf5-rs) after a year-and-a-half break. Rust ecosystem got more mature in the meanwhile so maybe this time I can actually finish it... // Rewriting proc macros to work with the latest syn and proc_macro2 was a real pain :) 
Does Rust have a Working Group for important issues like this?
I just noticed in that screenshot that `".rs.in"` is treated as a file extension for Rust code. What's it used for?
I don't need to imagine, as I had to use Smalltalk/V, ML, Prolog and Lisp for university projects a couple of years before Java was announced to the world. :)
It just feels weird to use a `Box` for this. You're creating a `Box` that it is not safe to call `drop()` on, so you have to be careful to never leak it to safe code and so on. It just feels like the wrong type.
Thanks God, I was already considering dropping Rust and switching back to C++ which has a better color.
The comments are bad but I'm even more annoyed by the emoticon reactions. For example, the PR message is reasonable and explains nicely why the author of the PR felt that the change would be an improvement. Yet it gets bombarded with thumbs down and confused emoji reactions. Same with all the comments. Whether a comment is reasonable or eloquent has seemingly no impact on the reactions it gets. If you're pro you get thumbs down and "confused" reactions, if you're against you get thumbs up and heart reactions. On reddit, upvotes and downvotes have some of the same problems but at least they help to filter away low-effort posts. On Github, these reactions serve no other purpose than to encourage group-think and brigading. Though I suppose no matter the means of communication, this would've been a mess. The discussion is about the color of a ~~bikeshed~~ 4 pixel wide Github thing.
Presumably it's for template input files for preprocessing, as in [this answer](https://stackoverflow.com/a/14248876/493729) about C header files.
Sadly I'm pretty sure borrow checking is undecidable, so perfection will stay forever out of reach.
The job at blueorigin looks sooooo nice! Too bad I'm not a us citizen. Rust in space
I'm stunned by this controversy.
[I still get this problem](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2015&amp;gist=054cb69bec0e5ec7346d29cea42d4624). | 1 | struct MathZipper&lt;X, Y&gt; { | ----------------------- method `map` not found for this ... 28 | let it_out = it_tup.map(|(x, y)| x + y ); | ^^^ | = note: the method `map` exists but the following trait bounds were not satisfied: `MathZipper&lt;std::slice::Iter&lt;'_, u8&gt;, std::slice::Iter&lt;'_, u8&gt;&gt; : std::iter::Iterator` `&amp;mut MathZipper&lt;std::slice::Iter&lt;'_, u8&gt;, std::slice::Iter&lt;'_, u8&gt;&gt; : std::iter::Iterator` = help: items from traits can only be used if the trait is implemented and in scope = note: the following trait defines an item `map`, perhaps you need to implement it: candidate #1: `std::iter::Iterator`
Good luck :) I've also just had to migrate type-deriving macro from early days of proc-macro v1 (and the same version of syn you're using, 0.11) to the latest syn/quote/proc\_macro2. Took me a good few days since most of syn has been completely rewritten, lots of types renamed or removed or merged, etc... (but it's well worth it in the end)
I created [an issue to update the Rust Cookbook with rand 0.6.](https://github.com/rust-lang-nursery/rust-cookbook/issues/497)
Delayed panics If an error condition should occur and a thread panic should result, the compiler is not required to signal the panic at the precise point of overflow. It is free to coalesce checks from adjacent pure operations. Panics may never be delayed across an unsafe block nor may they be skipped entirely, however. The precise details of how panics may be deferred -- and the definition of a pure operation -- can be hammered out over time, but the intention here is that, at minimum, overflow checks for adjacent numeric operations like a+b-c can be coallesced into a single check. Another useful example might be that, when summing a vector, the final overflow check could be deferred until the summation is complete.
I've also asked this on SO here: [https://stackoverflow.com/questions/53302482/using-tokio-and-the-experimental-async-await-support-wthy-is-a-boxsyn-sink](https://stackoverflow.com/questions/53302482/using-tokio-and-the-experimental-async-await-support-wthy-is-a-boxsyn-sink)
Like a true 10xer
I did a search on the title and OP's handle, and came up with this: https://gradebot.org/doc/ipur/
I am sorry! Here is the correct link: https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2015&amp;gist=64e5a5da076e8b61c4d745168ad470c1
I have the same experience 90% of the time I try to implement some weird functionality around `Result`, `Option`, and `Iterator` data. So many great goodies in the standard library
Quick, change all crate names to various fungus puns.
I typically use `SmallRng` when I just want speed. Anyone know the difference in performance characteristics between Xorshift and the new default PCG one?
The new one is typically slower, but we weren't happy using Xorshift as the default. You can run `cargo bench --bench generators` yourself. We're adding the Xoshiro family to Rand (but not as the default `SmallRng` algorithm): https://github.com/rust-random/rand/pull/642
Regarding the "expected reference, found u8" problem: calling `iter()` on an array of `T` returns an iterator that yields items of type `&amp;T`, not `T`. The easiest fix would be to instead use: let it1 = [1_u8,2,3,4].iter().cloned(); let it2 = [4_u8,3,2].iter().cloned(); You could also dereference the `&amp;u8` in your implementation of `next()`. match (self.x.next(), self.y.next()) { (Some(x_val), Some(y_val)) =&gt; Some((*x_val, *y_val)), // etc. }
This is doubtlessly the most significant development in Rust's history since the removal of argument modes. As such, it is obvious that human beings are simply ill-equipped to properly process the sheer outpouring of triumph and rapturous jubilee that such an occasion demands. I find myself lost, body and mind, to the quaking throes of exhilarated mirth; yet here in this moment of rare lucidity I acknowledge that the subsequent bacchanalia cannot be publicly archived, lest we one day reemeerge into reason only to find our hedonistic, animalian debauchery laid bare for all future generations of humanity to abhor. Go now, into the streets! Run, exult, and make passionate love!
I think your last link is missing a closing bracket of some sort. :-)
Really impressed by SmallTalk IDE… I wasn't even aware that such a level of introspection and close interaction with the code existed. My previous high bar for was my experience playing with the Clojure REPL… The bar just got propelled very high.
&gt; async methods are not yet being proposed for stabilization. Gotcha, thanks! Free functions are a big step up! &gt; About 10 hours ago Aturon made explicit that he wants to "pave the way for stabilizing core async/await within the next release cycle or two". Holy crap, that's fantastic news!
This dilemma could easily be solved by an opt-in `explicit_errors` compile flag.
I get where Microsoft is going and it's kinda cool but please, Code? Aside from it's busy config and plugin system, I never had an issue with package updates on any Debian variant until I installed that thing. If Windows users need some flare, that's cool. On this side, even Geany is better, IMNHO.
Maintaining statically ensured type and lifetime safety while things can be changed in and out behind your back by hotloading is going to be rather tricky. Smalltalk doesn't have that problem, as a Smalltalk system can reflect on itself dynamically, thus allowing it to identify and take corrective action on an invalid operation, right where it happens. 
Sorry mate but I think you're looking for /r/playrust.
Very rarely should you panic. Panics should only be used in the case that there's really no sensible thing that you should do in that case. If the caller decides they want to panic on failure then they should just do `.expect("couldn't set color")`.
Have you looked at `objcopy --prefix-symbols`? I haven't checked your build process, but it does exactly what you mention.
Awesome, thanks!
IIRC the Itanium actually had math instructions to do exactly that sort of overflow checking. I wish they were more common.
That's a useful benchmark, thanks. On my machine, `Mcg128Xsl64` outperforms xorshift on the bytes and u64 benches. rustc 1.32.0-nightly (9fefb6766 2018-11-13) test gen_bytes_mcg128_xsh64 ... bench: 334,503 ns/iter (+/- 32,394) = 3061 MB/s test gen_bytes_xorshift ... bench: 380,480 ns/iter (+/- 15,318) = 2691 MB/s test gen_u32_mcg128_xsh64 ... bench: 1,209 ns/iter (+/- 34) = 3308 MB/s test gen_u32_xorshift ... bench: 878 ns/iter (+/- 44) = 4555 MB/s test gen_u64_mcg128_xsh64 ... bench: 1,213 ns/iter (+/- 365) = 6595 MB/s test gen_u64_xorshift ... bench: 1,874 ns/iter (+/- 152) = 4268 MB/s 
* If you plan to store recycled values in a struct or use them in function signatures, adding the `Recycled&lt;T&gt;` type to your values can get a bit tedious. This is an issue for any smartpointer, however. (`Rc&lt;RefCell&lt;T&gt;&gt;` is a common example.) * The `Pool` will hold up to `MaxSize` instances of `T` until it's dropped or until you manually `detach()` some instances. If you set `MaxSize` much higher than necessary, you'll be using more memory than you need to. I've considered adding a `resize()` method (similar to [`Vec`'s `resize_with`](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.resize_with) function), but I'm not sure there's much use for it. * Each time that you request a value from the `Pool` when it's empty, it will allocate a new value to satisfy your request. This `Pool` allocation is slightly slower than simply allocating because the `Pool` needs to wrap the new value in a `Recycled&lt;T&gt;` smartpointer. In situations where you'll truly be reusing the `Recycled` values, you'll easily [make up for that overhead cost and then some](https://github.com/zslayton/lifeguard#highly-unscientific-benchmarks). If you configure the pool with much lower `MaxSize` than your use case demands, it could end up being slower overall.
If I understood correctly, it uses [LALRPOP](https://github.com/lalrpop/lalrpop) to do parsing and error handling.
For Option&lt;T&gt; optimization though you could also use unreachable hint https://doc.rust-lang.org/std/hint/fn.unreachable_unchecked.html
If your custom structure is backed by a Vec, it's possible to wrap Vec::IterMut to make a new mutable iterator without any extra unsafe code. The `slab` crate does this for example. But if you're using unsafe memory accesses under the hood, then yeah IterMut usually requires more unsafe code.
Generally, libraries should **not** panic: * Users of the library can not always catch panics. [Aborting on panic](https://rust-lang-nursery.github.io/edition-guide/rust-2018/error-handling-and-panics/aborting-on-panic.html) is a thing. * You can not tell if a function will panic from its type signature. You either trust the documentation or read the source code of the entire function. And anything it calls. And so on. IMO now that we have the question mark operator, the argument that handling `Result` is too verbose is a weak one. A long time ago [I wrote a blog post](https://justinas.org/best-practices-for-errors-in-go) on handling errors in Go, including thoughts on when it is okay to panic (Go has a somewhat similar panic mechanism).
Apparently it used to use pom (peg parser combinator) until today, the last two commits are introducing lalrpop and completely removing pom.
Your profile picture is showing as the thumbnail for the submission.
Their Updater is written in Rust too.
/u/icefoxen is no beginner, I'm pretty sure he know a lib shouldn't panic. Care to elaborate what made you change your mind recently ?
ok, so they have a project called inno-updater which is a few thousand lines of Rust. VS Code is still not written substantially in Rust, and it's still not how FoR works.
Thanks for sharing this! I'd actually been [considering this approach](https://github.com/zslayton/lifeguard/issues/5), but in the end I went with `ManuallyDrop` because it [simplified a lot of the code](https://github.com/zslayton/lifeguard/commit/c133e7edb3c0c01051780cabf48c2a05b511e21c#diff-b4aea3e418ccdb71239b96952d9cddb6L287) by removing the `None` branch altogether.
Yeah I wasn‘t arguing for OP‘s point, just wanted to add to your comment that they have this too.
I haven't changed my mind, but people keep making things panic anyway, and asking me to do the same. It makes me wonder why.
You're right, that's now how FoR works but there's no requirement that your whole product uses Rust. Many of the companies already on that page only use Rust for a few parts of their products. If Microsoft sent a PR with the description "We use Rust for the VSCode updater and the Azure IoT Edge project", I'm sure it would be accepted.
I agree, but OP is being ridiculous
That would be excellent, actually ! My code is a straightforward dense 2D grid structure backed by a `Vec`, there are no unsafe accesses in the code apart from the iterator, so I've tried to return a flattened iterator of 1D spans to build a 2D iterator (this is not correct but it was just to see if it would compile): ```rust pub fn iter_mut(&amp;mut self) -&gt; impl Iterator&lt;Item = &amp;mut T&gt; { let (y1, y2) = (0, self.height); (y1..y2).map(move |y| self.grid.iter_mut()).flatten() } ``` The problem is that this gives an error about lifetimes ``` error[E0495]: cannot infer an appropriate lifetime for lifetime parameter in function call due to conflicting requirements ``` The source for the entire module is here: https://gitlab.com/snippets/1777276
Trivially so; ```rust let x: T = &lt;expr&gt;; let y: &amp;T = if halting_problem(P) { &amp;x }; ``` will `x` be borrowed or won't it?
I have a fork of lifeguard (that I forked from someone else) that has an Arc version of the pool: https://github.com/justinlatimer/lifeguard/tree/sync?files=1
Thanks for the post, the content is great. Is there any particular guideline to get access/enroll to the full Standford course?
`rustup target add` downloads the stdlib for a target, but msp430 doesn't have a stdlib because it doesn't necessarily have an OS. If you run `rustc --print target-list` you should see `msp420-none-elf`, so it should work out of the box. You may need to install `msp430-gcc` for it to work, not sure if msp430 is using the lld linker yet.
To be fair, REPL-driven development with Clojure is still pretty darn nice, and you don't have to sign up for a binary code format. I really want to like Pharo/Smalltalk more than I do but it's too much in its own universe for me.
Is it the old `macro_rules` type expansion or an attribute like macro? function like macro? custom derive? 
Interesting presentation. How will your library compare to something like the SuperCollider audio server? It sounds quite similar (dynamic graph generation every control period) in operation. If you haven't read it, Ross Bencina's article on the SuperCollider audio server is worth reading. &amp;#x200B; Something that Rust would benefit from would be a crate with a DSP unit generator standard that could be used for anything from SuperCollider Ugens, to VSTs - and which provided common functionality for oversampling, SIMD operations. 
It Is a Macro Set To Control Your Recoil on a Weapon
Hey, neat! I've been dragging my heels on this because I didn't want to duplicate so much of the implementation for an `Arc` variant. I'd love to know how the `Arc&lt;RwLock&lt;_&gt;&gt;` version's performance compares to that of the `Rc&lt;RefCell&lt;_&gt;&gt;` version in the benchmarks. 
I'm somewhat disappointed that the primary reason I didn't adopt VSCode has a relation to Rust. I really wanted to like Code, parts of it are shiny, but the frequent held or broken package noise became unwelcome. I don't know whether my perception has more to with release practices than implementation language or even if the erratic behavior is still there. IMVCCO, there are better examples of Microsoft's excellence.
the problem is that you impl `Iterator` for `Item`s of type `u8` but `[1_u8, 2, 3, 4].iter()` returns `Item`s of type `&amp;u8`. you can clone (copy) the items to get owned values if you use `[1_u8, 2, 3, 4].iter().cloned()` [here the complete example](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2015&amp;gist=bee00c046d003d5e34b2d22fd2852893) 
I always think of panics like the famous red destruction button. There should be a really good reason to use it. Errors, however, can point towards a problem in the programmers code. And a good API/library should if possible prevent the programmer from doing something disastrous, not be the disaster. To me that sounds like the unwillingness to rethink a problem. Communication is key here. Panics should be like unwraps in libraries something to avoid, not something that should be added willingly.
I used it once when I was creating dynamic async streams for Kafka with rust-rdkafka to create a self-contained consumer+stream structure that could live on it's own and hence play nice with Tokio, basically - self-referential structure.
I'd be really tempted to put user space threading back (like Go). Not a fan of tail calls myself. Prefer usable backtraces instead (this is also an issue with "async" code).
This is perfect, I like how simple it is! Thank you very much for the help.
The other people are joking. This subreddit is for the programming language Rust, not the game Rust. I'd link you to the correct one, but you'd get banned there anyway if you try to sell cheats.
What is the current status of async / await? Is it in nightly? Is there any documentation available? Where should I be looking? I want to build something that (I think) it would make sense to do using futures. I'm happy to build it on nightly for now - I won't be deploying anything to production until next year or so anyway, but I want to get my hands dirty. The project in question exposes, consumes and transforms lots of asynchronous streams of data. It seems like I could: - Use futures 0.1.X, maybe with tokio, or [fibres](https://crates.io/crates/fibers). It seems like there's an ecosystem around this stuff, but also a reason why we're moving away from it. - Use [futures-preview 0.2](https://crates.io/crates/futures-preview) - ... Or [futures-preview 0.3 alpha?](https://crates.io/crates/futures-preview/0.3.0-alpha.9) - Stay away for now and build everything on top of threading, then come back to futures in the future? If I do everything this way I'll probably end up leaning heavily on threads and [channels](https://doc.rust-lang.org/std/sync/mpsc/fn.channel.html) / [crossbeam channels](https://docs.rs/crossbeam/0.5.0/crossbeam/channel/index.html). But I have no idea which is the better option right now. Thoughts?
Having a function return a `Result` is a good indication that the function might not succeed. On the other hand, having a function return a `()` can be taken as an indication that the function shouldn't fail. If every function is made to return `Result` that distinction goes out the window and we're more or less back to the exception model of "Any function might fail". For Rust's APIs to be as error-accurate as possible, more or less everything that touches memory would need to return a Result. TryInto would probably need to be `Result&lt;Result&lt;T, E&gt;, MemoryError&gt;` or similar construct (`MemoryErrorOr&lt;E&gt;`?). Things that end up using OS primitives (mutexes, semaphores, etc) would need to prepare for handle exhaustion. People have been arguing for out of memory errors as `Result`s, etc. On the other hand even a simple function call might result in stack overflow issues. Maybe a function call could return a result of whether the jump to the function succeeded? .. this might make '.unwrap()' an interesting concept. So hopefully at this point we can agree that neither "Don't care about Results, just panic" or "Never panic, always Result" is going to cut it. We'll need a compromise. Unfortunately the compromise depends on the target audience of your API. Is your API going to be used in low resource environment, such as an embedded micro-controller? Out of memory errors might be expected and need to be handled. You might want to err on the side of Results-almost-everywhere. If your API is going to be used in a massive enterprise application instead, where the fix to an out of memory error is to go shopping for more RAM sticks (or even better, move that VM RAM slider further to the right), you might opt for a more straightforward API that uses Results only in the places that are somewhat expected to fail in normal use. This issue is also affected by the complexity of your error objects. If I'm calling the `set_color` method referenced in the ggez issue, I see it's returning a Result **and** I want to handle that result properly, I might want to inspect the error value. In this case it's a `GameError`, which includes things like `ShaderProgramError`, `FontError` or `UnknownError`. I'm now wondering whether my `set_color` call may result in a `FontError` and how to handle this. Of course some of this is unavoidable. Coming up with 10 different error enums is pain for users (and maintainers). But at the very least we can avoid cluttering the APIs with obsolete Results to reduce the need for our users to deal with this issue. And finally an important point I've learned during my career: If you are developing a system for which people come to you for your expertise, and you encounter a situation where you don't know what to do, most often your users have even less of an idea. If you recognize an obscure error condition where your first thought is to just panic because there's no other sensible way to continue (program in invalid state, etc.), don't try to return that as a Result only in the hope that someone else might have a solution to the issue. I feel like a good test for this is to document those error results (something you should do anyway!). If _you_ can't describe the reason, effect and solution to an error, the error is probably too obscure for your users to understand anyway.
Luckily, the second edition of TRPL has got you covered if you need material to quote! https://doc.rust-lang.org/book/second-edition/ch09-03-to-panic-or-not-to-panic.html Here's the TL;DR for those folks that care: &gt; Rust’s error handling features are designed to help you write more robust code. The `panic!` macro signals that your program is in a state it can’t handle and lets you tell the process to stop instead of trying to proceed with invalid or incorrect values. The `Result` enum uses Rust’s type system to indicate that operations might fail in a way that your code could recover from. You can use `Result` to tell code that calls your code that it needs to handle potential success or failure as well. My strong opinion is this: for libs, prefer `Result` over `panic!`. It can be surprising how many errors one can recover from, and it's very, very rare that libs are in a position to tell whether or not it's appropriate. I think that *applications should make this decision, not libs*. and they can make that decision when you defer to them by returning `Result`. Another strong opinion: *fallibility is not an ergonomic hit*, just faithfully modeling the domain that you're working with. Unless you can **guarantee** that something is not fallible, just work with `Result`s. They're not bad. They're not hard to use. And if you're worried about somebody turning away from Rust because of `Result`, then it's likely that they don't value correctness like the Rust community itself does. That's okay! That's fine! That doesn't make them a bad person -- but working against a tool's philosophy and ecosystem can be hard on one's sanity, and I'd definitely suggest that they reconsider their reasons for using Rust.
Once upon a time, before Rust had procedural macros, you needed compiler extensions to achieve the same things. These were only ever available on nightly Rust - obviously no good if you want to target users on the stable channel! At some point, it became possible to do this in stable Rust, if you used a separate build step and pre-processed your Rust file. The suggested way to do this was to append `.in` to the source file, then output the `.rs` which was actually compiled. You can still see this in some older Rust projects, eg `pnet_packet`: https://github.com/libpnet/libpnet/tree/b74c3da988573a35ce1f9839317d3aa10b4b0a43/pnet_packet/src (build step: https://github.com/libpnet/libpnet/blob/b74c3da988573a35ce1f9839317d3aa10b4b0a43/pnet_packet/build.rs). Most projects have moved to procedural macros instead now - there's no need to do it any more. As an aside - it was actually me who added support for that: https://github.com/github/linguist/pull/2807
The answer is somewhat misleading. Rust can differentiate between external functions (which must be C-compatible) and internal ones, so it can adopt different calling conventions for each. Tail-call-optimization is basically stuck on a choice of syntax IIRC.
This question comes up so often, and there appears to be a lot of confusion around it. The choice is very rarely between "panic or Result," so phrasing an answer in terms of "use Result instead of panic" is a bit off. Panicking and Results solve two different problems. The easy way to answer this is to state the conditions under which panicking is acceptable, since it is the more extreme behavior. Namely, if your **library** is the source of a panic, then one of the follow _should_ be true: * Your library has a bug. * Your library documents a precondition of a public API item that, when not met, causes a panic. Therefore, the user of your library has misused your library, and _their_ code has a bug. If neither of those is true, then outside special circumstances, you'll probably want to _make_ one of those true. Which one to choose is sometimes judgment call, but either is valid. If your Rust **application** panics in response to _any user input_, then the following _should_ be true: your application has a bug, whether it be in a library or in the primary application code. The bottom line is that if a panic surfaces to an end user, then we ought to consider that a bug somewhere.
I'm (slowly) learning Rust by building a MUD / interactive fiction / text playground in my (scant) spare time: [https://github.com/textcamp/server](https://github.com/textcamp/server) &amp;#x200B; Not a lot to work with at the moment, but it's been a really delightful introduction to the basics! :D
I agree with what you've said before, but keep in mind that "ridiculous" in this case could merely be an OP not knowing what rules govern the FoR list.
[This](https://mail.mozilla.org/pipermail/rust-dev/2013-April/003557.html) implies that at least part of the reason why TCO isn't in rust is due to C interop (although I don't get the impression it was decisive).
https://api.rocket.rs/rocket/data/trait.FromData.html You can create your own `Image` type that implements the `FromData`. The `from_data` function gets a reference to the original request. The example on that page even shows how to access the content type.
&gt; not use extern crates For cryptopals this seems totally fine, but (this came up in another thread today) note that a lot of 3rd party crates are what other languages might consider essential parts of the language. For example, lazy_static and crossbeam-channel.
I think you're running into the problem explained here: https://stackoverflow.com/a/30422716. TLDR: you can't return references to the type that implements `Iterator` because there is no lifetime connection between `fn next(&amp;mut self)` and `type Item` in the `Iterator` trait, so there is no way for the compiler to know if the items will live long enough
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rng] [Rust rand lib version 0.6 release, now with a book](https://www.reddit.com/r/RNG/comments/9x39hi/rust_rand_lib_version_06_release_now_with_a_book/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Type-checking would be the main part yes, I'd also expect it to be pretty fast.
It's a 64-bit generator so it naturally has an advantage generating 64-bit numbers on 64-bit CPUs. The byte-conversion can also use this; however the `u32` conversion just throws half the bits away (it's not worth saving them).
I meant "only" part. Or does/will this also allow arbitrary dom interactions? Events, clicks etc.
AFAIK static, in the twitter thread the author notes that this could (eventually) be combined with Yew or whatever.
Hmm, I thought I benched this but looking at the commit history I guess I didn’t. I’ll see if I can get to it.
Unfortunately, `objcopy` isn't available on all platforms (e.g., not available by default on macOS), and not all versions support the flags you mentioned. I really wish it were this easy, but alas :/
And we'd love to have help making it better!
I'm only considering rust because it has strong C interop - which is not down to C but rather ahead of time compilation/no JIT, and no runtime garbage collector (deterministic memory management) .. C itself has strong 'asm' interop ... if I didn't want that, there's any number of more elegant languages.
Hello everybody, I want to define a function which takes a Result and returns a Future. The following implementation works: \`\`\` fn consume\_result\_box&lt;R: 'static,E : 'static&gt;(input: Result&lt;R,E&gt;) -&gt; Box&lt;dyn Future&lt;Item=R, Error=E&gt;&gt; { let future = input.into\_future(); box future } \`\`\`\` However I'm wondering if there is a better way instead of bounding the R (the Result) and E (the Error) to 'static. From what I understand that would mean that R and E can't be a reference. However sometimes this might be useful. Any recommendation to optimise this function or replace the 'static lifetime with something more generic? Thanks a ton!
This exactly. If it wouldn't be that close to C I would just stick to Haskell or elixir...
This release now allows for all macros that don't take runtime values as parameters to be used in the global scope when the `nightly` feature flag is enabled. You can learn how to do this [here](https://docs.rs/static_assertions/0.3.0/static_assertions/index.html#labeling-limitation-fix). The "labeling" workaround felt really clunky to use, imo. Once the underlying Rust feature that enables this is stabilized, this crate will be released as 1.0.0! I also finally got around to making [a sexy new logo](https://raw.githubusercontent.com/nvzqz/static-assertions-rs/assets/Icon.png) for the project, which is based on the design of Rust's logo. If you want a logo for your project, feel free to reach out to me :)
Well, you can make it generic over the lifetime, instead of forcing it to be `'static`: fn consume_result_box&lt;'a, R: 'a, E: 'a&gt;(input: Result&lt;R, E&gt;) -&gt; Box&lt;dyn Future&lt;Item=R, Error=E&gt; + 'a&gt; { let future = input.into_future(); box future } 
Yeah I know that, I will use them in the near future ;-)
Hello, I'm trying to learn how macros work, and I've been trying a macro to aplly a function to Option if they are all Some. But I can't create new variables inside macro_rules! to extract the data from Options. How should I do this? macro_rules! map_all { ($fn:expr, $($opt:expr),+) =&gt; { match ($($opt),+) { ($(Some($opt),)+) =&gt; Some($fn(($($opt),+))), _ =&gt; None, } } } It fails because of $opt is used as augument and inside Some($opt)
all alright know anywhere i can sell 
How would you handle AtomicPtr? Sure you can make a safe abstraction like AtomicOption, but it still uses unsafe to implement it...
damn chief 
Why do you even need the vectors? These functions are already present on iterators, I believe.
Ah thank you this works great! I think I'm missing a piece to the puzzle though because I don't see the difference between this and the for loop - could you help explain how it's different? The `next()` method takes `&amp;mut self` so I would assume it creates a mutable borrow.
Correct me if I'm wrong - the issue with greenthreads was that it required a run time, not C interop.
I've seen this in a C++ debugger and I want it
Seems unlikely that C is the main reason, since compilers [perform TCO](https://godbolt.org/z/X_Xi4C) on higher optimization levels.
This: for x in xs { foo(x); } desugars to something like this: let mut iterator = IntoIterator::into_iter(xs); while let Some(x) = iterator.next() { foo(x); } So in your case that hidden `iterator` variable borrows your `iter` for the whole loop, which is why you cannot use it inside the loop.
That logo is really sexy! What did you use to make it? 
It was both.
Rust *does* have a way of doing this, just not with this particular api and signatures. Scoped threads make this work; see scoped_threadpool or crossbeam.
All the links I see are working properly on Old Reddit. What do you see?
Thanks! I use [Sketch](https://www.sketchapp.com) for most of my design work these days, including this.
How so? I thought `become` and the syntax surrounding it was pretty uncontroversial and it was stuck waiting on some LLVM detail.
&gt;&gt; "You can provide C interop with an interpreted language and GC if you really feel like it. " true; i'm aware of C FFI from haskell, java , python etc; I guess I was trying to re-interpret the OP's intent r.e. what constrains Rust's design (which to me is requirements that allow it to target *the same niches* as C, rather than C FFI - which many languages support without being viable C replacements)
Ok that makes sense. Thank you for explaining.
Totally agree. But it is an interesting thought experiment 
Rust is much more approachable than Haskell IMO. 
Outside of C FFI, I've only had to use unsafe 2 or 3 times total.
The community is actually waiting for WebAssembly to support TCO. As I understand so far, this is the only thing blocking the `become` keyword.
I have this code fn build_assignment&lt;'a&gt;( assignment: &amp;'a ast::Assignment, scope: &amp;'a mut scope::Scope&lt;'a&gt;, ) -&gt; semantics::Assignment&lt;'a&gt; { let var = Box::new(... some value ...); scope.declare(&amp;assignment.var.id.name, scope::ScopeValue::Var(&amp;var)); semantics::Assignment { var: var } } But the code doesn't compile because \`var\` doesn't live long enough. error[E0597]: `var` does not live long enough --&gt; src/main.rs:232:68 | 232 | scope.declare(&amp;assignment.var.id.name, scope::ScopeValue::Var(&amp;var)); | ^^^ borrowed value does not live long enough ... 238 | } | - borrowed value only lives until here | note: borrowed value must be valid for the lifetime 'a as defined on the function body at 227:21... --&gt; src/main.rs:227:21 | 227 | fn build_assignment&lt;'a&gt;( | ^^ I thought that \`var\`'s ownership was assigned to \`semantics::Assignment\`, which is the return value with the lifetime \`'a\`. But the compiler still complains that \`var\` doesn't live as long as \`'a\`. I'm new to Rust and wonder what I am doing wrong here.
Thanks everyone for all the work put in to this. I have a lot of fun playing around with embedded stuff.
Here I try both approaches,both with types and with traits: [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=8ddda86b772bc0405ba70c613b28402d](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=8ddda86b772bc0405ba70c613b28402d) Use either build method to get the error message The error message with types: Compiling playground v0.0.1 (/playground) error[E0271]: type mismatch resolving `&lt;Builder&lt;_, Initialized&lt;Field_X, _&gt;, Uninitialized&lt;Field_Y, u32&gt;, Initialized&lt;Field_Z, _&gt;&gt; as TypeIdentity&gt;::Type == Builder&lt;_, Uninitialized&lt;Field_X, _&gt;, Uninitialized&lt;Field_Y, u32&gt;, Uninitialized&lt;Field_Z, u32&gt;&gt;` --&gt; src/main.rs:187:14 | 187 | .build(), | ^^^^^ expected struct `Initialized`, found struct `Uninitialized` | = note: expected type `Builder&lt;_, Initialized&lt;Field_X, _&gt;, _, Initialized&lt;Field_Z, _&gt;&gt;` found type `Builder&lt;_, Uninitialized&lt;Field_X, _&gt;, _, Uninitialized&lt;Field_Z, u32&gt;&gt;` The error message with traits: Compiling playground v0.0.1 (/playground) error[E0277]: the trait bound `Uninitialized&lt;Field_X, _&gt;: InitializedTrait&lt;_&gt;` is not satisfied --&gt; src/main.rs:170:14 | 170 | .build(), | ^^^^^ the trait `InitializedTrait&lt;_&gt;` is not implemented for `Uninitialized&lt;Field_X, _&gt;` error[E0277]: the trait bound `Uninitialized&lt;Field_Z, u32&gt;: InitializedTrait&lt;u32&gt;` is not satisfied --&gt; src/main.rs:170:14 | 170 | .build(), | ^^^^^ the trait `InitializedTrait&lt;u32&gt;` is not implemented for `Uninitialized&lt;Field_Z, u32&gt;` 
You could make a recursive macro, then you could create then one variable at a time. [Here's my attempt.](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=3d6721b4c3ed47b016db133d14e58c88)
I answered the Q myself in the end; the error was spot on (I just didn't expect it to be true!). I expect that the async shim in tokio reimplements the Sink trait and doesn't then impl on Box. In any case, writing a new type wrapper that does implement Sink does the trick (see the SO answer for more if interested) 
When you say that function result has lifetime `'a`, then it means that it borrows its arguments for lifetime `'a`, but not necessarily that its result will actually live for that long. For example, the user of your function could just throw returned value out immediately, and then continue to use the `scope`, which would now contain references to freed memory. In your case, I can think of two solutions: 1. If `... some value ...` is small and cheap to copy/clone, then you could store it in `ScopeValue::Var` by value, instead of by reference. 2. If you can't clone it easily, you could wrap it into [`Rc`](https://doc.rust-lang.org/std/rc/struct.Rc.html), and then have two clones of that (which would point to the same allocated memory).
I'm not looking at non-systems languages; targeting the same niches as C is an explicit requirement. Given that, I am curious about how much better Rust theoretically *could have been* by neglecting C compatibility. C is very old; there are many design decisions that could be modernized/ improved upon. Rust demonstrates this. I am not suggesting neglecting C would be a viable approach. I'm just curious. Hence the "thought experiment"; without C compatibility, could Rust technically be a much better language? 
&gt;This question comes up so often, and there appears to be a lot of confusion around it. The choice is very rarely between "panic or Result," so phrasing an answer in terms of "use Result instead of panic" is a bit off. Panicking and Results solve two different problems. Great answer! The rarity of this decision is something I disagree with. It is trivial to replace a Result with a panic. Especially budding Rust devs need guidance before they can build an understanding of why they should pick the approach cluttering their and their users' code and mess around with complicated error types, only for it to be propagated up to the main function just to essentially panic _anyways_.
Why does `Iterator` use an associated type and not a generic parameter? Why is it not implemented like this: pub trait Iterator&lt;Item&gt; { fn next(&amp;mut self) -&gt; Option&lt;Item&gt;; //all the default methods... } Is there any specific reason I am missing? 
I think people are talking about guaranteed TCO. rustc definitely does do the optimization, but there is no way to say "this must be tco optimized"
If your server is threaded, you can have a background thread that handles logging safely. Pass off an `mpsc::Sender&lt;String&gt;` to the slave threads for inbound connects and have them submit the requested document to the logging thread. Then in the logging thread you can just read these requests in a loop and write them to your log file.
Rust does have dead code elimination, so it shouldn't be a big issue?
I'm using Warp in this case. One idea I had was to perhaps chain in a logging function for each route, though I'm not sure how that will affect performance.
The implementation of a logging API should do this internally. It shouldn't be necessary to do this kind of thing manually.
You could probably add a middleware, actix-web has a [logging middleware](https://actix.rs/docs/middleware/)
&gt; So hopefully at this point we can agree that neither "Don't care about Results, just panic" or "Never panic, always Result" is going to cut it. We'll need a compromise. You may be interested to know that the author of Zig takes the "Never panic, always Result" route and at least earlier this year was _very_ adamant about this and therefore everything that allocates has error handling threaded through it, and there are plans to do static call graph analysis + other techniques to prevent running out of stack space. Also as a small point of correction, the Rust standard library _aborts_ on allocation failure, but most of the functions in the standard library that allocate can panic because of what's noted [here](https://doc.rust-lang.org/std/primitive.pointer.html#safety-1).
At this point one should consider using `slog` ecosystem, which implements that and more.
From what I understand, it's mostly that we don't want implicit TCO since having the difference between code running or overflowing stack being an implicit compiler optimization is not great. And an RFC for explicit TCO hasn't happened in a while.
This is what I've started to do here: [https://gitlab.com/srwalker101/rust-bokeh/](https://gitlab.com/srwalker101/rust-bokeh/) &amp;#x200B;
I created a trait called `trait Route: Send + Sync { fn exec(&amp;self, req: &amp;hyper::Request, logger: &amp;slog::Logger) -&gt; Option&lt;FutureResult&lt;hyper::Response,hyper::Error&gt;&gt;` which is wrapped by another type to expose the interior `Route` object as Hyper's `Service` trait. That _middleware_ type injects the logger and metrics. Seemed kind of hacky but it worked well enough for logging health check and diagnostic data. 
Rust could probably run on the PS4. I think sony uses clang, so rust could probably piggyback on that. :P
Isn't a question for /r/rustgame?
I'd start with: https://hackinformer.com/2018/05/05/psxitarch-a-linux-distro-just-for-the-ps4/
99% chance of that, 1% chance /u/NGT_Cerny actually was talking about the programming language.
We're working on it. 
Thank you!
&gt; dismisses the concept of object files and a linker for compiling binaries. Could you explain this concept further? I've never heard of any alternative and I'm stretched to think of what that could even be.
Yeah, apparently it took Chucklefish 10 days to customize rust for Xbox, PS4 and Nintendo Switch. Would really like to know more about it. And I'm secretly hoping that they'll release part of it when they are done with the game and got some time. &amp;#x200B; Official support would be the absolute dream.
The inspiration for this library came from of a discussion I had with Adam Nemecek about mathematics, in particular about linear logic, classical logic and theorem proving. We figured out that CHR makes some very good trade-offs between performance and provability, using the basic concepts of "simplification" and "propagation" of constraints. So, I wanted to an automated theorem prover using these ideas. However, since a generic solver can't keep track of active rules, I am using a bloom filter to detect cycles and then search for the minimum set of facts within the cycle. This works when the inference rules are deterministic and terminates, and the accuracy of the bloom filter is high enough to never expect a false positive.
/r/playrust
I can't speak for any of those platforms, but WiiU/3DS has a developers forums locked behind NDA that would be where you could share something like that. Nintendo at least treats their SDK as a trade secret. And I daren't say anymore lest I give the Nintendo Ninjas a reason to dislike me. The WiiU/3DS developer portal is public, though, so long as you (digitally) sign said NDA. Switch is hopefully eventually going to be so, but currently I think it still requires going through some sort of publisher or other connection.
I am talking about the performance gain from using Pool in general.
Probably no curly braces
I remember reading that now. Thanks. :)
I don't know what the author had in mind, but incremental compilation in Rust is probably along those lines since its saving pieces it has already built rather than only whole object files.
And if you don't want to rely on the halting problem, rely on the halting problem proof: make the result depend on the result. let x = ..; let y = if borrowck(Ask("y borrows x"), Program(this_file) { &amp;not_x } else { &amp;x };
I'm not a compiler expert, so my opinion does not have a lot of weight. In my (very humble) opinion, a language is useless without a build system. Failure to specify and standardize how a build system should function is detrimental to that language. I don't mean to suggest I'd like a language with no object files/linkage anywhere in the build process. What I mean is that linking is not orthogonal to compilation, one is meaningless without the other. Even with static libraries, the object code is going to be linked eventually, it's useless by itself. Now the tricky part is that when you get to *build* time, everything about the source is known. When you go the route of defining a compiler without the linker, one thing you lose out on is this fact - you can't defer definition until link time, essentially using a placeholder in the compiled object code to be filled during the build. Now I know the response to this - "forward declaration and external linkage." But that's not a perfect solution, because external linkage doesn't tell the compiled code anything - just that there's a symbol that will be defined later. In some cases, this is not acceptable, Take the following: struct Foo; struct Bar { char bytes[sizeof(Foo)]; }; This is a compilation error since the compiler doesn't know the size of `Foo` before compiling `Bar`, just that some struct named `Foo` will be defined later. The issue I have is that if `Foo` is a placeholder for something in some different compilation unit (could be your code, could be defined by a user of a library, etc), when the software is *built*, `Foo` will be defined and will have a known size. But you can't defer that compilation without build system hackery that will expose details of the build, which may or may not be acceptable. There are some use cases for programming *like* what I mentioned above, and they do have solutions in the language. But in my (again, very naive) opinion it's a result of the forced segregation between compilation and linking. That said, I understand it's a really complicated problem with 50 years invested into it, so I doubt I'm the first person to bring this up and there are probably great reasons to ignore this minor complaint. 
I dabble in operating system development in Rust, and you often have to use unsafe blocks whenever you’re interacting with hardware or manipulating the processor state in some way. But I’ve never used it in “normal” code.
Yeah, most languages can optimize some tail calls. When people ask for TCO, they're asking for language-level guarantees that tail calls will be eliminated (so that, for example, an infinitely recursive function is semantically equivalent to an infinite loop) rather than compiler optimizations (in which case an infinitely recursive function is still semantically wrong).
It is pretty obvious that a lot of software can't simply "panic" whenever there is a lack of memory. If word or excel did that, you'd not be happy about it if and when it happens. Even if paint or notepad do this, that might be a problem, when it could simply explain that the application is out of memory and that it is time to save and quit. Now if you quickly prototype a tool for yourself, then you might want to panic, because you know that you will never be out of memory, and that it is your responsability as a user not to be. I don't see that being the norm any time soon.
&gt; I'd like the idea of a systems language that supported a hierarchical memory model First you'd need an architecture that supported this. 
Having NULL be a special pointer isn't really natural or aligned with rusts design. We need to have pointers to be able to deal with uninitialized or freed memory, as well as for memory mapped IO, but a pointer that is marked as not pointing to anything at all should really be the None of an Option&lt;pointer&gt;. In practice the assumption that some otherwise normal address (normally 0) is the nothing address makes this horribly impractical, because just about everything is written C of built on top of it.
&gt; and there are plans to do static call graph analysis + other techniques to prevent running out of stack space. (I think it's yet to be seen how well this actually works) That _is_ an interesting goal. However isn't that more or less a halting problem? At least if the language allows recursion. My issue with "Never Panic, always Result" approach is that it easily trivializes Results - turning them into a generic exception system. Rust's compromise between "Usually Result, sometimes Panic" means that Results can be used in places where it is reasonable to expect an error and panics can be used in the obscure cases.
Smalltalk has never required you to "sign up" for a binary code format. Every code snippet you evaluate in essentially any context is immediately logged to a text file in most Smalltalks. The fact that code also enjoys an in memory representation (as well as a few others), which is far more efficient for most operations, does not detract from that. Also, having used many REPLs (though not Clojure's), that is not very close to a Smalltalk. About being too much in its own universe: can't disagree. Having very different main abstractions than the currently dominant paradigm has upsides and downsides both. But I wouldn't knock it till you're sure you've understood the upsides.
That makes sense, thanks!
I use my crate [tmq](https://github.com/cetra3/tmq) to serialize audit events into a backend service (which simply writes them to a PostgreSQL db). This was mainly to support other non-rust apps as well. For normal logs I use pretty-env-logger with runit's svlogd and a simple log file.
If I'm putting a lifetime param on an impl block, why do I have to put it after the \`impl\` and after the type name? For example: `impl &lt;'a&gt; Foo &lt;'a&gt; {` `....` `}` &amp;#x200B;
Only if the lifetime you're specifying is against the struct. For instance it could be against the function of what you're implementing (i.e, via a trait) It's the same with generics: impl &lt;T&gt; GenVal&lt;T&gt;
You may want to have a look at this RFC: https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md
Fair enough, thanks for the correction! I have definitely not spent nearly enough time with it to judge one way it another accurately.
Neat, though it has me wondering whether const evaluation will someday become powerful enough that we might be able to do `const assert!(foo == bar)` and have it just work out of the box.
Part of Piston, AFAICT? &amp;#x200B; [https://github.com/advancedresearch/advancedresearch.github.io](https://github.com/advancedresearch/advancedresearch.github.io)
Ah! that makes sense. Thanks!
I was very pleasantly surprised! What I hadn't thought about going into the first implementation was how much time I was going to save not only allocating, but also de-allocating and re-allocating. Interestingly, the improvement is even more pronounced now that Rust defaults to the system allocator instead of `jemalloc`.
This is interesting- id love to see rust the language on every fucking platform on earth. Rust the game though, and no offense, but I wish they'll change the name or something....
I've been working on Grapl for months now, [https://github.com/insanitybit/grapl](https://github.com/insanitybit/grapl) &amp;#x200B; I have two big things going on this week with it. &amp;#x200B; * Performance * ML Driven Graph Expansion Performance is a problem at the moment - I have extremely unoptimized code. Like, tons of O(n) algorithms that could be O(1), poor table modeling in MySQL, stuff like that. &amp;#x200B; The ML thing is determining which areas of a graph to expand when a node proves interesting. So, like, 'node is clearly malicious' - ok, now show me all of the other malicious nodes... but there's no labels that tell you they're malicious. Instead, features based on graph structure around the node are extracted and used to determine which surrounding nodes make the most sense to expand. &amp;#x200B; Should be fun. Contributors welcome if any of this sounds fun. There are multiple good 'getting started' issues - like I have trial SQL injection, and that's not fun.
I hope something comes out of the Enum variants as types RFC.
Generally we recommend installing via [rustup.rs](https://rustup.rs). Good luck!
Is there a simple map editor? I wasn't aware coding, or programming was involved. haha
For more detailed instructions, try r/playrust.
Is, https://www.rustedit.io/resources/rustedit-1-0-8.15/ safe? lol. 
A added some pretty heavy requests to the wishlist. Realistically I'd be happy with them by 2025, but until then Rust on embedded is a non-starter in my industry.
I also like to see rust on every platform - except my '89 VW van.
This is a subreddit around the Rust programming language, you're looking for /r/playrust
As far as I remember they were actually slow. Like, slower than OS threads most of the time.
The usual way to do things like this is to use [`[T]::split_at_mut()`](https://doc.rust-lang.org/std/primitive.slice.html#method.split_at_mut) to create two mutable non-overlapping slices from one. See also [borrow splitting](https://doc.rust-lang.org/nomicon/borrow-splitting.html) in the nomicon. I've modified the code you linked below to use this: https://play.rust-lang.org/?version=beta&amp;mode=debug&amp;edition=2018&amp;gist=6254ca1faa2af152e740379327dee661 It definitely isn't perfect and could be made simpler, but it should work, and does not use unsafe. In particular I kind of just shoved more variables into the iterator, and if more time was spent they could probably just use existing variables? Key changes: /// Mutable iterator over a Grid2D #[derive(Debug)] pub struct MutGridIter&lt;'a, T: 'a&gt; { owner_width: usize, owner_height: usize, grid_offset_returned: usize, grid_unreturned: &amp;'a mut [T], x: i32, y: i32, ofs: usize, /// distance between end of one span and beginning of another stride: usize, x1: i32, x2: i32, y2: i32, } impl&lt;'a, T&gt; Iterator for MutGridIter&lt;'a, T&gt; { type Item = ((i32, i32), &amp;'a mut T); fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt; { if self.y &lt; self.y2 { // This assumes no out-of-bounds access as the original rectangle // was clipped against the owner extents. // TODO cannot get rid of the unsafe here? // error[E0495]: cannot infer an appropriate lifetime for lifetime parameter in // function call due to conflicting requirements let ret = Some(((self.x, self.y), { let slice = mem::replace(&amp;mut self.grid_unreturned, &amp;mut []); let slice_idx = self.ofs - self.grid_offset_returned; let (elt_slice, remaining) = slice.split_at_mut(slice_idx + 1); self.grid_offset_returned += slice_idx + 1; self.grid_unreturned = remaining; &amp;mut elt_slice[slice_idx] })); // Advance self.x += 1; self.ofs += 1; if self.x &gt;= self.x2 { self.x = self.x1; self.y += 1; self.ofs += self.stride; } ret } else { // out of range None } } }
VST3 isn't actually a COM API, it's more "COM-like" in its design - this is one of those friction points and one of its many flaws. &gt;However given it needed to invoke some of the VS COM APIs, it has also evolved into calling COM through Rust trait That's what I opted to do, and peeking at your crate I think we have the same approach. One thing I noticed I'm doing differently is that all of my C++ wrapping is done in vanilla Cargo with a build script and it can be done in stable rust (but my needs are pretty limited in scope). The only reason I need cargo-make (or something more than Cargo) is because VST3s are bundles with more than just the .dll. The documentation for VST3 is in the [git repo] (https://github.com/steinbergmedia/vst3sdk) (don't forget to use `git clone --recursive`. It's pretty dense. 
It's any full Linux distro [by the looks of it](https://www.samsung.com/global/galaxy/apps/samsung-dex/). Looks like Docker too supports ARMv8 (which I believe the Kyro 385 uses). Your chances are good, if not a ready-made package for your distro of choice, compiling it yourself seems as though it *should* work.
Thanks for the answer.
The author has proposed a number of likely ways to cope with recursion, I suspect the most likely answer will be that a call to a function that the Zig compiler cannot prove is not recursive will possibly produce an error. Zig has an explicit error handling mechanism, it doesn't use sum types so it's not like the language is mucking about with your type signature. I've probably only written a few tens of thousands of lines of Rust but my experience is that the amount of `Result` varies massively depending on what kind of code I'm writing. Numerical simulations have essentially none (they do at startup and shutdown for I/O), but if you want to write a chat client there's `Result` _everywhere_ in the backend... but not the frontend. I also observe that when I get an `Err`, I often have something in mind to do in response. I don't often just return it to the caller which I think is your fear of trivializing things. My experience with big libraries is limited though, maybe the situation is different there if you have many layers of abstraction to get the error through.
I don't understand lifetimes with Box&lt;dyn Trait&gt;. This doesn't work: ```rust struct Blah&lt;T&gt;(T); trait MyTrait {} impl&lt;T&gt; MyTrait for Blah&lt;T&gt; {} fn foo&lt;T: Clone&gt;(x: &amp;T) -&gt; Box&lt;dyn MyTrait&gt; { Box::new(Blah(x.clone())) } ``` When I compile it: ``` error[E0310]: the parameter type `T` may not live long enough --&gt; src/lib.rs:7:5 | 6 | fn foo&lt;T: Clone&gt;(x: &amp;T) -&gt; Box&lt;dyn MyTrait&gt; { | -- help: consider adding an explicit lifetime bound `T: 'static`... 7 | Box::new(Blah(x.clone())) | ^^^^^^^^^^^^^^^^^^^^^^^^^ ``` What lifetime?? The struct takes ownership of the cloned object - so what reference is it talking about? How do I get this to compile? [Rust playground link](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=4d90f5607fb99783784bae1ac467d0f3)
I remember someone on IRC, rust-embedded channel, was able to run on PS2 at least
`T` could be a struct containing a reference, which would have a lifetime you'd have to handle. If you add the lifetime bound `'static` to `T` you say that `T` can't include any non-`'static` references: https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=3e83e01a816599b19452c08933406fbf
Ok, pretend for a second we have Results on allocation failure. What does Word or Excel or paint or whatever do now? After running out of memory on a modern computer, with stuff like page/swap files to handle exactly that situation so those must be full too, what does a program do? What can possibly be done? What would you expect it to do? 
Oh thanks! Is there a way to insert generic lifetime parameters so I don't have to make it 'static? How would I say "I want to return a Box&lt;'a&gt; that lasts at least as long as the lifetime of x.clone()"?
Thanks for sharing! 
Someone should correct me if I'm wrong, but I believe this code would have a problem: for i in my_iterable: println!("{}", i); The compiler would complain that it doesn't know the type of `i`. I *think* it would complain about that even if there's only one `Iterator` implementation available. The alternative would be for it to be a breaking change for a type to add a second implementation, and I think "adding impls is a breaking change" is the sort of back-compat hazard that the Rust designers tried to avoid.
What was the interop issue? Posix/OS threading? 
Doesn't prevent you from having to wait while it downloads them
Hyper is serious rocket-science (as opp to Rocket, which I also _loved_). Warp is the framework on top of Hyper by the original author, and that's what we use now.
Thanks for noticing! I added some information.
My brain must be miswired, because I didn't think about the 99% at all when seeing the title.
Maybe [JAMstack](https://jamstack.org/) is a bit of a hype right now, but I do use [Static Site Generators](https://www.staticgen.com/) for quiet some time to create my web pages. So far I have been using [Jekyll](https://jekyllrb.com/), but I really wanted to use **Rust** instead of **Ruby**, so I started investigating [Gutenberg](https://www.getgutenberg.io/). I also registered a new domain for a Rust project of mine, which deserves it's own **web page**: https://www.rs-pbrt.org/about/ Not much there yet, but it will be filled with content over the next few month. Hopefully at the end of the year I gathered all the information about things I have already implemented around the **Rust based PBRT** implementation and then I will post a **Call for Participation** [here](https://users.rust-lang.org/t/twir-call-for-participation/4821) ... ``` github/rs_pbrt &gt; ../onefetch/target/release/onefetch Project: rs_pbrt ` :y.`yy`.y: ` Language: Rust -``MNsNMMNNNNMMNsNM``- Authors: Jan Walter ` -MMNMMMMNNm``NNNMMMMNMM- ` `NNNMMMdo:` `+md/ `:odMMMNNN` Repo: https://github.com/wahn/rs_pbrt.git -ssNMMNo. .oNMMNss- Number of lines: 41840 `mMMMMNmmmmmmmmmmmmmmmdy+` `sMMMm` License: GNU General Public License v3.0 only `mMMMMMMMMMMMMMMMMMMMMMMMMMN/ hMMMMm` -oMN-:Ny:mMMMMMm oNMMMMMm oN::MMo- .yMMMhhh+ dMMMMMd:::::+mMMMMN/ odyhMMMy. -sNMMy dMMMMMMMMMMMMMMMMs` `yMMNs- -sNMMy dMMMMMNyyyydMMMMMMy .odMMNs- .yMMMm dMMMMMh +MMMMMM+ sMMMMMy. -oMMMMMMMMMMMMMMMMM+ mMMMMMMMMMMMMMo- `mMMMMMMMMMMMMMMMMM+ :NMMMMMMMMMMMMm` `mMMMm `-:o+:/mMMMm` -ssNMMMyomo smohMMMNss- `NNNMs+mN/-` `-/Nd/yMNNN` ` -MMNMMMMMNmmmmNMMMMMNMM- ` -``MNsNMMNMMNMMNsNM``- ` :y.`yy`.y: ` ```
I wrote a [logging system for sozu](https://github.com/sozu-proxy/sozu/blob/master/command/src/logging.rs) that reproduces parts of the log crate, but allows at the same time to use env\_logger-like logging levels, and a custom format string, without introducing too many allocations. It can separates access logs from normal (errors and such) logs, since access logs are generated at a heavy rate and can drown the rest. It can send logs to various backends, like stdout, syslog, TCP, etc. An important part of the design was that each process can send its logs individually, and we let the log aggregation system sort it out. Having the master process aggregates log would have killed performance.
I second this, used these two to get debugging for Windows MSVC working after following [this blog post](https://www.brycevandyk.com/debug-rust-on-windows-with-visual-studio-code-and-the-msvc-debugger/) on it.
how much of the extra complexity is behind an abstraction layer presented by the hardware though. What I *am* acutely aware of from low level optimisation is the importance of cacheing - and certainly C/C++ is misleading in that you get the impression all memory is equally accessible - but equally attempts to make alternate machines that expose this (software managed scratchpads memory with DMA transfers have proved unworkable for complex software (ok for finely tuned kernels , but there's a whole middle ground between 'high level UI' and 'low level kernels' that it turns out is just really hard to do without caches). Anyway I do also agree tweaks to make dealing with cache efficiency easier are possible. JAI addresses this with some features that make it easier to chop and change data between different component pointers (which is driven by empirical profiler feedback rather than architectural design), without needing to extensively refactor code
&gt; Given that, I am curious about how much better Rust theoretically &gt; could have been &gt; by neglecting C compatibility. C is very old; there are many design decisions that can be modernized/ improved upon. Rust demonstrates this. The answer won't be very useful if you are not familiar with C or with Rust. Rust is not C. Rust has a C FFI, and there are ways to pass data and call functions from some C implementations, but not from all. So in a sense, Rust is not C compatible, and if you want to get technical, no C implementation that exists today is C compatible either. It's all a wide range of greys. 
some good answers reveal even non-systems langauges have "C compatibility" - the ability to call (and even expose) C functions does not itself constrain the language; it is rather the choices of a systems language that mean *the rest of it* is quite close to the C model anyway. The safety is compile-time assist dropped at a certain level in the compiler, and there's just an issue of name-mangling to deal with polymorphism
I find `unsafe` much easier to use than C.
C is less verbose than Rust's unsafe
There's a gitter channel: [https://gitter.im/gtk-rs/gtk](https://gitter.im/gtk-rs/gtk) &amp;#x200B; There's also an IRC channel on the [Mozilla server](https://wiki.mozilla.org/IRC) (#gtk-rs) and another one on the [GNOME server](https://wiki.gnome.org/Community/GettingInTouch/IRC) (#rust).
Are you using rayon for your multithreading? I'm really surprised that you needed to use unsafe. 
Both languages tend to do their best at inter language interop using C interfaces so I would start there. Next you mention not just using returns but you also don't mention what strategy you planned to use to synchronize your threads. Assuming some sort of work and results I would add methods to push requests to say Rust and to push responses to say C++ (or visa versa). This will allow you to not have to worry about interlanguage in memory interop. Alternative would be to share some pointers and decide on a locking mechanism for the concurrent access. This might not involve a lock such as "only access in callbacks" or a method that signals you are done with it.
Is the example provided in the Readme supposed to be a simple example or a complex one? The deep indentation makes it look quite intimidating, and most the "action" seems to be cloning, so it is hard to tell where the main logic is 😐.
A slightly different workflow to consider: 1. In `poll`, do something like the below: ```rust let bytes = match self.receiver.try_recv() { Ok(t) =&gt; t, /// Other branches stay the same... }; // Ask for a new chunk, some sort of backpressure handling as well I guess... self.signal_sender.send(Signal::GetNextChunk); Ok(Async::Ready(Some(bytes)) ``` 2. In the event-polling thread, do something like: ```rust for _get_next_chunk in self.signal_rx.recv() { // For each chunk that is requested event_poll.poll(&amp;mut events // more stuff); let mut received_bytes: Vec&lt;u8&gt; = vec![]; for event in events.iter() { // append any read bytes to receive_bytes } if !received_bytes.is_empty() { stream_tx.send(received_bytes); } } ``` 3. Remove the `stop` method and the `thread_handle`. When a `ByteStream` goes out of scope, it will drop it's `signal_sender`, and the `for _get_next_chunk in self.signal_rx.recv()` loop will stop, along with the thread in which it runs. 
&gt; However isn't that more or less a halting problem? At least if the language allows recursion. Note that the halting problem is only an issue if the language is partial, you can still do things with a total language. ATS requires proving (to the compiler) that recursion always terminates for instance, that doesn't necessarily mean the language is useless (though it's not for the faint of heart)
That segregation is pretty much a C and UNIX way of compiling and linking. Other platforms and languages did have better toolchains already at the time. For example, watch Rob Pike's talk about history of UNIX and how productive he was with PL/C on an IBM 360.
Most of them are to satisfy the deprecations and will be removed in the future.
Rust unsafe has generics, references, tagged unions, pattern matching / destructuring, ... Rust unsafe is infinitely less verbose than C, and much safer too. 
You also have to have the namespaces and cgroups functionality enabled in the kernel. And root access.
This is a medium example. For more complex logic, you would probably rely on macros. However, macros do not show how the library works. For a more simple example, see: https://github.com/advancedresearch/linear_solver/blob/master/examples/walk.rs
I do need the `y` variable (the iterator needs to return the coordinates of the grid cell and a reference to its contents `((i32,i32),&amp;mut T)`), but had left that part out for simplicity Calling `iter_mut` only once would be a possibility, my iterator could wrap vec's iterator and `.skip` as needed. Hadn't thought of that, I imagined generating a separate iterator per row, for some reason. Might try that later. At least we have it working now using @daboross `split_at_mut` based approach!
Thanks, that's really awesome! Looks like the trick that I was missing in my own tries is the `mem::replace` causing the lifespans to overlap.
Wow, that's ugly? Am I missing something?
For Linux on DeX? So it's not just a hypervisor? It sounded like a hypervisor. [Oh... "A modified version of Ubuntu"](https://news.samsung.com/global/linux-on-dex-will-make-it-easier-for-developers-to-code-on-the-go). Looks like you could be correct, I had anticipated it sharing the hardware (to perform the "use it like a PC" spec, with a hypervisor, the Ubuntu portion essentially being a VM). That seems like a backwards way to have gone with it, does it not? A hypervisor with VM capability would surely be of more use and I don't foresee any security issues there, just don't share the drive, partition it off for the VM.
I can imagine you request certification. Why would we pay $10k+ licence on AdaCore while it would be offered for free by rust...
Thanks for your reply.
For Docker. I mean, makes sense for Linux on DeX to also be just a container — most people don't *need* a good modern mainline kernel specifically, just a desktop userspace environment. I wish KVM would've been available on Android. Unfortunately, KVM doesn't work, as there's already something acting as hypervisor on Android, before the Linux kernel boots.
You'd need root to launch a VM anyway. The reason I wanted KVM is to run FreeBSD :) anyway, maaaaybe the situation is different on non-Qualcomm phones? (I tried a KVM enabled kernel only on a Nexus 5X)
I've updated the example with comments on the inference rules. I hope this makes this easier to understand what is going on.
Interested in this as well. I have a Rust library which I want to export a C ABI library, which is used to use lib items in C/C++ (enums, functions, structs, etc.), then I want to use the same Rust library in the rest of the application as a rlib. The point of this library is to allow creating C ABI extensions to a larger application.
Sure this is not a safe API in C++, but it's definitely better than the std version of it. Since the project I'm working on is not in rust, so, probably that's the best I can do.
I wish there was a way to vote on the github repo. 
Shameless plug: as a contributor of ratel, I made a list of JavaScript related tools in Rust: https://github.com/ratel-rust/ratel-core/issues/99 If you are interested in web development tools, come and join us! The current state is that a few people are working on their own implementation without collaborating, and I look forward to having more people collaborating on one project.
I find `panic!` preferable in libraries when it makes no sense to handle an error. Take for example the [construction of a square matrix from a vector of values](https://docs.rs/pathfinding/1.0.4/pathfinding/matrix/struct.Matrix.html#method.square_from_vec). What would be the logic in using a `Result` there instead of a `panic!`? Why expect that the ilbrary user will handle the `Result` when it can't provide acceptable arguments to the function? The reasoning is the same for [matching in a bipartite graph](https://docs.rs/pathfinding/1.0.4/pathfinding/kuhn_munkres/fn.kuhn_munkres.html). Having more rows than columns would make no sense at all, why recover gracefully when it should never happen in the first place?
This is indeed one of the best summaries.
I don't think anything would be different about Rust's design if C compatibility wasn't a concern. This includes tail calls - honestly, C compatibility isn't a problem here, if anything `before` code could be designed to not work for `extern "C"` functions. Likely the language wouldn't have `extern` keyword and `CStr`/`CString` types, but that's about it. Most of C impact is seen in fs/io modules, but this isn't about C compatibility, but rather because the operating system (well, Linux) sort of speaks C - expects null terminated literals, and so on, and Rust has to interact with that. Even if Rust wasn't compatible with C code, it still would need to interact with an operating system.
May I suggest you to add this example in the README? It's much easier to understand and it helps to get the medium example. 
This is unrelated, but are you seeing [the same thing I am](https://i.imgur.com/evvXlQA.png)? Why is the generated code doing multiplications and shifts? [The playground](https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2015&amp;gist=8a7024327c2c0d700dbb93e3858645b9) also shows the same generated assembly. If I change `num - 1` to something else like `num - 10` the code looks sane again. Is llvm screwing the pooch here, or am I not seeing the whole picture?
I would be that person, hello!
This is a great article. Has it been posted/discussed on reddit before? I'd like to see the discussion.
I use [slog](https://github.com/slog-rs/slog). My logging middleware creates a Logger instance, giving it some contextual attributes such as a uuid request_id. Then, the logger is saved in a registry that is accessible from every endpoint. An endpoint gets a reference to the logger, creates its own local Logger instance, adds more context, invokes logging, and so forth. This process of creating a Logger, adding context, and logging wherever, continues through the entire process. Note that people are working on standardizing a structured logging solution for Rust stdlib, potentially deprecating the need for the slog crate. There's an RFC: https://github.com/KodrAus/log/blob/rfc/structured-logging/rfcs/0000-structured-logging.md#why-do-we-need-structured-logging-in-log
:) I think you posted in the wrong subreddit. This is for Rust the programming language.
!!! That's another interesting thought experiment: What would modern languages be like if ASCII hadn't been the basis of all symbol selection for programming? Something like [APL](http://archive.vector.org.uk/content/printed/251/saigusa/image001.jpg)?
Really you need some kind of extra support in the allocator runtime to handle this. Allocations could be marked as temporary or cache, or whole objects (e.g. documents) could be marked as "without current focus" and serializable to disk. Then when you run out of memory, there is some flexibility to get some memory back from somewhere. OS swapping is unhelpful here, though, which is why I prefer to run without it. Cluttering the code with allocation error handling everywhere wouldn't be much help, though, IMHO. There needs to be some layer above the allocator to handle this. However asking for 9999GB is a bug and is always going to fail, so what else can you do but panic in that case?
I think the lack of a member deref `-&gt;` operator is enough to make writing FFI feel a bit verbose.
Is there any crate to read and display a PDF?
Thanks for the tip! Example is now added. I also simplified it, because one only needs to check the `cache` instead of iterating through the facts.
&gt; Why expect that the ilbrary user will handle the Result when it can't provide acceptable arguments to the function? Because the library user might not be fully conscious every time he's using a partial function, and the library could choose one of two perspectives: a) The user is human, which tires, can face pressure to deliver and so on and might not realize something that is apparently so obvious when you stop to think for a second. b) Their fault for not being 100% attentive at a concept so simple to understand; as simple to understand as that you can't access an array index beyond the array's length, that a pointer can be null and you must check it before dereferencing it, that data shared between threads must have its access synchronized accordingly, etc.,... With that said, dependently typed languages help you catch bugs like this, and languages without such tools can opt to model their parameters as a type whose constructor validates the parameter; but the former is not the case for Rust (nor any mainstream language) and the latter is usually more inconvenient than just validating in the function call and returning a Result for the operation, so we opt for just that.
We could have a more ML-y syntax instead of something that requires curly brackets and `&lt;` `&gt;`. :-P
Yeah... I think this is one of those bots that goes around posting text stolen from blogs for... some reason. Copy a bit, pop into Google, see what happens.
There's discussion [here](https://www.reddit.com/r/rust/comments/8gj4go/c_is_not_a_lowlevel_language_acm_queue/) and [here](https://www.reddit.com/r/rust/comments/8g9y8x/c_is_not_a_lowlevel_language_is_rust/) :)
I would not recommend using Rust for machine learning currently due to a lack of libraries for that. Some smaller groups of libraries are also only bindings to C ones (like ffmpeg) and have no complete native bindings, though I would still prefer the C bindings over having to use C or C++.
Won't the PS5 be out by the time this would be ready?
I love that article too! I don't see how interrupts as first class citizens would be useful for anything other than writing operating systems. And even then the semantics of interrupts varies enough based on the hardware that I'm not sure encoding them in the programming language would be helpful. I may be wrong, but interrupts are *hard* to reason about, that's why we cover them up with things like async I/O. I do agree that a more explicit representation of things like branch prediction and speculative execution in assembly language would be nice... Itanium did this, and it's really interesting. But it also causes problems because you end up with things like "this chip has 2 integer execution units" being expressed in the assembly language and then when the next chip of the series has 4 execution units you have to change the assembly language or paper over the differences anyway. See branch delay slots in MIPS and such, as well. Assembly language is not a model of the hardware anymore, it is an **API** for talking to the hardware. Turns out the PDP-11-style API is pretty good! I'm sure it could be better, but some level of abstraction *away* from the hardware is also very useful.
I use esprit for parsing Javascript in a project of mine. It is solid.
There's always image-based systems like Lisp and Smalltalk. Essentially you have a running system, and if you redefine a function the compiler just plops the new function in memory somewhere and updates pointers referring to the old function to point to the new one instead. (Usually with a bit of extra fanciness to make this operation efficient.)
It's important to note that if there is ambiguity, the compiler will force you to specify which impl you are using read() from. For code readers, the IDE should help in showing what read() is called.
In Rust traits can have "blanket impls" which implement a trait on things that satisfy certain conditions. Also, in the case of the above post, there are also default methods. Iterator is an example of a trait where just defining next() gives you tons of default methods and blanket impls all over the ecosystem just with one method.
I hoped to find a book too!
I've lately tended to use the `log` crate with `fern` doing the processing and output. `slog` is also nice but I usually don't have the inclination to get fancy enough to make it worth it; YMMV.
I would leave the nomicon for later, maybe for the time you want to implement your own mutex with some unsafe code. Start a small project, have some fun!
Linux on DeX is based on lxc containers. That seems far more efficient than a VM. Not only do you get to share disk space, but you share a kernel as well. I don't think a phone is well suited to be doubling the OSes.
I added one basic test to the internal credit moving logic of Offst (Decentralized payment system), here: [https://github.com/freedomlayer/offst/pull/122](https://github.com/freedomlayer/offst/pull/122) it took pretty long time, as many bugs had to be fixed on the way. During this t ime I had my first stack overflow with Rust. I learned about it's reason in this issue: [https://github.com/rust-lang-nursery/futures-rs/issues/1330](https://github.com/rust-lang-nursery/futures-rs/issues/1330) &amp;#x200B;
Is there anyone working on a Rust implementation of TypeScript? Webpack with Babel and TS is agonizingly slow but I would still take a 5min transpilation time with types than 20s without.
&gt; I expect some operation (let's say typing a word) to fail You'd probably be screwed if an allocation that small failed anyway. On the other hand, if say Photoshop shat itself if it failed allocating the storage for a new layer of giant image, instead of popping up an error dialog saying "sorry there's not enough memory left for that" and aborting the operation... yeah I don't understand this "you can't handle allocation errors EVER don't even bother to check OVERCOMMIT RULES!!!1" mentality
Thank you, that's very helpful!
There's [an IRLO thread about Gamedev WG proposal](https://internals.rust-lang.org/t/a-working-group-for-rust-game-development/8240).
I recently created a type with a similar purpose: [https://github.com/bluejekyll/trust-dns/blob/master/crates/proto/src/serialize/binary/restrict.rs](https://github.com/bluejekyll/trust-dns/blob/master/crates/proto/src/serialize/binary/restrict.rs) &amp;#x200B; I really like the feature of the guard you put in place, it feels more general purpose. Really cool, idea.
There was this post yesterday: https://www.reddit.com/r/rust/comments/9wrtgs/asyncawait_status_and_tracking/ In general, if you want to be future proof, you should be using `std::future`. It's up for stabilization right now. You may or may not have to tweak some things depending on how the discussion goes, but that's the end of the road for this stuff.
Good point. I've never really used italics that way, but I'll consider using it. Small nitpick: we're not writing "in English". These letters we use regularly are of the "[Roman alphabet](https://en.wikipedia.org/wiki/Latin_alphabet)". To see just how poorly fitting it is for English, check out [Unibet's introduction to English speakers](http://shwa.org/english.htm) and see how [Unibet has each of the 44 sounds we need to write English](http://shwa.org/picturealphabet.htm) clearly and now has an easy method to learn the vowels with [Vowel Nicknames](http://shwa.org/learningaids.htm).
Egyptian hieroglyphs 32 c. BCE
If you plan to use register windows then you will want more registers, so that is a reasonable decision. Just make sure the windows are not too big to decrease instruction size. I also don't entirely know what you mean by 32 wouldn't be enough for a language. Keep in mind that registers only need to hold whatever is actively being used, while other memory can exist on the stack and heap. If you intend to put object pointers into your registers and operate on them directly, making the VM type-aware, then even less registers will probably be used. Maybe it would benefit you to do an analysis of how deep in the stack Java methods typically reach in the JVM, as that may give you a better idea.
CHR is an abbreviation for ["constraint handling rules"](https://en.wikipedia.org/wiki/Constraint_Handling_Rules) which is one of the worst language names. But the language has some very fresh ideas. Think of it as a performant prolog that takes advantage of linear logic to get around the limitations of prolog. I invite you to check the language out, you won't regret it.
Well, if panic, it wouldn't even pop an error dialog, would it ? Or does panic pop up dialogs ?
 [Here's the /r/programming ](https://www.reddit.com/r/programming/comments/96yz21/c_is_not_a_lowlevel_language/) discussion. People got a little hung up on the title, not the points in the article. 
With FFI, or in my OS project. I can't remember ever needing it outside of that. Maybe something small that I just don't remember.
But what if I want to store locals in registers, couldn't it be faster than storing locals in HashMap and then accessing it? I already created a very simple math expression evaluator: [link](https://github.com/playXE/Jazz/blob/master/simple_jazz/examples/math.rs) and if there is a large expression, the registers may not be enough, how I can solve it?
Not inherently, but that's likely how it'd be handled in a GUI.
Can you easilly override the default panic behavior ? Or does "panic" design something else ?
you may want to look into the [`nom`](https://docs.rs/nom/4.1.1/nom/) crate for abstracting away a lot of the boiler plate. 
On the interrupt point, assume we have an OS that can deal with this. What I'm imagining is a mental model of a program as a list of interrupts. No main function or assumption that your code is running in a vacuum, no thread abstractions. Just the ability to list processes to the OS. And you could do some cool things with it, for example we could have a functional style program where the main entry point would be an interrupt that takes the current state of the program and returns the next state. We could request the OS to schedule interrupts with hard or soft real time requirements, which would be great for games and multimedia. We could have our program driven by UI interrupts rather than relying on messages sent after polling. I don't think interrupts are so semantically different across platforms that they couldn't be wrapped in language semantics, since most of the difference has to do with linkage and memory mapping. Now all that said you could build an OS that does this today, or write a runtime in C/C++/Rust that wraps the program and provides this as an abstraction. But what I'd like is the ability to notate a function as an entry point/interrupt in the language, and not have to write a ld file. You can *kind of* do that in Rust right now. 
Very late response (I never seem to see responses for ages!): my goal is to have a single executable that you can run probably on a trusted intranet (eg inside an organisation) that provides a very simple way for people to share files with each other via the web interface that it exposes. In mine, files are streamed straight from one user to another and are not stored on the server at all, emphasising the goal of sharing (and I had in mind that this could run on a very tiny VM or something without much care for space etc if desired). &amp;#x200B; [https://github.com/jsdw/streamer](https://github.com/jsdw/streamer) is the github repo for mine. I've done a first pass over the backend but I have become somewhat distracted and haven't created the frontend yet :) I will get back to it though! &amp;#x200B;
Ooooh, I see what you mean in terms of an interrupt system then. That DOES sound interesting! I bet you totally could do that, current systems just make you use callbacks and do the wiring around it yourself. And then the problem basically becomes "how do I do this efficiently and with low latency without polling", which takes you into `select()` and all the things that descended from it. Though callbacks aren't always nice to work with either... If you have a way for a function called from an interrupt to raise another interrupt, or the equivalent, then you have a communication method between parts of the program that is a lot harder to inspect. You either don't have stack traces that can cross interrupt boundaries, or you have the OS do a lot of work to be able to trace and interrupts and provide that information on demand. You have to be able to answer the question "ok I got event FOO in this part of the program, but WHY did I get that event?" I am not an expert in such things, but my understanding is that lots of JS was written that way before the more modern promise-based systems evolved. Actor-based systems like Erlang avoid this by removing the ability of interrupts to be "global" and requiring all messaging to go through explicit channels. I think writing an OS or such that did this sort of thing, even a toy or emulated one, would be the first step, then we can ask more questions about "how should languages make this easier".
I don't understand what you mean.
&gt; Then when you run out of memory, there is some flexibility to get some memory back from somewhere. How do you guarantee *you* get that memory back and not one of the many *other* programs on your computer who need memory? The entire system is in desperate need of it, after all.
If you don't have enough memory for a single character byte where is the memory for an error message window coming from? It can't tell you anything other than a static str, because then it'd have to dynamically create a string, and you don't even have enough memory for one character in your example. &gt; i expect that it would let me save ...and if that needs memory? Who says it has zero allocation serialization to whatever format it saves to?
So your solution to running out of memory is... display an error and then pretend you didnt run out of memory by continuing to run? How does that work?
Another solution would be to make Result a 3-variant enum with a variant for the case which is currently covered by panics...
I really like this. I have a project I have been working on that this will be useful in cleaning up a lot of code. When I get some time I'll take a closer look.
Anyway, this is an vaguely related article at how D, Go, Rust are positioned: [https://www.quora.com/Which-language-has-the-brightest-future-in-replacement-of-C-between-D-Go-and-Rust-And-Why](https://www.quora.com/Which-language-has-the-brightest-future-in-replacement-of-C-between-D-Go-and-Rust-And-Why)
Ha woops, that was bound to happen eventually. I edited the braces back in :)
I don't read Graydon's email as saying that TCO cannot be implemented as C interop. C does appear multiple times his reply, but never in terms of compatibility. &gt; Tail calls also "play badly" with assumptions in C tools, including platform ABIs and dynamic linking. rustc leverages C tooling, which does not play well with tail calls. It would be possible to develop Rust specific tooling; it would also be expensive. &gt; Tail calls require a calling convention that is a performance hit relative to the C convention. It would be possible to use a calling convention that enables tail calls; it would also cost performance wise. &gt; We find most cases of tail *recursion* convert reasonably well to loops, and most cases of non-recursive tail calls encode state machines that convert reasonably well to loops wrapped around enums. Neither of these are *quite* as pretty as the tail-call-using variants, but they do work and are "as fast", as well as idiomatic for C and C++ programmers (who are our primary audience). It is not necessary to use tail recursion, although it would be prettier.
Focusing on just the error you're getting: It basically tells you what the issue is: You have some bytes, which you want to turn into a `String` using `from_utf8`. The problem is that your bytes are _not_ valid UTF-8. So you'll want to change your code to handle the error more gracefully, could be as simple as replacing the `.unwrap()` with something like `.unwrap_or_else(|_| "INVALID".to_owned())` &lt;sub&gt;Warning: code not tested&lt;/sub&gt;.
**This!** I think that the greatest pressure that C has had on Rust design is simply that *the current crop of computer architectures caters to C*, and therefore for performance reasons Rust has to reasonably approximate C. A great example is the handling over integer overflows on x86 for example. x86 sets a *flag* on the CPU in case of overflow. This is the hardware equivalent of setting `errno`, and makes it very difficult to implement high-performance overflow checking. An architecture which throws x86 out of the window, such as the hypothetical Mill CPU, has more latitude. In the Mill, you can simply poison the result, which indirectly poisons anything it comes in contact of, and the error is deferred to actually trying to use the value, at which point a trap handler is called which could panic. Thus, on the Mill, there's no runtime penalty to enable overflow checking. It just works. *Note: there may be performance changes from the optimizer, though, as overflow checking operations are not commutative nor associative, possibly inhibiting certain optimizations while at the same time restricting the possible range of values possibly enabling others...*
ups. Explicit, not Implicit.
&gt; 10x better theorists. Of the three, Rust is the only language with world-class PL theorists on roster. This can be seen in the precise definition of the language and the depth of its technical approach. Seriously? Does Rust have (full-time) progamming-language-researchers?
Oh hey! I really liked JDBI.. its been a while.
&gt; 1b37373331363f78151b7f2b783431333d78397828372d363c78373e783a393b3736 I solved it by changing this for s in vec_bin { let mut vec_utf8: Vec&lt;u8&gt; = Vec::new(); for i in 0..(s.len()/8) { vec_utf8.push(bits_to_int(s[(i*8)..((i*8)+8)].to_string())); } vec_plain.push(String::from_utf8(vec_utf8).unwrap()); } to this for s in vec_bin { let mut vec_utf8: Vec&lt;u8&gt; = Vec::new(); for i in 0..(s.len()/8) { vec_utf8.push(bits_to_int(s[(i*8)..((i*8)+8)].to_string())); } let mut tmp = String::new(); tmp.push_str(&amp;String::from_utf8_lossy(&amp;vec_utf8)); vec_plain.push(tmp); }
Mmm, fair point. C interop is not specifically mentioned.
I hope so. ;-) But anyway, the ownership model and type inference in Rust involves more PL theory that can be found in other imperative style languages (that I know of).
How much do you understand how function calls work in assembly? 
Hey, if you want, I can collaborate with you on this project. I'm not a rust developer, but I am a database performance engineer and I can give a lot of insight on how this can work faster with the database. jonathanvx on github.
Thanks for the offer! I'm certainly open to suggestions, issues, and pull requests. However, this library defers pretty much all database interaction to the \`mysql\_async\` library. The bulk of the code here is around proc\_macros, with a thin query interface layer to work with \`mysql\_async\`.
I go for diversity. I've believe most of the creativity in game designs happens at higher abstraction levels than system-language level.
Well, obiouvsly, you either should have already allocated the memory you need for those scenarios, or you should anticipate enough over the redouted situation, to tell the user well before that point that something is off. What you probably shouldn't do, is to hardcode some panic that doesn't display any message, and just write somewhere in an obscure documentation that "whenever there is not enough memory, the thing might shutdown itself, withouth warning or anyway to know what was going on". At the very least, you need to log something somewhere. Man software developpement seems hard.
I think one point of making an interrupt a "first class citizen" would be to discriminate one as *not* just a function, and make calling an interrupt a compilation failure. I guess what I'm envisioning is constrained Actor-model (forgive me I'm a EE, so my work is very outside language theory so I'm not familiar with many languages). But I don't like thinking in events and messaging, since for a GP low-level language those should be handled by libraries or an OS. So picture language/compiler semantics that reflect how an embedded DSP is programmed - finite number of entry points (interrupts), each interrupt has its own state, no interrupt can call any other interrupt (they aren't valid functions within the binary), all interrupts share the same address space, and users can create any futures/promises/channels/whatever to communicate state changes to another interrupt through the address space. Another difference that would be cool is that instead of the concept of forking a process into parent/child, but reporting back to the OS that you need it to trigger another program's interrupts for execution. Another way to look at an interrupt driven program is that it wouldn't just have multiple entry points, it would have multiple exit points. So say you need to package your binary with a daemon - you can have a daemon interrupt always running, and starting up another interrupt that interacts with the daemon doesn't require them to be in separate address spaces, eliminating the need for IPC. 
There's been some talk of this for various reasons. As you note, it's got pros and cons. If you want to see the current state of the discussion, search for "cargo-aware std".
https://doc.rust-lang.org/stable/std/collections/struct.LinkedList.html#method.append
You almost entirely want to use `Vec&lt;u8&gt;` instead of `String` and `&amp;[u8]` instead of `&amp;str` for cryptopals. They don't operate on strings, but on bytes.
What I meant to say was that it is not clear that Haskell's extra expressive power compared to Rust is worth it given the completely different mindset you have to have when writing Haskell; that is, perhaps Rust is already good enough at expressing common type-level constraints while still being pretty approachable.
What exactly, using four spaces for indentation? My guess is consistency, and it gives you more ways to align things without having to worry about other people's settings. 
Yeah, LinkedList could implement a bunch of stuff but doesn't, because it's so rarely used.
Would you ever use `get_char_unlocked()` though. I imagine the OS provides some syscalls for fast bulk reading - something like `fread()`.
Thank you for this work! This is really cool. I hope to be able to use it soon. One question I have: &gt;Once the underlying Rust feature that enables this What was the underlying Rust feature that allowed you to have a workaround to the unique labels? &amp;#x200B;
Just for reference, here's [a link to the RFC discussion](https://github.com/rust-lang-nursery/log/pull/296)
thanks, I've found [rust-embedded-wishlist](https://github.com/rust-embedded/wg/issues/256#issuecomment-438663318) and [Make Cargo aware of standard library dependencies](https://github.com/rust-lang/rfcs/pull/1133)
In the contests I've been in the time limits were generous enough that as long as you had a good algorithm a relatively inefficient implementation will do just fine. You can read/write the entire thing as a single string if the input/output isn't huge and you're worried about the overhead of many small i/o operations.
Count me in - if this Game dev WG spins up, I'm in to help get things done. I've got plenty to learn to be super useful, but I can definitely bring some sweat &amp; some perspective ;)
Docs link: [`io::Stdin::lock()`](https://doc.rust-lang.org/std/io/struct.Stdout.html#method.lock) The method returns a `StdoutLock` value that unlocks automatically when it goes out of scope.
Where did you read this?
&gt; Well, obiouvsly, you either should have already allocated the memory you need for those scenarios, ...allocate memory for the scenario where you can't allocate memory? And if/when that fails? &gt; to tell the user well before that point that something is off. How do you know something is off? On linux, overcommit, on windows, paging, and all the other programs. What happens if the user, or operating system, closes or pages out enough inactive memory between your bad error message and actual use that there isnt a problem anymore? &gt; somewhere in an obscure documentation that how dare a language and it's behavior need to be documented, and how *dare* you make me ***read stuff***. ---- The fact is, if you run out of memory it means one of two things: 1) Your code is bad and you should feel bad. Using arbitrarily large amounts of memory based on user input? Thats your crappy code. 2) The user ignored your documented\* memory requirements, so they're bad and ***they*** should feel bad. \* Unless, of course, your program is small enough it doesnt need them documented. Only using a few MB? If you run out of memory at sizes that small the user has bigger problems, if their system is even responsive. In my experience windows freezes up in situations like that(debugging out of control memory leaks is fun!) Word processors and image editing tools, for example, handle this by having a reasonable setting of maximum memory usage, for stuff like (in memory) caches. Usually user configurable. Word for example seems to have a 512MB file size limit, VSCode defaults to a 4096MB limit, [photoshop defaults to 70% of available RAM](https://helpx.adobe.com/photoshop/kb/optimize-photoshop-cc-performance.html#preferences) Running out of memory is not a recoverable error. It means your code is bad, or the user is bad, and in either case theres nothing your program can do about it.
I had this problem, as well, either C++ couldn't see the rust code, or it was a library for C++ and the second rust project would also need to be a wrapper, which defeats the purpose.
[Here.](https://doc.rust-lang.org/book/2018-edition/ch01-02-hello-world.html#anatomy-of-a-rust-program)
I meant database best practises for performance, not C level hacks to interact with the database.
Make sense. Thanks....
You can ensure that every byte stays a valid ASCII value by never setting the highest bit. Only test keys in the range 0x00 through 0x7f. If every byte is ASCII, then it's automatically UTF-8 compatible.
Are you sure it wasn't a reference issue? That is, are you sure that x\_val's type wasn't \`&amp;u8\`?
How big are we talking about? Have you considered moving them out to a file and using the ‘include_bytes!’ macro? 
You're looking for /r/playrust.
I'm glad you asked! The feature I require is [`underscore_const_names`](https://github.com/rust-lang/rust/issues/54912). Internally some of the macros do `const _: T = {...}`, which allows for evaluating the `{...}` on the right-hand side of the useless assignment, and benefiting from the side-effects of its contents. For example, look at [how `assert_eq_size!` is implemented](https://docs.rs/static_assertions/0.3.1/src/static_assertions/assert_eq_size.rs.html#64-66).
I prefer tabs too, but if you program in a particular language that has certain conventions you might as well stick to those, especially for projects where you expect to collaborate with others.
I think this linked list implementation might do what you need: http://contain-rs.github.io/linked-list/linked_list/ . See the Cursor docs. A week or so ago I saw some discussion on an RFC to add similar functionality to the standard library.
The requested operation can't take place due to lack of memory, but staying in the state the program's already in shouldn't require any memory. This should allow the user to close down something else using the memory and the continue.
Oh, no, they're not THAT large, something like `1162626336`. They're too many to externalize... it's really just a formatting issue, I don't want those separators, but I can't manage to deactivate the lint. (e) I mean, [this](https://github.com/KillTheMule/nvimpam/blob/master/src/card/keyword.rs) would be one of the files in question, if you're curious. 
We have 3 levels of stdlib though. level 1: `prelude` (`Option&lt;T&gt;`, `Result&lt;T,E&gt;` and a few more) level 2: `core` (Anything that is platform independent) level 3: `std` (Other stuff) So what you were saying is basically putting more things to `prelude`. I am neutral on this; I believe there are a lot more facilities should be there like `Cell` and `Future` etc.
This is also offtopic for playrust, they want /r/playrustservers.
&gt; There have already been several vulnerabilities in Rust and Cargo as well, so the safety is not really an argument. This again? "Your shield only stops 90% of bullets so we might as well not use it"
I was afraid of that. The official introductory Rust book is definitely the wrong place to peddle any portion of a style guide.
You can also try using the cpp crate: https://github.com/mystor/rust-cpp You can call C++ from your rust crate with the `cpp!` maco, and you can then callback rust from that C++, using the `rust!` macro.
the “lossy” in `from_utf8_lossy` means the bytes that are invalid UTF8 will be replaced with the [U+FFFD REPLACEMENT CHARACTER](https://doc.rust-lang.org/std/char/constant.REPLACEMENT_CHARACTER.html). This will change your data! I don’t think this is what you want. As others have mentioned you’re handling raw data and not strings so `Vec&lt;u8&gt;` is more appropriate. 
The RFC seems like a step into the right direction and makes linked lists somewhat useful. It won't support the move of a node from one list to an other but maybe this can be added later. For anyone else interested: The RFC is https://github.com/rust-lang/rfcs/pull/2570 
That's insanely cool.....
Incidentally, our bot flagged your post as a possible playrust submission. How ironic. That said, there are much less than 1/3 playrust posts here. I should know, because I (among the other mods) remove them.
Typically the compiled bytecode of the VM will store locals into the registers. If you are looking up things in a HashMap then you are also likely writing an interpreter, which, in your case, is probably not low level enough to utilize registers. Are you intending to write an interpreter or a compiled language?
That sounds like a sane way to solve the recursion issue. Err on the side of caution. &gt; Zig has an explicit error handling mechanism, it doesn't use sum types so it's not like the language is mucking about with your type signature. https://ziglang.org/documentation/master/#Errors Based on a quick skim through that documentation, it sounds like they do - it's just not visible because the error set is inferred, but I understood it's still part of the signature itself (which might be a bit painful for libraries). Although I'm not familiar with Zig so there's a good chance I just missed the gist of it. :) &gt; I also observe that when I get an Err, I often have something in mind to do in response. I don't often just return it to the caller which I think is your fear of trivializing things. My experience with big libraries is limited though, maybe the situation is different there if you have many layers of abstraction to get the error through. That sounds like a good approach. And of course often bubbling up the exception is the only sane thing to do (The user gave you some code but Syn couldn't parse it? You probably should inform the user that parsing failed). I also believe that it's a mark of good API design that when the user (of your crate) receives an Err, they usually have some kind of an idea how to react to it.
I had to use in a few places `vec.reserve(x); unsafe {vec.set_len(old_len + x)}` in order to no incur the cost of initializing the memory (like with `vec.resize(old_len + x, 0)`) that will be overwritten in the next instruction anyway.
What do you mean? Are you proposing that you have to `use std::prelude::*` everywhere?
I'm not proposing anything. Some people have proposed that, when you include a crate `foo` in your project, you get an implied `use foo::prelude::*`, like you currently do with `std` and `core`.
I think they're kind of funny.
That said, given how many of them I see, I've been considering writing an RSS filter/proxy which delays everything by 6 to 12 hours so that removed /r/playrust posts don't keep showing up in my RSS reader.
As [Learning Rust With Entirely Too Many Linked Lists](http://cglab.ca/~abeinges/blah/too-many-lists/book/) put it, it's the only niche data structure (in the context of the arguments presented) that gankro failed to shove out from `std::collections` into the crates ecosystem where such things belong.
Ohh, I see, thanks! It doesnt seem like a good idea since it's great to know where things are comming from. Multiple blob imports can be a pain in the ass.
No problem. &amp;#x200B; Yeah, that's certainly a big downside.
It is known.
Very cool. Still oppose using google stuff as much as possible. 
This isn't the subreddit you're looking for. Try /r/rustgame
One thing, if I'm following the code right: I'd prefer to define `UserDao` explicitly, myself, rather than have the macro create it wholesale, in case I want to do something else with it. 
Coming soon! :)
in regards to tooling, it would be amazing if hot code reloading were implemented into these game development frameworks.
I have looked into your example and spotted out some error, without reading @sjustinas 's reply. 1. `it1` and `it2` are slices. They cannot move values out, unlike an `Vec`. For this reason, your trait bound ``` where X: Iterator&lt;Item=u8&gt;, Y: Iterator&lt;Item=u8&gt; ``` should be ``` where X: Iterator&lt;Item=&amp;'a u8&gt;, Y: Iterator&lt;Item=&amp;'a u8&gt; ``` and you have to introduce a lifetime in your `MathZipper` struct. 2. accordingly, when use them in `map` you need to write ``` let it_out = it_tup.map(|(x, y)| *x + *y ); ``` 3. `it_tup` was consumed in the above `map` call. So you have to use `it_out` instead. ``` for i in it_out { ``` After fixing all above errors, your code is compiling and running well. https://play.rust-lang.org/?version=beta&amp;mode=release&amp;edition=2018&amp;gist=d7ae29ba302e0de4815f6314bdfb748e
Way to ignore everything i said, but i'll bite. What is "it" supposed to be? Programs handling their own memory usage? Paging existing? Needing to read documentation? What? Even so, whats your argument? "Well it didnt used to be so CHANGE BAD!"? Rust didnt use to be either, lots of things didnt used to be, what kind of "argument" is that?
"_The last great thing written in C was Schubert's 9th symphony_" - something I read online
It does, but you still shouldn't use it. Linux has fread_unlocked and fwrite_unlocked.
Your code looks horrible on Old Reddit. Please replace the triple backticks with a four-space indent.
You can't cast away a file lock, AKA a mutex.
Yes, this is enabled with 1.30's `proc_macro_attribute`. The generated trait method implementation is a pretty thin wrapper, though; all the database interaction is handled by `mysql_async`.
How do companies like Unity/Unreal get around this? They can build straight for consoles.
Did not expect to read that in Vice
I believe when you buy them you verify that you’ve signed the NDAs, right? I’m actually not sure, but this is a good question!
thanks for the response! i did have a solution like this at one point. i changed from it for fairly minor reasons. first, the first call to poll will be blank, even though the buffer isn't empty (i handled backpressure by setting an AtomicBool instead of a signal channel, btw). also, i don't like blocking for control flow; that's just unfounded personal preference -- it's probably fine. finally, this design assumes that the caller will wait around while the child thread buffers, while what i actually have is a gui loop that eats these buffers up, ideally around 60 fps/buffers per second. so i don't really feel bad about "abusing" mpsc channels as a sort of buffer. anyway, i don't think our designs differ by much in terms of correctness or performance, after i remove the dumb stop method. thanks for looking at it. i'm not as active in the community as i'd like to be, and i thought this might make a good crate. `simple_stream` or something like that.
I'm using gtk-rs and it works wonderfully. I made a test-app with a few buttons that do different things: Println, call other functions, etc. However I'm now at a point where I need to work with threads, because some functions take some time to finish and if I don't put those tasks in another thread, my gui will freeze up until the task is finished. Gtk objects aren't thread-safe. But I thought that I can just work around this by just passing a message back to the closure. First the code: let headerbar_clone = headerbar.clone(); button2.connect_clicked(move |_| { println!("Starting a new thread"); let (tx, rx) = mpsc::channel(); thread::spawn(move || { println!("This message is coming out of a thread"); thread::sleep(Duration::from_secs(2)); println!("2 Seconds are over!"); let val = String::from("This is coming through the channel"); tx.send(val).unwrap(); }); let received = rx.recv().unwrap(); println!("The message is: {}", received); headerbar_clone.set_title(received.as_str()); }); Explanation: If I press `button2` a new thread is started and a message is returned via a channel. That message (a String) is then used to change the title of the Gtk headerbar. I thought that this way I can work around the missing thread-safety and just assign the headerbar a new title within the scope of the closure. Which is exactly how it works when not using threads. Just to be clear, this is a working example of a button changing the headerbar: let headerbar_clone = headerbar.clone(); button2.connect_clicked(move |_| { println!("Doing stuff"); thread::sleep(Duration::from_secs(2)); println!("Finished"); }); This works without a problem, but freezes my GUI for 2 seconds. HOWEVER: Even when starting a new thread, my GUI still freezes. Why? I used a similar technique when using PyGObject for the prototype and it worked without freezing the GUI. That must mean that I'm using threads wrong. But I don't see anything that could be wrong. Does anybody have any idea of what I'm doing wrong? Thanks so much in advance!
I would love a Rust implementation of TypeScript too. But you can improve TS compile times by using the new babel TS plugin (which strips types without type checking), and checking types either in parallel as part of webpack, in your IDE, or manually at the command line.
&gt; Why is that? What does it matter what compiler is being used? Rust is Rust. What am I not understanding here? The commentor actually meant "c backend" rather than "gcc frontend". That is... generating C code instead of LLVM IR, then sending that through GCC. Some languages like nim do it this way, and mrustc used something similar.
Just checked Unity; you have to acquire the versions of them that build for consoles directly from the console vendor, or maybe through Unity's sales team.
gcc targets more architectures (not platforms) than LLVM... the concern from debian is for less-popular CPU targets like m68k.
I'm not sure I understand why glaubitz is upset. He helped port rust to more platforms and is now upset that people want to make use of that work? 
I'm pretty sure they did mean 'gcc frontend' - GCC's platform support is slightly wider than LLVM's iirc. That said, a C backend (which is what mrustc uses) does open up even more possible targets (because almost all architectures have a C compiler of some form)
No, I'm pretty sure the commentor meant a "GCC frontend". GCC is more than a C compiler, it has frontends for C, C++, Java, D, Go, Fortran, Ada, and others. One could, with a lot of work, add rust to that list.
No, I'm fairly sure they meant a gcc frontend. Go doesn't compile to C either. But, `gcc-go` is a Go frontend for the gnu compiler collection, so it can take advantage of GCC's optimizations and backends just the same as `gfortran` or other GCC languages can. GCC is not quite as modular as LLVM, but it has frontends, middleware, and backends all the same.
No, the commentor did not mean that. They meant a gcc frontend. That's what they said. Go doesn't compile to C either. But, `gcc-go` is a Go frontend for the gnu compiler collection, so it can take advantage of GCC's optimizations and backends just the same as `gfortran` or other GCC languages can. GCC is not quite as modular as LLVM, but it has frontends, middleware, and backends all the same. tagging /u/booooomba 
So I've been writing a lot of code for the ESP8266/ESP32 and C/C++ is the only real choice. This would seem like the obvious place to introduce rust. Is there any progress being made here?
The Rust project needs to find a way to apply to be an official middleware vendor for Sony. The hard part here is not on Sony's end as they already have this process. The Rust team would have to use this process to acquire devkits and documentation, as well as to distribute the resulting changes through Sony's channels. To be useful, this effort would probably need to produce wrappers of Sony-specific APIs as well. I'm sure there would be some additional restrictions but the only way to work it out is to actually talk to Sony. For an open project this would be a big shift, and it might involve some new technology for distributing things solely to registered developers, but it's really the only way to have drop-in support on game consoles. Companies like Mono have gone through this process, as well as Unity and Unreal mentioned below. There's a licensing link here that would be the first step: http://www.scedev.net/ps4/ I'm not familiar with Nintendo and Microsoft's current practices but I imagine they are very similar.
Would love to get involved with this - relatively new to Rust, but excited about it's potential with game development. 
https://github.com/emosenkis/esp-rs 
I complain because I care! One barrier to secure computing is the number of platforms supported by performant, safe languages: C, dumb as nails, has a basic compiler for quite a large number of platforms, while rust(up) completely ignores DragonflyBSD, NetBSD, OpenBSD, Illumos, musl/Linux, MINIX, and Haiku, not to mention other environments. Go is better, sporting easy, out of the box cross-compilation for most of these (sans musl/Linux). And of course Swift is quite laughable in this area, supporting merely Apple devices and specifically Ubuntu Linux. For better or worse, C/C++ are practical choices for software expected to run on many different systems compared to Rust. While I would much prefer to write my QNX, AIX, HP-UX, applications in Rust, for the moment the options simply do not include Rust. Aside from professional, mobile, and embedded computing environments, we also have gaming systems which support neither Rust nor Go. So it’s C++ or worse beasts. I believe Rust provides an enviable programming solution, in some ways better than Go. Unfortunately, Rust has not concentrated on making itself available on nearly as many systems, and so I hesitate to write much Rust where portability is a concern. I have come to loathe Java, even as its JVM is ported far and wide. .NET Core is getting interesting, though I suspect it, along with Crystal and Nim, don’t offer either cross-compilation nor many official packages aside from the big three, macOS, Windows, and GNU/Linux, haven’t bothered to check. People tend to focus on one or maybe two platforms at a time, and so portability has been late in coming. D will soon get as many platforms as gcc 9 ends up supporting, although of course D is not safe. So safety or portability, drag the slider one way or the other. C’est la vie.
You actually want to match employees.entry(department) instead of employees.get(department). Then instead of matching against None or Some you will be matching against Vacant or Occupied. The OccupiedEntry struct is where you get the (mutable) reference for your stored vector. I found the documentation page for Entry to be confusing until I realized that VacantEntry and OccupiedEntry were their own structs and had their own specific methods. I don't have time to flesh it all out, but hopefully this gets you on the right track! [https://doc.rust-lang.org/std/collections/hash\_map/enum.Entry.html](https://doc.rust-lang.org/std/collections/hash_map/enum.Entry.html) [https://doc.rust-lang.org/std/collections/hash\_map/struct.VacantEntry.html](https://doc.rust-lang.org/std/collections/hash_map/struct.VacantEntry.html) [https://doc.rust-lang.org/std/collections/hash\_map/struct.OccupiedEntry.html](https://doc.rust-lang.org/std/collections/hash_map/struct.OccupiedEntry.html)
Hi. Silly question here. I'm working on a set of utility libraries to be used by games. Mostly 3d math stuff. I've got a "workspace crate" with a small handful of internal crates. I basically copied the ripgrep structure. It works pretty well! I'd like to provide a demo example those shows my libraries in use. My question has to do with that library. My utilities are very lightweight. Only a couple of tiny dependencies. For the example I expect to depend on several large crates. In particular to handle rendering. How should I structure my example project so people who someday pull my crate from [crates.io](https://crates.io) don't also have to pull and compile everything for the demo example project unless they explicitly want to? Does that question make sense? Thanks! &amp;#x200B;
Are there any example of rust being used to render a 3d game in a mobile browser? I've found some 2d stuff, but nothing 3d. I've tried searching for rust mobile game webasm and webgl but so far have not had any luck. Thanks!
As much as I adore Rust, I have to point out that this uses mrustc, a Rust implementation that compiles to C, and is out of date if compared to rustc. The experience is not going to be as smooth as if it were officially supported.
It's not just Aaron and Niko but also Nick Cameron and pnkfelix who have PhDs in PLT related subjects. I myself study PLT and type theory at uni and there are compiler team members who also have similar ongoing studies or who read a tonne of papers in their work on Rust. Furthermore we have the Oxide project that Aaron Weiss is doing with Amal Ahmed and the work of Ralf Jung et al. in the RustBelt project. That said, world class is probably a bit too far as most cutting edge type theory is focused on Homotopy Type Theory right now. But certainly Rust is full of people with PLT and type theory backgrounds. 
Given the problem description, that's probably fine; any text with a replacement character in it is unlikely to have been English to begin with.
Programmers and developers spend all day dealing with it.
I was pointed to a [discord chatbot](https://github.com/Bocom/the-rotting-13) that uses [discord-rs](https://github.com/Bocom/discord-rs) as the base. It seemed simple enough to run, but after setting up the environment, trying to `cargo run` the project gets this: thread 'main' panicked at 'Connection failed: Json(Error("invalid type: string \"3864\", expected a u16 in [0, 9999] or parseable string", line: 0, column: 0))', libcore/result.rs:1009:5 Odd, but whatever. However, trying to run the [example minimal chatbot](https://github.com/Bocom/discord-rs/blob/master/examples/basic_chatbot.rs) included with the discord-rs package gives the same error and fails in the same location let (mut connection, ready) = discord.connect().expect("Connection failed"); or let (mut connection, _) = discord.connect().expect("connect failed"); respectively, so it's not something necessarily unique to the first project. Now, I don't know if this is a Discord API issue or a Rust issue or just a problem with discord-rs, or a problem with my own machine, but I am extremely new to Rust and I'd love any insight anyone might have into the matter. From what I've been able to work out, it likely has something to do with how Discord is passing back the user id discriminator("invalid type: string \"3864\") but beyond that I'm stumped.
I was going to say getting glibc on musl isn't that bad.
You might be interested in Ryan Dahl's work on a Typescript runtime implemented in Rust: https://github.com/denoland/deno.
Has anyone ever used program synthesis for something larger than a toy example? My own experience is that the constraint satisfaction search does not scale well enough to be useful.
This is really neat! I'm actually taking Professor Sampson's [course on programming language theory](https://www.cs.cornell.edu/courses/cs4110/2018fa/) right now, so it's cool to see his work pop up here. 
&gt; but with older machines with say 2gb RAM trying to run Chrome or similar Such a machine is far too old and outdated to care about, though. It'd be unreasonable to try and support that just like it'd be unreasonable to try and still support DOS and 2 MB of RAM. [Windows 7 for example requires a minimum of 1 GB for 32bit, or 2 GB for 64bit.](https://support.microsoft.com/en-us/help/10737/windows-7-system-requirements) And [chrome needs windows 7 at the minimum.](https://support.google.com/chrome/a/answer/7100626?hl=en) There has to be some reasonable amount of RAM to assume people have, and these days thats at least 4 GB and rapidly becoming 8 GB in my experience. Sometimes you just need more RAM. &gt; (especially if you're a non-technical user and you don't even really understand what memory is). I doubt such a user would have programs using such large amounts of memory in the first place, let alone know how to find and close them, in that case. If they even read the error. &gt; than the word process dying on OOM and you losing your work... That sucks, but so does any other bug causing a crash. And hitting OOM is just that, a bug. Plus, thats what autosaves and recovery files are for. What modern text editors don't save your work for you?! Even Word does these days. Hell, even [Vim](http://vimdoc.sourceforge.net/htmldoc/usr_11.html) has recovery files! So does [Nano](https://linux.die.net/man/1/nano). **If you lose work, the only person you have to blame is yourself.** Either the user isnt respecting your softwares system requirements, or your software can consume an arbitrary amount of memory based on arbitrary user input, which is just bad. In either case theres no way to recover. IDEs and text editors, for example, don't work on arbitrary file sizes. MS Word has something like a 512MB file size limit. VSCode defaults to consuming 4GB at most for large files, Notepad++ has something around 200MB. Photoshop defaults to 70% of your RAM. Google Chrome and Firefox aggressively suspend inactive background tabs to save on CPU and memory. Software has to handle it's own memory usage, and users have to respect those memory requirements. And even so, a *crash* because of OOM is something i don't think is even possible on a modern system on any workload a normal user is doing, let alone one who doesnt know what memory is. Thats what the page file is for. They would have to be using an unreasonable amount of memory to fill up all available RAM and the page file. Come to think of it, i've never seen a program crash because of it, even when I debugging out of control memory leaks. Sure slowed my system down, though.. That was a fun process to kill. Windows doesn't like this situation. I don't see any situation where you A) could encounter OOM and B) Can do anything about it. Either your code is bad, or the environment is bad, and neither can be solved from within your own program. And all of this applies to servers and embedded too. In fact, it's worse there, because you know *exactly* what your memory requirements are like and *still* cant bother to respect them!
Agreed completely. What's *only* in your `Cargo.toml` should never change how your code compiles except for `extern crate` statements.
I largely agree with the article and firmly believe Rust will be the eventual solution, but this made me laugh: &gt; Imagine you had a program with a list of 10 numbers. What should happen if you asked the list for its 11th element? Most of us would say an error of some sort should occur, and in a memory safe programming language (for example, Python or Java) ... Python and Java are both implemented in C/C++.
There's a pretty decent push for gaming on rust. Gfx-hal and gfx-portability are actively making progress. also wasm support and tier 2 platform support is pretty good. I think rust will get there eventually on the portability front. 
There's something wrong with the page at the link; clicking it brings me to a page with an error message telling me "This is a private web site open only to licensed PS4 developer, publisher and middleware companies.", and says that anyone wishing to become licensed should go to the following page: http://www.scedev.net/index.html . That page then asks me to select a console to view licensing information for, which is a link that takes me back to the first page!
musl/Linux is cool, it’s unfortunately just not a tier one platform for many software stacks. Go apps targeting musl require a musl VM or musl host, depending on your particular development environment. While a musl container with Go can target musl quite easily, that’s not a great bandaid either, as FreeBSD hosts can run only FreeBSD or GNU/Linux containers, not musl/Linux containers, at least last time I checked. **Really, supporting musl is quite easy compared to the more obscure platforms I mentioned.** Rust’s cross-compilation support is getting there, but the unfortunate externalization of the cross-compiler toolchain means there are many gaps: Targeting macOS from GNU/Linux with rustup would require someone to create a clang or gcc cross-compiler, cross-linker toolchain for that, which is quite laborious. The same goes for Windows MSVC, and I presume for musl/Linux. *Some* of these cross configurations are relatively easy to setup, such as GNU/Linux x86_64 host targeting ARM Linux. A few more are fortunately accessible for Windows, macOS, and Linux hosts via the `cross` project and its Docker images. Other cross build mappings are simply unavailable, which is not cool, because Rust would kick ass on OpenBSD, ruling out the biggest source of software security flaws that ever was.
The article is correct. Python and Java programs are memory-safe. They have well-defined semantics for accessing an out-of-bounds array index (among other things). Python and Java's interpreters are not written in a memory-safe language, so a bug in the interpreter could compromise memory safety, but that's not so different from Rust. When it comes right down to it, Rust compiles to machine code, and machine code isn't memory-safe. If the compiler is broken, the safety guarantees can be broken as well. And there are [several](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3A%22I-unsound+%F0%9F%92%A5%22) open unsoundness bugs in the compiler. More generally, all safe things are built on top of unsafe things. There's always the possibility of error in the theory or implementation. (Whether that implementation is an interpreter, a compiler, microcode, actual silicon, etc.)
&gt; Python and Java are both implemented in C/C++. Irrelevant to the point being made. PyPy is written in RPython yet it behaves the same way as CPython in the relevant example: $ python &lt;&lt;&lt; "a = 'X' * 10; a[11]" Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; IndexError: string index out of range $ pypy &lt;&lt;&lt; "a = 'X' * 10; a[11]" Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; IndexError: string index out of range 
I'm guessing you sourced that title from this recent article, "The C++ Build Process Explained": https://github.com/green7ea/cpp-compilation/blob/master/README.md
Could gfx-portability help here? Support building a library that targets vulkan and a shim or similar for developers who can complete the processes required. The same library could provide lower-level access for developers with full documentation or who can compile against the full SDK. 
As ever, a preemptive reminder to abstain from language zealotry. I'll inline steveklabnik1's comment from [the proggit thread](https://www.reddit.com/r/programming/comments/9xdvae/the_internet_has_a_huge_cc_problem_and_developers/e9rq3a6/): &gt; Hi folks, I'd just like to mention that this is the first time I'm seeing or hearing about this article; same as the rest of the Rust team. This is one person's opinion, who notably is a Rust user, not someone who works on Rust itself. We generally try to not frame things like this, because we don't think that it's a particularly constructive approach.
Another thing that could be useful: a BareFormatter and associated Debug trait, and maybe some kind of gradual implementation of `println!`. As format codes are used the underlying trait could be switched and rustc could give feedback of how many bytes are needed for this. This would apply to `ppanic_get! as well.
They're doing a whole week on hacking and cybersec apparently: https://motherboard.vice.com/en_us/topic/the-weakest-link
1. wrong sub 2. not funny 3. do you even humor?
How neat is that?
&gt; I should also point out that it doesn't need to be the Rust project itself that follows this process. Any third-party company could become a licensee, sign the NDA, modify rustc as needed, and give that to Sony to distribute Quite true. It would be most efficient for an existing game company or Sony themselves to do it, however that would involve a lot of sitting around and waiting for it to happen. I think it would be great if Sony themselves for involved in Rust... They have made several contributions to LLVM already. But for that to happen it requires their customers to want Rust support. I think for the customers to see the value in Rust support they would need to see it in action, so there is a chicken and egg scenario.
Rust is probably more approachable than Haskell to the average C-family language programmer, e.g. Java, C#, C++, PHP, ... with the standard use of curly braces and imperative control flow because that is what these programmers are used to (and Rust was intentionally designed this way...). From teaching, I've found that people who have never programmed before generally don't have any problems picking up Haskell because they don't need to "unlearn what they have learned". That said, I think Rust is a more complex language than Haskell particularly in that you need to care about memory while Haskell lets you punt on caring about performance until you need to (and GHC is pretty amazing at optimizing System FC to the Von Neumann architecture). If I want to build a binary tree in Haskell, I write: ```haskell data Tree a = Nil | Node a (Tree a) (Tree a) ``` In Rust, I instead write: ```haskell enum Tree&lt;T&gt; { Nil, Node(T, Box&lt;Tree&lt;T&gt;&gt;, Box&lt;Tree&lt;T&gt;&gt;) } ``` Now I have to care about `Box&lt;...&gt;` which I didn't have to do before. I think what makes Rust really approachable tho is its community and documentation; we have an excellent community which writes extensive, easy to read, and simple documentation with relevant examples. Meanwhile, while you will find lots of amazing libraries in Haskell, these are usually made by academics who are not the best at documenting their stuff.
You probably didn't read the instructions.
I became interested after reading about [Souper and superoptimization](https://arxiv.org/pdf/1711.04422.pdf), which seems very promising to me.
Oh I absolutely think Haskell's added abstractive and expressive powers are worth it because you can encode more type safe and more expressive and reusable libraries with those powers. In many cases there are no reasons why we cannot have some of Haskell's extra powers that Rust does not currently have added to the language. Indeed, we have been working on closing the gap between Haskell and Rust with features such as Generic associated types, Trait aliases, and Const generics. In the future we should be able to close the gap even further to make Rust a more type safe and productive language while staying true to the performance we deliver today and even enhance some of it.
I'd pick a Haskell syntax to commemorate the fact that Rust is literally Haskell; the syntax `'a list` in OCaml so trips me up ;) But Rust probably did the right choice in picking something familiar for C/C++/Java programmers.
A very interesting talk! Wish it had been a bit longer. :)
I think I understand, so I would like to re-state the position. Using Rust in "core" Linux libraries, while it can provide benefits to those projects, creates (in economic term) negative externality for Debian porters. (Really, for any Linux porters, but for new architectures it usually means Debian.) How? Because before such uses, it was sufficient to port GCC to new architectures to get "core" Linux system up and running. Now it requires LLVM port as well. "So port LLVM!" is not a great answer, because for an under-resourced port difference between porting GCC and porting both GCC and LLVM can be difference between being feasible and infeasible. In effect, such Rust uses double (or more than double; LLVM can be more difficult to port than GCC) the burden of porting to new architectures, and such doubling of burden can effectively kill many architectures. One interesting alternative is to port only LLVM without GCC port, to keep burden of porting to new architectures in a comparable range. There are many problems with this alternative, starting with the fact that Linux kernel does not officially support non-GCC compilers, but it is probably more feasible than porting both GCC and LLVM. PS on "LLVM can be more difficult to port than GCC": this is not a purely technical statement, although I personally think it works even that way. Difficulty can stem from more people knowing and having experience of porting GCC than LLVM due to its longer history, attitude of upstream project (e.g. GCC upstream may be more favorable to, say, m68k port compared to LLVM upstream; I believe it is actually the case), etc.
I'm glad other people are working on Rust. It's got the right idea, and will work for many ordinary solutions. But it's never going to replace C in our lifetime. The performance isn't there, and to get it back you have to go down into unsafe, and then you're writing C anyway.
I feel like he vented a little bit on the mailing list, but overall he's quite positive about Rust; he participates in the LWN comments on this article. I think that there is definitely work the Rust project could do to help out more here. For one thing, it would help to have at least one tier-1 platform that was not x86. I looked through the failures for the most recent build of rustc, and a large number of them were things like tests that were trying to use features like AVX on non-x86 platforms. Things that would be trivially caught if there were at least one non-x86 tier-1 platform, but aren't caught currently. Many of the rest of the failures seemed to be things like off-by-one line number errors in tests for compiler errors. The fact that Rust regularly has releases (once every 6 weeks) which don't pass tests out of the box on many platforms that are supported by Linux distros is a bit of a drag on distro maintainers, having to keep on tracking down and fixing these kinds of silly bugs. Just doing the bare minimum to have at least one non-x86 platform graduate to tier-1 status, in which CI is used to ensure that the compiler can bootstrap itself and tests pass, would go a long way towards reducing the maintenance burden on downstream packagers. Of course, there's more that would help; things like having a stable branch that would be maintained for more than six weeks, so bugfixes could be applied without having to deal with whole new sets of test failures, having backports of LLVM fixes and more CI on released LLVM versions, gettting LLVM to accept more architectures, and having a GCC backend, would all be things that would make distro maintainer's lives easier. But really, one of the bare minimum things that I think needs to be done is to just get some more platforms into the tier-1 status, since tier-2 is just not good enough for distros that require being able to bootstrap on fully supported platforms.
Then when it is compiled, you should be mapping locals to registers as appropriate.
More details in the sibling post, but one way to consider this is: you are a Debian m68k porter. Debian librsvg maintainer unilaterally decided to kill your port. You complain that while such decision can be made, it should be made by Debian project as a whole, not by Debian librsvg maintainer. Does that make sense?
sorry i'm autistic &amp;#x200B;
Get my feet deeper in rust i kind liked that way too, no big deal.
I'm quite sure that writing Rust spectre and meltdown did not happen... 
&gt;The official introductory Rust book is definitely the wrong place to peddle any portion of a style guide. Why is that? I'm on cap 3, and really like the way they build the guide, &amp;#x200B;
So, some clearing, beside some basic knowledge on bash scrip, rust is my first programming language. If you guys want to give some advise for e real newbie, wold be nice. And I'm brazilian, so sorry for any grammar o syntax errors, my bad.
The whole idea is that you use `unsafe` where necessary in the performance-critical building blocks, then expose an API which enforces safe use. That massively shrinks the portion of your codebase that you need to audit.
My problem with rust in this regard is that you can still use unsafe blocks. And for some things, you *have* to use them. I don’t think you could build an OS without it. Within those unsafe blocks is opportunity for these failures. Sure, it’s nice to isolate, and definitely better than C, but it’s still not perfect for every application. 
Every time someone says “C/C++” like they’re the same thing, a core dumps.
Spectre and Meltdown are flaws in the CPU itself. No programming language magically grants protection from them. The mitigations which are being added to compilers work by explicitly forcing the CPU to do extra work that serves no other purpose, so, if a lanugage was producing them prior to Spectre and Meltdown, it would have been considered a flaw in the compiler's optimizers.
Any place where there is more info on the Espressif LLVM version ?
On mobile atm but there was some talk about it on cfe-dev
C/C++ can be read as "C with classes". Modern C++ on the other side is inherently safer due to stuff like RAII. Rust goes some steps further of course. But yeah, whenever I read "C/C++" I want to shout "well there is your main problem"
It was sarcasm... 
Well depending on how loosely you want to use the vocabulary, type-directed function resolution is an extremely useful case of program synthesis that's used widely in many programming languages.
Convention says to put a /s at the end because text doesn't do nuance 
Ouch... Didn't know... 
Can't Rust (up until the MIR phase) not simply be considered a gcc frontend? Or is it a given that a gcc frontend can only go to an AST and from there map to gcc constructs?
Was just about to say that you probably shouldn't worry about memory corruption vulnerabilities with a microcontroller, but just looked into the ESP32 and it has its own version of malloc and a heap?? That thing can't have an OS on it right? Does the C library for it have its own memory management logic, with fake system calls?
Don't tell me about it. I worked as a tester in a team of 12 software developers for a big embedded system. Coming from electronics I think developers would be able to focus on getting the application functional. Not doing bug hunting half of the time. The project ran on VxWorks and coded C++ and used several other Domain Specific Languages. The code base was originally started in the 90s. One of the major quality goals was code reduction to improve the situation somewhat. Also eliminating older code generators from the 00's. Every week there was a new race condition, type mismatch, concurrency problem, timing violation, random crashes that would cost a developer 2 to 4 days to figure out. This happened for over 2 years. Even up just before delivery of the software to system verification. In order to improve the code quality, an automatic code checker went over the whole code base. Then every developer could take a coding rule and for a week try to fix those in the code base. Next to their normal job. Part of the acceptance test was a manual memory leakage test. That failed and took up to 4 weeks to find and solve. The developers were not able to use Valgrind or any other tooling. Because the application had not been coded to neatly close. No need to close the application, when the customer shuts down the machine. But it might come in handy for checking the code quality. Whenever people are looking for a job in tech, I tell them that software testing is the easiest to get into. No way you will ever get out of it. Especially with these kind of practices and legacy tooling. 
That is my current setup but the initial build time is still 4 minutes for a smallish project. It seems the vue-loader is very slow as well.
Check out mbox - https://github.com/kennytm/mbox
The Android Linux kernel is being built with Clang these days. There's really no major barriers to replacing GCC with Clang on the archs LLVM supports at this point.
I still don't understand. What is the problem with musl/Linux specifically? (I am also happily targetting musl for distributing binaries) What is "the unfortunate externalization of the cross-compiler toolchain"? Are you talking about `xargo`? `xargo` is not necessary to target musl, it is a `rustup target add x86_64-unknown-linux-musl` away. Is the problem that you want to target musl/Linux when your host platform is, say, Windows? I'm just curious, as I will readily brag about how well cross-compiling is supported and how easy it is to target musl/Linux.
Can Clang build glibc? "Use bionic" (Android solution) probably won't work for Linux distributions. "Use musl" probably works, but it's a big change.
I feel like we are going to be stuck correcting this misunderstanding forever. While unsafe code should not be used unnecessarily, Rust's goal isn't to eliminate all unsafe code. Its value proposition is that safe abstractions can be built even when unsafe code is used internally. "It's not perfect" is an unfortunate bugaboo of a lot of Rust critics.
But it was the upstream librsvg maintainer that made the decision. Unless you want Debian to just never upgrade.
I think this article is a pretty good assessment of the problem. It's such a simple problem, but it's been plaguing the industry for decades. It's obvious by now that hiring good engineers with strict code review processes and even good static and dynamic analysis tools, while helpful, aren't actually going to solve the problem. But you have to think that in the future, at some point, because of some new technology, it's going to be a solved problem. If you could time travel into the future 10-30 years, and a programmer told you "We don't really have memory unsafety problems in our systems programming anymore, because of X". What do you think X will be? Rust is the best guess that I have so far.
libgccjit can be used in place of LLVM, and rustc up to MIR can be shared between LLVM backend and GCC backend.
While C++ is a bit safer than C thanks to RAII, it still shares mostly the same issues, such as integer overflow, buffer overflow etc. So imo it makes sense to use them interchangeably when talking about memory safety.
What is preventing this currently?
Some models have 1MB memory. UNIX was written for a PDP/11 with less memory... :) Plenty of microcontrollers have OSes on them. Contiki &amp; MiraOS are made for IoT products. Mongoose is running on ESP32. As usual it depends on what you do with it. If it performs more than one function that needs a dynamic amount of memory, it might be better to use the heap memory instead of static buffers. You risk fragmentation and running out of memory unless you're careful though.
Note that "asking for them to do a lot of extra work to make something they don't use work" is exactly what Rust users are doing to Debian porters.
Words about diversity (in tools) are correct and pretty important. If one of such engines is "default", other possible projects will not even be started.
Not going to be perfect. But safe Rust is still Turing complete.
https://github.com/DMOJ/dmoj-rust From the readme: &gt; This crate provides print! and println! macros that shadow the prelude versions. These versions are about 10 times faster and fully API compatible, but sacrifice thread safety.
Most of the time that would work bit of you want top placement on ex Kattis you really need to squeese out every last stop of performance. I/O is often the thing that remains if 2 submissions uses the same algorithm
Thanks for the response!
Most of the time that would work, but if you want top placement on ex Kattis you really need to squeese out every last stop of performance. I/O is often the thing that remains if 2 submissions uses the same algorithm
Well yeah. I hope I explained why this is controversial. Basically, upstream is introducing a controversial dependency, in this case LLVM. The situation is analogous to GNOME introducing systemd dependency and controversy it generated.
I imagine you are relatively young. The ESP32 is more powerful than this baby here. https://en.wikipedia.org/wiki/Amstrad_PCW Which I spent quite a few hours at the high school computer club playing [Defender of the Crown](https://www.youtube.com/watch?v=o0G96TxxjPI). This is what many people don't realize, many modern micro-controllers used to be desktop computers 30 years ago, which already had Basic, Pascal, AMOS, Clipper, Lisp compilers, where C and C++ were just yet another language to choose from. Naturally anything that pushed the hardware was plain Assembly.
Sadly get used to it, and learn to get good arguments. As someone that learned systems programming via Z80, Basic and Pascal, before learning C and C++ and came to realize C++ was a much safer alternative, I am used to hearing that from C folks since early 90's. From their point of view we would still drive without seat belts, airbags and deformable structures, because people still die despite those safety measures.
I have to ask, have you tried targeting `musl` with Rust ? Because I write `cargo build --target=x86_64-unknown-linux-musl` and it "just works". I ship the binary, and it just runs. If I want to test that in a gnu system, I don't even need to install musl, or a VM, or anything. I just `cargo install cross &amp;&amp; cross test --target=x86_64-unknown-linux-musl` and it does all of that for me, on my machine, and on travis. So I don't really know what you are talking about when you say "Rust’s cross-compilation support is getting there". What is it missing? `musl` just works.
In C++ I always create a global with this initializer: const auto io_speed_up =[](){ std::ios::sync_with_stdio(false); cin.tie(nullptr); return nullptr; }(); Makes everything infinitely faster. I'd like to know how to do that in Rust.
I do both know that there's customers requesting Rust from them and that people are talking about ways to make that happen. Source: the toolchain team is present at conferences with a booth and very happy to chat.
The Rust project cannot deal with having a closed build with NDAs on the side. It runs fundamentally against how the project is run, also with respect to ongoing maintenance. In my opinion, the way is straight forward: we need a vendor with ties to the project that does that work for Sony or whatever. Sony is surprisingly approachable, but I'm still heavily searching for a contact to Microsoft/XBox.
Yes, C++ doesn't *restrict* you to safe code by default, you don't have to write `unsafe` to allow these issues, but still — idiomatic C++ is not nearly as error-prone as C.
The problem is in `lazy_static` is lazy. You need to call `lazy_static::initialize(&amp;_INIT);` before first logger macros usage. ``` fn main() { lazy_static::initialize(&amp;_INIT); info!("LOGGING"); } ``` 
&gt; PS on "LLVM can be more difficult to port than GCC": this is not a purely technical statement, although I personally think it works even that way. Difficulty can stem from more people knowing and having experience of porting GCC than LLVM due to its longer history, attitude of upstream project (e.g. GCC upstream may be more favorable to, say, m68k port compared to LLVM upstream; I believe it is actually the case), etc. Not taking away your point, but I at least have heard from some Debian packagers that LLVM is a good and predictable project to work with. It's not always gold, but you know where it goes. Also, Mozilla employs some Debian maintainers that are involved on this, so paths _can_ be short. 
is this one of those straw-man articles that doesn't admit C++ can actually express code that protects against buffer overflows. you could add a static analyser to C++. you could make the minimum assumption to avoid a need for reference lifetimes (and even come up with a template means of expressing a lifetime, checked by the static analyzer) There's other reasons to want to move to Rust. You dont need to exaggerate the safety issue. Rust is also NOT an unambiguous win, so you can't claim rust is a definitive solution. the safety comes at a cost. 
rust is ambiguous for gaming . ironically C++ can feel more 'fluid'/'malleable'. Rest is capable, but not an unambiguous win
they're closely related and there is a common subset. A C++ zealot might delude themselves but the level of C interop (the ability to write large amounts of C that compile in C++) is the real reason C++ is popular.
Weirdly, you get used to it. They annoyed me for a while, but generally the posters don't seem to be malicious and head to /r/playrust when pointed. I don't really get it, though. They can't be reading the rest of the posts here before posting, unless Rust is a very different game than I think and all this talk about borrow checkers and compiler optimisations makes sense in context.
&gt;Was just about to say that you probably shouldn't worry too much about memory corruption vulnerabilities with a microcontroller You can have memory corruption without a heap.. pointers / arrays are more than enough. I've seen huge failures of microcontroller based products in production lines in the automotive industry (random crashes, corrupted data,...). I'd say 80% of the time the reason was memory corruption or race conditions, followed by hardware problems. &amp;#x200B;
No, for embedded c/c++ is not going anywhere soon. Rust support is still limited, and many manufacturer does not even provide support for c++; but, and embedded developer as profession, I strongly believe that is one of the small area where c/c++ still make sense.
&gt; Glaubitz replied with a sizable number of complaints about Rust and its upstream; he is also skeptical of the security claims that are made for the language. If they don't care about Rust, why are they investing their free time into porting it to unsupported architectures? 
Because they want to run the latest Firefox on that architecture? There is no contradiction between wanting to run the latest Firefox and finding Rust safety not worthwhile.
&gt; For this to work, we'd need to generate the IR that GCC requires frontend to generate (cant remember the name). I think it was GIMPL or GIMPLe or something like that. 
Maybe you should give a try at [MicroPython](http://docs.micropython.org/en/latest/esp8266/quickref.html). A friend felt in love with it some weeks ago.
If unix, reading/writing to raw file descriptors is the fastest you can do. `Buf{Reader,Writer}` go some way to reducing number of `read`/`write` syscalls made. As such this will be fast: use std::{ fs::File, io::{BufReader, BufWriter, Write}, os::unix::io::{FromRawFd, IntoRawFd}, }; fn main() { let stdin = unsafe { File::from_raw_fd(0) }; let stdout = unsafe { File::from_raw_fd(1) }; let (mut reader, mut writer) = (BufReader::new(stdin), BufWriter::new(stdout)); // do reading and writing writer.write_all(b"hello world\n").unwrap(); writer.write_fmt(format_args!("hello {}\n", "world")).unwrap(); // drop without closing the fds let _ = reader.into_inner().into_raw_fd(); let _ = writer.into_inner().unwrap().into_raw_fd(); } Also note writes &lt; PIPE_BUF (which on Linux is 4096 IIRC) bytes are specified by POSIX to be atomic, in case thread-safe outputting is desired.
We need an operating system and kernel written in Rust.
This is just wrong, I do a lot of work with Rust performance and I very rarely drop down to `unsafe`. At least one piece of optimisation that I did took our performance to better than the highly-optimised C implementation while _reducing_ the amount of `unsafe` significantly. The necessity of `unsafe` is vastly overstated, and even in the relatively rare cases where `unsafe` actually does improve performance it's much easier to audit a small kernel of unsafe code with a safe interface than an entirely unsafe program.
Wish I was young, but unfortunately the tender age of mid-thirties. I just didn't realize they were selling hobbyist microcontrollers with full blown OSes. I mean I've seen [linux on an 8-bit microcontroller](https://dmitry.gr/?r=05.Projects&amp;proj=07.%20Linux%20on%208bit) but I didn't realize these sorts of arduino-like hobby microcontrollers went that far.
Wow, that's pretty damn impressive... And looked it up on amazon and it looks like it's only like $12?? 
Oh god this sounds very complicated. I think I will open an extra thread for this problem. Thanks for your help!
https://www.redox-os.org/
I read somewhere that micropython was 10x slower than the C++
Hello, So I just realized this already got posted here. (I'm Alex, the author of that post) I'm happy to answer any questions here if you have them. Thanks, Alex
Ah sorry. mid-forties here, I started to get used to talk about computer stuff to people that wasn't even born when I started using it. :)
I find ironic that some get upset with C/C++, which is just a simplification for writing C and C++, and actually quite common way of writing by ISO members. The sadly now gone The C User's Journal was eventually renamed to The C/C++ User's Journal and I don't remember ever reading a complaint letter about the name from the community back then. 
No, but if you turn on the warning levels and enable warnings as errors, although `unsafe` does not exist as such, one gets to use a couple of `#pragma` and `[[ ... ]]` instead.
It might not be an option to not use C++, but it certainly does not make sense. There is no embedded C++ code without race conditions and when this inevitably blows up projects the only answer is to use a RTOS, if that is an option. Compile time memory checks are a must for embedded programming. This produces billions in damage every year and the first major manufacturer who supports Rust or something else which solves the problem will have an edge because of this. 
Sounds good. If you're looking for ideas on how to expand the API, I recommend looking at [https://streams.spec.whatwg.org/#intro](https://streams.spec.whatwg.org/#intro) for inspiration...
An that is a bad deal. Depending on the configuration you can get it much cheaper if you can afford the lead time. 
It was very promising until they decided to design it in a way to not support Linux drivers as modules. If they did it would start to be ready for beta testing on real hardware. Currently, no chance for widespread testing as it is practically limited to virtualized installs.
Let’s face it. Most C++ is used to run JavaScript. 
printf out the serial port, like the good ol' days. 
I think you have loe expectations due to how awkward C/C++ make cross compilation. There's no reason why it shouldn't just be as simple as passing a flag to cargo/rustc.
Is there an easy way to make this work? &amp;#x200B; let array = [1, 2, 3]; let myfn = |scope: &amp;Scope| { for i in &amp;array { scope.spawn(move || { println!("element: {}", i); }); } }; crossbeam::scope(myfn) I get the following error error[E0597]: `array` does not live long enough --&gt; src/bin/crossbeam.rs:46:15 | 45 | let myfn = |scope: &amp;Scope| { | --------------- value captured here 46 | for i in &amp;array { | ^^^^^ borrowed value does not live long enough 47 | / scope.spawn(move || { 48 | | println!("element: {}", i); 49 | | }); | |__________- argument requires that `array` is borrowed for `'static` ... 61 | } | - `array` dropped here while still borrowed If I paste the closure directly into the scope function it obviously works. &amp;#x200B;
Cargo.toml is driving me crazy. [target.'cfg(target_os="ios")'.dependencies] mydependency = {version = "1", features = ["feature_for_ios"]} [target.'cfg(target_os="macos")'.dependencies] mydependency = {version = "1", features = ["feature_for_macos"]} Running cargo build --release --target=aarch64-apple-ios Will result in both features being compiled and build not succeeding. If I comment out the macos section it will work fine.
Good ol borrow checker question. Not sure if this is because of the types im using from https://crates.io/crates/specs, but i ran into an issue where i have a function like so: fn sell_power_to_cities( &amp;self, transform_storage: &amp;mut WriteStorage&lt;Transform&gt;, power_bar_storage: &amp;mut WriteStorage&lt;PowerBar&gt;, ) -&gt; i32 { Actually has more params than that, but those are the important ones. These storages implement Sync through: https://docs.rs/specs/0.14.0/specs/join/struct.JoinIter.html, which i leverage with the code: for (transform, power_bar) in (transform_storage, power_bar_storage).join() { } However, after the loop, I tried doing: transform_storage.insert(id, Transform::new()); And received an error that the value moved in the for loop. But im not sure why. The defined type is a mutable reference, wouldnt that be implicit rather than a move in the for loop? If i change the for loop to: for (transform, power_bar) in (&amp;mut *transform_storage, power_bar_storage).join() { It compiles.
You can spawn closures on the GUI thread with idle\_add() (Note that there are two different idle\_adds, one in gtk and one in glib which differ by the required closure bound \`Send\`). You then have the problem that you need a reference to the widget you want to change. &amp;#x200B; I recently made this ([https://github.com/Phaiax/gtk-rs-state](https://github.com/Phaiax/gtk-rs-state)) which may not be exactly what you need because it requires glade, but you can adapt it to work without glade. If you need help open an issue. But note that I don't know if that \`trick\` is idiomatic. &amp;#x200B;
That would be nice, or maybe something that can create a UWP package for the xbox one console. Also not sure how much access to the xbox one hardware you have in the UWP sdk.
Given that there is no tooling for people to determine the provenance of their dependencies or to distinguish random fly-by-night crates from those maintained by the Rust language maintainers, this seems like very bad advice, especially to a newcomer who doesn't want to spend time reading dependency source code instead of learning the language.
D is far safer than C or C++ and that's before you start using `@safe` or `-dip1000`, at which point it's only unsafe if there's a bug in the compiler.
If you care about bounds checking, you would just use the stdlib array or vector and write myarray.at(index) instead. 
**EDIT**: Other people have given suggestions probably more suited to GTK case, so prefer their advice over mine. The typical pattern is to spawn the thread at the same or higher level than your GUI code, via either just Rust threads or thread pools, then execute the code in that thread. With Rust threads, you can spawn the worker thread at the beginning, and have it wait on a [CondVar](https://doc.rust-lang.org/std/sync/struct.Condvar.html) via `cvar.wait(...)`, where `cvar` is the condition variable, then the closure provided to `button2.connect_clicked` will only need to do `cvar.notify_one` or `cvar.notify_all`. Wth thread pool, you can do something like `pool.execute(move |...| { ... })` which will not block, but collecting the result of a single thread in the pool might be tricky. I am not too familiar with async side of things in Rust, but that's another direction you can look into.
Which is why you use valgrind. Static analyzers are not conclusive memory checkers.
Can't comment on quality of the crates, but looks like signalo have at very least documented all its items: https://docs.rs/signalo Meanwhile `basic_dsp` looks like a meta crate for these two crates: - https://docs.rs/basic_dsp_matrix - https://docs.rs/basic_dsp_vector
Maybe (I've definitely read that it's "within order of magnitude", but does your code spend all its time using the CPU instead of waiting for some interrupt?
IF it works. And you have time enough. Otherwise toggle a pin and analyse the timing with an oscilloscope.
I wasn't pointing out a contradiction (as you say, there isn't any). My point is that there is choice, and the people involved talk like there is someone pointing a gun to their heads forcing them to do things. Wanting to use software that's not available is a common problem. You can invest an infinite amount of time on this problem, from porting toolchains, programs, to writing emulators like QEMU, Wine, ... Most people just use what's available (older Firefox, Chrome, or any of the many other open source web browsers out there). There are also many way to contribute to a distribution / platform. With all these available choices, they have chosen to do something that they do not enjoy, and it appears that they blame other people for that. 
&gt; The only extra piece of information is the lifetimes "only". I've used every tool I could get my hand on for C and C++ to try and avoid bugs. They were there all the same. These bugs don't happen in Rust, or D, or Haskell, or...
Hmm interesting approach. Can we talk noob/eli5 language here for a second please? So after `gtk::main();` you just created a loop that restarts every 4 milliseconds. OK I understand that. But let's talk about the LOCs I don't understand: &gt; `while let Ok(ev) = rx.try_recv()` This waits for a message and if a message is sent (meaning Ok()) then it executes code? I get that. So let's say I had a function `takes_5_secs_to_finish()`. How do i trigger it from the `connect_clicked` closure? &gt; `gtk::main_iteration_do(false);` What is this line for exactly? Just to tell GTK to do the main-loop-iteration again?
there are still bugs in rust programs. correct code just takes longer to write.. its not magic.
[Faust](http://faust.grame.fr/) compiles to rust now, you might like to check that out.
Or templates/snippets for common editors.
Thanks for the clarification! You can program in assembly. It's not pretty, but it works. I just want to say, that I'm quite surprised that rust (which I really like) has rather ugly parts too. And I think that's one. Or I'm missing a point and that piece of code is not just about an assert statement in an impl block. Anyways. It's not something I needed til now. Guess I can panic, if I want to.
&gt;&gt; or D, D isn't safe , so this sounds like exageration &gt;&gt; or Haskell totally different execution model- relies on a GC and has its own complexities when you need state/side effects. it might be that C/C++ just dont suit you - but i'm using Rust at the moment and the process is very similar to C++. The bugs it eliminates are trivialities, easy to track down. I'm spending just as long debugging (there's more that can go wrong in a program than plain memory errors)
Rust changed status quo. I think it is human nature to blame the party who changed status quo.
C++ is not going away anytime soon. Rust might be a solid augmentation for a long time, and maybe even a replacement in the far future, but we'll have to wait and see. Usually new programming languages appear, gain a lot of speed, and then fizzle out. (Python, Ruby, Elixir, even Go is at that point, no need to mention all the countless others). C++ is the only language that actually has been picking up speed. If Rust makes it past the 15 year hump - we actually have a chance. 
You seem to be operating under the assumption that the code I wrote was C++ rather than C. They are not the same language. (And, even if they were, the point is that humans make mistakes. In C or C++, those mistakes have to be audited for across the entire codebase while, in Rust, they're restricted to specific language constructs which can only appear within `unsafe` blocks.)
sounds like a job for the GPU (it would still be interesting to know if there are rust matrix libraries that leverage the GPU)
&gt; it would help to have at least one tier-1 platform that was not x86 I vote some variety of ARM, preferably 64-bit :) &gt; having a stable branch that would be maintained for more than six weeks I feel like this could coincide with "editions" to an extent. Maybe once each edition, there could be a blessed build that gets security updates for a year or two, or the next edition, whichever is longer. It's good to hear that he's not anti-Rust, just a bit frustrated since frustration can be resolved.
Author of signalo here. Happy to answer questions. :) I've so far mostly focussed on developing the crates, while adding the minimum documentation necessary. I plan to improves this soon though. APIs have mostly settled by now, but until recently things were quite fluid and I had lots of far-reaching refactors as well as API changes. As such I chose not to write too much high-level documentation that would constantly get out of sync with the code and block me from progressing. Signalo basically provides implementations of four basic traits: - `Source&lt;T&gt;`: `() -&gt; T` - `Filter&lt;T&gt;`: `T -&gt; U` - `Sink&lt;T&gt;`: `T -&gt; ()` - `Finalize`: `() -&gt; U` (With types implementing `Sink&lt;T&gt;` usually also implementing `Finalize`.) One of the goals of **signalo** is to have most of its implementations work with `no_std`. That's what I am using it for: doing highly efficient DSP on a Cortex-M4 where memory and computation cost really matters. --- Looking at **basic_dsp**`s docs it seems to **support both discrete, as well as continuous time signals** and **provide frequency analysis capabilities**, while **signalo** is more tail**ored to low-level processing on low-powered embedded environments**.
Not saying yes or no but I want to highlight that the render API is just one (actually pretty small) part of the console. There's a lot of other proprietary stuff for each console.
Spawn a background thread at the beginning of your program, send events to it through a channel as buttons are clicked. Use rayon's `par_bridge` on the channel if you want to handle requests in parallel via a thread pool. Use a `timeout_add` closure to poll for readiness and stop it once you have your result.
[https://github.com/AtherEnergy/rumqtt](https://github.com/AtherEnergy/rumqtt) Please give a shot to the new master. 
&gt; . This is purely for education and to possibly benchmark performance 
Very cool. Look forward to being able to contribute in the future. &amp;#x200B; SuperCollider in Rust would be very nice indeed.
&gt; C++ is the only language that actually has been picking up speed. I'd be curious data you're using to make this assertion. Going by [Stack Overflow questions](https://insights.stackoverflow.com/trends?tags=python%2Cc%2Cc%2B%2B%2Cgo) over a 9 year period, Python is rising meteorically from ~4% to 10.5%, C++ goes from 5% to 2.25%, Go from nonexistant to 0.5%. [TIOBE November 2018](https://www.tiobe.com/tiobe-index/) has C++ up by 2.94% and Python up by 3.2% in the previous month. [PYPL](https://pypl.github.io/PYPL.html) has Python up 5.4%, C/C++ down 0.4%, and Go up by 0.3%, all YoY. I'm just not finding anything to back up the assertion that "C++ is the only language that actually has been picking up speed", nor that "Python is fizzling out". I think sensational comments should be backed up with some hard data.
You can't have an article that blames C for being unsafe and hails Rust as the solution to it when it can also commit the same errors. Sure, it *helps* you not commit the errors, but you can still make them, and a lot people (including the author of this article seemingly) embrace the idea that it *is* perfect and "fixes" the unsafety of C. You can't blame *me* when it's other people acting like Rust is perfect. And I'm not even a Rust "critic". I love Rust and I think it's probably the highest potential compiled language out there today. But a lot of people act like it's perfect and I'm trying to say it's not.
Yeah, that appears to fit with how the persons involved assign blame.
OK so that means I spawn a new thread with a loop so the thread doesn't close. I know how to send Strings through channels. But if I do that, doesn't my closure still have to wait for the returned String so it can change the headerbar title? Meaning it would still be blocked. Can I pass a non-mutable reference through a channel? This way I could have a function named `change_headerbar_title()` and pass it the cloned headerbar. Is that even possible? 
OK that is more complicated than I thought. I need to look at this in more detail tonight. Thanks!!
Looks useful, thanks. &amp;#x200B; The \`json atom at path ".c" is missing from expected\` message seems wrong though.
C/C++ has been a necessary evil for a the past few decades. I'd say Rust is the first serious contender in a long time that improves things in a meaningful way without compromising on performance and while capturing enough developer mind-share to actually make a difference. If you are building something new, C/C++ is no longer the preferred or only option. At least not from a performance point of view. I don't agree developers are not willing to fix things. The Rust community is fixing things at a rapid pace targeting everything from critical libraries, operating system kernels, drivers, and key utilities. The thing is that, there's an enormous amount of really good C/C++ code out there and rebuilding all of that is going to take a long time. Also if the end result is that "now you can do the exact same thing but using code that is written in Rust" that is not necessarily a great incentive to spend enormous amounts of R&amp;D money. Yet, I'd argue projects to replace many of the critical bits of infrastructure with Rust are well under way. Long term there is also the potential to sandbox legacy C code using e.g. wasm. That on a Rust kernel, would allow for a smooth migration away from the current never ending stream of vulnerabilities that indeed always boil down to somebody finding yet another exploitable memory bug in C/C++ code. And that's happening in products where they've literally spared no expense (e.g. mac os, MS Windows, etc.) to prevent exactly that for the last decade. It's time to exclude that kind of thing that can happen in a system.
Thanks that's neat! Not a fan of the package management but the rest looks good.
Changing glibc to support being built with clang is also a possibility. Using `ifdefs` to support being built by the different compilers is the bread &amp; butter of writing portable C and C++ libraries. 
&gt; Note that "asking for them to do a lot of extra work to make something they don't use work" is exactly what Rust users are doing to Debian porters. Eh, this is not true. They are doing this because they want to. Nobody puts a gun to their heads and tells them "support software written in Rust or die".
You could try ndarray. Hijack! How are you solving the PDE, and what are you using for Energy and boundary conditions? I'm trying to make an ab-initio molecular simulator, modelling nuclei classically and electrons as wave funcs. Solving diffeqs in one dependent variable (like time) is straightfwd, but no idea how to approach it with 3 spacial dimensions, or what to use for BCs.
This was discussed (and postponed) in https://github.com/rust-lang/rfcs/pull/2483
Thank you for your response! I'll try it out
I'm only looking at essentially non-spatial problems so things like particles on a lattice (Bose-Hubbard model), optical cavities, or qubits. The total state is basically just a vector of all possible states of the system which is a finite set so the solution can be obtained by diagonalisation of the Hamiltonian. 
FWIW it is possible to do this yourself (I do it on my games), but it would definitely be nice to have built in.
Wow that seems really cool! I’ll check it out. 
&gt; What is "the unfortunate externalization of the cross-compiler toolchain"? Go wrote their own linker, and implements their own libc, effectively. This means that they can cross compile very easily. This also means they violate the platform's API stability, and so [really truly nasty runtime bugs can happen](https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/).
&gt; "Quite laborious" is a bit of an exaggeration. Granted, the process could be easier, but I used this tutorial and had it set up in about 20 minutes Go doens't have that 20 minute setup; you type a command, and you're done. There's good reasons that both setups are the way that they are, but it is true that Rust's cross compilation is good but not great.
&gt; There's no reason Well, there *are* good reasons.
&gt; You can't have an article that blames C for being unsafe and hails Rust as the solution to it when it can also commit the same errors. Note that none of us "had" this article.
&gt;Sony is surprisingly approachable, but I'm still heavily searching for a contact to Microsoft/XBox. Have you tried reaching out to say, the Ready At Dawn people?
This question is really impossible to answer without a concrete metric. Could you please provide a code sample demonstrating a performance problem and what your performance target is? Providing an equivalent C or C++ program that demonstrates that the performance target is reachable would also be useful.
Good question! I'd like to know why it is different passed directly vs not. The fix to that precise code would be to deref \`i\` eg \`for &amp;i in &amp;array\` so that it is copied into the inner thread, but I don't know why it does not work more generally (and what magic crossbeam does to make it different.. Reproduced here in the rust playground for easy experimentation: https://play.rust-lang.org/?version=beta&amp;mode=debug&amp;edition=2018&amp;gist=5f45f4e8c46e7136544eda1a6a1026c0
I honestly feel like people are purposely misconstruing what I'm saying. I *agree* with that sentiment. But *other people* seem to be claiming to have found perfection and they haven't. I've never once said not to use Rust or that it's bad.
the important detail is that writing correct code still takes effort, even in rust. Rust is not magic, it just disallows certain problems, which means demanding more upfront work. There is a downside which is: it must over-estimate safety. you must sometimes do more work finding a safe abstraction for simple things which are quickly verifiable to be correct through other means (*you still need to write tests*, in rust, because of the other ways in which programs can go wrong)
Thank you very much! More than I bargained for.
Your criticism is not interesting. I don't know of any credible source (even including the OP) that has claimed or even implied that Rust is "perfect." Every useful programming language in existence targeting the extant major platforms will always have a way of committing the same error. Properties that are universally true in practice aren't useful criticisms. Therefore, the interesting criticisms are in the details. The OP doesn't go into the details of how exactly Rust prevents memory safety related bugs, which is a completely fair restriction on scope. In general, if you find yourself believing that someone thinks something is a panacea, then you've _probably_ misunderstood their position unless it's clear that they are a [snake oil salesman](https://en.wikipedia.org/wiki/Snake_oil). But Rust isn't snake oil by any conceivable notion.
I write DSP/SDR code and Rust for a living, but not at the same time. If none of the available native options work for you, I suggest taking a look at [LiquidDSP](https://github.com/jgaeddert/liquid-dsp). It's the most comprehensively [documented](http://liquidsdr.org/doc/) DSP library I've ever seen. I'm tempted write bindings for it or just port it to Rust. Depending on how much functionality you need, you might do well with wrapping the parts you need.
You're welcome! Wishing you luck on your journey as a fellow Rustacean.
Your general comments really aren't my experience from using Rust daily at work now. By focusing on getting my logic right, I have been able to avoid encountering bugs for a while now (which is not normal in programming), even after rewriting functions that do things that aren't entirely protected by the type system (like using z-order curves correctly, boundary checks) and large refactors. I have been able to write things in significantly less time than similar C++ takes. Many such things would have required template metaprogramming in C++ that would not have been nearly as trivial as it is in Rust. I have experienced C++ development (writing tests, documentation, the like alongside code) and I really acknowledge just how much specialized knowledge is required to write good C++ and avoid "footguns" as some put it. My code also worked on Linux yesterday the first time it was tried. Such a thing is honestly amazing to me, as a C++ developer (python devs probably aren't as amazed). The development time of good Rust code seems to be significantly faster than good C++. The only case that might not be is when you have a C++ library for something, but not a Rust one, which does happen to us, and because of that C++ is still used for even some new projects. Also, there is some finickyness with using Rust with various debugging tools, and as you said sometimes you do get bugs in Rust. My point is that you seem to indicate there is some sort of tradeoff between the time it takes to write code and correctness that Rust does not solve. I think that production development would prove otherwise. Whether or not I have conveyed why this is the case, I can't say, but I don't think this is a zero sum game and Rust seems to be doing more than meets the eye when it comes to reducing bugs.
&gt;the important detail is that writing correct code still takes effort, even in rust. I think this is why you're seeing resistance. Rust isn't really about correctness; it's about eliminating a particular bug class. Yes, we care about correctness too, but it's not the first priority. You're talking about something that people here aren't talking about.
It will run on x86 machines from what I've seen. I am not sure if the ethernet drivers will work though. Obviously it's going to be pretty limited and unusable as a daily driver.
"This" likely means "have at least one tier-1 platform that was not x86". I think that's just a matter of declaration and probably won't help much. As I understand, Rust master is already gated on full test suite passing on ARM/Linux and ARM/Android.
I wonder if we could write a MIR -&gt; GIMPLE (gcc's intermediate representation) transpiler? If we did that, we could compile rust to all the targets that gcc supports?
I mean at this point I feel like we have different experiences of humanity. People *constantly* idealize almost everything. I really can't agree that almost no one in the world thinks something is perfect. That's an absurd claim. The article posted, definitely seems to have the attitude. Criticisms do not have to be interesting to be correct. I don't think any further helpful discussion is going to be had since we seem to live in different worlds.
Something is wrong if they don't design support for Linux drivers when Linux can use Windows drivers.
I thought about it, but I currently don't have the bandwidth to follow too many leads and don't want to waste their time :).
Fair!
4 minutes! How large is your project? You could also look into the webpack DLL plugin for dependencies.
you can't get that correctness whilst those bugs exist. my observation is that when you consider the big picture the front loading of *one set* of problems isn't always a win. Anyway I'm not *as* 'anti-rust' today. the language has been pleasing me a bit more recently. There's still tweaks that could help it though.
It is fairly small :( About 10k lines in total. Profiling with webpack shows that most of the time is spent in vue-loader and somehow css-loader. I am guessing something weird is going on there but between Nuxt, Vue and Webpack it's a pain to debug.
It seems you've gotten some really good advice about learning rust specifically and I pretty much agree with everyone so I won't reiterate that. I just wanted to give one more specific piece of advice. People are telling you to look at the field you want to be in and that's true but also look at the area you want to be in. Programmers are lucky in that we get opportunities to work remote and there are prospects in most cities. Some cities have slightly different ecosystems though. Like all the major languages are always useful and I've used C#, VB (.net and 6.0), Java, and to a lesser extent Javascript, Python, and Golang all professionally in Cleveland. The field matters the most, which is why you don't see any c or c++ in my professional languages. The area around me though is heavily skewed towards C# and the .net framework. If there was a new developer in my town I'd strongly consider them starting or focusing there. The area that you would like to work in could have a different ecosystem that jobs tend towards. So I would also consider that when thinking about where you want to do your "heavy lifting" when it comes to learning something new. P.S. I'm sure you've heard this and know this but any specific language is likely not going to be as important as the basic skills. A javascript programmer would likely have a tougher time moving to C++ but the basics are there and it's even easier to do something like Java to C# or the other direction. Especially for most junior and entry level positions. Like my current job is my first time really writing any Java heavily. As you get more experience and do bigger projects then being able to understand some of the finer points of a language will become more important. So I'll end with saying knowing the basics of a few things is great, so at least when you move around it's not so jarring. Knowing different paradigms is even better e.g. understanding functional. Learn what interests you the most, it keeps you learning and interested, but if you're going to deep dive a language I'd say focus on what makes sense in your field and area. Everything else is just bonus, they help you think in a different way, I think my Java is stronger because I know rust and think more about memory now, and when my boss says wow parsing these log files is going to take forever I can suggest trying to whip something up in rust and take advantage of that tool in my tool belt. Sorry this got a bit long but I didn't have some of this advice and it would have helped me with some stress so I wanted to pass along what I thought.
/u/sdroege - it seems like it would make sense to write a channel-like API on top of glib::idle_add? Maybe there already is one? 
Thanks for posting that link.
Could it make two u32s out of every u64? If the u64s are reasonably random, splitting them up into two parts should not introduce any bias.
That is not to suggest that people don't value the ability to use Rust in a wide variety of contexts, or that the Rust developers aren't willing to develop the language to support new contexts. However, at the end of the day, Rust *must* be memory safe, it *must* be performance-competitive with C and C++, and it should be as ergonomic as it can be while abiding by those two goals, while also striving to avoid footguns and easing the learning process for new users as much as it can. Where it is possible to expand Rust with new features that don't compromise these goals, there's no problem. But there's no free lunch, tradeoffs are everywhere, and Rust will simply never be the easiest way of performing tasks in certain domains. For a topical example, async/await (or anything congruent to it) is something that Rust has been trying to add in a fast and safe way since 2011, and only recently is the design coming together, and even once it arrives there will still be languages that are simply easier to use to get things done quickly, especially if you don't need extreme performance. Rust doesn't strive to extinct every other language. I know several languages that *do* strive for that. That's what I mean by "world domination".
What are you going to do with existing codebases? Rewrite in Rust? How long will you wait?
You can use the include or exclude fields in Cargo.toml, see https://doc.rust-lang.org/cargo/reference/manifest.html#the-exclude-and-include-fields-optional. Then exclude your examples, or better yet only include your code for smaller packages.
I think this is a hard problem if you want to do within your binary (that the window being of your application). However you could use something like open (https://crates.io/crates/open) to open the pdf with an external program. Your users might even prefer to use there own pdf reader.
The character choice in ASCII is mostly letters, symbols, and control keys on American English keyboards. APL required a language-specific IBM Selectric typeball to display its characters for recording source code and the teletype printers APL typically used for UI back in the day.
That's the actual headline.
There are a couple compile-time optimizations currently being worked on for cranelift. Those should improve this more hopefully.
Im a fan of cranelift. But I wish there was an easier way to use wasm with it. Something like WasmEnviroment::new(), then you give it functions rferences and wasm files and then you can "compile" it. So that the user doesn't have to deal with stuff like RelocSinks and NullTrapsSinks.
\`cranelift-module\` improves things somewhat. But, it's the responsibility of other crates, like \`wasmtime\` and others, to provide that sort of api.
Wrote a simple `map` command for the shell. It's simpler than xargs and hopefully more ergonomic. https://github.com/bddap/map 
I'm probably one of their loudest customers requesting Rust but I still feel there's a chicken/egg element to it.
You can do this as a one-liner: employees.entry(department).or_insert(Vec::new()).push(name); [Playground](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2015&amp;gist=7b4ce3e3f5d2b575826a389711dae286)
You can do it even shorter and more efficiently with: employees.entry(department).or_default().push(name);
Check out the Yew architecture; it's inspirations include Elm.
It's just that \`c\` *is* in the expected json and was missing from actual*.*
In some applications, using the CPU will be faster. In particular if you have a loop in which some ops cannot be performed (efficiently) on the GPU, then the cost of transferring data between the CPU and the GPU might outweigh the speed increase gained by doing the linalg ops on the GPU instead of the CPU.
Yew looks interesting, and I have used it as inspiration. However it's API is pretty far from Elm. I wanted to see how close Rust code could be to Elm code.
PBR stands for Physically Based Rendering ...see https://www.rs-pbrt.org/about The T might come from https://en.wikipedia.org/wiki/Blue_Moon_Rendering_Tools (as a reminder of BMRT). Or simply stands for Theory like in the book title: Physically Based Rendering: From Theory to Implementation
The OP never once uses the word "perfect," nor does the wording even imply it. The very last paragraph is very clearly not supposing that we can achieve perfection, but that we should instead endeavor to improve (with the obvious implication that Rust is one such vehicle for that improvement): &gt; Memory unsafety is currently a scourge for our industry. But it doesn't have to be the case that every Windows or Firefox release fixes dozens of avoidable security vulnerabilities. We need to shift ourselves from treating each memory unsafety vulnerability as an isolated incident, and instead treat them as the deeply rooted systemic problem they are. And then we need to invest in engineering research into how we can build better tools to solve this problem. If we make that change and that investment we can make a dramatic improvement to computer security for all users, and make HeartBleed, WannaCry, and million dollar iPhone bugs far less common
Really cool project! &gt; &gt; https://github.com/sindreij/willow/blob/master/README.md#quickstart &gt; &gt; cargo install wasm-pack &gt; wasm-pack build &gt; cd www/ &gt; yarn &gt; yarn start Why is yarn required? Is this usable without Node.js?
&gt; Does the compiler build your procedural macro into a dynamic library first and then run it against the AST during the compilation stage to produce the IR? Pretty much, yeah. &gt; Does the Rust code within the macro, the code that you write, end up in the final binary at all, or only the actual product of the macro after compilation? It depends - if you're building a linkable library, the proc macro code will be inside so that other libraries can import and use the macro; if you're building a binary, the macro code will probably be eliminated.
Okay, that's... interesting. Do they completely replace compiler plug-ins, or are they just 95% of the way there so that only *truly odd* things would require a compiler plug-in? 'Cause what the [typed-html](https://github.com/bodil/typed-html) library is doing with them seems like the kind of thing you'd have used a plug-in for, before.
Did you consider making `update` take the `Model` by value and return it? That would look more like Elm's update function. Not saying it would be better, but it's something to consider
That's a neat Idea. I feel like giving it a shot when I have time
With 2019 coming, I am excited about a number of possible developments in Rust, such as value generics and custom DSTs. Stacked Borrows, however, is definitely my *favorite*. Using unsafe Rust at the moment can be rather tricky, as what is allowed or not is not always clear. A specification/model for unsafe code is therefore absolutely necessary for Rust to be usable in domains where correctness is highly valued. And for most languages that would be it: write a specification, hope it works, call it a day. The idea of having (1) a formal, proven, model and (2) an automatic verification that the code follows the model? This goes beyond my wildest dreams. Of course, the automatic verification will not be "total": we are looking at a dynamic checker, not a static one. Still, it's so far beyond what I've come to expect from other languages, I am just buzzing with excitement!
When would you use an associated type (as in Push1) vs how Push2 does it? trait Push1 { type Elem; fn push1(&amp;mut self, elem: Self::Elem); } impl&lt;T&gt; Push1 for Vec&lt;T&gt; { type Elem = T; fn push1(&amp;mut self, elem: Self::Elem) { } } trait Push2&lt;T&gt; { fn push2(&amp;mut self, elem: T); } impl&lt;T&gt; Push2&lt;T&gt; for Vec&lt;T&gt; { fn push2(&amp;mut self, elem: T) { } } &amp;#x200B;
The issue is that `Filter::or` will wrap the values in a private `enum Either&lt;A, B&gt;`. If `A` and `B` are the same type, you can coalesce the value out of the `Either` via `Filter::unify`. In short, `dynamic.or(default).unify().map(handlebars)`.
I have considered it, however I think the design I ended with is easier to use, and will be just as safe as the Elm version. For instance doing what you propose will mean that we cannot move on if the update function panics.
this is incredible. 
To state it simply: In many other languages, strings are just byte arrays. In Rust, types `String` and `&amp;str` *always* represent valid UTF-8 strings. (The only exception would be if someone used unsafe code to force it, which would be unsafe.)
AFAIK Windows has a stable driver API while Linux doesn't
Already? What the hell. Last I checked Clif was still a very immature project (not in a bad way, lots of good action happening there). It just seems unrealistic that it already beats LLVM in such a metric, given how much development action and money LLVM has behind it.
It would be great to write co-routines with confidence that they won't allocate. The optimizations I was referring to are Gor's description of the LLVM advantage with cross-function boundary optimizations in co-routines. I'll take a look at the Rust co-routines examples to see if I can create similar cross-coroutine optimization in Rust.
&gt; By focusing on getting my logic right, I have been able to avoid encountering bugs for a while now Those kind of bugs are trivial. All my time goes on issues outside the language:- - navigation/discovery of APIs (and my own code from last week lol) - getting maths right - getting file formats right - getting interactive states right - getting maths right the other side of the CPU/GPU right rust's tools can help with some of this ('file formats' &lt;-&gt; reflection), it has certainly been pleasing for writing an async io system, but given the time I've spent adapting , and comparing the "achievement curve" i.e what can I do in year 5 of rust, vs what had I done in years 1-5 of C and C++, it's a disappointment. &gt; The development time of good Rust code seems to be significantly faster than good C++. I find C++ is still just better at expressing vector maths. enum/match is certainly very pleasing for events/message passing. I guess I've just got very good at handling raw pointers. I used to code in asm. it's possible the mentality for 68k post increment dressing etc translated directly into having ```*p++``` all over the place.. I have patterns around that burned into my head at the 'instinctive/intuitive' level.
Cranelift is making progress, and you can see in this link that there's now a prototype Rust backend that works well enough to compile simple Rust code, which is really exciting! The benchmark being discussed here is a microbenchmark, and it's helping us identify [opportunities for improvement](https://github.com/bjorn3/rustc_codegen_cranelift/issues/133#issuecomment-439471647), however we should refrain from jumping to broader conclusions at this point.
This means that Rust is getting mainstream attention, we're starting to cross the popularity threshold. Maybe 2019 is the year where "all the cool companies" want to be using Rust, so we could see a large increase of available Rust jobs soon..
One of the main points of --opt-level=0 is to help debugging. Source code is executed in order, all stack variables are 0 inited and probably some other things. Is it possible that cranelift is over optimizing and reducing the ease of debugging at --opt-level=0?
Was reading the other day, from [Cranelift compared to LLVM](https://cranelift.readthedocs.io/en/latest/compare-llvm.html): &gt; LLVM provides both common optimizations and a code generator. Cranelift only provides the last part, the code generator. Is this still the policy? Specifically, if I have a language writing `clif` files, am I expected to do most optimizations myself? Maybe an external project or two will implement optimization passes over IR like LLVM does?
This is still the policy, though, once we have a fleshed-out codegen, we are planning to explore superoptimizations. `cranelift-preopt` is currently the place where basic optimizations should go.
There are [two medium-term goals](https://github.com/CraneStation/cranelift/blob/master/rustc.md), one to support unoptimized outout for debugging as you describe, and one to be a moderately-optimizing backend with fast compile times. The benchmarking here is focused a little more on this second goal, though of course both are important.
... on a single tiny microbenchmark. But it does mean that we have a prototype and it's far enough along that we can do a few microbenchmarks with, which is a cool milestone :-).
Yeah. I expected to get c but I didn’t, so that’s an error. 
Ah I think I see it now. Lol. 
Thanks, you just made my day. &lt;3 Such comments are one of the many reasons I love Rust :) &gt; formal, proven, model Just to be clear, nothing is formally proven so far. Doing some of that is on our list of intern projects though. :D
This exists! You can't pass it an arbitrary function though, because it'd have no idea how long that function will take in total. You need to tell it how much progress you're making. [Check it out!](https://github.com/mitsuhiko/indicatif) It also supports spinners and bars that are finer than the ones cargo is using right now.
&gt; It's much like LLVM's text form ehh… LLVM IR actually does abstract a lot of the target arch. In Go asm you directly use the target's instructions. Well, the supported subset of them. If the stuff you need isn't supported, you have to resort to cgo (and its overhead) or [HORRENDOUS HACKS](https://github.com/minio/c2goasm). Go asm just tries to have uniform *syntax* across architectures, not instruction semantics. It adds the Go function and stack semantics though, with the requirement to explicitly specify used stack space (ugh)
&gt;The difference in philosophy on how to handle errors is interesting when comparing these two languages. They are very similar, and at the same time very different. I have no idea about Elm. If anyone has the knowledge, how do they compare?
Stupid question... Does this approach accept more correct cases compared to the existing borrow checker?
This is possible for Push2 but not for Push1. Push2 can be implemented multiple times for the same type, Push1 only once. (As a simple check: there is no way to disambiguate Push1 with target u8 and with target u32, so that's bad). impl Push2&lt;u8&gt; for Vec&lt;u32&gt; { fn push2(&amp;mut self, elem: u8) { self.push2(elem as u32) } }
Dynamic analysis tools are not conclusive either! They're only as good as your test coverage.
Static analyzers and valgrind aren't magic either, so a class of bugs which are usually impossible in rust are still there, and undetectable. That extra lifetime information you mentioned is how Rust achieves memory safety. It's what allows rust to statically know your code is fine. You need that information for this.
Thank you! I've been using js's `json-diff` external command in my tests just for that :) I think there's a room for making the diff prettier, but it already is very useful for me!
Note that llvm with no optimization produces absolutely ridiculous code that a human would beat without even trying.
Suggestions are very welcome 😊 
Yep, so does cranelift :) When cranelift is handed decent ir, it produces decent machine code, but the ir that rustc produces isn't great.
Most projects using an ESP32 run FreeRTOS which was recently purchased by Amazon
I am using draco which is another elm inspired rust crate. https://github.com/utkarshkukreti/draco
Wouldn't the later be better compared with --opt-level=1. I so rarely use that that maybe I'm miss understanding it's purpose.
No, you have the signal send the event, and at the end of the signal you create an timeout signal that will try to receive the response every 16ms or so. No blocking.
If you follow the link, we have O1 numbers too. But none of this a serious comparison at this point -- it's one tiny microbenchmark. It has meaning to the people working on it, but has little meaning otherwise.
I think the coolest thing about Cranelift is the logo. =P
This seems obvious, but I'm not sure. When writing a crate with no_std support, is it still possible to use functions like `std::cmp::min`?
For the kind of work that OP wants, common GPUs are useless, because they lack fp64 cores. If you want to diagonalize the Hamiltonian of a somewhat large system, you will get contributions that are very big and very small. You already struggle with finite precision on double arithmetic (and have to come up with tricks to fix that); if you are stuck with single precision you can as well go home.
Unfortunately, (well, fortunately for rustc,) procedural macro expansion order between items is undefined. It _might_ be _coincidentally_ possible to memoize work between invocations of a proc macro by (ab)using thread local storage, but this isn't in any way guaranteed to work. You'll want a pre-processing step handled by a build script. That can read through your source directory and emit a source file to be `include!`d. (This could be helped out at compile time by a proc macro, but the collection step has to run sperately to the compilation step that expands macros.)
Is there a reason you want to use fork/setuid? What does it give you that you can't do with actix (actor model) or the tokio ecosystem (futures)?
Procedural macros are basically `String -&gt; String` transformations (or more precisely token stream to token stream). I never used compiler plugins but they are probably more flexible than that.
I'm working with openapi yaml files. These files can have references to other pieces of the file. Resolving the reference is basically copy/paste the referenced object in the referenced place. This is also a highly nested structure. I would like to transverse it and resolve all the references so I dont need to deal with this in the rest of my code. But of course Rust does not like modifying somthing you are iterating over. As an example. `definitions:` `Country:` `properties:` `regions:` `items:` `$ref: '#/definitions/Region'` I'm using a crate which models this as BTreeMaps and Vectors. I'm very deep in this structure by when I find the $ref I want to substitute. Is there any solution to modify as I iterate, or if not, how do people deal with this problem? &amp;#x200B;
Zero optimizations means pretty much nothing. 
I do that as a security measure. The API needs to sometimes read and write files and other resources in the context of a particular web site, which are spread across multiple UIDs. As an extra layer of protection against creating files the web site could abuse or reading files the site wouldn't have access to, I setuid when possible so I execute as little as possible as root. This helps protect against both bugs and malicious users. The alternative with actix-web, as far as I can tell, is to either do all the protections in code (ownership, access checks, etc) in every place they are needed, or repeatedly switch in and out of setuid mode.
When you say it's not "total", does that just mean you can't catch undefined behavior if you don't actually trigger it? Is it possible to say with certainty that, if you do trigger undefined behavior, it will be detected?
I think it would, since this is dynamic at runtime and would only fail when you actually trigger undefined behavior for real. Lots of things are actually sound, and thus wouldn't trigger undefined behavior, that the borrow can't currently detect. E.g. all the stuff coming soon with NLL.
Is there any place I can go for simple code reviews? I wrote my [first lines of rust code ever](https://github.com/briankung/project_euler_rs/) and solved some Project Euler problems, and now I'd like a second look. I can already tell I'm going to have problems with the borrow checker.
Wait, what? Are you running your webserver binary as root? And using suid to manage user permissions? I can't think of a way to read what you said that actually is a beneficial to a security model. 
Do you ever use the array index operators?
Unfortunately, yes, because the interface is used to manage multiple sites/users on the same server, much in the same way as a SSH server would (or Telnet or FTP in the bad old days). As such, it needs to both act on behalf of multiple UIDs, and to access to resources the user wouldn't have direct access to, such as databases, files, mail spool, etc. The most direct solution is to run as root and setuid as soon as possible. Yes, it's (far?) less than ideal. If you have suggestions for how to restructure it to not run as root, I am open to reasonable alternatives.
Oh, and to be clear, the current API is not running under Apache or anything like that. It is a custom HTTPS server based on Python's http.server.
Looks pretty good to me. Here are some small things: - Instead of `let max_size = 4_000_000 as i32`, prefer `let max_size: i32 = 4_000_000` or `let max_size = 4_000_000i32`. The first one is a cast operation, which isn't what you mean, and I think in some cases it can silently truncate. - That said, most of the time you don't actually need to specify types for your ints, because the compiler can infer them. In this case, the line `if next_fib &gt; max_size` below will convince the compiler that `max_size` must be an `i32`. - The line with `sum` does need an explicit type, but I think it's slightly more idiomatic to say `let sum: i32 = ....sum()` than to use the "turbofish" `sum::&lt;i32&gt;` notation. But others might disagree with me here; this one's definitely a matter of taste. - An algorithmic comment rather than anything Rust-specific: You don't need to keep all the Fibonacci numbers in a vec. It would be more efficient to sum them as you go along, and to avoid using the extra storage. That said, your use of the `.iter().filter(...).sum()` methods is very nice. I also like your use of the `|&amp;num|` pattern match to dereference the argument; a lot of new Rustaceans don't realize that you can do that. - Rather than `fibs.get(fibs.len() - 2).unwrap()`, it's simpler to just write `fibs[fibs.len()-2]`. The behavior is the same, in that both will panic if the vec is too short. Usually I only reach for the `get` method if I actually want to handle the case where it returns `None`. - `println!("{:?}", sum)` is printing the "debug representation" of `sum`. In this case that's the same as the "display representation" (or whatever it's called), so you can just write `println!("{}", sum)`.
Yes, but rather than using `std::cmp::min`, you need to use [`core::cmp::min`](https://doc.rust-lang.org/core/cmp/fn.min.html). `std` is generally a superset of `core`, and it reexports a lot of things that are defined there.
If separate threads/processes are that important, then I'd suggest creating them manually in the handler.
ok .. worse happens in C++ :) I did think 'well at least if doing it as an external tool, the easy-to-grep syntax helps'.
Not sure how related it is but [I'm working on a tool](https://github.com/JordiPolo/minos) to compare server json API responses to their openapi definitions. Although it is not meant to be used in unit tests
Rust and then they pay me back into star wars It's a little while ago,
Chroot, jails, containers, even normal user/groups permissions should be flexible enough. Micro service arch could even work better where you’re actually running a different process for every user with some kind of dispatcher. 
You can use static globals (inside Arc&lt;Mutex&lt;&gt;&gt;) to hold onto procedural macros state. It's probably really hacky, but it works 
Rouille is a nice non-async web framework.
So I can almost promise you that you’re doing it wrong. Writing it in rust wont help this type of issue at all. Pm me a little bit more details and I’ll work with you this weekend. 
What version of rust are you using? What do you see when it hangs when running with the `--verbose` flag?
&gt; what’s the best way of serializing / deserializing a `Vec&lt;Box&lt;SomeTrait&gt;&gt;` object? Is your problem that there's no reasonable way to pass context around when deserializing? You could have a static global variable, but that's a bit icky. I'd suggest deserializing to a `(TraitClassId, &amp;[u8])` within some deserializing-specific structure, and then post-processing that into your real deal.
Love it
I added a simple function and reran the compiler and hanged at the step below. `$ rustc --version rustc 1.30.1 (1433507eb 2018-11-07)` `$ cargo build --verbose Fresh version_check v0.1.5 Fresh libc v0.2.43 Fresh cfg-if v0.1.6 Fresh ucd-util v0.1.2 Fresh rand_core v0.3.0 Fresh utf8-ranges v1.0.2 Fresh regex-syntax v0.6.2 Fresh rand_core v0.2.2 Fresh winapi v0.3.6 Fresh memchr v2.1.1 Fresh lazy_static v1.1.0 Fresh rand v0.5.5 Fresh aho-corasick v0.6.9 Fresh thread_local v0.3.6 Fresh regex v1.0.5 Compiling karma_dice_rust v0.1.0 (D:\Fat WAFFO\Documents\Projects\karma-dice-rust) Running `rustc --crate-name karma_dice_rust 'src\lib.rs' --color always --crate-type lib --emit=dep-info,link -C debuginfo=2 -C metadata=dc26bcdf8253feae -C extra-filename=-dc26bcdf8253feae --out-dir 'D:\Fat WAFFO\Documents\Projects\karma-dice-rust\target\debug\deps' -C 'incremental=D:\Fat WAFFO\Documents\Projects\karma-dice-rust\target\debug\incremental' -L 'dependency=D:\Fat WAFFO\Documents\Projects\karma-dice-rust\target\debug\deps' --extern 'rand=D:\Fat WAFFO\Documents\Projects\karma-dice-rust\target\debug\deps\librand-cf77ebb47b455c7d.rlib' --extern 'regex=D:\Fat WAFFO\Documents\Projects\karma-dice-rust\target\debug\deps\libregex-2e5b9f9b020c18c5.rlib'` Building [=================================&gt; ] 23/25`
I found myself musing recently about how fast Rust could compile if it bypassed LLVM entirely in debug mode and just dumped a bunch of naive assembly. As I understand it this is roughly what Jon Blow's JAI compiler does and that thing is _quick_.
&gt; Some models have 1MB memory. UNIX was written for a PDP/11 with less memory... :) Not to mention the flash. The ESP32 only has 520KiB of SRAM, but you can get ESP32 modules for a few dollars which come with 4MiB of flash memory.
This is way more than I could have asked for. Thanks! And I definitely don't deserve praise for anything here - any quirks, whether positive or negative, are more likely due to the efforts of some StackOverflow answer rather than my own cleverness. * Perfect, thanks. `let max_size: i32 = 4_000_000` it is * ...and nevermind, thank you! * Got it. I really need to look into the different type annotations and when you need to use them * I figured it was easier to do the easy thing first ("Stupid is as stupid does, sir!") and then try being more clever if it ended up being too slow for Project Euler's hypothetical 60 second cutoff. This wasn't an issue for this problem, even in Ruby. Oh, and the `&amp;num` dereference I absolutely cannot claim credit for; I got it from [this blog post](https://matthias-endler.de/2017/rust-for-rubyists/) * Wow, this is much better. I don't know why I didn't think of that. Thank you * Got it, thanks! Such great feedback, thank you very much!
I'll wait to watch the recording once it is available, but from the slides I have a feeling that this may be the *defining* introduction-to-Rust talk that I have been missing for a long time -- the one that finally articulates why so many people are so excited about Rust in the context of system software, the one you nudge people to watch when they are vaguely curious about Rust but dumping them into TRPL would be asking too much. The closest to a canonical introductory talk so far has been the one that walks through borrowing an element of a Vec, inserting into the Vec and potentially invalidating the earlier borrow, explaining why it's bad and how the compiler catches that class of bug (a few different people have given this talk in different flavors over the years). It's educational but I have never felt comfortable pointing friends to that talk before they were already committed to learning Rust, and by then there's no reason to watch the talk because The Book will cover the same concept sufficiently well. I didn't have a resource that could bridge the gap between "curiosity with a healthy dose of skepticism" and "committed to investing more time" (or at least "clarity as to whether this language is relevant to my interests") until now. Thanks /u/bcantrill!
Try r/PlayRust 