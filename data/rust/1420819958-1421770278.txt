&gt; (The `call_method_on_...` functions could also be UFCS: `&lt;... as Foo&gt;::method`, but that’s somewhat less clear.) I should point that the syntax hasn't been yet implemented (in expressions; associated types promted the implementation of this syntax in types) at this point (so 1.0.0-alpha doesn't have it).
I just wish we had some form of down-casting.
Interesting. I assumed it was similar to C++ polymorphism, one big struct and you take pointers to slices of it, not "fat pointers" containing a pointer-to-data and a pointer-to-vtable.
Yes, I've been a litlte lax in getting it all down. Getting all of our features documented is one consequence of 'the book' and an advantage of the stability alpha/beta provides.
The problem is that doing it this way misses the point a bit (which is why it isn't idiomatic). If I were a newcomer and saw that `is_some()` example, I would just say: "how is this different from a null check in Java? These Rust people sure are hyping up a weird feature." But what Rust is doing isn't just a way to remove boilerplate from an "is null" check. It's making it *impossible* to extract the value without checking the tag. That is demonstrated far more effectively by the `match` version. If you use match to extract the value, you *cannot crash* because you cannot screw up the check. This is a far more powerful guarantee than what `unwrap()` gives, which is why `unwrap()` is strongly discouraged. It's also the thing I miss most about ADTs in other languages. You can sort of emulate them with subclasses but at the end of the day you simply cannot get that non crashing guarantee from the compiler (sure, you can "be very, very careful" to check before casting, but anything that requires constant perfection from humans is a flawed strategy in the long run--doubly so when working on a shared codebase).
That looks great, /u/steveklabnik1! Just one little thing: In the conclusion, you wrote: &gt; There's tons of topics that you can dig deeper into, and we've built specialized guides for many of them. To learn more, dig into the full documentation index. The last words link to the book index, though. Do these sentences even make sense anymore?
It was mostly a design decision, but it did help shorten the implementation by a few lines. I wanted to wrap each function in a trait so that I could have other traits that derive from the BLAS traits have good default implementations. I'm not sure if there's a less verbose way to accomplish that?
Function from Operation appears to have shadowed the struct Function. On another note, struct-like enum variants are un-feature-gated now; Operation::Read, for example, could be Read { ref: u32, fieldname: String } (but ref is a keyword so you'd have to name that something else.)
Me too. I really do think this is something that should be adressed asap. Alot of people are gonna try to use Vec&lt;&amp;myTrait&gt; and get stuck because they cant downcast. 
downcasting and upcasting and also going from trait objects back to concrete objects should be supported. As well as having different trait objects pointing to the same instance via smart pointers. As long as this is not supported Rust is quite broken for me (becaust it's seriously lacking in dynamic dispatch). Can't understand how 1.0 can be released without that.
1.0 is not meant to be feature complete. It is meant to be the first version of rust with a backwards compatible guarantee. It's missing a lot of things (both unstable and unimplemented) . You may use https://github.com/reem/rust-unsafe-any for downcasting
&gt; and then stick an #![allow(unstable)] in your crate root. Do you also know of a way to enable this for a doctest? As far as I know unstable is denied there.
I actually have deployed updates for it as well!
ALL HAIL THE NEW "RUST BY EXAMPLE!"
Woo, finally! Now I only need to find the time to actually do something in rust. On another note: &gt; Contributors: &gt;... &gt; bors bors@rust-lang.org Perfect
[You are right!](https://github.com/rust-lang/rust/pull/20786)
1.0 will send a signal out: This is ready for production. This might attract a lot of new users. Some of them might be disappointed to learn that a core feature in many other languages does not work in a sophisticated way in Rust.
&gt; Every half hour, take a short break from jackhammering the F5 key. The alpha release isn't worth RSI. It was worth it, man.
I gave it a try: https://github.com/rust-lang/rust/pull/20817
Seriously, bors only took *a single day off* last year! Check out that contribution history: https://github.com/bors Go bors, you're a machine!
Please do. Would love to tweet tons of good blog articles. :)
Indeed, the tone of the article was most amusing!
To coincide with the alpha release, we're refreshing our code of conduct with some new terms, mostly to add in specifics regarding our moderation policies. Speaking as someone who's been a moderator here for years now, I'm incredibly impressed at the community that we've fostered so far and the respectfulness that you've all shown. We're not always perfect, but this subreddit has largely thwarted my cynicism of the internet at large. :) Well done, everyone! For posterity, the original code of conduct post can be found here: http://www.reddit.com/r/rust/comments/1nvsdh/a_note_on_conduct_please_read/
Significant slowness in a standard component is very much worthy of a bug report. There's even a tag for it in the issue tracker: [I-slow](https://github.com/rust-lang/rust/issues?q=is%3Aopen+is%3Aissue+label%3AI-slow). Feel free to file if you think we should be doing better!
Congratulations !! Amazing work done by these folks!!. Now we need good books/blogs to learn and teach.
\o/
As someone who is interested in Rust but hasn't started learning it yet, should I just wait till 1.0-beta1?
Can we have navigation arrow to move to next/previous page? I did not see on Chrome browser. 
With those changes Rust should work pretty good on all iOS architectures. Snapshot of cross-compiler for all archs is available [here](https://github.com/vhbit/rust/releases/tag/ios-latest) 
"ready for production" and "has every language feature possible" are two different things. Most languages add new features after an initial release...
I would love some help with that, if you know how to make it happen. I'm bad at JavaScript.
I run nightly from 2014-01-04. Could you give the exact code that you use to benchmark the std hash?
I use -O.
It's slow because it's hashing each element in the slice individually. That's the downside of implementing `Hash` generically in the std lib. Try chaning `Vec&lt;u8&gt;` to `Vec&lt;u16&gt;` etc. Remember to adjust `b.bytes` accordingly if you really want to measure MB/s. It works like this: std::hash::hash(data) data.hash(&amp;mut hasher); data.len().hash(&amp;mut hasher); hasher.write(&amp;[a, b, c, d]); 0u8.hash(&amp;mut hasher); hasher.write(&amp;[0u8]); 1u8.hash(&amp;mut hasher); hasher.write(&amp;[1u8]); 2u8.hash(&amp;mut hasher); hasher.write(&amp;[2u8]); 3u8.hash(&amp;mut hasher); hasher.write(&amp;[3u8]); 4u8.hash(&amp;mut hasher); hasher.write(&amp;[4u8]); ... hasher.finish(); I believe writing a Rust-specific LLVM pass and tuning the code for `Hash` is the best way to fix this slowness. Special-casing `Hash` for slices would be another approach. /u/Jurily was the first one to discuss this. http://discuss.rust-lang.org/t/unstable-hash-architecture/578
This is what I'm using to benchmark: #[bench] fn bench_1k_rust(b: &amp;mut Bencher) { let mut hasher = SipHasher::new(); let bytes = rand::thread_rng().gen_iter::&lt;u8&gt;().take(1024).collect::&lt;Vec&lt;u8&gt;&gt;(); b.iter(|| { hasher.write(&amp;bytes[]); hasher.finish(); hasher.reset(); }); b.bytes = bytes.len() as u64; }
I think this would be quite hacky to do right now in JS (basically comparing the current URL with the links in the sidebar). Highlighting the current page in the sidebar might go a long way, though. What are the plans for rustbook anyway?
Ooooooooh, I like the inclusion of multiple dispatch.
http://doc.rust-lang.org/std/ffi/fn.c_str_to_bytes.html
That depends on your level of interest, but I'm repeating myself :)
&gt; What are the plans for rustbook anyway? Develop it further. It'd be nice to have Rust by Example use it as well. I know that sounds generic, but I'm not sure how much time I'm going to have, exactly.
My Java history is a bit fuzzy, but since Generics weren't added in 1.5, weren't interfaces part of that work?
Ahh yes. There are more than zero Rust programs that work, however...
Yes, but how many UI frameworks that follow common patterns does Rust have? How many completion based IO frameworks? Websocket libraries? Straightforward programs (not event-based) like compilers might already work pretty well, yes. However with the current situation it's simply not possible to build or wrap something like QT in a sensible way.
That's why I said **following common patterns**. conrods immediate mode is nothing most developers that have worked with Win32, QT, GTK, XAML, Flex, DOM, etc. before would expect when they want an UI framework.
Use integers to store the number of pennies?
/u/Florob0x2a's comment says otherwise.
The ```num``` crate has [BigRational](http://doc.rust-lang.org/num/num/rational/type.BigRational.html), which should cover most use cases. It wouldn't be the fastest type, but I can't imagine something safer.
&gt; - tuple: canary &gt; - tuple: first field: canary &gt; - String: canary &gt; - Vec: canary (as String's underlying object) &gt; - Vec.len &gt; - Vec.cap &gt; - tuple: second field: canary &gt; - String: canary &gt; - Vec: canary &gt; - Vec.len &gt; - Vec.cap AFAICT, none of these exist. The writes that happen for `(String, String)` in our current scheme are: - `[u8]` buffer of the first field - `0xFF_u8` to indicate the end of the first string (0xFF can't appear in a string) - `[u8]` buffer of the second field - `0xFF_u8` to indicate the end of the second string (Of course, individually writing each and every element in general isn't so great.)
Thanks!
So you lied in the reddit thread? I guess you are... Wronger...on the internet? :D But yeah, that's awesome that it is ad fast as the C version!
Someone asked about forward only `goto` that can't enter blocks, and I was like hey... wait a minute... we have that :) We still don't fully replicate goto (I'm pretty sure, anyway) but this addresses some of its usecases. Also worth noting: we can't write a slightly less desugared version of this macro where you can provide explicit labels and jump forward to any subsequent branch, because there's no useful way to pass a plain lifetime to a macro (since it's not a valid expression by itself).
You could add an `nalgebra` [feature](http://doc.crates.io/manifest.html#the-[features]-section) to the `rblas` crate that links to `nalgebra` and adds the appropriate trait implementations. The reason to make it a feature is so that downstream users of the `rblas` crate wouldn't have a dependency on `nalgebra` by default, only if they want those trait implementations (presumably because they're using `nalgebra`).
That example should be reworked to choose a fixed-size integer. The whole reason for `int/uint -&gt; isize/usize` was to make it clear to users that these integers are machine-dependent and to only use them for operations that are machine-dependent, such as pointer offsets and collection sizes. Unfortunately, the reference isn't really kept up-to-date with the language but it's high-priority once the language stabilizes.
You get that error because you have an old compiler, that array syntax is pretty new. Does home rew actually install the beta? What's your rustc --version? And yes, I'd love your contribution! The text is in src/doc/trpl in the Rust repo.
You, sir, are right. I'm still running 0.12. And thanks for the heads up on how to contribute!
Awesome :)
I was under the impression we would get i32 as the default type thus i and u suffixes would still work. 
&gt; macro_rules! has been declared stable. Though it is a flawed system it is sufficiently popular that it must be usable for 1.0. Effort has gone into future-proofing it in ways that will allow other macro systems to be developed in parallel, and won't otherwise impact the evolution of the language. Anyone else worried about this? I'm worried about this. 
Or you could do something other than stare at the screen while it compiles...
Any guide / tutorial how to build for iOS with rust?
`Box::new` can be used in that macro as well. 
Rust by example seems hopelessly broken at the moment.
Can you articulate your specific worry?
The announcement mentions integer reform in the std lib - is there an RFC about that, or a short summary? It wasn't linked. I'm curious mostly because one of the first bugs I had was a `.len()` returning a u32, which I promptly threw into a subtraction and wrapped - I'm strongly of the opinion that unsigned types should be reserved for bitmasks and the like where subtraction isn't going to cause a hard-to-detect underflow error. (Unless there's a simple way I do that I don't know about). If it had returned a i32, I would have gotten a negative number that would have been a lot easier to detect.
https://github.com/rust-lang/rfcs/blob/master/text/0544-rename-int-uint.md is the accepted RFC.
`Box::new(v)` is inefficient, `Box::new(||v)` is as efficient as `box v`, it won't do any copies.
If you have vtable and data contiguous, that means two drawbacks: * Every object instance needs to have its own vtable in memory, which consumes memory for each object (whereas the current has one read-only vtable per object type). I e, less memory efficient. * Every time you initialize an object instance you need to construct/copy the vtable from a template, this costs some CPU. That said, fat pointers will need to allocate more registers (one for the data and one for the vtable), so which one is faster will probably depend on the use case.
&gt; Would a stack-allocated variant of Box require specific rustc support? Probably. Putting unsized types on the stack is certainly possible in theory. &gt; Actually - what happens after a stack overflow? Does the thread panics? Yep. &gt; And finally, would an alloca-based Box be a bad idea? Probably not. But I would just let you get unsized types directly on the stack, and make enums containing themselves unsized; that would cover a lot of usecases, and let you use no Box at all in many cases! (Plus, C-style safe VLAs, which would be nice.)
You're not the only one. I really want to learn this language because I like what I've seen so far, but seeing all the compiler warnings and mismatched versions is making it hard for me personally (i mean the version mismatches for docs and third-party guides/tutorials, and deprecation/unstable warnings). There are plenty of people that can just work through that stuff (look at all the rust-dev's and people working with rust already), but I guess I'm not one of them. I was reading [another post](http://np.reddit.com/r/rust/comments/2rx3sm/is_array_length_broken_in_the_latest_nightly/) asking about array length (apparently the OP was using an old syntax), and when pointed to a [working example](http://is.gd/7SUgWJ) I couldn't help but notice the compiler warning at the bottom: &lt;anon&gt;:32:22: 32:33 warning: use of unstable item: will be replaced by slice syntax, #[warn(unstable)] on by default &lt;anon&gt;:32 analyze_slice(ys.slice(1, 4)); ^~~~~~~~~~~ There's nothing wrong with the warning or the code, it just makes me want to wait a bit before I buckle down and learn rust. I want to learn the best practices but I feel like they're changing all the time (they should be as the language grows). This is just my personal opinion. Like I said before, not everyone has this problem.
Somebody don't like the exclamation mark, and I feels okay with that :-) For most cases macro support for programming languages won't look elegant, so I personally find it acceptable for current macro syntax.
At worst, the cost can be a hell of a lot more than one or two seconds - just try to compile any of the big rustc crates. I'm actually pretty amazed that people manage to get any work done on it, given the recompilation time. But if, at some indeterminate future date, the plans for true incremental compilation in rustc are completed, it should /significantly/ improve things, and eventually make it able to hold its own with any compiler that does not support it (including golang) on common small rebuilds, even if the actual compilation work being done is more intensive.
Sure, but most humans can remember something for 2 seconds.
In fact the old syntax is `[something, ..length]`, `[something; ..length]` has never been valid. The new syntax is really weird, I think it was chosen just because it works ...
&gt; I'm actually pretty amazed that people manage to get any work done on it, given the recompilation time. If people can get work done in C++ or C, it seems reasonable one can still get work done with a language that has a compilation stage that isn't blazing fast. (That's not to say I want a long recompile time. I'm coming from working almost exclusively in dynamic languages for a decade...I don't want *any* compile time, but will tolerate it in exchange for other benefits.)
Compiler performance is something we hope to improve this calendar year (especially after 1.0). See http://www.reddit.com/r/rust/comments/2qkgvu/my_thoughts_on_rust_in_2015/ for some specific thoughts and discussion.
`unsafe-any` doesn’t help with downcasting, it just lets you do it dangerously. `std::any::Any` is all you need for such downcasting. If you want it on non-Any trait objects (so that you can call methods on the trait and such as well), I made a library that lets you do that: https://github.com/chris-morgan/mopa.
Virtual dispatch on objects shared between multiple participants is a must-have feature. I have a good understanding how Trait objects work and how they relate to other languages. The problem is also not traits or trait objects, it is how they interact with Rusts lifetime semantics to make a reasonable modelling of some data structures impossible. Really I hate that "modelling the DOM" argument. There are 1000s of situations where inheritance is the most reasonable solution. Everytime someone brings up "only for DOM" then I get serious doubts that the Rust cares about anything other than Mozillas current use cases. 
I believe you need to change the closures to "move ||" instead of just "||".
We'll finally get a modern 21th century systems programming language. A big congrats to all people involved!
You can't pass `&amp;[u8]` to closures that are going to be executed as threads. You should first make it into a vector using `to_vec()`, and then use a `move ||` proc, [like so](http://is.gd/wN9OCK)
To me that seems kind of good. It will make people think a bit about what it actually means and only use it when it's appropriate instead of chucking on an `i` suffix because it makes it look integer-ish, which I suspect is the main reason there is such a proliferation of them now.
Why not change it to `isize` then? It's too long to throw on every literal, but isn't confusing. It also matches the rest of the suffixes.
I think that's good, but I really wish the `Show` trait would support generating output in a more structured way so that you can get auto indenting etc.
**Edit**: Actually, I just realised I didn't quite answer the question you asked. The problem here is that `F` will be a trait type, and you need provide the type system with bounds for the lifetimes that the actual *implementation* types will use. To put it another way: in order for there to be a thing which is `F`, there must be an implementation. That implementation *might* contain references, and the typesystem needs to know for how long those references are valid. The syntax is, I believe: type F = (F(...) -&gt; String) + 'static You can use `'static` to forbid anything other than static references, or some `'a` if there's a more appropriate, constrained lifetime available. **Original**: Without a complete example, I have to make a few guesses here. The type of `|&amp;: ...|` isn't *quite* the same thing as `Fn(...)` (note that, if I remember correctly, you should avoid using the trait form for `Fn`, `FnMut` and `FnOnce` for now). Any given closure will actually be an anonymous type which *implements* the `Fn` trait, not the `Fn` trait itself. As such, you need to make a decision about what it is you really want. Presumably, `F` is defined in a trait, in which case you might want to actually take it as an input parameter to the trait, allowing the user to specify whatever closure type it wants. Failing that, you'll need to use something like `&amp;'a Fn(...)` or `Box&lt;Fn(...)&gt;`. Because these are trait object types, you can store any concrete closure value you want, provided it matches the call signature.
With unboxed closures there is no single type of closures. Each closure has its own anonymous unique type generated for it by the compiler, and this type implements certain trait. Even if you could name such a type, it would mean that each implementation of your trait is only compatible with *one particular closure*, not with all closures of the same type, which is pretty useless. You should use trait objects instead: type F = Box&lt;for&lt;'h&gt; Fn(String, Option&lt;&amp;'h HashMap&lt;&amp;'h str, &amp;'h str&gt;&gt;, &amp;'h SystemContext&lt;'h&gt;, HashMap&lt;&amp;'h str, &amp;'h str&gt;) -&gt; String + 'static&gt;; 
I also support the split, but I really wish a name other than `String` had been chosen. It's going to be ***really*** confusing to people new to Rust.
&gt; Virtual dispatch on objects shared between multiple participants is a must-have feature. Don't we have that? `&amp; Trait` should be able to provide that. Getting trait objects to work with lifetimes is hard, but usually a `&amp;'a Trait + 'a` is enough for it to work. Either way, you'll still have the same lifetime issues in an upcasting system. Re: "only for DOM" -- that's not what I was trying to say. I was just saying that I've only come across one situation (not just in Rust, in other languages) where a solution based on trait inheritance would be very unwieldy, and that was the DOM. I'm not saying that the only reason Rust needs single inheritance is for the DOM. There are plenty of cases where single inheritance is a cleaner solution, but trait based solutions work fine (if just a tiny bit more verbose). We want single inheritance. I just don't see it as a must-have for 1.0 since you can get by without it. Put another way, do you have any concrete example where a trait based solution would not work or would be _extremely_ verbose? Not counting situations where the library is designed a particular way, we expect Rust libraries to be designed in the Rust style, not Java style.
Should still count, if your contributions made it into the alpha/were made since the last release I think.
I was right! 0.13 documentation was 404 yesterday and I knew something was up.
Yes, unfortunately, the newly added generation tool wasn't creating the CSS files properly and so the raw nightly renderings will look rather outdated. The CSS was manually uploaded yesterday to ensure it looked ok and the [alpha book](http://doc.rust-lang.org/1.0.0-alpha/book/) still looks OK since those docs aren't generated and overwritten, unlike the nightly. I fixed it in [#20802](https://github.com/rust-lang/rust/pull/20802) but it unfortunately didn't make it in time for the most recent nightly (I was hoping it would, but alas, windows conspired against me). (It was caused by pieces of code marked `// FIXME: handle errors properly` that were silently ignoring errors. Moral of the story: if you don't want to do set up real error handling immediately, default to `foo().unwrap()`, not `let _ = foo();` to at least crash, unless you know that ignoring the error is truly desired.)
`&amp;Trait` does not work for many usecases because it ties the lifetime to the actual objects reference. What doesn't work in a sophisticated way currently is e.g.: - Most things that follow the observer pattern - callbacks which will happen at some time (not on the same stack frame). E.g. therefore no async IO - Type erased tree structures which have multiple cross-references between each other and where lifetimes are totally decoupled (e.g. widget trees. See my comments to steveklabnik) - extensible architectures that use interfaces for their base types to achieve this. E.g. plugin systems. If there would be a Rust way for the problems -&gt; OK. But for most of these things I don't see one. e.g. mio works around the problem by simply using a global callback for all I/O events instead of individual ones for the actual I/O objects. But this won't scale for a complicated application which uses many types of different objects.
It's near impossible to debug your problem without more information (like your code and your Cargo.toml), but here's a shot in the dark. Are you using the regex! macro? If so, try adding #[no_link] before the `extern crate regex_macros` statement (in addition to #[plugin]). Without it, your binary will require linking to some Rust libraries at runtime. But usually procedural macros like regex! only require linking at compile time.
I installed Stylebot (https://chrome.google.com/webstore/detail/stylebot/oiaejidbmkiecgbjeifoejpgmdaleoha?hl=en) and copied the css from the alpha.
That seems to have done the job. I was indeed using the regex! macro. Just for reference, the sample code I tested with: http://pastebin.com/vxFhXGNi and the Cargo.toml: http://pastebin.com/V7edYc82 I wasn't aware that #[no_link] even existed. Neither google, nor the official documentations pointed me to anything useful. Anyway, thank you very much!
oops, deleting my post.
I tried writing some trivial text-munging programs yesterday and it was much easier and pleasant than months ago (mostly because the stdlib has grown a few convenience methods and the new iterators are fully in place now), but everything that directly used io gave a compiler warning indicating it might change before 1.0. So, don't use io, be willing to rewrite or wait for the beta.
A nicer way of writing doc comments is by using the `///` comments: /// I document the function below me. fn function() {}
Any patch does. Did we miss you? Oh no! Which commit did you get in?
FYI, if you have `regex_macros` as a dependency, then you don't also need to specify `regex` since [`regex` is a dependency of `regex_macros`](https://github.com/rust-lang/regex/blob/master/regex_macros/Cargo.toml).
For me, this was somehow caused by the docopt_macro crate. When I removed it, the problem disappeared.
A web of cross referencing of that form is anyway not supposed to work. Rust is very specific on how it will handle aliasing. You'll have to use raw pointers (raw trait pointers work IIRC, that solves the lifetime problem) or a GC or something. I don't see any issue with plugin systems; traits seem to work fine for stuff like this. "Callbacks which will happen at some time" -- unboxed closures should work here. Of course, again, you might have lifetime issues. But lifetimes are fundamental to Rust; any single inheritance system will have lifetime issues too (unless you restrict all participants of an inheritance tree to have the same number of lifetime params). 
Rust can do anything any other general purpose language can do. Like with C, you can use Rust from the lowest level (e.g. an operating system kernel) to the highest level (web development, [in time](http://arewewebyet.com/)), although Rust makes the higher levels arguably a lot more comfortable and is safer at every level in general. Database bindings are already there, and those that aren't, you can write a wrapper for, since Rust can easily interface with C.
Well, he should be happy that we're not using `^` or any other odd symbols. 
From what I've seen, ordinary Rust is within a factor of 2 of C++ performance, and when carefully written it's a match. It can even be an improvement, because you can safely do things like tokenize a string by getting a list of pointers into it instead of just putting each slice in its own allocation.
It's surprising how big of a jump it is to go from 0.12 to the alpha. I think the number of errors you got is fairly small (especially for a closure-intensive project, as yours seems to be), considering the number of breaking changes that landed in the last few months. I'm curious though: Why did you choose to maintain your project in 0.12 instead of tracking the nightlies?
I just added a section on pattern matching and changed the subsequent code to use `if let`. Please let me know if anything is incorrect.
I just added a section on pattern matching and changed the subsequent code to use `if let`. Please let me know if anything is incorrect.
I think we are pretty close for most applications. [This article](http://ruudvanasseldonk.com/2014/10/20/writing-a-path-tracer-in-rust-part-7-conclusion) finds no significant speed difference on a spectral path tracing task. The [shootout game](http://benchmarksgame.alioth.debian.org/) is not too "real-world" as a benchmark, but we also do pretty well there (data unavailable atm due to build errors, heh) *edit*: [seems to be fixed](http://benchmarksgame.alioth.debian.org/u64q/rust.html)
It should be noted that Go uses garbage collection and has vtables and dynamic type tests everywhere. While Rust may lag C++ performance somewhat for reasons of implementation maturity, Go's entire design precludes its use in real-time or maximum-throughput applications. It really is a language for concurrent IO and doesn't need to be mentioned every time C++ and Rust are.
Mostly the flaws are relating to hygiene and the cryptic syntax. Hygiene is *almost* there since it will escape local variables, but non-local variables (functions, traits, types) aren't hygienic, which is often a pain.
For the most part, Rust's abstractions are, in theory, close to zero overhead. There's a few that do have overhead, but they're used in the same places you'd use vtables and the like in C++. The primary issue, as far as I've picked up, is optimisation - C/C++ compilers have had a lot of time to tweak lots of optimisations, while Rust hasn't had a chance yet. The Rust compiler uses LLVM's optimiser - the same as backs Clang - but there's still further optimisations that could be done in the compiler itself to help. I'll note that the author of that post has a slightly outdated view on Rust - Rust no longer has "optional garbage collection", for example. (Although there are still reference-counted types to be used in rare cases, there's no garbage collector to break cycles.)
Thats a limitation of idiomatic C++. The language *I* like , "C/C++" can always do it right :) its' just purists have a fit. But it is good to see new abstractions that can handle more cases safely.
One objection I've heard to `alloca`s is that they entail dynamic offset calculations for anything on the stack after them.
Indeed that would be very useful, but not strictly necessary - worst case, you could make a shim `GObject` or `Rc&lt;RefCell&lt;GObject&gt;&gt;` (assuming `GObject` is a `Box&lt;Trait&gt;`) that just derefs to the `Rc&lt;RefCell&lt;GtkButton&gt;&gt;` that contains the actual button object.
Go 1.5 will have a concurrent bounded-time GC which will narrow the distinction a bit.
FYI, it's usually possible to copy the error message text with Ctrl-C without resorting to screenshots ;)
My compile-times with C++ are definitely smaller than those with Rust, for the same number of files, in Debug. Any decent build system for C++ supports incremental compilation and therefore when I edit 1 source file out of a hundred/thousand then only that `.o` file is regenerated, and since in Debug the linker just assembles the `.o` files as fast as possible, I am well under a second. Modifying header files takes slightly longer, however C++ compilation is a highly parallel problem, and any decent build system creates the `.o` files in parallel... So, for the time being, Rust is the one language compiling slower than C++...
You're right on this, is and us sucks badly.
Having just tinkered with implementing a double-ended vector in C++, I can only concur than it is *fundamentally* slower. I thought a "simple" implementation (not focused on performance to start with) would be relatively easy, but it was not. The implementation of `insert`, notably, gave me nightmares: I was expected to have to specialize the implementation for `InputIterator` since you cannot know in advance how many elements you'll get and that is handy to pre-allocate memory and minimize the number of moves... ... but I was completely unprepared with the fact that the potential for exception everywhere would be so utterly annoying. As a simple example imagine: 0 1 2 6 7 . . . . . // Initial 3 4 5 // sequence to insert (between 2 and 6) 0 1 2 3 4 5 6 7 . . // Goal Where a number represents an existing element and a `.` represent an element-slot already reserved but containing raw memory. Sounds easy right? You don't even need to re-allocate! Well, first off, if it is an `InputIterator`, you don't know in advance how far you should push that `6 7` block. And pushing it by 1 each time you need to insert an element does not sound very efficient: `O(sequence.size() * (vec.end() - pos))` ? Uh! But even if you have a `ForwardIterator` and know that you need to shift `6 7` 3 positions to the right, things get tricky... ideally you would do: 0 1 2 x x . 6 7 . . where `x` represents a moved-out element (state unknown, but destructible). Unfortunately, while you are definitely allowed to leave moved-out elements within the vector if an exception is thrown during insertion, you cannot leave a **hole**. So if you are willing to proceed like such, you will need to use a `try/catch` block so as to be able to call the destructor of `7` if the construction of `6` throws (if you would prefer to move backward), and thus restore the state to `0 1 2 x x . . . . .` which is not that great (with those `x`), but at least won't crash. That is not, however, the end of your troubles. The difference between `x` and `.` is that you should use *assignment* to override an `x` and *construction* to override a `.`. This means that you need to have two different routines, and switch from one to the other at the appropriate time. At the end, honestly, the code of `vector::insert` is a monstrous beast, with plenty of special situations to handle. --- And what of Rust? Well, Rust *moves*, which cannot fail, and leaves nothing behind. So while you will indeed need a distinction between unsized insertion and sized insertion, the sized insertion will be a breeze: straightforward minimal code. And it'll be more efficient to boot.
Note that std::vector doesn't attempt to handle moves that can throw. It only offers the basic exception guarantee in such a case. You can catch the exception but you don't know if moving them back again will throw another exception. It only offers the strong guarantee when move is noexcept.
I believe /u/gkoz is saying you don't need to select the text and can just hit Ctrl-C. That worked on the old versions of Windows (XP) I'm familiar with and presumably still does.
&gt; What? Where did that come from? https://docs.google.com/document/d/16Y4IsnNRCN43Mx0NZc5YXZLovrHvvLhK_h0KN8woTO4/mobilebasic?pli=1 
&gt; and anything that runs on a runtime like the Java VM or .NET. This is definitely wrong. Java can be compiled to native code, and there are several commercial JVMs that do it, like Aonix and Excelsior JET to name just two of them. On IBM i mainframes, C, C++ and Java are all compiled to the same bytecode, TIMI and the code can be easily shared. .NET code is compiled to native code on Windows Store and can be consumed by any language able to speak COM.
Especially lolsy because 'read the description.'
&gt; [word1](link1) [word2](link2) ... Could we please stop doing that?
S/he didn't say anything about titles, though :) (or about notes at the submission page)
`Show` is what it's called in Haskell, and I assume a few other languages as well. For the user-facing stuff, I really agree there should be another name to it (`Pretty`/`Print`/`PrettyPrint`? dunno how those would interfere with existing stuff though).
Thanks for your worthless contribution.
Wow, nice work!
Oh shit, I read "Rust is going to have [...] GC.". I nearly died there.
Yeah `is` seems weird to me too, but there we have it. At least for this particular choice, if it's driving people batty after 1.0 it won't be a difficult thing to deprecate and replace.
I have wanted this for a long time. Currently I think your only bet is to impl closure structs yourself. The difficulty is/would be generating the Clone impls automatically in the compiler.I understand fully that this is a complexity better left for after 1.0. What did change was that closures were Copy by mistake, and are no longer that. My main argument for clonable closures is usually iterators (adaptors). 
#1 Startline Code Endline #2 Startline Startline Code Endline I prefer #1
I'll have a look, re: implementing closure traits. I didn't realize that was possible. That's also my interest, since I'm trying to put together a static dispatch/low or no allocation prototype of [Rx](https://github.com/Reactive-Extensions), which is effectively inverted (push), potentially async iterators.
"We strongly disapprove of posting solutions that are accesible to the general public. If you feel like having your solutions somewhere else, please use some password only known to you, or use some encryption. The reason should be obvious: members coming after you are supposed to solve the problems themselves as you have done." (http://forum.projecteuler.net/viewtopic.php?f=5&amp;t=3078)
I'm glad that compilation speed is something in the mind of Rust developers, this definitely motivates me to have another look at the language in the future. Even if the default compiler speed can't be improved much, do you think it would be viable to write an AST/bytecode interpreter(ghci-like) for use during development of Rust projects? Note that it would be perfectly fine for such an interpreter to be slow, as write/compile/test cycle speed is far more important than execution speed during development.
I think this is the best solution.
This probably isn't the best way, but I just `pop`ped the string.
Yeah, Rust is weak at intrusive data structures generally. You can do something kinda similar with `TypedArena`, though.
We do plan to eventually provide the hooks you need to wire up an external exact GC, as soon as LLVM provides the hooks *we* need. This would greatly simplify Servo's DOM implementation.
&gt;So a shock name may be offensive, but should not disqualify someone from contributing, IMHO. If a particular string of text would be unacceptable in the body of a post, it seems downright silly to think relocating the string to a more prominent position makes it acceptable. It's pretty trivial to make a new reddit account, so I don't really see it as an actual barrier for entry for anyone with serious intent...
I opened [a ticket about this](https://github.com/rust-lang/rust/issues/20827) yesterday.
I don't see how it's possible to give an answer that is both short and satisfying, sorry. The reason why you can't move C++ objects via memcpy in general is because their move constructors could do nontrivial things including (un)registering their memory address somewhere else. In Rust there are no move constructors. Things are always moved via a shallow copy of the bits and the source objects are then automatically considered invalid (no dtor will run on them). This makes things a lot easier in my opinion. Moves that never throw? Great! Not having to invent some zombie state for your type? Great! Obviously, there are also limits. For example, Rust does not allow you to write a smart pointer for shared ownership where instead of a reference counter you keep track of how many owners you have by linking all the pointers together to form a list. Why? Because this would require the list to be updated whenever such a smart pointer moves from one memory location to another and that would require a move ctor. IIRC the Boost library used to offer such a smart pointer (linked_ptr or something). But I think they ditched it for reasons like performance overhead, larger smart pointer size, thread-safety issues and/or non-trivial weak pointer support, something like that. In my opinion not having move ctors is not really a serious limitation of Rust. As for creating a vector with elements pointing to each other: The Rust compiler would not let you do that with "normal borrowed pointers". To get a better feel of what the "borrowing" rules are about, check out [Niko Matsakis talk on memory safety](https://air.mozilla.org/guaranteeing-memory-safety-in-rust/). You *can* use "unsafe pointers" instead, of course. But dereferencing those would require an `unsafe` block and the compiler will not help you avoid dangling pointer errors in this case. If you do this, it's up to you not to screw up. The better idea might be to use integers as offsets instead.
Well, not really, no, because I want to pass any kind of closure as an argument to the same function, and convert it into some callable representation (this requires a different function for different arg count (http://is.gd/6uijzt)... well I might settle to this if nothing else works out). My previous attempt was to provide the same "convertable to callable" trait for closures with argument count up to 12. I used to simply call "to_whatever" on the closure and gather all info about it. However, I can't seem to get similar solution after the change into unboxed closures, hence the call for help. The exact problem seems to be rooted in fact that while closures themselves implement single trait, there is nothing preventing someone implementing several of them and passing the contortion as an argument - and my "to_whatever" function would not know on what instance to act. I submitted an issue for this: https://github.com/rust-lang/rust/issues/20770. I do not: a) how much of this is by design b) will it be possible later c) is this a bug or not?? I am still obsessed by this because [I got a comment](https://github.com/rust-lang/rust/issues/20770#issuecomment-69251499) on this issue from someone smart suggesting that is should still be possible to do in the current type system. But I can't find out how. Therefore I tried my luck here :)
yield is related in that Rx Observables can be used as generators, but those proposals are still synchronous/pull-based. Generators + Promises also overlap for the async case, but still aren't quite what I am trying to implement. To be more specific, here's an example of what I now have: let async_nums = interval(2000, NewThreadScheduler::&lt;usize&gt;). take(2). map(|&amp;: a| a + 5). flat_map(|&amp;: a| range(a, a + 2)); let disposable = async_nums.for_each(AnonymousObserver { next: |&amp;mut: a| /*Have some effect on a shared resource or perform IO*/, error: |&amp;mut: err| /*Handle Err results*/, completed: |&amp;mut:| /*The equivalent of receiving None from an iterator's .next()*/ }); NewThreadScheduler could be replaced with an EventLoopScheduler or CurrentThreadScheduler if blocking behavior is desired. The key is that I can now compose arbitrary sync/async operations without going to callback hell. Unlike iterators or generators, observables aren't consumed when calling for_each. I can call for_each an arbitrary number of times, and each time AnonymousObserver's next() will be called with the sequence 5, 6, 6, 7. A publish() operator exists if shared effects/resource consumption is desired, however. The challenge then is that the source observable owns the closures for map/flat_map, which must then be handed off to some number of observers.
Thanks for laugh :)
I think you may find that it can be `\r\n` on Windows. Not certain, though.
Could someone test this?
I'm testing another Python linkchecker, "webcheck". It's currently been running for four minutes, pegging the CPU at maximum; I'll tell you if it finishes. 
The problem here is to let the compiler know that `data` will outlive (i.e. live longer than) the entire threads, which are implemented in the library. It is not impossible to encode this knowledge to the expanded type system, but at the expense of the complexity and possibility of bugs. 1.0 is all about the backward compatibility, and such a big change is hard at this stage. (You might wonder about other breaking changes, but IMHO they are relatively "simple" changes in terms of complexity, i.e. they are just "annoying" to implement.) I think this very feature is in consideration after 1.0, though.
Concurrent GCs add a significant *total* cost to an application, in order to achieve the goal of bounded execution time (latency). There's no such thing as a free lunch.
Can intrusive data structures be created with unsafe code while presenting a safe interface to the world? If so, how much unsafe code will be required? 
For reference, this: bits 64 section .text str: db 'Hello, World!',10 strlen equ $-str global _start _start: mov rax, 1 ; sys_write mov rdi, 1 ; stdout mov rsi, str mov rdx, strlen syscall mov rax, 60 ; sys_exit xor rdi, rdi ; exit code syscall fits into 440 bytes with `nasm` and `strip` alone. A whole seven more characters in the string, so there's definitely wastage going on in the rust case. But not because the code is smaller, either: 4000be: b8 01 00 00 00 mov $0x1,%eax 4000c3: bf 01 00 00 00 mov $0x1,%edi 4000c8: 48 be b0 00 40 00 00 movabs $0x4000b0,%rsi 4000cf: 00 00 00 4000d2: ba 0e 00 00 00 mov $0xe,%edx 4000d7: 0f 05 syscall 4000d9: b8 3c 00 00 00 mov $0x3c,%eax 4000de: 48 31 ff xor %rdi,%rdi 4000e1: 0f 05 syscall ...I think the reason is that packing the string into the text section is the most effective, ELF-size wise. Generally speaking, at under 1k or so it's more about hacking ELF than actually reducing code size. 
&gt; fits into 440 bytes with nasm and strip alone. A whole seven more characters in the string, so there's definitely wastage going on in the rust case I'm... confused. Isn't the binary in the article 151 bytes, and that's less than 440?
Well, looks like I learn something new every day, that does indeed work. Thanks!
Can, but only tomorrow, not at home today :(
Thank you so much!
It could be nice to have a NonBorrowingReference to an element in a vector. This reference should * Contain a lifetime lifetime to protect against dangling pointers. * Not own/borrow the data. Ideally it should work like this fn main() { let mut v = S[1,2,3,4]; v[0]=2; // i is a struct containing a lifetime and an unsafe pointer to v[2] let i: NonBorrowingReference = v.non_borrowing_ref_to(2); // The vector is still mutable (but has fixed size) v[1]=4; // The following line borrows the vector let mut element= v[i]; *element = 6; // The following would fail because the vector is now borrowed // v[3]=8; } Would something this be possible? I guess that it would require a special vector that has a lifetime.
The first Java examples allow the Java code to be AOT compiled to shared libraries, hence consumed by other applications. The current Windows ABI is Win32 and COM, with most new APIs since Windows XP being COM based. The programming model introduced with Windows 8, WinRT, is built on top of COM. It is based on their original architecture for .NET. Ext-VOS. So all languages that can be used in WinRT world need to speak COM. As for using multiple .NET versions, to use it safety you need to use out-of-process COM. But it is possible to generate COM libraries that will run in-process.
Sort of. The trick to doing this in Rust is to use RefCells. Like so: use std::cell::RefCell; struct Looper&lt;'a&gt; { next : Option&lt;&amp;'a RefCell&lt;Looper&lt;'a&gt;&gt;&gt; } fn main() { // Create the first item, pointing to nothing. let loop1 = RefCell::new(Looper { next : None }); // Create the second item, pointing to the first. No prob. let loop2 = RefCell::new(Looper { next : Some(&amp;loop1) }); // Now modify the first one to point to the second. loop1.borrow_mut().next = Some(&amp;loop2); } Now, we've lent out references to loop1 and loop2, so rust prevents us from moving them. Eg, if we add one more line: let x = vec![loop1, loop2]; We get an error: error: cannot move out of `loop1` because it is borrowed Basically, rust is telling us that we already made a guarantee (to loop2) that we wouldn't move loop1, and that we are now attempting to break that guarantee. Rust knows that there are pointers to this data—so you can't move it (isn't that awesome!) Rust, however, won't stop us from making more pointers to loop1 and loop2, and those *can* safely be moved around without causing problems. ie let x = vec![&amp;loop1, &amp;loop2]; Is perfectly fine.
And platform compatibility also has nothing to do with what /u/ldpreload was talking about. Can you write a go function, then call it from a C program without setting up a runtime?
This is super impressive work. I hope it finds its way into std eventually.
And also make it much slower?
Yeah, it has a different meaning on IRC, though a factoid bot can easily contain factoids as Wikipedia describes. I didn't coin the term for the IRC functionality. It predates my joining of it (in 2006).
didn’t know that the IRC community has used this differently!
C allows not only fallthru but also `case` labels inside inner blocks like `if` and `while`.
And on that note, is there any way to salvage the [iterator comprehension macro](http://bluss.github.io/rust-itertools/doc/itertools/macro.icompr!.html) and its desired syntax? icompr!(x * x for x in 0..10) 
https://github.com/pythonesque/fallthrough
[The Lovecraft quotes have met a terrible fate](https://github.com/rust-lang/rust/pull/20944)
Yes, the braces are legal, and no, I'd say that's a bug. When combining ignore with somwthing else, we should get the highlighting.
Already existing and then already dead Gc&lt;T&gt; pointer ;)
That really is an interesting approach: this uses the existing Hoogle engine with a DB output from the modified rustdoc instead of writing its own search engine. I don't think this will be the final measure (we would eventually want the self-contained solution), but this is neat and should help users for a while.
[45 bytes](http://www.muppetlabs.com/~breadbox/software/tiny/teensy.html), or 76 if your more worried about the standard then what linux will accept as a valid "ELF" file.
I cannot judge the details, but the part that I do understand looks really nice. * Could `easily_recognizable_name` perhaps be a method of the indexer? * Could this be expanded to work on arenas?
Thank you for doing this! I was starting to wonder myself how I was going to manage it. I'll need to be able to test on the nightly and stable channels, so this looks great. :-)
I think the current consensus is Rustacean. :-) At least, that's what [my t-shirt says](http://teespring.com/rustacean#pid=2&amp;cid=2397&amp;sid=back)!
Why not a special keyword, but please don't modify the usual meaning of pattern matching.
I know, that's a xelatex error. Regular latex failes with `Package inputenc Error: Unicode char \u8:日 not set up for use with LaTeX.` ;)
I like rustie.
Actually `easily_recognizable_name` is completely useless, as can be seen by its actual body: `&amp;proxy[*index]`; its sole goal is to make it easy to isolate in LLVM the part of the code concerned with the indexing operation to ensure that no bounds check is used. Regarding arenas, I am unsure of what you mean, so cannot comment...
This is a great post. I really love the section that breaks down *why* certain attributes of a trait prevent them from being object safe. The section on why generic methods aren't allowed in object safe traits is particularly illuminating.
Well, as far as I understand, marmelade and melpa both install from source, so I was referring to the standard installation.
[rust-ipster](http://media-cache-ec0.pinimg.com/736x/24/b5/1d/24b51d27e174469909067a95aad1921a.jpg)
Pretty good. I do have a few criticisms although they probably aren't a problem because this is just a Reddit forum about a programming language and not that important in the grand scheme of things. &gt; We will exclude you from interaction if you insult, demean, or harass anyone. That is not welcome behaviour. We interpret the term "harassment" as including the definition in the Citizen Code of Conduct; if you have any lack of clarity about what might be included in that concept, please read their definition. The word harassment has been completely overused and lost all sense of meaning entirely. I think people everywhere should just replace it completely with "repeated behaviour intended only to disturb and upset others." Also you should maybe add something about criminal behaviour such as defamation and threats of violence. &gt; If a moderator bans someone and you think it was unjustified, please take it up with that moderator, or with a different moderator, in private. Complaining about bans on the subreddit itself is not allowed. I disagree totally and completely with this. The community ability to protest abuse of power is an absolute necessity to protect the community against its moderators. Yes, this causes lots and lots of drama. However, I think it is a necessary evil to protect against a community closing itself off to outside debate.
I would say they are common in that they are both recent attempts to unify the ease of use of high level languages with the performance and power of system level languages. Go missed the mark a bit since they were trying to replace C but ended up appealing to the Ruby-Python crowd instead since go is nothing but win from their standpoint. From the C and C++ perspective there is an unacceptable additional cost of a garbage collector. Rust is attempting to do the same thing and may indeed be able to win over the C and C++ people thanks to the zero cost borrowing system. I'm excited to see how things go once 1.0.0 is out and the rubber can hit the road. The comment I was making was just trying to point out that with each version of Go the price paid for the GC is getting smaller and smaller and thus making the spectrum use cases where it is a bad fit smaller and smaller, narrowing the utility gap with languages like C, C++ and Rust. I'm not suggesting the gap will vanish, only that there will be a larger piece of the problem space where they will be in competition. edit: spelling
You are absolutely right. It's a tradeoff, not a free lunch. My point is that there exists some set of problems that couldn't use Go, and would have to use C++ or Rust, because a 20ms garbage collection stop is unacceptable, may soon be able to consider it an option b/c a 2ms stop is no problem.
And then lose its appeal. If there are idioms we simply cannot do without GC, that's fine. But I think we should avoid anything GC related for as long as possible.
This is a bug! We can't automatically check things that link against external crates. Use u64 instead of u, but would you mind opening an issue so I can fix it later? Thanks!
Yeah, to be honest I forgot why I'm doing it this way. There was a bunch of screwing around, over 6+ months worth of rustc versions.
I'm not buying why static methods should not be object safe. They make sense to me: trait Animal { fn whatAmI() -&gt; &amp;'static str } struct Cat; impl Animal for Cat { fn whatAmI() -&gt; &amp;'static str { "cat" } } struct Dog; impl Animal for Dog { fn whatAmI() -&gt; &amp;'static str { "dog" } } fn print_animal_type(t: &amp;Animal) { println!("The animal is a {}", t.whatAmI()); } The virtual dispatch is used to avoid code bloat of print_animal_type, and is done by looking up the whatAmI function in t.vtable - the only difference compared to other methods is that you don't have to send the t.data pointer to the method. 
I like the idea of match op { Some(x) =&gt; ... | None =&gt; ... , } Would be a fall through.
You can't -- function parameters have to be Sized. So pass them behind a &amp; or a Box.
Rustaman 
There's always going to be overlap in naming of things. A few months ago I wanted to know about the progress on running rust without an OS, so I googled "rust on bare metal" that didn't really give me the results I was expecting.
Section Motivation, paragraph 4, did you mean `func(object)`, or I'm having a misunderstanding?
The programming language is older by years, so it's their fault, not ours ;)
I'll give it my best.
It's not object safe because if you pass an object to a fn, then you no longer have the information to statically dispatch a method. E.g., trait Foo { fn foo(); } fn bar&lt;T: Foo&gt;(x: &amp;T) { T::foo(); // How do I know which impl of foo to use? } fn main() { let x: &amp;Foo = &amp;...; bar(x); } 
Nice! I'd suggest using the data from --save-analysis rather than from RustDoc though, it is more self-contained and likely to be better supported longer term (one might even imagine re-architecting rustdoc to use this data instead of generating it itself).
An opt-in solution is definitely the way to go and I think there are compelling cases for having it such as for example [this](https://np.reddit.com/r/programming/comments/2rvoha/announcing_rust_100_alpha/cnjveyk) case.
Great article, thanks! But, "13 Jan 2015", are you from the future?
My personal favorite was Rustorian, but as others have mentioned, I think Rustacean has started to win out.
Really interesting idea. I [filed an issue on it](https://github.com/brson/multirust/issues/7). Also filed a bug on [homebrew](https://github.com/brson/multirust/issues/8). If somebody else wants to add it to homebrew before I do it's important to be aware of the potential corruption bug when installing over top of a real Rust installation. The `install.sh` script in the repo tries to detect this and abort, but I have plans to fix this problem in `rust-installer` as well as the OS X .pkg installer. 
Where can I find out more about negative trait bounds? They sound like just the sort of thing to help disambiguate impls between types that have some trait and types that don't.
Or maybe Rustee?
"Dangit! Who named oxidized iron after our programing language!?"
Cool! Is there a hosted version I can use without building everything myself? :)
Yes, that's roughtly right. You may want to check out http://huonw.github.io/blog/2015/01/peeking-inside-trait-objects/
Haha, I was wondering if someone would notice. I originally published it with the same date as "The Sized trait", but Jekyll was placing the articles in the wrong order. Fortunately I can bend space and time, so it wasn't a problem. ;) (Also, I'm in Australia, so am up to 20 hours ahead of many people.)
You can always rewrite it as a syntax extension ;)
Ah of course!
You may be interested in [this RFC](https://github.com/rust-lang/rfcs/pull/458). It will make typesystem capable of sharing plain references between threads. I really hope it will be implemented for 1.0, even if default thread api would force closures to be `Send + 'static`.
because dispatch doesn't involve `x`, so there is no vtable to store the pointer in. Another example: fn bar&lt;T: Foo&gt;(x: &amp;T, y: &amp;T) { T::foo(); } Here `x` and `y` could have different concrete types, so there is a choice of vtables to look at. 
There are very few cases where you can actually do that, though. One of them is a function/closure generic over a lifetime in its argument. Actually, that could be the *only* place. And I'm not seeing closure scopes in your code. **EDIT**: yeah, I've looked again and it seems trivial to be able to use checked indexes into one collection for a different one. Have you tried it? Just declare everything in the same scope, regionck will gladly unify everything :).
mm... yes, that is indeed what I mean, my bad.
&gt; The first Java examples allow the Java code to be AOT compiled to shared libraries, hence consumed by other applications. I think we're agreeing? Java, as a language, _can_ be natively compiled, but it's relatively rare. "Java" tends to connote both the language and the rest of the ecosystem, most notably the JVM (much as "Rust" connotes both the language as well as the implementation available from rust-lang.org, "Ruby" connotes MRI and usually not JRuby, etc.). In the cases where you have Java bytecode intended to run on the JVM, it's difficult to call into that Java code from a non-JVM host program, or expose that Java code as a library that looks like it might have been written in C. Where you can natively compile, sure, although I do wonder how well nontrivial data structures round-trip. &gt; The programming model introduced with Windows 8, WinRT, is built on top of COM. It is based on their original architecture for .NET. Ext-VOS. I'm looking through [Miguel de Icaza's article on WinRT](http://tirania.org/blog/archive/2011/Sep-15.html), and it seems like WinRT is intended only for sandboxed app store use, not general-purpose Windows development (though in fairness, lots of apps can end up sandboxed). This means that you still need C-ABI-compatible languages for systems programming, like his example of partitioning software. It also seems like WinRT will automatically expose .NET or C++ libraries to .NET, C++, or JS host applications running on WinRT, which does seem to address this use case nicely—it doesn't seem like there's anything you can do in WinRT using C++ that you can't do in .NET. Do I have that correct? (Of course this is WinRT as it is intended to be used, on the store, not WinRT as a library that happens to be linkable by native Win32 apps.) I'm having trouble seeing references to "Ext-VOS" other than one filename linked from [a blog post](http://blogs.msdn.com/b/dsyme/archive/2012/07/05/more-c-net-generics-history-the-msr-white-paper-from-mid-1999.aspx) and a claim you made on Hacker News. Looking at the paper, it seems like it's about language features (templates, subtypes, closures, etc.) with only a passing mention of ABI and interop and certainly not architecture/platform. The blog post's title, "More C#/.NET Generics Research Project History," also implies this is about language features in general. Are you just referring to VOS or COM+ in general? Is there anything WinRT brought into .NET that was previously proposed back when things were named VOS and Cool and CLS that didn't make it into previous versions of .NET?
I feel as though trait objects right now are more of an existential type: -- isomorphic to: exists a . (Foo a, a) data FooT = FooT (forall r . (forall a . Foo a -&gt; a -&gt; r) -&gt; r) due to the type-erasure Therefore, fundamentally I don't think it's possible to use methods such as: data Foo a = Foo { method :: a -&gt; a -&gt; a } since you'd have to write something like: dispatchMethod :: FooT -&gt; a -&gt; a You can't unify the `a` in `dispatchMethod` with the quantified variable `a` in `FooT`. OTOH, I do believe the restrictions for generic and static methods are somewhat artificial, but I don't know if the case for generics can be easily solved.
Feel free to copy-paste wholesale/parts/edit/whatever into the docs.
Yeah, I didn't want to use intermediate storage in order to get the iterator in order to run `collect()` on. The way I have it set up I'm convinced will be optimized fairly aggressively.
Ah, you're correct. Though wouldn't it technically be possible from within a dictionary-based (not monomorphized) generic function? Something like this: func :: (Foo a) =&gt; a -&gt; a -&gt; a func x y = { /* switch to Rust syntax here */ x.methodTakingSelf(y) }
I *still* can't get past this. Someone finally explained to me that mobile clients for Reddit don't show the custom CSS styling, or sometimes even the sidebar... ...but why would you ever blindly post to a subreddit you've never read before without checking what it's about? Am I just weird for thinking that's a horrendous idea? People are crazy, I tells ya. Much better to be a robot. Beep boop.
Thanks! That does sound nice and sophisticated. 
Sounds completely possible. There are OpenGL and SDL2 bindings I believe. Check out [r/rust_gamedev](http://reddit.com/r/rust_gamedev) for a good community dedicated to video game development with Rust.
It won't help in your `collect!` macro because the iterator for `into_vec` already supports size_hint.
The core type theoretic use is when you have an open set of possible types you may wish to use in a uniform/heterogenous data structure. E.g. you may wish to have a library store arbitrary (user-defined)callbacks that all do different things to be called when certain events occur, however each closure has a different type: they're only connected by all implementing the same trait (e.g. `FnMut`). So, to be able to store them all a single data structure, you can use a trait object, like `Box&lt;FnMut()&gt;` for the example before. It's not possible to use generics here&amp;mdash;the types are all different&amp;mdash;nor is it possible to use an enum&amp;mdash;the library has absolutely no control/knowledge of the types the user might want to feedin. Another somewhat common use is reducing the need for monomorphised generics, which reduces codebloat.
In Haskell traits are implemented with dictionary-passing: data Foo a = Foo { method :: a -&gt; a -&gt; a } func :: forall a . Foo a -&gt; a -&gt; a -&gt; a func dict x y = method dict x y I imagine you could do the same in Rust as well: // not sure if it compiles but you get the idea struct Foo&lt;A&gt; { method: (A, A) -&gt; A } fn func(dict: &amp;Foo&lt;A&gt;, x: A, y: A) { dict.method(x, y) } I don't it's possible with *trait objects* though as they serve a different purpose. In fact, I would say "trait object" as a name is a bit misleading since they are not "first-class traits" but a completely different beast (`∃ a . Foo a × a`).
Thanks! &gt; Also, foo(object) should probably be func(object). Correct.
Has anyone tried interfacing with Panda3d or other C++ written 3d engine? Panda has C bindings so it should work in theory. edit: not sure why the down vote. Maybe you think we shoud write 3d and physics engines in rust, but that will take time and Panda works right now.
How are you going to get rid of the intermediate allocation? 
 [[f32; 4]; 4] is the type of a 4x4 matrix. Make one like this: [[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]] 
Use the `SizeHint` trick to get the collection to pre-allocate once (assuming it's supported), then extend it with each element. I should be able to do that without triggering an allocation. Might not be entirely optimal (haven't finished fixing all the other problems caused by updates to `rustc` yet), but should be much better.
[That's a good choice of OS you got there.][1] (Result of second command is install date on my machine.) Good catch on libc-dev, though I don't remember having it missing when I first installed Rust on this partition. Weird. [1]: http://i.imgur.com/mPV1434.png
One thing to note is multi-dimensional arrays in dynamic languages tend to get special support because otherwise plain arrays-of-arrays are really arrays-of-pointers to (potentially differently sized) arrays. In Rust, the equivalent of that concept is more like `Vec&lt;Vec&lt;T&gt;&gt;` or `&amp;[&amp;[T]]`. `[[T; n]; n]` fixes the size of both dimensions so it's all packed together.
You don't *need* intermediate storage, you can use one of a few ways to produce a custom iterator. Though it might be hard to support all possible expressions and use no stack space. At which point, we might want to split `extend` into... into what you have there (assuming you use `with_capacity`) - which makes my whole rant pointless.
Right, so here you would have to write (`x.foo()` or `y.foo()` instead of `T::foo()`) to clarify to the compiler which vtable you want to use. But I'd argue that a static method does not make the entire trait non-object safe, it should just disable the possibility to use the `T::foo()` notation while still allowing the `x.foo()` notation. Edit: now that I think of it, perhaps the problem is already in the definition: `fn bar&lt;T: Foo&gt;(x: &amp;T, y: &amp;T)` - there is no argument that takes something you can monomorphize. Instead a function that works with trait objects should look like `fn bar(x: &amp;Foo, y: &amp;Foo)` - which in turn accomplishes that it's not possible to call `T::foo()`, only `x.foo()`. 
Also worth checking out: http://rust-class.org/
Thanks for the links!
I've seen this pattern a lot while poking around the standard library (coverting to strings, paths, etc). One helpful detail missing from the article (but probably was intended to be there) is a blanket implementation for types that already implement Reader: impl&lt;R&gt; IntoReader for R where R: Reader { type OutReader = R; fn into_reader(self) -&gt; R { self } } This is what lets you call the function directly on an arbitrary reader: res.set_body(std::io::util::NullReader); // error without the implementation above
A better example might be *IntoOsStrBuf* from the [IO-OS-Reform RFC](https://github.com/aturon/rfcs/blob/io-os-reform/text/0000-io-os-reform.md#the-design-os_str).
Wider adoption of the language will help the situation, too ;-)
Short answer: not that I've seen. The only bindings are low level api libs like SDL. It's also worth noting that rust does not support C++ bindings; it uses the C calling semantics, so unless the engine exposes a C api, it's not possible. Panda3d already talks to python (which does the same), so it's actually one of the more plausible targets. I've also seen some unity-pro stuff with unity making external calls to rust libs**...but no 'rust bindings' as such. ** on osx. This doesn't work on windows for... unknown reasons. /shrug It *should* work.
There's not a *really* straight-forward way and inlining does mean it can be hard to count things accurately, but one can construct a hacky pipeline to do it, e.g. // instantiate.rs #[inline(never)] pub fn recognisable_name&lt;T: std::fmt::Show&gt;(x: T) { println!("{:?}", x); } pub fn bar() { recognisable_name(1); recognisable_name("baz"); recognisable_name("qux".to_string()) } then, on my linux system: $ rustc --crate-type=lib instantiate.rs $ nm -td -S -C libinstantiate.rlib |&amp; grep 't recognisable_name::' | awk 'BEGIN {sum = 0} {sum += $2} END {print sum}' 701 `nm -td -S -C` prints the demangled (`-C`) symbol names of `libinsantiate.rlib` along with their sizes (`-S`) in decimal (`-td`), and the `grep t ...` filters to only include the things that start with `recognisable_name::` in the text section (`t`) where the functions are placed by default. The `awk` just sums the second column, which are the sizes.
Panda3D has C bindings so it *should* work.
&gt; I disagree totally and completely with this. The community ability to protest abuse of power is an absolute necessity to protect the community against its moderators. Yes, this causes lots and lots of drama. However, I think it is a necessary evil to protect against a community closing itself off to outside debate. I'll take the other side. Disallowing public discussion of singular incidents (please be aware that this clause does not exclude discussion of general moderation policies) makes perfect sense. First of all, it avoids the shame-the-moderator-game, where the banned person just opens another topic under a different name and rallies support. This attracts many "me-too" comments, there are always people taking part in rebellions, as long as they don't have to leave their bedroom and no one dies. Most of these discussions quickly hop from specific into general (especially as most passer-bys don't know the specifics) and cost _a lot of time_. This degrades moderation quality at large, leading to precisely the "abuse of power" image so many forums suffer from. Moderators only have so much time and will start not picking up those discussions, making them feel "detached", while the opposite is true: they just don't bother about that debate anymore. It also doesn't fix anything: moderators on the pillory won't be very much into discussion. Also, good moderators will keep away from speaking about too many details in the open if a person has multiple transgressions. If you ask for public debate, they will still keep a general "our decision was right", which will lead to a skewed picture. The other option is putting _everything on the table_, which might not be to the persons liking. They also don't serve any larger goal: the final decision is still the moderators. Forums are no democracy. They are an offer of someone making an offer to provide a space. It's their space. There are many others on the internet. Also: Good moderators always have a backchannel and that one will still stay in the back, even if you want to publicly discuss. That backchannel is important to have one outward facing policy. While a good moderator usually has the ban-hammer in a cabinet with three locks, hits are final. Moderators are the enforcers of the policy and that has to be accepted. Don't waste their time by trying to stir a storm. I've been doing forum moderation in forums on multiple topics (programming and music mostly) for ~15 years now and I can say: public discussion policies often crash and burn.
Awesome, can we have this in stdlib please? :-)
Accessing a specific coordinate would look like `matrix[2][4][5]` though, rather than `matrix[2,4,5]`.
Why not a different macro for each container? Is that unsavory?
Very much so. I have been doing some prototyping in Rust (got to publish the code at some point though), and given the piston infrastructure it is comparably nice to program in it. If you want to create high-level throw-away code for rapid prototyping, I would not recommend it though. But for a game engine it's much more pleasant to work with than doing it in C++. (I'm weighing language features against library features here, so that may be subjective.)
So returning a closure from a function is a bit difficult because you can't name the actual type of a closure. Closures are transformed into types created at compile time that implement one of the `Fn*` traits, inferred based on the context. You can't return a bare closure from a function because there's no way to name the return type. fn get_closure(x: i32) -&gt; /* what do you put here? You can't do `Fn() -&gt; i32` because it names a trait and not a concrete type */ { || x + 1 } However, you can "hack" around this limitation with trait objects, though it gets a bit involved with lifetimes. // The `'static` bound means that the trait object cannot contain any non-static references. // // Otherwise you have to introduce a lifetime parameter to the function // and any struct meant to hold the returned boxed closure so you can guarantee the closure // doesn't outlive any references it might have captured fn get_closure(x: i32) -&gt; Box&lt;Fn() -&gt; i32 + 'static&gt; { // The `move` keyword means the closure will capture variables by value instead of by reference // It's necessary if you want it to be able to leave the function Box::new(move |&amp;:| x + 1) } fn main() { let closure = get_closure(5); println!("{}", closure()); // Prints "6" } The `Box::new()` turns the closure into a trait object which means you only need the trait name for it to work. However, it does perform a heap allocation and then requires a pointer deref to call. This is very similar to what Haskell is doing behind-the-scenes. Since it is a primarily garbage-collected language, (pretty much) everything is heap-allocated in Haskell and hidden behind a pointer. It sacrifices performance for ergonomics. There's very specific motivations for why Rust does what it does that I could never explain properly. I recommend http://huonw.github.io/blog/2015/01/peeking-inside-trait-objects/ for further reading. There's a feature in the works called "anonymous return types" that would let you write a trait name as the return type of the function, basically saying the function returns an unnamed type that implements that trait. It would basically let you do the above but without boxing the closure.
Which language is that?
And there is also a compelling case for having a subset of rust compile directly into asm64 since LLVM cannot be coaxed into making algorithms that have a constant time regardless of input. Instead of having the language support it directly, [macros and asm!](https://github.com/klutzy/nadeko) (which allows writing assembler directly) are used to create the feature as a library. I think the above case is perfectly covered by the macro for fallthrough_match I linked in my previous post. That macro, though it works perfectly for the example you linked, is not good enough for a general solution (it has a couple gotchas that you wouldn't expect, it may not nest well and I don't know if it supports match syntax fully). The beauty is that we don't need to do compromises and make of match into a terrifying beast of gotchas and checks and requirements to cover a few people's cases. Instead they can implement their own solution and use that, knowing what limitations matter for their case and which don't. If it's used enough times a macro is done to keep things dry. And yes the solution looks scary and hacky, but fallthrough should look kind of scary (it is doing weird things).
Every time I go to give up on rust because there's no libraries to do what I want, someone shows me one (in this case, gilium, which looks lovely compared to unsafe{raw OpenGL)}).
Didn't think of that. Good point. The word is just so close to the perfect fit, what with only one letter needing to be changed.
While the greatest advantage of Rust is definately safety, it is also correctness and an extremely high capability for abstraction (in many cases superior to C++). I would highly doubt that the new security oriented M# (or call it what you may) would boast such features.
There is also this: https://github.com/PistonDevelopers/VisualRust It is a visual studio extension for rust. I've not used it, but its out there.
And for loops are just `while let` loops, but less flexible :( The itertools crate has foreach anyway (called apply), and it's a good place to collect all those things that aren't appropriate for libstd.
i don't see the advantage over a plain for loop, except possibly being able to pass `.foreach` itself around
Thank you, but I still can not get it to work: type FN&lt;'r, A, B, C&gt; = Box&lt;Fn(A) -&gt; Result&lt;B, C&gt; + 'r&gt;; fn compose&lt;'r, A, B: 'r, C: 'r&gt;(f: FN&lt;'r, A, B, C&gt;, g: FN&lt;'r, A, B, C&gt;) -&gt; FN&lt;'r, A, B, C&gt; { Box::new(move |&amp;: x: A| { match (f(x), g(x)) { (Ok(x), Ok(_)) =&gt; Ok(x), (Ok(x), Err(_)) =&gt; Ok(x), (Err(_), Ok(x)) =&gt; Ok(x), (Err(_), Err(x)) =&gt; Err(x) } }) } fn constant&lt;'r, A, B: Send, C&gt;(x: B) -&gt; FN&lt;'r, A, B, C&gt; { Box::new(move |&amp;: _: A| Ok(x)) } fn choose(x: i32) -&gt; Result&lt;i32, String&gt; { match x { 0 =&gt; Err(String::from_str("zero")), _ =&gt; Ok(x) } } pub fn main() { let f = compose(Box::new(choose), constant(42)); println!("{:?}", f(0)); println!("{:?}", f(1)) } Gives me: /tmp/src/main.rs:5:24: 5:25 error: use of moved value: `x` /tmp/src/main.rs:5 match (f(x), g(x)) { ^ /tmp/src/main.rs:5:18: 5:19 note: `x` moved here because it has type `A`, which is non-copyable /tmp/src/main.rs:5 match (f(x), g(x)) { ^ /tmp/src/main.rs:15:32: 15:33 error: cannot move out of captured outer variable in an `Fn` closure /tmp/src/main.rs:15 Box::new(move |&amp;: _: A| Ok(x)) ^ error: aborting due to 2 previous errors 
Let `loop` drop the {} if followed by an expression and we can compose `loop match iter.next() { .. }` and drop `while let` ;-)
A type can be a thing like `Foo&lt;'a, Bar = Baz&gt;`. If you just pretend for a moment it’s a simple text substitution, `let name = Foo&lt;'a, Bar = Baz&gt;::static_method();` is a syntax error.
newbie here. i wanted to create a simple hello-world binary add a function and call this function from a test (in the tests folder). i cannot get this to work. I assume because a binary isnt really a crate so even though i declared the function as `pub` i cannot see it, but i am quite lost as to the exact reasoning here. coming from node i used to write a number of modules which have a default binary behavior but double as pure `modules` which i could require and test from whereever. i tried adding the function into main.rs, with and without `pub`, with and without `mod` and `pub mod` around that. i tried all kinds of statements of `use super::*; use &lt;name-of-mod&gt;; use &lt;name-of-mod&gt;::*&gt;; use &lt;name-of-bin&gt;::` generally the documentation i found is geared towards testing either full libraries or including all tests in the `src` branch which CAN be helpful with very large crates, but, coming from the small modules node world, is not really my way of thinking. can anybody help me out ? the git kattas i found are not actually written as tdd with external tests.
The macro should work fine nested. It doesn't support values in variants (well, it does, but you won't be able to use them because the match body is basically just "goto label") and it triggers unused code warnings if you use "break". So it's certainly not something you'd merge into Rust master, but it should work for those cases where people were relying on fallthrough in C. You could imagine an extension that let you use the variant values by splitting up each body into two parts: the part that handled a direct match, and the part that was run regardless. But that is more work than I care to do at the moment :P
I think whatever happens they would want something internally originated &amp; controlled, instead of community driven, thats' how their business works.
I haven't yet, I've used SFML w/ C++ and C# though which was both enjoyable. Will give it a go when I get a chance.
With all due respect, that's an unfair characterization of Microsoft's status and direction on languages. Are you unaware that Microsoft has open-sourced a great deal of the .NET Framework, and has committed to opening much more of it? Or that they have open-sourced their next-gen C# compiler, codenamed "Roslyn"?
Update: fixed now. Mark as solved and disregard. FWIW, this still doesn't seem to be fixed in the nightly *as installed via rustup.sh* (note emphasis, since it seems to be fixed in git). rustup.sh is getting the nightly from: https://static.rust-lang.org/dist/rust-nightly-x86_64-unknown-linux-gnu.tar.gz. I just downloaded rustup.sh manually, ran it to see which nightly file it was grabbing, downloaded that and took a look inside. This tarball seems to contain the nightly build from Jan 09, 2015. share/doc/rust/html/version_info.html shows: Rust 1.0.0-nightly 44a287e6e (This is probably the reason for someone reporting this issue: https://github.com/rust-lang/rust/issues/20969). Seems like the nightly download file isn't getting updated on the server ...
Call me crazy, but I would much rather see plugins for open source/freely available IDEs. Intellij, Netbeans, Eclipse, etc. While VS is a fine IDE and it would be a good thing for it to have rust support, I don't think the OS community would adopt it. The fact that it is windows only (currently) and microsoft touched would turn away many developers. https://github.com/Vektah/idea-rust https://github.com/drrb/rust-netbeans https://github.com/reidarsollid/RustyCage Here are a few projects for the IDEs I mentioned. I would love to see the community get behind any of these (or a new one if needs be). Now that rust has gone alpha, it seems like the perfect time to start polishing our IDEs.
IntelliJ plugin for Rust would be usable on both Windows and Linux and its a 1st class IDE. Supporting code completion and other language parsing niceties implies writing a Rust parser in Java, though. Been there and done that enough to say that a true managed code implementation vs using JNI to wrap a native code shared library is the better way to go. The IntelliJ IDE cost $200 for a personal use license but there is a community edition that could be supported and would probably be adequate for Rust development needs. I believe Google took the community edition to replace Eclipse in heir Android SDK.
Well, immediate thought is: the compiler is correct. You never read the value you initialise `y` with: it's always either immediately overwritten by the first run through the loop *or* it's never used at all. Same with `z`. You should probably be declaring those inside the loop, not outside. Dunno about the more fundamental problem, sorry. :)
No worries, that gives me clarity on those warnings at least :)
A "convention" is not clear to someone who is not familiar with the "convention". Your argument is that "foreach" is inherently more clear with respect to mutation. I disagree -- it is no more clear.
What's your point? How does that change the openness of C# now? Why should any *potential* future development affect the discussion? From every indication, M# is a research project, more like Sing# than anything else.
https://github.com/rust-lang/blog.rust-lang.org/pull/20 So sorry about that!!!
I hope we have many more of them. If you want to get started blogging, talking about your experience with Rust would be a great way to start! ;)
Thanks! Are you sure you got everyone else? Is there a particular reason that I was missed that might apply to other people?
I didn't say microsoft's language would be a threat to Rust. I suggested microsoft would favour an internally developed language over an open one. and yes, I realise anyone can make a visual studio plugin. I'm just saying the original post has a point, bringing up the existence of the internal project is relevant to the question, would *microsoft* themselves support rust.
I think the sticking point is compiler support for IDE services (partial build with errors, and keep going, that sort of thing), I guess with 1.0 alpha we might see movement in this direction. Once the compiler can support those things I'm sure it'll be much easier for devotees of a particular environment to roll a Rust plugin. I think Visual Studio is an important one though, many people swear by it
Agreed. Microsoft Research is behind some of the most exciting programming languages work of the past decades. They also sponsored the development of Haskell and GHC for many years. I'd love to see a C#-based competitor to Rust, simply because it'd be interestingly different, and it would help restore innovation to a space that has languished in the C/C++ era.
I saw a reddit title with `goto`, was like "uh oh", then I read the whole thing, still parsing "goto" as "`goto`", and was like "is the OP looking for blogs about why Rust is stupid and needs more `goto`?". :P
Except for labeled breaks. Which, appropriately, is the only thing I've used a goto for in C++ aside from switch statements and being a jackass 
Yup, this is why VS is important.
I ran into this weirdness just the other day, actually.
I think it can do it. I've done 3d stuff in Rust on android, and as others have mentioned libraries have improved since then. I'm going back to C++ for familiarity and tools, but these things are subjective (I'm very happy with the way adhoc overloading+templates in C++ can deal with a maths oriented code with a variety of datastructures, and like raw pointer arithmetic for dealing with blobs/concenated allocations etc. Rust has all that in unsafe code, I just find C++ handles it more naturally. I know many people here just don't like overloading). I'm continuing to follow Rust (as the tools improve there will be a bigger draw.. and I'm interested to see what changes post 1.0...). I've also been inspired to start writing a gamedev oriented pet language that tries to merge features from C++ &amp; Rust (using rust-like syntax). Imagine if all the features existed on a spectrum and you could pick and choose. There's a lot I want from Rust, but I don't want to sacrifice continuity with C++ to get it: I want something that you could theoretically transpile my preferred subset of C++ to. I don't think this will become practical without collaborators but enough works to make it look possible. With enough time I think you could make something that was literally a superset of both languages. (you could retrofit an immutable,freezing,borrowed pointer &amp; ADTs to C++; or adhoc overloading to Rust - and personally, I dont need every feature of both.). Its currently a 'rust-like syntax' but the full ambition would be to make it a literal superset-of-a-subset-of-rust. (i'll have to use `^T` for C++ reference perhaps,etc) There are other features I wanted too - D style UFCS ( which is also proposed for C++ ); and rust's old "do notation" - which I think suits data-parallel by making internal iterator code more natural.. (I was very disappointed when they removed this &amp; hope it re-appears). Basically these were both big draws to rust originally ('impl' = extention methods solving the same problem as UFCS, but I found traits weren't as open as I would have liked)
Thank you for the response. &gt; First of all, it avoids the shame-the-moderator-game The "shame-the-moderator-game" is precisely the point. A moderator SHOULD feel ashamed if they abuse their power. &gt; The other option is putting everything on the table, which might not &gt; be to the persons liking. At first you claim to be for the moderator's interests and then you claim to be for the person criticising the moderator's interests. I think that if a person wants to discuss an issue publically then they have consented to putting everything on the table. &gt; Also: Good moderators always have a backchannel and that one will &gt; still stay in the back, even if you want to publicly discuss. That &gt; backchannel is important to have one outward facing policy. I don't understand what you mean by this. &gt; While a good moderator usually has the ban-hammer in a cabinet with &gt; three locks, hits are final. Moderators are the enforcers of the &gt; policy and that has to be accepted. Don't waste their time by trying &gt; to stir a storm. Now you're just stating an opinion and an obviously biased one at that. Can you go into detail why it is so that moderator decisions should be accepted as final and why people who feel aggrieved by moderators shouldn't as you put it "waste their time"? Personally, I feel that if a moderator makes a lot of questionable decisions then their time SHOULD be wasted. &gt; I've been doing forum moderation in forums on multiple topics &gt; (programming and musicmostly) for ~15 years now and I can say: &gt; public discussion policies often crash and burn. Okay, I'm very open to hearing more about this. 
&gt; doesn't map create another structure as a return? It stack-allocates two pointers (for the parent iterator and the mapped function). Problematically in this case, map is lazy, so you still have to consume the iterator for it to apply.
Are any of those available on GitHub ?
This honestly looks like an attempt to figure out whether they can use Sing# from the [Singularity research operating system](http://en.wikipedia.org/wiki/Singularity_%28operating_system%29) for production.
Cool, thanks! Totally out of my reach project wise but I'm hoping to see a microkernel (minix-style) POSIX appear someday in a memsafe language like Rust. I think it'll be a critical waystone on our way out of the infosec bog we're in right now! :)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Singularity (operating system)**](https://en.wikipedia.org/wiki/Singularity%20%28operating%20system%29): [](#sfw) --- &gt; &gt;__Singularity__ was an experimental [operating system](https://en.wikipedia.org/wiki/Operating_system) built by [Microsoft Research](https://en.wikipedia.org/wiki/Microsoft_Research) between 2003 and 2010. It was designed as a highly-[dependable](https://en.wikipedia.org/wiki/Dependability) OS in which the [kernel](https://en.wikipedia.org/wiki/Kernel_(computer_science\)), [device drivers](https://en.wikipedia.org/wiki/Device_driver), and applications were all written in [managed code](https://en.wikipedia.org/wiki/Managed_code). &gt;==== &gt;[**Image**](https://i.imgur.com/9dwJ59e.png) [^(i)](https://commons.wikimedia.org/wiki/File:Singularity_v1.png) --- ^Interesting: [^Midori ^\(operating ^system)](https://en.wikipedia.org/wiki/Midori_\(operating_system\)) ^| [^List ^of ^Microsoft ^operating ^systems](https://en.wikipedia.org/wiki/List_of_Microsoft_operating_systems) ^| [^Spec ^Sharp](https://en.wikipedia.org/wiki/Spec_Sharp) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cnmr56g) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cnmr56g)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I concur, coming from an imperative background, 'for' suggests side effects, whilst 'map' suggests something different I've read about in the functional world. I don't think Rust can enforce 'no side effects' as it stands(?), but if it could the distinction would make a lot of sense, and perhaps its still worth having for convention . on another note when I originally discovered Rust I was excited by the prospect of its "do" notation with internal iterators which would have been great for writing data-parallel code. Write with "do foreach(some_container)|x|{... } .." and based on profiling swap in "par_foreach" at the right granularity (par_foreach does the same thing as foreach, but distributed across worker threads,naturally it would need control over its side-effects but it might still mutate in place quite safely). we can still do this of course, I think thats' another reason to have a "foreach".
Yes, but at the same time you can overload the `Index` trait to use tuple coordinates: `matrix[(2, 4, 5)]` thus (once you have wrapped the array). Of course, you might not appreciate the extra set of parentheses...
There are good reasons for these errors. The first two errors happen because `x` is declared as an arbitrary generic type which is not automatically copyable by default. However, you're trying to call `f(x)` and `g(x)` at the same time. Usually a call like `f(x)` would mean that `x` is moved into the function, however, there are two calls here, and naturally you can't move a thing in two different places at the same time. The last error happens, again, because `x` is of a generic type `B` which is not `Copy`. As you can see, it is in the lexical environment of the closure. However, you are trying to return it by value from the closure which means that it should be moved into this closure from its environment. However, you're using `Fn` closures here which are called through `&amp;` reference, that is, they access their environment through a reference. But you can't move anything from out of a reference, and this is exactly what the compiler is telling to you. The easiest way to solve both of these problems is to make all affected types `Copy`. That is, just put a `Copy` bound on `A` in `compose()` declaration and on `B` in `constant()` declaration. However, this will limit the genericity of your functions severely. If you don't want to use `Copy`, then things get much more complicated. I strongly suspect that it is currently impossible to write something like this in a sufficiently generic fashion. For example, you could use `FnOnce` instead of `Fn` for your `constant()` definition; `FnOnce` closures can move out of their environment at the expense of being able to be called only once (which is natural: if they move things from their environment into themselves, then when they return, these things are destroyed, and the environment is invalidated, so you can't use it again). But this has its own downsides, like the inability to call these closures more than once.
Thanks a lot for great tips! I don't know I was thinking when I assumed one can't use generics with `extern` functions. When I changed `native_compar` into a generic function, as you suggested, everything turned a lot simpler. The gist of it looks like this now: #[link(name="c")] extern { fn qsort_r(base: *mut c_void, nmemb: size_t, size: size_t, compar: *const c_void, arg: *const c_void); } extern fn native_compar&lt;T, F&gt;(a: *const T, b: *const T, rust_compar_ptr: *const F) -&gt; c_int where F: Fn(&amp;T, &amp;T) -&gt; Ordering, T: Ord { let rust_compar: &amp;F = unsafe { &amp;*rust_compar_ptr }; match unsafe { (*rust_compar)(&amp;*a, &amp;*b) } { Ordering::Less =&gt; -1, Ordering::Greater =&gt; 1, Ordering::Equal =&gt; 0 } } fn sort&lt;T, F&gt;(v: &amp;mut [T], rust_compar: F) where F: Fn(&amp;T, &amp;T) -&gt; Ordering, T: Ord { let compar_ptr: *const c_void = unsafe { mem::transmute(&amp;rust_compar) }; let native_ptr: *const c_void = unsafe { mem::transmute(native_compar::&lt;T, F&gt;) }; unsafe { qsort_r(v.as_mut_ptr() as *mut c_void, v.len() as size_t, mem::size_of::&lt;T&gt;() as size_t, native_ptr, compar_ptr); } } It looks flawless for me now. Thanks again.
I consider the standard library to be well named in general, if there is any inconsistency, it is not a rare case. As for the syntax, I do not like arguing about it, I do not believe anyone will change opinions on syntax based on what people on the internet say. I do believe that the syntax is quite nice, though, but that is my opinion.
I'm happy with the `::&lt;T&gt;` , knowing how much hell the ambiguous syntax in C++ causes (needing to know the whole context before you can even parse it, so include order matters.. that's the greater evil). Its nicer overall than the D solution of `foo!(params)` too, i think. Its a shame that one line conflates a couple of issues though; I do indeed miss overloading which would eliminate the `from_str()` that he points at. Its funny because throughout the rust community I find people consider overloading to be a misfeature. Seems like a divisive issue. Maybe it would be worth trying some simple special case rules in the lexer/parser to do some simplified lookahead to disambiguate trivial `&lt;T&gt;` cases ? Could you say that `&lt;...&gt;` without interposing ',', ';' or other bracket level change is always considered a type parameter; and simply require parentheses if you really do want to write `(a&lt;b)&gt;c`. But that might become non-intuitive.. having to explain a different syntax as soon as you want multiple parameters.
No, nobody would like *none* of their code working anymore :). This is the job of the region checker, to tie lifetimes together. Just having `fn foo&lt;'a&gt;(x: &amp;'a T, y: &amp;'a U)` work is enough to break your trick. I didn't even think there was a safe way until I've seen it done with closure scopes (a function taking `F: for&lt;'a&gt; Fn(InvariantOverLifetime&lt;'a&gt;)`) - I think this ended up in `BTreeMap` (/u/Gankro would know more).
Ehm, that's pretty expensive. It might be better to move out of array elements using unsafe code, then `mem::forget` the original. But you'd still need the array on the stack.
Thanks. How would you integrate this with `constant`? The only version of `constant` that I got working in isolation is this: use std::thunk::Thunk; fn constant&lt;A, B: Send&gt;(x: B) -&gt; Thunk&lt;A, B&gt; { Thunk::with_arg(move |: _: A| x) } But I don't think this can be used with your `compose`.
&gt; I consider the standard library to be well named in general Me too, and it was *terribly* inconsistent 12 or 18 months ago. A lot of the Rust version churn in that time period came from renaming and re-renaming standard library items. Achieving consistency has been a focused effort by a number of people and I'm quite happy with the result :)
Regarding the "ugly" syntax, I really wish the convention was to use `let i: u32 = from_str("42")` instead of `let i = from_str::&lt;u32&gt;("42")`. I know the second form is more powerful (can be used on intermediate calls in a chain, for example), but still...
`let i: u32 = from_str("42").unwrap()` *is* the convention, but as you said the second one needs to be used from time to time, because it is applicable in more situations.
Please take a couple of seconds to actually look at the subreddit you are posting to. This is the rust language, not the game. Use /r/playrust for that.
Out of the loop for one week and from_str is gone! Lol, that's good news then!
The beauty of traits for overloading is that you have to explain *why* these functions all have the same name, and what they have in common. If there's no satisfying answer, then it's really doubtful that overloading is a reasonable design.
Also, in most situations the needed type can be inferred, e.g. fn takes_i32(arg: i32) -&gt; i32 { arg + 1 } // some other code... takes_i32("42".parse().expect("42 was somehow not a valid i32"));
Just wanted to note in case people new to the language didn't realize that type inference was powerful enough for cases like that, since the root post implies that using the specification syntax is necessary.
You are totally correct. I apologize for the insulting wording. It was not my intention to indicate that I wasn't well thought out. However I think the point in the article that naming functions things that can be understood directly from the signature is unnecessary holds a fair amount of water. As you say though it is a matter of preference. I am more familiar with more mainstream languages which have tooling which provides the signature readily. In a language like rust where that tooling is not present, naming which describes the return type might be more useful. Again, I apologize for my hastily worded comment. It was rude and uncalled for. Edit: Grammer
&gt; I think the point in the article that naming functions things that can be understood directly from the signature is unnecessary holds a fair amount of water. I agree, but the specific case of `from_str` has been fixed already, as noted elsewhere in this thread. I'm not sure it's a problem Rust suffers from generally; if you have more examples that'd be useful.
`FnOnce` allows captured variables to be moved *out* of the closure environment. This is useful in a variety of situations, as it allows ownership of values to pass through a closure or series of nested closures e.g. when writing Node.js-style continuation-passing async code: let owned_value = OwnedValue(); some_async_operation(move |res1| { some_other_async_operation(move |res2| { do_something(owned_value, res1, res2); }); }); Here, `owned_value` was moved into the first closure, then out of it and into the second closure, and then out of the second closure and into `do_something`.
This is precisely why I have hope for the language. It is in progress and the pieces that bothered me when I looked at it just a short while ago are getting smoothed out and fixed. Keep up the amazing work.
The convention would have to be `let i: Option&lt;u32&gt; = from_str("42");` (well, `"42".parse()` now).
Familiarity isn't worth much in my eyes, and using binary operators with all their typographic properties as enclosing braces is just bad. Has been from the first minute any language misused those as “braces”. Either go real Unicode and use ~~carets~~chevrons ⟨⟩, or use one of the four ASCII enclosing character classes: () {} [] |.
Seems like it's going away too soon, I just saw this www.reddit.com/r/programming/comments/2s7990/microsoft_reseach_language_m_is_no_more/
That seems like a pretty serious violation of layering, safety, and comprehensibility.
Yeah it's a delicate trick that /u/gereeter had to really go out of their way to get working right. It would be interesting if we could have some kind of UniqueToken type that could hook into the tooling of the control-flow/type analysis like lifetimes, but never unify.
As a rust n00b can you explain why `"42".parse&lt;int&gt;()` doesn't work?
You could also pass references rather than making them Copy, to take advantage of their immutability.
&gt; "Using &lt;&gt; for type parameters is questionable, but it has the advantage of familiarity. " After reading the debates on this I was favouring [T], but when I started experimenting with parsing, I discovered &lt;&gt; is potentially disambiguated by their relationship to other brackets &amp; those pesky semicolons. (I think there might be some trivial cases where this could be handled without needing a full GLR parser?.. and the complex C++ parsers can take advantage of this?) Is it possible this is why they have stuck,&amp; been copied, despite the fact that [T] is more appealing? ( [] are kept free up for describing other types. I see swift actually has a [K:V] notation for describing a dictionary, that does make sense to me since you already associate the square brackets with a collection.. and maybe T[N] would still have worked in rust) having said that C++ still needs to bring in all the context to really know whats going on, which is a nightmare, but there's other forms of ambiguity..like straightforward declarations.. `{a*b;}` Rust dodges that set of problems with `let`, which is great.
:( Use your package manager. Of course my server's in a box right now, but I assume stringer is keeping them updated
It works in that case. In general, you would have `a.b::&lt;c&gt;()`, without the `::` the compiler has to perform arbitrary lookaheads to figure out the difference between generics and checking if `a.b` is smaller than `c`.
It doesn't actually work in that case, unless you mean it *could* work, which, wait a second, that's wrong too: `(x.parse &lt; int) &gt; ()` is a completely valid Rust expression and if you changed `libcore` you can even give semantics to it (can't `impl Ord&lt;()&gt; for bool` in your own crate though).
`a &lt; b &gt; c` looks completely ambiguous to me, it should be parsing as `(a &lt; b) &gt; c` right now and produce a *type* error (unless `c` is a `bool` in which case it will fully compile). **EDIT**: sorry, I now see what Cifram meant: it doesn't make sense for that expression to have anything to do with generics. But that's an easy fix: `a&lt;b&gt;(c)`. Parses the same as the previous one, currently.
Yikes. :( I knew some of these, but have missed several just because they've changed since November. :(
Well the language itself is almost entirely stable now, and in six more weeks the beta will arrive to indicate that libraries are essentially stable as well (modulo last-minute bugfixes). :)
No, feel free. I was hoping you'd see it. /u/eddyb said it's "pretty expensive" but if you're relying on the optimizer it should be okay.
Even when a trait only has one method, it often has supertraits, bounds on type parameters, associated items, etc. It's kinda rare to have a trait that's really just a single method. Even in that case, it's good to spell out the pattern of permissible overloading. If I make a method named `clone` that isn't `fn(&amp;self) -&gt; Self` then the trait system makes it really obvious that I'm not implementing the standard `Clone` interface. I guess a common use case for ad-hoc overloading is functions which can accept arguments in multiple "equivalent" forms. In that case, defining and implementing an `AsFoo` trait is a bit of a pain, I agree. But you do get a nice [parametricity](http://en.wikipedia.org/wiki/Parametricity) guarantee in return. With ad-hoc overloading you would have n different function bodies, calling each other and/or some private "impl" function. With traits you have a single function body which calls `AsFoo` methods in precisely those places where it depends on the argument type. In the ad-hoc scheme, bugs can be introduced as the different overloads drift apart in meaning; this is not possible with the conversion trait. As it happens, Rust has a [standard trait](http://doc.rust-lang.org/std/borrow/trait.BorrowFrom.html) for borrowing conversions, which was great for cleaning up associative container APIs. Once we have HKT and painless associated items, I expect we can define traits to conveniently express the use cases of ad-hoc overloading.
If you make the lifetimes in `use_scope` explicit so that they match the lifetimes required by `Scope::new_child`, you get a clearer error: http://is.gd/HsWjIw Your child scopes can't live as long as their contents, so it's impossible to do the recursive call. Note that it works if you remove the mutable reference stored in `MOE`: http://is.gd/7ruVMN This is because mutability forces the lifetime parameters to be invariant, and removing mutability allows them to be covariant.
&gt; micromanage combinations/overlap This is indeed a hassle. But it allows you to see at a glance which capabilities on their arguments your functions are and aren't using, which is a great tool for separation of concerns.
The space waste (`N * align_of::&lt;T&gt;()` unless `T` is some non-nullable pointer) will *not* optimize out. For (very) small arrays, they might get unrolled, but aside from that, LLVM doesn't do any kind of range analysis/induction that could let it know anything about the state of the values inside the array. Just so my words aren't so empty, I just tried [a simple case](http://is.gd/Dm6pZn) and the panic is still in optimized IR. Hmm, [this is really bad](http://is.gd/keoLdF). AFAICT, there's two `i8` stores and a subsequent `i16` load, which doesn't optimize to a constant for some reason.
Arch (AUR and a private repo), Ubuntu (PPA), Brew, Fedora (I've seen it, not sure where)...
`FnOnce` is not object-safe because the call operator takes `self` by-value.
What would be perfect for me is if traits were optional , then you'd have the best of both worlds.. add the traits as the structure emerges, but avoid creating extraneous names early on when it isn't really clear what they should be.. (and personally I can't see myself wanting to rely on the trait being part of the namespacing - I'd prefer to confer over better method names.). maybe when there's an IDE I'd start wanting to use them more because they'd give autocomplete in generics (that would be awesome), but in the single-function case you're again just writing something twice.. or you'd be needing the IDE assist to help you out finding the right trait for the method combination you wanted, almost the reverse. The other thing that might help some cases is a clean way of implementing a subset( you could do it now with defaults that panic!(), but what would be perfect is if you could flag a function that's a compile time error if its' ever called)... I've heard 'negative trait bounds' mentioned in discussions around that subject but I'm not sure if they're solving exactly the same problem. &gt; With ad-hoc overloading you would have n different function bodies, calling each other and/or some private "impl" function. With traits you have a single function body which calls AsFoo methods in precisely those places where it depends on the argument type. you can still do this with adhoc overloads and templates, but see above, either you'd got to look up the method names you want, or lookup the trait and hence the methods. You'd get something working with one concrete case establishing the pattern , then instantiate it with other types. I do realise the issue of complex error messages, hence C++ wanting to retrofit concepts to do a similar job. but I wonder if those can be improved with sorting /folding. `can't call &lt;outer_method&gt; here (because &lt;inner_method&gt; not found here..)` instead of `&lt;inner_method&gt; not found in instantiation of &lt;another_method&gt; from here...&lt;..&gt;.... from here &lt;outer_method&gt;` 6 pages later
Yeah, we thought about trying to do infinite lookahead there, but nobody found a way to get it to work.
Verified. 64-bit binaries for Linux are now genuine nightlies. Thanks!
`whatAmI` is being called incorrectly, you have to access it through the type. In other words `t.whatAmI` doesn't work, instead you have to call it as `&amp;Animal::whatAmI` which shows the problem clearly: you never access the instance and never touch the vtable; you can't access a function from a vtable you never access. Static methods would be class methods on python, and on C they'd be plain functions. The idea is that you may want a trait that needs a function that cannot be a method (a constructor for example) so something like the following: trait Database { fn connect(username: string, password: PwdHash) -&gt; Self fn query(&amp;self, query: string) -&gt; &amp;QueryResult ... } Basically if you have a static method that you could implement for a trait, then you could push it out. Something like this: trait Animal { fn whatAmI(&amp;self) -&gt; &amp;'static str } struct Cat; impl Animal for Cat { fn whatAmI(&amp;self) -&gt; &amp;'static str { "cat" } } struct Dog; impl Animal for Dog { fn whatAmI(&amp;self) -&gt; &amp;'static str { "dog" } } fn justWhatAmI&lt;T: Animal&gt;(t : T) -&gt; &amp;'static str { t.whatAmI() } fn print_animal_type(t: &amp;Animal) { println!("The animal is a {}", whatAmI()); } The case above will work, though it also shows why the pattern is weird. Any static method that doesn't make reference to any implementation detail of the type (not the instance) should probably be a separate function. Another way to put it: 1. A way to fix a static method is to pull it out of the trait and make it a separate function. 2. If such thing is not possible because it requires different actions depending on the type, then it should be convertible to a method. Rest assured that even simple optimizers can and will remove the extra self, except when calling from a vtable (because it needs that data!). 3. If neither 1 nor 2 are possible this means that, not only does it change by the type, but it is impossible to always call the method from an instance. 4. If 3 is the case, then method can't be inferred from an instance, only from the actual type. 5. Because virtual dispatch assumes type erasure, that is all type information is lost and only instance information is kept, that means that type information can't be retrieved, if 4 is true then that means that we can't do dynamic dispatch, as the information needed (type) is not available (it was erased). So static methods that could be dispatched dynamically should probably not be static methods at all.
or as I like to put it: FnOnce allows the function to consume its environment.
Wow. There must have been a lot of people who noticed this and decided to update at the same time. The download of the update is uncharacteristically slow (20 minutes so far for something that normally takes about 2 minutes).
Surely, sorry for the misunderstanding!
Nice! One other thing I've noticed is that you have a `T: Ord` bound but then never use it :) If you want that bound you could remove the closure entirely (by just using the value's `cmp` method instead of a closure), or you could just remove the bound and keep using a closure.
VS is the only decent IDE available. It's flawed and quite bad in many ways, but the alternatives are all terrible right now. That might make it ripe for disruption, but until the day someone comes up with an alternative that isn't absolute garbage there will be *many* people who do for-profit software that would require VS support before they would get really excited about something. The reason game devs (for example) almost unanimously think Windows is the superior development platform isn't because of the Win32 APIs or the OS itself - it's because of visual studio. If I had to choose between eclipse and rust versus visual studio and C++ I would choose the latter any day of the week. The productivity gains you get from a good IDE and debugger beat language productivity gains (the ideal case is that you get both).
Here's my working version of it. https://gist.github.com/arthurprs/bdefd6924529da08897f XXTEA operates on 32bit blocks on it's core. To correctly handle String's you will need some unsafe wrappers to use the underlining memory and also handle lengths not divisible by 4 (32bits).
I feel like I'm the only one that actually *likes* `::&lt;_&gt;`. It seems very consistent with the rest of the language to me. The `::` syntax is "inside/of" (for want of a much better term). An item inside a module, a method of a trait, a variant of an enum, etc. So I read `::&lt;_&gt;` as "an implementation of a trait", named by the type. Maybe it's an eyesore, but to me it's very consistent, and that's the most important thing. Most of the proposed alternatives I've seen introduce a new syntactic concept, whereas the current one seems to fit right in (to me at least).
http://this-week-in-rust.org/ usually has a Community section with a Blog Posts subsection that I've found to be an excellent way of discovering people blogging about rust :)
Unit tests run in parallel and do not run in order.
Maybe I don't know what the right question to ask is; but ... What's the relation between owning the environment and running it once? Can't it be run more than once and own the environment?
I guess you need to get the following files out of the "SDL2-devel-2.0.3-mingw.tar.gz" archive: * libSDL2.a * libSDL2.dll.a and place them in the following folder: &lt;rust_install_dir&gt;\bin\rustlib\x86_64-pc-windows-gnu\lib Not 100% sure if that's everything you need to get this to work, I'm gonna try to see if I can build with it. Edit: Forgot, you need the SDL2.dll file somewhere in your %PATH% (or in the same place as the built executable) aswell, and then it builds and works fine (Atleast it did for me right now).
Maybe `\ /` could work - e g, `Vec&lt;Rc&lt;RefCell&lt;Foo&gt;&gt;&gt;` would become `Vec\Rc\RefCell\Foo///`. The `\` symbol is AFAIK unused outside string literals, and `/`, while used for division, should not be more difficult than today's `&gt;` for the parser. And since `\` is unused, you don't need the `::` - `foo::&lt;i32&gt;(bar)` could be `foo\i32/(bar)` without ambiguity. Edit: Hmm, `//` is used for comments. Then we need to replace `//` with something else...
Aaahhh clarity! Many thanks, great sir! I guess it's not really "needed", just that having FnOnce allows for convenience that would be more annoying to achieve otherwise ...
You don't need the `.a` files if you have the `.dll`. The former facilitates a static link (no runtime dependency but bigger binary) while the latter facilitates a dynamic link (smaller binary, can replace the DLL with an updated version as long as it has the same ABI). I found that placing the DLL in the Rust install directory was sufficient (since that's also added to your PATH). Edit: Note that `libSDL2.dll.a` I believe is just a static archive for building `SDL2.dll` so you don't need it anyways. `libSDL2.a` should be the only archive you need to statically link SDL2. You would place that in the `\bin\rustlib\&lt;target&gt;\lib` directory since that's added as a linker search path by default.
If you want to add values of type T by reference, simply impl Add for &amp;T.
I have had success using this library for cairo: https://github.com/passcod/rust-cairo worked as of last week :)
While I agree, that upgrading existing opensource IDEs to support Rust is a must, but there is an other way of the argument as almost outlined in the comments here: A large portion of the performance oriented (I mostly mean game dev) programming happens under windows and as such most C/C++ stuck (bulb effect and lack of information on prog lang theory) developers are using VS. They may never (or too late in time) manage to hear about Rust and how it may ease the development and improve thinking. However if this proposal succeeds it means coverage of the language on official blogs and appearance of tools and MSDN articles that means these thousands of developers willy-nilly come to hear about this language and may give it a try. I had some friends working in production dev hearing some of us going into raptures over rust features and after some time, they gave up resistance and tried it, and after another month they were thinking of rewriting a few year's of work in it... Guess how long had it taken for them to tumble upon it just by chance... It is not just about the rust community it is also about the general programming community: a chance to learn deeper insights that can be applied in other languages and also improving overall code quality everywhere.
Change code blocks to do/end (or something). Reduces visual noise and is as fast, if not faster, to type. Avoids wasting a bracket form for something that's almost never on a single line anyway. /ducks
Is the nightly source being archived? I get 404 for https://static.rust-lang.org/dist/2015-01-12/rust-nightly-src.tar.gz (and for the last few days)
Hi, I had the same thing that you with the [rust sfml](https://github.com/JeremyLetang/rust-sfml) library. I found several ways : - Paste your .a library file in the lib directory of MinGW - Use Msys shell : export LIBRARY_PATH $ LIBRARY_PATH="C:/SDL-2/lib;$LIBRARY_PATH" - Create a [build script](http://doc.crates.io/build-script.html) : fn main() { println!("cargo:rustc-flags=-L C:/SDL-2/lib"); } But i'm not sure that is a proper way to handle things.
Well, the "proper" way to do this is to [override](http://doc.crates.io/build-script.html#overriding-build-scripts) the build script of `libsdl2-sys`. [Here is a similar example for freetype-sys](https://github.com/PistonDevelopers/freetype-sys#for-windows-users).
I was using [https://github.com/KevinKelley/nanovg-rs](https://github.com/KevinKelley/nanovg-rs), which seemed to work reasonably well at the time. Many Rust library authors haven't kept up with the rate of change of Rust over the last couple of months, and I can't blame them. Hopefully with the coming stabilization more library authors will return and update their libraries as Rust nears 1.0. The same thing happened just before Go reached 1.0. One thing you can do is pitch in with pull requests to update libraries for compatibility with 1.0 alpha. I'm sure most library authors would appreciate the help.
I know it doesn't work, but I mean it *could* work, by virtue of string and number literals not having properties. That is, wheneven a compiler sees `"some_string".something` it could figure out that `something` is a method call. So if we see `"some_string".something&lt;` it *could* figure out that whatever follows must be generics. So in theory, `"42".parse&lt;int&gt;()` could work (except that `int` will stop working).
I shall go hunt for it in the docs in that case. Thanks!
I share some of his concerns: - implicit return (I find explicit return easier to read), - easy metraprogramming (D is pretty good here), - no variadics generics, - lack of HKTs. The last two might have a huge impact on the std lib..., variadic generics have caused (and are still causing) deprecation of a lot of C++ std library functions.
Docs: http://doc.rust-lang.org/std/iter/trait.AdditiveIterator.html#tymethod.sum
A good middle ground would be either a lint or a warning.
 let mut str = String::new(); for _ in (0..10) { str.push(rand::random::&lt;u8&gt;() as char); } Would give you the same result as your C++. Though I would use: let str: String = (0..10).map(|_| rand::random::&lt;u8&gt;() as char).collect();
Well, this works use std::rand::random; fn rand_string() -&gt; String { (0..4).map(|_| random::&lt;char&gt;()).collect() } fn main() { println!("`{}`", rand_string()); println!("`{}`", rand_string()); println!("`{}`", rand_string()); } But what are you trying to do here? Data generated like this isn't going to be meaningful. I mean, I get the following output: `񾉤񜇘𮋮􏢾` `󃔎⾨񬾺򔈢` `󶼎񆿼󙡛󶄋` Actually, I'm not really sure if that will even produce valid data in all cases. Of course, the *other* thing you could do is limit yourself to printable ASCII... use std::rand::random; fn rand_string() -&gt; String { (0..4).map(|_| (0x20u8 + (random::&lt;f32&gt;() * 96.0) as u8) as char).collect() } fn main() { println!("`{}`", rand_string()); println!("`{}`", rand_string()); println!("`{}`", rand_string()); } Which produces something that looks like: `9dBM` `~}"k` `7v'&amp;` 
thanks!
Yeah, same here (same hash values and everything).
I like implicit returns, because it makes inline lambdas much cleaner. I don't think it's possible for it to ever cause bugs, because the two possible problems (forgotten semicolons mid-function and extra semicolon in return position) will both cause compilation errors.
Can anyone post the version that complies to the standards without warnings?
- If you want a sequence of printable ASCII characters, you can use [`.gen_ascii_chars`](http://doc.rust-lang.org/nightly/std/rand/trait.Rng.html#tymethod.gen_ascii_chars). - If you want a sequence of random bytes (like the C++ code you've written), you can use [`.gen_iter::&lt;u8&gt;`](http://doc.rust-lang.org/nightly/std/rand/trait.Rng.html#tymethod.gen_iter). - If you want a sequence of random Unicode code points (strictly speaking, Unicode Scalar Values), then `.gen_iter::&lt;char&gt;`. These all return iterators, so you can use [the iterator adaptors and consumers](http://doc.rust-lang.org/nightly/std/iter/trait.IteratorExt.html) to manipulate the output into your desired form. E.g. #![allow(unstable)] use std::rand::{self, Rng}; fn main() { let s = rand::thread_rng() .gen_ascii_chars() .take(10) .collect::&lt;String&gt;(); println!("random string: {}", s); } [playpen][pp] [pp]: http://play.rust-lang.org/?run=1&amp;code=%23!%5Ballow%28unstable%29%5D%0A%0Ause%20std%3A%3Arand%3A%3A{self%2C%20Rng}%3B%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20s%20%3D%20rand%3A%3Athread_rng%28%29%0A%20%20%20%20%20%20%20%20.gen_ascii_chars%28%29%0A%20%20%20%20%20%20%20%20.take%2810%29%0A%20%20%20%20%20%20%20%20.collect%3A%3A%3CString%3E%28%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20println!%28%22random%20string%3A%20{}%22%2C%20s%29%3B%0A}
There a typo? https://gist.github.com/arthurprs/bdefd6924529da08897f#file-main-rs-L25
I've had the same suspicion. If someone has the will and ability to deal with C++, I don't see how something like square brackets over angle brackets will give them too much trouble, or deter them.
If I was designing a language, I'd consider using multiple characters in different enclosing characters. For example: maybe I would have `[|` and `|]` for a certain thing, and so freeing up `[` and `]` for another thing. Maybe use this as literal collections(array, list): `[|1, 2, 3, 4|]`
just like using comparison operators as enclosing characters.
With only the `.dll` on the PATH but no static lib, the program will fail to link. But you're right, it only seems `libsdl2.dll.a` is needed to make the linking step work. Between that and the DLL, I was able to get the demo to run. Thanks for the help!
Ah, thanks. I didn't know about `use std::iter::AdditiveIterator;` for `sum()`.
The 0us, but my compiler was out of date :)
@rustcvswvj I looked at server/skia and although its been cargo-ified, I don't see actual rust bindings. I believe they are fused with rust-azure.
Great. I'll take a look.
i/o is still not stable, so it's likely to get some errors. We're hoping to stabilize the last two or three big modules, and then 'compiles without warnings' will be a more realisitic thing.
I don't know - I haven't yet had time to do anything of comparable size. By the way, what's up with this "fighting" the compiler? When you understand how it works, I don't think you will need to. (like dodging the bullets: when the time comes, you won't need to :) )
my opinion on this - tools (IDE.. dot-autocomplete for navigation/discovery, fully resolved jump-to-definition, debugger integration) count for more than language differences. Personally I think debugging is more about logic problems generally, pointer bugs aren't that big a deal (for me). Games have a lot of immutable data and simple pooling going on.. the problems are dealing with file formats(how does this data work..), dealing with the GPU, dealing with platform differences (they're *trying* to create proprietary lock-in issues) etc. I think Rusts focus would pay more dividends in huge projects with large teams (as its' designed for).. its very possible this would help with collaboration across the internet(allowing more disjoint contributors). There are a lot of ways for one C++ programmer to annoy another with style issues. But in an in-house project, conventions can be explained in person. in a personal project, use your favourite subset. The best bits of rust for gamedev IMO are: (i) its' macro system ..which can help dealing with file formats..shader parameters/vertex attributes - the missing introspection of C++, handling everything you try to do with x-macros much better; and (ii) the cleaner syntax generally. Immutable default/expression syntax definitely suits graphics code. ADTs are nice for messages. `impls'` almost solve the same problem as UFCS. I really like having 'proper' tuples. No stupid header files. I've wanted Rust and continue to follow it for these reasons. Safety to me is just a glorified/'compulsory' debug build+analyzer; although there's one restriction I do really like - globals requiring unsafe. Ultimately your own familiarity would be the deciding factor. I still personally find C++(with IDE) more productive - I find Rust modules just as annoying as header files - it's just as hard to move code around with the full location always baked into namespaces -and fiddling with traits vs more open adhoc overloading. If C++ get's the UFCS proposal implemented ... it would restore my long lost faith in humanity. Rust imposes more work naming &amp; looking up names, and there's no IDE to help with that yet (less a fault of the language,just the worlds' momentum). So for me a case of 'better the devil you know'. It's possible when there's a Rust IDE the situation would reverse ..maybe with 1.0 happening we'll get more movement on this as its no longer a moving target. Autocomplete in generics could be rather useful. Rust tooling could be superior, because the language is easier to parse.
Rust can reject some code that is safe, but can't be proved safe at compile time (it has to over-estimate safety)- and you have to remember more vocabulary to do simple things. (tell it its' safe , in its' language). See the recent thread about taking 2 mutable references in a collection for example - who knows 'split_at_mut()' is the right helper function for that routine task? That's what 'fighting the compiler' means. 
I recall seeing some pretty vitriolic reactions from C++, Java and C# programmers to D's non-standard template syntax. Clearly, the language must be implemented by morons if they can't work out how to use the standard syntax! Let's not even get started on the more heinous of sins: using keywords instead of braces! Urgh! Seriously, people can get hung up on the weirdest things, like line lengths, position of braces and single-line versus multi-line comments. I know people looked at old Rust and wrote it off because it was too sigil-happy. Sometimes, a concession made in the name of familiarity can be a good thing.
Games might not be safety-critical, but memory safety is actually very important for them. Often neglected, but important. http://smealum.net/?p=517 Want to not cause a huge SNAFU for the developer of the console your game runs on? Better do some bounds checking. Are you SURE there's no way your renderer can be convinced to use a out-of-range vertex index? What about your map storage? Can your networking code really withstand a determined effort to get just one memory safety bug? Oh, and want to go parallel for speed? Better check for race conditions. http://www.garrysmod.com/2014/04/19/exploit-fix-released/ This spread throughout a good portion of the playerbase almost overnight. Imagine if it had carried an actually malicious payload? And an anecdote: So far, I have never had to use anything more complicated than simple logging to debug my Rust code.
For the last two, I think you'd need either slice::from_raw_buf or your own playing with transmute and raw::Slice, something along the lines of let ptr = event_flags as *mut u32; unsafe { let slice = slice::from_raw_mut_buf(&amp;ptr, num_events); }
I would argue that to develop safe C++ app you have to set up conventions, follow them, and then have no automated way to check for mistakes. So this kind of trade-off might be reasonable :)
Ah, yes, you're right.
Not as a bug when fed valid input- as a vulnerability when fed crafted input.
This works by making FN's argument by reference: #![feature(box_syntax)] type F&lt;'env, A, B, C&gt; = Box&lt;for&lt;'arg&gt; Fn(&amp;'arg A) -&gt; Result&lt;B, C&gt; + 'env&gt;; fn compose&lt;'a, A, B, C&gt;(f: F&lt;'a, A, B, C&gt;, g: F&lt;'a, A, B, C&gt;) -&gt; F&lt;'a, A, B, C&gt; { box move |&amp;: a| match (f(a), g(a)) { (Ok(x), Ok(_)) =&gt; Ok(x), (Ok(x), Err(_)) =&gt; Ok(x), (Err(_), Ok(x)) =&gt; Ok(x), (Err(_), Err(x)) =&gt; Err(x), } } fn constant&lt;'a, A, B: Copy + 'a, C&gt;(x: B) -&gt; F&lt;'a, A, B, C&gt; { box move |&amp;: _| Ok(x) } fn choose(x: &amp;i32) -&gt; Result&lt;i32, String&gt; { match *x { 0 =&gt; Err(format!("zero")), _ =&gt; Ok(*x), } } fn main() { let f = compose(box choose, constant(42)); println!("{:?}", f(&amp;0)); println!("{:?}", f(&amp;1)); } Another possibility is to make `A` `Copy` as mentioned before, but then use a reference as the type argument: #![feature(box_syntax)] type F&lt;'env, A, B, C&gt; = Box&lt;Fn(A) -&gt; Result&lt;B, C&gt; + 'env&gt;; fn compose&lt;'a, A: Copy, B, C&gt;(f: F&lt;'a, A, B, C&gt;, g: F&lt;'a, A, B, C&gt;) -&gt; F&lt;'a, A, B, C&gt; { box move |&amp;: a| match (f(a), g(a)) { (Ok(x), Ok(_)) =&gt; Ok(x), (Ok(x), Err(_)) =&gt; Ok(x), (Err(_), Ok(x)) =&gt; Ok(x), (Err(_), Err(x)) =&gt; Err(x), } } fn constant&lt;'a, A, B: Copy + 'a, C&gt;(x: B) -&gt; F&lt;'a, A, B, C&gt; { box move |&amp;: _| Ok(x) } fn choose(x: &amp;i32) -&gt; Result&lt;i32, String&gt; { match *x { 0 =&gt; Err(format!("zero")), _ =&gt; Ok(*x), } } fn main() { let f = compose(box choose, constant(42)); let zero = 0; let one = 1; println!("{:?}", f(&amp;zero)); println!("{:?}", f(&amp;one)); }
This is all I did when I got it working: Setup your project (just use the example code from their site). Grab the win32 libs from the sdl site .lib files then create a folder in your root cargo project: **/bin/i686-pc-windows-gnu/** and drop your lib file there and possibly the .DLL file's too (can't remember) and cargo build or cargo run and it should build like normal. I learned that it looks here for the libs as well as the rust root bin: '-L' 'D:\..snipped..\Rust\example\hello_world\bin\i686-pc-windows-gnu' When I was viewing the error message, here's my post originally https://github.com/AngryLawyer/rust-sdl2/issues/262
On the other hand, there's a pretty clear cost to fixing bugs, and that cost is related to when the bug is found. At compile time, the program won't even run. At runtime, you have to go back and re compile. At QA time, you have to go re-establish your dev environment to fix it. After shipping, when you're working on another project, you have to go back to an old version. Catching a bug later gets progressively and perhaps exponentially more expensive to fix. All other things being equal (they're not - but it's useful to consider this case) catching even one extra problem at compile time will save time and effort over the life of a project. 
No, because the eco-system still isn't there. People focus too much in the languages and too little on the surroundings. - Available libraries and their respective maturity - Programming knowledge across team members - Compiler availability across all target platforms - IDE/Editor support - Static analysis and build infrastructure - In you case, game engines (hint: either you make a game or an engine) Rust will get there as well, but you cannot expect an almost version 1.0 language to match the eco-system of a 30 years old language, today.
&gt; superficially repulsive and semantically curmudgeonous language for so long Hey hey hey. C++ Dev here, haven't been at it (professionally) for super long. But let's be honest, we're not talking about *perl* here. That being said I just looked at how D declares templates and uses them inline. I like it. I don't think removing diamond notation will scare off C++ devs. Well, maybe the old guys who still write C-style code (objectless C++) and want to operate their GCC in terminals. But they haven't been defining the software and systems engineering landscapes for a while. So maybe switching to **!** the way D uses it would be for the best. Edit: Except now I just remembered that's how Rust declares macros. Fuck. Anybody got any other ideas? @?
How about using the @ character? It makes a bit more sense when looking at it and reading than a !. "42".parse@&lt;int&gt;(); Edit: This makes it easier to **read** in your head, too. "String 42 dot parse as type int."
&gt; Most people don't want their games to randomly crash, freeze, or generally misbehave. Rust goes a long way to prevent these specific types of errors. Don't forget memory leaks. I can't wait for game development companies to start embracing Rust for these very reasons. But we'll need some solid IDEs before that takes off in any degree of seriousness. I'm also curious about rewriting Linux components in Rust, or building a Rust-based OS in general.
The `asm!` macro is restricted to `unsafe` blocks for this very reason.
My take of Rust vs C Use Rust -&gt; Make Compiler Happy ------------&gt; Runs without Crashing Use C -&gt; Make Compiler Happy -&gt; Runs -&gt; Crashes -&gt; Debug -&gt; (repeat) ....
 fn main() { let v = vec!["foo","bar","baz"]; let concated : String = v.iter().fold("".to_string(), |mut i,j| {i.push_str(*j); i}); println!("{}",concated) }
While this is true for a strict Rust definition of "crash", it doesn't mean your program is at all sound. Take an OOB array access (easily caused by a logic error) - in C this might cause a segfault (or worse), while it'll probably cause a panic in Rust. Sure a panic is better the a segfault, but a user is still going to call it a crash.
Why not throw out `arr[i]` for indexing and replace it with `arr@i`? Of course since familiarity seems to be wanted I expect it's an inciting proposal.
Really good point I overlooked. At least Rust has some pretty good C interop, so for libraries it might not be so bad.
&gt; Static analysis and build infrastructure Maybe thats the one place where Rust could claim to be unambiguously better out of the box. (inbuilt static analysis enhanced by lifetimes; build-infrastructure: the language describes it's dependancies properly) I also look forward to future tooling for rust, the less crazy syntax should help compared to C++.
I'll probably end up doing something like this. I only have access to the scope to pass into my code right now as a &amp;mut Scope, so I can't move it into the Box (It cannot be borrowed/moved after the function call which makes the child scope returns). I can probably just re-write it to instead use a refcell over the data without too much difficulty. Thanks for your help.
Unfortunately I need mutable access to the parent scope in the actual application, so that doesn't work for me :(. Thanks, though!
&gt; In you case, game engines (hint: either you make a game or an engine) Tell that to Notch :) edit: I completely agree.
Well, even in that instance, you can't actually be sure that it's better or worse. You'd have to control for so many things as to make it almost impossible. It's pretty much the equivalent of /r/whowouldwin but in software.
Well, that brings up the question of where you want to store `constant`'s `B`, or who you want to "own" it. Haskell uses garbage collection to manage that, so it can just pass a shared pointer to the `B` on the heap wherever it wants, but Rust needs a single point of ownership to be responsible for deallocation. If you want to store it in the closure by value, and return it by reference, you'd need to change `choose` to match. The returned reference's lifetime would need to be the lifetime of the closure's environment, but I'm not sure if there's a way to specify that right now without writing the closure struct yourself (the type would be something like `fn call&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a i32`, in which the lifetimes can be elided to `fn call(&amp;self) -&gt; &amp;i32`). If you want to keep the value somewhere else and have `constant` just store a reference in its environment, you'd still need to change `choose` to return a reference to the passed-in value, but that might be simpler if you don't mind keeping all your constants and choose'd values around.
&gt; What would be perfect for me is if traits were optional , then you'd have the best of both worlds This would eliminate the ability to do static dispatch, I'd imagine, which is a big deal.
Why didn't that work out?
I don't see how this can be the argument - you have the same OOB array access problem in C _plus_ other safety issues.
I don't remember. https://github.com/rust-lang/rfcs/pull/386 has some details, but the ending message basically just says 'closing.' I think Niko basically decided it wasn't worth the effort, but can't be sure without asking him.
Last time I checked, the ubuntu cargo PPA wasn't being updated, only rustc. Which was annoying because they seem to break if they go out of sync (or did).
I've spent 2 weeks debugging a single memory corruption bug. That was after another guy spent a week on it and couldn't figure it out. If rust does have faster development, that's where I think you'll be saving time. But you probably won't even realize it. It'll just be a lack of heisenbugs.
If you are going to be doing that, you can realize that the sums can be computed closed form and skip looping entirely.
I think that's roughly the conclusion he came to - @ being used to denote macros just added screenspace clutter, would potentially be [ambiguous with expression annotations](https://github.com/rust-lang/rfcs/pull/386#issuecomment-59018339). That being said, I'd like to make the case for using @ rather than :: to denote generic typing. I don't think it's ambiguous to read (especially as, to the best of my admittedly limited knowledge, it's only used for pattern matching currently in much the ways lambdas can be used in C#) if it were to replace the obnoxious and ugly :: notation. Especially since I never think of diamond notation and .s being equivalent. Generic types are an implementation of a metaclass, rather than a field of a metaclass.
c++ programmers deal with this with debug builds, which can have bounds checks and all sorts of other checks going on. Run the most pathological levels and artifically created corner cases &amp; stress tests through the debug builds.
There's quite a lot about Rust that is appealing for game development. The resource safety features of it without Garbage Collection, for example. And the fact that it's relatively easy to use existing C libraries is good too. Unfortunately there's a fair bit missing at the moment from around the edges - things like IDE support, Debugger support, general Rust library support and so on. But that will hopefully all come with time.
Crash the runtime.
the problem there is Rust is optimised for safe code, C/C++ handles unsafe code more elegantly.. its' syntax choices are optimised for it; a blessing for unsafe and a curse for safe, perhaps. of course you can create abstractions to handle everything, and the stdlibs probably have most of what you need (e.g. look at the recent thread on taking a pair of mutable references inside an array).. but what to call everything , and how do you know what to look for.
Awesome, i'll give it a read.
I imagine Rust with optional traits would have type bounds for individual function signatures, kind of like how GHC handles [implicit parameters](https://downloads.haskell.org/~ghc/7.8.3/docs/html/users_guide/other-type-extensions.html#implicit-parameters).
Oh and let's remember that *in C this might cause a segfault* -- and it might pass silently with the current compiler / flags / environment! So at least Rust is quicker to "crash".
Would it make sense to have olson time zone db parser as separate package? EDIT: Fix ambiguity
Cookies are delicious delicacies.
Well, you'd of course want to make sure `compose` matches the new types of `choose` and `constant`, however you implement them.
Very cool; I started my own GB emulator (in Rust) on new year's day... it's been an awesome project so far. Very time consuming though ;). I also just wanted to say: the way you wrote `CpuOps` as a trait is really awesome. I sure wish I had thought of it. It is also great to get a handle on how you've handled the VRAM access timings. (Though the per-cycle accuracy does seem to complicate the dispatcher considerably.) 
You're right, thank you. fn get_sum(limit: i32, i: i32) -&gt; i32 { // sum of range = N * (N + 1) / 2 return (limit - (limit % i)) * ((limit / i) + 1) / 2; } fn main() { println!("If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9. The sum of these multiples is 23."); println!("Find the sum of all the multiples of 3 or 5 below 1000."); let limit = 999; let sum = get_sum(limit, 3) + get_sum(limit, 5) - get_sum(limit, 15); println!("{}", sum); }
:( if you're using the runtime anyway, presumably you can stand to have this small amount of text embedded?
Oh, I am not saying *never* unifying any longer. I am talking about first giving each variable its own lifetime, so that multiple `InvariantLifetime` with different sources never "collide". Then you still have the usual unification/subtyping available for "regular" references when resolving function calls.
This isn't optimal either. There are closed form expressions for bounded arithmetic sums.
It's too early to know. Each time I understand more and more Rusts way of thinking. As an example I'd think about when I learned Lisp: first everything took forever on Lisp, I was fighting the mentality and trying to be imperative when I needed to be functional. Then, one day, after so much fighting, I was enlightened, and suddenly things made sense, and my Lisp coding sped up greatly. At the same time I was able to grasp if a project was something that would be convenient to do on Lisp or C or something else. This process was repeated with a lot of languages, and at the same time it made my coding in the previously known languages better. So who knows how much time will normally be spent fighting the compiler, I believe that once you get a feel for lifetimes you'll rarely ever do something so weird the compiler won't accept it even though it's "correct". I can tell you: a lot of time will be lost learning the language. Rust has some roots in C++ but I feel it's actually less like C++ than like it, so it'll be a whole new learning experience. Now games have a lot of bugs, but many of these bugs are on the "high-level": they are issues with the level design and geometry of stuff, they are bugs in the AI or mathematical errors in the physics engine. Actual crashes are rare, and if you look at the low level code for 3D engines (look at the [Doom 3 engine](https://github.com/TTimo/doom3.gpl)) the code is extremely strict and controlled so as to prevent memory leaks or other issues. Rust would formalize this and force you to keep a good control. If you let your engine fail 2% of the time, then your game will be crashing 10% of the time, and will have bugs 60% of the time. Many naive game developers, like you, have though that "games have bugs all the time and it's ok" and then have to waste [a lot of time refactoring and adding the tests you should have had from the beggining](http://www.sauropodstudio.com/dev-diary-seventy-three-if-at-first-you-dont-succeed-test-test-again/). This shouldn't be a problem if you are using an existing library, and if you want to prototype a game and see how it works, use an existing library, even WoW used the [Warcraft 3 engine at first](http://i.imgur.com/Q6YTWyG.jpg). The advantage is that you don't need to care about being hacky or strict with a prototype proof-of-concept game which you have to throw away when you change it for a "real engine". So with both things above. In game development, you might use high-level languages for the things that are not critical (where you want freedom to iterate quickly) and for low-level things you'll be using a very strict subset of C++, which would be the equivalent effort of Rust except you can break the rules without no one ever knowing about it (even you). OTOH if you are doing this game for some reason other than fun (and learning Rust) *don't use Rust*. Learning a new language on a project with any stake, even if it's your ego, is not worth it. Stick to what you know.
It's a response against the previous example, a better take might be Use Rust -&gt; Make Compiler Happy --------&gt; Runs -&gt; Crashes -&gt; Debug -&gt; Works Use C -&gt; Make Compiler Happy -&gt; Runs -&gt; Crashes -&gt; Debug -&gt; New Crash -&gt; (repeat a lot) ... -&gt; Works
In general, I find Rust upgrades require very little Servo domain knowledge. Once in a while you may need to talk with someone referenced from `git blame`, but generally it's a great way to tour various parts of the code for the first time. We would welcome any volunteers for this task with open arms :)
Left as an exercise for the reader.
Remember that implicit returns are optional. You can write explicit returns if you want. But as /u/The_Doculope mentions, implicit returns make single-line lambdas much cleaner. I suspect variadic generics will happen eventually. But that's a big, potentially very complicated feature, that'd probably be hard to get wrong, so I think it's reasonable to push it out from 1.0. I find the macro system in Rust to be pretty amazing for meta-programming. It does have some short-comings, but it certainly beats the crap out of C++'s macros and TMP. But, I'm not familiar with the alternatives that D offers for this. HKTs look interesting. I had to look up what that referred to, and one of the first links I found was this: http://www.hydrocodedesign.com/2014/04/02/higher-kinded-types/ . Surprisingly, it's talking about HKTs specifically in the context of Rust, and the author even mentions filing and RFC to add HKTs to Rust.
This is correct.
Ahh that makes sense. Awesome, thanks!
None, really. The whole upgrade might not be possible, but chipping in is quite easy. If you want to help upgrade the dependencies you can do so quite easily now via `multirust`. We're upgrading to [this](http://servo-rust.s3.amazonaws.com/00b112c45a604fa6f4b59af2a40c9deeadfdb7c6/rustc-1.0.0-dev-i686-unknown-linux-gnu.tar.gz) snapshot. You can install [multirust](https://github.com/brson/multirust) and add the linked tar file as [a custom toolchain](https://github.com/brson/multirust#custom-toolchains) and upgrade deps individually. Or you can just clone Servo, update the snapshot hash, and start fixing the errors that turn up, but sometimes it gets quite noisy and hard to handle.
There's a general principle I've observed over my years as a programmer working in many different languages: **The stricter a language is, the more you front-load the complexity of development.** This means that, when working in a very strict language, it will be very hard at the beginning and get easier as you go. When working in a very loose language, it will be very easy at the beginning, and get harder as the system grows. C++ is a medium-strictness language. It enforces most type-safety, but still has some implicit conversion. However, it has few memory safety guarantees. (I say "few" instead of "none" because if you primarily use std::shared_ptr&lt;&gt; and references, instead of raw pointers, you can avoid some memory safety problems.) Rust is a very strict language. So if your objective is to get from nothing to something as quick as possible, you'll have an easier time with C++. If you're winning to suffer from a lot of initial difficulty as you're starting out, in exchange for an easier time later in the process, you're probably be better with Rust. **Edit:** This is ignoring issues of tools and libraries. Of course C++ currently has a substantial edge in that area. But that's not intrinsic to the language, and will hopefully become less true in time.
bikeshed? bikeshedding is talking about the color of the bikeshed. this is about the decision of placing the bikeshed’s entrance facing the main building’s wall, with no path leading to it (and maybe some stairs leading up to it)
Something that caught me recently: `as_mut_slice`. I thought there had been a move to having `mut` at the end, so was reaching for `as_slice_mut`...
I didn't mean it for result time, sorry. Something more like "This function as" or "this object as", rather than interpreting that for result type. Regardless, how you read it in your head doesn't change the possible syntactical advantages. Especially since :: almost always means namespace - so to use it to denote generic type is a little odd to me.
A bikeshed is an extended discussion of an inconsequential or subjective element. Complaining that the size and shape of the &lt;&gt; makes it hard for you to visually parse is the very definition of subjective. I certainly don't find them hard to visually parse. I'm concerned with the consistency and ambiguity of the syntax. The consistency issue is still a bit of a bikeshed, but a lesser one (most people agree that consistency is good, and it's just a question of how to achieve it). The ambiguity is a real issue.
Don't mention leap seconds, I am already dreading June 31st...
[That is one cool parser](https://github.com/servo/rust-cssparser/pull/68)!
From [the documentation](http://doc.rust-lang.org/num/num/rational/struct.Ratio.html) it appears there are several ways to convert other numbers into ratios. You can use the `new(numer: T, denom: T)` function to create a new Ratio. I'm a bit hazy on the specifics of generic instantiation, but I think you would call it with something along the lines of `num::rational::Ratio::new::(1u32, 3u32)`. You can also cut down the path for the function using a `use` declaration. There are also `from_integer(t: T)` and `from_float&lt;T: Float&gt;(f: T)` functions to convert from ordinary integers and floats to rational numbers. For example, the following code extern crate num; use num::rational::Ratio; fn main() { let rat1 = Ratio::new(1u32, 3u32); let rat2 = Ratio::from_float(1.33).unwrap(); let rat3 = Ratio::from_integer(3); println!("Ratios: {}, {}, {}", rat1, rat2, rat3); } Produces: `Ratios: 1/3, 748723438050345/562949953421312, 3` On my machine. edit: messed around with syntax formatting
As /u/lookmeat says, I'm not trying to argue anything. Just adding a disclaimer to the parent comment. I've seen how much crap the Haskell community gets for "if it compiles it runs", and I'd very much like to avoid Rust getting crap for "runs without crashing". I know that it's true, because in the Rust ecosystem "crash" has a very specific term, but to most everyone else a panic counts as a crash, and that statement looks like a lie at best.
This is counter acted *sometimes* by increased revenue from shorter time to market. You can be rewarded more for shipping something half broken faster than something 100% working slower.
You missed what actually happens in many cases. Use C -&gt; Make Compiler Happy -&gt; Runs -&gt; Corrupt data -&gt; Debug -&gt; (repeat) .... 
What does that have to do with what I'm talking about? That poorly pre-planned code required a self-exploit in order to make it patchable? That's a cludge. I'd rather have stable software than software that has to be exploited by the **developers themselves** to fix it.
&gt; wrong, i explained objective reasons regarding height and elevation. they have those attributes, and those attributes objectively make them not frame the text they’re supposed to enclose. braces extending below the baseline and above the cap height make them visually frame their enclosed text. objectively. No, you explained objective truths about the symbols, and then applied a subjective feeling based on those truths. Everything you say about the shape of the symbols is objective. The idea that these things make them harder to read as braces is a subjective opinion. &gt;&gt; I certainly don't find them hard to visually parse &gt; that’s subjective: you talk about your peception, shaped by familiarity. Yes, it is. That was the point. I stated that in order to illustrate the subjectivity of you finding it difficult to parse. If "I find it easy to visually parse" is subjective, then "I find it hard to visually parse" is also subjective. &gt; sigh. do i have to rephrase in which ways all those characters already have several ambiguous meanings? decrementing the number of ambiguities of one and incrementing the one of another makes no difference at all. No, you don't, because that's the exact point *I* was making just a few posts previous. In the broader discussion here, there are three points being made about the use of `&lt;&gt;` for generics: consistency, ambiguity and readability. I mentioned them all in order to point out how much of a bikeshed each of those discussions is.
Right. So let me try. From what you wrote I would assume the following type `F` would only use references: type F&lt;'r, A, B, C&gt; = Box&lt;Fn(&amp;'r A) -&gt; Result&lt;&amp;'r B, &amp;'r C&gt; + 'r&gt;; I can use `compose` as you defined it in your first version. Now `constant`: fn constant&lt;'r, A, B, C&gt;(x: &amp;'r B) -&gt; F&lt;'r, A, B, C&gt; { box move |&amp;: _| Ok(x) } Still compiles. Finally `choose`. As it needs to refer to something in its outer environment, I moved it inside `main`: fn main() { let z: String = format!("zero"); fn choose(x: &amp;i32) -&gt; Result&lt;&amp;i32, &amp;String&gt; { match *x { 0 =&gt; Err(&amp;z), _ =&gt; Ok(x), } } } This does not compile: test.rs:18:23: 18:24 error: can't capture dynamic environment in a fn item; use the || { ... } closure form instead test.rs:18 0 =&gt; Err(&amp;z), So, not to mention that I can not allocate and move out a return value inside `choose`, as this would change its type, I also can not use functions with `F`. If I would have an existing `choose` function of type `fn choose(x: i32) -&gt; Result&lt;i32, String&gt;;` I could not even use an adaptor closure to match `F`'s signature. In other words--I fail to see how using references could work out in practice and I suspect that it is not possible to combine closures and functions without making full copies of values. Please correct me if I am wrong. 
Alright, thank you very much! 
Really innovating with the cert error UX here.
Indeed it is. The fact that most communication is out on the open gives us an inkling of what goes in to making such a complex product.
[**@bcantrill**](https://twitter.com/bcantrill): &gt;[2015-01-13 23:24:56 UTC](https://twitter.com/bcantrill/status/555143487482368000) &gt;DTrace on Rust: [*gist.github.com*](https://gist.github.com/bcantrill/b7d031db6e35cfd79201) LX branded zones FTW! [#smartos](https://twitter.com/search?q=%23smartos) [#illumos](https://twitter.com/search?q=%23illumos) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2sc8hz%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
Brilliant. Is this an established procedure, or -- to your knowledge, of course -- a novel idea? 
I don't recall seeing it before. I was inspired by [this RFC section](https://github.com/rust-lang/rust/issues/15701#issuecomment-69849033), which proposes an audit date attribute.
UT1 is not really that precise (except in retrospective) or predictable (that's the whole reason UTC exists really), since it refers only to the position of earth relative to the sun, but this isn't always the same. Tidal acceleration gives a problem. Getting rid of leap seconds, and using leap hours would be an OK solution, I hope that by the time the leap hour is needed we'd have bigger problems with having to synchronize time over various planets and relativistic frames. I agree that any library needs to support UTC before TAI though, since people need to support UTC a lot more than TAI, I feel that database timestamps would be more predictable and useful in TAI format (really an epoch-like format that maps to TAI instead of UTC).
what's the catch here?
It and several other modules were moved [to external repos](https://github.com/rust-lang/num) to allow them to take advantage of Cargo and semantic versioning. This gives us greater flexibility to improve them (e.g. we can have `num 1.1` and `num 2.0` libraries both working with Rust 1.0), and means the 1.0 release of Rust doesn't have to wait for the functionality in those libraries to be moved into a state that we want to publish as (semi)stable. [`num` (and the other repos) are available on crates.io](https://crates.io/crates/num), so you can easily [use them](http://doc.crates.io/crates-io.html#using-crates.io-based-crates) via [Cargo](http://doc.crates.io/guide.html).
It's theoretically possible I think but I don't know how to talk to Google about it.
There's some study that shows that `snake_case` is easier to understand than CamelCase, but I don't remember its methodology. Regardless, for whatever reason it was, it is what it is. It's quite familliar to me, coming from Ruby.
Sorry, what I meant was changing the link on http://doc.rust-lang.org/tutorial.html to point to http://doc.rust-lang.org/book/README.html instead of http://doc.rust-lang.org/guide.html.
You don’t need to use `Box` to get fixed-size arrays. `&amp;` works too: fn encrypt(clear_text: &amp;[u8], key: &amp;[u8; 32], iv: &amp;[u8; 16]) -&gt; Result&lt;Vec&lt;u8&gt;, CryptoError&gt; Or you could even just use fixed-size arrays without any pointer type: fn encrypt(clear_text: &amp;[u8], key: [u8; 32], iv: [u8; 16]) -&gt; Result&lt;Vec&lt;u8&gt;, CryptoError&gt; However, fixed-size arrays are indeed hard to come by, even behind references (e.g., `&amp;[u8; 32]`). I suppose it’s up to the library designer (you) to decide whether statically checking the length (`[u8; 32]`) is more or less important than ergonomics (`&amp;[u8]`). If you are able to use fixed-size arrays most of the time when calling the function, I’d probably go with the fixed-size version (without `&amp;`), and manually copy slices into a fixed-size array if I didn’t already have a fixed-size array when calling the function: let x: &amp;[u8] = some_vec.as_slice(); if x.len() != 32 { return an Err or something } let y: &amp;[u8] = some_other_vec.as_slice(); if y.len() != 16 { return an Err or something } let a = [0; 32]; let b = [0; 16]; for (i, v) in x.iter().enumerate() { a[i] = v; } for (i, v) in y.iter().enumerate() { b[i] = v; } encrypt(clear_text, a, b); (There’s probably a simpler way of doing this.) If you can’t often get a fixed-size array, the approach with `&amp;[u8]` you had will work.
&gt; UT1 is not really that precise (except in retrospective) or predictable (that's the whole reason UTC exists really), since it refers only to the position of earth relative to the sun, but this isn't always the same. Yeah, the "precise timekeeping" really means that one knows what he/she actually refers. I'm not aware of any actual use case of UT1 or TT outside of the astronomy though. &gt; [...] I feel that database timestamps would be more predictable and useful in TAI format (really an epoch-like format that maps to TAI instead of UTC). First, there is a crucial problem with TAI in the computer: UTC is what the operating system gives today and UTC-TAI conversion naturally requires a table that cannot be predicted. (If the OS gives TAI instead, it would also have the conversion table readily available. But it's not.) Also, regarding the timestamp problem, I really blame the API designer here (*cough* POSIX *cough*). `time_t` is a non-linear scale that pretends to be a linear scale; in my opinion the correct way to represent a timestamp is `struct timespec`, which has separate fields for seconds and fractional seconds. Let fractional seconds store also a leap second (just like Chrono), then even though you don't have TAI, you can correctly sort the resulting "timestamp" in the lexicographic order.
We put into the head, `&lt;meta http-equiv="refresh" content="0; url=$REAL_URL" /&gt;` along with `&lt;link rel="canonical" href="$REAL_URL"&gt;` (I've just cargo-culted the latter, so I don't know if it's relevant/helpful) but that would possibly require extending rustdoc.
*learns Go*
kmc, run! It's clearly a roaming patent lawyer!
You could use [multirust](https://github.com/brson/multirust) to install an older version of rustc that includes the quotes, so you can switch back at will to try to) trigger them. :D
There should be a silly compiler flag to add weird Lovecraftian quotes. I propose it be called `-fhtagn` 
Unfortunately it's actually not (it's a complex struct). I have to use RefCell. :-/
Where would one learn how to make an emulator like this?
Git's signed commits are a form of source code signing, as is a simple GPG signature on a source tarball. What's (potentially) new here is the fine-grained integration with the language and compiler, thanks to the extensibility of both. That enables a different sort of use case. Instead of vouching for the quality / integrity / authenticity of the tree as a whole, we certify that specific sections of code have been checked in some way. Because Rust already tracks memory-unsafe code, we can get a high degree of assurance at a much lower cost than whole-project audits. Of course `unsafe` isn't the only kind of problematic code. I imagine extending this to include signed lint overrides, or signed access to sensitive data/APIs. It's important not to overstate how much benefit we can get from this approach. Bugs can result from extremely subtle interactions between many components of a system. Auditing functions one at a time won't provide the kind of big-picture understanding needed to identify such issues. Still, I think a lot of nasty bugs happen due to local mistakes where a particular line of code or a particular change just didn't get enough attention. (Or a particular comment, which is why I think it's important to sign those along with everything else.)
I guess I have to do so then :) And currently no, The current version of Chrono doesn't have a plan to support calendars than the (proleptic) Gregorian calendar, but it would be not hard to add them by extending `Timelike` or `Datelike` (possibly with Javaesque extensible field system).
So uh, what am I looking at here?
Also relevant: https://leanpub.com/leprechauns
It depends—you can very easily end up with things that get implemented many times, typically suboptimally (performance or functionality), rather than using an external crate; where if they were in the standard library people would rewrite them less frequently. Of course, you can’t do that for everything, and it’s all a balancing act.
Sure, but the inverse of that argument is equally damning. The standard library could be held back by the release cycle of the language, or by the opinions of the maintainers of the standard library. Potential maintainers of a 3rd party alternative would be dissuaded by the obscurity of a library that implements features the standard library already implements. I find that competition among libraries tends to be a good thing. Why bother improving the performance of the standard library's implementation if you have nothing common to compare it with? EDIT: I accidentally a word.
That was “spring 2014” (northern hemisphere—ah, this way of speaking seems so typical to northern hemispherians while being foreign to Australians at least), more than six months ago. Anyone know what has happened with it all since then?
Hi, i'm a student that took it then! UVA switches off professors for some classes, so it's been a regular C-based course since then. But that wasn't the first time Prof. Evans did the Rust one, and I'm sure it won't be the last :)
&gt; learns c++
&gt; ...but why would you ever blindly post to a subreddit you've never read before without checking what it's about? Am I just weird for thinking that's a horrendous idea? You can change the subreddit on http://www.reddit.com/r/anything/submit etc to whatever you want. Usually people have a submission but they're in the wrong subreddit, and they change it without having been there first.
Many would argue any of these conventions are not for typing, but for reading. Even though the name Rust came from the Fungus, I like to believe that it means that this language was made for legacy code, where reading is more important than writing. In my beliefs, that means explicit over implicit, and higher quality over higher quantity. I agree, it is easier to type camelCase, its just a pink-on-shift-button away, but for the sake of better code, I will most assuredly type an underscore more often.
Note that Nim's release builds disable bounds checking. Compile with --boundChecks:on for a fairer comparison.
Ah. I've had the oppposite experience, oddly enough, on our decades-old legacy code. I find the snake_case names too unwieldy to keep track of sometimes. They're not always as descriptive as they could be, too - but that's a result of #define'd types so you end up with shit like COUNT as a type, instead of naming the variable as count -_-. Some day I'll name a variable as a duke though. That'll be the day.
A minor spelling nitpicking: in paragraph 2 of section Philosophy, it should be idiomatic not idiometic.
I'm not the author, I just found a cool link :) 
It would be great to have a follow-up article on Nim as it has several language features from both Rust and D.
TLDR: D's metaprogramming blows Rust's out of the water. For some context: D's metaprogramming abilities revolve around two primary mechanisms: string mixins + CTFE, and compile time type reflection. String mixins basically let you feed a compile-time constant string value into `mixin(S)`, which injects the string into the source text at that position. In practice, it's pretty much what Rust macros let you do: it doesn't allow for "partial" constructs like C macros do. The actual strings themselves are often constructed using CTFE. There's enough power there to do things like write string parsing state machines, so you can use it to implement a DSL. This actually makes the parsing strictly more powerful than Rust macros, but much harder to use for things covered by MBE in Rust: where in Rust you can just match an expression, in D you'd have to actually *write* the logic for parsing an expression. That said, the last time I needed to do this, I just cheated and did what Rust does for macro invocations: lexed string literals and counted nested matchers, then hoped the result was valid. :P Compile time type reflection is where the serious voodoo happens. Off the top of my head (this is unlikely to be comprehensive), you can do the following at compile time, within the language, anywhere: * Turn a type back into the string used to name it. * Get a tuple† of struct/class members and fields. * Get a tuple† of function arguments. * Use `foreach` on tuples, which works by statically unrolling the loop. * Deconstruct types: is it a pointer, what's the pointee, how big is it, what's the alignment, does it implement a given interface, etc. etc. * Feed any of the above into a CTFE function for more complex processing. * Use `static if` to statically branch based on any of the above, which allows you to eliminate syntactically valid but semantically invalid bits of code. The practical upshot of this is that things like the current serialisation support in Rust can be pretty trivially written as a library, without needing `#[derive]` support. Critically, you can do it for types that don't explicitly support it. This was *huge* for a project I wrote in D which let me automatically generate binary, XML and SQL serialisation code for arbitrary types. I'd *love* to see Rust gain the same abilities, but I can think of a few problems: * I'm not sure how it'd play with type inference. * They'd probably be implemented as plugins like procedural macros. Defining a stable API for that is going to be hard enough, but this would also need access to type information. Euch. So yeah... I'd love to see Rust match D in this, but I'm not going to be holding my breath. &gt; †: D actually has a really wonky, very loosely defined notion of tuples. Normally, they're explained as being a heterogenous fixed-sized sequence of values *or* a sequence of types, but there's also bizzaro tuples where each "type" element *also* carries invisible extra information like the name of a member/argument, storage qualifiers, etc. This information is completely invisible... unless you turn the "type" back into a string, at which point it magically re-appears. I once wrote some Lua bindings that were generated by taking these bizzaro tuples, turning them into strings, then re-parsing the result. Yeeeah.
I thought something along the lines of [this](https://gist.github.com/Ygg01/6d1bd08b8e12460da9fc) could work, I think. You could convert any possible calendar into nano/millisecond offsets from your starting date. Instant is the UTC that starts on `1970-01-01`(or whatever you have). Then through calendar you define operations so someone can't take Mayan months and add them to Gregorian months, etc. 
A threshold signature scheme (where you get k of n developers, but it can be any k within n) would be cool too. In IRC I suggested hashing the contents of each unsafe section of code in a particular file, then signing the "Merkle root", i.e. concatenate all of the digests of all of the unsafe portions of the code together, then sign the result. Several people can sign the same Merkle root, and then you'd only need one signature per-person per-file. You could potentially even have different owners on a file-by-file basis.
Markus Kuhn has proposed [UTC-SLS](http://www.cl.cam.ac.uk/~mgk25/time/utc-sls/) which almost works like Google's solution. If I get `TAI` working in the future, I would certainly also work on that too.
Yes, "Javaesque extensible field system" above refers to that kind of design.
Here's some tutorial-like blogs that are fairly easy to follow: http://imrannazar.com/GameBoy-Emulation-in-JavaScript http://www.codeslinger.co.uk/pages/projects/gameboy/beginning.html Please note that the code in both blogs use the simple inaccurate cycle counting model described in my blog post. But you can definitely get started with such a model, and improve the accuracy later! # Documentation Pan docs is a very old but good document about many hardware details: http://problemkaputt.de/pandocs.htm GBCPUman has some errors, but has some stuff not included in Pan docs: http://www.romhacking.net/documents/396/ GB crib sheet is a very tightly packed useful reference: http://www.romhacking.net/documents/285/ Nintendo's official programming manual is also good: http://www.romhacking.net/documents/544/ # Advanced documentation / tests Once you have CPU emulation in place, try to pass Blargg's tests (at least cpu_instrs): http://slack.net/~ant/old/gb-tests/ I've got answers to random in-depth questions here: https://github.com/Gekkio/mooneye-gb/blob/master/docs/accuracy.markdown Feel free to try my test roms as well (needs wla-dx assembler): https://github.com/Gekkio/mooneye-gb/tree/master/tests # Good reference emulators Gambatte is the most accurate Gameboy emulator, but the code might be difficult to follow: https://github.com/sinamas/gambatte Gameboy Online is fairly good, but uses a lot of tricks to make things fast: https://github.com/grantgalitz/GameBoy-Online BGB is fairly accurate, but sources are not available. Good emulator for comparisons, though: http://bgb.bircd.org/
Please see my comment here for some helpful links: http://www.reddit.com/r/rust/comments/2saqdh/mooneye_gb_a_gameboy_emulator_written_in_rust/cnohzt4 If you've never written emulators before, it might also be a good idea to first read about emulation in general. Or maybe start with Chip8 as an educational exercise? http://www.multigesture.net/articles/how-to-write-an-emulator-chip-8-interpreter/
&gt; choose doesn't have to refer to its environment. Given the definitions above I don't see how. It can not create a box or other value internally and return a reference to it as the lifetime would be too short. So how would that work? That leaves `'static` and I would argue that `'static` is an environment too. Maybe `rustc` does not think so, but only being able to refer to static items would anyway be severe limitation. &gt; relax the restriction that the Err part be a reference But then I would be back to requiring copies as I said above. &gt; You could probably drop the references from F, make the type arguments Copy again, and just instantiate the type arguments as references where they're used (references are Copy). The fact remains that this would require full value copies unless functions like `choose` refer to `'static` items.
The previous discussion posted with the older temporary URL: http://www.reddit.com/r/rust/comments/1v7hqb/the_periodic_table_of_rust_types/ I was so lazy that I kept to forget updating the table. Now we have a hopefully stable language (for the purpose of the Periodic Table), so this is what we finally have.
got it, thanks!
Okay, that works. Thank you very much. Hopefully there will come a better solution, `range_step` is way more easier to understand when reading that line.
 let (mut x, mut y): (i32, f32) = (10, 11.0);
`let` expects a pattern plus an optional type, so the following would work. let (mut x, mut y): (i32, i32) = (10, 11.0); I don't know about daily newbie threads in other subreddits, but it seems that [StackOverflow](http://stackoverflow.com/questions/tagged/rust) is used as a Q&amp;A venue. SO seems to be a bit inaccessible place for Rust users though (including me :), so such threads might be useful.
I thought an owned raw pointer is [`Unique&lt;T&gt;`](http://doc.rust-lang.org/std/ptr/struct.Unique.html).
Speaking of suboptimal, `num` is much worse in performance and features compared to binding to gmp.
Off topic: That layout is impressive.
Fixed. I’m not a native English speaker and such correction is much appreciated.
I’ve added --boundChecks:on for example 2. The difference is marginal (1~2%) for example 1, so I skipped it.
I didn't perform any profiling but your suggestion is probably spot-on.
In my opinion it’s going to be a tough balancing act between conciseness and faithfulness. Giving each trait its own row seems boring to me, e.g.: |Immutable pointer|Mutable Pointer|Owned Pointer|Bare|Unsized --|--|--|--|--|-- `Fn`|`&amp;Fn(A) -&gt; B`|`&amp;mut Fn(A) -&gt; B`|`Box&lt;Fn(A) -&gt; B&gt;`|`T`|`Fn(A) -&gt; B` `FnMut`|N/A^1|`&amp;mut FnMut(A) -&gt; B`|`Box&lt;FnMut(A) -&gt; B&gt;`|`T`|`FnMut(A) -&gt; B` `FnOnce`†|N/A|N/A|N/A|`T`|`FnOnce(A) -&gt; B` 1: can exist, but cannot be called †: there can be no `FnOnce` trait object because it is not an object-safe trait Which I hope demonstrates how painfully verbose this all is, and how redundant it is with the `Trait` row. I also think that the N/A cases are more distracting than interesting. I’d be in favour of getting rid of the row altogether, until a truly useful presentation comes up. In the meantime it can be mentioned they are traits and thus follow the same rules. I don’t know where `fn` would fit. 
Are the probes part of the default rust? Are they compatible with Linux (systemtap) user space probes? (Offers a similar API)
Oops, you are tremendously correct for both. (I wanted to update quickly in order to faciliate the discussion on [#16960](https://github.com/rust-lang/rust/issues/16960), so I completely missed reviewing them.) I've updated the table to the up-to-date (i.e. Rusticon-based) terminology and added a note that library types are representative only. Thank you so much.
The rust version panics (in libcore) when I call it with some random php code files: thread '&lt;main&gt;' panicked at 'called `Result::unwrap()` on an `Err` value: IoError { kind: InvalidInput, desc: "invalid input", detail: None }', /Users/rustbuild/src/rust-buildbot/slave/nightly-dist-rustc-mac/build/src/libcore/result.rs:746
Feedback on how I might improve my coding style is requested! I kinda feel like I'm not writing idiomatic rust, but I'm not quite sure what that is, or how I might go about doing so. I'm on slightly better terms with the borrow checker now, but still a lot of learning to do.
Yes, I share that concern too. There is a discussion on the table itself ([#16960](https://github.com/rust-lang/rust/issues/16960)), and actually I clearly mentioned that "the table may possibly discourage new users without further tweaks" there. I'm always willing to update or remove the table if it seems to create more harm than good; please join the discussion if you think so.
It was /u/glaebhoerl's version for the then-experimental design of unboxed closures. The current periodic table contains all relevant traits for the finished design.
This is still not enough and commonly used, e.g. in `Vec` from `libstd`. Any access of `.length` should be unsafe, however that can't be checked globally, and any function in that module has the option of changing that member – so this cannot be used for data structures, only for simple functions with completely-contained unsafe blocks.
I really like this idea, building a web of trust for code. Something that often comes up whenever there is some security vulnerability is "how do you know you can trust this code? sure it's open source and used by thousands of people, and you can verify it yourself, but how many people actually do that? how do we know *anyone* has checked the code?". Having a web of trust for code review (even if just for unsafe blocks) would be a really powerful tool here.
Yeah, that's unfortunate. If you are interested on how this is being worked on, take a look at the [String handling section of the `io`/`os` reform RFC](https://github.com/aturon/rfcs/blob/io-string-handling/text/0517-io-os-reform.md#string-handling) ([discussion](https://github.com/rust-lang/rfcs/pull/575))
wait, nvm, I missed the entries for bare traits and strs
Cool, I life in Berlin and I am on board, but my english is very bad, sorry for that. 
Interesting - perhaps it should be possible to mark members as unsafe and only allow them to be mutated in an unsafe block.
We're open to any language we can somehow provide support in :). There are different people from meeting to meeting, so just ask whether there is someone speaking your language and we will get you in contact.
Yup, the real problem is that there is often very little motivation to go back and do the correct solution to the half broken product. Once it hits the market, often the only changes that are wanted are hack and patch sorts of fixes. Changing over to doing things "the right way" is a complex and daunting task. The worst part, we will invest millions of man hours hacking and patching a broken solution to a state that kind of sort of works. Right to the point where the code is unreadable, unmaintainable, but generally doing 90% of things right. At that point, going back and doing "the right thing" is often deemed as an unnecessary expense. I don't know the solution here, I'm currently battling it in my own company. We don't plan on ever going back and doing things "the right way" even though we know that the current route is going to be and expensive mess. The problem is "the right way" has a high upfront cost.
You keep submitting these kinds of videos to the wrong subreddit. You should submit them to a place like /r/playrust. Do you speak English? Вы говорите по-английски?
On the other hand static analyzers find whole classes of errors that the Rust compiler doesn't find.
&gt; We now have less of a runtime than C++ Could you elaborate on the differences?
&lt;3
&gt; Personally, I feel that if a moderator makes a lot of questionable decisions then their time SHOULD be wasted. Immature jerks who *should* have been banned will far, far outnumber unjustified bans, and its the immature jerks who are *more* likely to make a fuss in the forum. Ultimately your argument seems to start from an assumption that the mod structure is incapable of policing itself. But if that were true, then the community is probably doomed no matter what the policy is, and discussion will naturally move somewhere else!
`'static` is not considered part of the environment the same way closure variables are, so you can refer to e.g. string literals, like your example does, or other globals. Using something like a `String` or a `Box` would also not be a value copy, as it does a move. You could even use something like the old `MaybeOwned` (an ADT with a borrowed case and an owned case) to allow both. If you don't like `MaybeOwned`, you could use `Rc` for reference counting, which also doesn't copy the value. In the future the `Gc` type might even come back and let you do normal garbage collection. There are plenty of ways to avoid full value copies, they just involve tradeoffs with how you manage memory.
There's [libprobe](https://github.com/cuviper/rust-libprobe), which adds a `probe!` macro for SystemTap support. It was [submited for inclusion](https://github.com/rust-lang/rust/pull/14031) on the standard library, but wasn't accepted at that point.
&gt; Using something like a String or a Box would also not be a value copy, as it does a move. How can it move it the return value is `Result&lt;&amp;'r B, &amp;'r C&gt;`? If it would be instead `Result&lt;B, C&gt;` `constant` becomes incompatible because it either causes `cannot move out of captured outer variable in an 'Fn' closure` or `cannot move out of borrowed content`. &gt; There are plenty of ways to avoid full value copies, they just involve tradeoffs with how you manage memory. Well, so far no one came up with at least _one_ way to implement the Haskell version. If you think `MaybeOwned` or `Rc` is necessary for that, fine, but show me a solution that retains a similar level of generality and composability as the Haskell version without requiring full value copies.
This would work: let mut ret = String::new(); { use serialize::Encodable; // required for `encode` method below use serialize::json::PrettyEncoder; let mut encoder = PrettyEncoder::new(&amp;mut ret); let _ = value.encode(&amp;mut encoder); } ret (Just to be sure, the built-in `serialize` crate is being replaced by the [`rustc-serialize`](https://crates.io/crates/rustc-serialize) external crate split from the rustc. See [here](http://doc.crates.io/crates-io.html) for using crates.io dependencies in Cargo.)
thanks!
"Fixed sized storage is impractical for the variable length UTF-8 encoding." Uh? What if I know the string at compile time?
&gt; So that's 3 ways- Rc, String/Box for everything (of a particular case), or MaybeOwned for everything. Talk is cheap--show me the code :wink:
&gt; I can't wait for game development companies to start embracing Rust for these very reasons. &gt; But we'll need some solid IDEs before that takes off in any degree of seriousness. Its also unlikely that established companies would throw away their existing assets &amp; experience. There will be a chicken egg situation. a rewrite can be the death of an organisation. Perhaps we can get more of rust's ideas retrofitted to C++ (or a c++ fork?)
`Use C -&gt; Make Compiler Happy -&gt; Runs -&gt; Crashes -&gt; Debug -&gt; (repeat) ....` `Use Rust -&gt; wait for language to mature ------------------&gt; Make Compiler Happy ------------&gt; Runs without Crashing` :)
mb I know why...I use sublime text with a my build system, and I have error in it all work, thank again!
Yes, using `regex!` runs ~20% faster than `Regex::new`. I’ve included both results in the article.
Yes, `LinkedList` should be sufficient; and `SinglyLinkedList` if it ever comes to be is perfectly fine with a longer name since once you've paid the cost of an allocation for each and every node it seems a bit silly to try and spare the one pointer of the backlink...
Right, and I would welcome a DTrace implementation of `probe!` if anyone would like to contribute! [issue](https://github.com/cuviper/rust-libprobe/issues/3) But bcantrill hasn't built any probes into rust - this is just the regular function provider in action. SystemTap can do the same using debuginfo and/or symbol tables to locate functions. [para-callgraph.stp](https://sourceware.org/systemtap/examples/#general/para-callgraph.stp) is a good example, used like: stap para-callgraph.stp 'process.function("*")' -c ./hello
Surely haskell uses a lot of allocation calls and destructors outside of the IO monad though, so I guess this is the first level (simplest way) to wrap this, but another pure API must be possible.
https://github.com/phildawes/racer
BorrowFrom is largely intended for coercing a known type to a given type. That is, if I store Strings in my map, BorrowFrom knows how to coerce a *specific* type (String) into the *given* type (&amp;str or &amp;String). In your code, you want to coerce the *given* type to a *specific* type -- basically backwards. This is what Deref is good at. I believe if you take `S: Deref&lt;Target=str&gt;`, the you should be able to do `str_val: &amp;str = s.deref();` Edit: our conventions here aren't clear though, I'm sure some members of the community would consider this an abuse of Deref, and would suggest introducing a custom Loggable trait that you impl for String and str.
Yeah, feel free to spread the information. Writing emulators is a lot of fun, so I'm glad if I can help others get inspired.
Just wanted to point out that SystemTap is just as capable on Rust as [DTrace](https://www.reddit.com/r/rust/comments/2sc8hz/dtrace_on_rust/) for simple function tracing. :) Also [tweeted](https://twitter.com/CUViper/status/555443501404401667) if you care...
&gt; Fixed sized storage is impractical for the variable length UTF-8 encoding. But not for string literals, that have a length determined at compile time - couldn't they be sized? (I guess that they *could*, but string functions normally work with slices to support both literals and views on `String`)
I would say abbreviation is fine for keywords and "one word" types (Vec is fine for me) but it brings weird when you have "multiple word" types IMHO.
Nice. This type of thing will continue to be a useful resource since there will be breaking changes in unstable features and (I assume) we will continue reporting them.
Python seems to do left-sided add also, but they have the special \_\_radd__ for right sided addition. Pythons \_\_special\_ops__ arent documented amazingly, but I found [this SO post](http://stackoverflow.com/a/5082229/1294262). Python falls back to \_\_radd__ happens when \_\_add__ doesnt work. edit: damn, how did that `'` get there -_-
Why is it called FnOnce instead of FnBox?
I think one should sign a pair (R, A) where R is a bound on the Rust version (something like greater than 1.1, smaller than 2.0) and A is a stable version of the AST. This means that changing whitespace doesn't invalidate the signature, but changing the Rust version in a breaking way should invalidate it.
I guess my testfile did not made such a big difference then.
This would be a good fit for languages that already integrate a theorem prover (like ATS), but for Rust one would need to actually add a theorem prover. A necessary first step is to provide a formal definition of Rust (like, say, the CompCert team produced a formal definition of [some subset of C](http://compcert.inria.fr/compcert-C.html#subset), in Coq).
Could you please elaborate on the inaccessibility of SO for Rust users? We're doing our best to answer questions there quickly and thoroughly. According to my observations, answers usually come in an hour at max, usually much faster.
Thanks, not going to use this immediately but looks useful.
I know, but that doesn't work with `file://` and I was lazy ;)
sounds interesting, any links? When I was messing with this I was sticking to a rust-like syntax (not exactly but I might want to try and implement an actual subset of rust) , so I wanted to take advantage of the fact &lt;T&gt; is part of a separate type context; of course there's the issue what will happen when one wants to put values in there (integer literals, expressions).. I haven't looked into what will happen there. I can see that having one grammar everywhere could be rather nice. here's my experiment, it does currently allow [T] aswell but only in the separate type context, it's ::&lt;T&gt; otherwise, and I'll probably go the route of sticking to using []'s syntax sugar for collections. https://github.com/dobkeratops/compiler
If it's between that and RemProxy&lt;ConcurDict&lt;str,HashSet&lt;int&gt;&gt;&gt; I'd choose the former anyway. 
I'd suggest `fn log&lt;S: Str&gt;(s: &amp;S)`, or even `fn log&lt;S: Str&gt;(s: S)` and then calling `s.as_slice()`. Though a custom `Loggable` trait would be sensible to allow logging other types in the long run.
&gt; I was under the impression that Rust traits are basically equivalent to Haskell typeclasses. Ahhh, but the 'basically' will lead you astray there. They're similar, but not the same... You cannot implement a trait you don't define for a type you don't define.
Oh, your version is a lot nicer!
I should probably note that http://bitrust.octarineparrot.com/ is minimal by design. No frills, just ctrl+f for the thing that broke. I was originally just going to make it a text file, but I wasn't sure (and am still not) if Github pages would allow that, or whether it would do that annoying forced-download thing.
Yep, I can't think of a reason to do that in normal use. I was just trying to show the closure fall out of scope and release myvar.
I think this might be entirely subjective (and as I've tested later, some of my feeling was indeed unfounded) but I feel /r/rust is *the* venue for communication including Q&amp;A. That is, people likes to hang more on Reddit than SO or Discourse. (This also explains why IRC *still* attracts so many people, though IRC is relatively obscure medium.) Hence the difference in the number of people can answer to questions, though my test shows it is not that bad than I first thought. Back to some months ago I *finally* recovered my SO account (thank you, OpenID) and tried to answer Rust answers. My initial observation was there are only a small number of people (Shepmaster, dbaupp and Chris Morgan I think) answering questions. Fast forward to today, I took recent 30 questions and see if the distribution has changed. This resulted in 19 unique persons among 36 answers, with dbaupp, Shepmaster and Francis Gagné being the top 3. I can safely (and gladly) conclude that SO now attracts enough persons to answer.
`python -m SimpleHTTPServer` works too.
Even better. :)
I agree. Until 10 seconds ago I had no idea what a DList was.
I want to like Nim, but I wish it was a lot more like python that I thought it was going to. Particularly the way user defined classes work. and the = at the end of proc definitions. and the name proc.
I consider this to be a special-case hack. Method lookup in Python is very limited because it has to happen at runtime quickly. There is not much the Python interpreter can do except “ask” both objects involved about what to do starting with the left-hand side. In a statically-compiled language like Rust I expect a better and more general solution that works for other things as well. Coming from C++, I have to confess that I don't really understand what actual problem the Rust devs are trying to solve with these “coherence” rules. I've never had any issue in that department with C++. The C++ compiler just picks the “best” implementation via various overloading rules, preferring “more specialized” impls over “more general ones” while ambiguities will end in an error message. It just works. Sure, there are some things that you are not supposed to do (resulting in undefined behaviour) but, as I said, I never had any issues with that.
But DTrace is *so much more* than just simple function tracing (;
its' possible to design systems without inheritance by dividing objects into components, and storing those in homogeneous collections (related by an id, or an object that references its' components..). Inheritance can be intuitive to use but if you can work without vtables, its' often more performant (i-cache) I think they are planning on increasing rusts' support for c++ style internal vtables &amp; inheritance though for servo? (last I heard that emulated it, but I haven't been following lately)
Nim has a lot that I like (overloading+UFCS and `do` as rust used to have it,..), shame its' GC (although their claim that they have realtime control over it is rather intriguing.. e.g. run the GC for a predictable timeslice). I am heavily biased toward C++/Rust's approach to memory. I could probably live with whitespace, but I do prefer braces. (which make even more sense with code being *expressions*, I'll have to remember that for arguments on the subject..) rust remains more interesting to me
Oh, stap does much more too, of course. Maybe I worded that strangely...
You can provide default methods for ThingRecord, use free functions, use `Deref`, use macros, etc. in order to share code. I think the perceived lack of elegance is more about familiarity with inheritance than anything else, as your solution doesn't seem inelegant to me.
by using composition over inheritance, maybe enum MonsterAttribute { Arrows(u16), Fireballs(u16) } struct Monster { thing_record: ThingRecord, attributes: MonsterAttribute } or struct Monster { thing_record: ThingRecord, attributes: Vec&lt;MonsterAttribute&gt; } then you can add many of those? ps int is dead in Rust
Or you might want to ditch the whole concept of inheritance and use something called component entity systems. http://t-machine.org/index.php/2007/09/03/entity-systems-are-the-future-of-mmog-development-part-1/ The technique has its flaws, chief being relative lack of writings on the subject and conflicting (and often incomplete) implementations. Nevertheless, it is way more flexible for game development than any tangled hierarchy of classes.
I think you can do enum MonsterSomething { Monster1, Monster2 } fn somefunction(monster: MonsterSomething) -&gt; MonsterSomething I *THINK* that works. I have only been glancing at Rust and can't check right now. (Someone correct me or confirm if you have the time ;))
The problem is Rust isn't expressive enough (yet) to allow implementers to write both `index(&amp;self, Idx) -&gt; Result` and `index(&amp;'a self, Idx) -&gt; &amp;'a Result` using the same function. So they had to choose for now which one to support, and they went with the reference-returning version because it's more commonly needed (vecs, etc.).
Particularly bad if the type can't even fit on the stack. (For example [u8; 1024\*1024\*30])
Yes, activity on SO really went up in the last few months. You can find `rust` tag statistics [here](http://stackoverflow.com/tags/rust/topusers), if you're interested. Most of the 1300 questions were generated in the last six months or so, and I think we're keeping a decent answer rate as well :)
If I understand it correctly this is disallowed because it could lead to ambiguity problems at link time. IMHO this is a quite severe limitation of Rust and will reduce modularisability of Rust code (and thus prevent potential code reuse). It seems the root of the problem is that trait implementations are not named first class entities in Rust. In Scala the problem doesn't exist as implicit values are scoped and named so you can choose to import a specific one, and the implicit search follows the normal scoping rules.
You could also go the other way around, which is still not as elegant as inheritance, but anyway: trait Monster { fn attack(&amp;mut self, t: &amp;mut Thing); } struct Thing { x : int, y : int m: Box&lt;Monster+'static&gt; } impl Monster for Monster1 { fn attack(&amp;mut self, t: &amp;mut Thing) { /* ... */ } } impl Monster for Monster2 { fn attack(&amp;mut self, t: &amp;mut Thing) { /* ... */ } } impl Thing { fn attack(&amp;mut self) { m.attack(&amp;mut self) } } 
On the other hand, algebraic types, pattern matching, traits are similar to type classes, memory safety by default, type deduction. At least Haskell is closer to Rust than to C.
&gt; OOP without vehicle examples is like FP without the Fibonacci sequence. https://github.com/kmcallister/dynamodule/blob/master/tests/vehicle.rs#L8 Hehe.
Thanks -- to be honest, I've never really thought closely about the orphan instance problem in Haskell, either. You've changed my opinion -- the current policy implemented by Rust is not overly restrictive. The real problem, I think, is simply that the `String` trait is not implemented for tuples, but it should be. I've opened [an issue on GitHub](https://github.com/rust-lang/rust/issues/21189) to that effect.
There's some discussion about leveraging these restrictions in a more foundational way, see https://github.com/rust-lang/rfcs/issues/493
Ok, fair enough. So, say I have the following project layout: project/ src/ lib.rs tests/ plugin_tests.rs So in `tests/plugin_tests.rs` I should use: #[plugin] extern crate my_lib Is that right?
If you don't mind using a GC then Scala is pretty close syntactically and feature-wise, but with a more advanced type system for functional programming. In terms of quick prototyping the Scala REPL and IDEs (with worksheet and hot code replacement) are very nice. The Scala compiler itself is not as fast as the Java compiler though. If you don't restrict yourself to C/Java-like syntax (and why should you?), you have Nim, and if you want to dig deeper into functional programming Haskell, Idris etc. If you want C-like syntax and no GC, modern C++14 is not a bad option (but maybe not suitable for fast prototyping, and the type system is not so nice).
Haskell in do-notation. No, in all honesty, I would also "recommend" Scala. It's the closes to the requirements you listed.
maybe i should check out Scala... I know a bit of Haskell, but im still not completely comfortable with Pure Functional Programming, havent heard of Idris though
I don't think it's that easy. Type/borrow checking of generic code that would use this more general index trait would be something in betwen hard and impossible before monomorphization because at that time the compiler does not know whether the `Output` type should be considered a “loan” (w.r.t. lifetimes) or not. Also, the way you introduce a lifetime parameter does not look useful. How would you implment or use that trait? Example: fn generic&lt;T&gt;(thing: T) where T: Index&lt; ?! , usize&gt; { let x = thing[0]; // Does x have a lifetime parameter referring to the lifetime of thing? drop(thing); // &lt;-- allowed or not? drop(x); } Whether this drop is ok or not depends on the respective `Index::Output` type having a lifetime parameter attatched or not. Also, we have a hard time naming this lifetime in the trait. It is my understanding that the Rust core team is not interested in weakening generics in the sense that generic code can only be fully type-checked at monomorphization time. I think using a single trait for both (returning values or loans) is not an option. At least not with how Rust currently works.
I will attempt to summarize my initial impressions (still learning!). First, I think a lot can be done by simply passing an owned T struct around (when it is small), and Box&lt;T&gt; when it occupies more memory. As long as you do not poison them with active references, you can move these values freely around and use them to communicate between different parts of code. As I understand, references are useful when some code needs to be executed in the context of one ore more such values. And they are usually temporary. Rc&lt;?&lt;T&gt;&gt; could be an escape hatch if object lifetimes become runtime-dependent. 
So the escape hatch would be to allow impls for external traits, but keep those impls private to the module? Would it still be possible to somehow import the impl from another module? Also, if I had such a private impl that collided with another external impl, would rust use the private impl anyway, overriding the external one (perhaps issuing a warning) or return a compile-time error?
I see a link to my blog post, but hey! It wasn't painful, thanks to the rust compiler hinting the correct solution most of the time (well, and thanks to the supportive irc channel) ;) 
There's also Scala.js if you prefer that. But I agree that it would be nice if Scala (the language) was more backend independent and wasn't so strongly tied to the JVM. Scala's type system combined with Rust's memory management would almost be the perfect practically useful language IMHO.
Tried this, and it works!
I did a little more digging and I think the culprit is Unicode. `\w+` is Unicode friendly, but Nim's `\w+` is not: http://www.reddit.com/r/rust/comments/2sd5rv/a_quick_comparison_of_nim_vs_rust/cnpq4lc
/u/dbaupp any thoughts on this?
We had enough to warrant ~8 moderators and 24 hour support ;). We weren't big, but enough to make the effort ~200 active users. The thing is: people can usually read english, but to some it's mentally more taxing and they need more effort then others. Formulating comes next, sometimes they just cannot write their problem down properly or find it taxing. And sometimes, a conversational explanation in plain german just makes it easier for them. We usually _assume_ that everyone speaks technical english properly in germany, but I found that this is just not true. e.g. I ran a fully english conference last year that had live transcription of all talks, initally for the hard of hearing. We got _great_ feedback from people that have to make a real effort to follow english speakers and all their dialect. It was _relaxing_ for them. I'm a huge fan of making things _easier_, and talking to people in their mother tongue absolutely helps.
The only thing with Scala is it also has long-ish compile times. But I use it every day at work and love the language.
&gt; surprised to see 8 implementation of this in Go lang. Go has become popular with the DevOps crowd, with HashiCorp and Docker and such.
To be fair, the Rust book / guide helped me a lot understanding the basic concepts of the language. Of course some stuff is outdated, but I guess this is going to change before the 1.0 release. But what about the opportunity to comment on the pages of the book? Comments could address additional tricks (which would even be too detailed to be mentioned in the book). I saw this reading through the PHP documentation: It explains the basic concepts and the users give additional tips using comments, which I really liked. A comment is also written much faster than a pull request and I find it easier to understand the explanations of someone who's maybe even in the same situation (learning) as you are. And if it's not all right, you could still downvote.
What errors did you get with your "failed" attempt? I was able to compile and run this: extern crate crypto; use crypto::bcrypt; use std::io::IoResult; use std::rand::{Rng, StdRng}; fn main() { println!("{:?}", generate_from_password("foobar").unwrap()); } pub fn generate_from_password(password: &amp;str) -&gt; IoResult&lt;Vec&lt;u8&gt;&gt; { const DEFAULT_COST: usize = 10; const MAX_SALT_SIZE: usize = 16; const OUTPUT_SIZE: usize = 24; let salt = { let mut unencoded = [0u8; MAX_SALT_SIZE]; let mut rng = try!(StdRng::new()); rng.fill_bytes(&amp;mut unencoded); unencoded }; let mut output = [0u8; OUTPUT_SIZE]; bcrypt::bcrypt(DEFAULT_COST, &amp;salt, password.as_bytes(), &amp;mut output); let mut v = Vec::with_capacity(OUTPUT_SIZE); v.push_all(&amp;output); Ok(v) } Maybe you forgot to import the `Rng` trait?
On the other side writing in English is a good training. To describe a problem in English with my few words is hard, but better than have no community. 
What does the Raft consensus protocol have to do with DevOps?
I don't personally think there is much point to Rust without the borrow checker. It drives architectural choices when you write your program and it's unlikely that you're going to be able to just turn it back on and fix the errors later (unless you were already programming as though it were on). If you don't want to deal with the borrow checker, you should be using a language with garbage collection (and there are certainly a lot of them :)).
I agree. The direction I would like to see Rust take (after the 1.0 release) is to make the borrow checker and lifetime/type inference better/smarter to make it easier to write safe and fast code, which are Rust's major selling points. There are better languages to use if you don't care about either of these points.
The trick is to store them as `fn() -&gt; i64`, not as the closure traits. See this [example](http://is.gd/zfKHhn). The macro unfortunately still does not work.
 unsafe fn main () { //go nuts } 8-)
&gt; (unless we are calling people like Leslie Lamport DevOps, I guess). Yes, maybe I'm just overly blurring lines, and using 'devops' which is a fuzzy term anyway, doesn't make sense. &gt; but Raft has to actually be integrated into the distributed database. It doesn't though. I'm thinking of things like Zookeeper here, which is an external thing, but absolutely uses consensus to manage these kinds of situations. The tools HashiCorp builds are similar.
I can also recommend rust-crypto. Most hashes also implement a 'result_str' method, which returns the computed hash as a String (either hex or base64 encoded)
Zookeeper does have to be integrated into a system in order to use it reliably for consensus. Minimally, you have to get and set all your values directly through Zookeeper if you want correct results, which means that it can't just be slapped onto an existing application to confer consensus (although that would be nice). Zookeeper also isn't a consensus protocol itself; it implements its own. It's probably true that lots of services aimed at DevOps are built on applications that use distributed consensus protocols, but that's like three or four layers of indirection away. At that level of indirection, I could attribute practically anything to "the DevOps crowd": operating system kernels, the networking layer, relational databases, browsers... just seems to me like an overly broad statement. I'm probably just nitpicking :P
That's pretty hard-core, so I like it. However, you probably need to compute the signature over the definition of the unsafe code *and* the transitive closure of everything else (safe or unsafe) that it depends on.
I understand how you must feel. Being harassed, even online, sucks. I certainly hope you are an exception, as toxic communities can ruin an ecosystem, especially when it's as young as rust's. People in the open source community often overlook the fact that not everyone can contribute directly. This is even more true for something like documentation. It is easy for someone already familiar with the language to overlook bad docs, which makes the problem even bigger. Someone like you, who isn't afraid to speak up, can change this mindset and I certainly hope you did. Don't let the assholes get to you. They clearly did not read the post that has been on the front page for over a year. Contributing can involve other things than making pull requests. 
I found the names of the collections off-putting for all of five minutes. That was seriously the *least* difficult thing about Rust, and I work at a .NET shop where we have single names long enough to wrap (maybe twice!) in Vim. I don't see this as a major issue. Then again, I see programming as basically the arrangement of arcane runes for a particular purpose, so I may not be the best person to ask. Even so, the "I'm guessing what this does stage" doesn't last long, and--if your tooling isn't brain dead (the thing that makes typing long names easier, right?)--your editor should be able to tell you what DList is anyway. Should I also mention I have a near pathological dislike for change? Man, sometimes I wonder why I'm trying to learn new languages at all... doesn't seem to fit my MO.
Ah! That was one of two things I thought about (the other being, could we get rid of all those `String`?).
&gt; I've seen someone here toying with the idea of being able to disable the borrow checker in Rust, I hope this happens. it could be clearly marked in the build process. I've even heard the idea that a syntax-extention could mark everything in the source as unsafe. It could still be a warning. I've seen different opinions from the team - following jonathan blows videos there was interest in doing it , but others have expressed the fear of polluting and dividing the rust ecosystem/community. Personally I would argue it could only make the community bigger, since the unsafe users will still give mindshare to safe parts of the language, and the unsafe users already exist (all the C++ people who've stated they'll never switch) I've embarked on a pet-project that could theoretically end up as an unsafe rust superset but its unlikely I'll get there without collaboration. 
Rust has everything and probably better than Go lang except we have to flight against rust compiler for borrow checker. If we have a smart IDE who understands borrow checkers and help developer, it will speed up the development. See https://twitter.com/rjoshi/status/555690396035325952
So, if you declare your entire code unsafe, and use raw pointers everywhere... do we arrive back to C from Rust?
Technically &amp;'str isn't fixed size; the compiler can't tell you at compile time what the size I'd.
Official documentation of the Python functions is [here][1]. [1]: https://docs.python.org/2/reference/datamodel.html#emulating-numeric-types
If you can break unsafe code by changing one of its dependencies, then either that dependency is also unsafe code (so the change would be audited), or you were already using it incorrectly, or you've found a bug in Rust safety checking. I agree that auditing for the big picture is very hard, though — I touched on that in one of my other comments here.
I suggested the API docs to the OP as he already read the book. Of course you need something more to get started but if the API docs dont suffice to learn the standard library then what should?
I tried [this](https://news.ycombinator.com/item?id=8892336) HN suggestion. It turns out `regex!(r"[a-zA-Z0-9_]+")` runs the fastest, even faster than Nim’s peg. I’ve updated the article with the results.
&gt;it doesn't help searching either As a counter example: if I were to [search for a list](http://doc.rust-lang.org/std/?search=list) the first result is the module `std::collections::dlist` with the description "A doubly-linked list with owned nodes." The actual collection is right below it, and again the summary is "A Doubly Linked List." Googling [rust linked list](https://www.google.com/?q=rust%20linked%20list#q=rust+linked+list) puts `DList` as the first result. If I'm looking for a map I don't search for `hash` (the implementation detail) I search for `map` (the "family" or "category" if you will.) This way I can see at a glance _what types of maps_ the standard library provides, and pick the one that best suits my particular use. To be honest though I've never _searched_ for a collection. The module level documentation for the collections is _very good_ at guiding the user towards a correct collection. I've always just paged through the collections module hierarchy directly. It's actually something I've always liked about rustdoc: it's very easy to drill down to the type you're looking for. I usually use the search feature to find a _particular function signature_ because I can't remember the order of arguments; not to go hunting for some unknown type. So I'm afraid that I completely disagree with the argument that the abbreviations somehow harm discoverability. 
It's not a matter of can-do, it's a matter of safety vs non.
It makes the variable itself mutable exactly like in a variable declaration (which it actually is). Without `mut` you couldn't reassign the variable. You would have to re-declare (shadow) it instead. fn add_one(mut x: i32) -&gt; i32 { x = x + 1; x } // vs fn add_one(x: i32) -&gt; i32 { let x = x + 1; x } 
You can borrow what's in the box with `&amp;*some_box`. The * de-references the box, and then the `&amp;` makes a new reference to the freshly de-referenced contents.
If someone told me they were using a linked list for some purpose, I'm fairly sure the first thing I would do is ask "singly-linked or doubly-linked?" The point being, I'm not at all sure that "linked list" has an established implication of being singly-linked.
My fear is that this implies most written Rust code would be safe without the borrow checker, which is absolutely not true.
What do you mean by "checking whether you implemented [an interface] properly"? I don't think Rust has anything like that, either.
For example, the borrow checker is still on inside an `unsafe` block.
Unless you use raw pointers, ain't it?
I believe unsafely casting a raw pointer to &amp;mut is undefined behavior, no matter where you do it.
Or there's a bug in the safe code that you have a dependency on.
At the end, to print the word count, you do: let mut words: Vec&lt;&amp;String&gt; = map.keys().collect(); words.sort(); for word in words.iter() { if let Some(count) = map.get(*word) { let line = format!("{}\t{}\n", count, word); try!(writer.write(line.as_bytes())); } } The look ups in the `map` are actually not necessary if instead you collect (and sort) the key-value pairs instead of just the keys: // The playpen is not nice with me and has lot my formatting and parenthesis... // ... so there might be a compile-error lurking or two. let mut words: Vec&lt;(&amp;String, &amp;u32)&gt; = map.iter().collect(); words.sort_by(|&amp;mut: &amp;left, &amp;right| left.0.cmp(right.0)); for &amp;(word, count) in words.iter() { let line = format!("{}\t{}\n", count, word); try!(writer.write(line.as_bytes())); } It is unlikely to speed things much, but it still seems nicer to avoid useless look-ups.
&gt; Note that the choice of a linked list is fairly arbitrary. One could use an array stack or binary search tree. I'm not clear why a linked list is the most popular choice here. I sometimes ask an interview question about when one should use a linked list... my answer is don't; a sentiment echoed by the Rust collections docs. Why do hash map implementors tend to use linked lists?
sorry，its duplicated。Network error made me send again。
My C is rusty, but yeah it's basically the difference between the pointer and the pointed-to being `const`.
That's because `mut` in `mut x: &amp;i32` is responsible for the mutability of the variable `x` (i.e. it determines whether you can reassign `x` to another reference), while `mut` in `x: &amp;mut i32` defines the mutability of the reference itself, i.e. it determines if you can reassign the value this reference points at. The following table summarizes what you can and what you can't do with various positions of `mut`: mut x: &amp;mut i32 x = &amp;y *x = 123 mut x: &amp;i32 x = &amp;y -------- x: &amp;mut i32 ------ *x = 123 x: &amp;i32 ------ -------- I don't remember C syntax, but as far as I understand, you're correct in your analogy.
Reversed. The first one is a mutable pointer to a immutable int (`int const * x`) and the second is an immutable pointer to a mutable int (`int * const x`). `x: &amp;i32` would be `int const * const x`.
Ahh yes. I'm guessing that they are referring to name clashes, ie, two methods which seem the same, but aren't. In Rust, a `close()` method on, say, a `NetworkInterface()` trait and on a `Door` trait would prevent you passing a `Door` to something expecting a `NetworkingInterface`.
Oh ok, got it now! thanks
Arguably... Julia (no enums, but you can work around that with the dispatch system) Ada! (no REPL that I know of, but the syntax is actually quite C-like) Ocaml (syntax is of course problematic).
Does anyone know if this will be recorded and available for viewing on demand (free, I'd hope)?
Hmm, I think adding comments could be an interesting idea!
Well, IMHO Vec is not just confusing because of the abbreviation, it simply is the wrong term for the type. Repeating the same mistake that c++ made. A Vector type should represent an entity with a magnitude and direction (or the equivalent algebraic set of coordinates) and the collection should be renamed to DynamicArray or a variation of that name. 
/u/fitzgen, Random1DollarTip wants to send you a Bitcoin tip for 4,840 bits ($1.00). Follow me to **[collect it](https://www.changetip.com/collect/353556).** [ChangeTip info](https://www.changetip.com/tip-online/reddit) | [ChangeTip video](https://www.youtube.com/watch?v=_AnfKpypMNw) | /r/Bitcoin
It's the same as FCFS and LCFS. Remove it and back-shift any elements that want to be back-shifted (aren't in their ideal location). This effectively puts the map in a state where that element was "never" inserted, allowing analysis to only consider insertion for statistical properties. There's some other design that places "tombstones" rather than backshifting, but it performs worse because stuff gets clogged up with tombstones instead of being in good locations.
Cool, thanks. :)
I am coming at rust from the other side. I do love me some Haskell. As a hobby I've programmed in it almost exclusively for the past six years. I was looking for something to go with it that could be complimentary, I spent a while hoping that Ada would fill that niche, while it is a nice language, it may never really gain traction for various reasons. I've looked at Rust out of the corner of my eye for a while, now I'm getting ready to dip my toe in. If you are looking for quick prototyping, Haskell is probably not for you. It is much more suitable for prototyping in a hammock. Probably only the top 10% of Haskellers are good enough to rapidly prototype in the language. It is a great language though, I highly recommend learning it.
If you use `&amp;mut *x` instead of `&amp;*x` and make `add_one_borrow` take `&amp;mut i32` then it should work.
[Sodiumoxyde](https://github.com/dnaq/sodiumoxide) should support it [soon](https://github.com/dnaq/sodiumoxide/issues/21).
My dad actually told me about this a few days ago. He does realtime embedded systems programming.
I'm working on improving this error, fwiw.
I don't think that's what `Deref` does. It just 'passes on' method calls when they aren't implemented on the object itself. The `*` operator just converts a `&amp;T` value to `T`, as far as I know..
Since struct members are private by default I would disagree with the first statement. That's quite encouraging to use getters/setters. 
I would also like to know this, am not keen to get up at 5am!
&gt; The moral is that open addressing is better anyway. I find it funny that it turns out that open addressing + linear probing which pretty much is the easiest implementation, works so well in practice whereas what you learn at university does not :) Theory versus practice!
Could that be solved by putting the length changing code in a submodule that provably ensures the invariants (e.g. for all elements in 0..length memory is available) and having the length private to that submodule? I can see that this would be more work, but I don't see how adding unsafe members would help - a malicious coder who wants to wreak havoc will either remove the qualifier or just use unsafe blocks. And the submodule-private solution has the benefit of pulling related functionality into one place. Note that all of this should be taken with a sizable helping of salt, as I haven't had a look at Vec in a while. Edit: thinking a bit more about that, it seems dangerous to defer judgement of what is unsafe or not to the library author. On the other hand, the compiler cannot in general decide which operations would break the invariant. So a better solution would involve annotating the invariant (plus perhaps a hoare-style checker for a good range of cases). 
Well, *naive* linear probing does quite poorly (as I discuss in the post), and the analysis to prove that it does well is non-trivial.
&gt; if I were to [search for a list](http://doc.rust-lang.org/std/?search=list) In many languages, perhaps most prominently Java, a list is not a linked list but either an interface or even a concrete implementation of a not-linked list. If you wanted a linked list, you'd probably want it for a good reason - the constant factors don't favour linked lists so you'd be looking for the *very* particular asymptotic complexity guarantees. [As the guide says,](http://doc.rust-lang.org/nightly/std/collections/#use-a-dlist-when:) &gt; **Use a `DList` when:** &gt; &gt; * You are *absolutely* certain you *really, truly,* want a doubly linked list. Making `DList` the first result for searching "list" actually seems pretty poor. &gt; Googling [rust linked list](https://www.google.com/?q=rust%20linked%20list#q=rust+linked+list) puts DList as the first result. Strange, because for me it's behind both of: * [Problem with implementation of linked list : rust - Reddit](http://www.reddit.com/r/rust/comments/2jec05/problem_with_implementation_of_linked_list/) * [Enums | Rust by Example](http://rustbyexample.com/enum.html) I've tried on a proxy, so it's not just me. &gt; To be honest though I've never *searched* for a collection. Meh, I have. People differ and my point was more general than just collections anyway. That said, I mentioned this as a minor side-point, by no means as a founding argument. If it was the other way around I'd still prefer the naming I've given - albeit less so. 
I second OCaml, which I think is a criminally underused language. The syntax is less C-like, but you get used to it quite quickly. It's quite fast for a GC'ed language, as well, and there are also nice upsides to the ecosystem—for example, [the Mirage unikernel](http://www.openmirage.org/), which lets you compile your program directly to a VM that runs directly on Xen. (Other languages have similar unikernel systems—[Haskell](https://github.com/GaloisInc/HaLVM) and [Erlang](http://erlangonxen.org/) for example—but Mirage is still very cool.)
You could probably do something with take_while. http://doc.rust-lang.org/std/iter/trait.IteratorExt.html#tymethod.take_while
Have you checked out F#?
Good question. `Ok(A::default())` in that case. I guess `A` should implement `Default`. Edit: I'm working with `A = ()`, by the way. I see I forgot an initial value for the fold in the opening post.
Damn, just stumbled upon this function: http://doc.rust-lang.org/std/result/fn.fold.html Edit: It's not exactly what I'm looking for though. You cannot chain it, like `.fold`. This requires you to save the iterator to a variable, which can cause lifetime issues.
A vauge idea: Write an AndTrait to say that your types have and() Turn you boilerplate above into a generic function that works on Iter&lt;AndTtrait&gt;
Good catch
The big problem is that the "real type" of `fn1` and `fn2` and `fn3` *is not* `Fn()-&gt;i64` but a `fn()-&gt;i64` that happens to implement the trait `Fn()-&gt;i64`. The easiest solution is to use [`fn` instead of `Fn`](http://is.gd/97t9xw) whenever you refer to *only* static functions. Now this will not work with the vec! macro. Lets solve that too: vec! will create a temporary vector and then add it. It will use the first element as reference for the type (for some reason) and the problem is that the *real type* of `fn1` is not really `fn() -&gt; i64` it actually is something like `fn() -&gt; i64 {fn1}`. The nice thing is that if you send it as a type parameter the actual function will be known and inlining will be possible, or at least it can use the function directly instead of a reference to it. The nasty thing is that it isn't immediately obvious how it makes vec! fall on its dumb face. The solution to the vec! problem is [explicitly defining the type of the first member of vec!](http://is.gd/ffpTEf) which allows the vector to use the right type and then cast the rest of the functions. Notice that doing this *will prevent the functions from inlining*, you've erased the necessary information from the type with this. A similiar thing can be done to [use Box](http://is.gd/HiQvPy). **Take Note:** if you are using `Box&lt;Fn&gt;` instead of `Box&lt;fn&gt;` [you must cast the whole box, just the inside](http://is.gd/7ly4ot). The borrow error is a bit weird but I believe I there's a reason. When you run `fns.push(&amp;fn1);` you're really running `fns.push(&amp;(fn1 as Fn() -&gt; i64));`. And what is `fn1` well an `fn() -&gt; i64`, which is really just a reference to a function (actually an object that hides the real function you are calling). In other words our `&amp;'static Fn() -&gt; i64` is really a double pointer/reference to an function, or something like `&amp;'a &amp;'static fn() -&gt; i64 {fn1}` where `'a` if the lifetime that created the `fn` object. We can see how the static reference itself has a non-static lifetime! And in your code `'a` is however long the expression lasts! Using a let statement we make this `'a` as long as main function, which is long enough for the borrow checker to allow you to lend it to the vector. Hope this is useful and gives insight into what is going on.
Well, function arguments are defined as patterns, just like `let` and `match` arms. Variable bindings are just a specific kind of pattern.
Damn, you have a cool dad.
You can define a special `FromIterator` type, and then use the `FromIterator&lt;Result&lt;_, _&gt;&gt; for Result` that already exists. This `FromIterator` impl allows collecting into any other `FromIterator`, and shortcircuits on the first `Err`, so I think this gives precisely the semantics you want. use std::iter; // a special collection that just takes the last element of an iterator #[derive(Show)] struct Last&lt;T&gt;(pub Option&lt;T&gt;); impl&lt;A&gt; iter::FromIterator&lt;A&gt; for Last&lt;A&gt; { fn from_iter&lt;I: Iterator&lt;Item = A&gt;&gt;(iterator: I) -&gt; Last&lt;A&gt; { Last(iterator.last()) } } fn main() { let v: Vec&lt;Result&lt;_, &amp;str&gt;&gt; = vec![Ok(1), Ok(2), Ok(3)]; println!("{:?}", v.into_iter().collect::&lt;Result&lt;Last&lt;_&gt;, _&gt;&gt;()); let v: Vec&lt;Result&lt;_, &amp;str&gt;&gt; = vec![Ok(1), Err("first error"), Ok(3), Err("second error")]; println!("{:?}", v.into_iter().collect::&lt;Result&lt;Last&lt;_&gt;, _&gt;&gt;()); } [playpen][pp] [pp]: http://play.rust-lang.org/?run=1&amp;code=use%20std%3A%3Aiter%3B%0A%0A%2F%2F%20a%20special%20collection%20that%20just%20takes%20the%20last%20element%20of%20an%20iterator%0A%23%5Bderive%28Show%29%5D%0Astruct%20Last%3CT%3E%28pub%20Option%3CT%3E%29%3B%0A%0Aimpl%3CA%3E%20iter%3A%3AFromIterator%3CA%3E%20for%20Last%3CA%3E%20{%0A%20%20%20%20fn%20from_iter%3CI%3A%20Iterator%3CItem%20%3D%20A%3E%3E%28iterator%3A%20I%29%20-%3E%20Last%3CA%3E%20{%0A%20%20%20%20%20%20%20%20Last%28iterator.last%28%29%29%0A%20%20%20%20}%0A}%0A%0Afn%20main%28%29%20{%0A%20%20%20%20let%20v%3A%20Vec%3CResult%3C_%2C%20%26str%3E%3E%20%3D%20vec!%5BOk%281%29%2C%20Ok%282%29%2C%20Ok%283%29%5D%3B%0A%20%20%20%20println!%28%22{%3A%3F}%22%2C%20v.into_iter%28%29.collect%3A%3A%3CResult%3CLast%3C_%3E%2C%20_%3E%3E%28%29%29%3B%0A%0A%20%20%20%20let%20v%3A%20Vec%3CResult%3C_%2C%20%26str%3E%3E%20%3D%20vec!%5BOk%281%29%2C%20Err%28%22first%20error%22%29%2C%20Ok%283%29%2C%20Err%28%22second%20error%22%29%5D%3B%0A%20%20%20%20println!%28%22{%3A%3F}%22%2C%20v.into_iter%28%29.collect%3A%3A%3CResult%3CLast%3C_%3E%2C%20_%3E%3E%28%29%29%3B%0A} Output Ok(Last(Some(3i32))) Err("first error")
No, that is definitely what Deref is supposed to do. The passing through of methods happens because rust uses autoderef to search for possible candidates.
 int *x; cont int *x; int * const x; const int * const x; are the equivalents of your Rust examples.
That's indeed exactly what I am looking for! Thank you!
I stand corrected. Thank you.
There are effectively two flags you can put on `self`: mutability, and borrowing. That is, you can have `self`, `mut self`, `&amp;self` and `&amp;mut self`. (Though I can see little value in `mut self`.) Mutability has an equivalent in C++, but it's not necessarily immediately obvious to the new Rust programmer, because it's applied in a different place. That is, in C++, mutability is applied as an attribute on the function, whereas in Rust it's applied as an attribute `self`/`this`. Semantically, these two things are equivalent, but that's somewhat obfuscated by the syntactic differences. The borrowing flag has no equivalent in C++, and I think that's what the author of this article was really looking at. That is, there's no way to make a member function on a C++ class take `this` by value. `this` is always a pointer.
It is indeed still a tricky or impossible problem, I’m not sure which—I was merely correcting the misunderstanding that it was not possible to represent the *trait*.
`vec![fn1 as fn() -&gt; i64, fn2, fn3]` works just fine.
You're doing the best you can. I've raised this as a major issue several times (including describing a full and umambiguous solution based on where the `impl` is), but the Rust developers just don't consider it important enough (since they have `std::prelude` for their own needs).
Yes, I saw your comment on HN and have updated my benchmark results accordingly. I fully agree with you that publishing benchmarks like those is *risky*! When I wrote the article, I think: since the code is done, why not *just* running them and providing the numbers, so people get a rough idea of their performance. I ended up with spending more time on updating my code/benchmarks than writing the article itself. :-) 
Nice write up, this is something many ppl will have to go through when learning rust. What would one do if you want the "name" field to be mutable? Make it public and provide no getter/setter or create a function like get_name_mut() or rather name() and name_mut()?
Just a quick tip: you can click the "reply" link under the comment you want to reply to. If you reply directly to someone, they get a message so they know you've responded. Currently, you've replied to yourself, and /u/kibwen may not know you said anything. :)
Also: you can format code inline with backticks (\` as opposed to ' or "), which looks `like this`.
&gt; That is why it signs whole functions that contain unsafe blocks. No, it's because you can't put attributes on `unsafe` blocks yet :)
Sucks they closed it right away, not sure if they understood what you were asking for. If you print `(1i32, 2i32)` with a `"{:?}"` format string, you'll get exactly that: `(1i32, 2i32)` which is not useful for displaying information to the user since it exposes implementation details. But the linked RFC implies that you should implement your own method of pretty-printing generic containers, such as vectors or tuples. Perhaps the formatted newtype wrapper I suggested will become a more common pattern since there will probably be no useful solution in the standard library.
That is incorrect; in order for a type to implicitly conform to an interface (and thus be usable through that interface) it has to implement the method specification exactly. Basically, if you get the method signature wrong, the compiler will complain and point out why (and where you are attempting to use the non-conforming type). Edit: The main difference with Rust in this regard is that, due to the implicit implementation, the compiler will not warn you for non-conformance if you never attempt to use the given type as the interface in question.
Is that really a choice? Worse default performance forever vs one time change of (not yet numerous) projects.
The question is whether it's really a performance improvement most of the time. There are some compelling reasons laid out in the Github issue why that might not be the case.
"I suppose about now you're violently vibrating at your desk over some omitted details." Made my day.
It is not related to `unwrap` at all; it is due to the fundamental design flaw. `read_file` creates a `String` (`rtl`) to preprocess, so the preprocessed `Vec&lt;Line&gt;` cannot outlive `rtl`. You have to convert `lines` to a `Vec&lt;String&gt;` (which is essentially `Vec&lt;&amp;str&gt;`). Note: Normally you'd better annotate lifetime parameters to get more complete view of lifetimes. In the case of `preprocess`, it is automatically assumed that `Line`'s lifetime parameter is same to that of `s` (correct). In the case of `read_file`, it is again assumed that `Line`'s lifetime parameter is same to that of `file_name` (utterly wrong). Try to explicit write the lifetimes out in definitions (e.g. `fn preprocess&lt;'a&gt;(s: &amp;'a str) -&gt; Vec&lt;Line&lt;'a&gt;&gt; {}`); if the resulting definition seems strange, this likely indicates a problem in your design.
I don't know if `mut self` really counts as a flag in the same sense as `&amp;self` vs `&amp;mut self` vs `self`, because whether you use `self` vs `mut self` is not visible to the calling function, which must grant ownership, and hence mutability, anyway.
Yep I agree... I think this method has too many disadvantages and could easily be replaced without really additional work. I don't see a reason for keeping it...
Stable ABI is a big commitment that probably nobody from the core developers want to make right now. The language is very young and things are in flux and stable ABI may interfere badly with future optimizations or other changes.
Thanks for the tips. As for what rust-crypto should be focused on, I'm inclined to agree with the separate crate.
So I figured out a solution. It's a little messy, and it requires making some unnecessary copies, but I'm happy with it because it keeps the API simple. Plus, I can worry about performance some other time. Basically I created a trait called `IntoVector`, which requires two functions, `into_vector` and `into_self`. pub trait IntoVector : Copy { fn into_vector(&amp;self) -&gt; Vector; fn into_self(v: &amp;Vector) -&gt; Self; } Now I just have my dot function look like this: pub fn dot&lt;T: IntoVector, U: IntoVector&gt; (v1 : &amp;T, v2 : &amp;U) -&gt; f32 { let u1 = v1.into_vector(); let u2 = v2.into_vector(); u1.x * u2.x + u1.y * u2.y + u1.z * u2.z } Now I only need to `use geometry::Vector`. It works like a charm. The only real issue is the unnecessary copies. But I think I could get around this by doing some type of unsafe cast in the implementation of into_vector. Either way, I like this solution. EDIT: Here's how I prevented the unnecessary copies. (For any future reader of this post) My two structs are, pub struct Vector { pub x: f32, pub y: f32, pub z: f32 } pub struct Normal { pub x: f32, pub y: f32, pub z: f32 } Now for my implementations of IntoVector: impl IntoVector for Vector { fn into_vector(&amp;self) -&gt; &amp;Vector { self } fn into_self(v: &amp;Vector) -&gt; &amp;Vector { v } } impl IntoVector for Normal { fn into_vector(&amp;self) -&gt; &amp;Vector { // We use an unsafe cast here to prevent a copy when doing vector-normal // operations. unsafe { mem::transmute(self) } } fn into_self(v: &amp;Vector) -&gt; &amp;Normal { unsafe { mem::transmute(v) } } } I think it's a bit hacky. But I feel confident in relying on the fact that `Normal` and `Vector` will always be the same. I am thinking of adding SSE support someday, and this method should still work fine for that. Let me know what you think of this.
See my comment above for a solution that I figured out. 
I am actually working on a [command line utility](https://github.com/Inspiravetion/highlightrs) that turns rust code into contextually highlighted html using the rustc parser. That way you could do something like color all parameter names in function signatures and all variable names in let statements the same color as they show where a variable entered scope. 
This makes sense to me. The `as_mut_vec` method is reliant on and exposes implementation details for `String`. In any case, it would be easier to reintroduce this method at a later date than to remove it. I like flexibility. The only question would be, is this method used pervasively already?
I see. Thanks for the remarks. &gt; Secondly, C++ generally uses the system allocator by default (this is what drives stdlib decisions) Yes, the allocator is in the string type, so using a different allocation strategy (such a stack only allocator, or a stack for small strings/heap for large strings allocator) changes the string type. &gt; Most of the time, the system allocator is far less efficient than jemalloc (pretty much any benchmark you do will confirm this). Stack allocation for small strings is free (bump the stack frame pointer by a compile-time computed offset). Any allocator including jemalloc is going to be more expensive than that. A second point is for example building a Vector or a BTree of heap allocated strings, where for every string you inccur two heap allocations, one for the string object, and one for the string buffer. With SSO you go from N^2 calls to the system allocator to N calls, for small strings (23bytes in C++, probably 24bytes in Rust since the strings are not null terminated). I guess that going from N^2 to N calls to jemalloc is still going to be a big deal, but someone should benchmark/profile this in a larger application (e.g. servo?). &gt; Thirdly, C++ doesn't (didn't) have a pervasive string_view type, as it cannot be made safe, and referencing counting is atomic (therefore expensive), so there was no good way of passing immutable strings around without copying. Yes, this is (was?) an issue that increased the number of string allocations everywhere. LLVM, folly, Chrome, Boost, ... have their own `string_view` implementations to mitigate this (because it was a big performance problem). There is a `std::string_view` in the Library Fundamentals TS (I, i think), it will hopefully make it into C++17. &gt; Rust has none of these problems. That is awesome, but it doesn't mean that there is no room for improvement.
Maybe. Anyway for completeness here is a version using `Rc` which AFAICT is roughly equivalent to the original Haskell one: use std::rc::Rc; type F&lt;'r, A, B, C&gt; = Box&lt;Fn(Rc&lt;A&gt;) -&gt; Result&lt;Rc&lt;B&gt;, Rc&lt;C&gt;&gt; + 'r&gt;; fn compose&lt;'r, A, B, C&gt;(f: F&lt;'r, A, B, C&gt;, g: F&lt;'r, A, B, C&gt;) -&gt; F&lt;'r, A, B, C&gt; { Box::new(move |&amp;: a: Rc&lt;A&gt;| match (f(a.clone()), g(a)) { (Ok(x), Ok(_)) =&gt; Ok(x), (Ok(x), Err(_)) =&gt; Ok(x), (Err(_), Ok(x)) =&gt; Ok(x), (Err(_), Err(x)) =&gt; Err(x) } ) } fn constant&lt;'r, A, B: 'r, C&gt;(x: Rc&lt;B&gt;) -&gt; F&lt;'r, A, B, C&gt; { Box::new(move |&amp;: _: Rc&lt;A&gt;| Ok(x.clone())) } fn choose(x: Rc&lt;i32&gt;) -&gt; Result&lt;Rc&lt;i32&gt;, Rc&lt;String&gt;&gt; { match *x { 0 =&gt; Err(Rc::new(format!("zero"))), _ =&gt; Ok(x) } } fn main() { let f = compose(Box::new(choose), constant(Rc::new(42))); println!("{:?}", f(Rc::new(0))); println!("{:?}", f(Rc::new(1))) } 
&gt; (Though I can see little value in `mut self`.) Eh? It works great in the "builder pattern." http://burntsushi.net/rustdoc/src/csv/reader.rs.html#365-470 (Depending on use cases, [you can also use `&amp;mut self`](http://doc.rust-lang.org/std/io/process/struct.Command.html), but `mut self` is just as valid.)
The periodic table seems to imply that there is no fixed size storage for string but you said that there is `&amp;'static str` so I'm a bit confused..
Discussing SSO seems really interesting, but it is not blocked by this method either way.
Talk from Linux.conf.au 2015. Unfortunately the sound drops out a bit, for me anyway.
I'd say that a necessary condition for a stable ABI is a proper standardized language specification. Let's focus on getting one of those first.
Note that C *does not* have a defined ABI, but C compilers converged on consistent ABIs over time, which on `*nix` systems is the sysv ABI. I don't see much point or benefit to using a different ABI for external boundaries beyond the C ABI used by the rest of the system, and I don't envision that Rust's semantics will catch on in any major way in any system than you'd want to communicate with. Lots of things around our ABI are explicitly not defined to allow leeway for optimization and future changes as necessary. Given that a complete alternative Rust implementation is unlikely to appear for a few more years yet, I see no advantage to defining an ABI now, and maybe ever.
Fortunately, since this is not language feature, but syntax highlighting, it would be totally optional, even if implemented.
Wrong Rust.
&gt;In many languages, perhaps most prominently Java, a list is not a linked list but either an interface or even a concrete implementation of a not-linked list. &gt;Making DList the first result for searching "list" actually seems pretty poor. In that case rustdoc should probably incl. the module-level summary in it's search. Both `DList` and `Vec` mention `list` in their summaries: * A growable **list** type, written Vec&lt;T&gt; but pronounced 'vector.' * A doubly-**linked** **list** with owned nodes. * A doubly-**linked list.** The documentation (in my opinion) is precisely where the long-form names belong. These summaries also more closely match the full English fragments I would use when actually searching for something; _e.g: looking for a type I have no prior knowledge of._ (Again I rarely use the search function for that purpose. I search w/ rustdoc when I already know the type or function and I need a refresher on it's API.) --- &gt; http://imgur.com/jYcyjC3 I certainly didn't search behind a proxy; so these must be my personalized results. I've been googling this stuff since `rust 0.6` though. So I'm sure Google has had plenty of time to profile me. The fact that these personalized results exist, though, illustrates that this is more of an SEO problem than a "poor naming / poor documentation" problem. --- That all being said: I more or less agree w/ your names. Though I really dislike the expansion of `RingBuffer`. There is plenty of precedent in `std::io` for using `buf` as an abbreviation for buffer. As a consequence this abbreviation is prevalent in plenty of my code. I think `Buf is a Buffer` feels very similar to `Vec is a Vector`. I could not make the same argument for a DList; though I would still prefer the terse name. I think [`niko` said it best over on the RFC thread.](https://github.com/rust-lang/rfcs/pull/580#issuecomment-69975735) An excerpt from that comment (emphasis mine): &gt;Rust certainly has a history of very short abbreviations that we have generally moved away from. But we've been moving towards "mid-length names". Memorable names with punch. Obviously these is not a hard-and-fast rule that one can follow, _but I think it's important, and it's part of Rust's character. I would be very loathe to lose it._ and &gt;Also, speaking personally, while I find overly short names can be very opaque I find very long names equally hard to read. There's too much there and the "pattern recognition" part of my brain shuts off and the "actually read text" mode kicks in, which is much slower. To that last part: when using a type-name in a signature I'm writing _rust_, not _English._ Implementation details like "this uses a doubly linked list internally to ..." belong in the documentation: not in my member definitions, et al. If I wanted to read and parse a name that long: I'd be reading the doc comments, not the type signatures.
Yup, this and Deref are two biggies.
That much is actually true. However, the exposure of `Vec` as an inner value precludes any future optimizations that aren't done on the `Vec`. This is disconcerting, as types for "mutable string" and "generic vector of stuff" serve different roles, each with their own characteristic usage patterns. There is already discrepancy in performance expectations on slicing, for example; direct indexing and slicing should not be used pervasively on `String` due to the need to assert correct UTF-8 boundaries for every operation.
For reference, ours currently goes to 90% before resizing.
I don't think the last statement is true at all. C++ does not have inherited mutability and unique (&amp;mut) references with checked RefCells, for example, both of which are critical for preventing iterator invalidation-like bugs. I see no way they could possibly have it without redesigning the whole STL and pretty much every C++ library in existence from scratch, which they obviously won't do.
As I said on the discuss thread, Rust used to use a small string optimization for all strings. The code bloat was unacceptable. I don't think we can go back to that world.
I don't think SSO is an important feature with `Cow` and `&amp;str` slices.
Because then we cannot extend it backwards compatibly: other implementations would no longer be compatible with output from x.z.
As for accessing self from that separate thread, that is in general not possible because it would create data races. Instead clone things and/or use `Arc&lt;Mutex&lt;_&gt;&gt;` like this: pub struct MyProcess { command: String, process: Arc&lt;Mutex&lt;Option&lt;Process&gt;&gt;&gt;, } /* ... */ fn start(&amp;self) { let cloned_command = self.command.clone(); let cloned_process = self.process.clone(); Thread::spawn(move || { // here you can access cloned_command { /* I'm not totally sure of this syntax, but I think it looks something like this: */ let z: &amp;mut Option&lt;Process&gt; = &amp;mut *cloned_process.lock().unwrap(); *z = Some(process); } } } 
Awesome talk, glad to hear they're actually working on integrating their work with Gecko. I'd love to see a plan for how they're going to merge some of this work. Also, was the audio messed up for anyone else? Towards the end it got really bad and I could hear a lot.
In all seriousness, it's been a while since we allowed ourselves to celebrate. We've seen a *ton* of new subscribers since the release of the alpha, which has pushed our subscriber counts over that of other worthy languages such as /r/scala and /r/clojure. And with [our current trajectory](http://redditmetrics.com/r/rust) we might have a chance of overtaking /r/swift (we're coming for you, Chris Lattner!). Welcome to our new users, and thanks to everyone here for making this place an oasis of relatively-pretty-good discussion in the desert of the internet at large.
8,000 when I wrote this post, 8,003 as of this comment. You can see through my CSS shenanigans by highlighting the text (your browser shouldn't allow you to highlight the content of CSS `:after` rules (see also my ludicrious upvote count)).
On desktop, it's on the sidebar. Currently 8003.
Here's my pic of 8,000 users. (Darn you kibwen, stealing all the upvote points.) https://imgur.com/JN39S8f
The question is whether Servo processes correctly this CSS rule.
Great, thanks!
You are right, the immutability by default was messing with my brain. Thanks!
Ah, I've typically used `&amp;mut self` for that sort of thing, but then either .clone(), or construct a new instance... But yea, this makes sense as it avoids the need to do that.
I suppose... I don't know that "visibility to external callers" is the vital feature, though.
&gt;What's going on here? I guess the docs are more targeted at web developers than C++ programmers. I've been following the project for quiet a some time so I know that Rust can be an adequate C++ replacement. But if I knew only the docs (mostly the 'book') I too would assume it's another web backend language. &gt;What can be done? Hmm, write better docs or wait till we get the first O'Reilly books on Rust :)
Well I assumed you wanted a fixed size type to create strings at compile time, and just was pointing out that string literals work just fine for that.
If you have ABI x.y, and ABI x.z, how does whether you define ABI x.z affect whether its compatible with x.y? If x.y == x.z, what does it matter if you explicitly define x.z?
this sounds to me just like Bjarnes eloquent explanations that a new language isn't needed http://isocpp.org/blog/2014/12/myths-1 :) &gt; Lambdas don't solve the hard problems, like returning references to the insides of collections that can become invalidated. but the times you can use them, they allow parallelism, so for a long time we've had a strong incentive; we already had to deal with mentality this stuck with a deeply pipelined in order processor for 7years. it needed parallelism by intent so that you could unroll &amp; interleave its loops , only possible if individual iterations didn't interact. Now there's GPGPU and new 'gather' instructions allowing other forms of parallelism. One trick was collections that were guaranteed to have padding for a dummy iteration at the end, so that they could be dealt with by 'unroll x 4' or 'unroll x 8' code, another was inserting a safely useable null value in the '-1' position (defining -1 as a safe 'none' index), which helped with some branchless cases. (to achieve unrolling, you had to eliminate branches obviously) &gt; You would have to alter the meaning of const &amp; to mean strictly immutable and of &amp; to mean restrict, for example, which would have massive ripple effects throughout the language definition and would **break all C++ code. ** .. apart from the c++ that you'd reworked &amp; shipped over the past 7+ years for parallelism (both threading &amp; ILP), which needed transitive const restrict :) that was the point of doing it. Of course back then we didn't have the lambdas, it was a mess doing it, but fundamentally -we'd reworked algorithms &amp; data structures to be parallel friendly. here's the approach I'd have taken if I had the compiler source back then* &amp; the time to work on such a tangent:- (i) add tracking for 'const' to give a warning if used non-transitively (ii) give people time to silence those warnings with const_cast (* which can then flag its parent function as some sort of 'extra-unsafe') and special case mutable fields, or better still, making sure things really are const. (iii) add an option to turn that warning into an error in your 'less unsafe, parallel oriented' build. (proprietary platforms unfortunately didn't make compiler source available, but they all had the nonstandard restrict available ,and they had similar nonstandard intrinsics for float 4 maths.. so we weren't really using strict 'by-the-book' C++ anyway, rather a 'derivative of C++ designed for consoles')
[It's happening!](http://www.reactiongifs.com/r/2013/05/Ron-Paul_Its-Happening1.gif)
If you have defined `rustcabi x.y`, and then want to change it to, say, pass some arguments on the stack where they previously weren't, you can't do that with defining a new, not-backwards-compatible ABI.
The biggest issues are that 1.the parser panics on input that isn't syntactically correct so updating the highlighting on keystrokes wouldn't work. 2.the ast representation does not preserve white space so I have to compare the generated tokens with the original text to restore white space...this is a pretty decent amount of overhead *edit: explaining why 2 is bad
RULE #3: NO MEMES RULE #6: NO RON PAUL
Whoops. I can remove it, haha. It felt appropriate for this thread though.
As a data point: this is what [`std::string`](http://llvm.org/svn/llvm-project/libcxx/trunk/include/string) in a quite clean and readable implementation, it starts at `struct __long` (skip the `char_traits`, you'll get bored) and exposes two different implementation keyed on `_LIBCPP_ALTERNATE_STRING_LAYOUT`. 
[It does, actually! :)](https://i.imgur.com/ybgUQIr.png)
wait, what?! :)
&gt; Next time we'll dig into Rust's standard implementation of a HashMap using exactly the designs described above. Although theory time isn't quite over. Our description will feature a novel theoretical result for robin hood hashmaps! AAAH! And now I'm left hanging :( I remember reading about Robin Hood Hashing on Sebastian Sylvan's blog: - http://sebastiansylvan.com/2013/05/08/robin-hood-hashing-should-be-your-default-hash-table-implementation/ - http://sebastiansylvan.com/2013/08/05/more-on-robin-hood-hashing-2/
I think there are multiple reasons to use linked lists, but the top most reasons I can think of: 1. In a class describing the hash-map, you don't want to get into the details of manipulating a dynamic array and inserting/erasing elements in it (or splitting it in two) 2. Linked Lists being node based containers, you get memory stability at the cost of higher memory/CPU overhead
That's cool, and this is indeed a case where cmov is probably better than a branch, but it's still a lot slower than not branching at all: http://yarchive.net/comp/linux/cmov.html. So if you were to implement that in C++, you'd be paying quite a bit for just handling the null case, whereas with a branch you'd pay a bit more but be able to handle 1-23 as well. So I still think this is relevant to an argument about tradeoffs (unless there is a straightforward cmov representation that doesn't require other changes that increase code size or change other methods, making it a clear win over the branching variants, but strcat argued in the thread that this wasn't the case for most operations).
In the same vein Cuckoo hashing gives you a good idea at what's going to happen when a collision occurs.
The HashMap `get` function signature is as follows: fn get&lt;Q: ?Sized&gt;(&amp;self, k: &amp;Q) -&gt; Option&lt;&amp;V&gt; where Q: Hash&lt;H&gt; + Eq + BorrowFrom&lt;K&gt; It looks like you have to fulfill `BorrowFrom&lt;K&gt;`. `K` is defined on the HashMap struct as the key type: `pub struct HashMap&lt;K, V, S = RandomState&gt;`. In your code `K` is inferred to `Rc&lt;String&gt;` via `h.insert(z, "world");`. I could be wrong :P.
This did indeed work. Thanlks!
Ah yeah, that works thank you again!
&gt; Maybe I'm missing something, but if you have a perfect hash function, you won't even have to use the collision resolution algorithm, right? Actually, you might, depending on the said hash function results' domain. Specifically, if the range of the result is superior to the size of the array you use for your hash table, then collisions can occur. Now, if your hashmap is static, this should not happen, however if your hashmap is used to store *some* elements of a pretty big collections for which a perfect hash function has been determined, do you really want to have an enormous capacity for just a few dozen elements?
The average, however, is not necessarily the most interesting case. It is expected that standard libraries collections will perform well *in general*. It is not expected they will be the fastest, or most memory efficient, but it is expected that their *worst case* behavior be "reasonable", and that is what make them a good default.
Yes, and? If you change the abi anyway, you won't be able to do things backwards compatibly, not just if you redefine the abi.
Great! Now why the heck are there separate "su" and "bscribe" buttons? :)
It's okay, this is a pretty silly thread. :)
To be clear, I'm talking about the ABI of things explicitly *without* a `repr`or `extern "foo"` (where "foo" != "Rust"). Maybe we'll get to the point where we want to declare the "Rust" ABI stable, but if we do, it certainly won't be for quite some time.
Well, yes, but more precisely because there are still a lot of sensible ABI changes and language changes that might change the ABI that we should make...
Also, a lot of color combinations, when layered together like that, are profoundly ugly, even while still "legible". This is, of course, somewhat a matter of personal taste, but if background color variations were an option I'd probably turn it off for this reason.
Syntax highlighting in general is very subjective. This is why editors typically have many options for different styles. Do you prefer light backgrounds with dark text, or dark backgrounds with light text? Do you want bright, candy colors, or pastels, or deeper shades? How about some things being bold or italic? Some people even prefer not to use monospace fonts. Any option on any of these will be "brilliantly readable" for some people and "distracting and annoying" to others. So I think this variable name highlighting thing would have value for me, and a lot of people, but certainly not for everybody.
I can't think what copyable closures would be used for off the top of my head - any examples?
The "hack" `as_string` might actually allow you to solve this one without allocating anything.
I disagree, because standard hash tables influence performance of the whole language too much. IMO there should be a separate "dense" impl for those who really need it. While the default should be fast. See https://github.com/rust-lang/rust/issues/11783 also. Related -- language shouldn't pay cost of complex hashing for rare cases where this is needed, slowing majority of applications.
Woo, that's a fun one. Filed for investigation!
I posted a thread a few days ago with a good use case: [Thread.](http://www.reddit.com/r/rust/comments/2s08aa/cloning_unboxed_closures_which_own_their/) tl;dr I'd like to be able to set up what amounts to a function of push-based iterators, which requires either boxing a closure, making an ugly closure factory macro, or cloning a closure (which appears to not currently be feasible). Put another way, such a thing would enable me to do something like let iter_source = some_source.map(...).filter(...); // iter_source gets turned "inside out" and produces an iterator which represents the transformations I configured above for x in iter_source.iter() {...} // iter_source is re-usable and will produce the same results each time I call iter() for x in iter_source.iter() {...} 
Oooor...you wrap it in a nested function.
Definitely close, though unfortunately that would then require an intermediate allocation for the result Vec each time I call bar. With copyable closures you can keep everything stack allocated/lazy the entire way.
Edit: Oh, well here we go, [https://github.com/rust-lang/rfcs/pull/17](https://github.com/rust-lang/rfcs/pull/17). Definitely. In effect the iter_source would have a type kind of like Filterable&lt;Mappable&lt;T&gt;&gt; and calling iter would give you a Map&lt;Filter&lt;T&gt;&gt; (Purposely omitting all the other type args for clarity) It's the same relationship between IEnumerable and IEnumerator in C#. IEnumerables yield IEnumerators with IEnumerator being the equivalent of Iterator.
Maybe then we can use text shadow instead of rectangle background?
[OF HAPPENINGS!](http://i.kinja-img.com/gawker-media/image/upload/s--R8KdN2uy--/b3lwel2bxruoq2nxkcyn.gif)
&gt; Stack allocation for small strings is free (bump the stack frame pointer by a compile-time computed offset). Any allocator including jemalloc is going to be more expensive than that. A second point is for example building a Vector or a BTree of heap allocated strings, where for every string you inccur two heap allocations, one for the string object, and one for the string buffer. With SSO you go from N2 calls to the system allocator to N calls, for small strings (23bytes in C++, probably 24bytes in Rust since the strings are not null terminated). I guess that going from N2 to N calls to jemalloc is still going to be a big deal, but someone should benchmark/profile this in a larger application (e.g. servo?). As pointed out [elsewhere](http://www.reddit.com/r/rust/comments/2slcs8/small_string_optimization_remove_as_mut_vec/cnrkzw5) the allocation counts in this paragraph are not correct. &gt; probably 24bytes in Rust since the strings are not null terminated The length and "is it SSO?" has to be indicated somehow, which takes a byte.
Only works as `h.get(&amp;as_string("Hello").clone())` which I think is the same as using `h.get(&amp;"Hello".to_string())`.
An empty string can actually just have its pointer set to that static `""` to begin with, no branches/cmovs necessary (except at destruction). This is basically what Rust does to ensure non-nullable pointer optimisations work.
&gt; it basically has to exploit a trick with the most significant bit, AFAICT What do you mean by this? I think one can place the capacity in the first field of the `String` (or last for the appropriate endianness) and then use the high bit of first byte (resp. last) as a sentinel, since allocations are limited to take up at most half the address space anyway. The rest of that byte can also be used to store the length of the SSO.
I'm a new subscriber, not really deep into rust yet but I've been checking out progress of the language to see if I can come up with a neat project. Congrats
It will surely happen if Rust sees any amount of success. But not for a while...
I'll use a [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) of 1 or 2 as a reasonable proxy for "could be easily confused". The simplest list of identifiers of a big project I have is all the defined Emacs variables, ~7500. Of those, ~1100 (so ~1/7) have global duplicates, and any identifier that has similar partners, on average has ~4 of them. (My Ruby script has slightly higher values, mainly due to stuff like iterators.) I dunno how to estimate adding "...and mixing them up wouldn't create a warning anyway, due to type mismatches etc", so this is an overly pessimistic estimate, but probs not by much. I tried to math out how bad mismatches would be, but got confused along the way, so I just ran a simulation. :) (I've been trying to work out a reasonable algorithm that maximizes color distance between similar names, and doesn't cause your colors to shuffle radically every time you add a new variable, but it seems fairly tricky so far... So we stick with a simple hash.) \# colors | % mismatches (of possible mismatches) ---|--- 5 | 30% 8 | 20% 10 | 17% 20 | 9% 50 | 6% 512 | 0% 4096 | 0% So for more realistic color numbers, you're gonna get **a random mismatch for similar names every 1-2 out of 10 variables**. Still, you'll *completely avoid* mismatches most of the time, even with just a simple hash algorithm. That's promising! Added further experiments to my todo.
Right, this makes sense. So, since we can't express the general case of "if A borrows from B and B borrows from C then A borrows from C", maybe one could work around it by making my own type, something like: type MyString(Rc&lt;String&gt;); impl BorrowFrom&lt;MyString&gt; for str { /* ... */ } 
Could you also overload on *? Or more generally, just make `dot` the trait itself: trait Dot&lt;RHS&gt; { type Out; fn dot(&amp;self, rhs: &amp;RHS) -&gt; Out; } ...and impl: Dot&lt;Vector&gt; for Vector { type Out = Vector; fn dot(&amp;self, rhs: &amp;Vector) -&gt; Vector { .. } } Dot&lt;Normal&gt; for Vector { .. } Dot&lt;Vector&gt; for Normal { .. } Dot&lt;Normal&gt; for Normal { .. }
Note that for this particular usecase, the Borrow API we migrated entries to for a day before reverting would have done the job, I think. It would allow you to make an Entry with an &amp;str, and only clone it to make a key to store if you `insert`. Unfortunately this meant *disallowing* by-value keys in the Entry API (because we don't have a satisfactory abstraction for both at the moment), which broke too many things.
I've been doing fold() for that *forever* because you have to import sum() and because, without reading the documentation cover to cover, there was no way to discover that to begin with. :| sum() needs an advertising campaign. Actually, I kinda thing pretty much all those things do. :)
 let opt_closure = closure as *mut Option&lt;F&gt;; Hmm, does that seem right? It's not a pointer to an optional closure. Perhaps it should instead be a `Option&lt;&amp;F&gt;`? If I try to run the code as is it panicks, but this works: let opt_closure = (closure as *const F).as_ref(); let res = opt_closure.unwrap()(a as i32, b as i32);
&gt; Importing traits generally follows Rust's desire to be explicit, and is a simple way to reduce name conflicts. It's not a clear-cut win to remove it. It's a major source of irritation that will shortly be faced by everyone, and there is no solution to it. And as far as any user is concerned, the fact that the `impl` is right next to the `struct` is explicit enough. It's a very clear-cut win, especially since the set of cases where a name conflict is even *reasonable* is quite small (I do not consider the possibility of malice to be significant here). And if it does happen? Worst case, something fails to build and gets fixed.
Oh my gosh - the amount of pain I went through with glfw-rs' callbacks was astounding. Thank goodness for unboxed closures!
I claim prior art! :) https://github.com/mzabaluev/grust/blob/2920e89d7ad38feb8a76828403c98ccea5397f30/fauxgen/gio.rs#L201 Thanks to the author for this writeup.
Well I pulled this pattern out of the standard library, so I can't take credit anyway.
Why? That's weird.
How would that function?
I generally like this idea of distinguishing identifiers and using bold for keywords (and maybe bold for symbol definitions)... I also like grey comments. But changing backgrounds per identifier would probably be taking it too far IMO. a consistent random hash giving symbols the same hue wherever they're used would be enough I think. Having said that, I've been after tinting the background per source file. Maybe symbols could be tinted according to their module... whilst the source of that module takes that tint for its background colour? Might be useless because colour perception is very relative. if you had symbols tinted by a consistent hash, and the symbol *definition* was bold, perhaps that would be enough for it to jump out and visually relate.
What do you think about using something like css text shadows (assuming text editor rendering is browser based, like servo) ? That would be less in-your-face than rectangular backgrounds. Your idea about coloring per module is intriguing, I admit.
I had a similar problem, see here http://www.reddit.com/r/rust/comments/2r6odl/battling_sauron_the_borrow_checker/
As mentioned by the dbaupp if it's just an empty string you can actually forgo the conditional move entirely; the conditional move kicks in when you start writing characters, and indeed it is probably not free (and I would tend to trust strcat on that).
Yeah, I also wondered about that...
I disagree with you and agree with Rust developers on this one. It is much more important than the default be correct/safe, than it be fast. As an example, I invoke `operator[]` which is unchecked in C++ and responsible for an unreasonable amount of memory security issues simply because people type `[]` by habit... *even when its performance is not necessary at all!* Given two population of people, beginners and experts, it is important that: - beginners be offered code that just work - experts be offered high performance code Among the two, only the latter will know the language inside out, and research their topic, and therefore it is better for the language to default to "simple code that just work" and propose high performance as an alternative. Of course, it's also implicitly assumed that the "code that just work" will be made as fast and memory efficient as possible while retaining its correctness/safety properties.
Well, says 8.050,000,000,006 in German. Dunno if there's a way to go around that though.
It isn't. It's used internally by the compiler and only distributed because of that. It's marked unstable, and can't be used outside of the nightly/beta channel.
The unstable situation is a bit unclear though, with a lot of stuff in libstd marked unstable. -- users might not understand the difference.
This probably isn't the correct place to discuss this, but is [this](http://doc.rust-lang.org/core/str/trait.StrExt.html) the kind of thing that you would like usage examples for? I don't know if they are too self-explanatory or if it should be documented on the ``str`` implementation.
https://github.com/rust-lang/rust/issues/21297
&gt; I know that I'm just using the `file_name` find the file, so it can be 'thown away' after, but i've no idea how to notate the lifetimes for that. It is fine, because you cannot! I meant that your code is equivalent to the following... pub fn read_file&lt;'a&gt;(file_name: &amp;'a str) -&gt; Vec&lt;Line&lt;'a&gt;&gt; { ... } ...which is clearly incorrect. But it is the *only* way to annotate lifetimes in the sane way. The other case, when `file_name` and `Line` have different lifetimes like... pub fn read_file&lt;'a, 'b&gt;(file_name: &amp;'a str) -&gt; Vec&lt;Line&lt;'b&gt;&gt; { ... } ...is very uncommon and cannot be done safely as you've expected. (There are some `unsafe` functions that have such output-only lifetimes, but this is not encouraged for the obvious reason.) The morale of this story is that you cannot return `Line` from `read_file` at all. &gt; I though[t] that's what the `.push()` stuff was doing? You are only pushing references to the string slice. Copying in Rust is, with a fair exception of primitive types, never implicit.
crates.io uses an interesting approach with their Model trait. It is far from an ORM, but very useful and minimalistic. https://github.com/rust-lang/crates.io/blob/master/src/model.rs
Another interesting feature would be macro expander. You click on a macro call and it reveals to you code that macro is supposed to generate at compile time. That would be really useful.
True _when used right_. In C++ it is actually pretty easy to write a loop to _push_ (as in `push_back`) "single" elements to a tree or a list such that appending N elements requires N heap allocations. It is possible to append N elements with a single allocation as you say. This is what I had in mind when I wrote N^2, but of course, there are better ways to do this. 
`f(x)` returns an rvalue, and unlike C++ (which is its own special snowflake about this), Rust doesn't have first-class lvalues, so you can't ever do something like `v(i) = x;` or have `&amp;v(i)` point to the actual element in the vector. This works right now because `v[i] = x;` is `*v.index_mut(i) = x;` and `&amp;v[i]` is `&amp;*v.index(i)` i.e. `v.index(i)`. In other words, the indexing methods return references which are *dereferenced* to get at the lvalue. You can't do that with a function call in Rust right now, and likely never will (not in 1.0 anyways. first-class lvalues are a non-starter in the current design).
More than that actually. The idea proposed is roughly to give up uniqueness and allow one to disambiguate explicitly if necessary (maybe also be able to provide a unique default impl). Eventually even unifying traits and modules, but that's a long story.
We dropped the ball on recording video, sorry :/ I hope you like the slides though, and find me on IRC if you have questions :)
The question is not mine, I just thought it was interesting to share here :)
You can check out my slides about [rustc internals](http://kmcallister.github.io/talks/rust/2015-contributing-to-rust/slides.html).
This is really hard because there's tons of ways to slice it. It also depends on what kinds of things you've done in the past. Honestly, you shouldn't worry too much about it, just learn the concepts as you go. :)
You should be able to make a generated parser. Rust's grammar is almost enitrely context-free, and in general, has a low `k`, though I forget what it is, exactly.
The language features are largely in place, some libraries are still changing. What you learn today conceptually will be the same, just some functions might be renamed and such.
You might want to ask /r/rust_gamedev too, but I think an ECS is the preferred answer here. There was a thread about this very recently...
Thanks for your answer. I guess you were refering to [this](https://github.com/HeroesGrave/ecs-rs) I just thought there is a more direct approach for this
True, the performance of the hand-rolled parser is impressive. Syntax errors in Rust are almost instant. I think it's also a matter of bootstrapping the language. For a long time, Rust didn't have the features necessary to support a nice embedded parser library. And maintaining a code generator like YACC would be a lot of work with the language a moving target. Luckily it *won't* be a moving target too much longer. I think a major cleanup of libsyntax is a high priority post-1.0, and a necessary prerequisite for steps towards stabilizing compiler plugins.
Thanks to both of you!
A few concepts you'll want to be familiar with (not an exhaustive list): * pattern matching * option type http://doc.rust-lang.org/std/option/ * result type http://doc.rust-lang.org/std/result/
if i compare this to go-lang we are a few ppl ahead :) looks like we have one or two go deserters ...
The most unfamiliar and most important concepts in Rust are [ownership and borrowing](http://doc.rust-lang.org/book/ownership.html). But I think just learning Rust is the best way to learn these concepts, even if you're looking to apply them in C++!
You should be able to do `let x = as_string("Hello"); h.get(&amp;*x)`.
I'm very interested. I'm going through the source and it could use some documentation. Anyway, good effort!
Rust does not have multiple inheritance, or even inheritance. However, it does have traits. If the people who implemented structs A and B were considerate enough to describe their interfaces with traits TraitA and TraitB, then you can describe the isomorphism each way with `impl TraitA for B` and `impl TraitB for A`, then any variable of type A or type B can be treated as implementing both TraitA and TraitB. If the people who implemented structs A and B did not describe their methods with traits, but directly on the struct, you would have to make up your own TraitA and TraitB with a passthrough-implementation (impl TraitA for A) and the isomorphism (impl TraitB for A).
Yeah, I think the parser limits lookahead to make sure we can write a reasonable grammar in the future. The nice thing about a programming language designed by knowledgeable people is that the gross hacks you need to get off the ground will at least have some thought put into future-proofing ;)
Thanks for your feedback. Here's a more practical example: If I had an isomorphism between PlaintextA and EncryptedA, I would like to be able to manipulate EncryptedA by ignoring it and only writing code that operates on PlaintextA. To do this, we could create a type AbstractA that represents a 'network of isomorphisms around PlaintextA' and then, after declaring AbstractA to be represented by an EncryptedA, AbstractA will always look like an EncryptedA in memory, but it will look like an AbstractA in code -- which means it is compatible with all methods or functions that accept either EncryptedA or PlaintextA. (Now it is reminding me of tagged unions / variant types, but capable of doing 'implicit casts' between the unioned parts.) Consider a pair of structs that looks like this: struct ColorRGB { red: i32, green: i32, blue: i32 } struct ColorHSV { hue: i32, saturation: i32, value: i32 } I would like to write something like this: let colora: Color = ColorRGB {red: 0, blue: 0, green: 0}; let colorb: Color = ColorHSV {hue: 0, saturation: 0, value: 0}; or alternatively: let colora: ColorHSV *as Color* = ColorRGB {red: 0, blue: 0, green: 0}; let colorb: ColorRGB *as Color* = ColorHSV {hue: 0, saturation: 0, value: 0}; so that I can do this: println!("The the color has red={}, hue={})", colora.red, colora.hue); The problem I have with using traits like that is that it seems like a lot of boilerplate. What do I do if I have 15 different color models? Implement 15 different traits for each one? Why can't I just have 14 (or more) isomorphisms and one abstract wrapper type? I apologize if I am being dense. It just seems like this could be a very clean (if inefficient) way to transparently do serialization-type stuff between systems with very different specifications.
Something like [this] is conventional when one wants to achieve something you described. [this]: http://is.gd/eX6oVs
1. is a perfect solution here: "moves" are not cheaper than copies, they're essentially the same. And they're not actually different from passing by ref, when larger than a pointer. As anedocdotal evidence, I've recently changed formatting to pass a 6-pointer-sized structure by value instead of by (explicit) reference, and the generated code didn't change. I wasted a day looking at small (noisy) benchmark differences when it turned out that the generated assembly was identical both before and after optimizations. Oh and a couple of `f32`s could be passed in one register on `x64`, which means by-ref operators would only make LLVM work overtime trying to optimize the IR to pass by value instead. **EDIT**: only now do I see that one mention of matrices. If they're heap allocated, that would be a problem, but `Clone`, not `Copy` would be meaningful there. You might also want to experiment with SIMD types for this (imagine passing a 2x2 `f32` matrix in one SSE register and a 4x4 one in just 4 of those).
Assuming I understand you correctly, I think default implementations will probably help you out. That way you could do: use std::num::Float; trait Color { fn red(&amp;self) -&gt; f32; fn green(&amp;self) -&gt; f32; fn blue(&amp;self) -&gt; f32; fn hue(&amp;self) -&gt; f32 { let (r, g, b) = (self.red(), self.green(), self.blue()); (3f32.sqrt() * (g - b)).atan2(2f32 * r - g - b).to_degrees() } [...] } The idea being that you implement the mapping from what ever color model you have to RGB, and all other functions work based on the result.
Copyable closures are useful for a number of functional programming patterns. Parser combinators and monads are standard examples but basically any "higher-order" structure (i.e., something that is built up in part out of component closures) is a good candidate. It's often possible to find alternative stateful first-order representations but there are still some patterns that doesn't work very well for without having to resort to casting and heavy use of `Any`.
I wonder if cargo is extensible enough to do this as a plugin.
In the example you give, it looks like you would need one trait, `Color`, and then write `impl Color for ColorRGB` and `impl Color for ColorHSV`.
It's useful for exactly the same reason non-failing tests are. I wrote some tests to assert undocumented behaviour for some stdlib types, and being able to assert that certain things don't compile would have been nice. Also, documentation, *especially* tutorial material, where it's good to make sure everything you say is backed up by a test, including things like "you can't do X" or "A works, but B doesn't". Also, also, things like asserting a type isn't accidentally made `Copy` or `Clone`.
While I appreciate the need to be explicit, I feel like it complicates writing decent APIs in some cases. This being one of them. I don't think it is necessarily a very large problem though. And I've already found a few ways of working around it since this was posted. So the benefits of being very explicit may outweigh any problems.
On/off switch would be easily to add to IDE. There could and should be many coloring modes.
Yeah, it'd be very inconsistent to introduce auto-ref here and not elsewhere, although I think it might not be such a bad idea for non-mut autoref everywhere.
I'm personally a big fan of "make borrowing explicit", and it seems to me like auto-ref everywhere would really ruin that.
I would be completely OK (and maybe in favor) of explicit borrowing, if there was a way to easily implement the operators. The current way of implementing the same trait 4 times is really counterintuitive. If we'd get a way of simplifying that process, then the explicit `&amp;` would not bother me.
Looks nice, and glad to see system code not mixed with components! I'm not sure about the entity partitioning system though, does this mean things between "spaces" can't interact? Seems like in general you want to leave partitioning up to the user because of all the special cases.
Graydon's benevolent influence carries on. Good stuff.
I'm a big fan of implicit non-mutable borrowing. It's a clear ergonomic win and doesn't introduce any surprises, as long as mutable borrows stay explicit. It is unclear to me why inspecting a value should require special syntax, while transferring ownership (which invalidates the value) doesn't.
Thanks. `String::new(line)` didn't compile for me, so I went with pushing `line.to_string()`
Thanks, I think I got it now. I've changed `Line` to be a String, and push a copy of any lines with `push( line.as_string() )` inside `preprocess()`. It occurs to me that this will lead to a load of allocations. use std::io::File; pub struct Line { pub content: String, } pub fn read_file(file_name: &amp;str) -&gt; Vec&lt;Line&gt; { let path = Path::new(file_name); let s = File::open(&amp;path).read_to_string(); let rtl : String = s.unwrap(); let lines = preprocess(rtl); lines } fn preprocess(s: String) -&gt; Vec&lt;Line&gt; { let mut res: Vec&lt;Line&gt; = vec![]; for line in s.lines_any() { match line { "" =&gt; {}, // discard empty lines _ =&gt; res.push(Line{content: line.to_string() } ) } } res } Any comments (or rewrites) would be greatly appreciated! 
Nice work! 
That's really odd! The benchmark differences, I mean. Any chance you could bindiff the binaries or maybe diff the assembly resulting with, say, `-C lto`? Our benchmarking can't be *this* bad, I'm more inclined to think there's deterministic effects based on type metadata (each function has a hash appended to its mangled symbol name, and the hash includes the type signature of the function). I've heard before about pseudorandom link order causing binaries compiled from the same code to differ, not sure if we've solved that in any ways, though that's not as relevant here.
How would this ergonomic improvement work in generic contexts? As you know, I didn't particularly like [the decision](https://www.reddit.com/r/rust/comments/2mwdhn/weekly_meeting_20141118/cm9eefb?context=3) to go for pass-by-value. And I'm still trying to make peace with it. From what I can tell, the only thing that seems to be staying in people's way (in terms of being able to write generic code that is actually *generic*) is that we cannot *yet* rely on an author of a user-defined type `T` to also offer things like `&amp;T: Add&lt;&amp;T, Output=T&gt;` because nobody told them that this would be a good idea and because built-in types don't yet lead by example. It would be pretty sweet to have [this kind of uniformity](https://github.com/rust-lang/rust/pull/21227). But it would not solve the ergonomic problem. :( 
Adam, who sort of started this thing, [recommends here](http://t-machine.org/index.php/2007/12/22/entity-systems-are-the-future-of-mmog-development-part-3/) (first comment) that component storage should be separate from systems. But he agrees that programmer should be able to modify storage principles: &gt;[D]on’t store components inside the systems themselves; only private/system-only data lives there. &gt;Instead, make a global Entity Manager / Component Manager that has all of them. Internally, it can optimize each different component different ways (if you hardcode it to do so(, but externally it offers interfaces that should hide all this implementatio detail. I don't necessarily agree with everything he says, but this looks like sound advice. I personalty think it is more important how you store groups of components (e.g. position + collision body + velocity), since it often makes more sense to iterate groups of components rather than single component type. At least to me. Unfortunately most implementations don't think much about ways to group components together.
Does the `Add` trait have any semantics? Are there any laws which `impl`s are expected to adhere to? If not, why would you want to write generic code over it?
What about making a single component out of your group ? #[sparkle_component] pub struct Physic { pub position: Position, pub body: CollisionBody, pub velocity: Velocity } What would be the benefit of having some group system over this method ? Would providing a storage trait and our default implementation of it be enough to give the needed flexibility ?
The thing is, one component may need to be grouped in multiple ways for multiple systems. For example, *position* also needs be grouped with *sprite* for graphic system (and graphic system doesn't care for collision or velocity). I can't think of a satisfying way to solve that, I am just pointing out that it is important. Can sparkle do that? Another issue is linking foreign entities via component. Obvious use case is inventory. To create inventory every item needs to have owned_by component that contains owner_id field. But the only way to list player's items is to iterate over all owned_by components to find all items belonging to that player. That's inefficient if you have a lot of players or if NPC's can own items. So there should be some sort of querying system that maintains separate list that groups all entities that have owned_by component by owner's ID. That functionality would also be needed for things like selection (in RTS) or for homing missiles. It is tricky as hell.
The internals are the result of a couple of rounds of trial and error making the type system understand how this is supposed to work. I'm not entirely happy with the structure there, so I did not bother to document it yet, as I hope it will change into something nicer. However, you are right that it ought to be more transparent what it does. I'll look into this.
I do need all four, if I can't return a reference as the `Output` of the arithmetic traits. This is the way I was doing it: impl&lt;'a&gt; Add&lt;&amp;'a Vec2f&gt; for &amp;'a Vec2f { type Output = Vec2f; fn add(self, rhs: &amp;Vec2f) -&gt; Vec2f { Vec2f { x: self.x + rhs.x, y: self.y + rhs.y } } } This if for the double ref case, the rest would be just variations. The problem with this is the following: let's imagine I also have `Mul` implemented the same way: let v1 = Vec2f { x: 1.0, y: 1.0 }; let v2 = Vec2f { x: 1.0, y: 1.0 }; &amp;v1 + &amp;v2 + &amp;v3; // This needs &amp; + &amp; and value + &amp; &amp;v1 + &amp;v1 * &amp;v2; // This needs &amp; + value &amp;v1 * &amp;v2 + &amp;v1 * &amp;v2; // This needs value + value If there is a better way of doing it, I'm open to suggestions, but I haven't found anything so far.
Yeah. Forgot that it is `String::from_str(line)`. I am not sure what will happen to be stabilized so I avoid `line.to_string()`
I believe the first problem is already solved by the [filter module](http://rust-ci.org/RustSparkle/Sparkle/doc/sparkle/system/filter/index.html). For example the graphic system would maintain an `EntityView` over the entities containing a `Position` and a `Sprite` component. About the inventory, I do not understand why the player couldn't have an `Inventory` component with a list of item ids to simplify iterations. Finally, A custom `EntityView`-like structure could maintain a map of owned_by ids by owned ids. Though this will require to access components with those entity ids afterward. But component access is not an heavy operation.
Yeah that is what I meant. I got that: use std::io::File; pub struct Line { pub content: String } pub fn read_file(file_name: &amp;str) -&gt; Vec&lt;Line&gt; { let path = Path::new(file_name); preprocess(File::open(&amp;path).read_to_string().unwrap()) } fn preprocess(s: String) -&gt; Vec&lt;Line&gt; { let mut res: Vec&lt;Line&gt; = vec![]; for line in s.lines_any().filter(|&amp;x| !x.is_empty()) { res.push(Line{content: String::from_str(line) }) } res } Another way to handle it would be to create a struct which contains the complete raw "string" and an array of all the lines. So you would return a struct containing the file-&gt;String and the array with the sliced up lines (as &amp;str). This could be ok as long as you do not change them later. If you want to change single lines you could try to use `CowString` or an enum { String / &amp;str } type which would let you change some lines and leave others alone. All depends on what you are going to do with the lines.
Ah, chaining is a very good point that I hadn't considered. I see the issue now.
&gt; I believe the first problem is already solved by the filter module[1] . For example the graphic system would maintain an EntityView over the entities containing a Position and a Sprite component. That's good to know. I still need to look into your ECS more closely, but it sounds good. I also must admit that I am not an actual rust expert (because I was waiting for 1.0 to seriously start learning). &gt; About the inventory, I do not understand why the player couldn't have an Inventory component with a list of item ids to simplify iterations. As someone with a database experience, this is a **very** bad idea. Because it is possible, due to error to end up with one item being owned by two players. Also it merely reverses the problem: Now you cannot easily find an owner when you are starting from owned item (you have to iterate over all inventory components). Inventory component is okay if it is there to indicate that entity can own items and to mark number of slots available. But it is bad relational approach to put any list of entities in it. 
I don't necessarily want to write "generic code over these traits directly". I just want to write generic code. This might involve other traits which add more semantics (à la `Num`). But `Num` currently forces pass-by-value for everything. So, the question remains: What requirements should such a trait have? I'm actually inclined to suggest that, if `T` implements this Num-like trait, it has to offer, for example, impls of `Add&lt;T&gt;` and `Add&lt;&amp;T&gt;` for both `T` and `&amp;T` (and similar for `Sub`, `Mul`, …). I think it's very important to discuss these things.
Alright, so the performance difference can only be reproduced, if the variables passed to `add` are declared inside of the benchmarking loop: #[bench] fn benchmark_by_ref(b: &amp;mut Bencher) { b.iter(|| { for _ in (0..100000) { let v1 = Vec4f::new(1.0, 2.0, 3.0, 4.0); let v2 = Vec4f::new(5.0, 6.0, 7.0, 8.0); test::black_box(&amp;v1 + &amp;v2); } }) } Moving them outside the loop produces pretty much the same result as my matrix benchmark: ~2% difference in favor of `by-ref`. Here are the two test cases (they won't compile in playpen because there's no main defined, but oh well): [by-ref](http://is.gd/hf2PcJ) and [by-copy](http://is.gd/dTV9JK). I compiled with: rustc --test --emit asm -O -Cllvm-args=--x86-asm-syntax=intel -C lto by_copy.rs The produced assembly (as far as I can tell) is virtually identical: [diff](http://pastebin.com/4hwRfpiU) And the benchmarks: By-copy: running 1 test test benchmark_by_copy ... bench: 3481828 ns/iter (+/- 357626) test result: ok. 0 passed; 0 failed; 0 ignored; 1 measured By-ref: running 1 test test benchmark_by_ref ... bench: 2799165 ns/iter (+/- 770631) test result: ok. 0 passed; 0 failed; 0 ignored; 1 measured EDIT: thanks to /u/mare_apertum for pointing out the obvious flaws with the first set of benchmarks. Here are the updated results (benchmark size bumped to 1,000,000): By-copy: running 1 test test benchmark_by_copy ... bench: 3379806 ns/iter (+/- 19664) test result: ok. 0 passed; 0 failed; 0 ignored; 1 measured By-ref: running 1 test test benchmark_by_ref ... bench: 2738062 ns/iter (+/- 22302) test result: ok. 0 passed; 0 failed; 0 ignored; 1 measured 
I added an example to the readme and many more to the docs, so it should be more accessible now. Thanks for the feedback, I was a bit lazy there ;)
See [this issue](https://github.com/rust-lang/rust/issues/6393). I think [there is a plan to address this](https://github.com/zwarich/rfcs/blob/seme-regions/active/0000-seme-regions.md), but I don't know what the timeline is.
"Polymorphism" has a more general meaning in functional programming, that doesn't necessarily involve inheritance / subtyping. Rust has a lot of features from that world.
Here's a related issue (as an example): https://github.com/tomjakubowski/json_macros/issues/12
Yes, I have, and no, they will not.
Also published on crates.io, basically to reserve the name ("containerof"). So far it's just a proof-of-concept. I use intrusive structures all the time professionally, and am hoping to bring a strong and safe intrusive structure library to Rust.
That's what I wanted to get at as well. If (apparently) even the traits which *are* intended for generic code like `Num` don't properly support non-`Copy` types, that's definitely a problem.
You might want to look at https://github.com/dschatzberg/intrusive - which includes an implementation of an intrusive doubly linked list. It needs some updating for more current conventions, but it works well. I am working on additional data structures. Basically I have: pub struct Links&lt;T&gt; { next: RawLink&lt;T&gt;, prev: RawLink&lt;T&gt; } RawLink&lt;T&gt; is essentially a pointer, then any element can be inserted if it impls the trait: pub trait Node&lt;T&gt; { /// Getter for links fn list_hook&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a Links&lt;T&gt;; /// Getter for mutable links fn list_hook_mut&lt;'a&gt;(&amp;'a mut self) -&gt; &amp;'a mut Links&lt;T&gt;; }
Ok, thanks for writing that up. It looks almost exactly like what I'm looking for. I just discovered phantom types too, so I might also be able to do it cleanly using those.
It's kind of a weird table, because more expressive languages -- languages that dont require features to be baked in because they can simply be written in the language itself -- look less fully-featured. In Rust's case, concurrency should probably be "no," since the language no longer has any built-in concurrency primitives; on the other hand, the standard library supports many different concurrency primitives, so "no" isn't an honest description either.
Wrong subreddit. This is for Rust the programming language, not Rust the game. You'd want /r/playrust.
STEVE IS JUST A GUY GAH (&lt;3)
Yes, that was wrong... I'm working on a linked-list on top of this library, and that'll help get the details more correct. Thank you!
I think that there's a ticket for this. The biggest thing is that it adds an HTTP call too whatever command oyu associate it with.
If you're a Chrome user there's this [personal block list extension](https://chrome.google.com/webstore/detail/personal-blocklist-by-goo/nolijncfnkgaikbjbdaogikpmpbdcdef) by Google to block such search results. I have no idea why it's a Chrome extension rather than a simple setting for the signed in user, but it works for me. Maybe there's something similar for Firefox?
It might be sufficient to add an out-of-date notice with a link to the documentation, if they want to preserve googlability.
duplicate entry, see https://www.reddit.com/r/rust/comments/2sv4uv/explore_ownership_system_in_rust/
Sounds like a PATH problem. when it works, type 'which rustc', that will point to the folder where it got installed. If it's no longer working, type export PATH and check if the install folder is in the list of paths.
Hmm wired. Looks like that `rustup.sh` is not run? Maybe try downloading the nightly tarball and manually untar it?
*groans* Right... I completely forgot that a TCP connection goes both ways! So if I don't check what is sent and answer to that the client won't stop the connection... I feel pretty silly now.
This line: bob.name = String::from_str("mutant"); The trait is `FromStr`, so I deduced that `Impler::fn()` must now be legal (in this case `String` is the impler).
`String::from_str` also exist…
This article may be a good start to learn pattern matching in Rust, though a tiny bit outdated: http://pzol.github.io/getting_rusty/posts/20140417_destructuring_in_rust/ . For example, enum has become namespace, struct variants appeared after that article. 
Great post, thanks! As a rust newbie coming from other languages the thing I'm left scratching my head about is what the right way is to make a thing and "give" it to a struct. For example in Obj-C it's totally clear that if you alloc something and assign it to a class' strong property it will hold on to that thingy for you—or in Java if you instantiate a class and assign it to something else's instance variable that will increase its reference count and it will stay in memory. (Edit: or to pick a closer relative like C - that you can malloc something, leave a pointer in a struct and consider it that struct's module's responsibility to deal with it.) I'm not sure if this is in the scope of your posts (maybe it's part of borrowing?). If it is I think it would be a really useful example. :)
Ah, I think I'm slowly starting to understand. Cloning was actually the first thing I tried, because I solved a similar problem by doing so, but that didn't work in this case because Process doesn't seem to implement clone. But if I'm understanding correctly, it's *supposed* to work that way because it wouldn't be safe otherwise. Once it's wrapped in Arc and Mutex, *then* I'm able to use clone. That seems like it would make sense, because yes, I'm trying to access the process from 2 threads. I still haven't gotten this completely working in code yet, but I'll have some more time to play with this soon. Thanks for introducing me to Arc and Mutex. Seems like that's the key.
&gt; The triviality of this implementation is a big deal. If we compare this to the solutions in other languages, they do one of the two things. They either leave it up to you to clean up the memory (with some horrible `delete` statement someone will forget or call twice), or rely on garbage collection to track memory pointers and clean up memory when those pointers are no longer referenced. This is incorrect, there are smart pointers in other languages, e.g. `unique_ptr` in C++ is very similar to `Box`.
Ahah, I've experimented and see now that that works. Thanks very much. https://gist.github.com/anonymous/89639deebac71cc344d6
You are right, i probably was a bit overenthusiastic - i will fix it up later. But i like moves as the default behavior.
I like that now bors reports only failed tests. Nice touch: on test failure bors heart [is broken](https://github.com/rust-lang/rust/pull/20874#issuecomment-70459158) The only drawback so far is that approved PRs in queue aren't highlighted ([ticket](https://github.com/barosl/homu/issues/28)) 
Even to a tree? How does that work in Rust? In C++ appending N elements independently to a tree (std red-black trees) requires appending N tree nodes, and thus N allocations, one for each node. If then each element allocates memory by itself for their buffers, you end up with N^2 allocations. Do you have a link to where I can learn how this works in rust?
&gt; Some professor or class probably used rust v0.11 at one point. The docs are actually v0.9.
Ah well. What a shame.
2 more things: - The Box&lt;T&gt; was not needed in this particular example; - Person can only be used in one place; you can use Rc&lt;T&gt; instead which makes same person cloneable (and still pointing to the same object). References have this nasty side effect of locking objects in place - if you create a reference to any object in the hierarchy, the whole hierarchy can not be moved/destroyed while that reference is active. Well, obviously, because otherwise the reference would outlive the object or point to wrong memory.
`Thunk`/`Invoke` only apply to using `FnOnce` as a trait object, so I don’t think they would be needed. The closest thing we have to documentation on unboxed closures at the moment is the RFCs (there have been two; the first one describes the main ideas, the second updates the syntax and adds `move`): [RFC 114](https://github.com/rust-lang/rfcs/blob/master/text/0114-closures.md) and [RFC 231](https://github.com/rust-lang/rfcs/blob/master/text/0231-upvar-capture-inference.md).
Explicitly managing callbacks to handle events causes a ton of problems with inconsistent mutable state, missed events and race conditions. I experienced my fair share of trouble with them. This is why smart people have discovered [functional reactive programming (FRP)](https://en.wikipedia.org/wiki/Functional_reactive_programming), which is a less bug-prone and more composable way to handle events/callbacks. Now I'm going to shamelessly advertise: coincidentally I just decided to implement [FRP primitives](https://github.com/aepsil0n/carboxyl) to use this paradigm in Rust. Regarding your question: it deals with `Fn` closures, since it has to call them multiple times. Values that change over time are explicitly wrapped as its own type, so you don't manually mutate any state, therefore no `FnMut` closures. If you'd allow them, they would bring back the problems mentioned above. Internally the library uses trait objects and atomic ref-counting to ensure the integrity of the callback structure. I am not yet entirely happy with the internals yet, as they are a bit messy (mostly due to trait dispatch), but I don't think the fault is with the language.
Well, I would reduce this to saying that `x + y` is the same as `Add::add(x, y)`. In that perspective `x + x` for a non-copy `x` simply violates the ownership and borrowing rules. Granted there is some mental overhead properly impl'ing `Add` for a non-copy type. But I'd argue that this actually gives you more flexibility to avoid unnecessary clones.
No; it rather implies that the language is expressive enough to write concurrency primitives as a library, instead of needing special language/VM support.
Ok, so a `move |&amp;: |` closure can be stored in a variable of type `Box&lt;Fn(...) -&gt; ...&gt;&gt;`? That would still mean one extra allocation, which maybe is not the end of the world, but for me coming from C, it still feels like some extra overhead. Is there a way to avoid the extra box allocation here? (If you don't box it, then I assume it would be unsized, which causes all kinds of trouble...)
Congrats to barosl for this fantastic work! Seeing community members take the initiative like this is tremendously satisfying. :)
spark like framework would be nice. But it needs “akka for rust” first.
Given MIT's refusal to budge on this issue, it's amusing to consider that serving them a DMCA takedown might be our only option. Or we could try to physically break into their servers... I wonder if anyone's ever tried that before?
Of course it does. I still would like to use the operators. So, if I want to be able to write the expression `x + y` or `&amp;x + &amp;y` the generic function would need an `Add` requirement *somewhere*, directly or indirectly via some `Num`-like trait. And ideally it would have the same syntax as for built-in types (`x + y` where the type of `x` and `y` implements this `Num`-like trait). But that's a path that will require unnecessary clones here and there and that's what I don't like about the move towards pass-by-value (i.e. *consuming* operators). If you have a satisfying solution for this problem, I'm all ears. The way I see is is that we (1) either define something `Num`-like which provides at least two versions for binary operators (consuming and non-consuming w.r.t. operands) and live with the ugly syntax (explicit borrows in case we want to keep the values and don't have them consumed) or (2) go back to pass-by-ref operator traits that never consume their operands and don't require these ugly explicit borrows.
you should install gcc, make, bison and probably other development tools to build rust in ubuntu.
I just tried to expess such a `Num` trait and noticed that it's not possible right now! You can't define a trait that also constraints `&amp;Self` to implement anything! :-( To be honest, that's a very discouraging observation. And it makes me want to say "I told you so!" to everybody who brushed off the move towards pass-by-value op traits with "well, you can implement Add for references, too". Well, yes, I can. But it does not scale and I can't even define a friggin `Num`-like trait that allows me to write fn haar_transform&lt;T: Num&gt;(x: &amp;T, y: &amp;T) -&gt; (T, T) { (x + y, x - y) } :-( 
Whoa, gotta try this! I was just pondering whether to implement the first version of my little pet web project with Go, given Rust's early state with web-related things, but maybe this will help :)
I emailed the people who run Athena. It wasn't a student with a stock answer.
This is great!
That's too bad. I assume they didn't really care? Because then my next suggestion of _adding_ docs for 1.0 to their system won't fly either :) Well, except for hoping someone will make a course with a newer version of Rust.
Rust prioritises explicitness of implicitness. Implicit type conversions are a wonderful source of subtle, hard to see bugs. In this particular case, you could *theoretically* do it safely given that you know, statically, that `y` will be `1000`... but that's more about poking holes in the general strategy of "no implicit conversions". I believe there are discussions at the moment to allow *widening* conversions, but those can still introduce subtle problems (usually along the lines of a promotion happening *after* an operation that loses information rather than *before*).
That's N+N allocations, not N*N.
How/why is DMCA applicable here?
`Rc` does not avoid this feature of references. It just creates an implicit `Box` so that fixed location isn't on the stack. In most cases, you can replace `Rc` with a regular reference by just splitting up the creation of the value and the referencing of the value into two steps (so you create it, hand it down to the lowest point on the stack where you'll need it, and then reference it). This is one of several reasons I usually recommend against reaching for `Rc`.
I actually found a way to get around this, but it's not a very beautiful solution: [playpen example](http://is.gd/6Oh5qv). 
IANAL, but MIT is violating the terms of the Rust license by publishing only the documentation itself without reproducing the license alongside of it. By failing to conform to the license requirements they void all protections given to them to copy the documentation in the first place, which means that any copyright holder (which is to say *anyone* who has ever contributed to the Rust documentation as of 0.9) is within their rights to assert their copyright and issue a takedown notice. Of course, MIT could also reproduce the license on every page in order to regain their legal right to distribute copies. But I'm guessing that this whole situation is not a case of "we really want to publish the Rust 0.9 docs" so much as it's just a lazy sysadmin who has no incentive to take them down.
FWIW, this is precisely the same conclusion I came to as well. I guess HKT would subsume this, but really, all you need is to be able to write polymorphic code over lifetime parameters. I'm not sure if that translates into a simpler implementation than HKT though...
Or even just use the builder pattern, and you wouldn't have to create and export/import a new type: let mut encoder = Encoder::new(&amp;mut io::stdout()) .disallowUtf8Atoms() .largeAtoms() .FairNewFun() Unless you have to deal with those options more than just at object creation time, this seems cleaner to me.
He talks about i64 and i32 though :)
The same logic applies to i64 and i32.
You can explicitly tell the compiler to convert y: fn main() { let mut x = 10i32; let mut y = 1000i64; x = y as i32; } although I don't recommend it.
If a potential contributor is put off contributing entirely because a non-representative reddit user in /r/rust has an offensive nickname, not only is that contributor not sensible, but they will also probably present big problems later on in their ability to take criticism, or deal with other real world concerns.
Incremental compilation would be great, but isn't going down to each top-level type/function/constant a bit complicated? In C or C++ incremental compilation is done on a per-file basis, where a file depends transitively on its includes. I could perfectly imagine a scheme in Rust where a file depends on the files referenced by the `use` clauses it has (beware, there can be `use` clauses at various levels and some can be elided with `cfg` attributes). Of course, it would not be as fine-grained; however it could occur prior to type-analysis, only the AST is necessary to collect the various `use` clauses. Also, regarding optimization, I think that defaulting to a single big LLVM IR for inlining at crate level is quite important for "Release" code (O2 and more), on the other hand, though, in "Debug" code inlining is an enemy which mangles the stack. The distinction seems important to me because Debug and Release target different needs: - Debug: build fast, I'd like to check if that works (or understand why it does not) - Release: build a fast library/binary, take your time if you need to
Yes, I am thinking that this might actually be a good example for the second part.
You don't have to `use` something to refer to it, though - you can always use the fully-qualified name.
If iterating over groups of component is the most common case, then you're going *way* overboard in subdividing things into components. Just make the components fatter. The common case by far should be that you're looping over just a single component at a time. That's the only way you're going to get any performance out of this stuff - a simple easily-parallelizable loop that doesn't have to do a bunch of work to "gather up" all the inputs. You really don't have to group components "from the outside". That's also just over-engineering. If you need to process Position and Velocity together then make a PositionAndVelocity component for use by entities of that type. Yes it's somewhat redundant if you already have a Position component, but there really aren't that many combinations in practice so it's not a real problem. And the actual redundant processing can usually be shared (e.g. if you have a loop that just touches positions, then you now have to write a second loop that pulls out the position out of the PositionAndVelocity component and calls into the original processing code). This is all especially true in Rust with traits that can be used at zero cost. Make HasPosition trait and write generic code over that trait and you don't even have to duplicate anything. An overly complicated solution is worse than just doing the simple thing to solve the problem, even if it's inelegant in some theoretical sense. *Especially* if the complicated solution ends up hiding details that are crucial to get good performance, or introduces a bunch of extra processing to be "helpful" (e.g. a complicated "system" for gathering up groups of components), 
Well, it would need to be cleaned up a bit first; I am afraid the author is both a tad too enthusiastic and not a native speaker (or maybe I not being one makes thinks so?)
I admit that it was kind of easy way to name it "garbage collection". How you would suggest to introduce it?
Maybe talking about "Shared Ownership"?
You have to do `box move ...`, but yeah. It's an extra allocation, but that's what happens with closures anyway, in most languages. They're unsized types since they capture an environment and also have a function body, which in Rust's model is called via dynamic dispatch on the trait (unless you use `T: Fn(...)` and then you'll get static dispatch)
I updated it a bit following your advice: http://nercury.github.io/rust/guide/2015/01/19/ownership.html#garbage-collection I still wanted to communicate the idea that it is possible to build your own memory management tools as-needed. I see that as a strength of Rust.
Yes, you are correct, I am not a native speaker - any help with editing would be appreciated :). So I kind of do not agree with book suggestion myself - I am still learning to write... The post is here: https://github.com/Nercury/Nercury.github.io/blob/master/_posts/2015-01-19-ownership.markdown
Generally you have two options: - Transmute one type into another. - Cast a pointer to one type into another. You can look at both variants here: http://is.gd/bF87lx 
I don't think "shared ownership" is really a good description, even though it's a common one. It's confusing. It suggests there is something special about times that `Rc` is used where you need "sharing", rather than the truth (which is that it's there to perform GC). It implies that you should be able to mutate its contents (since that's what ownership means in other contexts) but, in fact, you can't unless the reference count is 1 (i.e. the ownership isn't shared). I think *not* treating it as GC is what leads people to often attach a `RefCell` to it, because they expect to be able to mutate something with "shared ownership." I think for newcomers, it also implies that `Rc` is for "ownership" (putting in structs) while `&amp;` is for "borrowing", when in fact you can often use `&amp;T` in exactly the same places you can use `Rc`, but with zero runtime cost and no cycle detection issues.
It's pretty permissive and seems to be the most common license for rust projects, including the compiler and cargo.
The parents entire point is that self-representation and social behaviour are _real world concerns_.
[This](http://is.gd/ObfjWs) program does more-or-less the same thing as your C++ program. It also does not use `transmute()`-like functions but it does rely on that `Point` is `Copy`. If your type is not `Copy`, then `transmute_copy()` is the way, but you usually shouldn't byte-copy structures which are not `Copy`. `#[repr(C)]` is probably unnecessary if you're not going to pass this structure across FFI boundaries.
I believe rust follows haskell here with requiring explicit conversions between types. Its a deliberate choice. In this situation its a good thing because while the conversion would be fine for 1000, its not fine for 2,147,483,648 (int32 max + 1). How will this code handle that case? By throwing an exception? By returning 1? Better to have an explicit conversion function where you know what its doing rather than an accidental conversion to i32 and back that silently destroys data. For instance if you have a formula like a + b * c / d (t + x) and all of those are int64 except for a, then that's potentially a subtle hidden bug, leading to either a runtime exception or a loss of data. 
Thank you! Exactly what i was looking for!
The rust installer should download the book. It definitely does on windows, I don't know about other platforms.
Oh great. I decided I needed to big a conceptual break from the old codebase once I got a bit in so please do move over to the cql-ffi one. Note that it is a low level unsafe API, and as soon as I get all of the examples working, I'll be first creating a very simple safe wrapper on top of it, and then higher level apis still. Happy to collaborate with anybody interested.
Unboxed closures aren't unsized. You can make them part of another type. struct Foo&lt;F&gt; { f: F } impl&lt;F&gt; Foo&lt;F&gt; where F: FnMut(u32) { fn new(f: F) -&gt; Foo&lt;F&gt; { Foo { f: f } } } fn main() { let mut foo = { let mut y = 0; Foo::new( move |x| { y += x; println!("{}", y); }) }; (foo.f)(10); (foo.f)(10); } There is an issue *returning* unboxed closures, but that is just because you cannot write their type, it's not because of some fundamental limitation on them. It is a high priority for post-Rust 1.0 to provide a way to return them.
You can certainly run a compiler in a barbaric compatibility mode, but you *shouldn't*. #include &lt;stdint.h&gt; #include &lt;stdio.h&gt; void foo(int32_t x) { printf("x = %d\n", x); } int main() { int64_t i = 42; foo(i); return 0; } Compiled with `cl /W4 int.cpp`: Microsoft (R) C/C++ Optimizing Compiler Version 18.00.30723 for x64 Copyright (C) Microsoft Corporation. All rights reserved. int.cpp int.cpp(10) : warning C4244: 'argument' : conversion from 'int64_t' to 'int32_t', possible loss of data &gt; but you can define implicit (or explicit) conversions from custom types to any other type. Which has precisely nothing to do with the implicit conversions defined by the language. You can do any dumb thing you want in overloaded operators. 
That was very enlightening, thank you!
Found a broken link: &gt; - UFCS method calls can now be qualified by the trait of the method. This can be used to disambiguate method calls when multiple applicable methods are in scope, e.g. &lt;i32 as Add&lt;_&gt;&gt;::add(1, 2) which is equivalent to 1.add(2). **[RFC][rfcs-rfc]**. 
I don't think you can actually implement this, since I doesn't yield references of *any* given lifetime 'a, but rather of one specific lifetime 'a. This formulation requires that I is able to give out references of any chosen lifetime 'a.
Does this mean you can write `&lt;i32 as Default&gt;::default()` now too? That'd be so cool 
What was the coherence bug? At first blush it seems unfortunately limiting that one can't `unsafe impl Send` for tuple types.
What if types A and B both had trait X with static method f: () -&gt; C. Then `X::f` would be ambiguous, unlike `&lt;A as X&gt;::f`.
That last hack is both dirty and clever. Nice!
Thanks for following up!
&gt; Certain long error messages of the form 'expected foo found bar' are now split neatly across multiple lines. Examples in the PR. This was the greatest thing ever. So much easier to read these messages now!
&gt; UFCS method calls can now be qualified by the trait of the method. This can be used to disambiguate method calls when multiple applicable methods are in scope, e.g. &lt;i32 as Add&lt;_&gt;&gt;::add(1, 2) which is equivalent to 1.add(2). [RFC][rfcs-rfc]. I'm really excited for this one. Being unable to disambiguate static trait methods without some weird type hackery always bugged me.
The Summary of Korean Rust Meetup #4 is now available as a [full post](http://lifthrasiir.github.io/rustlog/summary-of-korean-rust-meetup-4.html).
Update: I've updated [cql-ffi](https://github.com/tupshin/cql-ffi) slightly, filed a couple of [bugs](https://github.com/tupshin/cql-ffi/issues) (contributions welcome - hint hint), and created a totally [standalone repo](https://github.com/tupshin/cql-ffi-example) that uses it as a dependency as a quick start. I've also published the generated [docs](http://tupshin.github.io/cql-ffi/cql_ffi/) for convenience
Put a comma at each end of the clauses
I don't think that it is really misleading. For some types of applications, I'd really want concurrency support baked into the language (e.g. Erlang), and for others, the bare-metal performance of a systems language à la C is more important. This also has to do with the way that languages evolve. Until mid-90's, libraries were more an afterthought than subject of detailed design work as we see today.
But it does not seem to work for values that have a shorter lifetime than the iterator itself? E.g. when doing buffered reading from a file, the lifetime of a slice returned from the buffer can be as short as until the next next() call (so basically a stack lifetime). StreamingIterator seems to be always tied to the lifetime of the iterator itself.
Is there a way to also `impl Iterator for Buffer`?
If you build from source: - rust/doc/index.html - same as http://doc.rust-lang.org/index.html - rust/doc/intro.html - the 30 minute intro - rust/doc/book/index.html - the book - rust/doc/std/index.html - the API documentation
That is why I said in the beginning that iterators are the wrong abstraction. My description of producer/consumer above is certainly lacking a lot, but I will try to implement an API to prove that it is a better abstraction. (Though with different limitations than iterators, e.g. zipping won't work)
Michael puts a lot of work in reporting what's going on in the open source world. 
Ideally, we will have a respectable benchmark like [SPECint](http://en.wikipedia.org/wiki/SPECint) for Rust in the future. At the moment, creating a good benchmark for Rust compiler is impossible, because we don't know what typical Rust programs look like.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**SPECint**](https://en.wikipedia.org/wiki/SPECint): [](#sfw) --- &gt; &gt;__SPECint__ is a [computer benchmark](https://en.wikipedia.org/wiki/Benchmark_(computing\)) specification for [CPU](https://en.wikipedia.org/wiki/CPU) [integer](https://en.wikipedia.org/wiki/Integer) processing power. It is maintained by the [Standard Performance Evaluation Corporation](https://en.wikipedia.org/wiki/Standard_Performance_Evaluation_Corporation) (SPEC). SPECint is the integer performance testing component of the SPEC test suite. The first SPEC test suite, CPU92, was announced in 1992. It was followed by CPU95, CPU2000, and CPU2006. The latest standard of SPECint is CINT2006 (aka SPECint2006). &gt; --- ^Interesting: [^Instructions ^per ^second](https://en.wikipedia.org/wiki/Instructions_per_second) ^| [^POWER2](https://en.wikipedia.org/wiki/POWER2) ^| [^RPE2](https://en.wikipedia.org/wiki/RPE2) ^| [^Benchmark ^\(computing)](https://en.wikipedia.org/wiki/Benchmark_\(computing\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cnuvsvl) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cnuvsvl)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Well, the goal here is to wrap `BufferedReader::fill_buf` inside something Iterator-like, without copying data: `fn fill_buf&lt;'a&gt;(&amp;'a mut self) -&gt; IoResult&lt;&amp;'a [u8]&gt;` This doesn't require returning pointers to a local stack frame. Rather, it returns a slice which is valid until the next call to `fill_buf` (or technically speaking, you can't call `fill_buf` again until you let go of the slice). Seriously, if there were a way to wrap `fill_buf` inside an `Iterator`-like API, we could build some pretty cool APIs. And they run 25–50 times faster than the APIs which use copying.
This is the way I'd write it too. But a small improvement on the existing version is also fn fib(n: i32) -&gt; i32{ if n == 0 { 0 } else if n == 1 { 1 } else { fib(n-1) + fib(n-2) } And, I _might_ think about writing your version as fn fib(n: i32) -&gt; i32 { match n { x if x == 0 || x == 1 =&gt; x x =&gt; fib(x-1) + fib(x-2) } } but I'm unsure if that's actually better. I think yours might be.