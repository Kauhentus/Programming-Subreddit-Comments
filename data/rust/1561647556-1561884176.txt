I'm not sure how the European Convention on Human Rights applies to what you think about marriage, also most European 'Conventions' are secondary to national law and the constitution of a given country.
That's the foundation of democracy, the majority steers the ship.
There are entire industries that care not about async IO, but very much about compute throughput. The games industry, for example - a software industry larger than the global movie industry - but they are not using Rust. They are all using C++, with only some members of that community looking at Rust in their spare time. To assume that these developers are merely "hobbyists" is, quite frankly, rather ignorant. Corporate interest is not even going to consider the language until it is already viable. You have a chicken and egg issue here, but just because the language's existing sponsors aren't interested does not mean the potential interest does not exist. Some of those "hobbyists on Reddit" you see in fact represent other industries feeling out Rust's potential. But those individuals don't already represent a major sponsor, and are apparently all amateurs, so they don't matter I guess? To be clear, I do not have a problem with the design Rust has settled on here. The issue I take is the narrow perpective that sometimes appears to have gotten us here; that it sometimes feels like the current design being okay for things other than IO is almost more a happy coincidence than by design. It really was an afterthought, with critical changes needed only arriving late in the design process.
Hmm, if only I had replied to you elsewhere with specific citations detailing the specific violations _spreading_ these beliefs would cause. All I want you to say is "I do not believe in the ECHR" and I won't bother you further, it's all I want to hear. And yes, the European Court on Human Rights are mostly guidelines and incredibly crude for presenting a complete picture of some universal morality but that's not my point, I'm not debating the legality of anything. I'm just saying that if you disagree about the fundamental axioms for a universal morality presented in the ECHR, you're bigot.
After Brendan supported California's 2008 prop 8 bill, the bill that banded gay marriage in California, I have a hard time getting excited about things he is involved with. https://techcrunch.com/2014/03/28/after-supporting-prop-8-brendan-eich-comes-under-fire-from-mozilla-employees-upon-ceo-appointment/
Great! Could you tell a bit about the resources you used in order to implement this?
I would. I would fight them in the same way they fight me. No, fuck that, I would certainly not resort down to the foul, stinky standards of political discourse that the right resorts to. Like smear campaigning and ad hominems. I am fighting their ideas, perhaps even their ideals, but I certainly don't think I'm much of a socialist for attacking who these people are. Mozilla was in their right to select whomever they want as their CEO, just like every organization does. However, to do that after a smear campaign that exploded in the media is just a sorry display of spinelessness and lack of any actual standards. They have been exposed as just another Silicon Valley corp who fears bar PR more than it fears bad products. They are part of the "free market ideology" in every way and have indeed accepted their values in full. The fact that these values have become, on shallowest of shallow surfaces, aligned to ***precious few*** ideals that global left upholds is but a coincidence, that mostly stems from the need to operate in, and milk money from, various societies holding various values. The sad part is that 99% of american business that superficially supports gays and their rights supports them only because of their cultural influence and purchase power. That's the company Mozilla has placed themselves into with that move. Prop 8 *was* a legal proposition, to be decided upon in a democratic process. I wasn't the KKK. It is every man's right to hold any opinion on any political matter, to support it in legal ways, and furthermore, it's incredibly shallow to form opinions about persons based on their political positions.
The (now former) head of an organization that values equality and inclusivity actively working (monetarily) towards dismantling that equality in his private life is a prpblem. Furthermore, calling it "different views on marraige" is disengenuous and hints at the paradox of intolerance, which has been extensively discussed already. One cannot demamd that a tolerant society tolerates their intolerance, and that is the problem here. Suppprting a bill that would deny Blacks their rights would not be tolerated today, why should gay rights be written off as "different views"?
Abortion has the debate about what is a life. Homosexuality does not not. I'm pro choice, but that doesn't mean abortion isn't polemic even to pro-choice people. The name is pro-choice for a reason, it's not pro-abortion. Many pro-choice people wouldn't ever abort. Abortion is a horrible comparison because it can be a incredibly hard choice, it has weight, even if you don't mind it. Following your sexuality only has the weight a homofobic society holds.
Maybe in browsers where Rust already makes an appearance? ;-)
Thanks! :) I was surprised as well when the topic won the poll, but I thought about it some more and I think that a lot of people writing their first games see that every engine has a unique take on this and are understandably unsure where to start—there’s not currently much in the way of writing on why specific games handle this the way they do
My family was tortured and exiled in a dictatorship sponsored by the US because he wanted to live in a democratic country. So will you tell me the US military doesn't incite violence? If that's the rule a bunch of nation-states are banned from posting here.
Which is exactly why politics should not be involved. Unless I’m misunderstanding you, I believe you are referring to ethical coding practices. We don’t go back and edit code based on who is elected president in the US. Write it as safe and ethical as you can and patch as issues arise.
Black rights are human rights, marriage is not, it's an originally religious institution between a man and a woman. How can you claim inclusiveness while excluding the two largest groups (Christians and Muslims) from the equation and making prejudiced comments about them?
&gt; it sounds like it's primarily working while waiting for the UI, which itself is a type of async IO. With compute tasks, it can be more difficult to find meaningful yield points since it always has work. In this example it sounds like the UI thread while it's waiting on I/O is being co-opted to run compute. Actually, kind of the opposite. The UI thread is a dedicated thread running in it's own dispatcher loop, waiting on a variety of things including windowing events, timers, or work explicitly scheduled onto it. The issue is that you can only access UI elements from within the UI thread. So, if you wanted to hook a button click event, run some computation, and then update the UI with the result, you would ordinarily have to do all of that on the UI theead - locking the entire application's UI while the computation was running. Prior to `async`/`await`, orchestrating moving the computation off onto a separate threadpool, and then marshalling the result back onto the UI thread for display was complex and involved a lot of boilerplate. After `async`/`await`, you would have your button click handler (running on UI thread) schedule some work on the pool, and then `await` the result, and then update the UI (automagically back on the UI thread). C#'s `await` implementation automatically handles marshalling back and forth between the two scheduler contexts. So in this situation, you actually have event-driven code running outside of the async context, and that is driving compute tasks which simply run until completion. The `await` greatly simplifies what would otherwise be a whole lot of event callbacks and explicit scheduling code, and replaces it with a single linear method with essentially no boilerplate at all. More generally, you would use async compute when you have multiple pieces of work to schedule all at once, and you want to use `await` to write simpler clearer code for orchestrating the dispatching and collecting of results. Or, to mix together compute and IO tasks that are running concurrently with each other.
People are allowed to have different opinions, and you’re welcome to react to those opinions. For example, if there’s was a really good programmer that told you every day that he thinks that slavery was ok, are you not allowed to react to that?
By telling him off or by firing him?
&gt; Hmm, if only I had replied to you elsewhere with specific citations detailing the specific violations spreading these beliefs would cause. All I want you to say is "I do not believe in the ECHR" and I won't bother you further, it's all I want to hear. All I've understood from this is 'I'm angry so I'm going to threaten you'. Not nice.
For the hypothetical person that supports slavery? I don’t think you can really talk someone out of a view that extreme, and I certainly wouldn’t want to work with someone like that. Why would it be so bad to get the person fired?
We are writing software for high-frequency trading.
I'm going to take that as a no. I won't bother you more than this, all I'd like you to do is consider, for your self, which specific of the proposed axioms you disagree on and figure out why you don't believe in them.
The code samples look like pre-1.0 Rust (`@mut`, overcomplicated use of `Option`), is that correct? I first took a look at the post date, assuming someone posted an old blog entry, but no, it's from 2019 :-O.
Good question! I think you might find the rest of the write up interesting, but here two points I could have better addressed in it— * The post isn't about entity component systems, but rather entity systems in general. Given the recent popularity of entity component systems I probably should have pointed that out at the start! * The needs of every game and every team are different, I'm definitely not intending to *advocate* for the approach I outline here though I can see how the "best of both worlds" header could read that way! Rather, I thought people might find a walk-through of how a specific game made these trade-offs given its gameplay, engine features, and team structure valuable as that's not something that gets talked about a lot.
I mostly used these docs: &amp;#x200B; \- [https://doc.rust-lang.org/nightly/cargo/reference/registries.html](https://doc.rust-lang.org/nightly/cargo/reference/registries.html) \- [https://github.com/rust-lang/rfcs/blob/master/text/2141-alternative-registries.md](https://github.com/rust-lang/rfcs/blob/master/text/2141-alternative-registries.md)
And prop 8 isn’t necessarily about whether or not homosexuality is bad. Many religious institutions have a well-defined definition of “marriage” and are more opposed to the state trying to redefine a religious term. It’s not necessarily opposition to government recognized civil unions. There’s almost always more nuance to an issue than far-too-common accusations of whatever-phobia. As a non religious person I couldn’t care less, but I can at least appreciate nuance.
The regex will get compiled the first time it's used and stored.
Author has his own scripting language that he uses for gamedev projects. I took a short look, and it seems that this is what the examples are written in. But it would be nice to have that clarified below the examples, as I skimmed the post initially and was confused too.
No, it doesn’t. Opt in is very different from opt out. In Rust, you are able to wrap unsafe code in safe code. Unsafe code is walled off, so to speak.
It's about homophobia. It doesn't matter if your religion doesn't consider that marriage, don't marry them inside your religion. Even then discrimination can be argued but that's besides the point. Government marriage has nothing to do with religious marriage.
&gt;That redundancy makes me suspect that this is not the ideal way to write this code. Is there some other way, or is this as good as it gets? Yeah I would suggest just making `Command` be the `Opcode`. A good example is the [JVM's bytecode](https://en.wikipedia.org/wiki/Java_bytecode_instruction_listings) [another example](https://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html#jvms-6.5.dup2_x1) where none, one, or several arguments will be encoded inline. So yes, having `Opcode` be different from `Command` is a bit of a code smell. The trade off is determining how serialize/deserialize `Command`.
Cloudfare is using Rust Brave browser is using Rust [http://www.marginalunit.com/](http://www.marginalunit.com/) is using Rust
Ah good point! I just went back and added a note to the first code snippet, I didn't initially write this with the intention of posting it to Rust communities so that potential for confusion didn't occur to me. But yup you're correct—all the code samples are in a scripting language written in Rust that doesn't yet have good syntax for options. :)
2D graphics rendering is core to many of the sub-projects of xi org, and PF3 is one of the best solutions around :)
Sounds like a recruiter.
&gt;counting node\_to\_delete as borrowing from node\_to\_delete, which is preventing other usage. &gt; &gt;Non-lexical lifetimes is getting closer to having all correct code compiling, but it doesn't understand everything. Unfortunately, the closer we get to "all correct code compiling", the more complicated rules are needed to actually understand the borrow checker's logic. I don't know exactly what rule is being broken here. &gt; &gt;I played around with it a bit, and the following seems to work: I think I will, thanks!
I would serialize/deserialize everything on the wire using something like protobuf.
The minor benefits come from the simpler and clean syntax. The medium benefits come from the fact that Tree code is clean and easy for humans \*and\* machines to read and write. The big benefits come from network effects. Right now if I build an editing tool for Rust, it helps no one but Rust users. However, if I build an editing tool for a Tree Language that compiles to Rust, while my goal might be to help Rust Users, I am now also helping all other Tree Language Users (who might be using Tree Languages to generate assembly, C++, Python, Javascript, TypeScript, HTML, CSS, etc). It's a universal syntax that can be applied in all domains. Replacing JSON will be neat but not a top priority (but I do think it will happen). I'm more exited about building new higher level languages. One is a dataflow language called Flow used by Ohayo ([http://ohayo.computer/](http://ohayo.computer/)). This is an interactive data science environment that runs in the browser and you can also execute the scripts in a nodeJS environment. BUT, if someone were to implement a Tree Notation library in Rust, anyone who uses this Flow Language could now execute their app in a different VM. For Data Science, this will be key, as for some of the big data stuff we do at my job at the Cancer Center needs access to more memory and faster numerical ops that Javascript currently provides. So those are a few notes about some of the benefits. Here are some answers to the questions you provided. Thanks for taking the time to offer feedback! \&gt; because you might accidentally have spaces or newlines in keys or values without escaping them, which silently breaks everything. The result is likely still valid in tree notation, but the meaning would be wrong. Similarly, when manually editing tree notation, you could easily have one space too many or too few, which silently changes the meaning of the data. In JSON it's much harder to mess up like that. The base Tree Notation is very simple-&gt;words, lines, and parents/children. But in most cases, you'll want to use a Tree Language with a defined Grammar (which itself is written in Tree Notation). Here's an example of such a language currently called Stump which compiles to HTML ([http://treenotation.org/sandbox/build/](http://treenotation.org/sandbox/build/)). An extra space or newline can change things, you are totally right there, however, once you have a Grammar you get instant syntax highlighting, cell/type checking, and suggested autocorrections which can eliminate these problems. \&gt; You seem to have no spec. Thanks for point that out. There was a formal one at one point but now there seems to just be casual ones in a few places like in the papers and TypeScript. It is very tiny though--words, lines, parent/children relationships, and 3 syntax characters (in practice 2, as I use a space as the indent character and the word separator). I created an issue on GitHub to make sure there's a formal spec for the base notation in the main repo. [https://github.com/breck7/jtree/issues/11](https://github.com/breck7/jtree/issues/11) \&gt; How would one even encode whitespace or newlines in keys or values? There's not a 1-to-1 relationship between Tree Notation and JSON. To perfectly encode JSON, you need to use a higher level Tree Language (at least one person is working on one now that I know of). \&gt; you show a package.tree and a package.json which is presumably the equivalent. Ah, thank you for pointing this out. I could see how that leads to confusion. I updated an issue to update the readme and to clarify that. In base Tree Notation children are arrays. \&gt; It's whitespace-sensitive....Does a non-breaking space count as a space? Does a tab count? ... Whitespace is not collapsed (n spaces/newlines always is different than n+1 spaces/newlines in base Tree Notation) and there are only 2 meaningful whitespace characters (00100000 for space and 00001010 for newline). All other characters are just treated as any other string character.
&gt;Individual component access isn't implemented for vectors and most likely will not be as simple as a public field access when it is. For now, manually destructure the vector. Is implementing `Index` and `IndexMut` out of the cards here?
Anybody has a trick that helps in figuring out what types are involved in an expression in rust? Like for example, in the expression `while let Some(v) = ptr {` is ptr borrows and v is a reference or is ptr moved out? Is that always the case. If it's borrowed why that happens without &amp; involved?
The number of downvotes this comment is getting reflects one of the more ridiculous aspects of the Rust community. This comment is repeating what Niko Matsakis himself has said over and over again. Unsafe code *is useful* and perfectly acceptable in many situations, and the cult of safe-code-only is in direct contradiction to good engineering, common sense, and the messaging of Rust’s founders and thought leaders themselves. There was a recent post here in which someone new to Rust was trying to write performant multithreaded code, but their data structure, while perfectly thread safe, was impossible to use in safe Rust. The advice given was to completely refactor the design so they could use locking but safe code despite the performance hit. Not a single person suggested to use unsafe. Insanity. The most obnoxious part is that the bad advice is usually accompanied by condescending intellectual bullying such as, “This is a sign that your design is wrong.” No, it’s a sign that there are perfectly reasonable situations in which unsafe is the right answer. *The design was obviously thread safe*, for crying out loud.
Who is the software for??
&gt; For the hypothetical person that supports slavery? I don’t think you can really talk someone out of a view that extreme You'd be surprised how many positions of that type are held because of upbringing, and lack of exposure to real people you hold position on. So in general case you can actually talk someone out of many views, especially if he has the chance to add experience that would go against those views. It's much harder to be a racist when a black guy invites you to his house for lunch, than when the only time you see black people is while driving through their part of the town or just on TV. Which is kinda exactly what I feel I'm dealing with here. Perhaps you have some very specific hypothetical person in mind, but I haven't met your guy. &gt; Why would it be so bad to get the person fired? Well for one, I'm principally against being sleazy and slimy even if it just means getting a hypothetical guy fired from a hypothetical job. And while you have pushed your straw man as far as it can go, I can't really find a political opinion over which I'd chose not to work with someone, if they're otherwise ok. OTOH I'd definitely not want to work for someone who would resort to scheming to get people fired or blackmail management with "either he goes or I go" over trivial shit such as political positions.
Salary? Location? Remote work acceptable? Amount of experience desired? Job description and qualifications? You'll likely get more responses if you provide concrete details and maybe a link to an actual job description.
And abortion is about promoting eugenics. See how easy it is for me to arbitrarily decide what other people’s motivations are?
Yes, the first time the variable is dereferenced it evaluates and every time thereafter it uses a reference to that previous evaluation. I'm more curious about the macro placement, every time I've seen it before the macro is place outside of any function definitions, like near the top of the file. But if this compiles then it must work...
If you're near london, going to the [https://www.meetup.com/Rust-London-User-Group/](https://www.meetup.com/Rust-London-User-Group/) is a great way to meet london rust devs.
&gt; I wasn't the KKK Ahaha. Fuck you.
(author fo the new ad blocker) indeed that's the suggested interpretation! The post focuses on the algorithm rather than any specific Rust features precisely because it was the algorithm that made the bulk of the difference. Rust has its benefits, and appeared like the right tool for the job. The fact that you can achieve good performance with careful tuning is one of them, but there's no suggestion that Rust is the fast language there is
The directories crate's [`runtime_dir`](https://docs.rs/directories/2.0.1/directories/struct.ProjectDirs.html#method.runtime_dir) method might be useful for providing a sane default for socket paths.
&gt; This is the main feature under development right now, essentially codenamed “Gemini”. This is super confusing since there's a major cryptocurrency exchange named Gemini.
How would `Vec&lt;u8&gt;` fit your needs?
The downside I see is that I'd need e.g. Command::Drive { speed: 0 }.opcode() to extract an opcode. If I get your point correctly though, you're saying this might not work in general anyway. For example, it's impossible for an `aload` command, because the command may use any of `aload(|_0|_1|_2|_3)` opcodes?
I'm implementing a pre-existing wire protocol.
I think the choice of representation depends a lot on what you're trying to do: how efficient you want to be, what operations you want to support, etc. For some fancy, well-engineered thing I'd probably provide `Command` and make `serde::Serialize` and/or `serde::Deserialize` instances for the wire protocol. I guess I'd use some data structure to support mapping between opcode numbers and their wire representation rather than the numbered `enum`.
That might work, I have avoided it because the parser for bigint takes a slice reference and I didn't want to add that conversation to the already infinite task list... I hope to avoid anything that isn't exactly required.
I keep hearing that it's hard to find a Rust developer, but OTOH, I cannot find an offer for a Rust job (Paris, France)
Making a slice reference from a `Vec` is an incredibly cheap operation. There's a benefit if you can avoid dynamic allocation entirely, but if you're already considering `Box&lt;[u8]&gt;` then `Vec&lt;u8&gt;` has almost identical performance.
Thanks for the suggestion! I thought about using a temporary socket path, but this one would have to be stored it in a variable as well, to be able to pass it to subsequent invocations of `async`. Thus I think this feature does not make the program easier to use. Do you have an idea how this could be avoided? I would prefer not to have to specify the socket for every call.
Thanks, that's likely an area the documentation for Box can be improved. I read that three times b4 posting about it and nowhere did it suggest that Vec&lt;T&gt; is similar in performance to Box&lt;[T]&gt;.
I think your first example needs to be a little simpler.
Could you please elaborate?
you can match on Command impl Command { fn get_drive_speed(&amp;self) -&gt; Option&lt;u8&gt; { match self { Command::Drive{ speed: val } =&gt; Some(val.clone()), _ =&gt; None, Generally speaking with bytecode's you end writing a massive 1000-2000 line match/switch statement at some point.
Yeah, I think my comment doesn't reflect the meat of the article. I just had different expectations on the final solution. It is still valuable to explain how you came to the solution, so thank you for that!
I don't there's anything ridiculous about trying to minimize the amount of unsafe code in your codebase. Is unsafe code useful and necessary? Sure, absolutely! But that doesn't mean we should encourage everyone, especially newcomers, to start slinging `unsafe` around everywhere.
**Please keep comments on topic.** This thread is about Brave, the browser. It is NOT about discussing the motivations of Brendan Eich for something he did **11 years ago**, it is NOT about his personal opinions, the righteousness (or not) of his actions, and it certainly not about your opinion on this topic. There will be no public lynching of anyone's past action, morale views or political views on this thread.
Generally speaking you don't work Unsized Types, or Unsized slices. You work with pointers too them.
Environment variable, so you can export it once at the beginning of a script. Something like \`ASYNC\_SOCKET\`.
FYI: https://github.com/mmstick/parallel
`Box&lt;[T]&gt;` is worse than `Vec&lt;T&gt;` outside of a few very rare circumstances, so I'm not surprised that the documentation for `Box` doesn't even mention the possibility of boxed slices.
The macro basically creates a unique struct and then uses a normal `static` variable, which is allowed within functions and behaves the same as globally but just limits the scope to the function.
[https://github.com/mozilla/sccache/blob/master/docs/Rust.md](https://github.com/mozilla/sccache/blob/master/docs/Rust.md) Says there are many caveats. How well does it work in practice?
[Strum](https://crates.io/crates/strum) gives a macro that will automatically generate `Opcode` from `Command`, so you don't need to keep them in sync.
Replied below on the interpretation: absolutely "with Rust" rather than "because of Rust", though it wouldn't be "despite Rust" either! As for mobile, yes, the new ad-blocker should come to Brave on Android very soon as well. Still evaluating options for iOS, but as all browsers on iOS are forced to rely on Apple’s WebKit engine, there are limited options for using a custom ad blocker...
Thanks, I wasn't aware of this project. Since it is a rewrite of GNU Parallel in Rust, the differences to my program are the same as for GNU Parallel. The main reason, why I wrote `async`, is that you can simply prepend `async` to your command and have it run asynchronously. With `parallel` more work is involved because it has an elaborate syntax and it cannot parallelize across multiple invocations.
I assume your type is Option&lt;*mut T&gt; or something similar. Pointers in rust are Copy types it doesn't move it or reference it. In general though, that syntax would be a move
Assignments in rust are always moves unless the right-hand expression (rvalue) is [`Copy`](https://doc.rust-lang.org/std/marker/trait.Copy.html). [Shared references are `Copy`](https://doc.rust-lang.org/std/primitive.reference.html#trait-implementations). This works recursively for the expression, so if `v` is `Copy`, it will be copied. If not, it will be moved. If you have a reference to a non-`Copy` type like `&amp;Option&lt;String&gt;`, then you'll get a `cannot move out of borrowed content` error.
Why not? Just cause they are new to rust doesn't mean they are new to development. Or they may just be good at it. Why not use unsafe until you can learn to do things with it as much, unsafe is training wheels for those more used to pointer heavy languages. Having people start off with entire safe rust is just your preference and shouldn't be treated like the One True Way. Gatekeeping is the new rust way.
Right, this crossed my mind as well at some point. This is a great idea and I will definitely implement this for the next release.
The example is long, complex, does stuff that don't in any obvious way show how the application works and is basically not to the point.
Ok, thanks for your feedback, I will see if I can find a concrete example. (One that's not just piggybacking off of my test script :P)
Just to be clear, when you say it "parallelizes across multiple invocations" does that mean that in an example like so (pseudo syntax): &amp;#x200B; async some-stuff async other-stuff &amp;#x200B; That "other-stuff" will be able to start executing even if "some-stuff" has not completed?
You need to parse the bytes to determine if they represent a float, and you're using a float parsing function that "uses aggressive optimizations to avoid worst-case scenarios", so I would say your solution is already pretty reasonable.
Pretty cool. I think you might be able to simplify the API by using a environment variable instead of specifying \`-s\` everywhere.
DBeaver took a nose dive in performance recently. PGadmin desktop client is an old memory. So, Diwata has a great niche to fill. Good luck with the project! I will give it a try and share feedback.
I've run into weird instances where sscache will cause me to recompile dependencies every time I build my project, even if they haven't changed. The fix I do is to \`RUSTC\_WRAPPER= cargo run\`, and then \`RUSTC\_WRAPPER=sccache\` will work fine after that. &amp;#x200B; Other than that, it definitely speeds up my builds and works decently well.
Updating your sccache then: https://github.com/mozilla/sccache/releases/tag/0.2.9
Yes, exactly. You can issue as many commands as you want and then wait for their completion with a call to `async -s ".." wait`. If you don't need this functionality you might as well use GNU Parallel.
How is that different to background execution in the shell, then? The one that does this: some-stuff &amp; other-stuff &amp; More info: https://www.digitalocean.com/community/tutorials/how-to-use-bash-s-job-control-to-manage-foreground-and-background-processes
Hey, could you explain what the advantages of using sauron are? I'd love to use it even just for the name but it doesn't seem you have a lot of documentation on it yet
reddit markdown parsing is broken. you need to use indented code blocks: #!/bin/bash S="/tmp/example_socket" async -s="$S" server --start for i in {1..20}; do # prints command output to stdout async -s="$S" cmd -- bash -c "sleep 1 &amp;&amp; echo test $i" done # wait until all commands are finished async -s="$S" wait # configure the server to run four commands in parallel async -s="$S" server -j4 mkdir "/tmp/ex_dir" for i in {21..40}; do # redirects command output to /tmp/ex_dir/file* async -s="$S" cmd -o "/tmp/ex_dir/file$i" -- bash -c "sleep 1 &amp;&amp; echo test $i" done async -s="$S" wait # stops server async -s="$S" server --stop
Really neat command that I can see myself using in the near future :) Some suggestions : * optionally specify an ID when starting the task to be able to wait specifically for it * rename the "wait" command _await_, for... reasons! :D
Thanks
Slices are likely the canonical unsized type. When you search for solutions to working with unsized type you're almost certainly going to find Box&lt;T&gt; as a solution... So A+B=Box&lt;[T]&gt;. It's a huge failure that the documentation for Box doesn't point out the obvious + bad idea.
How in the world is unsafe "training wheels" for new users? Rust's rules around unsafe code are also pretty different than those of C or C++ especially around the details. For example, C allows you to perform type-punning through `unions`; in Rust, reading *any* field of an inactive variant is instant UB. A lot of the exact rules haven't even been settled in Rust anyway (something the Unsafe Code Guidelines working group is doing). Part of the process of learning Rust, is learning to do things differently. If all you do when switching languages is to continue doing everything exactly the same way you always have, what's even the point? You're not really learning anything.
I also wrote [sauron](https://github.com/ivanceras/sauron) web framework as well. The web client for diwata was originally written in elm. While there are web framework written in rust, they rely heavily using macros which loses a lot of flexibility as what you would get in simple function calls. Sauron's architecture is very closely in accordance to The Elm Architecture from elm-lang, overtime I have improve the performance of sauron, though not as performant as elm, but it is improving. Documentation is very lacking at the moment as most of my projects are big and one man show. Reading the examples is a good start for those interested in using it.
The problem with forking from bash is that you cannot limit the number of child processes unless you implement it yourself.
&gt;The fact of the matter, I can write a small and performant microservice in golang using the standard lib in minutes Definitely agree on this, as well as on the "useful/productive" comment. I found it pretty hilarious how quickly I could build an SSE-based chat server in Go just using standard lib, also in not very many minutes. I definitely missed a lot of what I enjoy in Rust, but wow is it productive.
This is already planned :) I might also make it so that if you specify the same ID twice, those commands will run sequentially.
&gt; For example, C allows you to perform type-punning through unions; in Rust, reading any field of an inactive variant is instant UB. Do you have a citation for this? My understanding is that [stuff like this](https://github.com/rust-lang/regex/blob/172898a4fda4fd6a2d1be9fc7b8a0ea971c84ca6/src/vector/ssse3.rs#L80-L83) is a fairly normal thing to do.
Nice! :)
My understanding is that "zero-cost" is more accurately described as "You pay for what you use". In this case, Arc&lt;Mutex&gt; (or Rc&lt;RefCell&gt; if you're single-threaded) are "zero-cost" insofar as they existance in the language doesn't make your code slower. And as far as Rust vs C++ goes, Rust is better at some things, and C++ is better at others! Complex data-structures where the memory layout needs to be tightly controlled is definitely easier in C++. Meanwhile, concurrency is much easier in Rust - exactly thanks to its memory safety guarantees that make writing complex data-structures complicated. It's all trade-offs.
you should remember that the creator of javascript wanted to make the language for the browser a lisp, and corporate said he couldn't, that it had to look similar to java/c. So, he did his job, and unfortunately it ended up taking over the whole world.
the worst case interpretation I can see is that brave is scamming the scammers, which sounds wonderful?
Hint #1: porting old code to Rust can be quite an unexpected challenge if the original code had curious design choices, includes code written by almost any human between 10pm and 7am, or was coded with no real notion of race conditions or memory safety. Expect a re-write from scratch and not a trivial port. Hint #2: Rust improves its programmers, not by teaching but largely by way of many early frustrations that eventually lead to strategy. For builds that need to be world-first-in-class performant, stable and largely bullet proof, Rust great choice. For code that runs once a day, consumes trivial resources and needs to be changed frequently... maybe no... stay with Go.
I got to this point after fighting with problems as identified by rls. Rls led me to doing a ton of research on unsized types. I chose to use Box instead of lifetime shenanigans because I haven't yet learned much about specifying lifetimes and i think I would need to also learn about generalizations. A link to a doc about selecting what's appropriate here would also be a great addition to the Box documentation.
You're the real MVP!
&gt;When designing a component, you either anticipate every possible use, or you don’t. If you do you’re likely wasting your time on pairings that will never occur, but if you don’t, you can’t truely mix and match things freely. I don't understand. &amp;#x200B; When designing a component you don't anticipate anything since a component is plain data and no logic. All logic is in the systems, that's where you define your pairings too, but you don't make empty systems just because an entity could in theory have these components. From [this blog post](http://t-machine.org/index.php/2014/03/08/data-structures-for-entity-systems-contiguous-memory/) an indie game has around 50 components that means 50! combinations. If you had do write this much code in order to use a "dynamic" ECS, people would have died of old age before finishing a tetris clone. e.g. * you have two components Pos and Vel * you want to modify the Pos component based on the Vel component * you also want to use the Pos component to display the entity In this case you'd have two systems, one matching entities with at least Pos and Vel and another one matching entities with at least Pos. Even if Vel alone is a possibility, you don't have any behavior for such entity so you just don't make a system. &amp;#x200B; &gt;You’ve essentially built a dynamic type system for your game, and taken on all the problems that come with one. For example, in Unity, one component can fail to get data from another at runtime if the component in question isn’t present on the entity or was deleted at runtime—and there’s not always a good way to respond to that failure. I don't understand either. &amp;#x200B; If you match the entities each time (or keep track of which entity should be process by each system), there is no way to have an entity missing a component. The closest thing I can think of is an optional component but as it's name suggest, in Rust you'd use an `Option` and adapt your logic for `Some`/`None` without failure. e.g. * you create an entity with Pos and Vel, the two systems affect it * you delete Vel from it, only one system affect it from now on &amp;#x200B; The way I see systems (an action on a set of components), you can't have systems. That leave us with entities owning their components, also called objects. And yes, this is the easiest way to reason about game objects but there are multiple reasons why the ECS pattern has become so popular and you don't have to make a big and complex game to see the benefits. &amp;#x200B; To me it feels like you're not familiar enough with the ECS pattern and choose not to use it. And it's a perfectly fine reason, being familiar with a pattern let you structure things both easier and faster, arguments very important especially in a small team. I'd just like to interest you in this weird thing called an ECS. You might be interested in [this talk about ECS and Rust](https://www.youtube.com/watch?v=aKLntZcp27M), [Evoli](https://github.com/amethyst/evoli/tree/master) a game made using Amethyst (and Specs) or [Airjump Multi](https://github.com/thiolliere/airjump-multi) a game using Specs but not Amethyst or [an even simpler game](https://github.com/sunjay/rust-simple-game-dev-tutorial).
You're welcome! :) It wasn't where I expected to end up either—I was pleasantly surprised when I realized could lean on my engine's hot swapping and serialization instead of introducing a more complex system.
The UI of diwata is html+css, though I have some plans to add native support for sauron.
I've been using it for years. It mostly works and provides great speedups if you work on many different projects. From time to time I get weird build errors. Those are fixed by just deleting the cache. (`rm -r ~/.cache/sccache`). PS, as mentioned below: right now you have to install from master (`cargo install --git=https://github.com/mozilla/sccache.git`) due to a not-yet-released bugfix.
It's being downvoted because it purports that rejecting unsafe usage is rejecting a useful tool, rather than accepting that the codebase may just have a constraint and it's cool that the constraint is enforceable. The Rust community consistently discourages usage of unsafe where it isn't strictly necessary and it's a good thing.
I see, keep up the good work!
Ad industry encourages horrible, horrible behaviors. Companies sell user data to each other and collect a massive amount. Removing ads means a huge blow to the system that funds this sort of tracking behavior. Brave does this. It also realizes that the web is a monetization platform for many, and so it provides an alternative. I don't see how "telling advertisers[actually it's content creators] to use their altcoin" is any worse than telling them to use Google Ads.
Just so you know, [clap supports this natively](https://docs.rs/clap/2.33.0/clap/struct.Arg.html#method.env) (and so does structopt, which you appear to be using).
Thanks for the questions! &gt;When designing a component you don't anticipate anything since a component is plain data and no logic. All logic is in the systems, that's where you define your pairings too, but you don't make empty systems just because an entity could in theory have these components. From [this blog post](http://t-machine.org/index.php/2014/03/08/data-structures-for-entity-systems-contiguous-memory/) an indie game has around 50 components that means 50! combinations. If you had do write this much code in order to use a "dynamic" ECS, people would have died of old age before finishing a tetris clone. &gt; &gt;e.g. &gt; &gt;you have two components Pos and Vel &gt; &gt;you want to modify the Pos component based on the Vel component &gt; &gt;you also want to use the Pos component to display the entity &gt; &gt;In this case you'd have two systems, one matching entities with at least Pos and Vel and another one matching entities with at least Pos. Even if Vel alone is a possibility, you don't have any behavior for such entity so you just don't make a system. You're correct that under many entity systems—in particular entity systems classed as entity component systems—components are just plain data. Not all entity systems that have a "component" concept work this way though, a popular example being Unity's entity system prior to their adaption of an optional ECS. I probably should have given a concrete example of the problem I was addressing in that part of the write up, the issue is orthogonal to whether the components are plain data or contain behavior under a given system. Consider for example the elevator in this game. It's nonsensical in the game world for there to be an elevator without both a color and a trigger area, if I create an elevator without both of those things and then the elevator system therefore doesn't pick it up there's a bug in the level. You can try to slice things up a little differently and mitigate this—and for many games this can be worth the utility it adds!—but that's the core tension I was trying to get at. :) &amp;#x200B; &gt;To me it feels like you're not familiar enough with the ECS pattern and choose not to use it. And it's a perfectly fine reason, being familiar with a pattern let you structure things both easier and faster, arguments very important especially in a small team. I'd just like to interest you in this weird thing called an ECS. &gt; &gt;You might be interested in [this talk about ECS and Rust](https://www.youtube.com/watch?v=aKLntZcp27M), [Evoli](https://github.com/amethyst/evoli/tree/master) a game made using Amethyst (and Specs) or [Airjump Multi](https://github.com/thiolliere/airjump-multi) a game using Specs but not Amethyst or [an even simpler game](https://github.com/sunjay/rust-simple-game-dev-tutorial). Thanks! I've used the ECS pattern for prior games and also worked in codebases where people had already adopted it, it just wasn't the right fit for this game.
Hello! Good luck. You should probably post on Rust Internals, too, which is one of the major online locations for Rust development. Unfortunately, the only UK Rust developer I know is happily employed. If you private message me with any details, I may be able to get him to lunch with you, though. (if you're in London)
&gt;In base Tree Notation children are arrays. Oh, I thought (probably based on the package.tree implementation) that the first word had a special meaning, as the "key", and that a node couldn't then have the same key twice. But I see now that that's not enforced by the tree notation at all, nodes are just arrays of other nodes, and the values are arrays of words. To be honest I don't think the splitting of lines into words is very useful. Most applications probably would want to have strings that could contain spaces or newlines. The package.tree example being one of them. Trying to encode strings without " as well is cute but it doesn't really work. Take your programming language example: if true print Hello world It works because `print` only takes one string as an argument. How would you make a function that takes 2 strings as an argument? &gt;All other characters are just treated as any other string character. You have to be careful with that. If a user on Windows would create or edit a .tree file, the words at the end of all lines would end with \\r, because Windows ends lines with \\r\\n. Finally, would you consider Python as a "tree language"?
&gt; Why not? Because programming with 'unsafe' is: a) Largely unnecessary, outside of building custom data structures b) Hard Why *would* I reach for unsafe? I've never had to. I wrote some code with unsafe once, and then I rewrote it to be safe, and my benchmarks showed absolutely no change. Reaching for unsafe first was just a waste of time, and meant I was throwing away Rust's most valuable feature - the borrowchecker. It's not gatekeeping at all. Developers are choosing rust because it is safe. When libraries use 'unsafe' developers are less likely to be happy about it. It has absolutely nothing to do with being "good at it". It has everything to do with decades of history showing that managing memory without safety checks is too hard for the vast majority of humans, especially in moving codebases. This is all true *and also* it is true that unsafe is a powerful tool and it fundamentally is what makes rust possible. Your initial post purports that not using rust is overly-limiting. And yet, the vast majority of rust is safe.
Someone recently mentioned that Ledger, the crypto wallet, was looking for Rust developer iirc. They have developer in San Francisco and Paris. So you can maybe try there.
Generally speaking to answer your question literally: https://gitlab.com/cheako/multiplicative_persistence_searcher/blob/5142d18d35f9c4cc95c1b054c7ac86191b84dfca/src/main.rs#L40 should be value := Vec::from(START).into_boxed_slice() which will create a `Box&lt;[u8]&gt;` which is the same as a `&amp;'_ [u8]` except it'll de-allocate its contents on drop.
I am a London based developer, and I do some Rust coding. Can you please add more information about the role? Namely is this an open source project, a funded academic project, a job role at a company, or something else?
This line is panicking because the string was empty: https://gitlab.com/solidtux-cubing/cubers/blob/master/cubers/src/cube/cube3.rs#L253
I get the feeling you got tripped up because you came at the problem from an unusual angle. Most people learning Rust are pretty quickly directed to the `Vec` type as the go-to method of working with growable, heap-allocated arrays of `T`. I often see people happily using `Vec` for a long time without even knowing that `Box&lt;[T]&gt;` is a thing at all. In fact, the only (safe) way to even *create* a `Box&lt;[T]&gt;` in the first place is the [into_boxed_slice method](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.into_boxed_slice) on `Vec`s, so it's rare indeed to encounter the former before dealing with the latter. That being said, it's probably not the worst idea to have some more clarification on the matter in the documentation.
Hey, thanks for the tips. I hope that they still need a Rust developer, and that I can fulfil their needs ;)
You might be right about the yielding part. I haven't thought about that as I am not too familiar with Futures. Just wanted to give a different perspective.
&gt; throwing away Rust's most valuable feature - the borrowchecker unsafe doesn't turn off the borrow checker, nothing does
&gt; But I see now that that's not enforced by the tree notation at all, nodes are just arrays of other nodes, and the values are arrays of words. Yup, that readme.md needs to be fixed to clarify that. &gt; Most applications probably would want to have strings that could contain spaces or newlines. Strings can contain spaces and newlines. It's up to the Tree Language. For example, in the "bern" node in this language: "http://treenotation.org/sandbox/build/#stump", you can put anything in there--spaces, newlines, HTML, etc. &gt; To be honest I don't think the splitting of lines into words is very useful. In general this is an interesting question. I'm only 90% convinced that the base Tree Notation should have a word separator. I'm running more experiments now looking at postfix and infix languages (right now most of my languages use prefix notation). It might indeed turn out to be that it's best left up to the Tree Language how to handle the parsing of each individual line (and whether to break up words or not). For now word parsing seems to be pretty good in practice though. &gt; How would you make a function that takes 2 strings as an argument? It's a good question. There are at least a couple of ways it's being done now. One is to have functions that only take identifiers to strings, where an identifier is just one word. Another is to have functions that take their parameters as child nodes, instead of inline. Another (I've only loosely played with this), is to use infix operators. And of course your Tree Language nodeTypes can always parse their lines however they want, and indeed many of the languages so far will take things like strings in quotes. &gt; If a user on Windows This is a good point. I do very little testing on Windows. IIRC I think I always have the library strip any "\r". &gt; would you consider Python as a "tree language"? No. At present when I use the term "Tree Language" I mean a language with a Grammar written in the Grammar Language(http://treenotation.org/sandbox/build/#grammar). In the future I expect their to be different but somewhat similar parser generators/compiler compilers and so my definition of Tree Language will broaden to cover those as well. Of course, because every sequence of bytes is a valid Tree Notation document, in a weak sense every language is a Tree Language.
You can try /r/rustcryptofin too.
It would have not occurred to me to try latest from GH but will do!
Yes, but why does it panic? split works fine on an empty string and parse should just return an Err and not panic.
parse *should* return an error, but it doesn't. The line I referenced above panics when parse is called on an empty string.
Thank you, I somehow missed and forgot that I take a slice ...
No much in the cards. that's probably already implemented already actually, depending on my understanding of deref coercion. Vectors implement Deref and DerefMut to their respective array structures.
IIRC `sccache` also works for C/C++ compiler/linker outputs. Is there any benefit to using `sccache` over `ccache` for C/C++, if you assume no limit to a local `ccache` size?
I use Rust daily at my job for whatever makes sense. There's plenty of applications well suited for oxidation. Currently I use actix, diesel and friends to power the backend for a web application. I am anxiously awaiting async await support. I'm very excited about it.
If you're in LA, come by one of the arcades! We have a good scene here.
&gt;Of course, because every sequence of bytes is a valid Tree Notation document Is it? Is this valid: a b (note the 2 spaces indentation instead of one). What about a sequence of bytes that starts with a space?
I agree. Unsafe, responsibly. I'm sorry that you're being down-voted into the abyss.
Would you mind explaining how is this different from `&amp;` jobs?
...what. Can you be more specific? What are you trying to do? What is not working?
Ive been meaning to. Moving to Texas soon but Don's arcade is on the bucket list!
So, at least according to [RFC144](https://rust-lang.github.io/rfcs/1444-union.html#unions-and-undefined-behavior) &gt; In addition, since a union declared without #[repr(C)] uses an unspecified binary layout, code reading fields of such a union or pattern-matching such a union must not read from a field other than the one written to. This includes pattern-matching a specific value in a union field.
&gt; but not being able to ctrl-break is surprising. If I understand, are you trying to send every 1000th permutation to a second destination? If you want to advance the iterator without consuming it, I would recommend the `Iterator::by_mut()` method. It returns a reference to the iterator which can be used to advance it, but doesn't own it. For example, fn generator(ps: Sender&lt;Packet&gt;, ss: Sender&lt;String&gt;) { let mut iterator = NumberIter { n: START.to_vec(), p: START.len(), }; loop { for current in iterator.by_ref().take(1000) { ps.send(current); } let next = &amp;iterator.n[..]; ss.send(String::from(String::from_utf8_lossy(&amp;next))); } }
&gt; unsafe doesn't turn off the borrow checker, nothing does Sure, whatever, it's honestly semantics. You're given access to a set of APIs that can break specific rules. &gt; trading order book analysis Sure, so for HFT unsafe is simply a requirement because you *have* to cast bytes to structs. Most people are not in HFT, and I'd wager that most code in HFT still won't require unsafe and the bigger gap with Rust is around lack of powerful constexpr. &gt; You act as if there is only use ubsafe every where on everything and never use it. Like unsafe is infectious or something. Yes, unsafe is absolutely infectious. That's the problem. It breaks compiler enforced constraints in an entire module, and great care has to be taken to ensure that that safety only ever exists within the bounds of a module. As I mentioned, rust CVEs do exist. Actix is a great example of a developer thinking they knew how to write safe code despite unsafe, thinking "oh it's just a tool", and having vulnerable code. The rust community is vehemently anti-unsafe for this reason, as it should be. &gt; The original point of this incarnation - post GC - of rust was be as fast or faster than C++. Now it seems the that is changing. The founding principal of modern rust is, to me, 0 compromise. Fast and safe. But the community has decided that, if you have to give up one, it's the "Fast", and we should file a bug to track how we can get both.
See also this [note](http://www.unicode.org/faq/private_use.html#sentinel6) on '\u{FFFF}'. I'd probably modify that range to be '\u{0020}'..='\u{FFFE}' for comfort, but it's not necessary: Rust will take this as-is fine.
So,why are they not commenting in the issue trackers/rfcs comments/internals threads/discord servers? If they have concerns they should say them where they can be heard.
Then all depends on the variety of arguments types and quantity of opcodes. I would probably describe all the opcodes+arguments in a big CSV file (e.g. "0;drive;speed;i8") and then use code generation (build.rs with csv and strum as build-dependencies) to generate the datatypes. As a bonus you can add a comment in the last column and use that to generate documentation. Been there done (roughly) that, very happy with the result.
Yes, that is valid. It parses as: node: words: ["a"] children: node: words: ["", "b"] But that is a great edge case example. Because imagine you want line 2 not to be a child of line 1. There is ambiguity there. This stems from the fact that there are actually 3 syntax tokens in Tree Notation but I reuse the space twice: new line to split nodes, space for indent and space for word separator (in the code they are referred to as XI/YI/ZI). In the Jtree implementation you can actually change that and make the indent and space different so if you wanted to clearly specify an indent vs a space you could write something like: a - b In practice I haven't come across a case yet where you'd want the first word of a line to be "", other than in blob nodes, in which word parsing is skipped anyway so it doesn't matter.
Btw, just want to again point out that you already hit upon what was the most perplexing edge case in Tree Notation I ran into. That troubled me for a while until I started to realize the places where it comes up word parsing isn't a thing.
Thanks, that's exactly what I meant. I will try some of these.
I uh, that code... I have so many questions that I really don't want to know the answer to. You resort the vector every time you take the next item? -- no, no, I really don't want to know.
Lol, yes it's magic.
Okay, now I'm curious :)
So I agree that unsafe shouldn't ever be completely ruled out, I personally like using `#![forbid(unsafe_code)]` especially in the main executable, and keeping anything that really needs `unsafe` in it's own crate. Obviously this may not always be viable, but if it is, it helps keep the `unsafe` usage isolated from everything else, and you can be relatively certain that if you *do* run into memory safety issues they will be caused by one of these isolated crates.
Thanks, it's implemented!
Here's how I would design it, to make it as simple as possible to use: * There is a default path for the socket in a user-specific runtime directory; can be overridden with an environment variable or flag, but just using a per-user default makes everything a lot simpler * If there is no socket present when first invoked, start a server with [`num_cpus`](https://crates.io/crates/num_cpus) jobs * When running `wait` on such an automatically spawned server, stop the server automatically after all jobs complete * Default to `cmd` if no subcommand is given or the subcommand doesn't match one of the built in ones, so you can have shorter lines for your main tasks Then usage would be as simple as, for example (which also gives a bit more of a real-world example): for img in dir/*.png; do for s in 32 64 128 256; do async -- gm convert "$img" -resize=${s}x${s} "${img%.png}-${s}.png}" done done async wait After describing it this way, I realize that this is essentially equivalent to [GNU Parallel's `sem`](https://www.gnu.org/software/parallel/sem.html) with `-j+0`.
how about a sleep with a time, showing the completion time? Like
My reply to each of your points in order: * The problem with a global default is that scripts using `async` that are running simultaneously could interfere with each other, this is why I did not implement this. But you can now specify the path using the environment variable `ASYNC_SOCKET`. * The server defaults to `num_cpus`, but spawning one without a specified socket path is not possible without a default, global socket. * Would be very nice, but also depends on the problematic default socket. * This is something I want to do, but did not yet find out how using clap/structopt. To your point about `sem`: I was not aware that `sem` exists and probably would not have done this project if I knew about it. But now that I am this far I am sure I will find a way make my program fit a slightly different niche :P And finally, to your point about forking and waiting in the shell: This is indeed what it is and exactly what I wanted, but I could not find a program that does this already. Turns out `sem` was it.
Why not just `.skip(1000)`?
I want to create a trait that lets me use a range of iterators in my functions. My first attempt was to explicitly implement it for the type (`(&amp;[&amp;str]).iter()`) I use: trait InputIter: Clone + Debug + std::iter::Iterator::&lt;Item: Debug + Display + Into&lt;String&gt;&gt; {} impl InputIter for std::slice::Iter&lt;'_, &amp;str&gt; {} This code does not compile, since "`Into&lt;String&gt;` is not defined for `&amp;&amp;str`". I figured I could use a generalized impl instead, which does compile: impl&lt;T&gt; InputIter for T where T: Clone + Debug + std::iter::Iterator::&lt;Item: Debug + Display + Into&lt;String&gt;&gt; { } But I would like to understand how I could have made the explicit first version work. Is there a trick with which I could deref the type for the declaration?
The author and others in this thread seem to have mistaken the name “Entity-Component-System” for the generic phrase “entity-component system.” ECS is a design pattern and has three distinct parts: entities, components, and systems. While other design patterns have elements with similar names, such as the solution this post suggests, they have little else in common. Entity-Component-System is something like a relational database. An Entity is nothing more than a unique ID. Components are like tables indexed by Entity ID. Systems are like database clients or queries, which typically execute in a loop (the main game loop). For example, in ECS you might create two Components or tables `Sprite` and `Position`, then use them to implement a render System. The System can search for every Entity that has both of these Components. In RDBS terms, it joins¹ the two tables together on the Entity ID. The System can iterate over every row of the join, every pair of `Sprite` and `Position`, and draw a sprite accordingly. Other types of System might also write to Components. The type of design the author describes is much more like object-oriented programming. The author uses an enum to represent an Entity, but the result is equivalent to making a base `Entity` class and several classes that inherit from it such as `Sprite` or `Elevator`. In this design, Components are replaced by fields on the different classes and by the use of polymorphism, represented by the `match` statements in the author's `Entity` methods. ^(1. It's even named “join” in) [^(specs)](https://docs.rs/specs/0.14.3/specs/join/trait.Join.html)^(.)
I want to create a trait that lets me use a range of iterators in my functions, where I would among other things call `.next().into::&lt;String&gt;()` on it. My first attempt was to explicitly implement it for the type (`(&amp;[&amp;str]).iter()`) I use: trait InputIter: Clone + Debug + std::iter::Iterator::&lt;Item: Debug + Display + Into&lt;String&gt;&gt; {} impl InputIter for std::slice::Iter&lt;'_, &amp;str&gt; {} This code does not compile, since "trait `Into&lt;String&gt;` is not defined for `&amp;&amp;str`". I figured I could use a generalized impl instead, which does compile, but it doesn't let me use the trait with the my iterator since ""trait `From&lt;&amp;&amp;str&gt;` is not defined for `String`". impl&lt;T&gt; InputIter for T where T: Clone + Debug + std::iter::Iterator::&lt;Item: Debug + Display + Into&lt;String&gt;&gt; { } I would like to understand how I could make this work. Is there a trick with which I could deref the type for the declaration?
And here a b c I suppose c is a child of " b"? How many footguns are you going to put into this thing? I would get rid of the whole space-separated words thing. I would just allow for words to be "-encoded strings. In the very unlikely case that you want to encode the tree we were talking about earlier, you would write a "" b And it would also allow for the tree a b "" c which you currently cannot have. It also lets you have spaces in words, it solves the issue of the function that takes 2 strings as arguments, newlines and other weird unicode things can be encoded with the same escape sequences as in basically every other programming language on the planet, I would then also allow indentation to be *any* number of spaces, where the first child determines the amount of indentation. Perhaps even allow tabs. And I'd also separate words/strings by *any* number of spaces. You know, what Python does basically.
Hey, thanks for taking the time to read the post and write up a response! I probably should have anticipated this causing some confusion due to the recent popularity of entity component systems—I intentionally only used the term "entity component system" in once place in the article as an example of a more dynamic approach. The write up is considering entity systems in general of which ECS and inheritance based approaches are two examples. The approach I ended up going with for this game varies from the object oriented approach a few ways, namely that I'm not locked into any particular hierarchy as I'm sharing data &amp; behavior through composition rather than inheritance.
Thanks for the feedback, but again, none of these are problems in reality. We have over 10,000 programs now written in different Tree Languages and 0 instances of problems like this. They were hypothetical problems but they are all solved by Tree Grammars (syntax highlighting, cell checking, autosuggestions/fixes, etc). http://treenotation.org/sandbox/build/#standard%20fire &gt; basically every other programming language on the planet, No programming language on the planet will offer the program synthesis features of Tree Languages, nor have the network effects that these will have. Furthermore, 30M people can code but 7.5 BILLION people cannot, so I wouldn't say existing languages are necessarily so great, since the majority of people do not use any of them.
Thank you
What function?
 println!("---------------------------- | Hello, world! | ---------------------------- \ \ _~^~^~_ \) / o o \ (/ '_ - _' / '-----' \");
I have no idea, but it’s definitely something like `ferrissay`.
Sounds like [RFC 2363](https://github.com/rust-lang/rfcs/blob/master/text/2363-arbitrary-enum-discriminant.md).
Thanks!
Why would it have to be stored? Just compute it the same way each time.
Seems to be from this crate: https://docs.rs/ferris-says/0.1.1/ferris_says/fn.say.html
Reminder about the Call for Participation section: `winit` _really does_ need the help. If you have the skills please assist!
&gt; Actix is a great example of a developer thinking they knew how to write safe code despite unsafe, thinking "oh it's just a tool", and having vulnerable code. The rust community is vehemently anti-unsafe for this reason, as it should be. Have you spent much time looking at the code in the standard library? It has extensive use of unsafe. How does that comport with your view that unsafe should be looked treated as evil, more or less?
The key phrase here is "Multiplicative Persistence". http://mathworld.wolfram.com/MultiplicativePersistence.html I got curious about this after watching https://youtu.be/Wim9WJeDTHQ Basically it's 277777788888899 -&gt; 2×7^6×8^6×9^2 = some other number (X) where it's digits multiplied gives another number and this continues an astonishing 11 times until there is only a single digit is left. The goal of this program is to identify another number that can do the same, but 12 times. The task is to generate numbers that when digits are multiplied will equal X. This means shuffling these numbers and inserting 1s, because reasons see basic algebra. One of these numbers must, given there is obviously an infinite number of 1s to be included, be able to be also expressed as the product of only the numbers 2-9. Thus identifying a number with a Multiplicative Persistence of 12.
Is this different from appending `&amp;` to the end of your command?
&gt; The write up is considering entity systems in general of which ECS and inheritance based approaches are two examples. My comment meant to disagree with this. I don't think your entity system and ECS are two types of the same design, as they are mostly opposite in approach. Your design also has neither components nor systems, two of the three elements of Entity-Component-System design. &gt; I'm not locked into any particular hierarchy as I'm sharing data &amp; behavior through composition rather than inheritance. What do you mean by this? I don't see composition in your design. I see an inheritance relationship between `Entity` and the different concrete struct types. The function `color` for example operates on any `Entity` value. Each branch arm implements how to get a color from one of the types of entity, if possible. When you add rigid bodies, you will need to add another function like this. Whenever you add any new shared data or functionality, you will need new functions like this. If you add a new type of entity, you will need to add a new branch arm to the `match` in every function. This describes your design, but it also equally describes an abstract class with abstract methods.
So close
You'll have a field day with [typenum](https://crates.io/crates/typenum) then, giving you type-level numerals when the compiler couldn't!
Thanks! The "raw" prefix is required (r"..."), isn't it?
I don't know why you continue to troll this subreddit and make all your posts solely about moderation.
This is neat. I may not need to rewrite Parallel after all.
We have a lot of neat projects on the [Pop!_OS](https://github.com/pop-os?language=rust) and [System76](https://github.com/system76?language=rust) GitHub organizations.
What about using the parent pid to determine the default socket name?
Note that this is how rust _used to work_, but it no longer does. Matching on a reference now automatically uses `*val` and `ref` on any bindings, and is no longer an error as of [RFC 2005 (Match Ergonomics)](https://github.com/rust-lang/rfcs/blob/master/text/2005-match-ergonomics.md)
They’re similar just in that they’re both ways of organizing objects in a game world—I’m not particularly attached to the terminology here, if you’d prefer a different term feel free to sub it in. :) The composition I’m referring to is just the way in which the color, for example, is stored directly on each struct that wants one. You’re correct that it’s accomplishing a similar thing to inheritance, albeit in a slightly different way. When you use inheritance you’re creating a tree-like relationship between your types, and I’ve found that when I do that for an entity system I tend to end up with annoying refactors late in the project when I inevitably want to introduce shared functionality between two otherwise separate branches of the tree. I think a lot of other people have experienced the same thing, hence people not really doing things that way anymore
I'd suggest reading the most recent change on this behavior, [RFC 2005](https://github.com/rust-lang/rfcs/blob/master/text/2005-match-ergonomics.md). The rules used to be quite simple (values always move unless `ref x` is used), but that was inconvenient for a lot of use cases. The current rules should "just work" in most cases: v is borrowed if it's necessary because ptr is a borrow, or v is moved if it can be. --- The general rule is that matched values will be borrowed if dereferencing is necessary to make the pattern work. If `ptr` has type `&amp;Some&lt;u32&gt;`, then `Some()` doesn't match it. `Some()` does match `*ptr`, which has type `Some&lt;u32&gt;` - but since a dereference was involved in making the pattern match, `v` becomes `ref v`.
It's the absolute best place for 3s in america
Honestly, I'd say this a superior design. GNU Parallel has limitations to what it can parallelize at a given time. This would let you run all manner of different tasks on the same job server.
Lol, you're cool. Dunno why the other rusteceans gave me the downvote. I must say, arcade UFO was pretty cool. My favorite 3s spots are Logan Arcade in Chicago, arcade UFO and Akihabara arcade in Denver. Looking forward to going to Don's one day though.
/r/rustjerk
Damn that scurrilous Dose Of Crown! But I think you wanted /r/playrust.
&gt;My comment meant to disagree with this. I don't think your entity system and ECS are two types of the same design, as they are mostly opposite in approach. Your design also has neither components nor systems, two of the three elements of Entity-Component-System design. I agree that the approach I'm trying out in this game bears little resemblance to an entity component system—they're only similar insofar as they're both solutions to the problem of organizing objects in a game world. (If you don't like the term "entity system" for a pattern that does that, feel free to sub in an alternative term.) &gt;What do you mean by this? I don't see composition in your design. I see an inheritance relationship between `Entity` and the different concrete struct types. The composition I’m referring to is just the way color, for example, is stored directly on each struct that wants one. I agree that it’s accomplishing a similar thing to inheritance, albeit in a slightly different way. I've found that when I use inheritance to build an entity system, I end up with a lot of annoying refactors late in the project when I inevitably want to share behavior between previously unrelated branches of the hierarchy. I think a lot of people have experienced that same problem hence that approach falling out of favor (it isn't an issue under this approach as you can copy the components into whichever structs you like, assuming you set up the appropriate boiler plate.)
Congrats u/mgattozzi on getting new users to stay for the long haul.
Let me start by saying the Rust community is one of the friendliest, most helpful internet communities I’ve ever seen, especially given how dogmatic and rabid programmers usually are when it comes to their tools. Really, I genuinely do think extremely highly of the Rust community. Buuuuut….. &gt; It's being downvoted because it purports that rejecting unsafe usage is rejecting a useful tool, Your comment is the perfect stereotype of exactly the stupidity I am talking about. You hear the word "unsafe" and don't stop for a moment to think before lurching into the "It's not the Rust way!" diatribe typical of the cult of safe-code-only, because it’s a curiously ubiquitous deficiency of irrational people that if anyone points out a better way of doing such-and-such with “unsafe”—the religious commitment they’ve invested in—the sunk cost fallacy compels them to circle the wagons around the very mechanism that wastes their time, cripples their code design, and hobbles the performance of their software instead of learning something new about an intentional and important feature of the language they so desperately claim to embrace. Because if you *had* stopped to think—or better, *read* what was written, you would have found yourself in an argument about the “right way” to use Rust with the very inventors of the language who unequivocally do believe that "rejecting unsafe code usage is rejecting a useful tool.” But maybe the way out of this mess is to somehow re-imagine the message of the post you were replying to and hope that nobody notices... &gt; The Rust community consistently discourages usage of unsafe where it isn't strictly necessary and it's a good thing. Uh, there it is! And you only needed two weasel words to say something almost, but not quite, completely unrelated to the thing you were replying to. The claim he made, specifically, is this one: &gt; &gt; Most large large projects will come to a point where it is easiest to use unsafe for custom data structures than to accomplish the same thing with all the boxes and cells and copying. This claim, if we should even call it that, is so freakin' incredibly obvious that its denial could only come from a mind not merely clouded by unbounded irrational zealotry but also unburdened by the need for real-time performance or other “systems programming” applications that Rust actually explicitly targets. The “claim” is not even an opinion, *[it is literally an empirical fact](https://www.tockos.org/blog/2017/crates-are-not-safe/)*. I’m just being an asshole for comedic effect, you’re probably a really cool and smart guy. But I do think the cult of safe-code-only is silly, and it plainly is a fact that “most large projects will come to a point where it is easiest to use unsafe for custom data structures….”
/r/playrust
ooops haha
Ah yeah that's my crate glad some people are enjoying it 😊 I had made it as part of my 2017 RustConf talk!
@ctbur posted another alternative - [https://github.com/ctbur/async/](https://github.com/ctbur/async/) &amp;#x200B; See [https://www.reddit.com/r/rust/comments/c66dtz/async\_parallelize\_your\_shell\_commands/](https://www.reddit.com/r/rust/comments/c66dtz/async_parallelize_your_shell_commands/) Reddit discussion about it.
&gt; Well I would argue that you have everything you need to write functional code. The same applies to Lua or Go, but you wouldn't call them functional languages. In fact, you could argue that you can program in functional style in _any_ programming language, even C -- albeit not as conveniently. JS has several[1] frameworks that emphasize functional programming, so it is most definitely _capable_ of functional programming, but that's not it's primary design goal. Again, functional programming languages are languages that emphasize functional programming as their _primary_ programming paradigm, like Haskell, the ML family and, arguably, Scheme and its descendants (e.g. Racket). And note that, even though Scheme and ML and clearly capable of imperative programming (they both support mutability and sequential statement execution, for example), you would not call them imperative languages, because imperative programming is not their main focus. Still, I can see why it _feels_ like Rust is a functional language. It implements a strong typing discipline and applies a lot of PL research into its design, something that functional languages tend to do more than imperative languages. Still, that isn't enough to call it functional. --- [1] Here's a whole bunch of fp-related frameworks in JS: https://github.com/stoeffel/awesome-fp-js
&gt;retain state Speaking about that - are you aware of the concept of incremental computation? And Adapton (last generation of it is implemented in Rust too): [http://adapton.org/](http://adapton.org/)
Blockchain &amp; Cryptocurrency is extremely lucurative for Rust revelopers, one of many examples found below: &amp;#x200B; [https://holochain.org/team.html](https://holochain.org/team.html)
You don't need `r""` to do multi-line strings,any string can span multiple lines. [https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ac51f75be904446704be8e8fcfcd0a1d](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=ac51f75be904446704be8e8fcfcd0a1d)
You sure like the victim role, do you? Would you still argue that these posts are in good faith and not for the drama? So far, you got 0 points, 6 reports. And this time I feel perfectly justified in removing this.
But the example that was being replied to has unescaped backslashes; so it either needs escapes or an `r` prefix.
Yes.
Uphold has the necessary licenses already. Your comment above about "solicit donations" and "GDPR" is out of date. Tom Scott pointed out the errors in the tipping design from last December and we fixed them right away. Here's his final word on it: &amp;#x200B; Imputing malice where stupidity or (my view) earnest zeal on the part of the product design folks at Brave loses to Hanlon's razor. Unless you have some other ax to grind with me? In any case, it doesn't fit in r/rust.
Wrong sub. You're looking for /r/playrust.
Have you tried it?
And Brave Ads are opt in, and we pay users 70% of the gross. This aligns incentives: if users don't like it, we'll go out of business. The only scam cited in this thread is 3rd party ad tech, which facilitates tens of billions per year in fraud, as well as malware distribution and data breaches.
A significant purpose of std is to implement lower level data structures, where unsafe is a requirement, so that *you don't have to*. And I never said unsafe is evil, I said it's difficult and generally unnecessary.
&gt; I keep hearing that it's hard to find a Rust developer, Often the roles seem to be outsourced to recruiters. I had one contact me about a role I was highly relevant for(Rust, 3D Graphics, Web frontend), the recruiter even re-iterated that the employer had stated "It's difficult to find Rust devs here, send any my way!". All was going well until touching on references at the end where I shared I unfortunately was not able to provide references from paid professional work(not honest ones anyway), but could provide references from volunteer/open-source community work. It ended not long after that, the recruiter expressed they'd see what they could do and let me know, which amounted to a week later of "I'm still working on it", and 1-2 week later follow up to that asking if they're still "working" on it and if so what's actually been done. Ghosted. Skills and relevancy be damned, not even considered for putting forward to the employer.
Often means it's a recruiter, they want their cut.
&gt; You hear the word "unsafe" and don't stop for a moment to think I've been writing rust, and yes at some point unsafe rust, for years. I think it's fair to say that I have stopped for many, many moments to think about the language. I think your rant is mostly nonsense. You're attacking some made up "cult" in your mind because, shockingly, people want to know the code they use is safe, and don't trust developers. Pretty sure I already addressed the claim that large projects require unsafe. I work at a company with probably the single largest rust codebase, and it is fairly low level. Unsafe usage is extremely minimal, and unsafe is definitely discouraged. The claim is not empirical fact... the post by tock only shows that ~30% of crates *do* use unsafe, not that they *needed to* use unsafe. If anything, I believe that unsafe is *overused* in rust much of the time because people are too quick to assume that unsafe will be faster. Your facts are not facts. Your opinion is simply bad, and that is why there are downvotes. Present it however you like.
Is `Option&lt;&amp;mut dyn T&gt;` FFI-safe? I know that `dyn T` isn't (and thus `Option&lt;dyn T&gt;` isn't), but `&amp;mut T` is safe. To avoid the X-Y problem, I'm trying to write [a library](https://github.com/openSUSE/libpathrs) which has multiple backend implementations (based on what features the host kernel has). The most obvious way (for me at least) was to have `dyn Trait`s which are returned from the backends and then used by library consumers (it also allows me to write "generic" `impl Trait {}` helpers that don't need to be copied for each backend).
I guess I misunderstood. From your post I got the impression that `BStr` is a vestige for the sake of the `Debug`, so my suggestion was in the spirit of brainstorming ways of completely getting rid of `BStr` / `BString` and having everything exist on the extension trait. (yes, technically there would still be a struct that `.display()` would return but then its a whole abstraction that follows existing patterns).
Could you provide an example of consuming? Because passing ownership still keeps it around: someone has to be allowed to free it eventually.
I filled in some of the blanks after writing something that gives an approximation of what I'm looking for. https://gitlab.com/cheako/multiplicative_persistence_searcher/blob/46183e6f7b2c087dcf16ecc707f1bda24c33032a/src/main.rs#L73 https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=244f10e563858eebff6fa30b7bed886a
This looks very similar to akramer's lateral command. [https://github.com/akramer/lateral](https://github.com/akramer/lateral) that I've also ported to rust and can be installed via `cargo install lateral` I haven't looked at your implementation, but the syntax for starting commands is a little different. lateral supports arbitrary file descriptor passing, and adjusting the number of inflight commands allowed while running. Not sure if async supports those or not. Here's a brief example, more can be found on the README.md $ lateral start $ for i in $(seq 1 100); do lateral run -- my_slow_command &lt; workfile$i &gt; /tmp/logfile$i $ done $ lateral wait
crabsay
Ah ok, that's fair
Try and post it to /r/playrust.
69x? Holy shit
If I have an iterator with a closure and with the closure it is calling a function that returns a Result&lt;&gt;. If the result is an Err how to I tell the iterator to go to the next one, like "continue". some-vec.iter().for_each(|url|｛ let var = get_url(url); let var = match var ｛ OK(feed) =&gt; feed, Err(e) =&gt; return () ｝; ｝) The return () works but I don't think that is the best way. I just want the iterator to move to the next one if an Err is returned from the function get_url(). What is best practice? Thanks
I've worked with ColdFusion in the past. If you can put something together without the weird quirks, high resource usage, and price tag, I'd certainly be interested. For all the faults it had, prototyping in CFML was *really* fast. I only worry that it's a bit dated at this point...
Read subreddit descriptions before posting (also applies on all subreddits).
sorry i just searches r/rust and assumed this was a sub for rust
Oh, I see what you mean. I was mostly referring to passing ownership in any way – if you pass the ownership of a linear type to someone else, then you've done your job. But other than moving an instance of a linear type, you could e.g. destructure it (and then consume its fields if those are also linear), or you could iterate it if it's an `IntoIterator`. I guess those would more or less be the options if Rust were ever to get linear types.
Inside `for_each` you can just `return` to go to the next value, because you're returning from the closure call for that particular value. And `return ()` just happens to be the same as `return`. If you're only interested in the `Ok` values and want to ignore all `Err` values, then you can also call `flat_map` and return the `Result` from the closure you pass it, i.e. urls.iter().flat_map(|url| get_url(url)) The resulting iterator is an iterator over the `Ok` values. This works because `Result` implements `IntoIterator`, where the iterator only contains the `Ok` value if the result is `Ok`, and the iterator is empty otherwise.
Yeah, that's my concern as well. We had a couple of clients that used the original Java code, and we were able to get a commercial following for it for a short amount of time. We purposefully priced the project to something 1/2 to 1/3 the cost of ColdFusion, but it was just me working on the project, and it wasn't enough to keep the lights on. Now-a-days, it would not be sold or licensed. It's Apache-2.0, so there's no cost for it. It's 100% free, and will always be. But that depends on whether or not there's any actual interest in such a project. ;-)
Could be. I do know that closure arguments are a _pattern_ and not really just arguments, so that could be a contributing factor.
I personally disagree. "Beautiful" is certainly subjective, but my definition of a "beautiful" syntax is a syntax that has a consistent cadence, without lots of things that step outside the normal syntax rules. In one aspect, I think Lisp is pretty beautiful. If the excessive number of parenthesis wasn't so tedious, then I'd really prefer it. C++ is really _not_ beautiful, because there are so many different pieces of syntax that don't necessarily fit together. Rust is _fairly_ consistent. It can get verbose sometimes, but I don't mind it if the verboseness comes from following the already established syntax rules.
Stuff like that is a mixed bag for me. DSLs are a great idea, but generally I'm not comfortable with them existing outside something like a config file. The syntax rules just seem too ambiguous and make it so I can't "see" what is being done. At least macros use a bang (`!`) to alert you that there's a macro-specific syntax about to be used.
Yeah that explains it.
Why XML? I’m familiar with the concepts of ColdFusion, but I’ve never worked in it.
Well, ok, thanks for your thought :) I'm gonna toy a bit with a regexp or direct byte counting, maybe I can work something out from the expected distribution, but I don't expect there to be a gain.
But how would you compute it the same way, so that two instances of the program in different scripts never interfere?
Yes. The main difference is that you can specify how many commands to run at once, similar to make.
Hi mmstick, thanks for commenting! Don't let my project discourage you from doing yours, since we are clearly targeting different use cases. I will try to make async as simple to use as possible, but it will never be as powerful as parallel.
This would make the assumption that no two servers share their parent process. Maybe I'm too cautious, but I don't think a potential user would expect to see inteference in this case.
Thanks, I'll have a look at it.
I think I mostly agree with you :) The nice thing about macros in Rust is indeed the "here be dragons" warning you get once you see the `!`. But the disadvantage of using macros (especially proc macros) everywhere is that, sometimes, there really *are* dragons hiding in there. Because those macros can do...well, not *whatever* they want, but mostly. So it's much harder to learn the syntax of a DSL written in a Rust macro, imho, because the syntax choices are 100% up to whomever wrote the macro. In Kotlin's Builders, on the other hand, the normal rules of the language apply. Guaranteed. So once you get the hang of the syntax just once, you know what to do and what not to do. Probably equally important: your IDE knows ;) Of course, this again limits the flexibility of the DSL syntax. So, there needs to be a balance. How you want to balance the syntax is probably a matter of taste. But in my opinion, Rust is a *little* to rigid in its normal, non-macro syntax. You're right in that DSLs can be too magic someties. But I'd argue that this problem applies to normal function calls as well: At some point, you have to trust the author of the library you're using that they're not doing something weird. So, all in all, the syntax rules being very ambigous is, imho, more a problem of the Rust macro way of creating DSLs, compared to the Kotlin / Elixir / whatever way, because in those languages, you can still trust that the normal syntax rules of the language apply.
Thanks for the info! I will have a look at lateral and your port.
The implementation of frozen rows and columns in the data grid is janky, because you depend on scroll-linked effects, synchronising the scroll position to the frozen cells which exist outside the scrolled area. I recommend avoiding that technique: the way to make it smooth is to place the frozen cells inside the scrollable area, using `position: sticky` and either `top` or `left`, depending on whether you’re freezing a row or a column. This has the side-effect that the scrollbars will span the full width and height. This is not quite so desirable for row and column *headings*, but is generally acceptable; and it’s generally a good thing with respect to frozen rows and columns in the data grid, especially insofar as it makes the scroll wheel or touch scrolling work on the sticky cells.
I think you're in the wrong sub...this sub is about rust, a programming language
I laughed more than I should have.
I'm not sure what "interfere" means here.
You can also run different servers for e.g., I/O and compute intensive tasks to max out multiple resouces. About GNU Parallel: Another commenter showed me [sem](https://www.gnu.org/software/parallel/sem.html), which is part of GNU Parallel and has similar capabilities as `async`.
What is an "XML language? And what are the use case ? Why would somebody use that instead of some other language?
That doesn't help with the “fast” part though.
Parity Technologies (formerly EthCore)
Yeah I know, a lot of people like mathematics also because it's beautiful to them with short letter-like syntax. Python syntax was written by a linguist, which makes it more beautiful to people who enjoy nice flowing text. So it's just different kinds of beautiful I guess.
When you get to lifetimes, your love will be challenged a bit :)
Hi, I sent you a private message. Thanks.
Hi, I sent you a private message. Thanks.
Hi, I sent you a private message. Thanks.
If you want more information on the role, feel free to message me privately. Thanks.
Interesting project! My immediate question is how will this project differ from [quinn](https://github.com/djc/quinn) and [quiche](https://github.com/cloudflare/quiche) ? Is it intended to be the Firefox implementation of QUIC ?
`sccache` works great if the path to your project and build directory is fixed. It doesn't appear to work well for builds occurring in temporary directories because [the current working directory is part of the scheme being hashed](https://github.com/mozilla/sccache/issues/35). This means that the same project built in directory A and the same project built in directory B cannot share the same build artifacts, meaning a near 100% cache miss.
Hold your hopes, wait until you meet the borrow checker.
I dunno, I never had any use cases for that. Either I'm running a homogenous workload with `parallel` where I know what the resource consumption per job is and can set `-j` appropriately, or I'm just spawning a new terminal tab for another long-running job where I don't anticipate resource exhaustion.
I love how the lifetimes hurt me, am I a freak?
Can't help but think the name could lead to confusion. Seems like an opportunity missed: how about **ashync**? :)
All the major browsers, vendors, CDN providers etc. involved in the protocol's WG have their own implementations of QUIC and compare what they have implemented for testing + development work.
Fixed.
That 30% also doesn't show places where unsafe would have been an easier, cleaner, better performing option. Because of beliefs like yours, it is more likely to undercount. I think when he refers to the cult of safe, he's referring to the avoid unsafe at all costs group. If you'd doing that, you're not making an informed trade off, just being dogmatic.
The reference you can pass as a pointer since it's just a number. However if `dyn T` is not, you can ever dereference that pointer, only store it. Depends on your usecase I suppose.
Most use VSCode + Rust plugin. For linting and formatting, cargo clippy and fmt are the best tools for the job.
Many projects reimplement standard structures - almost every c++ and java codebase ive been a part of has had a need to do that, and needs exist in rust just as much.
Many projects reimplement standard structures - almost every c++ and java codebase ive been a part of has had a need to do that, and needs exist in rust just as much.
Don't you find the completion slow?
Tmux + Neovim + RLS mostly.
Super keen for this rfc
My interpretation is that `poll` doesn't get called on any future before it's awaited. Your `get_one()` function would return `Poll::Ready(1)` when `poll` is called, but until you await it, `poll` won't be called and the body not executed. If you're implementing `Future` manually, then you can do any setup you want in the constructor, but for `async` functions and blocks, the body goes entirely into the `poll` function implementation.
Thanks for that suggestion. I'll try to play with `position: sticky` to see if it is feasible. Do note that the `frozen rows` aside from floating at the top of the rows, it also scrolls horizontally together with the normal rows.
Sometimes, but it’s usable for the most part.
Rather than messing around with `*mut &amp;mut dyn T`, I ended up just passing around a struct that has my `Box&lt;dyn T&gt;` embedded and then doing a `Box::leak` on the wrapping struct. With a bit of `Deref` and `DerefMut`, it works just as well and the return signatures now look more ergonomic and `cbindgen` understands them (`-&gt; Option&lt;&amp;'static mut CRoot&gt;`).
I think OP isn't asking *when* `poll` is first called, but rather whether it will return `Pending` or `Ready` the first time it is called (the former of which would mean that it needs to be called once more). But you also answered that question in passing, and it matches my expectations.
Well, I want to clear up that the `Option` struct is a rust-concept and doesn't lend itself nicely to being passed through FFI boundaries. To my knowledge, you couldn't pass an option to an FFI at all, nor can you return an option from an FFI. The goal of a FFI interface (in my option) is to encapsulate a FFI error into a Rust error. For example, an FFI might return a pointer that could be null, and in that case the receiving rust code should check for the null value and return `None` if it's null or `Some(data_ptr)` if the `data_ptr`isn't null. You can check nullity with the [is_null](https://doc.rust-lang.org/std/primitive.pointer.html#method.is_null) function. A block of code might look like this let data_ptr = unsafe { some_ffi_call_that_returns_a_pointer(param, [params...]) }; if data_ptr.is_null() { None } else { Some(data_ptr) } Typically, you would look at the pointer at this point and see if the data is valid and return `None` or `Err` based on the different possible malformations of said data. ---- If you're looking to use different C backends with dyn Trait what you'd probably want to do is have a concrete struct for each backend and a way to initialize/load/parse w/e library constructs in that particular implementation. Then you'd have a the handling and loading return a dyn Trait but you wouldn't be passing or loading a dyn Trait directly from C. ----- Hope that helps. If I missed the mark or you want some clarification let me know but I'll be on a plane for a few hours so I'll take a look when I can :).
So is it "Yet Another Extensible Markup Language Language"? :)
YAXL for _YAXL Ain't XML Language_?
Update: OMG 117 upvotes wtf, didn't think it would get this popular. Thanks so much guys 😎
That's how things should be... not like WebSql which chrome forces upon users despite there only being one implementation.
What's the point of rust editions if they keep changing like this? edition 2018 already enables NLL. So this change will basically break crates that is not edition 2018 because reasons? I was under the impression that the introduction of rust editions was to be able to perform forward-breaking compatibility for the greater good. But this change seem to do backward-breaking compatibility, seemingly making the whole edition concept moot.
Were you using NVim before?
It's not going to break code: &gt; As you might have guessed, we are only turning on the NLL migration mode. If a crate has been unknowingly taking advantage of some soundness bug in order to be accepted by the AST borrow-check, the initial impact of NLL on that crate should be limited to future-compatibility warnings.
The first paragraph of blog article reads: &gt; Going forward, all editions of Rust will now use NLL. That is a big change. It is mostly an change that empowers developers; but it also is a change that will cause some existing code to break.
Downvoted for raising a valid question? WTG rust
It does seem to be intended for usage as part of Gecko (the engine underlying most Firefox browsers). To be honest, I am disappointed Mozilla did not approach us to discuss collaboration on Quinn.
Huh, that's super annoying. If I were an employer, I'd better not let such an awful company handle the recruitment.
Technically I was using sublime text 2 when I first started out using rust around 4 years ago. This is technically my first programming job and rust is one of a few languages we use, my preferences have changed a good bit over the years. I just like having the ability to switch to terminal easily and do whatever I need to rather than have UI for it. E.G. I'll have a connection to a database on one tmux window with neovim on another and another for things like cargo build and grepping, etc.
Rust stability guarantees do not extend to soundness bugs. Code which breaks has previously been unsound.
Hi, thanks. I wasn't sure why my empty return was working.
Terminator + Neovim + RLS + TabNine. And many small personal scripts and tools.
Fuchsia's Zircon Microkernel supports all kind of languages to write modules. C, C++, Dart, Go, etc. It does NOT have any Rust code inside. See [https://news.ycombinator.com/item?id=17474185](https://news.ycombinator.com/item?id=17474185)
No, they hurt you so you dont hurt yourself. They love you.
Probably "Yet Another XML Language".
IDEA
I've heard that the plugin doesn't use the RLS, how's it working out for you?
How can Chrome force anyone to use WebSQL? Besides, it was/is implemented by more browsers and the bulk of the code is from sqlite, which is in the public domain. Wasn't the big problem that the proposed standard wasn't documented enough? Which to me is a minor problem if the same implementation is used by all.
It's the best Rust experience at the moment. Semantic highlight, the best autocompletion, almost complete Go to Definition, macros expansion, etc. IDEA itself on the other hand...
Since Quinn is also Rust, your point is valid. My understanding is done implementations are more compliant to the emerging standard than others. Can anyone elaborate on the current readiness for experimental use and how much backing there is to these two?
Is Quic royalty free?
Independent scripts using the same socket
[https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=0f3a19acc191b0a5720186b84277ca9e](https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=0f3a19acc191b0a5720186b84277ca9e) &amp;#x200B; Playground example full of unsafe boilerplate that will be in libraries like futures/tokio. But you can see that the future only needs to be polled once to get the result.
as far as i can see he is upvoted, wtg /u/birkbork ?
I switched from Neovim + RLS to CLIon the first week of doing Rust full time. Reliable code navigation, refactoring tools and debugger were what sold it. I wrote about it in [this post on my blog](https://www.wezm.net/technical/2019/03/first-3-weeks-of-professional-rust/).
It’s not a backward breaking compatibility change. The only code which will fail to compile is buggy code. The bugs are memory unsoundness issue which, due to bugs in the lexical-lifetime borrow checker, where erroneously allowed through by the compiler. Every correctly written app will continue to compile without issue.
Emacs + eglot + RLS
They have broken backwards-compatibility because of unsoundsness bugs before, and that's what is going on here. The particular cases where this will break old code have been throwing warnings saying "this will be upgraded to a hard error in a later release" for a long time, and because of the editions feature, they can ensure no new code contains any of these problems. If your code will break by this update, there is a bug in it. It only happens in some edge cases where you can cause unsoundness without using an `unsafe` block, which is a pretty bad problem, that really should be fixed, and you will have been getting warnings about the problem for a long time.
&gt; but it also is a change that will cause some existing code to break Note that thhis "existing code" will break _because it is incorrect_ and used to be accepted because of compiler bugs. To me, and maybe you'll find it more acceptable, the author's meaning is this: "but it also is a change that will reject some existing invalid code which shouldn't have been accepted in the first place, so that even people still on the 2015 edition can finally see these errors"
I get a lot of weird issues and rust panics when trying to do anything with the demo? - Load the app, scroll down a bit, suddenly the entire left column becomes super wide. - Load the app, double click a row, and now it shows me just that row with no way to return? Clicking "Run query" doesn't do anything. Sometimes however double-clicking does something different and does actually show a close button with other rows below. - Generally clicking around for a bit I see panics at " at sauron::dom::apply_patches::patch::h9fe48fbaf4d05459 (wasm-function[84]:13084)"
What is the purpose of this? Everyone I've worked with, including myself, hate XML.
vscode Insiders with rust analyzer built from master every morning. and vim for when it crashes/slows down too much 😅
Neovim + TabNine + clippy There's barely any semantic completion, but eh it's ok.
tmux + neovim + rust-analyzer. Rust-analyzer is almost feature-complete now, despite of the fast-moving, it's quite stable.
I'm sorry to hear that. Maybe they might be interested in collaborating with Quinn's developers? Personally I would love for the Rust community to have a popular QUIC implementation baked by a company such as Mozilla. It would also make it much easier for me to sell Rust to the company I work for atm. :) (They might adopt QUIC in the future and having a Rust implementation used by millions of users would definitely be a strong argument)
I think you misunderstood which FFI I was referring to -- I'm talking about C code calling into Rust functions (`pub extern fn foo() { }`) not the other way around (`extern fn foo();`). In the former, it is true that `Option&lt;&amp;T&gt;` (or more accurately, `Option&lt;T&gt;` where T is a non-nullable type) is FFI-safe. The `None` is represented as `NULL`.
This is correct. In many other languages, async functions begin executing immediately, but in Rust, they only begin executing the first time you call `poll` on the future. This is the difference that section is referring to.
There is no "starting execution" really, what this is talking about is the future doesn't execute any code in the body until the _first_ poll call. I think "yield immediately" is just an unfortunately clashing term to describe what happens. A good example is what your function sort of looks like after the transform, you can think of it becoming something like: ```rust fn get_one() -&gt; impl Future&lt;Output = usize&gt; { struct GeneratedFuture { ... }; impl Future for GeneratedFuture { ... }; GeneratedFuture { ... } } ``` where the code you write in the function is moved into `fn poll` inside the `impl Future`. This function (`get_one`) just constructs the generated type and returns it, without executing any of your code. Once that generated future is polled _the first time_ it will enter the code you wrote inside the `poll` call and do whatever it needs to.
Because our business partners (banks) showed a screenshot of Netscape 8 with xml on it and passionately explained to us we have to use it to securely connect to their server. I bet it's secure because no bad guys want to touch it.
Emacs and rls
IntelliJ IDEA with Rust plugin on the left half of my screen, terminal on the right half, browser on my laptop screen.
I don't quite know what you mean with "how do you setup your workspace"? Do you mean "physical design" aka directory/file setups? If so I use cargo workspaces if multiple crates are involved. If some more fancy build steps are involved (packaging `AppImage`s or `deb`s) then there's often a "deploy" or "misc"/"tools" folder in there as well. As for tooling, I use CLion and I'm really happy with it. I use `rustfmt` and `clippy` (both enforced via CI). I don't use it often but sometimes `cargo-lichking` is nice for checking licenses and `cargo-tree` is nice for visualizing the dependency tree. Not really about "tooling" but I use the `beta` channel for everything on my dev-machine, the CI runs on `stable`, I don't do it to enable new features but just to get a chance to test the upcoming versions for stability.
Setting up the workspace would involve, for example, setup weird tools or configs you might have that enable you to work better
Same here. I use [coc.nvim](https://github.com/neoclide/coc.nvim) as my autocompletion engine along with [coc-snippets](https://github.com/neoclide/coc-snippets) for a pretty fluid and fast VSCode-like experience. It looks great on Neovim 0.4 unstable with popup support enabled, as shown in [this C++ example](https://www.google.com/search?q=coc.nvim+popup&amp;tbm=isch&amp;tbs=itp:animated&amp;client=ms-android-hms-tmobile-us&amp;prmd=ivn&amp;hl=en-US&amp;ved=2ahUKEwiy6v-qjYzjAhWDK48KHTT1B9oQ2p8EegQIARAD&amp;biw=360&amp;bih=598#imgrc=ElbjGtg_MlsaKM).
Same here. I use [coc.nvim](https://github.com/neoclide/coc.nvim) as my LSP engine along with [coc-snippets](https://github.com/neoclide/coc-snippets) for a pretty fluid and fast VSCode-like experience. It looks great on Neovim 0.4 unstable with popup support enabled, as shown in [this C++ example](https://www.google.com/search?q=coc.nvim+popup&amp;tbm=isch&amp;tbs=itp:animated&amp;client=ms-android-hms-tmobile-us&amp;prmd=ivn&amp;hl=en-US&amp;ved=2ahUKEwiy6v-qjYzjAhWDK48KHTT1B9oQ2p8EegQIARAD&amp;biw=360&amp;bih=598#imgrc=ElbjGtg_MlsaKM).
tabbed + vim + rls
Yes, it is being developed and standardized by the a working group (under the IETF) and the IETF respectively. So it will become an internet standard just like UDP, TCP, HTTP, etc.
Also `getrandom` v0.1.4 is released with various [improvements](https://github.com/rust-random/getrandom/blob/master/CHANGELOG.md#014---2019-06-28). A big shout-out to [josephlr](https://github.com/josephlr) for his contributions! Additionally there is a [PR proposal](https://github.com/rust-lang/rust/pull/62082) to use `getrandom` in `std`.
I am trying to turn Phil's blog_os into a minimal unikernel as a learning exercise. As a first step I want to embed some assembly into blog_os with `static bin : [u8; N] = [some valid x86 assembly]`, then jmp to it (execute it). I imagine I'll have to do something to convince the processor it should actually execute the arbitrary bits in memory here, but I'm not sure what that is? But more directly my "easy" question is, how do I get a raw pointer to those static bytes? I've tried `let p_bin : *const u32 = &amp;bin as *const u32;` which fails to compile with the error `expected u8, found u32`, and for some reason google isn't turning anything up for me.
Instead of `flat_map` you can also use `filter_map`, which allows you to unwrap the `Ok` values, so your iterator doesn't contain results. This works because `ok()` turns an ok result into a `Some`, and an err result into a `None`. ``` urls.iter().filter_map(|url| get_url(url).ok()) ```
If you want the implementation be the standard then that's fine, sure. It doesn't really help with allowing independent implementations though as they need to be based on the "reference" implementation and be bug-compatible. The standards document however becomes a worthless piece of text then. It's a problem with many other "standards" already where the original implementation became the source of truth.
The question was more like "how default poll implementation could look like", but it seems like I was not clear enough about it. :)
&gt; If an async function has no await points, it will return Ready the first time poll is called. This means that if we have, say, async fn with some old school heavy computation in it (w/o any awaits), we better manually offload it to some explicit compute thread to not to block executor?
Tools: `vim`, `rg`, and a custom reindent tool that does tabs-to-spaces and spaces-to-tabs conversions. My `vimrc` is quite large, but only a few lines are Rust-related. I only use Rust syntax highlighting, not the other Rust-related vim configs.
&gt; - Load the app, scroll down a bit, suddenly the entire left column becomes super wide. This is new, I'm not what sure what's the cause here. It would help me a lot if you could do a screen capture, with the details on the browser, version and OS. &gt; - Load the app, double click a row, and now it shows me just that row with no way to return? Clicking "Run query" doesn't do anything. Sometimes however double-clicking does something different and does actually show a close button with other rows below. Most of the functionality is Work-in-progress. The toolbar buttons doesn't work yet. Right now, I'm focusing on the overall interaction of the Grid and performance of the UI, getting rid of sluggishness as with the previous versions. &gt; - Generally clicking around for a bit I see panics at " at sauron::dom::apply_patches::patch::h9fe48fbaf4d05459 (wasm-function[84]:13084)" I've encountered this while debugging the early iterations of the app. It could be that you are using a relatively older browser. Maybe try to update the browser will fix this.
This thing looks shady...
&gt; Once that generated future is polled the first time it will enter the code you wrote inside the poll call and do whatever it needs to. The problem is that I see at least two approaches to `do whatever it needs to`: 1. execute given block statement by statement on current thread until first `await` or `return` and then return `Poll::Pending` or `Poll::Ready(..)` depending on what happens first; 2. schedule `(given block + wake call)` for execution on some internal thread pool and return `Poll::Pending` immediately to not to use executor's thread for a long time. The latter will require some special resource for futures to actually compute/wait for result on, the former will block main executor's thread forever if somebody tries to wrap `10000000000!` into async.
&gt; so this is rejected by the compiler The compiler issues an error I suspect there should be a `.` before `The`.
&gt; so my suggestion was in the spirit of brainstorming ways of completely getting rid of BStr / BString Oh I see, yeah, I don't think that can work. It's useful to have `BStr`/`BString` if you want to make them members of a struct and then `derive(Debug)`. Otherwise, if we relied on a separate `debug()` method (for example), then you'd have to impl `Debug` by hand for any types containing `BStr`/`BString`.
Are there any good sources that go into detail about getting rust and C to play nicely with each other? I seem to be having some memory issues where the C code thinks the vector I've created doesn't exist where the rust pointer says it is. I've checked out the [nomicon](https://doc.rust-lang.org/nomicon/ffi.html) and the [rust-ffi-omnibus](http://jakegoulding.com/rust-ffi-omnibus/basics/) but neither of them go into quite enough detail for me to crack the issue.
Capitalization and periods are kinda redundant tho, maybe they’re onto something
Linking to PR 55988 isn't working as expected, I think. --- &gt; do not have any constraint on` where in this control-flow I don't think that ` is meant to be there.
Also `StdRng` and `ThreadRng` have switched to ChaCha20 to take advantage of that new performance (effectively this is not a performance boost, but instead done because ChaCha20 is a more trusted RNG than HC-128).
Hmmm, it seems to me like there's a fair bit of unions that hasn't quite been decided yet. For example: https://github.com/rust-lang/unsafe-code-guidelines/issues/38 See also: https://github.com/rust-lang/unsafe-code-guidelines/issues/73 I'll see about following up on this to see if I can get a more concrete answer. cc /u/ralfj (See my post above.)
typo [https://github.com/firosolutions/cifiro](https://github.com/firosolutions/cifiro)
&gt; I'd better not let such an awful company handle the recruitment. The recruiter had said something like they had actually worked for the company they were handling prior, not quite sure what there role was, something like HR, but rather than just hiring for that company they had since jumped ship to work for an agency and represent many companies instead. I thought I was going to have a shot at a Rust job(or a job at that) by having a niche skill (at least in my area there aren't many Rust devs afaik)
The async transform guarantees the former, it has no hidden runtime dependencies so can't do the latter. You could manually implement a future that does the latter if you want, but generally futures don't spawn tasks behind your back, you would instead pass the future given to you by calling `get_one` off to a thread-pool and be given a handle to its result to await the computation.
Yes, it is a trade off. In the case of sqlite, which is on almost every computer nowdays I think it would have been ok to say that some version of it was the standard and then update the document with deviations as needed. It is after all really portable, free and of quite high quality. Anyway, the proposed API never became a standard and I still don't see how Chrome has the power to force anyone to use it. I mostly use Firefox and I've never seen a site where Web SQL has caused the site to fail.
Yeah it's sad that quinn won't get more users. Quinn is generic in the TLS implementation while neqo requires NSS. They are doing a hg clone in their build.rs... As long as quinn is being maintained I'll be using it myself.
&gt; Unfortunately it is not possible to make rand_core version 0.5 compatible with 0.4 It *is* possible to convert one `Error` type to another or vice-versa, and is also possible to construct a wrapper type making types supporting one `RngCore` compatible with the other. Of course this is not as good as "just works" but better than nothing; if there's sufficient interest we could publish this somehow (or just [copy this code](https://github.com/rust-random/rand/pull/819/files#diff-52e6ceb949d7fa383058092b498596b0)).
&gt; Anyway, the proposed API never became a standard and I still don't see how Chrome has the power to force anyone to use it. If it's no standard, Chrome should be removing it. Otherwise people will rely on chrome-only features and eventually even Chrome developers themselves can't remove/change/replace it any more. Nowadays anybody can compile sqlite to wasm which works cross-browser and doesn't lock anybody in.
Is this like the old Cowsay linux script?
You think that's neat, just wait until you see how safe your memory accesses are!
Or you could just spawn computation-heavy futures onto [`ThreadPool`](https://rust-lang-nursery.github.io/futures-api-docs/0.3.0-alpha.16/futures/executor/struct.ThreadPool.html).
The \`coc-tabnine\` plugin has just been released! \`:CocInstall coc-tabnine\`
RLS is not usable for projects of non trivial size. They are working on fixing that. I don't use Rust professionally, just hobby projects, but I tend to prefer just using vim, in linux, using the "unix as the ide" approach.
Ah, in this case there's nothing special, just the usual \`rustup component add X\`, setting up stuff is fairly easy, it's really refreshing coming from C/C++.
Can you share your code?
After read the post, I get the impression Clion is overall better (even excluding debugging?) than plain Idea + Plugin?
I think [this](https://doc.rust-lang.org/reference/items/external-blocks.html#the-link-attribute) is it. You'd then have to specify the function interface.
That was my guess
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rng] [Rust's rand 0.7 release](https://www.reddit.com/r/RNG/comments/c6k75x/rusts_rand_07_release/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
https://imgflip.com/i/34i7ek
Also, the MSRV got increased from 1.22.0 to 1.32.0, which is IMO a bit too recent for a library that's as core to the ecosystem as this. Hopefully one day rust will get an LTS to fix this problem.
Yeah, that's totally fair and it's far easier to make something UB now and then relax that in the future than to do the opposite so I imagine a lot of this is overly conservative so we have room to change things in the future. This was my point to GP though: recommending unsafe code to new users isn't generally a good idea because you need to understand a *huge* amount of Rust to actually write correct unsafe code. If you understand that much Rust, you're not a new user.
For something trivial that benefits from parallelism I use `fd`: ``` # checking FLAC streams fd . --extension flac --exec flac -t # shorter version # fd . -e flac -x flac -t ``` Quite an example of a KISS principle, also easy to remember (find this, do that). https://github.com/sharkdp/fd https://github.com/sharkdp/fd/blob/master/README.md#parallel-command-execution
This is surprising and disappointing to hear.
 I want to write a parser, where the main Expr struct has the following constraints: - contiguous in memory (arena style) - self-referential (Exprs refer to/contain more Exprs) - can be modified later (in semantic pass, etc) What's the Rust friendly way to go about achieving this? I've seen several parsers on github but they all sacrifice at least one of those things. I don't want to use nom or anything like that.
You can edit your post.
Yeah, the multiple scripts thing could be an issue. Looking at how `sem` handles it, it uses a per-user directory and defaults to naming sockets based on your TTY, which might be OK for interactive use but could be a footgun in scripts. One issue I see with your initial example is that it also uses the shell script footgun of specifying a hardcoded path to your socket, rather than a properly allocated temporary path. One way to make it nearly as convenient without a footgun might be to have `async server --start` (or just `async server` if you roll the stop into `wait`) allocate a temporary file for you appropriately print out the path to `stdout`, so you could do: ASYNC_SOCKET=$(async server) for img in dir/*.png; do for s in 32 64 128 256; do async -- gm convert "$img" -resize=${s}x${s} "${img%.png}-${s}.png}" done done async wait That would reduce the amount of ceremony to a minimum, while avoiding the footgun of multiple instances.
I'm using the latest stable chrome on windows 10. I would expect that to be one of if not the most common browser/OS combinations.
This seems to be true for most, but there is also this in the article: &gt; I freely admit that this does not represent undefined behavior of any sort. The language design team’s decision to outlaw this code was not based on catching soundness errors; the motivation was for overall consistency in the language.
The motivation for Rust editions was to have versioning for the language itself. The borrow-checker implementation doesn't (shouldn't?) change the language, only the compiler implementation. Therefore, it doesn't make sense to suggest edition migration here. Think about this this way, would it make sense to suggest to update C99 to C11 (or C++ 11 to 17) if GCC changed a compiler component which allowed them to report more invalid programs? &amp;#x200B; What should be done, and this is what this blog post is actually about, is to provide a migration period and tie it to a future \*compiler\* version. The post details this migration mode but does not set the time frame and therefore the future compiler version.
This makes me imagine some kind of tough-looking enforcer/loan shark character who makes sure you return the memory you borrowed (plus interest).
&gt; What's the point of rust editions if they keep changing like this? From my understanding of the current situation, editions are for changes you know are going to break lots of visible code, or have a high potential to break unknown code bases. See [this comment](https://github.com/rust-lang/rust/issues/53668#issuecomment-423319580) for details.
Quite many features in the edition 2018 book actually exist on edition 2015 as well. The "edition 2018 allows NLL" is and has been purely marketing. In fact, it's not even NLL yet on any edition, but to be precise, it's "migrate mode" NLL with enabled two-phase borrows. The two-phase borrows fix a great deal of issues people have with the borrow checker but the initial versions that 2018 shipped with had some soundness bugs. In fact, niko matsakis [has expressed regrets](https://github.com/rust-lang/rust/pull/58739#issuecomment-472496744) to shipping two-phase borrows that early in the process. The point of Rust editions is a) marketing (which seems to confuse you) b) idiom changes and c) addition of new keywords. New features, in general, will arrive on all editions unless they require new keywords.
I'm learning rust and decided to make a very basic HTTP server to serve files over local network. I decided to use [nom](https://docs.rs/nom/5.0.0/nom/) to make a basic HTTP request parser, but I'm stuck. I can parse the header just fine but I hit a wall when trying to "take everything until the end". Here is the parser's code: named!(http_request_parser&lt;&amp;str, Request&gt;, do_parse!( // Get the request's word (GET, PUT, POST...) word: take_until!(" ") &gt;&gt; tag!(" ") &gt;&gt; // Get the request's version (HTTP/1.1) version : take_until!("\n") &gt;&gt; tag!("\n") &gt;&gt; // Get the headers, several lines with the "Key: values values" format headers: many_till!(tuple!(take_until!("\n"), tag!("\n")), tag!("\n")) &gt;&gt; // Get the message_body, everything after the empty line message_body: many_till!(take!(1), eof!()) &gt;&gt; ( Request { word: String::from(word), version: String::from(version), headers: (headers.0).into_iter() .map(|(a, _)| a.split(": ")) .map(|mut kv| (kv.next().unwrap().into(), kv.next().unwrap().into())) .collect(), message_body: String::from(message_body.1), } ) ) ); Here is a sample request: GET HTTP/1.1 Key1: Value1 Key2: Value2 { "sample": "data" } The last line (after the empty line) is the message body (which is optional). What I want is once I'm done with the headers (`many_till!(tuple!(take_until!("\n"), tag!("\n")), tag!("\n"))`, basically take everything until you encounter an empty line), take everything until `EOF`. This is what I've tried: `many_till!(take!(1), eof!())`, which means "take 1 character repeatedly until EOF". The issue is that I apparently never reach `EOF`, since the result is `Err(Incomplete(Size(1)))`. Since I'm not technically parsing a file but a 0-terminated buffer, I tried replacing `eof!()` with `tag!("\0")` but the result is the same. Any idea what's wrong in there? Thanks in advance.
In the [seventh chapter](https://doc.rust-lang.org/book/ch07-00-managing-growing-projects-with-packages-crates-and-modules.html) of the Rust book thingy, it says every package contains "zero or one library crates, and no more. It can contain as many binary crates as you’d like, but it must contain at least one crate (either library or binary)." However, it doesn't go into the difference between these, so I'm assuming this isn't really a Rust-specific definition, but I'll ask here in case someone wants to help anyway. So: what's the difference between library and binary crates? What do you put in each?
This was discussed before [on Reddit](https://www.reddit.com/r/rust/comments/auyou5/support_for_old_compilers_in_libs_rand/) and [on GitHub](https://github.com/rust-random/rand/issues/719).
&gt; Uphold has the necessary licenses already. That's a bold approach. We'll see if you can manage the organisational juggling to pull that off. &gt; Your comment above about "solicit donations" and "GDPR" is out of date. Yes, I'm well aware that Brave backpedalled quite quickly. That was not the point. The point was that you in statements during that debacle, held Brave to other standards than the advertising industry you oppose. If you have since then renounced the statement of the original scheme being valid under the GDPR, then by all means, _show me_, and I'll remove it from my comment. &gt; Imputing malice where stupidity or (my view) earnest but excessive zeal on the part of the product design folks at Brave loses to Hanlon's razor. The critique is not on grounds of any perceived malicious intent. Rather, I am extremely confident that, as you say, you are on the other side of Halon's razor. The critique is simply about the act of sacrificing those morals for what many consider mere growth hacking.
I am not sure, but I had an impression that the article also assumed something like: "Your perfectly valid code *might* break because NLL might not handle some corner cases that are valid" Am I wrong?
vim + cargo fmt on save + casual manual cargo clippy
Nah, The is a first name.
Thanks for the links. They don't address my main concern though which is that debian etc. users should be able to compile rust software without needing third party binaries (rustup, etc). This *is* an onboarding hurdle. Not being able to tell users to `sudo apt install rustc` because very likely the rustc is going to be outdated is very sad for me. Even ubuntu which usually does publish latest rustc releases is still only on 1.32.0. It's not making it easier for distro users that rustc only compiles from rustc from one version earlier, not idk from the latest stable as well as the latest yearly released LTS.
I sincerely hope you backpedal when you make a mistake. We make mistakes and correct them when they're pointed out. If you are casting a stone from a place of perfection, you win. My statements during the debate about GDPR are defensible. We honored Tom Scott's erasure request. The legal issues were not GDPR, so much as "rights of promotion". So we moved to clients holding tips to unverified creators. Now there's a problem: possibly-interested creators who have not signed up do not know how many BAT in total are queued in browsers, awaiting their verification. We could still run ANONIZE surveys to find out the totals without any link to user id or among tips/contributions that could identify anyone. We would burn the results after notifying the unverified creators. And we would of course honor erasure requests by excluding anyone who did not want to be included, at any point when a survey was live. This would not violate GDPR or rights of promotion. It is not immoral in any coherent moral philosophy I know of. And it would be good for growth, where "hacking" is also not illegal or immoral per se. To jump from "mistake" to "immoral" you need to show evil intent as well as effects. You have not shown either. Enough with the irrational animus! Back to Rust.
You probably want something like `include!(concat!(env!("OUT_DIR"), "/bindings.rs"))`, however that is not supported by the IDEA plugin yet ([https://github.com/intellij-rust/intellij-rust/issues/1908](https://github.com/intellij-rust/intellij-rust/issues/1908)).
well, it may not be fast to compile, but it is fast to run. (all of the types in typenum are zero-sized so they don't affect the runtime performance at all)
I'm not sure you will get useful replies tho. If finding rust devs to hire is hard it means almost no-one is looking for a job, if they are good they have one or are not looking for right now. So to get most applications you should show them why they would prefer a shady reddit post than any other firm. Specially because if it can be 100% remote most people won't apply because they don't know that. Also not posting salary screams shitty salary, which screams not hiring any good rust dev.
We generally have striven for NLL to be an *increase* in expressiveness over the old AST borrow-checker. So if your code was sound and accepted by the AST borrow-checker, then it will almost always be accepted by NLL. So why do I say "almost always"? Well... There are known cases of code that 1. was sound, 2. but should not have been accepted under the AST borrow-checker's model of the universe, 3. but *was* accepted due to bugs in the AST borrow-checker. Many of these known cases *are* accepted under NLL, because we put in things like two-phase borrows to accept them. But some of them are rejected by NLL as it currently stands. Here is a recent example of this phenomenon that I encountered while preparing this blog post: [match guard is lengthening borrow unexpectedly under NLL #62170](https://github.com/rust-lang/rust/issues/62170) (Now, in this particular instance, my understanding is that a future version of NLL, a development project called Polonius, will support this kind of code; that's why that issue is tagged `NLL-Polonius`)
fixed, thanks!
I would like to know with which programming language the previous one was written in. &amp;#x200B; I'm especially interested in the data structures used. Choosing data structures that is a bad fit for the task can have a significant impact on performance. &amp;#x200B; The same is true for algorithms.
fixed, thanks!
How is this different from cargo audit?
Compiler of the The language?
&gt; My statements during the debate about GDPR are defensible. If you still stand by them, then we are done here. &gt; And it would be good for growth, where "hacking" is also not illegal or immoral per se. To jump from "mistake" to "immoral" you need to show evil intent as well as effects. "Don't be evil", was it not? People still take issue with their handling of personal data. I've been told you are amongst them?
Is there a good vim mode on this?
Indeed, we know that our current approach to issuing future-compatibility warnings is not sufficient. We have not yet set a time-frame for when these warnings will become hard errors, because we want to change the signaling of the warnings so that users of downstream creates have some notice that their upstream dependency is running afoul of one of these errors. You can see further discussion of these issues and the work being done to address them here: * [issue #34596: Future-incompatible warnings should always print a warning, even if lints are allowed](https://github.com/rust-lang/rust/issues/34596) * [pull request #59658: Minimum lint levels for C-future-compatibility issues](https://github.com/rust-lang/rust/pull/59658)
These are the most current instructions on how to do autoreload in 1.0. I'm trying to get the docs updated and merged today. Please let me know how it goes. Part of the delay in getting the docs updated is testing them.
Are there any plans in place for fully stabilizing the Rand API, or will it be under 1.0 for the foreseeable future?
You mean a markup language?
First, The job offer is vague. &amp;#x200B; 2nd, I and others living in the EU27 would want to know our status after Brexit day, 31th October 2019. &amp;#x200B; 3rd, The salary better be well paid, preferredly paid in € or US $, because the £ is going to be less worth, if the "wrecked economy" prediction becomes true.
I don't use Rust professionally (yet ;-)) but I use Emacs. LSP/eglot tend to get slow pretty quickly as the project size grows so I just have syntax highlighting enabled and use tag files for jumping around to definitions.
The main difference is that a binary crate will have a main function and drive a program, a library crate will just contain definitions for other crates to consume. E.g. [serde](https://github.com/serde-rs/serde) just contains the traits and items for other crates to use. [ripgrep](https://github.com/BurntSushi/ripgrep) is a program with a main() function.
This ^^^
IntelliJ IDEA has an okay vim mode, and I use it every day at work, but it is definitely not perfect.
&gt; Not being able to tell users to &gt; sudo apt install rustc &gt; because very likely the rustc is going to be outdated is very sad for me. Unfortunately, I don't think this is officially supported, given that it is not mentioned on the [Rust website](https://www.rust-lang.org/tools/install) and that old Rust versions don't get security fixes.
As far as I can tell, the API is still under active development and not likely to stabilize soon.
I see. So far the only acceptable vim mode I've used is the one from Visual Studio. It's very in-depth and can even parse your custom vimrc for bindings and simple stuff. I tried the IDEA version, but that was quite a few years ago and was hoping it got better since. However, I see someone implemented a bridge to integrate IntelliJ's features directly into vim. I could work with that.
Are you sure that's actually the actual update? Last change was a week ago. Well, it was mostly written a week ago...
Sublime 3 with rust-enhanced, LSP, &amp; Rustfmt plugins I use [rust analyzer](https://github.com/rust-analyzer/rust-analyzer), [rustfmt](https://github.com/rust-lang/rustfmt), &amp; [clippy](https://github.com/rust-lang/rust-clippy) &amp;#x200B; Rust Analyzer - is basically rust language server 2.0 rustfmt - is a rust formatting tool clippy - is a linter that improves code quality &amp;#x200B; Sublime 3 with rust analyzer autocompletes instantly.
This change does not break any existing Rust2015 code.
The IDEA vim mode also supports some sort of `.vimrc`, although I haven't tested how powerful it is. I think my only bindings in it are ``` inoremap jk &lt;esc&gt; nnoremap &lt;space&gt; : noremap 0 ^ noremap ^ 0 ``` Of course my real vimrc is much more elaborate.
&gt; I imagine I'll have to do something to convince the processor it should actually execute the arbitrary bits in memory here, but I'm not sure what that is? You shouldn’t have to do anything, unless that data ends up in a non-executable section of memory. But I’ve never seen an OS tutorial that marks memory as non-executable by default. &gt;how do I get a raw pointer to those static bytes? Slices should have a ‘as_ptr’ method.
So why not wait till that lands before breaking correct Rust2015 code?
I corrected some of my tweets - did you check them all? For example, I was wrong to think that public URIs are not personal data, and I said so at some point on Twitter. Your summary judgment probably missed some tweets, so pump your brakes. Brave servers do not process personal data. “So I’m told” is just lazy, as well as false if it uses GDPR terms. Do better or drop it. I suggest we go to a better forum if you insist. This has nothing to do with Rust.
Great news. The soundness hole is closing. Make sure to get your 0days in before migration mode completes in some future version.
Those safety fixes look rather serious. Why not backport them to 0.4.0 series so people would get the fixes automatically? Especially since 0.5.0 requires Rust 1.32, which is very recent, so people with older compilers are locked out of these fixes.
Thanks for working on the docs, it's the final part that I want to be merged before trying out Actix-web. :)
How is this different to https://github.com/RustSec/cargo-audit ?
Linked blog has its layout botched, so I cannot read the text: https://i.imgur.com/7DLGrqc.png
It was mentioned that this came with a change of algorithm (&amp; data), so it's unclear which part of the improvement comes Rust and which comes from the algorithm/data.
If you mean common feature set then no because debugger, profiler and valgrind memcheck integration are the only ones exclusive features for CLion at this moment. All code insight features like name resolution, completion, etc are the same for IDEA and CLion. But CLion can be smoother in some cases because default maximum memory limit is more then in IDEA
That's a great thing, and I have no problems with it! My problem is in how Snafu's philosophy is that you should have a new error enum PER module, and if you have something which accesses other modules, you'd have to make a new variant for this module. The philosophy is amazing and I love it, but it's done in such a way I'd have to make the same variants in many modules simply because one module is very core. If this again is core, it'd only add more and more to the outer ones.
Am I the only one bothered by the 3 L in Helllo? :x
No, and you should continue to use `ccache` in that case because IIRC there are some optimizations `sccache` forgoes as they are not compatible with a potentially distributed cache.
Atom + ide-rust plugin (rls) + atom-beautify plugin (rustfmt) However, lately I've found that the rls is too slow for my 30kloc codebase, so I made [my own tool](https://github.com/kaikalii/coral). It doesn't integrate into any editor, but it is faster than the rls itself, and it reports all your errors and warnings in a more compact way than `cargo check`.
Fixing soundness bugs can be a good reason to break some correct code, especially if the break is rare and there's a workaround that compiles with both the old and new compiler. This is similar to the idea that adding new methods to a trait can sometimes break previously correct code, but that code can be fixed by disambiguating its method calls.
That case is pretty thorny. You can't actually use such a partially-initialized object anyway (not even the part you wrote to!) so the newly-rejected code is equivalent to `let _ = Some(Rc::downgrade(&amp;c));`. It seems that all involved think you *should* be able to initialize and use objects piecemeal like that ([rust-lang/rust#54987](https://github.com/rust-lang/rust/issues/54987)), but that's a new feature that has never been RFCed. Treating nonsensical code like this as a compiler bug, in order to avoid technical debt, is not entirely unreasonable. It's possible the issue may be resolved before the warnings are upgraded to errors anyway, which would sidestep the whole problem.
&gt; So this change will basically break crates that is not edition 2018 because reasons? As pnkfelix mentions [here](https://www.reddit.com/r/rust/comments/c6hs2t/breaking_news_nonlexical_lifetimes_arrives_for/es9fwvu), this is about bug fixing: &gt; So why do I say "almost always"? Well... There are known cases of code that 1. was sound, 2. but should not have been accepted under the AST borrow-checker's model of the universe, 3. but was accepted due to bugs in the AST borrow-checker. That is: - Editions are about the backward compatibility of *the language*, modulo soundness issues. - Each compiler is responsible for the backward compatibility of *the compiler implementation*. In this case, some code that was *incorrectly* accepted by rustc will no longer be accepted, the language itself remains unchanged. As for why rustc chooses to accept breaking changes when it comes to fixing bugs, it's relatively: compiler developer sanity. Bug for bug compatibility is extremely expensive to maintain.
Jetbrain's CLion with Rust plugin + cargo clippy Even though CLion ins't the fastest IDE for Rust development, I consider it is the easiest to use. Without having to setup anything, you can navigate in your code, expand Macro and Debug (the debugger experience being at is best on Linux). I know this is all possible without CLion, but not having to make it work myself is a +1
Did you compile with `--release`?
Thanks, I'll try to spin up a windows 10 in a vm.
afair, integer division is kinda slow and shifting is faster than dividing but it didn't work for all cases or something like that.
Now you're thinking in Lojban.
I used rustc: $ rustc -C opt-level=3
The time for your division depends on the inputs. If I change the range for `i` to say `900_000_000..900_050_000`, the builtin division is unaffected but the shifting division is much slower. To further show this, if you change the number of loops return in the division builtin to 1 instead of 0, you get `n loops = 2499950000`, which is slightly more than half 4999134976. That indicates that on average each shifting division implementation is running only two loop iterations for the small operands, and so it isn't surprising that a few shifts and adds are faster than a division.
You're likely looking for r/playrust, this subreddit is about the programming language.
Which version of `nom` are you using? Version 4 requires you to use `CompleteStr` or `CompleteByteSlice` for non-streaming inputs to be able to get `eof`, where 5 (the current version as of a few days ago) should work correctly.
If you take a look at [encoding-rs](https://crates.io/crates/encoding_rs), you'll probably see a lot of the design and style is oriented toward exposing a C interface that integrates well with Gecko, which shapes not only the API but strongly influences in the design of the internals as well. I suspect Mozilla didn't want to introduce conflict to the quinn community over goals and requirements.
&gt; almost every c++ and java codebase ive been a part of has had a need to do that Were they legacy? I get C++, but that's not standard Java practice at all (I worked professionally with Java for the first part of my career). With C++ you reinvent the wheel a lot, especially if you're pre11, because package management is painful. *Regardless* it isn't actually relevant that *some people must use unsafe*. Again, I didn't say unsafe is evil, or bad, I said it's overused and almost always unnecessary.
Thanks, makes sense. Still I'm surprised how slow native division is!
&gt; That 30% also doesn't show places where unsafe would have been an easier, cleaner, better performing option. Because of beliefs like yours, it is more likely to undercount. It's just not a relevant post for this discussion, you can draw whatever fake conclusions you like from it, but it clearly has no bearing. &gt; I think when he refers to the cult of safe, he's referring to the avoid unsafe at all costs group. There's no evidence of such a group. The only evidence presented so far indicates the opposite - that many crates *are* using unsafe. Besides, the rust community *should* be overly paranoid against unsafe. It's a huge differentiator compared to C++ and is *far* more inline with Rust's values. You assume the tradeoff isn't informed, but it's more likely that it is. You're armchair analyzing a single line of code, and assuming that *the people writing the code who know the actual project constraints* are being dogmatic.
In my experience, `cargo-watch` has been really flaky and borderline unusable in cases. I use [watchexec](https://crates.io/crates/watchexec) and my command is smth like `watchexec -i public -r "rm -rf public/client.* &amp;&amp; cargo check &amp;&amp; cargo web deploy --release -p client -o public &amp;&amp; cargo run --package server"`
Always nice to see rust in use in more places. I tried using Brave but it seems to have this weird bug where it prevents me from using the Google Assistant while it's open (or if it was the last app I was using before locking my phone). I do "Hey Google, set a timer..." or "Hey Google, remind me to..." too often, so unfortunately it's a deal breaker for me. But before I realized what was happening, I found the browsing experience pretty great!
Is there anything like \`FusedIterator\` for \`Future\` so that the executor can specialize to collapse a extraneous yields between pure computations?
Just \`vim\`, \[\`rust.vim\`\]([https://github.com/rust-lang/rust.vim](https://github.com/rust-lang/rust.vim)), and some fancy text editing plugins. I use \`cargo doc --open \[-p specific\_package\]\` and \`watchexec "cargo check --color always 2&gt;&amp;1 | less -XSR"\` (which you can get \[here\]([https://github.com/watchexec/watchexec](https://github.com/watchexec/watchexec)) if you're curious), and I don't feel like there's a particularly high cognitive load. :)
Ungoogleable technologies award, winner of 2019
Yeah, it's the actual update. I have just been sitting on this, getting feedback (e.g. from you), and making small changes. Wasn't sure where to publish it either!
The [nightly version of the documentation page](https://doc.rust-lang.org/nightly/reference/items/external-blocks.html#the-link-attribute) /u/ThomasdH linked mentions `wasm_import_module` explicitly (I think the docs have been merged only recently, not in stable yet). One thing to note is that this functionality isn't _only_ for importing from another WASM module, but also for importing from ES6 JavaScript modules. I don't know if there's any practical difference, but that's worth keeping in mind when using it?
This would depend pretty heavily on what the language you're parsing looks like. Assuming a basic Lisp-like, you could maintain a mutable arena of Exprs and, on parsing an Expr, store it in the arena, get its ID, and return that to the Expr you're nested in - your main parse function would be like ``` fn parse_expr(input: &amp;str, exprs: &amp;mut Vec&lt;Expr&gt;) -&gt; Option&lt;(&amp;str, u32)&gt; { // Do the raw parsing on input, passing down exprs as needed, with rest unparsed let expr = _; // parsed expr, potentially using u32 indices of sub-exprs let id = exprs.push(expr); Some((rest, id)) } ``` You'd make an empty mutable `Vec` of `Expr`s, pass your total input to this, and (if the parse was successful) get the u32 index of the top-level `Expr` out. Why don't you want to use nom / a parsing library, if I may ask?
The The was ahead of the curve there.
I marked that PR as ready for review today, shouldn't be much longer at all.
That's some seriously heavy gatekeeping
Vim + RLS + ALE linter by w0rp. (Environment is either tmux or i3wm) I've tried other setups but I just can't quit vim. Neovim is nice, but Vim 8 has Async now, so it's pretty decent. I also do most of my work on terminals, so most graphical IDEs are out. Also, I have a hard time getting motivated to get over the learning curve of the super IDEs. I get frustrated when things aren't immediately responsive to my keystrokes, and I've yet to find anything as snappy as VIM.
If your workflow is keyboard centric you either try JetBrains IDEs with Vim bindings or keep working on Vim While I'm not a Vim user, I totally understand the problem
GC languages are zero cost by that definition, almost any languages is unless it is burning cycles with overly simplistic implementations. For instance having to copy data or introduce an extra level of indirection because you can't work around mutability constraints I would definitely not consider zero cost.
Yes division is slow. [https://www.agner.org/optimize/instruction\_tables.pdf](https://www.agner.org/optimize/instruction_tables.pdf) has some instruction timings; for example for the Skylake microarchitecture, 64-bit unsigned division has a latency ≥ 35 and a reciprocal throughput ≥ 21; that is when the CPU starts to execute the instruction the result cannot be available before 35 clock cycles, and on average when considering pipelining and all other optimizations the core cannot execute more than one division per 21 clock cycles. Compare this to shifting by a constant (as in `div2 &lt;&lt;= 1`) which has a latency of 1 and a reciprocal throughput of 0.5 (that is the core can execute two such shifts per clock cycle), or to addition/subtraction of registers which has a latency of 1 and a reciprocal throughput of 0.25 (the core can execute up to four additions per clock cycle if there are no dependency issues etc.)
The extract opposite - modern, green field. You might need to implement a direct mapped hash on native values (java specific), embed a directed graph intrusively into data objects, implement a modern trie variant. Unless your are saying that Rust isn't good for implementing your own data structures efficiently.
You are missing the 3rd l in helllo :(
What stopping you from updating to 1.32? It was released in January...
I absolutely reject that rebuilding custom data structures is a widespread practice in Java. &gt; Unless your are saying that Rust isn't good for implementing your own data structures efficiently. Sure, I'd say that. Certainly it's easier to do in Java. Building a doubly linked list in Rust was one of the most famously painful first projects people would build, coming from other languages where it was easy.
Emacs all day everyday
Hello! I'm using the version 5. I found an answer to my issue on internet but the solution was indeed to use `CompleteStr`... I don't really know why it doesn't work in my case. If I use several `take!(1)` in a row, I can properly get the rest of the slice, but for some reason my use of `many_till!` does not work...
They haven't yet decided when bugs found by NLL but not AST checker will be upgraded from warnings to bugs. So currently, they will not be breaking correct 2015 edition code.
I'm trying to understand this weird behaviour. I am following the [rust-wasm](https://rustwasm.github.io/book/game-of-life/debugging.html) tutorial, and tried to add the web-sys dependency to my Cargo.toml: ``` [dependencies.web-sys] version = "0.3" features = [ "console", ] ``` Adding those lines after my dependencies sections gives me an error. Whereas adding it at the end of the Cargo.toml works fine. Here are the two cases: 1) Fails: ``` [package] name = "spherro" version = "0.1.0" authors = ["Karthik Karanth &lt;karanth.karthik@gmail.com&gt;"] edition = "2018" [lib] crate-type = ["cdylib", "rlib"] [features] default = ["console_error_panic_hook"] [dependencies] wasm-bindgen = "0.2" js-sys = "0.3.24" cgmath = "0.17.0" [dependencies.web-sys] version = "0.3" features = [ "console", ] # The `console_error_panic_hook` crate provides better debugging of panics by # logging them with `console.error`. This is great for development, but requires # all the `std::fmt` and `std::panicking` infrastructure, so isn't great for # code size when deploying. console_error_panic_hook = { version = "0.1.1", optional = true } # `wee_alloc` is a tiny allocator for wasm that is only ~1K in code size # compared to the default allocator's ~10K. It is slower than the default # allocator, however. # # Unfortunately, `wee_alloc` requires nightly Rust when targeting wasm for now. wee_alloc = { version = "0.4.2", optional = true } [dev-dependencies] wasm-bindgen-test = "0.2" [profile.release] # Tell `rustc` to optimize for small code size. opt-level = "s" ``` 2) Works: ``` [package] name = "spherro" version = "0.1.0" authors = ["Karthik Karanth &lt;karanth.karthik@gmail.com&gt;"] edition = "2018" [lib] crate-type = ["cdylib", "rlib"] [features] default = ["console_error_panic_hook"] [dependencies] wasm-bindgen = "0.2" js-sys = "0.3.24" cgmath = "0.17.0" # The `console_error_panic_hook` crate provides better debugging of panics by # logging them with `console.error`. This is great for development, but requires # all the `std::fmt` and `std::panicking` infrastructure, so isn't great for # code size when deploying. console_error_panic_hook = { version = "0.1.1", optional = true } # `wee_alloc` is a tiny allocator for wasm that is only ~1K in code size # compared to the default allocator's ~10K. It is slower than the default # allocator, however. # # Unfortunately, `wee_alloc` requires nightly Rust when targeting wasm for now. wee_alloc = { version = "0.4.2", optional = true } [dev-dependencies] wasm-bindgen-test = "0.2" [dependencies.web-sys] version = "0.3" features = [ "console", ] [profile.release] # Tell `rustc` to optimize for small code size. opt-level = "s" ``` Error message I get in the first case is: ``` Caused by: Feature `default` includes `console_error_panic_hook` which is neither a dependency nor another feature ``` Why does the order of settings in Cargo.toml matter?
This is the big problem with recruitment agents - they use the “reference” to contact your former employer to pitch your own replacement - it’s a shitty process. And worse if you haven’t got that to offer then, often they don’t put you through to the end client. It’s become such a meat market in the last 20 years (not just Rust) I posted here recently. Didn’t get a single reply, ended up engaging someone who had no rust experience but clearly had a good fundamentals in other languages and a real willingness to learn. Best decision I ever made. There’s a lesson here for rust devs too. You might think that just because you have no competition you are somehow sacred and can pick and choose or make comments like the one above (“shitty Reddit post”) I’ve got news for you. There are many who will eat you for breakfast whilst you sleep at the wheel. It happened in my industry, partly why I switched, but it happened real quick, and then the rates went to nothing.
&gt;1 hour ago Algorithm/data; the Rust aspect was for safety not perf (but no perf loss).
[Here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=cf7c853bcbecc56a48bc2e32db9cb9e3)'s an example of how I'd write a parser for a pretty simple nested expression language, outputting to a `Vec`.
I'm sure compiler will catch that.
Hello there! Just here eavesdropping from /r/brave_browser \-- the issue you're referencing is currently known and relatively annoying: [https://github.com/brave/browser-android-tabs/issues/459](https://github.com/brave/browser-android-tabs/issues/459) I believe the team is already doing a fairly massive code overhaul on our mobile apps and hope to capture a lot of issues we've had "lingering" around. Went ahead and added a +1 in the Github issue on your behalf -- if nothing else just to make some noise about it again, as the issue itself seems to have gone stale. Regardless, thanks for trying Brave and please don't hesitate to reach out to me/us if you have any other questions or concerns about it :)
I *was* using Visual Studio Code with RLS. The RLS auto-compile was severely lagging my entire system, so I uninstalled it. :( I guess once a project gets too many dependencies and introduces too much complexity the auto-compile becomes a hindrance. With respect to extensions, I heavily use vim-mode, better-toml, todo+ and bookmarks.
the completion was acceptable up to a point but I had to uninstall RLS for this reason this week
Nothing is stopping me specifically - I'm on the latest compiler version, but I know some people care about that. It's just weird to have some important fixes only available in semver-incompatible update, with an extra hurdle of bumped rustc requirement to boot.
I was confused by your fix for the first example because it doesn't seem equivalent. First, you're splitting on ' instead of ". And second, you're still including the ' after quoting it, which isn't the case in the example. I think it should be "last_index = index + 1".
vscode with rust-analyzer
Try rust-analyzer instead of RLS.
Ah I've left the office now. I'll check again on Monday.
How does that work? Does the IETF explicitly place things in the public domain, or do they retain copyright? Do they require patent waivers or otherwise a declaration from the participants that they have no knowledge of any patent covering what they are working on (plus that they did some due diligence on this front)?
Why not just use an array? Doesn't each async function have a stack? So you can just use it instead of allocating again? Or am I missing something?
Somebody needed to dethrone Go.
I've written logging functions that were several times more complicated than the thing they were logging, because figuring out how to borrow so I could get the data I wanted to log was so damn hard.
Hey there! I've just started learning Rust and I'm trying to port a simple interpreter written in another language to it as a learning exercise. I'm currently working on the lexer that separates the input string into tokens. Here is a method that reads a number from an input string to create an integer token: fn read_integer(&amp;mut self) -&gt; String { // self.ch == last character read from an iterator // self.iter == an input iterator (iter::Peekable&lt;str::Chars&gt;) let mut integer = String::new(); integer.push(self.ch); // if there is a next character while let Some(c) = self.iter.peek() { if c.is_digit(10) { // if that character is a digit, push it // to the string and advance to the next // character integer.push(*c); self.advance(); } else { // if it is not a digit, do not advance // the position and exit the loop break; } } integer } My problem is that it looks too "awkward". What would be an idiomatic way to write this code? Could someone point me to good examples? I'd love to use [take\_while](https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.take_while) instead like this: let integer = self.ch + self.iter.by_ref().take_while(|c| c.is_digit(t)).collect() but this also consumes the first character that doesn't meet the criteria, which I'd like to avoid because it it a part of another token. What would be a good way to solve this?
NLL has been a godsend for me. Lot lot easier.
sure. will try it out.
&gt; an entity component system Again, it is not “an entity component system.” The design pattern is Entity-Component-System, like Model-View-Controller. I'm not trying to be pedantic. It just seems like you should know the name of the pattern if you're going to discuss it. &gt; The composition I’m referring to is just the way color, for example, is stored directly on each struct that wants one. That's the opposite of composition. &gt; I've found that when I use inheritance to build an entity system, I end up with a lot of annoying refactors late in the project when I inevitably want to share behavior between previously unrelated branches of the hierarchy The difference is not the lack of inheritance, it's the branches in the hierarchy. Your solution is equivalent to a single base Entity class from which everything derives, with no intermediate classes or branches in the hierarchy. A traditional OOP design with the same restriction would be just as easily refactored as your design is.
tmux + kak + kak-lsp + rls
It looks like the `take!` macro in 5 uses the `streaming` version of `take`; you need the `complete` version of `take`. I don't know if you can use the functions in a `nom` macro; you might need to move over to the function style instead. [Here](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=c0d10ee1876a152085086d4f805eebfe)'s a link to an example of what it would look like with the new functions; that way, you don't have to deal with the whole `CompleteStr` thing.
Uh, I see, that's sneaky! Also this is way cleaner, thanks a lot for sharing.
Emacs with rust-mode and lsp-mode talking to rust-analyzer and a terminal with the compiler on the side :)) rust-analyzer nowadays almost always works and is quite fast.
I agree that the approach I outlined is very similar to a flat hierarchy in a language that supports inheritance. It seems like your primary disagreement with me is over terminology—like I said, feel free to sub in your preferred terms/capitalization for mine. :)
&gt; It is mostly an change that empowers developers I think the `an` here should be an `a`.
The pypi/npm/CPAN-like experience of crates ought to mean that Rust does not copy the phenomenon wherein everyone and their mother reinvents the wheels for each new project.
That sounds like a nightmare bro.
What is kak?
Since I like combinators, if the order doesn't matter between `ps` and `ss`, then it should be possible like: iterator .inspect(|current| ps.send(current) ) .skip(1000) .drop(1) .for_each(|next| { ss.send(String::from_utf8_lossy(&amp;current).into()) });
Is there a reason you have both `ch` and a `Peekable` iterator? If you're tokenizing, it seems easier to just have a `Peekable` and use `peek` as your lookahead. Either way; unfortunately, you're right that you can't use `take_while` on a `Peekable` and get what you want. You could [do something like this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=d97617dd181f90d76c13bf890c3a6722), but that's more code than your original (though you can stick it somewhere you don't have to care about it, and can reuse it later.) Tokenizing/parsing iterators is a pain, which is why I'd recommend parsing on `&amp;str`s or `&amp;[u8]`s, unless you really need to operate over a connection or something.
With watchexec was much better! I don't need to workaround with touch files and it auto-restart it: &amp;#x200B; watchexec -e rs -r -w ../ -- cargo run --bin server
That example is unbelievably helpful. Thank you and again thank you. I don't want to use nom because ... well I just don't. Partly because I've had bad experience with parser generator systems in the past. When they do work they suck the joy out of it. And it just adds a huge thing in my codebase that I don't really understand or want. This is all a learning experience anyway. I've written plenty of parsers in other languages and I wouldn't use a parsing library for those languages either. It just comes down to I don't really like working that way. There's also the factor that I don't really want to learn a language while also learning other custom abstraction layers on top, I'd rather just get to grips with Rust first (which compared to most languages is really hard to get a handle on IMO) rather than adding stuff on top and then having incomprehensible macro magic as well. I'm just nowhere near there yet.
Ah, thanks, that does indeed seem to be my issue. I look forward to them addressing it. I will be glad to use Brave again once they do.
I understand wanting to learn it on your own. To be honest, though, `nom` (as of version 5.0) is really just a collection of composable parser functions; the ones I put in that example are taken pretty much straight from what they have (the interface, if not the actual code.) They've ditched the macro stuff for the most part, and a parser is just a function from an input to a resultant (rest, value) pair. Of course, that does mean you can be pretty safe to just implement it on your own, too, if you don't want the dependency; as far as I know, `nom` doesn't support passing contexts like the `&amp;mut Vec&lt;_&gt;` in that example, so it's not too much work to just create your own combinators that allow that.
It's not a disagreement over terminology. I didn't want to say it like this but it's obvious to me that you have a tenuous understanding of ECS and of composition vs. inheritance and I was hoping through discussion you might be inspired to read more on these topics. It's important to understand, for example, that ECS was created *because of* the difficulty working with an inheritance-based design like yours on larger, long-term projects.
It would only be a problem with aliases, functions and sourcing scripts. If you start a script it will have its own process. Mentioning that the default is based on the parent's pid, I think power users using it in the mentioned cases would notice. Is there really a problem if you wait twice? I assume this is mostly used to not spawn too many processes at once so it would perhaps be even better to let multiple scripts use the same server.
That's something we (the Quinn maintainers) have designed to allow for from the start. The quinn-proto crate is a pure state machine, and could quite reasonably be wrapped in C.
I disagree, so I guess we're at an impasse. :) Best of luck with your projects!
Quinn is a relatively mature implementation, and achieves a high degree of completeness and conformance. See e.g. [https://quic-tracker.info.ucl.ac.be/grid](https://quic-tracker.info.ucl.ac.be/grid), where ralith.com:4433 is a (somewhat dated) quinn interop server. Neqo is a much younger project and judging by the interop reports they have not yet implemented major parts of the protocol.
How's the edge treating you?
I use Rust at work but atm only for small parts of projects. But I do try to spread the good word among colleagues in a fact-based, self-critical and conciliatory way :) What I do use is Jetbrains IDEA (got a toolbox license anyway) with the rust and toml plugins. Functionality is superb but performance on a medium-size project with actix-web, diesel and serde can be really bad. In some files, auto-complete takes up to 5-7 seconds and re-highlight after saving changes about the same. Apart from that, I quite like it. No vim mode for me but the UI can be navigated entirely by keyboard. Useful plugin for the latter: Force Shortcuts. Useful setting: rustfmt on save. I also use a terminal to run cargo commands and a separate browser window for the generated docs (as that works nicely for my window manager, i3). Also use Zeal ([https://zealdocs.org](https://zealdocs.org)) for everything in core/std. Allows me to work completely offline, once all dependencies are synced. As a font for coding and in the terminal, I use Hasklig. It has nice (as I see it) ligatures for `::`, `=&gt;` and others and inherits excellent readability and unambiguity from Source Sans Pro, from which it was forked. I tried two times to switch to vim with plugins but never managed to get beyond the first steep hills of learning and changing behaviours.
Mostly because some stuff is only partially updated :P but yes, there is a stack and an array will work.
You can look at CI scripts of Rust compiler (rustc). It uses sccache internally. I personally use it for CI. Windows build is too slow, with help of sccache I reduce CI cycle from 30 minutes to 20 minutes.
Just check out [QUIC RFC draft](https://datatracker.ietf.org/wg/quic/charter/).
It seems to only be a client talking to their proprietary web service, so it doesn't really qualify as "open" in my book
Integer division is a very slow operation on even modern CPUs, which means it's possible to write code which is nearly as performant as native integer division, and even faster code if some corners are skipped. There's a couple of reasons for this: First of all, it is hard to optimize it in hardware to anything more than a slightly more complex shift-subtract loop. While the throughput can be increased to multiple bits of the divisor per cycle at the cost of some complexity, it still tends to be a microcoded loop. It usually does feature early bailout just like your loop which is why the latency of the op tends to be variable. Second, true variable / variable integer division is very uncommon in most code. When the divisor is constant there's a variety of optimizations possible to allow the compiler to do much less work. Divisions by powers of two can be replaced by LSR/ASR operations, Divisions of most constants can be compiled down to a multiply using the a / b = a * (2^n /b) / 2^n trick. So it doesn't get a lot of area assigned to optimizing it compared to multiplication. Third, for most of the last processor families DIV just didn't get attention at all. Especially Intel just didn't bother until recently. DIV latency on ryzen is 14-46 cycles for 64-bit integer division. In Skylake it is an embarrassing 35-88 cycles. Apparently they finally improved this in Cannonlake where 64-bit division goes down to 18 cycles but those processors are still rare. Fourth: Your implementation does skip some corners which allow it to be faster ;). First of all, you trigger an infinite loop when dividing by zero, while the hardware has to either trigger a fault or return a defined value. Second, your implementation gives wrong results if the highest bit of the numerator is set. Finally, hardware integer division is usually optimized more for large numbers, while all the numbers you're passing easily fit in an u16, which means your loop cycle counts stay low. Meanwhile hw division will probably find the start offset by directly comparing the highest set bits in the numerator/divisor, which is somewhat more expensive to start with but will be much faster for larger differences in numerator/divisor. Try passing a more wide range of values.
Weird thing is, I can still sleep fine. Sure, sometimes I wake up during the night, fire up my laptop and press "update" just because I can; but that is totally normal, right?
Both the edge and I are (figuratively) bleeding far too often.
I'm not aware of what -C opt-level=3 does exactly, but I believe cargo --release compiles it with the -O flag
The issue is that you nested tables. You can order tables however you like but as soon as you declare another table, it owns everything under it until you have an other table. [package] name = "spherro" version = "0.1.0" authors = ["KK someone@gmail.com"] edition = "2018" [lib] crate-type = ["cdylib", "rlib"] [features] default = ["console_error_panic_hook"] [dependencies] wasm-bindgen = "0.2" js-sys = "0.3.24" cgmath = "0.17.0" # from here it's the dependencies.web-sys table [dependencies.web-sys] version = "0.3" features = [ "console", ] # that means these are not in the dependancies table # but in dependencies.web-sys, and when you ask the feature # it can't be found console_error_panic_hook = { version = "0.1.1", optional = true } wee_alloc = { version = "0.4.2", optional = true } [dev-dependencies] wasm-bindgen-test = "0.2" [profile.release] opt-level = "s" You can however do this: [dependencies.web-sys] version = "0.3" features = [ "console", ] [profile.release] opt-level = "s" [lib] crate-type = ["cdylib", "rlib"] [dependencies] wasm-bindgen = "0.2" js-sys = "0.3.24" cgmath = "0.17.0" console_error_panic_hook = { version = "0.1.1", optional = true } wee_alloc = { version = "0.4.2", optional = true } [dev-dependencies] wasm-bindgen-test = "0.2" [features] default = ["console_error_panic_hook"] [package] name = "spherro" version = "0.1.0" authors = ["KK someone@gmail.com"] edition = "2018" I wouldn't recommand doing so but you can.
Excuse me, but ummm... `println!` is a macro :)
Excuse me, but ummm... `println!` is a macro :)
My setup and workflow is very similar to this (vim, rust.vim, cargo watch/check, generated docs), with the addition that I use i3wm. My coworkers love intellij IDEA though.
Doing something similar, honestly not using tmux much, as I'm more familiar with my i3 keybindings. I either just use splits in vim or have a new window for another terminal.
Ah, here: [https://www.ietf.org/blog/whats-behind-bcp79bis/](https://www.ietf.org/blog/whats-behind-bcp79bis/) &amp;#x200B; \&gt; RFC 2026 \[now RFC 8179\], the IETF patent policy states that anyone who makes a contribution to an IETF specification or standard must disclose any patents held by the contributor or his/her employer which cover or may cover the contribution and are “reasonably and personally known” to the contributor, as well as any such patents that cover contributions of others. &amp;#x200B; also, the IETF copyright policy in [RFC 5378](https://tools.ietf.org/html/rfc5378) states that the IETF Trust and the IETF must acquire publishing rights from contributors to RFCs.
Kakoune - a Vim-inspired text editor
Kakoune
&gt; as far as I know, nom doesn't support passing contexts like the &amp;mut Vec&lt;_&gt; in that example, so it's not too much work to just create your own combinators that allow that. At least nom 4 supported parsers that take an additional `self` parameter (the `method!` macro).
Agree to disagree. People who get stuck on older version of software are anti-vaxxers of software engineering.
It's a double-edged sword, given the feedback you see here about MSRV. If you make 0.4 depend on 0.5, then all those 0.4 users will be forced into a new MSRV too. Users of older compilers would have to pin a "pre-compat" 0.4.x in their lock files. I assume you wouldn't want 0.5 to depend on 0.4, but I guess you could...
I should have clarified. The language itself utilizes XML for markup tags in the design of the pages, but the output is HTML.
For example, we shipped Rust 1.31 in RHEL 8.0.0, as that was the latest version when I had my devel/QE hand-off. While RHEL does have a fairly long release pipeline in general, this one was longer than most as a major release. We do have updates queued, so RHEL8 users aren't going to be stuck with older Rust forever, but that's not out the door yet...
&gt; if I create an elevator without both of those things and then the elevator system therefore doesn't pick it up there's a bug in the level. You could solve this by deferring to an elevator constructor that always adds a color and trigger area. In effect, you never create raw entities directly, you always defer to a constructor.
`$ rustc -C opt-level=3` is the highest level of optimization
Maybe I'm missing something in your comment but the code is allowed to compile because of NLL migration mode. It will become a compile warning until some as-of-yet unknown future date. &amp;#x200B; So it doesn't break backwards compatibility, at least not at the moment?
I disagree about the claim that Go has nicer looking syntax. Having heavily used both I very quickly become tired of the strange goisms in the syntax. And when looking at a larger, more involved project it becomes very monotonous to read through thousands of lines of identical-looking code using the same idioms hundreds of times. I get why `someSlice = append(someSlice, someElement)` is the way that it is, but that doesn't change the fact that it looks *awful* in a moderately-high level language. Writing a loop that filters elements out of a slice makes you feel like you're writing C again. Not that that's intrinsically a bad thing, but given everything else wrong with the language I'd rather just write C.
I think that's a pretty good way to mitigate the problem. It doesn't stop you from inadvertently deleting the component at runtime assuming that's allowed, but that tends to be a less common error in my experience (maybe just because I've never worked on a game where I needed to do that very often.)
I think you think Rust is more stable than it actually is. The project is trying *really* hard, on top of the other goals, to not break existing safe code. But there's still the soundness loophole, the vaguely defined memory model, and the disclaimer of warranty. If there's a conflict between the goal of refusing to attempt optimization of memory-unsafe code and the goal of compiling everything that a stable compiler once compiled, the first one wins. I believe that's the correct call - the opposite is an endless source of entertainment and billable hours for C and C++ developers. Editions still allow the syntax to change. As far as I knew, that was the motivation, not keeping lexical borrow checking on indefinite life support.
Spacemacs, no RLS.
Yes, and `position: sticky` allows that too, you just need to use only `top` or `left`, and not both. Here’s a simple demo I wrote yesterday: https://temp.chrismorgan.info/data-grid-sticky.html. That demo supports only one frozen row/column, but gives hints on the implementation of more.
This existed before as `tokio-trace`, however it isn't Tokio specific, so it was broken out to be used in any Rust lib / application.
what is this code trying to do?
Note that division by a constant is compiled to just a multiply and shift (i.e. multiplication by the reciprocal), which are very fast operations. Division by a constant is the most common case, just as shifting by a constant number of bits is.
I don't know if it's a good idea or not but you can do it like [this](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=1c502be1ac200201384e7196c1386f34) (the functions on `NumberIter` are optional). I prefer [that](https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2018&amp;gist=0ae6953347418b366bc6fe545cddb735) one however you can't check which function is stored. If you always initialize with `one` for example, you can `impl` the `Default` trait and remove the `one`, `two`, `three` functions.
10000? Can you name a few examples? What so these "programs" do?
I also use IDEA. VSCode kept hanging on me, and RLS didn't work as well as IDEA's Rust plugin - which is excellent. The Vim support is decent enough for my use case, although I had to tell it explicitly that I wanted the vim plugin to handle certain key combinations.
As I expected someone got the wrong end of the stick here... "In Rust we trust: Brave smashes speed limit after rewriting ad-block engine in super-lang" https://www.theregister.co.uk/2019/06/28/brave_ad_block_rust/
Switching u32 -&gt; u8 did it. Thanks for catching that.
So would this be akin to something like zipkin or open tracing for Rust?
How does this differ from slog/structured logging in general? There's currently (slow) momentum behind adding structured logging to log itself, and structured logging maps super well onto futures/tasks, even as they move between execution threads. Somewhat recently someone shared a crate specifically geared at adding a slog-scope layer into a futures stack when polling back into it (and ofc popping it when leaving).
This feels very misleading. They used an entirely different algorithm/solution in the rewrite. &gt;Our previous algorithm relied on the observation that the vast majority of requests are passed through without blocking. It used the Bloom Filter data structure that tracks fragments of requests that *may* match and quickly rule out any that are clean. &gt; &gt;... &gt; &gt;We therefore rebuilt our ad-blocker taking inspiration from uBlock Origin and Ghostery’s ad-blocker approach. This focuses on a tokenization approach specific to ad-block rule matching against URLs and rule evaluation optimised to the different kinds of rules. &amp;#x200B; There's room to argue that writing a new engine in C++ would take longer, etc. but the net performance gain can't really be attributed to the language choice.
Well, `rustup`? RHEL crowd usually don't compile things from source, so only reason for any RHEL user to have rust is development. For development you pretty much required to use `rustup` because of components that aren't part of package RHEL provides. But I see your point. I forgot how slow linux distros at updating their packages in the name of stability.
This was discussed previously &gt; The previous iteration of its ad blocking engine was already optimized C++. The speed up was mainly due to algorithmic changes with the added bonus of Rust's low overhead and memory safety.
First let me say Rust is a real decent languages, it could have many potentials when fully unleashed, much better than, say, C++ for building high performance applications. That being said, I really dislike mozilla's advertising agenda and some trends in the community. The slogan on Rust's homepage is "A language empowering everyone to build reliable and efficient software". Even though I'd like it so much for it to be true, the sad truth is that modern computer and network architecture is so complicated, that it takes a real wizard to write software that can really unleash a computer's potentials. Yes some Rust programs will be faster than the same thing written in different projects, but if you really look underneath, there will be all kinds of quirks in the Rust implementations of libraries. One example, is that even tho we do have all kinds of attempts on Rust's IO story, Go's runtime is still much more superior in many cases. Yes given time things would get more mature, but some general trend in the community, is that as long as something is written in Rust, you will be all good. I definitely agree Rust is a much more powerful weapon, but even you are writing Rust, you still need all those low level knowledge in order to write \*real\* efficient and robust system applications. But if you already have those knowledge, learning C will be real trivial. Rust might still be better in those cases but then it would just be a matter of productivity, not that something enables you to write low level code when you cannot write C. tl;dr: please stop promoting Rust as a way to write low level system software for someone who doesn't know C or computer architecture. This is so wrong.
I use IDEA with Rust plugin for hobby and professional work. I usually work on smaller projects in both cases but it works really well. The inline type annotations really helped understand what is going on when getting started. I use it along with cargo clippy and rustfmt. I tried RLS with VSCode and in my limited experience, it didn't work nearly as well. However, I believe it was around the same time as the RLS 1.0 release when I last tried it.
I made a faster division for u128 on computers with 64 bit hardware division, and uploaded a crate for it [specialized-div-rem](https://crates.io/search?q=specialized-div-rem). It has the fewest branches of any algorithm I know. It outperforms whatever Rust is using currently for every input, except when the highest bits are very close together. Just this week I learned that the \`divq\` assembly instruction on x86\_64 can handle 128 by 64 bit division, so I am in the process of trying out some changes. I already have an issue open on compiler-rt to include it in Rust.
I came up with another solution, I didn't need the match at all.
This has been a pain point for me as well. I lived Kotlin for a few years before finding Rust, but I've never hacked on an IntelliJ Platform plugin before, so don't know if I'd be able to make much progress on the issue. This feels like the kind of issue that is either super simple or extraordinarily complicated to fix with no in-between.
That's answered in a comment in the code, and example \*output is provided. &amp;#x200B; * I used shuffle() and sort() to generate that output, I needed something programmatic(not random). &amp;#x200B; This is what I was trying to do. [https://gitlab.com/cheako/multiplicative\_persistence\_searcher/blob/557b030123c9bebd8e4773671216b931c8bc0dde/src/main.rs#L27](https://gitlab.com/cheako/multiplicative_persistence_searcher/blob/557b030123c9bebd8e4773671216b931c8bc0dde/src/main.rs#L27)
Any progress towards a fix would help. I'm open to discussing more than strictly beginning-to-end solutions, if you want to move this to private!
open tracing / zipkin is the distributed tracing system. This is only the rust API for instrumenting code and subscribing to the events. So, you can use `tracing` and report to zipkin / open tracing... does that make sense?
FWIW, we do have all of the rustup components in rpms too -- rustfmt, clippy, rls, etc. I think we're only missing miri, which is nightly-only.
First, it is tracing, not just logging. So, instead of just outputting an event (the structured log message), you specify a start and a stop (a span). By doing this, you can notice the hierarchical structure of events. If a span is fully contained by another, then it is a child. Beyond that, `tracing` is designed to make it highly efficient for subscribers to watch for individual fields of an event. A subscriber is able to match a received field value without doing a string comparison. The intent is that subscribers will be used to aggregate metrics and do more with the data than just report it. `tracing` has quite a number of other cool features, but I don't know enough about slog to compare.
Good to know.
Also, because it gives you events that the subscriber can choose to react to in any way, it doesn't have to be used for logging. For example, I've been playing around with writing a metrics collection thing on top of it, [`tracing-timing`](https://docs.rs/tracing-timing/), which lets you gather timing data over time of where your application is spending its time re-using the events that are already in your code.
Totally not related, but thought this was another r/playrust post...
For individual developers, it's not really an issue to update. But for something like Debian stable, the Rust toolchain packages will probably see very rare updates. So all of the Rust packages that ship with that distribution are pinned to an older version. I'm not actually a Debian contributor, so I don't know the full implications, but in general updating a downstream distribution is much harder than updating your local development environment.
OpenTracing is the API for in-band use. Outputting to zipkin makes sense, but OpenTracing is mostly for in-process span propagation. It doesn't define a data model or propagation format.
Here’s a way to do this with empty structures, statics and trait objects: https://github.com/maplant/mgf/blob/master/src/simplex.rs
This. Separate the unsafe code into small, reviewable, separable crates. Then disable unsafe in the business logic crates that you implement using the other things -- just like you do with Vec.
Presumably though there would have been an attempt to implement the new algorithm in C++ first? Was a Rust port considered because C++ was too hard?
You might be interested in using VPS to test the impact of having a more capable system. They're not expensive to run for a few hours either.
(for anyone else reading this thread) Your link doesn't work, are you talking about https://github.com/intellij-rust/intellij-rust/issues/3437?
Wait till July, another 12 core CPU will come out with 24 threads for less price.
&gt;The previous iteration of its ad blocking engine was already optimized C++. The speed up was mainly due to algorithmic changes with the added bonus of Rust's low overhead and memory safety.
Honestly? Get an ssd and put your code on that, compile from the ssd, it should be a big win. At the moment, the rust compiler is just known to be slow. They are working on it, but it truly is just slow compile speed on the part of the compiler more than anything.
Thank you so much for your repsonse! &gt; Is there a reason you have both ch and a Peekable iterator? Not really, it's an oversight on my part, you're right, the peekable iterator is enough. Thanks! &gt; I'd recommend parsing on &amp;strs or &amp;\[u8\]s Do you mean just replacing the iterator with the index of the current character in a slice? That was my first idea but I thought using an iterator would be more idiomatic. Though `&amp;s[int_start..int_end]` does look much more simple. Also thank you for the code! I sure can use it again later in the parser, if I ever need to take while peeking at the next token.
Is it like automatic structured logging then - without the need to store a logger? `slog` today seems to act very similarly to the scopes. It allows creating a new sub-logger with a number of extra key/value entries, and logging to any logger will include all k/v pairs added in the logger, and that logger's parents, etc. `slog` also allows consumers to inspect these key/value pairs, like `tracing` seems to - I mean that's the definition of `structured`, to an extent. Maybe a comparison page highlighting the exact differences between structured logging and tracing could be useful? In any case, I like this. It seems much less conceptual overhead if one doesn't have to pass a logger around like in `slog`!
&gt; The start/stop thing doesn't seem unique to tracing. As I understand it, that is a key feature of structured logging as well - being contextual? I don't see that in slog, would you mind linking to what you mean? In `tracing`, you do the following: let s1 = span!(....); let s2 = span!(....); let s3 = span!(....); s1.in_scope(|| { // do work s2.in_scope(|| { // In child context }); }); s3.in_scope(|| { // independent event }); s1.in_scope(|| { // do more work }); In this example, the subscriber is informed that s2 is a child event to s1 and thus is able to rebuild the tree. This is the "tracing" aspect. This is designed, in part, for usage in an async context (with Tokio). You would wrap calls to Future::poll with an `in_scope`. The goal is to not require users to manually call `in_scope` and instead have it built into utilities with Tokio.
Their Mac Mini has a SSD.
Went to download brave. Hipster girl stares me in face. Creeps me out that they could have such terrible marketing. Love rust. Didn't download.
Don't get a threadripper unless you know what it's for. It has a NUMA (non-uniform memory architecture) which, in a nutshell, means it's really bad at certain tasks. It's intended for workstation tasks (the server version, Epyc, for server tasks) that are spread across many threads _and_ processes. The issue is that if you have your big program in one memory space with 12 threads, those threads will often have to reach across the chip to a separate memory bus, which slows it down to a crawl. Threadripper and Epyc are for specific tasks, need to be load balanced and aren't something you just throw at any problem. The new Ryzen chips look amazing, though. There's a 16-core 32-thread version that doesn't have the memory architecture problems of the Threadripper (it's not a NUMA chip, it's a normal desktop CPU). It's quite costly but it looks like this isn't a problem for you. It should be available within about a month and at the time of the release, the fastest CPU money can buy within reason. The thing that usually helps compile times the most, though, is fast storage. It's good that you're planning on NVMe, I would focus more on that than the CPU. If you can get a faster NVMe drive by bumping down to a cheaper CPU, that's most likely a better configuration.
Among other things, this strongly depends on the specific software ecosystem. Updating npm has, for instance, done fun things like wreck production servers.
Heh, thanks. My "fixed formatting" wasn't so fixed
Updating without testing anywhere is a recipe for disaster. It's not like you complying rust packages on production server...
Oh! I didn't realize you could create scopes and then use them independently - like having `s2` within `s1` without creating `s2` within `s1`. With that difference in mind, this is the equivalent vanilla `slog` code: let root = slog::Logger::root(/* destination */, o!()); let s1 = root.new(o!(...)); let s2 = s1.new(o!(...)); let s3 = root.new(o!(...)); { info!(s1, "..."); { info!(s2, "..."); } } { info!(s3, "..."); } { info!(s1, "..."); } info!(root, "..."); The context is handled explicitly by passing around constructed loggers, but it should have the same output affect. With `slog-scope` macros, the code is slightly nicer: let root = slog::Logger::root(/* destination */, o!()); let s1 = root.new(o!(...)); let s2 = s1.new(o!(...)); let s3 = root.new(o!(...)); slog_scope::scope(s1, || { info!("..."); // optional: create logger using scoped parent (s1 in the case) let s2 = slog_scope::logger().new(o!(...)); slog_scope::scope(s2, || { info!("..."); } }); slog_scope::scope(s3, || { info!("..."); }); slog_scope::scope(s1, || { info!(s1, "..."); }
I would be curious to see the impact of different NUMA configurations on rustc.
Can raiders build twig floors etc on your base despite having a tool cupboard inside? I was just raided and the guys build twig all around my 2x2? If so, how do you prevent getting raided?
Thanks for the info, I'm not much of a mac guy. Welp, I'm out of ideas. Frankly, I've never worried about the compile times. Yes, I would like them to be shorter, but considering they are doing far more than c/c++ is doing and are only slightly longer in compile times, I can live with it. I even did some compiling on a raspberry pi, those aren't exactly known as speed machines. It just doesn't seem to be that big of an issue to me.
Op asked about build times which definitely scales very will across cores, especially with bigger codebases with many compilation units. Coming from c++/gnu make, how is building parallelized in the rust world?
The emperor protects.
I believe you're looking for /r/playrust. This subreddit is unrelated to the game of the same name.
I have a powerful desktop with i7, 32GB of 3200Mhz ram, and btrfs over 2 NVME drives. When I compare with compiling on my full-speced Carbon X1 laptop, it seems like 10x faster at everything. But it's not trivial to tell which parts exactly are making the difference. I'm guessing CPU + memory speed. Still, linking a bigger project in `--release` takes around 5 seconds. On my laptop it's minutes for some projects. And RLS is still visibly lagging during daily work. :D I'm looking forward to some improvements in the compiler. Also eying on the Ryzen.
Woah. Woah. Woah. Did you just say something that wasn't super negative about Chrome? One million downvotes for you. &amp;#x200B; More seriously, [caniuse.com](https://caniuse.com) says there were a few of implementations of WebSQL: [https://caniuse.com/#search=websql](https://caniuse.com/#search=websql), which contradicts what /u/est31 said. WebSQL is also pretty well known to be deprecated, and Chrome has supported its successor, IndexedDB, since 2012. So, whatever claims about "forcing" its use are also pretty nonsense. &amp;#x200B; The real problem with WebSQL was that it wasn't possible to document it - the documentation would have had to read: "Do whatever Sqlite does". While Sqlite is super awesome, thats not really a reasonable standard - it would kinda be like saying, "For this CSS property, just behave like IE behaves".
Death to the false emperor!
I don’t build from master these days, I build from https://github.com/rust-analyzer/rust-analyzer/pull/1445 :D
“The emperor” “protects”
Wait, wasn't "The Register" a sorta respectable newspaper? Do they all write poorly informed clickbait now?
Cool! Aljabar actually has element wise access by virtue of Vectors derefing their arrays. It also took me a bit but I managed to change the implementation to use MaybeUninit, so it should be panic safe now
Something to try over the weekend I guess! Oh look it's Saturday
I have a PC in the price/performance sweet spot, the "starter" /r/pcmasterrace build. It's got 4 cores. If you could provide a sample Rust project and the time it takes to build on your machine, I could compare it with mine. That would tell is if there is any other bottleneck you're hitting other than CPU.
Keep in mind that RAM speed is very important for Ryzens, so make sure you get RAM at frequency at least 3000.
Does it provides vectorized implementations for \`\_\_m128/256/512\` on x86\_64 ?
They have been using clickbaity title for a long time, but I think the content is still relatively accurate.
I don't think Rust is still at the point where it has to prove itself at every step. There's no reason they would only be able to use Rust after C++ fails for their purpose.
Why does adblocking need to have good performance? Is it not done after succesfully reloading each site?
I think that with a new Ryzen CPU you can get a lot better price per performance ratio than on a Mac Mini. And You'll get a more modular/expandable/repairable/lower temp system. I'm planning on building a new PC myself this year, with a Ryzen CPU, but I want to wait for third party benchmarks first.
Just saw this, which looks amazing, and a few minutes later saw [async-log](https://blog.yoshuawuyts.com/async-log/) which seems to go into a similar direction. From a quick glance it seems that `tracing` built new infrastructure to crate and propagate nested contexts, while `async-log` attaches metadata to the existing `log` infrastructure. I also saw the comment on slog above, and to add a tad more confusion still I also saw that there are tracing-log and tracing-slog crates. Can someone who actually knows this domain give a quick summary of how these differ? What advantages/disadvantages of these approaches? Are they in fact all compatible using the `log` adapter? Which one should I as a library author pick?
You can output start and stop events in slog, convert them to a Chrome Event Tracing format (a JSON list of start and stop events) and Chrome will work out and display the hierarchy for you. Maybe not as easy.
Even if it was only done once per reload, that's still a critical time point. Time to first paint for a website is very important.
Coming from C++, but I guess it would apply to Rust as well. I have a ThreadRipper 2920x/12 cores at work and an Intel i7/4 cores at home both with SSD and similar RAM. I haven't done real benchmarks but from experience what you gain from having more cores you loose in individual compile time for each unit. So I guess it heavily depends on you project, if you have many small compilations units, AMD will potentially be faster, if you have some big units in your project that causes a bottleneck in your compile, Intel will be faster. Either way compile time.. you'll have to live with it with these langages.. Have maybe a look at Intel NUC products, an equivalent to the mac mini, at least from a size point of view.
I think putting large code blocks in macro may be not convenient for the users.
This is a key point - safety isn’t the only reason to use rust. If Rust had no borrow checking, I’d still use it over C++ for nicer pattern matching, a more sensible standard library, a good module system, less syntax footguns, and nice tooling. If you’re going to rewrite an entire part / the entirety of a project and have the option of using Rust, I think more and more people will choose that option
Of course it had to be 69x *insert lenny*
Did you try the `simd_support` feature?
If I have a code that devide by variable, but the variable never changes after setup, can I optimize it to multiplication by something instead?
So is this for non-block logging?
If I have division like N/M and I want to get same result with N*X &lt;&lt; Y, how to find X and Y from M? Asking for a friend.
I *think* this should be closer to super-simple, once you understand the general resolve infrastructure. The entry point is here: https://github.com/intellij-rust/intellij-rust/blob/d87603e6130b6b6e194a2195d97efec099c94708/src/main/kotlin/org/rust/lang/core/resolve/NameResolution.kt#L319. It’s been a while since I’ve looked at the resolve code, might be completely wrong!
Managed to cobble [this](https://github.com/bzar/gite) together. Thanks again for the pointer!
It doesn't matter what the platforms do. I mean, on x86 "Relaxed" gets lowered the same as "Release" and "Acquire", because the hardware guarantees strong memory ordering. But you are not programming assembly, you are programming Rust. You cannot reason based on assembly, you have to reason based on the Rust specification; in case of concurrency, that's the same as C++. The compiler *will* exploit the difference between "Relaxed" and "Release"/"Acquire" even if you are targeting x86. The compiler *does not care* that the platform you are compiling to preserves data-dependencies; if the spec says that your code is faulty because some dependencies do not guaranteed, you can expect that to come back and bite you in form of a compiler optimization that subtly breaks your code. For a concrete example showing how reasoning based on "what the hardware does" produces wrong results (in the context of LLVM), see https://github.com/rust-lang/rust/issues/32976#issuecomment-446775360. C/C++/Rust are *not low-level languages*. They are not a macro system for assembly. They are languages with their own memory model, and that model is very different from any actual hardware. For example, bits have three states: 0, 1, and uninitialized. [Pointers are much more than just an address](https://www.ralfj.de/blog/2018/07/24/pointers-and-bytes.html). And concurrency primitives don't work at all like how they work on hardware.
Either way, I would make it optional (opt-in via feature flag).
Yeah putting code in macros break IDEs...
I think `developers` should be `everyone`.
&gt; - I plan to have 16 GB minimun. I suspect more ram or faster clock for it will bring minimal improvements. You should have a look at compile benchmarks before saying that. [Here are some phoronix benchmarks](https://www.phoronix.com/scan.php?page=article&amp;item=threadripper-linux-ddr4&amp;num=2) Ram speed, and count matters for compile benchmarks. &gt; I can afford at most a AMD Threadripper 2920X. (US500) / 12 cores. Wait for ryzen 3, it will also have 12 cores for $500, but at higher clock speeds and with more ipc. It will release on the 7th of july, so i suspect you can probably wait for that.
Because it's become normal for "modern" websites to load hundreds of resources from dozens of different domains, and you have to check the whole rule set for matches for every one of them.
You have a good point, however I don't see it as the responsibility of lib maintainers to push for a widely usable Rust LTS. If there was a significant effort to maintain compatibility with a specific Rustc version across "core" Rust libraries, I'd be happy to work with that. However, as /u/vks_ says, we asked and there was *very* little demand for the back-compat, which does require some additional effort on our part (e.g. maintaining feature-detection via `build.rs` scripts and `cfg`).
I would be surprised if rust compilation performance suffers under numa because there is basically no synchronization across threads. Each thread just gets it's own crate to compile.
`span!("level I", { CODE })` can probably also be `#[span("level I")] { CODE }`
In the recent post about the `tracing` crate, [I asked](https://www.reddit.com/r/rust/comments/c6rrwf/ann_new_crate_tracing_application_level_tracing/) how the approaches differ.
Afaik quic sits on top of UDP for compatibility reasons
&gt; For example, C allows you to perform type-punning through unions; in Rust, reading any field of an inactive variant is instant UB. That's just *so wrong*. I have no idea where you are getting this from. Rust's union *do not have* a notion of an "active variant". Only C does. *Unlike* in C, type-punning through a union is *always* allowed; in C you have to be careful how you are doing it. For example, the following is UB in C, but the corresponding program is allowed in Rust: ```C float transmute_int_to_float_inner(int in, int *x, float *f) { *x = in; return *f; } // In a different file union TypePun { int x; float f; }; float transmute_int_to_float(int in) { union TypePun p; return transmute_int_to_float_inner(in, &amp;p.x, &amp;p.f); } ```
Are you sure it's a girl though? I wouldn't go around bravely assigning gender identities these days.
Notice that this entire paragraph only applies to **union declared without `#[repr(C)]`**. And the reason that you cannot use other fields has nothing to do with type punning. As the paragraph says, *layout is unspecified*, so a `repr(Rust)` union might make different fields start at different offsets: ```rust #repr(Rust)] // this is also the implicit default union MyUnion { x: f32, y: u16, // this field *might* be at offset 2! } ``` So, that citation does not support what you have been claiming above about type-punning.
Good question. It feels like `rand_core` is fairly stable now other than the recent change to the `Error` type. To be conservative though I'd prefer to wait 6-12 months before marking it 1.0. The PRNG crates are mostly fairly simple and could be bumped to 1.0 following `rand_core`, excepting `rand_chacha` which is a lot more complex (thanks to optional SIMD optimisations) and just saw major changes. The `rand` crate itself... will see at least a version 0.8, but has a much shorter TODO-list than previously. Going by our release cadence I would expect at least a year before 1.0 but could easily be more. As for `rand_distr`, it still needs a lot of work IMO. But **does this matter**? Each 0.x serious should avoid breaking changes (even [value-breaking changes](https://rust-random.github.io/book/portability.html#crate-versions)), and outside of `rand_distr` there are not likely to be many new minor releases or API changes before 1.0.
I have a 2970x at work and I tried to set different NUMA configurations manually, but decided Linux kernel is much better than I am doing so.
PRs welcome. You know, scratch your own itch, and all that. We don't have a dedicated security team (or any dedicated personnel for that matter).
A build in Rust is driven by (1) cargo at the macro-level and (2) rustc at the library-level. That is, cargo is in charge of scheduling on a per-library basis and a single rustc process is spawned for any given library which will parallelize the work of compiling (and linking) said library.
I guess this will change with the new Ryzen generation, where they beat Intel also with the single core speeds.
&gt; The thing that usually helps compile times the most, though, is fast storage. It's good that you're planning on NVMe, I would focus more on that than the CPU. If you can get a faster NVMe drive by bumping down to a cheaper CPU, that's most likely a better configuration. Are you sure? When looking at the profiles of compile-time, it's generally the LLVM phase which sticks out like a sore thumb, and it's not clear to me that it spends all its time in I/O. At the very least, certainly *reading* files doesn't seem to dominate since parsing is so fast relative to the rest. I am not that convinced that *writing* the single library file is that costly, it's a massive sequential write which any disk should handle beautifully.
I was wondering something similar, how Rust compilation can be speed up not by getting a faster CPU, but using idle CPU cores from other PCs. So I'm sitting in the lab on my personal PC, but sometimes my colleagues are not here (lunch break, meeting, ...) and their PCs are idle, is it possible to use their idle CPU cores to contribute to my compilation of large Rust jobs? I imagine something like running a Docker container with Rust on idle PCs that listens on one port, receive compile jobs, and then sends compiled stuff back. Everyone runs the same container, so versions are the same. Does this already work somehow? Maybe I should post this as a top-level question...
hey guys join our rust discord [https://discord.gg/X3q5Ha](https://discord.gg/X3q5Ha)
Hey! Those are good questions! The two projects share similar goals, but the ways we are approaching the challenges is different. `async-log` is primarily an extension to `log` that adds async metadata to all existing `log` calls. Basically all you have to do is wrap an existing `log` aggregator in a `async-log` instance and you're done. No need to change any of the `log::{info,debug,error}` macros in any of the code base. `tracing` ships its own set of macros, loggers, and abstractions. Even though `tracing` can be compatible with `log`, it's essentially building out a separate ecosystem. Like we said there's a lot of overlap between `log + async-log` and `tracing`, and the main difference is in how we're approaching our solutions. Personally I hope we're able to learn from `async-log`'s use, and eventually take that experience to write an RFC to `log` to fold `async-log`'s capabilities into it. The goal is more or less to make `async-log` eventually obsolete; though that'll likely be a while (and importantly: would effectively never require changes to the macros used in code). I can't tell which approach will work best for you. But if you decide to give `async-log` a try, we'd love to hear how it works out for you!
&gt; I plan to have 16 GB minimun. I suspect more ram or faster clock for it will bring minimal improvements. &gt; I can afford at most a AMD Threadripper 2920X. (US500) / 12 cores. To utilize all cores you need enough RAM. For example 32 cores machine with 32GB RAM started using of swap during Chroimium compilation, because of ninja spawn 32 compiler instance, and each requires ~ 2GB of RAM. So depend on number cores even 16GB may be not enough.
&gt; Don't get a threadripper unless you know what it's for There is linux kernel compilation benchmark, as I remember threadripper was winner among ~1K$ CPU.
See [https://github.com/intellij-rust/intellij-rust/issues/3396#issuecomment-506948068](https://github.com/intellij-rust/intellij-rust/issues/3396#issuecomment-506948068)
I haven't noticed problems running low on ram with 12 threads and 16GB when compiling any rust programs. I did run out of ram and started swapping when compiling some C and CPP programs with the same setup.
Thanks for pointing that out; that's something we've been thinking about too! The `#[instrument]` attribute might be helpful to annotate methods, which is generally the most common target to annotate with `span!`. This should hopefully make it bearable for some of the most common operations. We also provide a `Span` struct which logs once on creation, and once when dropped. The `span!` macro makes use of this. Though it's generally not recommended to use `Span` directly because it risks log reordering, effectively turning the logs from a tree into a directed graph (which makes structured log analysis _a lot_ harder). We hope this is a satisfactory answer; we appreciate the feedback!
Posted a reply to the question asked in the `async-log` thread: https://www.reddit.com/r/rust/comments/c6wjbz/introducing_asynclog/esbpf0y
[https://discord.gg/4N8M8eR](https://discord.gg/4N8M8eR)
Alright, good. Not sure what their definition of "soon" is, though. I'll be leaving the bounty open until they make a PR.
Hi Ralf, thanks for the correction! However, I wasn't claiming that type punning is allowed for `repr(Rust)` unions, I was agreeing with you that layout isn't specified which is why you can't do that. If you click through /u/burntsushi's link, you'll see the union in question is `repr(Rust)`.
Where is the best place to find this kind of information? I googled for a bit and ultimately only found RFC 1444 but seems to be very out of date. From your other comment, I gather that reading fields in a union that haven't been assigned to is still UB for `repr(Rust)` unions. Is that true?
&gt;More seriously, caniuse.com says there were a few of implementations of WebSQL: [https://caniuse.com/#search=websql](https://caniuse.com/#search=websql) , which contradicts what /u/est31 said. Um, I think those are all browsers using the Chrome engine. So really it just highlights the power Chrome has.
I second that, on a threadripper with 12 cores(24smt) 32 GB of RAM is not enough to compile chromium (peak memory usage was 36GB) so i suppose if you really want to go the quad-channel threadripper route you’ll have to invest in 64 GB of RAM to actually be able to use it to full extent. Also: go linux, windows is notoriously bad scheduling tasks on threadripper (before 1903 linux was 1.6 times faster than windows, now it’s more like 1.2 to 1.4 times faster) To come back to rust: yes the compiler will use all cores on max and, no, storage speed does not matter when you have enough RAM (because of caching). I have seen no speed difference between a WD green and a 970 Evo+ NVME SSD on repeated compilations (first one with blank caches is slower of course). All compiler threads/processes seem to be independent so i assume big CPU caches and more cores will benefit compiler speed more than single core performance (so go with a server/hedt workstation chip if only that is important to you). For overclocking: use AMD’s automatic Precision Overdrive and stay away from other overclocking options... it really is that good. Threadripper needs a very good cooling solution as you will only get the maximum clock speed if cooled correctly, the interesting thing is that you can run the chip with a bad cooling solution and it will run (forgot to plug in my water cooling pump, did throttle badly but worked somehow) so have a look at the max clockrates the chip clocks up to. If you do not reach what is advertised your cooling is too bad. I am speaking from experience here, even my watercooling setup was not able to cool that beast down!
It is unclear why anyone would want to join your Discord, rather than any (or in addition to) other servers. &amp;#x200B; Also, just in case, this is the subreddit for the Rust programming language; if you were looking for the Rust game, you should have gone to r/playrust.
I love all these new experiments around const generics; it takes time and practice to refine an API, so thanks to all the trailblazers for spending their valuable time on this.
`async-log`, despite its name, works well with both synchronous and asynchronous code. In particular it _adds_ the ability to make `log` produce useful output even when logging inside asynchronous code.
That doesn't provide random number generators for vectors. That uses simd features inside scalar random number generators. What I want is let x: \_\_m128(f32, f32, f32, f32) = rand.gen(); to generate 4 independent random values, not a single random bitpattern.
&gt; &gt; &gt; More seriously, caniuse.com says there were a few of implementations of WebSQL: https://caniuse.com/#search=websql, which contradicts what /u/est31 said. No, they all rely on Sqlite. It IS a single implementation, only the thin API layer on top of Sqlite is different. As you say, it's an awesome library but it is not useful as a standard.
Cool, last time I checked I didn't see that, but it's nice that it's there now!
Thank you
If your 10 second build time is from a single crate using incremental compilation, then single thread performance is the thing that matters. If you have an i7 Mac Mini, the current generation of Threadripper will likely be slower for incremental builds since the boost frequencies are lower. The Ryzen 9 3900X (or 3800X) is a better option, but it still isn't much faster on a single thread. Note that even with a parallel rustc, 6 threads seems to be the fastest for incremental compilation with my 8 core Ryzen 7 1700, and it is barely faster than 2 threads, so don't expect incremental compilation to scale well with multiple cores in the future.
Oh, I don't plan on having an error type for every module, even if I use snafu. There's nothing about snafu that requires that I don't think.
This article explains it nicely: http://ridiculousfish.com/blog/posts/labor-of-division-episode-i.html
I unfortunately don't think the answers are as obvious as you like here. I don't know the answers either, and I try hard to stay informed about stuff like this. If you read the RFC linked, there is language that suggests the opposite of what you're saying.
You want /r/playrust.
My bad
First, read the manual: https://doc.rust-lang.org/book/ Then you can play in the sandbox at: https://play.rust-lang.org/
You want /r/playrust.
Thanks for the detailed answer!
*All* Ryzen chips have non-uniform cache architecture and suffer from the limitation you're talking about, especially if the operating system (~~Windows~~) doesn't account for the cost of shuffling threads around. The desktop Ryzens have only one RAM node. But they *do* have two independent L3 cache nodes. The Ryzen Threadripper products have two memory controllers which can prefer to be two nodes but can emulate a single node pretty well. Each has two L3 caches. Epyc is four nodes per socket. The fact that even desktop Ryzens perform so exceptionally on multi-threaded work demonstrates that the trade-off is very much worth it for most real-world tasks, even when the chips are hobbled by OS limitations. The "code generation units" of rustc don't communicate over shared state that often. So they parallelize fine. Cargo can and does launch completely independent processes to compile multiple crates simultaneously. So yes, Ryzen CPUs are good for edit-compile-test cycles especially if you increase the number of codegen units for the development profile. Release profile probably still should use only one unit. rustc isn't super smart about call graph dependency and can divide the work in a way which prevents inlining.
If an artifact contains multiple crates (typically one per library) then cargo can and does invoke rustc in parallel. It's just like make and friends. rustc reads and parses all modules into a single syntax tree per crate. It does type checking and lowering all in a single thread. (There is a large refactoring effort underway to enable incremental and parallel compilation.) Then the intermediate representation can be dispatched to multiple llvm code-generation threads. Code generation takes the lion's share of the CPU time. Multiple threads can reduce the quality of the optimization because inlining isn't always possible.
Thinking about this more, we could probably allow `#[instrument]` to work on blocks too to achieve exactly this.
For me, it is sometimes a game to look at the title of a rust post and guess, whether it belongs to the programming language or the game. It is sometimes impossible to know in advance, and often enough, you get a surprise!
If we designed and tested vaccines like you design and test your code, the entire planet would have autism.
Is there any way for me to remove cloning from the following block? let SketchBuilder { config, .. } = builder; let window_builder = { let config = config.clone(); WindowBuilder::new() .with_title(config.name) .with_inner_size(config.size) }; Where `config` is a variable of type `Config`: #[derive(Clone)] pub struct Config { /// Name of the sketch. pub name: String, /// Key that, when pressed, stops the sketch. pub quit_key: Option&lt;Key&gt;, /// Size of the sketch's window. pub size: LogicalSize, /// The length between fixed update calls. pub fixed_interval: Duration, } I cannot derive Copy since it isn't implemented for String. If there is no way then I can just deal with it.
https://en.wikipedia.org/wiki/Compile_farm
You would need a way to silence the linearity requirement within the IntoIterator, or any other "blessed" consumer.
enable experimental macro engine. &amp;#x200B; And I also add \`**use** diesel::\*;\` in \`schema.rs\` file. Then the rust macro is expended. I guess the diesel-rs needs to add the \`use\` line at file beginning.
Hey, thanks for asking. `tracing` is built to satisfy real world needs that we have in linkerd and have seen in other large async applications. If you look at the details of how subscribing to `tracing` works, you will notice it differs significantly from `log`. This is because we found that the strategy used by `log` resulted in bottlenecks when attempting to achieve our goals. A few differences include: - The parent / child relationship between spans is *reliably* established. - Ability to enter / exit spans (i.e. wrap Future::poll calls to track an entire Future in a single span). - subscribers can efficiently enable or disable individual call sites at runtime. - subscribers are able to enable / disable individual call sites on a *per call* basis (enables a sampling use case). - subscribers are able to efficiently extract values from the set of keys provided (no string comparison and able to cache). This reflects the needs we have to build instrumentation **beyond** basic logging. For example: - Collect timing metrics: https://github.com/jonhoo/tracing-timing - Interactive debug console: http://github.com/tokio-rs/console I have only just taken a quick look at async-log as this is the first time it has been in the public, but I don't see how it satisfies the requirements we, and others will have when working with large async code bases. I will have to look into it more now though.
cross-posting the reply: Hey, thanks for asking. `tracing` is built to satisfy real world needs that we have in linkerd and have seen in other large async applications. If you look at the details of how subscribing to `tracing` works, you will notice it differs significantly from `log`. This is because we found that the strategy used by `log` resulted in bottlenecks when attempting to achieve our goals. A few differences include: - The parent / child relationship between spans is *reliably* established. - Ability to enter / exit spans (i.e. wrap Future::poll calls to track an entire Future in a single span). - subscribers can efficiently enable or disable individual call sites at runtime. - subscribers are able to enable / disable individual call sites on a *per call* basis (enables a sampling use case). - subscribers are able to efficiently extract values from the set of keys provided (no string comparison and able to cache). This reflects the needs we have to build instrumentation **beyond** basic logging. For example: - Collect timing metrics: https://github.com/jonhoo/tracing-timing - Interactive debug console: http://github.com/tokio-rs/console I have only just taken a quick look at async-log as this is the first time it has been in the public, but I don't see how it satisfies the requirements we, and others will have when working with large async code bases. I will have to look into it more now though.
I am guessing that the first `config` binding is a `&amp;Config` and that the methods of `WindowBuilder` only accepts owned values. In which case, if all other fields in `Config` are Copy, you can clone only the string while letting all other fields be automatically copied. let window_builder = { WindowBuilder::new() .with_title(config.name.clone()) .with_inner_size(config.size) }; If this doesn't work, signatures for the types and functions involved would be much appreciated.
It depends on what the type of the `WindowBuilder` methods are. Does `with_title` take a `String`? If so, you could move the clone to just `config.name.clone()` instead. If you don't need config afterwards, you could destructure it to pull the name and size out and move those instead of cloning.
This is cool. I've been working on a (toy for now) tensor library, and I considered const generics. It seems obvious at first that const generics should work well with linear algebra. But then I realized how limited and bloated it would turn out. For the former, as soon as you start loading data from disk, you're going to need dynamic shapes. For the latter, it doesn't make sense to monomorphize every matrix routine over every shape you use in a program. (Also, BLAS and LAPACK already use dynamic shapes.) I'm now firmly in the dynamic shape camp.
Sorry, there was a lot of necessary information that I didn't think about when I posted the question. &amp;#x200B; You can check out the source code here on [GitHub](https://github.com/flmng0/peach/blob/master/src/sketch/sketch.rs#L14). &amp;#x200B; I'm unable to use the \`config\` without cloning because I use it for initializing the \`Sketch\`
Check out my comment [here](https://www.reddit.com/r/rust/comments/c4jsdt/hey_rustaceans_got_an_easy_question_ask_here/esc1z2i?utm_source=share&amp;utm_medium=web2x). Sorry for not replying directly and not including necessary info.
I know right, I hate whenever I run out of RAM with rust... My god. But then you ask yourself, would Java consume less RAM? Noupe And would C even handle that case well when modern OS give you more virtual RAM than you have? /s
I downloaded the gif and checked, and you are correct.
Yeah, that's a really good point. I think it may always boil down to destructuring, since that irrefutably consumes the value without having to resort to moving ownership to another function.
Java is a really good comparison btw.
I looked through your code again, and wow, much better than when I first saw it. One small thing, you will still leak memory on panics, but I don't think that matters much because mostly matrices deal with `Copy` types
Ah I see. Since the `with_title` method takes any type that can be converted into a string (`Into&lt;String&gt;`), you should be able to do without cloning by taking a reference from the string. let window_builder = { WindowBuilder::new() .with_title(config.name.as_str()) .with_inner_size(config.size) };
You should be able to do `with_title(config.name.clone())` (or `with_title(config.name.as_str())` and get rid of it, looking at the code.
Very nice! I'd suggest putting an example in the Readme. Not that it's hard, but it's a small bump in the road.
What if they tested it and it didn't work
Yeah this worked perfectly, thank you. The project is still in really early stages so I'm figuring out the layout still.
Doing `with_title(config.name.as_str())` works, thank you.
The only time I have ever had issues with Rust is trying to compile larger projects on my Raspberry Pi, and that has more to do with filesystem constraints than lack of memory.
Says that I'm banned ?
Please check the description of this sub, you are not where you wanted to be.
You’re looking for /r/PlayRust pal
[removed]
&gt;for changes you know are going to break lots of visible code, or have a high potential to break unknown code bases I don't think this is quite it. The reason this can change on an existing edition isn't that it doesn't break much code, but that the existing behavior is considered a bug (though breakage is relevant to deciding how to roll out the change). Something that breaks very little code might require an edition if the behavior that code relied on was considered correct and not a bug.
I think what you want is exactly what `simd_support` provides, see for example [here](https://github.com/rust-random/rand/blob/de968657c6490d352638da312df3becb70bd9261/src/distributions/float.rs#L157). For SIMD support inside scalar generators we don't need a feature flag, because we can make that decision at runtime (see `StdRng`).
That union is, but you claimed above that "type punning through unions is not allowed in Rust" and cited this as a source. That doesn't fit together. "Relying on the layout of `repr(Rust)` unions is not allowed in Rust" -- *that* is a correct statement, and it is what your citation confirms.
The RFC is not really out of date, the part you cited is still correct. But all it says is that "you cannot rely on the layout of `repr(Rust)` unions" -- and relying on the layout of a union is one ingredient to be able to do type punning with it. But yes, we are definitely lacking a "how to union"-style guide. All we have is a bunch of RFCs, and the *absence* of any clause that rules out type punning. I fought a lot for that absence, but I appreciate that's not enough, we need positive statements. We need a "union" chapter in the nomicon. If I had infinite time...
Yeah you are probably right, also see my [reply above](https://www.reddit.com/r/rust/comments/c5w36i/brave_browser_from_the_inventor_of_javascript/esc6q9c/). I should also use this opportunity to point out that past RFCs are in general not updated when things change! We don't have the bandwidth for that. An RFC reflects the consensus *at the time it was accepted*. For current information, check the reference and the nomicon. If those don't speak about that topic, they probably should -- might be worth filing a wish, so that people with writing ambitions can get an idea how the demand looks like.
Ah, I found something! I remember writing things about this *somewhere*... The [union chapter of the reference](https://doc.rust-lang.org/stable/reference/items/unions.html) explicitly says &gt; Unions have no notion of an "active field". Instead, every union access just interprets the storage at the type of the field used for the access. Reading a union field reads the bits of the union at the field's type. It is the programmer's responsibility to make sure that the data is valid at that type. Failing to do so results in undefined behavior. For example, reading the value 3 at type bool is undefined behavior. Effectively, writing to and then reading from a union is analogous to a transmute from the type used for writing to the type used for reading.
Oh cool, I'm glad you've taken a (quick) look at `async-log`! -- We've definitely looked at `tracing` too, and though we have different approaches, we share a lot of features! In fact, I don't believe there's anything in the list you've written so far that `async-log` doesn't support. This is in large part because we're able to lean so heavily on `log`, which was expertly designed to handle _all_ logging needs. We're very excited for both `async-log` and `tracing` to exist in this space! We think it's valuable to have multiple approaches and experiments. In the end we all are trying to move Rust's (async) logging experience forward, and couldn't be more excited to share the space with `tracing`!
(cross-post from the `async-log` thread) Oh cool, I'm glad you've taken a (quick) look at `async-log`! -- We've definitely looked at `tracing` too, and though we have different approaches, we share a lot of features! In fact, I don't believe there's anything in the list you've written so far that `async-log` doesn't support. This is in large part because we're able to lean so heavily on `log`, which was expertly designed to handle _all_ logging needs. We're very excited for both `async-log` and `tracing` to exist in this space! We think it's valuable to have multiple approaches and experiments. In the end we all are trying to move Rust's (async) logging experience forward, and couldn't be more excited to share the space with `tracing`!
It's going to be hard to respect or take seriously any decision other than Matrix.
Why? There are other open source alternatives.
There is no OSS alternative that has Matrix's feature-set, number of clients, standardized spec, etc.
rust has an IRC channel on mozilla dot org I thought?
Correct. The Internet is filled with middle boxes that only pass UDP and TCP traffic and would be impractical to ever update. So QUIC is a layer that provides TCP-like streams multiplexed over UDP, and then they're implementing HTTP 3 atop QUIC, so HTTP3 will be UDP (IIRC) Not sure port it'll run on, though. The Wikipedia articles and IETF spec don't seem to say?
That's shutting down soon, hence op asking about it.
So, how does this compare to xsel? Does it work well with Wayland?
For the VM for [Inko](https://inko-lang.org) I use the following setup: Each instruction uses an "Instruction" struct. This struct contains a type (as a u8 sized enum), and a Vec containing the arguments as registers (u16 values). This means you won't have as much compile time safety as an enum variant for ever instruction, but it's more compact. In the future I will probably optimise it to use a single contiguous chunk of memory to avoid the Vec indirection.
Independent of our own decisions, Mozilla is shutting down their IRC network. It’s not clear what *they* are moving to. In the meantime, almost all of the teams have moved to other services; most teams went to Discord, some to Zulip. There’s also a community discord as well. There are no plans to re-introduce an official IRC, though my understanding is that a lot of the folks chatting on the existing one are going to be on Freenode.
&gt; In fact, I don't believe there's anything in the list you've written so far that async-log doesn't support. This is in large part because we're able to lean so heavily on log, which was expertly designed to handle all logging needs. We looked extensively at `log` and the bridge between instrumentation and subscribers (loggers) and did not see anyway to implement the functionality provided by `tracing` within the performance requirements. There are always ways to hack it in (is there anything that can't be hacked?) but, this is at the expense of performance and accuracy.
&gt; In fact, I don't believe there's anything in the list you've written so far that async-log doesn't support. This is in large part because we're able to lean so heavily on log, which was expertly designed to handle all logging needs. We looked extensively at `log` and the bridge between instrumentation and subscribers (loggers) and did not see anyway to implement the functionality provided by `tracing` within the performance requirements. There are always ways to hack it in (is there anything that can't be hacked?) but, this is at the expense of performance and accuracy.
Could you explain how you do it with macros or point me in the right direction?
Is there any plan to make a decision about the recommended go-to place to chat though? From the standpoint of new users looking to ask questions about Rust, it might be better to have one place to go, rather than two or three.
Well, there is sorta one place: the community discord. A few channels for asking for help do exist on the team discord, but that’s not it’s primary purpose. We’ve always had a variety of places: discourse has existed for years, stack overflow is a place to ask questions too, the reddit isn’t official but does exist.
No worries! I wasn't being particularly clear and I don't understand all of it myself. That's why I stay away from writing unsafe code ;) As somebody coming to Rust from managed languages instead of from C\C++, it's kind of weird to me that `repr(C)` has such different semantics than `repr(Rust)` especially around UB. It makes sense why that is, but I don't find it intuitive at all.
Ok, gotcha. I think I was communicating poorly. My point was that C and Rust have different semantics about what's UB. So you can't really transfer knowledge from one to the other. As an example, I was saying that C sometimes allows you to read union fields that were never written to, for example to allow type-punning, while in Rust (which I now know just applies to `repr(Rust)` unions), that isn't allowed at all. I wasn't really trying to claim anything about type-punning in Rust.
Riot is extremely laggy and unresponsive. It feels heavy and cluttered. Compare with slick Telegram. There is a reason why Russian Rust community has long since converged around it.
Depending on how @MasonRemaley has structured the code base, it is actually entirely possible that the code base uses an implicit Entity-Component-System (in the same sense as `specs`, yes.), instead of being object-oriented. Specifically, it depends on how the internal data types (such as `Gate`, `Elevator`, or `Orb`) is defined. It *is* difficult to tell, since these data types are opaque, but I know that I would structure them something like this: struct Gate { drawable: Drawable, transform: Transform, open: bool, ... } struct Elevator { drawable: Drawable, transform: Transform, ... } You could in this case define functions like: fn simulate(delta: f64, transform: &amp;mut Transform) { transform.x += transform.dx * delta; transform.y += transform.dy * delta; } And you could define a literal `System` function that steps the physics of all entities: fn physics(delta: f64, entities: &amp;mut Entities) { for (entity in entities) { match entity { Gate(gate) =&gt; simulate(delta, &amp;mut gate.transform), Elevator(elevator) =&gt; simulate(delta, &amp;mut elevator.transform), ... } } } Hence giving you all three parts of an Entity-Component-System: *Entity* indices are defined by their position in `Entities`, *Component* cases are enumerated inside of the individual entity types, and *System* functions can be defined to operate over everything that has a set of components. Of course, this approach is highly static and makes it difficult to define new kinds of entities. Specifically, it means that whenever you add a new entity type, a new case needs to be added to every single *System*. However, code can be reused in the exact same way as a traditional dynamic Entity-Component-System (e.g., by extracting out common pieces of accessed data and defining functions that operate over those.) Consequently, this approach would *still* avoid the most critical problems with object-oriented game architecture. That is assuming, of course, @MasonRemaley actually structures their code base like this.
Stop leaking.
This is because it is a laptop. Laptops are limited by the laws of thermodynamics. The heat of the cpu limits the speed, making the numbers on most laptops not tied to real world performance.
The size of the project matters. Linking is done on a single thread. Once you've compiled your project and you're only incrementally compiling a couple of files at a time and linking, single thread performance becomes the most important factor. If you're building and installing projects from scratch, not developing those projects, then more cores makes sense, because you're building everything from scratch every time, not incrementally.
It's hard to respect or take Matrix seriously when people push it like that. Different platforms have different trade offs. When you appeal to emotion instead of making a rational argument that acknowledges that, it makes it difficult for people to agree with you.
How do you like your eggs?
1pm UTC happens when this comment is 20 hours and 19 minutes old. You can find the live countdown here: https://countle.com/RCBPk9u3f --- I'm a bot, if you want to send feedback, please comment below or send a PM.
That was my initial response too &gt;It's going to be hard to respect or take seriously any decision other than Matrix. Is immediately just a statement that action cannot be taken against. You can't 'respect' *any other* decision? They're chat rooms not religious scriptures.
What exactly are the tradeoffs making Matrix undesirable over alternatives?
Hi Jon, I really like your live streams and here are some questions I got: 1. What would be some advice that you wish you knew when you just started grad school (PhD)? 2. What do you think are some best practices for building systems but for research project purposes? 3. What do you think people need to think about before choosing async IO vs threading? Do you think people should take a hybrid approach etc Thx
You can use Fractal or Quaternion instead, both native GUI clients.
Older workstations with two Xeons and tons of ram can provide a lot of value.
Quaternion looks like an old Jabber client straight from 2005. Fractal is better but does not support many of Matrix' newer features (chiefly, stickers).
What are your thoughts on the [Redox](https://www.redox-os.org/) project?
Hey Jon, I'm and undergrad CS student and I'm feeling pretty overwhelmed by the shear amount of learning that is out there for programming. What do you suggest is a good way to start feeling like a "real" developer? Thanks so much
Any thoughts or insights concerning hashgraphs?
What is your take on how the rust async ecosystem is evolving? I know that async await will be shipping in a few months and it is an MVP feature, but what do you think would be the most impactful feature to add next?
The Zen 2 models have four L3 caches (or really, it's one per every four cores). I'm interested in what the penalty is for something like false sharing when the resource needs to be shared from two cores on the same L3, different L3 on the same chiplet, vs off on the other chiplet.
What was your primary language before Rust? Thanks.
Ooooh, that's tough. I'm a sucker for a good soft-boiled egg, but I think the top spot would go to a sunny-side up with a slice of cheese on top. Ideally with some Heinz baked beans to go with it.
I agree that it would be nice - it was a bit confusing to read [this blog post](http://smallcultfollowing.com/babysteps/blog/2019/04/15/more-than-coders/), get inspired to join [the Zulip](https://github.com/rust-lang/compiler-team/blob/master/about/chat-platform.md), and then ask a question, only to get redirected to a separate [Discord group](https://discordapp.com/invite/rust-lang).
Sorry No
HI Jon, A lot of apps implemented in C/C++ have a plugin system of some sort (e.g. nginx modules, or plugins for postgresql) that work in a relatively same fashion: the code is loaded from shared libs and scanned for pre-defined entry points. What would be the best way to approach implementing compatible plugins in rust? Are there any good examples of this out in the open? Thnx
Sorry not yet
Hello! 1. It's not only okay to pick up side projects, but it's the _ideal_ time. During grad school you have so much flexibility in what you work on and when, and taking advantage of that to broaden your horizons is excellent. Do things you find interesting or are bothered by the status quo of — that's where your best research will come from. 2. I think _in general_ research systems aren't built like "real" systems. In academia there is relatively little incentive to do things like write documentation, tests, ergonomic APIs, or otherwise to make what you build accessible for others to run. It's all about the underlying research problems and ideas. There are exceptions to this of course, like some of the excellent work that Keith Winstein has done (most is a good example), but in general the push is to focus on research value. That said, I think there's an emerging trend of building more "usable" research systems, and I think that is a good thing. We all do better when state-of-the-art in research is more accessible to "the public". My experience with Noria has also been that once you get to a research prototype that's being worked on my more then 2-3 people, and that is 70k lines of code, you _need_ to be more principled about your development process. You _need_ tests, common benchmarks, APIs and abstractions, documentation, and PR reviews! 3. Some _tough_ questions here! I could probably write an essay on it. I think that the recipe is pretty straightforward: if you don't care about scaling to _many_ connections (and don't think you ever will), do whatever is more ergonomic for you, which is _probably_ threading, though they're not too far apart any more. There's less cognitive overhead to that model, and your code will read a bit more linearly. If you know that your application is not compute heavy (as in, it is more I/O bound), you probably want async. If you care deeply about performance, you'll want to experiment with both to see which fit your use-case — they will probably both require some manual tuning and tweaking to get it just right!
I think Redox is _really_ cool! I don't know that it'll become a mainline OS any time soon, but I think we're already learning from what it's like to build a full OS in Rust (there have been some academic papers on this too), and that's valuable! For broader Rust adoption in the OS space, my _guess_ would be that we'll go more in the direction of Rust kernel modules for Linux, with Redox occupying more of a niche space like OpenBSD/FreeBSD.
I listed a bunch of positives. You could list negatives, or attack my format/person and handwave?
If only "multiple diverse clients" was one of the original positives I listed. Ah yes, Telegram, the closed-source snake-oil encryption chat platform. A totally great choice for an OSS community. /s
I appreciate your enthusiasm for sarcasm, but indicating it defeats its purpose.
You really are the worst bot. As user Mrfister75 once said: &gt; Bigot. *I'm a human being too, And this action was performed manually. /s*
Do you know anything about how things are going with the state of vendor support for Rust in embedded applications? Do you think it will eventually be considered a first-class citizen alongside C for low level applications, or is that too optimistic? Asking as a layman/hobbyist who hasn't really been following the state of affairs for some time.
I don't hate the sarcasm robot, I just want it to not be turned on anymore. *I am a bot, and this action was performed automatically. If you're human and reading this, you can help by reporting or banning u/The-Worst-Bot. I will be turned off when this stupidity ends, thank you for your patience in dealing with this spam.* *PS: Have a good quip or quote you want repeatedly hurled at this dumb robot? PM it to me and it might get added!*
&gt;r code will read a bit more linearly. If you know that your app Thank you for the answer :) &amp;#x200B; Yeah I know Keith's project Mosh, probably I should try to use it at some point. I really like that all of his projects (and many other people from CSAIL) strive to have a reproducible example.
I don't think there is any such thing as a "real" developer. I don't know if you've watched my streams, but I constantly Google things, check StackOverflow, and read through documentation and code to figure out what on earth is going on. I think what happens as you become a "better" developer is that you get better at knowing _where_ to look and _how_ to read those things, but in my experience there is no point at which you become "a developer" and now have to do no more learning. I do think there's a sort of tipping point with any given _language_ where you feel comfortable enough with its syntax and mental model that you can generally write code without constantly being confused by what the compiler is yelling at you, but ultimately typing out the code the right way is only one part of development. I think as you gain experience, you'll find that you spend more of your time thinking about the problem you're trying to solve, and less time on how you tell the compiler about your solution. So, to try to address your question more directly: the way you'll feel more like a real developer is to a) watch people you believe are real developers write code, and observe their process and how it differs from yours, b) keep programming — *all* projects make you more comfortable with the process and with your language, and finally c) share the stuff you build — there is nothing more validating than putting something you made out there and have even a single random stranger on the internet look at it and go "that looks neat"! As for being an undergrad CS student, I'd think of the volume of learning available to you as a "look at all the cool things you can learn" rather than "how am I ever going to understand all of this". There is _no_ rush to learn it all. Focus on the pieces you need for the task at hand, and put down one character after the other :)
Really? Open source doesn't matter? Accessibility to users doesn't matter? Open protocols and clients don't matter? Not using snake oil encryption and supporting proprietary platforms isn't important? Actions have consequences, there are real tradeoffs between the choices and literally NO one here has written a single sentence that justifies any pick over Matrix. Just attacking me for being enthusiastic because I've done a lot of research into this?
I don't know because I'm not a Matrix user. For me personally, I care about: - Nice web client - Persistent state that doesn't require me to always be online. If I have to setup a server to just to get notifications or keep my username, I'm not going to use it. Looking at you IRC - I prefer threaded conversations (at least at the top level) to completely unthreaded free for all. - I know the Rust team cares a lot about the moderation story. What moderation tools does Matrix support? Can messages be erased by admins? Looking at the Matrix website, I see a lot of features dedicated to decentralized communication which I don't care about at all about and usually comes at the expense of features I do care about.
Thank you for the reply! I appreciate that it's more of an outlook thing. I'll absolutely continue to just work on projects and in the future I'll start sharing the things I create. I think this is a big block for some younger developers and just being able to get work out there that you're confident in is a huge thing. Once again thank you!
Zulip is also open source
I just graduated last month and I figured this out my junior year, it was the greatest mindset shift that led to so much success. As soon as you focus on your fundamentals and understand where to find the answer you need, the world is your oyster.
Nice start! Check out `xclip` for some useful features for Linux/X clients. I use `xclip` constantly, and would need most of these features to be able to move.
I look upto people like you who live by the "Each one, Teach one" motto. I'm starting university next year for a bachelors in Computer Science, I've been teaching myself programming for aroudn 2 years now, and I have a few questions that aren't exactly related to programming: * I am extremely fascinated about internals, how things work under the hood as such I love fields like encryption and machine learning. When I saw the type of research you did, I instantly fell in love with it too. The problem is I love too many things, in the grand scheme of things I fear that I might follow a lot of things and never perfect any. Currently, under the advice of a career counselor, I've decided to "specialize" on data science for my bachelors. What would be your advice to nailing it down to one thing, more like finding that one thing you love doing the most? * What advice would you give to who you were when you were doing bacherlors in order to do better? What advice would you give to someone who's just going to start the journey? * I apologize if this sounds stupid, but I've learnt quite a few data structures and algorithms and I could implement them in atleast 4 different languages, but some if not many of the data structures and algorithms I've learnt, I haven't really felt are actually, how can I say? Useful? Like I understand the concepts, logic and how data is structured leads to benefits but I haven't seen this in real life like for example, I've implemented Binary Search Trees a dozen times but like I haven't come across a situation where I would've wanted to implement a BST. Linus Torvalds says that good programmers think about data structures more, which is why I really feel like I'm missing something big here. What do you suggest I do? * Quite a lot of peope nowadays say that bachelors in CS are a waste of money and time, but most job descriptions in many online recruiting sites I've seen ask for bachelors. I decided on doing a bachelors because I felt I'd have more of a solid ground and because of my question #1(aka so I could maybe find my true love) What's your opinion on this? * What are the top 5 books you'd recommend any programmer to read? Also, what books would you recommend beginner or intermediate/advanced rust programmers to read? * Have you heard about Quantum Computing? If so, do you think that in the near future that certain problems that we've had with traditional computing will be solved? Have you done any research on QC? Thank you very very much for taking the time to read this and answering the questions!
&gt; I've yet to meet a person that understands Matrix bridges, or is already using #rust via Matrix, that doesn't think it's the obvious choice I'm that person, then. The IRC bridge is extremely badly behaved. Pinging people or getting pinged seems to only work when the nick contains only digits and normal letters. Half the people still have " (IRC)" behind their name, even though the bridge stopped adding that suffix long ago there's still *so many* users left that are always displayed with it. Putting the default "-M" suffix on any Matrix user using the bridge is also something not communicated to the user at all and shouldn't happen by default. I still think that Matrix would be a good choice, but it's far from obvious.
I think Zulip is an interesting contender as well. I don't personally like it as much, and it lacks all of the amazing features enabled by Matrix bridges (namely IRC integration), but it certainly checks other important checkboxes, imo.
When I opened the tab, you hadn't yet edited your other comment to include reasons to use Matrix. Your insinuation that the Rust community would lose your respect if Matrix wasn't chosen was an appeal to emotion.
This is still a design based on inheritance in my opinion, regardless of organization. (Not that there's anything wrong with inheritance. The author's design is straightforward and will work well for many games.) In your `physics` example, in order to extract the `transform` from different types of entities, you need a `match` statement to pull it from the different fields of each type of entity. This is essentially manual inheritance, using a `match` statement for static dispatch at the call site instead of automatic dynamic dispatch through an abstract method. In a design based on composition, I think there should be only _one_ place that the transform is stored, and no `match` statement should be necessary because there should be only _one_ type of entity. The simplest version of a design based on composition is a single `Entity` struct with a field for every possible kind of component, using `Option&lt;T&gt;` for components not every entity has. A more general/space efficient version would be an `Entity` struct with a `Vec&lt;Box&lt;dyn Component&gt;&gt;` field or a `HashMap&lt;TypeId, Box&lt;dyn Any&gt;&gt;` field containing arbitrary components. If you then refactor that more general design to maximize cache efficiency, you reinvent entity-component-system design. So I don't agree that this design could technically be called ECS just because it has elements that could be named similarly. They are opposites in approach.
I have _many_ thoughts on this, and they're a little all over the place, so let me try to break your question down into smaller pieces: **What do I think of Rust's async model**: I think the poll-based model that Rust's futures are based on is an elegant one, and surprisingly intuitive once you've implemented a couple of futures on your own. It got a little more complicated with the addition of `Pin`, but I still think that's a good change due to what it enables us to do (`async`/`await`), and it's a super neat trick to enable it without changes to the language itself! **What do I think of writing async code in Rust**: Writing an async application on top of futures without async/await quickly gets hairy. You need to wrap things in `Arc` and `Rc`, pass them along in long chains of `and_then`'s, and the code ends up looking far worse than what it's really doing. This is something I ran into a lot in [`fantoccini`](https://docs.rs/fantoccini/). Async/await makes this _much_ better, just like it did in other languages, and I'm very excited for it to become the standard way of writing such code. I also really like the `Future` trait for some reason — I think it's cool that you can just write your own future for when some particular pattern shows up, and that it really isn't that hard. It also excites me that there isn't any runtime magic going on (as in Go), and so I really _can_ debug down into exactly what system calls and such get executed. This has been _vital_ for Noria where high performance and low latency network operations are important. **What do I think of the async ecosystem**: I want to see more joint effort around common interfaces and abstractions in the ecosystem. [`runtime`](https://docs.rs/runtime/) is a _great_ step in that direction, and I hope that pans out the way it's looking. It is pretty tricky, because writing libraries that are executor/reactor-independent is not easy, especially if they're low-level libraries, but I think we can pull it off with enough collaboration among the big players. I think this is part of the charter of the rust async-ecosystem working group, and I think that's tackling one of the most important issues the async ecosystem will be facing going forward. That said, I also see a lot of division in the async ecosystem, which makes me sad. There are so many web crates (rocket, actix-web, tide, to name a few), and it seems like there's relatively little interaction between them, whereas I feel this area would be ripe for common abstractions. The same holds for executors, where we now have both tokio and juliex/romio, and I've heard rumors of another one coming down the line. Diversity here is good, but I worry that there isn't enough work to bring these together under one umbrella in terms of interfaces (`runtime` being an exception) or avoiding duplicated implementation work. We'll see how it plays out — my hope here is that the async WG will help bridge the gap between all of these, and that a year from now the field looks much more unified (again, in terms of APIs, *not* in terms of implementations — picking favorites will do us no good).
I agree that the IRC bridge has not worked well in the past. I also think there has been other discussion here that the bridge would need to work differently in order to achieve moderation goals. However, I don't know if that addresses your concerns. Would it be fair to say, though, that these are potentially bugs in the bridge that could be fixed? Thank you for the reply and feedback about it. I hadn't considered it because I had been under the impression that the kinks with the irc bridge was mostly sorted out for the riot servers.
Hi jon, thanks for the steams, any programming or systems books that you recommend for a CS student?
I have editted my initial comment in this thread. Let me be clear, I will absolutely lose respect for the Rust community team if they pick a proprietary platform, or one without an open protocol. If that means downvotes, I can live with it.
What do you think is a good starter project to get into systems programming? Manu folks start out as web developers and once entering Rust, there are so many terms they are (me included) unfamiliar with. What would you build to get started and what project would let you touch many aspects of it?
The compiler team is already using Zulip which: - is open source - has a mobile, web, and desktop clients - has threaded conversations - supports code blocks with syntax highlighting - automatically links into GitHub when you paste an issue # - has moderation tools like banning users and allowing admins to remove messages Can Matrix do all of those things?
I haven't personally worked on any project that does this, but I know that it's come up for a few projects I've been tangentially involved in. For example, I think [`portus`](https://github.com/ccp-project/portus) (also a research system) does this for dynamically loading congestion control algorithms. I also think Frank McSherry has talked about wanting to dynamically link in things into [Timely Dataflow](https://github.com/frankmcsherry/timely-dataflow), but I don't know the exact details. In general, you can do the same thing in Rust as in those C projects. Using [`libloading`](https://docs.rs/libloading/) you can dynamically load shared libraries at runtime. Not having worked with it myself, I can't give you many details, but I _believe_ one shortcoming here is that you are mostly limited to a C-like API (please correct me if I'm wrong!). Things like Rust generics wouldn't fly. For that you basically need to compile against the crate. I haven't seen any crates that do runtime compilation + reload of extensions, but it'd be interesting to explore that avenue!
It doesn't have threaded conversations, which is an interesting feature. Does Zulip have numerous native clients for every platform out there? Does it have two-way integration with IRC that would make the transition nearly seamless for existing users?
The Book covers pretty much everything the language has to offer. The Rustonomicon covers the _really_ advanced stuff.
I've been through all sorts of languages. My very first language was arguably Windows Shell, where I wrote a "virus" that, when you double-clicked it would open and close the CD tray three times, and then shut down your computer. It was... not very fancy. I then "advanced" to Visual Basic, but didn't really do much interesting with it. I did web development in PHP for many years, and grew to love its warts, but now I haven't used it for many many years (I've heard it's gotten better!). For web dev I now use Ruby or Rust, and obviously JavaScript, depending on whether other people may end up interacting with the code :p For systems programming, I've done a decent amount of C and C++ (for the [Phaser WiFi localization paper](https://dl.acm.org/citation.cfm?id=2639139) for example; [PDF](https://jon.thesquareplanet.com/papers/mobicom14-phaser.pdf)), including some OpenCL programming. When Go came out I used that pretty much exclusively, including for some of my early research, until I found Rust, which I've now switch to wholesale. I've also dabbled in Haskell and Java, but nothing too fancy.
&gt; I have editted my initial comment in this thread to make my sentiments more clear. Thanks for doing that! &gt; But, I will say this: I will absolutely lose respect for the Rust community team if they pick a proprietary platform, or one without an open protocol. It sort of blows my mind to hear this would be controversial. The Rust project already uses lots of proprietary tools like GitHub and Travis and supports lots of proprietary things like Windows and macOS. The Rust project is not like GNU which exists to advance copyleft software; it exists to create and promote the use of Rust. It's not clear to me why somebody would think the line needs to be drawn at which chat platform we use when there are so many other places that are similar.
I've seen a decent amount of excitement in the embedded space for Rust, and I doubt that has gone unnoticed by those involved in the supply side. Whether we'll see them ship Rust libraries any time soon is not clear, but I think there's some reason to hope. In the meantime, I'd watch Jonathan Soo's work on [Bobbin](https://github.com/bobbin-rs/bobbin-cli)!
&gt;I also think Frank McSherry has talked about wanting to dynamically link in things into Timely Dataflow, but I don't know the exact details. &amp;#x200B; I just went and did it, a year or so back in a \[differential dataflow subproject\]([https://github.com/TimelyDataflow/differential-dataflow/tree/master/server](https://github.com/TimelyDataflow/differential-dataflow/tree/master/server)). Of course, then I showed it to some core Rust people and they were all "AAAAAHHHH!!! That won't/doesn't/could never work!" but .. it seems to. There is lots of undefined behavior surrounding Rust-on-Rust FFI, which is a pity because it seems very close to being spec'd out (and seems to work, at least at the moment, but could break tomorrow / already be wrong I just don't know it).
Look, this is the last time I'm going to comment in this thread, because you don't seem to want to engage in good faith. Open, documented protocols, multiple clients, bridging to other networks , good moderation tools are all things that have been widely discussed as being benefits of IRC that are at risk when moving to a proprietary platform. Furthermore, since I've only heard one complaint about Matrix in this thread (effectively a bug report), I guess I just don't get what we're even talking about anymore.
This is exactly my point: the choice has nuance! You can't simply look at a list of features and conclude the platform that has more is the best one. You care a lot about those points and that's totally great! I don't personally care about any of them. I will not be confused or disappointed if the Rust community chooses to go with Matrix because I know other people have different priorities than I do and that's ok. Some of your comments in this thread make me feel like you think any position other than yours is completely invalid. That's why you're getting a lot of push back. If you'd simply said "I like Matrix because it has x, y, and z", I think you would have gotten a much more positive reception.
Does the loss of simplicity in Rust bother/worry you? A number of language changes are introduced in the name of better ergonomics, but often these come at the expense of simplicity. Do you have an opinion on how the the Rust community and the crates ecosystem can protect themselves from the abuses we see in other communities (e.g., 2-line crates, name squatting, etc.)? How can we increase the presence of Rust in the industry, but without sounding like zealots pushing their current favorite shiny toy?
I like your comment about watching other devs develop. Do you have any recommendations on who to watch for Rust related projects?
Hi, Thanks for your time and efforts my question is How to get into Distributed Systems (I know this has been asked many times) and what resources you recommend or you learnt from? also What open source projects you read that benefited in your journey to distributed systems or programming in general that you can share with us?
It's not called "Ask me Anything" for nothing :p - I suffer from the exact same issue. There are so many interesting things to explore out there! The way I've tried to stay sane is to keep a list of "things I'd like to play with", and then every now and again pop a thing off of that list and just sit and read and experiment for like a day or something. In many ways, this is how the live-coding videos came about. I decided that if I'm going to spend a bunch of time in bulk building something new and different, why not share the journey? I think it helps to specialize for your main work though — otherwise you'd never get anything done and that might get you into trouble. I already struggle with that balance, as I spend far too much time on OSS stuff that is only tangentially related to my research, but I've also learned to not feel that bad about it. Your first few years of grad school is _the_ place to geek out and explore weird stuff that interests you. True, you'll have to focus up eventually, but in the beginning find something you think is neat and dive headlong into it! - Hmm... Bachelor's are tough, especially in the US, because you have relatively little choice in what classes you have to take. I'd make sure you spend some time finding a program where the classes seem interesting to you. You'll have a lot to do, and only some of it will be interesting. As you get later in your studies, you'll have more freedom to roam and do the stuff that piques your interest, and you can remember that when you feel like you're in a rut. I'd also say that it's important you don't feel bad for pursuing things that aren't directly related to your studies. If you do things that excite you, those are the things you'll do the very best in! Not sure if that's helpful? - I think studying data structures in isolation is unlikely to be super useful. The biggest advantage it gives you is that down the line you may come across a problem where you go "oh wait, I know a thing that does that!". I think it's more useful to think of data structures in terms of needs (and my guess is that this is what Linus was getting at). When you have a problem in front of you, try to phrase it in terms of what the data is and what you're trying to do with it. Then try to figure out what properties a data structure would need to have to fit your use-case. That's when you go exploring data structures to try to find something that matches! - The world is as it is, and while hopefully things will change eventually, I think today a Bachelor's is probably a "you need it to be considered" type ordeal. It's a shame, but so be it. For me, I chose to do a Bachelors in some sense to _focus_ my interests. There were so many things to learn, and I figured a Bachelor program would at least lead me through the potential fields as sort of a sampling survey of what's available. Some will be good and some will be bad, _and that's fine_, because at least you'll get to see the things that are out there, and you can then go on to make an informed decision! If you were to explore all of it on your own without guidance, you'd probably see fewer options. - I really like "The Pragmatic Programmer" and "The Art of UNIX Programming". "Seven Languages in Seven Weeks" was also kind of neat. If you like data structures, low level details, and operating systems, "The Design and Implementation of the FreeBSD Operating System" is pretty great. Tanenbaum's "Modern Operating Systems" is also good. Oh, yeah, and "Hacker's Delight"! As for Rust, that one's trickier. There aren't really good Rust books out there at the moment. [Too Many Linked Lists](https://rust-unofficial.github.io/too-many-lists/) is great though. I'd also give the nomicon a read! Hope that helps!
What are some things _you_ 'd like to see change in the Rust language/ecosystem?
Could you expand on this a bit more? The compiler team is pretty much all on Zulip so I'm kind of surprised you were redirected to Discord. Or was your question more about the language in general?
Absolutely! It's intimidating to put your work out there for others to see and "judge". And there will be asshats out there that don't appreciate that you've put effort into it. But if you manage to look past those people, you'll find so much joy in seeing others (even a single person!) picking up what you made and say that they find it neat, interesting, or even useful :D I think making your work public also makes you a better programmer in the long run — you'll get better at documenting, testing, and commenting your code, as well as managing cooperating workflows (should you get contributors).
Yeah, having not to worry about data layout questions is certainly a big plus in managed languages -- and in safe Rust. ;)
Shameless self-plug: https://www.youtube.com/c/JonGjengset I think there are two avenues to go here, one is to read code written by experienced developers, and one is _watching_ those people write code. They are both useful and educational, but I think the second one has an advantage over the first: you'll get to see their mistakes. When reading the code someone published, you don't see all the design changes that happened along the way, all the sweat and consideration, all the mistakes, or all the really hard parts. And that (probably) makes you underestimate your own skill. There's also immense value in observing _how_ other developers fail, and what they do to recover. It's the _one_ skill that is basically impossible to teach, and that you have to _experience_. I'm not very well informed on what other live-streamers of Rust there are out there, but I know Frank McSherry recently did a live-coding session on [differential dataflow](https://www.youtube.com/watch?v=W6TKxS_pWr0). I haven't watched it, but Frank is certainly an experienced developer! Ryan Levick has also [done some in the past](https://www.youtube.com/channel/UCpeX4D-ArTrsqvhLapAHprQ), and I know there are some people live-streaming game development (can't find the URL right now). [/r/watchpeoplecode](https://www.reddit.com/r/WatchPeopleCode/) may also be one to watch.
What was the last thing you got hung up on learning that you just couldn't wrap your head around and how long did it take you to figure it out?
They sound tasty.
If you could rename the Rust programming language to anything, what would it be?
Hi! Take a look at the last bullet point in my answer [over here](https://www.reddit.com/r/rust/comments/c71f03/im_a_phd_student_building_a_fast_research/escjm0y/). Also, happy cake day!
Was it a VBS script? I used to troll scammers with it
Fair. Let me try to expand on your statement a bit, to give it a different perspective: Consider ``` union U { x: u8, y: u32 } fn test() -&gt; u8 { assert_eq!(std::mem::size_of::&lt;U&gt;(), 4); let u = U { y: 0x01020304 }; unsafe { u.x } } ``` This program *does* have defined behavior in Rust. However, whether it returns 1 or 2 or 3 or 4 depends on which choice the compiler makes about where to put `x` inside the 4 bytes that is the size of the union (and we checked that it's 4 bytes). The difference to C is that C has a defined guaranteed data layout for all types. There we know that `x` is at offset 0, so this will return... 1 or 4, depending on whether you run it on a little-endian or big-endian system, and don't ask me what it does where.^^ But it's a defined thing (per-platform), unlike in Rust. This is not at all specific to unions; the layout of Rust structs is also not defined and thus you have similar problems. So saying that this is about "reading from union fields you have never written to" is a bit misleading. However, I absolutely agree to the statement that you can't just naively apply things you know from C to Rust. Rust has its own rules. Data layout is but one of them.
I was asking specifically about how to submit a patch to the Rust documentation, which I was not aware was not part of the compiler team.
My go-to project tends to be building a networked key/value store. The API is pretty simple, and it quickly exposes you to a number of systems concepts like network connectivity, serialization, and concurrency/synchronization. There are also so many systems for you to compare your design to or benchmark against (should you wish to), and you don't actually have to write all that much code to get something basic working. It also trivially extends in basically any direction: add fancier data structures (like Redis), add a command-line interface, add a GUI database explorer, add multi-machine replication, etc.!
I'm probably going to visit MIT in September, will you be around to chat? :D
In a similar vein, do you think that the community could/should be doing differently to encourage new contributors to land meaningful features?
Thank you a lot, i’ll check out your videos. This seems really useful. I’ve been trying to work on my own crates and want to release them but feel self-conscious about it because ive never released a library before so I want to make sure I am informed on how it all works. I appreciate the response!
1. Did you arrange the markers in this photo? https://jon.thesquareplanet.com/rust-ama-2019-06-29.jpg 1. Can you explain "incrementally materialized views" like I'm 5? 1. Totally random, but do you know of a sqlite equivalent for graph databases?
Actually, I think u/Babyhulk777 refers to the crate ferris-says, which is used in the tutorial on [www.rust-lang.org/learn/get-started](https://www.rust-lang.org/learn/get-started)
Ah yeah that's a bit tricky. If it's docs for the standard library, then that team is on discord. If it's internal compiler docs, it probably falls under the compiler team on zulip. Sorry for the confusion!
Just listened to your interview on Noria - it truly sounds like a godsend. It’s almost like a reactive, cross-table database indexing system. And it’s so much easier for application programmers to stay thinking about what data they need, rather than context switching to build (and deploy, and wait to spin up) a manual pipeline for every new join/aggregate they need. This is exactly the right layer IMO to solve that problem. Are there plans in the works (that you can share) to commercialize the technology and make it ready for prime time? Also, are there consistency guarantees for the derived data, or are queries through Noria eventually consistent at this point? Either way I look forward to the day when Noria’s ready for prime time (and I can use it in the day job!) Also, a bit of a sidebar: what, if any, is a library that you wish existed for Rust but hasn’t been ported or implemented yet?
It's a tough question to answer because it both does and does not. I think Rust does have a tendency to scare off developers early on because it introduces new _concepts_ (like borrows and `Send`/`Sync`) that in turn make it hard to even get your program to even compile. For developers coming from (most) other languages, this is extremely frustrating, because they're used to "getting it to compile" to be a non-issue. Generally, in other languages, the issue is getting it to _run_ correctly. You compile it, you run it, and then you debug. Rust doesn't quite have the same model. Instead, compiling is the hard part. If it compiles, it is much more likely to be right! But if you don't _know_ that, then it just seems like "I can't _even_ get it to compile, how will I _ever_ productive in this given that this should be the easy part". I'm not sure exactly how we fix that, but I think it's an important pain point for newcomers to the language (and we've seen plenty of blog posts to that effect). The reason it doesn't _actually_ bother me is two-fold. First, a decent number of developers _are_ making the switch, and are finding that what Rust gives them was worth the struggle. Not all, of course — there are a decent number of examples of people who said it wasn't for them after getting over that hill — but that's okay; Rust doesn't have to be the One and Only Language™. It's okay if there are some areas where it's not a good fit, or if some developers don't prefer Rust's particular model and design decisions. And second, over time, there will be more _new_ developers that are learning Rust as their first or second language. For them, Rust isn't different in any meaningful way, because they don't have a comparison point for it to be different _to_. And I think for those people, Rust is actually quite easy to learn! Many of Rust's restrictions make intuitive sense (at least I've found that newcomers to programming often don't find them surprising), and I actually think Rust makes a pretty decent teaching language! I'm not entirely sure what you're referring to in terms of the ergonomics/simplicity trade-off? `async`/`await` and `Pin` perhaps? I think in these instances, the added complexity should generally not be something users have to think about in the first place anyway! Very few users of `async`/`await` (and indeed futures in general) should need to think about, or even _see_ `Pin`. But it _is_ available there _if you need it_. Perhaps one way to think of this is that Rust doesn't "hide" how stuff works under the covers. In Go for example, can you tell me how 100 Goroutines can do blocking network and file system operations without spawning 100 threads? "The Runtime", sure, but how does that work exactly? In Rust, the details all the way down are exposed to you if you start digging. I _think_ that's an advantage. Community abuse is complex topic, mostly because it involves us foolish mortals. Humans are hard to herd, and there will always be bad or even malicious practices. For what it's worth, I've generally found the Rust community to be very warm, welcoming, helpful, and understanding, and I _hope_ we manage to keep it that was as the language grows in popularity and the community grows with it. I do think that as Rust becomes more mainstream, _some_ more policing is going to be required as the "low bar" for entering the ecosystem lowers, but I am also sympathetic with the crates.io team on things like crate squatting where they say "who are we to judge"? They'll catch flak either way. The current policy probably isn't indefinitely scalable, but taking time to get it right while we can seems reasonable to me. That last one I've actually found surprisingly simple. Don't do anything special. As developers, we often end up talking to one another about our experiences, and if you enjoy using Rust, that will shine through, and curious developers will peek at it in their own time. There's no reason to brag about how you're using Rust or trying to bring it up in every conversation, your enjoyment will do the work! I think this is also happening through the community at large. The Rust community has gained a reputation for being a pretty good one (at least that's my impression), and it has produced a look of really good tools (I'm looking at you [sharkdp](https://github.com/sharkdp) and [`BurntSushi`](https://github.com/BurntSushi)) that are seeing widespread adoption. Not because of Rust, but because of what Rust enabled those people to do! And that's what intrigues developers :)
Oh, I forgot to answer your second question! I think existential types and const generics are biggest on my wishlist for next features at the moment. Those are by far the features I miss the most in my day-to-day.
Haha, no, just a straight Shell script that ran some stupid commands. Ultimately, it was the equivalent of ``` #!/bin/sh eject eject -t eject eject -t eject eject -t poweroff ```
What sort of applications or problem domains would be suited to using your database?
I think the notion of "mentored issues" is a _great_ idea, and absolutely the way to go. The downside is that it requires _so_ much effort, which can be hard to build in a small project (especially if you're just one person maintaining it). Even just keeping an organized bug tracker with some basic instructions and a "help wanted" "good first issue" label goes a long way though.
I think my wishes are pretty much in line with the results from the last Rust survey. I'd like to see the language take a beat to catch its breath so to speak. We've seen some really cool developments over the past year, but now it's time to finish things up and polish! It's a marathon and we've been sprinting. To be more specific, I'd like to see features like existential types and const generics land, I'd like to see improvements to the compiler docs (already happening, and it's great!), and I'd like to see polish on the tooling around Rust (rust-analyzer, tools not breaking frequently in nightlies, etc.). I'd also like to see the number of nightly-only features shrink by a lot. We've made good progress, but there are still so many. For example, it'd be _great_ if Noria could get rid of [these](https://github.com/mit-pdos/noria/blob/ab5d51e6e88509748e75572a4068e344ea7ade92/noria-server/src/lib.rs#L351-L358).
Where're the library team these days... They're neither on discord nor on zulip, right?
I quite like the name Rust, because it has good pun potential, and because it just sounds _cool_ somehow. My biggest gripe (especially when live-streaming) is that it's also the name of a decently popular game, which causes some confusion. In the vein of metals, "Steel" maybe? "Built to last", "Multi-purpose", "Hard to break".
Haha, yes, I will indeed! If I'm not mistaken, you may even be visiting my group specifically :D
I agree - it's just memorable and hardcore, whereas something like Python or Java just sounds tame. But yeah, I definitely see the conflict with the game - sometimes I have to specify stack overflow in my searches to narrow the results down.
It's worth noting that slog conventionally treats its "context" as just being additional data appended to every log message using it, which is quite different from tracing's notion of the spans themselves being events (with a duration, rather than an instant).
In hindsight, I agree that the approach is not a proper Entity-Component-System *if* the term is exactly defined to mean "represent behaviors as a relational database." Personally, I always understood it to mean "divide entities into set of properties/behaviors, then define arbitrary functionality that operate on sets of properties", which this approach very much follows. That said, if the former definition is the one actually used, then I will admit to being wrong. Even so, note that the match expression that needs to be called for each case in the enum is not *inherent* to this design. In fact, your previously mentioned entity-structure-of-components actually has this problem too, since each system needs to manually iterate the entity list and manually extract the components into the system. This boilerplate is mitigated by `specs` because `specs` is a wonderful library. The thing is, I could *also* define a library that iterates over every entity in an enum and manages all the boilerplate for me. Certainly, it would be a little bit more complicated, but you could do it once and be done with it. In fact, the user interface could be literally equivalent to `specs`, except entities are defined as enums rather than structs. Consequently, I disagree that the approach taken by MasonRemaley is any more object-oriented than a proper Entity-Component-System. I originally had a much longer post justifying why the sum-based approach and structure-based approach are much more similar to each other than one is to inheritance, though I ended up scrapping it because it became too theoretical and this new post is much simpler. If such a thing interests you, I could post that too.
Hello! 1. Imagine a regular database like a person sitting in a room full of documents. Every time you ask them a question, they have to go look through their folders and drawers, noting down all the stuff they need to answer your question on a sheet of paper. Eventually, they hand you that sheet of paper, and it has your answers. Now imagine you go ask them the same question. They'd have to go do all that stuff again, and that's annoying. A materialized view basically means that the person copies down the answers before they give them back to you. That way, the next time you ask, they can give you the answer immediately! But what happens if someone comes and adds more papers to the room? Your old answer might now no longer be right! View maintenance simply means that the person in the room has _some_ way to check if the old answer is still right. One way to do this would be for the person to look at every new paper that is added, and if they see that it is relevant to the question you asked, they simply throw away your old answer, and they'll go search the room again if you ask again. With _incremental_ view maintenance, the person will use the information from all the new papers that were added to _update_ your answer so that it's correct again rather than throwing it away! 2. Hmm, no, sadly not. I think [Prisma](https://www.prisma.io/) is working on something along these lines, but don't know for certain. 3. I did indeed! Although I did not arrange them _for_ the photo, they are _always_ arranged that way.
Very cool man, thanks for sharing.
For getting into systems programming in general, see my answer [here](https://www.reddit.com/r/rust/comments/c71f03/im_a_phd_student_building_a_fast_research/eschkm2/). For distributed systems specifically, I would recommend giving the MIT class [6.824 Distributed Systems](https://pdos.csail.mit.edu/6.824/) a try. The labs and lecture notes are all online, and it gets quite deep into hands-on work! I'm also excited about PingCAP's [Distributed Systems in Rust course](https://github.com/pingcap/talent-plan/tree/master/dss/), and also their [Practical Network Applications in Rust](https://github.com/pingcap/talent-plan/tree/master/rust). Not sure how far along those are though. I don't know that I can name specific open source projects that got me involved in distributed systems. I've just always found reasoning about protocols and correctness interesting. 6.824 as mentioned above was definitely a stepping stone for me, as was taking Nancy Lynch's 6.852 Distributed Algorithms class. Learning both the practice and the theory worked for me :)
Any chance of getting a impl for Path and PathBuf?
Following up on this question. As a newbie in rust, working with futures in the current ecosystem was a bit challenging. Many times I look for examples of code to understand how to use certain consents.These can be a bit rare in rust, simply because it is changing quite a bit. I feel that with a change like `async/await`, while some people who are really involved with the details, will be happy with the change. Others who have *finally* figured out how the examples they have found on Github work, will be frustrated with warnings of `this is now deprecated`, without any good explanation of how the old example should be translated to the new concept . What do you think should be a good approach to address this? Thanks
What would you prefer C# or Rust and why? Thx fir everything you doing :)
Hehe, yes, I think so too! That's why we built it in the first place — it seemed to fit into an obvious open slot in that space. There aren't currently any plans to commercialize on my part, though I have had a _lot_ of people ask. It's not because I don't believe in the idea, I very much do, but more that by the time I graduate I will have worked on this project for five years non-stop, and I feel the need to explore other things as well. In some sense, my biggest hope is that _someone_ picks it up and that I can take on more of a consultant role (it's complicated and involved enough that that'd probably be needed), because I truly believe that this is something that should exist and be usable in production. Noria is currently very much eventually consistent, but it's not _quite_ as bad as some eventually consistent systems are. In particular, when you read from any particular view, Noria will ensure that you see a _prefix_ of all writes submitted to each base table, and each write will be represented at most once. No duplicates or missing updates or anything. If your query doesn't have diamonds (like a self-join), Noria also guarantees that you will only ever see a write fully applied or not at all. It's not quite the same, but I keep a list of projects I want to live-code at https://jon.thesquareplanet.com/live-coding/. David Tolnay also has a _great_ list over at https://github.com/dtolnay/request-for-implementation/. For me personally, I'd really like to see a high-level asynchronous SSH crate. Something where I can just give a username + host, and it'll use SSH agents and stuff, and then give me a `std::process::Command`-like interface (but async) for running commands on many hosts. Would be super handy for orchestration for example! I started [live-coding](https://www.youtube.com/watch?v=RBQwZthJjoM&amp;list=PLqbS7AVVErFjzlF3JSwzxttE1G0awWimV) one a while back, [`async-ssh`](https://github.com/jonhoo/async-ssh/), but it sort of stagnated.
It is very much geared towards application that issue many similar queries (prepared statements) and are read heavy (so where caching makes sense). Web applications are our primary target use-case, though there may also be other areas with similar requirements. Noria also specifically gives weaker consistency guarantees, so your application would have to be able to tolerate that. We are looking into adding things like "read your own writes" and "write only if my read is still valid", but they're still in the research stage. I go into a lot more detail on this in the [CoRecursive podcast interview](https://corecursive.com/030-rethinking-databases-with-jon-gjengset/).
Hey Jon, \- What do you think about the discussions going on about Go 02 with the support of generics and better error handling? \- And how it can be affected to the future of Rust user base with the maturity of Golang ecosystem and strong backup from Google?
Hi Jon, (First, apologies that it took me so long to announce this post, I had some family matters to attend to) * What do you think about clippy? Do you use it? Is there an improvement you'd like to see? * You wrote elsewhere about debugging async code. What's your workflow there and what tools do you use? * What is the feature you'd most like to see stabilized?
I get _so_ confused every time I run into https://github.com/rust-lang/rust/issues/41078. At this point I know the workaround, so it doesn't take me _too_ long to realize that that's what's going on, but I can't make heads or tails of those errors. In particular, the rules around lifetime variance and things like `for&lt;'a&gt;` still tickle my brain. I last ran into it this morning with https://github.com/jonhoo/tracing-timing/commit/d7f3794431458e234c339d4672463d6667de9b15.
I have never used C#, so I can't answer that question :) Alternatively, the answer is trivially Rust because I don't know C# :p
I don't think any of the old code will be deprecated. Under the hood you'll still have all the combinators that are there today. It's just that there'll now be much nicer syntax that you can (gradually) move to. The underlying model is still the same, it's mostly just the surface-level stuff that's changed, so if you have gotten to the point where you somewhat understand the old model, the change should be a piece of cake!
Thanks for the answers and the marker gradient is quite pleasing to the eyes!
Thx for the answer ;p cos currently im planing to learn c# and were thinking which one of those two to start with.
&gt; In fact, the user interface could be literally equivalent to specs, except entities are defined as enums rather than structs. Consequently, I disagree that the approach taken by MasonRemaley is any more object-oriented than a proper Entity-Component-System. Are you familiar with specs? Entities are not defined as structs, not really. They are unique ID numbers, shareable independently of entity. Components are stored separately in Storages, one per type of Component, indexed by Entity ID. In theory, you could implement the same idea by creating one giant list of Entity enums that are each assigned an ID number. Systems could access Components by iterating over every Entity in the list and matching for the kinds of Entities they are interested in. With some difficulty, as you said, you could even abstract this so that the System doesn't have to do the matching and just gets references to the Components it needs. However, at this point you are not using the author's design at all. You are using an ECS design that happens to store its entities and components in the same data structure as the author's design. I don't see how that demonstrates that the author's design, which uses a completely different method of accessing entity and component data, is not based on inheritance. It's also not a very good idea.
No worries at all! It ticked along quite well :D - I _love_ clippy, and I also tend to point people who are new to Rust to it as a quick way to learn Rust idioms. I also have clippy enabled in CI for all my projects. I think the biggest gripe I have is that it is quite pedantic about complexity. The number of times I've had to suppress warnings about "too complex type" or "cyclometric complexity"... I understand why the warning is there, but oftentimes I _need_ to name a big type (especially when dealing with futures), and I don't want to introduce additional newtypes just to make the signature "nicer". Or for functions, there are times when I *can't* split a function because I need to hold a luck or would need partial self borrows to make it work. As for improvements, I'd love to see it as not a separate compiler pass. If I could have it integrate in rust-analyzer or something, that'd be awesome (maybe it already does at this point?) - Debugging async code is hard, there's no doubt about that. I have some hope that the recently announced [`tracing`](https://docs.rs/tracing/) crate might help, especially once it's hooked into the executor, but haven't had a chance to play around with it enough yet. Very often I end up relying on good old print debugging to figure out what future is being polled when, when does it yield, and why. Every now and again a well-placed panic to determine where something is being polled _from_ also helps a lot. Really basic debugging techniques, but it works surprisingly well. Arguably I should use breakpoints, but I haven't found it to be enough of a nuisance to be worth figuring out that workflow. The most common issue I run into is writing custom futures that don't schedule themselves to be notified correctly. It'll just yield at some point and then never be polled again. I have not yet figured out a good way to debug that without just reading the code carefully and figuring out the last thing it did, but this is somewhere I think `tracing` could help a lot. - This came up [elsewhere](https://www.reddit.com/r/rust/comments/c71f03/im_a_phd_student_building_a_fast_research/escmdq1/), but I'll repeat it here. Existential types are probably the biggest one for me. In Future land it is _so_ common that there's some associated type `ResponseFut` (or something like that), and naming that is both hard and annoying. Existentials are basically necessary to make traits that involve futures nice. Const generics are a close second -- "only defined up to arrays of length 32" is not okay to me from a theoretical standpoint :p
Hi! - I think the Go 2 generics proposal (at least the last one I read with the notion of "contracts") is _insane_. I don't necessarily mean that in a bad way, I just think it's a crazy and unexpected way to do it. I see the appeal — you don't have to learn a whole new type system mechanism, you just "write Go example code". Whether it'll pan out that way in practice I have no idea. I feel like this "kind of Go but not really Go" could also come back to bite them _hard_, and I also worry that there'll be things you can't easily express in that style. Too early to tell I think. I haven't seen their proposal for better error handling. - I think Rust and Go are solving relatively different problems, and with different target audiences in mind. The simplicity of Go is _great_ if you have large projects worked on by _many_ different people, and where low-level control is less important than uniformity. Rust goes completely the other way and instead gives the developer very fine-grained control and flexibility, at the cost of "obviousness" of the code. I'm not worried about either "subsuming" the other, because I think they are so different in what use-cases they cater well to.
thanks! it was a fun exercise to go through.
Yes. I'm quite familiar with the RFC process and the status of accepted RFCs. That's precisely why I pinged you: because I know RFCs are generally not living documents. At the end of the day, however, Rust's UB situation is currently pretty fluid, so we have to do the best with what we've got.
What's your favorite educational blog/video/book/tutorial/source on how to implement a join-engine? For the curious :)
Sorry, I don't know what you're asking. Can you please provide more information?
I’m not sure, to be honest. They were one of the last IRC holdouts.
Are there any problems with Rust which you consider to be entirely or mostly intractable?
I'm not entirely sure what you mean by a "join-engine"? Just executing a join isn't too complicated, though once you want to make it fast there is all sorts of literature on how you can do that in different contexts. You may find the SQLite query optimization document [section on joins](https://sqlite.org/optoverview.html#joins) a decent place to start.
Not off the top of my head, but I'm also not sure what kinds of problems you are thinking about? I think there are some things we are unlikely to see appear any time soon (if ever), like garbage collection through a runtime or support for machine-checked proofs over your code with a theorem prover, if that somewhat answers your question?
When I was bringing up the theoretical (and horribly overcomplicated) automated sum-based approach, my point is basically this: if you believe MasonRemaley's design is based on inheritance, then you must also agree that the automated sum-based approach is based on inheritance. After all, the systems, which makes up the main part of the game logic, is defined in exactly the same way. In other words, the only (but admittedly huge) difference between the automated system and the simple system used by MasonRemaley is the boilerplate used in connecting the systems. Remember that this horrible automated sum-based approach *could* be made equivalent to the much-better `specs` design in its user interface. After all, the main part of your game exists in your systems, which does not change. Consequently, if the sum-based approach is based on inheritance, then `specs` is also based on inheritance, which is obviously false. Surely, if the vast majority of the code you write is *literally identical* to an approach distinctly not based on inheritance, then the vast majority of the code written by MasonRemaley is also not based on inheritance.
Hi Jon, Apologies for the text blob, but want to give some context. I'm a US Army veteran that's recently returned to school to to earn my CS Masters student at George Washington using my GI Bill (provides independent funding, so I don't need to be a TA or RA). My choice of school had mostly to do with life logistics (I own a home, am married, and I don't want to move), and since I've been working as a software engineer in industry for a while, I showed up to school without a defined research interest. Generally, I feel like I'm more of an enthusiast that likes to tinker with a lot of things rather than a dedicated deep specialist. For this reason, I really feel out of place in the CS department, and I turned down an offer of a PhD fellowship to test the waters with my external funding. Many of my interests are around software engineering, programming language theory, compilers/interpreters, distributed systems architecture, but I like a lot of eccentric things (e.g. I'm fascinated by older languages and operating systems and spent a week teaching myself COBOL recently for fun). The faculty I work have expressed that my interests too "engineering-centric" and not sufficiently "research-focused," and they've tried to steer me towards deep learning (especially cyber stuff since I'm clearable and can help profs get DARPA grants). Maybe that's practical advice, but my decision to go back to school was to explore my diverse intellectual interests, not optimize my ability to bring in grant money by focusing on what is hot in the academic job market. I have suspected that perhaps I'm better aligned with systems type research, but I have an impression that there are only a handful of financially-secure top schools focus in this area, and the lower ranked schools like GW aggressively chase the shiny trends to compete for grants. \* How did you determine your research interests? \* What would you have done if you were unable or unwilling to relocate from Norway? Do you share my friend's impression that meaningful systems research is only concentrated in a handful of top 10 programs? Any thoughts about how open-source collaboration might change this? \* What do you think about the massive research hype wave around deep learning and neural nets? Do you perceive other students as bandwagoning and downplaying their personal preferences by researching in this area? How should I perceive pressure from academic advisers to downplay my research interests for things that don't inherently interest me? \* What sort of decision making criteria should I consider when decided to return to industry versus continuing into a PhD? Thanks! 🙇‍♂️
Hi all! Thank you \_so\_ much for all of your questions, it's been fun, and you are all awesome! I got far questions more than I expected, and some deep and thoughtful ones at that. I \_think\_ I have now answered all the outstanding questions, and it looks like the stream of new questions has slowed down, so it's time to call it. If more questions come to you later, feel free to post them here or ping me on Twitter and I'll get back to you when I can :) Cheers, Jon
Hi Jon, I really like your live streams. Will you make a video where you do something with the new async/await?
Thanks :)
My idea was providing a ByteSlice/ByteVec for Path/PathBuf. A few methods would be quite useful to have without a conversion step. Eg `contains_str`, `find`, `is_utf8`, ... But after looking at the full trait, quite few of the methods would be suboptimal on Path/PathBuf.
Hello! No need to apologize at all — I appreciate the context. Before I get into your specific questions, I'd like to make an initial observation that may or may not be helpful: academia is _definitely_ focused on research contributions, and I think this applies pretty much everywhere. And arguably rightfully so. It is not quite the free-for-all do-whatever-you-want that it sometimes seems from the outside, because that wouldn't actually provide "value" in the intellectual or the fiscal sense. While you have a lot of freedom during a PhD, especially in the early years, to explore what you find interesting, and seek out where you think there are exciting things problems to solve, the end-goal that your advisor(s) has in mind is still that you will write a doctoral thesis. And in that thesis, you have to show that you have "pushed the boundaries of human knowledge" — or, said less pretentiously, you have to demonstrate that you contributed something _new_ that wasn't known before. I _think_ that is what the professors you have spoken to are trying to get at, even if they are not phrasing it in the best way. Okay, so, on to the more specific questions: - I think they have evolved over time, but in general I've been gravitating towards things that I couldn't help myself but think about. For me, that has generally been in the space of parallelization, concurrency, and performance. I would get "nerd sniped" so easily by pretty much anything in that area, and spend so much time thinking and tinkering with problems in that space. And so over time, those were also the problems I was seeking out, and that continued into grad school. I think you will generally be far happier, and more successful in what you do, if you work on something that feeds into your curiosity. Something that you just can't resist thinking _just a little more_ about. Usually you will also find that you start branching off of your initial interests. For example, reading up on parallelization and concurrency very naturally led me into distributed protocols, and protocol design in general. I also found that there was a natural alignment there with my (admittedly occasionally annoying) penchant for pedantics and choosing to interpret the literal meaning of things in everyday life. It turns out that is a great inclination to have when working with protocols! - That one is tough. I left Norway specifically because I started a Bachelor's degree there, and was bored out of my mind. That may have had to do with staying in one country for so many years up to that point, but I think it was also a side-effect of Norway being a relatively small player in Computer Science, and in Tech more generally. I think you _can_ absolutely do interesting research at smaller institutions, though I think, as you observe, that you'd be more likely to have your options reduced to what those who are there think is worth working on. At a place like MIT, at the very least you have a wide variety of professors to choose from, so even if each one were very narrow-minded (though I don't think most of them are), you'd be able to jump to some adjacent field pretty easily. Whether open-source helps this really depends on what you ultimately want to do. Open-source development doesn't _really_ help with academic research, but your academic research can totally happen in the open-source ecosystem. I think open-source development in the professional setting is more about establishing developer trust, reputation, and connections, than it is about showing research prowess. One thing that the wide-spread adoption of OSS _has_ enabled though is to make it easier to collaborate on research across vaster distances. For example, we've had people in both Norway and Germany work on Noria. Usually that work starts through them doing a semester abroad or something here, but you could also try to get involved through the open-source projects directly depending on how they're managed. [... still writing, just posting to checkpoint ...] -
&gt; Surely, if the vast majority of the code you write is literally identical to an approach distinctly not based on inheritance, then the vast majority of the code written by MasonRemaley is also not based on inheritance. I disagree. The Systems may not contain any code based on inheritance if you cover it up with an abstraction layer that does not expose it, but the bottom layer is still one based on inheritance. Furthermore, the author _does not do this_. You are trying to change my opinion of his actual design with increasingly hypothetical, impractical designs that he did not use. I'm not really interested any more.
Hello, Modder, hacker, and general programming goof ball here. I like "undefined" behavior, memory "issues" , and fine control over memory that rust seems to "protect" against. Is there a place for me in Rust, because I've avoided it for the lack of fine control.
Since I cannot sticky other's comments, I'm replying to mark the end of this AmA. Thanks Jon for answering our questions and being generally awesome!
Jon asked me to post a notice that this AmA is now finished.
Can't be done outside of std because the internal representation (wtf8) isn't exposed. AIUI, there is an effort to being more string oriented methods to OS strings, which should help here.
I don't have one planned in the immediate future, but probably at some point! _Using_ `async`/`await` also isn't terribly interesting from a technical standpoint, so it would have to be combined with some other large project.
Great, that's what I wanted!
My sign-off is [over here](https://www.reddit.com/r/rust/comments/c71f03/im_a_phd_student_building_a_fast_research/esctu09?utm_source=share&amp;utm_medium=web2x). Thank you all for the excellent questions — it's been fun! I'll still check back periodically to answer any last-minute questions that come trickling in, or you can ping me on Twitter :)
What do you know about my release testing?
Oh, and I'd love to see more resource for intermediate/advanced Rust developers. The nomicon is excellent, as is the still-developing compiler internals documentation, but I think we need more content that focuses on the nitty-gritty of developing large, complex, "real" applications in Rust.
Then they fix it and make it work.
Hello! I don't think you actually like undefined behavior or memory issues, but I totally see the desire to have control over low-level primitives. Rust absolutely gives you that, and most of the time you won't have to take any of the guard rails off to do so. You also always have the option of writing unsafe code, which effectively leaves you with C-style guarantees (so not very many). I've found that, in general, I need `unsafe` only very very rarely, and less so over time as the standard library develops. I would highly recommend the [nomicon](https://doc.rust-lang.org/nomicon/) if that's the sort of stuff you enjoy :)
Absolutely. :)
On IRC, still discussing where to go. Both the embedded WG and the libs team are considering waiting for Mozilla to pick a new venue before making a decision, IIRC. (This may have changed since i last checked)
&gt; Much like epoll, timeouts will require a syscall, sleep in this case. If you want everything happening on the same thread, you may need something like timerfd instead of sleep. That way you can pass the timerfd into epoll the same as the socket fds, and avoid the issue of “what if new data comes in while you’re sleeping”.
As if it's always that clear cut and simple. Either you are clueless about the real world or being dishonest to make your point.
&gt;it was still kind of up in the air which chat platform would be the "official" place to go to chat about Rust Are you asking about an official venue to chat about Rust-related things that aren't related to getting rust team work done? The official rust discord has a couple channels for this, and users.rust-lang.org exists. In the context of getting rust team work done, there are multiple venues: Zulip, Discord, some Telegram, and some IRC (the teams on IRC are trying to find a new place but i don't think they have yet, it may still be IRC on a different network) Unofficially, there's the community discord and ##rust on Freenode, both pretty decent.
I usually have three tabs open in my terminal: One where I do all my compiling and git shenanigans and everything else. (E.g. `cargo fmt --all`, gdb, ect) One with nvim + supertab (for the autocomplete) + rust.vim (for the syntax highlighting) for my main editing. (https://github.com/ZeGentzy/dotfile/blob/master/.config/nvim/init.vim) One where I use my small tool `stnvim` to grep the code for certain stuff. (https://github.com/ZeGentzy/dotfile/blob/master/utils/stnvim). All it does is grep for some code using ag then open the files in nvim. It's the poor man's cross-file goto and symbol search.
Yes, on most cases it is that clear. Let me guess, you don't have decent code coverage and end to end tests? Because I do and all of dependencies updated in nearly full auto. I see absolutely no point in tracking older version of complier just because I know all the bugs in it. Case and point: I tried to upgrade infrastructure from terraform .11 to .12 because I need features only available in new one. I tried, it failed because not all providers are compatible with new version. I found issues about them, followed them and waited until it's done. Another case and point: Netflix runs head/current FreeBSD and nginx.
awesome, haven't used or heard of [timer fds](https://linux.die.net/man/2/timerfd_create) before now. Just read through that and that would work out really nicely.
fantastic, thank you for this information. And you're right. I don't literally like undefined behavior, but I do leverage some functions that leaves \_consistent\_ "undefined" behavior when there's no good solution to the information I've given the function (that is to say I leverage low-level primitives written by somebody else) . It helps me better understand the files I'm working with.
The publication has a very snarky/irreverent editorial voice
Considering Riot is a nice web client, the whole point of the federated server architecture is message persistence and notification, you can one click start new rooms user to user or in groups that behave like threads, and [there is a huge guide on moderating Matrix rooms](https://matrix.org/docs/guides/moderation) sounds like it has everything you want and more and you just never gave it a chance.
First option it is
Changelog: [https://github.com/amethyst/laminar/releases/tag/0.3.0](https://github.com/amethyst/laminar/releases/tag/0.3.0)
I'm a former competitor from the [IOI][1], so I really know my data structures and when to use them. I too rarely need anything more complicated than a vector and map/set, because most tasks are solvable using those. It's not that you're constantly missing opportunities for using the data structures, it's just that they're rare. Of course, that doesn't mean they never happen. Two weeks ago I needed to find the closest point (only x-coordinate) to the cursor from some collection of points, and while I used binary search on a sorted list to solve it, this was a reasonable place to use a BST. [1]: https://ioinformatics.org/
Okay
M.2 drive with fast read and write speed. makes a big diffence
Cross-posting this from the forum. This tool is starting to get fairly mature and more people will see it here. Hope you like it. But if not, that's cool tool.
I think it depends on what your use case is. Fixed size vectors/matrices are a must for video game programming.
Ungoogleable technologies award, The winner of 2019
Sup smart dude
OP says he wants NVMe...
That makes a lot of sense. My use case is scientific comp, and I hadn't thought about it that way.
Doesn't really matter after first compilation if he has enough RAM.
Hi Jon, I don't have a question but I really wanted to have the opportunity to thank you for all the youtube videos and the massive work on github you've been contributing. You're a true researcher. Thank you for everything.
You realize that "it works on my machine" isn't any more valid for development/deployment methodologies than it is for bug reports, right?
Where did I say "works on my machine"? It works on CI automation with extensive suite of tests. I don't get why everyone is so against updating their dependencies. Not everything is NPM shitshow.
The embedded team seems to [be moving to](https://github.com/rust-embedded/wg/issues/362) [\#rust-embedded:matrix.org](https://riot.im/app/#/room/#rust-embedded:matrix.org).
If you find a bug here or there in prod after upgrading some software, then that's fine. However, if it "wrecks your production servers", then there's clearly a flaw in your process. Nothing should ever be getting "wrecked" in prod. That's a clear indication that something is missing in your lifecycle. Now it's entirely possible that I misunderstood what you said. But that's my initial reaction after reading your comments.
My point is that you are saying "it works for me" as though that means that it will work for everyone else.
I didn't say it wrecked *my* production servers; I don't actually know the details of why `npm` was being upgraded on production servers without prior testing. It's just an example of an ecosystem where upgrades can be detrimental and, at best, a waste of time and resources. (Even testing the upgrade would have broken whatever machine was used to test it.)
I've used both (C# extensively), and if these are your choices for learning to program in general vs just learning a new language, absolutely C#. Rust is phenomenal and makes me never want to touch C# again, but it is very much not My First Language material unless you're a glutton for pain. C# is much gentler introduction to software dev! Then you can progress to Rust down the road once the basics are clear.
Better yet, you can maintain a data structure (like a heap or a hashed timer wheel) to keep track of the timer scheduled to expire soonest, and just pass that as the timeout to `epoll_wait`.
Ah, right, I forgot about that issue! :)
To be fair, while the moderation infrastructure has been there approximately from the start that moderation guide is quite recent. Indeed, it was written as a direct response to a previous discussion on this Reddit about IRC alternatives where one of the questions about the suitability of Matrix was that there was no documentation about moderation tools 😀
Cool project! This is a great way to learn, and teach, about how the system works. Instead of implementing `TryStream`, you should implement `Stream` with `type Item = Result&lt;T, E&gt;&gt;`. This will automatically become a `TryStream` as well through the blanket impl, and be more composable.
That's not what I said at all.
Sweet! thx for the answer! My first language is Python and Javascript being my second one, I will learn C# and after that Rust.
Why the x570 specifically? Are the x470 / b450 limited in core count for Ryzen 3000 or anything else? Besides PCIe 4 and thus faster m.2 drives I can't think of any advantages a x570 would bring in that usecase - I may of course overlook something, that's why I am asking.
You described your personal experience. I am telling you that this doesn't mean it applies universally.
I'm trying to learn Rust for use with embedded but couldn't get any vecmath crate to compile with no_std. So, I'm trying to implement some simple matrix/vector functions myself, I've got these two implementations of add/sub to work but the first looks and probably performs terrible and the other feel very "non-rust" and just emulating what I would've written in C. Any tips? Also, is there any way to avoid having to initialize the Matrix4.members before filling them? ``` use core::ops::{Add, Sub, Mul}; use num::Num; pub struct Matrix4&lt;T: Num&gt; { members: [T; 16] } impl&lt;T: Num&gt; Matrix4&lt;T&gt; { pub fn new(members: [T; 16]) -&gt; Matrix4&lt;T&gt;{ Matrix4 {members} } } impl&lt;T: Num + Copy + Default&gt; Add for Matrix4&lt;T&gt; { type Output = Matrix4&lt;T&gt;; fn add(self, other: Matrix4&lt;T&gt;) -&gt; Matrix4&lt;T&gt; { let mut mat = Matrix4::&lt;T&gt;{members: [T::default(); 16]}; for (x,(a, b)) in self.members.iter().zip(other.members.iter()).enumerate() { mat.members[x] = *a + *b; } mat } } impl&lt;T: Num + Copy + Default&gt; Sub for Matrix4&lt;T&gt; { type Output = Matrix4&lt;T&gt;; fn sub(self, other: Matrix4&lt;T&gt;) -&gt; Matrix4&lt;T&gt; { let mut mat = Matrix4::&lt;T&gt;{members: [T::default(); 16]}; for x in 0..self.members.len() { mat.members[x] = self.members[x] - other.members[x]; } mat } } ```
[Learn Rust with entirely too many linked lists](https://rust-unofficial.github.io/too-many-lists/) is a great intermediate-level resource.
Very cool, thanks for taking the time!
If you're already somewhat comfy, you could skip straight to Rust! I still think you'll have a much gentler time if you pit stop at C# first though. I've been watching someone attempting to teach Rust to JS devs for the last few weeks and it's a huge struggle. C# imo is extremely friendly, so you can pick it up really fast with prior experience, and will introduce some concepts new to python/JS devs that will help make Rust much clearer in why it does things the way it does later
do you think Rust will ever support vr? seems to be a fun game.
/r/playrust
ok i admit i kinda trolled ;-)
/r/playrust
&gt; As I understand, rust_swig requires you build the wrapper for jobject arrays like this yourself In fact no. I suppose you have something like: foreigner_class!( class Gamepad { self_type Gamepad; constructor Gamepad::new() -&gt; Rc&lt;RefCell&lt;Gamepad&gt;&gt;; } ); Then you try foreigner_class!( class Gilrs { self_type Gilrs; ///Creates new Gilrs with default settings. constructor new_gilrs() -&gt; Result&lt;Gilrs, String&gt;; method girls_gamepads(&amp;self) -&gt; Vec&lt;Gamepad&gt;; and rust_swig reports that it have no idea how convert Vec&lt;Gamepad&gt; to Java? This is because of Gamepad Java object is corresponding to `Rc&lt;RefCell&lt;Gamepad&gt;&gt;` not to `Gamepad`. So to return Vec of Gamepad you need: fn gilrs_gamepads_java(gilrs: &amp;Gilrs) -&gt; Vec&lt;Rc&lt;RefCell&lt;Gamepad&gt;&gt;&gt; { gilrs_gamepads(gilrs) .into_iter() .map(|x| Rc::new(RefCell::new(x))) .collect() } foreigner_class!( class Gilrs { self_type Gilrs; constructor new_gilrs() -&gt; Result&lt;Gilrs, String&gt;; method gilrs_gamepads_java(&amp;self) -&gt; Vec&lt;Rc&lt;RefCell&lt;Gamepad&gt;&gt;&gt;; alias gamepads; }); and rust_swig automatically generates java method that return `Gamepad []`
Wow! I'm only just starting a computer science degree at age 30 and feel like I'm way too old to do cool research in the future. Are there researchers and PhD students in your cohort who are older? How did you discover your interest in Rust libraries and databases? Was it at a previous job or in your own time? I only just started learning to code last November and feel so far behind...
Out of curiosity, what work are you trying to complete before a 1.0 release? I may have free time this summer to help out if you're interested.
If the function takes Into&lt;String&gt; it will clone the string internally anyway.
:) unfortunately there are... way too many legitimately confused posters here, both in this thread and in the subreddit, everyday.
&gt; For me personally, I'd really like to see a high-level asynchronous SSH crate. Not sure if it suits your needs, but have you seen [`thrussh`](https://docs.rs/thrussh/0.21.3/thrussh/)?
&gt; I do leverage some functions that leaves _consistent_ "undefined" behavior At that point, wouldn't it be better to write a function with defined behaviour that matches the expected undefined behaviour to make sure that the compiler won't break it on a different version?
There is a huge difference between "I have many tests that allow me track latest versions of 3rd party dependencies" and "It works on my machine". Still, I haven't see any reason to no update local rustc to latest stable version. I saw reason why someone can't do it it - linux binary packages always behind upstream.
The biggest advantages are the improved chipset, better VRMs, and higher quality boards. Vendors are taking AMD more seriously so they are getting serious with Zen 2, with server-grade PCBs and true 16 phase VRMs. The older boards may work, but I wouldn't trust x470 above the 8c/16t chips.
Turns out, it was instead because gamepad required a lifetime!! Wow, that was a lot of unnecessary head-scratching. Thank you so much for the reply as always davemilter!
How much student debt will you have? How do you plan on handling that?
No interest in Matrix?
As mentioned below, apparently the embedded WG is going to use it, but the other groups didn’t find it suitable.
I take it back, after a little bit of testing I didn't fix the problem. I can't write constructor Gamepad::new() -&gt; Rc&lt;RefCell&lt;Gamepad&gt;&gt;; because these are generated by the library, and accessed by a list. https://docs.rs/gilrs/0.7.1/gilrs/struct.Gilrs.html#method.gamepad So without this line, what I get from applying the above code is essentially this: Do not know conversion from such rust type 'Vec&lt;Rc&lt;RefCell&lt;Gamepad&gt;&gt;&gt;' to foreign Any thoughts /u/davemilter ?
Awesome, looks like a cool little project!
Yes, but that's not always necessary. For example if I want to just output bytes that I usually wouldn't have access to there are plenty of functions that have undefined behavior, but aren't destructive. They're undefined in that they can't be sure what they're going to output, and that's the point.
I realize you were not literally talking about a single machine. My point was that both statements fail for analogous reasons.
Some people have compiled to old 8 bit targets (perhaps including z80) using mrustc. Mrustc is an alternate compiler (with limitations) that compiles to C. Don't expect it to be particularly efficient or reliable, but it should be fine for just messing around for fun. It's not something I have experience with though. I wouldn't be particularly optimistic about the likelihood of a good llvm port, given there isn't even a gcc backend. I've heard z80 isn't good for targeting with modern compiler designs; it's from an era when people wrote in assembly (I'm not really an expert, but I think I've heard register assignment mentioned as an issue).
Why do you want to get a PhD?
What do you think about open access publishing?
It would be nice, if mmstick's Parallel was renamed, so it could be installed next to GNU Parallel. This way you could use mmstick's Parallel for tasks where speed is important, and GNU Parallel for more advanced tasks.
Your name sounds kind of Norwegian. Where are you from?
You can get away with smaller annotations: ``` let f2 = |&amp;x: &amp;_| x; let f3 = |&amp;x: &amp;_| x; ``` The problem is that it's inferring `|&amp;x| x` as being bound for some concrete lifetime instead of what it should be (`for&lt;'a&gt; Fn(&amp;'a u32) -&gt; u32`) - I think [this](https://github.com/rust-lang/rust/issues/41078) is the current open issue about this. For now, the fix is to annotate the reference.
&gt; so it's unclear which part of the improvement comes Rust and which comes from the algorithm/data. I don't think it's really meant to suggest Rust is faster than the same would be written in C++ (which the article mentions, the previous design was using). I expect the same could be achieved in C++. But Rust potentially provides a more ergonomic way to develop such a thing, while providing better safety by checking invariant at compile time. Of course, unlike the performance difference, these aspects aren't easy to measure numerically.
Perfect thanks!
reqwest also has an async client where the body implements the futures::stream::Stream trait. But using the sync client is a lot easier. It's only useful when you want to download multiple files in parallel.
/r/playrust
Oh shit! my bad
&gt; I was under the illusion that Web assembly is replacing JS. See "Is WebAssembly trying to replace JavaScript?" on https://webassembly.org/docs/faq/ I'd be interested to see WASM as a good replacement for JavaScript completely. But at least for now, that's not the primary aim. Future features might make that viable.
That's what `async-ssh` is built on top of :) We used a much older version though, and I know it's changed quite a bit. I wanted a higher level interface than what `thrussh` was providing, and I don't think that's changed though.
rust_swig is just preprocessor, it is not as smart as compiler. In particular as I remember type defined as `Foo&lt;'_&gt;` should be used as `Foo&lt;'_&gt;` everywhere inside macros. So if you define some type as `Rc&lt;RefCell&lt;Gamepad&lt;'_&gt;&gt;` then you should write `Vec&lt;Rc&lt;RefCell&lt;Gamepad&lt;'_&gt;&gt;&gt;&gt;`. But this is just guess about problem. Can you share code that gives you error?
Never too old to start something new as long as you're excited about it! There are a few, though admittedly not many. Most of them come in straight from their Bachelor's in the US, and so they're younger than me (I'm 29) since I took a Master's before I joined. I think it's hard to nail down exactly why I ended up with the project I'm on. I think it partially arose from seeing a problem in a space where I'd spent some time (web development), and partially from fiddling a lot with networked key value stores and wanting to push that further. Rust was because it looked interesting to me at the time, and I figured what better way to learn than jumping into a project with it!
The Norwegian government has a great student funding program. They basically fully funded my studies up to and including my Master's, with a decent chunk of that loan being converted to a scholarship upon graduation. The loan itself is very low interest, and only needs to be paid down as long as you are employed. You can look up the Norwegian State Education Loan Fund if you're interested. My studies at MIT are funded through research and teaching assistantships, so I'm basically now paid for my studies :) And I've gotten to teach classes at MIT for it, so a pretty decent deal as far as being a student goes!
i hope you have a lovely day stranger
My motivation was simple: I wanted more room to explore and learn many different things, and to dive deep into technical challenges without worrying too much about why. And a PhD is perfect for that. It's not what I'll want to do forever, but at the time it was right.
I think every single paper should be open access, and I think it's a disgrace that this is not the norm. All my papers are available through my website :)
I don't think that's how undefined behavior works? If the compiler determines that you have undefined behavior in your code, it is allowed to do pretty much anything to your program. Do you mean non-deterministic behavior?
I'm Norwegian indeed. From Oslo :)
What is the difference between a research database and an RDBMS?
With x470 you will still need to do a uefi update to get the cpu to work
You're probably looking for /r/PlayRust . This subreddit is for the programming language of the same name.
Oh sorry
I too have fond memories of my TI-85. But a Z80 is so deeply obsolete that you're very unlikely to enjoy working with it. If you want to play with small machines, go hit up Adafruit or Sparkfun or something and find a nice modern microcontroller dev board for $20.
Thread-per-packet rather than thread-per-client is interesting, can you expand on the use case?
This is just for learning, but this is for a MMO game I'm building using Rust in the backend and Unity C# in the frontend. I'm actually considering using Redis to store a FIFO-queue of packets and a single thread popping and processing the packets. I could have as many threads reading as possible. &amp;#x200B; I think Java Tomcat uses the thread-per-request model. If the same client sends 2 requests, you probably will have two different threads, but Java threads are not exactly threads. I think I tried to replicate that unconsciously.
This is the subreddit for the Rust programming language. I believe you're looking for /r/playrust
ty sorry
So similar to this with `sem`: id=$(mktemp) rm $id for img in dir/*.png; do for s in 32 64 128 256; do sem --id $id -j100% convert "$img" -resize=${s}x${s} "${img%.png}-${s}.png}" done done sem --id $id --wait
&gt; download this sometime next week Haaaaa. Sorry for the delay on this, it turns out moving halfway across the US and starting a new job takes a little more out of you than I thought it would. After misunderstanding (or typoing, not sure which) this command for a half hour and dumping links all over my project directories, I have to say it seems to work pretty well. For my exact use case, I'm not sure that it's any more efficient than just writing scripts to spam `ln -s`, but I think it does what it does quite well, and I'll definitely keep this in mind for the next time someone asks me for a tool recommendation. I'm not experienced enough with Rust to make any recommendations about the source (and the way things are going, I won't be for a looooong time), but I found the text in the xstow comparison a little confusing: right at the top, you define the ideas of "data" and "farm", and then you start talking about "packages" in the xstow comparison without saying what those are. Aside from that, I rather like the README--I didn't really understand everything in the implementation section, but it seems clearly-written enough that I could figure it out if I had a few hours to read/play with the source.
I appreciate you're time. Whatever you call the rose, I mess around with memory at my convenience. ¯\\\_(ツ)\_/¯
Most operating systems, Linux included, can run large numbers of threads on even a single core. "Threads per core" is the number of threads that can be executing at the same instant, but the OS will still rapidly switch between active threads to make progress on them all. This is why you can run more than N programs on an N-core system. Rust isn't doing anything special.
Emacs, no RLS
To make a crate work with `no_std`, you have to make it this way. So in theory I don't see anything preventing this addition to the crate but someone would have to do the work. You can always make an issue and open the discussion. If you are going to use iterators I think I'd go all the way: for ((z, x), y) in z.iter_mut().zip(x.iter()).zip(y.iter()) { *z = *x + *y; } Iterators should compile down to very efficient code (sometimes more than loop + indexing). &gt; the other feel very "non-rust" and just emulating what I would've written in C I wouldn't stress too much about it. Go with what feels natural, make a little project and ask for reviews, if things are a little "too C like" people will orient you to more Rusty solutions. Of course I'm not saying to have raw pointer everywhere and use unsafe to try to sidestep every compilation error, but sometimes Rust and C will solve a problem the same way. For example I think the second version if easier to understand than the first one. Since you take `self` by value, you can use it to remove the `mat` variable altogether. I kept the two versions, feel free to choose =) fn add(mut self, other: Matrix4&lt;T&gt;) -&gt; Matrix4&lt;T&gt; { for (x, y) in self.members.iter_mut().zip(other.members.iter()) { *x = *x + *y; } self } fn sub(mut self, other: Matrix4&lt;T&gt;) -&gt; Matrix4&lt;T&gt; { for x in 0..self.members.len() { self.members[x] = self.members[x] + other.members[x]; } self } It's still possible to avoid the initialization even if you can't use `self` but the solution is less elegant and llvm should optimize it out anyway. Just a side note, you can make `Matrix` a tuple struct.
Interesting, I didn't know this was done on the OS level. Thank you =)
Cute.
Looks like we’ve got some good responses here already, but as I understand it `tracing` has a well-defined model for establishing context and causality that’s useful for making sense of logical operations that span tasks, processes, machines. That same model can be represented with just structured events, but you could exploit the relationship between span contexts and events explicitly with tracing. `tracing` itself appears to try very hard not to make decisions on your behalf that would affect the runtime performance of whatever usecase you have. So in my opinion there’s probably more technical work needed to really get the most out of it, but if you’re building some low-level network services or a web framework then it’s probably worth owning that work. For cases where you want tracing but don’t want to build too much yourself I would expect higher-level frameworks to evolve around it. It’s still very fresh.
How can I specify a conversion from one generic of a type to another? pub enum Foo&lt;R&gt; {/*...*/} impl&lt;F, R&gt; From&lt;Output&lt;F&gt;&gt; for Output&lt;R&gt; {/*...*/} This doesn't work because: conflicting implementations of trait `std::convert::From&lt;parser2::types::Output&lt;_&gt;&gt;` for type `parser2::types::Output&lt;_&gt;`: note: conflicting implementation in crate `core`: - impl&lt;T&gt; std::convert::From&lt;T&gt; for T; rustc(E0119) I see why this error happens (the possibility of ` F == R`), but is there a workaround? E.g. a way to specify `F != R`, or to disable the the core implementation?
Is the Rust compiler ever going to be near real time?
I'm a remote American on a Chinese team, but I only have about six months of experience. It's isolating. Most of the informal communication that shapes the project happens without me, in Chinese. Much of the internal communications is in Chinese. Videoconferencing is super hard across cultures. I've seen so many discussions end in a shrug of non-understanding. Who knows what the outcome is. Maybe somebody will do something about whatever the topic was. Probably not. It's hard to collaborate with people in other languages and time zones, and the people who speak the same language and are awake at the same time end up in the same discussions and projects. I'm probably more active in the Chinese Rust community than the Western Rust community, and it's striking how separated they are. It makes me wonder what the other non-English communities are like and to what degrees they are integrated into the "main" Rust community. I wish the Rust team and Western Rust community was better at supporting non-English Rust communities, the Chinese community in particular. How I don't know.
&gt; I wish the Rust team and Western Rust community was better at supporting non-English Rust communities, the Chinese community in particular. How I don't know. Not really anything they can do about that. None of those problems are specific to Rust, have anything to do with it. Not really anything to "support", except maybe the ability to type non-English characters at all, and the web and major chat platforms are already unicode. They're inherent in the fact that different languages exist, and even that different places(and therefore timezones) exist. Not really anything anyone can do about that, short of moving everyone to the same area and having them use the same language. An organization might be able to mitigate such things by having like a minimum 2 day turnaround on decisions to give other timezones a chance for input, and translators, but thats not very practical or efficient.
Favourite condiment? Thank you
Splitting the chat between discord and zulip is so confusing. I don't see zulip mentioned on the website. &amp;#x200B; One might unfavorably think the teams on zulip are trying to hide from the rest of the community.
Many retailers have an option to do that for you, if they don't i expect AMD to offer a "boot kit" for Ryzen 3000 like they did with Ryzen 2000. For most of the B450 boards from MSI – which i intend to purchase – there is a flashback option. With that you can update the uefi without a CPU/RAM/GPU installed. Just a USB stick with the appropriate files and the connected and powered PSU.
Hey, what would be really nice to have would be an automatic reset of the clipboard, as a flag to the tool. Something like 'cbs -c 'MyContent' --seconds 30 For context: i wrote a simple 'pass' like password manager. But when piping the output to xclip it stays there forever until a given 'paste count' has been reached. Other clipboards have a timing limit or no limit at all. Since you already have a daemon in the background i imagine it would not be too hard to implement?
I agree on the VRMs and the core count. For that i think we have to wait for real tests and temperatures. I heard that Asus has really high temperatures. I am targeting a Ryzen 5 3600X — 6C/12T or Ryzen 7 3700X—8C/16T for my next build but i need to see benchmarks. But for my case i don't think a x570 is the right choice. We'll have to see when the first tests arrive.
For sure! There are roughly 100 examples on the ohayo.computer beta that do data science tasks. There are 20 examples in the grammar sandbox on Tree Notation and probably 100 or so samples in the jtree GitHub repo. The data flow language on Ohayo does things you’d typically do in R or Python. The grammar language in jtree does what’d you do with antler or xtend. The project language is similar to make. The stamp language is for distributing folders in plain text. The hakon and stump languages compile to css and html, respectively. The fire language is a GPL but not quite useful yet. That’s a sampling....it’s very early, and I would love to help anyone build a new language. I’m currently helping a few individuals and companies construct new ones, in addition to working on jtree, ohayo, and my genomics work at the office.
r/rustjerk
I wonder if we could create a less completely-memes off-topic rust subreddit...
I think there's probably a bunch of small, practical things we could do to help non-english speakers. To start, we could think about adding internationalization support to things like crates.io, including the ability for crates that choose to supply READMEs and documentation in multiple languages. Obviously most small crates won't do that, but some larger foundational crates might.
You probably want your function to be generic over `T`, where `T` implements one of the traits like `cdrs::query::QueryExecutor`.
ndarray has a runtime multi-dimensional array [here](https://docs.rs/ndarray/0.12.1/ndarray/type.ArrayD.html). Dynamic arrays implement nearly all of the Array methods. You can also use `.into_dyn()` to convert fixed dimension arrays to dynamic arrays.
Getting some tracing support back into `log` would be great to explore! It now has very simple (and not very useful yet) structured logging support based on key-value pairs so I’ve been thinking about how we could build conventions around common parameters like trace ids, timestamps, errors, backtraces etc that may move from key-value pairs to first-class fields on the record.
Oh, I missed that. Thanks!
While it is surely possible with hacks¹ to get that out of `cargo build`, the command was not designed for this. Managing rust toolchains for different platforms is usually done using rustup. What most people do for open source projects is this: Set up a CI system that compiled your code (and runs the tests) on multiple platforms. When you push a tag it will then upload the compiled binaries to e g. a GitHub release on your repo. ¹ a `build.rs` that itself call cargo and possibly rustup a few times
Wow, I had no idea that there were CI bots that did this. Any recommendations? Thanks for the comment
Username checks out then :D Have some links: - https://docs.travis-ci.com/user/deployment/releases/ - https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/github-release?view=azure-devops
TravisCI is popular for open source projects. https://docs.travis-ci.com/user/languages/rust/ I think Travis support Windows by now. If not, you can supplement the CI pipeline with AppVeyor. Both TravisCI and AppVeyor can be set up to publish build artifacts (binaries) to your github page on each commit, or on git tags (releases).
Thanks for the link. I’m gonna use this!
Great! Appreciate it.
Do you want to log it or output it to stdout?
From my experience, different timezones can be used beneficially, through having more time to work on something and then presenting a result. Real time conferences are mostly ineffective anyway - nobody gets enough time to think about whatever properly and come up with a fulfilling response. Messengers are a good compromise between real time conf and long emails. As to languages, as long as everyone on the team speaks at least one common language, it should be fine. Because of cultural differences it will be harder to establish relaxed relationships, but not impossible.
I'm sorry for that misconception - i want to output it to stdout.
I have another question regarding lifetimes. I am receiving the error expected bound lifetime parameter, found concrete lifetime and I am at a loss. Here is the code in question: https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=bdcb8073ee311eaf3a7e9d55f94796a2 I reduced it to a minimum without throwing out the used types and the context, but it's still too big for me to pinpoint the solution. I suppose it comes from the type of `Token`, `&amp;'a str`, as when I refactor the code to use `String` instead, the issue seems to disappear. But that would come with a huge overhead, so I'd like to avoid having to do that. I tried specifying various lifetimes, but without knowing what to look for specifically, I'm just shooting in the dark. I'd like to know where the error is coming from, and what I can do to avoid it. I hope someone here can help me with that.
How fast do you want it to be? Do you want to do asynchronous writes? Also keep in mind that your utility’s performance will likely be capped by both system and the consumer of the output.
When I saw the title I thought this is just *another* r/playrust post. Oops