When you are abstracting common functionality between multiple structs is the way to go with interfaces. &amp;#x200B; A common example is the Reader/Writer interfaces in the standard library in Go. &amp;#x200B; Multiple structs implement them along the standard library
Sadly I won't be in Berlin in the next 6 months, I would have happily applied, as golang is my main and favorite language. 
I’m not sure. I haven’t tried that. It’s likely to work with well known port names tho. 
It's just informal slang. It's not wrong. Loosen up.
I haven’t used it specifically, but I’ve been passively following it. EDS is just a protocol. With kubernetes, you can use Istio pilot to watch kubernetes control messages and make decisions. Then, you use the EDS balancer config inside gRPC to connect to Istio Pilot. In your gRPC config, you would use grpc.WithBalancerName(“eds”). I don’t know how one configures it tho as I’ve never used it. I may take some time this afternoon and fiddle with it. 
You can definitely create complete projects without ever defining an interface.
It implies to me the minimum version of Go for the project, which defaults to the current version if not specified. Looks like it's just a way to convey more information about a build failure if someone tries to build something using Go 1.8 and it fails because it's using a stdlib feature added in 1.12
Even if it is a small project that isn't exposing library functions to others, you may naturally encounter a situation where you need an interface. You may want to create a slice of two different types. The only logical way to do that is to create a slice of a common interface between them (or a slice of interface{} which is less type safe) 
great article, i might try to reimplement it on my own now :)
If it ever worked, what you have there is not what you are executing, nor is that the output it would generate. `exec.Command(...)` returns an `*exec.Cmd` object, it doesn't execute anything, and it doesn't return an error. You don't want those quotes around the command. The code you have there, despite what the terminal output may look like, is actually the equivalent of running bash -c '"mv 2018MobileThreatLandscape-Appendix.pdf pdfs"' which is attempting to run an executable named `mv 2018...` (and so on), which doesn't exist. You'll want to go with something like this, at least for debugging: cmd := exec.Command("bash", "-c", "mv 2018MobileThreatLandscape-Appendix.pdf pdfs") cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr err = cmd.Run() if err != nil { log.Fatal(err) } The lines setting the Stdout and Stderr make it so the subcommand will emit errors to your terminal's Stdout and Stderr, which _really_ helps with debugging.
It’s very useful for mocking in unit tests. For example, if you have a struct that communicates with a database, instead of calling the database during your tests, you simple pass a “mock” version of the struct that fakes the responses. Reader/Writers are also great examples as they mean you don’t need to write a specific piece of code for every struct you’re interfacing with. The sort package is another great example. 
Yikes. 
okay, it makes sense, thanks for clarifying the issue ! :)
I also see places using a test database (gobuffalo iirc). Reader/Writer are really nice example but they're used everywhere so this justify their existence. sort seems to be the best example imo
&gt;The correct solution would be to compare string representations instead of raw values. Or, alternatively, the correct underlying value. It depends on what you're looking for from your error. If it's something you're consuming from another library, I wouldn't worry *too* much about string comparisons, but if you're testing the errors the local package is emitting (and... you *do* test those, right? They're part of your code's API too!), I'd recommend checking with a correctly-constructed value. If you have trouble getting DeepEqual to do the right thing in those circumstances, I'd consider that a Sign.
Not sure if intended to be rude, but it sure comes off that way. It was 5am, cut me some slack! :P
Well reader and writer aren’t just used to justify their existence. They’re used to make generic functions. Eg, a gzip writer. You open a file, open a gzip writer, and then pass the gzip writer to whatever needs a simple writer. Now you have a gzip file instead of a raw file without making a single change to the code that actually is generating the data. Same goes for encryption. And you can layer them as deep as you want. 
I thought this as well, however since modules only interact with Go 1.11+ wouldn't that imply that the minimum that would ever be set (as to be a useful addition to failure information) would be Go 1.11?
I’m just startled by the approach. Recompiling code just for a module? That seems insane to me. There’s no security at all. Would be better to sign a binary and load it as a module. Never load the module unless it has been signed, so do some runtime checks. 
What you really want here is a select over the slice of channels until all are sent. Since there's no syntax for a dynamic select, you have to do this: go func() { cases := make([]reflect.SelectCase, len(dataChannelSlices)) for i, ch := range dataChannelSlices { cases[i] = reflect.SelectCase{ Dir: reflect.SelectSend, Chan: reflect.ValueOf(ch), Send: reflect.ValueOf(data)} } remaining := len(cases) for remaining &gt; 0 { chosen, _, _ := reflect.Select(cases) cases[chosen].Chan = reflect.ValueOf(nil) } }() You can handle timeouts by implementing putting a time.After as a reflect.SelectDefault in cases. No more blocking forever.
Nah, you misunderstood. No modules here. I was looking at having multiple separate applications running, one of which is an updater. It checks a git repo, sees a change for another running application, pulls it, compiles it, starts it, and kills the old version.
You should probably look into docker. It’s designed for this kind of thing. It guarantees consistent builds. Then just fetch the new docker image and re-run it with the updated version. 
I am aware of docker, just never messed with it or any other form of containerization. Any recommendations for a quick start guide for getting one's hands dirty with it? Building images has always seemed intimidating and best left for another day, even though I imagine it absolutely isn't.
Try to look into Hasicorp Consul's and nomad's clustering. It may be an option for you. Maybe not
https://docs.docker.com/develop/develop-images/multistage-build/ I always prefer multi stage builds in docker. Golang is the perfect example for it too since go produces standalone binaries (libc if you link certain packages tho). Means you have a tiny docker image on alpine that takes less than a second to pull and start. Then there’s orchestration with kubernetes for large scale, but generally, a compose file is good. In your case, launch docker directly is probably what you want. 
Dope! Thanks for weighing in and pointing me in the right direction.
I guess an eventbus is equivalent of a broker. 
Interesting :) Do you know also how to run multiple golang apps with a single port, like a proxy? I heard about caddy, but I don't know if it's the right thing.
If you really need to use plugins, then why not use the [hashicorp gRPC based plugin, mentioned in the linked thread?](https://www.reddit.com/r/golang/comments/acx5cm/request_to_the_golang_developers/edc940a)
It's for that kind of change, but in the future. Say Go 1.15 adds something you want to use, so you set it to 1.15, and then older versions of Go will be able to report that if you try to build the project with them. It isn't particularly useful _now_, but it's forward thinking.
If you’re looking a something self contained you want to look a serf and raft (again by Hashicorp). These tools/packages are used by larger systems like Consul. https://www.serf.io/
Downvoted for asking someone to think about the problem for a minute...
Yes, but you have to add it *now* for it to be useful in the future. 
On another note. Why not make a `type topic string`. Would make the map easier to read. 
What's not mentioned is that they are also useful for data hiding. You can define an interface that other parts of the system depends on, and that can *only* access the functionality in the interface, and not the actual implementation details it depends on. For example, you might have an interface to load users from a data store. The struct that implements it could also implement an interface for creating users, but that's hidden if the client code only depends on the first interface.
That is cool, I think i will build a package that will manage the clustering part and it has a multiple drivers and serif can be one of them
I generally write functions to rely on functionality. For example, let’s say I want to make a function that... reads a value from a cookie in an HTTP request. Rather than accept the argument to an actual `*http.Request`, I create an interface like this: ```go type Cookier interface { Cookie(name string) (*http.Cookie, error) } ``` Then my function looks like: ```go function cookieValue(cookier Cookier, name string) (string, error) { c, err := cookier.Cookie(name) // ... elided for brevity } ``` Then I can pass it an `*http.Request` and everything works as expected. This method allows me to easily isolate the functionality I actually care about and leave the rest behind, creating a nice and easily testable unit of code that is flexible in the future. I highly, highly recommend this approach. 
Thank you for the info. I believe the way forward for me initially, is to generate JAXRS/Java Rest API microservices, at least for the public facing API. I would approach it as API first design, using RAML or OpenAPI to define the APIs and generate server stubs and payload objects. I know this well, and it would allow me to quickly iterate on API design on a per domain/service. The question then is, can I add gRPC server internal and use protobuf from the JAXRS API java code to golang back end service code (and vice versa). I like this idea, if it makes sense in terms of eventual scale and maintenance capabilities. My one concern would be maintaining two data formats for one "service" per se.. e.g. JSON Schema (or RAML 1 Types) for the Rest API Req/Resp payloads, and a similar but not quite identical protobuf file for the objects between the service tiers using gRPC. I really dont think it is a lot of work. It is not like I would be rewriting an existing application with 1000 endpoints or something. This would be done one or two at a time.. as I either build a new service, or migrate an old service to this new way of building the application. Once the protobuf is done, it should be fairly locked down.. e.g. bug fixes or new versions, not a continually changing file, especially if the API/JSON bit is pretty well thought out, then the protobuf is more or less very similar to that. If that changes, so does the protobuf at the same time. In fact, I would most likely keep the files in the same directory with the same naming so as to modify them together. Which does beg a question. Since protobuf would be the binary format going between multiple services (at least two.. API to back end), I assume the generated code from the protobuf would need to be put in some sort of package/library that can be shared between the two (or more) services. What is the way this is usually done in Go? Like.. in my Java days, with monolithic apps, we typically have a "shared" folder with code that is used between two or more modules of code.. though in Java since it all runs in one JVM it is usually just importing of the classes and making method/class calls. Back in the day with separate servlet and EJB servers, we had to bundle up the objects on both sides so the serialization/deserializaton worked on both sides. I assume something similar is done with golang and grpc? 
So, for example, if a project currently supports go 1.10+ this value should be \`go 1.10\` when the module is initialized?
gO iS a SiMplE lAnGuAgE
Never mind it doesn't work for me. It asks for the srv but then doesn't know how to handle `namedPort`. After some digging I found out that grpc reads `_grpclb._tcp.KubernetesService` more or less correctly but then does not use it and rather uses the `KubernetesService` resolved + a `defaultPort` if you do not give any port, which is `443` or `80`. If you give `namedPort`: `unknown port`. Looking up srv record seems like it doesn't do anything to me.
Yeah, you'd have have to use some kind of proxy. Caddy is a decent option. There are things like HA Proxy too, etc. For personal stuff I've not got enough on the go to have more than one app on a single server right now, so I've just not had that issue. I usually just stick things behind Cloudflare to let them take care of the webserver configuration stuff. It keeps things nice and simple, and also easy to destroy later on. At work, we currently use a mixture of Elasticbeanstalk (so, we have an AWS Elastic Load Balancer (ELB) for each application in that case), and Kubernetes running Istio, so there it's an ELB per Istio Ingress Gateway. As far as I'm aware, the Istio Ingress Gateway at it's core is an Envoy proxy. Envoy is a very, _very_ flexibly proxy, and Istio makes extensive use of it for many components. So there are a few different ways of doing things, there's no right answer, it's all situational. For something simple, if you want to stick to one machine, Caddy would be a good option, it covers a lot of bases, is simple to configure and run, and is performant too.
Well, no, since Go 1.10 doesn't even support modules. It should be whatever version of Go you're currently using when you start the project, unless you have a good reason to set it to an older version (and actually test it on that version with CI!). No real need to ever change it to a newer version unless and until you do something that is only supported by a newer version.
The Go tooling from 1.12 onward will set the version to the current one when you do `go mod init`, if that's what you mean, but you can always edit it by hand to whatever you feel is appropriate. The tooling isn't going to go through your code and determine the minimum version that's possible to select.
\`create-react-app\` and a minimal css framework that is easy to branch out from and add to.
I made a funky event bus a while back that handled event subscription and unsubscription as events themselves. I thought it was a pretty cool idea: https://github.com/erinpentecost/deterbus
I made a funky event bus a while back that handled event subscription and unsubscription as events themselves. I thought it was a pretty cool idea: https://github.com/erinpentecost/deterbus
Never mind that doesn't work.
I've wanted to do this as well and I think the best way (not tried yet) would be to do it with plugins that can be dynamically loaded at runtime. Start the app, read the config, load the specified plugins, and you're good to go.
how does one create a read-only backend with pgBouncer. This is a little late, but I am pretty interested in this because I though only pgpool2 could do this, and that pgbouncer couldn't.
Options include: \- a codegen tool, like you mention. This would kind of follow the [Goa](https://github.com/goadesign/goa) model, and you'd probably want to add in some parsing to make sure your output would actually compile \- compile everything in and either use reflection or a plugin map. :-\\ \- [pkg/plugin](https://golang.org/pkg/plugin/), which won't work everywhere and can't be unloaded \- RPC over a local socket like [go-plugin](https://github.com/hashicorp/go-plugin)
The problem with this article, and your title is that neither state that panics should be rarely, if ever, used. They are for truly exceptional things only. DO NOT use them for error handling or exception handling like you would in C++ or Java. To be clear, through the dozens of services I and my teams have written, there are only a handful of times Panic was ever used.
is this for performance or availability? You really should consider a Layer 7 load balancer &amp;#x200B;
Welcome to Reddit!
Check out Authelia https://github.com/clems4ever/authelia . You can hide your services behind a reverse proxy that manages all the authentication and authorization for you.
Is it the same bitcask implementation as Riak had or is it different? 
I think channels are really unnecessary here. What's the benefit of using them over a callback model? ``` Publish(topic, data) Subscribe(topic, callback) ``` With channels if you have issues, it's a lot more complex to debug. You remove a lot of the complexity around blocking, goroutines and channels by avoiding them.
The current documentation of this feature doesn’t make it easy to answer this question. I’ve filed [issue 30791](https://golang.org/issue/30791) about resolving that. I’ll quote a part of Ian Lance Taylor’s (who created this directive) reply from there: &gt; The basic guideline is fairly simple: a "go" directive 1.N means that the code in that module is permitted to use language features that existed in 1.N even if those features were removed in later releases of the language. So setting it to the current version of Go (i.e., 1.12 at this time) should be a good strategy to use. The value will make observable difference only when some future Go language version deprecates and removes some language feature.
Yes :)
I recommend dropping the filename semantic and reading from STDIN as the gods of unix intended. 😎
yes, thanks [justinisrael](https://www.reddit.com/user/justinisrael) ,as you said that project could have benefited from your time and gained transaction support in its front-end. It is easy to build another ledisdb yourself based on nutsdb.
I don't know, I have never really felt the need or desire for a DI system in Go. 
This is highly nonidiomatic in Go. Inject dependencies by passing values to functions, nothing more sophisticated than that is necessary or useful.
What does it do, exactly? It is only for APIs, not web apps with frontends, correct?
Here is a basic method that can probably be improved upon (using []int for simplicity for example): package main import ( "fmt" "sort" ) func InsertSorted(s []int, e int) { s = append(s, 0 /* use the zero value of the element type */) i := sort.Search(len(s), func(i int) bool { return s[i] &gt; e }) copy(s[i+1:], s[i:]) s[i] = e fmt.Println(s) } func main() { s := []int{1,2,3,4,6,7,8,9} InsertSorted(s,5) }
I am also about to schedule deployment of a SSO within my project (\~80% Go, \~20% Python). Currently I've fixed with the following options: either use SaaS (like auth0 or okta) or use LDAP (like FreeIPA). The rationale behind is all about simplicity of integration with existing services using standard protocols as well as ready-to-use libraries. 
I will update the article. I feel using channel is simple for me, they cutoff interface implementation for a callback and provide a nice clean way to subscribe for an event. It means yes you can subscribe inside just a plain function without using a struct :) 
it seems very cool, thanks for sharing
thanks for feedback :)
Agreed, I've been fiddling with Go on and off for a while now but I've decided to use it for everything going forward (when possible) - this is a super helpful list for me.
Thanks for filing the issue, documentation could certainly be improved here.
Nope. Tracking issue here - https://github.com/golang/go/issues/15108. Feel free to subscribe.
Here's an example from utility. ``` type AddUserUseCase struct { Auth AuthRepo Storage UserStorage Validator InputValidator } func (auuc *AddUserUseCase) Execute(input Input, aup AddUserPresenter) { if auuc.Validator.Invalid(input) { aup.Present({//Failure notice, which is not necessarily an error}) return } if !auuc.Auth.IsAllowed(input.Username) { aup.Present({//Another failure detailing auth not allowed, could have an error}) return } // some code uses input to create new domain level struct if err := auuc.Storage.Save(user); err != nil { aup.Present({//Failure notice}) return } aup.Present({//Success notice}) } ``` While simple, composition like this allows for testing the use case since all of its fields are actually interfaces. I can plug in different implementations for error flows, etc. Now if the entire project was only one such struct, DI is overkill. Picture 40 such structs. It can get more complex when the repositories themselves are complex such as when a URL to a service changes between environments. DI is helpful. 
You might find inspiration here [https://github.com/stuartsierra/component](https://github.com/stuartsierra/component). Basically it spins around trying to satisfy dependencies at runtime, which I know many gophers will bemoan. If it can't satisfy them, it fails to start. If it finds a dependency is missing, it looks to find an implementation. It does this until it finds all of the concretions and works its way up the dependency chain.
&gt; common functionality between multiple structs I think you meant types, not all of which are struct based. 😊
We need more detail. If these are stateless services, you don't need redis. If they are independent services that need communicate asych with each other, redis would work as would RabbitMQ, etc. As of right now, the best we can do is throw out our preferred messaging implements. I vote RabbitMQ, which isn't really helpful.
The best is to insert it to the right place - do the binary search lookup first as @Stuck_In_the_Matrix suggested. Heap can work, but keeping the heap invariant is also n*log n, and the heap structure is not a sorted list (see the "heap invariant").
Why do you need to use a slice at all? How often are you inserting vs reading?
&gt; While simple, composition like this allows for testing the use case since all of its fields are actually interfaces. Yes. Most of my programs are full of components like this. &gt; Now if the entire project was only one such struct, DI is overkill. Picture 40 such structs. &gt; . . . I write this crap by hand, but it is easily the worst part of writing services in Go. The "pass values to constructors" approach scales beautifully to 40 or 400 components. The thing to keep in mind is that you're not supposed to optimize for the time of the programmer first typing the thing, that's irrelevant in the life of the program. You're always trying to optimize for the time it takes the _next_ programmer to read and understand what's going on. DI frameworks subvert this priority.
Seems like the `append(s, 0)` should happen after the `sort.Search()`.
Well, the link says that a panic is used only rarely, "is an exception", in Go. :) The very first paragraph of the article also states this and links to two articles about standard error handling: &gt;Panics are similar to C++ and Java exceptions, but are only intended for run-time errors, such as following a nil pointer or attempting to index an array out of bounds. To signify events such as end-of-file, Go programs use the built-in error type. See [Error handling best practice](https://yourbasic.org/golang/errors-explained/) and [3 simple ways to create an error](https://yourbasic.org/golang/create-error/) for more on errors. &amp;#x200B;
That copy will probably kill your performance. Imagine you only insert small items then you always copy close to the whole slice. I think a heap approach would work better. Maybe you also dont want to increase your slice by just one entry at a time but manage that yourself because each time the underlying array needs to be resized that means another copy and an allocation.
Apps and APIs, it gives you an auto-scaling serverless HTTP application, running behind API Gateway and Lambda, which is on-demand pricing and scaling. Once it’s deployed you basically never have to operate it again.
I am pretty sure that you will always have a worstcase of O(n) for inserting into an array (or slice in this case)
&gt;Unlike PHP, you probably won't find something like traditional shared hosting for Go. Go programs can run on a shared hosting with FastCGI though. Compiling with FastCGI support is trivial. I tested a with a simple golang program on my local shared hosting provider and it worked without any issues.
As map is accessed via a method i really don't think this is necessary. But as I've already mentioned this is just a POC
It is a stateful messaging service and we need a multiple nodes running within a cluster. RabbitMQ is very helpful to connect these nodes through real time events. Each node has to notify other nodes on the cluster with any message comming. So i use redis as storage since it is fast and we need a fastdb with presistance. RabbitMQ to populate messages withing the cluster and consul or any other solution to build a proper cluster. 
So what I'm proposing here *is* exactly this, but the code that does it is generated from a config file instead of being hand-coded. Just because the Go code that does the wiring will, over time, get complicated when dependencies change but generating it means you could keep the config file in whatever structure you want and it will generate the Go code in the correct structure.
&gt; The "pass values to constructors" approach scales beautifully to 4 or 40 or 400 components. The thing to keep in mind is that you're not supposed to optimize for the time of the programmer first typing the thing, that's irrelevant in the life of the program. You're always trying to optimize for the time it takes the &gt; next &gt; programmer to read and understand what's going on. DI frameworks subvert this priority. I'm not sure I agree there. When your setup code is in a single Go file, and it is only a few dozen lines long then yes it's really easy to read. My example above would be this kind of situation: ``` import ( "github.com/sazzer/project/database", "github.com/sazzer/project/users" ) func main() { db := database.New() userRepo := users.NewUserRepository(db) userHandler := users.NewUserHandler(userRepo) } ``` As your application gets more complicated, your setup code gets from dozens to hundreds of lines long. If you're building a non-trivial monolith then the above might end up with dozens of imports and scores of components being constructed, and you've got to ensure that they are all in the correct order for it to work. And this order then changes if your dependency graph changes. It then gets reasonable that you're going to want to split this across many files - you might somehow have a file to build the various components in `users`, and another one for `posts` and `comments`. As soon as you do this, you have your setup logic split all over the place, and need to go and find it to know what's going on. Worse, if your components take interfaces then your autocomplete might not be able to work this out. And if you have two sections that are inter-dependent then it all falls apart. Factoring this out into some form of DI will, assuming that the readers understands that DI system, make it easier to read than finding all of the components across all of the Go files in the codebase. And under a DI system that uses code generation instead of reflection, you still have the generated file to read if you so desire.
[removed]
The way we implemented at work was to create an alias database name in pgBouncer like "prod_foo_ro" which only has backends for the replicas (which are by their nature read-only) and pointing to the real database name ("prod_foo"). Clients which only need to read give this alias database name.
No worries! We do have some exciting remote roles on their too, if that is more relevant to you right now!
Im pretty lazy so Goland from Jetbrains does it for me, student here so I have it for free. 
It looks like it requires 686. See the GO386 mention on: https://golang.org/doc/install/source Your two choices appear to be GO386=387 which requires Pentium MMX or later, or GO386=sse2 which requires Pentium 4/Opteron/Athlon 64 or later. 
Yeah JetBrains IDEs are pretty smart but it costs money.
I think you're looking for this? https://github.com/vmware/dispatch/wiki/Configure-GoLand-with-golint
Use GoLand for a ide and I use Wombat which is a old Vim colour scheme I keep porting to every ide I use
Absolutely. Didn’t mean to be rude. Rarely use types beyond structs myself so I thought I’d mention it. 
Cheers for the link. I tried that; `golint` is red in the configuration box, and it will throw an error in the event log related to permissions when I change a file :/
Somebody else's problem
What package/library are you using for logging? It’s possible that you don’t have the “log level” configured correctly. Some log packages allow you to change the level via environment variable, which may be setting to the some default level.
Expense it or use the education version until you have a job that will let you expense it.
Simple does not mean that you don't have to think or do some research. It is a simple language, not a \`I aM dUmB aNd I dOn'T kNoW hOw To CoDe PrOpErLy\` language.
Take a look at Core OS blog post: https://coreos.com/blog/grpc-protobufs-swagger.html Link to github source is at the end of the article and is a great starting point.
Inserting into a slice is an O(n) operation because of the copy, so it isn't significantly faster than insertion sort if at all. It really depends on how you use the slice. If you are using it to get sorted sub-slices within a range of values, a sorted set would be the appropriate data type. Most sorted set interfaces provide some kind of get in range function which gives you a sorted sequence of elements between two values. Alternatively, if you are querying for the top/bottom k elements, a priority queue such as a heap would be more appropriate. If you have so many elements that memory usage is problematic, you should consider using a database. 
In the Go std library the sort.Sort() algorithm uses a few different sorting algorithms depending on the input; from memory I think they do an insertion sort on small slices then various versions of quick sort. Have a look at the Go source code for inspiration.
I made it work! I set it to gometalinter for the template, then just switched it with golint and used to environment variables as the standard template values were. Nice! Thanks :)! Do you know if there is any way to see it in the code itself? A la marking the errors red(so, visual linting)?
Actually I prefer Vim, but can't stick with it at some point then I use VSCOde. It's a pretty good stuff that comes from Microsoft as OSS. I also used Goland for a while. My question wasn't about IDE/Editor by the way.
They also have a fairly good vim emulation mode. And I just realized that your original question was about theme and not the editor. 🤦‍♂️
I knew people would be butthurt, but going around calling people dumb because of 1 line of text that said absolutely nothing personal about anyone is on another level.
I don't recall calling you dumb
Huh, that's really interesting. Do you still end up with a long-lived process handling incoming connections? I'm curious about how this works, as I never thought this was possible.
I think you two may both be misunderstanding each other. I think /u/HeavilyFocused thinks you mean that you pass dependencies required by each function or method as arguments to the function or method. When as far as I can tell, you are saying if you have a struct with methods on, and those methods share dependencies, then pass the dependencies to a constructor and set some fields on the struct so you can access those fields in your methods instead. If you do actually mean you'd make a struct, and have the dependencies like database connections passed as arguments to every method, instead of being fields on the struct the method belongs to, then I agree with /u/HeavilyFocused, that is horrific and would cause an unnecessarily long chain of dependencies through your code. Passing to constructors OTOH is indeed beautiful, it does scale very well, and writing manual wiring is still really easy too, and as you have mentioned, you get a lot of compile-time benefits from this approach too.
I think you're correct here, but that the two of you are talking about 2 different problems. Implementing DI itself, and organising the construction of your types via DI. Some people swear by jamming it all in main, and I would agree with you /u/sazzer, that becomes messy and hard to follow when you have even 10 types being initialised in there. I have a more manual approach that I've followed for a long time now that [I wrote about](https://www.elliotdwright.com/2018/02/27/how-i-structure-some-of-my-projects/) a while ago. The approach I take lets you look at a single dependency and see how it's constructed, and exactly what dependencies it has, without having to worry about how those other types are constructed, or if they can error during construction, as all of that is handled elsewhere. This leads to something that sort of ends up looking more like configuration that code, but is still just plain Go, so is very powerful. Honestly, code generation for DI is not unidiomatic. What would be the difference between writing the wiring code by hand, and writing a configuration file to generate it? If you can make that configuration file concise and it's simpler than writing the code itself, then I say go for it - as long as you're avoiding things like reflection and the change of runtime panics caused by dependencies not being set properly, etc. then IMO it's a fine approach.
There are already libraries that do this. There is no approach to this problem I can think of that would work at runtime without drastically increasing the likelihood of your application falling over and panicking at runtime when in reality a compile-time check could have caught the same issue. Things like Facebook inject, and Uber's dig do this, but they do have a lot of issues, and it leads to really nasty code.
Just to build a binary and push that using FTP or something. You don't even need docker.
It's pretty much the same as deploying anything else, but easier because you can cross-compile your binary for that system. For example: `GOOS=linux GOARCH=amd64 go build -o server cmd/server/main.go` &amp;#x200B; Now you have a binary with the entire app, unlike something like Node where you'd have to install all node modules and perform a build in CI, then zip that up and deploy it however you like. &amp;#x200B; If you just want to get an app or API deployed quickly, check out my project Up [https://github.com/apex/up](https://github.com/apex/up) it may help, you just run \`$ up\` — so you can throw that command in a CI well for continuous deployment.
You seem to be looking for a "npm install enough things and it'll work automagically"-kind of solution, but that's rarely the best solution (in Go or elsewhere). Go is stunningly easy to deploy. It's just a binay. I don't see how anyone can call this a "nightmare". Your entire approach smells overly complex devops obfuscation. You just want to upload a binary and run it, you know. People were doing this in the 1970s. Related: https://arp242.net/weblog/dont-need-k8s.html
I’m so confused. It’s a binary. What could possibly be easier? 
Technically you can not completely achieve this at runtime, as go needs to be compiled and, unless you use a plugin system and swap out the plugins, the (compiled) code would not be available. &amp;#x200B; If you, however, accept to compile all possible packages in, you have three options: * Construct everything by hand. This has been discussed and is the most stable solution, however, also the most tedious, as for big projects this scales really bad. * Use code generation like [https://github.com/google/wire](https://github.com/google/wire): This will generate everything as static code, which you can much easier compose. Adding some configuration for which code should be used at runtime should work here too. Or you decide at generation time which ProviderSets you use. * Use a DI container like [https://github.com/i-love-flamingo/dingo](https://github.com/i-love-flamingo/dingo): This will wire the code completely at runtime, giving you more flexibility but also more possibilities to fail at runtime. Beside dingo there are more solutions such as [https://github.com/facebookgo/inject](https://github.com/facebookgo/inject), [https://github.com/sarulabs/di](https://github.com/sarulabs/di) and [https://github.com/go-ozzo/ozzo-di](https://github.com/go-ozzo/ozzo-di).
The point is, even though Node required a lot of ,,behind scenes'' work, that is the CI work. Not mine, once I've set everything up, all that I as concerned about is to push new changes to master. From that point forward, everything happened automatically - my project . was built, was tested and then deployed. I had no downtime, I just replaced files and new backend was working without anyone noticing anything. I don't see a way to do that here with go, since even if I bind deployment of my app binary to a command, I still have to ssh on my server and go \`./my-binary\` Or do I?
Phwoaaar this is a great article! Well done /u/kasvith
Blasphemy!
Not having downtimes due to having manually switching up binaries and running them after every change to an application. :(
If the app falls over at runtime it would do so immediately and only if it couldn't find the plugins or the symbols it needs within the plugins. If you write your application well then you anticipate these failures and report them to the user. I didn't realize those DI libraries did it that way. I think it's a viable approach for applications that have multiple large dependencies that can be used independently so your main application doesn't become bloated with everything when a fraction of the code will get used at a time. I like compile time checks too and most of the time (IMO) when using DI you just have a single Implementation for production and a mock Implementation for testing.
So what I was thinking was some step whereby you execute `go generate`, and it converts the above JSON file into something roughly like: ``` import ( "github.com/sazzer/project/database", "github.com/sazzer/project/users" ) func main() { db := database.New() userRepo := users.NewUserRepository(db) userHandler := users.NewUserHandler(userRepo) } ``` This is then a standard Go file that gets compiled along with the rest of the source code. You'd need some way of actually making use of the wired up dependencies as well, otherwise it's kinda pointless, but that's not too hard to solve.
Here's what I do: \- A short shell script to build the binary (on the dev machine) \- A short shell script to rsync the binary to the production machine \- Some code in the binary to automatically restart itself when a new binary is detected
Note, when you use Hydra (and Keto, et al), the onus of implementing the authentication is up to you. I started a project using [Authboss](https://github.com/volatiletech/authboss), and while it might be suitable for the authentication layer in an application, it didn't really lend itself to being a stand-alone authentication app. (The project was eventually scrapped, or suspended indefinitely.) There were however some nice things in that project which you could probably cherry-pick to help you on your way, if you choose to travel down that path. If you're not set on building your own, the [gologin](https://github.com/dghubble/gologin) package is similar to the [Passport](https://www.npmjs.com/package/passport) JavaScript module, providing ready-made handlers for well-known identity providers.
&gt; I still have to ssh on my server and go `./my-binary` Use systemd? Or runit? Or whatever?
Cool
Question: post.ID = strconv.Itoa(rand.Intn(1000000)) could possibly cause a duplicate? 
Deploying go shouldn't be very different from how you deploy anything else. if you're using kubernetes and docker for everything else, I don't see how you can call it a problem. If you're not using it for everything else, well you're the one that decided to do it differently for Go for some reason. Lots of people use Docker just as a deployment strategy without really caring about the containerization part, which is fine, but there's no law saying you have to use Docker with Go. You could use any other automated deployment mechanism out there, you could even build OS packages to install, you can integrate with your init to control start/stop, it doesn't have to be different from any other thing you're doing.
Leave the key value generation to the database backend. This is example code.
I thought me coding Go services would be the database backend logic. You mean let whatever DB/caching (Postgress, mongo, redis etc.) built in functions achieve this?
Most of my experience is with MySQL/Mariadb and SQLite. If you define the table with an id column marked as "primary key", it will automatically generate a (sequential) unique key when you insert into that table.
That's a lot of questions all bundled up into one. Lets try to break this down into steps and start simple. First, write a hello world program in Go. Doing that will get the basis covered, like installing go, writing a line or two of code, and compiling and running it. Next, learn how to do serve a single static web file, or a folder of static files. That'll get you rocking with your first Go served website. From there you'll be in a much better position to learn how to do the more complicated things like work with databases and serve dynamic web content, etc. 
I've inherited projects that use this kind of approach before, and they don't always fail at runtime, and in fact in some cases, things can fail and not result in a panic, but can result in slower performance, or just plain weird bugs. For example, if you have a dependency that is optional, or something that is lazily created, or if a zero-value can be accepted and not panic. These are indeed all things you can work around by writing additional code to handle those cases, but you can also easily avoid them and gain lots of benefits by writing the code so that errors occur at compile time instead. I can definitely understand the draw to these kinds of libraries, especially if you're coming from a language where DI containers are frequently used, or if your application is large enough that DI is tricky to manually maintain with wiring code - but I personally don't think the minimal benefits you may gain outweigh the definite problems they introduce.
Right, so as a thumb of rule, let the db (or db lib f.ex mysql golang lib) handle key generation for CRUD insertions?
How about new post using DB ?
This is an entire engineering sub-speciality, called DevOps or Operations or Systems Administration, etc. This is not a simple topic, but if you're interested in learning from the ground up, I suggest [O'Reilly](http://shop.oreilly.com/) books. If you just want to get a server up and running quickly, Heroku is a decent option.
Emacs with gruber-darker. But that is not Go specific: It's the right choice for almost everything.
There's more than enough of these kind of examples online already in my opinion. This is more of a "how do routers work" example than a "how to create an API" example. Your still missing a DB, structure, models, logging, authentication. I wish there were more advanced posts than this kind of blogspam. 
This looks interesting. Looks as if this would make 2FA and single sign on a lot easier. However, the documentation doesn't seem to exist and the website is sub par. But thank you for the suggestion. This post seems to have gone into oblivion. 
I can't argue with experience. My root comment was speculative and I do think the true need for this style of DI is few and far between. It's too bad that plugins don't fail cleanly like the rest of Go seems designed to do.
I think then google's wire is the best choice, as that is aiming to code generation. Obviously the usage is a bit different, there are the wire sets, not a JSON config. But I think it's no problem to use them? Or, in the worst case, create a JSON to wire transpiler?
I've never seen FreeIPA before this. I will def look into it as it seems to be an even more fine grained way to control access to resources. Thanks for posting!
Sounds to me like you're testing in prod.
Looks good, good choice!
My problem with Wire, if I understand it right, is that you are explicitly saying which Provider you want to use instead of just telling it which Type you want to be given. Say I've got a `UserRepository` interface and a `DbUserRepository` implementation of it. With Wire I then say that I want to use the `NewDbUserRepository` provider to provide a value for my `UserService` struct. However, if I then add a `CachingUserRepository` as well, I've got to update everywhere to now use the `NewCachingUserRepository` instead. It's easier if I can just tell it to "Give me whatever was built with the name `userRepository`" and have the actual container that wires it all up know what that is. Then the change from `DbUserRepository` to `CachingUserRepository` happens only in one place. And yes, I know that you could have a Provider of just `NewUserRepository` that returns the correct one, but I wonder if that's the right place to put the knowledge of what is wired up where.
You can definitely run go in docker-compose just like you did with node. Instead of copying the javascript files into the docker container, you copy the go binary (or you can build in the docker container, but that just bloats the container for no reason.. that's one of the great things about go, the binary is self-contained, you don't need a runtime in the container). &amp;#x200B; Honestly, you don't even need docker, but I understand that a lot of systems have docker-shaped holes that need to be filled. &amp;#x200B; Try this: [https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/](https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/) &amp;#x200B;
Yes, i am aware that the ORY stack is lacking an Authn layer (and that is what Authn-server is going to be used for). Authboss is out of the question unfortunately due to its lack of support. Gologin may be promising though! I'm not sure if it fits into the ORY stack but i'm going to look into it further. Thank you for the post! [Disclaimer, i am certainly not the world's best dev either. But i have an end goal and this is one of the things in the way. I appreciate the help!]
&gt;you can build in the docker container, but that just bloats the container for no reason Let me introduce you to the magic of multi stage docker files. [https://docs.docker.com/develop/develop-images/multistage-build/#use-multi-stage-builds](https://docs.docker.com/develop/develop-images/multistage-build/#use-multi-stage-builds) It is so useful for anything you want to build with docker, but want the resulting docker image not be bloated.
I have to agree with you, though I dont mind them as I am still learning. That said, I also suspect a LOT of these blog posts are devs trying to put on their resume how they blog/work with community/etc because lately dev jobs seem to value not only that you are full stack (and expert in every area of full stack, including devops, ci/cd, automation, data/algorithms, etc) but that you also spend whatever time you have left awake participating in dev/tech related stuff with the community. &amp;#x200B;
&gt;As your application gets more complicated, your setup code gets from dozens to hundreds of lines long. If you're building a non-trivial monolith then the above might end up with dozens of imports and scores of components being constructed, and you've got to ensure that they are all in the correct order for it to work. And this order then changes if your dependency graph changes. If you're writing a "non-trivial monolith" that presumably contains a lot of lines of code, I don't see the value in trying to save a few lines in your initialization code. You're trading compile time safety and simplicity for the sake of cutting down on a few lines of code. &gt;It then gets reasonable that you're going to want to split this across many files - you might somehow have a file to build the various components in users and another one for posts and comments. As soon as you do this, you have your setup logic split all over the place, and need to go and find it to know what's going on. Worse, if your components take interfaces then your autocomplete might not be able to work this out. And if you have two sections that are inter-dependent then it all falls apart. Why are you treating initialization/setup code different to any other? It's just code. The same techniques you use to make Go code maintainable, easy to understand and navigate, and logically structured works here too. I've written a fair amount of Go, from small personal projects to large enterprise applications and have not had these issues you're talking about. A little bit of up-front thought about how to structure your code will solve these problems without having to turn to a config-file-driven DI framework that comes with a whole load of its own problems. &gt;Factoring this out into some form of DI will, assuming that the readers understands that DI system, make it easier to read than finding all of the components across all of the Go files in the codebase. And under a DI system that uses code generation instead of reflection, you still have the generated file to read if you so desire. Understanding the framework is not the issue. Navigating the code is simply not a easy if you're using a DI framework, regardless of how well you understand how it works - particularly when it comes to IDE integration (which won't have clue about a config file containing names of structs). And even using code generation, you're still adding an extra step to your build process - which isn't a particularly big deal, but the fact remains that using such a framework at all is simply unnecessary.
This is a great way to learn how to build an API manually, but I will say it is not how it should be done today if at all possible. There are tools like RAML and OpenAPI that can and should be used that speed up API definitions, which you then use to auto generate documentation, test code, server side interfaces, even client side SDKs. Never ever code an API first.. use the API first single source of truth pattern... use RAML or OpenAPI and let it generate a ton of stuff for you rather than waste a lot of time coding first, then trying to manually write tests, mocks, documentation, etc. 
Thanks! This works on GoLand 2018.3.5 (OSX).
I use VSCode with the Go extension. I constantly change the theme, so... 🙄
&gt;I have a more manual approach that I've followed for a long time now that [I wrote about](https://www.elliotdwright.com/2018/02/27/how-i-structure-some-of-my-projects/) a while ago. The approach I take lets you look at a single dependency and see how it's constructed, and exactly what dependencies it has, without having to worry about how those other types are constructed, or if they can error during construction, as all of that is handled elsewhere. This leads to something that sort of ends up looking more like configuration that code, but is still just plain Go, so is very powerful. I haven't looked at your post, but this is exactly the sort of thing OP *should* be doing instead of looking at third-party DI frameworks. Config-file-driven frameworks are a complete pain to work with, and even code generation adds unnecessarily complexity and dependencies. &gt;Honestly, code generation for DI is not unidiomatic. I disagree, and the fact that we're having this discussion helps to prove it. In Java, DI frameworks are not unidiomatic - in fact you could consider using one in a large application *idiomatic*. But this is not the case with Go - people can and do write very large applications in Go without the need for such a framework. Idiomatic Go is supposed to reject the kind of helpful "magic" that other languages embrace - it's one of it's best assets. DI frameworks blatantly fly in the face of this - not simply by adding complexity, but by being completely unnecessary and a carry-over from other languages.
Make sure you look into [HTTP Graceful Shutdown](https://gist.github.com/peterhellberg/38117e546c217960747aacf689af3dc2) and combine that with another binary that starts up the new binary and moves traffic over. You can use nginx, [caddy](https://github.com/mholt/caddy), or one of the other [tools on github](https://github.com/facebookgo/grace). Make sure to build your binaries in docker, and simply put that new binary on the server.
So according to you prod environment is immutable, unbreakable medium. Thank god you aren’t developing Netflix else I’d have to watch 20 min episode for an hour due to you swapping out your backend features...
Thanks will look into that! 
[https://lets-go.alexedwards.net/](https://lets-go.alexedwards.net/) It covers everything you asked for and is up to date for go 1.12, meaning it uses the new module system, excellent book. Not affiliated, but I bought the book and consider it money well spent.
Yes ... sort of. The web server starts your go program and will keep it alive for a certain amount of time. If there haven't been any requests in that time, the process will be stopped and restarted when another request comes. &amp;#x200B; The cool thing is that you can use the same MUX you use to handle HTTP requests to handle the requests via fastcgi. &amp;#x200B; I haven't played a lot with it though - I just created a few handlers using go-chi for routing, compiled it and copied the binary file in the cgi-bin folder in my shared hosting. Depending on the server config you might need to create an .htaccess file to enable fast-cgi, but that's about it.
The "problem" with go is that you have to read the documentation. Going from node to go taught me how to program.
Would you have an example of a code that restarts upon being updated? This one looks promising
Well I do not see big difference deploying Node project and Go project. But of course it depends on how your CI was built. Could you please tell a little bit more about your Node CI pipeline?
As I mentioned earlier, I used travis for CI work. I had a trigger on my github repo that would work upon pushing on master ( that is pushing to prod, analogically pushing to dev would mean pushing to development server) . It was build and then custom script would send newest files on my vps. From there I have docker compose that manages all my services. So it had volume on a node backend directory and that’s it. Files change, backend changes everything gets updated. 
Well in this case you can still use Travis CI with the same approach. Here is the example how to build go projects using Travis [https://docs.travis-ci.com/user/languages/go/](https://docs.travis-ci.com/user/languages/go/). On servers you can use same approach with docker compose. How does exactly it reloads/restart service on file change?
100%. Your data source should be leveraged for capabilities it offers. Column uniqueness, primary keys, these are powerful offerings from the database that if you did on your own would be terribly slow (checking an identifier doesn't exist, repeat until true, then insert? That's a lot of network calls, and IO is slow) and prone to error (even if you did find one that didn't exist, in the case of parallel connectivity you have edge cases for failure even still). tl;dr use your database for the strong and robust functionality it provides.
Try doing that in your reverse proxy or load balancer. Redirect new connections to the newer binary and remove old binary when all connections are closed. Probably write a plugin for nginx to do that? And then opensource it! Looks like the community needs this. Or, see if you can adapt this: [https://github.com/facebookgo/grace](https://github.com/facebookgo/grace)
I would guess that you use something like nodemon to restart Node on source code change. It could be the same approach with binary. Here is some ways to do that [https://stackoverflow.com/questions/12264238/restart-process-on-file-change-in-linux](https://stackoverflow.com/questions/12264238/restart-process-on-file-change-in-linux)
Yes. That's literally what production is. And if your services take more than a minute, let alone an *hour* to pull down and back up you're doing something terribly wrong. If you change something in prod, that's what we call an "outage". Feel free to test as much as you want on your own instance but if you change stuff on a public-facing machine without a failover set-up then you will be out the door before you can say CORBA.
A very small kubernetes cluster cost 10-20€. Write a swiss army knife where you can do `swiss build push -b` which tags a new version, builds it and pushes it to private repository and updates kubernetes-server.yaml with the new image url, then `kubectl apply -f kubernetes-server.yaml` or `kubectl rollout` to make the deployment use the newer images. With that tool it's like having the ability to scale built in. Simply use service names for your services to talk to each other and load balancer/node port for outside. Tip if you are starting out: I use a monorepo and put `Dockerfile.servicex` into the root of it. Now I don't have to write Dockerfiles anymore since they are pretty much the same content anyway (except occational go generate and make, which can be automatically called in a standard `Dockerfile`).
Are you considering Indians who have work experience with MNC, having worked in Tokyo and now based in Bangalore and have experience working with 2 startups as tech lead? Any options. Not an alcoholic but workaholic.
You can change the severity of issues found by file watchers in general under Editor &gt; Inspections &gt; File Watchers, but I'm not aware of a way to make it any more specific than that.
This would be good only for server side rendered HTML, correct? no react, vue or anything like that. Sorry i'm still learning, i will take a look. Thanks!
Got you, Lol.
https://github.com/golang/go/issues?utf8=✓&amp;q=is%3Aissue+is%3Aopen+label%3Agopls
[removed]
I made a post that goes a bit more into detail of you are interested https://link.medium.com/PNo0tixO1U
That was very basic - but good job anyhow..
[https://github.com/golang/go/wiki/gopls](https://github.com/golang/go/wiki/gopls)
Is it really common in Go apps to plop a DB directly in a controller? I get the gist of the code, but an example of a properly abstracted project that fits the gopher norms would be great.
 ___T_ | - - | |__v__| .=[::+]=. ]=' [___] '=[ / | _\ |_
I found this project on Reddit which was helpful: https://github.com/spy16/droplets
Parametric Polymorphism is interesting.. Good explanation..
Is it just me or does this seem like a carbon copy of this tutorial https://www.youtube.com/watch?v=SonwZ6MF5BE
It's dirt simple and there are prolly better ways, but here's what currently works: &amp;#x200B; `package updater` &amp;#x200B; `import (` `"log"` `"os"` `"sync"` `"time"` `)` &amp;#x200B; `func Start(Wg sync.WaitGroup, done chan bool) {` `Wg.Add(1)` `go func() {` `log.Println("Start updater.")` `name := execFile() // get name &amp; path of our exe file` `mtime, err := getMtime(name)` `if err != nil {` `return` `}` `log.Println("Exe file:", name, mtime.Format("2006-01-02 15:04:05"))` `updTicker := time.NewTicker(10 * time.Second)` `defer Wg.Done()` `defer log.Println("Exiting updater.")` `defer updTicker.Stop()` &amp;#x200B; `for {` `select {` `case &lt;-done:` `return` `case &lt;-updTicker.C:` `mtimeNew, err := getMtime(name)` `if err != nil {` `continue` `}` `// log.Println("Check for exe update.", mtime.Format("2006-01-02 15:04:05"), mtimeNew.Format("2006-01-02 15:04:05"))` `if mtimeNew.After(mtime) {` `log.Println("New exe file detected, restart.")` `// we restart by exiting and let systemd restart us` `log.Println("Ordering shutdown.")` `close(done)` `return` `}` `}` `}` `}()` `}` &amp;#x200B; `func getMtime(name string) (time.Time, error) {` `mtime :=` [`time.Now`](https://time.Now)`() // dummy value` `f, err :=` [`os.Open`](https://os.Open)`(name)` `if err != nil {` `log.Println("Unable to open exe file:", err)` `return mtime, err` `}` `defer f.Close()` `stat, err := f.Stat()` `if err != nil {` `log.Println("Unable to stat exe file:", err)` `return mtime, err` `}` `mtime = stat.ModTime()` `return mtime, nil` `}` `func execFile() string {` `exe, err := os.Executable()` `if err != nil {` `log.Panicln("Unable to obtain executable name:", err)` `}` `return exe` `}` &amp;#x200B; Call it like this: &amp;#x200B; `func main() {` &amp;#x200B; `var Wg sync.WaitGroup // to wait for the goroutines to exit` `Done = make(chan bool, 1)` `updater.Start(Wg, Done) // if new exe appears, we restart ourselves to run it` &amp;#x200B; `// your stuff here that runs forever until 'Done' is closed` `}`
Apologies for formatting, evidently "inline code" has it's own ideas.
cute ___T_ | q p | |__`__| ,"|+ |". _\|+__|/_ /7 [| \/7 [|_
Hah, nice - that actually makes a lot of sense now I think about it. That approach hadn't sprung to mind at all. Thanks for the insight.
&gt; just set up docker-compose and push your repo changes into volumed directory. I think this is rather an anti-pattern. Yes, it probably works most of the time. It might give you problems if there are breaking changes in npm dependencies with C extensions. I think to do it right, you should have a reverse proxy/ loadbalancer and be able to run the new process on a new port or new IP. Then switch the loadbalancer - either through new configuration, iptables (probably not) or through the [Ambassador pattern](https://docs.docker.com/v17.09/engine/admin/ambassador_pattern_linking/)
I'm currently studying CS so please forgive me if this sounds stupid. Is CI/CD usually deploying to testing for a time before deploying to canaries/gradual role out to production? If so how does continuous CI/CD see health in the testing environment, does it only look on the service to currently deploy or also neighboring services using the current version, and how does it do that? I guess testing and prod usually reside on different kubernetes clusters.
Woah hold up. Are you using docker as just a starter that then loads code mounted into it? Ie, you mount /app and let the server interpolate whatever is in there, and you simply swap out the code underneath? I’m seeing that pattern a lot more lately, and it’s an extremely bad way to use docker. Volumes are for your persistent data; images are for your app. That is, you put things like user uploads in the volume. Volumes are for state, not code. So, with docker, you can always just start the app by pulling the image and running it with the port bound. You should need nothing else. It doesn’t matter if that’s Node or Go or PHP. To upgrade, you simply change the tag in compose/swarm/kubernetes, and tell it to update. Done. No complicated side-channel dev-ops going on. A server should never be downloading from Git on a production system, ever, when running docker. 
You sniffed out the same problem I see. Effectively he seems to be using docker as just an easy way to install a server and then doing traditional devops underneath. Really bad anti-pattern IMHO. 
&gt;I'm not sure what approach would be best for slices with a large size (in the millions). sorting slices in the millions seems unproductive. &gt;Any ideas? use a tree.
getting it to show is actually already in their docs https://github.com/golangci/golangci-lint#install
Another similar question. Does development testing, release testing and user testing share the docker registry? Should I tag the images differently, with a prefix to signify that images have setup inside which only works for the specific environment?
try caddyserver. join the community - ask questions. learn from the code and the community.
Now, I work as a tester and am in charge of CI, but I do not work in Go professionally and I will not admit to having any sort of deep expertise on the subjects. CI/CD doesn't need containers or managers, especially not for Go, which is statically linked by default, and so has no required dependencies other than non-code resources. Deployment is easier with something like Docker, but for Go the advantage is smaller than for dynamically linked languages. A "testing environment" is not always a requirement, and what constitutes a "testing environment" is not set in stone. If you have no dependencies, your testing environment is wherever you put the binary that isn't the "normal" site. If you have a local instance of the dependency you need, the testing environment can just as well be your development machine. If you have tons of dependencies and spinning up an instance of your application manually is a pain, your testing environment is typically a machine, virtual or otherwise, with specs as identical as possible to your production environment. Generally, when using the last definition, the testing version of your binary will be deployed to the testing environment, overwriting what was already there, *after* all automated tests that the CI suite can run has passed. If the automated tests fail, there is no use deploying the thing. If an environment is needed for that process, that environment usually contains an external test runner program that can poke your application in the right ways and spit out a result file formatted in a way the CI pipeline can display. The JUnit XML format is pretty common for that, and most CI systems contain tasks that wait for JUnit files to be created before considering the task done. When a testing environment is used for more than automated testing, it's usually all manual stuff or external stimuli like sending out a beta link to a select group and having them try and break it. Only when the testing version is considered passed can you (usually manually) merge that code into your stable branch, which will trigger a completely different build pipeline that then spits out a stripped version of the program with incremented (again, usually manually) version numbers to your (hopefully redundant) production machine. Testing and feature branches in Git play a large role here. Most CI/CD suites bind their pipeline to a branch, so when they get triggered by a commit to the testing branch they will run the testing pipeline, and the same for release. For my particular scenario, our "environment" is a custom embedded system. There is no test-specific area, all tests are run against a "production" unit with some extra helper programs and more lenient firewall rules. There is an "autotest environment" where the binaries that are supposed to run on the hardware are run in an emulated environment with mock versions of all their dependencies, but that's just a logic test since it won't be able to find bugs that the real system can cause. 
Docker is not a requirement for testing. Personally I have never used it. Look up best practices for whatever method you want to use.
I would personaly suggest using nginx. It's a reverse proxy allowing you to never expose the actual go application behind it. Plus it's easy to configure, fast and lightweight, flexible and can be used with certobot in order to automate https certificates. Bonus points if you let nginx serve static files and let go handle api calls
The project I'm working on now generates ids in code, but I can't remember why. Could it be that you can't have multiple writes to the same table if you have it set up so the db handles the ids?
Thanks for your help! I am currently serving a static website. But only one page. It seems to send across the css and js too which is nice. But I'm trying to get into the more comprehensive server stuff now and struggling to take that leap
Any tutorials in particular you can recommend? I've been going through some books but they're mostly just telling me the basics of how structs and maps etc works. Thanks!
Cheers for that I'll look into it!
A horrible cookie dialog that can’t be removed takes up half the screen on mobile 😕
Code to explain: https://play.golang.org/p/c6nl9c-PcnA See also: https://blog.golang.org/strings 
I'm trying to go through all the documentation but I'm just struggling to piece everything together because most parts are taught separately. If there is a particular resource you would recommend do let me know. Thanks!
I was hoping to go with vanilla go but I'll have a look, thanks!
&gt; As your application gets more complicated, your setup code gets from dozens to hundreds of lines long. If you're building a non-trivial monolith then the above might end up with dozens of imports and scores of components being constructed, and you've got to ensure that they are all in the correct order for it to work. And this order then changes if your dependency graph changes. You don't have to ensure it, your compiler does that for you. My claim is that moving your wire-up from compile time (Go code) to runtime (config file) has no actual benefits, and many real drawbacks. 
&gt; As your application gets more complicated, your setup code gets from dozens to hundreds of lines long. If you're building a non-trivial monolith then the above might end up with dozens of imports and scores of components being constructed, and you've got to ensure that they are all in the correct order for it to work. And this order then changes if your dependency graph changes. Yes, as your program gets more complex, its component graph also gets more complex. This complexity is not accidental, it's necessary: things that depend on other things necessarily create a dep graph, and future maintainers need to understand that graph intuitively to be able to do their job. And so you shouldn't try to hide it away behind a wall of magic (satisfiability-deduction) or config (your proposed config file) but rather lift it up, front and center, in your func main or some short hop away from your func main, as explicitly and declaratively as you can.
Rebecca Stambler of the Go team says it is ready for alpha testing: [https://groups.google.com/forum/m/#!topic/golang-tools/jzX6fEjjYb0](https://groups.google.com/forum/m/#!topic/golang-tools/jzX6fEjjYb0)
Don't forget CORS
Gets more fun when you use grpc-gateway and swagger generator for OpenAPI compatibility
I recommend you read each of the projects here: https://awesome-go.com/#web-frameworks These frameworks and routers will show you how _most_ of the Go community views HTTP servers. You will learn about data binding, validation, auth, routers/muxes, middlewares, etc.. 
A tester, eh? Thank you for staying with me here, this is interesting! Assume I develop an service application. Do I write each integration test myself, meaning "spin up this", then drive the application with the data and see whether there's the correct output or do I launch the whole application in a cluster, drive test data through and CI/CD detects what crashes occur? The first way is much more controlled but the second approach can show errors which come from the specific setup. How is this usually done?
Will do, thank you.
These are called grapheme clusters. I don't think there's anything in the standard library to deal with them, but I think the external package [golang.org/x/text/unicode/norm](https://godoc.org/golang.org/x/text/unicode/norm) can be used to break a string into logical characters. [Example.](https://play.golang.org/p/f4R6RW3DpC2)
REST is deprecated, use gRPC and if you need legacy just throw gRPC-gateway in front of it
Google calhoun. What you are saying is that you don't know how to read documentation, and I agree with you, it is hard, so keep going. When you are really new, you don't know what to input to google. No cure for that except keep trying.
Define "fast" (Not trolling, I mean it -- what precisely do you mean?)
The garbage collector [1][2]. [1] https://blog.golang.org/ismmkeynote [2] https://blog.golang.org/go15gc
 |---| |n n| |_-_| /|(\)|\ d |___| b |_|_| /_|_\ 
 |---| |n n| |_-_| /|(\)|\ d |___| b |_|_| /_|_\ 
/u/cbll is not talking about golangci-lint, they are referring to golint [1]. [1] https://github.com/golang/lint
[SublimeText + SublimeLinter-golangcilint + LSP](https://raw.githubusercontent.com/SublimeLinter/SublimeLinter-golangcilint/master/screenshot.png)
Computation speed. Like a calculation in C would take 10 seconds and the same one in go would take 15 or 20
The garbage collector. &amp;#x200B; The go language syntax could perhaps be made as fast as C++ (if garbage collection were replaced with manual management on heap), but the runtime is too heavy and GC is too slow otherwise.
**جميل**
Also look at https://godoc.org/golang.org/x/text
I wrote out a long post about this a while back: [https://www.reddit.com/r/golang/comments/af721g/why\_is\_golang\_not\_as\_performant\_as\_c\_or\_c/edw2llm/](https://www.reddit.com/r/golang/comments/af721g/why_is_golang_not_as_performant_as_c_or_c/edw2llm/) &amp;#x200B; &amp;#x200B;
شكراً لك صديقي
The Go Community is growing! &amp;#x200B; Additional like for the logotype :)
The garbage collector is the wrong answer. If it becomes a performance issue, then look at your code. The compiler needs to improve especially with regard to inlining. Also, bounds checking is not free (but can be disabled).
So you are asking why a particular benchmark is slower I Go? Which one?
We would need WAY more detail about what you did, and specific questions you have about it. &gt;instead of the migration one which is a pain and has many issues What pains do you have. Migrations are pretty universal at this point and the Go support for them is pretty reasonable.
This is exciting.
I know this is just an exercise but I would have done it like this: &amp;#x200B; [https://goplay.space/#MDgpX9jlW0U](https://goplay.space/#MDgpX9jlW0U)
Default Server mux is not the best performing mux - Refer to this - [Routing Benchmarks](https://github.com/julienschmidt/go-http-routing-benchmark#conclusions) Also, i find gorilla mux more developer friendly, specially for getting URL parameters..
All of them: https://benchmarksgame-team.pages.debian.net/benchmarksgame/
Yes
This outlines how to do with Serf and Raft: https://thehoard.blog/building-a-kafka-that-doesnt-depend-on-zookeeper-2c4701b6e961
I'm also writing a book on how to build distributed services for Prag Prog but it's not in beta yet.
Ci lint can use golint. And since the normal lint isn’t supported on GoLand, seems like a better alternative. 
If you are thinking on using http alternatives, check go-gin also
Thanks for all the links, I'm sure they will help. I do find I am slowly picking things up. I'll look at them tonight!
Recovering the deleted comment by /u/bmw417 --- I've used `exec.Command()` many times, but now it's throwing an error and I don't know why. There's two of these commands that are failing - one moves a file from the current directory to a subdirectory, and the other removes the file from the directory. The commands look like this: command := "\"rm " + title + "\"" err := exec.Command("/bin/bash", "-c", command) if err != nil { log.Fatal(err) } ​ command := "\"mv " + title + " pdfs\"" err := exec.Command("/bin/bash", "-c", command) if err != nil { log.Fatal(err) } The terminal returns this: 2019/03/12 13:04:49 &amp;{/bin/bash [/bin/bash -c "mv 2018MobileT hreatLandscape-Appendix.pdf pdfs"] [] &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; [] &lt;n il&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; false [] [] [] [] &lt;nil&gt; &lt;nil&gt;} ex it status 1 However, if I copy/paste the command into my terminal, it executes right away! Again, I've used this command many times but it's only now giving me issues.
Recovering the deleted comment by /u/bmw417 --- I've used `exec.Command()` many times, but now it's throwing an error and I don't know why. There's two of these commands that are failing - one moves a file from the current directory to a subdirectory, and the other removes the file from the directory. The commands look like this: command := "\"rm " + title + "\"" err := exec.Command("/bin/bash", "-c", command) if err != nil { log.Fatal(err) } ​ command := "\"mv " + title + " pdfs\"" err := exec.Command("/bin/bash", "-c", command) if err != nil { log.Fatal(err) } The terminal returns this: 2019/03/12 13:04:49 &amp;{/bin/bash [/bin/bash -c "mv 2018MobileT hreatLandscape-Appendix.pdf pdfs"] [] &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; [] &lt;n il&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; false [] [] [] [] &lt;nil&gt; &lt;nil&gt;} ex it status 1 However, if I copy/paste the command into my terminal, it executes right away! Again, I've used this command many times but it's only now giving me issues.
Recovering the deleted comment by /u/bmw417 --- I've used `exec.Command()` many times, but now it's throwing an error and I don't know why. There's two of these commands that are failing - one moves a file from the current directory to a subdirectory, and the other removes the file from the directory. The commands look like this: command := "\"rm " + title + "\"" err := exec.Command("/bin/bash", "-c", command) if err != nil { log.Fatal(err) } command := "\"mv " + title + " pdfs\"" err := exec.Command("/bin/bash", "-c", command) if err != nil { log.Fatal(err) } The terminal returns this: 2019/03/12 13:04:49 &amp;{/bin/bash [/bin/bash -c "mv 2018MobileT hreatLandscape-Appendix.pdf pdfs"] [] &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; [] &lt;n il&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; &lt;nil&gt; false [] [] [] [] &lt;nil&gt; &lt;nil&gt;} ex it status 1 However, if I copy/paste the command into my terminal, it executes right away! Again, I've used this command many times but it's only now giving me issues.
 )_( |n n| |_A_| 7--|=0=|--&lt; |___| (_|_) (o|o)
URL parameters is the usual thing. 
adding new tables is easy. Modifying existing ones, especially where they're involved in relationships with other tables, is hard.
amazing &amp;#x200B;
To get url parameters, and specify request method.
from the links you provided these two are for different type of doc from godoc. 
Thanks for taking the time to code that up. but that didn’t help. I’m aware of RuneCountInString though. It still treats ன் as having rune length 2 when it’s just one logical character. However that function is doing what’s its supposed to do. One of the other redditors on this thread mentioned that I would need a package that treats graphemes clusters as one logical cluster. I think that’s the way to go. 
Well, I hate to comment without leaving more detail (I'm strapped for time and have to run, so I may edit this with more information later); however, if you think Gorilla seems 'very basic' for 'nearly the same functionality', then you haven't used it much. Read the blogs specific to why they chose it over the standard library. As others have said, it's not light-weight, but it's feature-rich. Depends on what you're looking for, it may or may not be the solution. I've used it a lot in some simple back-end services. I've since, however, moved on from those frameworks and strictly use Swagger to generate my services. Having a detailed Swagger spec detailing exactly how your API works is great. I'm not much of a fan of boiler-plate and generated code, but I've made the exception when it comes to creating my back-end services... as it saves so much headache later down the road, especially if your API service because huge and sophisticated.
This is dope. As the kids used to say. 
Oh no! We've all done this... let our pelican beak override our hummingbird ass and make us look embarrassingly stupid. Learn your lesson, and if you're against what somebody says (even in this case, where they are correct and you're unfortunately not), don't word it like you did. Learn... and don't bark at those trying to assist you. Just my advice. You got this though... keep truckin'. Go is great for back-end micro-services. The tools you specified, which you seem against, are the standard atm. Most Fortune 500 companies employing Go devs are now requiring those with DevOps/SRE experience. Don't go against the grain... learn it.
Don't do benchmarks on t2-t3 instance types. They provide shared/burstable CPU between multiple customers. That results in constant spikes and blips despite CPU being very low in usage. &amp;#x200B; You can never trust benchmarks you did on T type instances. AWS does not recommend running production workloads on T types, they are meant for development. &amp;#x200B; Launch an m5.l or c5.l and repeat your benchmarks
VSCode w/ Dark+ theme (although most any dark theme will work).
Good article that goes out of its way to back itself with quotes.
I didnt know this. Is it fast/efficient? Does it match just the properties in the json to the proto schema? E.g. if json has name, address, city, state, zip on the req payload, but the proto file only has name and zip, will it auto populate just those two values in to the proto generated object? 
Passing data channel slice as a parameter to goroutine leaks the slice out of mutex control. 
&gt; REST is deprecated - Any proof supporting this claim? Or gRPC is really the way to go? I would love to learn more on gRPC :)
Not entirely sure how that all works yet, but my desire is to use RAML vs OpenAPI. RAML 1.0 is so much better to define APIs with. RAML types is just awesomesauce for defining payloads, and I suspect it could be pretty easy to generate .proto files from as well. If only there was a good RAML 1 Golang parser! Damn Mulesoft for not making it a priority to build tools for RAML! 
jar jar, is that you?
Can you provide any more details about what you are executing and the full error? GOPATH has already defaulted to $HOME/go since v1. 8 so it could be a red herring. 
Nice
It does not pass channel slices with parameters. It pass the channel to be registered as a subscriber to the function. Slice is an internal structure which used to hold these subscribers for a topic. So it is not exposed to direct use.
Run `go env` and report what it says. 
GOARCH="amd64" GOBIN="" GOEXE="" GOHOSTARCH="amd64" GOHOSTOS="linux" GOOS="linux" GOPATH="/home/user/go" GORACE="" GOROOT="/usr/lib/go-1.7" GOTOOLDIR="/usr/lib/go-1.7/pkg/tool/linux\_amd64" CC="gcc" GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build342973615=/tmp/go-build -gno-record-gcc-switches" CXX="g++" CGO\_ENABLED="1" &amp;#x200B; &amp;#x200B;
I was trying to run the go get github-url-here command and it was throwing that error. 
Nice !
I can't really speak to "is it fast", but I've never had issues with serialization speed being my slowest link. Here's an example proto for you: syntax = "proto3"; package main; message Person { string firstName = 1; string lastName = 2; int32 age = 3; string hireDate = 4; } Some test code: func TestBuildSampleData(t *testing.T) { person := &amp;Person{ FirstName: "John", LastName: "Doe", Age: 21, } raw, err := proto.Marshal(person) if err != nil { t.Fatal(err) } t.Logf("Raw data (%d bytes):\n%s", len(raw), hex.Dump(raw)) t.Logf("Test String: %s", base64.StdEncoding.EncodeToString(raw)) jpb := &amp;jsonpb.Marshaler{Indent:"\t"} jsonText, err := jpb.MarshalToString(person) if err != nil { t.Fatal(err) } t.Logf("As JSON:\n%s", jsonText) } Produces the following output: s11n_test.go:92: Raw data (13 bytes): 00000000 0a 04 4a 6f 68 6e 12 03 44 6f 65 18 15 |..John..Doe..| s11n_test.go:93: Test String: CgRKb2huEgNEb2UYFQ== s11n_test.go:99: As JSON: { "firstName": "John", "lastName": "Doe", "age": 21 } Using this as a baseline, if I try to unmarshal json with an extra field, I get an error "unknown field ""whatever"" in example.Person". Unmarshalling other data (a string) is met with "cannot unmarshal string into Go value of type map[string]json.RawMessage". On the flip side, unmarshalling and only specifying one field in the json works just fine. The rest of the fields are set to default values. All in all, the main difference between the jsonpb and proto formats is that proto allows for extra tagged values to be unmarshalled without error, while json does not. Most everything else is similar. 
the Gtk bindings are no where near thread safe. Hell, it crashes randomly like a dice for me.
Hi! The project seems quite promising for small teams like mine's! Is the project still maintained? Last commit was 2 years ago; possibly the development moved somewhere else?
In Golang, godocs are generated from the comments that precede the function.
I would hope that after the name of the func, the why/what/how/etc is explained to provide as much detail as possible. 
I mean in this example OP is right. There shouldnt be a why/what/how for a new method that returns a basic struct like shown here. New methods / constructors are commonplace enough that it would be overkill
I was under the impression Chi was the new Gorilla/Mux.. smaller/faster/lighter/easier with more or less the same routing capabilities?
I always thought Go was a sort of python/java/.net replacement in terms of threading, scaling, performance. C is too low level in general, isnt it? The only way Java beats C/others is the JIT that optimizes code at runtime, but it takes a bit for that to work and I think that is more for things like games or something than server side. Golang as I understand it is quite a bit more scalable and performant for things like microservices and such compared to Java, Python, and .NET. Take this with a grain of salt, just been doing a variety of reading the past few months and some of the things I have read are dated, so not sure how well those stand.
Yeah, I could literally smell a typical ,,hey your dumb I’m smart” attitude with his sentence. Should’ve just ignored it, and I think I just phrased my thoughts incorrectly because I still disagree with what he said, now even more once he admitted he never used Docker. I think there is a better way to letting someone know that he is wrong (in ones opinion) rather than saying ,,Sounds to me like your testing on prod, brah”.
It's probably worth mentioning that it's because of the way the runtime works. Golang does not exist to make performance faster for a single operation. Operations that are implemented in Go are made to be reasonably performant, which you can tell the core team is constantly working to improve upon. This can be seen in discussions about file IO access if you feel like doing some searching, look for those discussions. Where Go becomes highly performant is in the category of concurrency. It takes full advantage of multi-core systems with minimal effort to run tasks in parallel at a very cheap resource cost. If you really need speed, use Assembly.
The two bullet points are both true statements, but that doesn't mean the comment needs to be this useless. There's often more to say, but even if there isn't, this allows automated documentation to be generated.
&gt; Is there any way not to do this while keeping the linter happy? No.
I would say either the function should not exist if all it’s doing it returning a new struct of type `Server`, then the calling function could just as easily do `&amp;Server{}`. If it is actually setting up parameters for the server then the comment should state how the server is getting configured: // NewServer returns a default telemetry server that is configured to handle ssl and a time-out of 5 minutes... Etc. 
It's irresponsible to imply that either Iris or fasthttp are valid choices for HTTP frameworks.
&gt; Only works for linux and darwin OS I'd like to report that it also works on FreeBSD, and probably also the other BSDs.
That's what I intend to do. Just adding. So, what I'm doing safe? 
I've posted two weeks ago the problem was this: &gt; I'm working on a project that uses goose for a project where I use both MySQL and SQLite. However, I keep encountering [an error](https://imgur.com/a/3FFR1qP) while I did give migration access and I've found this comment in this [post](https://www.reddit.com/r/golang/comments/9p6dx2/how_does_everyone_do_database_migrations/e7zzbtl) to be having the same thing I had but still the problem is there. What I want is to give another migration access to the init and make other SQL files. Thanks in advance, I'm actually quite new to this and any help is much appreciated. And while I'm at it, the migration worked in the open source way. Why I was doing new migration was to make my tables added. However, I only wanted to do the addition part not the modifying and it didn't show any errors...
lots of code uses that way of creating the constructor that golang doesn't have
As I said in my other answer, I've never used Docker for testing as it is not useful in our business. We're running networked services, but on our own hardware and with our own proprietary protocols. Orchestration software is generally something I care very little about as I do not tend to find scaling up useful in my job. We make devices that have a global market of about a hundred thousand, and which may connect to the on-line backend about once a month.
 comment on exported function NewServer should be of the form "NewServer ..."
&gt; Gowitek is a leading Golang Development Company and still does not know that our favorite language is called Go instead of Golang
If you can't do c++ or rust I suppose it's better than nothing. But with articles like this leaves an impression that some programmers pick Go not because it's actually most optimal solution but just because they like the language. And that a major flaw many even proficient programmers have. For example Rob Pike, one of Go inventors at Google shared in langnext 2014 panel, that there are now plenty of things written in Go when C++ should have been picked.
`// NewDefaultServer :` `func NewDefaultServer() {` `}` IMO this is acceptable in some cases. It tells me that *in this case* there is nothing unexpected to note which isn't already indicated by the name of the function. Mostly, I'd agree with gdey, but I'd rather add this minimal comment than become desensitized to linter warnings.
I usually just do: // NewServer ... if there is nothing special in there, if something changes and I put some small amount of logic in there I add that to the comment. It’s not a lot of overhead and I don’t have to worry about warnings. If it’s a service and I tie together different resources I describe what the whole service is about in that comment.
This comment is four months old, does the same still apply?
``` // NewServer returns a new Server with every field set to its // default value. This function is useless, just write &amp;Server{} // instead. func NewServer() *Server { return &amp;Server{} } ```
It's not GC it's just the runtime. 
This doesn't look like an exported function. What the hell are you talking about?
This is the error message `golint` gives back, when I put in OPs example. You know, I actually tried it.
Yes, It is.
I'm going to PM you to see if we can get this bug fixed
I deployed a snippet to [jsgo.io](https://jsgo.io) so you can try it in your browser &amp;#x200B; [https://jsgo.io/c95d11902ac9464c57697e6363b5bf6371945bf4](https://jsgo.io/c95d11902ac9464c57697e6363b5bf6371945bf4) &amp;#x200B; source code: [https://play.jsgo.io/2e3ae93fde592ec6e8d0f09b5cd39eaa66d538e4](https://play.jsgo.io/2e3ae93fde592ec6e8d0f09b5cd39eaa66d538e4)
That's ok :) This is just a PoC you can do whatever you please with it
thank you :)
as a ops person that is a very bad way to do it 
I'm glad you made text version of this [https://www.youtube.com/watch?v=SonwZ6MF5BE](https://www.youtube.com/watch?v=SonwZ6MF5BE)
Yeah, that'd make sense. We didn't run test on other linux variants to put this in README. Travis CI also doesn't support FreeBSD.
Yes. It is called "correctness" and "safety". C offers less on these two things and can thus be faster. The fastest language just output 0 for all calculations, segfaults on the first instruction and compromises your machine. C is a **much** slower because you _can_ write a program which does not segfault and produce a correct result. Go is a tiny bit slower than C (if compared to the fastest language) but it is _much_ _easier_ to write a program which does not segfault, result in a correct answer and does not compromise your machine. 
Gin looks pretty simple. Its good. 
Why? I have always found react easier to reason with, than a templating language server side.
It's for godoc. godoc basically change these comments into documentations. You can read more about godoc here:[https://godoc.org/github.com/natefinch/godocgo](https://godoc.org/github.com/natefinch/godocgo)
But developers see a golint warning and add a useless comment just to appease it. It may even be a policy that code with warnings can't be deployed to prod.
His example is an exported function given the function starts with a capital letter, so the linter will complain if it's not commented.
Indent with 4 spaces for blocks of code. E.g. func main() { var Wg sync.WaitGroup // to wait for the goroutines to exit Done = make(chan bool, 1) updater.Start(Wg, Done) // if new exe appears, we restart ourselves to run it // your stuff here that runs forever until 'Done' is closed } 
Given the example, if you're not overriding any default values for fields in the type, then a constructor is overkill. Just comment the type, and let the consumer do `s := &amp;Server{}`. If you are setting fields to non-default values in the constructor, then commenting the function as required by linting, you'd document what was being set instead of the default values.
&gt;The Go linter expects every function to have comments I switched from using golint linter to golangci-lint linter which doesn't insist that you comment all exported functions. You might want to give that a try.
Yeah, that's what the error message states ;-)
Just pointing out that the way you embedded your code block is not working on [old reddit](https://www.reddit.com/r/golang/comments/b0wm7z/is_this_really_a_convention_in_go/eihvaq2/) I think putting four spaces at the start of each line works on both Test: // NewServer returns a new Server with every field set to its // default value. This function is useless, just write &amp;Server{} // instead. func NewServer() *Server { return &amp;Server{} }
Just realised I replied to the wrong comment! My bad. :)
I think the *actual* reason for short and quick comments like this, in Go, is so that it can be parsed for documentation, moreso than explaining what the next bit of code is doing. So although the comment is overly simplistic and only stating the obvious when looking at the code, I think the more important function of being parsed into actual documentation will put it into a reasonably sensible context. 
I understand why people do the US address thing but it looks a bit corny coupled with an Indian phone number. 
Cool! This looks like you have a fun, interesting, and exciting business! I would love to learn more about how Go is used on devices (Raspberry Pis, ESPs, etc.) Have you built or do you use any publicly available packages? 
what happens if you type the following?: $ cd $HOME 
Can you elaborate on this Swagger integration? What kind of tools are you using to generate code, how it handlers API changes?
I think it comes down to two things: * are your program's needs static * is your initial domain understanding complete If and only if you can answer yes to both these questions, then you should reach for type-proofs and the languages that support them. If, however, you are either chasing a moving target or you don't know everything you need to know about the domain initially, then your solution is more iterative than deductive. -- I've been [re]reading prior art in this tradeoff/dichotomy since you posted this (thanks by the way). I'm late to the conversation but hopefully my conclusions can help someone. Best of the 100s data points I traversed * [Worse is better](https://en.wikipedia.org/wiki/Worse_is_better) * OOP vs DOD (data oriented design) * [reddit discussion](https://www.reddit.com/r/programming/comments/9t3tfi/dataoriented_design_vs_bythebook_oop_outside_of/) * [blog post](https://passwork.me/info/blog/applicationdesign) * [Cycles of paradigm popularity](https://news.ycombinator.com/item?id=10294908) * [Bug density by language](https://labs.ig.com/static-typing-promise)
The standard net/http package can already handle HTTPS requests: [https://golang.org/pkg/net/http/#ServeTLS](https://golang.org/pkg/net/http/#ServeTLS)
Since you are using Go 1.7 you have to manually set you gopath. Add this to your `~/.bashrc` file export GOPATH=~/go/ You can set it to whatever you like ofc. Please also install a more recent Go version. Only the latest two are supported (1.11 and 1.12). You can get Go 1.12 by go get golang.org/dl/go1.12 &amp;&amp; go1.12 download and then add `alias go=go1.12` to you bashrc file. Cheers.
This is great news!
https://github.com/fabiolb/fabio 
Is there a specific reason why they chose dep instead of go modules?
Please search next time. https://www.reddit.com/r/golang/comments/af721g/why_is_golang_not_as_performant_as_c_or_c/
Might want to have a look at Caddy ([https://caddyserver.com/](https://caddyserver.com/)). It seems to do what you want. It has directives for reverse proxying and automatic https form LetsEncrypt if you don't turn it off or provide your own certs.
It does help me. It's an interesting collection of links, so thank you. With that said I tend to disagree about your two questions. A programme's needs need not be static. If anything, _some_ form of verification makes it easier to make non-breaking changes quickly, whether this takes the form of static typing, a test suite, or a state-of-the-art SAT-solver.
I think this website covers a lot what you asked about: https://gowebexamples.com/
Im ok with that ! If your comment is useless so your function is probably useless too. Convention comment provide a great comprehension code. Dont loose Time to search exception. Juste Ask you if your function is useless
Just guessing: maybe there were no go modules when they started development and they didn't bother to switch?
Yeah, mgo did a a great job until the last MongoDB major version, but it's even better to get an official lib
I already looked at caddy. I just want to write it on my own for the learning experience.
thanks. I know that already. I just wanted to write a proxy for ssl offloading for the learning experience.
Oh, OK. In that case you'd to dig into the SSL/TLS protocol and see how the handshake, key exchange, certificate stuff, etc. is being done and handled. Basically, when the connection is opened you first establish a secured SSL/TLS communication and via that communication channel you do normal HTTP protocol. Given I understood it right, now :-)
If I understand you correctly, this is my failure in communication rather than our disagreement. My argument is: * abstraction increases rigidity * some problems are less rigid * thus unstable problems require less rigid solutions, solution creation paradigms, and solution validation paradigms finally * types are more rigid than code * go encourages validation via code rather than validation via type (proofs) * thus go chooses to better fit for less rigid problems
I completely missed passing in the chan! Thanks for the tip. You're right that buffering all the channels might also fail if a channel gets backed up and blocks the main goroutine. I think you'd need to check for full channels. Something like this: for _, ch := range dataChannelSlices { go func(ch DataChannel) { select { case ch &lt;- data: default: fmt.Printf("Channel %v is full. Discarding data=%v\n", data.topic, data.data) // Or add more consumers for this chan and retry // Or add to backlog chan }(ch) } 
yep you did :D Thanks for the help
Iirc gin is for webservers, it inject PORT envvar and expect you to use it to bind, while he act as a proxy
have you tried fresh?
https://github.com/teamwork/reload works well for me (I wrote it).
It's in the roadmap, just wasn't included in the 1.0.0 release. You can follow the ticket for it here, if you'd like: [GODRIVER-543](https://jira.mongodb.org/browse/GODRIVER-543).
+1
That depends on right to work in the UK - unfortunately we're unable to sponsor visas for this one! 
Line 34 in Publish function passes chans which will be used by the goroutine without the lock. &amp;#x200B; LINE 42 in Subscribe function appends to chans assuming a lock. &amp;#x200B;
Now that is slick. My thought is Rest APIs with JSON (rather than trying to get consumers like JS/React developers to use Proto JS library), and converting JSON to Proto to send to services either via grpc or as payload in MQTT (more likely). So my thought is, the incoming JSON would potentially have more data in it, maybe not, but potentially. Can I convert the "more data" json directly to a .proto object that has less fields than the json, and the conversion simply ignores any extra fields in the json? I assume the answer is yes based on the reverse of what you did/said above. Like I said, most likely I would hope the JSON req payload has just the data needed by the back end service. But I can see where we may have a Rest endpoint that would call 2 or more back end services, where the incoming json contains parts of the data that is "broken down" for each service. However, after some more reading, it seems in this case, it would make sense to have a back end service handle all the multiple service calls. What I mean by that is, lets say creating a new user sends out a verify email, and updates two other services in the back end. The POST /users call contains name/address/email/phone/etc. It seems microservices architecture would have an API microservice that would then send that payload json data (as proto hopefully) to a backend service (async) that then aggregates the multiple service requests and responses. The front end API handler would return right away (202 most likely in this case, or if it was using websocket, some indication status that its received and in process). Once the back end service gets all the responses from multiple other services, it then responds back to the API service (which would have a listener in it as well) the results. Make sense? 
Yah, def need the go module support! &amp;#x200B; Is mongo still used a lot today? Seems the nosql movement has kind of faded and either ORM or direct SQL based DBs are back in the path.
This is one area I'd like to see Go do better with, sometimes people allow \`var s Server\` and lazily initialize with sync.Once (if necessary at all), sometimes people use constructors, sometimes accepting Config structs, sometimes functional options. &amp;#x200B; I'd say \`var s Server\` is cleanest if you can get away with it, but at the same time it becomes unclear at the API / documentation level that you should just use the struct itself, I find I'm usually hunting for a \`New\*\` but maybe that's just me.
The correct response is to fix the comment to be useful, not to remove the requirement to document your exported functions.
Definitely still used. Although maybe not from go primarily. 
All grok implementations compile the patterns to a regular expression. The PyPy regex package is faster than Go's. https://github.com/golang/go/issues/26623
I'm the only one who is annoyed since it seems they does not support the mgo interface? 
The kubernetes codebase is littered with this kind of stuff, I always wondered why.
Got it now, it seems a real issue thank you. But i think subscribe method is ok, publisher have the issue. In real life scenarios a Set would be used instead of a slice. It can be solved in that scenario :)
that explains it. thank you
Why would you rather use go modules than dep?
A bit late, but I just finished the game. The Bear’s story was so touching and reminded me of my own experience. Thank you so much for this game. It really made me think and reflect personally. 
mgo wasn't an official project and the owner wasn't using Mongo anymore and finally decided to stop support.
if you actually read the comments of that issue you know your summary are not really true. Also https://swtch.com/~rsc/regexp/ (which is also mentioned in the comments)
I don't say it's a bad choice per see, that's why I asked if there are any specific reasons. My understanding is that the community's best practice is versioning of dependencies via modules
Are you saying that PyPy regex isn't faster than Go's?
I'm saying the benchmark result from the issue you linked cannot draw that conclusion because it included regexp compilation time. Also there's no such thing as language A's regexp is faster than language B's, you can only say "language A's regexp is faster than language B's in this case", the link I gave explained that part (Go's regexp implementation scales linear with string length, while python's implementation doesn't scale that well).
Ok then, PyPy's regex package is faster than Go's is almost all common use cases.
&gt;export GOPATH=\~/go/ none of those suggestions worked. I added the changes to the bashrc file still same error. Debian Stretch seems to have golang tied to golang1.7 even though they do have golang1.8 in the repo and can be downloaded. If I try to uninstall golang1.7 it uninstalls the main golang package and go commands then don't work at all. The command to download the new version with go get does not work hence my original question :). 
I tried it and does not work.
because it's the official solution with seamless support built into the compiler, and it's much faster.
Go 1.12 massively improved the inliner. We had noticeable improvements in some of our projects, so much so that I had to double-check it. I'm sure there's still room for improvement, but they are definitely improving it.
Right.. it is just that a few years back mongo was everything.. companies were stammering to jump the SQL train to noSQL and mongo. Now I dont hear about it that much any more. I suspect part of it is those that were so eager to just jump on the latest/greatest finally learned that mongo and nosql has its place, but it isnt for everything.
Perhaps what's stopping that handful of [tiny tiny toy Go programs](https://benchmarksgame-team.pages.debian.net/benchmarksgame/why-measure-toy-benchmark-programs.html) from being *"as fast or faster than C"* is the way those particular programs are written? 
OK, so do you literally have the following line? : GOPATH="/home/user/go" ^^^ If so, that's the issue. Unless your username is 'user' this is why it's failing. I define mine like this (literally): export GOPATH=$HOME/go Using $HOME will look for whoever the current user is, rather than a literal user name. After modifying this, type: $ source ~/.bashrc That should reload it, and be good to go. Let me know if that helps, or not. 
The main problem with inlining is that it is based on a cost threshold per function. IMO, it is a bad decision for several reasons: first the threshold can change on a Go release basis (it happened before). Second, a small change in your code can make your function cross the cost threshold one way or another (very unpredictable). Third, developers are going to try and write their code in a special way to stay under the cost. Finally, this mechanism will not inline "big" functions that may be in the hot path (bringing us back to my 3rd point). So, yes there is still room for improvement with the heuristics. I wish the developer would have the ability to give hints to the compiler. Use go test -gcflags="-m=2" 2&gt;&amp;1 | grep "too complex" to see which functions are not inlined due to cost.
 func isString(fl validator.FieldLevel) bool { _, kind, _ := fl.ExtractType() return kind == reflect.String } This is pretty basic stuff.
I started writing my own because I felt I have the experience and thought it would be fun, but after two evenings of work I started to think about all the features I'd like from Caddy and abandoned ship. Certainly it's fun though. Server and network tools are my favorite. :)
Sure, there's a lot there. Most of them look reasonable though. I did a comparison with 1.11 and it's inlining a lot more of just the application code. However, the biggest win is that it's inlining all of the calls into the logging framework (zerolog). It would be great if that could be explicitly flagged to always inline, yes. It's still a lot better in 1.12 than 1.11. I don't remember the specifics but it was something like 30% latency improvement at the cost of ~2 MiB larger executable.
&gt;source \~/.bashrc export GOPATH=$HOME/go was already their and yes my user name is user. Is that the issue because none of these suggestions are working unfortunately. I even tried this [*https://golang.org/doc/install?download=go1.12.linux-amd64.tar.gz*](https://golang.org/doc/install?download=go1.12.linux-amd64.tar.gz) and it did not even install it said command not found for go. This is one weird language. I have messed around with python and php some and I have never seen a language install from the repo that fails to work in the basic functions. 
OK, this problem is certainly down to your environment variables. your user name being user should not be a problem, assuming all the directories you're using and pointing to actually exist. Frankly, the installation of Go is VERY simplistic. All you have to do is drop a copy of the binary in a location, create a path to that location and it will work. The second part of the installation is setting up your own workspace, which consists of creating some directories, and creating paths to those. By doing this yourself, you're forced to learn how your OS and the compiler work a bit. And there's no hidden or mysteriousness to the installation (which would make it a bit sketchy) That said, please double check that the directories exist. And, please specify exactly where you've installed go (`/usr/bin/go`) and where you have created your go home dir (`$HOME/go`, `~/go`, `/home/myusername/go`) Then compare these to your `go env` results. And also check your path variable (`echo $PATH`) to ensure that the go binary is in the path somewhere. Finally, are you familiar with how bash loads initializes itself? Check this reference if you can use a reminder: https://superuser.com/questions/789448/choosing-between-bashrc-profile-bash-profile-etc 
I'm in favor of keeping the "factory function" instead of calling &amp;Server{} directly just because later you might want to initialize your structure in some way. The compiler inlines that anyways, so you're paying the price of a function call by using the `NewServer()` initializer, and it makes code more clear (and easier to later do some initialization if necessary - let's say, specify a custom port, etc). You can still document how to configure the behavior of the server (or make it explicit that it can't be configured), etc.
I now remember having had a similar issue on debian. I think you have to manually add you go version `go1.7` to `/user/lib/go/VERSION` or something similar.
How does it not look like an exported function? It starts with a capital letter.
Go 1.12 just released
@[jasonscheirer](https://www.reddit.com/user/jasonscheirer) it does not work. I used `fl.ExtractType(fl.Field()).` The problem is that it is returning empty string for { "_p_createdBy" : true } which will always return true. Can you have another way?
New to golang, wonder if someone could help with general module use: I have a github repo that contains my main file, and then a folder containing two folders for interacting with 2 separate apis. Should both of those folders for the separate apis use modules? I plan on having the main go file turn into a handler that can run as a go function on google cloud platform. Essentially: - main.go - apis (folder) - api 1 (folder) - multiple go files - api 2 (folder) - multiple go files
True. Pick the right tool. Mongodb is quite successful in it’s space. 
Only if you can actually share some code. I have no idea what you're doing wrong.
I am struggling to think of a problem with the existing informal Go meetup universe, which is solved by formalizing a "Go Developer Network".
So, currying functions?
Ok but I mean, is definitly still used a lot. Transition would be much more less painfull IMHO :)
Because dep is really slow on moderately sized projects. Go modules is much faster
Ah, I'm thinking about CGO which requires syntax like this, because we're talking about the comment: https://github.com/protosam/go-libnss/blob/master/shadow-nss.go#L31-L39 The fact that he's having to put the function name first in a comment where the godoc would be is completely arbitrary. 
Go linter only expects this for exported functions. Do you mean for this function to be exported?
Yeah, but it shouldn't care about the function name at the beginning of the comment. There's nothing in any spec I've seen that wants that. 
It's not a spec. It's not go fmt, it's just golint. If you use it, you use it. You don't have to. It's something you might want to add to your CI or your editor. You just want it to warn you, you don't want the build to fail, because you forgot to comment in a hotfix.
What are some constraints that makes him think C++ would be a better fit for a project?
I think if you use the files inside the api folder to build or run or use any go tool then yeah they need to use go mods if they are outside the gopath. I am also very new so I might be talking nonsense in which case disregard what I am saying. 
All of these live within $GOPATH/github.com/my_username/repo/
You can check the whole video here: [https://www.youtube.com/watch?v=BBbv1ej0fFo](https://www.youtube.com/watch?v=BBbv1ej0fFo) Due to the agenda of the event he did not went into the detail. However expressed the though nearly word for word at the Q&amp;A section if I'm not mistaken. I can only guess, reasons may be numerous. Too slow for lower level programming, garbage collected, run-time which may conflict with pre-existing environment, go-routines while cheap on their own requires fat runtime to work as any green thread implementation, fat std lib (I'm not sure if there is idiomatic version of Go with gutted std lib). I liked Stevens Klabniks comparison of Go vs Rust. Which is not a very fair comparison, apples vs oranges really. But Go is a high level language which attempts to reach down to systems level and rust is systems level language which tries to reach out to higher level abstractions. I mean the answer is not that hard to reasonably speculate accurately.
thanks man!, logo was made by https://gopherize.me/ :)
Was there ever a video of this talk??
I uninstalled 1.7 and install 1.8 and I saw this [https://stackoverflow.com/questions/21082664/golang-command-go-not-found-when-running-via-upstart](https://stackoverflow.com/questions/21082664/golang-command-go-not-found-when-running-via-upstart) someone suggested running from binary and I have tried to do that and now it seems to work but the particular github is not building correcting but I think I can at least run go. Thanks for your help. The command *exec /usr/lib/go-1.8/bin/go seems to work.* 
No, they're simply different packages. You'd want them to be modules if they had different dependencies than the main modules (the one with `main.go`), and/or you wanted them to be installable without including the main module's dependencies.
Relational databases are also getting a lot more nosql type of storage features too(ie postgres). For most organizations, having a table with a json column type gives them most of the benefit of a nosql db without having to do a full migration or supporting a new tool and the associated infrastructure. 
Thanks that looks really useful!
You are talking nonsense. :-) Structure should be parent parent/projectname parent/projectname/go.mod parent/projectname/go.sum parent/projectname/main.go parent/projectname/api1 parent/projectname/api1/files.go parent/projectname/api2 parent/projectname/api2/more_files.go Traditionally, parent had to be $GOPATH/src or if $GOPATH is unset, $HOME/go/src, but with Go modules, it doesn't matter anymore. Projectname by convention is a URL-like path that can be used to download the project if it is open source, e.g. github.com/user/myproject as sub-directories, but this is not necessary if you aren't going to open source the project.
OK, so you probably need to add /usr/lib/go-1.8/bin/go to your path... so you can run `go` from anywhere on the system. After you get that working, you can correct the path to the specific versions. Maybe you create a link to /usr/bin/go for simplicity sake? Each distro has it's own way of installing things... That way may be different from the "go way" but the beauty is that you have ultimate control over making it work how you want it to. 
Nice blog post! You may also want to include `-mod=readonly` in your CI script so that you get errors if you make a change to your source that requires modifying the go.mod file (like adding an import).
It can be helpful if you're replacing existing code that has a URL hierarchy that uses features that gorilla supports, but the built-in one does not. When creating new sites, I prefer to just stick with what the default library offers, and sometimes a couple of helper functions for URL-based parameters if that's desirable. (It's not such a complicated feature that it needs a whole library, IMHO.)
We commit our vendor directories at work and unfortunately, the vendor created by `go mod vendor` is much, much larger than that of `dep` since `dep` prunes, but go doesn't :(
More HTML crap; yawn. I wish there was a usable real UI library for Go. There are a few but I always ran in to issues with stuff missing pretty fast :-(
I would recommend not using \`go mod tidy\`. It pulls in all dependencies for your dependencies, including test dependencies. From my experience, that seems to cause more trouble than good as I have had issues where import paths for projects in test dependencies were renamed and \`go build\`, etc would break because of an issue with the modules. I am currently using \`go list ./...\` as an alternative to populate the go.mod file with just the things the project needs.
nice thanks :+1:
there are never any cool meetups or conferences in florida.
This. If it doesn’t actually add any defaults or configuration, this function isn’t needed. 
Pointless constructors are pointless, though.
Fits my use case.
Much to my surprise, I agree with almost everything - #1 definitely, #4 not so much.
yeah, adding a new table is always safe, provided you're not involving it in any foreign key relationships with existing tables. 
Appeasing a linter is not a valid programming style. It tends to indicate the linter might need to be modified.
hmm, it could be managing dependencies. If Server supports an interface that the function caller knows about, and this package is implementing that interface with Server, then this would make sense.
Regarding #2: Doesn’t Go schedule goroutines on a number of underlying OS threads matching the number of CPUs? This means that the Go runtime already does in the first example what he tries to do by himself in the second. IIRC a goroutine will run uninterrupted until completion (or until blocked by IO, channels or similar), so you basically have cooperative multitasking (not preemptive) between goroutines running on the same thread. He does have a point however that it’s more complicated than necessary compared to e.g. Java.
this. At least that comment should have some explanation about why it's needed and what it does differently to `s := &amp;Server{}` but I'm as guilty as most gophers for not commenting my exported functions properly. It's definitely a common thing. and I have found the golint's insistence on this annoying but necessary - there have been times when its annoying insistence has lead me to start writing a comment and then realise that an explanation was actually really necessary for that function.
[https://floridagolang.com/](https://floridagolang.com/)
I gave modules a try today and immediately hit bugs trying to add the client_golang package from Prometheus and the gosec linter :(
I probably spent a solid 5 months trying to decide between rust and go for migrating our PHP app, which has clearly outgrown its roots. Ultimately it came down to #1 on this list -- lack of fp. The iterators in rust are very similar to the Array methods I'm used to in js, and everything in Go just felt too procedural. I think the startup cost to writing new things from scratch is orders of magnitudes higher in rust, and they're both good at concurrency in different ways, but once we have established patterns that can be farmed out to the juniors being fp-heavy helps a lot.
Thanks
Yeah, but the modules are the same
Yes indeed. Go modules will be enabled by default in the next release, 1.13. I'll update the post to specify this! 
Seems like a good practice, I'll update the post with this, thank you! 
First example is O(N^2), which is a pretty good example of why FP is dangerous if you’re not paying attention. 
Which bugs did you encounter? I use the prometheus libs in different projects all using modules and never had an issue. 
Just curious, why the need to commit the vendor dir? 
Lack of functional programming? 😲 I wonder why that could be
Dude... Coming from Groovy / Java / Python / JavaScript I'd agree with pretty much you stated here...
Maybe try explaining rather than being snarky? You aren’t helping anyone with this comment
Author states they don't want generics in Go. Author goes on to mention something missing that's impossible with Go's syntax without either generics an unhealthy dose of reflection, and even with either would be highly verbose. &amp;#x200B; Go is too verbose to efficiently write functional code.
I think OP is implying that the work is very cpu bound which would mean they want to match it up to the available cores so that workers aren't waiting for cpu time. 
I kept getting the error: “go get: error loading module requirements” and higher up I saw “go: github.com/golang/lint/@v0.0.0-20190313153728-d0100b6bd8b3: parsing go.mod: unexpected module path “golang.org/x/lint”” no clue why though or really what the error means
&gt; The problem with the above firstly you need to use an old school for loop. Use a range and the above will not do what you expect, with the output being the same as the input. I didn't understand this comment. A range would have worked fine as well: https://play.golang.org/p/mDlGJvg-iH6 
I guess that's why the team decided to go with something a lot of people are familiar with, reducing the bar for adaptability and having a stable already agreed on standard. 
I think he talks about this https://github.com/robpike/filter.
Release note: &gt;go1.12.1 (released 2019/03/14) includes fixes to cgo, the compiler, the go command, and the fmt, net/smtp, os, path/filepath, sync, and text/template packages. See the Go 1.12.1 milestone on our issue tracker for details. 
If a remote repo I dont have any control over gets deleted, I dont want to be scrambling to find an identical source especially if in the middle of deployment or something. This has already been learned in more mature ecosystems, but look into something like go-bindata a year ago for a go specific example. Or, left-pad from node.js, another situation where vendoring would have helped. 
How about this? I've run into the issue myself before and wasn't able to resolve it: &amp;#x200B; [https://stackoverflow.com/questions/55171764/how-do-i-use-a-vendored-argument-to-a-function-in-an-external-package](https://stackoverflow.com/questions/55171764/how-do-i-use-a-vendored-argument-to-a-function-in-an-external-package)
The problem with it is that you're loading a huge amount of stuff just to ... display a bit of text and buttons? I'm not *against* this kind of stuff as such, there is a place for it. But for many desktop apps native UI libraries are a better choice.
&gt; The problem with the above firstly you need to use an old school for loop. Use a range and the above will not do what you expect What am I missing? toProcess := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} var wg sync.WaitGroup for i := range toProcess { wg.Add(1) go func(j int) { toProcess[j] = someSlowCalculation(toProcess[j]) wg.Done() }(i) } wg.Wait() fmt.Println(toProcess) It does what I expect, and functions the same was as the original code.
I think the author doesn't quite understand the basics of the go cooprerative scheduler and effectively* reimplements his own to ensure that its one goroutine per core to avoid the issue that preemptively interrupted threads would have. *Goroutine might yield on syscalls, go statements, chanel operations and non-inlined function calls.
SIMD/GPU is great for numeric computation, but won't help you at all if the steps involve I/O. For example, if you're fetching a bunch of URLs. 
Point #1: I don't want generics but I do want this thing that is most easily solved by adding generics. 
“What is going to be a problem is that each one of those go-routines is going to fight for a slice of the CPU. As such this is not going to be the most efficient way to perform this task.” I’m going to politely refer to a William’s Kennedy video on this topic. https://youtu.be/OTLjN8NQDyo He basically test this and finds no difference (or at least not much gain) on restricting goroutines to the number of cpus. You should measure this and see what you find out
As someone who has had to debug other engineers functional code, I don't really agree with (1). I think for a personal project all bets are off. Do what makes your life easier. But for a team project I'd much rather have code that is depicted in the GO example. If I'm on a multi-language team there isn't a single thing I need to lookup to understand how the GO example works. For the Java example I need to look up and read about stream and collect, and possibly filter, to understand what the output is going to be. It'd be nice if more "basic" tasks were available natively in the go library. Which we may get when Generics make their way in the future. But obfuscating away the intricacies of what code is doing doesn't make it more elegant IMO.
Not yet.
I will try.
Fetching URLs is something Go is great at because it handles async thread mapping the connections automatically.
Why are you building source in a deployment? That seems far more terrifying. We commit the vendor dir because it's too hard to proxy everything through artifactory. Mostly because the enterprise team is too stupid to set up artifactory correctly to do it. 
I think the way you're forced to handle errors in Go is fantastic, but I agree with you that having to type all the boilerplate error handling code is a drag. Fortunately, it looks like this and some other issues with errors may be addressed in Go 2. Check out the design for handler/check: [https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md#draft-design](https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md#draft-design) &amp;#x200B;
I think he understands it but is trying to minimize the overhead of creating goroutines across a (presumably very large) list. It may be very small overhead but it is non-zero
Just upload your code. They can download the dependencies directly. Also, use Go 1.11 modules. That way it ensures they download the same module versions when compiling it. 
If you think a little this is pretty common. A dire bug is found in prod, time to rush out a bugfix, lets quickly build a new docker image and deploy it... Oh wait somebody deleted a git repo and the docker image cant find the dependencies during build time, hence no deployment. Docker images dont magically make the source not matter.
Well, I usually build in the build step. Then it gets through testing, and approvals to be deployed. Then there's the actual step to deploy the artifact. I never said anything about Docker. I'm just saying your process is fucked if you don't have a successful artifact ready before it actually becomes time to deploy. Do you clear your build workspace between every build? You don't cache anything? If a repo is gone, nothing should be affected since we've cached the vendor and build dirs to reuse between builds. I'm used to working in regulated industries where you can't just say "I'm going to deploy this fix I wrote myself directly to production." So the idea of building a new one during deploy is insane to me. 
Process... What a nice word... Could probably use more of it. Anyway, not all workplaces have layers of process for each build, and just the fact that not vendoring your dependencies requires a whole lot of said process to already be in place before it becomes sane is enough proof for me. 
Hi I updated it. Can you check now? 
I said I do vendor my dependencies you weapon. If you can't follow the conversation, sit quietly. 
Calling someone a weapon is an unique insult. I will admit i thought you were the other guy.
bad article is bad.
maybe give it a shot. it's super easy to set up. 
[https://github.com/zephinzer/godev](https://github.com/zephinzer/godev)
[More interesting](https://github.com/golang/go/issues?q=milestone%3AGo1.12.1): [misc/cgo/test: failing TestCrossPackageTests [1.12 backport]](https://github.com/golang/go/issues/30816) [cmd/go: duplicate symbols when including two main packages in -coverpkg in module mode [1.12 backport]](https://github.com/golang/go/issues/30684) [cmd/go: module loader looks for the wrong tags if the "go-import" prefix includes the major-version suffix [1.12 backport]](https://github.com/golang/go/issues/30665) [path/filepath: EvalSymlinks, incorrect traversal of relative paths [1.12 backport]](https://github.com/golang/go/issues/30586) [os: RemoveAll doesn't remove nested un-readable directories [1.12 backport]](https://github.com/golang/go/issues/30579) [cmd/compile: function inlining produces incorrect results in certain conditions [1.12 backport]](https://github.com/golang/go/issues/30567) [cmd/go: error if GOCACHE is set but is not an absolute path [1.12 backport]](https://github.com/golang/go/issues/30493) [fmt: map printing sort does not deterministically sort differing types [1.12 backport]](https://github.com/golang/go/issues/30484) [cmd/compile: KeepAlive doesn't actually keep stack object alive [1.12 backport]](https://github.com/golang/go/issues/30478) [sync: random errors on sync.Once running on MacOS Mojave or High Serra [1.12 backport]](https://github.com/golang/go/issues/30470) [cmd/vet: Consider reverting tag conflict for embedded fields](https://github.com/golang/go/issues/30465) [text/template: panics on method on nil interface value [1.12 backport]](https://github.com/golang/go/issues/30464) [cmd/go: error if GOCACHE is set but is not an absolute path](https://github.com/golang/go/issues/30447) [net/smtp: SendMail AUTH error with PlainAuth and successful STARTTLS](https://github.com/golang/go/issues/30403) [fmt: map printing sort does not deterministically sort differing types](https://github.com/golang/go/issues/30398)
Yep, I was trying for webserver only.
Recovering deleted message by /u/bmurph15 --- Why is the function below, that unmarshals a pbf from a raw bytes consistently 100x faster than an unmarshal on the actual pbf struct than shoves it into an implementation struct?? Am I doing something wrong in my implementation? Both functions produce identical structs. Also its not the other struct initialization causing the slow down the marshall is &gt;95% of spins. // reads a raws frame func ReadRawFrame(bs []byte, startpos int) *Frame { var offset int var latitude, longitude float64 frame := &amp;Frame{} mypbf := pbf.NewPBF(bs) for mypbf.Pos &lt; mypbf.Length { key, typeval := mypbf.ReadKey() switch { case key == 1 &amp;&amp; 0 == typeval: frame.Count = mypbf.ReadVarint() case key == 2 &amp;&amp; 0 == typeval: frame.Timestamp = mypbf.ReadVarint() case key == 3 &amp;&amp; 1 == typeval: latitude = mypbf.ReadDouble() case key == 4 &amp;&amp; 1 == typeval: longitude = mypbf.ReadDouble() case key == 5 &amp;&amp; 2 == typeval: frame.Street = mypbf.ReadString() //cont... } } } Also the library used to serialize / traverse the pbf struct is just a small library for reading through pbf primitives I wrote.
&gt; First example is O(N2), which is a pretty good example of why FP is dangerous if you’re not paying attention. This. The particular complaint boils down to "I want to write very bad code in a code golf manner, so nobody notices". Personally, I'm so glad Go "way" screams "the king is naked". The author lost me at that point. 
Looks like a great release! I'm going to check it out
Wow, great work!
Is there a "usable real UI library" that is available for C++, but not for Go? For Java? Which one is it?
How well do you know tview? I need to trigger the redraw of a textview on a keypress and have the "mode" change from one to another on each F1 keypress and have the text in textview update accordingly but i don't know what's the issue i'm facing. Here's my code if you or someone else can take a look at it. https://hastebin.com/egowikapax.cs
1) initialize the git repository in your “my-project-for-github” directory 2) vendor your dependencies so there’s a vendor folder in your directory 3) check in your dependency folder too 4) push to Github If you want to use Go modules it’s a bit different but in general it’s not a bad idea to include your dependencies in the project.
&gt; (2017 words) You could have added just two more words! This makes the article feel so... 2017. ;)
Did you try to import `golang.org/x/lint` as`github.com/golang/lint`?
*Eyy, another year! * It's your **10th Cakeday** ihsw! ^(hug)
Yes this is doable and there are several such libraries which are available. However we do not have any such libraries currently. 
&gt;This is defaulted to 1 When this articles was written? It's defaulted to a number of CPUs in all recent Go versions. &amp;#x200B; &gt; After being stopped for garbage collection cycle Goroutines cannot be stopped. They can only yield execution, even to GC. If some goroutine happens to be in a tight for loop then GC wouldn't even be able to run. Eventually all other goroutines will yield execution and application will lock until left over goroutines reach a preemption point. It could actually be any non-inlined function call. You can observe this with the following example [https://play.golang.org/p/XmNRoMLQExR](https://play.golang.org/p/XmNRoMLQExR) On my machine after about 8 iterations the loop stops and never resumes. &amp;#x200B; &gt; This is better than pre-emptive scheduling It's not. Cooperative execution doesn't allow you to properly schedule threads exactly because they can block and never yield execution for a long time even in a properly written application. We're just lucky that most applications eventually reach a preemption point and everything seems to run smoothly. But there're corner cases and bugs due this, which is why Go team is moving to preemptive scheduler. There were experiments with inserting artificial preemption points in tight loops but it didn't work out.
Don't know why I'm being downvoted, it's a legitimate question, because I simply don't know. Thank you for clarifying. 
I hate SO MUCH the new GoLand... Every time I close and open it there is something new that has been moved from it's place. I'm really considering moving to VSCode
&gt; Modules must be semantically versioned according to [semver](https://semver.org/), usually in the form v(major).(minor).(patch), such as v0.1.0, v1.2.3, or v1.5.0-rc.1. The leading v is required. https://github.com/golang/go/wiki/Modules#modules
 go get -u github.com/foo/bar@v4.2.1
So many goodies! Vendor support and predefined sublimetext keymap (I had to add my own). Integrated alternative profilers. 
New issues which got closed do not come up in the `new issues` list. Just search for a newly opened and closed issue and find it in the closed section only.
&gt; Regarding #2: Doesn’t Go schedule goroutines on a number of underlying OS threads matching the number of CPUs? Since Go 1.5 there are as many schedulers as there are logical cores on the system, but creating &amp; switching goroutines is overhead so if your work is CPU-bound and *especially if there is very little work per item* (e.g. you just want to increment everything by 1 but you've got lots of stuff to increment) then the overhead will be sensible or might even dwarf the work itself (and any gain you'd have from parallel computation). In this case, even in Go, you want to create as many workers as there are available cores and have each worker process some number of items. Some languages have a concept of sub-thread item e.g. Haskell has "sparks" which are a small bit of work getting scheduled on an existing *haskell thread*, which are similar to goroutines and themselves get scheduled on OS threads: https://i.stack.imgur.com/f57Hm.png
Hi, I'm sorry that you have such a hard time with the IDE. Could you please please help us identify the problems so that we can fix them? Feel free to DM me here, on Twitter at dlsniper, or open an issue on the tracker at https://youtrack.jetbrains.com/issues/Go Looking forward to the able to solve the issues and make your experience as good as it should be.
The debugger with goroutines instead of threads will be very handy, 
go list -m -u all
&gt; Is there any way not to do this while keeping the linter happy? Let me counter that: Why do you *want* to not do it? Depending on the details the comment or the function might or might not be redundant. But that's at best countering implicit arguments for why it *should* be there. That's not the same as reasons for why it *shouldn't* though. What does it *hurt*? At worst, it's a negligible amount of extra typing you have to do. So, why is "it makes the linter happy" a bad reason to just do it? (FWIW, the linter insists of it, of course, not just for shits and giggles, but because the convention has some value, but that's just an aside)
&gt; It may be very small overhead but it is non-zero It may also be a huge relative overhead depending on how slow the slow computation is e.g. if you're reducing or manipulating a huge amount of numbers, you might want to parallelise the aggregate but individual manipulations take very little time (on my machine, spawning a goroutine apparently takes around 750 cycles or so).
&gt; Seems like the only way to save that character is to use a rune or byte slice. Or a `string`, which is probably what you want :) &gt; That compiles. But now I can’t do a proper count. len(x) will be give me 2 and not 1. There's a conceptual issue with natural language in that it's not entirely well defined what a "character" is. There are multiple different answers and each of them are valid in different contexts. On a language level, Go has decided that a) `string`s *sometimes* assume UTF-8, b) but *mostly* don't care about encodings or semantics and c) there's a `rune` type for a unicode codepoint, whatever that means. There are good arguments for having a type representing a grapheme cluster instead and there are good arguments for having it represent bytes or having it represent… codepoints :) (for example: Say you'd argue in favor of "grapheme cluster" or whatever - then how does that type treat different encodings of the same character?) IMO, the best way to deal with it, is to question your assumptions that a "character" is something that needs to be used as a concept. It doesn't actually *help* with anything - you can't universally split on "characters" and interview questions like "reverse this string" just inherently have no meaning and are artificial. IMO, it's a good decision to not solve this at a language level, but instead delegate it to third-party libraries that can be more deliberate and opinionated in what they specifically do - because they don't have to be universally useful. &gt; There are many other string manipulation operations I cannot properly do if strings have characters occupying multiple runes. I don't think there *are* a lot of string operations that have universal semantic meaning. Even concatenation, I'd assume, has weird corner cases around RTL languages and the like. Personally, I'd consider stings opaque data that is taken from users and passed to rendering engines. Or just stored and reproduced, where you don't really have to care about semantics (you do have to care about encoding, but luckily, that's where choosing codepoints as a basis is a blessing). Admittedly, I'm a bit privileged in the kind of software I write, though :)
Yes, many? Qt, Gtk, what have you. I'm not sure if I understand the point you're trying to make here?
Does Goland use delve for debugging or something else?
Yes, we use Delve under the hood, with some special features IDE side to achieve things like Smart Step Into.
Sweet, will check it out.
Great! So if I add a release with the tag `v4.2.1`, it should be ok? Even if others releases are tagged without the leading `v`?
You’re 3-4 years too late on the “I don’t like go” train. My suggestion is don’t use it. Many of your points are explicitly described behavior by the language writers, if you had checked, it would not have been a surprise.
Hi I posted a suggestion the other day about that. My main problem with it(obviating the false misspelling ones which I guess can be disabled, I just don't know how) is that whenever I try to do something to help me understand better the code(like using ";" or joining code) if the IDE don't like it then no matter how much I ignore it or even supress the warning, it just will be removed and done the "GoLand" way anyway at startup. So I usually end up with some parts of my code looking different from the others which instead of solving my problem makes a total mess.
I understand your frustration, and it does sound like a problem with the IDE. But we need a way to replicate the problems with examples of code where this happens and perhaps the IDE logs. Do you have gofmt or goimports file watcher enabled? Or any other file wacther? If it's about how the code is formatted that could explain it as the IDE tries to follow the gofmt formatting rules (which can include reformatting the code or removing parts from it). As for the spelling issue, you can disable it by searching for "spelling" in the IDE settings.
Intellij is so nice to use in general, very good!
They are available for Go.
It's not that easy. You might want to read [https://github.com/golang/go/wiki/Modules#releasing-modules-v2-or-higher](https://github.com/golang/go/wiki/Modules#releasing-modules-v2-or-higher) and see how to properly release a V2+ version.
I think cleaner way would be to use some sort of mirror/cache. Haven't researched it for go, but since virtually all other languages have them, there should be something. Nothing changes, but when you pull dependencies it goes through your cache, it fetches the remote and stores a copy.
Thanks, let’s dive in
I just checked and what I sent was a FeedBack message from the "Help&gt;Submit Feedback..." tab. In response to your question, I use the default settings and don't have any file watcher at all(Just heard of them and checked my settings). The main changes I can think of are the GLSL and Markdown plugins installed by the IDE itself. One example that happens a lot is that whenever I try to read a binary file and fit code in the same line(to help me see everything without scrolling) like this: b = make([]byte, 6); reader.Read(b) // note: reader is bytes.Reader If I close the IDE and open it again the code gets formatted like this: b = make([]byte, 6) reader.Read(b) And so I end up with different code everywhere. This is the simplest example I can think of by now and yet a really frustrating one. PD: I can open an issue if you want me to providing extra log info 
That proposal doesn't fix what IMO is the biggest problem: it litters error handling code in the middle of your happy path. Same thing with the current nil-err-check idiom. *That* is the root of my dislike of the current idiom and the proposal. It's not so much the pain of writing the err-nil-checks (but it *is* painful), it's more about how it impacts readability during a code review. My thesis is that the overwhelming majority of error handling just immediately exits the scope by returning the error, possibly by adding some additional contextual information (eg.: "failed to load file: %s"). Why does all this clutter need to be interspersed with the business logic?
&gt; Go is too verbose to efficiently write functional code. I'd love if they implemented Java-like lambda syntax. So for example if I need to pass a `func(string, int, map[string]interface[]) bool, []string, err` I'd just need to write/read something like `(s, i, m) -&gt; true, strings, nil` instead of having to - once again - write/read the function's signature again just to return the values I already have. 
&gt; Example two is a) factually wrong as another commenter has explained b) a bad approach in general. To do array processing, you want SIMD of CPU or GPU. Using multiple threads/cores is less efficient. Use a library like Gonum or else you’re not make full use of your system. I think you missed the OP's point here, which is about control of concurrency, not necessarily doing some computations on simple numbers.
Yes. Since a given name can't have multiple signatures, Go could be easily infer the signature of a given func parameter to allow for lambda syntax. I don't think this violates the priority on compile speed either since it's not that complicated.
Most code doesn't care whether it is O(N2). Go is still really fast. Go should not place the burden on the majority with all this verbosity.
Thanks!
Just use emacs/gvim with plugins...
Sure, if this gives you the same productivity and level of features, then feel free to use whatever works for you.
[removed]
It seems that my colleagues cannot find the feedback ticket. So, with apologies, I have to ask you if can please open an issue on the tracker and attach the logs from the IDE as well. You can find them under Help | Compress Logs and Show in &lt;file browser&gt;. Take that zip and you can attach it as jetbrains-team visible only so just us can see the contents. Thank you for your time and help.
Yes, it fixes the issue. &amp;#x200B;
Unfortunately this is presently buggy. You to do something like this &amp;#x200B; go list -mod=readonly ./... &gt; /dev/null go mod tidy &amp;#x200B; And then ensure go.mod/go.sum haven't changed via git diff. &amp;#x200B; Example at [https://github.com/nhooyr/ws/blob/7eb2affac82d428a17b2b4aa9c5009d75a660f32/.github/deps/entrypoint.sh#L13-L14](https://github.com/nhooyr/ws/blob/7eb2affac82d428a17b2b4aa9c5009d75a660f32/.github/deps/entrypoint.sh#L13-L14) &amp;#x200B; See https://github.com/golang/go/issues/27005
Are these integrated new aspects of the official tools or is jetbrains working on their own proprietary ones instead of contributing back?
Would you mind writing a better article on go routines? lol sounds like I should be reading yours and not this medium one. 
&gt; Most code doesn't care whether it is O(N2). Wow. Just wow.
While reading or writing business logic code, isn't it less cognitive heavy to handle errors as close as possible to their source? Think fail fast and early. I'm asking because that's what I've been doing all my life and so I can't judge if that's better than having the happy path separated from error handling. I'm truly interested in learning this different mindset of handling errors and would appreciate if you could point me an example repo to grok.
&gt; Are these integrated new aspects of the official tools or is jetbrains working on their own proprietary ones instead of contributing back? /u/eikenberry we use tools like Delve for debugging but provide our own functionality on top of it for features like Smart Step Into. For the profiler, we use the pprof tool and our UI. For inspections, refactoring, editing, completion, qucik fixes, indexing, etc. , we use our own internal engine, with our custom logic. We regularly contribute back to various projects by opening issues or sending PRs to them whenever we can (for example if a new inspection finds problems in open-source code), or our users face problems with them.
I totally agree, handle errors right where they happen. Don't make me guess which wrapping caller is going to try to handle them.
Sciter
With Go, you have to give up most of what you know about code organization and reuse. It doesn't provide generics and parametric polymorphism. You have to give up everything you thought you knew about object oriented programming. With Go, you have to deal with a poor choice when you have a library or dependency that doesn't exist natively already. You can use cgo, which makes a lot of things worse. You can reweite it, which is expensive and may be very difficult. You could make a subprocess and communicate with it via IPC, but that may be too non-performant.
It sounds like you might have something running `go fmt` automatically somewhere. This could be in the IDE or elsewhere. In the IDE, check Tools &gt; File Watchers to see if that's running it.
Industrial programming is not about the happy path. The happy path is the uninteresting one from an engineering perspective. What happens on the "happy path" is so trivial that even business people can understand and describe it. A machine could implement the "happy path". The whole raison d'etre of our job _is_ the error handling. It is not that different in other engineering disciplines: Scaling up a chemical synthesis is about preventing contamination (or even explosions). Mechanical engineering is concerned with wear from vibration, corrosion, etc. It is just in software engineering that professional complain about error handling instead of understanding that this is at the heart of the art.
&gt; Why does all this clutter need to be interspersed with the business logic? If your business logic only needs to work 95% of the time, then it doesn't.
Where in FL are you? All the meetups seem to be in Orlando and I'm 2 hours away so that's kinda far...
Go mod works as follows: 1. If it does not find a [semver-tag](https://semver.org/) it fetches the master branch and adds the date and the commit-has, hence `v0.0.0-20190313095320-ab78559710f4` 2. If it does find a semver-tag it chooses the greatest 3. If the greatest tag is v1.x.x or v0.x.x it fetches it 4. If the version is v2.0.0 or greater the last component of the module path has to match `github.com/foo/bar/v2` 5. If this is not the case the folder v2 (matching the version) will be checked for a matching module 6. If this also fails it is marked `incompatible` and fetched So to make your collection of packages module compatible you append the major version to the module name, update potential import paths and then commit, tag and push. Everything here is explained in the go-wikki in greater detail https://github.com/golang/go/wiki/Modules
OK so I ended up creating a new repository for the library code. Now it works as expected :) thanks everyone!
Thanks for the explanation!
OT: seems WeWork has added an enterprise sales team to Meetup ? Does anyone know ? Because I am seeing more and more big companies utilizing Meetup in this way since WeWork bought Meetup. At 180 per yr per single group this will quickly add up to serious money.
[Accidentally quadratic](https://accidentallyquadratic.tumblr.com/).
Stop giving him ideas. Formatting conventions are a feature. there should be a feature in Git servers that blocks pushing commits that don't adhere to them.
VSCode also reformats the code because that's how it's supposed to look. Many large go projects only allow properly formatted contributions and that's for a reason.
Tampa bay area. There's one in Hollywood in September too.
Daily reminder to ditch J*tbrains and use our lord and savior VSCode
Just do it. VSCode is literally the best IDE that exists.
Makes me feel like a student again. Cohen-Sutherland is easy to understand but have you considered the more efficient Liang-Barsky algorithm [https://www.geeksforgeeks.org/liang-barsky-algorithm/](https://www.geeksforgeeks.org/liang-barsky-algorithm/) ? Liang-Barsky translates quite well into Go, particularly if, say, a function literal is used for clipLine() as this saves some parameter passing - the joys of a garbage collected language.
You absolutely can set up hooks in your repository for it. On the other hand, if somebody is writing their own project and they absolutely hate the style conventions, let them turn it off. The tools shouldn't get in their way.
With its half-baked sometimes working as long as you don’t use go modules integration? Yeah man totally equivalent. 
The fuck are you on about? Have you actually used it? I used it both with modules and without, works fine. Go spread your FUD elsewhere, shill.
&gt; I have always found react easier to reason with than a templating language server side. 1. That statement is vastly subjective and also depends on the context. 2. Even if your point is valid (which due to 1 it most likely is not), you need to remind yourself that software development is not about developer happiness. It is about the end user happiness. Just because a React salesman on Twitter sold you that framework, it does not mean that the end product will be be the best possible that your users can experience.
Use it daily. Does not work with modules for me on certain projects. On others it does, but it’s super slow. It does work with the traditional Go toolchain a lot better. Goland integration is much tighter since they don’t rely on the dozen packages that VsCode Look at how many bugs, today, are tagged as “go-modules” in the Microsoft/vscode-go repo. So kindly fuck off, fanboy. 
I think what Go community needs is a non-simple, aka real world, web application with Go. Just look how this sub receives one or two posts every week asking how to structure my web app project or which framework vs stdlib to use.
I use it daily too, I use it for work. Never ran into any issue aside from go-rename. Oh no, lots of bug reports. Almost like there’s a lot of involvement from the community on reporting every issue so it can be fixed, unlike garbage other editors where you look for solutions on SO. GoLand has way more issues. It’s way slower, their entire framework is a mess (Java, go figure). I have like a billion plugins. Stop spreading FUD you paid shill. Look at your own life.
Hahaha “paid shill”. Man I *wish* I was getting paid! You seem to be really emotionally invested in a *software product* - let that sink in for a minute. Not an idea, or a cause, or a political party - bits stored on a computer. I feel you would physically attack me, if you could, because I prefer one *software product* to another. That’s pretty fucking hard-core? You even assume I’m a “paid shill” without any backing evidence? That’s borderline mentally unhinged thinking. Really think about that. I wish you all the best, hope you find the help you need. 
Has anyone got Mozilla's rr recording debugger working? I haven't had any luck, it just constantly says that it quits with a non-zero error code :(
I can confirm. Module support is still terrible.
There are some heavy restrictions around where rr can work. Please see https://blog.jetbrains.com/go/2019/03/04/debugging-with-goland-advanced-debugging-features/#mozilla-rr-reversible-debugger for more details. Do note that if you have an AMD processor this is currently not supported.
This is an amazing utility. No mucking about with the infrastructure set up. It just works!
I've become so used to the high quality stdlib of go that I started to develop "thirdpartylibraryphobia"
Nice find!
Some useful advice: Rule 1. You can't tell where a program is going to spend its time. Bottlenecks occur in surprising places, so don't try to second guess and put in a speed hack until you've proven that's where the bottleneck is. Rule 2. Measure. Don't tune for speed until you've measured, and even then don't unless one part of the code overwhelms the rest. Rule 3. Fancy algorithms are slow when n is small, and n is usually small. Fancy algorithms have big constants. Until you know that n is frequently going to be big, don't get fancy. (Even if n does get big, use Rule 2 first.) For example, binary trees are always faster than splay trees for workaday problems. Rule 4. Fancy algorithms are buggier than simple ones, and they're much harder to implement. Use simple algorithms as well as simple data structures.
https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md The check/handle approach do address this to a large extent.
This is helpful for sparse arrays. Just set the non-blank values. 
That's awesome. No idea if I'll ever use it, but awesome nonetheless. 
oh nice
Dafaq. When it's useful captain?
Reason: [https://golang.org/ref/spec#Composite\_literals](https://golang.org/ref/spec#Composite_literals) `The types of the elements and keys must be assignable to the respective field, element, and key types of the literal type; there is no additional conversion. The key is interpreted as a field name for struct literals, an *index for array and slice literals*, and a key for map literals.` &amp;#x200B;
Oh, I thought it's 101.
Interesting. Gave you a Github star -- no extra charge. :)
TIL there is a built-in `println()` function: https://stackoverflow.com/questions/14680255/whats-the-difference-between-fmt-println-and-println-in-go Still recommended to use `fmt.Println()` instead, though.
Agreed all of what you said. But please note it has _no_ connection to the O(n) vs O(n^2) problem.
*Wooo* It's your **4th Cakeday** kapoof_euw! ^(hug)
Also if you wanna use constants as index values: ```go const i = 1 fmt.Println([]string { i: "Hi", }) ```
Yes! An example that brings in seeding, testing, caching, sessions and something like queue workers or an event bus would be so valuable. I guess no one ever had a problem with structuring 3 endpoints in a single main.go, but scaling that thing up and introducing domain logic can be very frightening (looking at you, circular dependencies). 
yeah, i tried all that, and still had no luck. I was trying to get the debugger output or figure out what commands intellij / goland (I tried both) was running, but I couldn't get any output logging except for the debugger exiting with a non-zero error code.
What's the difference between that and [this public doc](https://docs.aws.amazon.com/lambda/latest/dg/go-programming-model-handler-types.html)?
&gt; I think what Go community needs is a non-simple, aka real world, web application with Go. I would argue that is [Upsin](https://github.com/upspin/upspin), created by the core Go team no less. It also drives home the point that an idiomatic Go application isn't just a web application, but an application that may have a web interface, along with other potential interfaces.
Also println writes to stderr, fmt.Println to stdout 🤷‍♂️ 
Up provides quite a bit of management utility on top of api gateway and lambda, such as dns records, custom domain names, ssl, rollbacks, stage management etc. When you use Lambda on its own you’ll also need to use the SDK event structures instead of net/http. Hope that helps!
Helpful comment 
Well, we can do some investigation here on reddit, on Gophers Slack (DM me at dlsniper) or on our issue tracker, whatever is more convenient for you. Start by running your application in the IDE and then use ` rr record -p pid ` where pid is the PID of your process.
I know I know. I should not have said that.
I haven't used goland and do use vscode daily for work and home projects, and modules support is terrible. Until last week I was still working without modules and everything was fine and fast: autocompletion, search, renaming, etc. Now everything takes several seconds to appear, searches sometimes don't work, RAM and CPU use have gone way up, and so on. I actually disabled gocode for a couple of days as it was slowing down everything. So yeah, vscode is great, I switched from Sublime like a year ago and pretend to go on using it. They'll probably get the plugins working with modules eventually, but you have to admit that right now it's not pleasant to use.
Thanks!
&gt; But please note it has no connection to the O(n) vs O(n2) problem. It does though. The assertion upthread was that most code deals with a small enough *n* that the differences between O(n) and O(n^2\) makes no difference in practice. The parent has continued the theme of discussion by pointing out that until you have reason to believe that your *n* is large enough to cause a problem, it is going to make no difference in practice which algorithm you choose. The only outstanding question is whether or not the original claim is true. Does most code deal with a small enough *n*? I don't know how we would go about proving it, but in my personal experience it is largely true.
Because you’re claiming VSCode is unusable. It’s clearly not, and all I can see you gaining from spreading FUD about VSCode is not very savory. And then all the rest of your shit, lmao.
What’s your platform, out of curiosity? Never ran into this issue.
I found println() was very useful the one time I was debugging fmt.Println().
cool, i try evaluate and test in my business trial project, it work great.
I'm running Linux Mint 19 on a Lenovo notebook with Intel i7-7500U CPU @ 2.70GHz × 2 and 8 GiB of RAM.
Huh, weird. Guess I’m just lucky? Idk
Admitting that is super admirable, don’t even worry about it. I was probably being needlessly snarky on my part. Hope you have a great day and happy coding! 
Lol nice, story time? What were you debugging?
Think about sparse matrics.
add example: ``` package main import ( "context" "fmt" "os" "runtime" "time" "github.com/kaiserkarel/go-cron" ) func main() { // runtime.MemProfileRate = 0 runtime.GOMAXPROCS(128) signal := make(chan struct{}) fmt.Println("----------------&gt; cron test") var routine cron.Routine var err error routine = func(ctx context.Context, args map[string]interface{}) error { fmt.Println("called", time.Now()) return nil } executor, err := cron.New() checkErr(err) err = executor.Register("printroutine", routine) checkErr(err) // Start the global executor go func() { fmt.Println("----------------&gt; cron global running ") err = executor.Start() checkErr(err) }() // Add an entry to our global crontab err = executor.Add(cron.Entry{ ID: "myjob", Expression: "@every 1s", Routine: "printroutine", }) checkErr(err) // Wait forever. // time.Sleep(10 * time.Minute) // executor.CancelAll() // select {} &lt;-signal } func checkErr(err error) { if err != nil { fmt.Printf("error: %v ", err) os.Exit(-1) } } ```
Twice. Once I was working on the \`%08b\` format when applied to \[\]byte. I wanted it to print like '%x' does, as one long continuous binary number. The other time IIRC I was hacking %x to handle huge \[\]byte slices. It used to write to a temp buffer, and thus temporarily allocate a buffer 2x the size of the input. It might help when implementing a custom fmt.Formatter too, though you might be able to debug that outside of fmt.Printf
He's making the common mistake of confusing concurrency with parallelism.
Can anyone share experience storing standard related data when using serverless / Lambda? Do you use one of AWS/Google/Asure's cloud databases or deploy your own Maria/MySQL/Postgre/TiDB cluster somewhere else?
I like to use `println()` when debugging as well. I often do a quick grep for `println` to ensure I didn't leave any of those in... Where as there might be a good reason for `fmt.Println` to belong. Ideally I would notice before committing, but being able to do a quick grep makes me feel better about it.
I assumed it was in there somewhere!
Indeed. The happy path is rarely exceptional and our job is making sure the non-happy path is also rarely exceptional. When things go sideways (and they always do), they should do so in a predictable and graceful way that enables humans (like us) to institute contingency plans. This is only possible with rock-solid error handling (and logging, and tracing, and metrics gathering, and autoscaling, and self-healing infrastructure, and [...].)
Would this be useful for sorting? Just a brainfart.
&gt; It does though. The assertion upthread was that most code deals with a small enough n that the differences between O(n) and O(n2 ) makes no difference in practice. Uh. Are we even using the same definition of complexity classes?
I don't know. What definition are you using?
You could at least have tagged me, rather than attacking my attitude without me noticing. I'm willing to help anyone who doesn't just snap back. Not that I could have assisted in this case since, as you correctly say, I have not used Docker in a production environment. It's just that in your introduction and follow-ups, you didn't give any information as to why docker is needed. To be, that gave the impression that you were doing it because that's what you did in your previous environment. I therefore made a root level comment saying you should try deploying without docker. Your comment on not wanting to have downtime due to switching binaries further made me assume that you were switching binaries on the main server, which is why I commented on testing in prod. Your acerbic response led me to again wrongly assume an unwillingness to learn.
Hmmm. I like this, but it also seems like a map would be more appropriate so you’re not instantiating a large array to only fill in sparse values?
Wat? The stdlib is not an application. We ae talking about how to build an app here.
Your simplest option is to use return type of \[\]interface{}. I personally find that to be a code smell, but it does work: [https://play.golang.org/p/5E4Wtpv4u9y](https://play.golang.org/p/5E4Wtpv4u9y) What you are looking for are generics. Currently in early draft for go2: [https://go.googlesource.com/proposal/+/master/design/go2draft-generics-overview.md](https://go.googlesource.com/proposal/+/master/design/go2draft-generics-overview.md) &amp;#x200B;
Yep, am trying to avoid returning interfaces out of the list methods. As the saying goes: accept interfaces, return concrete types.
Have you tried to use them? Because last time I tried I ran in to "oops, this feature I want to use isn't implemented yet" pretty fast. Of course, I could spend time on implementing what I need, but it was just for an experimental hobby project. I'd love to hear about it if this has changed in the meanwhile.
cron?
Seems like a good option but it also seems like I'd have to keep a heroku worker running constantly for it to work which is more money. I don't have an option to run this locally
It seems more an heroku specific question that golang. I don’t even know heroku pricing, I prefer real server, anyway first result on ddg is https://devcenter.heroku.com/articles/scheduler
It's a golang question, I'm open to any recommendations on what others are using to host their golang-based web services. What you suggested was [cron](https://godoc.org/github.com/robfig/cron) which would require me constantly running a server as opposed to specifically opening a server to run the task then shut it down. Which, though I don't have a ton of experience sounds like it's going to cost more money whether I'm using what you're describing as a "real" server or not.
No, for cron I meant the unix daemon. But would be equally impractical in your case. Still, some agent somewhere should trigger the execution of your service, so I think you should look at heroku scheduler or have a cron or equivalent in another machine that uses heroku api.
Ah, a mix up indeed; but yea nonetheless not really an option in the moment. (Once I start refining this out however I'd like to run it on a raspberry pi in-house so thats an option then) Scheduler is what I'm currently trying to get to work actually, that and looking into serverless. Thank you for the recommendation though.
You could run it as a “service” from systemd 
Just a tiny logging thing I'm enjoying to use. Please take a look and give me some feedback. Feel free to change anything you like.
Wouldn't you want to use a map? I would expect it to still allocate the full array even if you only set party if the indices. 
If you have map[byte]T, it’s more efficient to just use [256]T, since the lookup is a single multiplication. 
for that second part about key for map literals what would the equivalent of this example be?
hah! ok now the question again at a higher level: what were you working on that required all that
Doesn’t work different than this (I think) https://play.golang.org/p/Ht14JXfLzii Alternatively you could implement an interface `Lengther`, which would make a function length pretty obsolete. 
Work stuff.
Not familiar with how things are on AWS but you can generally access GCP hosted services (eg: Cloud SQL, Datastore, etc) via the GCP Go SDK. However, direct access to other compute resources (eg: Compute Engine VMs, AppEngine services) via internal networking is sadly not available. You can use GCP PubSub (like AWS SQS) though and I've had good success with this.
not the answer i was looking for but if you must keep it a secret (◔_◔)
One other alternative to having to commit a List() method to returning a slice of interfaces is to provide a Count() and `At(i int) Route` and `At(i int) Service`. Then you would be able to treat both those return types as a common interface without having to commit the actual signature to return an interface. Not great. But it's there, as opposed to the other options. 
Might be a little too complex though, given this is not just a full application - but a federated one with custom protocols: https://upspin.io/doc/overview.md
Thanks, as you may have noticed I only want answers from other users who share a cake day.
&gt; So I have 2 structs that both have a List method 2 structs that, perhaps, could adhere to an interface. &gt; however the method signature is slightly different. You don’t need a language feature, you need to align their interfaces.
I don't think so as the index must be a constant.
&gt; As the saying goes: accept interfaces, return concrete types. In your case, in my opinion, return an interface. Or return a struct that includes two lists, one each of both types.
&gt; Your simplest option is to use return type of []interface{} The path to hell is paved with simplest options.
You can add a `Len() int` to both structs. Then your function is something like `func length(lister interface{Len()int}) int` (and you can name the type `Lenner` or something if you want to). The key is accepting an interface in your length function. Whatever work you are doing on the result describes this interface.
I truly dont understand the whole serverless.. at least in the context of building a money making service with it. Would love someone to explain to me a bit more how you would say, put a little go app (or other app) as a serverless deployment, and somehow make money with it. Do you use serverless like each one is a microservice, and then you deploy an API somewhere (also serverless??) and somehow charge for API requests, that then make calls to other serverless modules? I get it for simple things like if you wanted a really simple way to store something and show it in a web site, but I dont see how you build a business off of a variety of serverless deployments? Please help me understand.
So here is the thing.. I love IntelliJ. But lately VS Studio Code is looking really good.. especially because I will be working on several microservices and the fast/easy way to edit with VS Studio vs IntelliJ looks ideal. However, I am unsure if VS Studio supports Goland anywhere close to what Intellij/Goland does? I would like to consider switching to VS Studio, but am afraid I may be losing updated Go stuff, like when a new version of Go (e.g. 1.12) comes out, how long until VS STudio supports it vs Goland? &amp;#x200B;
it's a nice convention for when you need to add a new dependency. Or when you add a map to the struct that has to be initialized, and you only need to initialize it in the func instead of all the call sites that initialize the struct literal.
Tried to get this going as I'm interested in learning more about microservices and kubernetes, but fails in a pretty non-descriptive way when trying to skaffold run on windows with Docker for Windows: &amp;#x200B; `Sending build context to Docker daemon 106.5kB` `Step 1/16 : FROM openjdk:8-slim as builder` `---&gt; ca76a0748b8a` `Step 2/16 : WORKDIR /app` `---&gt; Using cache` `---&gt; 864059e8cd26` `Step 3/16 : COPY ["build.gradle", "gradlew", "./"]` `---&gt; Using cache` `---&gt; 48f29d815557` `Step 4/16 : COPY gradle gradle` `---&gt; Using cache` `---&gt; 73dad6186fb8` `Step 5/16 : RUN chmod +x gradlew` `---&gt; Using cache` `---&gt; 1a6fd6f3c5b6` `Step 6/16 : RUN ./gradlew downloadRepos` `---&gt; Running in 2f828af865d5` `/usr/bin/env: ‘sh\r’: No such file or directory` `FATA[0033] build failed: building [adservice]: build artifact: The command '/bin/sh -c ./gradlew downloadRepos' returned a non-zero code: 127`
\&gt; On a more serious note, you need to put *serious* effort into [https://spaceuptech.com/docs/security/database](https://spaceuptech.com/docs/security/database) because the idea of directly exposing databases to the browser has some serious obstacles to overcome. Ive updated the docs. It would be of great help if you could check it out once again!
GoLand supports working on several projects at once in the same window, we did so since the start. Can you please describe what kind of fast editing you are missing from the IDE?
I've updated the docs. You think you can check it out once again to see if it makes any sense?
I have updated the docs to be more specific. Does it makes sense now?
I honestly dont know yet. I have opened a project, and when I try to open separate Git repos, they are separate IDE window frames. How do you group one, two or so separate projects (e.g. git repos/projects) in the IDE in one left side project so you can see two (or more) in the tree structure to expand and open up source files in each? How do you run two or more separate git repo projects simultaneously to see if service A sends/receives to/from service b?
To add multiple projects to the same IDE window, when opening a project select the Add instead of New Window. Alternatively, go to Settings | Project Structure | Add content root. To run multiple services/commands at once there are an array of options. Starting from running each service manually one after the other (you an still have multiple services running on parallel), to using a Compound run configuration from Run | Edit Configurations | +. Please let me know if I can further help you.
Exactly why I said it was a smell. I try to avoid interface{} like the plague.
This seems like something that could be solved with a FaaS like AWS Lambda with a CloudWatch trigger. Have you looked into that?
&gt; or which framework vs stdlib to use. I was replying to this.
You don't have `go.mod` and `go.sum` files? How did you use go modules exactly? Also are you sure you want to use flex env? I think that's the one that just build and use docker images, so you actually compile your go code locally, not on app engine? 
This is what I do for some scraping stuff at work, very easy to setup and works wonderfully. 
Yeah. The good way to find out some interesting syntax stuff is to read [https://golang.org/ref/spec](https://golang.org/ref/spec)
How up compares to serverless framework? https://serverless.com
Completely depends on what you’re trying to accomplish. You don’t build a business off of serverless, the same way you don’t build a business of the cloud. You solve a problem for someone and they pay you. If serverless tech helps you solve that problem, great, if not, then don’t use it. 
If you have all your dependencies in your vendor folder (`go mod vendor`) you need to build your app with the mod flag (`go build -mod vendor`) Now go builds everything from your vendored dependencies
Do you have a go.mod file? What happens if you run `GO111MODULE=on go build` locally?
Is it a long time ago? Which feature is missing? Do you require a pure-Go implementation, so that bindings to the C libraries are not good enough? * Qt5 https://github.com/therecipe/qt/wiki/Gallery * Gtk3 https://github.com/gotk3/gotk3
If there's one thing that surely must be available for Go right now, it's a library that can also "Build cross platform desktop applications with HTML, CSS and [SIC] script". For example: * https://github.com/richardwilkes/cef * https://github.com/asticode/go-astilectron 
Serverless is more general purpose for managing many Lambda functions, Up basically abstracts that away entirely so you’re writing HTTP apps as you normally would without functions-as-a-service. If you’re writing event processing you’d want to use something like Serverless for sure, but if you’re writing apps or APIs you may find Up much easier to use. 
As you would with any server, create value with your product 😊. Serverless isn’t a be-all end-all solution yet, but for many types of work it is quickly becoming the obvious default choice. You pay only for what you use, so you can basically deploy an app and never touch it again, knowing it will always be available, unlike maintaining your own cluster where you would need at least two nodes and a load balancer, even when completely idle. 
Except that functions should return structs, not interfaces. It can return a struct that implements an interface though, but it's not very useful if it returns that interface specifically. Cfr. "Accept interfaces, return structs".
That’s really useful, I already have a use case for it! Thanks for sharing!
use [beego](https://github.com/astaxie/beego/)
You make it sound like giving up needless complexity is a bad thing.
Why? 
very popular on github. I used in many projects. also you can use [qor](https://github.com/qor/admin) for admin area.
There is no most typical or common stack. A usual answer is to start with the standard library with middlewares. My proposal is: sit down and do some brainstorming about your app. Figure out what you need and how it will all fit together. After that read more about gin-gonic, buffalo, go-kit ..... and their capabilities. Also (maybe wrong): if you need NoSQL buffalo is out because, if I remember correctly, buffalo can only work with SQL. 
What is the difference between "normal" and "enterprise" web app? I've worked on huge java monoliths and smaller java "microservices" with spring, mainly using REST apis, but I wouldn't consider it enterprise web app really. For Go, it really depends. I have not done extensive re search into different frameworks because I never intended to use one seriously (and I never intended to build huge servers with Go). I have no doubt that they are quality frameworks (given the popularity). One interesting thing for me is https://github.com/goadesign/goa which could enable you to describe your API in a DSL that generates your code. That seems interesting on the other side of the spectrum. I expect my microservices to be tiny so I don't use any specific framework, other than something like gorilla/mux for some quality of life router setup. I could be shooting myself in a foot avoiding some other quality of life abstractions these frameworks provide - absolutely possible that they would save you time. On the other hand, coming from something like Spring Boot, I am very vary of introducing huge amounts of "magic". I enjoy the fact that when using simple stuff, I know exactly what is going on anywhere in the code.
Thanks!
I second that. Had a rather bad experience using buffalo for a simple µservice-type API. It required a ton of dependencies and was really overkill. Stepping out of usual tooling was a pain (e.g. using `buffalo` binary for everything) made CI templates and existing Dockerfiles useless. Migrating to modules was a pain. &amp;#x200B; All in all, I trashed almost everything and rewrote the thing using `gorilla/mux` &amp; `ozzo-dbx`. No more magic, a bit more code, but everything is much readable and straightforward now.
Is there a way to view the link w/o having a Tumblr account?
It's just an environment to use cheap compute. If you're doing a lot of background tasks then the cost is pretty competitive compared to Compute Engine.
`ozzo-dbx` looks nice, but dead.
I'm slightly tilted that they didn't mention edgex foundry. It's a iot gateway platform that was completely refactored from Java to go and got insane improvements to perf accepts board. Also, the OCF cloud spec is being implemented in go
Gin framework plus the dB of choice is all you need.
For enterprise applications you will probably need, at some point, an ability to customize everything. Therefore it might be safer to choose a solution with as few dependencies as possible. instead of going with a framework, pick up packages and compose them themselves. here is an example: [https://github.com/julienschmidt/httprouter](https://github.com/julienschmidt/httprouter) for routing. It does nothing but match a pattern to a handler. [https://github.com/elgris/sqrl](https://github.com/elgris/sqrl) \- have query building capabilities decoupled from the database client. and so on, according to your needs. The reason that this approach is good for Go is thanks for Go interfaces. You should create an abstraction for each of these packages using a Go interface. Then, you can write you business logic in pure Go without coupling yourself to the underlying package used. I suggest visiting the go-kit examples as I got my ideas from there. &amp;#x200B; &amp;#x200B;
[removed]
The difference between an enterprise app and a normal app is typically observability. In enterprise you collect tons of metrics, logs, request traces, etc... so people not familiar with the code base can still hunt down problems and bottlenecks.
Gin is a really good framework. Fairly performant (IIRC it uses tries for its routes) and it lets you avoid a shitload of the boilerplate you need when using plain `net/http`. Of course if you only need a couple of routes and no real bells and whistles, `net/http` is a perfectly good choice
You're being glib. I've seen programmers who struggled with first understanding and then leveraging Go's interfaces and embedding concepts simply because they're so used to another model. Until you get past it, that's a cost you have to accept and deal with in terms of productivity for a switch.
Just curious, how to you specify a middleware with standard library. I'm using mux atm and didnt know you could apply middleware with standard.
When I think Enterprise apps I think of three things: 1. Authentication. Must support both current and legacy authentication schemes, from SAML to Kerberos, LDAPS to certificates. RACF2 is always a nice to have. 2. Traceability. There needs to be sufficient logging options that I can drill down to triage problems, combined with support for centralized logging services. 3. Maintainability. The app needs to be able to be maintained without an outage. Whether that's something as simple as a load balanced setup and you're only taking a few nodes offline at a time or something truly robust, the app can never be seen to have gone down.
Sorry I forgot to include them but they are also there.
Sorry I do have the go.mod and go.sum
If you need more than one endpoint gin isusually the way to go. Normally people need gin, redis driver, Postgres/MySQL/MongoDB driver, migration of scheme took as standard for any non trivial project. Most of the time you may also interact with rabbitmq etc. I personally use gin if I’m making a web GUI in go. The other point is, if it is bigger maybe it will be faster to make it in nodejs or rails. But that is a different chant and go fanatics would eat me alive for using right tool for job approach :)))
Could you elaborate on the nodejs part? I am coming from using eggjs which builds with koajs underneath. Smaller memory footprint and a working but minimal type system are what attractive to me at the moment.
Wouldn't that just be a normal map literal?
I'll have to check. My go source is still in my gopath for now so ill have to see where the vendor repo is
There’s no dedicated middleware type in the stdlib. But you can achieve the same with http handlers that return handlers like `func1(func2(func3)))`. Check out Alice (or some similar name) for a pkg that makes it a bit easier. 
You might get something good from https://awesome-go.com/
Lookups in a small array would be faster, I expect.
Maybe building stuff in nodeJS is faster but it will never be as performant (which also has implications for operational costs)
Nodejs / ruby could be faster to build and easier to maintain or find people to work on it in future. Everything depends on what you want. Finding good go specialist is not as easy as Nodejs or ruby guy. But that is entirely different topic. There are things to consider :) that’s it. To put it choice is not always black and white.
For most projects operational cost is lower than development cost. :)))
I came from Java world where Spring rules the "enterprise" world. When I started to research web development in Go, I came up with the thought that using standard packages and some middleware like gorilla is really the good point. But after huge Java experience I thought that may be I've missed something.
In golang there's no "default" or more common stack like Java (with Spring) or Javascript (with Express). But i'll say that using [Gin framework](https://github.com/gin-gonic/gin) it's a good choice. &amp;#x200B; If you need to do http calls to another api you can use the built in package http, but there's two libraries that simplifies the job a little bit: [resty](https://github.com/go-resty/resty) and [mercadolibre's rest client](https://github.com/mercadolibre/golang-restclient) &amp;#x200B; DB: based in my own experience, you can use MySQL and MongoDB without any problem. MySQL using the package [sql](https://golang.org/pkg/database/sql/) with plain SQL statements, or using [GORM](http://gorm.io/) ORM if you feel more comfortable. MongoDB's guys have released an [official driver](https://github.com/mongodb/mongo-go-driver) a few weeks ago. I hope it's useful :D
You could be right. Depends on the life expenctancy of the project I guess. 
+1 for Gin. We use it extensively across many different sizes of project. net/http is tedious in comparison. I'll always reach for Gin instead of messing around with it. 
/u/JaegerBurn is right. Example like: `func withLogging(next http.HandlerFunc) http.HandlerFunc {` `return func(w http.ResponseWriter, r *http.Request) {` `log.Printf("Something to log)` `next.ServeHTTP(w, r)` `}` `}` &amp;#x200B; `http.Handle("/", withLogging(route))`
That seems interesting. A lot of people recommending Gin. I'll definitely try it. 
Gin has middleware built in, and a pretty large library of contributed middlewares for common things like session management and jwt.
Very informative. Like the regex article too. 
I really like and agree with this explanation. Abstract error handling sucks and makes code readability far worse. It's one of my biggest complaints with idiomatic Java + Spring.
Thank you. I was thinking of how, on a local machine, with each service in its own container, I run them on the same port. I know you cant, and I know you can use a router/reverse proxy in some way. I found a few examples. My concern there (which is off topic but will put it out there to finish the thought) is if I use some Docker compose file to spin up say nginx, with external config that routes to individual services, and spin up those services, thats fine... but that isnt how it will be deployed in production and other ENVs. So I was thinking it might be better to try to mimic the staging/production envs, using minikube perhaps, on a local box. 
Yah, someone else responded too. I may have to just "learn" how this is done. I am used to loading a project via maven, and when I have two separate repos/projects, I recall having to load two instances of the IDE to work on them, switch back and forth. I guess there is a way to add a 2nd (or more) maven project (for java), goland, etc all in the same one left side project view. Just not sure how the flow is with moving to a microservices development process. 
Personally I think dynamically typed languages are an absolute nightmare to maintain
The complexity of nested O(n) calls is just as obvious to anyone who has ever done functional programming as the complexity of nested for loops is to anyone who has ever done imperative programming. (and it's actually O(n*m))
If you have one call to filter and then another, it’s only polynomial if you nest them. So, `l.filter(conda).filter(condb)` is good but `l.filter(items =&gt; items.filter(condb))` is bad. I think this is more subtle to see than with a loop where if you have `i` and `j` then you are polynomial but two `i`s is fine. Basically anytime you see J you should examine the algorithm, so it’s an easy heuristic. Obviously it depends on paying attention either way. 
Nice. Concise and helpful. Wish strings.Builder had a more prominent mention rather than just a link out. Same with multi-line literals. &amp;#x200B;
I haven't used gorm myself, but from the looks of the documentation, you may need to reference the association before you can query it. Have you tried throwing in a .Association("Ingredients") before the where clause?
Start with your form tags. They’re all colons, and the middle colon should be a semicolon. Make sure they’re also composing gorm.Model or including an ID field. 
Agreed. Stringbuilder seems to get the short end
I find it funny that go interfaces are seen as such a game changing mechanic. Is is not the exact same with Java/C# or even Ruby/Python? Yet somehow Go is the only language where it's common for people to mash some libraries together! I feel this is because of a lack of good frameworks rather than by design, yet it seems I'm alone in thinking this...
Just FYI, Reddit doesn't do Github-style Markdown.
I don’t think it’s bad, but other languages have much more developed ecosystems for tooling. So it’s more of a maturity problem than a language problem.
I'm an author of a game library for Go ([Pixel](https://github.com/faiface/pixel)), so I may be biased. Probably the biggest criticism one could have is the performance of C interop. Game development usually involves calling to some C libraries (for OpenGL and stuff), and the performance of those calls could impose a bottleneck in an intensive game. Another criticism would be the semi-maturity of libraries. Don't get me wrong, there are great libraries out there, including Pixel and [Ebiten](https://github.com/hajimehoshi/ebiten), but they are not as well established as some libraries in other languages, and so on. If you were thinking about GC latency, that's really a non-problem. Go has a magically well made garbage collection with virtually no pauses, so you will almost never skip a frame due to GC.
Is there anything stopping a modern SUV from being as fast or faster than a Lotus Elise? Modern cars dramatically increase driver safety by introducing ASR, ABS, ESP, mirrors blinking when being overtaken, rain sensors, automatic shifting, backview cameras, the whole nine yard. This makes a car pretty easy to drive nowadays, even non-experienced drivers can keep it in the middle of the road. Of course all those gadgets add to the overall weight, which makes the car less performant. This is not an issue today, 99,999% of all car miles are driven in large cities at 25 mph.
Why does it need to be one line?
Thanks for the response. I'm surprised it cant use those C++ graphics libraries directly since it compiles to C++, as far as I'm aware that's what languages like Haxe do. Do you think this can ever be fixed, and does every language not written in C have the same deficiency?
Make a function for it. The function call will be one line. Make sure the function does bounds checking and errors if the data doesn’t fit. 
I tried, still the same error :(
Vim, Amber on Black, Go fonts (https://blog.golang.org/go-fonts)
[removed]
Well, there are good frameworks but we do this by design. Go intefaces are not like java or c#. In Go, a type ("class" in Java) implicitly implements an interface. And while you do have this feature in ruby and python, those are not typed languages. 
Ballin. The Kafka tools are fucking garbage. This looks promising. 
Are you saying that go isnt fast because people who use it dont need to go fast?
I've used gin a couple times now and I like it. It did take a while for them to merge a bug fix that I submitted and people are still waiting on a v1.4 release, since the last release was Aug 2018. I decided to give the Echo framework a try on a new project, but now I wish I had just stuck with Gin since I like it better. 
I'm starting a Kafka backed project soon, so I will give this a try. Thanks! 
1. What happens when you run `GO111MODULE=on go build` locally? 2. What's the exact error you get when you try to deploy to Google Cloud?
`--color=auto` means it auto detects the output medium, and only colorize when it detected terminal, not a pipe. If you want color, you need a different value for `--color`, maybe something like `force` or `always` (I'm on phone right now so can't check the manpage)
You rock for doing this. I would love to see a summary like this each week.
What I find confusing as a relative newbie is that you can compare strings and not byte slices, but you can convert a byte slice to a string and then compare it directly.
Thank you, that solved it! :) 
Bias alert: you will get a lot of just use the stdlib in this community, which is typically not of practical help for people that ask questions like yours. If it was helpful, we would not have this questions asked here at least once a week. Because of this community bias, the mentioned frameworks will never become a de facto in Go.
Unfortunately Gin does not use standard http handlers. So all of that community contribution cannot be used for people who want to adhere to the standard.
Fair enough, but go is my first real commitment to learning coding and I've made it a habit to avoid 3rd party libraries unless it's a propriety thing (stripe, aws), just for the sake of learning everything I absolutely can. I would love to manually implement middleware rather than gorilla and get rid of that dependency, even if it is "harder". That's just me though.
&gt; I came from Java world where Spring rules the "enterprise" world. What are your reasons for choosing Go over Java for the new enterprise app?
Gin is one of those libraries that was good at marketing 'Github stars'. Hence it makes more noise, but may not be the best solution. Specifically it does not use standard http handlers. IMO there are better solutions with less hype out there, Chi may be one of them.
\&gt; Is is not the exact same with Java/C# No. In Java, the class that implements an interface **must declare the interface**. In Go, **anyone** (not just the implementor) **can declare an interface**. And the interface can apply to already-written and even already-compiled classes that existed before the interface was written. This allows any programmer to find their own abstractions without forcing those abstractions onto every other programmer. \&gt; Ruby/Python? Ruby and Python have far more magic, which is part of the problem. If I show you an entire Ruby file like this, what can you tell me about it? `require 'somefile'` `foo(blarp + BORG)` The answer is: Literally nothing. You have no idea **what file** declares that function, no idea **what file** declares that variable, no idea **what file** declares that "constant". It could be in `somefile` .. Or not. Those items could have come from a gem included by `somefile`.. Or not. It could be nothing is in `somefile`, and those items actually came from *some other random file not mentioned here that happened to be loaded before this one*. Some file declares 'foo()', but we don't know where. It might not even be "def foo()", it could be created in dozens of other magic ways (method\_missing, define\_function, etc). There is literally no way to tell. (Note that "constant" is in quotes because, surprise, changing a constant is only a warning!) But if you try that example in Go, you will realize that *every item* is explicitly linked to the **exact package** that declares them, and the exact object it operates on. No exceptions. That kind of clarity really helps when you have a large team, and is not available in Ruby or Python.
There's a newsletter called [golang weekly](https://golangweekly.com/) you might like. Check out the [most recent edition](https://golangweekly.com/issues/253) to see if it's what you're looking for.
@chezhead That is exactly the newsletter you should not subscribe to. It's made by a lazy "professional" publisher that earns money with advertisements in its weekly, yet just copy-pastes content that is already published on Reddit. Completely filled with old news. 
Pretty awesome list
Is there anything better out there?
Well, you are being referred to it in this post: [https://www.getrevue.co/profile/golang-jexia](https://www.getrevue.co/profile/golang-jexia)
Sorry I tldr'd the whole thing!
Recently found both newsletters and instantly subscribed! Pretty neat content
&gt; convert a byte slice to a string and then compare it directly. Surely you're not forgetting about Unicode Normalisation too?
I agree with everything you said so far, yet fail to understand why any of it makes it better to not use frameworks.
Why do automatic interface implementation or types make it better not to use frameworks? Of course I appreciate the differences between go and Java, I'm not sayings they're the same thing, just that for the purpose of deciding wether you benefit from frameworks they are no different
 What's the cli equivalent for Tools -&gt; Memory Snapshot? Is it `gcore`?
Having used serverless, lambda, and its variants for a few projects my point of view is simple: It is insanely easy to get going. Clearly the "up" service makes it even easier. Bottom line is a lot of developers are not comfortable managing servers. Handling security, updates, deployments, backups, etc. Serverless architectures remove that burden. They obviously increase the cost, but for a proof of concept or a light usage system that cost is literally pennies. I have a friend that has a service that gets a couple thousand requests a day through his site. He pays AWS practically nothing. As for how you monetize - no different than any other business. Serverless just changes your operating costs structure. I have also seen companies build out on lambda then move to their own infrastructure once the cost outweighed the benefits. &gt; Do you use serverless like each one is a microservice, and then you deploy an API somewhere (also serverless??) and somehow charge for API requests, that then make calls to other serverless modules? Serverless is just an automation platform for hosting. How you architect the interaction is up to you. I have seen serverless used by some banks that get a couple dozen of a certain type of integration call from partners per day. The lambda function basically transforms the request, stores it and drops in a queue. Bottom line for me: this technology is a tool. Imagine the number of technology projects that fail. This is a tool to reduce the ramp time. Nothing stops you from switching from serverless to your own infrastructure, especially if you use a tool like "up" that insulates you from the Lambda SDK events and such. 
There is a hasher interface. Have a map from string to Hasher then use that instead of the Sum shortcut function. 
\&gt; yet fail to understand why any of it makes it better to not use frameworks. The advice is **not** "it's better not to use frameworks". The standard advice is "it's better **not to start with** a framework". Two reasons spring to mind: 1) Among all the languages you listed, Go is the only one that was written after the Internet and the Web were popular. It's the only one were all the internet protocols were designed right in the standard library (and along with the language). In other languages, saying "I want a web server" also means giving up writing "standard code" and being forced to adopt a library like Tornado or Event Machine. You need this because all modern servers have more than 1 CPU these days. (Heck, my cell phone has 4 CPUs, and it's getting old.) Not all libraries were written to be compatible with those hacks. If you add a framework after writing your code, you can easily get yourself into trouble. &amp;#x200B; In Go, all code is goroutine safe. (Sure, it's possible to write broken code, but you'll get complaints from the built-in go race detector, from the built-in go vet, etc. Not being goroutine safe is literally violating the language, not some 3rd party library.) &amp;#x200B; 2) Frameworks come and go. Seriously, there are dozens of them in every language. Even in Ruby, Ruby on Rails isn't the only popular framework. In a typical language, writing your own framework is nuts. But in Go, the standard library will get you pretty far. And if you feel some abstraction would help, you will have a better idea of **"what problem are you solving?"** The reason there are different frameworks is that they make different trade-offs of abstraction, performance, etc. And if you do implement a framework, very little of your code needs to change. That's because they **all** re-use the same parts. (Standard HTTP functions, contexts, etc.) &amp;#x200B; The advice boils down to: "for many tasks, choosing a framework in Go is actually more risky, since it could force you into some abstraction that actually makes your problem harder." Don't apply the advice from other languages ("It's better to choose a framework early") to Go.
Go doesn't compile to C++, if that's what you were implying. But even that aside, Go and C++ are very different languages. It would be very hard to establish a connection between the two. Go can call C code no problem, but it's not super performant (it's usually not a dealbreaker, though). The problem isn't that Go isn't written in C, the problem is just the differences between the languages themselves.
*OwO, what's this?* It's your **5th Cakeday** JamesIsSoPro! ^(hug)
I'll disagree with you on that one shouldn't subscribe to such a newsletter. Sure there are advertisements, but there's nothing wrong with them if they're clearly marked and are compensation for the author/organization spending time putting it together. I'm not going to spend a lot of time sifting through subreddits to find good news, and the utility of such a newsletter is to get a quick digest. It's made by a [professional publisher](https://cooperpress.com/publications/), but they're professional, consistently publish content, and have experience with this kind of journalism. How is it different than a newspaper? And I wouldn't say "copy-pastes" content from reddit, it just aggregates content like the subreddit does. The news isn't "old" as much as it's not "bleeding edge" -- You'll find more new news on this subreddit and hackernews, but you have to sift through a lot of junk. Thanks for the link to the getrevue newsletter though, it looks better than what I've linked.
I think you'd get more attention if you wrote what your project does, and what sort of people might be interested in it, and such. The fact that you worked 12 months on it and believe you're at a "1.0" release level is not a compelling reason to click on a random github link.
Your/someone's attempt to use github.com/golang/lint as an import path would have failed without modules, too. https://github.com/golang/lint/blob/d0100b6bd8b389f0385611eb39152c4d7c3a7905/lint.go#L8
[removed]
For triple A development it's too slow and doesn't provide enough control. That being said, C# is used in unity to a great extent. So I don't see a reason why Go couldn't be employed for more simple games. Most likely the main issue is tooling?
[removed]
[removed]
The funny thing is that, when I was lookin at the *first* implementation, I was thinking: “ugh, this is O( n^2 ), it can be done in O( n log(n) ) or O( n )”...
[removed]
Ditto, if you think it’s so shitty, make your own. As of now, it’s the best. 
Did you happen to notice the `query` rule? You could actually trigger database querying to validate incoming requests? Any scenarios you think all this won't work!?
[removed]
[removed]
repeating an almost identical piece of code for each case just sounds like bad practice, I assumed there'd be a nicer way.
Just started writing blockchain node on Go half year ago and I loved it. Go syntax and principles are much more pleasant. I tired of all this OOP stuff. I like Go for its simplicity, for its standard library, for its goroutines. When you reading code on Go, it's like a pleasant walk, without huge amount of pointless abstractions and dependency injections. So, now I questioned myself. How to write an enterprise web app with Go? Cause, let be honest, currently most applications are web applications. And I definitly don't want to turn back to Java or even Kotlin. 
\+1 Sometimes returning an interface is just the best option. There are many instances in the standard library of this (such as functions returning hash.Hash and image.Image)
[removed]
[removed]
[removed]
[removed]
[removed]
[removed]
Fun fact: The myriad of symbols in a golang binary have a strong utf8 bent to them. This is why "Hello World" takes 3 MB.
Well, it's an LSM so it's "like LevelDB" (more suited for a high write-to-read ratio). I'm not aware of any production quality LSMs written in Go.
[removed]
You do make a fair point. Its true if not taken proper care it could be dangerous. For now the default mode is deny. So if you haven't mentioned the table name in the config file no operation will be allowed. Any suggestions on how we can minimise the risk? 
[removed]
I don't understand the logic for why using a temp variable temp := md5.Sum(data) hashed = temp[:] is better than this. hashed := md5.Sum(data)[:] I would never allow my team to write this specific code with the unnecessary intermediate temp variable. It is not more readable, "temp" conveys no extra information to the reader, it's not faster. The non-temp version is not considered "cleaver"... it's just normal every day programming. I would be curious why this choice was made. It must be some other reason that is not obvious from this code snippet. &amp;#x200B; &amp;#x200B;
I know, I don't want to use it. But doing `hashed := md5.Sum(data)[:]` doesn't work for two reasons: - Defining `hashed` there will scope it to the case, so I can't use it anywhere else. - You can't take slices of the result of functions (i.e. `md5.Sum(data)[:]`)
Capture Memory Snapshot is meant to be used for the IDE debugging. If you want to debug a Go application, see this post https://blog.jetbrains.com/go/2019/03/04/debugging-with-goland-advanced-debugging-features/
[https://github.com/contribsys/faktory](https://github.com/contribsys/faktory)
Yeah AWS always refuses to do what actually makes sense, but I recall Google’s having much worse performance than Lambda, hopefully that will improve though. 
Sorry, I should have tested this first before I posted. I didn't realize you couldn't take a slice of the result of a function. In case anyone is curious, the error is invalid operation md5.Sum(data)[:] (slice of unaddressable value) &amp;#x200B; &amp;#x200B;
Start with standard "net/http" package. After that if you felt you a specific need that standard package can't provide than reach for other libraries like mux,gin,chi,... to name a few. 
I’ve found echo very easy to use.
https://awesome-go.com/#web-frameworks
Echo and gin, my favorites!
Bad bot
Thank you, iwaneshibori, for voting on CakeDay--Bot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://botrank.pastimes.eu/). *** ^(Even if I don't reply to your comment, I'm still listening for votes. Check the webpage to see if your vote registered!)
this!
You can use something like package main import ( "crypto/md5" "crypto/sha1" "fmt" "hash" ) func doHash(data []byte, algorithm string) hash.Hash { var h hash.Hash switch algorithm { case "MD5": h = md5.New() case "SHA1": h = sha1.New() } h.Write(data) return h } func main() { unhashed := []byte{0, 1} h := doHash(unhashed, "MD5") fmt.Printf("%0X\n", h.Sum(nil)) } https://play.golang.org/p/8-yAyIj-C17
Thats nice advice! Thanks
Thanks! This ended up working :)
&gt;.Association("Ingredients") Yeah, doing that gives me runtime error: invalid memory address or nil pointer dereference &amp;#x200B;
I used to use chi but echo is a quite cleaner with JSON responses - I'm also enjoying it.
Another upvote for Gin.
FTR: The issue was triggered by an interaction between AdBlockPlus and the mandatory banner presented when accessing the link from an EU country, with the usual BS like "Please review Tumblr’s updated Terms of Service and European Privacy Policy.". I want to live in USE (U.S. of Europe), not in this fucked up EU ruled by a bunch of non-elected morons :-( 
I'm enjoying Echo now, and only used chi before :P What do y ou prefer about Gin?
I found it more fiddley to control the log formatting in Echo. There seems to be more than one place where loggers are used so setting the formatting middleware doesn't change the echo server logger. I think the middleware is a little simpler to write in Gin. Echo server seems to want to control an instance each of a http and tls server, where I might want to start two instances of tls on different ports with different server options. Gin seems simpler in just passing the router to multiple listeners. I completely accept that I might have overlooked alternate usages of Echo. 
I find it great. I'm just some guy
Well, I wouldn't call it journalism, if this is what this publisher dares to claim. How is it different than a newspaper, you ask? A newspaper exists of articles written by their own reporters. If Golang Weekly would be like that, I would feel you when you say 'compensation for the author/organization spending time.' Golang Weekly doesn't exist of an author, it's only curating content. Professional, you say? Still cashing advertisement money for poorly curated (from Reddit copy-pasted) content, doesn't justify advertisement income in my opinion. Only if it would be given back to the true authors, the bloggers that are now providing somebody money that otherwise would have to seek another job
&gt;anacrolix In that case you'll find the other one even a lot greater.
https://iris-go.com I've used iris and it's quite nice and simple!
The greatest resources I found https://programming.guide/go/ https://github.com/golang/go/wiki http://golang-examples.tumblr.com https://github.com/GoesToEleven/golang-web-dev?files=1 https://golang.org/doc/effective_go.html#Getters Or I just share my notes https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
I played with a few before settling on [gobuffalo](https://gobuffalo.io/en) . Before you go and start with the standard library I recommend [watching this video from Mark Bates](https://m.youtube.com/watch?v=J0JnHNgPMRk) on why have a framework rather than use the stdlib. Building a web app takes more than just solving http.
A huge portion of the news in a newspaper is not actually written by a newspapers' own reporters. Articles get aggregated and resold. The aggregation here is still ultimately sending additional traffic to the bloggers 
...this is so sad.....
What do you mean? 🙂
For loops don’t create a new namespace for each iteration, so if you write a closure over `i` it will end up with the wrong value. The corrected example copies `i` to `j` and closes over that, so it works as expected. 
You might be a bit more idealistic than me. My point was that it's alright to subscribe to a subpar newsletter. It's helped me get some news.
Same here. Some guidance will be much appreciated
This is what I got so far https://github.com/pions/webrtc
I reply to this comment just for reference, just in case anyone wonders (like I did 30 min ago) why I got downvotes on my comment. I've used it a couple of time and I haven't had any issues, that's why I recommended it. But since I got a few downvotes today, I decided to google (probs I should've done this earlier) why you should *not* use it. I've found this article: http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html?m=1 Reading through it, looks like the author isn't doing legit things neither with the repo nor with the stability of the framework. Definitely worth a read. Saying that, I don't recommend iris, or at leastif you want to give it a go, read through the problems that it has around it. Thanks for the downvotes to make me google that, I'll definitely try something out next time! 
I disagree insofar as the direction the [draft](https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md#draft-design) is heading is that all the error handlers need to be declared *before* the `check`. So in the best case scenario, where "best" = separation of error handling from business logic, the function begins with a number of error handlers *and then* you get to the logic of interest.
*crickets*
I shouldn't respond (because you've not really said anything, especially in the thread with u/bobappleyard), but have you looked around at common code produced in any language? We don't generally pre-optimize code in real life situations due to time and/or other constraints *unless* the performance penalty is plainly obvious.
&gt; Go decided to make error handling a first-class citizen You mean with the new draft proposal for error handlers or something? Because right now error handling definitely does **not** have first class citizenship. `err` is just a value like any other.
I use errgroup to kick off large number of tasks concurrently that all need to complete before proceeding to the next step. Every task, once completed, is marked as finished. If one of them fails, I log the error and kick off the remaining tasks until everything completes successfully. In this case errgroup behavior is desired and would be useless otherwise. Kicking off tasks again while previous ones are still running would cause duplicate tasks to be executed. In the end, errgroup is just a wrapper around regular waitgroup that makes error handling easier. &amp;#x200B; And in general, when doing stuff like that, you wait for goroutines to finish or, at least, move to a state where they can't cause trouble by running concurrently. Leaving goroutines running in an unknown state is bad practice. Their lifetime is your responsibility.
And yet, you just side-stepped my point. It's about *how* we should handle errors, not *if*. &gt; What happens on the "happy path" is so trivial that even business people can understand and describe it. This is a **good thing**.
Vue + Vuetify
Well, that is exactly what the new proposal for error handling will have you do.
Overall, I stick with the Gorilla toolkit, using Mux, sessions. For DB work, I use SQLx on top of database/sql, which provides a few niceties. For form validation, I use my own project, gitlab.com/Artemix/validator-go
There's a data race on the Upgrader.CheckOrigin field. Fix by setting CheckOrigin in the composite literal instead in the handler. The example CheckOrigin function should not be used in an application that uses cookies to identify logged in users. I suggest serving index.html from the Go application so as to eliminate the need for the CheckOrigin function in the first place.
Can you do it faster without incurring additional space complexity?
Would love to hear more about this part as i'd like to avoid webpack Interesting getting Go's template engine to handle the component merging, too. I don't use Webpack or Babel, and instead just have a template for each component, and merge the components to a single inline script tag in the HTML for the page. Load times are good, and not having to deal with Webpack's bullshit is awesome :)
I love both go and Javascript. Perfect combo IMO. JS is perfect for front end dev because of its dynamism. 
Good catch, Ill update the text when I get a moment! Thanks for your feedback!
As a side note, how is the c interop performance when using gccgo? IIRC I've read mention that gcc doesn't take as big of a hit when calling c functions.
You can use Vue in a plain old HTML page just like you would jquery. No need for webpack or other bundler. 
I think people have the misunderstanding that you need to use webpack for stacks like Vue. You absolutely do not. Only if you want to use .vue files.
&gt;While reading or writing business logic code, isn't it less cognitive heavy to handle errors as close as possible to their source? Think fail fast and early. I find it less cognitive heavy because I prefer the bigger picture first, *and then* dive into the details. Failing fast and early on *preconditions* makes sense because they're part of your function's contract, but failing due to an error returned by a third party library is just typically *implied* in your contract. The typical pattern in these cases is to simply return that error. Look at [this](https://github.com/go-swagger/go-swagger/blob/873540c64f4fe25ef1d4859f6f9400c53d421eac/generator/model.go#L53) example from go-swagger. Out of a total of 7 returns, I count 4 instances where the error is returned with no additional decoration. The final `return nil` is just there because the function's signature requires it. These 5 instances add no value to this function and are there just to fulfill its signature. &gt; I'm asking because that's what I've been doing all my life and so I can't judge if that's better than having the happy path separated from error handling. I'm truly interested in learning this different mindset of handling errors and would appreciate if you could point me an example repo to grok. I suggest you look at a language with exception handling and then rewrite some stuff with it and make up your own mind. Or you can also look at how some Go packages actually use panics internally but recover from them just in time to translate them into an appropriate error for the caller - see https://eli.thegreenplace.net/2018/on-the-uses-and-misuses-of-panics-in-go/. This benefits the developer of the package, but the caller is still left with no other recourse than to check if `err` is `nil`.
Version in the http header
in the URI
Premature optimization and selecting an O(n) algorithm in favor of o O(n^2) one, particularly when the code complexity of both options is about the same, are two unrelated concepts regardless of any attempts to pretend otherwise. "Most code doesn't care whether it is O(N2)." is either bad engineering or ignorance. I wonder what's the choice you are trying to defend? Don't get me wrong: Linear search, for example, beats logarithmic search for small n, sure, and that's a special case. But still, that's _not_ the same as "most code doesn't care ...", because that is simply false. _Some_ code, as exemplified just now, may get away w/o caring, but _most_ code definitely does and must care about the complexity class. Most code are not special cases, but the boring production code that may accidentally need to scale - while the original coder didn't foresaw that and left the company years ago, so now nobody knows what the hell is going on.
I'm using Echo and enjoying it. The documentation is slim but efficient. I wish there were some more advanced examples but what's there is pretty easy to follow to get you started because the syntax just makes sense.
Look at [pinned](https://github.com/sjkaliski/pinned) 
Sorry, thanks for the clarification. I dont know how I got the impression it transpiled to C++. Thanks for the clarification.
Probably the best framework-like thing I've seen in go is [goa](https://goa.design). I definitely suggest reaching for what the other commenters have suggested (just using "net/http" and then adding in gorilla or similar) while you get your bearings, but once you start wanting to build APIs, make swagger definitions, and a CLI, goa is nice because it handles the boilerplate and generates type-safe and generally quite readable / debuggable Go. It's also nice that it doesn't force you to use it everywhere, so it can be scoped to just your API surface if you want.
[removed]
Hello all, My emacs go-lang setup is more or less the same as https://lupan.pl/dotemacs/. I get suggestions from company-go for standard library (like fmt for example), but I don't get any suggestions from my own packages (that i am writing currently) whose sources reside in the same GOPATH. Any idea can be done to make company-go suggest completions from my own code ?
Okay. I hear your point. Thanks for your feedback.
well, tbh i've thought you are just another one of the authors alts to chill Iris, seeing you have a new account with basically no other post ;). No offense.
“My server” - if Templar’s rendering is really the bottleneck then you have a good and relatively easy problem to solve. Focus on the product instead of your template rendering engine. 
Lol none taken, I understand I don't have any other comment so I might look suspicious. Just wanted to clarify it anyway just in case someone's not aware of iri's issues!
&gt; html/template is a pleasure to use. It's very simple and it escapes HTML for security. However, my research suggests it does not scale well at all. I don't want to deploy this app using html/template then have to completely re-write the rendering logic if it gets really popular. Worry about it later. Chances are your app will not get popular. I hope it will, but odds are just that it won't. So most likely it'll be a non-issue. Premature scaling is the root of all evil ;-)
Hm, i think it's important to know HOW dynamic your site (or app?) will be. I won't classify a few update on comments every now and then as highly dynamic. Keep in mind you can cache responses if it ever becomes a problem. Suddenly populating templates with data get's erased from the equation. Go's html/template package isn't the fastest.... but honestly: if you ever reach the point where it actually becomes a problem you'll most likely be able to make enough income to sink in some time to optimize further. 
func (vm *VM) Run(instrs []*Instruction) error { vm.loadInstructionsInMemory(instrs) vm.printIfVerbose("Execution flow:\n") if err := vm.instrLoop(); err != nil { return err } return nil } Last 4 lines can be replaced with return vm.instrLoop() 
Also avoid putting commented code in master branch
I haven’t heard of errgroup until just now, but you can achieve your desired behavior using the errgroup.WithContext(context.Context) method. Create a context of whatever flavor you want. A cancelable context or timeout, or even a basic background context. Whatever. The second returned value from the call should then be passed into your functions. If doing a web request, pass that context to it. Anything without context support you’ll need to implement, but most things in the standard library have support now. If one routine errors out, it will cancel the rest immediately and you’ll get a return on the waitgroup. Errgroup just seems to be a convenience wrapper around some primitives. You can easily roll your own to behave however you want. If you want it to return all of the errors you can use a channel attached to a waitgroup. 
Prefix the URL. Https://myshitshite.com/v1/endpoint If you neglected to do so when starting, that’s fine, just prefix v2 and onward. Use symver as well. So don’t bump the version unless it breaks the old one. You can add new endpoints or functionality without bumping the version. 
Just sort the second list for log(n) lookup time
&gt; "Most code doesn't care whether it is O(N2)." is either bad engineering or ignorance. I wonder what's the choice you are trying to defend? My answer is: none of the above because "bad engineering or ignorance" is a false dichotomy. Most code just wants to *get the job done*. And I still think you're thinking in terms of pre-optimization. Our discussion arises from OP's example #1 where the job is to find the intersection of two lists where the elements happen to be numeric. Yes, OP's example is the straightforward way, and yes, there are more performant ways (that typically sacrifice other things, like readability). So now let's say OP's code meets all requirements, is well-tested according to those requirements, and has worked in production for *years* (huge win). Changing performance requirements does **not** automatically mean his code was the result of *bad engineering or ignorance*. It means the software needs to be changed in order to fulfill this new requirement. That's all.
&gt; My answer is: none of the above because "bad engineering or ignorance" is a false dichotomy. Most code just wants to get the job done. And I still think you're thinking in terms of pre-optimization. We can agree to disagree. ---- Okay, you like and/or prefer shitty code for no good reason. I don't. And honestly, it's simply because I wrote a lot of shitty code myself during the years/decades and it kicked back so many times. So I learnt my lessons. Good luck with yours. 
Both. B should log something "Failed to query %EXTERNAL\_RESOURCE%", A should log "Failed to query B/something\_you\_need\_from\_B". You should propagate RequestID during your call and include it in both logs, so that later you can join logs from all services involved in processing a single request.
That's quite possible, but I can't really tell, because I've never used GCCGo :)
And to extend on that, the logs from both should be sent to a central logging server.
Great video! Thanks for this.
I'm glad you liked it! :D
I personally use https://github.com/valyala/quicktemplate when doing server side rendering, not even because of the performance, but because I like the syntax a LOT more than Html/template . The performance boost is just a welcome side effect
Thanks that's a nice suggestion. Would you have any recommendation? I was planning on storing logs in Redis but that might not be the best solution out there.
Im pretyy new in golang, and everytime I do sth I struggle to find any decent sources or tutorials and when I finnaly manage learnbit by myself, there come those great tutorials. Why cant I save up time sometimes... 
[removed]
You're going to want to use an interface and reimplement a mock ES client like you show in your last example. The interface should look something like this: type EsClient interface { // You want all the methods that you use in the client here. Reindex() EsClient // ... } And then you'll accept this interface in your method rather than defining the method on the struct itself: ``` func reindex(ctx context.Context, es EsClient, indexName string, mappings, settings map[string]interface{}, includes, excludes, types []string) error ``` Your EsClient interface needs to have every ES method you use in your methods because in that case, the actual ES client will satisfy the interface and then you can pass either the real ES client or a mock ES client into your method. Here's an article I just found on Google explaining this same concept in much more detail: https://nathanleclaire.com/blog/2015/10/10/interfaces-and-composition-for-effective-unit-testing-in-golang/
Redis is not even not the best, it's a completely wrong tool for that. ELK stack is the standard way of storing and analyzing logs. You can ditch LogStash for something simpler and lighter but ElasticSearch and Kibana is the way to do it.
Replied to your question on github, copied here for redundancy: The issue is you do not have an index on projections for steamer_id. ```sql CREATE INDEX idx_projections_steamer_id ON projections (steamer_id); ``` XO will see this and generate code like: ```go // ProjectionsBySteamerID retrieves a row from 'public.projections' as a Projection. // // Generated from index 'idx_projections_steamer_id'. func ProjectionsBySteamerID(db XODB, steamerID sql.NullInt64) ([]*Projection, error) {... ``` Note, this is an accessory method, not directly attached to the Players object. Use it like: ```pp, err := ProjectionsBySteamerID(db, myPlayer.steamerID)``` Unrelated, any reason not to use projection.player_id = player.id as the FK instead of the surrogate? NB: I use postgres so have not tested this in mysql, but when translated to psql syntax it works as described above 
like /user/Sambooi says. also If you're building a SaaS as project I would shamelessly plug an open source Go library I'm working on https://github.com/dstpierre/gosaas it might help you with some starting point ideas on using net/http alone
Is there an example that you personally prefer ? If so, can you provide the link please ?
I would start with this book: [https://lets-go.alexedwards.net/](https://lets-go.alexedwards.net/) &amp;#x200B; I am about a fourth of the way through it and, so far, it is the book I wish I had when I was first learning how to build web apps in Go. So far, he has used only standard packages that come with Go and he has really given clear explanations on why he does what he does and how to properly structure a project. This is something that I think is one of the hardest things to figure out in Go when coming from another web framework like Ruby/Rails.
Question. How do you determine how many sockets a single server can handle at one time? I am thinking if I deploy my Rest API in the cloud, and want real time updates using websockets, there has to be a way to ensure my 1 instance that I pay so much a month for can keep all those sockets open. Does the back end possibly "pause" sockets to handle a lot more of them, so to speak? Or do you just have to spin up (and pay for) a lot more instances to handle say 1000s of simultaneous connections? Is it common for the client developer to read docs that indicate a socket will only stay open for say 10 seconds, then close, so the client should listen for a 500 or 400 or something, and re-establish the connection? Is that a typical work flow for using sockets so you can handle a lot more without having to spend a ton scaling to handle the load?
Large application follow https://github.com/golang-standards/project-layout which the article you posted follows to some degree (some differences) A good example of it being used is the Kubernetes project; they have multiple commands (programs) under one repo. https://github.com/kubernetes/kubernetes Other Go projects like etcd or cockroachDB are also good to look at. For a large scale monolithic web application look at Mattermost (Slack clone) which is open source too.
No, it's not a thing. This is one of those arbitrary "senior developer has important opinion" pieces that is cultural detritus 
So typically, Go will spin up another Goroutine per WebSocket connection. This will be kept open indefinitely until the server or the client kills the connection. You could consider doing things like pro-actively killing WebSocket connections on the client if they are inactive for X amount of time, but then if you have to send state to your client on WebSocket connection then this might not be the best approach. I would recommend checking out: [https://medium.freecodecamp.org/million-websockets-and-go-cc58418460bb](https://medium.freecodecamp.org/million-websockets-and-go-cc58418460bb) which covers some of the memory limitations in section 2.3 and some of the extreme optimisations you can implement in order to handle more socket connections. I would also possibly consider using 2 slightly smaller servers and putting them behind a load balancer if you want to make your system more resilient. I hope this helps! :D
Organizations at the scale of twitter and facebook typically have many systems and APIs both on the front and backend, and usually employ some sort of gateway to bridge a lot of them into unified endpoints. In the case of what you’re describing though, the web app is likely still communicating with an API, but it is being passed by proxy at a different URI path (I can’t speak to this though, not a twitter developer.) 
Assuming you meant non-commented code... :P
&gt; I would also possibly consider using 2 slightly smaller servers and putting them behind a load balancer if you want to make your system more resilient. Ideally also autoscale them based on the resource usage, active connections or some other metric.
Attack people personally? I don't see a personal attack anywhere in his post. Unless you see it as an attack when someone tells you that you don't know what you're talking about, which may be false, but it's not an ad hominem. Furthermore you didn't respond to his points at all, just deflected by acting concerned about a 'fruitful discussion' and in turn honestly proving him right.
Maybe some thoughts on this? Advices?
Stuff like [this](https://github.com/ViRb3/brookshear-vm/blob/66789fcc188712cee069556859f81b40a8fe5f96/pkgs/cmd/decompile.go)
I have implemented your suggestion, thank you!
I have fixed that, thanks!
Thanks. I plan to deploy with Kubernetes, have auto scale, etc in place.. what I wouldnt want though is for auto scale to kick on 200 instances and suddenly I got a crazy bill I cant afford. Naturally I would set limits, do lots of testing, etc before hand. But I was just curious about this as I have yet to do any real websocket work. The other thought is why not set up a Callback system, webhooks, rather than web sockets. Not enough experience with this yet either, but prior to web hooks we used a sort of API interface we expected clients to implement and provide us with a URL where by we sent back requests based on that API. Essentially web hooks before it became a thing. I am guessing this depends on the consumer/client though. Mobile devices and desktops may not be able to provide a good URL to get to them.. especially behind firewalls, etc. 
I see that as a great example to drive home the point that your application shouldn't be a web application, but an application where the web is one of many possible interfaces. Too many web frameworks focus specifically on the web part and do not detail how you might reuse the code in other environments, which leaves a lot of open questions for inexperienced engineers, which leads to not properly separating concerns more often than it should. Experienced engineers understand how to architect an application so that is not an issue, but they don't need the hand-holding to begin with as it relates to this discussion.
What would one use mmap for in a Go program?
The Transport.Proxy field is already a function that returns the proxy per request.
It is used for Databases and other such programs. For instance here in Bolt: [https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/bolt\_unix.go#L50](https://github.com/boltdb/bolt/blob/fd01fc79c553a8e99d512a07e8e0c63d4a3ccfc5/bolt_unix.go#L50)
Make sure you're only checking .go files.
I disagree with this 100%. Over engineering to optimize everything might be an issue, but planning ahead and doing a little bit now that ensures/takes advantage of knowledge others have already been through could be the difference between the app starting to grow/crash/fail and start to grow/can handle some load/scales easier/faster. There is nothing wrong with trying to spend a little time now planning ahead and taking some steps that can put the app in a better position to handle more load/scale than just wait till it is a "good problem to have" then hope you can figure it out.
Took our IT guy over 8 months to implement this. It is a very heavy weight solution. Does offer a lot of power.. but for me this only makes sense for large organizations with multiple products, etc. For a single app being used by multiple microservices, I would go with something much smaller/faster/lighter. I dont have a recommendation though.
How do I go about doing this?
"Never think about any scaling issues" and "optimize everything" are two extremes. To clarify, I never argued you should *never* think about it. In general, I've found that focusing on just writing good – or at least *decent* – software will prevent many performance/scaling issues from occurring in the first place, and will make it fairly easy to fix most of the issues you do encounter later on. In particular avoiding complexity is important; it's much easier to replace 50 lines of code than it is to replace 500, and the ode you never write is even easier to replace!
&gt;it complains not satisfying all requirements That is the exact problem it spits out. 
1. nothing happens, it appears to succeed 2. `ERROR: (gcloud.app.deploy) Your application does not satisfy all of the requirements for a runtime of type [go111]. Please correct the errors and try again.`
Figured it out, turns out for flex environment, the runtime has a different format: `runtime: go1.11`
Agreed, and fair enough. 
I feel for you. You don’t have friends yourself? Do you need me to become your friend?
Hi /u/coding2fun, just a couple of comments. Something worth mentioning is that the linked list implementation actually does more work than the array implementation. To find an item in the array you can perform a binary search with memory address offsets (which sort.Search will do for you). To find an item in the linked list you need to traverse every memory location. So it's not just caching effects we're seeing here but algorithmic inefficiencies. We have to access more memory locations in addition to straying outside the CPU caches. As an idea, you could implement a binary tree instead of linked list, or you could rework the code to have a second array example with much more data in each struct (reducing the number of items per cache line). I think either of these could demonstrate the effects. Also, any sequential access in the array example might also be benefiting from the prefetcher (a useful cache effect) in addition to a hot cache line. Thanks for putting up this example. This kind of thing is interesting to lots of people and it's nice to see some go examples coming out. Also it'd be helpful to [link to the benchmark code](https://github.com/KishoreKarunakaran/Coding2Fun/tree/master/Blog/Understanding%20CPU%20cache%20friendliness/cache) so others can reproduce your results and play around with it. I looked for a link on the page and I'm sorry if i missed it :) There are also some other neat examples of this kind of thing here: [https://github.com/Kobzol/hardware-effects](https://github.com/Kobzol/hardware-effects)
I agreee on the algorithmic differences. The comparison solely based on cache is not correct imho.
I'm learning golang for web. Nice tutorial, thank you.
I understand, the linked list implementation does more work than array since we use sort.Search in array but in linked list you have to traverse to the required node, Even if you didn't perform binary search for the array instead find the required element via linear search then also you can reproduce the same i.e. array is faster than the linked list. Yes I've updated the benchmark URL link the [medium blog](https://github.com/KishoreKarunakaran/Coding2Fun/tree/master/cpu_cache) Thanks for the [hardware-effects](https://github.com/Kobzol/hardware-effects) repo
Based on BigO, searching for an element in array and linked list have O(N) but with different constant factor
True, with the very naive solution of just iterating through all elements which you never should do in a sorted array.
There is another template engine that is among the fastest ones and is not compiled, also its syntax isn't weird it's called [Jet](https://github.com/CloudyKit/jet).
Isn't search through an array of sorted elements O(log(n))?
Well if you are applying binary search yes it's O(log(n)) but for linear search it's still O(n)
Of course but why would you ever use linear for it? In the example, binary search is being used (sort.Search).
nobody said anything to the contrary, agreed
Right, In the code I've used sort.Search(Binary Search), Even if you didn't perform binary search for the array instead find the required element via linear search then also you can reproduce the same i.e. array is faster than the linked list. 
[This](https://stackoverflow.com/questions/54499650/deploying-helloworld-to-app-engine-flexible-with-go111-fails) suggests you may need to change `runtime` in your app.yaml to `go1.11`.
In Kubernetes you limit to how high an auto-scaler can go though, so that's not something to worry about. Regarding WS servers and number of connection limits, it depends a lot on what your server does per connection. You need to figure out the amount of resources you require per connection (i.e. #go-routines spawned for it and their mem consumption, []byte arrays, etc.). The 1 million websockets article focuses on this part a lot, and mainly reducing the amount of memory required per connection. This article has a bare-bone server though, it does nothing per connection. I assume you will do a number of things per connection. 
WoW, This is what I'm looking for. Thank you so much.
Yes, of course, it is ok. But I just see that there's a better alternative, not only in terms of ethics but also in quality
Also, is this not a stack vs heap question. How was it measured that you were getting cpu cache hits
Are you not aware of the fact that newspapers pay money for press agencies' reports? That is a fair business model. What is not fair, is a business model where you did not produce the content you offer yourself, additionally did not pay for the content, yet still cashing money on copy-pasting via advertisements. The other weekly doesn't have a business model, there are no advertisements shown in it
This isn't really a Go question as far as I can tell. You are asking about intricate design compromises that nobody here can really help you with because we don't know what you are building and what the use cases are. Your post is also all over the place and very difficult to follow, it would be better if you provided the following in a structured way: * This is what I'm building * These are my options as I see them * This is what I think about each option. From what I can glean from your post I would just use a message broker and create small services for different features and separate the front end REST API from those services by communicating over the message broker. For example in your last paragraph you are struggling to find a compromise when different API's want to create an order with different attached behaviors. Just accept an Order message on an appropriate message subject, this way any service, whether it is the front end public API or some back end service can create an order simply by publishing it on that subject.
Here is [a benchmark](https://github.com/go101/go-benchmarks/tree/master/cpu-cache) which shows the effect of CPU cache. 
&gt; The fact that my parent comment gets heavily downvoted, shows the sad state of the web development as a result of uninformed, uneducated yet arrogant developers making poor design choices for the rest of the users. That's a really arrogant statement. Has it occurred to you that thousands of web developers choosing to use a technology is an indication that they get value from that technology, and your refusal to see it is an indication that you don't understand the technology properly? I'm like this with Docker. I still don't get the thing with Docker, even after having tried it. Either the entire rest of the industry are idiots, or I am. I'm beginning to think I am...
looks OK, but I'm never going to pick it over github.com/pkg/errors. Might help if you said why it's better/different than go.uber.org/multierr instead of just "inspired by" - what inspired you about that, and why did you feel the need to create your own?
The best advice I've heard on creating a microservice architecture from scratch is... don't. Build a monolith first, get it working and serving customers, and go through the first few months/years of massive iteration and change. Only then will you know the problem domain well enough and your traffic and usage patterns will have settled down enough to be able to make sensible decisions. Once you get to that point then the lines along which things need to be split out will be obvious. And if there aren't any, then you don't need a microservice architecture. 
I am trying to say that performance in Go is a well balanced compromise of multiple factors, whereas C worships runtime performance. Checkout "zero cost abstractions", such as [https://joshpeterson.github.io/a-zero-cost-abstraction](https://joshpeterson.github.io/a-zero-cost-abstraction). &amp;#x200B; The bug i personally introduce the most is the so-called Obi-Wan error (off-by-one). Go's runtime checks is exactly what I need, happily accepting the performance impact because runtime performance is still excellent compared to C and WAY ahead of Shell and Python.
sorry, I'm not sure what you mean by a typecheck...?
&gt; Based on algorithmic complexity, we know list is the better choice for this problem, since inserting an element and deleting an element from a linked list without moving other elements. No, that’s essentially never true. There are basically no real world use cases where linked lists have good performance. 
A binary search isn't cache-friendly
Those files end in .s, not .go. They are assembly, not Go files. 
Relavant: [What is a concise way to create a 2D slice in Go?](https://stackoverflow.com/a/53575298/452281)
Code complexity linters usually calculate how many branches the function can take. With properly formatted code it's not possible to have this too high for a small function. 
I second Gentlemen-Tech's point. We are currently finalizing the first validated version of a not-so-micro-service application based on a previous monolithic version of the same service developed by the same team. Finding good boundaries is still very tricky. Especially once performance considerations and permission handling come into play. We have solved the problems you mention as follows for this project: \- At the edge of the network, there is a reverse proxy handling user authentication and session-management, which provides respective id-tokens to all upstream services \- A graphql-api-service handles all api requests and forwards them via grpc to various upstream services, using grpc-middleware to forward id-information to the respective services \- Every service hosts its own database and is built with at least a use case package, implementing all grpc service methods, and a separate repository package, thus enforcing encapsulation of the database layer \- Permission checks and email sendouts are implemented directly in the use case layer of the respective services \- The actual sending of emails is implemented in a separate micro-service, which other services directly connect to \- Requests that require asynchronous flows or information from multiple services are orchestrated at the graphql layer, which also enforces a certain timeout for all requests. &amp;#x200B; So far this approach has worked quite well for us. We were also looking into a message bus based approach but decided against it for two reasons: \- Transmitting larger payload data usually needs to be implemented separate from the message bus \- With the current setup, the main business logic, includinge email sendouts, is contained in the use case layer of each service. This makes it easy to understand what each use case actually does. Using a message bus approach, you would send the same message into the bus over and over, until all required services have processed the request and have added all required response information upon which a final service would send the response back to the client (can be implemented with response-topics). This is very nice in terms of composing and load-balancing. But it can sometimes get tricky to really understand the application flow, unless you are very good at documenting this kind of stuff and keeping the documentation up-to-date. &amp;#x200B; We also saw, that from an end-user-perspective most users expect an immediate response to an action – i.e. clicking the save button should result in a notification that the data was saved – and having asynchronous notifications to such actions is sometimes difficult to put into context. This becomes more tricky if you actually give users access to the api. An asynchronous response would then need to be parsed and handled by the caller accordingly.
Just put it in the project root... it’s a hidden file for a reason.
OK, just trying to follow the project structure that's suggested, will of course default to root if there isn't a nice solution.. 
These are guidelines, not strict rules for project layout. &amp;#x200B; Making a (hack) workaround to support having the file into a subdirectory is not a nice solution.
As u/EmmEff said, these are guidelines only. But also these are not in any way official or "standard", despite the name. Unless you have a very large project that would actually benefit from having a directory structure this convoluted, I'd ignore it completely.
Yes, exactly this. Unless you have a very large project with lots of different components, just keep it simple. Splitting your code up into meaningful packages is the most important thing, but whether you then put them in a "pkg" directory doesn't make any difference unless you have a good reason. My personal rule of thumb when writing a package is to keep the code in root directory alongside a readme, go.mod and maybe your CI build file. If you want to add on an executable, then create a "cmd" directory with a main.go. Prematurely "bootstrapping" your project with an all-singing, all-dancing structure is needlessly complicated. If you structure your code well (into well-defined and well-named packages), then moving the directory structure around later down the line is simple.
Gotcha. Will ignore it. 
the trick is, that people can write complex functions, or simpeler function with lots of lines. Each of those situations should be covered, but only the first is, while the second is perhaps a refactor candidate too. It's not about small functions. It's about a computer program that can decide if a human can understand the code. The less complex code is, the more change it has in surviving the future without refactoring. Maintenance of software is an underrated hidden cost, which this will tackle in the very beginning. Thats why they "invented" Cognitive Code Complexity. Which my son doubts if it is a valid "calculation" and for which I agree.
Jenkins is still painful to work with and debug, but somehow people still cling to it. 
Cognitive complexity still refers to the amount of nesting in a function. A large function with no nesting is not cognitively complex, it's just cognitively taxing to reason about. With most static analysis tools I've worked with, they calculate cognitive complexity and have another flag for excessive function length.
I apologise in advance about the video quality. Looks like screen capture software is more complicated than writing software! If people like the content, I'll re-record it and continue doing more videos.
I learned that: my salary is (almost) the lowest in our team and it does not reflect my experience nor competence or efficiency relative to my colleagues. Also this year's raise has nothing to do with the effort or merit. I learned that, after some level, learning is a complete waste of time and searching better and more often for new jobs is much more financially rewarding. I wish this was a joke (it's not).
I can relate. I left my last research lab after finding out that I was being paid less than the other students (and was having a hard time making rent + groceries comfortably) -- indeed, often the best way to improve your wage situation is to simply switch jobs.
I been studying Go for a while and just discovered embedded interfaces but...I don't think I did it right. There is something about initializing structs and embedded structs inside a struct of interfaces that I'm simply not getting. https://play.golang.org/p/7UZUogIW_n
Nice hook!
I’m not convinced that benchmark is actually measuring cpu cache performance. The global variable should still be in a cache line during the hot loop because it’s accessed so frequently. 
I learned that all (found 3) APIs for using GraphQL and Go does not support null. The draft for GraphQL specifies that a value can be something, not there and null .. Thinking about writing my own since I think its a a feature that makes the experience for the user way cleaner than to make a API call that nullifies a field
I know what they do (as does mine), but what does this mean. Cognitive complexity is how a human would look at the code and decides how complex it is. And there is the thing. code with more lines is more complex than code with just a couple of lines. This means that the way "we" calculate the Cognitive Complexity is wrong, because a human would look at it differently than the software would. And the point was to look at it the way humans do.
I'm taking a stab at 3D in Go with little fuss: https://github.com/thegtproject/gravity
Omg finally not a shell script or juva app, thx!
Is there a something you're attempting to solve by embedding an interface? Embedding interfaces has the side-effect of getting rid of compile time checking that a type actually implements the embedded interface which can lead to seg faults. [https://play.golang.org/p/g3ZBvszjYoj](https://play.golang.org/p/g3ZBvszjYoj) I would avoid embedding interfaces unless there's a specific reason or use-case where the behavior is desired.
One thing I've missed from moving to Go from node.js is the amount of very common tooling for things like this. Having a hard time finding pre-commit hook tools as easy to configure (and more importantly, \_share config\_) as husky, commitlint, etc... Are there common tools lots of people use rather than try to get every developer to paste in a shell script to hooks?
Can't you still use those tools for Go projects? Who cares what language the tool is written in.
If you're not going to use the standard definition, maybe call it something else? The point was not that you could have a very complex mathematical function taking up many lines, but that you would have to consider an ever increasing number of paths through the code where the number of conditionals and loops increase the potential different results you have to mentally reason about at once. Much like OO was about breaking programs down into smaller pieces that you could reason about, Cognitive Complexity is about reducing the amount that you have to reason about in one go, where the number of flow statements can increase the number of paths very quickly. So it's not about long functions, because without different paths that the execution can flow through, they should be relatively easy to test for correctness (few edge cases to verify).
Mates who come to me regularly for questions, opinions and help (and who carefully avoid any hard or "unpleasant" work) make ~10% - 20% more than me, while I'm being "evaluated" by someone who does not work directly with me and being refused with a straight face any raise on the grounds that this year's raises were decided by HR alone and they are equal for everyone (0.15% over the official annual inflation).. That kind of killed my motivation :-|. Time to refresh that CV.
Hi [/u/coding2fun](https://www.reddit.com/u/coding2fun), First of all do mention the content source, it's bad practice to put someone else work without mentioning about the source. The example's and things discussed and these lines on your post matches so much line by line. from talk [dotGo 2016 - Damian Gryski - Slices: Performance through cache-friendliness](https://www.youtube.com/watch?v=jEG4Qyo_4Bc) *Based on above numbers, Let’s say you have a 3GHz processor. That’s three cycles every nanosecond. If your processor can do 4 instructions per cycle, then in* ***100ns it takes to fetch a cache line from main memory you’ve just stalled for 1200 instructions****. You can do a lot of work in 1200 instructions. So, while we can process data faster than ever before, the bottleneck is now getting the data to the processor.* Coincidence ? &amp;#x200B;
Sadly this is the truth, moving is how you get more money
"*Even if you didn't perform binary search for the array instead find the required element via linear search then also you can reproduce the same i.e. array is faster than the linked list."* Please Read [qwak](https://www.reddit.com/user/qwak) comment again. Simply put It's not about the algorithm you use , it's about how the array and linked list are laid inside the memory. 
Care to explain why? I'm thinking about using fasthttp
I've never had to use a hook like this. Any editor I use is going to be running goimports or similar and always keep my code formatted correctly.
Hmm I knew there would come a bad side lol I just wanted to initially automate creating apis. I was creating the function that takes in an API url and a type (struct of structs). You do need to make some kind of inference to the structure of the API if you want to call the right API from the function. Basically I wanted CreateApi("https:www.fakeapi.com/v1", structofstructs) The problem was that structofstructs gets goofy when you start calling different parts of the API. Because those structs structure are different. So I wanted a way to automatically take in an API no matter it's structure and call it by it's method. Hence the interfaces. I was trying to separate the concrete from the API consuming process and I thought embedded Interfaces might be best. It sorta works but you end up with a god type I'm afraid. 
Don't worry about it... It would be nice if Gitlab CI was flexible enough to choose a non-root location, but until it does it's ok to put it there :-)
[removed]
[removed]
That there doesn't seem to be a whole of freelance work for Go devs out there.
But, for what I understood, Code Complexity has nothing to do with how easy it is to test the functionality. It has to do with how a human (a developer) would understand the code. So based on the human side of this, I think my son has a really good point. And to name it something different is weird also because the first car was still a car, even if we have advanced in the technology (to name some example about naming stuff we create). I can't help to start smiling about the "Cognitive" part of this because the longer I think about it, the less "Cognitive" I think it is.
[removed]
[removed]
[removed]
[removed]
This is the sad state of the world. Companies wonder why people have no loyalty anymore. It’s because companies have no loyalty to their employees. I read an article a while ago about an employee at a major company. I believe it may have been IBM but I don’t honestly remember. They worked in maintenance as a cleaner, scrubbing toilets and emptying trash cans. But they had a dream to be more, so they were going back to school. The company heard about this and started partially funding the night classes and generally supporting them. Years later, they had become some kind of VP at a high level in the company. In the article, the person was lamenting how the culture had changed, not just there, but everywhere. Now, that same janitor role would be filled by someone who wasn’t an employee but a contractor (or employee of a contract company). They weren’t paid enough to really get by, let alone go back to college. The company had no way to offer the person more, and the janitorial company would have zero incentive for the person to better themselves as they would then lose an employee. The door that this VP came through remained closed for all newcomers. All of this is to further the goal of more corporate profits. It’s sad but it’s reality. A company, no matter how much they pump everyone up to believe the company cares, does not actually care about you. HR isn’t an appendage that works for the people, they work for the company to keep you both subservient and compliant. They know what the minimum is that they can pay you. HR, Human Resources, is the to treat you the same way that we, as a society, treat natural resources, with complete abandon. They’ll burn you out, and move on. They’ll take the top off a mountain if they can get someone to allow them to. And yet, nobody fights back. Your only way to fight back, as an individual, is to just keep job hopping. Staying in place is what they want. You become cheaper than an outside hire and they don’t need to retrain. 
[removed]
For the `go vet` change I could go either way, but surely it is simpler to actually _fix_ the formatting than alert on it? I have my editor configured to format code when I save, which sidesteps this problem - If [goimports](https://godoc.org/golang.org/x/tools/cmd/goimports) is present it will be used, otherwise we'll fall back to the default `gofmt`-based formatting. 
Could also use distributed tracing for this, IMO would be a great fit. https://opentracing.io/
Yes, IDEs
It's just the classical herd effect cancer. You cannot just dismiss anyone suggesting a herd effect in the community by arrogance. Your worry about Docker is partially valid: you don't need Docker for every fucking project. But everyone is doing it because everyone else is doing it. This is as fucked up as the Kardashians are famous because they're famous. For some reasons, this herd effect is a lot more pronounced in Javascript community. &gt; Has it occurred to you that thousands of web developers choosing to use a technology is an indication that they get value from that technology, and your refusal to see it is an indication that you don't understand the technology properly? Most of them do not 'choose' the technology. They follow a few 'influencers' who choose the technology for them. Yes as in cheap Instagram influencers, and the herd effect again. For instance, there are other technologies more superior than React, but React became popular because it has these public figures on social media who people like to follow. Another example is Angular 1, which by no means was a superior technology. But the herd followed it because Google acquired it. The technology does not live in its own bubble, it is interconnected to a lot of other factors such as social. Reducing this observation to arrogance is ignorance.
I'm currently working on a project in development (https://github.com/pushshift/rinzler) -- I started using Go about a week ago and love the language. However, I'm aware I'm probably doing a lot of things incorrectly (or against Go style conventions). When learning a new language, learning the culture is probably just as important as learning the syntax. Right now, this is just a development branch but these articles do help guide me in the right direction.
I write a lot of Go, but `go fmt` has never sat right with me. I'm not opposed to most of it, but there are a couple things it does that actively make code harder to read. And because of the lack of configurability, I can't turn those parts off and so I just never run it. I really dislike our community forcing bad code formatting on everyone and everything. He also says that not running `go fmt` will cause other peoples commits to have too many whitespace changes, but the first rule of committing in code you didn't write is "don't screw with the formatting". The 2nd rule is "check your commits and don't commit more than you actually changed". It's your responsibility to make commits look reasonable so that people can code review your PR. If you have random whitespace changes everywhere then you have actively made code review harder. That's on you and not the original formatting. 
That seems to be the compromise of go fmt - it's nobody's preferred formatting, but the benefit is uniformity. Personally, I find it quite aesthetically pleasing that Go code looks the same everywhere. In the last large C++ codebase that I worked on, everyone had their own style of C++. The inconsistent formatting made it even more annoying to understand the tricky parts of the code. 
He wants to sell you buffalo. What were you expecting?
It's fine to have opinions on what you consider more or less readable. Nobody will ever agree 100% on everything, but one things the Go community did agree on is to enforce a uniform way of formatting so that all code is alike. In the end, nobody should be rude to you for bucking the rest of the community on that because your code is your own, and your aesthetics are your business in either your private personal project or in a business where you have some authority. However, if you want to work with others ion an open source setting, it's professional and polite to use the standards the community has agreed to.
Thanks for taking the time to put this together! I look forward to seeing more. 
&gt; He also says that not running go fmt will cause other peoples commits to have too many whitespace changes, but the first rule of committing in code you didn't write is "don't screw with the formatting". There is no way you're going to persuade people to format their code manually to your personal weird spec just to contribute code. If I got as far as submitting a change and you bounced it back to me with "Don't use go fmt, use my custom rules", my conclusion would be "This guy is a crank, find a different project".
&gt;I really dislike our community forcing bad code formatting on everyone and everything. I think the majority of people are happy with the current formatting on the whole. I'm sure a lot of people would make small changes based on personal preference, but I think you're in the minority if you believe that the current formatting is objectively "bad". &gt;He also says that not running `go fmt` will cause other peoples commits to have too many whitespace changes, but the first rule of committing in code you didn't write is "don't screw with the formatting". The 2nd rule is "check your commits and don't commit more than you actually changed" It's your responsibility to make commits look reasonable so that people can code review your PR. If you have random whitespace changes everywhere then you have actively made code review harder. That's on you and not the original formatting.. This is probably true, however when the other 99.999% of people are all using the same formatter, it's just a pain in the ass to selectively *not* commit code that isn't formatted the same way. Code formatters lose most of their value when not everyone uses them, and whilst you could make it a rule in *your* particular project to not use `go fmt`, it leaves you somewhat at odds with the wider community. If I arrived at a company that writes go but didn't use `go fmt`, I'd run a mile. There's no good reason not to, and apart from making everyone's lives more difficult, it would be symptomatic of wider issues regarding attitudes towards collaboration and code quality.
go goes kafka, thx!
&gt; For the `go vet` change I could go either way, but surely it is simpler to actually fix the formatting than alert on it? You wouldn't want that when you run `go vet` as part of your CI pipeline.
don't most editors take care of this with go fmt and go deps? &amp;#x200B;
Sure, but a CI pipeline wouldn't be using a git-hook, it'd be using a workflow/pipeline/whatever. 
Experience has taught me that some people will refuse to use tools like that no matter how much easier it could make things for them.
What configuration needs sharing? Go only really has one code formatter, and if you want a pre-commit hook, there’s plenty on GitHub to look at. Node tools such as Husky &amp; Commitlint abstract away too much, and don’t really offer any advantage in Go. 
Break your commits in two: 1. Your feature bug with code unformatted 2. Re-formatting
Can you share this load-balance + auto-scale part of your Kurbernetes configuration?
Are you Ted cruz?
I initially hated the formatter when I started learning Go, so much so that I stopped learning it in disgust; I was learning solely out of my own curiosity. It wasn't until much later when I'd been writing JS that I noted code formatters Prettier or Standard were taking off in a big way. After trying them out, I realised the benefit to me: I no longer had to waste time endlessly shuffling around my code so that it would look nice, nor have arguments with other programmers about what was nice and what wasn't nice. It made me more productive instantly! When I later returned to learning Go I found I had completely gotten over previous feeling of revulsion towards standard formatting. I just don't want to ever have to think about it ever again.
It is nice that GitHub can recommend .gitignore files for projects. It would be really nice if they could also recommend hooks. I know that the kind of user that would use a hook would likely want to customize that hook, but for folks who are new to hooks, it might be a great way to start using them.
Not yet.. still learning/figure it out. Want to do some form of article on it.. just in case there arent enough out there already, once I get it working.
You can set custom path of gitlab CI yml in Settings / CI/CD / General Pipelines / Custom CI config path.