there's `duit`: - https://github.com/mjl-/duit pure-Go, with an eye to the plan9-way of doing things. (which, really, are probably the same things)
What does the server do when it receives a request? Does the handler need to perform some work before responding or is it a single line that returns "hello world"? If it's simple hello world response it shouldn't take anywhere near that amount of time. Additionally, check out [fasthttp](https://github.com/valyala/fasthttp) 
&gt; What I am more looking at is just a way to inject the variables. As mentioned in the article, vgo will compile a list of all used packages with corresponding versions in. Look for `goversion -m` in the article.
Either extend the keep alive on connection in pool or accept that behavior as something normal. Depends on the need. Often people simply accept it as with average volume of traffic you should never see this a problem in production.
What I mean is this: when I started using PyCharm about a year ago, it took me a few days to get my bearings. This is expected. However, I already had about 7 years of Python experience using Emacs + bash as my environment. But if I had been trying to learn Python at the same time, the additional learning curve of the IDE might have compounded the difficulties. Another point, coming from a no-IDE background, is that when learning a new language or just trying something out it feels weird to organise source code in "projects". Of course you can always have some sort of "sandbox" project lying around but there is still some vague kind of overhead in my mind compared to firing up a simple editor. I imagine this is why Go Playground exists. I'm not sure if this is helpful feedback as it seems intrinsic to having an IDE. In any case, I have the All Products subscription so it can't be all that bad ;-)
I've created [a wiki](https://github.com/tomarus/go-gui-libs/wiki) a while ago to compare all GUI packages i could find. So far i haven't really decided which one to use yet.
Have you used pprof to profile that application. Also look at trace. It is easy to do and will tell you what is running.
Ah, sure... 1. with regards to filtering, currently all the filters are for specific single type which means that extending with custom filter functions, would be difficult. This of course would require exposing the underlying filter interface. 2. making the filtering work on types such as Column / Const, would allow filtering based on more complicated relations e.g. filter when `col a + col b &lt; 32`. Sure it probably can be done with temporary columns. 3. the grouping / manipulation was just few ideas how to make the writing more uniform API. I.e. aggregation is just a special case of grouping and then reducing lists. PS: Much of the ideas were based on first impressions and designs that I've found useful.
Use [httptrace](https://golang.org/pkg/net/http/httptrace/) or [httpstat](https://github.com/davecheney/httpstat) to get a better idea.
[go-vim](https://github.com/fatih/vim-go). None of this VSCode nonsense.
As I'm following the code and assuming f() is not inlined, what's stored in the `[]byte` block is a pointer to `x` (which is heap allocated). `pp` points to the `[]byte` block, which has been reinterpreted as a pointer to int. `pp` itself is probably not heap allocated, since it's a pointer that's returned by value and otherwise doesn't escape `f()`. In this situation, in order for garbage collection to not prematurely free `x` it must know that the `[]byte` memory contains a pointer, because this pointer is the only reference to `x`. However this memory block was not initially created as a pointer-containing type, just a block of bytes. It's possible that putting a pointer in it causes Go to mark it as pointer-containing, although I don't see a clear indicator of this in the disassembly.
Perhaps the process has been swapped out. Can you test if this happens on other machines with more memory?
Correct, testing and feedback is what I was trying to accomplish. Especially for other internal teams at my company who are looking at vgo. I didn’t know if I was doing something stupid since all the articles were saying how easy it was to move from dep to vgo. 
Built this for my own practice and also because I don't need the many many features that all the similar, existing packages provide. Welcome to any criticism and of course, any PRs!
Everybody talked about files, but don't closing rows when doing sql requests also causes major issues very quickly. If you don't close your rows, the connection to the database won't be closed; It will be kept open. That means that after 50 or so requests which happens very quickly, your database won't accept new connections. And uh... that's bad.
&gt; There's a bug about this with quite a lot of comments. link: https://github.com/golang/go/issues/19412
One of the comments you made about gin is incorrect. You can have routes like `GET /users/token` and GET `/users/email` you could just need to make a router group of `users` https://github.com/gin-gonic/gin/blob/master/README.md#grouping-routes
I did make router groups, you can check [Gorsk-Gin](https://github.com/ribice/gorsk-gin). You can replicate the issue in under a minute and test for yourself. There are few opened issues on Gin's repo about this.
I'd personally say GoLand, the fact it will analyze your code without you having to save is a lifesaver, second choice would be VS Code
So I just edited an existing api I had to test this out ``` package routers import ( "net/http" "os" "time" "github.com/gin-gonic/contrib/ginrus" "github.com/gin-gonic/gin" log "github.com/sirupsen/logrus" ) //Router initialize API router func Router() *gin.Engine { router := gin.New() logger := log.New() logger.Level = log.InfoLevel logger.Out = os.Stdout logger.Formatter = &amp;log.JSONFormatter{} router.Use(ginrus.Ginrus(logger, time.RFC3339, true)) router.Use(gin.Recovery()) user := router.Group("/user") { user.GET("/token", token) user.GET("/login", login) } return router } func token(c *gin.Context) { c.JSON(http.StatusOK, gin.H{"token": "hello"}) } func login(c *gin.Context) { c.JSON(http.StatusOK, gin.H{"login": "world"}) } ``` And everything worked as it should ``` computer:~ user$ curl localhost:8080/user/token {"token":"hello"} computer:~ user$ curl localhost:8080/user/login {"login":"world"} ```
How do you like them apples?
I personally use vim with go plugin, I can't explain why, I just do. But logically I should be using GoLand.
ah, crap - yes, you're entirely right. i had a note on this that i must have dropped when restructuring the contagion section. I'll find it and add it back in as soon as i get back to my laptop. sorry! the common problem here is when people set overly restrictive constraints - that's a harmful externality. the key word there is *overly* - when they accurately describe an incompatibility, it's good. but, as the information loss section details, the conflation of minimum and current make it impossible to fully avoid harmful externalities, no matter what update strategy choice you make. 
Thank you! I'll try to replicate it myself and show you the issues I stumbled upon. Can you try the following (since these are the cases that did not work for me): `/users/:id/token` `/users/:id/email` Also these don't work afaik: `/users/:id` `/users/email`
yes, my mistake. `pp` is not allocated on heap. It is that `x` and the underlying part of `s` are allocated on heap. The direct part of `s` is allocated on stack. After invoking `*pp = &amp;x`, the direct part of `s` becomes unreachable, but the underlying part of `s` is still reachable, for `pp` still references ot. My mistake 2: there is a hidden `px` of type `*int`. In fact, there is not a such `px`. Sorry. &gt;It's possible that putting a pointer in it causes Go to mark it as pointer\-containing, although I don't see a clear indicator of this in the disassembly. Yes, the explanation for this will touch the detailed implementation of the garbage collector. I do think the standard Go compiler handles it correctly, but I.m not sure.
&gt; Honestly, yes. A v0 means you make no commitments to stability, consistency, or reliability. That's absolutely fine when the project importing it is also a v0, but once you get to something serious, it's a serious concern. In an ideal world, perphaps. Consider [Thrift](http://thrift.apache.org/), it's widely used in production and supports more than a dozen languages, only one of which is Go. The latest version is 0.11. The next one will be 0.12 as we won't be changing our versioning scheme just because a single language we support has a unique idea about versioning. Real projects in real life have their own rules, are messy and imperfect, which vgo does everything it can to ignore. I don't think that's a feasible solution.
Should I take your lack of response as an acknowledgement that you don't actually have anything connecting the Go community to sexual harassment?
Yeah you could get `/users/:id/token` `/users/:id/email` and `/users/:id` to work but `/users/email` will not because in `/users/:id` `:id` is a named wild card param so doing `/users/email` it would trigger `/users/:id`. ``` package routers import ( "fmt" "net/http" "os" "time" "github.com/gin-gonic/contrib/ginrus" "github.com/gin-gonic/gin" log "github.com/sirupsen/logrus" ) //Router initialize API router func Router() *gin.Engine { router := gin.New() logger := log.New() logger.Level = log.InfoLevel logger.Out = os.Stdout logger.Formatter = &amp;log.JSONFormatter{} router.Use(ginrus.Ginrus(logger, time.RFC3339, true)) router.Use(gin.Recovery()) user := router.Group("/user/:id") { user.GET("", id) user.GET("/token", token) user.GET("/email", idEmail) } return router } func id(c *gin.Context) { c.JSON(http.StatusOK, gin.H{"id": fmt.Sprintf("my name is %s", c.Param("id"))}) } func token(c *gin.Context) { c.JSON(http.StatusOK, gin.H{"token": fmt.Sprintf("hello %s", c.Param("id"))}) } func idEmail(c *gin.Context) { c.JSON(http.StatusOK, gin.H{"email": fmt.Sprintf("%s@example.com", c.Param("id"))}) } ``` Responses: ``` computer:~ user$ curl localhost:8080/user/john {"id":"my name is john"} computer:~ user$ curl localhost:8080/user/john/email {"email":"john@example.com"} computer:~ user$ curl localhost:8080/user/john/token {"token":"hello john"} ``` Is echo able to handle the use cases you specified above because I fill like that is going a problem regardless unless you had some kind of prioritization where it matches exact paths first so /users/email then if an exact match is not made it falls back to parametrized paths.
&gt; I don't know why your comment isn't rated higher Because you can get the same result with glibc. if you turn the nsswitch feature off. You aren't gaining anything by not using glibc you are just losing the ability to have a correctly functioning binary if you need the nsswitch features.
From a quick look, this looks like you're not properly encoding the log contents as HTML, opening yourself up to XSS attacks when viewing the email: for scanner.Scan() { message += scanner.Text() + "&lt;br&gt;" } Take a look at `html/template`'s `HTMLEscapeString()` function.
I'd love to try this with vim ale.. Gometalinter is slow
I totally agree that in the real world things are messy and far from ideal. I don't think that's an argument against vgo, though. I'm not saying you shouldn't use v0 packages, in saying that using them has risks: - Every single version change could be like a major version change, with breaking changes big or small. - Being less mature and with fundamental changes being made quickly, v0 packages are more likely to have bugs. We should always be careful with v0 dependencies, and package management is no exception.
Sorry, [my former reply](https://www.reddit.com/r/golang/comments/8ll6lf/how_to_safely_use_typeunsafe_pointers_in_go/dzljrnv/) has many mistakes. The [6 unsafe.Pointer use patterns](https://go101.org/article/unsafe.html) don't include the case in your example.
Oh, excellent. I wasn’t sure if that was for sure or not. Looking forward to it! 
Please search the golang.org/issues or https://goissues.org/golang.org/x/vgo for this issue. If you don't see it, please file a new issue.
&gt; it’d be nice to just change the import to try just that part By this, do you mean like a compatibility layer of some sort? (That’s actually a great idea!) Unfortunately, no I did not implement the parsing of combined small arguments... maybe in a future version!
Goland for sure.
the main func is huge, I'd break that up into smaller functions to improve readability, such as the logic at [https://github.com/muhammadmuzzammil1998/Log\-mailer/blob/master/main.go#L24](https://github.com/muhammadmuzzammil1998/Log-mailer/blob/master/main.go#L24:5) and also the logic for reading the log file and sending the mail. This would also make it easier to write tests for those components.
Well your gain could be not to use glibc ;) 
Extremely unlikely the problem is http routing related, I don't think suggesting fasthttp is likely to help OP.
After reading this, I guess what I’ve been doing the last few years [0] was “Riding the Top” and following a “purely altruistic strategy“. I enjoy this approach, but have very little experience with alternatives. [0]: https://github.com/shurcooL/SLA
Your Pros outweigh your "Cons", which are entirely negligible inconsequential non-issues: &gt; The repository can quickly become very heavy I never experienced such a sensation.. what's a "heavy repo" anyway? Tough to carry around? Generated code is not for reading, it has a comment at the top usually letting the reader jump to source template (or other codegen-source logic) instead.. &gt; We know that some git providers like GitHub can distinguish generated code in RP and collapse the file, but that's rather an exception Github does it, Gitlab does it. Covers how many 90+% of projects? Exactly..
I just use `git describe --always --tags` for this purpose. 
A: Of course, it's the only option that keeps the repo go-gettable.
I love go but this feeling of "finally basic things are being added to the language" comes a bit too often. Anyway as you said, finally! 
Yes, that is what I am currently using now, was looking for something without cgo. This has C bindings. Thanks for the suggestion though!
Yeah, it seems andlabs and duit are the only native ones. I am going to check out duit in homes that I can cross compile and have slightly faster compile times. Thanks for the comment!
One additional con: You can get weird merge conflicts. This is a huge issue if you're committing Webpack-built files, but it's far less of a problem for Go code. 
This has to be the correct answer.
What does this mean?
See my edit :/
https://en.wikipedia.org/wiki/GNU_Readline &gt; GNU Readline is a software library that provides line-editing and history capabilities for interactive programs with a command-line interface it's not actually using gnu readline, but same idea.
Only the authors knows for sure, since there's no comment explaining the (highly inconsequential, in this particular individual situation, as far as one can discern from the above) decision. But apparently they didn't want to return a copy. They *could* have, seeing as they don't (appear to) retain the `r` they create (and it would be odd practice if they did, given the semantics one expects from sth called "New"), but they decided against returning a copy, opting for the reference aka pointer. Maybe it's a big struct (I can't tell from my vantage point here) so why copy it (or rather, "risk copying it") on return. More commonly than not, in such instances, it's mostly just force of habit than anything else or any particular good reason or other.
Gives it better command line support like you are used to at a shell prompt. Things like history, (configurable) emacs-like keybindings, etc. https://en.wikipedia.org/wiki/GNU_Readline
Package C is breaking the import compatibility rule. A package manager that tolerate these rule-breakers is definitely harming the whole ecosystem. 
There's also https://github.com/aarzilli/nucular (Based on an early version of nuklear. It's using shiny under the hood)
It makes more sense to just re-run the generation process when resolving the conflict, overwrite the generated files and commit that. 
No. They're build artifacts. We're still working some of the kinks out of the resulting IDE situation, admittedly. I take the point that the Go authors make, which is very practical, although I would be pretty certain that inside Google they don't commit any generated Go code... :) You missed out the biggest con by far; the generated code can become out of sync with the source of truth. There's an extra step in the change process that developers have to remember to do manually, and when there are such steps at some point someone will forget it, because we're all only human.
It's a shame you're getting downvoted, you make valid counterpoints. I can see both sides. Our team went with committing for similar reasons to why we commit our vendor/ directory, but there's nothing at all wrong with running code-gen as the build process instead of committing generated code.
No, it's very unlikely. Which is why I'm asking OP to elaborate on what the handler is actually doing. Suggesting fasthttp was on a separate note since OP seem to be very concerned about speed. 
Heavy means when you clone the repo you end up downloading tons of code you’re never going to use because it is outdated. Not a dealbreaker but not idea either. 
That’s a good idea.
Returning a pointer is a rule of thumb in writing idiomatic go. why would you want to return a copy if you can return a reference instead? Returning a pointing means less memory foot print in your go code! After that has been said, also note that in some special cases, you could return a copy instead. tiny info here -&gt; https://github.com/golang/go/wiki/CodeReviewComments#interfaces
Which extensions do you have installed to assist with Golang for auto-completion, linting and what have we?
Yes, but as long as the old APIs are still there, it's not a guaranteed breaking change. The only places where there is a temptation to make it a _breaking_ change are the places where currently there is an interface{} _and_ it is something that should be replaced by generics. For instance, the JSON library wouldn't necessarily change with generics; it uses reflection, and it is not trivially obvious to me how to "fix" that with generics. So, basically, just the handful of data structure packages, for which it is no great pain or loss to just implement a second new generics package rather than overwriting the 1.0 API.
The bullying and misinformation generated by the big names behind dep is real.
Thanks!
Its not idiomatic Go, it really depends on the situation. See https://github.com/golang/go/wiki/CodeReviewComments#receiver-type
Sure, it's a fairly important difference to me, and either approach is fine.
For anyone building web services in Golang, this should provide some impetus and direction to your endeavours.
Haha, yep you were right, gonna try it out. Thanks!
https://github.com/golang/go/issues/25567 mentions an unrelated issue, but seems to imply that the rewrite rule should work fine.
On my phone still so i can't link, but reread the intro. The compatibility piece explains will address why these issues should be expected. In brief, though - import compatibility can only be specified at the API level; behavior-level compatibility is unspecifiable in the general case (at least, beyond "no observable behaviors changed," which is basically freezing the software). Also, v0.
What makes gometalinter needlessly slow that this project avoids?
Reason why its so much faster is explained at https://github.com/golangci/golangci-lint/tree/bbd28f4618715566af08390565034281b99e3d6c#golangci-lint-vs-gometalinter
&gt; By this, do you mean like a compatibility layer of some sort? (That’s actually a great idea!) Yeh, I like the API for the std. flag pkg, and being compatible with it is worth a lot anyway, but the command line UI sucks.
Been debugging third party js scripts for the last two days.... Yeah please do this. Nothing like a third party script that takes in depencies from another server that relies on other scripts to load at certain times and has different scripts for different sites that may have these scripts... Please
What an absolute garbage proposal. It makes pretty much every Go 1 library unusable day 1, it makes it impossible to usefully build a library on top of another one, and it encourages overscoped packages. The way to solve dependency hell is not to make dependencies unusable.
Its starts a conversation about dependencies and provides an idiomatic approach. I think its an interesting approach even if the downsides seem prohibitive. 
It servers well as a thought experiment, as it is well-intentioned. There are, in truth, many libraries that should be more generic. This would server as an interesting method of *forcing* them to be generic. However, interfaces aren't powerful enough in Go to make something like this workable. None of a struct's methods could ever return anything that a library could use, without main providing wrappers. If, somehow, Go allowed a `func() Implementation` to satisfy `func() Interface`, it could work and might actually be quite interesting. As it stands, though, there is far too much garbage to wire up the libraries. I posted this in the issue, but here it is again for anyone curious: https://play.golang.org/p/zYaBPs6nuKz
This is a great concept for an experimental language. Not for a general-purpose language that people actually use in production.
Not at runtime, but have fun auditing say - the buffalo project with all its dependencies?
I replied in the ticket. There is a way to make the example work, but it is a bit ugly.
yup, and it's a great strategy (for the ecosystem) when people can employ it. we just don't want to have to have that negative externality of unnecessary breakages. this is Russ' "ratchet," which he sees as good, and i see as resulting in unnecessary conflict, both human and machine, and a perverse arrangement of responsibilities onto the wrong parties.
It is somewhat obnoxious to grep a codebase with tons of the exact same idioms in generated code just to find the one or two source files that caused them, especially if the generated code isn’t constrained to a set of folders 
My view is you should return the type that will be used. If the methods that are attached to the struct use pointer receivers than you should return a pointer. If there are no methods or the methods us non-pointer receivers you should return the object itself.
https://www.twitter.com/carlmjohnson/status/982747054614220800
Not the same as what the comment suggested. The implication is that this proposal would solve the same problem u/icetheace faces in javascript, where dependencies are dynamically loaded at runtime, and loaded dependencies dynamically load more dependencies. Go doesn't have that exact problem since a manifest of dependencies can be discovered before compilation. Auditing the changes of tracked and versioned dependencies is a different story.
There are less jobs than other languages, but every Go shop I know of is desperate for talent. 
Do you know what a pointer actually is? Might be better to start there. Have you done the Tour?
Well my comment was really mainly cause I was tired of debugging js code but also an extreme want for simplicity. Cause everyone knows at work if something has too many dependencies or unfamiliar packages then it becomes..."new file time!" And that defeats the entire point. Yet happens at every company, almost every day. This is prolly one of the biggest problems never talked about in coding. Cause your cto only cares about clients and your top devs just say, "yeah that file was a mistake and that Dev that used to be here well, he wasn't all that great... This couldn't be more of embarrassing issue. No company likes these things pointed out so no one ever talks about it. It's just terrible all the way around. What that has to do with js and go is that I don't ever want to even partially deal with anything that ever has to do with scripts, packages, files, or whatever that gets in the way or turns into one of "those files" in any directory. If your company pushes less then 100k lines of code apps to clients then so be it but after 10 years this becomes a real issue on many levels that cost a crazy amount of money. My company with php + composer just speghettied their dependencies in different directories. It's a horror fest and they don't even know it's a problem yet cause not one line of code is reusable so...I guess it's not a problem right? No it's a huge problem they haven't even realized some how. Go from the ground up is about packaging and reusability. You can't expect people to reuse something they can't parse out from a low level. This would also fundamentally antagonize the original inspiration of the language. This needs to be simplified for the sake of future reasoning, legacy code, and my eyes and back.
&gt;When I need to pass pointer reference to a function(as arguments) and why? An example of why you would want to do this is if you want the function to change what the pointer references. For example, say you have a pointer to an int called i, and it points to the address of something holding the value 5. Then in your function you take its single int argument and add 5 to it. You call the function on i as a value, then you check i. What do you get? i==5. You call the function on i passed as a pointer reference, then you check i. What do you get? i==10 as probably intended.
As someone employed to write OO programs, I regularly struggle approaching go architecture with a different mindset. Somethings in your article just eureka-ed for me. Many thanks
Fast compile times are definitely a consideration but we've sacrificed compile time before for what I believe were good reasons. Converting the Go toolchain to Go slowed down compile times significantly but I think it was the right choice.
https://softwareengineering.stackexchange.com/questions/247298/
In regards to network statuses not only 200 is success all of 2xx are success to be fair. Common mistake is not handling 201.
Here's a helpful way to think about it: Traits are compile-time resolved interfaces. 
This is pretty cool!
&gt; the best way to create code for reusability and composability [citation required]
That's great. Any other reason? And what about the second question?
Where's the part about "Scalable"? Article should be renamed to "Building Web Services in Golang".
I completely agree! I usually create a map of status codes I whose handling is customized. I dumbed that down for the example in the article so people could find some stuff out on their own, tbh. I'm delighted you spotted that really. Was sincerely hoping people would rack their brains and come up with good stuff. :D I am keenly inclined to upload a more robust version of that function on github soon. 
I am truly glad that I could be of assistance! Your kind words mean a lot to me. I only hope I can continue to help by sharing my learnings. :\)
In hindsight, I realize you're absolutely right. I had a lot of things I wanted to write, but ended up with a fairly long article which I didn't want to overcrowd with too much information. Ended up missing out on scalability. Thanks for the feedback, and I think I will tackle the scalability angle in a Part 2.
&gt;How much does it all cost? I read an article about a guy doing a serverless effort for less than $5 a month. I find this aspect of serverless interesting for a guy coming from a weak currency country! You get charged charged per request, so as long as you're not serving a massive amount of requests, it's probably one of the most economical models, if you're expecting thousands of requests per second continual traffic throughout most of the day, then you'd probably want a server (or EC2 instance). I haven't done much cost analysis other than that, but you can read more about the pricing here: https://aws.amazon.com/lambda/pricing/
thank you for using and feedback! 1. we've fixed vendoring of self\-repo and documented how to do it in README in [FAQ](https://github.com/golangci/golangci-lint#faq) section, check it please. If it doesn't work please file an issue in GitHub. 2. we already use `runtime.NumCPU()` as default concurrency, please file an issue with output of `golangci-lint run -v` and `golangci-lint run --help` and information about your environment in GitHub
That's company icon
I think the question stems from the confusion some people have with pointer vs. reference. But the term 'pointer reference' beats that by a long way IMO.
TAC? What did it mean? Type Agnostic Code? Take another compiler? Thank yo (in swedish)? Three-Address code? :)
You never NEED to do any of this. 1\) You can choose to pass a pointer to a memory address if you want to use that memory address in a function. 2\) you can choose to return a pointer to an address if you are sure that address is not freed from the memory.
In the context of the above listing, you fully well know it's the latter =)
I can't really speak on rust but I prefer the ability to just tie types together by methods without setting an implements call or keeping track of interfaces it goes by. There are always nitch small cases where people abuse this but honestly there is a lot of magic to these type names that you really have to dig into to appreciate. This is not to say it's impossible in other languages but the appreciation of it's simplicity becomes apparent when you take apart these type names and also be able to utilize them freely in a package. When Google makes a type name there is a lot of architecture magic going on behind them for what methods they use and don't use. One of my favorite instances is the Reader type. 1. You can get it by using string.NewReader() 2. You then automatically get all those io methods 3. You get the string the NewReader utilizes. 4. You can easily cast into a map. 5. You then get something that basically is generic by being able to take in any type. 6. The string becomes mutable but in a different memory spot. 7. The best part is if you want to utilize this just grab the Read() method. 8. You begin to detect why they only chose those io methods for that Reader type. Too little and it's not that reusable and too many and no one will try to use it. Implementing it then becomes extremely easy and you get all these benefits with one line of code "anyone" can read. You also are doing some crazy low level stuff with []byte. This of course has big impacts for using it in another languages, other packages, and for distributed services. If you had to use each interface with implements and usually set these per one interface you would really lose a lot of that architecture magic. I don't think people realize the importance of utilizing these type and methods so easily. It's readability, great architecture of methods, and easily implemented are what allow devs from all levels to be able to reason with this design. None of it has code visibly problems or looks too dangerous to reuse. You pretty much can rely on it and the junior Dev can pick it right up. This contributes to better packages and reusable code from the ground up and for the behavior of long term process. A lot of companies in other languages don't even touch traits let's say in php. Because this starts to get into magic coding or so they believe. It takes years to come up with use cases at this level and to have the know how to architect. In go you just utilize the methods from the start and move on. Big difference. https://medium.com/@matryer/golang-advent-calendar-day-seventeen-io-reader-in-depth-6f744bb4320b 
Yes, I know. But when I need to do this and why?
They should move into maternity wear. 
You have to merge when doing a rebase too sometimes. Same thing applies. 
Use a pointer when you need to be able to change the original object. Don’t when you don’t mind using a copy of the object instead. 
Two quick notes: * The name of the language is "Go" not "Golang" * Don't embed sync.Mutex in an exported struct, or the locking methods become visible outside the package
Yes, on local developers, not on CI.
1. I followed the instructions in the FAQ and used `dep ensure -add` to vendor it. It worked beautifully! Thank you so much. I now feel confident enough to roll this out at work next week. 2. Great! Glad to hear it. I was confused by the `--help` text. ``` Flags: -j, --concurrency int Concurrency (default 4) ``` I filed issue [#23](https://github.com/golangci/golangci-lint/issues/23) to change it to `default NumCPU` or something similar. This is really great work and I hope you get all the GitHub stars for this!
I prefer #2. I love iota 
Oh man, I needed a good laugh.
An embedded sync.Mutex will be exported, though
But if OP did that it's be just like the 9,000 other articles about this topic. 
It's really easy to handle that. Basic public/private comcepts
It's really easy to handle that! You could prevent it from being misused or even accessed really easily. I'm not gonna spoon feed how to solve that. The article was aimed at more architectural guidance than programmatical tutorial, which is why I've intentionally left out some programmatical nuances, or linked to external sources where you can read and learn them from. Giving you exact executable code was never my intention. Just plant a seed of thought pointing you in the right direction. I'd much rather you figure out the code yourselves. Nitpicking on an example which was meant to be pseudo code isn't what I expected people to be focusing on when they read the article. 
Okay brother. As long as people are focusing on what matters. 
It will indeed. Good catch.
Another reason would be to use less memory. In a 64 bit system a pointer is 8 bytes, if the thing you are passing to the function is greater than 8 bytes, then passing a pointer takes less memory. There's also times when you would not want to do this. For example say you have a multithreaded program. You have an int i and you have two functions that will take i as arguments. The first just needs to know the value of i from the start, it doesn't matter if i changes while the function is executing. The second function may change the value of i. In this case its best to start a thread for the first function and pass i by value, then start a thread for the second function and pass i by reference. Now if the second function changes i while the first function is still executing, the first function won't know. As for returning a pointer, we again have memory issues, many times a pointer is faster/has less of a memory footprint compared to a large struct. Also, it makes it easier to dynamically allocate some memory in the function and pass it back to the calling function, rather than have to fit a given size or type (this is what I know from C, could be different for Go).
Just wanted to say thanks for working on an awesome DB project. You simultaneously satisfy my hatred for Java with my need for a noSQL DB that's both performant and has a proven architecture/query language. 
Tbh, you're right. I wanted the article to provide more architectural guidance instead of talking about reverse proxies, multi threading, go routines, and the same spool that everybody has been weaving off. But I do want to add more to this, and hopefully address scalability without sounding repetitive. 
Do you mean that for the first function to not fail on `math.MaxUint64` I would have to expand it like this: units := []string{"bytes", "KiB", "MiB", "GiB", "TiB", "PiB", "EiB"} If one can not pass anything beyond an `uint64` (?) and `math.MaxUint64` is 0,016 `ZiB`, it should be safe to leave it at that and not add `ZiB` to the slice, right? &gt; Inputting 0 will not return the same output. Do you mean that both functions will return a different value for `0`, i.e. "0 bytes" and "0" or something else? The former would be an error on my part. 
That's neat, thank you! I will try it out.
Conclusion time: I have done some testing with the two best native cross platform GUI library's that were suggested to me in the comments and below are the results. So, between DUIT and UI, UI is the better option and here's why: UI and DUIT both do require a CGO cross compiler and both have slow compile times. Now, UI is easier to understand/learn, has a smaller binary size, and good looking GUI and no weird mouse selection. DUIT will only work on windows with the patch found at this link: [https://github.com/ktye/duitdraw](https://github.com/ktye/duitdraw) I hope this has helped anyone following this thread understand, it has definitely helped me. Thanks everyone for the comments!
In fact I did consider to write such a language for some time (that would compile to Go or be derived from the Go compiler). Since Go2 is now something to talk about, I thought: What the hell. Make an issue and see the reactions. Maybe they'll find something you did not think about. Well - not so far. The reaction was pretty predictable.
This particular optimization makes me sad.
Strange concept, being sad about nice things. 
You got it. If I would have written a blogpost "Avoidance of dependency hell thinkable" nobody would have listened. Now people try to find arguments for what looks obvious at first sight, but not so much after thinking about for some time and trying things out with code.
Care to explain why?
3 address code. `.s` files are essentially that
Alternatively, Go could have gone down the Ocaml path and specified a module and functors (which are essentially method dictionaries). The performance per trait is in tight loops - doing this is terrible: ``` for i := 0; i &lt; N; i++ { b += a.(AnotherInterface).DoThing() } ```
I don't know if it makes me sad, but it is strange. To me, `len([]rune(s))` says "Convert a string into a slice of runes, and then find the length of that slice." which is different from "Find the number of runes in this string." I would not expect it to be the optimal way to get the number of runes in a string. Especially since there are already several ways to get the number of runes in a string in the standard library. I guess enough people are doing it that way that it's worth adding a specific optimization, but in general it seems like a strange thing to focus on.
They exist to serve as build-dependencies of other Debian packages. There's probably no reason why you would want to use them.
I maintain close to 150 golang packages in Debian's Go packaging team (Ubuntu packages come from Debian). We don't recommend users to use those packages for anything. We use them to build go software and we update them as needed, without any other consideration.
the length of a slice of runes is the number of runes, so I'm not sure how it's different?
Converting was already O(n). This remains O(n) while avoiding allocating a throwaway slice of runes
first of all, ORMs are not popular thing with Go with that said, see if this can help you : https://github.com/jinzhu/gorm
The part I take issue with is the conversion. I guess my problem is just comparing Go to other languages too much. In Go, type conversions are often free, whereas in other languages you expect them to involve a bunch of work. I guess from that perspective this optimization makes sense. Maybe in Go 2 we can try to capitalize on that more and get rid of some of the redundant string manipulation functions.
You may want to use Json tags annotation in other to explicitly map the fields of Json payload to Person object (not a requirement, but quite handy )
This is how I would do it, though your method is totally acceptable too. https://play.golang.org/p/3ACaSY0Wp1f
How does `for r := range s` give the string length?
[removed]
Boom. This guy big Os.
More relevant is whether it's better than implicit interfaces.
Thats not the full picture is what I meant, there must be a counter somewhere for the total length of the runes. So this is what the &gt; new rune counting runtime function. does.
Also reduces the constant on that n. 
[removed]
My team commits vendor directories because not all of our teams write Go. We are also behind a proxy. So we need our builds to be self contained to enable anyone to build the project from a checkout. 
I don't understand your example code. Is that one single linear example or is it multiple examples? If you read the body, you advance the seek position (if it's an underlying seekable type). So the answer is to just read it once. 
*taking shelter*
net/http \(standard library\) is enough for most use cases [http://www.gorillatoolkit.org/](http://www.gorillatoolkit.org/) is good, primarily [http://www.gorillatoolkit.org/pkg/mux](http://www.gorillatoolkit.org/pkg/mux)
I took a quick look, this looks good! Just a few things I'd ask/comment on, just from the readme: * What's the point of printing to ctx.Stdout() instead of just os.Stdout? When would it be different, except when the program itself changes the value? * Generally, avoid naming types `Context`. The standard library context is pretty prevalent.
The same reason Seek isn't implemented on response.Body--because go is actually reading directly from a socket buffer as the data is received. After you read til EOF, the socket buffer is empty and any further reads will return an empty array. Once you read the data into a variable, just use the variable rather than trying to read the body again.
Not sure if I'm understading your problem correctly, but you can think of a Reader as a byte array where you advance the index as you go. You cannot go back and re-read data you've already consumed with a read (unless it omplements io.Seeker). Since you already read the data in io.ReadAll, the body no longer has any data to be read. Same thing the other way around, decoding before reading. If you need to use both the raw bytes as well as decode, you could use json.Unmarshal, which takes a []byte, not an io.Reader.
At my company, we commit the vendor folder so that nothing breaks if people change/delete their library on Github. If you're only working with internal packages or you have them all duplicated in Github Enterprise then it's probably okay to not vendor. This isn't really a Go specific issue \- for any language, if you use third party packages and don't vendor them then you run the risk of someone deleting them one day. So if you just do whatever your company does for other languages, you'll probably be okay.
[https://astaxie.gitbooks.io/build\-web\-application\-with\-golang/en/](https://astaxie.gitbooks.io/build-web-application-with-golang/en/) is quite a good tutorial for rolling your own—which Go seems to encourage.
My recommendation: https://github.com/labstack/echo Feature-rich, actively developed, easy to use. 
[removed]
It is turing complete and can bind with C, so you can do anything with it. Same as Java, or C#, or C, or OCaml, or Rust, or Python or whatever. 
Yeah, I'm sure you can but it must have a specific area where it beats all those other languages. 
[Julien Schmidt HttpRouter](https://github.com/julienschmidt/httprouter) and the net/http standard library. You don't need anything more than this, especially for a single page app.
web development! its popular in china because it can handle millions of requests
Its main focus is on creating networking applications like servers. Additionally it makes it ultra easy to create multi-"threading" applications by leveraging the concept of communicating sequencial processes.
As other people said, very wide range. It is lightweight, simple and full with libraries, so you can replace scripting work you would otherwise do in python \(this is why people use it for automation\). It is also very popular with high performance and scaleable management system \(docker and kubernetes are written in go\), that would otherwise be written in Java \(note that go does not need a JVM\). Would not try to do C work in go, as it is no "low level" enough, but this is actually a plus for most things :\-\) Would suggest to go on github, see which projects are written in go, and take it from there.
The reason i was inclined towards a framework was it provides lot of features out of box, like routing, caching, logging, ORM etc and speeds up development time. Any thoughts on beego?
Why it's not popular? it's straightforward and make an abstract layer to keep many thing simple.
Makes me wonder, if one extracted some `foo := a.(AnotherInterface).DoThing` (no call) outside&amp;before the loop --- does the func var point to the implementation (resolved) or the dummy v-method on the interface type. With runtime rather than compile-time resolution, it must be the latter I guess, and the cost per iteration remains. But if code (that might be generated not hand-written) were to use method-dict-records as I outlined above, `foo` would point already to the _implementation_! Saving an indirection-per-iteration.
If you want the full package you should have a look at Beego, Revel and Buffalo. I once used Revel for a site like this \(a few pages\) and it works wonderfully until today \(it was years ago\). The other too will probably also be good \(check their issues on Github etc.\) and compare their features to find one that fits your needs. Most people in this reddit will however recommend using standard library or gorilla to assemble your stuff. I don't think this is the right way for what you are planning. No need to reinvent the wheel but you will be doing it for sure if you use net/http.
Thanks for your input. I am also not looking to reinvent the wheel and the reason we have frameworks is they take care of some of the basic stuffs so the focus can be on other parts of the application.
This is correct, and the context here is the `New()` function where it makes perfect sense to return a pointer to the newly constructed object instead of creating a copy of it (which would turn the original object into instant garbage immediately after creation).
I'am curious why they are even in repos?
VSCode is best paid or otherwise. Don't know why people keep pushing paid products.
go developers tend to stick to the std lib as much as possible, and prefer to write raw sql codes by hand :)) 
I kinda like [Gin](https://github.com/gin-gonic)
* How do you plan to secure your api? * Do you have time to pick up a framework * What DB do you plan to use I would start with the standard library \+ gorilla toolkit \+ custom middleware to handle the "secure" part. I don't have an advice for which framework to pick up but you should consider things like \(right off the top of my head*\)*: * Learning curve * Testing * Security * DB support
Depending on more context, the code in your example could be perfectly sane code. OTOH, I'd not let `len([]rune(s))` pass my code review.
I am recommending Beego. Also you can use "qor" for admin area.
It is OK now! Thank u very much! 
Have you done any (and I mean *any*) research before asking this question? 
This [https://echo.labstack.com/guide/static\-files](https://echo.labstack.com/guide/static-files) will be useful for SPA dev. I used to use go\-chi, but trying Echo now just to expose myself to different codebases/styles.
relevant recent article https://www.ribice.ba/golang-web-frameworks/
So instead of collaborating either with `dep` or `vgo` teams you are building yet another tool. Now I've read it fairly fast but I don't understand what limitations either of the two imposed that made you want to build your own tool? You've also decided to go with roll-your-own ini parsing while there are a few that were fairly widely used - why? As a learning project - sounds like fun, but I don't see what this project solves that others haven't. I think right now there are basically forming two different grouping of how package management should be done before a standard is defined: `vgo` and `dep`. Now we might not end up in "this is how we do it for everything" and might have multiple ways to do this, just like Java has `maven`, `ant`, `gradle`, etc (which are more than just dependency management tools) but I think every effort should be made to improve `vgo` or `dep` and strive to solve problems for majority of cases. My comment is not to spit over your shared project - but more of trying to understand the reasoning behind building this specific project instead of improving on couple of emerging ones.
Everyone will have a different experience. But I personally found Go much easier to learn than C++, and much shorter ramp up time to become productive. As for speed, again it depends on the problem domain. For some problems, little effort can result is very performant results. For other problems careful attention is required. That is the best I can do with such a short and broad question :-) 
Well I used to do a lot of work in C++ from 90s to around 2006 and I can say only few thing; * in c++ every ducking framework has to implement string class and there is no such thing as out of box utf-8 support * you need to learn valgrind as your perfect code will probably be leaking memory * build systems are something you need to learn as m4 cmake are more flexible than make * what go has is easy to use stdlib with solid gc. C++ is like go without any stdlib except maybe file handling :) everything else is system specific. And zero gc so you allocate and handle memory on your own. Even today people argue what is better and when mallock or jemallock and what to use and when. So yeah fuck c++, Go is much better in every case I can think about. 
[removed]
\&gt; I don't understand what limitations either of the two imposed that made you want to build your own tool? I try not to compare it with dep or vgo, mostly I compare it with current "go get" and "go clean". I explain it in the "Problems" section [here](https://kilabit.info/journal/2018/05/Beku__dependencies_management_should_be_simple). Now, if you really want to compare it, here is some questions for dep or vgo, * How do you list installed package in your system \(GOPATH\) using dep or vgo without reading the toml/yaml file? * How do you remove package and their dependencies using dep or vgo? * How do you review update before updating dependencies using dep or vgo? \&gt; You've also decided to go with roll\-your\-own ini parsing while there are a few that were fairly widely used \- why? AFAIK, none of them preserve comments and does not have subsection, like how git config works. \&gt; My comment is not to spit over your shared project \- but more of trying to understand the reasoning behind building this specific project instead of improving on couple of emerging ones. Also in [here](https://kilabit.info/journal/2018/05/Beku__dependencies_management_should_be_simple).
In the same order: * You read the file, `less`-ing a .yml is not that hard * You stop importing them and run `dep prune` * You don't mindlessly update stuff. You rtfm before updating a package
That is the basic premise of a stream in any language. [Read here](https://en.wikipedia.org/wiki/Stream_(computing)), but basically think of streams as a queue, when you pop an element it leaves the queue. Same, but with bytes of data.
Go is great language. But than again, all I see sometimes on github is some project that is so low level, and its done in C/C\+\+ . Like image compression, processing, on such low level. To me it looks like they can do so much more in C/C\+\+ ...
[removed]
I know C\+\+ is harder to learn, has stepper learning curve... but than again I see some projects on github in C\+\+ and they have everything. Like GUI building \(Qt\), Some low level stuff. Can Go do everything as C\+\+ ?
[removed]
&gt;How do you list installed package in your system \(GOPATH\) using dep or vgo without reading the toml/yaml file? Vendoring is in place for this reason and is meant to support reproducible builds and have different projects in GOPATH depend on different versions. While there might be some reasons for some projects to keep all dependencies in GOPATH, vendoring is introduced out of GOPATH limitions and also the ultimate goal is to remove GOPATH \(I've read this in analysis of dep vs vgo a little while ago\). Now yes \- you've outlined the fact that vendoring doesn't solve a certain problem but it feels like you are addressing it from a single developer &amp; single machine perspective and not from a multi\-developer project with CI/CD pipelines, etc. I've had several cases where bumping a dependency of one project was not possible yet due to some breaking change while other projects successfully upgraded. I also recall I think there is a cache in vgo to ensure if you resolved it once \- it can be resolved again for the same version for different project \(I might be very wrong but it does ring a bell\). &gt;How do you remove package and their dependencies using dep or vgo? Removing is simple: Remove it from your package file/module file and then re\-sync. For instance dep will remove all packages that are no longer used or not in your definition. &gt;How do you review update before updating dependencies using dep or vgo? Update reviews are done simply by keeping the lock file and the definition file in your repo \- changes to either of them are clearly visible and thus detected in PRs. &gt;AFAIK, none of them preserve comments and does not have subsection, like how git config works. If you need to comment around dependency and version number choice and what not \- all comments are preserved in TOML of for instance dep. The lockfile is the only thing that is auto\-generated there. From what I see vgo is an improvement on\-top of go\-get while dep is more like your tool. It will be interesting to see how it plays out between the two.
You can do the same low-level stuff in Go. The only things that are difficult to do in Go are... * direct hardware access (i.e. not mediated through a device driver) * inline assembly (not implemented, you need to put assembly in separate files) But apart from that, most C code can be translated to Go without much hassle.
I'm still trying to learn Go, C++ was kinda hard, i hated the syntax, but Go syntax is even worse, wich complicates stuff a bit Overall i'd say Go is easier to learn if you don't mind the ugly syntax and the forced coding style
I updated the proposal and relaxed to "published" packages (that have domain name as part of the path) to give freedom to mono-repos and inhouse development.
If that is `dep` definition of simple, I think we are far away from using computer as a helper. How about tools? non-imported binary in your environment? Did `dep` suggest blank imported them (as in `_ "github.com/golangci/golangci-lint"`) in project?
Then you have to learn a different ORM for each language. And finally learn also sql when the ORM shows his limits. It's simpler to just learn and use sql one time for all ;-) 
&gt; So instead of collaborating either with dep or vgo teams you are building yet another tool. I am nobody. If I go post my idea on Go's issues, I don't think they will ever listen to me. So, instead of talking, I show them proof of concept. I show them code. I hope that at least one of `dep` or `vgo` maintainer will considering what I put here. But, once again, this is not about `dep` or `vgo`, but about `go get` and `go clean`.
No, but unless you have very specific needs, Go is probably better for you, and even if it's not, you should probably consider Rust or even plain C over C++. As for what Go can't do: hard real-time. That's pretty much it. Go has a garbage collector, which means you can't make strong guarantees on when a certain computation will finish. Mind you, you can have a very high confidence, which is usually all what you need and want. Languages without GC are generally either fairly unsafe (like C/C++), or fairly complex (like C++ and Rust), so it's a trade-off. Also, note that it's not really about performance, but about _predictability_. There's a high chance a GC will be faster than your own code would be. 
\&gt; Now yes \- you've outlined the fact that vendoring doesn't solve a certain problem but it feels like you are addressing it from a single developer &amp; single machine perspective and not from a multi\-developer project with CI/CD pipelines, etc. No, it was based on real life, multi developers, problems; where multiple repositories share dependencies, isolated in one GOPATH.
&gt; Most believe it will be better than dep [citation needed]
Because other things in the repo uses them.
Go is slower than C++ because it can't optimize the code and have a GC. Hand-optimized Go code that performs well looks way more unreadable than it's C++ counterpart (which usually looks like regular C++ code). PL tribalism is not my thing, and I use both languages, but I hate to hear about Go's speed over and over again. The compilation speed has its price. This price is lack of decent optimization.
chi is really good, simple, fast, compatible with standard library. It's the most convenient router right now
I like Go, don't get me wrong, but I do think Rust has far better community management / interactions with the core team. The difference between the two approaches is stark, and I know which I personally prefer.. but I've resigned myself to accept that this is likely never to happen with Go. What I find particularly disappointing is that the Go team aren't really making use of their power to move fast on issues as compared to the design by committee approach. They seem to mostly have a hands off approach, occasionally appearing to resolve a problem then disappearing again for a while. I'm aware of the risk of baiting people by these statements, and I don't intend to at all, but I feel it's important to discuss both positives and negatives to this language.
[removed]
With a SPA, I don't think you gain anything in a framework that isn't already in the standard library. A get request is basically /api/handler-name and a query string, and a post is all in the body where all the URLs you see in the browser bar are made in the SPA frontend library, so there isn't a lot to do with routing. If you need relational data, I recommend standard library or SQLx, and if you don't, use github.com/coreos/bbolt for a solidly supported, mature key value store (or asdine/storm if you need a little more query lookup flexibility (less mature, but I love what it provides). Logging should still implement the standard library interface for logging regardless of what you choose, so the choice won't be made by most library frameworks. Auth is tricky, and I do wish it was easier to point to something very feature ritch like Identity Framework in .NET, but there isn't really a comprehensive identity solution covering that much out of box. You might be able to find the answer to your specific use case, though. 
I don't think they compare that well. C++ is an object oriented language where (almost) everything is a class; go isn't. If there was a Go++ ( may be go 2.0 ? ) may be it would be easier to compare. Go is much closer to C in terms of philosophy and/or syntax. Coming from a C background, it was so familiar for me that I instantly loved it, to me it was C without memory management and with native goroutines - plus a few more nice things - that all together made programming in Go very 'ergonomic' to me. I think go inherited the knowledge and past of C, which turned out into efficiency and simplicity. Which is why it's a great language. Now when I pick a language I always think of the goal+lifetime of the project and go is very often a good option for system/backend programming, because it's super scalable, super maintainable and will adapt to a lot of envs when things are done properly. Now I think c++ is super powerfull and awesome but I'd use it where I need ultra fast performances or/and some object oriented features. 
C++ has features that are not so easy to transfere tho
I would require caching to store some commonly accessed information minus the invalidate functionality. The idea was instead of going with different packages for each functionality (like you mentioned for Routing and Logging) rely on a framework that comes with it. That way you are not bothered about individual packages but a single framework. Database would either be Postgresql or Microsoft Sql Server. I was looking at ORM as some frameworks provide it out the box and easier to switch between databases.
Debian repositories contain everything that is needed to build everything else in Debian repositories. The build scripts that we use to build go programs don't use go get. Instead, we install stuff from Debian packages. The go ecosystem makes it a bit hard for us: - nobody wants to version anything - everybody vendors stuff and falls out of sync with many libraries
Hard real time is also questionable on c++ as it requires special hardware to be precise. Hard real time is kind such a niche :) I’m pretty much sure not many of people on reddit did it.
C\+\+ has such thorny syntax, every line I wrote was shot in the foot. Tried to make CSV reader once...dear God...
I’ll bite. Which language has the best syntax, in your opinion?
Opinions do change.
What alternative code would you suggest in code review?
This. You really probably do not need a framework outside of net/http. Maybe a lightly nicer muxer.
You might find this chart helpful. It is from a presentation Rob Pike gave a while ago. https://cdn-1-ednsquare.com/i/5d2d3098-61ca-11e8-bdf4-42010a800002.png
This was a good post and certainly relevant, thanks for sharing.
Hey mate I've had a crack at splitting up your main function - feel free to [review my PR](https://github.com/muhammadmuzzammil1998/Log-mailer/pull/4)
Are you referring to ioutil.ReadFile\(\)? If so, that does a defer Close\(\) internally and takes care of that for the user.
I see, thanks.
In addition to what others already mentioned, Go is also great for making CLI apps. It gives a static binary, you can cross-compile and scp it anywhere, etc. You could make one for something you need.
Verbose != bad readability. BTW, `math.Round` was not supported before, for a good solution was not found. This function and `math.RoundToEven` is supported since Go 1.10, for a good solution was found.
I actually suspect we're really underestimating how much it happens. There's a whole lot of turbines out there, and then there're lathes, centrifuges, storm barriers, internal combustion engines and probably even dishwashers. A lot of weird software that doesn't even use React. 
https://github.com/gobuffalo/pop
&gt; So yeah fuck c++, Go is much better in every case I can think about. There are broadly 2 domains that are probably the most resistant to GC: operating systems and memory-constrained embedded systems. I can't see Go being successful in either of those over the next 10-15 years.
I did it, once. Anything embedded on a robot must be hard real-time.
It's the 80/20 rule. Go will be as good as C++ in 80% of the cases for 0% of the complexity (made-up numbers, but you get the idea). In those 20%, though, you're out of luck, because go won't fit the deal : mainly hard realtime or non-negociable constraints on CPU / memory.
Thanks! I added your suggestion, what do you think of the following: func humanBytes(bytes uint64) string { if bytes &lt; 1024 { return fmt.Sprintf("%d bytes", bytes) } base := uint(bits.Len64(bytes) / 10) val := float64(bytes) / float64(uint64(1&lt;&lt;(base*10))) return fmt.Sprintf("%.1f %ciB", val, " KMGTPE"[base]) } I found the bit shift and use of a string interesting — of course math.Pow(2, base * 10) would also work for the former. For 750 bytes it results in: 750 / ( 2^0 = 1 ) = 750 bytes 750 / ( 2^10 = 1024 ) = 0,73 KiB 750 / ( 2^20 = 1048576 ) = 0,0007 MiB ... For declaring a variable, is `x := uint(5)` just as valid as `var x uint = 5` or are there any gotchas I am missing out on? 
True. Compilation speed is not tied to the language, though, as go is a specification-defined language, not an implementation-defined one. You could totally have a sufficiently smart compiler (TM) that takes more time to compile but generates faster executables. I don't know the status of gccgo, but I think it was the case some time ago.
Is it not a good sign that after ten years there is so much non\-pleasant waves scattering inside Go community. While Go team can improve the atmosphere and culture partly, seems that is not the main problem. I do not have any specific big problems with Go itself and I love it. But something is amiss \- I do not have a big enough picture to pin point it, just thoughts.
There is a Go slack that is very friendly and helpful. The invite page is [https://invite.slack.golangbridge.org/](https://invite.slack.golangbridge.org/) and there is a newbie channel.
I'm a big fan of the whole of Go testing. The simple minimalistic testing library, table driven tests, subtests, and the speed at which they run.
Some backstory: Many members of the core Go team have been involved in other OS or language committees. They want to take community feedback. They have in vgo. They have in type aliases. But at the core this is not a committee vote. People who have technical concerns should voice those technical concerns. I've always (100% of the time) seen them addressed, with proposals often modified due to this process. No, this isn't a committee process and it is different then Rust. But that's okay. Two project styles can have different trade-offs. It doesn't mean either is wrong.
I hope this does not come across as a shameless plug, but the [lecture about pointers](https://appliedgo.com/courses/mastergo/lectures/2618279#/notcoveredinthevideo) from my [Go course](https://appliedgo.com/p/mastergo) is available as a preview and may help understanding pointers better. If this does not anwser all of your questions on pointers, feel free to pm me.
ideally, generated files can be excluded based on filename (eg. *_easyjson.go). I assume you have to generate the code at some point to build, regardless of if it's in source control, so surely at that point this is a problem with generated code rather than checking it in?
[removed]
Did you find an answer for my question ? Or you gonna list some useless blogs using GO to render basic static data. 
So your logic is "don't optimize x compiler because y might not work the same way", makes total sense. /s
I don't believe anyone who says that they found C++ easier to learn than Go. I was a professional C++ dev and it took me ~3 years to feel like I was basically competent in C++, by which I mean I was writing software that was reasonably production-ready. This was mostly because manually managing memory is tricky and it's easy to think you know what a given C++ feature does or how it interacts with another feature only to find out that it doesn't at all. It took me another two years to feel like I understood the compiler errors well enough to be meaningfully _productive_ in C++. With Go, it took me only a month to feel like I mastered the language. No doubt that would have been a bit longer if I hadn't already learned C++, but I can't imagine it would have taken even a single year much less 5+ years.
Of course this is true, as with all data structures there are caveats. In this case multiple bloom filters with different hashing mechanisms can handle most false positives. Worse case you don't get to save space and have to keep an exhaustive list of values but then again you are only checking the full set after it gets filtered.
I saw that picture before. It is very nice representations. Wp
&gt; Also, it's not possible to write generic code, that doesn't have runtime performance penalty in Go. How would you know if it wasn't readable?
I programmed robots and I didn’t share your experience
Yes. Those are nice questions. I would like to see some project or idea, and start building it. I saw a few days ago some guys build gameboy emulators in Java, Go. I remember seeing [nude.py](https://github.com/hhatto/nude.py) on github. Like, what is this guy even doing ? Calling C code from Python, and reading image. Most importantly, analyzing it. To me, it is such low level and understanding and making some bigger project to work really good any way he wants.
Our Lord and Savior Rust, of course. 
not sure this is completely 100% relevant: `go-interpreter/wagon` doesn't target js. it's supposed to be a "bare-metal" wasm interpreter, written in Go :) (so w/o the need to touch nodejs nor npm)
/u/ChurchOfRust
If I was starting a project from scratch and had to make a choice between C++ &amp; Go. I'd choose go everytime.
It's interesting that listening and making a decision is no longer good enough. The decision process itself needs to be under public scrutiny. Peer review is important for acceptance. The public is expecting politics become more scientific now.
FWIW, I believe this is actually coming from a talk given by Brad: \- [https://talks.golang.org/2014/gocon\-tokyo.slide#28](https://talks.golang.org/2014/gocon-tokyo.slide#28)
&gt; They want to take community feedback. They have in vgo. That might be true. The issue is, it is not perceptable by the community. I am not deeply involved in the pros and cons of dep vs. vgo, but what I do know from a ton of text Sam wrote over the last 2 years(?) is he is an authority in respect of dependency management. I am personally interested in him being heard. If I have the feeling that his opinion has not been heard, understood and incorporated to its full extend into the process, then I distrust. Which is exactly what my problem at the moment is: I do not trust the process. I do not have the resources to study the topic deeply enough to build my trust on technical facts alone. 
So you are saying that c++ of today is a different language than 12 years ago? Another strike against c++... if I've got to learn a new language anyways, might as well be a modern one with gc. I've been reading an awful lot of c++14 code lately, and I can't say it's a substantial improvement, despite what the proponents say.
Nothing changed since last time i worked with it in major terms. So yeah c++ committee work is another reason to fuck that shit. Integration with boost was a major buff but too little too late.
If you're using pretty much *any* of the interesting features of c++, you're in for a surprise if you're trying to do hard realtime.
to get a job
I am aware that you can just `if len(slice) &gt; n { val := slice[n] }` but as channels, maps and type assertions use a different syntax I would argue that `if val, ok := slice[n]; ok { ... }` is more coherent.
&gt; ducking Put the phone down.
&gt; the speed at which they run That’s another thing I really like about testing Go. I don’t even filter the tests I run anymore because I can run all the tests in the project in less time than it takes to think about what tests I should run. 
I think this might be interesting, because Go is from the guys who didn't bring us C++.
C/C++ are over 30 years old. There are inevitably going to be more projects written in them than in a language that is 9 years old. 
I don't agree with using the vendor folder as a way to cheat in relative paths; it confused me looking at the source because the main logic of a go project generally have found in the vendor directory, and I looked at every other directory first trying to find some substantial go code.
Ελα ρε φιλε. Τεφτερ; χαχαχαχαχ καλο !!!!
Dear Rust, who art in memory, Referenced be thy name. Thy value come. Thy syntax will be observed, in our code as it is in the crates. Give us out daily compilation, and forgive us our life time errors, as we forgive those who wrote the libraries we use. Lead us not to mutual borrowing, but deliver us from unsafe code. All hail the crab.
Hey, you literally copy-pasted parts of my blog post without giving any credit... For example the OAuth2 flow description. My website: https://jacobmartins.com/2016/02/29/getting-started-with-oauth2-in-go/ Your website: https://github.com/plutov/packagemain/tree/master/11-oauth2 
Learning a new language itself is worth it. Start chewing on the advent of code, project Euler, benchmarksgame, exercism, ... Instead of absorbing advice wether you should have your steak blue rare or well done, find out for yourself. So much fun! "And I want to learn those new languages[...]" Go for it!
I found this bit particularly interesting: &gt; The foundation begun in C\+\+11 is not yet complete, and C\+\+17 did little to make our foundation more solid, regular, and complete. Instead, it **added significant surface complexity and increased the number of features people need to learn**. C\+\+ could crumble under the weight of these – mostly not quite fully\-baked – proposals. We should not spend most our time creating increasingly complicated facilities for experts, such as ourselves. &gt; &gt; We need a reasonably **coherent language that can be used by “ordinary programmers” whose main concern is to ship great applications on time**. We now have about 150 cooks; that’s not a good way to get a tasty and balanced meal. &gt; &gt;We are on the path to something that could destroy C\+\+. We must get off that path! Emphasis mine. Bjarne Stroustrup, creator of C\+\+.
\+1 for it. chi is amazing, very easy and play nice with the std lib.
Have to agree and typically you don't want to deploy test code to the live server. There's no reason to.
I don't find that to be a good reason for the separation. What I find problematic is the separation of test support code. There isn't a great and logically separated place to put setup and support code when your tests live in the same directory as your production source files.
I have been using C\+\+ for a \*very\* long time \(\+20 years\) and I still find things I haven't seen before, and I'm always looking! Sometimes it's mind\-boggling.. But you know what, every time I find a new feature I am glad it exists. I think of all the times I could have used such a feature had I known about it.
[removed]
[removed]
I there any particular project you have in mind? C++ (or C) *is* better for some applications than Go, but IMHO those are really specialised to where you need the extra resource control. If your project needs to get as low-level as C, you could check if Rust could be right for you. It is as close to the metal as C but offers more modern features to prevent bugs.
I agree, but not for the same reasons you pointed out here. I've found that the current system is great. Having tests in the same package as your source code allows you to test private functions defined within the package. However, I've also found that if users consume your package, it's a great practice to write tests in a separate test package. That way, you can test a package as if you were an end user, thus making you think about how you structure your package for external use. It also serves as documentation for developers to figure out how they can handle certain use cases as well as write better unit tests when fixing bugs.
&gt; Having tests in the same package as your source code allows you to test private functions defined within the package. If you have to organize code in a particular way in order to make it testable I consider that a bug against the programming language. 
If you're already so starved for generics you end up [here](https://old.reddit.com/r/rust/comments/5penft/parallelizing_enjarify_in_go_and_rust/dcsq64p/) you'd already have a build step that needs to spend time creating type-specific implementations of a function that go would then compile. If you're not in a problem space where you end up needing that sort of thing then the compiler doesn't need to resolve your generics anway. Simply adding support for generics doesn't have any huge costs at compile time, it's actually resolving generics that has a cost.
&gt; I actually suspect we're really underestimating how much it happens. There's a whole lot of turbines out there, and then there're lathes, centrifuges, storm barriers, internal combustion engines and probably even dishwashers. Yup, but people have this confusion between "fast" and real-time. So micro-controller software must be real time. Software running on Linux, FreeBSD, Windows or macOS can't be realtime. 
That is right, Sythe2o0, this structure brought me more work than I expected, because I needed to setup dependencies manually using the godep package. Besides that, I did not find a way to make it work in VSCode \- the godep package is not working into the editor \- so all builds were made directly in the console and VSCode can't autocomplete the code for objects from the vendor package. Thanks for the feedback, I am going to change this in the next version.
&gt;gccgo I remember hearing that's it's actually slower than goc, but maybe llgo is faster?
&gt; But at the core this is not a committee vote. Tiny note here: Rust isn't done by voting either. It's a consensus process. That said, we make unpopular decisions from time to time too.
Most people recommend net/http \(rightfully so for most cases IMHO\), but rarely do I ever read an explanation why. So as a learning exercise, I decided to write a basic REST API using a web framework, [https://github.com/gin\-gonic/gin](https://github.com/gin-gonic/gin) in this case, and then re\-write the same API using the standard library. I used Gorm for persistence in both cases. Here's my experience. Using Gin did shave off some lines of code mainly around marshalling and unmarshalling structs. Gin Contrib middleware was useful for auth \([https://github.com/appleboy/gin\-jwt](https://github.com/appleboy/gin-jwt)\). Had I decided to harden this API I could have leveraged the CSRF, Helmet, and rate limiting middlewares. These were a nice touch, but I could likely find similar, non\-Gin specific libraries without much effort. Using net/http plus [http://www.gorillatoolkit.org/](http://www.gorillatoolkit.org/) was just as simple as using Gin with the added benefit of more standardization \(why learn two tools when you already have one\). I did have to write some boilerplate code for error handling and marshalling/unmarshalling as mentioned above. Both Gin and net/http were very easy to unit test. Code was organized very similarly in both examples so this likely played a large part in testability. I didn't test performance though. This is where I'm curious if I would have gained a benefit from best practices implemented in Gin. Looking back on my experience I would still go with the standard library in most cases because I don't feel a web framework provides enough additional benefit to warrant the increase in complexity. It's a marginal increase at best. I am curious about [https://github.com/gobuffalo/buffalo](https://github.com/gobuffalo/buffalo). There seems to be some good momentum behind this project. Going the standard library route means you'll need to make a lot of micro decisions on other libraries for certain use cases. Decision fatigue can set in very quickly if you don't have go\-to libraries and opinionated patterns of usage. I feel like Buffalo, if done right, can make that go away. Just tell me the most populate tools for each of the standard problems, give me some reasonable conventions to follow, so I can get things done. You may also find [https://golanglibs.com/](https://golanglibs.com/) useful in deciding which library to use.
I'm not clear which end of http you are coding. Client or server?
Assuming client: 1. Generally http requests will fail if the remote certificate is expired or untrusted, assuming you do not go out of your way to skip verify or anything like that. 2. Http.Response has a TLS field that has a [TLS.ConnectionState](https://golang.org/pkg/crypto/tls/#ConnectionState) you can examine to get the full certificate and all details. 
just started learning go and hadno idea there were this many options that people used
I was watching a lecture from one of the creators of cockroachdb and he made it seem like rust is a much better fit for databases compared to go but felt professionally uncomfortable disparaging the language choice of his project. I'm excited to see other projects pick up tikv as a foundation. 
As someone who's looking for an excuse to learn more about go and developing for crypto, do you have any recommendations? 
I heard that K&amp;R took Bjarne out on numerous wilderness camping trips, but somehow Bjarne kept finding his way back and inventing new language features anyway. "Next time," K once grumbled, "We'll weigh the sack down with copies of *ISO/IEC 14882:2017\(E\)*."
FWIW your tests don't have to be in the same package as your code. However, you can only test against exported (public) methods if you go this route. I'm on a large go project where we have the whole gamut - unit tests for the deep business logic, integration tests against exported APIs, and end-to-end tests which drive our CLI against running servers.
Hey author \(r2d4\) of the tool here. As some other users noted we chose alpine for a few reasons here: 1. Minimal containers. We also have [https://github.com/GoogleContainerTools/distroless](https://github.com/GoogleContainerTools/distroless), which is a similar principle \(a little larger, but uses glibc instead of musl\). This is important since we want to show this is a good tool for iterating on your application \(lots of redeploying the image\). We should probably use the distroless image, since we continuously scan and update those for security vulnerabilities. 2. SSL certs. Sure, we could check in and copy over ca\-certificates \(we've done this in other repositories\), but its a bit of unnecessary overhead. A shell for debugging is nice too, but not something we explicitly needed in this case. Happy to answer any other questions about the images :\)
It's the client side, we receive a URI and then need to verify everything before posting consumer data to it.
Correct. I will check that out tomorrow. Thank you.
For context though, we're talking about 800 documentation pages of new features and extensions with C++, vs adding generics and sum types in go. His concern there is the same as that stated by the go devs, but with C++ it's actually a legitimate concern. With go devs it's more like when python initially refused to add functional programming stuff like lambda expressions, `map` and `filter` just because Guido didn't like/use them and not for any legitimate fear of complexity or sprawl.
A note for those unaware: you can have tests external to the package in the same directory by naming the test package itself with the ‘_test’ suffix (in addition to the file as usual). For packages I’ll often have both internal and external tests within the same directory as the package code itself. 
My god, it's still growing. They should make a proposal to retire the language. This thing has turned into Frankenstein's monster. An experiment that flexes one's curiosity to see what can be done at the expense that you end up with an abomination you ought to put down, but it escapes into the world, and comes back to kill you for bringing it into existence. 
That's great until you have to manage updating queries when you change databases or realize they don't fit your current business logic. Or maybe you hire someone that doesn't know SQL at a DBA level. Raw SQL always leads to problems in my experience.
Using distributed storage is as simple as using a storage engine in single machine，it make the cost down dramatically for higher level development.
FYL, it's a PDF for those on mobile or not wanting to download PDF.
[removed]
Mind explaining what the difference between voting and Rust's consensus process is? At the surface they seem the same.
Russ actually posted about MVS about 1.5 years ago. [https://research.swtch.com/version\-sat](https://research.swtch.com/version-sat) It's unfair to thing that `vgo` was just sprung on everyone at the last moment against Sam's wishes. It's also unfair to think that Sam hasn't heard from rsc during this time either. Luckily understanding the topic _is_ up to the community and I think the community has responded both pro and cons against vgo to help illustrate what the fundamental differences are. You shouldn't have just one person's opinion on it.
Great project! The code is **very** readable and I really liked the visualization. The one thing that seemed a little odd to me is the use of `append` on the `Points` type, considering that it's basically exposing an implementation detail to clients of the package. That's probably just me being unnecessarily pedantic/a matter of personal taste though.
And Guido has stated that after adding map and filter that he regretted it and there were better alternatives that were in the language. They are now in Python forever. [He tried](https://www.artima.com/weblogs/viewpost.jsp?thread=98196) removing them but push back was too great. I think his reasoning was valid and after implementing them he had regrets. This isn't because he "didn't use them" but rather it didn't fit the language. Being very careful on what you add is important and i would rather Go be slow and methodical vs just trying to implement a feature because another language has it. Go core team never said that generics or sum types should never be added, rather that the use-cases and implementation should be thought out and not just imported (i.e LISP map/filter -&gt; Python vs Python comprehensions). Go is special because of what it doesn't implement, not because of what it does. What is the tipping point of C++ bloat? Is is C++17, was it C++11, was it C++09? 
My main language at work is C#, I found go very easy to pick up, but I've also dabbled in tons of languages. the "for" statement is definitely a bit bonkers but you get used to it then it is fine. Overall the language is simple so it shouldn't take you too long for it all to click. You might like my video series as a fun way to practice/learn: https://gameswithgo.org/ 
It will expand your knowledge of watching how a language is made rather then push the limits of what code can do. The go docs provides packages based on types. After trying to write it and then read about it, you will start to see the mastery of leaving things out and how that can greatly improve how you put things together. This is what I have read. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk This is what I am reading. https://www.manning.com/books/get-programming-with-go None of these really matter when you begin to see how types can be crossed together to make methods and packages. First learn the syntax. Then learn the Reader/Writer types. Then try to learn how the io package is put together. Then learn about zero values and interfaces. This will explain those bigger packages and more abstract concepts of the http package. The basic components have magic on top of magic built with them. Learn to read types, combine types, write types, appreciate the core types.
You can read the [go book](https://www.amazon.com/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440/ref=sr_1_3?ie=UTF8&amp;qid=1527566016&amp;sr=8-3&amp;keywords=go+programming+language) which I think is a pretty good source. If you don't have the money for that I would do the go tour, read the Go language specification, and then read Effective Go.
Exactly, The important point of ORM is implementation version controlling over your models, I think this context in enterprise applications are very useful.
I personally think from a QA point, its a must to commit the vendor folder, otherwise, you can never be 100% certain something hasn't changed between builds that could possibly break your product. So we most definately commit the vendor folder, its the same with our C++ products, all thirdparty libs are committed to the repo for build purposes, and only updated once they have been tested on another branch, and then committed to the main branch. I have been in situations (long long time ago), where this was not done, and it only takes this to happen a few times, and you are running around trying to work out what broke the build (good case), or why the product all of a sudden has an intermittent crashes.
You probably meant ***DEFINITELY*** -not *definately* --------------------------------------- ^^^Beep *^^boop. ^^^I ^^^am ^^a* ^^bot ^^whose ^^^mission ^^is ^^to ^^^correct ^^your ^^^spelling. ^^This ^^^action ^^was ^^^performed ^^automatically. ^^Contact ^^^me ^^^if ^^I ^^^made ^^^A ^^mistake ^^or ^^^just ^^downvote ^^^^^^please ^^^^^don't
A 182 KB one.
Go is a very simple language to pick up. It doesn’t have the same sharp edges as c++. It has a very good stdlib, and lets you drop down to a Low level when absolutely necessary. I don’t think you’ll struggle with it.
I like emulators, how they make compiler, raw image processing, reading sound on so low level, making databases. I like any project I see, and how they can make it. 
&gt; gives value proportionate to the complexity Yeah..."We don't like/need it it so we call it too complex." Bjarne is talking about actual complexity measured in hundreds of pages just for *the documentation* of a feature.
Lazy consensus is the practice that if you're working on a proposal, you run under the assumption that silence means approval unless someone raises an objection with your proposal. With voting, a vote must pass in favour or against your proposal, therefore you run under the assumption that you do not have approval.
So, no strings.Builder for you?
Please do not use the lazy shortcut "C/C++". C is a fine compact language with utmost performance. C++ is a bloated monstrosity that is so complex it is almost impossible for compiler writers to implement without significant bugs. Many of the features have a significant cost in performance. Go and C++ do not play in the same space, there is a hard divide between manually managed memory and automatic garbage collection. The true replacement of C++ is really Rust.
I know it is not same. Thats why I didnt wanted to write in post header "Go vs C/C++" . But more and more projects I see in C++ (databases, emulators, compilers... and even some tutorials for that in it) than in C. Thats why I asked for C++ . I would honestly Like to learn C but it just doesnt have some good documentation as Go. Everything is outdated or tutorials ste learning what is struct, functions, etc and they show some simple data structure and that is it. Thats why I'm asking for Go, beucase it seems preety good documented. And has some really awesome projects (docker)
... so, less than half the size of loading this page!
 Why not just build the executable and deploy that, instead of shipping the entire source repo?
C++ is well beyond the point of no return or redemption.
Interesting, don't know C++, but I do know a little Rust and I feel like they are adding so many features, syntaxes etc, that it's becoming more and more unapproachable. Go really hits the spot for me, most productive language I've ever worked in.
Please see the section on templates of the C++ spec PDF. It is the single largest section. Of the 447 pages of the language spec (the other 1000 pages are about the standard libraries), almost 80 pages of that are about templates. I would appreciate if you'd elaborate since templates fall into the category of large features taking (nearly) a hundred of pages to document.
Lots of things use `unsafe` in the standard library, but that's _the standard library_. `unsafe` is allowed to break packages that depend on it, but not the standard library, so it's not the same thing at all.
It's different for the standard library. The standard library is guaranteed to work (or should be), but a third-party library is not. So a third party library using the unsafe package is not ideal, especially since unsafe is NOT backed by Go's backwards compatibility guarantee.
Lua is another language that, like Go, has resisted large additions to the language. I really need to check out Rust at some point.
Bjarne lists 43 papers and the few I glanced at were around 20-30 pages each, so I was guesstimating 800 pages based on 40 x 20.
Well you could have a ci machine that is the same as the target platform, build and deploy from there...
Voting means that when it’s time to make a decision, everyone says “yes” or “no”, and if more people say yes than no, it’s accepted. Consensus means that when it’s time to make a decision, if anyone says no, then it is not accepted.
Your build server/pipeline should handle that.
I am curious about point #3. I between setting up image to work on "golang:1.10.2" vs "golang:1.10.2-alpine3.7", I found that using "golang:1.10.2" is a lot easier. If I recall correctly, on alpine you have to manually get git/curl/Go/vendor tools.... while on golang basic image, you have those out of the box. So I am curious about you building process. Dont you have to use git/curl and vendor tool(godep/vgo/glide)?
Why do you vendor your linter? I really don't get the point of that, besides fluffing up the vendor folder :D I've been using dep since it was somewhat stable (and slow as heck), into what it is now - a stable and fast environment that I don't have to think about. My linter is installed globally on my machine, as well as on all our CI images. Same goes for `grift`, `statik` and the rest, wherever they are needed. It sounds to me, like you're really trying to glorify the role of a dependency manager from something that moves dependency management out of your way, into something that you actually pay attention to. As long as my project works fine after a `dep ensure` and until such a time, where I can comfortably use vgo or a suitable versioned alternative, `dep` has all that I need and not much else. Which sounds quite go-like to me. With that in mind, your package does have it's merit. It's just a *tad* rude of you to announce it as the saviour of all and ignore the now-two-year-long attempt by the majority of the active community to contribute to solutions that are both idiomatic, community-driven and easy to use. Because, mate, as much as I love `pacman`, it is **not** user-friendly and should not be used as an example. Going back to your question about pruning unused packages wdyt about `pacman -Rns $(pacman -Qtdq)`. That look like using the computer as a helper to you?
With that attitude nobody would be contributing. I think it's worth an attempt to join in on discussions \- I've found out the go community and maintainers of many projects and language itself are quite open and welcoming \- they realise that you need to do things together with the community.
Nah, mate, you're looking for something that's not quite golang :D Idiomatic go supposes that you know what you need and what you're going to use it for. And it really comes with batteries included, down to the drivers for most DBs. Frameworks are a kind of big, big no-no in the go community, for reasons better left to [this article](https://blog.golang.org/organizing-go-code).
[removed]
I use https://github.com/rubenv/sql-migrate with go-bindata and sqlx. No ORM.
Ok, thank you for your feedback.
VSCode is not written in .Net [https://github.com/Microsoft/vscode](https://github.com/Microsoft/vscode) additionally, its opensource and you can audit the code like it was done with .Net core in the link you posted
&gt; I remember reading somewhere that there is a standard way to do vendor now, but i find many conflicting information so I hope to hear some up to date opinions. • https://blog.golang.org/versioning-proposal • https://github.com/golang/go/wiki/vgo • https://github.com/golang/vgo &gt; Are there any new virtualenv-like thing for golang ? Which one should I use ? How do the community thing? Most people I have worked with either have [a single Go environment](https://github.com/golang/go/wiki/GOPATH) or [use Docker](https://hub.docker.com/_/golang/) .
&gt; I remember reading somewhere that there is a standard way to do vendor now, but i find many conflicting information so I hope to hear some up to date opinions. • https://blog.golang.org/versioning-proposal • https://github.com/golang/go/wiki/vgo • https://github.com/golang/vgo &gt; Are there any new virtualenv-like thing for golang ? Which one should I use ? How do the community thing? Most people I have worked with either have [a single Go environment](https://github.com/golang/go/wiki/GOPATH) or [use Docker](https://hub.docker.com/_/golang/) .
From it what looks like from that thread, it is opt-in in .NET core, isn't it?
I honestly didnt read it all but I saw someone mentioning that it is not on a recent comment. Cant vouch for the accuracy of the comment thought
\&gt; Are there any new virtualenv\-like thing for golang ? Which one should I use ? How do the community thing? Usually there is no need for one, Go is backward compatible, so you're unlikely to find yourself in situation where you need to switch to the older version of Go.
I know a lot of people have already hammered this point home, but you really don't need to have a framework for all of that. It's not about reinventing the wheel or anything like that, the amount of code you'd have to write to tie a few libraries together to write an API is absolutely tiny (honestly, it can be one type called from main, or even just main if you wanted it to be). As for ORMs, I've still not touched one in Go because they frequently make code more magical than it needs to be, and often slower too because of the use of reflection. Plain SQL is supported by the standard library, and if you wanted to make that a little less verbose there's always [sqlx](https://github.com/jmoiron/sqlx). For logging, I'd look at something like [zap](https://github.com/uber-go/zap). I can speak from experience here that a fast logger is a good idea, you'd be amazed how much some logging can slow down an application if you've got a slow logger. I have already mentioned it elsewhere, as have others, but [chi](https://github.com/go-chi/chi) is a great router. Feature-rich, and extremely fast. For caching, you can always just write your own cache interface and then plug a library for Memcached or Redis in. But you should also bear in mind that that's only really "necessary" if you are using multiple application instances, and even then it might not be worth it that much - because you also have the application memory since your Go app will be a long-running process. If those few things are all you really need, it honestly will be worth your while to just tie some libraries together yourself. You'll get the best options available, and you'll find it easier to swap things in and out as needed.
use gometalinter, warnings about shadowing variables that I dont care about are annoying and counter-productive thus the reason it's not there by default 
Go doesn't do warnings: https://golang.org/doc/faq#unused_variables_and_imports "There are two reasons for having no warnings. First, if it's worth complaining about, it's worth fixing in the code. (And if it's not worth fixing, it's not worth mentioning.) Second, having the compiler generate warnings encourages the implementation to warn about weak cases that can make compilation noisy, masking real errors that should be fixed." Shadowing might be disallowed someday in Go 2: https://github.com/golang/go/issues/377
`go vet` will check for shadowing.
We don't do this; proposals need an explicit acceptance from the relevant team.
This. Always have `go vet -shadow` in your Makefile's check target, along with errcheck and megacheck.
&gt; Why do you vendor your linter? I really don't get the point of that, besides fluffing up the vendor folder :D Yeah, I agree with that, it's just a bad example of tool that can be included. BTW, this tools is not talking about vendor, it's about tool to manage package in GOPATH. &gt; With that in mind, your package does have it's merit. It's just a tad rude of you to announce it as the saviour of all and ignore the now-two-year-long attempt by the majority of the active community to contribute to solutions that are both idiomatic, community-driven and easy to use. I have said in the beginning "to overcome the limitation that "go get" and "go clean" currently can't handle". If its has any functionality that resemblances with `dep` does not mean I am suggesting to replacing `dep`. &gt; Going back to your question about pruning unused packages wdyt about pacman -Rns $(pacman -Qtdq). That look like using the computer as a helper to you? For people that know what `pacman -Qtdq` do, and know the consequence of `-Rns`, I will say yes.
As far as I know it was always a JS application. Here's the Linux RPM dependencies \([https://github.com/Microsoft/vscode/blob/master/resources/linux/rpm/dependencies.json](https://github.com/Microsoft/vscode/blob/master/resources/linux/rpm/dependencies.json)\) it has nothing to do with .Net or even Mono on Linux. I think it does require .Net framework \(!= from .Net core AFAIK\) to be installed if you are using VSCode on windows but I don't know why
As they say: Q: There are a ton of other high-perf packages for JSON parsing in Go. Why creating yet another package? A: Because other solutions suck. They require either rigid JSON schema via struct magic or perform poorly when multiple unrelated fields must be obtained from the parsed JSON. Additionlly, their APIs suck. Don't like it, don't use it.. rule of thumb.
vscode is electron application.
I haven't checked, but it probably forks, why do you care?
Well, it has served well these projects https://github.com/topics/go?l=go&amp;o=desc&amp;s=stars
C++17 really went over the line, but C++11 was probably around the time it got really bad. I’d love to see genetics and sum types added to golang. I don’t need anything other than that. Really just generics. I know that’s a meme over at places like /r/pcj but it’s true for a lot of programmers (lol no generics). I also agree with you about python and lambdas, map, and filter. I’m really starting to believe that having a benevolent dictator so to speak (Guido, Linus, etc) is that right move for language and tech design. Design by committee has failed so many languages and other ventures that it just doesn’t work. 
I'm primarily a python developer. Long ago I started to learn C++ and found it boring and complex. I put that aside and learned Go starting back when it was in the pre 1.0 state. It was way more fun, and easy to become productive. I know C++ now, but Go is still the most fun to write. I would prefer to write as much as possible in Go until a project forces me into python or C++. 
This doesn't seem like the same person. The English in the article you linked is much better than the posted article making me think that English is the first language of the person who wrote the article you linked, whereas the author of the article in this post may have English as a second language.
Thanks for the kind words! Are you talking about exporting Points publicly? Otherwise it's just a type definition for a slice of `float64`s, so the append isn't anything extra-ordinary.
Yeah theres a different license when you compile it yourself to just downloading the install. It is built on atom, which is built with electron. Yeah there is a license attached that says Microsoft can do anything it wants. Mainly because there is a huge difference between free and open source. Plus, those extensions are not free either. 
https://trends.google.com/trends/explore?date=all&amp;q=golang
It's literally huge there. https://blog.golang.org/gopherchina https://blog.golang.org/hello-china People before go1 a lot of times picked up Chinese to English translations books on go to find resources. 
Yeah that's basically what I mean. Again I'm being *super* pedantic here and it's actually not a big deal, but I'd personally implement an `Append` method on the `Points` type. The idea being that if you were to change the implementation of `Points` somehow (maybe you want the slice to be thread-safe and hide it behind a mutex, or you want to use some exotic key/value store for storage) consumers of the package shouldn't have to change their calling semantics. Hope I communicated that in a way that makes sense. I'll even open a PR for the change if you're open to the idea, shouldn't be more than a few LOC + updating any relevant tests.
Nothing different in declaration methods. 
The best book on plain C is "C: A Reference Manual" by Harbison and Steele. The K&amp;R book is too ambiguous and out-of-date. [See here:] (https://smile.amazon.com/Reference-Manual-Samuel-P-Harbison/dp/013089592X) 
What is /r/pcj?
Thanks. only my fault. editor's flycheck startup another compile process.
Thanks for the link, i will read more in depths. 
Thanks for the links. I guess I not concern with go version. I am more concern with the different packages version.
In my half-sketched Go generics idea, it basically boils down to proposing that we carry this idea out into the user-visible level, allowing users to declare interfaces that they can use generically, and letting the compiler do much the same thing. Go is already not the Fastest Language Evar, so if the implementation of generics involves "generic" code that uses lots of interfaces (or interface equivalents) rather than code generation that hard codes everything and gets every optimization, I still think it would tend to satisfy most of the requirements of both the Go users and the Go designers. In brutal competition terms, I consider Go's competition to be more the Python sort of languages, the dynamic scripting languages, rather than, say, Rust. If you gave Go this style of generics, it wouldn't move it closer to Rust, but it would carve another hunk out of the dynamic scripting languages, at least once it got around enough and the libraries started showing up on GitHub for it. What remaining reasons I would have to prefer Python over Go would almost completely disappear at that point.
Realtime applications don't fit well in Go, due its unpredictable GC and scheduler.
Yeah the whole Model, Service, Controller system does help but it doesn't remove the need to rewrite your queries when the DB changes. I've had to move a project from Postgres to Cassandra to Athena and it was awful. All of that was because the project lead doesn't like ORMs. To really see query times better than what an ORM is going to produce you need to have either a very complex query or really be a database expert to squeeze that extra performance out. I've never been in a real situation where the overhead of writing all of our queries by hand was worth the perf boost.
I've written a lot of python, and I've used map and filter. Python would have been better off without them. To go full /r/Golang ... it would have been better off without list comprehensions too.
There's no good way to remove features from a language, so I don't see how C++/Rust can ever tone down their positions.
`unsafe` is used only for zero-allocation conversions between `string` and `[]byte`. See `b2s` and `s2b` functions. I think it is possible to get rid of `unsafe` dependency without performance drop. Will try doing this :)
No, I can totally understand your point of view and as a matter of fact I already had that method implement, but dropped it again for performance reasons (function call overhead). What would probably have a similar performance impact, would be turning `Point` into an actual Interface with a `Float() float64` method. That would give you the flexibility to to turn pretty much anything into an acceptable `Point` and you can directly correlate it with your existing data (without a mapping table). I'm still toying with the idea in my head, but I think that would make a lot of sense. I'm absolutely open for PRs, of course! Issue #2 should probably be tackled first, though, so we can properly measure the actual impact between changes.
Curious, we're similar but different, as in my case: &gt; actually appears to be the author's credo, so I personally try to keep watch on his output. This old-school ensemble of opinionated, raw-perf-focused, outspoken, no aim-to-please rhetoric, no nonsense has gotten all too rare in the field (and is usually promising --- either for outright usage or at the very least for learning hi-perf mindset). Especially when you have an initially low-level-ish, C-alternative-ish, compiled typed "systems lang" that gradually gets infested by the fluffy fuzzy "web set" fleeing Py, JVM etc. Seeing too much hyped, finely-logo'd bogus and Github self-marketers, not enough meat nowadays.
programmatically challenged juveniles
Ah, great points. I also love AllocsPerRun and related functionality
Go has extremely short GC pauses and you can do thread pinning to avoid scheduler issues. Perfectly fine for many realtime applications.
It looks more consistent, kind of. But that's not a great thing because a slice and a map don't operate the same way in other regards. Eg. mymap[foo] = bar // automatically grows myslice := []string{"a", "b", "c"}[0:1] myslice[1] = "bar" // not automatically grows
Generics were one of the most far-reaching changes to Java. APIs had to change everywhere. And with Go it will be an even bigger change, because Java at least already had parametric polymorphism.
97% of people using Go cannot name one core member. 99.97% do not know who wrote `dep` or care. Go cannot exist to pander to the egos of "high profile" contributors/community-drivers. 
Any time.
&gt; fastjson doesn't panic when parsing unexpected JSON &gt; ... &gt; For instance, when Int is called on the Value containing an array What do you call this apart from "unexpected JSON"???? &gt; There are the following approaches when the caller improperly uses the provided API (e.g. programming error): &gt; ... &gt; Go way. Panic on programming errors, return library errors. This usually minimizes the time required for fixing programming errors This is a fine definition, because when the programmer calls the API improperly it will always fail. Minimal testing will catch this. In your case though some input works and some panics. This is not improperly using the API (a "programing" error).
Really, on low-level components ? What happens if garbage collection is triggered when the emergency-stop button is pressed ?
Given the optimization is known/done I don't see why the smaller form is "bad" from any of your links. If your mental model is that the language _should_ allocate the slice when both you and the compiler know that isn't required ... that seems like more of a problem with your mental model. Much like arguing against the string &lt;=&gt; []byte in maps optimization.
&gt; In Go, type conversions are often free, whereas in other languages you expect them to involve a bunch of work. I guess from that perspective this optimization makes sense. &gt; &gt; Yeh, this is pretty much my view. It's very common to have an int type and then need to do a "free" type conversion, and string/[]byte/[]rune feels very similar to that.
U mean I don't a busy schedule
Also, something like [gocraft](https://github.com/icexin/gocraft) will probably give you some ideas since they have made a fair bit of progress on a Go version of Minecraft. It might be nice to also look at the long abandoned [chunky monkey](https://github.com/stefanha/chunkymonkey) approach since it is a very small start to the idea and you might be able to learn from seeing a much earlier stage of development.
I respectfully disagree. The conversion in `string(byteSlice)` is sometimes unavoidable (like in the maps-key-cannot-have-slice-keys case), thus it's sane code, so optimizing the conversion away wherever possible makes sense. OTOH, the conversion in `len([]rune(s))` is _always_ avoidable and it's thus not an example of good code.
Sam has been heard. Very well. I personally worked with Sam two years ago on vendoring for some time. If you have any questions about community feedback, please just read the top comments on the vgo proposal issue. They are by Russ and edited over time to be accurate summaries. The community has been heard. A few people do disagree. If we are specifically talking about vgo, I'm very excited to see this happen. I disagree with Sam it is a bad foundation to build on. Sam is far from the only person in the community to work deeply on this subject. 
[https://astaxie.gitbooks.io/build\-web\-application\-with\-golang/content/en/](https://astaxie.gitbooks.io/build-web-application-with-golang/content/en/) quite a good resource on Go web development
Nice write-up. I was surprised to learn that many people don't know about the `testdata` folder. I think it's extremely handy. Two small suggestion, though. I would avoid using `fmt` or `log` to print information during tests whenever possible. Instead I would use the [logging functions](https://golang.org/pkg/testing/#T.Fatalf) provided by the `testing` package. In a similar vein, I suggest you have a look at the [Helper](https://golang.org/pkg/testing/#T.Helper) function, which allows you to mark your helper functions. That will make your stack traces a lot nicer to read and frees you of having to use `runtime.Caller`.
to be honest I don't feel there is a lack of it. But maybe is because I'm already a web dev with experience in other languages &amp; frameworks, but I understand it might be challenging for a newb. I would recommend learning with this book: [Go web programming](https://www.amazon.de/Web-Programming-Sau-Sheong-Chang/dp/1617292567/ref=sr_1_7?ie=UTF8&amp;qid=1527614164&amp;sr=8-7&amp;keywords=golang) Follow through code with it, then just use the seed project there and build your own web app from it. Use it as a "seed project"
[removed]
I would recommend looking up Jon Calhouns gophiercises and also his new book about web development with Golang at www.usegolang.com
You have explained `sliceHdr.Data uintptr` twice, and I've never [intentionally] said anything to the contrary. What I keep bringing up that the actual type of what sliceHdr points to is a string, and if the gc knows this, which somehow supposedly it does, it ought to follow the pointer in the string buffer and keep it alive.
I would suggest that in Go, you don't write web applications per se. You write applications that are agnostic to how the user accesses it (web, terminal, GUI, etc.), and then you write a thin layer that mediates the user input and output with the rest your application. There is not much for web development specifically because there is not much that is specific to web development. Strictly speaking, all languages encourage this kind of separation of concerns, but often other languages end up with frameworks with leaky abstractions and then you get books that detail those abstractions that are specific to the web. The Go community, in contrast to some other language communities, is more staunchly in favour of that clear separation. Once you understand how to read query/POST parameters and write a response using `http.Handler`, everything else about your application is pretty much the same as if you were reading environment variables and command line flags and writing to stdout. As a result, you may want to also consider books about Go in general, especially those about application architecture.
When you have generics to implement zero cost abstractions you have a lot of free time left.
Thanks for the comments guys, one thing I realized was the over-reliance on 'make' for build large projects. I think this is a hangover from C/C++. What do you guys think?
Real\-time term has different meanings nowadays, but on real\-time embedded systems, sometimes known as "hard real\-time", the system must have a **deterministic execution time**. Not the fastest nor the lowest latency.
@ligustah Thanks for the feedback! I will definitely look into the \`testing\` package 👍
Thank you! That is very helpful.
I know. I was talking about soft realtime applications like audio mixing.
This whole debate / attack is mainly fueled by people who worked on dep and are rather butt-hurt that the go project went with vgo rather than dep as the default versioning manager. Most of the "points" in all sdboyer's posts applies as well to dep/glide but somehow vgo is the devil.
[https://golangbridge.org](https://golangbridge.org)
the name is similar with fastjson of alibaba
The key point is that maps and channels require the feature. Slices do not require the feature. So adding this would not gain anything, except another way to do the same check. 
In the first example you’re defining multiple variables (`_` and `i`) and in the second you’re more or less concatting multiple statements on one line like you could do for: `if err := myFunc(); err != nil { ... }` vs `err := myFunc() if err != nil { ... } ` It are two completely different things!
I began with learning normal Go and then I looked into [https://echo.labstack.com](https://echo.labstack.com), they have nice examples.
[removed]
It seems like you believe that in the first case we have the two parts `_` and `i := range x`. That's not the situation. In the first case we have *one* statement, an assigment, with two variables \(`_` and` `i\) on the left hand side. The first variable gets the index and the second one gets the value. In the second case, however, we have three parts between `for` and `{}`; first one statement, then one expression, and then another statement. The first statement is an assignment with one variable \(`i`\) on the left hand side.
Nitpick: Your two examples aren't quite equilevant. x := []int{10,9,8} for i, v := range x { fmt.Println(i, v) } x := []int{10,9,8} for i := 0; i &lt; len(x); i++ { fmt.Println(i, x[i]) } Those two snippets should produce the same output. In the for...range example, 2 values are returned by the range x statement: the index and the value. If you only want the index you can omit the second variable. If you only want the values, you need to 'assign' the index to the placeholder '_'. At any rate, commas are used to separate values while semicolons are used to end statements. Normally you don't see the semicolons since they implicitly exist just before the '\n' character, but in the traditional way of expressions for loops (with the init step, the exit conditions, and the increment) you have to tell the complier where the statements end.
Fixed link: https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics
Need examples of using it in an expression context. E.g. what happens when I run: `foo := bar ?: baz`? So now the compiler has to unify the two types to a generic parent type? This is pretty annoying for a compiler writer. You shouldn't ask for an elvis operator in a language until it has a ternary (or allows if/else as an expression not a statement).
Its okay, but in spite of all the criticisms go err handling has grown a lot on me. Honestly this wouldnt change much about the idiom, only very slightly shorten it in some cases. I dont mind the proposal but lets be clear this is nothing more than alias like functionality
I don't think this solves much. Most things have two return types, so I can use this like: `foo := getFoo() ?: return errFromFoo` which is the big use case anyways. Also, I consider an elvis operator to be generically applicable, not just for errors. How about this alternative. Put a question mark on any var on the lhs of an assign stmt, then run any side-effecting stmt on the rhs if any of the values are non-nil, e.g. `foo, err? := getFoo() ! return nil, err`. Or how about just a ternary and ask go fmt to allow single lines em, e.g. `foo, err := getFoo(); err != nil ? return nil, err`. But the real answer is easier macros so we can just have `try!` or `getFoo()?` like Rust or something but it will never happen since they want all code generation to be explicitly invoked.
Not heard of that one. I use vscode and it has served me very well with support for interactive debugging and so on.
I really do not like the “semver-like” versioning string requirement. My packages are already tagged with valid semver releases and now I need to change them by adding a “v” prefix. If you don’t know what I’m talking about vgo requires the release to be tagged like “v1.0.3” which is not standard semver. 
Tags are just that, tags They are not semver specific, thus it would make more sense to signal that the tag is a version string by having a little v prefix. 
Ah, a wonderful explanation! Thank you! I'm still pretty noobie with the language so that really tripped me up! Thank you so much!
Got it! I really should've been paying attention to the syntax in variable declaration. I probably would've picked up on that. Thank you!
Awesome work Russ! &gt;Unfortunately, the GitHub API is far more restrictively rate-limited &gt;than plain git access, so the current vgo implementation has gone &gt;back to invoking git. Would be cool to hear from Github and see if they could help with this
As long as the committee makes sensible, well-thought-out decisions that make sense with the goals of the language, it's fine. The community on the other hand demonstrate the exact opposite sadly. No coherent "taste" about the language.
Actually, back when semver said anything about how git tags should be named, it did recommend the "v" prefix. They removed all mention of tags right before release 1.0.0 https://github.com/semver/semver/issues/1 That said, the "v" prefix is fairly common in the git community. I think GitHub even suggests using it in their UI. I honestly don't care which one vgo prescribes, as long as it has a single recommendation. Go is better when we agree as a community to be consistent. Tag naming conventions are like code formatting conventions. We could have let every project dictate it's own code formatting preferences by giving gofmt a lot of knobs and encouraging each project to choose the settings it liked the best. Oooooor, we could just have one recommended and consistent formattl for the whole community. I don't care if we use the v prefix or not, but I'm very against allowing both prefixed and unpredicted versions without a good reason for avoiding consistency.
&gt; inspired by C's ternary operator Go discarded the ternary operator because it's ugly. So why base a Go proposal on its syntax?
main() { }
Cool! It is curious to me that Go's map implementation is both adored and hated by so many precisely because of the *generics* debate. As for me, I still can't deny that this is a clever implementation specially for its simplicity.
Man I'd love that along with generics.
This is awesome, man! I just started learning the language a few weeks ago! I can only hope to do this in a years time!
Maybe something like this? https://github.com/tebeka/selenium
There are a few Chrome devtools clients available, listed here: https://github.com/ChromeDevTools/awesome-chrome-devtools#chrome-devtools-protocol I am the author of https://github.com/raff/godet, if you want to try it out (I have some examples that do most of what you ask, but I don't have a specific example that fills a form - I have done it before by simply running a script when the selected page becomes available) 
Go doesn't implement maps "without generics". Generics are a programming abstraction, not an implementation strategy: all three languages discussed have generic types. Go's approach is simply a hybridization of specialized code generation (what C++ does) and single implementation with boxing (what Java does). But this "best of both worlds" means it is hand crafted specifically for maps and does not generalize across other container types. That's why it is inaccessible to the programmer.
A special case for GitHub is separate from forcing people to use only GitHub. We were always also going to support other sites and hosting setups too, but that's not ready yet. 
I don't get the point of all this versioning nonsense. If you put out a public API you don't break it. If you want to change it then add a feature test and extend the API. It isn't rocket science. It is just good design. Versioning is a bad approach and I am a bit frustrated the Go people are buying into all this semver nonsense and trying to emulate NPM. 
What if you publish an update that doesn't change the API but changes behaviour subtly or introduces a bug. People want to use version tags to keep their code working with known versions of a package.
Having a language dependent on a single vendor maybe isn't a great idea.
https://play.golang.org/p/04Lud8ExLVW See that last line that I added. It does not compile so a person is not a human. You can use this way to test if a struct correctly implements an interface. This is what interface is for, to make sure certain rules are followed.
I'm not trying to bash this resource because I'm guessing there are a ton of great bits in there, but if I recall correctly at one point the author called base64 an encryption algorithm, which it is most definitely not, and I recall many people pointing this out and the author refusing to change it. Do you happen to know if this was remedied?
Thanks for the kind words! Technically the book isn't new - I think I released it over a year ago - but I have modified and improved sections since then so in a way some parts are new ;)
Thanks for finding that issue. I could not find anything about prefixes on semver.org for the latest spec which led me to believe it should not be added. I understand the "v" prefix is common and has been used for a long time for many projects. However I wanted to abide by strict semver and from what discussions I did find it was not a settled debate. Many popular open source projects go without a "v" prefix or have other tagging templates. I honestly appreciate Go for removing the knobs and setting standard. I only wish this was done earlier rather than later. To ensure users of my package who are using dep with my tagged releases I will have to duplicate all my tags. 
I replied to the parent comment but wanted to reply to you as well. Sorry if my comment came off as rude or unappreciative, I love Go and benefit from the fine work you and many others have committed. My frustration came from having recently migrated downstream users to dep and having them already pull packages with semver tags minus a prefix. I think now my best course of action is to copy the existing tags with a v prefix and support both dep and vgo. 
Thanks Jon for a great explanation. This makes absolute sense, and I will be purchasing your course. My fear is that I would get fatigued when relying solely on the standard library as this will be my introduction to backend development. But I'm glad there is a Slack group associated with the course to help.
FYI, I think dep works just fine with v prefixed tags. Hell, [dep's own tags](https://github.com/golang/dep/tags) are formatted that way. You may be able to replace the old tags without causing problems for your dep users. It depends on how dep's lockfile is implemented. It's safer not to remove or change your existing tags in general. Even if dep handles it well, someone or some other tool could always be relying on them and not expecting them to dissapear. But going forward, you should only need make v prefixed tags and both vgo and dep should respect them. 
It is meant for testing, but Agouti (https://agouti.org/) might meet your needs.
Preventing DDOS attacks by rate limiting one protocol but not another makes exactly as much sense as securing your home by locking your front door, but leaving the side door wide open. There must be some other reason besides standard DDOS protection.
The method Greeting is declared on a pointer receiver and in your chemist struct is declaring a value. take a look [at this example](https://play.golang.org/p/0NrhQ_Bn0ed). The documentation of the language on [structs](https://golang.org/ref/spec#Struct_types) might also be useful to understand embedded fields \(and how they interact with interfaces\)
[removed]
[removed]
Was literally sitting down to write an interceptor for my backend. Thanks for the good read. 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/metapcj] [Yeah, I found the subreddit shortly after and was amazed that people spend their time sharing their strong sometimes unfounded opinions about other people's posts of their own strong sometimes unfounded opinions.](https://www.reddit.com/r/metapcj/comments/8n5prr/yeah_i_found_the_subreddit_shortly_after_and_was/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
&gt; C++17 really went over the line, but C++11 was probably around the time it got really bad Care to explain?
In Go, semicolons separate statements, and commas separate variables in multi-variable assignment. You will not see many semicolons outside `for` loop statements or `if err := f(); err != nil` constructs though, since they are not strictly required. The Go compiler inserts them automatically. (This is one of the reasons why Go source code looks so clean and readable.)
See also: [proposal: Go 2: simplify error handling with || err suffix · Issue #21161 · golang/go](https://github.com/golang/go/issues/21161) 
I reference that in my proposal, stating that because it doesn't explicitly return that it is unintuitive and not very readable.
[removed]
I think there's a distinction to be made here between _implemented without generics_ and _exposed generically_. The implementation does not use generics. The compiler rewriting allows it to be exposed generically.
Any news about the proxy package network ? Is there a chicken-and-egg problem also ?
This series is very welcome because we don't know exactly how to follow Vgo which is not versioned himself :-) 
I'm going to brag that I thought of including the version number in the import path myself. There's no need to ever delete any public API when you can create a new import path. It's a fairly obvious conclusion, Google even uses it in their Go API libraries. The minimal version selection insight is genius however.
From someone who's anxious to learn Go, thank you!
Deno is an anagram of Node. Good one, Ryan Dahl 
I keep hitting these nuggets of common sense ... most disconcerting.... thanks for the info
I don't understand what prevents you from thinkcing the runtime,KeepAlive line is needed. So here is my last try to explain why. func ByteSlice2String(bs []byte) (str string) { sliceHdr := (*reflect.SliceHeader)(unsafe.Pointer(&amp;bs)) // Assume the following KeepAlive line is disabled. // Now (a clever) garbage collector thinks bs can be // garbage collected now, for it will not used any more. // Although sliceHdr.Data stores the address of the // underlying elements memory segment of bs, as // sliceHdr.Data is not a pointer, the garbage collector // still think the underlying elements memory segment of // bs will be not used any more (for no alive pointers // reference it now). strHdr := (*reflect.StringHeader)(unsafe.Pointer(&amp;str)) strHdr.Data = sliceHdr.Data strHdr.Len = sliceHdr.Len // runtime.KeepAlive(&amp;bs) // this line is essential. // (a possible gc run may collected the underlying // elements memory segment of bs at this time) // Now, the underlying byte memory segment of str // is invalid, for it may be already collected. // Program may be ill behaved from now. return }
It gets tiresome to have the same discussion over and over and over again. Voting provides a way to signal disagreement, without being forced to invest unpaid labor.
Heh, I appreciate your PoW. In fact, I think I even share most of it as I also think solution often end up geing too fancy and high-level for too little benefit. Still, at my $dayjobs, I had issues with speedfreaky code for too often to trust it (unless, well, paid to support them). Anyway, a rare case where I'm pleased to agree to disagree ;-) 
I wished that blog post was longer 🤔
 We learned that the Go language provides packages for three symmetric encryption algorithms: base64, AES and DES. Still there.
[removed]
&gt;&gt; fastjson doesn't panic when parsing unexpected JSON ... For instance, when Int is called on the Value containing an array &gt; What do you call this apart from "unexpected JSON"???? Sorry, I meant *incorrect* JSON, not unexpected JSON. This means that `fastjson` shouldn't crash or misbehave when parsing arbitrary incorrect JSON from untrusted sources. &gt; There are the following approaches when the caller improperly uses the provided API (e.g. programming error): ... Go way. Panic on programming errors, return library errors. This usually minimizes the time required for fixing programming errors &gt; This is a fine definition, because when the programmer calls the API improperly it will always fail. Minimal testing will catch this. The API may fail either by returning an error on improper use or by panicking. The returned error is easier to ignore or improperly handle than the panic. &gt; In your case though some input works and some panics. This is not improperly using the API (a "programing" error). Agreed. Changed the API - now `Value.{Object,Array,StringBytes,Int,Float64,Bool}` return errors instead of panicking when the caller tries obtaining value with incorrect type. Thanks for the suggestion :)
Fixed this - now methods return errors.
No, there's no chicken-and-egg problem here. It's just step 2 or so, and we're still on step 1. 
&gt; IMO it's not really recommended to use it in this case, because slicing the input byte-slice/string for creating keys/values will may leave garbage in the memory, that is not necessarily required (JSON with many spaces/newlines) `fastjson.Parser` stores a copy of the input JSON string and then just references all the JSON items (as `string` / `[]byte`) from this copy . The copy remains valid until the next call to `Parser.Parse`. This ensures that `fastjson` doesn't hold references to the user-provided JSON string.
Substituted `&lt;watever&gt; sucks` with more polite explanations in the `README.md` :)
I was unaware of [Alibaba's project](https://github.com/alibaba/fastjson). I hope projects won't clash since Alibaba's `fastjson` is for Java and my `fastjson` is for Go.
&gt; at one point the author called base64 an encryption algorithm, which it is most definitely not The dictionary defined encryption as *"the process of converting information or data into a code, especially to prevent unauthorized access."* Can the output of base64 not be considered a code, which is defined as: *"a system of words, letters, figures, or other symbols substituted for other words, letters, etc., especially for the purposes of secrecy."*? base64 definitely does not provide prevention of unauthorized access or secrecy, but those are not strictly required by the definition.
Hooray!
Thanks Sam for taking the time to write this. The failure modes and the ideas presented in your post are interesting, but I fail to see what you suggest to move forward, in the context of the vgo versus dep drama ;\-\) Do you think we should carry on with vgo \(and improve it later if the failure modes you described are real problems in practive\)? Do you think we should just use/merge dep? Do you think we should wait for gps2 design to be complete and do nothing in the meantime? Most of us have interpreted your critics about vgo as a position "against" vgo. But maybe it's a misunderstanding. And it appears, according to your own analysis, that dep is not really a final solution either. So, what do we do now? 
It sounds like a really neat utility, but maybe make it open source?
I've heard that GitHub has entire teams and infrastructure set up to deal with Cocoapods. It really is asking a lot of one private company to support the entire canonical Dev flow for your language.... For free. A bit of a chicken and egg thing though, as they have enough Enterprise customers paying to support some of this crazy open source stuff.
By that logic zipping a file is a form of encryption. This came up in one of the various crypto laws that tried to go through US Congress a few years back that wanted to prevent data from going through that mutations that were so generically described...
It is possible to just get a random proxy for using it with your own http.client. I added the example to the readme:)
\&gt; Although we'd still [like to move away](https://blogs.msdn.microsoft.com/devops/2018/05/29/announcing-the-may-2018-git-security-vulnerability/) from version control as the default mechanism for obtaining open source code Whoa, didn't know that. Maybe I should read these blogs more often. Using source control as the default mechanism for obtaining open source code was actually one of the things that attracted me to Go, so I'm not sure how I feel about this. Has there been talk of what the next step might be, or is this just a vague goal right now?
 func f(left, right chan int) { left &lt;- 1 + &lt;-right // bafter 1st right read, locks until left read } https://github.com/kevchn/go-concurrency-patterns/blob/93ff18892f662c948ca62c7cf1a127ebc07aabed/2-3-daisy-chain.go#L15 Please don't.
Believe it or not, you can do this: for i := 0 i &lt; 10 i++ { fmt.Println(i) }
Buy The Go Programming Language. Work through it chapter by chapter, doing all the exercises. At the end you will know Go. The book is relatively easy if you can already program, there's not much in the way of new concepts or mind bending material. It's also short and interesting, as far as these kinds of texts go.
Hi all, this blog introduces the IPv6 Neighbor Discovery Protocol \(NDP\) and shows how you can make use of it from Go! I plan to use this as the basis for my GopherCon talk later in the year! I'm happy to answer any questions you all may have! Enjoy!
It is possible to just get a random proxy for using it with your own http.client. I added the example to the readme:)
Check this [https://research.swtch.com/vgo-module](one) out, it should explain most of it. 
[removed]
I'm still trying to understand it completely myself but it looks like an alternative to Node that defaults to Typescript. It looks like the v8 (javascript) parts can be sandboxed and can communitcate to the golang parts through protobuf so you can run privileged code. Anyway, it seems really neat. Ryan is truly a mad scientist. 
/u/Morgahl said it well, but to add a few more points: 1. Where did you get your definition of base64? I suspect wherever you got the definition is in the wrong, as the RFC for base64 doesn't mention the word "secrecy" once - &lt;https://tools.ietf.org/html/rfc4648#section-4&gt; - and base64 is never secret (literally anyone can Google "base64 decoder" and read the data in plaintext - that isn't what I'd call a secret). 2. Even if we assumed that base64 met some broad dictionary definition of encryption, this book has a much more narrow context. Base64 is mentioned as an encryption algorithm in the section on security in a book on web applications despite it not being appropriate at all for web application security. Even if it did meet that broad definition, I believe it is irresponsible to tell beginners to web dev that it is an encryption algorithm in that context. That said I still don't believe base64 meets any reasonable definition of what encryption is. 
&gt; That’s why with revive, we can make even more syntax-related arguments irrelevant by defining more opinionated rules and providing stricter presets. I'd love this. The more things I can enable as 100% rules on pre-commit and pre-merge requests the better, imo. I love linting, but if I can't automate the enforcement of it then it doesn't matter, imo.
[removed]
0.5.1 \- new API, better README [https://github.com/dc0d/dockage](https://github.com/dc0d/dockage)
You'll want to send a pull request like [this one](https://github.com/Microsoft/vscode-go/pull/1693/files) to the vs-code go plugin if you're serious about promoting this tool.
Ah, that is fantastic, thank you! So, I see that this way structs can "inherit" the properties of structs inside them and have the access to all the functions that are associated with them. I'm a fairly new programmer, so I am not really familiar how inheritances work in other languages. This seems pretty logical. And this makes sense in my code now too. I had person embedded in chemist So chemist was the higher level. And when I created a separate interface with a caller for chemist, it was available only to the top level struct, and not the bottom level, original "human" struct. Cool beans, man! Thank you!
[This](https://github.com/golang/go/issues/25632#issuecomment-393185775).
i prefer using net/http just to be as lightweight as possible 😊
&gt; For example, most people think that we format Go code with gofmt to make code look nicer or to end debates among team members about program layout. But the real reason for gofmt is that if an algorithm defines how Go source code is formatted, then programs, like goimports or gorename or go fix, can edit the source code more easily. This helps you maintain code over time. That smells a bit post-hoc to me. I'd bet the real reason was and is the former :p
Yeah.... Goimports and gorename should be operating at a level where the formatting isn't important (I.e. ast).... And I'm pretty sure those tools don't fall if you have poorly formatted code
What does "implemented without generics" even supposed to mean? What's "implemented *with* generics"? Is it the way C++ does things? The way Java does things? Both? If it's both, how is a hybrid of both approaches *not* "implementing with generics"?
Right, but the resulting code can be gofmt'd after tweaking the AST. So, I read that as it makes it easier not to parse it but to output it and have it remain consistent with the rest of the code around the edits.
Which is why I'm trying to convey here. Why use web framework to build a REST API server when you already have the net/http package.
I do, full time for over a year. It's woefully lacking in functionality, though I do have basic go functions like jump to def, error reporting, etc. Kakoune comes with some of this in the builtin [go-tools](https://github.com/mawww/kakoune/blob/master/rc/extra/go-tools.kak) package, which you have to enable iirc. With that said, I use my own implementation fwiw. I wanted more ability to interact with various Go tools (linters/etc), so I started a Go API to interact with Kakoune to write kakoune plugins in Go. With that, I added my own error reporter *(it's broke as hell atm lol)*, code jumper, etc. The API I wrote may be of interest, but I'd advise against using my kakoune plugins, as they're way not complete or functional.. I've not been arsed enough to fix and add more hah.
I don't know what to say, except that you'd lose that bet. 
If he didn't trust your blog post, why should he trust your reddit comment :)
Yeah I just use httprouter for mux n write everything else myself. I feel like if you're going down the rabbit hole of frameworks you're sort of ignoring the point of go and it's keep-everything-simple and small mentality? Maybe im wrong Regardless of that though doing everything yourself is so easy it doesn't make that much of a difference, you just reduce overheads
&gt; Of course, you can't go wrong complementing with gorilla/mux. [I disagree](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html)
Damn. I realise it's weird for someone to try and debate this from the outside, but I'm in a hole and so I'll keep on digging: https://talks.golang.org/2015/gofmt-en.slide#3
Some interesting stuff in that post, but by far the most interesting was the link to Titus Winter's talk.
I think that anyone who thinks that has never written a serious application in their life. There's no "just" about it.
But it's still making the returned value unsafe. Deleting one key from the returned object will leave a garbage in the memory (the deleted key and its value - if it's a string) - because you use slicing. There's a reason why the standard library copy each string and not use slicing for strings. Let me know if you get what I'm saying here, I don't mind to give more details about it.
They're not moving away from tight integration with source control. What they are moving away from is using the `git` and other VCS command-line tool directly as the primary way to obtain the source of your dependencies, wasting time cloning the entire history of dozens of repos when all you wanted to do is build a specific tagged version. It still works the same way from the surface, it just means that under the covers it might use a Go-aware proxy that can serve just the revision you need.
Yes, a shitton of work that is trivial. And when it's trivial, I doubt it's even written as a serious application. 
Care to explain more? Then by using only net/http, how would you implement a parameterized route? I'm interested on how you would come up with.
I have both Go and Elixir services running in production and love both languages. If you choose to learn either one (or both) of them you will not have wasted your time. Elixir+Phoenix is definitely faster to go from nothing to a working prototype, and there's a huge Phoenix community to turn to for best practices and "how do you guys handle XYZ." And as you've noticed, this includes books that offer clear suggestions you can run with. With Go, you will spend more time bike shedding design decisions, because you need to make so many more of them yourself. For each of the things joncalhoun mentions (cookies, XSRF, db connections) and many more, you need to decide if you're going to roll your own solution or go with one of the many libraries available (but none with overwhelming community support). Of course, once you've taken a couple laps around the track this drawback diminishes. I think Go's type system gives it the edge over Elixir for bigger projects and longer term maintenance. It's something you'll appreciate more and more the bigger a project gets. It also will generally have a smaller memory footprint in production. For me personally, I prefer Elixir when time to MVP is important, or if rendering HTML is a core part of the app, and Go for everything else.
Most of the time, frameworks hide in exchange of over-simplicity, elegance and magic. The net/http handler functions already expose the necessary http.Request and http.Response but frameworks like Echo hide it and instead, provide you a Context handler. These web frameworks don't give you immediately the opportunity how basic request-response architecture works and it becomes harder when a developers integrates more packages.
&gt; By that logic zipping a file is a form of encryption. Think so? I haven't looked at the specification in some time, but from what I recall there is no coding of values defined by the specification. And I am not sure why the spec would want you to, save encrypting for secrecy? &gt; Or even that act of storing a file to disk would meet that requirement. I suppose you could argue that substituting an electrical bit for a, say, magnetic bit is coding. If if the disk also stores the contents electrically, I'm not sure you have coded anything. This starts to be moving beyond the sprit of word though. &gt; This came up in one of the various crypto laws that tried to go through US Congress a few years back that wanted to prevent data from going through mutations that were so generically described... Dictionary definitions are not always equivalent to legal definitions. I think I was pretty clear that I was referring to the dictionary definition? I literally said so.
I read your post and I disagree on what you're trying to make. It adds more complexity to your code and many developers prefer a simple style that immediately reveals to them what services/controllers they're developing with in relation to a particular route. In other words, they want to see "foo/bar" immediately to their eyes. If I change the structure of my paths, then I have to change your Mux logic. If I'm in a team of developers, then someone should be assigned to maintain how the routes structured and how they worked. You should definitely add a way to comment your posts on your blog.
&gt; Where did you get your definition of base64? Does base64 need to be defined? Everyone knows what base64 is. &gt; RFC for base64 doesn't mention the word "secrecy" once Nor would I expect it to. Why would it? It is not a secrecy algorithm. Again, the dictionary defines encryption as: "the process of converting information or data into a code". The Go standard library even includes base64 within the [encoding package](https://golang.org/pkg/encoding/base64/) and provides the function `Encode` to produce the base64 output on recognition of this being what you are doing. 
No, honestly I have no clue what you're even saying, you seem to be using "trivial" in a way that English speakers do not, and I don't have any interest in even trying to follow if the only purpose is going to be to insult me.
Oh, are you talking REST API or Web application? With full Web application, even 2-3 pages, you'd have to support OPTIONS verb, proper caching headers, compression, and a few more nitty-gritty details. A nice micro-framework does it for you or helps you to be a good netizen.
I fail to see my replies here are an insult to you. Clearly, you don't have a clue.
I mean you are not really wrong either. I'm just making the point that the generically described action of converting data to a different format and back does indeed cover encryption, but it covers so many other domains that you can't really use it as a realistic definition for encryption. Thus base64 is not sufficiently defined as an encryption format under those rules.
&gt; I read your post and I disagree on what you're trying to make. That's fine :) &gt; You should definitely add a way to comment your posts on your blog. Unfortunately, I can't really justify the toil that moderating that would require, so I intentionally left it out. You can find some of the discussion of this particular post (including my opinions/retorts on the point you are bringing up) [in this reddit thread](https://www.reddit.com/r/golang/comments/6i22tm/how_not_to_use_an_httprouter_in_go/).
It's nice to have a framework that does all the work with you whether it's lightweight or with batteries included, but over time when a web application scales, you want to have a full control of which compression library or other nitty-gritty details that works some particular use cases to the web application. Of course, someone can fork and inspect the source code of the web framework but it definitely beats the whole purpose of having a web framework. I might be wrong here but in Go, it's far more common to integrate libraries than frameworks.
&gt; we won't be changing our versioning scheme just because a single language we support has a unique idea about versioning. Can you elaborate on what about the presented ideas about versioning is unique? It would seem to me, that it's a very straight forward application of semantic versioning, which seems to be pretty mainstream (for better or worse).
&gt; this is Russ' "ratchet," which he sees as good, and i see as resulting in unnecessary conflict, both human and machine, and a perverse arrangement of responsibilities onto the wrong parties. I think a key observation is, that neither is particularly well supported by observational evidence. Personally, I've been on the receiving end of the negative externalities in dep's approach¹ and this biases me towards optimism for vgo's approach. I'm also part of an ecosystem that works essentially like this² and which I perceive as fundamentally less toxic and overall healthier than the current open source ecosystem. You try to argue for your predictions with game theory. But in my opinion, game theory is incredibly hard to apply to practical situations and when you try, fails more often than not. Even more so, if you do not actually model payoffs (which, TBH, seems intractable for an open source ecosystem). If you remove that, however, you basically come down to what /u/nicpottier argues [here](https://www.reddit.com/r/golang/comments/8m2zro/vgo_analysis_failure_modes/dzktp33/). So, I guess my personal conclusion of this post is that 1. At least in a couple of places you appear to me to make uncharitable assumptions about how vgo's technical design could or couldn't change in the future. 2. But some of your arguments are really good, from a technical standpoint (at least the section about losing information seems hard to refute). They definitely deserve consideration, made me think and will continue to do so. 3. But in the end, everything (on both sides) still seems to hinge on vague predictions about how the community will handle certain situations. And not only is it very hard to actually argue about that - I'd even go so far as to say such differences in opinions are fundamentally unresolveable. It is that last part, which really excites me for vgo, FWIW. My predictions (based on my anecdotal experiences) to how this will play out and what the actual effect on toil will be seem to vastly differ from yours - and they are, what underlie my resistance to vendoring, to dep and also, initially, to vgo :) --- [1] Trying to package ruby software for debian. Which implies using recent-ish versions of the transitive closure of dependencies. Which implies resolving all the API changes and incompatibilities that have accrued since some library author vendored some of their dependencies several years ago. [2] I always compare working at Google to working in a hermetic open source ecosystem. Most of the processes and incentives work exactly the same. You can see other people's code, you can file bugs against them and you can send "pull requests". You have no leverage over other people and other teams' priorities and if a team refuses to fix a bug or breaks you, you have exactly the options you line out in your post. While there is a theoretical tool of escalating differences of opinion up the hierarchy, it is (in my experience) rarely used and even more rarely passes beyond the managers of the affected teams. The main differences, from my experience, are a) a universally enforced code of conduct and b) a generally shared understanding that everyone should be cooperative and work together to make the whole ecosystem work well. I really wish that we can get both of these into the Go community and hope vgo can help with the latter.
As I understand from source code, [gjson](https://github.com/tidwall/gjson) returns strings pointing to the input string. So, multi-megabyte input JSON string remains in memory until reference to a short string extracted from this JSON exist. `fastjson` copies the input JSON string to internal byte slice and then return references to it via `*StringBytes` methods. Documentation for these methods warn the user that he cannot hold the returned byte slices after the next call to `Parser.Parse` The `Parser` re-uses the internal byte slice on each `Parse` call (i.e. new input JSON string is written over the previous JSON), so all the previous values become garbage. This means the user had to copy the returned byte slice (or just wrap it into a `string(byteSlice)`, which makes the copy under the hoods) if it should survive the next `Parse` call. This way the user obtains small independent copies of byte slices returned from `fastjson`.
It's secure in the sense that JavaScript code can only do unsecured operations by asking Go runtime to do them and you can configure Go runtime to allow/deny those operations. So it implements the same sandboxing idea as seccomp but differently. seccomp is a tool to tell kernel what to allow/deny to sandbox any native app. deno allows you to tell Go runtime what to allow/deny to sandbox deno app. 
&gt; Also, "not so bad" - why are we satisficing? Why accept sub optimal designs when we don't need to? This seems misleading, unless you suggest that dep (with either gps or gps2) is optimal. And even then, that seems to only get us to bicker about what the right optimality criteria are. Which IMO is exactly one of the main points of contention here - that we are having different priorities what to optimize.
There is a fine line between library and framework. Some call Gorilla Toolkit a set of libraries. It could be called a framework too. It's especially difficult to tell with router libraries where you plug your handlers into the framework. The discussion started with `net/http` or framework, i.e. no 3rd party or with 3rd party. 
Your proposal sounds interesting but I can't quite follow it. How would you, for example, implement a custom type `Map[k,v]` in your proposal? (The built-in implementation is pretty nasty, as it's actually doing pointer math...) (Regarding speed: while Go is certainly slower than C++ and Rust (which are themselves much slower than custom-asm, in many cases; e.g., no one is implementing things like x264 in a high-level language), it's a lot closer to those languages than something like Python!)
Interesting. Is there a big market for adding dimensions to filename from a command line utility?
[removed]
[removed]
Agree. I'm definitely on /u/frou's side here.
That looks like what I've been looking for, but it's pretty expensive!
I find that is very often the case when they explain anything in the language. I like golang but , gosh, the team can be hard to take. They always come up with something to say , not even true like in this case, just to make them look so much smarter than everybody else.
It should be a win-win. Less traffic and presumably less load on their servers, faster speed for go users.
I'd say, golangci-lint can use revive internally. golangci-lint can battle with gometalinter and others.
Yeah I got a few links on interfaces here. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk But to be honest, I wouldn't over use them cause they really are specialized glue for a "reusable" package. It's not really meant to just carry over methods. I'm kinda trying to write an article on types....ish but it's really dry cause I didn't add context but the point was an appreciation of the design of the types not so much high level stuff. But it helps you understand packages instead of just using them. https://medium.com/@d35da8f0b148/2ba61290a5cf?sk= And https://medium.com/@d35da8f0b148/30fa200bef8f?sk= And thank you for the gold!!!!
[removed]
agree on the import path design in Go is better than Java.
What's the performance compare to other methods such as pass the interface? I mean: type thermometer interface { outsideTempF() (float64, error) } type car struct { outsideTempF thermometer } c := cat{} c.outsideTempF.outsideTempF()
The blog posts I've seen cover it in fairly more detail than you're describing, though I'm not sure I'd call them documentation: * [Profiling Go Programs](https://blog.golang.org/profiling-go-programs) from the Go Blog * [Profiling Go programs with pprof](https://jvns.ca/blog/2017/09/24/profiling-go-with-pprof/) from Julia Evans * [Profiling Go](https://www.integralist.co.uk/posts/profiling-go/) by Mark McDonnell (also includes expvar/memstats documentation, though actual [source documentation](https://golang.org/pkg/runtime/#MemStats) for memstats is excellent and there are [more goodies](https://golang.org/src/runtime/mstats.go) in mstats.go) * [Profiling and Optimizing Go Web Applications](https://artem.krylysov.com/blog/2017/03/13/profiling-and-optimizing-go-web-applications/) by Artem Krylysov Between these a lot of details and use cases are covered. Do you have specific questions not covered by these?
Perhaps you need to pick a protocol for your server and client to communicate with first. I’m not entirely sure what your building but it sounds like arbitrary command execution which I would certainly advise against. If that is really what you need I would use something like salt instead of rolling your own. Otherwise define all the commands a client should do, pick a protocol like grpc for the client and server to communicate with. You could use the streaming API to stream commands back and forth, where command could be as simple as a struct with a string of Args and a specific command type. At least this way the command names are no longer arbitrary. Once you have a protocol- whatever it may be, picking the transport is easy.
http://goog-perftools.sourceforge.net/doc/heap_profiler.html Here is docs for C++ pprof, but I believe columns and flags are the same.
There are various profilers and they work via different mechanisms. There is also the tracing framework, which imparts a heavier runtime hit, produces vastly more output, has much more to it and is similarly fairly undocumented. The most commonly used profiles are the CPU and Heap profile, though. I've generally obtained these by using `net/http/pprof`, because I work on mainly daemon processes rather than scripts or batch processes. The CPU profile works by taking a snapshot of the running goroutine stacks periodically and then using that to estimate how much time has been spent in each function. Since stacks have a hierarchy to them (the first function calls the next, calls the next, and so on) you can use this to estimate not only how much time was spent in a particular function (how many times was it at the end of the stack) as well as down what paths it had been called. The first measure is the time spent in a function that is executing, but often you want to now how much cumulative time was spent in particular functions that call many other functions, which is where the cumulative time comes in. The heap profiler is different, and there are a few different modes as well. While the CPU profile samples over a period of time (30s by default), the heap profiler can tell you about various memory allocation statistics. Typically, you want to either know "what allocated the memory currently on the heap?", which is the default when using http/pprof, or "where has memory been allocated thusfar in the lifetime of this process?", which can help you identify places where many allocations are made even if they do not live for a long time. The fancy output organizes this information into a hierarchical graph so you can more visually and easily figure out where the expensive paths in your program are. For instance, if you have a function that is being called from multiple places, and you are spending a lot of time in there, you can often see fairly easily on the visual output which callsite is contributing the most to that time spent. The same is true for memory allocations. pprof has a lot of other nice things, like being able to show to-the-line where time is being spent (or mem is being allocated) with `list` and even show to-the-asm-instruction where time is being sent with `disasm`. If you have something you want to profile, I suggest you poke around a bit with the online `pprof` tool and then produce graph output with `pdf &gt; out.pdf` to see its output on code you are familiar with. This is all covered fairly comprehensively by the official Go blog post: &gt; When CPU profiling is enabled, the Go program stops about 100 times per second and records a sample consisting of the program counters on the currently executing goroutine's stack. [..] In the `go tool pprof` output, there is a row for each function that appeared in a sample. The first two columns show the number of samples in which the function was running (as opposed to waiting for a called function to return), as a raw count and as a percentage of total samples. [..] The top10 output is sorted by this sample count. The third column shows the running total during the listing [..]. The fourth and fifth columns show the number of samples in which the function appeared (either running or waiting for a called function to return). The main.FindLoops function was running in 10.6% of the samples, but it was on the call stack (it or functions it called were running) in 84.1% of the samples. &gt; To sort by the fourth and fifth columns, use the -cum (for cumulative) flag: Given this, you should be more than vaguely aware that `-cum` stands for cumulative. I suggest reading the official Go blog and the package documentation carefully, sometimes multiple times if you're feeling like you are missing something. It has a purposefully terse and information dense style; when learning I often feel lost for ages until I finally figured something out at great effort, only to find that the documentation already covered my issue adequately but I kept on skimming over a word or sentence that contained the vital insight I was seeking.
I'm not so sure about a nomenclature. This just looks like a normal \(callable\) dependency to me. Using functions instead of an interface/concrete type. I've used this pattern at many places before, and I've burned my hands with it a few times. In particular, when introducing composition to the mix, things start to get out of control. for instance: \`\`\` type Resolver func\(int\) io.Writer type BigComponent struct { resolver Resolver } // client code bc := BigComponent{ resolver: func\(int i\) { // code } } \`\`\` now lets say I want to create a create another component that creates BigComponent \(via a Factory\) and I want to be able to parameterise the dependency of the BigComponent, in this case, I need to introduce another level of abstraction over the resolver \(let's call it ResolverFactory\) that is a function that returns a function. \`\`\` type ResolverFactory func\(...interface{}\) func\(int i\) io.Writer \`\`\` \^ now this could be implemented using closures \`\`\` func customResolverFactory\(...interface{}\) Resolver { return func\(int i\) io.Writer { // code } } \`\`\` but this gets out of hand really fast. I have some code in production with 4 levels of closure because of using this pattern. When I refactored it to use sane old interfaces it became much more managable.
Rob Pike did it so I had to too :\) Definitely a heinous piece of code right there though.
I think there are two viewpoints of software. The first would see software construction (aka programming) as searching in a solution space for the best fit. Given a well-defined or thorough-explored problem, we will find out the best abstraction perfectly manifesting the architectures/algorithms. The hypothesis of the view is that we can have a concrete, definite target to reach. Consequently, the processes and techniques of making software should be measured for *the* final outcome — how it is distinct from the perfect form in the Platonic world. The vagueness or fluctuation of the target is due to the immature understanding or failures in the process. On the other hand, software can be seen as something living, fluid 
Actually it's not clear what exactly you need. Raw TTY passthrough? Internal ssh rerver? Without an understanding of the final goal, it is difficult to find a suitable solution.
It shouldn't, though. The solution is that what you are doing is either a) a fork in the gh-sense, the same project, just created to experiment or create a PR. In that case, add your fork as a new remote to the repo and don't touch the import paths. Or b) a fork in the open source software sense, a new project, with changes, meant for actual usage and long-term maintained. In that case, changing the import paths is the correct thing to do.
Go ( ¨̮ )
google caddy, beego, gorilla, web templates with golang, tls-tris. Then tell me again there is a lack of web dev for golang. 
base64 is an encoding mechanism. The astaxie book if it really states it as an encryption algorithm, that is incorrect. The rest of the content of that book is pretty damn good as a summary of web development with go. I would recommend it as the second book to read after reading a go programming book.
Hello Fellow Gophers! I finally resorted to using a Map \(map\[int\]struct{}\) to de\-dupe and used [https://github.com/shawnsmithdev/zermelo](https://github.com/shawnsmithdev/zermelo) to sort it. Benchmarks \-\&gt; [https://github.com/karthikraobr/go\-sorting\-bench](https://github.com/karthikraobr/go-sorting-bench)
Also, here's where I said the same thing immediately after the open source release ([on Nov 11 2009](https://groups.google.com/d/msg/golang-nuts/HC2sDhrZW5Y/7iuKxdbLExkJ)): &gt; But all of this misses what I think is the most exciting thing &gt; about gofmt: the fact that we have a tool that can pick up every &gt; source file in the Go tree, parse it into an internal representation, &gt; and then put the exact same bytes back down. (A large part &gt; of this is due to the amount of work that went into gofmt, and &gt; the rest is because we have agreed to standardize on gofmt's &gt; style.) Once you have such a tool, it becomes very easy to &gt; insert mechanical processing in the middle, between parsing &gt; and printing. So we have all the hard parts of a program &gt; manipulation tool just sitting waiting to be used. I've started &gt; writing similar tools for C before and never quite got the output &gt; to match the input exactly. Agreeing to accept "gofmt style" &gt; is the piece that makes it doable in a finite amount of code. 
you have to open the search up for remote, or move to a technology hub. Meetups are a great place too. I personally work remote. While I can't speak for those two places in canada, I do know searching for work in a non\-tech hub is h\-o\-r\-r\-i\-b\-l\-e . Your best solution , if you want to stay in the area, is to bid on contracts from local businesses. 
Well, I dunno how you'd be able to follow a sketch of a sketch and get down to that level... but the general idea is that the pointer math is already abstracted by type. Basically, more of the runtime grows the ability to do things like "Have a slice of things that according to Type.\_\_magic\_method\_Size() are 64 bytes wide", rather than "Have a slice of struct{ A int; B int }" the way it does now. The downside is potentially more indirection at runtime in the naive implementation; the question is how much we could recover on optimization passes.
It's pretty rare to find a job in vancouver/ontario area that are hiring for Go, and if they are, the pay is pretty abysmal compared to the states. If you want to stay in Canada, it's best to find a job that's looking for remote or semi\-remote \(where you fly in to the office every few months for a few weeks\).
The section on "Dynamic Analysis" has some good content: [https://github.com/campoy/go\-tooling\-workshop](https://github.com/campoy/go-tooling-workshop)
I don't know about other regions, but there are a bunch of companies in Toronto that are using Go--more and more every day. I'd start with looking at local meetups: E.g. https://www.meetup.com/go-toronto/events/past See who hosts them, who presents, who attends, and follow up with those employers. Just searching `golang toronto jobs` reveals lots of jobs listings from all kinds of random companies, including banks. Another vertical is cryptocurrency-related companies. Go is fairly popular in the space, and Toronto is a bit of a hub for this, lots of R&amp;D around Ethereum going on. If you're into it and have some relevant experience, there's no shortage for work. Overall: Don't be too broad in your search. Focus on specific regions that are popular with tech companies (e.g. Toronto, Waterloo, Vancouver). Check meetups, check specific verticals, etc.
Yeah I can see this being useful for options but I'd prolly tie it to structs. Only because when people want to read it and reuse a part of it. I suppose in some form you can tie it to a type instead. I just get cautious with nested functions and property functions cause they are hard to read and can go deep. I think though for an API to allow parts to be used and not used, it is a good idea.
Depreciated, very likely. I read deprecated, though, and that throw me off.
Thanks! It works now. One suggestion—you might want to exclude the vendor directory by default (although `golint` doesn't; I wonder why?).
someone just posted a mcafee job in waterloo on the wrong go mailing list: https://careers.mcafee.com/job/waterloo/sr-software-development-engineer-cloud/731/7932960
See also: https://golang.org/doc/diagnostics.html
The most likely problem is that you're trying to use the shell without a Pty. This gets you tantalizingly close to working, but then you hack on it and hack on it and never quite seem to get to fully functional. You will need to open a PTY on the remote side, which can be done with [github.com/kr/pty](https://github.com/kr/pty), and you'll need to multiplex a stream with something like github.com/hashicorp/yamux , because you'll need a stream for the PTY itself, and you'll need a control stream where you can pass along things like SIGWINCH to work properly. You also need to pass along at least the TERM environment variable to the remote shell. If done correctly, you get a full SSH-like remote shell that can support vi/emacs/less, etc., not just command-response command line programs. As you might expect from this description, I have this working in Go. I'm willing to open source it if there is interest, but it will take me a bit to extract it out of my source code.
Well, i hope that following the example below you will understand my task better. Imagine, you have a device, for instance, Raspberry. It's being used as STB, with a lot of multimedia stuff installed, and is connected to the TV. For some reasons you can't use SSH to get access to it, but you need to edit channels lists, perform updates, managing config and doing other stuff you would normally do over SSH. As the result you have to create an app (client/server) which does all the SSH stuff, but without SSH itself. 
Thanks, that sounds like a good plan for me.
Thank you for pointing me out "stream multiplexing", a lot of really useful stuff came up!
THANK YOU, yes, that's exactly what happened :S
Thank you for such a detailed explanation, seems that it's exactly what i was looking for!
What about remote jobs? GitLab is hiring go developers around the globe, and Canada is not an issue. 
As others have mentioned, it's either remote work or finding someone to refer you.
What are the advantages to using this package over [https://github.com/google/go\-cmp](https://github.com/google/go-cmp)?
Hey Matt! Thanks for the blog posts and libraries, I've learned a ton from them. I have a question but not about this post. I'm following a few Go and /x/ issues related to raw ethernet socket support. I know you have your raw package, but do you know if there has been any movement on a cross\-platform option? 
And what is the error? syscall.Mount function returns error. Are you trying as root user, can you mount share from command line?
I know in Montreal I've seen a couple of Go job advertisement from MindGeek
Just nothing. It doesn't error but blocks the CLI window and not responds to signals. I found the solution. Just changed "nfs" with "nfs4" and it worked.
Zenreach in Kitchener is a golang shop
Ah, not the North East of the US then... ;)
True. I also see the same behavior. 
I think noone can give you THE solution to your question. For me, building a Vue site making api calls to your go server and host your site on your go server (static file server), seems just right and should be more than powerful
Be aware of the NFSv4 overheads. Since it is a stateful protocol, it can have performance overheads for meta data intensive operations. I would try with 'nfs3' or set NFS mount options "version=3” to get NFSv3
Sigh. Stuff like this is exactly why I have such a frenemy relationship with Go (that is, with Go as it is and with Go as it is advertised). What I mean is, the blog reads like the typical Go PR which I dislike so much: Exaggerate disadvantages of other languages, stay silent about the ones of Go, and season with a bit of handwaving. Notice how the blog carefully wheighs tradeoffs of C++ and Java hashmaps, but then the same thing is not done about Go's hashmap? Also, why is C++'s template code "bloat" criticized so much? Did the author measure that C++'s hashmap's increase binary size in an even remotely impactful way? And anyway, since when does Go care about binary size? I don't think it does, what with all that static linkage, which increases binary size much more than a few map instantiations :D If I were to criticize C++'s map types, I'd say they are harder to use and also unsafe (because of iterator invalidation). Since the blogpost author conveniently forgot to apply the same tradeoff balancing to Go's hashmap, let me try to fill it in: Advantages: - Straightforward and versatile usage (AFAIK it works with all types) - Relatively low overhead (doesn't require boxing like in Java) Disadvantages: - No custom hashing alg for the hashmap - No custom hashing strategy for key types (as far as I know, feel free to correct me if this is wrong) - The implementation is very specialized, relies on thigh dependency between the language, the compiler, and the runtime 
Thank you. Taking it into account.
At AgileBits (1Password) we have a fairly large go team. I'd suggest reaching out to see if you might be a fit. I'm not sure if we're hiring anything specific at the moment but it never hurts to [send your information](https://support.1password.com/contact/) in and take a chance. We do both Toronto (where our office is) and remote. Our 1Password.com server is written in go, and we're sponsoring the upcoming GopherCon, so we'll be there as well if anyone is interested in talking with us directly there. Kyle AgileBits
Do you have SELinux running? `strace` is your friend for this as it allows you to monitor running syscalls.
I'm part of the KW Go Meetup - there are a few companies that use Go here: * Zenreach * Dejero * Index Exchange * Keyfree Also look for remote opportunities, like others have pointed out. https://www.meetup.com/Golang-KW/events/past/
Hey, Gobot is good project of especially for IoT devices and machine learning.
I'd personally go with the approach you've outlined. Use front-end tech like React, with server-side rendering, making calls to your Go-based HTTP web service(s). You could use something like PHP for it, but I'd personally prefer to use a more modern stack that provides a richer front-end experience. Of course, if you're planning on making a stupidly simple site then you won't need it however.
PalmLand() sweet!
You can look at https://github.com/golang/go/wiki/GoUsers for companies in Canada that are using Go, although it's not broken down by province. As has already been suggested, you can also try remote for a company either in Canada, the US, or elsewhere. Finally, check various city channels on the Gophers Slack.
&gt; I added my edit long before you replied, so I'm not sure what the point of this comment was unless you missed the edit? The purpose of the edit was unclear. If you realized that you misinterpreted my comment, why not delete it? The comment serves no purpose if it has no relevance. That you decided it was worth keeping gave me the impression it was worth replying to. &gt; I'm also not sure what your overall argument is. I don't know that I have an argument. Do I need an argument? I'm not in a high school debate competition. Just spending some free time on an entertainment website engaging in friendly chatter. &gt; It sounds like you are arguing that based on some very loose generic definition of the term encryption that base64 is an encryption algorithm Which it is, based on the definition the dictionary provides. &gt; and in that context encryption has a more strict definition And in the context of the original link it is clearly a typo. Everyone knows it is a typo. It is hilarious that we're spending so much time talking about a simple typo.
Everytime I hear Gobot, I think of these from childhood: https://en.wikipedia.org/wiki/Gobots
For now, I'm inclined to agree that your instinct to look outside of Go to do front end development is the most straightforward path. Here are the options as I see them. Simple sites ---- If the dynamic functionality you need can mostly be done on the back-end (aka server-side), then https://golang.org/pkg/html/template/ is all you need. You can have a few lines of vanilla javascript here in your template for minimal front end execution without requiring a whole framework. Complex sites --- When you will need a lot of front-end (aka client-side) execution, using Vue/React/Angular/etc. for the front-end and relegating Go to the back-end is the most common approach. This approach is a great solution for polyglots who favor the "choose the right tool for the job" approach. Just like how, IMO, Go is a much more natural fit for a backend than javascript/node, the javascript community has done way more experimenting in the MVC space, and as a result, their solutions are much richer than what Go currently offers. That said, there are advantages to having your front end and back end in the same language. Isomorphic patterns, less cognitive context switching, and faster training all make a single language solution compelling. To that end, Go does have a few projects that can be used to write client-side code, namely [joy](https://github.com/matthewmueller/joy) and [gopherjs](https://github.com/gopherjs/gopherjs)/[vecty](https://github.com/gopherjs/vecty). Gopherjs has been around longer, and joy doesn't have a companion framework like vecty, at least [not yet](https://github.com/matthewmueller/joy/issues/80), so if you want a Go web MVC framework today, vecty looks like the best (only) option. Maturity aside, the bigger difference between the two projects are their goals. GopherJS was created with the goal to run arbitrary Go code in the browser. While the quality of the generated javascript is important, it isn't as important to the gopherjs project as supporting the full Go language. Joy was created as an alternative to typescript. The quality of the generated javascript is more important than supporting the full Go language. Go features that are not supported by the joy transpiler will result in a compile error. More info in the [joy FAQ](https://mat.tm/joy/#faq-gopherjs) and [this github issue](https://github.com/matthewmueller/joy/issues/56). Lastly, as much as I love Go, I'd argue that javascript currently has a better story on the server-side (node) than Go has on the client-side. If you need to start a single-language, full stack project today, javascript will serve you better than Go will. Hopefully, that will change once [WASM support](https://github.com/golang/go/issues/18892) lands in the Go compiler and WASM evolves to [support DOM and other Web APIs](https://github.com/WebAssembly/design/issues/1079). Until those two things happen, Javascript is a necessary evil of client-side development. Your only choice is whether you want to write it yourself or let a tool generate it for you.
GitLab pays absolute shit tho... they use a standard system based on your location, you can go look up your location before even applying. When I was changing jobs recently, for my location and experience it gave me a number 50k below my current salary at at the time, not even close to the number I was looking for in the new job. There must be some incredible intangible benefits to that job...
What is that? &gt; Golang framework for robotics, drones, and the Internet of Things (IoT)
That’s awesome! I love 1Password and use it at least 5 times a day. It’s great to know some of my favorite software uses Go. 
Thanks.
At Chefhero we are using Go for our backend and we are hiring!
Fuck Medium.
People regularly post Go jobs in these two Slack workspaces [1][2]. [1] https://yvrdev.herokuapp.com [2] https://vantech.herokuapp.com
Make sure your project is in GOPATH, as described here, https://golang.org/doc/code.html#Workspaces, that the IDE GOPATH setting is pointing to the same GOPATH (via Settings | Go | GOPATH), and that should be it. If this doesn't work, opent an issue on our tracker, https://youtrack.jetbrains.com/issues/Go, and provide the IDE logs via Help | Compress Logs and Show in... and attach the zip file created. Thank you.
[removed]
The project itself is nothing too big, but nothing too simple either just enough complexity to really learn and achieve what I'm trying to do, displaying a lot of data from the db, accepting queries, updating data that sort of stuff, so I think it's enough with templating package 
Can I use gobot to receive a video stream from my raspberry pi camera module?
I've had my eye on Gobot for a while, and I've been really impressed with what I've seen too. Admittedly without having dived in yet, the overall design looks very good - especially the smoothness of targeting different platforms via their adapter layer. I've been looking to scratch a personal itch, and for a project I'm going to be running a slimline Linux distro with a deamon (probs via systemd) that does some network communication *and* device interaction over GPIO. Gobot seems absolutely ideal. I didn't realise there was a Firmata Adapter for Arduino and ESP8266 though, that's a pleasant surprise. 
Hey, thanks a lot for the detailed information about the choices for this project, I think I'm mostly interested in using templating with HTML/basic css or using a js framework, even though I don't have any experience with one, but how do you know when what you are building is complex enough to the point that a framework like Vue is actually helpful? When does using html/css is just not enough?
So I'm currently writing a progressive web app using Vue for my front-end and firebase for my back-end. I'd argue that if you think you *might* want a framework eventually, it's safer to just start with one now. Vue and (p)react are both simple enough to not be massive overkill for small sites, and then you wont have to rewrite the whole thing if/when it gets complex enough to need a framework. I wouldn't use a framework if I had a go service and I just wanted to expose a simple admin webpage. Something to view the service's health and maybe change the log level. Same with a blog site or something else with a lot of purely static content. Almost anything you'd call a "web app" I'd reach for a framework. Finally, if you want something with most of the benefits of a framework without a big fat js layer between you and the native web platform, I'd check out polymer and [their new starter kit](https://github.com/Polymer/pwa-starter-kit). It's still early days, but polymer3 + lit-html feels much saner and more go-like than the direction the rest of the web community is going.
So many typos, misspellings, and run on sentences. Did the author even review this once?
I think mine is the closest to that at the moment. It should work on anything except Windows and Solaris. PRs certainly welcome to close those gaps.
Many people are moving away from rendering html from the backed “web server.” It’s a dying pattern. People are embracing SPAs now and hosting on CloudFront or something similar. So due to that, we have to look at the world through a different lens. That is to say from a web API perspective. Nothing too new here either of course, but it’s really so straight forward that you’ll probably find little “magic” or resources about it. It’s just repetitive after a while. What more can be said? There are many http request routing packages for Go. Echo router is one of my favorite. After you write up an API using that (which is pretty quick and easy to do). What else is left? JavaScript. React? Vue? So we’ve now left the realm of Go. If you’re really looking to stand up an API in lightning speed that can handle http request routing, scheduled events, Oauth, etc. ...and you’re interested in “Serverless” - give Aegis framework a look. https://github.com/tmaiaroto/aegis It’s certainly a resource for “web applications in Go,” but it’s a bit different than your normal Echo or Gin or Gorilla. Just throwing out other ideas. There’s a wealth of packages for API development. At least I think so.
Golang shines in server-side applications where low latency and scalability are critical. There is limited support for the use cases you mentioned (client-side code) but that is changing as the language continues to grow in popularity.
I thought this was a bot to tell Reddit that go 1.11 was released. Lol
Thanks a lot for the recommendations, will check out polymer!
Do you think the language could eventually get as much support as python?
Definitely. Python still has its sweet spots, but I’m invested enough in go hat I’m rewriting all my big python stuff in it. Tons of imported libraries, virtualenvs, etc.. replaced by a single, tight speedy binary? Yes please!
[removed]
To be clear, Python is not widely used in mobile dev or game dev. 
&gt; Tons of imported libraries, virtualenvs, etc.. replaced by a single, tight speedy binary? I just spent about an hour trying to install the Elastic Beanstalk CLI on my Ubuntu laptop. . . only to finally resort to Python 2.7 (I prefer Python 3.x). I love Python but Go's "one binary to rule them all" approach is a breath of fresh air. Ruby, node.js, PHP, Java. . . those languages all have the same problem. Although with Java, you can build a "fat jar" which is similar to having one Go binary (you still need a JVM too though). 
Why keep fighting with goland? There are plenty of other editors out there with great support which don't break.
the good news for gamedev: * there are good bindings for important libraries like SDL2 and opengl * the GC is low latency * AOT compile binaries the bad news: * overhead for calling into C, which is necessary for things like opengl, vulkan etc, is higher than other languages like C# and Java I did a video series a while back teaching programming and gamedev with golang, it was fun! https://gameswithgo.org/ 
Because if it breaks in our editor at least we'll do everything we can to offer a solution to fix the problem. And because if it breaks in out editor, it will break in those alternatives as well.
Calgary: Hahahahahahahaha hahahahahahaha. Ha. :(
Thanks for the post. I created an NDP proxy awhile back as a learning exercise [0] I used libpcap as AFAIK it's not possible to read neighbor solicitations where the destination solicited-node multicast address does not belong to the local host. [1] [0] https://github.com/porjo/endyp [1] https://stackoverflow.com/q/39425574/202311
Use strace to compare your syscall with mount command's syscalls.
Sorry i ment relative to the gopath. Let say i made a starter. I placed it in $GOPATH/src/github.com/xxx/yyyy Now when I want to import packages i use that path above. Lets say somebody wants to use my starter. But they put it under $GOPATH/src/github.com/aaa/bbb. Now all their imports will be broken and will have to manually edit them.
any feedback aynone ? For a next project I will have to dive inside Echo, I have never learned from an e-book don't know how effective is it
Depends which operation is causing the blocking. If it's `stat`, then there's perhaps not much you can do. If it's actual reads/writes, you can [set a deadline on *os.File](https://golang.org/pkg/os/#File.SetDeadline).
The logic is a bit different. As [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) provides you functions acting outside unit testing \(like [EqDeeply](https://godoc.org/github.com/maxatome/go-testdeep#EqDeeply) and [EqDeeplyError](https://godoc.org/github.com/maxatome/go-testdeep#EqDeeplyError)\), its main purpose is to be used during unit testing, with the help of [testing](https://godoc.org/github.com/maxatome/go-testdeep) standard package. It handles fail reports as [testify](https://github.com/stretchr/testify) does for example. [go\-cmp](https://godoc.org/github.com/google/go-cmp/cmp) handles the Equal method \(if it exists\) to compare specific value types. To achieve the same goal with [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) you can provide a [Code](https://godoc.org/github.com/maxatome/go-testdeep#Code) TestDeep operator instance. [go\-cmp](https://godoc.org/github.com/google/go-cmp/cmp) rely on paths to declare specific comparison rules, while [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) uses [TestDeep operators](https://godoc.org/github.com/maxatome/go-testdeep#TestDeep) almost in place in the expected data structure. [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) TestDeep [operators](https://godoc.org/github.com/maxatome/go-testdeep#TestDeep) offer the maximal flexibility during a comparison without typing any specific go code \(except for [Code](https://godoc.org/github.com/maxatome/go-testdeep#Code), of course, that can be used as a last resort when the other TestDeep operators cannot fulfill your needs.\) Note that I am the author of [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) and I am not an expert of [go\-cmp](https://godoc.org/github.com/google/go-cmp/cmp).
https://github.com/golang/go/issues/22114
The logic is a bit different. As [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) provides you functions acting outside unit testing \(like [EqDeeply](https://godoc.org/github.com/maxatome/go-testdeep#EqDeeply) and [EqDeeplyError](https://godoc.org/github.com/maxatome/go-testdeep#EqDeeplyError)\), its main purpose is to be used during unit testing, with the help of [testing](https://godoc.org/github.com/maxatome/go-testdeep) standard package. It handles fail reports as [testify](https://github.com/stretchr/testify) does for example. [go\-cmp](https://godoc.org/github.com/google/go-cmp/cmp) handles the Equal method \(if it exists\) to compare specific value types. To achieve the same goal with [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) you can provide a [Code](https://godoc.org/github.com/maxatome/go-testdeep#Code) TestDeep operator instance. [go\-cmp](https://godoc.org/github.com/google/go-cmp/cmp) rely on paths to declare specific comparison rules, while [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) uses [TestDeep operators](https://godoc.org/github.com/maxatome/go-testdeep#TestDeep) almost in place in the expected data structure. [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) TestDeep [operators](https://godoc.org/github.com/maxatome/go-testdeep#TestDeep) offer the maximal flexibility during a comparison without typing any specific go code \(except for [Code](https://godoc.org/github.com/maxatome/go-testdeep#Code), of course, that can be used as a last resort when the other TestDeep operators cannot fulfill your needs.\) Note that I am the author of [go\-testdeep](https://godoc.org/github.com/maxatome/go-testdeep) and I am not an expert of [go\-cmp](https://godoc.org/github.com/google/go-cmp/cmp).
Context package 
you could use a thread-library and kill the thread when you timeout you could use an externtal program also (guessing tho!) 
This was my thinking; a textbook use case for `Context` surely? 
This. NFS is notorious when it comes to these kinds of problems. When the share is unavailable, anything accessing it will just hang in uninterruptible IO (i.e. you can't even kill it with SIGKILL).
Try HN ? Good luck :)
Generally this is a nfs client (ie, mount) configuration issue. Most notably, this is the difference between a `soft` and a `hard` mount, you should use the `soft` mount if you want to or are able to gracefully recover. Here's a [source explaining some things](https://www.ibm.com/support/knowledgecenter/en/SSEQVQ_8.1.2/client/c_bac_nfshsmounts.html). While you can't set the timeouts on the Go side, you very much can when mounting the NFS endpoint.
You have to use async I/O if you want to be able to cancel the operation. You will also have to make sure that NFS is mounted with the `soft` option, or else operations will block and wait forever instead of returning an error. As /u/i_regret_most_of_it says, deadlines were added to os.File. That happened back in October of 2017, so if you're not compiling with a new enough Go version, you might be out of luck.
I know that that's how it's documented - but my experience says it's not how it works in practice. I.e. I used soft mounts exactly for that reason and still regularly ran into this problem. YMMV, but I've pretty much abandoned NFS for that reason.
Thanks will give there a go.
Just like moving a particular file to a new place breaks every program, using the old hard-coded path. Locations in a file systems are identified by a path. Import path in `import "github.com/urs/prjct"` (note, no leading slash) is a hard-coded path that's translated in a known way to a file system path. I guess I don't get what's perceived as wrong about it. 
We're still on it, and due to some other characteristics (multi path, dual data mover controllers, etc.), we don't have an issue with them yet. That being said, a proper distributed filesystem would be closer to my liking, however all the implementations have constraints that don't work for us, mostly in regards to latency. The thing is, migration from NFS to something else is much harder to implement in non-Go languages, while in Go you'd just implement a few interfaces and could move from the filesystem to something like https://minio.io or even S3 if you like (they actually share the API). Alas, 15 years of legacy apps which don't look like they are going to be deprecated any time soon, limits our options. I'd be a happy kitten if I could move everything to HTTP and call it a day.
[removed]
Out of interest, why?
Congrats, fist post!
Yes absolutely , although there’s a lot of arguments about avoiding context completely ... but meh ... is good for a poc and more 
You really need to look into it and meet people directly right now, it seems as though the pool of jobs is small and easily filled due to a high number of what I would consider legacy systems still being actively used/developed. Company I work for has switched to golang for a lot of backend systems.. It took me a lot of convincing and I wrote most of the systems myself (very small team) but we saved in terms of technical debt. I think we will start to see more and more of this. Am based out of Toronto as well.
Nice! I was wondering the same but in MetalLB we were able to pick up neighbor solicitations by joining the group after computing it for a virtual IP address. Hope this helps! https://github.com/google/metallb/blob/master/internal/layer2/ndp.go
there a slack for golang as well ;)
Thanks for link! I read it but I'm not completely sure about what problem you're trying to solve. Are you proposing a modification of the declaration format in go.mod and the MVS algorithm in vgo, or are you proposing to design something completely different from vgo? I don't understand your comment about the "artificially short timeline". The dep project, whose goal was to explore dependency management for Go, was started more than one year ago, and Russ started to share some of his concerns as early as March 2017 (https://groups.google.com/forum/#!msg/golang-nuts/PaGu2s9knao/Bq4vmFh7AgAJ). What am I missing? Have a great vacation :-)
What are the arguments to ignore context? Genuinely curious.
Three articles per month and a giant nag screen to remind you to register and login.
Hi r/golang! I have some Go code in this post so thought I'd put a link here in order to get feedback or suggestions for improvements. If you see something I could/should change, feel free to tell me!
context is not magic. you can't expect to just add context and boom it works. for NFS read, if you try to wrap it with a function with context, there's no way to add context cancel check in the middle of the read. you can only check before and after the read and that doesn't help the situation.
\+1, I'd also be interested in this.
The context with cancel would apply on Time.after and not on the read nfs call , I wonder to know what would happen to that syscall
&gt; you can't expect to just add context and boom it works Yes, but you can create a [context with a deadline](https://golang.org/pkg/context/#WithDeadline), then start two routines, one to read from nfs, another to wait for the deadline to happen by using select. select { case &lt;-time.After(1 * time.Second): fmt.Println("overslept") case &lt;-ctx.Done(): fmt.Println(ctx.Err()) } 
Keep in mind that `echo` has good documentation an is well covered by tests. Look at tests for examples of code use when in doubt. Also, check [Building Golang Server with Echo](https://www.youtube.com/playlist?list=PLFmONUGpIk0YwlJMZOo21a9Q1juVrk4YY) on YouTube.
Keep an eye out on https://github.com/thejerf ; I think I'm going to call it https://github.com/thejerf/goremsh . However, there's a couple of other dependencies in the way before that shows up. I was looking at the extraction process and while there's a couple of things that are of purely local interest that I will remove (the hooks will be there if you want to implement them yourself, or anything else you may want, but these specific things are not interesting to anybody else), there's also a couple of core capabilities I want to put in as separate repos as well, and they'll come in first. I expect it'll be some weeks. But I do have some time carved out at work for this, so it should happen.
Yes I'm aware of that. But let's assume NFS reads hang for 5s and you have a 100ms deadline. so after 100ms you read function returns with timeout, but you still have a goroutine and a channel hanging for 5s. One read call doesn't seem like a huge problem, but imagine you made 1000s of read calls, then you have 1000s of goroutines and channels hanging. That's a big problem for production code. Is it better than 1000s of read function hangs? Sure. But it's still a problem and not the real solution. Per my understanding to context (correct me if I'm wrong), this is the reason that you should not implement a function with context like this (but it's OK if the function in goroutine also supports context so it won't hang for a lot longer than the parent function).
&gt; Because if it breaks in our editor at least we'll do everything we can to offer a solution to fix the problem. And because if it breaks in our editor, it will break in those alternatives as well. Meh; I'm guessing you are from jetbrains. I've heard more people have issues with Goland than vim or vscode. Not sure why people decided to downvote my comment; I'm guessing it was you and your co-workers. Not sure thats a good way to manage your brand.
Really nice to see a book and this package as a whole progress. It’s hands down my favorite. Sadly I’ve moved mostly to Go in AWS Lambda so I don’t get the usage I once did out of it anymore...but it’s a terrific package worthy of a companion book.
Game industry uses other tools and languages. It’s an extreme uphill battle for Go to be used there. It’s not that it’s not capable, it’s that so much groundwork has to be laid. It may have an easier time making its way to the mobile scene. Either case, it’ll be years before there’s a broad usage in those spaces that would provide community support. You would be pioneering right now...but that may not be a bad thing. Depends on your needs.
10 is an untyped constant in this example. Its type is inferred to be whatever works.
The basic idea is that 10 is a constant and the compiler knows to convert it to whatever type it needs to be. Same reason you can multiply a float variable by 10 rather than 10.0. Intn returns an int which is an explicitly different type that a time.Duration. I'm sure someone else can explain this deeper than I can but that's the gist. 
&gt; Is it better than 1000s of read function hangs? Sure. But it's still a problem and not the real solution. Heck, it may even be worse depending on the specifics of the situation. At least the blocking reads might help throttle the service, just making it slow - rather than fully failing at some random point in the future. Of course, true cancellation would be great, but that's not really an option from the sounds of it.
yeah that's a good point
Read up about [constants](https://blog.golang.org/constants) :-D
Three articles per month? Is that if you're not signed in or something? I guess I've just not noticed any of it because I've been signed up and in...
Do a := 10 dur := 10 * time.Duration and you will get a compilation error. Every Go dev has been there.
You mean a * time. Duration? 
Yes, thanks, edited. I type from my phone and this happens.
You can do hot/live reloading instead of rolling out binary blobs.
Intr has been a no-op for over a decade. 
`Duration`'s underlying type is an `ìnt64`, which the compiler knows how to convert to. Literals and constants are untyped until they are used, unless explicitly declared. `rand.Intn` takes an untyped literal and returns an `int`, which has already got a type.
We've just opened up our first Go job at Kira Systems in Toronto. We already have a few people doing Go internally and are officially adopting Go as a second language. Our company produces machine learning powered applications to analyze contracts for law firms, audit firms, and large corporations. Job: [https://kirasystems.recruiterbox.com/jobs/fk01uxa/](https://kirasystems.recruiterbox.com/jobs/fk01uxa/) I'm one of the founders, happy to answer questions if you have them!
because 10 isn't an int it's a constant. https://blog.golang.org/constants
Because it is clear something is wrong with the OP setup as I have never had such a problem and never heard about it from others. For me it always was just `goland $GOPATH/src/&lt;path to package&gt;`
``` package main import ( "fmt" "time" ) func main() { fmt.Println("Hello, playground") sleepTime := time.Duration(int64(3)) time.Sleep(sleepTime * time.Second) fmt.Println("Goodbye, playground") } ```
[removed]
Your "without" code is wrong; you'd only need to have the `jen.` qualifier on the first part of the expression chain, and the rest would be methods. Dot import: f := NewFile("main") f.Func().Id("main").Params().Block( Qual("fmt", "Println").Call(Lit("Hello, world")), ) fmt.Printf("%#v", f) Regular import: f := jen.NewFile("main") f.Func().Id("main").Params().Block( jen.Qual("fmt", "Println").Call(jen.Lit("Hello, world")), ) fmt.Printf("%#v", f) I dunno, this doesn't seem much worse to type, and it's a lot (lot) easier to parse. Using the dot import for this use case is biasing your code for write efficiency over read coherence. Almost always, this is the wrong tradeoff.
Hi sorry for the mistakes, I am not a native speaker and writer I will try to improve this.
Oops, missed that blurb on man page - thanks for correction.
I'm afraid you are confusing complexity and size. Go has a lot of the latter and little of the former. If you rewrote that code with the same control flow in Ruby, you'd see it's not complicated. So, to answer your question, Go does not favor/allow any more complexity than Ruby. But it does use many more lines/characters.
Wow I'm an idiot thank you
In terms of code style I would always first take a look at [Effective Go](https://golang.org/doc/effective_go.html) There is also a subsection on Methods in Go [Effective Go Methods](https://golang.org/doc/effective_go.html#methods) Hope this helps!
The last commit was in 2016 \- have you tested this? Does it still work fine on all platforms?
Creator of Notary (https://github.com/theupdateframework/notary) here. We started with go-tuf and built out a complete TUF service. Early on we submitted a couple of PRs back to go-tuf but we drifted apart to the point that became infeasible. Depending on what you need to do, notary may let you start further along. 
It's folk wisdom at this point, memories from a time when it actually helped :) Other fun facts: /bin/umount *stats* mount points before using the unmount syscall, so it will never work on a hung NFS mount! You can often work around this by calling the unmount sys call directly. 
FWIW, I don't think there would be anything wrong with trimming the function down into: func Activate(c *context.Context) { code := c.Query("code") if len(code) == 0 { sendActivationEmail(c) return } if user := models.VerifyUserActiveCode(code); user != nil { activateWithCode(c, user, code) return } c.Data["IsActivateFailed"] = true c.Success(ACTIVATE) } if that's what you're talking about
In addition to this act of desperation: dur := time.Duration * 10 will not work either.
I'd love for hogwild to make it into gorgonia :P
You can redistribute it, but I believe go calls out to separate processes in several cases. And that's not even considering the stdlib that has to be present too.
I dont mind including all the go dependencies, is it possible to just move the C:/Go folder to my project and use "Go/bin/go.exe build main.go" or some command like that?
I haven't compiled go on Windows but if it's anything like Linux then as long as all the environment variables like $PATH, $GOROOT, etc are set correctly you should be able to do something like that.
Why? If you're distributing this on any Linux, just require the golang package. It's almost surely a better idea than bundling Golang. Are you going to do emergency security maintenance releases when Golang has security releases? etc. Package managers are a thing for a reason.
amazing talk! i'm so impressed.
Im not sure what you mean by the golang package. The compiler for the programming language outputs a golang file that needs to be compiled to a binary to be used. To do this, I need to package a golang compiler in the distribution so that the compiler for the programming language can build the golang file generated by the compiler.
The author here and to make it clear, basically this is a tool that will generate Typescript \(or ES6\) classes to make it easier to enforce typing when you're communicating between Go \&lt;\-\&gt; browser.
Except they still can be ignored.... The only paradigms that force you to handle errors are monadic ones. Scalas Either is a good example, or things like Promise and Future that force you to error handle
&gt; or Python [Python's not Turing complete.](https://web.archive.org/web/20161123042252/https://learnpythonthehardway.org/book/nopython3.html)
the claim there is not accurate, not sure if he doesn't understand or if he is joking.
Out of curiosity, why can't you use ssh? 
There is no way to unlink a plugin. However, they are only useful for linking with other Go binaries. However, you can always just "exec" the program in your host OS and communicate/kill it, all with the Go stdlib. There's also no way to execute arbitrary code in Go.. You could try and have more control, actually manage threads/scheduling/etc, but you'd be fighting a lot and relying on C/Asm to do it, for no real gain. Using Go to build an actual bootable OS is basically not worth trying, but I don't think it's what you want to do anyway.
Docker maybe?
On linux it's typical for this kind of dependency to be handled by a 'Package manager' like apt (for debian/ubuntu), yum (for CentOS/RedHat), etc. By providing your software in a package you can declare that it depends on the Go package and let the distribution handle sourcing it, keeping it up to date and so on. Even if you're not packaging it yourself I wouldn't distribute the Go compiler with your code for the reasons /u/colemickens mentions above.
You’re talking about cleaning up and repopulating the symbol table and the associated addresses from 1. Heap 2. Code section of the dynamically linked lib 3. Data section of the dynamically linked lib Tbh, there are no obvious or straightforward language constructs to do this. However, it is possible to do this using some hacks. For instance, with root privileges, you technically have all the permissions to write over the above 3 mentioned sections. However, I wouldn’t go about doing this by hacking the runtime of Golang. I would do this by building a new system that acts as the runtime for your OS. 
Seems fair to require your users to install the go compiler. If you're transpiling to go, they need to know about golang runtime concepts anyway. Sort of like how the JVM-based languages expect you to understand how the JVM works and for you to have your own JDK installed.
Could iexpress work for installing the go compiler and other dependencies?
Fantastic article. Just tweeted about this article, we’re entirely simpatico. Simple is good, and as my friend Ezra Zygmuntowicz said “No code is faster than no code!”
It's 2018, didn't everyone move to immutable infrastructure?
I am currently testing out echo. I find the middleware collections to be lacking. I tried gitter and Dev were not very active. I wish there were good documentation and example on how to use middleware
&gt; x is not reachable Thanks for trying the experiment. The result is what I expected, and it shows the gc doesn't use the compile-time types of pointers.
I understand your argument. I just think it's mistaken. The gc knows what strHdr points to contains a pointer. Why? Because when that memory (the 24 bytes) was allocated (at the `&amp;bs`) they were a []byte. And I think that will keep it alive.
Really great talk.
Glad to hear I’m not alone recommending people stay away from distributed systems for “simple” ML solutions. 👍🏼
Cool, I had no idea. I wish the Go docs said this. The link they currently have is broken: https://github.com/google/pprof/blob/master/doc/pprof.md
Not complexity, just a lot of nested conditionals. Good to know, thanks for the response. 
Any video for this?
He used to believe that seriously, and it quickly became a meme. Not sure what his current stance on Python 3 is lol.
That's be awesome!
Your understanding is wrong. You should read this article [https://go101.org/article/value\-part.html](https://go101.org/article/value-part.html) to get the underlying structures of all kinds of types.
Your understanding is some weird. This example proves "gc does use the compile\-time types of pointers, but may not use run\-time types of pointers".
Super off topic here, but why should I get goland over VS Code? I already have Webstorm for frontend work because I found it gave me something - goland I don't really feel I can justify the cost, because I feel VS Code can give me most of the features. 
I switched from Mux to Gin a few weeks ago and it's been fantastic!
&gt; Erlang is robust and suitable for some scenarios, its syntax and mindset deviate far from the main stream, making it hard to learn. Erlang considered counter-revolutionary.
Not sure why others are saying you can't: You absolutely can. You will need to bundle Go for the user's architecture and platform though.
To be honest, I don't think this is a task Go will solve well. An awful lot happens at compile time that you can't do again at runtime. From my experience, Ruby would be ideal for this as it has a lot of tools for runtime introspection and capability development.
Some network security restrictions in the company i'm working for plus the list of things [u/jerf](https://www.reddit.com/user/jerf) described in his answer below. 
I can't give you a definite answer, but I can think of the following reasons: - scheduling cost between cpu - decreased locality of the memory on the cpu Considering the work here is completely cpu bound, I'd say no go routines at all will actually produce a higher ops count, simply because there is no scheduling overhead.
So first of all why doesn't the number increase with more parallel threads? This is simple because none of the work is parallelizable, all threads are contending for access to the same variable. Now why does the number decrease? This could be due to a couple of things, firstly it might be that the atomic int slows down as more threads contend for it (unlikely but depends on implementation). More likely this is a cache coherence effect: every time one of your cores writes to the variable your processor has to invalidate it from all other cores caches (so they don't see an old value). This means you're going to spend large (and variable) amounts of waiting for the cache coherence protocol to pass the variable between cores.
Also interesting to note that this cache coherence effect can also be seen if two threads are writing to two separate variables that just happen to be located in the same cacheline. This is so called https://en.m.wikipedia.org/wiki/False_sharing
Non-Mobile link: https://en.wikipedia.org/wiki/False_sharing *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^188405
Going by https://github.com/golang/go/issues/19435 and https://groups.google.com/forum/#!msg/golang-dev/tcl_XFLUfcE/V6JUoZD-DAAJ, it looks like these are quasi-internal methods for `x/net`.
Makes perfect sense!
It is not possible to do this right now, as you are not given access to a list of used types in the program. In *theory*, the static list of concrete types is compiled in, so you could use unsafe to inspect the memory of your program to find it and use that, but in practice, that's unlikely to work. There's also a couple of unexported symbols in the `runtime` package that you could use, if you resort to assembler or the like. But even if you manage to somehow get it to work, it would probably be incredibly non-portable, depend heavily on internals of the runtime (and thus have the chance to break at any Go release, even if it's just a debug release) and even *then* still suffer from the problem that the list of all types implementing an interface isn't static - new types can be created with `reflect` and be added to the list. In short: On 1, that's a hard No. On 2, that's possible with a hand-rolled tool and probably not even that hard. Still only gives you the static list though. The standard way to do this, is to register the types in a map, akin to how [database/sql.Register](https://godoc.org/database/sql#Register) works.
It got badger
This is absolutely possible. You just need to set GOROOT and PATH. I do this on Windows all the time. Actually, the first thing I do when opening a shell is to source the following: ``` export GOPATH=~/stuff/go export GOROOT=~/sw/go1.10.2 export PATH=$PATH:$GOROOT/bin:$GOPATH/bin ``` 
It works exactly like that, not only "something like that". :-)
File a bug.
Thanks so much!
I didn't find any post about this here under r/golang so I posted it here because it's made in Go and it looks like a neat project. Curious to see what people think about it too.
go influxdb instead :)
I've been using [go-carbon](https://github.com/lomik/go-carbon) as a receiver for a while now, and it's pretty neat. InfluxDB always seems neat, as do some of the newer alternatives like Prometheus, but I've no particulr pressing need that migrating would solve.
well, I moved from graphite to influx cpl of years ago, mainly because you can send more/bigger batches, and the timestamps have nanosecond resolution. query lang and other features are a plus, for no cost in terms of ease of use.
I suspect the problem is that you're operating on the wrong layer. I suspect what the simulation did when the author wrote it is define operations as an "abstract syntax tree" combined with an interpreter that implemented it, and something else that manipulates it. Then, all of this ceases to be a problem because instead of it being Go code, it's all just Go data structures and you can easily see how to do anything you want. Even if you ultimately prove to need to execute these things at native Go speed, this is where you'd use the plugin architecture; you write something to convert those internal data structures into equivalent Go code (basically a compiler), then compile that and load the plugin. Before going down this route, though, be sure you need to. You need to be able to recover the compiler's execution time vs. the speed of your interpreter, and a toy simulation is unlikely to need enough execution time for that to be a win. And interpreters are not always as slow as you might naively think; modern-day CPUs have a ton of features designed to make interpreters go fast. If you need help with a specific aspect of this post, please do ask questions. However, the project you're specifying as a whole is a bit large for me to sketch the whole thing for you without being asked. :) You may also need to read up a bit on interpreters.
Even though I don't know much about 3D, I really enjoyed these slides. Any chance for a video?
We use json all the time in a large project, and we don't have a single instance of map\[string\]interface{}. Is there a reason you don't define specific / typed structs? This feels like an anti\-pattern.
I'm currently writing a server that will handle lots of JSON and I'm using that type for all communication with clients (both for requests and responses). It can be simpler that way, or at least it is if you've started out like that and don't feel like turning all response types into structs. I see clear benefit to structs and I wish I started out with them, but it's just a lot of work and could feel constricting. That being said, I don't agree with either of the suggestion by the OP. The first one is reasonable but pretty useless, while the second one is just terrible (for Go) and will never happen. Might as well use structs.
&gt; the most commonly used type is map[string]interface{} I sure hope that's not true.
One of the reasons is we get the sql query results without struct type. When we look at Google search we can see that this type is used too much "if err != nil" : 17.300 "map\[string\]interface{}" : 55.100
I’m doing the same thing, but I’m pretty new to the whole go thing and I’d be lying if I said it didn’t feel suboptimal. In my case I’m doing it this way because I don’t know what shape the JSON objects I’m passing around are going to take, the structures and data types are all fluid. I’m all ears if there’s a better way of handling arbitrary JSON than recursively walking through a map[string]interface{} and checking types as you go. 
I have added "I guess" before the sentence. 
&gt; use of this type [...] causes a huge code complexity in the code By complexity here you seem to mean "more symbols typed"? This is not the usual definition, and I doubt I'd create a local type just for that. Saying that if you define JSON as a local type, you can add a key() member function ... if you really want (I also don't see the usecase here). Also I'm not sure you are aware of: https://mholt.github.io/json-to-go/ which makes using structs even easier.
As a note, consider that map[string]interface{} can represent a JSON object, but not a JSON _document_, which can be either an object or an array.
&gt; I guess, the most commonly used type is map[string]interface{} after Go basic types like string, int. What? I hope not. https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=8m7s
&gt; could feel constricting Never knowing what is in your variables is far, far more constricting
As a Rails developer this was a great article about the benefits at a high level. However it did leave me wanting a more detail article about your experiences of building on Golang after using Rails for so long. What packages did you use? What approaches did you take breaking services out? Did any of the services talk to your Rails database? Etc
But I do know. I know what types to take out of the request. None of the variables have interface{} type, everything leaving the request becomes static or fails. You could say "why don't you just use structs if you know everything" and I very well might do that in the future, but I'm just playing devil's advocate here. Using map over structs probably doesn't make for a very stable or well defined API, but I'm not thinking about that yet. P.S. I just realized I lied. I don't use map[string]interface{} for requests. But I use the JsonParser library which functions similarly to what I would be doing if I was using map[string]interface{} (getting fields of specific types instead of unmarshaling).
Very curious to see how scalable this really is. When I last looked into running a large -scale MQTT broker there weren't many options, and what was out there was expensive and proprietary. Their "scale" plan only allows up to 500 unique devices.
&gt; I guess, the most commonly used type is map[string]interface{} after Go basic types like string, int. I don't believe this is at all true. I think you are biased by your corner of the industry. I don't think, in fact, this type is *at all* useful, outside of very narrow use-cases, like API proxies that don't know anything about what they are proxying for. Even most JSON/toml/yaml consumers will know enough about the structure in the data to use more specific types. &gt; `type JSON = map[string]interface{}` Note, that there is nothing "JSON" about this. It's both useful outside of JSON *and* JSON-data contains significantly more structure than this. For example, `[1,2,3]` is valid JSON but can't be deserialized into that type. &gt; Can JSON could be added as an alias type to core library for `map[string]interface{}` like int that is alias for int64 and int. `int` and `int64` are different types, but that's beside the point. More importantly: What would be the advantage of that? Anyone who wants that, can just declare that alias themselves and it becomes completely interchangeable. i.e. there is no interoperability advantage or anything.
It says '500 Unique Devices, $0.10 per extra 100'. So 500 is not a limit, merely what is included in 10/month.
Nice reflection, which mirrors my views on Rails and the move to some go-dness
Follow These 10 Simple Steps To Become A Haskal Wizard Today And Unlock Your Inner Programming Genius. See Testimonials From Satisfied Customers [Here](https://youtu.be/dQw4w9WgXcQ).
I'm on phone so it's hard to link, but there are several projects that take in literal JSON and output Go structs. That and some simple search &amp; replace can make it not that hard to switch.
Thanks for your input. I am not overly attached to using Go for this - my main interest in doing so stemmed from the fact that I've already been working on a life simulation in Go, though no so ambitious as to have my the application be self modifying (yet). It would've been nice to use any language specific insights gained from this in my main project. There are some languages the authors suggested as potentially being well suited for this kind of thing. They focus on Smalltalk-80 and also list Lisp, Python, Prolog, Ruby, and JS as options maybe worth considering. I'm going to do some thinking and look into different approaches before continuing, thanks again. 
Thank you. I am going to look into maybe taking another (non Go) approach for this, as well as playing around with the option of #2. 
Thanks, that is the impression I get from the other feedback as well. I'll look into Ruby but also into some of the other languages listed in the paper as potentially suitable for this sort of approach, like JS and Python (both of which I'm much more familiar with than Ruby right now) 
One of those has already been posted in this thread already. But that's the easy part I can do myself. The hard part that I have not figured out yet is how to do responses like that. In other words, how to go from "all these request handler functions return one map type" to "they all return their own struct". Do I just use an empty interface for their return values? Kinda ironic, considering I'm moving away from interfaces, but I guess that could work. You bring up great points that I can't disagree with. I'll look into transitioning away from maps.
[removed]
Exec sort of defeats the purpose of my thought experiment, which was (among other things) to be able to pass around native Go structs and share memory across programs. Also, it would be neat to apply this to a modified Go runtime that runs on bare metal.
Good point! Would love to see some real world demos and scale examples on their site then!
Loved watching your talk, thanks a lot Hunter, and happy honeymoon 😀
[removed]
I agree with op that you should probably register types explicitly - however it's not really that involved to get the *_type struct at runtime if you're just looking to experiment with a prototype. It's just one line of code and is portable as any other Go code (though mileage may vary under deeper introspection of *_type fields). example from a [test repo](https://github.com/cstockton/safer/blob/master/type.go#L52) of mine: type *_type struct { // https://github.com/cstockton/safer/blob/master/type.go#L108 } func typeOf(v interface{}) *_type { return *(**_type)(unsafe.Pointer(&amp;v)) } 
I agree with op that you should probably register types explicitly - however it's not really that involved to get the *_type struct at runtime if you're just looking to experiment with a prototype. You will want to extract the `moduledata` from the symbol table, which is a linked list in `runtime/symtab.go` which contains the data you need for `*_type` traversal in the `runtime/type.go`. I'm not 100% sure what you're doing but between those two files and the `typelinksinit()` / `activeModules()` func you probably have most of what you need. Once you have the type information, getting association from values at runtime is pretty easy using: type *_type struct { // https://github.com/cstockton/safer/blob/master/type.go#L108 } func typeOf(v interface{}) *_type { return *(**_type)(unsafe.Pointer(&amp;v)) } 
Indeed, it's using badger KV working out pretty well for us so far, getting around 400K writes/sec on the storage level, with small messages.
It's all open-source so feel free to check it out and try on the particular workload (https://github.com/emitter-io/emitter). The cloud plan is there for people who don't want to host emitter themselves. We'll get some benchmarks and more demos in the near future as well.
curious: where is "JSON document" defined? json.org does not specify it, and the go parser does not complain on top level literals either, so I'm pretty sure any json value is valid at the top level.
\[The original JSON spec\]\([https://tools.ietf.org/html/rfc4627#section\-2](https://tools.ietf.org/html/rfc4627#section-2)\) defined a "JSON text" as "a serialised object or array". It seems like they backtracked on that \[on a later RFC\]\([https://tools.ietf.org/html/rfc7159#section\-2](https://tools.ietf.org/html/rfc7159#section-2)\), since most JSON implementations don't actually care, so now a JSON text is essentially equivalent to any JSON value.
Packages are not required to be in the GOPATH in order to be imported. Whenever I need to import packages into my local directory, I just do something like `export GOPATH=$(pwd)` and continue working as if nothing had happened. Three new directories will be created: bin, pkg, src as described here [1]. Having your packages in GOPATH is just something "nice to have" because the majority of tools and IDEs out there assume your packages are there, but I have been working like this _(with the local GOPATH)_ for +4 years now and haven't found any difference. [1] https://golang.org/doc/code.html#remote
&gt; (Both env vars and flags can be inspected by other users of the system at runtime.) How are env vars inspectable by other users at runtime? The only place they are preserved AFAIK is /proc/[pid]/environ, but that file is only readable by the owning user. 
How else can Go force you to use static typing if it made dynamic typing easy?
Go 1.8+ doesn't need GOPATH. Also, generally, you don't need to care where the packages are. What issue are you running in to that you actually want to fix? "go get x.com/pkg" makes the package available, why are you concerned with it's final resting place?
vgo is mostly what you want (it needs gopath currently but that's "hidden" behind the scene and could use default value if you don't do anything) vendoring doesn't need gopath, but you need some local path structure
Some of the best advice I've ever seen. I've been pushing these concepts for years, now I'm just going to consider this article as required reading. It would be nice if there was a cliffs-notes version, though, with a table of contents and a bit less story.
As someone who also came from rails years ago I found the package ecosystem in Go barren. The worst thing was not having easy libs for Auth (devise) and Database (Active Record). Missing these two cornerstones made me feel a lot less productive. So I'll shamelessly plug my libraries that help fill the gap because I think they're great for people who are coming into the Go ecosystem from Rails. Specific to your question as well sqlboiler is a database first approach allowing you to talk to an existing rails database with Go very easily. https://github.com/volatiletech/authboss https://github.com/volatiletech/sqlboiler 
It is this one: https://www-users.cs.york.ac.uk/susan/bib/ss/nonstd/ecal11-17.htm
[removed]
If you want dynamic typing, use a dynamic language.
&gt; And config files are great for declaring verbose configs, as well as being the only secure way to get secrets into a program. Also, how are config files more secure than environment variables?
Even if your data types are fluid, you don't have any advantage by not using structs. If you change the structure and types on the other end, you still have to edit your code that manipulates your interfaces to match. It's just as easy to change your struct fields/types. If you do have json data that you aren't manipulating but are just passing through to a database or another service, take a look at `json.RawMessage` that doesn't waste time unmarshaling the data and supports both objects and arrays.
That's what I was thinking. You'd need same user or root to access either one. Seem equivalent to me.
\&gt; Do I just use an empty interface for their return values? Kinda ironic, considering I'm moving away from interfaces, but I guess that could work. That is what we do. Every request/response path has a typed struct associated with it. We unmarshal the request body into the struct and then operate solely on the struct. The typed response is returned through the router as an interface, which then passes that through into `json.Marshal` or whatever type the `Accepts` header wants back. That separates the business logic that only deals with types, and the routing logic that uses `interface{}`.
Exactly.
I’m the author of the post and am glad to see it posted here. That said, and going back to your reply, I plan on writing a few more thorough posts about moving to go, in the meantime, if you have any specific questions, feel free to ask!
good bot
Here's a good post that explains why you shouldn't use environment vars for secrets:. https://www.google.com/amp/s/diogomonica.com/2017/03/27/why-you-shouldnt-use-env-variables-for-secret-data/amp/#ampshare=https://diogomonica.com/2017/03/27/why-you-shouldnt-use-env-variables-for-secret-data/
It’s possible I’m an edge case, or maybe there’s something I’m just missing. I’m not able to define structs in advance, because the structure of the data is unknown at compile time - my app doesn’t find out how the data is structured until it pulls it and a template describing how it‘s going to be used from the KV store.
Hah thank you!
The conference recorded video; I'll post on /r/golang once it's up!
The conference recorded video; I'll post on /r/golang once it's up!
Thanks, I enjoyed yours too! I meant to find you after to ask you some questions.
&gt; Scatter-gather The example given there is map/reduce, where you want to farm out the workload across your cores and later perform some aggregation on the result set. [scatter/gather](https://en.wikipedia.org/wiki/Vectored_I/O) is a different technique, used for treating fragmented data sources as a contiguous whole.
 var fs myflag.FlagSet var ( foo = fs.String("foo", "x", "foo val") bar = fs.String("bar", "y", "bar val", myflag.JSON("bar")) baz = fs.String("baz", "z", "baz val", myflag.JSON("baz"), myflag.Env("BAZ")) cfg = fs.String("cfg", "", "JSON config file") ) fs.Parse(os.Args, myflag.JSONVia("cfg"), myflag.EnvPrefix("MYAPP_")) Would the idea be that the file named "cfg" contains the configs in json format, or that the "cfg" flag contains the path to the config file? Also would this package allow unmarshalling into a struct, or just into basic types? 
Am I missing something or do all the issues mentioned in that post go away if the application changes the environment var once it’s read the value? I understand that’s not typical, which is kinda one of the points made, but at least it only needs to be thought about at one place. 
That sounds pretty edge case to me, and you are probably stuck with some form of recursively walking the tree. Depending on your performance needs, access patterns and what your template looks like, you might be able to use the `Get` style functions of [https://github.com/json\-iterator/go](https://github.com/json-iterator/go) to retrieve values instead of unmarshaling the entire struct.
Not that compelling vs the tradeoffs. I mean if you are using docker swarm or kubernetes, then using the built in system makes sense. But if not I think it makes more sense to use environment variables and be careful vs the added complexity of adding an external secrets manager. I.E. simplicity trumps correctness.
why not just use kafka?
Any benchmark comparison with normal `net.Listen` ?
&gt; The problem with context.Value is that the key and value are untyped and not guaranteed to exist You can work around the specific problems this creates (and you do have to deal with these problems if you're using `context.Value`, but the article doesn't spell out how to manage this and i think it would have been good to provide solutions) The concern with untyped keys is that doing something like `ctx.Value("user")` could pick up an unexpected value due to a key collision with some other package using the same key. The `context` docs deal with this explicitly &gt; The provided key must be comparable and should not be of type string or any other built-in type to avoid collisions between packages using context. Users of WithValue should define their own types for keys. Here's an example in action: https://play.golang.org/p/gGHR2JOV239 The second part of the problem can be addressed by using a helper function to extract values from the context rather than using the context directly. If it is set then it can be coerced into the appropriate type. If the value is not set you can do whatever makes sense. Using both together you can isolate the logic for dealing with these concerns in one package using private context keys and helpers for creating a `context.WithValue` or pulling a value out of a context. If you have an auth package adding user details into a request context then this might be a good place to isolate all that related logic, and anywhere in the code you need access to the user you consume this package. In summary, it's easy to misuse contexts but it's also easy use enact discipline around their use in which case they are quite powerful. 
For myself, the primary purposes are orthogonality, reordering, reuse, and short circuiting control flow. If you feel like data is somewhat being thrown out into the void leaving you hoping that it will be caught, then my guesses are: 1. The request context is being loaded with failure\-related data with the logical ramifications being handled at some other disconnected stage. 2. The request context handling is getting repetitive and/or inconsistent/sloppy instead of being wrapped in a convenience subroutine that handles both retrieval and loading. Though, there might be other interesting reasons you've reached this feeling.
[https://gobyexample.com/](https://gobyexample.com/) is pretty neat.
It looks like you know in advance \(statically\) what fields you are expecting so it would be more idiomatic to have typed functions like this: func (rep *Repp) RunPDF(dest []*RunPDFArgs1, obj *RunPDFArgs2) *RunPDFResult { /* ... */ } The have the calling code parse the JSON in advance like so \(error handling omitted\): var dest []*RunPDFArgs1 json.NewDecoder(destJSON).Decode(&amp;dest) var obj RunPDFArgs2 json.NewDecoder(objJSON).Decode(&amp;obj) repp.RunPDF(&amp;dest, &amp;obj)
I wrote this silly package to help out with option #2: github.com/zeebo/goof Let me know if it works out for you lol
[removed]
[removed]
Read this and practice from this link.thanks bro.
Thanks!
Being careful is easier said than done. This approach can be extended to a lot of security related problems where you can say, 'just be careful and don't have security vulnerabilities' :-) You never have those on purpose and in most cases you try to be careful. Either way, it's always a trade off. In some cases it really doesn't make sense to go with a secrets manager and in other cases it's a must have even if you don't use docker/Kubernetes. Hashicorp's Vault is definitely used in non-container environments, for example.
[removed]
got any code to delete the first 3 cols?
Wouldn't i make sense to have an optional "--analyze" run mode, where it wrote to file all interface usage, and that one could chose to use that info for an optimized compile? I see that this might go against Go's idea of simplicity...
&gt; Would the idea be that the file named "cfg" contains the configs in json format, or that the "cfg" flag contains the path to the config file? The latter. &gt; Also would this package allow unmarshalling into a nested struct, or just into basic types? Just basic types. I find taking flags into a strict tocbe a mild anti pattern, because it encourages you to pass that flags stuict wholesale to components, as a big ball of config. This is usually more config than any single component needs/uses, and so it subverts a reader’s comprehension: which specific values are being consumed in this case? I have to read the code to find out. Much better to pass flags individually.
You’ve described some conventional workarounds to specific technical issues with context.Value, but you haven’t spoken to my main point in that particular section, which is that using context as a sort of opaque sidechannel for dependencies to components subverts a reader’s ability to easily see, via e.g. type or function signatures, the dependency relationships between those components. Concretely: if a type uses a DB handle to do its job, I want to see a DB handle passed to that type explicitly, when it’s constructed; I don’t want to have to read the code to discover that it extracts a DB handle from the context that I pass to it when a request arrives. This subverts my ability to mentally model the program.
I’ve seen this done correctly perhaps once. Risky.
&gt; I find taking flags into a struct to be a mild antipattern, because it encourages you to pass that flags stuict wholesale to components, as a big ball of config. What if each component defines its own config struct, which is then embedded into the main config struct? For example there could be a db package that contains: type Config struct { URL string User string Password string } And inside your main.go, there could be: type Config struct { DB *db.Config } This way you only pass cfg.DB to the db component rather than the whole thing. Would you still consider this an antipattern? Perhaps it is a bit of a side question, but I am also curious how would you handle the config for a package which has functional options in its API and provides some default values for the non-specified options (e.g. "localhost" as a default URL and no TLS by default) db.New(db.WithURL(...), db.WithUser(...), db.WithPassword(...), db.WithTLS(...)) Now what do we do if we want to use a flag's value if it is specified, but use the default values defined by the package if no flag is specified? Do we put a bunch of if statements in the main like so: func main() { // parse configs ... var dbopts []db.Options if cfg.DB.URL != "" { dbopts = append(dbopts, db.WithURL(cfg.DB.URL)) } if cfg.User != "" { dbopts = append(dbopts, db.WithUser(cfg.DB.User)) } .... db.New(dbopts) } Or would you handle it differently?
Sorry but this is a boring, uninspiring and totally pointless article in my opinion. It would be much better to write about what kind of problems did you try to solve in Ruby/Rails and why did it fail / was too slow. In my experience it's never so slow that it requires a complete switch to a different technology stack. There really is not much to gain for a rails shop to start using Go.
Cross compiling with cgo has been a hassle for many. Thank you to show everyone it is possible and not even that difficult.
Since Go 1.8 the GOPATH is implicitly set to ~/go/ Just enter 'echo $GOPATH' to verify.
 io.Pipe with io.MultiWriter and io.Copy 
If you have any type that is more complex or a basic type that occurs often in a specific context I suggest introducing a new type and favouring a distinct type over a type alias. In one code-base the type `[2]int` was used to represent a filed in a table. So I introduced `type field struct{row, col int}` which is more explicit. I really like your second proposal with map indexing but maybe I'm just biased by my lua background.
&gt; What if each component defines its own config struct, which is then embedded into the main config struct? This is definitely better, but I don't really see a clear advantage to supporting this abstraction, versus just having a flat set of flag vars. &gt; I am also curious how would you handle the config for a component that has functional options . . . [do] we put a bunch of if statements in the main? Yeah, that's what I'd do exactly.
Excellent advice! Thanks for writing this down
This is a SHAMEFUL copy of http://www.golangbootcamp.com/book/frontmatter - if you're going to straight up steal someones hard work atleast link the source in the page.
I didn't speak to it because I agree with all of that. There's a line saying "the problem with context.Value is..." that omits solutions to that problem. Taking on the emphasis of your post, i think the problem with contexts is not untyped keys/values but that they're used to do DI in a dirty way. At least that seems to be the main point you're making there (and i agree with that point).
wow, they didn't even try to differentiate themselves.
I seed them in Go, for the reasons you've listed.
this pattern \*is\* called scatter/gather, in parallel programming circles: \- [http://mpitutorial.com/tutorials/mpi\-scatter\-gather\-and\-allgather/](http://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/)
The Linux support is quite bad, but it’s definitely a nice and neat looking tool! Thanks :)
Thanks, i learned something new
I seed data using SQL scripts. Seeding data to db is a detail and can be done in a separate process. 
Another option is to just use a pre\-seeded Docker image with a package like [https://github.com/ory/dockertest](https://github.com/ory/dockertest). The image will work for any language, you'd just need to spin up a new container per test.
Here is my actual code without exceptions: func (b *BaseRequest) Tx(next)... return func(context)... { b.tx, err = b.db.Begin() if err != nil { return err } err = next(context) if err != nil { b.tx.Rollback() } } } serve("/page1", func(ctx){ r := SomeRequest{BaseRequest: b} makeChain(r.Auth, r.Tx, ..., r.ServePage1) }) instead of just: serveWrapper(serve func){ tx = db.Begin() try { serve() } catch(e) { switch e { case "tx_error": tx.Rollback() case "auth_error" ctx.WriteStatus(403) case "404_error" ctx.WriteStatus(404) etc... } } } servePage1(ctx){ ... } serveWrapper(servePage1) finally I don't get what you are saying :)
Ok but enjoy sharing data between middlewares with the context.Context map. You may explain yourself :\-\)
Your program will end immediately because you're spawning the signal handler in a goroutine - there's no blocking calls in the main thread.
Actually there is. I am running a ticker and listening to it in main routine.
 // Only some kinds of files support setting a deadline. Calls to SetDeadline // for files that do not support deadlines will return ErrNoDeadline. // On most systems ordinary files do not support deadlines, but pipes do. 
Ahh, that makes sense then. You'll have to run the signal handler in a goroutine then. Unless you want to set up a for/select that handles the ticker and signal handling in the main thread.
If your seed data is boring, use an sql script (like populating a list of categories that are static for example). If you're seeding for lorem ipsum kinds of reasons e.g. to see what a site looks like when it's full or something then that needs a bit more logic than I'd care to write in sql and I'd use Go (gotta avoid duplicates on unique indexes etc.). In terms of reusing the code created for normal use, don't write this code by hand if you were planning to, use one of the Go ORM-style packages out there (kind of sounded like you were, since if the code was generated it could hardly be called reuse).
Linux gives a numerical error code for problems with sockets (well, all kernel interfaces). This translates the numerical code to a human readable error message. [Here's a list](http://www-numi.fnal.gov/offline_software/srt_public_context/WebDocs/Errors/unix_system_errors.html). It's considered good practice (for code portability reasons) to use the system's translation table (e.g. `syscall.ENOENT`) rather than hard-code the numerical values yourself.
After a quick look, I'm not able to make sense of the snippets. Making a runnable example on https://play.golang.org would probably help others understand your intent. Also, I'm sorry anyone has downvoted your request for clarity.
Oh, didn't know about the bad Linux support, but good you like it.
It seems to be too complicated and... Useless framework. Sorry bro but I'd prefer to write all the code by myself than setting root directory and so on.
I don't demonize all empty interfaces. There are different kinds of empty interfaces. While the Haskeller in me would love a type that correctly represents "things that can be safely JSON serialized/deserialized", as a pragmatic matter, using `interface{}` that way is fine. I have multiple places where I've got an `interface{}` documented as being "things that can be JSON encoded or decoded", or similar such things.
Yes, either call `runSignaler` as written, or remove the `go` level from runSignaler. In general, I think the latter is slightly more correct (usually whether something is run in a goroutine is something the caller should decide, not the function, though there are exceptions, such as the popular "this object is actually a server" pattern), but for such low-level main.go code I tend to not worry so much about those sorts of rules. And even this is just for cleanliness and clarity; the runtime penalty here is pretty much exactly "spawing and tearing down one goroutine", which is not much penalty.
I saw it in HackerNews... couldn't install it though. I don't have GoLang installed in my computer but since I saw it was written in Go, came to this subreddit. Need help installing it!
Great article! thanks for sharing..any ideas on implementing tracing in container based deployments?
I was just being a bit silly with that empty interface remark. Anyway, I've replaced maps with structs and it did indeed simplify many things, aside from making the code more solid in general. So thanks!
[removed]
I've got a similar automatic release setup that I like, using TravisCI and goreleaser. The workflow that I like is that I just need to push a semver tag to master, and the whole thing kicks off. Goreleaser even writes a changelog to my github release. https://github.com/justinfx/gofileseq
Note that syscall.ENOENT as other syscall.E\* errors are [syscall.Errno](https://golang.org/pkg/syscall/#Errno) type that already implements error interface. So no need to translate them to custom errors which, in your case, cannot be compared by the caller as they are instantiated each time the translation happens...
You can get rid of the goroutine inside of `runSignaler`.
yup. But the best part is Go has such awesome tooling, that if you conform to [this pattern](https://blog.chewxy.com/2018/03/18/golang-interfaces/) you can write the generator yourself for a specific package that you control
[removed]
I agree with you, it is a useless framework, I wrote this just for practicing Go. But it indeed saved my time in writing some small Go Web porjects. And I hope there will be more interesting and excellent Go Web framework wheels.
Edit: Go against the grouthink. Get downvoted. Days later Microsoft is in talks to buy Github and Gnome and Debian have migrated to Gitlab.
I don't quite know what you mean by `fields combine`, but start by making yourself some structs to make extracting the data easier: type Filter struct { Field string `json:"field"` Operator string `json:"operator"` Value string `json:"value"` } type Resource struct { Name string `json:"name"` Type string `json:"type"` SearchCriteria struct { Filters []Filter `json:"filters"` } `json:"searchCriteria"` } type Top struct { Resources []Resource `json:"resources"` } Now you can unmarshal the response to an instance of `Top`, and range over the resources to extract your row data easily.
I mean you may make it better and easier to use. Have you tried Django?
That's a good point. Thanks for the input. Would you consider making a separate "component," in the native language as opposed to SQL script, that handles the separate process? Then, you can just ignore this component in production. Wouldn't this component essentially be equivalent to the SQL script?
Thanks for the input. I like that distinction between test\-data and lorem\-ipsum. This is true, I was thinking of creating my own models for the time being. Initially, I was going to use CockroachDB with SQLBoiler but I think the SQLBoiler team is still in the process of working on getting it to play nicely with CockroachDB. So, I will be using regular SQL for now and hence, I'll need to create my own models.
@justinisrael just checked out goreleaser, it looks awesome! Seems like it aggregates gox, ghr and semantics functionalities into one package. Really cool pointer, thx for sharing!
I think I used to use goxc for a while, but then I discovered goreleaser and loved how easy it was to wrap it all up into a workflow. I guess I just like the specific action of specifying a tag as opposed to needing to conform to a commit to trigger the release. What if you want to trigger a patch release later after you have merged various commits? Does that mean you have to make a dummy commit with the message "minor:" to get it to trigger? 
I have tried flask and I think the example I gave is simple enough.
Good article, sums up a few of the issues that people overlook when making these sorts of proposals.
Each time you type "go" you're sending that work off somewhere else. Either of your options are technically valid. The question should be more about "API design" than anything else - think about what the users would be expecting. If you function was named "nfs.RegisterCleanup", it should look like what you have. It should **immediately** register the cleanup functions, but not wait for it to run. In this case, we expect it not to block, so as a user I know I don't need to call it with "go". If you function was named "nfs.CleanupWhenReady", it should **immediately** block until the cleanup is called (which means it editing your function not to use "go"). As a user, I now have more control - if I want to wait for it to finish, I can just call it. If I want to fire-and-forget, I can call it with "go". You can provide both options, if you like. If providing only one, it *should* block. As a user, if I have the blocking method, I can make it nonblocking by using "go", but if you only provide the nonblocking method, I can't call it in a blocking manner. The main takeaway is to remember rule of least surprise. Make sure your functions do what they say they are going to do. runSignaler is, ultimately, a bad name for a function. With a clear name, it will be obvious whether the function will be blocking or not.
Hey, author of jennifer library here. Dot imports are a controversial subject! My personal opinion goes something like this: I wouldn’t use them if the jennifer code was just a small part of the overall package. However, some packages are 90% jennifer code (e.g. https://github.com/dave/jennifer/blob/master/genjen/render.go)... I think it makes sense then. However, to avoid controversy, avoid dot imports 😉
My 2 cents: 1. No tests, and not very testable functions. 2. Package globals used for configuration. 3. Lots of small files. 4. No godoc comments on anything. 5. Handlers are tied to http.
Great points! I plan on refactoring to make it more testable as my top priority. Still trying to learn best practices. 
Here you go, homie. https://play.golang.org/p/m_zs4_3tdc4
I would not create a separate component just to execute the data seeding process, and I don't believe that is completely equivalent to the SQL script. Here are my reasons: 1. When such component is implemented, it is possibly going to introduce a lot of maintenance issues. For example, what if the database driver needs to be updated? You have to compile and test that component. When you migrate your database from Postgres to SQL Server? You have to update the component AND the SQL. SQL are designed to run directly on the database server. Adding a component does not really enhance your project. Instead, it may introduce a lot of bugs. 2. Maintaining SQL code for large project is not trivial work, even if it's just a test database with very little data. If the project is very large and complex enterprise application, your database will be maintained by a designated DBA team, instead of maintained as a side project by one or two developers. I have not worked in a DBA team yet, but from what I heard, DBA team creates SQL script based on the need of the application, so they can optimize the query and indexing of tables. In this case, your DBA does not need to know if you are using Go or .NET. All they need to know is what kind of table you will need and they can optimize the database for you. If you integrate the SQL into your Go project, your DBA team will be required to work with Go to some degree, and it's not always ideal.
It speaks volumes that the minimum version described in rust crates is actually useless when those versions are never used. Also it appears that new rust version selection feature does something completely different from vgo for transitive dependencies, otherwise it will be easy to specify all the dependencies to use the latest version as the minimum version from the top level project. Tl;dr: In rust, the minimum version is what was used when the project first got started, it's soon loses all meaning since it's never used anymore once the library updates.
Nice. Always good to have another one to look at. Thanks
He just show that when you don't use MVS by default you can have a manifest file not reliable. 
How does gvisor implement system calls? How can you prevent code from executing system calls directly (e.g. without going through libc)?
How easy is kafka to understand? How quickly can you build a kafka cluster, an app, and deploy it?
That's a shame! I'm the primary author of sqlboiler :) glerchundi has been working hard on the cockroachdb driver and he just made a commit to track my latest changes in the v3 branch, I'm sure he'd love someone else whose interested in crdb to be trying it out. From what I understand it should be mostly working. It wouldn't be a completely stable path as there's one more syntax-breaking change remaining in v3, but it's fairly small (eager loading related). If you were happy to collaborate a bit and keep up with the latest until release (1 week or so I think) it could be interesting. You can reach us on slack if you're interested. Glad you had sqlboiler on your mind!
https://golang.org/pkg/image/ (and subdirectories draw, color, jpeg, gif, png). Once you get the hang of it, it does all that stuff and plenty more. I played with it at a workshop, it was fun. In some ways the API was a bit weird, but once you get going it's fine.
Why are we writing the data to both wBackupStream and wUploadStream?
50.0 miles = 80.47 kilometres ^(1 mile = 1.6km) ^(I'm a bot. Downvote to 0 to delete this comment.) _____ ^| ^[Info](https://www.reddit.com/user/Bot_Metric/comments/8lt7af/i_am_a_bot/) ^| ^[PM](https://www.reddit.com/message/compose?to=Ttime5) ^| ^[Stats](https://www.reddit.com/message/compose?to=Bot_Metric&amp;subject=stats&amp;message=Send%20this%20message%20to%20get%20some%20stats!) ^| ^[Remove_from_this_subreddit](https://www.reddit.com/message/compose?to=Bot_Metric&amp;subject=Blacklist%20this%20subreddit&amp;message=golang) ^(^Beta) ^| ^[Support_me](https://www.reddit.com/user/Bot_Metric/comments/8lt9lf/donate/) ^| ^[v.4.3](https://www.reddit.com/user/Bot_Metric/comments/8o9vgz/updates/) ^|
utrack/clay is an attempt to generalize gRPC+HTTP endpoints over one [interface](https://github.com/utrack/clay/blob/master/transport/handlers.go#L17) to make them easily pluggable. You can use `clay/transport/server` to run the server in a few additional lines of code, or implement a server that supports the interface for your own intra-org platform and reuse it between projects, avoiding any hardcode or ugly interfaces related to `Register*Server` funcs.
Looks good! I found the methods to crop and reformat, but I didn't find the ones to resize/ scale. Can you pinpoint me? Thanks.
I don't think there's a runtime for bare metal ARMv6 yet. Your best bet is probably [porting GERT](https://github.com/ycoroneos/G.E.R.T) to your board.
Hmm, I'll give it a look and if it doesn't require a tremendous amount of work I might port it. Thanks ;-)
- https://github.com/h2non/bimg - https://github.com/h2non/imaginary (as a microservice) I use pretty much all of the things you said, the only caveats are that gifs were poorly supported (might be better with recent versions), and the underlying libvips has some weird issues with [certain png files](https://github.com/h2non/imaginary/issues/168) which I worked around by pushing it through imagemagick...
Depending in what you are doing, if it's mostly for resizing, then [imgproxy](https://github.com/DarthSim/imgproxy) is fantastic. It's a 12 factor app, and it keeps the "Single responsibility principle" nicely. 
&gt; A simple CircleCI setup to publish Go packages to GitLab FTFY
Lack of function return covariance is annoying when testing, because typical Go code returns a struct pointer in New\-style calls. It means you either have to write a wrapper function and accept lower test coverage or hack around the limitation with method pointers: Regular approach: type WindowsEventLogger interface { Info(eid uint32, msg string) error Error(eid uint32, msg string) error } // untestable line of code, because func(source string) (WindowsEventLogger, error) = eventlog.Open does not compile func(source string) (WindowsEventLogger, error) { return eventlog.Open(source) } 100&amp;#37; coverage hack: // direct struct method mocks func(l *eventlog.Log, eid uint32, msg string) error = (*eventlog.Log).Info func(l *eventlog.Log, eid uint32, msg string) error = (*eventlog.Log).Error
&gt; Maybe now that we have -Z minimal-versions, it will be easy to add these checks to people's CI (or even on the crate publishing path), and we can enforce that what we write down is accurate. This seems like the best way forward here. Forcing everyone to use old versions of everything just so you can get more testing on them seems a bit wacko.
&gt; accept lower test coverage Yes, that seems like a reasonable thing to do :) I don't think 100% test coverage is a good thing to optimize for, because it means that the code you are testing and the code you are running in production is going to diverge. Plus, line coverage alone is pretty meaningless, path coverage is much more useful (and 100% path coverage is unattainable). All of that being said, I think variance for functions would make some code more reusable - and IMO help significantly with error handling. Because it becomes less problematic to return specific error types, that can carry details without needing type-assertions.
Thanks this is exactly what I've been looking for!
&gt;Yes, that seems like a reasonable thing to do :\) I don't think 100&amp;#37; test coverage is a good thing to optimize for, because it means that the code you are testing and the code you are running in production is going to diverge. Plus, line coverage alone is pretty meaningless, path coverage is much more useful \(and 100&amp;#37; path coverage is unattainable\). Statement coverage seems to be still useful in practice according to [https://youtu.be/NKEptA3KP08?t=14m25s](https://youtu.be/NKEptA3KP08?t=14m26s) I'm not sure why you think the code will diverge? Any examples? In my experience, it's exactly the opposite, just readability might get worse.
&gt; Meh; I'm guessing you are from jetbrains. Yes, I am working as a Developer Advocate for JetBrains, I'm not hiding this at all. &gt; I've heard more people have issues with Goland than vim or vscode. I don't have any metrics on this, but if you have any, please let us know. It would be great opportunity to see what we can improve. &gt; Not sure why people decided to downvote my comment; A wild guess would be because you just went off-topic, the comment wasn't helpful, and I can think of a few other reasons. &gt; I'm guessing it was you and your co-workers. While I can't speak for everyone here, you should probably consider that it's not just me and my colleagues watching this space. &gt; Not sure thats a good way to manage your brand. I'm trying to help out a person who has issues with the IDE/project setup. If you have any suggestions on how I/we can do better, please let us know. Thank you.
 rBackupStream, wBackupStream := io.Pipe() rUploadStream, wUploadStream := io.Pipe() done := make(chan struct{}) defer close(done) go DoBackup(rBackupStream, done) go DoUpload(rUploadStream, done) go func() { defer wBackupStream.Close() defer wUploadStream.Close() mw := io.MultiWriter(wBackupStream, wUploadStream) // Copy your data to multiwriter io.Copy(mw, data) } //await until job is done
Are you going to put it under a OSS license? Don't see a license file. I've been looking to write my own web framework on my own, but haven't found a suitable light framework to start as a base / inspiration. Looks good man!
That sounds awesome!
Glad to be some of use to you. I have added MIT license.
Check out https://github.com/disintegration/gift, that is higher level functionality you'd need to build on top of `image.Image`. For just changing format, you can use https://golang.org/pkg/image/png/#Encode , https://golang.org/pkg/image/jpeg/#Encode , etc after decoding with https://golang.org/pkg/image/#Decode .
Thats a good point \- the ideal workflow will go via following the necessary keywords in a commit message on merges/changes. But yes in the case where a patch needs to be triggered \(without any actual changes\) then the only way to do that would be with new dummy commit. Tbh I haven't tried Goreleaser's approach yet but its a really good point and an interesting tradeoff to consider. 
Wondering if golang:alpine docker image would be an easy choice!
You get an upvote for that my friend:(
Oughtn't affect Golang itself no matter how it'll be handled, since the golang github is just a mirror. 
It's not that simple, unfortunately. If someone wants to delete his/her Github account*, there seems to be currently no way to report issues on the project tracker. Just one example that comes to my mind. *: I would normally already have my Github account deleted. I did the same with my Skype account the day Microsoft announced the acquisition. But this time I'll postpone it and first decide where else to put my repos, properly announce that and delete the account only afterwards. I've also mailed golang-nuts with request for comments about this new situation, so I'm not ATM sure what will my next steps actually be. Not happy about this is the only thing I know for real.
It's mainly around not using it for passing values around. Other people also don't like how verbose using context is, saying it's like a virus in your code. I can see where they're coming from to an extent, but it's also extremely handy. My view on it is that it's incredibly helpful for handling cancellation and timeouts. It's very "Go", in that like errors, it's very explicit. Initially I hadn't realised that and didn't like context, but once I realised that it sort of clicked and I think it's great now. The values side of context is also useful, but I think you have to use it carefully. I only use context values for things that don't affect the logical flow of an application. In other words, for the most part, if some value isn't in context, it shouldn't break anything, and things should really behave normally even. People tend to "abuse" it though, and in the past moreso, people have put things like singleton services into request contexts to pass them to handlers and that sort of thing. Of course, that's completely unnecessary and horrible.
While `go bug` defaults to github, the [golang mailing lists](https://golang.org/project/) can be used as alternative. 
Provided someone nice copy pastes the report to the issue tracker. But yes, there's a way to do it.
Consider posting to the Go-Forum with the code-review tag. There are a lot of skilled people with great experience. You can also look at JustForFunc for code-reviews on others code: https://www.youtube.com/playlist?list=PL64wiCrrxh4Jisi7OcCJIUpguV_f5jGnZ
Please tell me when you find a viable alternative and which one it is :D
Correct me if I am wrong but Go's import\-path is formed from a URL of the repository and over the years, it had created a some form of dependency. I think this makes harder for Gopher to consider migrating to other platform. I think this incident also might affect vgo's implementation in terms of providing options to mapping one form of import\-path to another? I am just thinking out loud.
BitBucket is what I personally use.
Check gitlab
I started using gitlab for work and have slowly been transitioning to it at home as well
Why not move your repos but keep your account to participate in projects that stay on github? I have accounts on gitlab and bitbucket even though I don't host any project on either currently.
Here's a loose argument by contradiction: if middleware chains were made to solve exception handling, wouldn't it make more sense to pass a `handleIfNotNil func(error)` function alongside `next`? You could save yourself all the `if e != nil` boilerplate.
Definitely possible and will be/is still considered. However, so far I want to delete my Github account. That decision is not set in stone because it would not affect only me.
That was my first strategy, here. Unfortunately, I was having issues building vgo in Alpine, and then not having a clear-ish path for installing go package dependencies in the container for compilation. I would love it if I could use a throwaway alpine container as a build environment, but it seemed a bit more work than just compiling from MacOS where I already had dependency pipeline in place.
Nice read although I wont have much use of most of this. 
[anthonynsimon/bild: A collection of parallel image processing algorithms in pure Go](https://github.com/anthonynsimon/bild)
UPDATE ALL IMPORTS!!
Has Microsoft changed something regarding Github?
You can already use vanity import paths to point somewhere else.
It's not that easy as GtHub path of a repository may be used in various other libraries. I am sure it's possible to create a tool with mapping of original repo to a new URL and perform recursive retrieval and import rewriting on the fly. 
When doing dependency injection, how do people prefer passing along a large number of dependencies? I prefer using configuration structs instead of long function signatures. It's easier for me to see at the call site what each dependency is used for, especially when there are multiple of the same type.
Its not just you, in a similar position and so far from what I have seen given the priorities of the language... there are just no elegant solutions to potentially arbitrary json without what feels like reinventing the wheel.
No, just a bunch of FUD
You can override what it trys to pull from using git, either locally or globally on a system. For example you can say for anything [github.com](https://github.com) use [myprivaterepo.com](https://myprivaterepo.com) instead, then the rest of the url is tacked on.
Although the code is mirrored, the Go project uses Github for issues. 
&gt; Did Microsoft change something regarding Github? I don't know and I don't care - even when I expect them to destroy it in the long run. I don't have and I don't want to have any Microsoft controlled account anywhere, regardless of what they will do or will not do with Github.
I don't think there's a specific Go way. Anyway, I use docker containers together with docker-compose to simulate a real running system. 
Did you clear the database between runs?
Commenting to follow. Sorry I can't help!
To expand upon that, try running it with sqlite in memory if possible. People report docker having issues with disk I/O speed.
Yes, each run creates a new and empty sqlite database.
That's your choice. Like many choices it has consequences. The consequence is that you won't be able to report some bugs. It's not someone elses responsibility to make your fundamentalism convenient for you.
I've heard this for docker for mac which syncs the (bind-mounted) volumes between a linux vm and the mac host. Not sure if there are other disk I/O performance issues.
Gitlab has a good interface and much nicer work flow than github. But it's such a horrible beast to host it yourself. I've been peeking at [gogs](https://github.com/gogits/gogs) recently, not because of the microsoft thing, but because I want to host my own code. It looks promising, but it's a bit telling that its main development is not self hosted.
It sounds like it is being run on a Debian server which wouldn't have the same performance degradation as docker for Mac.
No problem, everyone likes a good perf debugging challenge :D For the future, Reddit has this save feature that'll, well, save posts in your account.
Huh, I really figured it was `musl`. Python code can be an order of magnitude slower when running on Alpine. /u/Willson50 made a good suggestion. Try running the DB purely in memory in both instances. Otherwise, try out a profiler. It's probably a syscall that's taking a long time.
Are you on OSX? If so you probably are running into a IO bottle neck with your DB because of the volume mount. One way you can address this is to change line 73 to be somewhere else in your docker file when you create the SQL lite file: &gt; db, err = sql.Open("sqlite3", "/var/db/dco.sqlite3") If you want to use /var/db you might have to ensure that exists first so you can add: &gt; RUN mkdir /var/db Right after you do FROM alpine:3.6
Disk I/O was the constraint! Amazing work, detective :) With `file=dco.sqlite3?mode=memory`, Docker can push ~2.9k req/sec. I knew there would be *some* disk I/O penalty for the abstraction, but I didn't know it'd be *this* huge. Oh well, lesson learnt (with numerical estimates for how much the real-world impact is!).
This is awesome! This gives me a really good base, thanks for the reply. I'm still learning, but i basically want to write these to an actual CSV file. I've gotten as far as csvfile, err := os.Create("asset_groups.csv") if err != nil { fmt.Println("Error:", err) return } defer csvfile.Close() if err := items.ToCSV(os.Stdout); err != nil { fmt.Println("error encoding to csv", err) return } But i'm sorta stuck actually getting the output to write to an actual csv \(i'm assuming using IO.Writer or something?
/u/Wil Docker's disk I/O was the bottle
I had something similar happen to a Go service in docker on kubernetes. It ended up that the resource constraints I'd placed on the container were too low and it was having to constantly GC between each method call
My mistake, it doesn't resize. I've used imgproxy before (see another comment), it worked really well. This one looks fun, it offers several algorithms for resizing: https://github.com/nfnt/resize
What do you mean by "stay around there forever"? How are you determining this?
It's awkward, but you can just leave it. You can see the reasoning as to why here: http://golang.org/cl/5491059 If you really want to though, you should be able to just close it yourself.
It is said in docs and on github that this channel is not closed : // Stop turns off a ticker. After Stop, no more ticks will be sent. // Stop does not close the channel, to prevent a read from the channel succeeding // incorrectly. If you do not close the channel it stays alive. Will garbage collector close such abandoned channel or I would have a memory/resources leak?
&gt;Are you on OSX? I'm running Debian 9.4. &gt;If so you probably are running into a IO bottle neck with your DB because of the volume mount. I tried measuring without a volume mount, and the performance didn't improve. However, I tried an in-memory sqlite3 database, and Docker was on par with the binary! So you were kinda right, it was I/O related, but not exactly volumes. Just general disk I/O on Docker (even on Linux) is pretty bad.
Do I understand correctly that such abandoned channels would be recycled by garbage collector automatically?
Try running your docker instance under [strace -T](http://man7.org/linux/man-pages/man1/strace.1.html) or [perf](https://perf.wiki.kernel.org/index.php/Main_Page).
Apparently it does :/ disk I/O was the bottleneck and switching to an in-memory database solved this. I can't even imagine how bad it'll be on a macOS server if Linux is this bad.
&gt; That's your choice. Like many choices it has consequences. The consequence is that you won't be able to report some bugs. It's not someone elses responsibility to make your fundamentalism convenient for you. Please remind where I'm blaming someone of anything or looking for anyone responsible of something. And your fundamentalism tag is based exactly on what?
channels don't need to be closed. Closing a channel is a type of send operation, it does no cleanup. 
What do you mean when you say the channel seems to say around forever? If you fear the channel will never be disposed unless it is closed, that's now how the Go GC works. Unless you have a goroutine still reading from/waiting for the channel, it is considered no longer in use and it will be garbage\-collected in due time. There is no need to close a channel unless you are relying on it being closed to stop something.
Makes sense. I was thinking it was due to the volume because it seems that your workdir is the same as the volume target where the sqlite file gets created. Glad to see that was sorted out based on /u/Willson50 suggestion. 
Yes.
There is also gitea thats great for using with raspi
Just a heads up, Reddit does have a save function so you can revisit things later - it's super handy.
It will eventually be garbage collected.
But is this the final answer? Does this mean "never put I/O heavy stuff in Docker"? Is it a Go-related issue? Is it an (go-)sqlite issue? The logical consequence would be to never put a database in Docker and when running in a Kubernetes environment to also not have the DB be managed by Docker.
Yes, I was afraid that it would be never disposed. I come from the C++ world and used to 'close'/free all the resources I acquire. So for me it was quite natural to close the channel. I see now that it is handled by GC. Nice. Do you know any good reading on GC internals and stuff? Thank you.
Good. Thank you for help.
I see now. Thanks for explanation.
I can confirm the disk I/O issues on docker for Mac. It actually stems from VirtualBox. We get the same issues with our Vagrant VMs. I wonder if they’re working on this. 
Thanks for help.
&gt; But is this the final answer? I think so; since the only difference between the two experiments (filesystem-wise) is Docker's abstractions. It can't be a (go-)sqlite issue because performance is much, much better when ran natively on the same SSD. Not sure if it's go related, since it's basically the same binary, but dockerised.
I guess you wouldn't dare to run it on Windows! ;\-\) I had a PHP test suite, running API tests within a docker\-compose environment, on Windows because of the resetting of the MySQL DB between tests it was 1 second/test, while on a Linux machine 25ms/test. :\-\) That's when I discovered the tmpfs config for the data dir. :\-D Magic! ;\-\)
Docker for mac doesn't use VirtualBox, and Vagrant is just an automation wrapper for different VM engines--it isn't a VM engine itself. Docker for mac uses its own virtual machine built from Mac's hyperkit APIs.
Run 'docker info' and find what your storage driver is. Perhaps there is an optimization that can be made there?
 Server Version: 18.03.1-ce Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true Note: this is on a DigitalOcean VPS.
That's backwards. FUD happens when Microsoft is _not_ in control of something important.
Just gotta send your `csvfile` in as the argument to `items.ToCSV`. Read the docs! The functions I wrote have godoc comments that explain this. :)