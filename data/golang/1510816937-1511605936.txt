 type Animal int64 func (a Animal) String() string { if a == 1 { return "This is a cat" } return "This is a dog" } const ( Cat = Animal(1) Dog = Animal(2) ) func main() { fmt.Println(Cat) // Prints "This is a cat" instead of "1" }
Thanks. So similar to what https://godoc.org/golang.org/x/tools/cmd/stringer generates?
I didn't know about that package at all, but yes.
Care to elaborate on that &gt; a pointer to a DLL outside of my Golang program bit?
The DLL I am looking to get the memory address of is of one inside the proccess csgo.exe I have elaborated my whole issue by comments in this pastebin.com link. https://pastebin.com/X7cE8GfJ The English language cannot express my appreciation for you taking your time with me. 
"The cost is doing the verification twice, though even on the largest codebases that is likely to only be a couple seconds' worth of work" `dep ensure` takes multiple minutes for us on a small codebase. Didn't know it's meant to be fast ....
I might misunderstand the approach, but the address spaces of separate processes are fully virtualized; I mean, each process gets some 0x0..0x7fffffffff (or so, 48 bit) address space and the address 0xdeadbeef in a process A has no bearing on the memory at the same address in a process B. I, for one, know of no possibility to somehow programmatically access the address space of B from A—except unless both of them explicitly use some sort of shared memory IPC (such as memory-mapped files etc).
From what I gather the output is meant to target projects where reducing runtime overhead is critical, i.e. projects that probably wouldn't consider implementing in Go to begin with. I could see this language being transpiled to Rust (Although Rust could wrap the C versions). Is it even possible in Go to bypass all the runtime checks that this project tries to avoid? My knowledge of low-level Go is not great. I guess it compile to Go asm...
Why do you think it's more idiomatic than pkg/errors? I don't feel `goerror.GoError` to be idiomatic at all. Also why it's lighter, what are you comparing? The pkg/errors is a drop-in replacement for the errors package, while yours is not.
A question and a tip. Question: In what aspects do you consider this package more "idiomatic" than `pkg/errors`? Or, to put it the other way round, what problems did you have with `pkg/errors` that made you come up with an alternative? And the tip: Add comments to the exported types and functions, to make the [`godoc.org` page](https://godoc.org/github.com/prasannavl/goerror) more useful. 
I've been told before by people that they've refused to use Go because errors by default didn't have stack traces, so I think it's interesting that you removed them, relative to `pgk/errors`. It's true that it's relatively expensive to get a stack trace when compared to doing nothing, but once something has broken, getting a report of how it broke so you can fix it is in my opinion more important than the little speed boost you get from reporting a less informative error. That said, `Callers` isn't super expensive. I've run games at 60 fps that were making thousands of log calls a minute (sorry I don't have a better estimate, this is a conservative one), all of them calling `Callers` to figure out what file they came from, and at one point in time I was worried that these calls were adding lag to the game, so I got rid of them all with a compilation flag. There was no discernible change in frame rate, when the rate was unlocked, up to 240 fps, by removing those log calls. I agree that having a way to combine errors together is something `pkg/errors` lacks, but I'd probably build upon `pkg/errors` instead of trying to replace it. It's good that you use the same `Cause()` function as it does, however.
It's lighter because, it's just a struct that holds things together and provides composition. It doesn't do expensive calls like `runtime.Callers` on each invocation - which `pkg/errors` does. PS: Your questions are already answered in the readme. Regarding the drop-in replacement - it actually is, except for the package name - Which I might change to `errors` after getting some valid feedback :)
&gt; on each invocation What if I want that call? Maybe better would be to make pkg/errors configurable instead?
&gt; I find taking stack traces along with errors to be harmful, and not idiomatic go. I stopped glancing at the README at that point. I don't know about your magical codebase, but a stack trace is a brilliant way to pinpoint where the error originated. This is especially important when working on large code bases or with third party packages. There are [so](https://sentry.io/welcome/) [many](https://airbrake.io/) [software](https://rollbar.com/) [solutions](https://firebase.google.com/products/crash/) [created](https://raygun.com/) [around](https://newrelic.com/) [this](https://www.datadoghq.com/) [simple](https://www.bugsnag.com/) [fact](http://try.crashlytics.com/). Maybe you are harmful?
Thanks for the tip. Yes, I just haven't got around to the docs yet. I would likely also be getting to it, after moving the package name to `errors` so it becomes a drop-in replacement. And why more idiomatic - because one of the idioms of Go is to keep things as simple as possible. And with respect to error handling, that translates to passing around lightweight errors - `pkg/errors` unfortunately isn't light (or rather it isn't errors in it's nimblest form). It does a full recording of the stack frame. And passing stack frame along feels more like dealing with exception traces. I'd like to see the idiom of error handling to be built around simple error types and codes (atleast that's what I gathered from the Go design philosophy, unless I'm mistaken). I've been using it a while internally, and has felt refreshing. I take stack traces only when I need to without other external helpers based on the errors.
I discovered the answer for my case from a friend of mine - tl;dr she said to use w32.ReadProccessMemory on the offsetted "pointer" address and it will get the underlying value. 
Not magical - rather a more thoughful design instead of mindless runtime stacks - In Instances like component or contextual boundaries - you can always just wrap it in a higher order function to take stack traces. I find simple composable errors with codes to be basic building block - not errors with expensive caller stacks. Caller stacks can always be wrapped in a block above. Would you really be happy if the standard library `fs` package recorded stack frames on every error to fs.Open, or f.Write? Contextual flexibility is important.
Deterministic performance/latency.
You can very easily just wrap the errors package to do so. :) That's what I like about having the most minimal blocks. You can compose. But `pkg/errors` forces you to. Making `pkg/errors` configurable would be breaking it's core, and frankly deviates from the minimal first philosophy - so I doubt that's a path forward.
First of all, thanks for the constructive feedback. :) &gt; There was no discernible change in frame rate, when the rate was unlocked, up to 240 fps, by removing those log calls. That's quite interesting. I'll try to do some actionable benchmarks when I get time next. That being said, as I've mentioned in the other comments: &gt; I find simple composable errors with codes to be basic building block - not errors with expensive caller stacks. Caller stacks can always be wrapped in a higher order functions. Also, with regard to the claim of simplicity - it is much simpler in the fact that all it really does is wrap your errors messages, and/or types and provides a way to compose them. It does nothing more, nothing less. I think a fair comparison would only be to compare GoError. Not the entire package - As `CodedError`, `HttpError` etc, are things just add a field or two to support the contextual use case. While there are many types, what they do internally is extremely simple. While `pkg/errors` obviously does significantly more. 
Well, all of this depends on the definition of "simple". From a user's point of view, `pkg/errors` already has a [very simple API](https://godoc.org/github.com/pkg/errors#pkg-index). It does embrace the Go idiom about errors being just values. But I understand that `pkg/errors` is not for everyone. There have been debates in the past about the right way to approach error handling, and I am not sure if any consensus has emerged from these debates. 
I do agree with you there, that these will essentially be debates with no conclusive consensus. **It's also for the same reason that I'm against basic building blocks taking opinionated approaches.** With `goerror` style handling, you can always have a block above it to do what `pkg/errors` does, and users can choose based on their needs, requirements, and philosophies. And `pkg/errors` is one of those that is targeted to be a fundamental building block, but makes the assumption that it knows best on your needs, or apparently you're just plain wrong. An unfortunate direction, that the threads also seems to be moving toward.
Indeed, `pkg/errors` may be biased towards a particular way of error handling, but nobody is forced to use this package if they don't agree with that way. I don't see the "you're just plain wrong" part. And in general, I don't think that there is such a thing as a completely neutral, unbiased, un-opinionated approach to do a particular task. Even the standard error handling in Go is not a neutral approach. I recently flipped open my old copy of "Clean Code", just to discover a section that rants about how bad returning errors as values is, and explains why exceptions are so much better. (Got me chuckle a bit.) Almost anything about software development is based on someone's opinion of how to do it best.
My impression is that they want to eventually replace all of the C libraries for file formats. libpng, libjpeg as examples. So the C is for portability, as pretty much every other programming language can link C libraries like the aforementioned ones and if that "C" library can guarantee safety from common vulnerabilities via Puffs, great :)
I concur - there's a lot of truth to what you're saying. However, on that note, I do have to say how I'm pleasantly surprised by modern languages like `Rust`, which moves closer and closer to unbiased neutral approaches. Both the language, and the community are extremely adaptive and accommodative. That is of course, is if you're like me and buy into the fundamental bias of how it's memory management works first ;) 
done. sorry, repo was published a bit earlier than I expected :)
The enthusiasm is great and all, but writing programs inside [XML](https://github.com/cheikhshift/momentum/blob/master/gos.gxml) to be transpiled later is pretty much the last thing that any programmer I know would want to do. Let alone the audience of Go programmers who generally shun any abstraction that isn't worth it's weight in gold.
For this, we don't commit the vendor changes until the last commit. We do the code reviews before that commit with the caveat that last commit has a very quick once over to verify it was only vendor changes.
Having not used dep yet, are you just referring to the version lock files? As for checking in vendor being "ugly," I'm reminded of "nobody likes Go's format, but everyone likes gofmt." I'm on the struggle-bus for understanding why you wouldn't want to check in your vendor directory (outside library packages). The benefits of checking in the vendor directory seem solid to me. The code can't disappear, versions can't get force changes that silently change the code without changing the version, you no longer have a network dependency when building in CI (assuming you have the code pulled down), and, as a potential benefit, you can CR dependency changes if you are inclined (which you usually should be).
the part of `dep ensure` that's slow isn't the verification part :) and we're working, slowly but surely, on the rest. https://github.com/golang/dep/blob/master/docs/FAQ.md#why-is-dep-slow
two other reasons beyond what's already been said that ppl avoid it: 1. repository bloat 2. if you can't guarantee that your project's dependers are using dep, then they may end up with nested vendor dirs, which can get very messy.
Stack traces are a necessity in languages with exceptions where a big chunk of code may be wrapped in try .. catch and exceptions tend to be rethrown. One quickly loses control over where exactly it occurred. In Go we check or generate errors on specific lines and one can immediately embed location of error into message without using reflection or generating stack traces. Location is known at compile time. I really wish we had a couple of "magic" constants like `__FILE__` and `__LINE__` in other languages. That would eliminate need in run-time stack traces for the most part.
I had hope that https://github.com/golang/go/issues/13504 would make it. But I guess not in this release now.
Nothing about `go dep` entering the toolchain. Is that not going to land in 1.10 anymore?
dep still has a ways to go.
From the `gofmt` changes: &gt; some complex three-index slice expressions previously formatted like x[i+1 : j:k] and now format with more consistent spacing: x[i+1 : j : k] TIL [three index slices](https://tip.golang.org/doc/go1.2#three_index).
Go does allow you to manipulate raw pointers with no checking via the unsafe package, but at that point you're just coding in C except with worse syntax and even less safety.
[removed]
Nested vendors can lead to the diamond dependency problem. At work, we've settled on "services vendor, libraries don't" to help with that. 
That was never realistic. Even if by some miracle they'd stop fiddling with what it does, it would need to be rewritten to actually go in the stdlib. I wouldn't hold my breath.
Ping the team in the CL and see if that will be considered or not. There are still CLs that are being merged / in flux.
I don't doubt your main point, but why would it need to be "rewritten" to be included in the stdlib? Reorganized and cleaned up, maybe.
@epiris, thank you! It is a helpful feedback - for now and future. &gt; Place test folders (mock_) should probably in a testdata dir. Done, [it is in the `dev` branch](https://github.com/didenko/fst/tree/dev) until a merge. &gt; Merge most of the project into 1-3 file / test pairs. Will consider. Go for Visual Code does not (maybe yet) support proper type tree browsing. Hence navigating long files is a nuisance. For now I organize files in a more granular fashion, so that file names provide a better hint of what is inside - instead of lumping logic together, like into a `file_util.go` &gt; The test coverage seems really light I was concerned about it and I agree with the importance of test coverage, especially as it is a part of value of these routines to begin with. I found that most of the not-covered code in this project is: * a very elementary error handling, like `return err` or logging * standard package calls, like `os.RemoveAll(...)` * a couple cases a path to the `cleanup()` code, which is tested otherwise If you do not mind to take a look I have [posted the coverage report](https://didenko.github.io/171116.fst.cover.html) - which execution paths would you add tests for? &gt; don’t want to be responsible for the security of people who rely on my packages, so I don’t host my repositories It is a good point indeed. For this publishing project my goals included to learn how vanity URLs work. So while the project is hosted on the github, there is indeed a redirector running on a free-tier Google App Engine instance - with their automatic SSL handling. The 65-line source code of the redirector is [published for public review](https://github.com/didenko/go.didenko.com). &gt; minimize potential issues by setting a jailed root That is interesting. By a jailed root do you refer to an OS-level integration with chroot or namespaces, or a specific Go feature I missed? Thank you again!
It is sad because cgo introduces additional pain points that are not present in an application that is entirely written in Go. Nobody thinks that Go is able to provide the most optimal performance possible.
&gt; I really wish we had a couple of "magic" constants like `__FILE__` and `__LINE__` in other languages. Is there any meaningful advantage to them being constants over simply looking them up with `runtime.Caller`? I struggle to imagine any scenario where it would make a real difference in the real world. The overhead isn't that significant and you can still resort to hard-coding/go generating the values if you somehow get stuck in some really performance sensitive error returning. It is not like you would choose Go in the first place if you need to eek out every last CPU cycle. 
I think the intent was to say it would need relocated to the stdlib under a new package namespace like golang.org/x/tools/cmd/dep instead of github.com/golang/dep.
Not sure what I was expecting, but I was hoping for more cool toys to play with in a 1.10 release.
[removed]
I've taken a look at it and find it very hard to navigate the code base. A lot of functionality is split across too many files. And because of that almost all functions are exported. 
Yes, runtime CPU overhead is small because errors mean something went wrong, which should be rare. However, the technique with constants would be tremendously useful for large volume logging/tracing.
The dependencies cannot legally enter the main repo just like that, even if they were welcome. https://godoc.org/github.com/golang/dep?import-graph&amp;hide=2
Finally a round function. Had to add this myself i was shocked that the math pkg does not have such a basic func
I think the docs need to have more guidance for when to use strings.Builder instead of bytes.Buffer. They seems pretty similar. 
There's no concept of "injecting" or "adding" generated code to an existing Go binary. You need to recompile the binary with the new code, which requires invoking the `go` compiler, terminating the existing process, and re-starting it.
**Edit:** The comment I replied to asked how the example in the release notes for a three index slice got `7 - 2` from the syntax [2:4:7] The capacity value is based on the source array/slice, meaning that since their source array has a capacity of `10` you are only allowed to use up to and including `10` as the max valid value. So when they use the value `7` it's saying that the capacity of the new slice would be the first 7 values of the source array/slice, but it's then adjusted for the origin, which in that case is `2`, so that's where they get the `7 - 2` from. In the example: var array [10]int slice := array[2:4:7] The source array has 10 values in it, the new slice includes indices `2` and `3` and the capacity is `7 - 2` because the `7` is adjusted for by the origin, which is `2` [0123456789] The source array indices [__2_4__7__] The values used in the slice syntax [2:4:7] [__^^______] The new slice contains these indices [2:4] [^-----^___] The capacity if it started from 0 [0:4:7] [__^---^___] The capacity when adjusting for the origin starting at 2 [2:4:7] I'm not sure if that helps or just made things more confusing.
If you want to load it from a running instance you may want to take a look at https://golang.org/pkg/plugin/ . In this case it looks like you should run `abigen`, drop the result in your source tree and then run `go build`.
In 2016: &gt; When asked what changes would most improve Go, users most commonly mentioned generics, package versioning, and dependency management. Other popular responses were GUIs, debugging, and error handling. In 2017, you're going to see the same responses. The only progress on these issues have been things the community has driven. Things like delve (from the community) and dep (also from the community). I would love to see the core team take ownership of something the community wants.
So I should run `go build -buildmode=plugin -o out/contract.so in/contract.go` in my go code using cmd.Exec like I did abigen to generate the contract.go file, and then I can use plugin like `plug, err := plugin.Open('out/contract.so')` from within my running instance, with the methods available on my `plug` var, like `plug.Method()` as long as `Method()` is exported from my original .go file. Am I on the right track? edit: Okay, so I think I need to use `m, err := plug.Lookup('Method')` first and then I have the `m` var I can type-check against to make sure I have a function or interface or whatever.
it's the reverse - nested vendors _solves_ the diamond dependency problem. unfortunately, it solves it in a way that can create [intractable type errors](https://groups.google.com/d/msg/golang-nuts/AnMr9NL6dtc/UnyUUKcMCAAJ) and duplicate global state. dep strips nested vendor directories, which makes it fine to commit vendor for either "libs" or "apps," at your discretion, as long as your dependers use dep. but, that means the diamond dependency problem is possible. dep's approach to addressing that is a SAT-equivalent solver. more on the tradeoffs involved in algorithm selection can be found in [my article](https://medium.com/@sdboyer/so-you-want-to-write-a-package-manager-4ae9c17d9527) or [Russ's](https://research.swtch.com/version-sat).
Not the downvoter, but you’re being downvoted because there is literally plug-in support in the standard library: https://golang.org/pkg/plugin/ (It’s not great yet, and comes with a ton of caveats, but it does exist). 
Cool, if it works for you that's great. I'm happy to be able to build from the lock files. Network is cheap (to a point) and you can always cache if needed. I just don't find checking in vendor to clean. Too many times I've seen vendored code is patched locally, but not upstream. This creates a situation where nobody can update a package because there are numerous changes in vendor that haven't really been tested. That's just me though, and whatever works for you is up to you.
Perhaps, but I think it's pretty straightforward. If you want something that implements `io.Reader` and `io.Writer` and is backed by RAM, you want a `bytes.Buffer`. If you want to build a string for, for example, returning from a `fmt.Stringer` implementation, you want a `strings.Builder`. I'm actually quite interested in this. I use `bytes.Buffer` for this all the time, but knowing that it had to do a copy afterwards always bugged me. I guess I could have just done the conversion myself with something like `tmp := buf.Bytes(); *(*string)(unsafe.Pointer(&amp;tmp))`, but this is quite a bit cleaner.
Exactly!
Puffs currently generates C code. Generating Go code (with or without package unsafe) is a long term goal (as per https://github.com/google/puffs/blob/master/doc/roadmap.md) but in the short term, the Puffs language is still changing week to week, and with N compilation targets, changing the language is harder the larger N is. We generate C code to provide safer GIF, PNG, etc. implementations, without giving up speed. We will generate Go code to provide faster GIF, PNG, etc. implementations, without giving up safety. dgryski linked to the github repo but the announcement (https://groups.google.com/forum/#!topic/puffslang/2z61mNTAMns/discussion) mentions some current Go benchmark numbers (compared to C). But in the short term, we'll generate only C.
Yeah, that'd be nice. :-)
I managed to get code injected to an existing Go binary within an hour of posting this topic. I appreciate you posting regardless, but if you don't know your answer is correct and phrase it like an absolute, then your comment hurts more than it helps.
Could someone explain the "filtering without allocating" point? I'm not sure if I follow. `b` is still allocated, isn't it?
Peter is indeed correct, but perhaps may have misinterpreted your intentions. I think the terminology used here may be confusing. Perhaps you mean you have recompiled to dynamically load a library (binary) during run-time?
Ah, local changes. That is a fantastic point. Thanks!
We need debugging/debugger to be first class citizen. I'm afraid to use at work and then have colleagues complaining that debugging is far behind other languages.
Umm..you didn't post the struct for alerts.Alert and can you post a minimal repro case?
I have edited the code above, `alerts.Alert
Thanks. I'd admitted that I didn't try your code but I have a better understanding of it now. I found one thread on stackoverflow that seems to suggest that it's not possible without a workaround but I'll keep looking. https://stackoverflow.com/questions/26039580/how-to-use-interface-type-as-a-model-in-mgo-go
Glad to see Russ Cox came to his senses. ~5 years ago he was of the opinion that rounding isn't useful enough to be in the standard library: &gt; Floating point numbers don't have digits. The bar for being useful needs to be pretty high to be in the Go math package. We accepted most of what's in the C library but we're not going to take all the routines from other libraries. The Javascript round is a 1-liner: int(f+0.5). &gt; &gt; WONTFIX https://github.com/golang/go/issues/4594 The Riemann zeta function made it to the standard library, but not rounding. How many of you have used the zeta?
Put common types in a third package and then have the function in the plugin return that. If you want to be able to use a type defined by the plugin, put an interface in the third package and have the plugin-defined type implement it. For example: ```go package api type Example interface { Something(int) error } ``` ```go package callee func InitPlugin() Example { return &amp;exampleImpl{} } ``` ```go package main import ( "api" "plugin" ) func main() { p, _ := plugin.Open("callee.so") ip, _ := p.Lookup("InitPlugin") ex := ip.(func() Example) err := ex.Something(3) if err != nil { panic(err) } } ```
Wonder how many years it would take for `min` and `max`
Already in there https://golang.org/pkg/math/#Max
!isbot perrycohen I demand at least a vaguely witty reply.
[Original thread](https://www.reddit.com/r/golang/comments/7d54vq/how_do_i_get_the_underlying_value_on_a/) (to avoid double effort for suggestions already given) What type of data is behind that pointer? In general, you need to convert the pointer to the desired type, in order to get a typed value back. So if `jesus` points to an `int64`, this should get the value back: fmt.Println(*(*int64)(jesus)) 
You are right about the plugin option, but this still requires building the plugin; you cannot have a Go binary execute Go *source* code on the fly. Also worth noting is that, at least in its current state, the `plugin` package allows loading a plugin but not unloading it again. So plugins are probably not the best way of injecting new code on a frequent basis (which, as I understand it, is what the OP wants to do), as they will accumulate over time until the binary gets restarted.
&gt; Go was never designed for embedded applications, specially when executing on environments with severe memory restrictions such as many microcontrollers. Apologies if this is a stupid question, but how does transpiling to C++ make Go more "embeddable"? Especially when considering that Go has a non-trivial runtime, including a garbage collector and support for multithreading. 
I guess that most math libraries are optimized for speed (think data science/machine learning), hence the common lack of support for `math.big`.
It turned out I do a lot of work with parsing, thus the main thing I lack is proper algebraic/variance typing support.
Depends on the embedded platform. Gomoku isn't targetting 8-bit microcontrollers; it's targetting the 32-bit ones, with reasonably fast CPUs (over 40MHz, sometimes with dual cores running at over 100MHz), and a few hundred kilobytes of RAM and a megabyte or so of ROM. For instance, it's possible to run JavaScript with zephyr.js, which also has a non-trivial runtime and garbage collector. Zephyr also has threads and all the basic building blocks necessary to build Go's primitives on top of, and it's the embedded operating system Gomoku is targeting first. (Linux will be supported as well mostly for debugging reasons.) The standard template library will most likely be used at first to support the Gomoku runtime, but it'll eventually be ditched for something that works better on more limited platforms. Also, the Go standard library won't be used as is on embedded devices; a new one will most likely have to be written.
[removed]
We clone all of our dependencies and use a shell script to setup a Go workspace using the appropriate git commands. This is super simple and rock solid. This simple approach works because the Go development tools that we use don't care one wit about how the workspace was constructed. The script is checked into our repo. We update our git clones and the shell script as needed.
Why did you disable issues? Anyway, when you have a sec, would you mind fixing my name? :) &gt; Fork from Matt Hole
We're using [Glide](https://github.com/Masterminds/glide) with a carefully-constructed Makefile.
So... I was using glide and was happy with it until a couple days ago, when I ran into this maddeningly annoying bug with Protobuf and vendoring (if your vendored version doesn't match the version that generated the Go code from your .proto files, you are screwed... even worse: it took me *hours* to figure out what the hell was going on.) I just switched the project to [Virtualgo](github.com/GetStream/vg) which works in a similar way to a Python virtualenv and provides somewhat better isolation for your project. I'm pretty happy with it so far, it allows me to install binaries from my "vendored" libraries, and uses `dep` for dependency management.
Just use dep. It works fine :)
&gt; there don't seem to be "production ready" dependency management tools available. No, you confuse this with "there are no *officially blessed* dependency management tools available." Having worked through this, I'd put my 2 ¢: * Here at my $dayjob we're using `govendor` because we vendor all the dependencies to not be bitten by network outages or political correctness outbreaks of lunatics at that popular Git hosting service etc which can suddenly make many of your dependencies unavailable. * The `dep` tool *is* an officially-blessed one, finally. Supposedly it's not 100% polished, but it * Reportedly works just fine for people. * Is scheduled to be eventually integrated under the `go` tool umbrella. My personal opinion is to just pick *any random* vendoring tool — be it `glide`, `govendor`or whatnot and use it until you * Better understand where the chosen tool sucks. * Find a better alternative, if any. Thinking too much about such things up-front is fruitless because it's exactly like with performance optimizations: you *can* do certain estimations before actually writing code, but only profiling it under a real workload is able to show you where the bottlenecks are.
I evaluated many active vendoring tools by vendoring some big projects like docker, and `govendor` is the mature one. People at hashicorp use it as well. 
Same here. At my $dayjob we also switched to govendor after using Godep for some time. Godep was OKish, but it had some issues and the workflow was a little annoying. So we evaluated, and actually used for some time, different vendoring tools. govendor seemed to be the most sane choice back then so we stuck with it. This was before go dep and the official vendor support existed. Since go dep was announced we keep an close eye on it and will probably switch some day, but so far it didn't seem to be mature enough (the last time we tried we immediately hit a critical bug).
You should use `dep` unless you have a good reason not to. It is going to be the official tool, the `Gopkg.toml` format is locked, and the command line interface is mostly locked. We've been using it for months in production environments. Instead of `npm install package@version` you do `dep ensure --add package@version` (or if you already use the import in your code, just `dep ensure` will pick it up). Don't fret - the Go dependency problem is almost solved. Now we just need to convince everyone to use semantic versioning and push their tags to GitHub. That's not as easy to fix!
Are you sure you want them to be on different ports? You can just host both on :443: autocert.NewListener("api1.example.com", "api2.example.com") and deal with the different hostnames in your handlers. But the post on go-nuts is right - autocert won't help you if need to work outside of the limitations of the http-01 challenge.
you could use the default logger with a few flags to get the full path to the file and line number. &gt; import("log") &gt;Log = log.New(os.Stderr, "", log.LstdFlags|log.Llongfile) Log.Println("Hello world") I hope this is what you wanted.
What's next? This comment is a perfect example of a big issue in our community: everyone expects the Go Team to do something. How about we, the Go Community, do something for them and provide a debugger? Or a package manager? Should the Go Team take ownership of other projects as well? What does it mean for our community? That we are a bunch of freeloaders? A bunch people that can do anything more complex? If that's the case then Go will not survive the test of time.
Then contribute to delve or Go to make the debugging experience better.
Why?
Alright, you've convinced me. I'll just use dep. But yeah, I'm a little worried about the whole lack of tags thing. I've already seen a couple libraries that don't use them at all and just push stuff to master. I suppose I could always fork at a certain commit and then create my own tag to get around that issue.
oops... I'm terrible sorry! it's done.
&gt; There are no substantive changes to the language. love it
Some config files written in YAML and I just don't want to write config struct by hand.
[removed]
Those two different processes with different release timelines. I just simplified for brevity. Thanks :)
You don't need to do all that. Dep has fairly sane behavior for libraries without any tags. It will start you out with the latest version, but it is smart enough to never update the version of a dependency unless you explicitly ask it to or some other dependency specifically requires it to. So you can still use untagged repositories with a reasonable amount of confidence as long as you check in your lockfile. If you're paranoid, just review any changes dep makes to the lockfile when you check them in. The only case that is particularly problematic is when a library used to tag versions a long time ago but hasn't tagged anything recently. Then dep's default behaviour of using the latest tagged release is generally not what you want and can be changed to behave as described above by adding a `branch = "master"` constraint. In the very worst case, you can always manually pin to a specific git commit, but most of the time, that's unnecessary and harmful in the long run. Learn to stop worrying and love the lockfile.
I thought it was always going to just be `dep`? Not `go dep`?
Being employed as a full-time Go programmer since 2010, I used a debugger a couple of times with Go, but not in the last 5+ years, I think.
TL;DR: Like most other package managers, dep uses a lock file to lock versions once they're retrieved the first time. Subsequent installs will install that same version.
Some good changes here. I'm wondering about this coverage stuff though; will it also show coverage info when you're looking at a file? (i.e. will it highlight covered / uncovered lines?)
Honestly, I read the blog and your comment and still didn't understand it, but it's early, I should read it later again. 
So it depends on your exact use case, but 99 times out of 100, you'll be better off compiling and spinning up your code into a separate process on the fly and then using some kind of [standard](https://golang.org/pkg/net/rpc/) RPC [library](https://grpc.io) or [framework](https://github.com/hashicorp/go-plugin). The plugin package has a ton of additional complexity and disadvantages when compared to separate binaries and RPC. I strongly recommend checking out [this video](https://youtu.be/x-LhC-J2Vbk) that explains when it would make sense to use each of the various build modes including plugin.
&gt; That we are a bunch of freeloaders? So expecting the language developers to provide basic tooling (and yes, a debugger is tooling 101) is freeloading now? &gt; Should the Go Team take ownership of other projects as well? What does it mean for our community? A bunch people that can't do anything more complex? From last years survey, the top 3 requests were generics, package versioning, and dependency management. Of these, generics and package versioning simply can't be done in a third party library (generics, because it needs compiler support and versioning, because it needs to play well with `go get`) and dependency management is being worked on by, surprise surprise, the community.
And finally my bug will be fixed
&gt; So expecting the language developers to provide basic tooling (and yes, a debugger is tooling 101) is freeloading now? Yes. &gt; Of these, generics and package versioning simply can't be done in a third party library (generics, because it needs compiler support and versioning, because it needs to play well with go get) False. Only generics is a language change. Versioning / dependency management is not a language concern. The fact that you conflate ` go get ` requirements with the greater topic shows your lack of understanding of the problem space.
Thanks for explaining this, and also for considering my question worth adding to the FAQ. So you don't target 8-bit microcontrollers? Now that's disappointing! How would I then ever get a Go app into my [Digispark](https://appliedgo.net/digispark)? Just kidding. But still, cramming a Go runtime (plus the actual space for the app to run) into a few hundred KB of RAM seems quite ambitious, as well as rewriting the stdlib completely. I guess that's quite a couple of person-years of work until we'll see a 1.0... 
&gt; Versioning / dependency management is not a language concern. Versioning and dependency management are two separate things. The language can choose to support versioned imports (especially since import paths are already based on URLs), regardless of what dependency management tool is being used (if any). &gt; The fact that you conflate go get requirements with the greater topic shows your lack of understanding of the problem space. It only shows my disagreement with your position.
I wonder if a slightly different explanation would help. `slice[2:4]` means take a slice of some source array/slice from index `2` up to but not including index `4`. So it's a half open range `[2, 4)`. slice[2:4:7] means the same as above, so, take a slice of data that is the half open range `[2, 4)`, but this time also set the capacity from index `2` up to and not including index `7`. So it's a half open range `[2, 7)`. In both cases `2` is the starting index, and it uses the 2nd index (in this case `4`) as the position of the end of the data to slice, and it uses the 3rd index (in this case `7`) as the position to use for the capacity. If you ignore the `4` and think of it as `slice[2:x:7]` then you can see that the range `[2, 7)` is `5` indices (or `7 - 2`). So: var array [10]int slice := array[2:4:7] fmt.Println(len(slice), cap(slice)) // Prints "2 5"
the hi-res of this print in [white](https://github.com/jstpcs/lnxpcs/blob/13623317b4de9aa34a5f53f6dc36717a92a213f8/cards/classic/golang-card.png) and in [black](https://github.com/jstpcs/lnxpcs/blob/13623317b4de9aa34a5f53f6dc36717a92a213f8/cards/black/golang-card-black.png) colors. all the other [cards](https://github.com/jstpcs/lnxpcs/tree/master/cards). the github [repo](https://github.com/jstpcs/lnxpcs) with all my pics (mainly related to linux)
&gt; The language can choose to support versioned imports (especially since import paths are already based on URLs) False, https://golang.org/ref/spec does not provide any such reference about import paths being based on URLs. Please provide the language specifications which state that import paths are based on URLs. &gt; It only shows my disagreement with your position. Let's agree to disagree :)
Doesn't work on integers. Supports only pair of values. Doesn't support passing slice It is fucking awful.
&gt; False, https://golang.org/ref/spec does not provide any such reference about import paths being based on URLs. &gt; &gt; Please provide the language specifications which state that import paths are based on URLs. Nice strawman. I didn't say it was specced like that, simply that it's based on the URL. Or do you mean that `import "github.com/foo/bar"` isn't based on the URL of that repo?
&gt; Nice strawman. I didn't say it was specced like that, simply that it's based on the URL. Or do you mean that ` import "github.com/foo/bar" ` isn't based on the URL of that repo? Yes. It's not. It looks like a url but it's not. Furthermore ` import "turbo" ` is not based on an URL import. I rest my case. 
Sick! It should be possible to create a card game with these.. which rules would you create? 
&gt; Yes. It's not. It looks like a url but it's not. It looks like a URL, because it is *based on* the URL of that repo. &gt; Furthermore import "turbo" is not based on an URL import. I know. So? `github.com/foo/bar` is still based on a URL. 
I still use glide because it works in the situation where I am in a limited proxy environment and part of my dependencies are internal gitlab repos that don't use a proxy and some are external that use the proxy. I tried to switch to dep and it basically doesn't work for me in this situation. I was given reasons related to how it treats the source vs name, etc. Basically I couldn't get it to work in a mixed proxy environments and gave up and stuck with glide. At least with glide I can specify all the information it requires for the internal repos so that it doesn't complain about them and uses the proxy properly for the github deps. 
Nice work! I like the little details everywhere.
This is actually sick. Well done all round!
Its growing on me. 
Same here. I work full time in Go for over two years, done a lot of various projects and never really felt a need for debugger.
And also current status says it's ready for production use: https://github.com/golang/dep#current-status
&gt; I'm wondering about this coverage stuff though; will it also show coverage info when you're looking at a file? (i.e. will it highlight covered / uncovered lines?) Yes, it can already do this. The changes done in Go 1.10 will further enable more use-cases to be displayed without the IDE or the users having to perform a lot of operations.
Wow. Impressive work.
glad that you like it.
thanks for your kind words.
The details are not the details. They make the design. - Charles Eames 
i was asked several times about a deck of cards, but now i just create pics in this style. maybe one day it will be a game, anyway i'm always open to ideas.
Sorry, I mean can it do it within the IDE, rather than looking at a HTML coverage report for example. Can GoLand already do that?
So basically, it takes the values at 2 and 3, and the remaining 3 are empty/nil?
Wonder if you’re allowed to sell these on T-shirts, I’d buy one or two. 
Great, btw the super user one is my fav, the combination of details it's just purrfect 
Got the cron one hanging at the office, love your work!
Okay so in the end a password isn't even necessary lol. Good job on the website by the way, I'm looking forward for some new content!
I loved it! Really great job! I want a lot of shirts now… But I live in Brazil… ;.;
the links to ready shirts for all my pics are in repos [readme](https://github.com/jstpcs/lnxpcs) file. or you can browse the [site](https://www.linux.pictures/), under the every image on the right there are links to ready shirts and github for hi-res. also i really don't mind if you get the hi-res and make a tee yourself.
the tees are shipped worldwide, you can use the [links](https://github.com/jstpcs/lnxpcs) in repo's readmy, but i really don't mind if you get the hi-res from github and print the shirts at the nearest location in brazil for you and for your friends. if you have some troubles with images or need bigger ones, just pm me.
thanks a lot!
Slices in Go comprise of three values: the location (pointer to the first index), the length and the capacity. The capacity is the actual memory length the slice has occupied (like in C), but only part of it is initiated; up to the slice's length. Two indices set start and length, three indices set start, length and capacity.
So you don't need to do reallocations every time when you append.
Same here indeed: we picked `govendor` when `dep` was in its infancy and might consider switching to `dep` eventually. But as of now this would not buy as anything.
I love Liz Rice's '... from scratch' talks. She always manages to get complex concepts across in an entertaining way within a very short time. Fantastic!
Yes, as I said, the IDE can do that as part of the basic functionality: https://www.youtube.com/watch?v=L5EDgJ5Pk2A
I was going to request a black one, but you have it here. thanks!
Gentoo should be a [hand drawing itself](https://upload.wikimedia.org/wikipedia/en/b/ba/DrawingHands.jpg) / because all that time spent recompiling itself
Beautiful!
you are welcome!
great idea!
This was easily the best talk of this year's dotGo for me. Speaking to other attendees after the event, it also seems like a common sentiment.
[removed]
Rather have a C/C++ to Go compiler. Having a helluva time trying to learn Go.
I'm surprised that Glide is being used tbh. The first thing I did when I wanted to start to manage my dependencies was try glide and I immediately stumbled across a bug that prevented me from updating the packages to the latest version. If it can't do something as basic as this, well I'm not going to use it.
The idea is just to use the C++ as an assembly language. I'm also having a good time learning Go, precisely because I'm having to learn a lot of the details.
I think you mean function overloading.
https://github.com/pkg/math
Gomoku is my third attempt at making a Go compiler for embedded devices. The first two attempts were precisely targetting 8-bit microcontrollers. I got some things working, but never enough to make a release. Even goroutines are possible (by converting them to state machines and each one not having a dedicated stack) on these devices. Maybe after Gomoku is capable of running a hello, world program. :)
People are downvoting you. It seems you have hit the raw nerve. Considering the angry crowd when Caddy developer tried to make some money out of their hard work. Now they may not be most tactful in their methods but crowd response showed it is mostly free loaders who would not support any project with time or money but by a raging self entitlement.
I've seen these cards posted all over the place and they never fail to impress me, awesome work!
Sure her talk was amazing, as always she is. I am waiting for Sameer Ajmani's &amp; Fransesc's talks. How were those ?
&gt; so we should all volunteer our time to do their work for them. Their work? Google has whole lot of paid engineers who do their work and lot of time give their work to open source community. Since when my demands for features which I do not pay for becomes Google's or any other companies work?
&gt; Google has whole lot of paid engineers who do their work and lot of time give their work to open source community. Ok? Not sure how this relates to my comment. &gt; Since when my demands for features which I do not pay for becomes Google's or any other companies work? It's not "my demand" when I say debuggers for a language are "tooling 101". I'm not *demanding* anything. The Go developers ***asked the community*** what is missing, and one of the big items in the community response was debugging. Seriously, look at the responses from the last survey: &gt; generics, package versioning, dependency management, GUIs, debugging, and error handling To my knowledge, *not a single one* of these items is being worked on by the Go team. Google has the resources (financial and otherwise) to change that. That's all I'm saying.
To be fair about the question if there's any missing libraries that we'll like to see, a whole bunch of libraries already exists for my current need but having them in the standard library would guarantee that they are stable, well coded, well supported, and no crazy license. Things like a uuid package, toml parser, yaml parser... On the other hand, the go team won't do that for the reason that libraries already exists and it would mean more work for them for no direct gain.
One way could be on request check the database “session_expiry” - if it’s passed then expire the token and redirect. 
If you're using it as a mechanism for identity, have you considered JWT? There are libraries for that, and it's a known standard that you can find advice about, plus expiry is built in to most implementations. There might be reasons not to - such as you're storing very mutable information in your sessions, or large data, but you could still build identity on that standard.
No mid-stack inlining yet?
&gt;bytes &gt; &gt; The Fields, FieldsFunc, Split, and SplitAfter each already returned slices pointing into the same underlying array as its input. Go 1.10 changes each of the returned subslices to have capacity equal to its length, so that appending to a subslice will not overwrite adjacent data in the original input. Not sure if this will break any existing code that relies on this behavior, but I think it's a good change.
Easy said than done. But I have contributed to vscode's plugin already. And also it's not the point, the point is that I believe that golang would be even more successful if the debugging/debugger was one of the core developers' concern.
I love the Arch calendar, I might have to order one for my office. How hard would it be to auto-generate a new calendar each year with a script? If you haven't already done it, I might take a crack at it.
Nice! You can get custom decks made up at (among others a quick google turned up) https://legendsplayingcards.com/ (though there's a MOQ of 1000)
I, after 2 years of golang (non-full time), also can live without using the debugger every time. What I mean is that I believe that debugging/debugger is one entry barrier for people who are starting.
FYI `log` package uses the same `runtime.Caller` to figure out file and line.
&gt; Easy said than done. I agree :) &gt; But I have contributed to vscode's plugin already Congratulations! I have a few small contributions to delve / GoLand / (former open-source Go plugin for IntelliJ) myself. And I'm trying to help the newbies learn as much as possible to that the more people knowing Go, the better chances we have to get someone to contribute to these areas. &gt; the point is that I believe that golang would be even more successful if the debugging/debugger was one of the core developers' concern. Debugging IS a concern for the Go team. I've personally spoke with Russ Cox and Sameer Ajmani at GopherCon and dotGo about this and debugging is a big topic for the Go team. Just look at the improvements between Go 1.8 and Go 1.9. Same was done for Go 1.10 to further help the debuggers work with Go. What people seem to want is the Go team to actually own the debugger, which I don't think they should do. The Go team should focus on the compiler giving any debugger all the information it needs to do its job. Have a look at this issue for example: https://golang.org/issues/21678 which is critical to have in order to improve the debugging experience. It shows how hard it actually is to get things that seem trivial done and the amount of effort required to do them. There are also a number of other issues under the Debugging label which need to be fixed and a bunch of them that have been fixed already: https://github.com/golang/go/labels/Debugging But as I said, the Go Team or the Delve can't do this alone and we should stop complaining about the debugging experience for Go and organize / contribute to them to make this a better experience for everyone.
&gt; To my knowledge, not a single one of these items is being worked on by the Go team. Google has the resources (financial and otherwise) to change that. That's all I'm saying. Please have a look at: https://github.com/golang/go/labels/Debugging and see for your self about the state of debugging for Go with relation to the Go team. And all the work done in Go 1.9 for it and now in Go 1.10. As for the others, except for generics, nothing else needs to be addressed by the Go Team, that's something that the community should be mature enough to handle it.
&gt; It is going to be the official tool, Is this true? So far everything I heard from core team members has been to shy away from blessing this as the official. &gt; Now we just need to convince everyone to use semantic versioning and push their tags to GitHub. I think a public package repository solves this similar to npm. Is that idea still being floated around? 
i will think about auto generation for next year
Are there no good opencv bindings in Go ? Seems like a pretty low hanging fruit. EDIT: Found this - https://github.com/hybridgroup/gocv. Its a bit hard to google it. 
thanks, i hope that one day i have enough cards
thank you
Come on Florin. You know full well the community has already provided a debugger in Delve. The community also has like 50 different efforts to provide a package manager. It seems like go dep is going to win because Sam is doing amazing and it’s his sheer force of will to make Go suck less. I’m not sure why you’d call the community freeloaders when basic platform features are missing from Go that are literally in every other major language platform. The fact of the matter is that the Google team seems to only work on things important to Google. Fine, but this means the community suffers and people, especially enterprise will move on to more mature platforms. 
[removed]
Very nice! Kudos! Really like your art style.
Go on an 8-bit mc with goroutines! Now that's indeed impressive. You have a point with regard to the stdlib. But still it seems there is quite some work ahead. Unfortunately I am not able to contribute to the project.
Go works well on ARM in terms of functionality but if you care about performance especially for https servers you may want to wait a bit. There are multiple assembly improvements coming from the ARM developers themselves (based on the CLs I've seen) that should make it into the Go 1.11 release. I've seen multiple ones on the crypto front which has been a sore point in terms of TLS performance. Cloudflare had a good blog post about it last week as they are evaluating the use of ARM servers instead of amd64 ones All that said I'm definitely looking into tinkering with Go on ARM as well. Got it installed on my dragonboard 410c without problems :)
Yeah, all the options suck to be honest. One of the most annoying things is having to keep your source code in the GOPATH to begin with. I hoped `dep` would fix that, but nah. I literally can't think of any other language that forces your code to live in a particular directory. I can't think of any other language that forces you to do that. Vendoring only solves half of the problem (keeping your versions separate from the system's) but it doesn't fix the namespacing issue.
This is awesome!!
i tried once with cc license and when i found that my pics where sold on shirts on one of online shops, i asked the administrators to remove the pics without any penalties to the person that uploaded it. as a proof that the works where mine, i provided the links to github, but i was requested to fill and sign 6 different papers. it was needed only to to open an dispute. i make the pics as a small hobby for relax, i don't make my living from it, so i decided to distribute it as is. most people respect the work, but those that don't can be stopped by any license. what's more, i'm not a professional artist and very often purchase some elements from graphic stock (for example when i have an idea but have not enough skills to implement it).
Having read your comment, I begin to wonder if there’s little trouble in delaying ARM adoption until these improvements are released. Doesn’t seem to be much to worry in development, considering your code gets built for a target architecture. If there’s no additional hurdles to jump, then adopting ARM seems to be straightforward at the build stage. This also makes me eager to see future mobile and embedded applications written in Go. Open-source projects like runc and Kubernetes prove a lot about what is possible, and I believe Gophers will chew through the levels of complexity present in app development. I saw a GUI library for Go that leveraged HTML and stylesheet descriptions not too long ago! I’ll look into the Change Lists concerning future releases of Go. Cheers!
It's already odd for me that your code needs to live in a workspace but I guess the benefit is that I don't have to desperately try to remember where I saved my project, it's always under GOPATH.
[removed]
Yes, exactly. My intention was just to get a dynamically created .go's functions, variables, and structs available to me. I see now I need to package my structs outside in a shared package!
In a situation where I have a Go service dispatching workers onto jobs from RabbitMQ and dynamically using that `abigen` function to make my .go files - what is the best way to recompile on-the-fly to load that code in, without stopping my numerous other workers who are doing something similar? They will need to be doing this task many, many times in my app. This "bouncing" you mentioned where it's trivial to bounce a separate process to an updated version sounds very confusing to me, if you meant that I can do it dynamically from within my code. I'm basically attempting proof of concepts here to see what works, and can see that this plugin / reflection method is going to cause many headaches...
Beautiful work!
That was badass, lowlevel and from scratch... awesome
Include the creation time in the session key and check before accepting one. Issue new keys periodically.
This looks good - can I ask you one more question? My dynamically created .go file requires me to get that struct, DadToken, which will be dynamically named. The struct looks like this: type DadCoin struct { DadCoinCaller // Read-only binding to the contract DadCoinTransactor // Write-only binding to the contract } // DadCoinCaller is an auto generated read-only Go binding around an Ethereum contract. type DadCoinCaller struct { contract *bind.BoundContract // Generic contract wrapper for the low level calls } // DadCoinTransactor is an auto generated write-only Go binding around an Ethereum contract. type DadCoinTransactor struct { contract *bind.BoundContract // Generic contract wrapper for the low level calls } I obviously won't be able to make an interface with DadcoinCaller and Transactor in my shared library, and the Caller/Transactor each have the same parameter - a contract *bind.BoundContract. These are NOT dynamic and will always be the same, it is simply the name of the Structs that will change. How can I make my shared library interface implement this? 
Image processing is costly operation. I took fast vips image processing library and write a simple program which reads a small 223×198px² image (10.2Kb) into the memory, then decode for 1 second in a loop and accumulate image average values in a process. It took about 161.000 operations per that second. /* compile with * * gcc -Wall vipsavg.c `pkg-config vips --cflags --libs` */ #include &lt;stdio.h&gt; #include &lt;vips/vips.h&gt; #include &lt;cstdlib&gt; #include &lt;unistd.h&gt; #include &lt;thread&gt; const char *g_get_prgname() { return "program lol"; } bool end; void thread_func() { sleep(1); end = true; } int main(int argc, char **argv) { VipsImage *im; if (VIPS_INIT (argv[0])) vips_error_exit("unable to start VIPS"); if (argc != 2) vips_error_exit("usage: %s &lt;filename&gt;", g_get_prgname()); end = false; const int SIZE = 10243; char buf[SIZE]; FILE *file = fopen(argv[1], "r"); if (file == nullptr) { perror(""); return 1; } if (fread(buf, 1, SIZE, file) != SIZE) { perror(""); } int useless_value = 0; im = vips_image_new_from_buffer(buf, SIZE, "", nullptr); if (im == nullptr) { vips_error_exit("got no data for %s", argv[1]); } double avg = 0.0; int i = 0; std::thread thr(thread_func); while (true) { vips_avg(im, &amp;avg, NULL); avg += 1.0; i++; if (end) { break; } } thr.join(); vips_shutdown(); printf("%d images processed in 1 second\n", i); return 0; } And take this as a reference https://github.com/art4711/cgo_overhead. 72.2 nanoseconds in seconds is 7.22∙10⁼⁸. Thus, you can call 1/7.22∙10⁼⁸=13.850.415 161000/(1/7.22∙10⁼⁸)=0.011, this is 1%. In other words, the call overhead is barely 1% of easy image operation without even IO to load them. In reality you will not have these 161000 image decoding and primitive processing: the IO will not let you make it.
Haha, that's a problem I never had. Old the way back to when I started programming as a hobby I've had a "~/Projects" (or C:\Projects).
Can you provide the Go team with an experience report? Please!
Now I just think you're a troll. People were not upset that the Caddy developers were trying to make money off open source. They were upset by the Caddy Sponsers header. Then they were upset by stupid crap like https://github.com/WedgeServer/wedge/issues/2 Also, their sponsors were upset (notable minio). So spread your FUD elsewhere.
Cool
I'd say Go is a wisely crafted "food" for "little poor person brains" and for those who are sick of tasty "food" that actually makes you feel bloated.
If it gets integrated in the toolchain it will be `go dep` of some variant managed by the `go` tool (I think). Right now it is just `dep`. Unless, of course, they go the Rust/Cargo way.
I was hoping for this as well since an intern worked on it some time ago. Apparently it's not production ready yet.
Hah! Nice rickroll
Will do that on the example of one library which I will likely to introduce in the next week or two.
Ended up with a less than elegant solution involving a switch and json marshalling. Thanks for the tips
So I'm understanding your edit correctly that there is a way a way you can achieve your goals without generating new go source code on the fly, that's probably the best option. But to answer your question and clarify what I meant. For the sake of example, lets pick https://github.com/hashicorp/go-plugin to manage your RPC although it may be overkill for your purposes. The [output of abigen](https://gist.github.com/karalabe/5839509295afa4f7e2215bc4116c7a8f) doesn't contain a main method, so by itself, it cannot be compiled into a process. You would need to have a main method as well in a separate plugin_main.go file. That file method would look something [like this](https://github.com/hashicorp/go-plugin/blob/master/examples/basic/plugin/greeter_impl.go) but the interface it would expose would be implemented by the generated code instead of that simple GreeterHello type. Also worth noting, [that exposed interface](https://github.com/hashicorp/go-plugin/blob/master/examples/basic/commons/greeter_interface.go) would need to be in a separate package that is imported in your original binary as well as in plugin_main.go. This interface absolutely must be identical between all of your plugins. Hopefully, you could design the interface so that your plugin_main.go is exactly the same for every plugin that you load, but you may have to generate a slightly different one for each plugin using a simple template. So putting it all together, your psudocode might look something like this import ( "github.com/org/project/sharedinterface "github.com/hashicorp/go-plugin" ) //to keep the example simple i'm assuming that you only need 1 plugin running at a time //you could easily keep a map of these instead of a single one var currentClient *plugin.Client func newPlugin(&lt;some inputs&gt;) (plugin.Client, error) { runCmd("abigen", "with", "input"); //generatePluginMain("some", "input") //if necessary runCmd("go", "build", "-o", "foo_plugin", "/path/to/plugin/dir") //containing plugin_main.go and abigen_output.go return plugin.NewClient(&amp;plugin.ClientConfig{ Plugins: map[string]plugin.Plugin{ "foo": &amp;sharedinterface.Plugin{}} Cmd: exec.Command("./foo_plugin"), //other config options here }) } func onRabbitMqMessage(&lt;some input&gt;){ if currentClient != nil { currentClient.Kill() //bring down the old plugin } currentClient, err = newPlugin(&lt;inputs&gt;) //generate and start the new plugin //handle error //do things } When newly build executable runs, it will register itself with the hashicorp/go-plugin package, and with then be accessible from inside your original binary via plugin.NewClient like in [this example](https://github.com/hashicorp/go-plugin/blob/master/examples/basic/main.go). If/when you want to update your plugin, you would simply use [Client.Kill()](https://godoc.org/github.com/hashicorp/go-plugin#Client.Kill) to bring down and unregister the old version of the plugin followed by. I hope that clears some things up.
It's pretty much one of the best intros to upspin . 
I didn't quite get this talk. He started to go somewhere, and then dismissed all of it, and in the end went nowhere. What was the point again?
Da Real MVP
&gt; Come on Florin. You know full well the community has already provided a debugger in Delve. The community also has like 50 different efforts to provide a package manager. It seems like go dep is going to win because Sam is doing amazing and it’s his sheer force of will to make Go suck less. I know. And I'm saying that's exactly what the community should do instead of ask for these projects to be taken on by the Go Team. &gt; I’m not sure why you’d call the community freeloaders when basic platform features are missing from Go that are literally in every other major language platform. Maybe I was a bit too harsh? But then again, I don't see these as basic things every other language has that are also provided by the team that created the language. Imho the language team should be focused on the language itself, the standard library and the compiler. They should be concerned if those things do not meet the needs of the greater community / people that work on tooling for the language. Anything else called out by you are not concerns that the Go Team should address, they are busy as they are. &gt; The fact of the matter is that the Google team seems to only work on things important to Google. Fine, but this means the community suffers and people, especially enterprise will move on to more mature platforms. Having been in contact with various team members of the Go Team I can assure you this is not the case. They do in fact care a lot about the community and the people in it. They care a lot about tool builders having all the building blocks they need in order to provide gophers with a great experience. I can list a number of issues that were being addressed by the Go team for 1.9 which make a visible impact. And I can do so for Go 1.10 just as well (even if things are still a bit in flux right now). And these are just two of the latest examples. The Go team said countless times, they need more people that can trust with having reviews / commit rights into the project, they need more support from the community to help them do the things the community needs. So asking them to take on board two massive projects would not only add a lot more work for them, it would also distract them from fixing issues / adding features we all need. It's our responsibility as a community to help the Go team help us.
Awesome design! But... just a tiny tiny question... would you - just maybe - consider making a second version... without "lang"? :) ʕ◔ϖ◔ʔ 
These are dope AF. Great work!
is that JetBrains Go IDE? 
its Vscode
I personally use https://github.com/OneOfOne/git-go-vendor just because I don't have to maintain any extra config files with it. Of course that only works with git so ymmv.
Francesc's was pretty cool. Sameer's was lightweight and enjoyable, but it wasn't really about Go. 
thank you .. please notify whenever you find the videos are up :)
Sure thing!
&gt; The dep tool is an officially-blessed one, finally. "dep is the official experiment, but not yet the official tool." https://github.com/golang/dep
Do you think I really care about downvotes? I care about well argumented, reality based, facts or opinions. And, at the end of the day, everyone wants the same thing, a more thriving Go ecosystem.
That's just utterly fugly workaround
It's almost same thing. It is overloading where you can also specify conditions, so it is not only a compile-time decision Like instead of writing: func (z *struct) Pay(amount int) error { if amount &lt;= {return &amp;ErrHowAboutNo{}} ... you can just write func (z *struct) Pay(amount int {amount &gt; 0}) error { 
There are different CC licenses for every purpose. You can allow or disallow commercial use, making derivative work, and so on, and make attribution mandatory, and you can say whether derivative work must use the same license. If someone ends up selling t-shirts based on your work in violation of your terms you should always demand that they remove it and demand compensation, or find a deal so you get your cut. If you don't want to do that then just allow commercial use in your license. 
I just spent way too long going through your repo. These are incredible! 
now this is a tech talk! i wish more golang presenters will do this format, just like famous presenters from others languages like chandler carruth for c++ and david beazley for python.
Why can't you make these vector images?
Try using the `template.HTMLAttr` type instead, like this: https://play.golang.org/p/8vsbvWZ9S2
Awesome, thanks for creating these, I recognize your work I remember asking months ago for a golang version!
http://xyproblem.info/ The thing you are trying to do will produce invalid HTML. What do you actually want to do?
Anything with TLS, you're going to suffer greatly with performance. 
No.
Also you can't reload the plug-in if it updates
As far as I can tell `&lt;input value="&lt;b&gt;text&lt;/b&gt;"&gt;` isn't actually invalid HTML, at least in HTML5. You just need to escape any `"` and `&amp;` characters inside the quotes from what I remember. I haven't found anything myself to show that this is invalid, and all HTML5 validators I've tried have no problem with it, so is there anything you can point me to that says this is invalid? Because if it is then I would really like to know so I can stop doing it in my own code for things like tooltips etc. That said I don't know how well Go's templating will handle stuff like this. There is `template.HTMLAttr` which is what I suggested to use, but I tend to stay away from Go templating so I don't know how well `template.HTMLAttr` works in cases like this. Good point about the XY problem though :)
Hopefully I'm not missing an easy way to use an io.ReadCloser with io.LimitedReader, if so, I'd love if you could tell me how!
My take away is the idea that you should think about your code mathematically, in terms of its structure. Reducing your control flow graph to a linked list makes it easy to reason about things. The easier it is to reason, the more complex tasks you can take on. Personally, I was pretty dubious of the talk until quite a ways through.
If you made this specifically to use with the `r.Body` where `r` is `*http.Request` then you can use `http.MaxBytesReader` for that instead, like this: r.Body = http.MaxBytesReader(w, r.Body, 1000)
It is likely what /u/qrv3w really needs to do is [this](https://play.golang.org/p/s_jkHt9kWl), which is the original post with the `template.HTML` wrapper removed from the string. Tags within attributes may not be invalid in HTML5, but it's still asking for trouble. For one thing, if the contents of `template.HTML` end up with user input in them, this will, despite the html/template's author's best efforts, end up permitting cross-site scripting attacks and such. It's just better to learn to "color within the lines" with HTML rather than use the escape hatches. The only conceivable reason I can imagine to want literal `&lt;b&gt;` within the value attribute is "I like the way it looks better than all that `&amp;lt;b&amp;gt;` stuff", and the solution to that is just to let that desire go. :)
Oh... thank you, I did not know about MaxBytesReader :). I did actually make this specifically for `r.Body`, however like you said that's specific to `net/http`, so this could still maybe be useful in other situations.
lol data race
 type LimitedReadCloser struct { io.LimitedReader io.Closer } func NewLimitedReadCloser(r io.ReadCloser, max int64) { return &amp;LimitedReadCloser{io.LimitedReader{R: r, N: max}, r} } io.Reader and io.Closer satisfied by the composition. The only slight quirk is that with composition, both the LimitedReader and the Closer are exported and _technically_ somebody could reach in there and reset one of them directly or set them to two different things. But my solution is to not do that. Plus in most cases they'd have to be penetrating an interface anyhow.
I agree it's definitely asking for trouble assuming you can't 100% guarantee the contents of the HTML you want to output, and the Go documentation of course makes it abundantly clear that it is a security risk and should only be used on trusted sources. In my own experience I have had to do what the OP is asking for so I could pass HTML formatted tooltips to a JS library that was just printing out any form of escaping as the literal values, which is why I just gave a straightforward answer. But of course I wouldn't inject any user input using this method. My own answer to the question just assumed that things like XSS were obvious to be careful of, but I'll edit it to point directly to the documentation and mention the security issues, just in case anyone takes my answer at face value and just dumps it in their code.
That is a much simpler solution, thanks!
I didn't know about `http.MaxBytesReader` until recently too, mostly because I expected it to be called `http.LimitedReader` which of course doesn't exist. I thought it was strange that I don't see it in beginner tutorials more often as well, because it would help a lot of people make their applications a bit more secure against large malicious requests, but maybe the naming of the function means that most people will never find it even for the purposes of tutorials.
Well done, packages that are small and simple like this are my favorite. 
It's amazing how often "don't do that" is a perfectly acceptable solution.
Yep, very strange! Especially because I've even seen tutorials use io.LimitReader when reading, instead of the proper MaxBytesReader. Thanks again for mentioning it to me, I almost always prefer the stdlib over my own implementations.
[citation needed] https://istlsfastyet.com/
I agree, the language is called “go”
this is stockholm syndrome
you sound like a PR guy for the Go team, stop that nonsense man
I've been using dep for about a month and I've had plenty of instances where it absolutely does not "work fine". If you use it, be prepared to occasionally hunt through transitive dependencies for specific version requirements that didn't get correctly resolved by dep. There are even some fairly well known libraries, the Kubernetes client-go library for example, that advise against using dep. That being said, I've been able to work around most of the issues I've had with dep and I imagine it will continue to improve. It still feels very much like a beta version, though.
Nice picture. Why is the domain name on the banner missing the '.org' suffix?
Awesome!
I always enjoy Chandler Carruth, all his Cpp Con talks are a treasure house.
[removed]
Some applications, like network interaction processing, are easy at first glance and thus they are easy to debug with logging. The harder is logic, the less effective is debug printing.
How? 
What nonsense? Or you don't like the reality? 
Is this that GoperSauce thingy? Can you run it without this? Why does it need to be run with this GopherSauce thing at all? XML reminds me of coding in Java 10 years ago, XML should be dead for project configuration, it's horrible.
I am using the [trix editor](https://trix-editor.org) which is HTML based. To repopulate the editor with saved content, the trix editor requires putting in HTML into the `value` attribute of an `input` tag (documented [here](https://github.com/basecamp/trix#populating-with-stored-content), and see the source of https://trix-editor.org for another example). Therefore, I would most like to have code like `&lt;input id="content" value="{{ .HTML }}"&gt;` to repopulate the trix editor with the HTML when processing the template. The editor can also be repopulated by setting it with Javascript, so my current workaround is to set set it a Javascript variable in the template, and then I have Javascript that unescapes it and then uses the [trix API to update](https://github.com/basecamp/trix#inserting-html) it. Its not very elegant, so I was curious if I could directly just put it into the `value` attribute.
I think this solution will work for me, thanks! The HTML is coming from https://trix-editor.org/ which will escape tags on the input and only adds HTML internally. Also I will also be sanitizing it with bluemonday.
&gt; yeah it seems like it would be one solution. iam just wondering is this the best way as there would be a lot of overhead to constantly be checking through each logged in user. like depending how often iam checking this table and if i have thousands of logged in users. 
cool. thanks for the tip ill check it out
Out of curiosity, do you have a link to that GUI library?
On cancelling, the blog says &gt;To be fair (uh!), what we need is not fairness, but priority. The context cancellation case should have a higher priority than the other. However, there is no easy, built-in way to do this. But you can solve this with an extra `select`: // create a context that can be cancelled ctx, cancel := context.WithCancel(context.Background()) // start the goroutine passing it the context go worker(ctx, jobChan) func worker(ctx context.Context, jobChan &lt;-chan Job) { for { select { case &lt;-ctx.Done(): return case job := &lt;-jobChan: select { case &lt;-ctx.Done(): return default: } process(job) } } } // Invoke cancel when the worker needs to be stopped. This *does not* wait // for the worker to exit. cancel()
For the last example, I think you should be able to use one cancel channel for all.
[Matterbridge](https://github.com/42wim/matterbridge) It's a group chat platforms bridge. Works with Mattermost, Slack, Discord, XMPP, Telegram, IRC and tons of others. These days, everyone seems to prefer their own platform and this let's us all be on the one we want and still talk to others. The quality of the code is great and the dev is very responsive.
I think this is the project used by Gitea for it's Discord&lt;-&gt;Matrix bridge. Indeed this is an useful project.
Even simpler: if ctx.Err() != nil { return }
waitTimeout potentially leaks goroutines forever doesn’t it? Jobs better complete or be cancelled (which is just a form of completion really)
Or just the job channel. job, more := &lt;-jobChan if more { process(job) } else { return }
Which was?
[GoTTY](https://github.com/yudai/gotty) has been pretty awesome. For a shell in a browser, it's extremely responsive and any hiccups I've had using this as a TTY I've gotten around by typing `TERM=xterm`. &amp;nbsp; At work, I've taken the philosophy of importing external libraries extremely rarely and instead favor writing against the standard library unless that external library provides incredible value that would otherwise take entirely too long for us to roll ourselves. To that end, I find myself using [Logrus](https://github.com/sirupsen/logrus) in all of my projects because I like the approach taken to logging and so that in the future we can hook into one of the many supported technologies to send logs to (for example: Slack, Mattermost, Discord (for home projects), and many others). &amp;nbsp; I've also recently pulled in [mgo](https://labix.org/mgo) (pronounced magno) for a MongoDB driver and it's been working beautifully in my latest project with extremely low overhead.
&gt; Go is a systems programming language. Go really shines for stuff such as cloud systems (web servers, caches), microservices, distributed systems (due to concurrency support). No it's a general purpose programming language. Go is no more a system programming language than Java or C++ and nobody calls Java or C++ system programming languages. 
Go crypto isn't optimised for ARM yet. See the "Go crypto" section in https://blog.cloudflare.com/arm-takes-wing/
In Go, any goroutine that waits forever will leak, no matter what you wrap it with. Since there's no way to prevent that, the fault is on the goroutine that didn't have a timeout.
This is so cool
Here some more projects: - [MailHog](https://github.com/mailhog/MailHog) - is a fake SMTP server, useful for testing applications that send emails. E.g. you just configure the right port in your app, and you can see the sent email in a web interface; - [rcrs](https://github.com/akavel/rsrc) - you can use this to add an icon to your apps executable. Just use proper build tags, because this file is OS specific; - [sqlfmt](https://github.com/jackc/sqlfmt) - format SQL files (analag to gofmt). Not perfect yet but worth trying; - [gofpdf](https://github.com/jung-kurt/gofpdf) - generate PDF files. Self-contained: don't depend on any other executable; - [cron](https://github.com/robfig/cron) - job scheduler for apps. Launch goroutines in specific days, hours, etc. E.g. run this job on Mondays and Fridays at 21h00; - [zglob](https://github.com/mattn/go-zglob) - easily get files that matches a global. Supports double star syntax (`foo/**/*.go`) that stdlib doesn't supports.
Yep gotta complete all outstanding work one way or another. This is common in C threadpool systems with task queues as well! I guess one’s design drives what to do when waitTimeout times out.
[To be updated] Will update when I arrive at my desk. I’ll leave a link to the library I was referring to.
Hey, this is a little late, but take a look at: https://github.com/dave/courtney
Keep it stupid simple :) No framework, and pure http(s) You’ll have a time to improve once necessary 
Thanks! Kinda hilarious that you would say that because I think I first learned I should limit reading from http body from a comment you made on one of my posts a while back, which inspired me to make this!
yeah, we've deferred on GOPATH until after dep/its successor moves into the toolchain. here's a draft description of what that might look like: https://gist.github.com/sdboyer/def9b138af448f39300cb078b0e94cc3
yeah, the main issue for this is here: https://github.com/golang/dep/issues/860 this isn't unsolvable - just, time and relative priorities.
?
Go + gRPC + Kubernetes
gRPC + kubernetes
Feynman's paraphrasing "Calculus Made Easy" in that quote. Nice.
No framework. Just use chi as router gRPC as protocol
Why do you think you can do that? 
maybe confer with https://github.com/hpcloud/tail...
[here's](https://youtu.be/lLDWF59aZAo) a great tech talk on this topic
I don't know what you are trying to do since you only provided two lines of your code, but does this example of pointer arithmetic help? https://play.golang.org/p/Y7TE1pq8e_ If you could describe what it is you want to do that would help us to answer your question better, since there is probably a better way than pointer arithmetic.
sending each line via the channel doesn't look like the best idea
Turns out I was being dumb and didn't execute the env.sh that sets up the appropriate environment variables needed. I was able to get a build with that. I'm still interested in some machine learning with computer vision if anyone has any suggestions.
A demo link or some screenshots on your readme would be great.
Friendly reminder that Iris is the framework that was [removed](https://www.reddit.com/r/golang/comments/57w79c/why_you_really_should_stop_using_iris/) from [awesome-go](https://github.com/avelino/awesome-go#web-frameworks) due to [shady practices](https://www.reddit.com/r/golang/comments/57tmp1/why_you_should_not_use_iris_for_your_go_projects/) by the author/maintainer [kataras](https://github.com/kataras). Maybe it's gotten better since that fiasco, but just posting this here so that new gophers know the background here. Also worth noting that the only framework [the author of this article](https://github.com/speedwheel?tab=stars) has starred is Iris (along with 4 of kataras's other repositories), and Iris seems to be the only framework he's used in any of his github projects. Furthermore, a tiny bit of text analysis shows that Iris is mentioned in this article about twice as much any of the other framework. To be clear, none of this invalidates the authors points. I'm just always extremely skeptical when someone writes in a style that appears unbiased at first glance, but then actually has a heavy bias on closer analysis, and most importantly **doesn't disclose that bias**. Something along the lines of *"Full disclosure: I've used Iris in multiple projects and I'm a big fan. I have less experience with the other frameworks, so if I've overlooked anything, please let me know in the comments"* at the bottom would have made a huge difference in how deceptive I find this article. The subtle bias *I can see* makes me wonder about the things that aren't as easy to notice or verify. For example, I wonder how cherry picked that feature set is so that it just happens to include everything that Iris does and nothing it doesn't do. To be fair to the author, this cherry picking isn't necessarily intentional. If the author simply started with the feature-set from the framework that he knows and loves, it obviously wouldn't include anything that framework couldn't do. That's obviously not a good way to do an unbiased comparison, but it's an easy mistake for an undisciplined person to make. TLDR This article is sneakily biased towards Iris, which is the one framework that most of the go community will tell you NOT TO USE! The author may be intentionally spreading propaganda, but [Hanlon's Razor](https://en.wikipedia.org/wiki/Hanlon%27s_razor) would suggest that he's probably just let his own biases creep into the analysis.
**Hanlon's razor** Hanlon's razor is an aphorism expressed in various ways including "Never attribute to malice that which is adequately explained by stupidity" or "Don't assume bad intentions over neglect and misunderstanding." It recommends a way of eliminating unlikely explanations for a phenomenon (a philosophical razor). As an eponymous law, it may have been named after Robert J. Hanlon. There are also earlier sayings that convey the same idea dating back at least as far as Goethe in 1774. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
It's a minor detail not important to the topic, but don't pass unknown content to the format string in `Printf`, such as in `fmt.Printf(string(by))`. Instead, do either `fmt.Print(string(by))` or `fmt.Printf("%s", by)`.
I agree! I'm also using it that way. I just wonder what people are using as well.
Yep, chi is idiomatic, that's why I like it. Do you use distributed transactions? I use consul for that. But, I'm trying to stay away from txns as possible.
Do you use cloud services like AWS etc?
Not even something like Mux to define your routes?
&gt; Since Go seems to be a success, can't a tech giant like Google assign a few more resources to the Go team? Honest question here. Put yourself in Google's position. They use it for their internal needs. If it's good enough for them at the current level, why should they invest more very expensive engineers into this? The language is open source and they never declined a contribution, and as I said, aside from generics, nothing else is a concern of the language. So what would they gain from that? 
[removed]
Thanks for this article. I agree with all of it, from first to last sentence. Just recently I read another blog post that promotes self-documenting code, and, once again, I was not able to follow their reasoning. (To be fair, the article was about some aspect of game development, and maybe this is a realm where pure code *can* speak for itself, but this would then be the exception rather than the rule.)
Why not? Channels surely are fast enough to handle it.
Because 1. It is easy to do without channels 2. Channels are still heavy 
Define heavy. Channels are the go-to construct in Go for such operations, what are you gonna use? Callbacks? Or I'd you are gonna read from a Buffer, just don't use a library. I would love to see some data backing up this statement. Not trying to be offensive, just genuinely curious.
because of possible injections? 
I will try to find another way to port over this configuration system with AST.
Yeah. It's not vulnerable as it would be in C/C++, but it might be ugly.
Do you have an example of a chi/gRPC app lying around? I was going to do something with both interfaces, but there wasn't a really nice pattern which I felt comfortable with for passing data around (and hopefully not duplicating the structs with protobuf/json...).
Use RabbitMQ as messaging system. Connect to it using amqp library. No framework. Just some library code to create subscribe-and-handle routines, and that's it.
Correct. One cancel channel that you close will "broadcast" to every listening go-routine.
Yes, I use aws.
We’re developing micro services, so if gorilla mux isn’t required in one of them, we don’t use it. You can always improve performance by using a different router (and it’s not the main reason for using mux), but we try to keep the dependencies to the minimum. 
I disagree quite a lot. I'm not saying comments are bad but a lot of comments in a code base is usually a sign of bad code. A lot of times when I have to work on a code base with a lot of comments I fold the comments and the code becomes easier to understand after that. One of the best analogies I have heard is the comparison to manuals. People usually try to figure it out first and then consult the manual. I think most people do the same with code. The issue in programming compared to the manual is that the manual pages aren't taped to all the components they describe where as the comments in code usually are and this makes the code sometimes completely unreadable.
Okay, thanks!
I find that people that try to figure it out first generally take longer than if they'd just skimmed the manual first. :) Also, correlation does not imply causation. I think code from junior devs has more comments because they havent been berated by senior devs yet for writing too many comments. That's half of why I wrote the post... Because I want senior devs to comment more, not less. 
Good comments explain *what* a function is for. If you need line comments (which usually are trying to explain *how* rather than what) for more than a few edge cases, one of these is usually true: 1. Your code is bad and you should feel bad. 2. Your knowledge level of programming is on the low side, and you're assuming everyone else needs a "//this is a for each loop" comment, when something so incredibly obvious needs no explanation. 3. You have a monstrous function that needs to be broken down into smaller functions.
&gt; Channels are the go-to construct in Go for such operations 1. For pythonistas may be. I did this kind of work (monitoring, data gathering, etc) at my previous job and in reality you must be ready for hundreds of thousands lines per second. Channel of lines is about the worst solution for this purpose. Channel of buffers is OK, channel of lines is a clear sign of the lack of experience. 2. Second, [this](https://github.com/hpcloud/tail/blob/37f4271387456dd1bf82ab1ad9229f060cc45386/tail.go#L29). Channel of strings. Go SUCK when it comes to data allocation performance, thus initially questionable solution becomes even worse than it looked at start. Proper approach for the task is a separation between data gathering and incoming data notification, where there is a possibility to get an information about some data was written to some file and special buffering object what will take a care about line breaks. 
Makes sense thanks.
This is exactly the attitude that I am speaking against. Correlation does not imply causation. Just because some bad code has a lot of comments does not mean that having a lot of comments makes your code bad. Having lots of comments will make your code more accessible to programmers more junior than you. Maybe they haven't seen a recusive descent of a tree before. Even for someone that has, putting a little comment at the top means they immediately understand what's going on without having to read through the whole function and deduce it. Most algorithms and patterns are easier to describe in one or two sentences of English than they are to write in code. The problem with comment shaming is then people avoid comments when they really *should* be writing a comment, and that makes everyone's life worse. 
Is there a reason you like chi over the http mux stuff I've seen for most grpc setups? I've not run into an example combining chi and grpc.
I disagree with the fact there are no bad comments. When comments aren't maintained they can be out of sync with what is actually happening with the code. In that case they are worse than no comments. 
That last sentence is complete hyperbolic nonsense. You want them to comment just enough to ensure that sections of complex code are understandable. No more, no less.
Thanks for that, I think I started off with `fmt.Printf("%s\n")` and then later forgot to refactor :).
I feel those who think they can live without comments, don't understand what comments are for. i try to think of it as: Code describes HOW something is done. Comments describe WHY something is done. The two complement each other and are therefore both necessary to create the complete picture.
I feel those who think they can live without comments, don't understand what comments are for. i try to think of it as: Code describes HOW something is done. Comments describe WHY something is done. The two complement each other and are therefore both necessary to create the complete picture. 
I suppose. I just generally feel like comments are used as a copout. The "I am too lazy to change this into good code so I will just leave a comment" mentality is something I deal with every day so I feel kind of strongly about this. If you also have test in place there are few cases where I feel like a comment is needed. There are however also cases where a comment is needed. Usually I find these cases to appear when you optimize the code for performance. Also if you write a library with a public API then of course you need documentation.
Code should be clean, concise and easy to read, comments tend to get stale and you have to second guess if the comments are still applicable. In my personal experience, I've found tests to be better documentation then comments. A well maintained code base should always maintain the test suite. Also, when a bug does come in, you can create a test for the situation to help insure that the app does not regress in the future. 
&gt; I could get an example to run with go run but not build This mystifies me greatly. Care to expand?
this!
&gt; For pythonistas may be This can be read a few different ways. Maybe the nicest is "people who value code readability over performance", and using channels passing []byte seems like the best ratio ... the fact channels are 4x the cost of a mutex is hardly where I'd start looking for savings anyway. As you alluded there are other concerns when you try to scale in different ways, like are you better just poll'ing ever 1/10th of a second. Should you separate the "copy data" and "parse data" into entire separate processes (on different machines) instead of just different goroutines. As an initial solution to the problem I'd much rather have string for each line being passed over a channel than something that could have been written in C.
It's amazing to me that an article would mention Iris but not Chi.
Nice work
Why not define a language close to go, with — dare I say generics — that compiles to c++?
Agreed, the problem I see is that a lot of new developers end up commenting WHAT. I do think these things aren't inherently bad, but I still always raise the issue when I see them in code reviews.
The example would run with go run, but doing a go build resulted in linker errors. I'm also mystified as to how it could work one way but not another. There are environment variables for the opencv library that are needed that point to the source libs.
either that or port [node-msmq](https://github.com/marcobarcelos/node-msmq), seems to have a simple API
Then it wouldn't be Go. :) But a language like this already exists. Try looking at Nim: https://nim-lang.org/
This starts with a straw man position, which doesn't bode particularly well. I'm sure that there are people who take the position that all comments are bad, but it's a silly position to take and is, in my opinion, relatively easily refuted. Code is a description of what we want to do, especially so in imperative languages. Sticking with imperative languages, and given code that works, we have some sort of description of what, no matter how bad. What we don't typically have in code is a "why?". I can see you set the timeout to some value, but why? No matter how readable you make that code, it's unlikely to tell me that. On the other hand, a comment like: // BWM-1534: Setting the timeout to the maximum SLA for this service (1s) // At the time of writing, the average request time from the account system was 90ms, but the maximum was up to 800ms // beyond that, we're likely to be causing service slowdown issues. gives me a reference to some sort of bug and a point-in-time reference to why this code was put in. There are a set of assumptions in here that I can examine and test. Similarly, tests are really useful, but even if we somehow managed to set up a test that checked for a slow response, it might not tell us why it was there. It doesn't always tell me intent or architecture. I think it's really easy to show examples of bad comments... https://monolith-programmer.tumblr.com/image/160950124640 (from real code in Eve Online) However, I do believe that it's easy to take a position where if you're reading code and a comment is required to explain what is being done, it's worthwhile to consider if there's a refactoring that allows the code to "read like well written prose". If your code reads like: // must call DoSomething before DoSomethingElse _ = a.DoSomething() a.DoSomethingElse() Sure... a comment makes that temporal coupling visible, but only in this one place. b = a.DoSomething() b.DoSomethingElse() Now you don't need it, and you don't need a comment in almost every place you have a DoSomethingElse(). Changing the code to be clearer works at every call site, adding a comment doesn't.
I addressed all of these in the post. We disagree, and that's ok. :)
No, I really want them to comment more in general. It's hard to tell what one person will find confusing vs someone else. 
Might be a start to know it is called 'Go' not 'Golang'...
This article seems to capture the situation pretty well. I'll probably link to it when I need to explain what makes people think Go is a good tool.
&gt; but Hanlon's Razor For the record, Iris' author has repeatedly shilled for Iris in this subreddit under different sockpuppet accounts in the past and every time being called out by different people. I don't believe OP is the case, but just bringing it up because Hanlon's razor here is not as straightforward to apply as it seems.
Nice tool - just what I need. A recursive option would be great, even though most shells provide a workaround. It is just that I usually forget the exact syntax of the recursive treewalk thingy of the shell I am using. (find -R? for i in ...?)
why switch to `proto2` ? gogoproto works perfectly with `proto3`.
I'm just trying to warn people without re-igniting a toxic flame war.
I understand needing inotify to respond to things like log rotated files, but could you use the regular `select` system call to handle responding to new content in an already open file descriptor?
Yes. I know. I just can't edit the title in Reddit. It's just that when I search, it's easier to search for golang rather than go, so habits die hard.
The article says nothing about job queue persistence. If you launch a goroutine to send an email, but the process or the machine crash before the email was sent, then nothing is sent...
Then to OPs point, the comments are part of the code. They are the why and the person updating the code, doesn't update the comments they are writing bad code. 
From the blog: &gt;Yes, using gogoproto, you cannot use protocol buffer 3 because it does not support extensions. There is an active [issue](https://github.com/gogo/protobuf/issues/324) open which discusses this in further detail.
That's what I was thinking too! I saw the article, WTF Iris AGAIN! and no Chi, it made me not even want to read the article because I was so angry at it mentioning Iris again.
That's not really true. We're using gogoproto on proto3 files with extensions just fine (most notably stdtime and nullable).
It's not a straw man. I wrote this post in response to three different tweets of people saying that you should refactor your code until there are no comments and/or people striving to have "self-documenting" code. 
I'm kind of surprised so many here have a generally negative attitude toward comments. Does anyone have evidence, other than anecdotal, that verbosity or frequency of comments somehow is the hallmark of an inferior developer? Have studies been done to back up this claim? I think the idea that _code should be self-documenting_ is a unicorn. Sure, very simple blocks of code are easy enough to read. But there will always be code that has pitfalls, gotchas, ambiguities, and other potential problems. No one likes to write this kind of code, but sometimes there's no other option outside of major refactoring that no one has the time to do because you're in a sprint and have to ship a feature. When I come across code like this, there had better be good solid comments around why it was written the way it was. But even the most self-evident code is not harmed by the inclusion of comments, provided they are contextual and accurate.
[removed]
I somewhat agree with OP and prefer reading code with at least _some_ comments. I think completely self-documenting code is not possible in most codebases. I don't always think that more comments are always better, though. At some point your spacing out code that would be more readable with fewer comments.
[removed]
if go channels suck, and channels are go's main selling point, why use golang at all? imo go is not perfect (lol no generics) but channels are very good and works 9/10. unless i benchmark my code and identify that channels are the bottleneck i wont chang replace channel and at that point why not just use a "fast" language like c++
Thanks.
What's stopping you from learning them separately? Just setup a gRPC server inside a container on one of the pods. Then call it from another. I have a minimal example project on [GitHub](https://github.com/tinrab/kubernetes-go-grpc-tutorial).
Why not gRPC? Along with gRPC gateway?
This is linked from this subreddit's info: https://dave.cheney.net/resources-for-new-go-programmers. In my opinion, this is the best resource: [astaxie/build-web-application-with-golang](https://github.com/astaxie/build-web-application-with-golang). After that, check out any popular project on GitHub for how to properly structure Go apps. Finally, develop lots of tiny single-purpose apps, including tests, docs, benchmarks, etc.
I would think of these as separate tasks like the other commenter said. I assume you already know Go so I would say the next step is to get familiar with gRPC... Just start with a basic gRPC setup. Then as you get comfortable with that you should move on to k8s. One more thing, you should absolutely have a project or some idea to test these new things on... Otherwise you won't progress much from the tutorial stage. A project will make all the warts come out and dealing with those is how you'll actually get to learn those new technologies.
I think you can't find similar episode(s) from justforfunc videos ;)
I messed around with [this repo](https://github.com/ahmetb/coffeelog), it's a pretty thorough and practical example.
No need for gRPC Gateway :) https://improbable.io/games/blog/grpc-web-moving-past-restjson-towards-type-safe-web-apis
I would also highly recommend this route to learn those things, it's much easier to debug what's wrong as your learning seperately. Get kubernetes working and have a few services chatting to each other via rest from a request you send so you can see the result from chained service calls in the backend and verify its working Learn grpc and have a few local booted services intercommunicate in the same way. Than drop in a grpc version to replace the previously created simple rest services. I've found it useful to write a little script to generate all your proto's and then move the resulting go files to package folders within your project so all your services can reference them via the gopath so your clients and servers have the same updated file without the risk of human error from needing to copy paste stuff around. My current folder structure is like so. Protos/ ---- service1.proto Services/ ---- service1/ -------- service1.proto.go -------- main/ ------------ service1-main.go Thus clients can easily reference other services to make calls against, and I have a utility package which just reads in all my services url/port information from environment variables so each one knows how to contact each other and made it easy to have local Dev testing and work in the cloud as you set the environment variables in the docker file or some build tool. But ofcourse I haven't fully flushed out if I like that structure since I'm still semi new to using grpc in production and it's in flux currently for me so just decide on a method that suits you and your project, I hope my example helped you wrap your head around some stuff.
Google asks for feedback about the language for just ignore it
Interesting. When I tried it, it gave a compiler failure.
I think the prevailing wisdom in Go is to use a flat directory structure and only create new directories when you are building self-contained functionality.
Funnily enough, I just saved this article to read later. Maybe it'll help you too: https://outcrawl.com/getting-started-microservices-go-grpc-kubernetes/
You just copy pasted this: https://github.com/golang-standards/project-layout
This is why I'd like to see more platforms adopt doctests, the way Elixir and Python do. Make the examples in comments executable in test mode, forcing people to update the comments alongside the implementation.
What are you guys using for service discovery?
Incredibly cool how well you packaged this project and how fast it was to play around with with just one command (`docker run -p 8080:8080 wendellsun/2048-ai`). Well done!
What's the purpose of this code? func (a *AI) deptSelect() int { dept := 4 max := a.Grid.Max() if max &gt;= 2048 { dept = 6 } else if max &gt;= 1024 { dept = 5 } return dept } I can't tell if it's making the search look deeper or shallower (more or fewer calculations) as the numbers get larger.
Meh, I keep it simple: `/app` &lt;- your actual app code. `/config` &lt;- app config stuff. json/yaml/ whichever fancies you. `/vendor` &lt;- standard Go's vendor folder. `main.go` &lt;- obvious. What goes under `/app` depends on the kind of app. If I am writing a RESTful app, I would for example use `/app/routes/v1`.
Hey! Love your website, I've read just about every article you've got! The website is so damn fast! I know its a SPA, angular 4? What the secret sauce to the speed?
But doesn't your argument about code reviews make sense here to. You said that during code reviews usually people are told when they have to many comments. If some one during a code review says "I have no idea what is going on here" then you can discuss adding a comment.
as it is the package can suck up gigabytes of logs in a minute. i think you're optimizing prematurely.
I feel like teaching the junior developers make more sense than putting a bunch of comments in the code. Comments have a tendency to get out of sync with the content and they are a lot harder to keep updated because usually people don't even look at them. If you are working on a team then ask someone. They will explain it and you will have learned. If you are the only senior developer in a team with only juniors then the lack of comments will be notified during a code review.
Hi. I'm recently using Consul. [Check out](https://www.consul.io/intro/vs/index.html) the differences.
I’ll just plug my project for testing gRPC services with a GUI client. Might be useful as you’re learning. It also has some nice features for hitting kubernetes services. https://github.com/troylelandshields/omgrpc
First thank you like it, this make me feel relaxed. Above code section adjust depth value larger as the grid's max value get larger, this will takes more calculations and move became slowly but maybe have a better score result. Thank you point out documentation lack, I'm not doing well at that. I will complete code comments tonight and notice you.
Hey guys, I'm happy to announce go-astits, a Golang library to parse and demux MPEG Transport Streams (.ts) natively: https://github.com/asticode/go-astits It allows you to either retrieve raw packets or event better retrieve complex data spanning over multiple packets. Let me know what you think! Cheers
Here is a paper on gRPC, with a step by step presentation: https://medium.com/pantomath/how-we-use-grpc-to-build-a-client-server-system-in-go-dd20045fa1c2
That's why I said "blessed" and not "accepted" or something like that :-) The point was that for someone who clearly sought something which "would stay afloat in the long term", being officially acknowledged is a big—maybe the biggest—"pro" point.
Maybe look at [`gb`](https://dave.cheney.net/tag/gb) then. I, for one, do not understand what's the problem people have with `GOPATH` but there is a robust solution for those who do ;-)
took a peek at nim, doesn't look like a better alternative to writing c++ directly and taking advantage of everything available
Can you please explain how are they doing this? 
This is a great structure IMO. I think maybe some people are confusing what you're recommending here, and thinking you are saying that _all_ of those directories should always exist, which I don't think you are. I always start with a `cmd/` folder and a `pkg/` folder, and move from there. The next most common I use is `scripts/`. It's interesting to see that the same directory names are so prevalent in the community.
Seems legit, code looks clean. What’s up with the name tho? I keep reading it “as tits” - no offence.
It's made with GatsbyJS and hosted on S3.
"Give us generics, because well, I shouldn't have to explain why generics are an obvious must for everyone everywhere!" is not a suitable feedback to base major, maybe even backward incompatible language changes on.
I've tried `gb`, similar issue: you can't run binaries generated from your vendored packages. You have to do "go install ..." and that'll install on the GOPATH (but you can't control the version to match your vendored version.) So far, "vg" (virtualgo) is the closest thing to what I want for development. For deployment it's never a big issue as I build using a docker image.
yeah that was something I was worried about. Basically I prefix all my repos with "asti" and this one was about "ts" so the logic name was "asti-ts". But as you stated, unfortunately, when one reads it, he/she can even see "ass tits" which is not intended at all...
Just for reference this is the repo that was copy pasted from: https://github.com/golang-standards/project-layout
Random thing from the README that jumped at me: for s := range ch { cancel() return } can be &lt;-ch cancel() (also yours won't compile because `s` is unused)
Indeed, thanks a lot! I've updated the readme :)
There is https://github.com/asticode/go-astilectron
What's the categories for? Accessing a subset of all movies? Make it only a GET endpoint then.
Yes, but they're managed by user. So user need option to create and delete categories. 
I do not _know_ why so many people tend to argue against comments but I believe it is because: * Writing good comments is complicated, requires training and self-reflection. * If you want your comment to describe the What, the Why and the Why-not-that-other-solution you have to _have_ an other solution and judged both solutions while most programmers are happy to come up with any solution at all. * Formally there is a "solution" to the missing comments: The "self-documenting" code which is thought of as being better, cleaner, superior than code+comments. * It rationalizes why you didn't write comments. "I didn't write comments because comments are a sign of bad code and comments might become stale and thus might be even more problematic than undocumented code. My approach is even better! (And much easier for me...)" It is the same with commit messages: "The change is self explaining". "The Jira ticket number is enough". "There is no need to restate what was done in the commit message." It simply is much easier to come up with arguments why comments, commit messages, documentation, etc. is _not_ _needed_ than writing proper ones.
We currently use CGO and ffmpeg to do this. I'm guessing you have been down that route as well. You see any performance increase using this vs CGO?
Changelog: https://staticcheck.io/changes/2017.2
On zsh or bash with globstar flag, recursive patterns are available. liche **/*.md **/*.html On other shells, liche $(find . -name '*.md')
You can always use some struct type with your fields, so it'll accept only this struct. But if you want to do it, remember to never put context inside struct(as a field). So it would be something like this: func (sl *SomethingLong) WithAReasonableName(ctx context.Context, ys YourStruct){ ... }
In that case, the code needs to be escaped to work properly, and you don’t want to work against it. Try it: see how `&amp;lt;` or `&amp;amp;` look when you round trip it. 
I use [variadic functional options](https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis).
That JS library couldn’t have been any good though because the DOM’s getattribute method will convert character entities for you. If they weren’t using it they must have been doing something weird and wrong. 
I know it's not the intent of your library, but do you know of a project which would packetize a mp4 video (h264) into .ts chunks for HLS/HDS delivery? I cringe at using os.Exec() to invoke ffmpeg to do something like that, ...
Nice, I was looking for some guidelines for the `pkg` directory. This is helpful ;-)
I just leave the line long and rely on the soft-wrapping of my editor. Of course, if it gets too much, I'll try to find a way to refactor it or choose better names; but less because it's too long a line and more because a *much* too long line indicates that the naming/signature was probably chosen poorly.
I take advantage of that where possible, but it's not always possible, or the right choice. I stick to using them when I need 0 or more of some specific thing, and not some distinct things.
That's not a bad idea!
hate being this guy, but gRPC is a framework.
REST+JSON when it makes sense, net/http and gorilla mux. go-kit/log for logging gRPC for internal services database/sql and prepared statements for most things, dynamic queries where this isn't sufficient. DNS for service discovery. I test against an actual database in most cases Simple structs for my domain models, and a simple Store interface to CRUD it up. Amazon ECS and Kinesis keeps us scalable and prevents data loss (kinesis retains messages for up to 7 days, in order), lambdas for any post-processing tasks like sending events to a data pipeline or an ELK stack, or sending data to a reporting database that analysts can query. Has worked pretty nicely so far.
&gt; There’s a disturbing thread that pops up every once in a while where People On The Internet say that comments are bad and the only reason you need them is because you and/or your code aren’t good enough. I'd like to see a link to one of those outrageous articles. If they were included I think this article would have delivered a bigger punch. As for the main topic of the article, I believe nothing says it better than our Go proverb: [Documentation is for users.](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=19m07s)
I don't reckon there are any GO libraries that can parse h264 mp4 videos and write ts packets at the same time. I think your best bet is to use CGO + ffmpeg using libraries like [this](https://github.com/giorgisio/goav). That way you don't use os.Exec() and still profit from the ffmpeg features. Beware as your project won't be automatically cross-compilable as with CGO you need to set up cross-compilation toolchains.
Well what does your model look like exactly? Maybe have another endpoint `/categories/:id`, returning a category with a set of movie ID:s, which you then query for on `/movies/:ids`? type Categories { ID int Name string Movies []int ... } 
Ok, thanks. Too bad nothing imports it judging by godoc, I'd hope at least for a semi functional hls/hds thingie built on it, sort of like [this project](https://github.com/shimberger/gohls) but without the dreaded os.Exec :D 
 Hey, main problem is, i will have multiple resources with categories managed by user, that's why i cant have something so generic like ```/categories/:id```. For example, let's say i will have movies, series, books and comics and every of there resources will have categories. So for now i will probably stick to this model: ```/categories/movies/:id``` ```/categories/series/:id``` etc...
Author here, feedback very welcome. I want this to be as helpful to newcomers as possible. 
I haven't benchmarked both solutions but that would be an interesting thing to do. I'll post the results here once I'm done. That being said I think using GO to parse and demux a .ts makes sense if your whole workflow is using GO since it's "only" reading from an io.Reader and parsing the bits in the correct order, nothing else. Enabling CGO (which I think should be used last resort) just for that matter would be too much of a hassle as far as I'm concerned. Things are obviously different if you're using other features of CGO + FFMPEG...
This is mine site : http://www.golangprograms.com/ you can learn basic to advance topics from here.
I think a fairly typical structure would look something like this: GET("/movies", listMovies) GET("/categories", listCategories) POST("/categories", createCategory) DELETE("/categories/:categoryId", deleteCategory) POST("/categories/:categoryId/movies", addMovieToCategory) DELETE("/categories/:categoryId/movies/:movieId", deleteMovieFromCategory) If your API needs to be able to list all of the categories that a movie belongs to, then I'd add categories as a sub-resource of movies: GET("/movies/:movieId/categories", listCategoriesForMovie)
I meant web framework, gRPC is not web framework.
Thanks for comment. Currently i'm using this approach: POST("/categories/movies", createMoviesCategory) DELETE("/categories/movies/:id, deleteMoviesCategory) POST("/categories/series", createSeriesCategory) DELETE("/categories/series/:id, deleteSeriesCategory) POST("/categories/comics", createComicsCategory) DELETE("/categories/comics/:id, deleteComicsCategory) I see your approach uses one generic Categories resource for all other resources. It can work, because some categories can be shared among movies/series/comics etc... 
I see. Then you can just change the paths to /movies/categories/:a and movies/titles/:b, right? 
This is a pretty good answer, thanks. 
No, because there are conflicts in routes. For example DELETE("/movies/:id", deleteMovie) DELETE("/movies/categories/:id", deleteMoviesCategory) Will produce conflict, because {:id} can be anything, even "/categories/:id".
amazin' I appreciate the dank information
Well, I'd agree that you should strive to have code that doesn't require comments to make sense of where possible. I'd disagree that you can write code that eliminates the value of all comments, because there are different types of content that can go in comments.
Indeed, I will say I'm a fan of doc comments that can be used to generate documentation in HTML and hosted for consumers.
I'd make a debug version of that external library and use it for debugging the problem. Log everything that is passed to this library on Go side, and do the same in the library - extend its source to log anything that comes back from WinAPI etc. Hopefully this would give you a hint what is going and where the bug may be.
Currently I'm trying to single out the lines of code that potentially causing the issue and writing a small program of those lines to see if they are causing this issue. But it's very counter productive. Especially if we are coming from Java background..
This boils down to the lack of GDB support for Go applications. There's nothing magical in Java / JNI.
The site seems to be down.
That's strange :S seems okay for me, checked on here too: http://downforeveryoneorjustme.com/ewanvalentine.io I've just chucked it behind Cloudflare just to be super sure. Will update Ghost incase there's a bug also. Thanks for letting me know! 
io domains are known to have frequent DNS issues, as the institution operating them isn't really able to operate them well.
In Windows errors always have a code that you can look up for the exact cause, so check the error value for a concrete type that contains the numeric code if it does't expose it in the string. Edit the library if it doesn't include this data and open a issue with them if possible. In general failures in Windows are almost always related to acls in one way or another, which usually propagate into the event viewer as well. Have it open at all times when writing software in that developer hostile environment.
&gt; Is there a reason you like chi over the http mux stuff Boilerplate? I really do not know how can a non trivial project ever only use pure http mux. I do not get people who insist on it.
I added some code comments and hoping it can help you. If you have other question, please fell free to reply, I'm glad talk with you.
Ahaa, I did read something about this, serves me right for buying a vanity domain! Possibly time to resurrect the old .com domain! 
Excellent, keep it up!
I prefer to keep code like what you would put in your `app/` folder in `internal/`, as it's specific to that application and won't be re-used, and `internal/` is a good use-case for this kind of code, i.e. this thing: https://golang.org/doc/go1.4#internalpackages
May be checking the amount of boilerplate in all code bases is more than enough, also there are a lot of this reports in the golang feedback.
Good libraries don't hide where the error originates from. For example, stdlib uses [os.PathError](https://golang.org/pkg/os/#PathError), [net.OpError](https://golang.org/pkg/net/#OpError) and such to wrap the error in a way that tells you more than the underlying system error does.
Huge thanks to Dominik for the fantastic, very high-quality work on these excellent tools for Go!
Sure, but it's still officially acknowledged only as an experiment. Even worse, dep would have to be rewritten pretty much from scratch to be integrated into Go itself. Don't hold your breath. My personal expectation is that, *at most*, what comes out of this "dep experiment" is a file format and command line calling conventions.
The hubris of some rando naming their github organization "golang-standards"..
I get you completely when developing a rest API, but with grpc I thought it handled most of the code for you. Just point grpc at a mux and it registers all it's own endpoints
In my case user.Current() from standard lib gives me an error. I will look if it gives more than that. If not I'd standard libs themselves don't give debuggable errors, I'm not so positive that third party libraries will give much more than that. It gets complicated with the fact that the errors I'm facing are native API related.
thanks, this helps
Thank you, much appreciated :) 
This article feels more like a strawman mixed with an ad-hominem more than an argument for commenting. 
This *really* does not look "simple".
Hey epiris, if you don't mind could you tell me if by ACLS you mean permissions? The issue I'm facing only comes if I run via ssh terminal logged into Windows. Basically my program is trying to write to Windows credentials manager. (A specified login session doesn't exist. It may have been terminated) Underlying native API is CredWritew. I'm using cygwin as ssh server. But thanks very much for event viewer tip.
You didn't read what he wrote..
That's a problem with httprouter. It's the main reason I stopped using it. Other routers allow you to create those routes without conflict.
I appreciate the simple explanation of microservices followed by the-depth links as well. Thanks!
Why don't you call the function `Type` and return `Expr` which is a `const int` (from an enumeration)? You don't need any interface checks either.
I'd still need to implement Token() on each struct, and I need _Statement_s and _Expression_s to be separate types.
Yea, permissions. The fact it only happens during ssh is telling, Ssh server is probably running as network user, which you can think of like “nobody”. The path of least resistance is a windows service that runs under a service account with access to the api you want. Then write and deploy a small exe to manage it that you can use from ssh. The general problem your solving here is crossing user boundaries securely, so the same Unix solution space generally applies. More correct solution would probably be (windows service Local daemon) &lt;— (GRPC service listening remotely with client cert auth) | (grpc clients). When in windows world you need to be careful not to try to Unix your software into place, it’s a security nightmare as is so layering Cygwin on top of it is a bad idea. But if your risk / impact is low than it may be harmless. Good luck.
Define a common expression struct and embed it in your real structs type exp struct{} func (e exp) Expr() {} type someExpression struct { exp Tok token.Token }
Looks awesome! The link to the github repo seems to point back to the article
Good idea - I completely forgot about composition :)
Actually, my problem is a little different. I'm not actually writing anything that works in this kind of infrastructure. It's just enough for me to write a program which run in a box just fine. But when we want to execute that to try it out in a remote computer(for example, in a windows server), we are facing that issue. So, it seems like my problem is how to run a windows program in a remote windows with correctly with a right tool. May be I should use something other than Cygwin. But the program I'm developing might be used by customers, and if they also use ssh to login to their windows, then they might also face the issue. Thank you
&gt; The permission tag is a set of numbers like pex:"120123". Each index in the number string corresponds to a user type, that is, imagine that a regular user has the userType = 1, then his permission would be 2, which is the corresponding index on the 120123 string. That seems pretty far from friendly..
Thank you! :) And good spot, fixed! 
Thank you! I'll keep up that format in the new posts in that case 
This approach fails when the user specifies an import path deeper in the repo. I found the easiest way to make things work on a static state was a custom 404 page with all the possibly relevant meta tags: https://bazil.org/demo-does-not-exist-for-reddit
It's Go not Golang.
Go isn't very SEO friendly unfortunately. 
Ignoring the title...You care about "Golang" keyword density within your article?
For me it is readable but of course it would be since I was the one that designed it :) So what do you suggest to make it more friendly?
To make sure I grok this, are you saying that `go get foo.org/pkg/subpkg` fails with the current approach? With the current approach, getting a subpackage (e.g., `go get go.avalanche.space/lyft-go/auth`) fetches the entire repository. I _think_ this is the expected behavior, based on the fact that [rsc's meta tags do the same](https://github.com/nishanths/metaimport/issues/1#issuecomment-343622077). 
If the url fetched is not found in the static files served, and the meta tags are not included on the resulting 404 page, go get isn't going to find a working import path there. Repositories are always cloned fully.
Thanks for clarifying. `metaimport` takes care of generating static HTML files for the [each subpackage in the repository](https://github.com/nishanths/metaimport/blob/bebc2e9d18367dcd48a53cfcda4e8edea2eb5fbe/metaimport.go#L100-L149) too, so running `go get` on valid subpackages shouldn't result in 404s. If you find a case where it messes up, please let me know.
&gt; I cringe at using os.Exec() to invoke ffmpeg to do something like that, ... Well, just in case you're looking for a neatly-executed example of that: https://docs.google.com/presentation/d/1EvaSzUjQc4zUNJxDPMzsDFTwGt1HssSBUX1-jF_HsQc/edit#slide=id.p Also, I'd rather do that than use ffmpeg as a C library. When it's a subprocess, you can shove it into a sandbox.
That said, running `go get` for a package or subpackage that doesn't exist will return a 404 (instead of serving a 404 page with meta tags for all known packages).
 type Employee struct { Parent Income float32 `pex:"foo:ro,bar:rw"` } employee := Employe{...} x := ExtractFields(employee, "foo", ActionRead) y := ExtractFields(employee, "bar", ActionRead) 
Yes, this works very well for simple projects ;-) But for projects with several executables this does not work very well. So then I use a structure similar to the one here. From now on I will adopt this one.
Feedback: The text is nice to read and I am currently doing the tutorial and I liked it so far but got a bit irritated by some things: If you want that the user clones your GitHub repository [shippy](https://github.com/EwanValentine/shippy) you should mention it somewhere. You nowhere mention it so I think you want that people create it from the roots then you should mention the parts to be replaced in the makefile and to make it work on Fedora I had to replace $(GOPATH) with $GOPATH. build: protoc -I. --go_out=plugins=grpc:$(GOPATH)/src/github.com/ewanvalentine/shipper/consignment-service \ proto/consignment/consignment.proto I will add more feedback.
Very good points! I'll add an explanation on how people can follow along, and I'll find a more cross compatible approach to vars in the Makefiles, or make a note of that difference somewhere 
If `Expr()` func is only used to differentiate the two interfaces and the types which implement the interface are in the same package, this method could also be defined as not exported method, which would remove the necessity of having the method documented.
If `Expr()` func is only used to differentiate the two interfaces and the types which implement the interface are in the same package, this method could also be defined as not exported method, which would remove the necessity of having the method documented.
This is actually what [the `reflect` package](https://golang.org/src/reflect/type.go#L290) does for the various `Type` implementations.
Not saying you're wrong, since I obviously haven't seen your code, but why do you *need* them to be different types? I'm always wary whenever someone asks a restricted question based on the assumption that the rest of the code design that resulted in that question being necessary to ask was correct in the first place.
+1 on this, https://godoc.org/github.com/aws/aws-sdk-go/service/s3 (and others libs in that package) use this pattern a lot and I really enjoy it.
[removed]
Why gRPC/protobuf and not a more asynchronous method of communication? We use HTTP (either just plain `http.Client` or gRPC/protobuf) for some things (either internal or external services), and one issue we have with it is that it's really bad at dealing with temporary errors. For example when the service is down, DNS resolver is down, or got some mystery network error, then your entire microservice chain kind of breaks down. The way we "fixed" this is basically by just ignoring errors. We only use http services for non-critical stuff, and missing a few requests usually isn't a deal-breaker. Still, it would be better to retry a bit later, for "eventual consistency". We use RabbitMQ for some other more critical communication already, and that works really nice. There are definitly cases where you *do* want synchronous communication and hard fail when that doesn't work, but in my experience those cases are the exception, and not the rule. I don't know if you're planning to touch on this later on, but IMHO this should probably come *before* communicating over gRPC.
Is there a reason in particular you use "old" `golang.org/x/net/context` package instead of the `context` package Go ships since 1.7?
It's not _needed_ as such, but it helps because the compiler ensures at compile time that I only have expressions where expressions should be and the same with statements.
Or you could have the master in a sandbox, and don’t have process spawning overheads. What you suggest is wasteful of your systems resources, especially when dealing with low latency streaming (short keyframe intervals like 1-2sec). 🤔 Edit: just wanted to add that I’m refering to playing back a VOD file, which is a different beast than live streaming. People can seek into vod files requesting specific chunks, usually ffmpeg would be then used to extract one chunk at a time unlike Brad’s long running ffmpeg for the purposes of a live stream. There’s also other considerations like remote storage which is better interfaced at cgo level with such libs (if theres no go implementation...)
I actually do leave a lot of code review feedback that includes "add a comment here clarifying..." But I alone should not be in charge of figuring out where comments should go :)
I'll link to a few tonight. I thought about doing so when writing, but just got lazy. 
[Seems to work well enough](https://duckduckgo.com/lite/?q=Go%20microservices)
There is generally no reason to have asynchronous API Interfaces in Go. But it's easy to start a go routine for that if needed.
Goroutines stop when the process is killed, so doesn't seem very safe to me. Roll out in the wrong moment and you lose data. Also a performance/ddos issue. what is hundreds of thousands or even millions of requests fail? Goroutines are cheap, but not *that* cheap.
If you're talking client side then there is no issue, but by default Go network calls are asynchronous because of how it's tied to the network layer but appear synchronous. Do again no need for asynchronous API. 
I'm not sure if we're talking about the same thing here; so let me give an example: Our service accepts emails and we run a spam check with SpamAssassin and some other tools. To do this we have a small microservice called "mailchecker" which we communicate with over http. A few weeks ago the mailchecker service ran out of file descriptors and was offline for an hour or so. All emails accepted in that period weren't checked for spam. Not great, but not a disaster either. If we had instead used RabbitMQ to communicate the messages would still be in RabbitMQ's queue, and the emails would still have their spam status checked.
Personally I'd rather send everything to my logging service and only perform filtration afterward. Better to have insight you don't need then to need insight you filtered out early in the process.
Indeedy, and it's an annoying reason. The old context package is used throughout Google's protobuf libraries still, and because of the strict typing, "context" != "golang.org/x/net/context" so you get type errors. Unless that's changed recently (it could have?), you're forced to use the old package :( 
I don't like it either. I mean, the directory structure looks like it would be useful in some cases, and a lot of the ideas seem to have been taking from existing projects, like Golang Tools; Dep; Docker; and Kubernetes, but the name is definitely misleading especially for those who are new to Go.
Looks pretty straight forward to me, isn't that what simple means?
That makes sense from a HA point of view for fail over, but what does that have e to do with Go grpc Interfaces needing to be async? Unless I missunderstood your original message. 
In that situation there's nothing wrong with having a queue-based service which uses protobuf! I actually have worked on a library which defines the building blocks for these type of asynchronous services.
Looking forward to the next ones! Great write-up.
Thank you! Really appreciate it! Next one should be completed in a couple of days :)
ROFL, yeah, that's the first thing I noticed with this, and I'm not even the kind of guy that notices that kind of stuff (I guess when there's nothing else your brain can match the word with, it falls back to "as tits")
With Go 1.9 and the latest version of the proto generators it will use “context” instead of x/net/context
This is exactly NOT what the community needs. Don’t be nit picky. 
Go 1.9 introduced type aliases(I guess, not sure). So, you can use context package instead of net/Context.
hey, pls stop trolling here, thx.
Off topic. Don't use "I" in front of an interface name. In C# or Java that's okay but not in Go. Use "New" instead of "Create". Less is better.
It's much simpler to sandbox an ffmpeg subprocess ("this should do nothing else but read read stdin and write stdout"), compared to sandboxing the complete, complex, app, which may include network activity etc. Sure, you don't want to spawn several ffmpegs per second. One per user-initiated seek might be doable, as long as you're not trying to provide a live video preview during the seek (which I actually love as a feature). For lots of little things, I'd try to build a "command mode" on top of the ffmpeg libraries, still keeping the codec well contained.
Well, considering that I think the example fails to handle errors properly, and that fact is really hard to 1) notice or even 2) ascertain because of all the moving parts, I'm gonna go ahead and say that I have no idea how this can seem "straight forward".
Huh what? It seems you're trying to draw a distinction between "return a 404" and "serving a 404 page". That's the same thing. `go get` asking for a HTTP resource that doesn't exist gets a 404 response, if that 404 response has the right meta headers `go get` will happily follow them. And I'm the reason that works ;) https://github.com/golang/go/issues/13037
It messes when a new package is added.
Have you checked for an update on those libraries as i thought they were using a compiletime flag to gate the context library? or have they not rolled that out to the protobuf stuff?
The community needs generics, but that’s a lot more difficult than typing the correct name. 
Agreed. Different projects call for different structures. Go is a multipurpose language that there really isn't a particular Go project structures. One single folder structure with just .go files can be sufficient if you are writing libraries.
Also, just read the comments here :) https://twitter.com/gonedark/status/931195727195332608 https://twitter.com/schmonz/status/929009042546098177 https://twitter.com/ChristosMatskas/status/931875045684727809 
&gt; It's true, not having overloaded methods is simpler. But it also bloats your code base by forcing you to come up with unique names for otherwise identical functions On the other hand, the different function names are already half of the documentation. In the provided example, it is quite clear what `ParseWithLocation` does differently compared to `Parse`.
Or even have a separate []ACL argument which defines the ro,rw rights etc. Because permissions may change in the runtime, however Go field tags will not. 
I wish I had the knowledge to actively help Delve, but unfortunately I don't. All I could do there was opening issues. So yeah, I get your point... saying that the core team doesn't care about debugging isn't fair. However, it seems to me that it is a matter of perception. Even though there are efforts to improve debugging, as an end-user of the debugger, I don't have the perception that it improved since the last 1 year. Like I said earlier, I'm not a full-time go developer yet :( so I'm probably being unfair here, but what I mean is that: people might not be realizing the improvements that are being made not only in debugging but in other aspects as well.
You could use [delve](https://github.com/derekparker/delve)
Is there a paticular reason for using protobuf instead of [gob](https://blog.golang.org/gobs-of-data)? It would just seem to me that if everything is being written in Go, that gob might be a tad more simple to implement.
One more of these "I don't know how the language is called but I'll write a series of blogpost on it because being an expert includes the right to name things!". (Please note before explaining that "Go" makes a bad search term and therefore it must be called Golang wherever possible: Linking to the official golang.org site might be better than 20 "Golang" terms on the page for search visibility.) 
 way to sound like a tool man
Why do you think I'm trolling?
Thanks!
By opening those issues you contributed to Delve, so congratulations!
Shooooooooooooooooooooooooooots! I'm from Maui! I never thought I'd see someone from Hawaii post about Go. Do you use it professionally? Do yourself a favor and use Meetup. It seems kinda lame but you'll be surprised at the response.
[removed]
[removed]
[removed]
[removed]
because no generics
Thanks, I didn't even know this existed! It seems much simpler without the need for a protocol compiler.
It's a bit naive, as ffmpeg can have network activity (reading a file from a remote source like S3 or http hls/hds stream...), as well as privileged level access to libraries like CUDA for transcoding purposes. There's a very limited set of circumstances where sandboxing ffmpeg would be possible, and further limited by your actual requirements on the app side. It feels hacky to even try to wrap a media server solution around only the ffmpeg binary. But alas, if you want, I can't really stop you :)
&gt; I am hearing that from everyone for almost 3 years now and to this day there isn't even one LLVM optimization pass done by Rust developers that I am aware of, why is that? We do contribute to LLVM. However, for LLVM to get the kind of aliasing info we have it would require large changes and it's probably just not worth it. We'd rather do the optimizations on our side. It took nearly a year to get the framework in place (MIR) that lets us even think of doing this. There is a _ton_ of higher priority compiler work in the way, but I suspect folks will get to it eventually. Just because something is possible doesn't mean it's high priority.
[removed]
[removed]
[removed]
[removed]
I think this is one of those things, where i am sure it is pretty good. But it just seems like solving a issue that only google has. 
Default is ctrl + shift + a
`C:\golang\codes` Code not formatted with gofmt.... Why make examples if you don't know what you're doing?
This shortcut for macOS ? I’m using macOS 
[removed]
command + shift?
I expected this to show patterns from stdlib internals. Not how to use packages in the stdlib
Very true!
I'm a little late to the discussion, but I've been working on a tool ([documentation](https://havoc-io.github.io/mutagen/), [repo](https://github.com/havoc-io/mutagen), [FAQ](https://github.com/havoc-io/mutagen/blob/master/doc/FAQ.md)) to enable exactly this sort of workflow. The bottom line is that it's a cross-platform bi-directional synchronization tool, but unlike the competition (SSHFS, Syncthing, Dropbox), it's purely user-space, operates over SSH, handles conflicts properly, only needs to be installed on one side of the connection, and is much more robust to connection dropouts. The idea in your case would be to basically mirror the code on the remote system and use a locally installed IDE to edit the local copy. The tool is still lacking a little bit of UI "sugar," but the underlying algorithm is complete and pretty fast. I'm using it to enable a very similar workflow (using Sublime Text locally and mirroring code to remote servers, virtual machines, etc). I'd be interested in feedback if you give it a shot.
This is probably a little late, but see [my other comment](https://www.reddit.com/r/golang/comments/7cwj9k/remote_ide/dq4ybzi/) for a solution I've been working on. I know you're against synchronization, but maybe it's simple enough to sway your opinion :-)
I had searched keymap with command keyword. But turn out it is “find action”. Thank you very much. You saved me many hours. 😊
dem page views pay the bills
So, you are saying that instead of declaring the permissions in the struct, the developer would create a map "Field -&gt; Permission" and send it to the "ExtractFields"?
There's also double-tap shift which will open "Search Anywhere". It's been a bit buggy for me at the moment though, so I've stuck to just opening files, can't remember the default shortcut for that now...
That seems pretty fair! Although I wonder in case you have user types with long names if that still remains user-friendly :S
I love this IDE!
I do like this new addition of the build config but would love drop down boxes in a build config for the GOOARCH and GOOS variables. I'm forever looking them up!
Me too! It really is so much better than VSCode etc!
Have a look at: Settings | Languages &amp; Frameworks | Go | Vendoring &amp; Build Tags
thanks
Yes that is what I use as a reminder but would be nice in some drop downs on the build config per build
"so much better" is really a stretch, if it is better at all, but it is nice to have an IDE available for Go to attract the class of developers that prefer to have an IDE! Great work.
I've filed https://youtrack.jetbrains.com/issue/GO-4939 for this, thank you for the feedback!
Gotta be honest, this has been a great way to get better at Go.
Could you please describe what the IDE could better in order to improve? Thank you!
Thank you!
Should EAP 20 have migrated my run configs? They are showing up as unknown. https://imgur.com/TjfvBsG
Are they still planning to have no community edition?
Same here 
I just raised this... https://youtrack.jetbrains.com/issue/GO-4943 
Why not pay for it? 
It did. Since 1.9, [`golang.org/x/net/context.Context` just aliases `context.Context`](https://www.godoc.org/golang.org/x/net/context#Context).
[removed]
It's just not something I need. It has some nice-to-haves, but compared to VScode or Atom with plugins, it's not enough to make me consider spending the amount they generally charge for a license. If they had a community edition I'd make the switch, because it is a nice IDE, which is why I ask. I'm sure it's worth it for plenty of people, just not something I need. Hell, I end up writing code in vim most of the time.
That seems pretty fair! I have used it :) You can check the changes in the repository! Thank you for your suggestion!
"ffmpeg might do all kinds of things" is a great reason to sandbox it when you only want it to do a single well-defined thing.
All search engines know that 'golang' and 'go' are the same thing, so it's necessary (and unnatural). You can count the number of times 'golang' appears on golang.org on one hand. The takeaway is that 'golang' is a longer version to be used for identifiers in a namespace that enforces uniqueness.
Hi, thanks for asking. I don't feel as though my feedback would be valuable as I am not your intended audience, which was what my comment was about -- there just always seems to be a certain type of developer who prefers the command line and a text editor, and certain class of developers who are more comfortable learning the idioms of a particular IDE and becoming real power users within that environment. As far as my quotes around "so much better", and being someone that has heavily used Intellij Ultimate in the past for Java development, that remains to be seen, at least in my opinion. I am equally productive in my current environment of the command line and VSCode. I understand the arguments of "well you really need to spend time to learn to be productive in the IDE and learn the shortcuts" and whatnot, and I understand that, but that's kind of my point -- I have already spent time learning the command line and the command line tools and unix utilities and my editors shortcuts. If time was free and I had a couple months, maybe I could step back and give a better assessment, but the advantages of GoLand would have to so far outweigh using the commandline and standard tooling that it would be considered stupid not to use GoLand which by initial pass we know not to be true considering GoLand/Gogland EAP has been available for quite some time and vi is still the #1 editor for gophers by a mile, followed by VSCode *then* followed by GoLand (and I think I am being charitable here, I believe Sublime or Atom might even be higher). If it were really so plainly obvious that GoLand was "so much better" I think we would have seen a tipping of the scales. In general the IDE seems to be coming together nicely, and you have definitely done a nice job, it sounds like people who are real Intellj enthusiasts are pleased, so definitely kudos to you! There will always be those developers who prefer to use an IDE, you serve them well.
gvm integration?
I have looked at this before looks cool but are there any examples of the distributed mode ? The docs talks about hash function. But other than that there seems to be no HA/Gossip network/rebalance or the scatter/gather function etc. Are you saying starting up several riot engines on a known numbers of servers from the start ?
I think you are confusing between real time systems and embedded systems. Not all Embedded systems are real-time nor do they need to be. For instance, an ATM is an embedded system. They usually run some form light weight Windows CE or Embedded OS. There is no need for real-time responsiveness. It is fine if a response takes couple of seconds. But it it still is a an embedded system. "Efficient" is a subjective term. For an ATM, "efficient" may be light weight software running on lot cost hardware and giving responses in couple of sec. Other systems might be real-time or close it, but not necessarily embedded systems. For example stock market related CEP systems might be large distributed systems with terabytes of RAM and lots of Processing power and operate in real time. 
I think the biggest reason is in the introduction of the article you linked. &gt;And for many purposes, including communicating with tools and systems written in other languages, they're the right choice. &gt; &gt;But for a Go-specific environment, such as communicating between two servers written in Go, there's an opportunity to build something much easier to use and possibly more efficient. If you want a language-agnostic encoding format, use protobuf. I don't think there's anything wrong with gob, but I think protobuf is a more practical choice when dealing with lots of microservices and potentially multiple teams (who may or may not be writing those services in Go).
Any word on when the IntelliJ IDEA plugin will be updated? That one's currently at version 14 (as of early September 2017).
Downvotes for this amateur night bullshit. We don’t need this low-effort “please check out my useless web page guys” crap. 
Rob’s quote on how this is *not* basically a language research platform really drives the point home. I have Haskell for those times when I want to curl up with some hot cocoa by the fire and learn esoteric computer sciency things. I use Go to build stuff. 
Use IntelliJ IDEA 2071.3 EAP and it will be updated.
generics
What kind of integration would you like to see? The IDE can manage multiple Go versions by itself, per project, without the need of gvm or similar.
Distributed examples in the data directory, use etcd management.
What company is using Go out there? I'll send a resume. I've been trying to get back on the island for a while, but the mainland is cheap and pays well.
More features are still planned and in progress.
Ok, so how do you add/multiply quaternions/vectors/matrices in your code? Or does that not make sense to you either? Overall I've seen far more people bitching about operator abuse than the actual abuse during my career (20+ years).
More features are still planned and in progress.
I updated README.md, more features are still planned and in progress.
GoLand doesn't currently have context-sensitive help. When pressing F1, it should bring up the documentation for the word in the editor that the cursor is currently on. This is very basic functionality for an IDE - Delphi, Visual Studio and many other IDEs have this, I am surprised GoLand didn't implement it. If you can't ship a Go programming reference with it, pressing F1 should at least perform a Google search for the word at the cursor.
Ctrl+click transforms any word in the code into a hyperlink. Also, the debugger works, with breakpoints and step by step execution. These are really nice to have.
With every new release I try to download GoLand in order to give it a new chance, but as soon as the indexing kicks off and my computer sounds more like a jet motor I quickly retire to vscode. Imo the only feature vscode is lacking is good renaming functionality, but this should be fixed upstream anyhow 
You mean like it does with Ctrl-Q on a given symbol or something else?
Is it possible to enable the “introduce local variable” option for expressions which comes up on right click?
&gt; I'm not really an IDE person, I prefer minimalism. It certainly depends on your taste / needs, there's no doubt about that. But depends on where you draw the line between by minimalism vs functional / helpful. Or is this an UI / UX issue? &gt; Maybe you can convert me. Are there any features you can't live without in Goland? I won't try to convert anyone, the best I can say is: give it a try and see if you like what you see. And if not, maybe spare a couple of minutes to drop a note on the issue tracker of why you don't like it / where it needs an improved. As for the features that I use daily, in a totally random order (and definitely not all of them): - refactoring (rename) / extract (functions) - implement interfaces on types / navigating to/from interfaces to types - find usages / call hierarchy - inject languages (especially when working with SQL database that's &lt;3 ) - (smart) completion (which actually works better the more code you type / the IDE reads) 
&gt; With every new release I download GoLand in order to give it a new chance, but as soon as the indexing kicks off and my computer sounds more like a jet motor I quickly retire to vscode. That is a bit of an annoyance yes, but on the other hand, once it's finished, usually within a couple of minutes (and usually once per IDE / plugins upgrade), then it won't stand in your way. It's the feature which allows things such as telling you in an instant which interfaces are implemented by a type, navigate from an interface to all types that implement it, have completion sources from across the whole GOPATH as well as the refactoring functionality you mention. It's a shame that you so quickly dismiss the IDE because of this.
It depends on which platform you are working on / what keymap you have. It can be either F1 (on OSX) or CTRL+Q (on Windows / Linux). Furthermore, this Quick Documentation feature works on the completion dialog as well as other places in the IDE. You can lookup the key for you by going to Settings | Keymap and searching for Quick Documentation.
While I agree with you in general, that the whole thing with Go needing to be a snowflake is silly, your implication that type inference is a feature taken from C++ or closures is a feature taken from JavaScript is ... misinformed to put it politely. Actually pretty much every language source you listed is wrong.
Just popping in to say that as a front-end developer whose only just slowly getting into Golang, the IDE has helped a lot in learning the fundamentals. Thanks for your hard work.
Thank you! I'll pass it to the devs (who are watching anyway).
This works for me just fine. 
Yes, please see the video: https://youtu.be/UFUWZmcQEAY
I've dabbled with GoLand and it's prety nice, but ultimately I need to be able to work from more than just one device/platform. I'm running the self-hosted version of Cloud9 and I can code from anywhere that I have a browser. Yes, it lacks many of the more advanced features you get with a full IDE, but integrated debugging and such are less important than "being able to work at all".
Do you pre-index the Go standard library, or is that done on the client?
The Go SDK is too small compared with the rest of GOPATH in general. And as usual, the faster the drive (SSD preferably), the CPU and memory are, the quicker the IDE will finish. I'm not saying that there's no bugs, but if you think it's taking too long to index your environment, please either ping me or open an issue and I'll be happy to guide you through the process of profiling this so that the team can have a look at it.
Wow, didn't know about this, thanks
I haven't noticed it myself, I'm just thinking out loud about the other poster's issue. Generally speaking, though, I'm in favor of pre-rendering if the output is always the same, but I also don't know the extent of the indexing you're doing. 
It will never become better than vscode or emacs. But if you are used to use the best Java IDE ever made (IDEA) then you'll use it. That's it.
 &gt; refactoring (rename) / extract (functions) available in vscode &gt;implement interfaces on types / navigating to/from interfaces to types available in vscode &gt; find usages available in vscode &gt;inject languages (especially when working with SQL database that's &lt;3 ) I'm assuming you mean run hard coded queries from your source files without running the application. If so, vscode can do that. &gt;completion available in vscode
It sounds like there could be something wrong with your machine tbh. I’ve always found the sound to be more like a helicopter;)
I haven't said some of them are not available in vscode, but use them and you'll notice the difference. Or maybe not. If vscode is good enough for you then that's ok.
&gt; &gt; refactoring (rename) / extract (functions) &gt; available in vscode Is it the same though? For example, in the code below if I rename `bar` it renames the function definition, the invocation, the comment and it offers to rename the string literal. Does vscode do the same? // foo calls bar func foo() string { return bar() } // bar returns a string func bar() string { return "bar" } &gt; &gt; implement interfaces on types / navigating to/from interfaces to types &gt; available in vscode Similar question here. Navigating from an interface to its implementations is easy, but is the reverse possible? i.e can you ask vscode *"which interfaces, if any, does this type implement"*? &gt; &gt; inject languages (especially when working with SQL database that's &lt;3 ) &gt; I'm assuming you mean run hard coded queries from your source files without running the application. If so, vscode can do that. It's a bit more than that. Intellij IDEs can provide sql autocomplete and dialect-specific syntax check inside string literals. For example: query := "SELECT * from `my-table` WHERE id=?" here, the IDE can autocomplete `my-table`, `id` and automatically add backticks (`` ` ``) if you are using mysql.
&gt; but ultimately I need to be able to work from more than just one device/platform Intellij IDEs work on Linux, Mac and Windows. What device/platform do you have/need outside of those?
I spend most of my time on a Chromebook.
In that case, you might be interested in [crouton](https://github.com/dnschneid/crouton) (if you are not already aware of it) which lets you run regular linux apps.
&gt; It will never become better than vscode or emacs. What is it missing that makes that huge of a difference?
I am aware of it. It might even be possible to run GoLand IDE in Crouton on an ARM-based Chromebooks with a little work. But I can also just use my C9 environment and not have to jump through any hoops at all, and be able to work from any device with a modern browser.
You can play with this yourself. Remove the GOPATH entries from your settings (Settings | Go | GOPATH) and then File | Invalidate cache and restart... Do the restart and see how long it takes to index the Go SDK only. Then you can add the GOPATH back and see how long that takes. In my case, Go takes 35 seconds to index (+ the current project which is small enough) while the whole GOPATH takes about 6 minutes (~24GB). I do have an SSD and an i7 6700HQ CPU.
&gt; I don't feel as though my feedback would be valuable as I am not your intended audience Any feedback is valuable as long as it's constructive. As you said, at the end of the day, it really depends on whatever a developer prefers in order to get the maximum productivity. And thank you for the kind words, I'll pass them along. 
But he asked you why you would stay in goland vs vscode, implying what does goland have that vscode doesn't
After invalidating the cache, my laptop takes 31 seconds from hitting enter on the startup command to launching and completing the indexing. I've only got a small test project, but I also have a fairly beefy laptop (i7-7500u, 16GB, SSD). 
I believe /u/callcifer made an excellent write up of those features and their differences: https://www.reddit.com/r/golang/comments/7ehuhy/goland_eap_20_is_out/dq5mx21/ I am not a vscode user so I cannot tell you how it compares. All I know is that everyone working on medium to large projects prefers GoLand for its speed and some of the things above. Like I said, I don't try to "convince" anyone of anything, the IDE is available for download and you can try those yourself to see how they stack up.
&gt; Is it the same though? For example, in the code below if I rename bar it renames the function definition, the invocation, the comments and it offers to rename the string literal. Does vscode do the same? Method and comment but not the string value. I think you might be able to do the string value with Ctrl + F2 though. &gt; Similar question here. Navigating from an interface to its implementations is easy, but is the reverse possible? i.e can you ask vscode "which interfaces, if any, does this type implement"? Callables, no. Which is why I didn't quote it. &gt;Intellij IDEs can provide sql autocomplete and dialect-specific syntax check inside string literals. That I'm not entirely sure about because I use Procedures instead of SQL strings. I know you can do it in standalone files but it wouldn't surprise me either way if you could, or couldn't, do it.
Good to know, thanks. Ultimately, everyone should use whatever they are comfortable with. Personally, I've been using Jetbrains IDEs for a *very* long time and I can't imagine switching to something else and losing my efficiency and customization (macros, keybindings, UI arrangements etc).
1. Goland's reφactoring works even if there're errors in a code. Also, GoLand asks if you want to rename all receivers or just one. This is a noticeable advantage. 2. Indeed, interface implementation is about the same. Although I am afraid it may not work if there're errors in a code. Noticeable advantage, not big though. 3. Indeed, guru works great. Although it definitely doesn't work when there're errors in a code. Not a big advantage of Goland again. 4. Language injection. Not sure if it worth a mention. Too much cases of such injection is a sign of poor code. 5. Completion is better with Goland: * Works even if there's no import. The best gocode can do is to autocomplete on standard library. Goland does this for all GOPATH. I cannot say this is a big advantage though. Nice to have, but minor. * Goland reorders autocompletion based on context. I don't found this feature working well though. But I really dislike Goland doesn't support standard linting on the fly. This is an area where my Emacs setup is totally superior. IMO Goland has an advantage in general but I would not call it significant and all well supported editors like Emacs, Vim, VSCode, Atom, etc with 3rd party is nearly as potent as Goland. 
I want Go(g)Land to automatically read the appropriate Go version from a .go-version file, just like IntelliJ reads the Java version from jenvrc. Users shouldn’t have to manually configure their editor, nor depend on editors to setup projects. Editors should be able to read project settings from the very same files that CLI workflows use.
&gt; I am not a vscode user so I cannot tell you how it compares. Being a long term user of Jetbrains IDEs, I'm definitely in the Goland camp, but I'm also the [vscode maintainer for Arch Linux](https://aur.archlinux.org/packages/visual-studio-code/) and as far as I can tell, people who come from a Sublime Text / Atom / Notepad++ background are quite happy with vscode's Go support.
I used something like this to get SublimeText keymaps: https://github.com/ekaragodin/idea-sublime-keymap I find it has most the equivalent functionality as SublimeText. The multi cursor support isn't exactly the same but it is close. 
This is generally not what you'd want I think, but the `reflect` package does support initializing values from an `unsafe.Pointer`, assuming you know its type in advance: https://golang.org/pkg/reflect/#NewAt
Anyone using u-root here?
Thank you for the information, this is very helpful. I don't understand, however, why every IDE I worked with until now calls this "context sensitive help" and binds this function to F1, and GoLand names this differently and binds to a different key. I don't mean to criticize but honestly try to understand why things such as this happen. It is.. strange!
[removed]
Has anyone looked at how this package compares to https://github.com/Comcast/gots?
Agreed, it should. I've added your feedback here: https://youtrack.jetbrains.com/issue/GO-3031 Please feel free to vote it in order to keep track of the issue. But without more people voting for it / explaining why it's important, this doesn't look like a very popular request compared to some of the others.
&gt; 4. Language injection. Not sure if it worth a mention. Too much cases of such injection is a sign of poor code. It depends on what you work on. If you have SQL code you want to analyze, that's useful. If you edit JSON, that's useful. If you write Go code inside a Markdown document, that's useful. If you write Go code inside Go code (for generators to use) that's useful. &gt; But I really dislike Goland doesn't support standard linting on the fly. This is an area where my Emacs setup is totally superior. Can you please explain what would you like to see more than the current inspections? And btw, the way they work right now is on-the-fly, real-time, as you type, without having to save the file or do anything else. I would say this is a big advantage over anything else, knowing something goes wrong as soon as you do it and (sometimes) having the option to let the IDE fix it for you. Thank you for the feedback.
This is because the IntelliJ Platform (all other IDEs from JetBrains) name it like this and have these shortcuts by default. You can of course customize it as needed. Hope it helps.
Websockets are upgrades over the http protocol. Try http long polling to a list/map of http writers. 
I would like to export each of them as a single gopm package as I done on npm. Do you believe that can be useful? 
I don't make money off my open source programs that I work on my free time so dropping a couple hundred american dollar every year is very cost prohibitive. Alternatively, if I was running a small company it would be even more cost prohibitive. Even if we were exclusively working in Go, it's a big money sink and when we consider that there are free alternatives. I would pay for a one time affordable license though.
Ctrl + shift + n for file
How does this compare to https://github.com/knq/chromedp?
How does u-root compares to *mkinitcpio* included in Arch Linux?
I like to use `make`, since it's fairly standard. One of the great things about this is make can assume that Go is installed on the builder machine, so you can `go get` other Go tools and run project "scripts" with `go run some_script.go`.
&gt; I don't make money off my open source programs that I work on my free time so dropping a couple hundred american dollar every year is very cost prohibitive. Personal licenses (which allow you to use them for both personal projects as well as in a commercial environment) are $89 / year in the first year and they drop to $53 / year after the third year. Or $8.9 / month. &gt; Alternatively, if I was running a small company it would be even more cost prohibitive. Even if we were exclusively working in Go, it's a big money sink when we consider that there are free alternatives. &gt; &gt; I would pay for a one time affordable license though (for non commercial projects). If you are an open-source maintainer, you can qualify to receive a free IDE, license, https://www.jetbrains.com/community/support/#section=open-source (GoLand will appear there when it will launch) Furthermore, here's a page that might be interesting for you: https://www.jetbrains.com/store/?fromMenu#edition=discounts The IDE is: For startups 50% OFF - free for: user groups, Open Source projects, Microsoft MVPs, students and teachers, for education and training - 25% off for student graduation - 50% off for startups Same applies to all their IDEs and talking to their Sales department might also help.
Oh, so that's the price it's going for? I retract my words then, 89$ is affordable.
&gt; Oh, so that's the price it's going for? I retract my words then, 89$ is affordable. I'm sure there are plenty of people that cannot afford that or are not willing to pay it, but I wanted to give people a rough idea on what the pricing is and possible options for getting a discounted license. Hope it helps.
I thought it was going well over the 100$ mark tbh.
So. Much. This. Neat implementation, but nobody else should have backed themselves into this particular legacy accident.
It the stdlib error isn't "debuggable", it's likely the operating system never gave Go anything useful either.
While I respect that people will all have a different preference and you being one of those who uses a command line for coding, how would you compare yourself productivity wise? When I first learned to code I would only use command line or a text editor, but since projects I work on now are thousands of files, it feels like using an IDE is the only feasible way to get around.
From /u/rsc "This only happens if you are reusing big.Ints (using non-zeroed receivers), which no crypto code we've written does, and also only if you are doing x^1 mod m, which is also super-rare in crypto. We don't believe there's anything here other than a dumb bug" -- https://twitter.com/_rsc/status/933156332030611456
To begin with, version control the scripts into some git repositories. Bundle into a Docker container, RPM, DEB, TGZ, or such. Gradually replace each script with a pure Go equivalent.
both of those work in VSCode too, btw.
Yeah, that's one approach to take, but you have to run two instances of a service for that, and with dozens of microservices – some of which aren't very critical or very commonly called – it kind of adds up.
&gt; No framework, and pure http(s) You’ll have a time to improve once necessary. This is a common advice that I see from Gophers, and I *kind of* agree with it. But ... on the other hand, at my $dayjob we've sort of written our own framework we use for a bunch of apps. I am reminded by Greenspun's tenth rule: &gt; Any sufficiently complicated C or Fortran program contains an ad-hoc, informally-specified, bug-ridden, slow implementation of half of Common Lisp. Or, paraphrased and more general: &gt; Any sufficiently complicated program contains and ad-hoc informally-specified, bug-ridden, slow implementation of half of a framework which solved the same problems already. Not saying that you should always use a framework, but I feel that the value of frameworks is vastly underestimated in the Go community.
I love Goland. I really do. I’m going to be a day 1 customer. A few annoyances for me as a noob... I feel like goimports could be handled more gracefully. I feel like the ide should cache lib uses and remove/add them as you work. Instead I end up having to goimports every file as I work. Better glide integration. Still a pain point for go as language but this the next area I am constantly struggling with. If you recognize glide, ask to glide install packages instead of go get them etc. passively check for latest versions. Could also be integrated with deps. Notice private repos. Type assertion should be something suggested to be done for types that don’t match. Generators for wait groups. Showing a reference of the “golang time” while doing time.Parse operations. I always have to look that up Warnings when you try to string(int) For some reason I still prefer to use command line git. Keep up the great work guys. Still my fav IDE besides Rubymine ;)
&gt; I just leave the line long and rely on the soft-wrapping of my editor One downside of this approach is that you have horizontal scrollbars in godoc, which is bad UX IMHO. Not always an issue, but something to be aware of, especially when you're writing public libraries.
&gt; Can you please explain what would you like to see more than the current inspections? 1. Community did a lot of great linters (golint which I don't need to setup for every project, errcheck, etc) which your IDE can't match. I prefer to have them on the fly rather than on save – these are not errors. Emacs check them on the fly. In Goland I will either have limited set of on the fly inspections or need to run linters on save – I said why I prefer to have them on the fly. 2. Visual design. The visual design of your editor is acceptable but not something to rave about. I dislike how errors are highlighted in your editor in all your products. I prefer how Emacs does this. I tried VSCode and also like their version more than yours. Probably Java related, Java GUI stuff somehow manages to look retarded on all platforms.
Appreciate the article. If you want to run an SPA quickly, I wrote Spin (http://github.com/everdev/spin) that will serve all static files in a directory and optionally redirect all non-asset URLs to your SPA. For SPA deployment, I've found Netlify to be the easiest.
&gt; Are there any features you can't live without in Goland? there's nothing. They are slightly better than the competition, but not by much.
Why, in the name of all that is good and holy, would you put a script into a Docker container?
Not for transport, for installation. Glue code is a vague term. If the script is meant to function as part of a machine, then install it so. If, on the other hand the script is meant to manage machines, and be invoked by humans, then just keep it in a git repository.
IMO that has the same severity as having too long a line in general; it's not like it's *great* if my editor has to soft-wrap. From this POV, I consider this caught by the second half of my answer :)
The two goroutines you have create run concurrently and hence the order they push to the channel is unpredictable. So, the Go channels are FIFO, you just have an unpredictable order of who goes first and who goes last *into* your channel.
I’ve long assumed there’s a real big opportunity for developing a framework that integrates the development/deployment of modern SPAs with golang APIs. This seems like a decent step in that direction, but I think there could be even more automation.
You can't know in which order the two go-routines are run.
Thanks for sharing.
If you switch the order of the go-routines the order also changes. I suspect (without digging into it) that it is related to the internal workings of go-routines - the compiler likely reorders code execution. If you change the channel to a buffered channel and omit the go-routines it actuall behaves like you'd expect: https://play.golang.org/p/NPb7khoh-F 
Thanks!
I think it boils down again to "are you a smart editor user or an IDE person" (no matter the phrasing). I use Jetbrains IDEs every day and love them, however I also am impressed but the quality of VS Code support. One thing to note here is that if I just want to quickly take a peek at the project and open a folder from command line I aways do it with code. Its nice it's very fast on startup and doesn't need to do indexing (visually at least it's unnoticeable). And if I'm just changing a handful of lines it's great to have some basic smart functionality in that scenario. However if I have GoLand fired up already or am going to spend more than just a few minutes - GoLand makes me feel just so much more productive. I do believe the speed at which the IDE empowers me to work on a code is much higher. Yes, there are similar features but one thing I've learned in regards to IDEs based on IntelliJ platform is that they are always superior to any smart editor while keeping things snappy (after initial indexing ;-)) and clean (for my taste and from my viewpoint).
In addition to the answers given to your by other users, please keep in mind that the Go Playground is deterministic, meaning you should get the same result each time you run a program on the https://play.golang.org website. If you run it several times on your local machine with the `go run` command you should see that sometimes `x` is `-5` and sometimes it's `17`.
@cs-guy I'm also interested in what people think the advantages/drawbacks are between my package and [gots](https://github.com/Comcast/gots). For what it's worth, I've started using [gots](https://github.com/Comcast/gots) first when I decided to switch to native GO to parse MPEG transport streams. But I was not really satisfied with the way it was built and above all its API. I'm not saying my package is built perfectly either but I wanted a package more idiomatic to GO. That's why I've decided to keep it simple and propose this API: - New(context.Context, io.Reader) (Demuxer, error) - (d Demuxer) NextPacket() (*Packet, error) - (d Demuxer) NextData() (*Data, error) and not split the code into multiple packages. Obviously the main drawback of my package is the fact that it's pretty recent but I'm testing against production data. I'm welcoming any kind of feedback :)
Please see my comment here: http://reddit.com/r/golang/comments/7ehuhy/goland_eap_20_is_out/dq609oe Given you are still on school you are highly likely to qualify to get all their IDEs for free.
Both goroutines block until the receive can succeed. The first receive allows a send in one of the blocked routines to succeed (undetermined order). There is no guaranteed order in goroutine scheduling.u
Thanks for the reply, could you please clarify what do you mean by "Generators for wait groups"?
I would suggest to add the possibility to use Go as a script language. D lang already support this. The she bang instruction would have to be ignored by the compiler. The code would be compiled into a cache so that if the source file is not modified, the cached binary can be used. This would make Go more convenient to use. This should allow to use packages as normal go programs. The only difficulty I see is with the current strong dependency with the workspace directory... and to convince people that this could be a good idea. ;) 
Why do you think that reloading or swapping go processes is lately getting so much attention? There are at least three projects in the last few weeks which have been submitted here that deal with this problem area. Why now?
I went back a bit just to add the links to [codegangsta/gin](https://www.reddit.com/r/golang/comments/7bbslf/codegangstagin_live_reload_utility_for_go_web/) and [gobwas/graceful](https://www.reddit.com/r/golang/comments/7c02cr/graceful_a_library_for_graceful_restarts_in_go/) which have been posted in the last two weeks.
Could you give some examples of what you mean by “context”? (OP and commenters)
https://golang.org/pkg/context/
Thanks for the link. As usual Dave Cheney illuminates, and makes me want to rewrite chunks of my code. 
I don't know? It's not really "new", I've been using this for half a year, and used another Python-based wrapper-script solution before that (which was a bit ugly and never made public). It's only yesterday that I took the trouble to remove the dependency on our private log package.
&gt; Community did a lot of great linters (golint which I don't need to setup for every project, errcheck, etc) which your IDE can't match. I prefer to have them on the fly rather than on save – these are not errors. Emacs check them on the fly. In Goland I will either have limited set of on the fly inspections or need to run linters on save – I said why I prefer to have them on the fly. There are tickets for all the various inspections that the IDE should add. Please go on the issue tracker https://youtrack.jetbrains.com/issues/Go and vote for them in order to help the setting the priority for them as needed / important for you. And if you can't find something in particular, please open an issue. Also, please note that on-the-fly for me means: in editor, without creating external files, invoking any external tools, or saving the file. If emacs/other editors do exactly this then that's great, I learned something new. &gt; Visual design. The visual design of your editor is acceptable but not something to rave about. I dislike how errors (including inspection warnings) are highlighted in your editor in all your products. I prefer how Emacs does this. I tried VSCode and also like their version more than yours. Probably Java related, Java GUI stuff somehow manages to look retarded on all platforms. Out of the box, the errors in vscode are highlighted exactly as they are in GoLand, but maybe I'm missing something? I definitely don't know how they are in emacs, so would you mind sharing a screenshot of how you configured emacs to display them? Or how it looks like? My IDE looks like this: https://i.imgur.com/iqshzvZ.png Thank you for your feedback.
To avoid the usual "it works on *my* machine..." issues.
Hi, Thank you for feedback! Please see the responses inline: &gt; I feel like goimports could be handled more gracefully. I feel like the ide should cache lib uses and remove/add them as you work. Instead I end up having to goimports every file as I work. The IDE currently has the option to automatically add imports on-the-fly, when it's save to do so, and when not it will ask you to disambiguate the import statement. It cannot currently automatically remove imports when they become unused, please follow https://youtrack.jetbrains.com/issue/GO-1268 for updates. You can meanwhile invoke the builtin formatter and that will remove them automatically. &gt; Better glide integration. Still a pain point for go as language but this the next area I am constantly struggling with. If you recognize glide, ask to glide install packages instead of go get them etc. passively check for latest versions. Could also be integrated with deps. Notice private repos. As the whole community is converging towards golang/dep, probably glide doesn't make sense to be supported. Regarding support for golang/dep, please see: https://youtrack.jetbrains.com/issue/GO-4201 and https://youtrack.jetbrains.com/issue/GO-4871 &gt; Type assertion should be something suggested to be done for types that don’t match. Do you have an example of this situation? A playground link or a link to a repository would be enough. &gt; Generators for wait groups. See /u/ignatovs's reply. &gt; Showing a reference of the “golang time” while doing time.Parse operations. I always have to look that up Please see / vote / follow https://youtrack.jetbrains.com/issue/GO-3366 &gt; Warnings when you try to string(int) I've filed in order to address this: https://youtrack.jetbrains.com/issue/GO-4951 &gt; For some reason I still prefer to use command line git. If you can think why that would be useful to know how the VCS integration can be improved. &gt; Keep up the great work guys. Still my fav IDE besides Rubymine ;) Thank you! And thank you for all the feedback, this is very useful.
And here I thought people are aggressively writing this stuff to avoid some third party process manager which does it for them...
I didn't know this! I was dubious so I had to try it out myself: https://play.golang.org/p/dhMO7xLZwn Super weird. I wonder if it's a function of caching the output that causes this, and not the playground's Go runtime being different. I feel like the latter part would cause issues since code running on the playground would not behave the same as code running locally.
Not looking good :( https://stackoverflow.com/a/29083319/977939 &gt; The problem with this is that OS X is based on BSD, and BSD doesn't allow you to program raw sockets at the TCP level. You have to use go down to the Ethernet level in order to do so. &gt; I'm using the pcap library with gopackets to do the job. &gt; https://godoc.org/code.google.com/p/gopacket/pcap
If anyone is interested, this package makes heavy use of go/ssa and go/callgraph to do the heavy lifting. With those, the core of detecting whether a parameter is unused is just a couple dozen lines. I went with the CHA algorithm, as that's the more conservative one. In other words, it detects calls that *may* happen, as opposed to calls that *will* happen. Of course, the devil is in the details - the many hundreds of lines of code are for all the edge cases and false positives that the tool has to deal with.
Do what?
What is an SPA?
Personally, I still don't think it's been done right. There's only been one that I've tried that's not been for a framework / library specifically, and all of the ones I've seen have been exclusively related to Go. It'd be kinda nice to have something that watches for some files to change and then lets you have a lot more control of what happens when they do (i.e. run a build, run tests, run some FE build pipeline, run all of those things in a script, run a long-running process and be able to restart it when more changes occur, etc.) I want a Go based solution, otherwise I'd just set up Gulp to build my Go code for me and run tests for me, but I don't want to rely on another languages tools and libraries, etc.
Single page application. Think Angular.js or Ember.js
Thank you.
I know that the go playground is frozen in time, that is, you will always get the same time from a call to `time.Now` for example, so it’s deterministic in that way. They also use some other tricks to fake things like `time.Sleep`, the file system and the network, which you can read about here: https://blog.golang.org/playground I don’t know how their modifications for the go playground affect things like goroutines or map key order though, so I would assume that those are to do with the caching, which is why I mentioned it. I don’t know how long the cache lasts, but it could be that if you happen to run the program again after the cache is invalidated that you might get a different result which would then be cached again.
It's always interesting to read about how a talk doesn't quite work. At the end I was trying to dismiss the idea of rewriting handlers as I had described in the talk, because if you take this approach it doesn't handle passing data between steps very well. If I'd had an extra 20 minutes it would have been interesting to look at how the handler example becomes complex, and what you can do about it (and ultimately how Go's simple type system imposes restrictions on how you can write code in this way). It's unfortunate it came across as dismissing everything up to that point. That wasn't my intention. The point I was trying to make is that a number of seemingly different programs ultimately have the same underlying structure, and understanding this structure is a step towards being able to find a simpler way of expressing the code. This is really just a teaser for saying "hey look, category theory gives us a way to reason about the composition of our code in general", but that is far beyond what I can say in 18 minutes.
This package is very simple and does just one thing: restart the process when the binary changes. It's not a generic file watcher, and doesn't aim to be. Personally, it seems to me that using an established utility is the way to go; I don't see much value of having it implemented in Go.
Yeah, I'm trying to figure out what is and isn't overkill. Obviously there's added benefit for deploying to S3 or a CDN, but for people who don't want to deal with CORS, this approach is more ideal. And you can throw a CDN like Cloudfront in front of it as well.
You can try [Task][task] + [Minify][minify]. (Or Gulp/Webpack/Browserify for front-end if Minify is not enough for this). [task]: https://github.com/go-task/task [minify]: https://github.com/tdewolff/minify
It isn't clear to me exactly what network architecture you are going for here, so all I can offer at the moment are these factoids: * Websockets _are_ upgraded HTTP connnections. There's no other way to get one. * If you're speaking to and from a web browser, the only truly bidirectional option is a websocket. If you are almost entirely sending and receiving only rarely, you can send server-side events (google around, there's some packages for it) and accept events from the client as independent AJAX posts. However, you will get rate limited by the browser as to how many of those you can have going at once. It's gone up (in the not-so-distant past it was 2), but you can still overwhelm that limit if you try hard enough. Some use cases you won't even have to dream about hitting that limit (user fills out a form, posts the results when they hit submit), others you can hit almost instantly (autocompletion tries to autocomplete every time they hit a key, and the total latency of the request is much slower than the rate they are typing keys). * If you are communicating internally, you can use TCP sockets directly. But you can't get a raw socket out to the web browser.
Too complex - I'd love some examples on how to achieve things like "tunnel HTTP traffic from my android phone in local network" to outside network. I used to do this with another Golang library you used to work on, but on this one I can't understand how..
To clarify what I mean by glue scripts. Before running any terraform commands, we have to make sure that: - terraform init has been run in the correct environment - that any terraform modules have been downloaded - we need to grab a couple secrets from AWS Parameter Store that serve as input to Terraform - etc... So I'm looking write a script that encapsulates some of these things in single commands like: `builder init staging`, and so forther
You're welcome! :D
The ability to be an elitist editor snob. When an IDE comes perfect ootb, there is little room to be a gatekeeper and tell others that they aren't real devs unless they use X Y or Z.
Could you explain what simple would mean to you. Or you just need a working example?
Yeah, I guess a working example would be great. Its really the same thing I was doing back then when you helped me an year ago: Local Network Android phone (192.168.0.101) Linux box (192.168.0.100) VPS 10.20.30.40 I want to expose an application that is running on the phone, port 8080 (say) so I can access from outside my local network. Server on VPS, Client on Linux box. What kind of config do I need?
Comment from above: &gt; I feel like goimports could be handled more gracefully. I feel like the ide should cache lib uses and remove/add them as you work. Instead I end up having to goimports every file as I work.
&gt; Comment from above: &gt; &gt; ... Is there anything that I should add to: &gt; The IDE currently has the option to automatically add imports on-the-fly, when it's save to do so, and when not it will ask you to disambiguate the import statement. It cannot currently automatically remove imports when they become unused, please follow https://youtrack.jetbrains.com/issue/GO-1268 for updates. You can meanwhile invoke the builtin formatter and that will remove them automatically.
Again, please fire your feedback my way! Really appreciated it last time. I'm still making improvements to the first article on the back of that. Cheers! 
Wait a minute.. You've built a binary and it's working on Alpine?
Yep! I use Alpine loads with Go! I used to use scratch or busybox I think it was, but found I had issues with certs and ssl :( 
Another question, in java etc, on pressing alt-enter within an expression, say a function call, there is an intent (I believe that's the word for it) which comes up to create a variable. Can such an intent be added to goland? I looked at the intentions list but did not find anything similar. Right now I use ctrl-alt-v to create variables from an expression (I also added the option to the right click menu as you listed in your other comment). 
Am I missing something? Your binary shouldn't work in Alpine. What's your libc?
I'm running it with GOOS=linux GOARCH=amd64 if that's what you mean? I've had problems with libc and Alpine in the past, I had to use Debian in a previous project. But I've not had problems with Alpine this time around. So maybe they've patched it? 
This definitely works for me, I develop the code first, then write the articles. Could you let me know if it works for you? Cheers! 
It shouldn't work. Go binaries are linked to glibc, but Alpine uses musl. So, it should not work. If you want to run your binary on alpine you have to build a new binary linked to musl or disable cgo. For example, you can build your binary with golang:alpine(not sure) and copy it to your container(COPY --with-builder, again, not sure).
I had the same issue until I copied the ca bundle file to the image and it worked with only scratch. Take a look at this: https://golang.org/src/crypto/x509/root_linux.go
I agree that not everyone wants to run tests - that's exactly my point. I am aiming to build something that could do exactly what your project does, but would give you the flexibility to run literally anything when something changes. You could watch for a change in a binary, all of your source files with or without tests, just HTML files, whatever else. Using an established tool would be great, but not one that requires an interpreter that's not widely preinstalled on a system. That's where Go would have it's advantage, it wouldn't need one at all!
You can just use the normal string methods in the regexp package. They support unicode.
Oh right! I'm confused as to why it's working for me in that case 😖 unless I'm compiling it with a missing library that's installed on my machine. I might switch it to Debian in that case 
&gt; I am aiming to build something that could do exactly what your project does, but would give you the flexibility to run literally anything when something changes. I'm confused what you want, because earlier you mentioned that a lot of tools have problems of "keeping track and watching new files as they're created", but my package doesn't watch any Go files at all – much less new files as they're created – it only watches the go binary. If you *do* want to watch just the binary and configure what happens when it changes, then I'm not against adding options for that. The only reason there are no options is because I never needed them and no one ever asked for them.
Really? I thought I tried that - I guess my regexes just didn't support unicode. Thanks :)
Haha, now I'm confused. From what I can gather, your project watches a Go binary, and restarts it if it changes. That's quite a specific use-case, a good one, but a very specific one nonetheless. I'm looking to make something broader, but not too broad, with some simple configuration. The tool I have in mind would be able to watch either a directory, or a specific file, and would be able to run _something_ when that directory (or files in it, including newly created files after watching has begun) or that file you specify changes. You'd be able to filter those things too, so if you were watching a directory you could say something like `**/*.go` to watch all go files, or `**/*.{go,html}` for example, and also make it so you could exclude files in the same way too. I'd be aiming to make it have some sane defaults, and would be trying to keep the configuration as simple as possible. You'd be able to use it to (for example) watch all of your Go source files that aren't test files and rebuild your binary then run it (maybe you'd use a shell script to achieve that). You'd be able to watch your Go source including yours tests, and run your tests and generate a coverage report in one fell swoop. You'd also be able to watch your binary and when that changes run something (e.g. the binary itself). It wouldn't be specific to Go, it'd be able to be used with any file types, and run any shell command (including shell scripts).
&gt; From what I can gather, your project watches a Go binary, and restarts it if it changes. That's quite a specific use-case, a good one, but a very specific one nonetheless. Correct. &gt; I'm looking to make something broader, but not too broad, with some simple configuration. That seems like a useful program, but is not really related to my project, as such. I mean, it's just 87 lines of code, half of which are comments, import statements, and other stuff that doesn't "do" anything. It's not especially hard to do, https://github.com/fsnotify/fsnotify takes a lot of work out of your hands with regards to file watching, but there are some caveats with regards to watching for new dirs/files and such (which is why many programs don't deal with this). It would certainly be a lot longer than just 87 lines of code :-) If there is a Go program that does everything that you want except new files then I'd create a PR for that.
I've already got the watching files part done, using fsnotify. They don't (yet) implement the recursive automatic directory watching, but it's quite easy to implement it yourself. It's just the running things / configuration I need to get done. I'd still not figured out how I wanted to handle launching shell scripts, but I may take an approach similar to Docker and default to `bash -c`.
The usual question comes to mind just quickly looking at the code: why MySQL, why do people still choose MySQL today over Postgres today at all? It's using Gorm but HARDCODED to use MySQL and no way to choose Postgres. WHY? Today we only use PostgreSQL so it really surprises me MySQL still gets chosen at all for new projects, it doesn't really make sense to me.
&gt; Go binaries are linked to glibc Only when some package actually pulls it in. Most of the standard library doesn't.
Golang is very very good at serving static content, too.
Yeah, I guess so, but still, we should be explicit about libc.
Yeah, I was referring to the "why does it work" part.
I've just realised why it works for me. It's fine on OSX, but not on Linux. That's why I had to use Debian for some of my other projects, because I use CircleCI, which uses Ubuntu... Which then fail with Alpine! I'll update the article to explain this, mention libc and also give and example using Scratch or Debian. Thanks again for pointing this out!
Hi! Good idea! To be fair that part wasn't given much thought at all. It's a young project and there is a lot to do so we just focus on the momentum right now. I have used Postgres in the past and it's great. We will have a look.
A lot of people are using alpine with Go and it's working.
In addition to what singron said, keep in mind Go doesn't use PCRE so details/syntax might be different. [Ctrl+f "Unicode" just to be sure](https://github.com/google/re2/wiki/Syntax) :)
If it's not broken don't fix it. Mysql has been part of the very common LAMP stack for 20 years now. It's a proven track record.
Sounds kinda like [modd](https://github.com/cortesi/modd) to me. Maybe except the "sane defaults", AFAIK modd doesn't do anything without config.
What's a "gopm package"? If it's just a chunk of json, embedding assets in a Go app is trivial.
Can you please tell me what is buggy about Search Everywhere? I haven't seen any reports about this so I'd like the chance to forward it to the dev team. Thank you! 
&gt; gopm I'm not a go programmer but I've found this that should be the equivalent of npm for go. Am I wrong? https://gopm.io/
At least on Linux, across all JetBrains IDEs I use (IntelliJ, PhpStorm, and GoLand) I've seen consistent behaviour, in the latest version (and some past versions) of all of them: every other time I open search anywhere, it opens without focus. If I click on it, it does regain focus, but it does throw you off. If you try type, or hit escape, it has no effect on search anywhere. I can try open it again whilst it is open, and it sometimes regains focus then.
As a package you can benefit of the versioning.
I can't actually remember if I tried modd or not now. Either way, I'll give it another shot, because this does look like what I'm after really. I might still have a crack at making one of these things myself just for a little project to work on. Thanks for the link!
There's no need for such in Go, it uses git natively.
Why would I get more response on meetup than here, do you think?
Nobody that I know of. I'm still trying to get go into play where I work, but I work for a SF Bay Area company, not a local company. If you find a Hawaii company that uses go, let me know! :)
Well, this was a bust. Too soon, I guess. Hopefully as people get more interested, this post will be discovered. I went ahead and updated [the go users group wiki page](https://github.com/golang/go/wiki/GoUserGroups) to point to the [google plus community](https://plus.google.com/communities/103024089946238586108) I created for when it's time to actually form a group.
&gt; When I first learned to code I would only use command line or a text editor, but since projects I work on now are thousands of files, it feels like using an IDE is the only feasible way to get around. I'm definitely an IDE person nowadays, but I used to have a vim setup that basically made it an IDE, and emacs is definitely capable of the same. You could arguably probably be more efficient with a custom-built vim/emacs configuration since you know exactly which features you have and how to access them, but the setup itself takes a lot of time and you have to basically build your own IDE out of different "modules." When I wasn't programming professionally I seemed to have a lot more time to tinker with my OS (i.e. Arch or Gentoo) or editor (i.e. vim/emacs.) Now I just want shit to work so that I don't have to attend to every single detail, hence I'll go for something like Goland over an artisanal vintage vim config.
Can't you just set `CGO_ENABLED=0` and it will work?
Most random seeds are based on the timestamp. If time is frozen then so are randomized seeds which could be used to determine which goroutine to run next if both are available.
I use sqlite with an in-memory database for unit tests For integration tests we attach a MySQL container (or postgres or a matrix if it needs to support several)
&gt; so each test should get its own fresh copy of the DB, and that's going to be really limiting/expensive/enforce them to be run sequentially. It has been surprisingly fast for me. I highly recommend this approach.
All the IntelliJ IDEA-family IDEs do that. I don't know if this is why they do it, but it does mean you can have per-project configs without knowing an OS-specific directory for storing the settings.
I think OP might not expect the "upgrade this HTTP connection" bit to be exposed as part of the API? It's not that odd for someone not to know this is how things work "under the hood" with APIs that hide this.
I’ve done something similar but slightly different setup. I have dgraph being built from event stream. Some changes to child nodes can bubble up and change parent nodes. To make that happen I have a consumer that builds the graph in memory (only the relevant bits to that mutation), consumes change events and follows up the tree via normal object reference. Where a change in parent is caused it will produce a new event in the queue and it will cause a chain reaction. That way the original dgraph isn’t really responsible for knowing how to mutate data up the chain, it only listens to events and makes updates. That solution decouples the specific business requirement from the way we are projecting data in dgraph, a typical event sourced + micro architecture.
Not OP but one reason I use the command line still is because the VCS operations shortcut C-V for me on macOS only allows me to push and pull. Also I had a question about GoLand's renaming ability. Whenever I rename a variable and the Find Refactoring Preview pops up, I always have to use my mouse to click `Do Refactor`. Is there any keyboard shortcut for this?
I am aware that it is unusual to announce paid products in this subreddit, but I hope it is still ok as it is strictly related to Go. If I am pushing the boundaries of the unwritten community rules too much please let me know. Since almost a year (not counting all the preliminary work), I have been working on an online video course about learning Go. It is made for everyone who knows how to write code but knows little to nothing about Go yet. I already announced it to my (little) email list when a few lectures were still in the making. Now as the curriculum is complete, I am excited (really!) to announce the course to a wider audience. 
&gt; Not OP but one reason I use the command line still is because the VCS operations shortcut C-V for me on macOS only allows me to push and pull. &gt; I'm not sure I understand. Can you please describe what you want to do and where is the IDE failing to do it for you? &gt; Also I had a question about GoLand's renaming ability. Whenever I rename a variable and the Find Refactoring Preview pops up, I always have to use my mouse to click `Do Refactor`. Is there any keyboard shortcut for this? It should be ALT+D, at least on Windows/Linux, (D should be underlined). Is it not for you?
I use KUbuntu 17.10 (KDE on Ubuntu), and I've used all versions since 15.10+, but I haven't ran into this issue so far. Maybe it's an issue with the Linux version you have?
[removed]
Thank you for your suggestion, I've created this issue: https://youtrack.jetbrains.com/issue/GO-4954 to keep track of it.
&gt; I'm not sure I understand. Can you please describe what you want to do and where is the IDE failing to do it for you? Sure. If I press CTRL+V in the IDE, I get the VCS operations popup. Looks like https://imgur.com/a/aPdBB I can push, but I can't pull. I could set a shortcut for this, but I don't want to do that when there is a VCS operations popup that I'd like to use for all my other VCS needs. So I just end up using only the git command line as its easier. &gt; It should be ALT+D, at least on Windows/Linux, (D should be underlined). Is it not for you? ALT+D works for that on macOS. Thanks! Though when you do press ALT+D instead of the "Refactor" button, the IDE does not replace any of the instances of the symbol in comments. Is there another shortcut that will replace the symbol inside of comments too?
Thanks, this makes a lot of sense. Do you have any experience with cayley? I'm responsible for building this component of our application but we're currently using postgresql for the application and oracle for our manufacturing/plant db. I've heard that dgraph is significantly faster and it seems to have better documentation; however, my boss is a little leery of using another database so I need to know if I should push for using dgraph over cayley. 
he is desperate to be accepted.
I don't. Even that dgraph deployment is new to us. The new 0.9 version released recently had some BC breaking changes (removed upserts) which caused us massive pain. We are cool with that tho, I mentioned the micro architecture - because dgraph servers only one function we are happy to put an egg into this basket, there's many other baskets with only few eggs in them too. If I had to base it all on dgraph I would probably think twice, but mostly how to avoid that central dependency ;)
Good to know, thanks thornag!
What's with this global `wordList` thing?
The IDE stores the project settings there so that they can be moved around by versioning the folder. This is something that's done in other editors as well. There's a ticket to separate the non-sharable files of the sharable one, please see: https://youtrack.jetbrains.com/issue/IDEA-90785
I suggest you this [video](https://www.youtube.com/watch?v=HxaD_trXwRE). 
Thanks!
It's a list of words and their definitions. I made it global because it's almost a constant, and I don't want to reload it on every connection. I would have kept it in a SQL database instead (querying the database instead of the `map`), but it's much easier to edit flat files than a DB.
That’s what I was thinking too, but I couldn’t find anything written by the Go team about it so the caching seemed worthwhile to mention as well. 
I enjoyed the flow of the writing. Thanks for the nice write up!
Some of the functions are big, might be better to break them down a bit!
You can find the source code of both Go Playground and Go Tour at: https://github.com/golang/playground and https://github.com/golang/tour respectfully.
ah, you should probably wrap that up in an struct somewhere.. it's a little weird that other packages inject words into the CompilerLibrary package via InitWordList
Is it good if I ignore the this folder. Is there any cons if I ignore it. 
We use Docker to spin up a PostgreSQL container for testing. Tests still run relatively fast and it's easy to setup for running on a dev machine and on travis.
http://wondermark.com/1k62/
If you mean gitignore, then yes it's safe to do so.
I think the structure of the project could be improved. Take a look at [this article](https://medium.com/@benbjohnson/structuring-applications-in-go-3b04be4ff091) for some tips. I also don’t like that the CLI requires you to spin up the sever locally. If you were to separate the logic from the http handlers, you could use it directly in the CLI. In general a http handler should only be responsible for transport related logic: reading from a request and writing the response. The actual business logic should exists some where else. [This example](https://gokit.io/examples/stringsvc.html) from gokit demonstrates this pattern well. 
Ya you will be surprised at the response, plus you can try it for free. Altho Go might be a bit specific.
Ya working remote is your best bet. How did you find your job?
This series so great. I would love to get notifications for future posts by email!
Exception handling cannot be compared to Go's panic/defer/recover mechanism alone. Go's error handling approach is a combo of errors as return values and panic/defer/recover, with a clear separation of concern between the two. This alone makes Go's error handling approach fundamentally different from excepion handling in other languages. I say "different", not "better" or "worse", because both approaches have their pros and cons.
Awesome!
Hi, I'm the author of sqlmock, which is meant to be used for unit tests only to test all critical paths possible for certain logic. But you should also have integration tests using your real database and for that. I have also built https://github.com/DATA-DOG/go-txdb which in general makes a database connection perform within a single transaction. That means, if you setup a database, all your tests will execute within transaction, when database is closed, transaction is rolledback. For that reason, all tests execute very fast and for every test you can have a clean isolated state. Also for integration tests, there is BDD framework - cucumber https://github.com/DATA-DOG/godog. All these tools are usually my daily stack for testing purposes. I also make randomized brute force like tests (which for example generates random data and performs assertions for a certain run period), since you will never find all edge cases in your unit or integration tests.
I second this. For the cli I would prefere a way to only call the compiler once. 
`CGO_ENABLED=0`
Strange port 9997, try setting the server on port 443.
Yep, I agree. I stumbled upon it yesterday and I wanted to share it. People have discussed it with passion back then :)
When you say `my parser` it sounds like you already have the data as a `[]rune` possibly for other reasons other than just the regexp matching. If that's the case then you can also implement a `` use [FindReaderSubmatchIndex](https://golang.org/pkg/regexp/#Regexp.FindReaderSubmatchIndex), [MatchReader](https://golang.org/pkg/regexp/#Regexp.MatchReader) or [FindReaderIndex](https://golang.org/pkg/regexp/#Regexp.FindReaderIndex) play.golang.org doesn't allow me to share so attaching an untested and undocumented snippet below. Feel free to question anything that's not clear. package main import ( "fmt" "io" "regexp" ) type runeReader struct { src []rune pos int } func (r *runeReader) ReadRune() (rune, int, error) { if r.pos &gt;= len(r.src) { return -1, 0, io.EOF } nextRune := r.src[r.pos] r.pos++ return nextRune, 1, nil } func main() { s := "Hello, 世界! 世 界 World 世界 World!" rs := []rune(s) re := regexp.MustCompile(`(?i)(\S+界 W\w+)`) fmt.Println("match:") fmt.Println(re.MatchString(s)) fmt.Println(re.MatchReader(&amp;runeReader{src: rs})) fmt.Println("findIndex:") m := re.FindStringSubmatchIndex(s) fmt.Println(m, s[m[2]:m[3]]) m = re.FindReaderSubmatchIndex(&amp;runeReader{src: rs}) fmt.Println(m, string(rs[m[2]:m[3]])) } 
Write your own NullUint64 type implementing the database/sql.Scanner interface.
A channel with buffer of zero items cannot have LIFO nor FIFO nor any other ordering semantics and the observed ordering of the values is decided only by the scheduler algorithm which is nowhere guaranteed to be deterministic. Actually, the more it's fair randomness, the better.
Peter, how's this any useful at all?
I didn't want to stop nginx on that server, but thanks, because on 443 everything works! BTW, one thing I found confusing on the server side is the use for those 3 args: -tunnelAddr ":443" -httpAddr "" -httpsAddr "" 
I'd also note that LtU appears to me to be "a bit" biased towards computer *science* — as opposed to computer *craftsmanship.* I mean, folks over there at LtU are passionate about discussing various approaches to meta-inference of dependent poliexistential types over coalgebras defined on monoidal semirings. That is cool, in itself, but Go is the language designed to get the shit done and I, for one, love it exactly for this practical stance. That's *not* to mean Go's design decisions is somehow low-tech, just a warning to perceive the LtU's gobbledygook bashing those decisions with a huge grain of salt. Stay reasonably down-to-Earth, remember https://xkcd.com/224/ :-)
Yep. Could I ask you to contribute some sort of tutorial of what you are doing? It's very cool and would be a great example to put GH wiki or project page.
Sure, I'll try. Thank you.
&gt; Exception handling cannot be compared to Go's panic/defer/recover mechanism alone sure they can, they are (inferior) exceptions. errors are values are just a convention, not a language construct. 
Cool, but I think you have a data race on the client list. Register and unregister are ok, but you read the list in the broadcast which happens in different goroutines.
Yes, that is a option, I was looking at the current implementation in the sql package, and it is rather complicated, and I don't want to copy&amp;paste the entire sql package. My question is why is there no built-in type in the sql package, from looking at their source code, it looks to me a simple matter of writing 10 lines per type (with their current code)...
Maybe Peter is trying to politely say "Please stop being a sea lion"? That's what I gather but not 100% sure.
Thank you!! I'll see if I can get email subscriptions set-up :) 
Maybe in their evaluation, most programmers would not use the nullable types so much and that justifies casting your (db stored) int32, uint32 into a higher capacity NullInt64. So, if you need this optimization, as /u/0xjnml said, you could use the interfaces and write your own.
Looks trivial to me: https://github.com/golang/go/blob/5476967b1a3d29fef4061999c00cadbec19ac0e3/src/database/sql/sql.go#L184-L208
Yes, it did to me too if not for function convertAssign, look here: https://github.com/golang/go/blob/ff4ee8816226b6c84690a56fb3b16c9210e68431/src/database/sql/convert.go#L209-L425
What i tried to say is that where other languages have exceptions *only*, Go has two separate mechanisms with two different purposes, so if you want to compare exceptions with Go's error handling, you have to include both mechanisms. Exceptions are the one-stop shop for error handling in C++, Java etc. As such, they are responsible for handling expected errors as well as unexpected errors. Go distinguishes between expected and unexpected errors. The former ones are return values, the latter ones are panics. So you cannot argue about panic/defer/recover alone and ignore standard error handling. One part is incomplete without the other part. 
It's always sad when mature conversations cannot happen. But then again, this is /r/golang and when people see leaders of this community act like this why would they want to improve themselves?
Not tested: https://play.golang.org/p/kfecNFJ1SO
To be clear: They support *UTF-8*. "unicode" is not well-defined in this standard. If your strings are not UTF-8 (for example on Windows, UTF-16 is still very common), you are going to have to convert them first.
The Dota 2 API is an interesting choice. It has a large amount of matches finishing every minute and offers good options for processing the data. It can be rather unreliable and requires rate limiting your own API requests, so is interesting to implement. You can get information about it [here](https://dev.dota2.com/showthread.php?t=47115). You could also use something more general like the Twitter [real-time tweets filter](https://developer.twitter.com/en/docs/tweets/filter-realtime/overview). A real-time dashboard for a particular brand/event/sport might be interesting to you?
Oh yeah - what I meant was that my regexes don't match unicode strings
&gt; It's always sad when mature conversations cannot happen. It's difficult to have a mature conversation when there's all this drama and passive aggressive comments over nothing. &gt; when people see leaders of this community act like this why would they want to improve themselves? Again I'll emphasize that this was purely a speculation from my part. I don't know what Peter truly meant with the comic if anything. 
Check out [this article](https://husobee.github.io/golang/database/2015/06/12/scanner-valuer.html). It has helped me before when I had to create custom db types.
[Seems to be working fine](https://play.golang.org/p/nvSGagdufO) And to be clear: "unicode" is a character set - utf-8 is an encoding. It is important to distinguish the two, because if you are not using utf-8, but a different unicode-encoding (either in the regexp or in the searched string) it won't work. So, if "you thought you tried that", that might be explained by an encoding-fubar :) It helps to be specific here about what unicode-encoding you tried to use in your regexp, what unicode-encoding you where trying to match against and - if it doesn't work - give examples of specific strings/regexps where the results don't match your expectations. "unicode" just isn't the right term to use in this question :)
Daybreak Games's [Census API](https://census.daybreaktames.com) has quite a bit of info available. There's a realtime websocket API for PlanetSide 2 that allows access to info about, for example, player logins and logouts. I wrote [a little app that tracks those to calculate average time spent online](https://www.github.com/DeedleFake/ps2avglogin) if you want an example.
Amazing thanks 
Other languages have functions which return values too. In C++, exceptions are not the one-stop shop.
Not sure why it has not come up yet, but X11 forwarding over SSH should get the job done, and is IIRC possible also if the client runs OS X or Windows. The application runs on the remote server, but interfaces with the X server on the client. Personally I prefer Vim for editing, but I have used this method for executing graphical software remotely before. You should look it up.
You can use your mouse to control Vim in a terminal that supports it.
I have to say, that `convertAssign` function is a terrible, awful thing. You shouldn't need anything like that, since you know exactly what you're receiving from MySQL and exactly what you're trying to put it it into. Here's a full implementation for a type that simply unmarshals json into a struct and then marshals back into json to be stored as a byte array: https://github.com/motki/motki/blob/master/model/user.go#L324-L336
&gt; How do you all manage your dependencies? Pulling the latest commit off master off some random github repo and hoping for the best scares me a bit... You can vendor your dependencies.
If you're interested in cryptocurrency you can take a look at various exchange APIs like Bittrex, BitStamp, Poloniex, etc.
I'm not sure my grandson would agree with you
https://media.giphy.com/media/pUeXcg80cO8I8/giphy.gif
lol seriously, this might be the greatest accidental troll I've seen in weeks. But seriously, I found this to be an interesting case study.
Why use Postgres instead of CockroachDB?
OP needs to use gRPC in go. Fixes OP's complaints about 2 connections and pub sub. Not to mention blazing fast. 
The comment about channels being slow is probably because you are overusing (or abusing) channels? To make the best use of channels you must make sure the work being done by the consumer is greater than the channel communication overhead, otherwise, the channels will indeed be the bottleneck.
And how would grpc help him in that case? Since its js in browser, you can't use grpc directly, so grpc-gateway for rest interface. Then whats the profit of using grpc at all in that situation? Or am I missing something?
dlsniper, please stop being a sea lion.
I used channels once.... never again...
lost me at I don't want to write it in something as boilerplate as C/C++ wtf does that even mean?
https://github.com/opengemara/opengemara-compiler/blob/master/compiler/compiler.go#L103 It is sleeping for 200ns not 200ms. You'd want time.Sleep(200 * time.Millisecond) https://github.com/opengemara/opengemara-compiler/blob/master/compiler/compiler.go#L107 The else clause isn't needed, just do the if .. break, and keep the rest inline https://github.com/opengemara/opengemara-compiler/blob/master/compiler/compiler.go#L122 This else isn't needed since the if statement returns, keep it inline https://github.com/opengemara/opengemara-compiler/blob/master/compiler/compiler.go#L133 fmt.Sprintf would be a cleaner way to construct a string https://github.com/opengemara/opengemara-compiler/blob/master/compiler/compiler.go#L122 use resp.StatusCode == http.StatusOK https://github.com/opengemara/opengemara-compiler/blob/master/compiler/compiler.go#L114 I don't think that check is necessary, won't it keep in the loop until error free or panicing? https://github.com/opengemara/opengemara-compiler/blob/master/compiler/compiler.go#L50 I wouldn't use a channel for passing back errors, it makes the logic less clear. I'd have processFile also return an error and keep track of them in a slice inside https://github.com/opengemara/opengemara-compiler/blob/master/compiler/compiler.go#L52 https://github.com/opengemara/opengemara-compiler/blob/master/server/server.go#L39 don't you want to return here if err != nil? https://github.com/opengemara/opengemara-compiler/blob/master/server/server.go#L79 is that the status you want, seems suprising https://github.com/opengemara/opengemara-compiler/blob/master/server/CompilerLibrary/compiler.go#L388 else not needed since if returns https://github.com/opengemara/opengemara-compiler/blob/master/server/CompilerLibrary/compiler.go#L431 string constants should be stored as consts https://github.com/opengemara/opengemara-compiler/blob/master/server/CompilerLibrary/compiler.go#L504 return nil explicitly since err was already checked https://github.com/opengemara/opengemara-compiler/blob/master/server/CompilerLibrary/compiler.go#L579 this func is getting crazy deep, refactor 
It probably means NodeJS has libraries for complex coding requirements like leftpad.
The [ESI API](https://esi.tech.ccp.is/latest/) for EVE Online has a lot to offer, and its 100% free. Especially with Market and Killmail data. You can retrieve a near live feed of killmails from [RedisQ](https://github.com/zKillboard/RedisQ). CCP Games has always been great in supporting 3rd part developers.
[removed]
&gt; dlsniper, please stop being a sea lion. And you please start being a nice person.
I feel like the JSON design choices he made contributed to memory issues he saw. Anytime you work with that kind of dynamic JSON it tends to create quite a bit of allocations. That said grpc is not exclusively a Go thing and would probably be a better long term choice. As a bonus if he wants to write an Android or iOS client you won't have to write the majority of your comments stack. In addition I don't think the requirement for 2 go routines per connection makes sense. At 5k or even the 1.5k mentioned in the post, the concurrent connections you are talking about 10k(3k) go routines and you will have no reasonable guaranty that both side of a communication will be active at the same time. Better to keep it all in one per user
Good point. I missed that one.
You legitimately made me audibly laugh with that. Well played.
I've seen frameworks that use one reader and one writer goroutine per connection, so the 2x per conn doesn't surprise me, but I am surprised that OP ran into resource limits with 1500 clients. Memory overhead of 3k goroutines should be ~ 6MB. I'd guess a resource leak somewhere.
This looks fun! Signed up!
Yeah, I have no idea what this even begins to mean. Does C/C++ have too many libraries or something that wouldn’t make his project challenging enough?
I've looked at the code he has like two channels per connection as well and I think what he is not mentioning is the memory accumulated for incoming messages backlog that WS library might have when there is so many goroutines are context switching. Article is definitely missing information but then again he mentions he wants to post that as separate blog post.
The issues that OP was experiencing in terms of memory and performance have nothing to do with Go, Rust, Elixir, or any of the other languages they used. The issue seems to be that the architecture is severely flawed. Processing such dynamic JSON in any language is going to be intensive. Why not figure out what properties need to be sent (e.g. user, room, message, time stamp, etc.) and (un)marshal that using structs in Go and whatever front-end library (un)serializes JSON for you so you can cut down on unnecessary processing? Computers love doing repeatable, boring, repetitive tasks after all. Also, I’m not 100% convinced OP understands the [Go Concurrency Patterns](https://youtu.be/f6kdp27TYZs). OP mentions needing a lot of channels, and that they’re not fast, but I don’t see how that makes sense. Channels are for communicating between goroutines. Was the messaging passing rate not fast enough? Or was the processing done by the functions at the end of the goroutines slow? OP could have had a subscriber struct for each room, publishers being the users in the room, and all communication happens over one channel per room because the channel would receive and send some predefined JSON messages, or is that wrong? That whole post just seems off to me. 
TLDR; They are more experienced in javascript, so it's perfectly reasonable for them to prefer it. But they did not take the time to learn the language, instead deciding to half ass it and blame their defeat on the short coming of the language which took away all the value they could have gained by going through the exercise. I'm really not sure how an engineer comes to these kind of conclusions, how do you possibly look at a language that powers kubernetes and moby but find your 1k~ loc to be too difficult to solve lol. The [Go version](https://github.com/maxpert/raspchat/tree/79315d861968c1266701d07cb11d1db2fb95f47c) of this application was not written like Go. The only tests I could find were generated for them. It has major security vulnerabilities, such as [directory traversal attacks](https://github.com/maxpert/raspchat/blob/79315d861968c1266701d07cb11d1db2fb95f47c/src/sibte.so/rasfs/local_fs.go#L70) on windows because they use path instead of filepath, if they simply set the mime header key for filename to something like "..\..\foo.txt", i.e.: Content-Disposition: form-data; name="writeTestsPlease"; filename="..\write\tests\please.txt" I scroll to the next function and sure enough I can [download any file](https://github.com/maxpert/raspchat/blob/79315d861968c1266701d07cb11d1db2fb95f47c/src/sibte.so/rasfs/local_fs.go#L96) on the file system for any platform. There are [race conditions] (https://github.com/maxpert/raspchat/blob/79315d861968c1266701d07cb11d1db2fb95f47c/src/sibte.so/rasweb/direct_pages_handler.go#L31) in several places that would be easily found with.. tests. Going into the [rascore](https://github.com/maxpert/raspchat/blob/79315d861968c1266701d07cb11d1db2fb95f47c/src/sibte.so/rascore/transport_json_decoder.go#L13) main package leads me to tons of anti-patterns that were working against them and the performance of their application. Considering performance was their primary complaint- why not ask for help? Most their assumptions in the reasons listed are in fact wrong, and better patterns exist for their problem space that people would have been happy to help them with. Also amusing how they talk so much about performance being the other determining factor, but where are the benchmarks? Profiles? I'm not sure how they even know what the performance characteristics of their application are- let alone make assumptions about why they may be the way they are before ever measuring them. For example: &gt; Disappointed with both solutions I looked at other patterns like Disruptor Pattern but there were no mature implementation(s) (the one here recommends to stay away and use channels instead). I would rather spend my energy on solving problem at hand. May be someday I will write a go lang disruptor library that is well tested and is usable in production. Lol what on earth... it would make very little sense to port a library that provides a set of primitives for concurrent queues considering the [circular buffer](https://github.com/LMAX-Exchange/disruptor/blob/master/src/main/java/com/lmax/disruptor/RingBuffer.java) is .. wait for it, a buffered channel. Except to use it they need to also implement several other primitives on top of it which will all operate outside of the intelligence of the scheduler. No merit here, so won't continue on.
You can safely statically link musl unlike libc. I have several go projects that I build this way. I've found it works great plus the resulting binaries are portable between distributions for the most part. You can even run them inside of a naked container with nothing but the binary.
Started learning go one month ago. Ill give it a try, thanks!
Sounds like you definitely experienced them enough to draw a reasonable conclusion through logical deduction like an engineer should.
Note you could also download historical data and write your own endpoints to feed the data, might be easier to practice channels since it will be deterministic when writing tests. One place I like to look for this kind of stuff (plus it has some interesting metrics, least to me which is a bonus) is https://www.data.gov/. It has a lot of file formats.
It is starting way way more goroutines then there are available threads to run them, so while there is a lot of concurrency, there is also a lot more work spinning up goroutines than is optimal. I think you would really like watching the video /u/campoy made on the go trace tool where he uses it to profile a similar program. https://www.youtube.com/watch?v=ySy3sR1LFCQ&amp;list=PL64wiCrrxh4Jisi7OcCJIUpguV_f5jGnZ&amp;index=1 
Looks nice!
Yeah that memory amount really speaks to me of retained data during his JSON decode/encode process.
You could very well be right about the backlog. I'll need to actually dig into the code.
You position in the file moves when you write to it. When you call copy you are getting everything from the current position in the file to the end, reopening the file is equivalent to calling seek(0) on the file.
Ah that makes perfect sense. Thanks :)!
The resemblance is uncanny!
check out /r/opendata and related sidebar subs and /r/datasets
Last posted less than a week ago: https://www.reddit.com/r/golang/comments/7cay29/gophercises_coding_exercises_for_budding_gophers/
Can't upvote this enough. "meta-inference of dependent poliexistential types..." rofl 
Those exercise gophers are adorable 
Oh what the hell :D +1 on the adorable mascots I need more fuel for getting a custom sticker made that says "I write horrible go"
&gt; Since its js in browser, you can't use grpc directly Why not
It’s still alive!
TL;DR;TL;DR: They are more experienced in javascript so they are switching back to it. They decided to blame Go while the issue is that they half assed everything.
I'm don't know how they're counting packages. I see the fantastic stdlib coupled with a foundation of really solid packages as one of the strengths of Go. I don't feel a need for validation by a high number of new shiny things per day. I think the package/library ecosystems of other languages beat it into me that more does not mean better. Personally, I build solid, reliable services using a handful of packages. I don't feel like I'm missing anything right now as far as packages are concerned.
• Sheer size of the community • General tilt towards quality over quantity: we don't need 20 libraries for doing the exact same thing (except for http routers ;)))). Plus the stdlib takes you a long way (and the apis are so well thought through and the docs so good compared to pythons you don't need no alternative for most stuff) • A little copying is better than a little dependency, nick the parts u need, mash it up as needed
modulecounts changed their source of go modules. At the moment its using https://gopm.io/, which seems to be undercounting.
Instagram is another API which has pretty high rate limits. 
No idea why you were downvoted. I thought it was kinda odd as well and I created the course.
I'm headed to bed (long day and crashing early) but happy to answer questions in the morning. There was also an issue with Mailgun a day ago where some emails weren't being delivered and I'll be manually triggering those access emails tomorrow as well.
What a stupid metric. It's like judging your congressman based on how many pages of legislation he writes.
Anti-intellectualism at its finest. All because you can't/won't understand an extremely fundamental, 50-year-old idea that those egghead Java and C# programmers use every day.
bad joke. I love Golang lol
[removed]
Lol, sorry for the down votes, a /s woulda saved you I think :-)
One of the issues may be that he is running it on Raspberry Pi which is ARM hardware. Go as per my knowledge runs well on ARM, but still not very optimized. Secondly, the code probably has a resource leak somewhere. I have myself built a Real-time messaging system around Gorilla Websocket/SockJS as part of my Job. Our message format is also JSON and we could handle C10K with very little memory. Even during heavy load, the application is CPU constrained than memory.
By the way, sensible persons with very strong CS backgrounds do actually exist. I, for one, truly enjoy [every single post made by Jesper Louis Andersen to the Go mailing list](https://groups.google.com/forum/#!topicsearchin/golang-nuts/authorname$3A%22Jesper$20Louis$20Andersen%22/golang-nuts/UH1aPn_Jc88).
Sorry I had missed the original post. Came across this on HN and decided to share here as well.
Which third party process manager is this?
This is easy to do, write your own type, and satisfy a few interfaces: Like so: https://goplay.space/#cW_1BGPcje
You can, but it was a bit slow when I checked it last time. (There were no low level bit operations in the browser js, which added a lot of overhead.)
You're right, somehow I've completely missed grpc-web.
[removed]
&gt; Or do you mean that import "github.com/foo/bar" isn't based on the URL of that repo? That is what he is saying, and he is correct. Some use the convention of namespacing packages by taking features of the repository URL (domain/path), but there is nothing that specifies that you need to use that convention. You can put packages wherever you want, as long as they live in the src directory. Try creating a package in the root of `$GOPATH/src`. You will see that it imports just fine.
Sure, everyone knows that. It still doesn't change the fact that github.com/foo/bar is based on the url of that repo. 
*If* you have chosen to use that convention. If I keep the package in "third-party/friends/bar", then it would not be based on the URL of the repo.
It sounds like you are missing the context I said that in: &gt; The language can choose to support versioned imports (especially since most non-stdlib import paths are already based on urls) Specifically, the Go developers can *choose to* support a way to use versioned imports of a package. This would require runtime and tooling support which is why I said it can't be done in a third party library.
Which cave have you been living in lately
&gt; It sounds like you are missing the context I said that in: Honestly, I think your point is just being lost. Perhaps you can rephrase it? &gt; Specifically, the Go developers can choose to support a way to use versioned imports of a package. Okay, so let's say I want to use v0.7.0 of Dave Cheney's errors package. Github provides this URL. https://github.com/pkg/errors/tree/v0.7.0. So, assuming I like the URL convention, my import path would become `import "github.com/pkg/errors/tree/v0.7.0". What more needs to be done?
I end up feeling that way about every language, to be honest. Conceptually they should be useful, but in practice I find them to be less effective than other methods.
Is this like ngrok but self hosted?
&gt; Honestly, I think your point is just being lost. Perhaps you can rephrase it? Yes, perhaps. &gt; `import "github.com/pkg/errors/tree/v0.7.0"`. What more needs to be done? Personally I wouldn't go with that syntax as the biggest advantage of versioned imports is importing multiple versions of the same package. For example: import ( errorsold "github.com/pkg/errors" "v0.7.0" // an older version, perhaps needed by some dependency errors "github.com/pkg/errors" // the version from git HEAD, the one *I* want to use ) Similarly, I would expect `go get` to handle different versions in a reasonable way. For example, running these: go get github.com/pkg/errors v0.7.0 go get github.com/pkg/errors v0.5.0 should create `$GOPATH/src/github.com/pkg/errors` containing *both* versions. I don't know how the directory structure should look like, but that's an implementation detail. This is all just pseudocode off the top of my head, but hopefully it gives you an idea what I mean by it needs to be done inside Go and not in a third party library.
Yes.
You mentioned that one of the biggest upsides to using go-micro is that it helps with service discovery. Is this irrelevant if we are using Kubernetes?
&gt; Personally I wouldn't go with that syntax as the biggest advantage of versioned imports is importing multiple versions of the same package. How is that any different than the following, which already works perfectly *today*? import ( errorsold "github.com/pkg/errors/tree/v0.7.0" // an older version, perhaps needed by some dependency "github.com/pkg/errors" // the version from git HEAD, the one *I* want to use ) Not to mention that it stays with your idea of namespacing packages using components of repository URLs. &gt; I don't know how the directory structure should look like `$GOPATH/src/github.com/pkg/errors` and `$GOPATH/src/github.com/pkg/errors/tree/v0.7.0` seems like the logical choice. You don't even have to change a thing. You can start using this right now.
How does this compare to packr (https://github.com/gobuffalo/packr)? One difference I'm seeing is it looks like this generated a single statik package for your project, while packr has a slightly different approach. Anything else I'm missing?
That's awesome. I'll certainly give it a shot.
&gt; How is that any different than the following, which already works perfectly today? No it doesn't: $ go get github.com/pkg/errors/tree/v0.7.0 package github.com/pkg/errors/tree/v0.7.0: cannot find package "github.com/pkg/errors/tree/v0.7.0" in any of: /usr/lib/go/src/github.com/pkg/errors/tree/v0.7.0 (from $GOROOT) /tmp/go/src/github.com/pkg/errors/tree/v0.7.0 (from $GOPATH)
I’ve never been clear on why for web dev a single binary is better than a binary plus some folders full of templates. In most cases, whatever deployment process you have should be able to handle sending out the files with your binary. For distributing “app-like” binaries to customers, it makes much more sense. 
The site used to over count by counting the number of packages on godoc.org/index. This page listed packages whether the package was intended for reuse or not. The godoc.org/index page was removed.
I don't know. It works fine on my system. mkdir -p $GOPATH/src/github.com/pkg/errors/tree/v0.7.0 &amp;&amp; cd $GOPATH/src/github.com/pkg/errors/tree/v0.7.0 &amp;&amp; git clone --branch v0.7.0 --shallow git://github.com/pkg/errors . Imported into my codebase: package main import ( "fmt" "github.com/pkg/errors" errorsold "github.com/pkg/errors/tree/v0.7.0" ) func main() { fmt.Println( errors.New("HEAD"), errorsold.New("v0.7.0"), ) } Produces: HEAD v0.7.0 
Now I'm not sure if you are trolling? *Of course* it works if you manually create a directory named `tree/v0.7.0` and clone a specific branch to there. Quoting myself once again: &gt; Specifically, the Go developers can choose to support a way to use versioned imports of a package. I'm talking about versioned imports supported by the entire Go toolchain: compiler, runtime, go get etc. 
&gt; I'm talking about versioned imports supported by the entire Go toolchain: compiler, runtime, go get etc. Remember that `go get` is built around the convention that you will *always* fork the code you are working on. If you need v0.7.0 of the errors package, then the URL convention will be `yourdomain.com/errors` (or wherever you decide to store your copy of the v0.7.0 errors package). `go get` will already work with multiple versions if you used it as it is designed. I can appreciate how that may not fit your desired workflow, but that suggests that `go get` is simply not the right tool for your job. Have you considered using a different tool?
Sorry, could not install today. hugo@hp ~/play $ go get -u github.com/mmatczuk/go-http-tunnel/cmd/... unexpected directory layout: import path: github.com/cenkalti/backoff root: /home/hugo/go/src dir: /home/hugo/go/src/github.com/mmatczuk/go-http-tunnel/vendor/github.com/cenkalti/backoff expand root: /home/hugo/go/src expand dir: /home/hugo/go/src/github.com/mmatczuk/go-http-tunnel/vendor/github.com/cenkalti/backoff separator: / 
&gt; Beyond that tool that might not be right for you, what else needs to change? You are basically asking *"besides the thing you'd like to see change, what else needs to change?"* Yes, I know I can fork a package to use different versions of it. I simply think it's *preferable* for this use case to be supported natively, behind the scenes, by the toolchain.
&gt; You are basically asking "besides the thing you'd like to see change, what else needs to change?" You said that the compiler, runtime, etc. also needs to change. It is not clear to me why or how? `go get` seems to be the only program getting in your way and that is because you want to break its conventions. And even it already supports your ultimate goal, just not in the exact way you want it to. Which is fine. You are allowed to have opinions about how software should work. However, other people have different opinions and `go get` already matches how they want to deal with this issue. Are changes really necessary just to keep you happy when you could easily built a tool that does what you want, without impacting everyone else?
&gt; It is not clear to me why or how? For the "how", refer to my previous example: import ( errors5 "github.com/pkg/errors" "v0.5.0" errors7 "github.com/pkg/errors" "v0.7.0" "github.com/pkg/errors" ) This would need compiler and runtime support. It also makes the *intention* (importing different versions of the *same package*) much more clear compared to a fork. As for "why", I think it would be better a user experience. &gt; Are changes really necessary just to keep you happy when you could easily build a go get replacement that does what you want, without impacting everyone else? None of the language changes (e.g aliases) were/are necessary. The only concern is if a proposed change results in a better, smoother user experience. For versioned imports, my answer is yes.
&gt; For distributing “app-like” binaries to customers, it makes much more sense. That's exactly the point. Together with something like [go-update](https://github.com/inconshreveable/go-update) it makes it easy to build self-updating apps. Sure, you could use Docker or similar, but that is not easy when you don't have complete control of the infraestructure (because it's not you taht host it).
&gt; It also makes the intention (importing different versions of the same package) much more clear compared to a fork. I'm afraid I still do not see any difference between that and "github.com/pkg/errors/tree/v0.7.0". The intent seems the same in both cases, and GitHub has already settled on using this methodology to convey that information. Why not try to keep consistent with the service that most people already use for storing remote Go packages? Yes, it is true that `go get` does not support GitHub's convention for pointing to specific versions, but everything else in the toolchain is quite happy with this. 
Because the Go language spec shouldn't be designed around a specific VCS, let alone the conventions of a third party hosting company. My proposal hides all the git/svn/bzr/github/bitbucket etc. implementation details behind `go get` (like it is right now) so the compiler and runtime can remain generic. `import bar123 "foo/bar" "1.2.3"` doesn't imply anything about a particular website or even a specific version control system and I think that's a much better interface.
&gt; Because the Go language spec shouldn't be designed around a specific VCS It need not be. It's just a URL. That is the one GitHub provides, but you can point to any URL. What is the point in using URLs if you are not going to use URLs all of a sudden? 
I should have said "I also domestically abused channels" lol. still haven't used channels personally. but even if node is faster, I feel Go makes you learn way more of the basics and proper configuration.
I've always used an nginx proxy, any reason to use this instead?
I wonder how professional you can get these plots to look. And does gonum have good matrix calculations like numpy?
I really like that Go is getting a dedicated IDE, but I still prefer Visual Studio Code.
I like the idea of a single binary with all the assets included.
cool!
This is pretty great. I've never been a fan of how numpy works. This makes a whole lot more sense.
&gt; (except for http routers ;)))) As Benjamin Franklin said, a nanosecond saved is a nanosecond earned.
Not entirely, it's to do with portability. Go micro let's you entirely change your service discovery backer with just a few environment variables. Consider as well that you may not want to use Kube to develop locally. But we'll get to that in the coming posts :) 
If any of the goland devs are reading this and you want to increase adoption of the IDE, then add support for visual studio code keyboard shortcuts and a good monokai color theme
I'd rather use something like wkhtmltopdf with a go binding/library instead of this. It's way easier to position stuff with css. Tried using this and wkhtmltopdf like a year and a half ago, and both weren't really friendly to use. 
VSCode has extension with IntelliJ shortcuts... So you can learn IntelliJ/GoLand shortcuts and use them at both places :-)
Vs code all day 
looks pretty cool. trying it out now.
I have the same bug like the release before, the run configurations are all shown as "Unknown" after I imported the old projects.
Thank you for your suggestion. You can follow these issues: - keybindings: https://youtrack.jetbrains.com/issue/GO-4648 - monokai theme: https://youtrack.jetbrains.com/issue/GO-4863
Sorry to hear. Can you please open an issue on https://youtrack.jetbrains.com/issues/Go and attach one of the ` .idea ` folders from a project which suffers from this issue? Thank you.
VS Code or vim-go are the best imo.
I guess this goes beyond the scope of the article, but I'm curious if you've had to deal with rate-limiting from Instagram?
wkhtmltopdf is WebKit based, something not many of us are comfortable in shipping to web servers due to the security issues it poses.
I wish it were that easy. Years of using Visual Studio has meant that the keyboard shortcuts are now part of my muscle memory. Visual Studio Code supports them, so it feels natural and I can be far more productive using it. If I was convinced that Goland was the way to go, I would put in the effort to learn the shortcuts. Otherwise, it's hard to justify. That's the way I see it.
Thanks @dlsniper, I will. Definitely a good start to see the such response to the community.
&gt; I still prefer Visual Studio Code. If you don't tell us why, what else are we supposed to glean from this post?
This stuff is all fine and well, but the expiration date on my demo's gonna run out soon... will I be able to buy this IDE ever or am I going to have to use something else for a while?
A few weeks ago I tried all of the "embedd all the stuff" libraries I found and stayed with packr! Everything is just working, really nice project
I’ve used both and I prefer vs code because it’s very lightweight and works out of the box. Go is very lightweight so the two work well together. If you’re working in something like PHP then an IDE like IntelliJ or PHPStorm is great because it brings everything into one spot. Go doesn’t need this because everything you need is in the cli, you really just need to script the Cli to get your go environment setup. This is why lightweight IDEs or even text editors are far easier for go
If you have to script the CLI then it doesn’t work out of the box. Just sayin’
Can this generate a PDF from plain HTML?
The expiration date for the RC is: December 23, 2017. Make sure it's build #GO-173.3727.96 (go to Help | About). As for when you'll be able to buy it... Pretty soon hopefully, unless some major issue is discovered in the RC stage, so please make sure you try it. Furthermore, the IDE will be automatically added in the All Products toolbox. Hope this helps.
Just wondering, was vfsgen one of the libraries you tried? What did you like/not like about it, in case you remember?
Support for .go-version?
What is ` .go-version `?
So glad they renamed this from gogland.
I use WebStorm w/ the Go plugin. At my work, everybody uses Atom. They've tried to convert me, but I just can't. WebStorm is the shit (I've tried Atom, LiteIDE, and VS Code). With WebStorm, I'm able to get plugins for editing my protobufs, yamls, etc. all in one IDE. I know I've asked this before, and the answer was they're the same... but is there still any reason to switch to Goland over WebStorm, as far as Go-specific functionality or does the plugin provide everything Goland does? Also, if I want to continue using an IDE that supports other formats and document types like I stated above, then I assume I'm better off sticking to WebStorm or does Goland provide some plugin functionality?
[removed]
[removed]
That I'm glad Golang is getting more traction, but that I still find IDEs to be a drag most of the time. I don't do too much big projects that I need an IDE, but if I do I'd definitely use one from JetBrains, as the ones I've used for Java have been great.
Atom all the way
thanks you
[removed]
I primarily use vim, have used vim with eclimd to write Scala for a while, but still hop in IDEA or Gogland for larger projects.
Really? Last time I tried it, it was slow as heck.
When was the last time?
I've been using [Go Rice](https://github.com/GeertJohan/go.rice), what advantages can I find in Statik to try it?
Fair enough. I am longtime IntelliJ user, so I prefer its shortcuts. 
A couple of months back. Have things improved?
Really superficial look only, but the code in comcast/gots sucks on multiple levels and this looks.. complex but ok. (Likely because the problem domain is complex.)
 time.AfterFunc(5*time.Second, func() { fmt.Println("hello in the future") }) That's racy if anything else uses `os.Stdout`, use `log.Print` instead.
I can understand the sentiment. The go plugin for VSCode takes care of downloading a good collection of tools and keeping them updated, or at least prompting you to install and update them. Not a lot of manual work needed in terms of connecting things until they work right. In addition, the VSCode team has been listening to the community quite a bit and every release brings something that makes things even better - multi folder workspaces comes to mind in the latest release. They have set a pretty high bar.
If I buy an "All Products Pack" licence before the first stable release of GoLand, will it still be covered by my licence?
Done with https://youtrack.jetbrains.com/issue/GO-4972
[removed]
Coming from intellij this IDE is fantastic