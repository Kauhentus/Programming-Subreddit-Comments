The design is backward compatible, it can be introduced Go 1.x. [https://go.googlesource.com/proposal/+/master/design/go2draft-contracts.md#Summary](https://go.googlesource.com/proposal/+/master/design/go2draft-contracts.md#Summary) *"This design is completely backward compatible, in that any valid Go 1 program will still be valid if this design is adopted"*
Glad to see InfluxDB will eventually support Prometheus exposition format and PromQL :) VictoriaMetrics already supports this and [even extended](https://github.com/VictoriaMetrics/VictoriaMetrics/wiki/ExtendedPromQL) it a bit. I bet on PromQL among competing query languages for time series data: * SQL is powerful, but too verbose (hello, TimescaleDB) * Flux looks too complex and artificial * PromQL is the most practical
I am unable to get logrus to include the full stack. I will do better in future posts to include github, or other host, references. 
All animals are equal, but some animals are more equal than others. All types are equal, but some types are more equal than the others - the language favours `float64` as a default. 
\`\`\`code type Repository interface { Save(a \*Account) error Delete(id ID) (a \*Account, err error) GetByID(id ID) (a \*Account, err error) GetByEmail(email string) (a \*Account, err error) } &amp;#x200B; type ReaderRepository interface { List(start int, end int) (a \[\]\*Account, err error) GetByField1AndField2(field1 int, field2 string) (a \[\]\*Account, err error) } \`\`\`
That's interesting, I wouldn't have guessed that to be the case. I always do this sort of thing in tensorflow (with the python bindings) with float32 or 16 for speed reasons. 
Good read, thanks for sharing! &gt; Don’t chase for big O notation. Simpler algorithms and data structures are usually faster on small inputs An example of this in the wild can be seen in [Array.Sort on MSDN](https://msdn.microsoft.com/en-us/library/6tf1f0bc\(v=vs.110\).aspx) where the algorithm used is an introspective sort. Did a blog post on the specifics years ago but the TL;DR is O n^2 algorithm used for small inputs. * insertion sort if input partition size &lt; 16 elements * if number of partitions exceeds 2 * LogN (N being the range of the input array), heap sort is used. * Otherwise, use Quicksort.
Whatever Linux you are using probably has a package, both a current one in the official repo, and some community-maintained one somewhere else. If it's debian-based (includes Ubuntu), you can use [godeb](https://github.com/niemeyer/godeb) to build a package anywhere, then you can move the package over. The whole process is auditable, though for godeb you may want to manually download the source and verify it with the SHA256 checksum, which seems to be strongest assurance on offer. (Do you have a particular reason to need to compile the compiler on the air-gapped computer itself?)
Try `logrus.WithField("stack", string(debug.Stack()))` or actually describe your problem. "I am unable" is a problem description which makes it very hard to provide help.
As expected, an excellent presentation! P.S. I use many of your fast\* packages in my projects, and I would love to be able to buy you some coffee or [beer](https://beerpay.io).
How about this ? https://www.8hrs.xyz/
You can use `go list` to list out the dependencies from a package. For example: $ go list -f $'{{range .Deps}}{{.}}\n{{end}}' k8s.io/api/core/v1 Note: This will add k8s.io/api/core/v1 to your go.mod, but running `go mod tidy` will clean that up again.
No. I'm new to this, i tried to find a golang .rpm (yes im using rpm based system) it does not seem to be easily found. typically when I build something like go from source it "installs it" so i dont know if i can compile it and then..."scp" it over to the system. 
The word "build" is a bit misleading there. Apart from that, "Package build gathers information about Go packages." is a good summary. It's not really about building Go, it's about looking at Go source trees and extracting information. At this time, there is no librarified compiler for Go. Instead, you just call `go build` in a subprocess.
I like %+v
Oh hey, that's great. I haven't been following the proposal lately so I'd completely missed that
Those debugger changes look great. I’m also glad they’re finally making renaming an interface be able to change the methods that implement it.
[removed]
Get a core dump and a backtrace, see where the execution is.
[removed]
&gt; Gotcha. But that doesn’t exactly help when you’re checking if a user exists in a database and then not checking the password that simply doesn’t exist. Compute the hash on the login attempt either way?
Also, don't use `type A string` because that lets string constants silently convert to A's: https://play.golang.org/p/vB3cMfdWH7Q With `type AError struct { msg string }` the accidental recursion no longer happens, either.
if you want to have 'not there' as a valid value use a pointer :) cf: https://stackoverflow.com/questions/38486564/golang-unmarshal-marshal-json-with-int-set-to-0-does-not-seem-to-work
You can use pointers - which comes with its own drawbacks and are not always suitable. 
thanks for the insight
care to elaborate on the drawbacks i'd face by using pointers
What a vague article, the author seems to have very little grasp of the things he's talking about.
Primarily Nil pointers panic if you don't check for them and the compiler will not help you catch this type of error. They might also cuase heap allocations at times or just add extra padding to your structs - a `bool` or `uint8` takes up a single byte, but `*bool` adds 4 (on 32 bit systems) or 8 (on 64bit systems) bytes to this (assuming the compiler cannot optimize this away, which it might be able to in some situations). It is honestly one of my most hated features of any language as it is the cause of far more easily avoidable problems then any language feature should. There are [many good reasons](https://www.lucidchart.com/techblog/2015/08/31/the-worst-mistake-of-computer-science/) to why they are so bad but in most languages they are unavoidable.
&gt; Are your opinions about Go the same now? The same as they were 4mo ago? Yes. There are not many job openings for Go developers, but if you're proficient and have a solid software development background you can get a job fairly easily because Go developers are also a rarity. I've noticed a lot of Go job listings are looking for a much higher level engineer than the *average* Java or Javascript developer so it could still be hard to get your foot in the door without a good deal of SWE experience. For someone trying to simply get a job in any software development field they can get their foot in the door at, I'd learn a little bit of Java, Javascript, C#, and Python and later pick one you really like, stop playing with the rest, and master your pick. Build a bunch of apps and put them on your Github. Then maybe later tinker with Go on the side. Since you're a mechanical engineer I'd recommend the same but with Java, C++, C and maybe focus on some embedded development in those languages. You could line up some really sweet gigs working on both software and hardware in the robotics or aerospace industries and make a ton of money doing the kind of work most programmers dream of.
I haven't looked in a while, but are the following supported? * Automatic use of modules where a go.mod file exists * Initializing a module * Updating a dependency / rolling back an update * Vendoring a module automatically PyCharm for example has a whole load of pip support, so it would be nice to move towards a similar level of integrated support.
Any more details anywhere? The CPU and CPU cache section is a bit light on details
They probably won’t make many module changes until 1.12. Anything can change until then.
Fair enough. The specific issue is that there is a WithError function. Give some research it appears that logrus has some idea of pkg/errors. I ask here to see if anyone else had a solution that seamlessly integrated the two. 
Yeah, I think you're trying to make an inherently sequential algorithm concurrent, hence bottlenecking on this structure. The priority queue is the hard bit, not the trivial expansion/costing. Also, as I understand it that's not a branch and bound method. Branch and bound methods find feasible solutions aggressively, then discard all branches of the problem that cannot beat them (hence "bound"). Your method actually reduces to something like A* search, where the first complete solution it sees is the optimal one.
What does "tilting" mean here?
anyone have experience running Dgraph and/or Badger in production? seems relatively new
Probably the biggest thing is to make a benchmark that gets things set up and then turns on ReportAllocs and runs your inner loop code `b.N` times. Ideally you should see that, on average, it allocates zero or one time (or at least some very small number like that). Memory allocation is both slow and can be a source of contention as well if I remember correctly. If you're using too much memory and want to cut it down, or if your benchmarks show you are creating a lot of garbage, you'll want to use the memory profiler to see where the allocations are and how big they are. Fewer, larger allocations are easier on the GC. The 'list' command to pprof with a memory profile is super useful here.
My point was that we're not being "paranoid" to think that this actually does happen, and that it's a risk. As you say, how high you evaluate this risk is up to you. The last large dev team I worked at used Rails as a basis of their product. Rails undoubtedly saved them a lot of time when they were starting out, and allowed them to hit early goals that would have been harder to hit without it. But at the point I joined the team, they were fighting Rails every day. Upgrading Rails cost the team thee months work. It was definitely a net loss in terms of manpower over just writing the thing from scratch. The team was (is still) building a financial services product. There was definitely money at stake. Every gem had to be audited for malicious code and possible security breaches. And we found quite a few. Nothing obviously malicious, but plenty of security holes that we then had to get the gem maintainer to patch (or fork the gem ourselves). And of course every time a gem updated its version we had to review what changed and see if that introduced new bugs or security holes. The point being that the team gradually moved from "gems are great and save us time" to "gems are a pain in the arse and are costing us time. We can write better code than most gem maintainers". And that went for Rails, too... it was a net loss of time. You can argue that the time saved up front was worth it because of the timing of that, and I'd probably agree, but that's a trade-off that's not often talked about when discussing frameworks. I think there's a huge difference between trusting Google (and Linux, GNU, etc) than trusting a random package maintainer. I know Google are perfectly capable of being evil, but that evil is in a range of behaviours that I can live with (I use gmail and google docs too, after all). But that's totally different from trusting Random Hacker who churned out a halfway decent authentication library from her bedroom a few years ago, which then got popular and is becoming a pain to maintain, and is now working out how to fund college. As you say, it's about evaluating risk. I'm comfortable using a bcrypt library adopted as part of the extended standard Go library. I'm not comfortable using an authentication library I found on the internet one day because it's got a couple hundred stars. In terms of risk, as you put it: I think I write less risky code for my product than the average package maintainer, but more risky code than the Go standard library authors. You're probably drawing that line elsewhere. 
I love [benchcmp](https://godoc.org/golang.org/x/tools/cmd/benchcmp). Just tee the benchmark output to file at key points, and it can show you the difference between them
I assume he's deriving it from the gaming sense, where someone plays worse than usual, often because of some frustration. It's used kinda weird here, but I guess he means "zero values really throw me off"
OMG! View as Hex! I was literally looking for this feature yesterday!
it sounds like overkill, but writing your own marshaller for your specific use case isn't that hard, and you can deal with all sorts of spiky edge cases in there.
I'm looking forward to this. I have a project coming up that could use Go at about the time this should be released as stable. 
r/roastmycode
Details were on a Go meetup in Kyiv - https://www.meetup.com/uagolang/events/257995262/ :) Probably I'll talk a bit about it on the [GopherCon Russia 2019](https://www.gophercon-russia.ru/).
I set the field to accept interface{} then avoid serialization if it's nil. 
I use both, badger with blockchain/ledger and dgraph for general db for spark connector. it's has been rock-solid since v1.0.8. My largest dataset is 25G, not huge but not small either.
the tarball should have a bin folder, add that to your path and you're done. The message you received is like you are compiling it from source, which requires a bootstrap set of binaries (what the message is requesting).
Amazing comment. Thank you! However I can't seem to get the benchmark function to set the stop since Go complains stop isn't used? https://s.natalian.org/2019-01-25/1548379925_2548x1398.png Also the index proposal had big gains for me, not just 500ns. https://s.natalian.org/2019-01-25/index.mp4 Wonder if there is a Golang meta tool for benchmarking between branches?
will you notice 这 bot?
Try building with `-race`
Author here. Among the many other users, Dgraph is being used by at least 2 Fortune 500 companies in production (whose names we don't have permission to reveal).
Please stop using `nil` as a meaningful state. Use an `enum` to represent whatever presence means to you in this case and let values always be values.
I do not completely understand what you trying to achieve but I can answer some of the questions above Why not rust or python - python is nowhere close when it comes to efficiency and execution time. Rust I have not worked so can't comment. How to run tools that are local to server from remote client - Create the script that does all of that put it in server. Client just sends a signal through http. Security concerns - you can use one time passwords or tokens for this. Ignore if you were already aware of all this
"tilt" comes from pinball machines, where if you rough up the arcade too much in an attempt to influence the ball it goes limp and displays an error message simply saying "tilt". https://en.wikipedia.org/wiki/Glossary_of_pinball_terms#T source: was old enough during the 80s :)
I appreciate the response. This clearly shows how one might do this. Given the handler concept mentioned in another posts I see how that blog post could help. For others that showed this information, I was simply flummoxed that there was no better way than this. I appreciate your help as well.
I use the pattern from the standard sql library, something like type NullInt struct { Valid bool Value int } And you can define marshal/unmarshal to load/unload it correctly with the standard json package.
Hey! Thanks for the reply! A better description of what I'm trying to accomplish might be that I'd like the customer support/client side to be able to generate a Let's Encrypt Cert as part of the setup process for the customer without pinging me to do it for them, since I'd rather not have them mucking about in the back end. I have a script I wrote in bash to make it where I just login, and type the domain, and it does the rest... Could that be implemented in Go, and stuffed in a webpage? I'd rather have it Sandboxed instead of just "https -&gt; server script with root access" because at that rate, it'd be easier to let them into the server? Idk, it just doesn't feel right to have code execution built in like that...but, again, I'm a novice programmer at best. 
I use Jon Calhoun's method described here: https://www.calhoun.io/how-to-determine-if-a-json-key-has-been-set-to-null-or-not-provided/
 Obviously you wrote badger to solve specific problems you faced and now use it. I don't get the title. 
Sure. You could have a standalone web page send a post request to a golang backend, have go serve up the page and handle the backend as well. GitHub has tons of golang http server samples. Check out golang libraries https://github.com/gorilla/mux https://github.com/go-chi/chi is another popular library for http but I've not used it yet. I know there are some let's encrypt libraries as well. https://github.com/mholt/certmagic Search GitHub golang letsencrypt and maybe you'll find something to for your needs. Good luck.
It's explained right in the article under the section *The Motivation*. It's a play off of the title of a similar article by CockroachDB called [Why we built CockroachDB on top of RocksDB](https://www.cockroachlabs.com/blog/cockroachdb-on-rocksd/). &gt;The Motivation &gt; &gt;Recently, our friends at CockroachDB wrote about why [they use RocksDB](https://www.cockroachlabs.com/blog/cockroachdb-on-rocksd/). &amp;#x200B;
I am pretty sure it's branch and bound. 
`cmd.Process` is nil before `Start` or `Run`.
You wouldn't have this problem if you treated your errors as [part of your domain](https://middlemost.com/failure-is-your-domain/).
 fmt.Printf("%#v\n", a) works just fine for me
(Three days late but) do you know reddit let’s you bookmark posts for this specific purpose?
Tip: beef up the readme a bit. What does stitching mean here (for example, does this mean the same as `cat infile1 infile2 ... infileN &gt;outfile`), when and how to use each of the yml options, etc. 
Yeah, I read stitch, stitch, stitch... What does it mean?
Let's Encrypt is designed for automatic cert handling. Have a look at [caddy](https://caddyserver.com), a Web Server with super-automatic TLS enabled by default, to see how well Let's Encrypt can be automated in general and specifically with Go. If you want to write your own Go tool for generating certs for your reps, there are Go libraries like [foomo/simplecert](https://github.com/foomo/simplecert) available (disclaimer: I have not used simplecert for myself yet, thus cannot say anything about stability, ease-of-use, etc). 
The answer is not yet for modules, but yes for dep. If you need IDE based dependency management *now*, go with dep.
Besides stitching as a handcraft, I hear this term often used when, well, *stitching* video snippets together. Which means to concatenate them seamlessly.
Yes, I know "stitching" from panorama photo software where one picture is stitched together from several smaller ones. But this doesn't match with the example config given.
The support for both dep and Go Modules is the same in the IDE currently. You can read more about the supported features here: [https://blog.jetbrains.com/go/2019/01/22/working-with-go-modules/](https://blog.jetbrains.com/go/2019/01/22/working-with-go-modules/)
Sorry if its a newbie question. Can you please tell me, if internally tarsgo uses Rest or some other protocol? Also, if there are many, could you please share the list? And a reference to the page with details about that? Thanks a lot in advance. &amp;#x200B;
Sorry if its a newbie question. Can you please tell me, if internally tars go uses Rest or some other broker protocol? Also, if there are many, could you please share the list? And a reference to the page with details about that? And, is there a way to change the message broker protocol ? Thanks a lot in advance.
Could you please tell me, if we can use MQTT as messaging broker with Go Micro? Thanks in advance.
I stand corrected, thanks.
Thanks!
Hi. We recently released this post on how the IDE allows you to work with Go Modules: [https://blog.jetbrains.com/go/2019/01/22/working-with-go-modules/](https://blog.jetbrains.com/go/2019/01/22/working-with-go-modules/) To address your points specifically, please see below: &amp;#x200B; \&gt; Automatic use of modules where a go.mod file exists This is not present yet, but it's an existing request which we plan to address. For now, you'll need to manually check a box to turn on the Go Modules support in existing projects. &amp;#x200B; \&gt; Initializing a module If you mean create a new project supporting it, then yes, this has been supported almost since Go Modules were announced. &amp;#x200B; \&gt; Updating a dependency / rolling back an update For now this is a semi-manual operation. You have to edit the go.mod file manually to tell the go tool which dependency version you need and then the IDE will run the required actions to get the dependency in the Go Modules cache. &amp;#x200B; \&gt; Vendoring a module automatically We don't have any support for this at the moment as this is not a requested feature. Can you please describe your use case for this? &amp;#x200B; Our support will likely improve in time, as the Go Modules eco-system shapes up and modules registries come to the community. We also need user feedback like yours to help us understand your needs and what to work on next. As such, thank you for your feedback and please let us know if there's anything else that we can do to make your Go coding experience as smooth as possible.
gathering stack traces by default is wonderful, and better support for wrapping errors is also great.
&gt;Badger is probably the only key-value database which exposes the versions of the values to the user. Bigtable has similarly versioned values. 
&gt;pattern from the standard sql library, somethin I prefer similar approach, if you really want to make your code reliable this is the Special Case &amp;#x200B; [https://martinfowler.com/eaaCatalog/specialCase.html](https://martinfowler.com/eaaCatalog/specialCase.html)
That error would have, but you can always wrap it when you receive it, so you know where in your code it occurred.
Hey, take a look at Benthos: https://github.com/Jeffail/benthos
Maybe I missed it, but how in this proposal do you add context to a returned error? I can see extra info printed in an example (with the frames) like with "dial myserver:3333", but I don't see how that info gets added. In other words, is there some equivalent to `pkg/errors`'s `Wrap` functions?
You wrap an error with [`New`](https://godoc.org/golang.org/x/exp/xerrors#New) and [`Errorf`](https://godoc.org/golang.org/x/exp/xerrors#Errorf).
Thanks, glad to help. The stop var needs to be at package level (outside any function/method) or the compiler can still potentially elide the entire contents of the benchmarking loop (and that way you'll avoid the not used error too). &amp;#x200B; Cheers.
I see, the Errorf changes are what I missed in my read-through, though don't really find the requirement of using a special format string verb and specific position for the argument very intuitive over Wrap and Wrapf... I think I'd be spending a lot of time going back to the docs to figure out the right way to add context to an error.
DEDIS created the best libraries, I hope they continue implementing more and new cryptographic algorithms, because I am learning cryptography from their library.
Great! I have found it frustrating when I need to print multiple values on many different lines. Dbg gives you not only the value, but the file, line, and expression that generated that value
[removed]
I was expecting graphs in dgraph blog post :D 
[removed]
[removed]
If you are rewriting an existing website, then why not actually rewrite it in Go? If you're looking for another CMS to switch to, then why choose Go in the first place? In any case, I'd suggest you roll your own.
How about reconsidering your criteria getting rid of the database and dynamic content, and trying a static site generator like [Hugo](https://gohugo.io/)? This removes nearly all of your threat surface.
&gt; Gathering frame information may slow down errors.New slightly, but this is *unlikely to affect practical programs* Nice to see a reversal on the previous statements re:stack traces here. Anybody who understood that there aren't thousands of errors generated within seconds from a single program already knew that the performance penalty was an empty argument. I for one, welcome stack traces in the stdlib warmly!
Take a look on qt bindings https://github.com/therecipe/qt/wiki/Gallery 
[https://github.com/golang/go/wiki/Modules](https://github.com/golang/go/wiki/Modules) or plain old git submodules
git submodules I would definitely not recommend over dep. So far modules have been working great for me; but apparently when your package also has non-go files; modules become tricky.
The new Go modules in Go 1.11.
Yes. I thought they are only hidden from the list of questions but are still accessible when accessed via direct URLs. Looks like one has to have a rep above certain amount to do that. Sorry about that.
Unfortunately it's not an option. I'm going to migrate an existing Django site with users to Go. 
I rewrite it in Go because Go is much more performant. I don't want to start from scratch, to save time, and also enjoy best practices of an open source project and avoid some pitfalls that a novice like me fall into. 
https://github.com/ponzu-cms/ponzu
I 100% agree on that optimization is good when it doesn't lead to mega complicated code. If it is clean and works fast its optimal for me :)
I still need to know where the error occurred. For example, I had a Repository error, which is a domain specific error, that occurred due to a RabbitMQ issue. The function from which the error occurred is a common function called in multiple places. That made the message hard to pinpoint. If I were to follow your blog post, I would be no closer to knowing the problem due to the multiple callers. 
GO Modules
I still like to have modules locally so that build systems and other users don't have to fetch them, and I don't need to worry that a github repo is deleted.
Please see the MQTT broker in go-plugins https://github.com/micro/go-plugins/tree/master/broker/mqtt
Awesome, there's some good stuff here to get started. Thanks! 
Nice! Thanks! I'll get started looking at these. 
github.com/go-kit/kit with an MQTT-specific transport?
recruiters and HR people may not know, so I'd recommend having both for keyword searches etc.
I've only ever referred to it as "Go" on my resume and haven't had trouble getting work, but that's just me.
"Go" is working fine for me.
Just Go! Go is for humans. https://twitter.com/rakyll/status/751662589864611840
[Answered in the FAQ](https://tip.golang.org/doc/faq#go_or_golang). But I concur with /u/Redundancy_: if you rely on HR people somehow finding your CV, you might add the `golang` keyword, too.
25G in graph data? how many edges/vertexes does that translate to?
are you allowed to share what scale they're running in in terms of edges and vertexes? thank you
Why did you decided to break everything in separate packages if they can’t really exist without eachother?
Try to incoperate the module / package idea. basicly meaning that everyone of your folders should work without any of the otehr ones. what you then need to do is have main.go (or another package) load, feed and control global, data and router. see it as playing with legos. You build the bricks first, and them assemble them somewhere else. this way you will end up with realy flexible code. if you realy need to have them use each others values, then its best to define them as one packe / folder. &amp;#x200B; &amp;#x200B;
That's what I'm trying to achieve but how can I make router/ work on its own when it relies on a database?
 main -&gt; global / data /router (main)- initiate router with global values (main)- initiate data with global values (main)- create route -&gt; make it use data &amp;#x200B;
I cool so I use just Gizzle Langizzle.
username checks out?
My Rome today won’t be open source so the qt license will be an issue 
Try adding a new package for data layer contracts. Your current data layer would implement the interface. Router would take the interface. Main would instantiate out of data and pass to router. you might need to add a constructor method(s) to the router to take the proper interfaces.
I'd suggest the third option - Go (Golang) - if you are putting this info also on LinkedIn. I work with HR managers and recruiters on a daily basis, most of them never heard of Go and don't know the first thing about boolean operators in the LinkedIn search :) &amp;#x200B;
Turn your struct in global/env.go into interface and let main, router, data depend on it but do not import anything into env. Add internal/env.go, make that depend on data and router and implement interface defined in global/env.go. Let main depend on this internal implementation but always pass only interface around. That way neither data nor router will be aware of internal/env.go. You may have to add various "getters/setters" to interface to avoid mentioning data and router structs explicitly. Interfaces are your friends.
What exactly is the problem? Have you tried ’y := int(i)’?
If you look at network protocols implementations, lost packets and timeouts are a norm and generate a lot of recoverable/handled errors. Performance is very important there. With stack traces it may still be good but no longer great. Notice that Russ calls slowdown "tolerable". In my opinion, it would have been better to build a derived type on top of standard error and add Frame and respective functionality there. Use simple error where performance is required and advanced everywhere else. However, that would not be a drop-in replacement and would require a lot of work to transition huge standard library to it. Hence, the compromise. Time will tell. 
You've stumbled across a slightly tricky thing! In Go, static literals (like the number 7) are interpreted to be the type required to satisfy their next use. If you look at the `t.Add()` signature, the argument must be a `time.Duration`, not a `int`; If you drop 7 directly in place of y, it will start working due to the aforementioned interpretation. To fix this update your code to something like: var y = time.Duration(i) * time.Second t = t.Add(y) See here for an example of someone else who hit a similar problem: https://stackoverflow.com/questions/43892039/golang-how-to-convert-int-to-calculate-into-time-duration
For a CMS, performance typically comes down to adding good cache control headers on the front end and good DB indexes on the back end. The language doesn’t usually have a big impact. 
Cast to Duration for the time.Add call.
Thanks, but often i just look at github from a stupid browser... But I believe it's something that could be made from godoc.org or something like that. I'm not too much anxious :)
Indeed. That's what was stumping me. Typing in the int directly (7 in your example) would work, but casting it to int wouldn't. &amp;#x200B; Thank you (and to everyone else who replied). 
if the performance is the issue, why don't you change the website into static files? you can use this library [here](https://github.com/datadesk/django-bakery)
Could it be that the compiler see that the error will never printed and then doesn't need to be with stack ?
If I'm generating thousands of errors per second, there's a decent chance I'll _appreciate_ being slowed down by stack trace generation.
As someone who's moving across to Go more and more from python and Django, I'd be really interested to hear about your progress! 
This is interesting: [https://github.com/mongodb/curator](https://github.com/mongodb/curator) \`curator \-- Artifact and Repository Management\` &amp;#x200B; I hope Jenkins-x folks take a look and see if it is feasible for use this instead of artifactory which is written in Java so quite heavy weight according to Jenkins-x developers.
In general, performance is a bit of an odd duck. It's generally a niche concern, but because that "niche concern" can contain calls to the standard library, that drives the standard library to be at least reasonably fast. But error generation is a special case. It is, by definition, not supposed to be the common code path. So I think it's OK to slow the execution down a bit to make them more useful, given how we've all felt the paint of them missing. This is also OK because there's an easy workaround: Make your own error type that doesn't collect a stack trace. Even if you have managed to write code that is generating so many errors per second that the stack trace is noticeably slowing you down, and even if this is considered perfectly normal and desirable functioning such that the system is considered to be degraded by the inability to generate error objects quickly (rather than degraded by the underlying causes of the errors themselves), even I stipulate these rather bizarre conditions that I've literally never written or even encountered in my entire 20+ year career, it _still_ won't be something spread across your entire program. 95% chance there's one single line you can change to use a custom error type to fix this problem, 99.9% chance it isn't more than 5 places in your code. Catering our error handling policy to this bizarre one-in-a-million program at the cost of degrading something that has affected every serious Go programmer would be crazy. The only reason anyone's even considering it is just the availability heuristic running amok again. Engineering-wise it's a no-brainer.
You should definitely be able to find a Go RPM for your system. I don't know what RPM system wouldn't have an existing RPM for Go. It will often be fairly out-of-date, but as long as it is after the compiler switchover, it is generally an easy task to update it. You can find tutorials online on how to unpack the RPM into its constituent pieces. Then you can update the manifest file and rebuild it into the latest version. Generally the only "trick" is that if you find an RPM that applies patches, you want to just remove all the patches the RPM applies, because they probably won't apply to the later version. (And the fixes are probably, although not certainly, incorporated into the later source code anyhow.) I know this is probably a bit more effort that you probably wanted to spend. :) But in the long term, it'll probably be a net time savings, and if you are dealing with installing things on an air-gapped system, learning how to do this will come back to you several times over.
Database connection in a separate package. In general, you can solve almost any such problem by taking the circular-inducing content and pulling it into a new package. In my experience, this tends to produce very nicely factored code in the end but it can sometimes be a pain getting there. It seems to be fairly popular in the Go community to just put all that in one package, too. Personally I break things up fairly granularly all the time, but I'm pretty sure I'm in the minority.
After doing all the optimizations, the language is now our bottleneck. 
The site has users!
very nice
It doesn't have to be open-source unless you statically link it.
I personally use golang
If the result of obtaining stack frame was assigned to a local variable and never used, it would eliminate dead code. But it is assigned to a structure field and there is no way to trace its usage completely. 
Maybe I need to read again, but I still don't understand how does wrapping an error maintain the type information. I am still forced to pass a string. So during unwrapping, how should it know what to return ? And how is all the stack information of the previous error preserved ?
you can say that again
I've put Google Go. People who know will know, other people will see Google and know it to be good.
Instead of passing around large environment structs, you should define rather small interfaces that the respective structs will fulfill. This way you can easily inject your struct while conserving the separation of concerns in other packages.
Hmm, the choice of making wrapping part of `Errorf` is a bit strange to me. That function is doing a couple of pretty distinct things there now, providing both string formatting (as suggested by it's function name), and wrapping (which IMO is not very clear at all). When you wrote this comment I still had to hunt to see what you meant because they don't show it in the examples either. I looked at the signatures for `New` and `Errorf` and saw no `error` typed argument, and assumed was left thinking "what was /u/Ainar-G talking about?" until I read the description. Where I work at the moment I wrote an error library that works very similarly to upspin's error handling, but with a more general approach that can be used anywhere. We treat errors similar to log lines, and make them more like "structured errors" (which also happens to make them much easier to log and subsequently search for consistently). I'd love to see a solution similar to that in the stdlib. Otherwise, there are many parallels between the approach suggested here and the library I wrote - it'd be nice to offload it to the stdlib instead.
Presumably there will be a field for metadata (maybe `map[string]string` ?) to attach to the error.
Doing fmt.Printf(“%v:%T”, t, t,) Is a great way to make sure that all the variables are working as expected at the end of the function. Very very helpful for debugging a new function pattern
&gt; Looks like one has to have a rep Only rep I have is being a gigantic asshole. What does that get me?
Yet I've had conversations with recruiters before where I exclusively refer to it as "Go" (spoken aloud) and they continually repeat back "Golang" to me throughout the conversation as though I were using the slang and they were correct.
Just go. Golang is for google.
I'd write "Go" if the context is obvious (ex. list of programming languages) and "Golang" if not. 
If you look at the current implementation (which the more I think about now, the worse it seems to me), you can see it is how it is described in the godoc for `Errorf`: https://github.com/golang/exp/blob/master/xerrors/fmt.go#L51 If you end the error message with `: %w`, and the last argument to `Errorf` is an error, it will keep that error as is, and wrap it. As in, a reference to that error is kept and stored on the new error produced. Also see the `wrapError` type in there.
[removed]
This is the best way by far. It also allows you to mock a lot of interfaces for running tests, which drastically helps in a lot of ways. Eg, if you’re using a database, just make an interface and use that everywhere. When you set up the main run program, you instantiate from the real database package. When running tests, you instantiate your mock database package. Typically all of that is done in the main package, so it’s easy to swap out components. 
On the other hand, I appreciate the behavior that you still get an error when you wrap a nil. I've had a few bugs crop up with accidentally using `Wrap` instead of `Errorf` and they're a PITA to diagnose. Example: mymap, err := getMyMap() if err != nil { return nil, errors.Wrap(err, "error getting mymap") } val, ok := mymap[key] if !ok { return nil, errors.Wrapf(err, "no value exists for key %s", key) } return val, nil
I feel like you missed something here. You asked your answer as if it were a question...
Circular dependencies took me a while to get around when I was new to Go, it's a bit mind-bending sometimes when you get one, and can be pretty frustrating! There's instantly an obvious problem in your package structure though. `global` as a package is a big red flag. So is the stutter you've probably got going on in your `router` package (unless you've just got a function in there called `Build` or something). Using dependency injection instead helps solve a lot of circular dependency issues, because you can take advantage of Go's interfaces and their duck-typing. This allows you to define an interface for a type where you are planning on using the type, letting you avoid importing the real type. Of course, interfaces aren't always necessary and using them just to avoid circular dependencies can certainly feel like a bit of a hack (IMO anyway). Another potential problem you might be having is that you're trying to split code that belongs to a single domain out into multiple packages. A telltale sign of this is that you're importing between all of those packages involved. Maybe you don't actually need any separate packages, and you could just get away with having a package named after your app, or whatever domain your app is handling (e.g. `users`, or `orders`, etc.) If you've got basic types (think Java beans, Scala case classes, "beans", or "entities", etc.) then maybe they can go in a package that doesn't import anything else, that moves them into a place where you can't get a circular dependency from those then. This would let you import those from anywhere, but it can also be very tempting to end up having packages called things like `types` which are just as bad as having packages called `global` IMO. TL;DR: * Use DI and interfaces to your advantage. * Group up code related to a single domain in the same package. * Split shared basic struct types into their own package if they really are used in loads of places.
Running 6 to 12 node cluster.
Wish Bigtable was open source :-). But I mention that in the footnotes in the blog post.
[https://perkeep.org/](https://perkeep.org/) (nee Camlistore) by Brad Fitzpatrick on the Go team is the premier CMS written in Go.
Go is the name of the language. Calling it Golang, GoLang, Go Lang, GO, or similar can make you look like a Go newbie or like someone who does not care enough.
Yes, that's another known use of "stitching" in the IT world. I am okay with using it as a synonym for concatenating if the intent is to make the project tagline stick in our minds. (And the fact that we are discussing this here proves that it does indeed stick :)
Thank you so much
Thats great. But can I please ask, if this library has support for service discovery etc? Also, if its a streaming library, that means its synchronous right ? Also, someone just confirmed that go-micro has support for MQTT. I will start with that first. 
Yes, I think i will have to use either go-kit or go-micro. Need to read about both of them.
Well, not `Go!`. That's completely different ([see Wikipedia article on Go!](https://en.wikipedia.org/wiki/Go!_(programming_language)), and it was a contention when Go was announced.
Some measurements would be good. What is the expected performance impact? Even with it being less it could still be acceptable (loss of packets and timeouts are already not great for performance :))
You can more easily create your own error types to contain domain specific metadata and they are easier to get to even when wrapped/hidden by other errors.
Yeah I'm not really comfortable playing guessing games with custom error types, having a standard string map for metadata is good enough.
I thought this...
In your project you can define an standard error type to do that. I don't think it should be standard. ``` type MetaError struct { msg string map[string]string } func (err *MetaError) Error() string{ return err.msg // or add meta information here or in detail. } ```
And often HR uses computers to weed out resumes for relevant keywords. I vote `Go ("Golang")` so that you don't accidentally miss out on opportunities due to keyword mismatches.
* Pull relevant structs/funcs out of the main package * If you've exhausted that and there are still issues, use interface types liberally In all honesty, you should probably start with your `global` package relying on your `router` package. That's not good.
I'm using `golang` to find something related. The Go is ambiguous as keyword. 
I've found the alternative worse, having to handle undefined, nil, and zero values differently whenever you want to access a value gets tiresome fast. 
[removed]
Why did you have everything in one package with explicit dependencies on DB? The code looks impossible to unit test, though I guess you could move the sql/\* APIs. I don't mean this as a criticism pre se, but it goes against my inclination to use interfaces to logically separate goals from implementations.
The correct answer is why are you doing this? 1 package seems fine for now.
Interesting; have you check whether someone has requested the feature? It would be nice if Jenkins in general were a little lighter weight but that kind of change might disrupt the ecosystem. &amp;#x200B; Make a feature request? [https://github.com/jenkins-x/jx/issues](https://github.com/jenkins-x/jx/issues)
That's an interesting argument. However, it's also pretty rare that I feel I need a stack trace for most errors. In general I make sure my errors messages have enough information to let me or a user know what is wrong. A stack trace is really only useful to me during development when I'm debugging. One risk to adding it by default is that it may lead people to become thoughtless about their error messages, relying too much on the stack trace to know what happened. A stack trace is generally a lot of noise for most problems. 
That is definitely reasonable feedback. Unit testing is on my todo list and might involve some refactoring when I get there. For this iteration, I liked the simplicity/readability of keeping the DB functions close to where they were used.
They're coming :-).
Nothing wrong with errors as they are. However, I'm under no illusion that the vocal minority expressing itself via social platforms will no doubt win the day.
But still the official MongoDB driver for Golang is still in beta. ☹️☹️
For template updates, you could let users take advantage of the [go generate](https://blog.golang.org/generate) tool. You would just need to add the following line to your `main.go`, right after the `package main` line: ```golang //go:generate go-bindata templates/... ``` This will let your users simply run `go generate`, and the template bindata will be regenerated. Granted, they will still need to `go get` go-bindata first.
Or like someone who has tried to google go at least once 
Hey CS:GO players of r/golang It's been about 6 months since I [posted here to announce the v1.0.0-beta](https://www.reddit.com/r/golang/comments/8ymm1c/demoinfocsgolang_a_go_library_to_parse_and/) of my CS:GO demo parser. Now, v1.0.0 is finally done (and I'm pretty stoked how far it has come!). There's many new features and tons of API improvements (like mockability, ease of access etc.). I won't bore you with the details but I hope some of you can use this to create awesome apps. For inspirations you can checkout the [examples](https://github.com/markus-wa/demoinfocs-golang/tree/master/examples) which show how to create [heatmaps](https://github.com/markus-wa/demoinfocs-golang/tree/master/examples/heatmap) or [grenade trajectories](https://github.com/markus-wa/demoinfocs-golang/tree/master/examples/nade-trajectories) A contributor also created [noesis.gg](https://www.noesis.gg/) which has some fairly cool features to analyze demos.
"Go" if context is obvious. "The Go Programming Language" otherwise.
I would love to hear more about that. What are your response times for readers vs editors?
Like clang. But then all you can find is information about a specific compiler.
Very cool. I will add that in shortly.
As opposed to Javalang, Clang, Rustlang, Pythonlang, and Rubylang, to name a few?
Golang damn it
This deserves more upvotes.
It should probably be Go until the first hit golang.org 😆
A whole lot of assholeness, I reckon!
As a notice: You don't need to use `math.Pow10` here. `10e7` is much clearer or even better `1e8`. So you could just write func AddGigasecond(t time.Time) time.Time { return t.Add(time.Second * 1e8) } . And btw. the prefix 'giga' is used for 1e9, so you might have a bug.
Is that really the alternative? I mean, isn't that pretty much exactly where Go also leaves you when you do need to differentiate between unset and zero value? 
Thanks that’s good to know. I was looking to use 10^7 but that didn’t work. Then I realized it didn’t work in c and java as well, so not sure why I thought it would. Maybe cause it worked in excel, cause that’s all the code I’ve written recently? I’m coming back to programming after 15+ years and the pockets of ignorance within knowledge (or maybe the other way around) make this incredibly frustrating. You think things should work a certain way but they don’t. And yes I did catch the 7 should have been 9 but sharp eye there :) Thanks 
Two things come to mind: 1. Why did it need "extracting" when reflectx is already its own package (albeit under sqlx)? 2. You seem to have taken Jason's code verbatim but not honoured his LICENSE which says you need to retain the copyright notice, and instead put it under your own, different, license.
What does the library do exactly? Going by the example, it seems to just eliminate some fairly simple tasks, like parsing struct tags. The shitty part of auto-populating structs from text—converting string values to other types—[appears to be left up to the user.](https://github.com/scylladb/go-reflectx/blob/b900ecd1caa0a3e65ba1fa9dd09335f41b7c9ee3/example_test.go#L75) Have I missed something?
I think it's just a clarity issue... If it's in a list of programming languages, Go would be fine. If it's in some other context where it wouldn't be glaringly obvious that it's the language, Golang. The worst part of Go is the name Go.
Such hot path errors will not be created as they occur. They will likely use a global variable which, since its already created, will not be calculating the stack frame each time it is used.
Whatever you do, no quotation marks. Not everyone reads that as a string:) But more seriously it feels more like personal communication than formal. Or you can go Prince and answer “all of them” if they ask about languages :)
I think they are taking stack frames, not full traces. From what I see, each time an error is wrapped, an new frame is added. So it all depends on the amount of wrapping you do.
Will do! and yes, that is the sole point of the repo: to concatenate other files into one big file. My incentive for doing is to have an easier time with goyesql, [https://github.com/nleof/goyesql](https://github.com/nleof/goyesql). I wanted my codebase to be really clean and spread across multiple files, so making a new variable for each file seemed a little too obnoxious to me. I'm well aware of other repos where they also have CLI for file concatenation; however, I want a configuration file to address what directory I want the file to be in and what files to exclude. 
&gt; What's an idiomatic way to solve this? "Accept interfaces, return structs". `router` and `global` can use each other's types; they just can't import each other. So to use types from `router` in `global`, define an interface in `global` that your type(s) from `router` implement (and vice versa). There's a bit of a whiff about a package named `global`, though. 
Qt rocks. I use it for Go to all platforms. The only issue being it’s version of SQLite - it’s an old version and I just can’t get it to update to a newer model with JSON data types and security for data at rest. However - everything else just works. I write in Go and then compile on my Mac for whichever target required. You will still need Xcode for iOS though. So database aside, Qt works well. 
&gt; may lead people to become thoughtless about their error messages, People already are, 99% of the time people handle errors with `return err` if you're lucky you get a "stack trace" like `fmt.Errorf("currentMethod: %v", err), if you're really lucky you might even get `fmt.Errorf("currentMethod erroringFunctionCallName: %v", err)`. While I totally agree you should add useful context if you have it, the vast majority of the time simply knowing the file and line number is sufficient and more than you often get today.
Ayyy, I went to a conference where JBD gave a talk about Distributed Tracing at Google Cloud.Unfortunately there was no talk about Go.
I'm assuming you mean that Wrap/Wrapf will pass through `nil`, which could bite you, yeah. But I think modifying `Errorf` just opens the door to even more suble bugs than `nil` checks. For example: e, err := doSomething(s) if err != nil { return errors.Errorf("doing something with %s: %w", s, err) } I could accidentally write this, typing `e` instead of `err` (maybe after an auto-complete): e, err := doSomething(s) if err != nil { return errors.Errorf("doing something with %s: %w", s, e) } There's no strong typing, so you'd probably not realize until later. Similarly, I could typo and write: e, err := doSomething(s) if err != nil { return errors.Errorf("doing something with %s: %w ", s, err) } With a space after the `%w`, and now I break the rules `Errorf` defines, again because it relies on the user remembering a specific format string pattern instead of using the compiler. Compare that to `pkg/errors`: e, err := doSomething(s) if err != nil { return errors.Wrapf(err, "doing something with %s", s) } If I mistype `err`, I'm much more likely to get a compiler error (if `e` is `error` then I may miss it), and I don't have to remember `%w`, because the signature of `Wrapf` tells me exactly how to use it.
And every argument they listen to pushes us two steps back towards Java and C#.
Sorry, I guess I was confused between Artifactory vs Nexus. The comment was about nexus. See here [https://jenkins-x.io/about/decisions/#nexus](https://jenkins-x.io/about/decisions/#nexus) &amp;#x200B; \&gt; " [Nexus](https://help.sonatype.com/repomanager3) is an overweight JVM that recently moved to OSGi however it does the job we need of it. ...If someone developed an open source artifact repository server in a more cloud friendly language like Go then Jenkins X would likely switch to save on cloud bills. .."
FWIW, `go test` can check that `%w` always uses an `error`
Well, it's pretty new. The Mgo package was very well-received to the point of an official one not being pursued at first.
This is the least controversial proposal. 
I think it's a mistake to think only humans will be reading your resume.
Do you mean that someone could write tests for their functions to check the returned errors, or do you mean due to the fact that `go test` now runs `go vet`? The first is certainly good practice, but IMO using `go vet` and `Errorf` feels like piggybacking on format strings and `interface{}` varargs for error wrapping in an effort to reduce the number of functions/types added in the proposal...
Well idk about that. It doesn't take long before you realize you have to adopt some kind of convention for adding detail to errors in complex programs. But it doesn't take much additional context to know what's going on in most cases. This is an area where I feel that it is better to be more permissive to the programmer even if many new programmers will not write good error handling. I don't mind go's error handling. It forces you to pay attention imo.
Post this in /r/GlobalOffensive . Might be better received.
The “s” is for “stack”, maybe?
I did! doesn't look like it though: [https://www.reddit.com/r/GlobalOffensive/comments/ajt1kx/demoinfocsgolang\_a\_csgo\_demo\_parser\_in\_golang/](https://www.reddit.com/r/GlobalOffensive/comments/ajt1kx/demoinfocsgolang_a_csgo_demo_parser_in_golang/) &amp;#x200B; Probably since there's not many go-devs over there.
Options are always a good thing. I'm a novice go programmer, but I'll give it a shot :) The examples are pretty great.
\&gt; The examples are pretty great. Thanks! &amp;#x200B; Let me know if you end up doing something with it, would love to see it.
Would be cool if this could be used as an ETL tool to put the events in a database that could be analyzed with a BI tool.
What are readers and editors? By language being bottleneck, I mean, based on our very rudimentary observations using \`top\` command, most of the server resources are spent on WSGI handling python app, and we get fair share of 502 due to that, while the database is cool. So we suppose that it is the Python which is the culprit. Based on my previous joyful experience with Go (few microsecon responses time is quite a feat!) Python in it's best is an order of magnitude slower than that, so by changing the codebase to go we hope to get a huge optimisation, both in load and stability of the app/site. 
I've got some stuff using dep, most stuff I just use good old fashioned go get + gopkg.in All that said, I've been meaning to switch to Modules as it's the "standard" way forward, but I'm not super happy about it.
[removed]
[removed]
There is a long road ahead, and as you can see we are at the first stage. But I hope I can share useful info sooner rather than later. If you don't want to change underlying data structure, rewriting code into new language that you're familiar with is not that hard. &amp;#x200B;
It seems that TarsGo uses an in-house RPC protocol(a simple request-response cycle with any serialization format) on top of TCP/UDP for messaging. You may want to open an issue on GitHub to get a precise answer. Here is the code: [https://github.com/TarsCloud/TarsGo/tree/master/tars/transport](https://github.com/TarsCloud/TarsGo/tree/master/tars/transport)
It should be possible to use it for something like that I think 🙂
You're showing us code organization here, but not showing us your object model/data model. Every program has inputs and outputs, and some set of transformations between the two... how is that supposed to work for your use case? Can you sketch that out for us? Your data model is independent of how you represent it in code, but it can guide how the code is organized. Obviously what you've chosen is suboptimal... Reading between the lines, it appears you're interacting with a database. Since a database has a schema, you have one set of data models that should be obvious: each row in a table should be represented by a struct in your code, at minimum. Put these structs in a `models/` directory, that you can import them wherever needed without any sort of circular dependency. The fact that you're clumping all your data into a single, global struct is a design smell. This is going to make your code incredibly difficult to test and/or debug. What is the need for such a design? Do you not know what data your functions will need, so you just send everything, everywhere? Ideally, you'd couple your functions as loosely as possible, using a minimal set of inputs / outputs for each. This will make it much easier to set up a test for each function. This will also reduce the amount of data each function can touch / transform, in turn, making the program easier to debug when a bad output appears. If there truly is a place where you need all your data to appear at once, minimize the scope in which that happens. Ideally, it would only take place in the one function that needs it... but it's going to be a whopper to test...
Just Go. I somehow use this kind of standard keywords to filter out those incompetent companies.
Just Go. As said Rob Pike at the last Meetup, there is no such things as "Golang" 
I have always designed my code around that problem. Avoid pointers in structures and avoid pass nils around (until nil is a sensible value for that type or accompanied with an error value). Go initialize unset values to the zero value automatically so you'd have to work very hard to recreate that. 
Thanks, but actually I decided to continue with go-kit. I think, using that would help me understand the microservice architecture in a better way then using trans
I'm not 100% sure what you're really referring to by "the navigation changes based on the user's roles while still displaying page specific information." Generally you would build the frontend as a SPA with react or something and then the backend (Go) would just render json.
&gt; I have always designed my code around that problem. Me, too. But that quickly falls apart when you have to deal with 3rd-party APIs that aren't designed with the same attitude. 
What we now take for granted was incredibly innovative and very hard to arrive at in the past. What a great mind and computing pioneer!
I’m looking for people doing things more old school. Is anyone rocking the web template libraries like it’s 2005?
A big part of the community follows the Go philosophy of going with logical stack traces (human readable) instead of the usual stack trace you see in other languages. Personally I am against pkg/errors. Not only errors are not part of your domain but there's always the confusion of how many times to unwrap till you find the cause. And of course, it brought the stack trace mess into the ecosystem. It's an unfortunate sign that laziness and convenience will always win. Thinking about errors and programming errors is hard.
I see. I still do not think it is worth to add as a dependency to a project. The standard tooling works well enough. I could see using it by having it installed in GOPATH, type it and auto import it, then delete it when debugging is done. Unfortunately this doesn't work well outside GOPATH with mods and all.
\&gt; My desire is to see how people control the competing demands of different section of the HTML rendering which talk to differ data repositories all under the same route. &amp;#x200B; Simple, you tackle the complexity by separating the backend and frontend. Keep the backend clean with Go and use the whole Javascript mess for the complex UI.
Dear lord. We are slowly turning into Java. WTF is Rob Pike doing?
Keep your domain structs at the root of your project and all your problems will disappear. Also, if these are your actual package names, consider changing them because they are very generic and frankly just bad.
While modules are currently experimental, I think it is worth going through the pain and report all the errors you find. Modules are simply a superior solution to dep.
What do you have in mind? It's a CLI tool... there is no graphical UI. (Yet?)
Structs define a record format. Typically a field name and the type of a value. This can be used for a variety of things, loading/saving database records, reading or writing to a file, loading or serializing JSON objects. 
[removed]
A problem with this is that the JS front ends take up more bandwidth. So you use more of your customers’ limited cellphone data. Phone caches are small. If you bundle your view technlike React into your Web Pack results you can’t take advantage of common caching. Your app is likely getting redownloaded each visit. 
Ah my bad, I thought it was graphical.
Why does `As` take an interface as the target and not an `error`? Cause every unwrapped error in `err` will still be of type error and therefore the target must always be an error.
You can do server side rendering in react
A struct is similar to a class instance having only properties. A struct is declared by: `var variableName structName` or `variableName := &amp;structName{}` You can set properties by while creating a struct by: `structInstance := &amp;structName{var1: "abc", varFloat64: 123.45}` Accessing properties is the same. ``aStringVar := structInstance.var1` Hope that helps 
A struct is like a python class with properties only (no methods). You create an instance of a struct just looked instantiating a class. https://gobyexample.com/structs
Rob Pike isn't on the authors list for this proposal, so I don't think he was involved.
Using tool a few months back was really a pleasure!
Do you have New Relic or some similar product to do a trace? Go is faster but Python shouldn’t be adding much compared to how slow databases are. 
Could this parse an embed voice chat?
I write Go and PHP both nearly every day. I would say there are many things PHP is far more suitable for, just as there are many things Go is far more suitable for.
Cool project, nice job! This sort of reminds me of dotabuff's [manta](https://github.com/dotabuff/manta) for Dota 2.
As to performance, I don't know. From a safety perspective, won't this panic if some implementation didn't have a float64 in the column specified?
[removed]
Ahh I see. Well, this is indeed a surprising behavior. All to maintain compatibility. I wonder whether a new API taking an `error` param for Go2 should have been done. 
[removed]
[removed]
I've been trying to figure out Go's approach to errors for the last week. There is a silent minority that flat out refuses to teach newcomers how to properly use them. Few people in this world are coming to Go fresh from the womb. Most are coming from Java/C# or any other language with stack traces attached to runtime exceptions. Without a kind community to help move people from exceptions-every-where to errors-are-part-of-your-domain, you're going to lose the battle. If enough people simply down vote questions here or on SO about how to do X in Go when it's clearly written from a Java perspective, you're going to either become more like Java in order to get mind share, or you're going to be in a dying/niche language. Haskell has a small community. Do you want to be the next Haskell?
Python objects are something like a Go struct (https://docs.python.org/3/reference/datamodel.html#slots) and a `map[string]interface{}` (https://docs.python.org/3/library/stdtypes.html#object.__dict__) (and probably some other stuff) in one. The closest Python equivalent to a Go struct is an object with just `__slots__` and no `__dict__`, like https://docs.python.org/3/library/collections.html#collections.namedtuple
This code is way too complicated. What does the input data look like?
It seems like you're breaking your abstraction. If you know that no matter what there is a string version of the column, why not have a function GetAsFloat64(columnIdx int, table) where you iterate the table and cast the string to a float?
Why is this a giant script? Why didn't you structure the code into units? I'm not harping or attacking. I'm curious about your design philosophy.
I'd go farther than fsckdevnull. A struct is a python class. ``` type Person struct { Name string Age int } func (p *Person) MyFunc() { fmt.Printf("Hello my name is %s", p.Name) } ``` is the same thing as ``` class Person: def __init__(self, name, age): self.name = name self.age = age def myfunc(self): print("Hello my name is " + self.name) ``` Are you having problems with the above, something else, both? 
Regarding tight coupling, the entire point of interfaces is to prevent tight coupling. [Accept interfaces, return structs](https://github.com/golang/go/wiki/CodeReviewComments#interfaces). Philosophically, Go doesn't promote tight coupling. Regarding architecture, stop trying to overdesign and just write code, lest you become an [architecture astronaut](https://www.joelonsoftware.com/2001/04/21/dont-let-architecture-astronauts-scare-you/). You use whatever architecture makes sense for your code, not force your code into whatever architecture you chose up front. This is what refactoring is for.
Not really. In python you can export the "train\_op" tensor, which can be run from Go. &amp;#x200B; I'm playing around an alpha-zero implementation and using Go to simulate the board game and train it in this fashion.
In the past 24 hours there have been at least two projects submitted to golang asking for feedback. Neither introduced their own interfaces. One used layers. The other was a large script that used closures that accidentally enclosed outer variables while using channels communicate. When I see blog posts online for go, the majority have the DB as an explicit argument to router code. Many times the handlers explicitly use the DB to execute queries. From an architectural perspective many Go apps appear to be [transaction scripts](https://dzone.com/articles/transaction-script-pattern). Is that as common as I think? Is it generally the right direction in the communities eyes? I am asking for your opinion. Can you point me to a go based REST service that is good example of the proper level of abstraction in Go? 
Except structs are not classes and composition is not inheritance. You’ll run into issues down this path. 
Okay there’s actually a bunch of performance issues I could address here I think, but the biggest is that you’re doing a memory allocation for what, 1.5 million floats, inside your timing measurement. Also let’s be realistic about how long you expect this to take. You can’t do reflection on n columns * m rows and expect it to be blazingly fast. 200ms is not a bad result for m=1.5 million and any value of n. 
Yes
I fully agree with this. If you want or need such behavior, I believe that you can achieve behavior like inheritance by having the struct implement all interface that the embedded implements. The methods would pass through to the embedded or do the work themselves. 
A struct is a Python class that doesn't support inheretence, doesn't have a builtin constructor function, and doesn't have magic methods. Without being too technical, there are alternatives in Go for the different concepts from python 
I just put "Go." Recruiters that are serious will figure it out. But I'm also only ever in passive job hunting mode these days. It might take a different strategy if you're actively seeking a new job that focuses on Go.
Except you don’t have method overriding either, just message deferral to the embedded struct, which acts as if the “base object” doesn’t exist. 
[removed]
1. Check resp.ResponseCode 2. Print for us body - json string returned from server
Ah! .Decode() returns error, not data :-) data are in hakaton variable
&gt; You don’t have method overriding either, just message deferral to the composed struct, which acts as if the “base object” (the one doing the composing) doesn’t exist. I appreciate this kind of triaging. Between the link in my answer and this back-and-forth, the generalities of structs should now be concrete.
Why don't you just use `json.Unmarshal`?
&gt; https://github.com/mongodb/curator `mgo` was so comfy, I am pretty sad it was abandoned.
Probably just like you would in any other language: an unmaintainable mess of partials that accumulate way too much complex logic and make caching nightmarish. There's a reason nearly everyone is moving to UI frameworks for UI and using languages like Go for what they're good at instead. Some sites are even moving to running e.g. React on the server, essentially making that partial template mess much easier to scale and maintain. 
The idiomatic way is to make packages based on they do, not what they contains. So avoid `util` or `global` package. If you need database, make a `database` package.
&gt; Practically all code paths from syscalls to user code in stdlib use `*net.OpError`, `*os.PathError` etc wrappers. If those start collecting stack traces, Why would they suddenly start collecting stack traces? &gt; they'll slow down execution of many useful programs, for sure Let's not overstate anything without actual measurements first, shall we. &gt; Global variables for errors sounds like the stack traces on many, *many* errors will be quite useless then. A top-level `var FooError = errors.New("...")` won't have any useful stack trace information attached I don't see why global variables made by errors.New would contain the stack frames. It's not like it would be nontrivial to figure out if your caller is the global scope 
Nothing wrong with making the language actually suitable for large projects and teams.
Ultimately an error can be anything. It could be a negative integer return value, or a string that says "bad things just happened." In low-level code which demands high performance, there's no good reason why actual `error` types need to be used. 
Unfortunately this doesn't appear to be in the demo files. Chat messages are available for some demos but not MM (they are encryped).
Made a minor update. What do you think now?
@AskAlexSharov Made a minor update. What do you think now?
Made a minor update. What do you think now?
Interesting...Do you know where it is stored? Weird I wonder how the esea demos with that embed voice chat work.
You have to check the body if it really returns the expected JSON body.
Yes, it does. Something is going wrong with the JSON parsing part!
I understand what you mean. And I am also looking for this kind of code examples. In ASP.NET(and ASP.NET Core) this is handled easily by using attributes over controllers and writing roles and other things easily. I wish I could see the same alternative of Golang code.
It doesn't. Your struct will compile to { [ { "title": "mytitle", ... }, ... ] } Meanwhile the API returns { "January": [ { "title": "mytitle", ... } ] }
Yes, if you put the Hackalist JSON into https://mholt.github.io/json-to-go/ you see this problem right away.
&gt; Can you point me to a go based REST service that is good example of the proper level of abstraction in Go? No language dictates a "proper level of abstraction." Build what you need to build and abstract when the simplest form of your implementation becomes heavier than the abstraction would be. That's as true in Go as in anything else. If you're interested in Go-specific best practices, I'd recommend reading [Effective Go](https://golang.org/doc/effective_go.html).
Wow that's a neat tool. Bookmarked. Thanks man.
Print body please. Need to see your json
Simpler, easier to use, more popular, but translation flexibility similar to gettext: https://github.com/nicksnyder/go-i18n More advanced, not updated recently and harder to use, but imo more flexible: https://github.com/go-playground/universal-translator
Also there is an official go attempt at that x/text https://godoc.org/golang.org/x/text
When building restful api, I usually have a controller package to handle routing, a model package to handle db CRUD. Data types and their methods are put into other packages as you like. The main imports controller which imports model. The main, controller and model could import various types defined in other packages, but these three packages never import each other.
NO. If it's spa then the browser should render this. I don't want to run go app. and then a memory hog of node on the server.
Yeah, you need to benchmark that and find the bottleneck. Python can be very performant if done right. Just changing the codebase from one language to another without adapting to the language in the first place won't really help.
And rebuild/fix 20% of code everytime you do everything every 6 months because the BC went to hell in between.
I know that the functionality is minimal, so started writing without thinking about writing tests. I will structure the code when it seems appropriate.
It looks like the ESEA voice data might be there! I am seeing this network message is present in some demos: [https://sourcegraph.com/github.com/markus-wa/demoinfocs-golang@012df0eca77337c8d01c3ac34df59b412aaf084c/-/blob/msg/netmessages.pb.go#L872:6](https://sourcegraph.com/github.com/markus-wa/demoinfocs-golang@012df0eca77337c8d01c3ac34df59b412aaf084c/-/blob/msg/netmessages.pb.go#L872:6) Check out this example on how to read the data (the message-ID is `15`, type `CCLCMsg_VoiceData`): [https://github.com/markus-wa/demoinfocs-golang/tree/master/examples/net-messages](https://github.com/markus-wa/demoinfocs-golang/tree/master/examples/net-messages) &amp;#x200B; Regarding chat, I don't remember the details as it's been a while since I've investigated it but here's some more info: [https://github.com/StatsHelix/demoinfo/issues/45#issuecomment-93006545](https://github.com/StatsHelix/demoinfo/issues/45#issuecomment-93006545) &amp;#x200B; The data could be in `CLCMsg_ClientInfo.Payload` but I'm not sure. There's also `WatchableMatchInfo.ClDecryptdataKey` which might contain the info necessary to decrypt this, but I'm not sure what algorithm would need to be used. &amp;#x200B; (Oh and if you want you can also join our gitter to discuss this further) &amp;#x200B; &amp;#x200B;
Thanks! I'll join tomorrow when I have more time
You’re not wrong: two approaches; 1. Error when created should get caller info only to log the file/line where that happens (effectively free as it could be resolved by the compiler), 2. Stack trace could be added when the error object leaves the current scope (a function call like fmt/log or return), but not necessarily a compare for io.EOF Also, log package has an option function that can turn on caller information (Lshortfile or something) and it affects log functions globally. There’s no reason the errors package wouldn’t have the same (and you could switch it on/off in runtime depending if youre debugging or want performance)
Please stop spamming this subreddit
I don't see how it is not suitable for large projects and teams when it comes to errors. We are free to program our own error strategy. The fact that people are lazy is irrelevant. It can be solved with some good blog posts and talks. I really don't see why we need all this complexity.
Yup and that is the problem. He stopped caring. He said it clearly in his latest talk. "I won". If he and the original authors do not step it, their language will slowly become more and more complex as well as similar with other languages. Exactly the thing he tried to avoid in the first place.
You shouldn't be using projects looking for feedback as a reference point. That's like taking an undergrad's thesis draft as the gold standard for scientific studies. &gt; When I see blog posts online for go, the majority have the DB as an explicit argument to router code Blog posts aren't good examples for production code either. With that said, what's wrong with passing DB directly if you don't ever plan on changing it? You're probably thinking of designing a nice abstraction layer wrapping DB, right? [You Aren't Going To Need It](https://martinfowler.com/bliki/Yagni.html). If you do need it, why are you even asking? You know you need the abstraction, you know what the abstraction should look like, so just write the code. &gt; I am asking for your opinion. Can you point me to a go based REST service that is good example of the proper level of abstraction in Go? Depends on what you're doing. The point of programming isn't to produce perfect code, it's to solve problems. The approach should match the problem.
What are you talking about? Do you think writing Go templates with a bunch of ifs and other logic is maintenable? If you think that, then go ahead and try it. It will all be peachy at the start but later you will learn the true definition of unmainainable nightmare. Sure Go is maintenable. But Go templates are not Go. Whenever you like it or not, you currently have zero choice when it comes to writing frontend. No matter what you do, you end up with HTML/JavaScript/CSS. What? Typescript? Dart? Sorry mate, it's all just JavaScript in the end. So how the hell are you going to maintain complex JavaScript injected and separated in a bunch of Go templates? You just can't. As soon as you reach a certain level of growth, you will realize that you lack the tools to maintain the frontend code. &gt; And rebuild/fix 20% of code everytime you npm install on a different machine. You've heard about Docker right? &gt; You can't leave npm code at rest for 6 months and expect that it will still work. I don't want to do a constant upgrades so I can still build old code. What? Why? Oh wait, is it because you are using the amazing latest frontend framework Rectanguvuelar 43? Did it just release a new version and you have to update all your code? Oh noes! Well let met tell you a little secret. Stop cargo culting and use the web standards. Then you won't have to change your code ever again. Ever heard of them? Standards. All browsers have to implement them. Why? Because they are fucking standards motherfucker. Standards. They are awesome. They are here. Use them. Stop drinking the Reactanguvuelar kool-aid and use the fucking standards.
You're trying to suggest that one should always assume to be better than person your talking to? Yes one should assume that one might be less competent than other person behind the screen. That's called humbleness. I'm not entirely sure why attempting to flex at expense of others, often imo by lying (statistically improbable occurences), is so prevalent in go community. For example React ppl don't have it. Rustaceans are super humble, even then they have all the reason to be. And now you just exhibit it again : l
I suspect it does marshalling in a streaming fashion thus reducing the memory footprint but i'd like to be corrected on this.
Russ Cox is the Go project lead and co-author of this proposal. Pike, Cox and Thompson have been colleagues since Bell Labs / Plan 9 days and they share a very similar design philosophy.
It seems you are new to the ecosystem and judging by your words, you seem to have a strong background in Java/OOP. Well, Go doesn't work that way. Remember that when you bring your design patterns and clean architecture to our world, you need to change them accordingly to use Go's strengths. Please do not blindly translate your patterns to Go. We are tired of it. Go is not Java. I have no idea how you concluded that we like tight coupling and all that. It's obviously that you are missing some important resources. I hope these will answer your questions: * [Ben Johnson's DDD/Clean architecture](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1) * [Code like the Go team](https://talks.bjk.fyi/gcru18-best.html#/)
That would be my thinking too. If I'm already putting the JSON into a writer, I'm not going to take the detour of getting a byte slice first.
Thanks guys :)
The encoder also gives you some additional control like being able to error on unknown fields, which json.Unmarshal does not do.
I agree that its hard to compete with a dynamic language + mature framework like Laravel for complex server side UI.
&gt; What? Why? Oh wait, is it because you are using the amazing latest frontend framework Rectanguvuelar 43? Did it just release a new version and you have to update all your code? Oh noes! So your recommendation is to do everything myself? And don't use 3rd party code, and deal with browser sh*t myself. While everybody else will be overtaking me from left and right. 
I don't have any posts I can share, however I do have a code base you can see... As an alternative perspective to this thread, I was never a Java dev but I enjoy the principles around clean architecture, SOLID and TDD+BDD. As such my colleagues and I tend to write layered Go software, typically in an ATDD style. Heres a small-mid sized repo you can take a look at (its work in progress, but serves the point): https://github.com/endiangroup/specstack Its a mixture of package level functionality (see exports of config pkg) and layers (see application.go &amp; personas or any storer.go's and persistence). We tend to hybridise the features of Go with the aforementioned methodologies / principles. I for one enjoy lots of the stdlib (and am incredibly grateful for it), but some of it makes me cringe at how hard it is to parse, typically large function bodies and undecipherable variable names. They tend not to refactor much from what I've experienced. But thats also ok, just not my preference :)
Server side rendering is more bandwidth expensive over the whole session. SPAs are less so if built properly.
Thanks for the example. It makes sense now.
Not much difference in code: * https://golang.org/src/encoding/json/encode.go?s=6430:6473#L147 * https://golang.org/src/encoding/json/stream.go?s=4800:4847#L185 Some reflections: * If you're marshaling few and small values, it doesn't matter. * If you're marshaling to a byte slice, using `json.Marshal` is probably quicker. * Both first marshal into the `bytes.Buffer` of an `encoderState`. * I wonder why it doesn't write to the `Encoder`'s writer directly... Maybe to avoid an indirect call in the inner loop? * So I'd say it's more about convenience than performance.
&gt; Why doesn't this work? y is casted as an int. I can't explicitly cast that as: &gt; &gt; `int y = int(i)` Because that's a mix of C (on the left) and Go (on the right) while invalid in both languages. 
I'm a big fan of Clean Architecture and believe that software platforms should be developed according to its principles, meaning that you could start out with something fairly closely coupled and then decouple things as the application grows. Go is really no different for me. I've been doing some small tools and a micro service so far, and Clean Architecture is overkill for this kind of project. I still attempt to decouple different aspects of the service so they can evolve without too many growing pains, but this is part of my point: maybe you've been looking at the "wrong" projects. You could look into what larger projects such as Docker and Hugo do in order to maintain structural integrity and decoupling throughout. I certainly hope to learn a bit from these projects at some point.
I tend to use `json.Marshal()` in HTTP handlers. If the marshal returned an error I might want to do something like `w.WriteHeader(http.StatusInternalServerError)` before writing the error message to the `http.ResponseWriter`. If you simply write straight to the `http.ResponseWriter` without `w.WriteHeader()` first, the HTTP package will make assumptions and set the response code to 200. In other cases I don't see why you couldn't use use the encoder.
Having run large systems with Django, I suspect you've reached the wrong conclusion from some very incomplete data. You need proper instrumentation and observability before you can make the call that it's the language. I'm not saying Go wouldn't be more performant, but there's a tradeoff in all these things, and there will be some very straightforward optimisations you can make in the existing system once you understand what's happening in the stack - a complete rewrite based on looking in top is not a great business decision. &amp;#x200B;
The first question is... why are you implementing this. Excel sheet and high-performance reporting require significantly different design. Think implementing in terms of columns, rather than a single value. type Table struct { Titles []string Columns []Column } type Column interface { Count() int AsFloat64() []float64 AsString() []string } Also see https://medium.com/@egonelbre/manipulating-json-fields-f787d56bbd1d for a similar problem that was asked previously.
Clang is the Clang. Clang is not the C. Python is the language rather then the Monty Python. Ruby is some girl (image search), or the language rather then the gemstone. Rust is the language rather then what it means. And, finally, Java is the language rather then the island. When I'm seeking for a job, I'm using 'golang', since Go produce unexpected result rather not Go-related. But Google understand the 'Go' keyword ok. With some programming context 'Go' is enough.
What you describe is actually a method i.e. a struct paired with a receiver argument. A struct is definitely not a Python class. A struct is a container (or user-defined type) that holds typed fields.
Docker can be a POS IFF you build/use shit and do not know how docker works. Otherwise not too bad
You should commit all your vendored dependencies. You already using dep. That way you have full control of your dependencies and do not care even if whole GitHub disappears.
I commit my vendored dependencies, but that would not fix the problem. I'd have to vendor code from my own repository in my repository, so I would have: $GOPATH/src/myproject/ /vendor/ /github.com/myprofile/myproject/pkg ... /pkg/ env/ handler/ main.go But what version would I vendor? Also, does this not seem a little bit strange solution? Also, to vendor this, I would have to call **dep ensure** which would vendor **master** again unless specified in Gopkg.toml. And that seems a no-go.
If your package is part of your project then don’t add it to dep on the first place. And you don’t need to call dep ensure in CI job if you vendor your dependencies. The whole point is that you can just clone and build even offline.
Oh god, I'm really stupid for missing this. Just not use dep ensure. I'll try that, thanks!
Well, you can call dep ensure. If properly done, it wouldn’t do anything. It would check that all your dependencies are already vendored and leave everything as is. Dep locks git tag or commit in gopkg.lock. Updating your dependencies is a manual operation that should be done by hand. You do commit gopkg.lock do you?
Might be to not write anything before all error checking is done. 
Typically if Marshaling fails there’s a bug in your code. 
Https://gohugo.io
&gt; Clang is the Clang compiler. That's just an unfortunate coincidence. &gt; Python is the language rather then the Monty Python. But too easily confused with the snake. &gt; Ruby is some girl (image search) But also too easily confused with the gem. &gt; Rust is the language rather then what it means. Also too easily confused with the result of oxidization. &gt; And, finally, Java is the language rather then the island. Again too easily confused with coffee. 
They fixed NPM. Code rot is not an issue now that they have lock files. 
&gt;R Yup, ripped that out for sake of code length.
Thanks for the link, I will take a look. We (partially) disagree on thinking in columns vs rows. 15 years of creating solutions for very large data sets has put me into a mind set of records. It's like my thinking on how to handle things is back in the 80s. It's a debate for another post. Really this project, besides an excuse to learn Go, was to attempt to create a record based system and see if we (my company) can get around the issues we find with column based solutions in R and Python.
You can't be too careful. It is good to handle all errors no matter how small or impossible it is.
Yes I commit gopkg.lock, it seems I had the CI and the dep ensure configured in a way that it vendored my own repository. I think I know why. Because our company uses CamelCaseUserName, that has to be exact in the imports, otherwise it imports it as a different repo/import but with same content. I just noticed this when re-doing the imports. &amp;#x200B;
I'm not English native and a meaning of this words for me is primarily about programming. And, as rule, seeking for something in Google I've got programming-related result, regardless keyword used (Go or Golang). Seems, Google targeting does this work for me. But when it comes to seeking for a job, Go gives the maximum ambiguity. But. I never searched a job for any other language xD. I think C programmers uses C-language, or something like this. The Ruby, as rule, comes with Rails and Ruby-on-Rails is univocal. `Rust` gives me links to * the Rust language * a game called Rust (2-3 page) * some town or city in Germany called Rust (pronounced as Roost) * on 4-th page something to read about explosives So, nothing about rust cleaning agents.
I use go.mod now and it solves a lot of headache. You don't have to put your source in `$GOPATH/src` anymore. You just have to `go mod init github.com/my/package` in your package root directory.
Yup, go mod is on the TODO list.
It does not yet but it may in the future. There is a bug on the GitHub repo re this.
Lock files don't help if the code goes missing from the internet. Leftpad anyone?
I got into Golang after 11 hit so I’ve always used modules. When I read about gopath I just shake my head. Feels it flies in the face of the simplicity of Go. 
Yea, developing a forked project used to be so painful.
If your question is regarding the future of Go on mobile, then basically there isn't one. Mobile is a duopoly between iOS and Android. Android is an interpreted environment based on Java. Kind of the opposite of Go. iOS is controlled by Apple. They really love control and their own languages- see Swift; ObjectiveC; $kit. Coupled with the fact that cross platform audio and video don't exist with Go? Yeah....
Having multiple mains is still kind of a pain. I do appreciate them wanting to keep things simple and avoid “let people do everything in every random way they want to” to make things manageable. So we’ll see what the future brings. 
The `json.NewEncoder` allows JOSN-stream encoding. For example ```json ["a", {"b": "c"}] ["d", {"e": "f"}] ``` etc. Also, if you want indented JSON in some cases (by configurations, for example), then you can ```go enc := json.NewEncoder(w) enc.SetIndent(true) ``` That, seems, faster then the `MarshalIndent`, since the `MarshalIndend` is the `Marhsal` and the `Indent`. Anyway, an indented JSON is not for production and this speed has no real meaning. But configurations applying is easier with the `SetIndent`. Also, the `json.Encoder` has [SetEscapeHTML](https://godoc.org/encoding/json#Encoder.SetEscapeHTML) option.
Can you post your test configuration?
I like Go because it has a strict idiomatic way to do anything and they actually enforce it. It is so comfy when I read someone's code and I already familiar with the structure and programming style.
Go fmt ./... is really nice. People ADD code way too much and write too much uneeded code, and then get busy inventing coding standards etc. Better to focus on solving real problems :)
It's easy if you `git clone` the fork to the repo's original path in the Go workspace. 
If an error is really impossible, it’s best to panic because at that point your system is in an undefined state. You see this in various parts of the Go standard library. 
It did before but now it doesn’t. 
It looks like you have your entire gopath or projects folder open. I think GoLand is having trouble discerning where to import files from. It doesn’t know in what context you are testing. Open the specific project in your IDE. If it’s not in your gopath, use go modules to initialize the project.
Have you done the tour of Go 'tour.golang.org'? The is a chapter on advanced types like structs. A struct is like a dictionary but you have to pre-declare all slots you want to use. Python: d = {'a': 5} d['b'] = 3 Go: m := map[string]int{"a": 5} s := struct{a int}{a: 5} m["b"] = 3 // works s.b = 3 // does not work, there is no field 'b' In Go you usually declare a new type for a struct, because you probably want to use it multiple times.
Yea but what if I still use that original repo?
Sure, the solution highly depends on the exact thing you are doing and what the data is. Other ideas I can think of: 1. array of blocks of columns - kind of a mixture of columns/rows 2. specific types and you use reflection during reading (the previous link and https://github.com/loov/csvcolumn/blob/master/example_test.go#L18) - doesn't suit when the exact operation isn't known at compile-time 3. custom allocator and memory management - allows to specify the memory layout better 4. unsafe operators on structured data - write operators that work on ptr + stride + repetition, or generate the code at runtime 5. disk based allocator and dynamic mapping into memory - in case problem doesn't fit in RAM Can you explain the underlying problem you are trying to solve? What are all the different columns and types. What information do they contain. Do they contain errors? etc. _I understand if you can't due to NDA._
Related: [http://www.json2ts.com/](http://www.json2ts.com/) &amp;#x200B;
If you want to temporarily or permanently vendor in your fork of a dependency, you can use the "source" config var in Gopkg.toml.
The idea is to not go file jumping when reading code. The code should read top-down. That's one of the fundamentals used by Go team in stdlib. Separating out every unit into its own file is not idiomatic. Feels like you are just trying to mimick Java in the project you posted. 
Is it impossible to write a Dalvik back end to the gc compiler? Even if it were, ART compiles Dalvik bytecode to native machine code anyways... seem logical that the next step would be to just allow apps to install native code.
I never said to not use 3rd party code. There are frameworks/libraries that result in code that uses web standards. Well trust me man. I love Go. I've TRIED to write server side applications with Go templates. Once you reach a certain growth and complexity, it becomes unmaintenable. It is not anything that the language does wrong. In fact, I think Go templates are great. It is the front end world that is fucked up. So heed my advice. Keep your backend clean with pure Go and let the frontend world do their black magic. You cannot escape it.
Just to clarify, the error struct is just one field with a string, which is a pointer. Slower than passing integer values but not much. I'd say negligible. Since errors are returned from functions, they "escape" and, hence, allocated on the heap. It's a good practice to declare various errors you may return as global variables: allocate once and keep for duration of the application.
i only wish menya would really work
I completely agree. Moving large enterprise projects that are already using vendored packages to use Go modules instead can be a lot of work. There's also complications introduced by enterprise tooling that does not always play nice with the go toolchain. An example of this is using 'go get' to fetch dependencies, which uses an HTTP protocol implementation that your enterprise VCS server may not support. My team has also found that CI builds and Dockerfiles are simpler using Go modules. 
Json marshalling is, as far as I know, not endorsed by the type system, but 100% deterministic. For a given type, it either will or will not succeed. If you want to be maximally careful... and why not?... you can test it in a unit test and dispense with the err handling in the production code, and it is as safe as expecting that an int variable can't have a string.
I don't think it's Go's official philosophy, but my own design principle is K.I.S.S.
How much memory and CPU usage are you looking at? I've found that memory usage spikes uncomfortably when performing a large number of inserts.
[removed]
Think about how Go works, it compiles to a self contained binary for any supported OS. That's kind of the opposite approach to 'run anywhere' than Java. There is the [Android NDK](https://developer.android.com/ndk/) I suppose you could create a transpiler but: * It would be an enormous amount of work * You wouldn't be able to use some core native Go features- parallelism? * You'd be working against the host OS for things like opening and closing files * There isn't a clear benefit **It actually appears that someone has done this** see [Android-Go project](https://github.com/xlab/android-go)
[removed]
Speaking of reflections, if the marshaling is performance sensitive then it is worth exploring alternatives that don't use reflection.
The reason to have the wrapping, at the least, is testing. If there is a tight requirement in the routes to know about the DB, it's hard to test them without a) mocking the sql.* package, or b) having a full blown DB running. If you chose B, you get into differences between PG and MySQL or HSQL. YAGNI above all else seems like the Gopher way. In your experience do you find long term maintainability a primary concern? If Go is a get-stuff-done language, I can see the idea that services are essentially transient would lead to not teiring. 
I may have come out rude, but this was not my intention. But I have to fight the mentality od everything must be a javascript frontend/SPA at work even if it doesn't make freaking sense. e.g. the page is 98% static except for about a week where the changes are done externaly multiple times a day. &gt; I never said to not use 3rd party code. There are frameworks/libraries that result in code that uses web standards. There is Svelte/Sapper whit great promise but it seems they are unable to make it popular despite its promise is beater that the one of the standard bunch. Also the lit from google is a bit too much on the lower side. So any suggestions. 
Thank you for the links. I personally use Clean Architecture. While the form is a bit monotonous, it makes routes, DB, domain, and use case layers are testable. On the flip side, the lack of an easy DI like Spring makes wiring them up annoying. Have you discussed clean or DDD with other Gophers? I've tried that before. I was accused of being an Architecture Astronaut. One point of contention is the aggregate root. When people did talk with me, they said that smart structs are terrible. Instead I should have a shared domain from Request to Response, all of which should be as anemic as possible.
With KISS, do you carve out a place of importance for testing?
Instead of `$GOPATH/src/myproject` use `$GOPATH/src/github.com/myprofile/myproject` everywhere. This solves all of your issues and makes imports consistent with path. Or you can move it outside of $GOPATH completely and use go.mod. 
NPM issues break the builds at my company at least once a week, it's a mess. Better than it used to be, sure, but certainly not "fixed".
Mmm got it thanks.
I mean GoMobile exists and works and has been around for few years. So it’s not really impossible. 
Yes, I unit test every function that is exported to avoid regressions.
I use \`NewEncoder\` when working with request or response bodies since they are \`Reader\`s and it saves you a step of turning it into a byte array to use with \`Marshal\`. I use \`Marshal\` with just about everything else.
If a downstream remote within GOPATH is too restrictive, vendoring the desired version within any given project should be sufficient.
One thing Go taught me is to not follow design patterns and architectures blindly. It is often very good to go one step back and be able to observe the greater picture. Some people in this thread already mentioned that blogs and projects looking for feedback can be a bad starting point. Blogs try to be concise such that they can show a specific concept. From my perspective many blogs simplify code and are pragmatic. I've seen this lack of architecture and coupling in other languages such as Java, JavaScript, PHP, etc.; It's a problem in all languages. In Go we tend try to use interfaces where possible. This makes code extremely easy to test. My work requires me to work with Java and React. Writing tests is a pain. React provides a way of testing which requires you to record the state of a component (*the rendered html*). Then, they test whether the *html* is the same. If a test fails you have to take a look if you broke the build or if the test output changed. Imho this is something you do not want as mistakes can happen very easily. Lets dive into Java for a second. Java is the language in which I see the most uses of dependency injection *frameworks*. Yes, the frameworks can help to decouple code. But there's a reason we don't like these frameworks in Go! They make code more complicated at the same time. Valuable information is hidden with the frameworks and its not always obvious how you can create objects from the dependency injection frameworks. For example, I'm writing a plugin and required an instance of a class with ~ 15 constructor parameters. Documentation did not show how I could create or where I'd get these parameters. At the same time, the dependency injection framework couldn't be used because in this part of the plugin it would not instantiate the class. Result? Well, we're going to spend many hours to rewrite the whole data structure such that we no longer need this specific class instance. Thank you for abusing dependency injection in such ways. We should learn that not every added language feature or design decision helps us in the long run. Often its better to use simpler code, i.e., following K.I.S.S and YAGNI. 
When I first started writing go in 2015 for a class of took me almost two weeks to figure all that shit out. Especially submodules. 
Yes, I've done the tour but I'm looking for an example how it look likes in Python. Yours also help me understand it.
[removed]
It depends on whether there are imports between the different packages provided in that project. From your screenshot it's all the same package. So that shouldn't really matter whether it's on the GOPATH or not. It only matters if the source files have package imports that need to be found. The error implies that your test configuration is set up to run a specific _test.go file instead of running "go test" against the directory. It is only considering one file. 
Yea, it sounded like the whole problem was a mistake in the first place, so this makes sense now. When I read your original problem, I was wondering why your project would try to reference an external master copy of itself. I figured it would come down to not cloning and running out of a matching gopath import. But I actually had a similar problem once for about 5 minutes when I messed up my imports and was pulling in an external clone of itself through Glide and Go.mod
I've used Go since 1.1 before they introduced vendoring. It really was painful.
Submodules as in git submodules as in the worst feature of git? Either way the gopath is the most restrictive thing I’ve ever ran into with a well used programming language. Soo crazy.
It is a good practice to handle any errors given even though you know the function **currently** just return it as `nil`. 
Why the introduction of another format variable? Why not just use `%v`? Like what problem does it cause with existing code.
No, a transpiler is way too much for this task. I was thinking the NDK with Go bindings to the LLVM? It might not belong on the phone, which is fine, servers are much more fun to build anyways.
Could be because of this: https://stackoverflow.com/a/50861413/496445 Chrome doesn't allow unsecure websocket connections over localhost and it would have to be ssl (wss://) 
Please go to this page and check if web sockets actually work in your browser [http://www.websocket.org/echo.html](http://www.websocket.org/echo.html). If not, then this might be a problem with a firewall or proxy server. If it works than you should probably post your code or open a respective GitHub repository so others can advice you.
I was about to dive in and waited for 11 as well. I understand the module stuff is still being worked on, that 11 is more or less a trial run/beta, is that the case? I am curious, when your project depends on libraries that are not updated to 11 and use modules themselves, how does that work? Do you have to do special vendor/ or something else to use those libraries.. or does Go 11+ know how to resolve all that? Does the go module stuff work with versions? I thought I read that you can import packages by versions as well? Like, nodejs, package.json, you can specify a specific version, or the ability to "pull in the latest minor/patch" (based on semver) version to stay somewhat updated without breaking backwards compatibility. Does the Go import in 11+ do this?
It's basically another collection but you can tie method signatures to it. You can also nest them. https://play.golang.org/p/DhT__tgtd6 https://play.golang.org/p/IA09xBX7dYF There are also slices that I think are more interesting. https://blog.golang.org/slices https://blog.golang.org/go-slices-usage-and-internals https://research.swtch.com/godata https://www.ardanlabs.com/blog/2013/08/understanding-slices-in-go-programming.html https://nanxiao.gitbooks.io/golang-101-hacks/content/posts/the-internals-of-slice.html
\&gt; And often HR uses computers to weed out resumes for relevant keywords. Yes. If a company is too stupid to hire you based on your actual merits, then you should avoid that company. Good programmers can afford to be choosy about where they work.
1) Right now, my favorite front-end is ELM (/r/elm). Even though it's a functional language, it's got the nicest developer UX because the compiler error messages are very clear. It's even better at Go at ensuring you have thought deeply about your types, so the compiler can spot your mistakes. &amp;#x200B; 2) In the future, we will just compile our Go into WebASM, and everyone will forget that JavaScript existed. (So many people think they are using integers when writing JS, or that they can store a 64-bit number...)
I recommend checking out the docs on mods, they explain it better than I can. I’ve never tried converting an old go app or similar. In my experience I haven’t had any real issues with go modules. It’s all worked like a charm. I’ve yet to care about versions but they seem to have it covered with the go.sum file etc.
Author here, all contributions, feature requests and bug reports are more than welcome.
Reddit cliché noticed: Reddit cliché noticed Phrase noticed 568 times. ^I'm ^a ^bot, ^beep ^duh. ^Message ^me ^if ^you ^want ^to, ^I'll ^tell ^the ^code ^monkey
I think you have to tease apart the two different forces at work here: &amp;#x200B; 1) **Clean Architecture**. Obviously, this is a good idea, but sometimes it requires extra work. (Such as creating new structs that represent your data in your DB that aren't tied to your DB.) 2) **Microservices**. I heard someone once say "a true microservice is no more than 300 lines of code." While a bit extreme, I do think that you are doing it right if your microservice is tiny and can be replaced in weeks instead of months. So, if all your service does is pull customer data out of a DB and expose it as JSON, then you don't need to think too deeply about abstractions/architecture. If you find things hard to test, or the logic is complex, then you might head towards Clean Architecture. I usually end up somewhere in the middle. (Hexagonal Architecture seems like a subset of Clean Arch.) I explicitly try to move as much code into "domain" objects (that cannot depend on any external system. So a sorting library is OK, but not a database library.) (P.S. Another great rule of microservices I heard is "You are doing it wrong if your website goes down because of one of your microservices being down". Always try to make things event-driven, and asynchronous. NetFlix maintains a list of a few "critical" services, and all the rest must fail gracefully and not cause problems when down.)
I don't know if submodules is the right term. I basically needed to have two seperate packages in the same repo for an assignment but the sub package had to be in an underscore directory or it didn't compile correctly. 
What you do depends a lot on background and the projects you've worked on. DHH and others may not see the point in decoupling your database for testing - maybe there are some common properties of the projects they work on that mean it's not as necessary. I've dealt with some things where being correct was money, and in those contexts I like not to trust anything. Decouple your external APIs, because they probably don't provide ways of checking edge cases and failure conditions. Test for cases they swear aren't even possible, like a gateway error that returns html not json. Decouple your DB so that you can test fast, inject whatever you need, avoid license issues and migrate to something else. Decouple your business logic from your APIs, so that don't leak implementation, and so that you can more easily support tools, different API types, public private endpoints. But if there isn't a "so that" that you care about... don't do it: write your code so that it's easy to refactor, rather than a spaghetti of useless abstractions. Go's interfaces however, do give you a very powerful form of decoupling, and interface segregation. Composition, decorator patterns, rather than inheritance give you code that you can depend on because it's open for extension and closed for modification. Dependency injection with interfaces works well. If "Clean Architecture" is your thing, there are a good number of blogs on it that are easily google-able.
Here's an interesting discussion from a few years back on DDD in Golang. https://www.reddit.com/r/golang/comments/6ugzo2/domain_driven_design_and_go/
&gt; just spending more time with quality source code, and writing more. Unfortunately I've not found places where I can hook up with good code. Many of the blog posts teach get-stuff-done. The general idea is the service is the unit of work from all external perspectives. To that end, it can be tightly coupled. Do you have a suggestion or two? 
If you need abstraction for testing, then add it. Testing against an actual DB is preferred if it's viable. I don't see what your problem with B is. If your package supports both MySQL and HSQL, then your tests should verify that it works for both MySQL and HSQL. You seem to be suffering from a misconception that you can't add abstraction later. You don't need to overdesign for long term maintainability. &gt; In your experience do you find long term maintainability a primary concern? I use Go because long term maintainability is my primary concern.
Yeah it’s pretty finicky in several ways. Not all bad, not all good:)
&gt;I don't see what your problem with B is. If your package supports both MySQL and HSQL, then your tests should verify that it works for both MySQL and HSQL. When I work with PG, I tend to leverage PG features. For example the JSON type. This means that I'm not using ISO-SQL anymore. In order to unit test a handler, for example to make sure that the handler properly maps inputs to the query, I'd have to have a full DB running in a prepared state. That is a lot of work to make sure that the parameters are properly mapped. It's also slower. A unit test that should take 2ns to run now has an external dependency and takes probably a second to run since the IDE has to spin up a lot of parts to run the test. 
I appreciate the Go does not necessarily dictate behavior. Being Turing Complete it's possible to do pretty much anything a user wants. Idiomatic Go and Go's community tend to push others into a "Go philosophy". Depending on how fervently such people adhere to what they believe is the Go way, they will down vote "misthoughts". They try to enforce a dogma (Java folk do this too). I'm trying to find what the ethos of Go is. What is the community view of architecture. Since Go is largely tooled to create services at Google, my focus is on service implementation.
Until they figure out vendoring I can't switch to modules. Doing go build -mod-vendor is ridiculous and I hope Go team will make everything right, ie Go should use vendor by default if it's present like it is with gopath. Another case of Google monorepo specifics creeping into Go and ignoring the rest of the world where vendoring and reproducible offline builds are a must.
Well you spoke about complex UI before. If your UI is mostly static then I suppose sever side with Go templates can work just fine. In fact you can still keep the code bases separate. Have 1 back end service written in Go and another one that renders HTML with Go templates. That way you have more flexibility in case you want to make an SPA in the future as your backend will remain the same.
Why the worst? In my experience, people complain about git submodules because they don't understand the reason it's done like that. It works exactly like vendoring in Go. You pull dependency code in your project and lock it on a specific revision. Yes, working with submodules is not fun and user friendly but git in general has bad UX and submodules is consequence of that. If you understand the basics, submodules will be just clunky to work with.
It's actually very simple, even simpler than modules now. What's more simple than go get. The problem is that it doesn't align well with the reality of github and git distributed nature in general. It's no wonder vendoring became such an important feature for many.
I understand why it was done that way, and how it works. It just doesn’t fit well with some of the basic use cases, but people try to use it that way. It’s very messy for sharing code between projects, and if you want to pin versions other tools such as bundler, npm (it it wasn’t a mess), go mods, etc are more fit for purpose. Basically I think repo next to repo is better than repo in repo. Simpler. 
If you read Ben Johnson's article you'll realize that it does clean architecture and thank god it doesn't have horrible package names like models etc. I don't know what kind of clean architecture you are using but I've seen many java people attempting to do "clean" architecture in Go and it usually doesn't look good. Not sure what there is to discuss. The links I gave you show the architecture that the majority of the community follows, at least the more experienced part. We take it as a given. Well of course you are going to get accused of being an architecture astronaut. I mean, have you tried to read your comments? I need like a dictionary to discipher the terms you are using! LMAO! So yeah. I can't really help you. I have no idea what an aggregate root or smart struct is. The design in the links I have provided have served us well all these years.
The OP link doesn't work. But hey, there's me complaining about package models a few years back. And I still do! I haven't changed at all! :P No wait. I am going to be an egotistical bastard and accuse the community for repeating the same mistake over and over! Muwahahaha!
In my view, Rust is the superior language in terms of being a programming language - I'm more confident that when my Rust code compiles, it's going to work the way I expect it to than in any other language and it'll do it efficiently as well. But it builds slowly, its concurrency story isn't quite there yet and this is largely fixed by third party libraries in particular Tokio. Its most mature/featureful web framework, Iron, seems to have died a death which has left it in a bit of a weird state where things like Rocket and Actix are rapidly catching up but still aren't quite there yet (particularly where Iron has a lot of middleware extensions which are quite easy to use). Go, however, has a vastly stronger ecosystem which is partly attributable to it being a Google project (mind you, Dart doesn't enjoy anything like this so it's clearly more than just that). Error handling in Go is a *nightmare*, almost every other language does it better. Exceptions are a better way, monadic options are a better way (especially with pattern matching). There are reasons why the enterprise world is going to prefer Java: one is that they really aren't going to trust these git based dependency systems. Who's to say some usernames don't get switched around and a repository gets stolen by a bad actor? A common VM enables greatly simplified artifact management for binaries which also means that, while Maven has a reputation for "downloading the internet", at least you don't then have to compile the internet as well. The fact that both Go and Rust prefer source code dependency management is largely because managing binaries on many different platforms would be a daunting task. Developers with any experience of an OS like Gentoo where the entire package manager works on the basis of downloading source and building it for your system might have an understanding as to what working with a large Rust or Go codebase might be like.
&gt;In my view, Rust is the superior language in terms of being a programming language - I'm more confident that when my Rust code compiles, it's going to work the way I expect it to than in any other language and it'll do it efficiently as well. That entirely depends on your requirements. It's great when a language gives you high correctness guarantees, but there are other factors you'd consider, including suit for rapid prototyping (in the post-agile world, almost every big project starts small and needs to have rapid value-adding increment capability), cognitive complexity, ecosystem, etc. These all *are* part of the language in the broad sense of choosing one to work with; syntax and semantics are not everything. &gt;A common VM enables greatly simplified artifact management for binaries which also means that, while Maven has a reputation for "downloading the internet", at least you don't then have to compile the internet as well. The fact that both Go and Rust prefer source code dependency management is largely because managing binaries on many different platforms would be a daunting task. Both Rust and Go compile-from-source, but the similarites end there (at least prior to `go deps`, which I haven't had a chance to use). Rust (just like JavaScript and Ruby) has a "manifest" approach where every version is listed logically (as entered by a developer who first introdues or changes it) as well as "snapshotted" (so that every *other* developer, CI tool, and production environment) is guaranteed to get the exactly same version). This also comes with capability like transitive dependency resolutions (e.g. if you have libraries A and B, which depend respectively on library Cv1 and Cv2, Rust will detect a conflict). This is vastly superior from making a developer manually manage every copy in their repo and hope every dependency properly works with every other dependency, because in a large enough repo, this quickly becomes DLL hell. 
&gt; There's a reason JS is one of the most popular languages out there lol
Discredting Rust due to its lack of maturity in web server frameworks feels very disingenuous to me. HTTP is one of many, many communication protocols, and it does not make sense to shy away from a language due to fragmentation in the open source world's use of that language. Not to mention that Rust prides itself on safety in low level systems programming, not that it can serve websites. The web makes up a small percentage of all software.
I think you make some good points - with respect to your latter point, however: &gt; This also comes with capability like transitive dependency resolutions (e.g. if you have libraries A and B, which depend respectively on library C-version1 and C-version2, Rust will detect a conflict). This is vastly superior from making a developer manually manage every dependency as a direct source copy in their repo and hope every saved dependency properly works with every other dependency, because in a large enough repo, this quickly becomes DLL hell, especially given that in most projects, dependencies must regularly be updated, and every time this creates an opportunity for a compatibility regression. You are correct but I was making a comparison between tools which all do this so it seemed redundant to go into this topic.
Why the fuck would they? It's 2019
An unpopular opinion: I actually really \*like\* Go's error handling. It's incredibly explicit, and very dumb in design. It requires you to consider error conditions very explicitly at every layer of abstraction. It forces you to think about when to handle an error with logic or propagate it to the next layer. Sure, it gets tedious, but it automatically enforces rigor in a giant codebase when hundreds of people are making changes to it at once.
I don't think Rust has a future outside of hobbyist programming. I could definitely be wrong. But I think it's choked on itself. It's too complex and too slow to develop in. The end result may be really nice from a theoretical perspective, but we live in a world where code ships fast and somewhat broken. Go has all kinds of problems. There is far too much potential for runtime errors. But it's unquestionably fast to write things in, and the results are "safe enough" for most applications. I think Go has a bright future ahead of it, if Go 2 solves a few of the more divisive pain points like generics and error handling.
Note: been writing Go for 4 years, only one year in Rust, a year ago. I must say that after writing in Rust I felt more aware of memory, what and how I'm passing it, as well as what is owning the variable (still possible in Go, just without compiler guarantees). But other that I found that assumption of "if it compiles it works" gives fake confidence. It's easy to ignore writing tests then. There have been plenty of times where I had the general flow of the application working, but then I've spend 2x as long to make it compile. Maybe it was because I was still not thinking much about memory leaks, but it still made me exhausted and frustrated. If you write idiomatic Go, error handing is not that big of an issue. I agree that Rust does it better with `Result`, but that is also not exceptions. Using `github.com/pkg/errors` makes the code even more readable as you have human readable error wrapping while adding context to the original error. There are talks of getting this library into stdlib for Go2, which is also supposed to improve error handing to be more exception like, but local to the function so you don't have to jump all over your code to determine where certain exception is caught, or thrown. If you do not trust your dependencies to be online - fork them. And as one of the Go Proverbs say - a little copying is better than little dependency - something that JS world especially doesn't seem to understand. And if regards to direct comparison to Rust, the fact that even something as basic as JSON is not included baffles me. I find that you can write most things using just the standard go library, without third party dependencies. Rust on the other hand is missing logging package. Enterprise prefers Java because there are plenty of people who know Java, so tapping into the talent pool is not hard. It was still THE language that my university thought until last year when they switched to Python. No doubt I will try Rust again, but so far all of my experiences have been more negative than positive. They both serve their own needs, but based on the time spend to write code, and mental capacity required to read it, I find Go just to be easier and definitely faster to get comfortable with. Many of the points are shared with other comments.
So my browser DOES appear to support web sockets, thank you for that link. I took a look at the sample code again, and discovered my issues....was missing two important javascript lines for the template. Ugh. Glad to hear its not something weird with gorilla web sockets and me. Thanks for your time!
While I'm a fan of Rust, I'm constantly find it's immaturity, unlike Go. Rust is the greatest tool if you need to rewrite old posix bin, that you plan to work only via calling via sh. My last project was to rewrite some lib from go to rust, and maybe because GO applies it's own paradigm, resulted code became a mess, and I'm started to doubt if I've chosen right technology. Simple example — concurrency. In GO you just have to avoid races by yourself, it gives simple mutex primitives and channels. While Rust's Arc, Rwlock are more demanding. In Rust I constantly have finding myself in situation that I have completely change internal class structure, just to deal with borrow checking. In GO there is no concept of borrowing so you can pass data multiple times and leave this burden to gc. While in rust you constantly must choose will this struct passed as &amp;mut, will this struct must be wrapped in Rc&lt;RefCell&lt;T&gt;&gt;, or &lt;Arc&lt;RwLock&lt;T&gt;&gt;, should it impl Borrow, AsRef, Deref, constantly deciding something. This actually disappoints in process of porting that struct you've made, have to be rewritten to be Arc&lt;RwLock&lt;T&gt;&gt; so you can just clone pointer. And then fill your code with `self.node.upgrade().unwrap().read().unwrap().db.write().unwrap().tx = 120`. Wrapping public struct for example in &lt;Arc&lt;RwLock&lt;T&gt;&gt; itself is dissapoints because you have to either: * make another wrapper with public interface, which includes lots, lots of boilerplate code. * make methods that relate to Arc and RwLock via trait, and then `impl Trait for Arc&lt;RwLock&lt;T&gt;&gt;`, so end user of library will have to know that to make things work he have to import struct and trait and use it accordingly. * be a macro guru, idk. In rust you constantly find that there is rfc for what you just need, but it's not even have discussion closed. For me it's [arbitrary self types](https://github.com/rust-lang/rust/issues/44874). Also you always find useful apis which is night only, like TryFrom. So, comparing these langs I think is pointless. Go is soon de-facto webserver app's first choice, gc based, more concentrated on dev's productivity. While Rust is somewhat academic language for me, it has a lot of new abstractions introduced, it constantly changing and if I have to flight to Mars on Shuttle I prefer it's software to be written in this language.
\&gt; (For example in Go, I'm yet to find a good way to fork a library, \&gt; patch it, publish it under my own GitHub account, and still be able to \&gt; use it without changing all the imports to the "forked" location...) [https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive](https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive)
&gt;(For example in Go, I'm yet to find a good way to fork a library, patch it, publish it under my own GitHub account, and still be able to use it without changing all the imports to the "forked" location...) [https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive](https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive)
Go is a pleasure to write in, Rust is not. For me (hobbyist), that's pretty much where the story ends. 
...while we compare a language with a garbage collector with a language designed to strive for safety in a context where garbage collectors are undesirable, I think it would also be useful to know everyone's opinion on 1.3mm hex wrenches vs PH4 screwdrivers. While you might have some overlap in useful projects, Go and Rust have wildly different motivations, and it shows. Most of the "mental complexity" of Rust doesn't come from having a "Result" type, but from lifetimes and borrows - and those exist because Rust didn't want a GC (which is understandable - in some contexts any unpredictable GC pause, however small, is unacceptable). So unless there's a more specific context to talk about, this question is fairly silly. I disagree with the author on tooling - my current experience with Rust tooling is very positive, and I'm under the impression there's just more of it than for Go. Rust packaging in particular is far ahead, even though I'm the weirdo wishing people would stop doing that and just accept our lord and savior, vendoring everything into the repository. On the other, I have the same experience as the author with actually ever using either. It's a very tough sell, and in practice it's still hard to beat the choice between Java and Python, with C++ for those rare cases where you really don't want GC. I like neither of these particularly much (especially Java - I haven't touched C++ for long enough for my dislike to wear down a little) but they're far easier sells to other developers. 
That opinion is not that unpopular. It’s just popular with people who want to pick on Go. There are some idioms that don’t exist in other languages like Must methods, and I do hope for some syntax help for error handling in Go 2, but error handling by return value isn’t that bad. It’s just *different*.
If you want to make love wearing nothing, choose C. If you want to make love wearing a condom, choose Go. If you want to make love wearing a spacesuit, choose Rust. &amp;#x200B; [https://twitter.com/PrgrmmrHumor/status/1005338598659350528](https://twitter.com/PrgrmmrHumor/status/1005338598659350528) &amp;#x200B; &amp;#x200B;
IMHO, I can't bear the syntax of Rust. Its generic design is a mediocre which makes Rust code look some dirty. I even can bear the lifetime syntax of Rust. 
You can always do `go mod vendor` though.
I’ve been making due with a mix of http://intercoolerjs.org and https://github.com/valyala/quicktemplate , may not work for you, but suits my needs pretty well so far.
Completely agree. I initially was bummed about the error handling too (coming from Python) and wishing that we had exceptions. But when actually programming in Python, I found the error handling extremely thorough, forcing you to deal with every single possible error that could occur or explicitly ignore it. Compare that to Python (which I love btw), where you may never know whether an exception can be raised, which exceptions could occur .etc. So unless you literally wrap your entire program in `except Exception` you risk your app dying unexpectedly.
Saved. I need a good bloom filter right now, and was about to be integrating it this week. Very apropos. 
Third. With exceptions I'm always tempted to put a giant try catch for a group of operations and leave it at that. In go, I don't get that liberty, and I think that's honestly a good thing. Plus the syntax reminds me of python while keeping the structural rigor of lower level languages.
I find, given suckless' principles, the promotion of a language that has 'magic' constructs that aren't user-extendable, garbage collection (and a runtime at all for that matter), and is maintained and used by a corporation they despise, really jarring. Don't get me wrong, I love Go, but Rust seems definitely more in-line with the suckless philosophy (if you choose to give it credit in the first place). I have a feeling there's a bit of contrarianism in this here situation. The main thing I miss from Rust when working with Go is that all of Rust's syntax is built off of a much smaller syntax, i.e. for loops are sugar for Iterators which you can implement yourself for any type you come up with. Same with arithmetic operators, deref, indexing, and all the rest. I get why Go chose not to do these kinds of things and why Go rejected typical 'operator overloading', but it makes the language feel a bit ... opaque.
I disagree with your premise that Rust doesn't have a "garbage collector". It has one, it's just static\[1\], or enforced by the compiler. What you are referring to is more like "C vs Go", where in the former you manage memory explicitly. That's not the case for rust. &amp;#x200B; I think you are also mistaken in that Go and Rust have "wildly different motivations". I think they are very much direct competitors, and Rust will have a performance edge. &amp;#x200B; An example is how Firecracker, AWS new virtualization tech (\*somewhat\* comparable to Docker, which is written in Go) is written in Rust. It's smaller, faster, more predictable… and yet does many of the same things Docker or K8s do: expose a REST API, invoke a bunch of system calls, etc. &amp;#x200B; \[1\] [https://words.steveklabnik.com/borrow-checking-escape-analysis-and-the-generational-hypothesis](https://words.steveklabnik.com/borrow-checking-escape-analysis-and-the-generational-hypothesis) \[2\] [https://firecracker-microvm.github.io/](https://firecracker-microvm.github.io/)
I want both languages to succeed. I use Go primarily at work and it’s great for banging out code related to distributed systems and backend. Great concurrency model and standard library for doing everything. Not so good at dependency management (with modules coming it should be better soon though). Rust is doing something important: basically offer a C/C++ alternative that is modern and more pleasant. It’s pretty neat although as others mentioned the relative immaturity of most packages makes it hard to ship production code, right now. It’s also kinda hard to get productive in because the compiler is so strict. Both languages have strengths and weaknesses and their own use cases. Ultimately however we want both to succeed to prove that we don’t have to be stuck in Python/Java/C++ land for all time and that modern languages should be first class citizens and taught in schools for example. 
Could you please elaborate a bit what makes your implementation "high performance"? Thank you anyway!
My solution to that would be the use of Go modules and _replace_ directive. See for more details: [When should I use the replace directive?](https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive)
How is this different from Docker-Compose? (Not trying to insult you or your work, just wondering how I'd use it differently)
Give us more context, don’t understand your question. “Interface” word means “UI” or “golang interface{}”? If you feel totally lost, just use gobuffalo.io, it will good starting point for you. 
That’s not a garbage collector. That’s memory management. Like objective had release/retain. I also think go and rust have very different motivations. I see rust targeting systems-level, such at compilers. I see go targeting a bit higher level for seriously concurrent servers and such. 
"**Interface Driven Programming" is all about Object Oriented and Interfaces. Not User Interfaces**
Grom what i experience Rust is speedy and has type matching with coming from erlang is really nice to have. But Golang has much better support for concurrency and some of the concurrency related tasks can be described much easier ;) also Rust has a lot of unwraps :)))
I have been using Go (TiDB, go-ycsb, go-mysql, LedisDB...) and Rust (TiKV, grpc-rs, raft-rs...) to develop many projects in recent years. Go is easy to learn, easy to use, and easy to verify the prototype when we want to build a system. I even use Go instead of Python to write many simple tools. So if you want to develop a high-performance service and you are stretched for time, Go may be one of the best choices for you. &amp;#x200B; But Go still has some problems, sometimes the latency may be high and you have to pay attention to the GC and goroutine scheduler, and spend much time to optimize your codes. &amp;#x200B; For Rust, the learning curve is steep, in our TiKV team, we even let the new members spend at least one month to learn Rust, then start to write codes. But after you conquer the first learning problems, you can find it is easy to write programs - especially for concurrent, high-performance programs. &amp;#x200B; But Rust has a very big problem - the compiling time. E.g, building release version of TiKV will take us at least 20+ min, so we can't use Rust to fastly verify the prototype or do rapid iteration. &amp;#x200B; In general, Go and Rust are both great, they both have advantages and disadvantages. so maybe the best choice is to use them together like me in your work :-) &amp;#x200B; &amp;#x200B;
In go “interface driven programming” described by rule “use interfaces only when you really need them. In MVC controller will describe what model interface he expecting, then model implementing this interface and you injecting model to controller by controller constructor. REST and GraphQL do not change anything in this app architecture. Another example related to GraphQL - If you will use some code generators, like https://github.com/99designs/gqlgen they will generate for you basic interfaces of resolvers (resolver in graphql is same thing as controller in mvc) - then you will implement them. But “interface driven programming” - when for every class you creating interface - it’s “bad practice” in Go world, here we creating interface when we need them, not when we can. 
Lol how hard is it to run a global replace command? 
I tend to agree, if you actually strictly use modern c++ then you get a lot of the features of Rust.
Funnily enough, I love GOPATH (and hate what other languages do) because of its simplicity. "Here's a directory containing all of your source code" - can't get much simpler than that. What I'm saying is, that simplicity is in the eye of the beholder :)
Objective-C and Swift still use retain/release, don’t they? It’s just that the compiler automatically adds the calls for you.
&gt; There have been plenty of times where I had the general flow of the application working, but then I've spend 2x as long to make it compile. Clearly, if it isn't compiling, you don't have "the general flow of the application working".
I like both and use both , go is kind of a RAD tool and Rust is a surgical tool (performant and precise)
Congrats on your first release of this! Would love to see comparitive benchmarks against any other implementations out there.
Rust vs. Go syntax visualization: [https://imgur.com/a/bwKK6Zz](https://imgur.com/a/bwKK6Zz)
The point is, this should only be a temporary state. You should open a PR to the original and delete the replace After the PR got accepted
As a hobbyist, that would make sense - it takes quite a long time for the borrow checker to finally click. However, once you do get a good grasp on memory management, the simple fact that Rust has `Iterator` with associated methods and Go does not is enough to make Rust more of a pleasure.
&gt;You are correct but I was making a comparison between tools which all do this so it seemed redundant to go into this topic. Did Go do this prior to `go deps` though? I thought it esentially was up to the developer to manually vendor every physical library into their source control, manually deal with updating it, and manually ensuring introducing or changing one library version didn't cause a dependency problem in either your application code or in some other library that depended on it?
I also like Go's error handling, but Rust's `Result` and `match` does the same thing but *much* more elegantly.
The simple one is no problem I just wanted you to know why I was being harsh. I'm still interested in your framework/libraries that use web standards.
But Go will ignore it until you call go build -mod=vendor It’s very easy to build with one version of dependencies when developing and commit other versions. Gladly, there are open issues for both of these this and they are quite popular.
Looks neat. For persistence, you might consider using mmap. This is the approach used by pybloomfiltermap - [https://axiak.github.io/pybloomfiltermmap/](https://axiak.github.io/pybloomfiltermmap/)
Amen brother
Well, adoption rate of Rust is faster than that of Go now and when compared to Go 3 years ago. Just feeling a need to point this out. So no, it's far from being "hobbyist" language like Crystal for example is. It isn't used for web related stuff, so one may not get into contact with it as much.
It sounds like you're completely ignoring Go modules, which works like the "manifest" approach but it is vastly superior with minimum version selection and semantic versioning. I've been using it for five months now, it's great.
&gt; I disagree with your premise that Rust doesn't have a "garbage collector". There is a significant qualitative difference between the borrow checker and a garbage collector, which many real-time programmers consider rather critical. And honestly, the first post you're linking is Steve Klabnik being a total modernist, shouting "you are not finding this ~~ugly~~hard, you just didn't try it enough." As someone who happens to like both Rust and concrete cubes, I sympathise, but I also understand that many people have different tastes and find different things hard to work with. They're not less smart (that require a different kind of disagreement), they're not "not committed enough," they're different, and maybe their needs are different. Also, one part there: reference counting isn't "really" garbage collection until it handles reference cycles. This is both because until then you still have to think about it (and remember to use weak references and such) _and_ it doesn't have the performance implications of GC. 
Sorry, I actually meant the new go modules, just got the name wrong (haven't used Go in a long time).
I'd take unwraps over if err == nil ... ad nauseum any day but that's just me.
Eh, for me it's about coding speed. I can throw something together in Go and it takes a similar amount of time to write as Python, but it runs faster. If I want iterators, I know C++ (at a decades-long hobbyist level anyway). I really like the ideas behind Rust's memory management, but when your code is typically in the few-hundred-lines range, it's just waaay more trouble than it's worth for me. 
&gt;adoption rate of Rust is faster than that of Go now how do you measure it? Looking at job postings at [itjobswatch.co.uk](https://itjobswatch.co.uk) for example gives 350 for GO and 8 for Rust. So Go is clearly used more in companies.
Well, maybe not unwraps, but definitely map_errs
[removed]
I've noticed that for any non one liner project, the coding speed is insignificant. It looks like programming is predominantly thought bound, rather than write bound
The thing is, the same can be said about rust, except that the latter is not as tedious, and the code ends up being generaly more readable as a result.
Generally by major companies who report to use Rust in production. Job postings has little to do with it, because there aren't that many Rust focused engineers. Usually what happens at early adoption is that language is picked up inside a company, and once it gets traction after few years job market responds. It's not vice versa. Another point to consider, that Rust is fairly complex language to pick up, unlike Go. Which is barely more complex than modern javascript if not easier, due to how bloaty js can appear to newcomers. So the language necessitates more on job training as 2nd or even 3rd language, rather than trying to search for someone from outside at this point. C++ is different story, because you get uni graduates. It might be used a bit more in companies, because don't forget it had 3 years head start. Official release was 2012, Rusts 2015. There was a good overview provided here with some real case examples and even metrics here, I'm sure you could find more, I'm personally lazy to dig through internets on sunday afternoon: https://www.youtube.com/watch?v=6qCH7Y2rc_w 
They are for totally different things. I worry when I read articles like this. I worry that me 20 years ago would read them and not realize that anyone picking a side is basically not to be trusted, especially the initiators of this discussion. There are no best IDE's, no best languages and no silver bullets. I don't give AF what language you code in, but if you represent that it's a silver bullet or the best, or better than another, then I don't think you should be left in charge of crayons.
My guess is compared to docker-compose's declarative approach xenvman is rather imperative (at least based on the tutorial), which provides better flexibility, not sure it's needed though.
Really think the two play different roles.
Would generally agree. I do develop in both and Go is easier and faster to pick up.
Would disagree on Rust adoption being faster than Go. I do like both languages and I use each for different purposes. But Go adoption is well ahead of Rust.
This is the kind of comment that only very core people to Go has the authority to make. Ian Lance Taylor is one of them. Now, diving into the merit of the comment. This is the kind of statement that feels like a wool ball that you once you start unraveling it you find many non-obvious consequences. One of them, for instance, Go's type system is weak - so it means that you cannot redefine equality at a type level. Thus either you code the equality in the code level (`func (Type) Equal(Type) bool`) or you have to rely on the compiler definition of equality - and that can be defeated: https://twitter.com/bradfitz/status/860145039573385216 
I don't get what you're trying to say. Yes, func can't ==, and I don't see a problem with that. It's actually more straightforward not to be able to redefine ==, since you don't have to wonder whether == has been redefined for this type. You also can't redefine it to something meaningless.
Use the `?`, Luke.
&gt; It requires you to consider error conditions very explicitly at every layer of abstraction. It doesn't require you to do anything. You don't have to `if err != nil` and the compiler will not complain. &gt; It forces you to think Doesn't force you either. You don't have to `if err != nil` and the compiler will not complain. Go error handling is C error handling, you're free to not do it if you don't want to, which is a step in no direction. I think you are ignorant of how other languages approach this problem and this makes you think Go has invented some kind of superpower for explicit error handling.
I don't feel it is accurate to say you are forced to think about types. Go and Rust and C all have the same primitives, those types are always there and if you want you can program with only those in Rust. Go has interfaces and Rust has traits which are similar. You \*can\* get into complex type stuff with generics if you want to in Rust or C++ but you aren't forced to. &amp;#x200B; I do think some people make some bad choices and \*choose\* to make huge puzzles out of fancy type systems for not very good reasons sometimes with Rust/Haskell/C++ etc. For instance I have seen people in Rust trying to make a vector math library that is generic across arbitrary \*dimensions\*. That is a neat project but not really useful ( or rarely so) &amp;#x200B; Here is an example of something I did with fancy type stuff. It is a library that you can use, and write an explicit SIMD intrinsic function with. At compile time, the compiler will make functions that use SSE2, SSE41, and AVX2, and non SIMD instructions. You can then select at runtime or compile time which function you will use based on the cpu available: &amp;#x200B; [https://github.com/jackmott/simdeez](https://github.com/jackmott/simdeez) &amp;#x200B; I used this library to make a noise generation library: [https://github.com/jackmott/rust-simd-noise](https://github.com/jackmott/rust-simd-noise) and it saved me from having to write thousands of extra lines of code that all have to be maintained in parallel. &amp;#x200B; There is no way to make such a library in Go. One would just have to write their function 4 times, and maintain all 4 parallel paths forever. Or do code generation at which point you are creating your own generics. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Why not Cobra? https://github.com/spf13/cobra
I honestly lost track a couple years ago but I think they did add a GC when the added *autorelease*
Is it weak because it has type inferencing? I think that saves me hours per day compared to something like java. 
I'm referring to adoption rate. Not how prevalent currently it is in the market. If we compare the raise of popularity in of the language when normalizing for how many years it has been introduced, Rust is being adopted faster than Go. &gt; I also think there is a better chance for Go to be big 10 years from now versus Rust. I'm not sure what you are sure what you ment here yourself though. Rust is systems programming language. Go is server side programming language. "I think that Java will be bigger than C++". They are not directly competing.
[removed]
&gt; I'm referring to adoption rate. Was talking adoption. If you look at the number of products used with each the list is a lot bigger for Go. Plus some really important applications. Really do not think it is close. Now really like Rust and just being factual. &gt; Rust is being adopted faster than Go. Do not agree. Both from data I have seen online and from personal experience. Once again this is NOTHING against Rust. Really hate this post as it is sounding like I do NOT like Rust. Which is far from the truth. Just keeping it real. 
Hey, thanks for the reply :). &amp;#x200B; What I mostly like about docli when comparing to Cobra is that you get to define the CLI through a help message… but docli **is just one more option** available for the go community, I wouldn’t say that is better or you must choose it over Cobra.
Sorry, wasn't my intent. I just feel a need to remind that there is 3 years gap between the languages. Also I don't think mozilla have the resources to push development as fast as Google can. In turn, a lot of features of the language are not yet stabilized to warrant full scale adoption and usage in production.
&gt; I just feel a need to remind that there is 3 years gap between the languages. According to this there is less than a year difference. Is it incorrect? Looks to me like 8 months. I do NOT want to sound negative about Rust. But I am someone that likes to work with facts. https://en.wikipedia.org/wiki/Rust_(programming_language) vs https://en.wikipedia.org/wiki/Go_(programming_language) &gt; Also I don't think mozilla have the resources to push development as fast as Google can. Definitely not. Plus Google name on something holds a ton more weight than Mozilla. But why does that matter? &gt; In turn, a lot of features of the language are not yet stabilized to warrant full scale adoption and usage in production. Most definitely which really scares me. The window is open for Rust. You have to cease now. It is what drives my point where I could see Rust never getting there. It is a far bigger risk than Go.
I've been far more productive in go than any other language. It combines the looseness to get started and do things dirtily to then go back and refactor them as necessary, with the power to do things across a wide spectrum of tasks, e.g. concurrency, net, web servers etc. And, above all, (poorly coded libraries aside) it really is cross-platform, unlike the nightmares I've had with c# and mono.
Well, why stop there. Lets involve pre-production documents. Or perhaps the date when language was first conceived in some engineers head. Official release signifies that it should be ready for production. Language being first introduced tells nothing, we do not know the development estimates. &gt; Definitely not. Plus Google name on something holds a ton more weight than Mozilla. But why does that matter? I mean this is a big plus for Go over Rust is it not? I'm not sure. I don't think that companies like Amazon would prefer to depend on Google research team. So it's double edged sword actually. And mozilla is not a small player either and also somewhat neutral, in the way that they are not trying to dominate / take over the internet (and this is correct expression) the internet like Google. &gt; Most definitely which really scares me. The window is open for Rust. You have to cease now. It is what drives my point where I could see Rust never getting there. It is a far bigger risk than Go. I guess point of perspective. If some major companies already rewritten parts of their critical infrastructure code in Rust, given that some features aren't yet stabilized suggest that language offers so much benefit, that it outweights the obvious current drawbacks.
Totally agree. C++ and C# for example are immensely powerful languages, but it's very difficult to constrain yourself away from types because you're 'expected' to do so.
Go has build tags so nothing stops you from writing versions of a function that uses different ASM instructions. 
&gt; Well, why stop there. Lets involve pre-production documents. I went to the Wiki for each as three years did NOT fit with my memory. Checked and shared the dates. You might not like the facts but the facts are the facts. I work in facts. Not emotions or wishes or love. It sounds like this is quickly spiraling into emotions versus the facts. &gt; I don't think that companies like Amazon would prefer to depend on Google research team. What? Echo, Dot, Show, Spot, Fire TV, Fire Stick, etc all exist because of Google IP with Android. Amazon browser, Dolphin, is Chrome. Amazon uses Map/reduce, K8S and tons of other Google IP. What in the world are you talking about? &gt; And mozilla is not a small player either and also somewhat neutral Mozilla is a tiny company. Plus their primary product, Firefox, is dying. Now down below 10% market share and falling. Even MS called them out yesterday. Quote is below. I very much worry that Rust will not make it. It is why I now suggest C, C++ and GO instead of Rust. I did recommend Rust for a couple of years now but have stopped. "Microsoft engineer: "Thought: It's time for @mozilla to get down from their philosophical ivory tower. The web is dominated by Chromium, if they really *cared* about the web they would be contributing instead of building a parallel universe that's used by less than 5%?""
Objective C had a GC option briefly but it was removed in favor of automatic reference counting, which is what Swift uses as well. 
Type inference does not mean weak typing. Many strongly typed languages, such as Haskell and Rust, support type inference. This article explains what weak typing (vs strong typing) is: https://en.wikipedia.org/wiki/Strong_and_weak_typing
Coming from an interpreted language background, Go does seem strongly typed to me. What is the reference language we are basing against?
Yes, it's similar to docker-compose. But xenvman is a bit more dynamic, I think. With docker-compose you statically define your environment in a file while with xenvman you can control your environment over HTTP, creating and updating it on the fly directly from your test code. Also it's easier to change environment composition while it's running, say you want to simulate a node crash or a new node arrival, you simply send an HTTP request from the test to achieve this. &amp;#x200B; Also templates provide a more flexible way to parameterize your environment than a purely declarative approach, I think. Even though underneath it's still works in a declarative fashion. 
Also, because it's configured over HTTP you don't even need to have docker installed on the same machine where your tests are running. xenvman is actually more similar to [https://www.testcontainers.org/](https://www.testcontainers.org/), but without any strong connection to Java, because it's pure HTTP, it's easy to add support for any language.
Yeah... I've always thought of Go as strong/static with inferencing.
Rust syntax produces me eye strain and I found Go syntax very appealing to my eyes, also the simplicity of Go tends to make me more immersed in to the problem I am solving and not wasting time fighting with the syntax and googling for things I don't remember. But you know it's only my appreciation.
 There are quite a few small places that I find go's weak type system to cause me to write a little more code than I would like, especially when trying to model constraints on simple domain types, E.G. type string150 string func newString150(chars string) string150 { if len(chars) &gt; 150 { return string150(chars[:150]) } return string150(chars) } type Bio string150 // this constraint wont work as a normal string can still be passed to the Constructor function func NewBio(bio string150) Bio &amp;#x200B; Instead off the above I end up having to write this &amp;#x200B; type string150 struct { val string } func newString150(chars string) string150 { if len(chars) &gt; 150 { return string150{val: chars[:150]} } return string150{val: chars} } type Bio string150 func (b Bio) String() string { return b.val } func newBio(bio string) Bio { return Bio(newString150(bio)) } &amp;#x200B; Not really a huge deal , but it can add up if there's lots of constraints that I want t to enforce, especially if I always want an Aggregate type to have a constructor that always returns a sane default as opposed to an error. I'd rather deal with this than the insane levels of complexity I have to deal with in other languages both at design time and operationally. Go and the tooling around it just makes life easier for me.
It's weak compared to Scala/Haskell/Ocaml et al
&gt; For instance I have seen people in Rust trying to make a vector math library that is generic across arbitrary *dimensions*. You realize that vectors aren't just used to represent spatial coordinates? Arbitrary dimension vector math is incredibly useful, and not at all rare. 
IMO the type system in C++ is more powerful than that the function system, and I regularly used type-based tricks to ensure it was doing what I wanted. That did not lead to easier-to-maintain programs, but it was powerful. Now that I write almost exclusively Go (by happenstance), I appreciate the obviousness of it and would frown on some of the "dirty tricks" C++ requires to push the logic into compile time (enable_if - I am looking at you).
Go until the world learns to for loop, then Rust until we get qubits in our phones.
[removed]
Why did you pad your post with so many empty lines?
In \`Go\` you write code for yourself and other developers, in \`Rust\` - for the compiler.
What about it makes it weakly typed compared to those languages?
You can make more type-safe code with them
Yeah but I gotta say what's so bad about programming in types? My mind was changed greatly when a friend of mine sent me an article about programming tic tac toe in haskell, and it was literally impossible to write anything with the api that did not follow the rules of tic tac toe that did not also fail at compile time. 
&gt; It requires you to No it doesn't. &gt; It forces you to No it doesn't. &gt; automatically enforces No it doesn't.
This is exactly how the go standard library does it. It's pretty easy to write platform dependent code in go with a common interface.
What? Unless you import unsafe and reflect, Go is 100% type-safe.
What I meant is you can express more with the type system which results in either duplicated code or reflection. The obvious things that makes the type system "weaker" is no generics
For the author of the post "tooling" = "package manager". The "non-existent" tooling of Go actually contains \`go fmt\` (now copied by other languages), \`go vet\`, \`go pprof\`, race detector, and a lot of linters made possible by rich facilities of the standard library. &amp;#x200B; I respect what Rust does. If I were to work on a VST plugin, for instance, I'd use Rust. But for my everyday tasks - console utilities, Web back-end, network libraries - Go is a good fit, better than many other choices. Not best. There is no such thing. Practical.
'error' is a type just like 'int' or 'string'. It is declared as part of a function signature, often the last returned value from a multiple return value ex: func myFunc()(string, error){ return "", fmt.Errorf("something happened") }
Thanks. Is err and error the same?
err is only the variable name.
Can you point to an example of a production Rust codebase that is being used widely? Go has some extremely high profile projects on its side, including docker, kubernetes, grafana, elastic beats, concourse CI, to name a few. All of these are being widely used by the industry. Rust has... hobby projects like Redox OS.
Or npm. I've provided a list somewhere in this discussion already.
Thank you!
`err` does not but, type `error` type is predeclared in the universe scope: https://golang.org/pkg/builtin/#error. 
The run time package is neat too. https://play.golang.org/p/82H1l4WZ-1z 
I don't mind you being harsh. I was expecting it actually. Because on my first response, because I am passionate about the subject, in my mind I was doing a Pulp Fiction/Samuel Jackson impression. But on written speech it's hard to understand those things. Anyways, my advice is to take a look at web components which combine standards like templates, custom elements and shadow dom. Admittedly it's been a while since I've written front end code so I haven't kept up with the latest libraries/frameworks for that. I believe you can look at [litElement](https://lit-element.polymer-project.org/) and [lit-html](https://lit-html.polymer-project.org/).
I think the idea is that time you spend thinking about types or appeasing the compiler is time that you could spend implementing business logic. A type error in Go is likely telling you what behavior you need to add; a type error in C++ is likely telling you what syntactic or structural requirement you need to meet. The former, in many people's experience, makes for a more productive language.
Sure, be choosy, but that's a terribly arbitrary thing to cut your nose off to spite your face about for someone on /r/golang
&gt;I've been far more productive in go than any other language. Which languages were you using and what were the barries to productivity there?
C# doesn't compile well in linux systems (was a year ago or so I last used it). I had big issues with locking and concurrency when compiling for linux. It isn't a one-size fits all. PHP lack of concurrency and having to work with over-engineered solutions (e.g. the symfony libraries) Java is ancient, huge and feels very verbose as a language. With the lastest Oracle case, it looks like Android's life could be at risk.
C# doesn't compile well in linux systems (was a year ago or so I last used it). I had big issues with locking and concurrency when compiling for linux. It isn't a one-size fits all. PHP lack of concurrency and having to work with over-engineered solutions (e.g. the symfony libraries) Java is ancient, huge and feels very verbose as a language. With the lastest Oracle case, it looks like Android's life could be at risk.
Small correction, java does have local variable type inferencing since jdk10.
C# doesn't compile well in linux systems (was a year ago or so I last used it). I had big issues with locking and concurrency when compiling for linux. It isn't a one-size fits all. PHP lack of concurrency and having to work with over-engineered solutions (e.g. the symfony libraries) Java is ancient, huge and feels very verbose as a language. With the lastest Oracle case, it looks like Android's life could be at risk.
You can write more *statically* type-safe code that doesn't rely on runtime checks for safety. In Go, your code that, say, casts to and from `interface{}` is type safe, but that safety relies on a cast which may fail at runtime. So, at author time, you know the code won't reinterpret bits in memory and go off the rails, but you don't know if it will run without error. With a more statically expressive type system, you can write similar code and, at author time, know that there will be no runtime type errors at all.
Very rich type systems are good for building libraries or giving talks about how clever you're by implementing JSON parser in contexpr. It's cool but not very useful. Take C++. You can write almost anything you can imagine and then some with template magic. But how often do we, regular programmers, write libraries like boost? Almost never. In my experience, you don't need rich type system to build an actual product. In fact, it even hurts because it takes time not only to appease the compiler but it also pushes you to overthink and constantly refactor your code. It takes time to read others code because everyone writes in their own subset of the language. In theory, you could choose a subset of, say, C++ and write simple and easy to read programs. But it falls apart the minute you join a team of other programmers. It would be very difficult to force everyone to write code the same way in very syntactically rich language. Eventually you will be forced to remember every obscure syntax just to understand others code.
By that logic, JavaScript is even better, which I doubt was your point. What is the difference? I strongly disagree with a flat statement that types complicate things; used properly they dramatically simplify things, especially for the future reader of the code.
that would be great if auto vectorization was magic but it isn’t 
every language can target different architectures 
Agree with your assessments but, you only tried C#, PHP and Java. That's very few languages, and a choice of pretty ugly languages by the way. 
Missing modules support was annoying. It appears to be fixed https://github.com/99designs/gqlgen/pull/514
You can write some go code to connect to your webserver, instead of JS and HTML :) That way you'd have written both sides of the websocket.
I find it baffling that you can find people that scream bloody murder when you use a singleton (not a problem), a global variable (must be restrictive to avoid issues), or goto, yet love and adore exceptions. The more code you have to read to reason about the code in a function the worse. With an error returned it’s very easy to reason about. With exceptions you have no good clue on what throws and what catches until runtime. 
&gt; I disagree with the author on tooling - my current experience with Rust tooling is very positive, IDE tooling is not quite where it needs to be for rust. It especially becomes apparent when you're trying to write async code with `tokio` or something. Once you get a little too nested with combinators both RLS and intellij plugin lose the ability to provide any sort of information about types, let alone autocomplete. This is especially necessary for async because tokio expects &lt;(),()&gt;. It's been quite frustrating to say the least.
You might want to re-examine C# since they released .NET Core. It should work fine on Linux.
to answer your question, yes i realize that. as to the rarity, this can be a relative idea so maybe you can talk about some of the projects that use n dimensional generic vector libraries and how performance compares to ones specialized for each dimension. im interested.
Functions in Go can return more than one value, the rule is that any function that can fail should return an error value as the last item the function returns. So a function like JSON.Marshal return a byte slice (which is your JSON string as bytes) and an error. When you write your own functions, every time you use a function that can fail, you do this If err != nil { return nil, err } Each time one step of your function fails the error (generated by the internal function failure) will be returned from your function. Assuming everything executed correctly, the last line in your function should be return myvalue, nil This way when you run your own function you can do this myresult, err := myfunction() if err != nil { // Do something } So if an error occurs error gets passed from one smaller function to its parent until it comes out. Otherwise you get nil for the second value Edit: Corrected formatting Edit2: Sometimes the compiler won’t let you return a nil as your main value, in that case just return and empty value like an empty array 
This is a really good idea. Although I don't want to completely modify what I already have, I'll consider adding this as an optional feature. Thanks!
&gt; With the lastest Oracle case, it looks like Android's life could be at risk. There is a reason why Google is trying to invest so much in Kotlin right now, as the next Android language. Also, let's not forget that Oracle is now starting to charge for the use of its JDK / JRE. There are open source versions of JRE, which could still be used for commercial purposes. But still, it seems like Oracle is trying their very best to bring down Java. 
To me, the value of types is less about the type itself, and more about what you can (and just as importantly, what you *can't*) do with them. I come from a Ruby background, the type system of which is either strong or weak depending on your definition. Type conversions are implicit (*when it makes sense*), duck typing is popular. What's important to me is not fine-grained control over various integer sizes, or working with pointers (everything except primitives is passed by ref and autoboxed). I can, as you mentioned, write code rather than write types. What I *do* care about is actually enforcing the duck type paradigm, something that Ruby doesn't always do well. It doesn't make sense to add a string to an integer. Ruby raises a runtime error when you try to (which is still a step above something like JavaScript, which just produces a nonsensical result). But I can't extend this to method signatures, and say "this argument needs to be a numeric". I don't care about the exact concrete type, but I want to be able to express some kind of guarantee that whatever argument is passed here, can be treated as a number and added to another number later. I want to work with a language that can intelligently and implicitly substitute or convert types, but only where it's possible to do so without violating an assumption about how the program actually behaves as a result of this conversion of substitution. This is an inherently subjective desire, because one person's invariant is not another's. E.g. something like auto-growing a fixed int to a bigint is fine if all you care about is the output, but not fine if you care about performance or memory usage.
what' s wrong with code generation? i use it for the rare cases ( like your example) . The resulting code is faster , safer and more readable than added complexity and slower stuff baked into the language imho. Go is a more productive c in this world of multicore processors. Managing (user) threads and memory by hand is fun ( and for resource constrained or critical path software the way to go) but takes a lot of time...and testing. With these managers using the time to market whip and a future where machine learning can maybe optimize garbage collectors and schedulers for your program... I think go is an excellent future proof programming language.
Thanks! Formal benchmarks are definitely next on my todo list for this project. When I have the time, I'll test ring against similar implementations and be sure to publish the results.
Precisely.
This is precisely why we end up with shitty code bases.
So you are willing to sacrifice correctness for development speed? Bizarre.
You seem to be taking my comments as criticism of go, because you are presenting a bunch of arguments about why Go is good, that have nothing to do with the discussion of types. My comments are not meant to be a criticism of Go. On this same topic I could go on at length about how impenetrable a lot of Rust code is because people choose to do crazy stuff with traits and generics for no good reason. Green threads and thread safe queues are very nice tools but lots of languages have that. Its nice that the friction for using them in Go is very low though. 
I agree that this should be implemented. When I find the time, I shall find a way.
Your whole rant is against complexity as C++ does it, not against static types.
&gt; a type error in C++ is likely telling you what syntactic or structural requirement you need to meet ...a structural requirement that you yourself put there to minimize mistakes, yes.
I think with types, there are two optima. One is somewhere around Go, though I personally would still like (some aspects of) generics. I've been programming in Go for a while, so obviously I am living without it, but I have had some cases where I really wished I could write "a function that returns the same type that it takes", or code that could do some channel manipulations without having to be specialized to the exact channel type. But Go is decently close. Here, types are rarely getting in your way, but they provide useful guards against really stupid behavior, and with a bit of modest cleverness with the visibility rules and such, you can still put up some nice guard rails for both you and the other users of your code without having to put too much work into it. The other is either Haskell, or even a step beyond, where you can use types to make very, very sophisticated guarantees about the nature of your code, and you do get some extremely powerful tools of using this code with these guarantees as a result. But there is a cost, which is that this one is intrinsically harder for the programmer and takes more cognitive firepower. It does allow you to craft jewels of magnificent precision, the likes of which Go can't dream of, but it comes at a much higher cost. But there are programs I would be willing to write with this class of language that I simply would not take on with Go, because while it provides good bang-for-the-buck on safety vs. effort, there are some programs in life for which I'm still not willing to accept a language being "close" on safety, especially as the size of the program increases and all these "just sorta close" things start compounding on each other. (Despite having spent the majority of my 20-ish year career in dynamic languages, I no longer consider that one of the optima. Now, 20 years ago, they actually were, because ye gods were the static languages a nightmare of accidental complexity and nightmarish complexity for little gain. But those languages have largely stood still in this sense, whereas the static world has given us newer, better options, and I think dynamic languages are now only the best choice for certain very constrained niches.)
a lot of engineers think complexity == quality so prepare for down votes
&gt;Go has enough of a type system to avoid most of the careless mistakes that plague programmers in dynamic languages, but it has a simpler type system than comparable typed languages. This approach can sometimes lead to isolated pockets of "untyped" programming within a broader framework of types, and Go programmers do not go to the lengths that C++ or Haskell programmers do to express safety properties as type-based proofs. But in practice Go gives programmers much of the safety and tun-time performance benefits of a relatively strong type system without the burden of a complex one. Page xiv in *The Go Programming Language* book. I think that description is quite accurate. Personally, Go is my most productive language too. I love the fact that I can attempt plenty of prototypes faster than in most other strongly typed languages. Then if I like the direction of the prototype itself, it's reliable enough to dive deeper into the project with the existing code.
Good job, here are a few suggestions: - Always format your code using `gofmt -s` [1] - Exported functions and types should have comments or be unexported [2] - Replace _“spf13/cobra”_ with `flag` [3] and make the CLI run the “hackathons” command by default, then print the version only if `-v` is set. There’s no need to have big dependencies for minor features - Replace `ioutil.ReadAll` with `json.Decoder` or read this article [4] to learn more about ioutil.ReadAll; you could simply write `json.NewDecoder(resp.Body).Decode(&amp;hackathon)` - Use HTTPS whenever possible. The API that you are using supports HTTPS [5], so you should use that instead of basic HTTP [1] https://goreportcard.com/report/github.com/jamesgeorge007/hackalist-cli#gofmt [2] https://goreportcard.com/report/github.com/jamesgeorge007/hackalist-cli#golint [3] https://golang.org/pkg/flag/#StringVar [4] https://haisum.github.io/2017/09/11/golang-ioutil-readall/ [5] https://www.hackalist.org/api/1.0/2019
I'm glad someone asked (the repo needs more documentation). Bloom filters require this tricky balance between memory, speed (throughput), and the number of false positives. To decrease the false positive rate, the underlying structure must grow, increasing the memory required. For a lower false positive rate, there also needs to be an increased number of hash rounds. I consider this implementation "high performance" for two reasons: * **MurmurHash3 with optimizations**: For a bloom filter to be effective, the hash function(s) must ensure random uniformity to minimize the number of false positives (Neustar has a good [article](https://research.neustar.biz/2012/02/02/choosing-a-good-hash-function-part-3/) on this). Other implementations (in Go and other languages) often use FNV for hashing as it is very fast. Unfortunately, FNV has a higher number of false positives due to decreased random uniformity. The choice of MurmurHash3 provides a great balance between uniform distribution (accuracy) and performance. To help accommodate for the increased computation of using MurmurHash3, I apply optimization techniques found in a [research paper](https://www.eecs.harvard.edu/~michaelm/postscripts/rsa2008.pdf) (and [here](https://www.eecs.harvard.edu/~michaelm/postscripts/tr-02-05.pdf)). This optimization "simulates" additional hash operations without actually performing them. This creates a significant speed up, especially since bloom filters require multiple hash rounds per each operation (insertion and test). * **Auto calibration**: This implementation automatically uses the fewest number of bits and hash rounds, based off of [Probability and Computing: Randomized Algorithms and Probabilistic Analysis](https://books.google.com/books?id=0bAYl6d7hvkC&amp;pg=PA110&amp;redir_esc=y#v=onepage&amp;q&amp;f=false). This minimizes the memory and number of operations required to insert and test elements, while staying within a pre-defined false positive rate. All someone has to do is specify the maximum number of elements they may want to store within a specified false positive rate. This will automatically adjust the storage and hashing to maximize the speed while minimizing memory consumption. Outside of the theoretical zone, by doing some simple benchmarking against similar implementations, this did have a higher throughput, while consuming the same or less memory. When I have the time, I will be building a formal test suite and publish the changes in the repo.
Compared to global variables and unlimited goto (unlike Go's goto), exceptions are at least limited to a specific subtree of execution. So even though I agree with you, they are still on a tier below those things. It does depend on language too. Some languages, like Swift, do actually force you to explicitly show which expressions can throw, which ends up being quite similar to Go's errors though a little less verbose. 
C# is a great language and you can be productive very easily with it. It’s not even remotely on the same page as Java. The issues OP mentioned about dealing with Linux, well, that’s less of language issue than an implementation issue, and it’s already changing due to Microsoft‘s changed course. 
Yeah, performance wise it seems to be close to a standard gin web server, only about 30% slower maybe. It doesn't heavily rely on reflection which i think is the main problem of the other libraries, when you get to runtime reflection in \`Go\` to do things you do easily in other languages like node.js and python, then i think your using the wrong tool for the job. I also think the API is pretty nice and easy to understand, a main problem is that running into issues w/o getting a error message is pretty common in the beginning. E.g. if you just create a interface and don't make any concrete implementations of it, it will do switch cases with non-existing type placeholder just called \`Type\` and things like that. But it is open source, seems like they're open to receive PRs
Tell him what does it better.
To be fair, complexity itself is a hindrance to correctness and C++ isn't exactly known for its achievements in correctness either.
Funny you mention JavaScript. I just read a [really neat article](https://medium.com/javascript-scene/the-typescript-tax-132ff4cb175b) on "the TypeScript tax", the cost of dealing with types. One of the things he mentions is that all that type checking will catch type errors, but type checking comes with some hassle and if you're doing reasonable other methods for reducing bugs (design/spec/code review, TDD), the type checker isn't going to catch much extra. An unrelated point, but one worth mentioning: &gt; In the cost of typing overhead, I’m including all the extra time spent typing, testing, debugging, and maintaining type annotations. Debugging types is a cost that is often overlooked. Type annotations come with their own class of bugs. Typings that are too strict, too relaxed, or just wrong. &gt; &gt; This cost center has gone down since I first explored it, because many third party libraries now contain typings, so you don’t have to do so much work trying to track them down or create them yourself. However, many of those typings are still broken and out-of-date in all but the most popular OSS packages, so you’ll still end up backfilling typings for third party libraries that you want type hints for. Often, developers try to get those typings added upstream, with widely varied results. &gt; &gt; You may also notice greatly increased syntax noise. In languages like Haskell, typings are generally short one-liners listed above the function being defined. In TypeScript, particularly for generic functions, they’re often intrusive and defined inline by default. &gt; &gt; Instead of adding to the readability of a function signature, TypeScript typings can often make them harder to read and understand. This is one reason experienced TypeScript developers tend to use more reusable typings and interfaces, and declare typings separately from function implementations. Large TypeScript projects tend to develop their own libraries of reusable typings that can be imported and used anywhere in the project, and maintenance of those libraries can become an extra — but worthwhile — chore. The author likes Haskell's style of annotating types _outside_ the function body because it minimizes visual clutter. In the comments, someone points out that one can use JSDoc to do type annotations in comments above the function body, in JavaScript. The author likes that style, as do I. (I write JavaScript in Visual Studio Code with type annotations, and it seems like I'm getting most of the benefits of TypeScript without the hassle of setting up `tsc` in a build step for my static sites.)
weak type system =/= weakly typed
It'd be nice to take in a context so you can stop waiting to retry if the context is canceled. 
Actually, usually it's a structural requirement put there by someone else. The standard library, your organization's library, or someone who predated you on your project can all also impose requirements. In my experience it isn't usually to prevent mistakes, it's to allow future flexibility that you don't need (and usually that never wind up being necessary). If it's something you put there yourself, it's probably not causing you much trouble.
How? By letting people solve their problems with code? I have news for you: people will write shitty code no matter the language. Complex shitty code is harder to fix than simple shitty code, and solving problems by adding complexity isn't making code any cleaner. You need robust code review procedures and a culture that believes in code quality to prevent shitty code.
Sounds useful, I'll see if I can add it in the next release. Nice idea, thanks! :-)
Well, in the short-term I'd think every Android device would shoot up in price, causing people to move to (or back to) iOS, decreasing the information Android has about you which would have drastic consequences on their adword platform. Honestly, I can't blame Oracle. They own IP and as a company, exist to generate profit. I'd thought it would give the dying Windows 10 another breathe of life. Window devices are still really huge in business.
Type systems can be frustrating if you know your code is correct but can't prove it to the type system. Imagine dealing with strongly-typed collections in a language that lacks awareness of covariance and contravariance. Compounding the problem, type systems complicated enough to express all you'd want to communicate with them are hard to understand (see: “fighting the borrow checker” in Rust.) I like typing even though I haven't needed to go Full Rust for anything, but it's not all wine and roses. 
Please don't refer to this as something it's not. (1) This is a combination of two data structures, without the semantics being clear. e.g. if using the ring buffer, doesn't just "avoid short term false positives" - things are deleted from the set after the ring wraps around. (2) You're using a byte for every bit, losing most of the space advantages of a bloom filter. Shared libraries should do one thing well... I'd suggest if you want to publish a bloom filter library, make it do that job well.
Complex solutions tend to find themselves being simplified and optimised by subsequent generations of developers. In fact, simplification is one of the easiest wins when it comes to optimisation. Just look at the core of the internet (dns, email, html, tcp/ip etc). They're all excellent systems for generating research papers, citations and careers - but massively overcomplicated, full of security flaws, and crying out to be overhauled.
This is true. Usually they just put in some keywords to match against the resume. So make life easy and make sure both keywords match.
why `waitTime int64` instead of using `time.Duration`?
I don't find it arbitrary at all. If companies can only hire programmers who "work the system" to bypass their crappy HR, they aren't hiring based on programming talent, but on their ability to "working the system". I'm just making a statement that I only work at companies where their "HR" department helps the company hire talent instead of being an impediment. After all, the quality of a company isn't just about it's engineers, it's about it's ability to "execute" on all things.
I have something like this in my own code (not a public lib) so I have a few comments to offer... This doesn't seem to increment the wait Time or exponent over the course of retries. How does the retry use exponential backoff? There is no jitter in the backoff so it could end up having multiple clients hitting retries all at the same time. I find the interface/reflect approach a little overcomplicated. In my own implementation I just accept a `func() error` and then allow all of the return value logic to just set scoped variables from a closure. That closure function calls whatever needs to actually run and just has to return an error. It removes the need for type assertions and inspecting the function. 
I'm not sure I quite get your point. First you talk about how types are restrictive because the compiler makes you meet them, now you give an example where you have too much flexibility? If I understand you correctly, you're basically worried about being in a situation where the flexibility makes the code verbose because you have to prove to the compiler that your values adhere to the rules imposed by the types in the code? But then in such a situation, dynamically typed languages run into the dual problem of having ultimate freedom which means all those correctness rules you were able to encode into types with a static language, will have to stay in your head instead. I mean granted, I don't think either paradigm is bad because this *is* a tradeoff. That's why basically every scripting language ever is dynamically typed - it's easy enough to verify correctness in small programs.
Maybe my experience with C++ is colored by a large code-base, but most type errors that I see engineers struggle with are errors surrounding templates, polymorphism, argument-dependent lookup, macro expansion, references, const-ness, and various kinds of casting. Many of these are tools to allow future code to be flexible, but they introduce a lot of complexity in order to achieve that. Even "simple" things like trying to send a class value to an ostream instead of the field you meant to send can result in pages and pages of error messages explaining the types of overloading that the compiler tried and failed to specialize. I recognize the value in these errors when you are actually trying to do something complicated, but in most cases you aren't, and the type system is getting in the way of that.
&gt; if you're doing reasonable other methods for reducing bugs (design/spec/code review, TDD), the type checker isn't going to catch much extra. This sounds like opinion of someone who has never had to write and maintain code in production. The amount of errors you are able to catch with typing (and the increase in errors you can catch with linting) are a huge advantage.
I would say much like everything else in programming, it's hard to read and write typed code when you first start out, but if you don't give up eventually it becomes much easier. And the clarity and ease of use of your typed system is something that depends on the skill of the writer, which also increases with practice. 
&gt; The ability to not have to think in terms of types allows you to chop and change things as you wish, without having to remember: what type to change, which methods within that type which are affected by the change, and other code that is also affected etc. Holy shit lmao. You're literally arguing *for* types with this shit.
I've used many more though. Javascript isn't a language in my opinion and isn't even worth mentioning to be honest, yet I see people have. Very surprised.
Links not reproduced here, but at the bottom of the article: &gt; Eric Elliott is a distributed systems expert and author of the books, “Composing Software” and “Programming JavaScript Applications”. As co-founder of DevAnywhere.io, he teaches developers the skills they need to work remotely and embrace work/life balance. He builds and advises development teams for crypto projects, and has contributed to software experiences for Adobe Systems, Zumba Fitness, The Wall Street Journal, ESPN, BBC, and top recording artists including Usher, Frank Ocean, Metallica, and many more. He's probably not lying about his credentials, considering [Programming JavaScript Applications](http://shop.oreilly.com/product/0636920033141.do) is an O'Reilly book.
Implementation issues are language issues. Windows needed one piece of code for locking, linux another (not so well documented) chunk of code. Having to figure this out, find it, and implement it costs me time. Time I could be spent making money.
I think you might benefit from getting exposed to some of the newer languages out there like haskell or clojure. Types have advanced a lot since the 90s and I'm not sure if you've noticed it yet.
Clearly hasn't coded anything bigger than a 'hello world' application.
Oh yeah, now I see your point. Yeah, I agree with that. C++ has made some horrible design decisions that lead to ridiculous complexity down the line. At first I thought you were talking (powerful) static type systems in general.
[removed]
Thank you all. I really appreciate the help. I was able to complete my new script that involves parsing of JSON from a file and API response. You guys are awesome!
I personally prefer the Ada way, which is heavily focused on types and very sound but without any of the impractical computer-sciency stuff. I miss integer subtypes, for example, and do like the extreme overhead of defining a type for nearly all data structures you use, as long as most conversions are zero cost. I'm also looking forward to generics in Go. I originally come from a LISP background where you'd use many powerful but easy to implement abstractions. Go doesn't fit my personal preferences well in that respect but I chose it for its overall high level tooling, support, and a great result-oriented pragmatic community, and because it has a GC. I've learned it a bit of Rust and read through one of the books, but in my opinion it is the exact opposite of how a technology should be. A technology should serve humans rather than humans serving the technology. Abstractions are only useful as long as they allow you to achieve your goals easier and make code more readable and maintainable. If there was a less verbose, modernized Ada with the same level of support as Go, I'd use that. But I don't think there is ever going to be such a language and Go is IMHO a very good language for getting things done. 
I mean, I'm not surprised that's how you retort because I'm not sure either how you could have defended your original statement.
*Golang has much better support for concurrency* It certainly makes it very easy. It gives us goroutines, channels, and locks to play with. But rust gives us "fearless concurrency", not having data races IMHO is quite a supportive feature! On balance, I can't decide which has better support. (Sure, Go has a race detector - which seems the far less robust approach to me - basically wait for them to happen at runtime and hope you catch them.)
Some of these are types (structs/interfaces), some are just collections of functions. 
There is a sweet spot inbetween no types at all and ridiculously convoluted type system. Go hits it pretty well.
What should we be looking at? It looks like you forgot to link to the thing you wanted to share.
Wait a few hours (days) and I'll likely catch up
I do like types. However, there is a barrier where more typing information makes programming harder, not easier. For example, I found that languages which only allow me to dereference pointers once I proved that they are not null pointers incredibly cumbersome to use. I don't see the point here; if I dereference a null pointer, the application crashes which is a defined and easily-debuggable fault condition which always indicates an incorrect program. So there is no point in languages preventing this from happening; the only thing that does is turning an easily-debuggable fault condition into a fault elsewhere that is much harder to debug. Also, if a language's typing features are too advanced, programmers (like me) start to think more about the right types to use than about solving the problem, which greatly drops productivity with nothing substantial gained.
If you were using a language that doesn't rely on runtime type assertions but you were using them all over the place because _the same business logic_ would somehow supposedly be "simpler" I would accept a merge request only if you changed it towards polymorphism. It's not like types were all syntax.
Having said that, you can write "Go", "Golang" or "Go(Golang)" but at the end of the day you will still receive inboxes for a Node Developer position in one of the hottest startups in the Machine Learning field.
A package for "defs"? Like constants? I am a firm believer that constants and types should be defined not only in the same package but as near to their use as possible. This does sound extreme and sounds like editor gymnastics to get anything done.
Cannot blame him. The terms _weak_ and _strong_ aren't well-defined with regards to a type system. Only _static_ and _dynamic_ are well-defined categories of type systems.
I'm using it in a production project, and like it. It solved some issues I'd been having with the previous library I used for other projects (the neelance one), but I don't recall what those issues were. It's also helped me fall in love with automatic code generating, so I've been using that for other parts of the project too.
It's primarily so it only writes a complete value but also for buffering, since if the writer is something like stdout making multiple calls would be inefficient.
I cannot blame you. The terms _weak_ and _strong_ aren't well-defined with regards to a type system. Only _static_ and _dynamic_ are well-defined categories of type systems. Most commonly used _weak_ and _strong_ only say something about the relation between quantities of type system features between languages of arbitrarily selected set of programming languages.
`defs` is a small package for constants that have to be global, like the project's version number and banner text. (Code [here](https://bitbucket.org/bagab/bagab/src/default/app/data/defs/defs.go).)
Sorry! I'll edit my comment.
Hey! After thinking about it, I agree with everything you said. As a result: 1. I've removed the circular buffer. The name of the project is still "ring" (which may be a little misleading), but it is just a standard bloom filter now. 2. I knew I was forgetting something when I originally pushed to GitHub. Surprisingly, this was still consuming less memory than other implementations (bad when you think about it). Thank you for pointing this out.
This package layout reminds me of [this article](https://dave.cheney.net/2019/01/08/avoid-package-names-like-base-util-or-common), specifically these lines: &gt; For example, the net/http package does not have `client` and `server` packages, instead it has `client.go` and `server.go` files, each holding their respective types. `transport.go` holds for the common message transport code used by both HTTP clients and servers. &gt; Name your packages after what they *provide*, not what they *contain*.
It panics with a case it can't handle. ``` godocc ioutil WriteFileX panic: exit status 1 goroutine 1 [running]: main.main() /home/kostyarin/go/src/github.com/inancgumus/godocc/main.go:19 +0x3bf ```
Although it might be justified in this case, I think you are probably confusing the concept of a package with a class. That said, I do have some projects that get this way in places, where it’s justified keeping things very siloed and private. As much as Domain Driven Design drives me up the wall, you might benefit from reading some of the material. It made me think about Go in a totally different way when I started visualizing packages as domains. 
At work our options are C++, Go, Java and Python... So those are the main ones I've had a chance to see outside an academic setting. I haven't seen how the stronger type systems work out in practice, unfortunately. I am curious to see what happens if Go gets generics. I think it might become one of the most powerfully simple type systems in practice if it manages to reduce the number of times people resort to interface {}.
Psst, channels have subtypes
Nice! I'm using docopt but have no real idea where that project is going. I'll look into your solution, seems neat!
[removed]
You realize you just indicted about 3/4 of the web development community... I jest but there is a serious aspect to it. They are pretty much ready to give up anything to make development faster.
Please, have you forgotten the merits of debate? To weigh up Pros and Cons? What world do you want to live in where it's forbidden to have a good old fashioned argument? Women and Men have different roles, so anyone discussing their differences should not be trusted?
/r/javascript
Here's a sneak peek of /r/javascript using the [top posts](https://np.reddit.com/r/javascript/top/?sort=top&amp;t=year) of the year! \#1: [PSA: There are over 1000 people in the U.S. named "Infinity" and the jQuery .data() method attempts to convert to number when reading off the DOM](https://np.reddit.com/r/javascript/comments/8f57i1/psa_there_are_over_1000_people_in_the_us_named/) \#2: [I built Apple Music using ReactJS, Redux, and Styled Components](https://v.redd.it/3qxy9xbbc5e11) | [112 comments](https://np.reddit.com/r/javascript/comments/94mqj0/i_built_apple_music_using_reactjs_redux_and/) \#3: [Oracle Owns "Javascript", so Apple is taking down my app!](https://np.reddit.com/r/javascript/comments/8d0bg2/oracle_owns_javascript_so_apple_is_taking_down_my/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
I ask this regularly as an interview question for software developers. I work in games. Most experienced game designers can solve it easily, with working code. The binary search of the array of probabilities is a nice touch but N is so small in practice (for games, six-sides dice, and so on) as to be an inconsequential gain.
I used to do this as well, but eventually I started getting cyclic dependencies so ended up having to restart my whole project :( I think you have to really plan how to package things together otherwise it gets really messy quickly. What I found helps is to look at other Golang projects (big projects like those by Hashicorp) and learn how they structure their code base. 
To clarify those folders aren't files of the same package. They're all individual packages. For organization you can use subfolders but from the compiler's point of view they are each their own package.
I’m probably stupid, as I’ve never done this before. But can’t you just put them all in an array, sum the weights, generate a random number between 0 and total, then loop through them, adding the current weight to a rolling sum. If the random number is larger than the current sum, and less than the sum plus the weight, then pick that number? 
There really shouldn’t be much fuss over Go’s typing IMO. The lack of generics sometimes sucks, but I can appreciate the ruthless pursuit of simplicity. If there’s one thing I learned from years of JavaScript, it’s that sometimes you need to enforce your own rules and conventions to a subset of the language to increase safety. Go is typed. Weakly typed, but typed nonetheless.
he stacc he overclocc but most importantly, he go docc
Thanks for the clarification, I guess I won't be able to pull it off :p
Not sure I follow what you’re saying. How is Rust more magical? It’s still a case if you needing to write out the intrinsics and have some system for compiling them or choosing them at runtime. Go’s main deficit as I understand it is that there are no ASM/intrinsic primitives in the language itself, but you can still link in an ASM file. 
Mono is garbage. Try .NET Core. It works flawlessly in Linux. I do most of my C# dev in Linux now. At work, we have a major system in production running on a Linux server.
They're both ugly languages. You can argue that one is better than the other (and both sides do), but you're kidding yourself if you think either of them is the clear winner as your comment implies.
I think it's true, though still kind of not ideal in some ways, after a few years of writing Go. It could probably be a bit looser: * You know, I don't really care about numeric types that much. There's often a bunch of random hassle when libs want one kind of number but you have some other kind of number. I regularly use: int, int32, int64, uint64, and big.Whatever(). Even standard libs like math often confuse the matter by forcing you to typecast to float64 to use math.Round, and then it returns another float64 even though a rounded number is an int. * I never had the need to use reflection for many years, and truly it was glorious. But now I do need to use it, and it's unavoidable. Reflection code isn't very simple in Go, and requires quite a lot of understanding of its inner workings. There are also a lot of inconsistencies with how it works, especially for global variables and objects. JS is too far on the loose side, but I do sometimes envy the `number` type that just kinda works without having to think about it or write a bunch of different functions for different numbers. And JS provides reflection as kind of a core feature, so you can trivially access functions using their string name, etc.
Haha. Cute. What graphics library did you use? It’s looking really nice. 
I'm using faiface/pixel and some GLSL for effects.
impressed with the destructible terrain
Its amazing ! Would you like to share source code.?
I might do that later when finished. I usually share all my code on my github.com/lallassu
Because io.Reader is an interface. It includes methods for reading. bufio.Reader implements all of those methods requires to satisfy that interface, and therefor, it can be used as that interface. Effectively, you aren’t requiring a concrete type, but any type that implements that interface. 
It looks awesome! Great job.
Neat! Could you give a heads up if you ever open the source? I'm curious what it looks like. 
ohh, got it. thanks :) 
Hot damn! I like the look of this! Well done
Pozidriv screwdrivers FTW. Also, your bikeshed would be much better if painted black, with a red door. 
Sentiment is great, but nothing is error free when kernel space interactions are involved. :/
Great GL library. The creator is really helpful as well
First off.. &gt; We increment the count of lines before checking the error—​that looks odd _, err = br.ReadString('\n') lines++ if err != nil { break } That is because your code is simply odd. It would make more sense to structure it like this: _, err = br.ReadString('\n') if err == io.EOF { lines++ // Add the last line break } // Unexpected error if err != nil { return 0, err } Aside from this, hiding errors reduces the number of "smart" actions you can take based on an error. In some cases it does indeed not make sense to handle all errors, and a wrapper such as your writer can come in handy. That's not a general case though so it's good to have the option for very granular error handling if you'd need it.
Isn't this very similar to other retry-packages such as https://github.com/eapache/go-resiliency ?
Please be sure to post here 
I feel oblidged to reiterate that "green threads" is not what make Go stand above most other languages which have them; rather, it is those green threads _having been integrated with runtime I/O scheduler._ This feature allows the programmer to write dumb _sequential_ code rather than callback spaghetti—no matter the number of layers of coolness ("promises", "futures", etc) it's wrapped in. 
Don't &gt; do like the extreme overhead of defining a type for nearly all data structures you use and &gt; A technology should serve humans rather than humans serving the technology. contradict each other?
That gore though
No, there is no contradiction, on the contrary. Nobody forces you to make use of Ada's strong typing, but in canonical Ada programs become way more readable and maintainable. Good Ada programs are self-documenting. For example, you pass a value of type `Celsius` to a function that returns a value in `Kelvin` instead of having a function that takes an integer and returns an integer. Or, you pass a value of type `TrafficLight` to a function, and this type can have values `red`, `orange`, `green`. You can constrain these types to certain ranges, for example you can define a type `DayOfMonth` as a range from 1 to 31. You can then loop through a value `day` of this type by going from `day'First` to `day'Last` or by using `day'Range` directly. (Admittedly, in this example it doesn't make so much sense, since some months have less days but you get the gist.) To be fair, most of this apparatus is no longer needed. Ada is highly optimized for static memory management where you'd have a lot of arrays of fixed size with corresponding types and ranges. Nowadays, almost everything is dynamic and in the end you probably store everything as strings or blobs in some database anyway.
r/Jetbrains
Really cool :)
That's funny. Although on a serious note, I know Goland has advanced UI features like being able to display color swatches and icons of values in code. It is likely it is trying to display image paths you have referenced in your code? 
This is really cool...and very fast. 
Your layout literally has one package file + test per directory. Sounds like you got way too granular about your packages before there was a need. I usually start with a file and then split it into a package when it starts to take on its own standalone responsibility. No offense, but if I were another developer that had to work on that project, I would find that current layout obnoxious. Just my 2cents. 
Looks like you actually only need 3 packages from what we can see there - this _is_ too over the top!
Thanks for sharing! We have another coming this week - keep your eyes peeled :)
Hi. This seems to similar to a known issue described here https://youtrack.jetbrains.com/issue/IDEA-199737 If you can provide more details in the thread there that could be useful. Ultimately, this seems to be a bug in macOS for file access under the $HOME directory.
Fair points. Let's see where we are in 5 years.
Indeed, saw this on Visual Code and go vet runs also.
Gore and cute at the same time. I like it.
Wow, this is great! As the creator of Pixel, I'm very happy to see these things! :)
Reminds me a bit of liero
Why not simply clamp your weights between 0 and 1 and then generate a random number in the same range. Then you can add up your weights and the first one that gets you over your random number is the element you want.
&gt;and have some system for compiling them or choosing them at runtime That system can just be a Rust library, rather than having to write a program that can parse a new language and output go code. Like, you seem to be saying that both languages are Turing complete so there aren't any fundamental differences between them, which...yesss. 
Can you show an example of what you mean? I don't understand how I can use goroutines and/or channels to write code that is any more dumb and sequential than if I used, say, a bunch of Tasks in C# with a concurrentqueue
Looks like another implementation exists, I didn't see this, thanks!
is this linux? if yes, there are ways of doing it, for example using the `memfd_create` syscall. Full example: https://github.com/guitmz/memrun
Each consumer doesn't need to \`import "time"\` if they're just passing in scalars. This is an option though, would you prefer to see \`time.Duration\` and import yourself?
without the source code we cannot say what is wrong; however your setup seems weird. It'd be more logical to have a single channel and have the workers read from that channel. The dispatcher should not have to care about how many workers exist. 
I use a package in my package that does exactly this: https://GitHub.com/gopherworks/senulator
If you are using a select, there is no order for it in case of multiple active options.
Go is well suited for domain driven design. If these are all independently, reusable packages; sure. I would recommend not doubly nesting packages, unless you provide an implementation for an interface e.g. - root/hash: defines an interface for a Hash - root/hash/sha1: provides a Hash implementation using sha1 In your case it seems you have lots of interdependent packages, meaning they are not really packages at all, just organized in a bad way. There is no need for a separate **tests** directory; you can declare a file as a test by appending _test to the package declaration, which treats it as a separate package within the same directory. Structuring a project this way adds a lot of mental overhead, keeping track of what lives where. 6 months down the line you will notice the problem. Normally I'd say, go ahead and do what works for you; but Go's strength is its strong, opinionated style, and this is not very idiomatic. 
There seems to be a misconception here around "more strongly typed" being synonymous with "more good". While you're right that generics would reduce boilerplate and allow for more static expression, and I would definitely prefer Go to have generics, that has nothing to do with strongly vs weakly typed.
The blog belongs to Dave Cheney, so I would reconsidering the "your"s you used
Not an expert but the scheduler may not be able to schedule the other goroutines if the first one is cpu-bound. Try it with "runtime.Gosched()" which time.Sleep() calls under the covers.
Your games always look very enticing. I don't play many games, but I really want to make the time for this and another you posted. :)
As a result of this I've learned about [jitter](https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter]) and understand how it's useful with many consumers, found a bug, and gotten an alternative API which I like for the type safety. Thanks a bunch for the constructive criticism :-)
Do you have an example of how this works? Do I have to make C Go links and pass the `show-libs` flags in the linker?
I don't look into who wrote a blog, that's not relevant. The content of the post is what matters. If the author has any input as to why he structured his code example oddly to prove a point, he's free to provide it.
Sure: ``` var buf [8*1024*1024]byte _, err := io.ReadFull(buf[:]) if err != nil { ... ``` would read the whole 8 MiB worth of data using any number of syscalls, with the executing goroutine sleeping during the periods when there's no data and automatically awakening and continuing execution when there is. From the standpoint of the programmer, all the trickery around `recv(2)`-ing from a socket is completely hidden by the runtime I/O scheduler: the goroutine just reads the data and eventually continues execution after the statement following `io.ReadFull` — no matter how many other goroutines are doing stuff at the time of the complete data reading session.
All im saying it’s not his code. You keep saying “your” to op. The writer aint here
Actually,no wonder it is used in k8s: Google. But, more importantly, Go is stable. This is extremely important for large/enterprise projects. Rust is a moving target still, not everything is stabilized and it may even have some syntax changes yet. How would you plan a serious long term project with that? 
Completely agree. The worry is that there is only 8 months age difference between the two and yet Go is much further along in maturity. 
&gt; So there is no point in languages preventing this from happening; the only thing that does is turning an easily-debuggable fault condition into a fault elsewhere that is much harder to debug. MFW a compile error instead of runtime segfault is harder to debug.
Doing automatic vectorization in a compiler is hard. Go now has SSA, which helps. But at this point vector operations can be used mostly in peephole optimization and optimized ASM versions of performance critical standard library methods. Rust itself does not have auto vectorization, LLVM does. So LLVM Go should be able to have it too.
That seems like more a property of having a nice convenience function available in the standard library (something in general Go is very good about!) I don't think C# has exactly that built in but you could implement ReadFull equivalently using ReadAsync and a few lines of code, I believe. I'm just not sure the Go runtime is a necessary condition for this, perhaps I am wrong. 
None of what you said precludes automated stack traces being useful. In complex programs necessitate a convention for adding detail to errors, specifically location, it hints that the standard lib should come with such an abstraction. Fortunately we have one that's battle tested in virtually every programming language: stack traces. This obviously doesn't preclude adding context specific information such as the value of locals in a stack frame, but it makes the common case much easier to deal with. Especially in code bases that are less ruley (which tend to be more common than most of us want to admit).
It's not the compile error that results from enforced null pointer checking. It's the weird errors further down the path after half-assed error handling for a case nobody expected to happen caused the whole program to silently do the wrong thing instead of crashing immediately. Or to say it differently: removing the ability to crash does not remove the ability to err; it just moves the eventual fault condition to a different, harder to debug place.
ASM is a first class part of Go, it’s just not put in the .go files. They even have their own semi-platform agnostic syntax which is not the same as standard platform ASM. (People mostly find this annoying.) You can and often do use ASM distributed in a “Go library”. They just don’t have syntax for putting ASM into .go files. 
Yes I just mean that auto vectorization in general is not magic. Some people do about doing SIMD coding by writing normal C in such a way that gcc or llvm will tend to vectorize it, this is nice for a few reasons but you can't always pull off as optimal a solution as you can with intrinsics, and it can be brittle. Also tricky to use that approach with runtime selection though I think it is possible in some C compilers. &amp;#x200B; &amp;#x200B;
What is `Result&lt;T, E&gt;` :S
&gt;https://github.com/guitmz/memrun Thank you very much! I'm also looking for Windows as well as it will run cross-platform (with 2 sets on internal tools).
windows will be more difficult.. there are ways to do it fairly easily but they are usually flagged by antiviruses
He's not talking to the OP. Are you really this dense?
ok so show me something like, vector normalization function in Go asm, written one time, such that at runtime it will use SSE2 instructions if AVX2 is not available, and use AVX2 if it is available. &amp;#x200B; &amp;#x200B;
I'm not /u/logicaleak but I do agree that it's not correct for /u/kapoof_euw to address /u/pdq as though /u/pdq were the writer of the article. His (/u/kapoof_euw) criticism is spot on though. Performing error checking within the loop is closer to the intent and returning a zero value is more appropriate.
What are you trying to say?
&gt; once the dispatcher receives a channel, it sends a task to the worker associated with that channel Make sure that the channel is buffered.
Properly balancing between all of the workers is almost always done by using a single channel that all of the workers are simultaneously reading from. My guess is that there’s some kind of loop going on and it’s fixating on one. We would need to see the code, but it’s still pretty weird. 
This will probably help: https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1 ------ TLDR: Basically you just want to move any shared components closer to the root of your repository. Packages should never depend on any adjacent packages (example: global + router) with the exception of main.go which will exist in its own cmd package (this is where you wire up your dependencies). This also has the added benefit of allowing you to more easily identify any core components within your codebase.
&gt; According to this there is less than a year difference. Is it incorrect? Looks to me like 8 months. &gt; &gt; I do NOT want to sound negative about Rust. But I am someone that likes to work with facts. &gt; &gt; https://en.wikipedia.org/wiki/Rust_(programming_language) &gt; vs &gt; &gt; https://en.wikipedia.org/wiki/Go_(programming_language) Really? You used the first appeared date to go by? If you want to deal in facts and not emotion as you say, at least use something reasonable, such as first stable release. The date for "first appeared" is irrelevant for most contexts of discussion.
I can't change the date the two were introduced. It is important because one of the issues with Rust is that it is taking too longer to mature. You have to cease while you have the momentum. 
You generally want to use a single channel, where the scheduler pushes work into the channel, and the children all listen to the same channel. I [wrote this out into the playground](https://play.golang.org/p/eABQICmDBNX) a while back so I could avoid having to recreate it every time. Also, "fair" isn't necessarily the target with a work pool. If you're pushing work in such a way that at any time there's only one job to do, and the first worker always does it, that's just fine. It's easy to be in that situation accidentally, too.
You're asking us to choose between performance (1.3mm hex) and wide spread compatibility from years of consumer market share (PH4). ;)
Ye man, I am so densely stupid. You the smart big man, everyone knows that. Dont worry
Why would anyone mind importing a standard library? The reason to use `time.Duration` is because that's what it's for, and there's no ambiguous. When you do `waitTime int64` and the documentation doesn't say anything about what's the unit of `waitTime`, your consumers would need to guess (or check your code) to see if that's seconds or milliseconds or nanoseconds or some other unit. Not to mention there a whole family of helper functions around `time.Duration` to make people's lives easier.
\`net/http\` will likely split into a client and server package in the future. [https://github.com/bradfitz/exp-httpclient](https://github.com/bradfitz/exp-httpclient)
See the .s files in Gonum, eg: https://github.com/gonum/gonum/blob/master/internal/asm/f64/dot_amd64.s See also the .s files here: https://github.com/golang/go/tree/master/src/math 
But that applies to every bit of I/O, automatically. I mean, any `Read` call on a socket will suspend your goroutine if there is no data and wake it up when the data will be there. You just did not have to think about this stuff, ever. The distinction about concurrency-as-a-library and first-class concurrency is covered in [this classic essay](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/).
Interesting. Cool to see Ebiten progressing as it is. &amp;#x200B; Also, great idea on the mobile game.
that looks like it will only do SSE
Here’s a file that specifically checks for SSE: https://github.com/golang/go/blob/master/src/internal/bytealg/index_amd64.s Anyway this isn’t my area of expertise and I don’t know how well Go does this in general but it certainly is doable. 
In the following example in the article: func (e *errWriter) Write(buf []byte) (int, error) { if e.err != nil { return 0, e.err } var n int n, e.err = e.Writer.Write(buf) return n, nil } Is there something wrong in `var n int n, e.err = e.Writer.Write(buf)` ?
Interesting usage of both great languages. The language debate usually just shows how much people don't understand the tool. It is too easy to fall into a simplistic aesthetic debate.
Keep in mind that it seems that the go authors don't really have experience in languages other than C and C++, which you should keep in mind when reading comments like the above. They fail to see the benefits of established concepts such as compile time checked enums, which are already being seen in more established languages like Java, and most modern languages.
My pleasure. Glad my comments helped you improve your package! 
See this, eg: https://github.com/golang/go/issues/19593
Thanks for the feedback! Sure I don't disagree you have to do some file jumping, I personally don't find it that much of a problem with fuzzy finders... etc especially when we tend to use standard file naming conventions such as `{interface}_{implementation}.go` and so forth. But yes stdlib is a lot of related code in single files, I can see the appeal!
Again, this isn’t my area but here’s another relevant issue: https://github.com/golang/go/issues/15403 Not to say Go is great or well optimized or whatever. I’m just saying it’s in principle possible to do what you’re talking about doing with Rust IIUC. 
“Register to read more”. Had I seen this 5 months ago I might have considered it...
Onefootball?
Fair enough, but even if that specific example doesn't hold, the principle does. A package "providing" something implies that it's not required, so it's easy to imagine a package `net/http/server` which provides an HTTP server, without a client. It'd be tough to say that about the `defs` package in this project.
Agreed.
Very cool. Did GC pauses cause any issues with gameplay?
https://caniuse.com/#search=components I have read previously that the W3 standard Web Components haven't taken off because they are poorly supported, whereas reactanguvuelar has all of the required browser compatibility shim/polyfill stuff integrated and handled for you automatically. Have I heard wrong or misunderstood?
Be aware of [mmmap gotchas in Go](https://medium.com/@valyala/mmap-in-go-considered-harmful-d92a25cb161d). I'd prefer simple `Store(filepath)` / `Load(filepath)` API for the persistence.
Cannot find your game in the German play store, broken link?
Fair points. On the naming I could have named it better like `waitTimeInSeconds`, but `time.Duration` is more obvious I think. Thanks for your input!
Go's context package has timeout support, so you can just replace `waitTime` with a context and check context cancellation instead, unless you have some reason not to use context.
This (and your awesome pbr project) led me to follow this ebook also. Didn't take long to write the whole thing, but now i'm gonna take time refactoring it into something more idiomatic and with tests. I feel like i was just transpiling c++, so im also gonna sit down and go deeper into the maths. [https://github.com/alisdairrankine/turner](https://github.com/alisdairrankine/turner)
Pretty much. If you look at the things that matter (HTML templates, Shadow dom v1, Custom elements v1) you'll see that support is fantastic as it is and with polyfills you can cover even IE/Edge. In the end it comes down to what you want. Standards are here to stay and are natively supported in almost all browsers today. So basically you use the browsers native tools so they are blazingly fast whereas the popular frameworks have to reinvent all that stuff and there's no guarantee that they are going to stay. Just try to create a native browser component which includes look and feel (and its CSS won't affect other components) with React. You can't. Not today. In case you didn't know, YouTube Gaming is written using web components. Components are also used by McDonalds, Coca-Cola as well as EA. There's much more but just from the top of my head.
Thats what I thought 
Yes please!
Go has &lt;100 microseconds GC pauses (and only with big heaps), while frames take 16 milliseconds at 60 FPS, so GC really doesn't cause any problems in Go regarding gameplay.
It's not that I don't see the utility of stack traces in many situations, it's just that I don't usually need it. So because I don't normally need it, I don't care for it as an automatic process builtin to the language. It's more than I need. When I do need a stack trace, I can add that to the code as needed. 
You need more details about the nature of the connection to get any useful help beyond what you already said: "sockets". Also, what's Go 2?
[Supervisor](http://supervisord.org/) is a great tool for managing processes such as these. You could also containerize your server (really easy with Go) and let your docker daemon handle it. 
Golang v2, and what kind of details would you need to be able to help? 
Right now, Go 2 is a bunch of draft
Look at GRPC. It makes a lot of this really easy and solves a lot of the issues you’ll run into rolling your own. If you have a lot of servers, look at containerizing and putting it on kubernetes. 
Thanks, have you got any info on containerising go process? 
Amm i think this really depends on your use-case. Maybe you could give us more info? what will be the size of the payload? does it need 100% delivery? Because request alone means nothing :) 
Just docker. There’s a lot there, but generally you make a Dockerfile. Ensure your go program is configurable through env variables, like setting hostnames. 
&gt; It's the weird errors further down the path after half-assed error handling for a case nobody expected to happen caused the whole program to silently do the wrong thing instead of crashing immediately. Then don't program like a fucking idiot. If you didn't have compile-time enforced non-null checking then your application would crash *first* (good luck reproducing this reliably in anything with concurrency btw), and then by your logic the exact same half-assed error handling could be written to fix the crash.
Thank you 👌
for simplicity without monitoring and auto restarts, use nohup ./&lt;app&gt; &amp;
The size will minimal, probably biggest 2MB max, normally 50kb, though it would be useful if it was scalable. And yes, it needs to have 100% delivery rate, possible encryption though this can be done before and after sent. 
If you need something *really* easy, just use [screen](https://linuxize.com/post/how-to-use-linux-screen/). You just run \`screen &lt;your-project-run-command&gt;\` and you're good to go and can close your SSH client.
Thanks! I'll use this until I can implement a more elegant and stable solution.
The 'correct' ways to do it would be to either containerize your application or use the init system of your distro (probably systemd) to start the program as a service.
Saw the same thing for webstorm today in a different post. Is definitely a jetbrains issue. 
The beauty of go is the backward compatibility. You can learn from any book because things don't change so drastically in go.
Hello time traveller! How is the future, and how are you finding Go 2? Are generics working out to be all people expected?
I've actually never used docker, so this will give me a good opportunity to brush up on that and make the server more stable :)
Yes, currently in a time loop, got to correct some bugs before they annoy me in the future, or my past. I don’t really know. 🤔
Jetbrains said - this is a Mohave problem :) 
Been using supervisor for years and like it.
&gt;akes a lot of this really easy and solves a lot of the issues you’ll run into rolling your own. &gt; &gt;If you have a lot of servers, look at containerizing and putting it on kubernetes. Did you tried using ws (websockets)? I know it doesn't sound like new bleeding edge technology but it works. [https://medium.freecodecamp.org/million-websockets-and-go-cc58418460bb](https://medium.freecodecamp.org/million-websockets-and-go-cc58418460bb) Also don't forget that you can use WS over TLS (WSS). And regarding scale - I think this should come from your system design :). P.s. we are currently sending 350k+ messages/second in our production env :) 
I’ve looked into it but didn’t know if there was anything better? 
Thanks for the suggestion, certainly taking it into account 👌
I think I'm hitting a limitation to gqlgen.. &amp;#x200B; Since the return types of a parent resolver is not able to return interface{}, the child resolver cannot get data from the parent resolver's result? type ChildA { name: String age: Int } type Children { childA: ChildA } type Query { children: Children! } &amp;#x200B; Generated resolvers: func (r \*queryResolver) Children(ctx context.Context) (models.Children, error) (r \*childrenResolver) ChildA(ctx context.Context, obj \*models.Children) (\*models.ChildA, error) &amp;#x200B; Is there any way I can fetch data in the Children resolver and pass that to the ChildA resolver and let ChildA use that data and resolve for models.Children? &amp;#x200B; &amp;#x200B; Like in graphql-go , if we can do something like graphql.ObjectConfig{ Name:"Query", Fields: graphql.Fields{ "children": &amp;graphql.Fields{ Type: Children, Resolve: func (p graphql.ResolveParams)(interface{}, error) { data := getData() // This does not return Children type return data } }, "childA": &amp;graphql.Fields{ Type: ChildA Resolve: (p graphql.ResolveParams)(interface{}, error) { // extract data we need and filter it accordingly.. ChildAData := moldIntoChildA(p.data) return ChildAData } } } } &amp;#x200B; Any help would be great thanks! 
Hey have any of you guys hit this limitation with gqlgen? Since the return types of a parent resolver is not able to return interface{}, the child resolver cannot get data from the parent resolver's result? type ChildA { name: String age: Int } type Children { childA: ChildA } type Query { children: Children! } Generated resolvers: func (r *queryResolver) Children(ctx context.Context) (models.Children, error) (r *childrenResolver) ChildA(ctx context.Context, obj *models.Children) (*models.ChildA, error) Is there any way I can fetch data in the Children resolver and pass that to the ChildA resolver and let ChildA use that data and resolve for models.Children? &amp;#x200B; Like in graphql-go , I believe we can do something like graphql.ObjectConfig{ Name:"Query", Fields: graphql.Fields{ "children": &amp;graphql.Fields{ Type: Children, Resolve: func (p graphql.ResolveParams)(interface{}, error) { data := getData() // This does not return Children type return data } }, "childA": &amp;graphql.Fields{ Type: ChildA Resolve: (p graphql.ResolveParams)(interface{}, error) { // extract data we need and filter it accordingly.. ChildAData := moldIntoChildA(p.data) return ChildAData } } } } &amp;#x200B; Any help would be great thanks!
This is the exact implementation or close enough, when I remove the call to sleep, worker one does all the work
Hi thank you for replying. I went to my project directory and ran `go mod init` [`github.com/exercism/go/isogram`](https://github.com/exercism/go/isogram) so that I have a go.mod in my project like so but it I am getting the same messages. &amp;#x200B; The weird thing is that the app I am using (exercism.io) has always been outside of my go path but always worked. I assumed that it added itself to the go path (as some sort of alias pretending to be inside my go path?) so I am not sure what's going on there but maybe that has to do with it. I will contact them to see if they have any suggestions.
Hi yes [https://imgur.com/a/YV1UOSL](https://imgur.com/a/YV1UOSL) &amp;#x200B;
Hey do you think you can give me a hand with this problem.. &amp;#x200B; Since the return types of a parent resolver is not able to return interface{}, the child resolver cannot get data from the parent resolver's result? type ChildA { name: String age: Int } type Children { childA: ChildA } type Query { children: Children! } Generated resolvers: func (r *queryResolver) Children(ctx context.Context) (models.Children, error) (r *childrenResolver) ChildA(ctx context.Context, obj *models.Children) (*models.ChildA, error) Is there any way I can fetch data in the Children resolver and pass that to the ChildA resolver and let ChildA use that data and resolve for models.Children? &amp;#x200B; Like in graphql-go , I believe we can do something like graphql.ObjectConfig{ Name:"Query", Fields: graphql.Fields{ "children": &amp;graphql.Fields{ Type: Children, Resolve: func (p graphql.ResolveParams)(interface{}, error) { data := getData() // This does not return Children type return data } }, "childA": &amp;graphql.Fields{ Type: ChildA Resolve: (p graphql.ResolveParams)(interface{}, error) { // extract data we need and filter it accordingly.. ChildAData := moldIntoChildA(p.data) return ChildAData } } } } &amp;#x200B; &amp;#x200B;
Hey do you think you can give me a hand with this problem.. &amp;#x200B; Since the return types of a parent resolver is not able to return interface{}, the child resolver cannot get data from the parent resolver's result? type ChildA { name: String age: Int } type Children { childA: ChildA } type Query { children: Children! } Generated resolvers: func (r *queryResolver) Children(ctx context.Context) (models.Children, error) (r *childrenResolver) ChildA(ctx context.Context, obj *models.Children) (*models.ChildA, error) Is there any way I can fetch data in the Children resolver and pass that to the ChildA resolver and let ChildA use that data and resolve for models.Children? &amp;#x200B; Like in graphql-go , I believe we can do something like graphql.ObjectConfig{ Name:"Query", Fields: graphql.Fields{ "children": &amp;graphql.Fields{ Type: Children, Resolve: func (p graphql.ResolveParams)(interface{}, error) { data := getData() // This does not return Children type return data } }, "childA": &amp;graphql.Fields{ Type: ChildA Resolve: (p graphql.ResolveParams)(interface{}, error) { // extract data we need and filter it accordingly.. ChildAData := moldIntoChildA(p.data) return ChildAData } } } } &amp;#x200B; &amp;#x200B;
This is getting ridiculous. People are just scanning boards like Reddit, looking for topics they know will generate clicks, then writing vapid blog posts which are advertised on the same platforms! All of which just serves to reinforce the belief that there are issues with certain features. Please stop.
/u/justinisrael is correct. The issue here is that you're pointing to a single file. All other files, even though they're in the package, aren't going to be imported. go build has this same behavior if you are targeting single file to build and forget to include other files it uses in the command. Change the test kind to "Directory" and files to "/Users/m/Exercism/go/isogram". This will then include all files in the directory during build and should look for all \_test.go files to execute tests.
Hate gRPC. I can’t understand how code generation makes any sense outside of writing public client libraries. 
At the risk of over complicating your app, try using an event based message bus like rabbitmq or something. Just serialize the messages to JSON. Or fuck microservices. Seriously. You don’t need it. 
There's really no reason to use websockets if your client isn't a browser.
It makes more sense in modern microservices. If you have a hundred developers, some will like Go, some Node, some Python, etc. makes it easy for everyone to communicate. It’s also a nice library that solves a ton of issues like when to reconnect and connection multiplexing (http/2). But you can roll your own. Takes a lot of time that you could otherwise be building the actual services, but that’s up to you. 
Same for Canada
gopl.io will _always_ be a great book.
What specifically is vapid about the post? The errWriter struct is a great way to simplify error handling.
The Go Programming Language is pretty good, but I feel the best resource for go is this udemy course https://www.udemy.com/learn-how-to-code/ Covers a lot of basics and more advanced stuff, he's good at breaking down the more confusing parts into understandable info, lots of good practice, teaches you how to use go's doc sites and packages which is crucial in my opinion. I'm a big fan. When I have time he has a web apps in go course too I want to go through.
So even in this implementation when you comment out the time.Sleep, one worker steals all the work, I just want to understand why?
I believe it's missing a newline: var n int n, e.err = e.Writer.Write(buf) 
Hex and PH4 are nice, but I’ve recently discovered the joys of countersunk self drilling torx screws driven by an impact driver and now I want to use that for all the things. 
[removed]
I think you could override the default model for models.Children so it includes the extra data you want (including an interface{} type if you need that kind of generality). Then you can just add that data to the models.Children value that gets returned. I'm not sure which page here, but try reading the first few pages and you should be able to work out how to create your own custom resolver model instead of using the auto-generated one: [https://gqlgen.com/](https://gqlgen.com/) I override the models a lot.
This is probably a really stupid question because I don't do much android development. If _most_ android apps are based in Java, and _most_ iOS applications in Swift and Objective C, how does someone develop an app in a language not in either of the ones I mentioned. I did a quick search and mostly what I turned up was IDEs and not applications, if anyone has a article recommendation or how to redefine my search, I'd appreciate it. Planning to look at this a bit tomorrow because now I'm interested. 
&gt; I'm in your computer, stealing your n00dz! -- GoLand
&gt; This approach has the benefit of having every error in the chain checked in contrast to Cause (pkg/errors), where only the innermost error is checked That doesn't sound like how pkg/errors says it works: &gt; errors.Cause will recursively retrieve the topmost error which does not implement causer, which is assumed to be the original cause. -- https://github.com/pkg/errors#retrieving-the-cause-of-an-error
You can have systemd or similar set up a "service" to run your executable in the background, similar to how nginx, mysql, or any other service runs. https://www.freedesktop.org/software/systemd/man/systemd.service.html In that way you can toggle the system on/off with `service mycoolapi start`. The other options listed here work better if you're regularly changing the API for development work on the API itself. But if you're API is only built every once in a while, and you're working on front-end kinds of things, set up a service.
He explicitly states he has little grasp: &amp;#x200B; &gt;The last time I was serious about PHP as an app server platform was way back before PHP 5. &amp;#x200B; Sooooo.... why would we care what the author of \`script-v2-backup-live.php4\` thinks?
&gt;is that I'm no just curious. can't you also just add "&amp;" at the end of the command to run in the background? Thanks.
I imagine the work is getting done faster than new work items are enqueued. I think it's cheaper to wake up the last worker goroutine used than to pick one at random, so if it's real fast it will just use one.
Well then you are free to write your own multi-language RPC library and object serialization framework from scratch. Code generation makes sense when it solves complex, time consuming development work. It makes even more sense when that code generation is developed, supported, and used by some of the worlds largest tech firms.
I'm on mobile so I can't expand too much on the topic. You could take a look at https://godoc.org/golang.org/x/mobile/cmd/gomobile or https://github.com/golang/go/wiki/Mobile For Android (as far as I remember) gomobile will build your code as c-shared library and generate the bindings to call them from your Java Code. So in the end it's actual native code that exports your public functions so they are callable from outside, but there are limitations to what types and features of go you can use. If I'm wrong I'm sorry. Been a while since the last time I took a look at gomobile
Yeah, precisely like I said. Cause: only one, the innermost; As and Is: all in the chain. Ofc both stop when they reach an error they can't unwrap.
I agree, this is a great resource, and I also recommend it. I just want to mention there is an updated version of this course at [https://greatercommons.com/learn/golang](https://greatercommons.com/learn/golang)
As someone that has never written one of these, given a small set of weights I would have just generated a slice/array equal to the total number of weights (36 in his fruit example) with the values repeated. `['Banana', 'Lemon', 'Lemon', 'Apple', 'Apple', 'Apple', 'Apple', etc...]`
That's awesome! I'm going to browse through yours to get ideas. This has been a great opportunity for me to see how other folks (especially C++ devs and Gophers) structure programs.
Sorry I didn't say that but the release date is Feb 6, next week.
Thank you, Daigo (the main game designer) would be happy to hear that :-)
Do you have 100 developers?
Go does not need generics. I hear the same argument when I discuss with someone that it is also okay to repeat yourself.
Why do you think it doesn't need generics? It seems like generics would make it so making your own data structures would be a lot less hacky. 
Damn Greeks.
You can use flag package. [https://golang.org/pkg/flag/](https://golang.org/pkg/flag/)
Interesting. I was going through safe casting and checking of Timeout() (and Temporary()) on errors returned by functions from `net` package. It does not look nice at this point (due to additional import and my own wrapper) but works out. New errors package is neater. 
Just an opinion here, but I personally believe that most code is more legible and easier to follow the flow of without generics. A lot of the time the examples people give for the usefulness of generics are extremely simple, and yes in those cases I can see the value in it for things like utility or helper functions. However, I feel that generics encourage people to re-use code when it would be easier to read and understand had the developer just repeated themselves a little. Simply put, I believe Go's strength *is* it's simplicity, and that Go's strive to remain readable even under potentially complex tasks is an attribute not only of the community but of the language itself; and I believe generics have a very high potential to damage all of that to one degree or another. This is all from the perspective of someone who's done a lot of PHP programming, a language which is widely known for how easy it is to write bad code in. In PHP's case, this is possible because the language gives the developer too many options. Even today it takes the developer opting into type safety and coding standards for it to begin to become difficult to write bad code in it.
&gt;However, I feel that generics encourage people to re-use code when it would be easier to read and understand had the developer just repeated themselves a little Are you actually saying code reuse is a bad thing? 
Of course I should have checked out the godocs, thanks I'm going to do some reading.
Try using bufio.ScanLines for in scanner.Split; then output of scanner.Text will be the whole line, and the output of strings.Fields will have the individual words in that line. Something like this: [https://play.golang.org/p/VrzBCoXERVd](https://play.golang.org/p/VrzBCoXERVd)
I'm saying that code reuse *can* be a bad thing, or in other words, copied code *can* be more clear than reused code. This is entirely context dependent, and is certainly not true of every situation. Generics are a feature that have a high complexity overhead. When used in the right situation, they provide reduced complexity and code reuse. My fear is that it is easier to use generics wrong and *increase complexity* only because of code reuse.
Copying code is such a bad practice though. Even if it's less readable copying code makes it really easy to introduce bugs and generally just creates a ton of work for you. 
Again I believe this is contextually sensitive. For example, what happens if you introduce a bug into a generic-powered piece of code. That bug can now propagate to any piece of the code base which relies on the generic; in other words, the bug can spread quickly. I also believe that generics are more likely to introduce bugs because of their complexity overhead. A bug introduced into a generic will propagate out into all code which implements that generic. Copied code, on the other hand, often changes from it's original source. Outside of very simple situations it's very uncommon for copied code to remain identical in 2 different places, and often it's only a small piece of that copied code that remains the same.
Do both
!remindMe 10 hours
I will be messaging you on [**2019-01-29 13:43:58 UTC**](http://www.wolframalpha.com/input/?i=2019-01-29 13:43:58 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/golang/comments/ajaxoa/imdariomergo_mergo_a_helper_to_merge_structs_and/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/golang/comments/ajaxoa/imdariomergo_mergo_a_helper_to_merge_structs_and/]%0A%0ARemindMe! 10 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
This won’t scale down to very rare events (e.g. one in 1 million rare item encountered). But I would consider that to be a fair first stab definitely and then I’d add that constraint to push you towards an answer more in line with OP’s.
I honestly can't believe I'm having this argument, incredible. The fact that copied code often changes is bad, very bad. If you have a generic piece of code that has a bug in it then you fix the bug, be done with it and it's fixed everywhere immediately. If you copy code and change it then when you discover a bug in one part you don't know which other places you copied it will have that bug. You'll then have to find all the places which you copied the code, and if you miss places you'll likely introduce bugs, and the process of fixing it is a lot harder and a lot more likely to introduce more bugs. 
[removed]
There are always trade offs to everything. What if a fix to a piece of code using generics introduces a new bug elsewhere? What's the solution other than copied code? As you said, copied code isn't perfect and obviously is a hassle when a bug comes around but generics are *more likely* to generate bugs. They're more dangerous because they can be used in many different contexts, some of which may be incompatible with the work that the generic code is performing. I believe it is a poor decision to simply make the decision that DRY is the only thing that matters and any instance of copied code is bad. Programming is far more complex and not so black and white; there are some truths, but I believe the teachings of DRY has proven more effective as a guideline than a hard rule.
Please see my comment above and the bug it refers to. If it doesn't seem to be the same scenario as stated there, can you please help us understand it by describing how this happens for you? Thank you.
How would someone make a game like this in Go? What engine or graphics library did you use ?
[removed]
We're using (and developing) Ebiten https://github.com/hajimehoshi/ebiten
I don’t. But I also find it much easier to develop than writing rest endpoints all day. And there’s some things that GRPC does really well. 
[removed]
Background processes started with the "&amp;" suffix get terminated along with their parent shell. This is the reason things like `nohup`, `screen` or `tmux` were created. `nohup` decouples your process from its parent shell thus making it survive when the parent shell exits. `screen` and `tmux` keep the shell itself alive (and thus also all its subshells and child processes) when the ssh client disconnects. I have a tmux instance running for weeks now on a server, along with `mosh` (an ssh auto-reconnect service. tmux and mosh make a ssh session look like a local, always-on shell). I do not deliberately start server processes as tmux subprocesses though. I use Docker containers for that, which I personally prefer to `systemd`, which is another good way to start and maintain long-running services.
I am still ambivalent about generic types and functions in Go. On one hand, they would make some things possible without code duplication, empty interfaces, or—eeek!—ugly reflection (like e.g., a statically typed sync.Map, or vectors and matrices of any numeric type). On the other hand, as Ian Lance Taylor [wrote](https://www.reddit.com/r/golang/comments/akbmzp/ian_lance_taylor_go_intentionally_has_a_weak_type/), "Go in general encourages programming by writing code rather than programming by writing types." Generics bring the concept of "programming by writing types" to Go, for the better or worse. 
Reading the debate back and forth, I think both of you guys are correct, and in-correct. Overall, it all comes down to the situation, sometimes, generics fixes the issue, and sometimes generics can break a lot of situations. Personally had to have 3 seperate implementations for a graphics engine where the geometry was pretty much identical in how it was generated, but had a few exceptions for the other types, it was in this case, we would break the tests and testing every once in a while when a change was made to the generic interface to fix one object type, so in the end, three implementations saved the day, even though you could compare the 3 implementations and the diff was very close to identical. The best thing in this case was you would make a change for implementation 1, and you know very well the others are safe. The opposite is also true too!!
There is a difference between searching Go content and talking about Go, especially in a job interview. 
I prefer 1000 times repeated code that I can reason about that bad abstractions that are commonly found in, for example, java code. &amp;#x200B; [https://www.entropywins.wtf/blog/2017/09/06/the-fallacy-of-dry/](https://www.entropywins.wtf/blog/2017/09/06/the-fallacy-of-dry/) [https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction](https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction) &amp;#x200B;
I usually don't leave feedback but this article got me so congrats, i probably was targeted. :) &gt; Do you think that WebAssembly (WASM) is only used for image manipulation, hard math, or other niche use cases on the web? No ! &gt;Are you still confusing WASM with Web Workers and Service Workers? Who does that ? &gt;Not interested because you think that JS web apps being developed today will still need to be maintained for the next 10+ years? i am interested but i also think that will still need to be maintained for the next 10+ &gt; Do you want to do frontend web development in non-JS languages? I try but i can't get rid of JS even with wasm. &gt; Think of WASM as the Universal Virtual Machine (sandbox), where you write ANY code once, and it runs everywhere. This makes me think of JVM and i am scared. I like to think of wasm like another operating system, wait for it … the Browser !
that argument also works the other way around, since your generic piece of code becomes a dependency of the whole project a change on it can introduce bugs everywhere breaking the failure isolation and making it much harder to maintain.
Problem that having high noise to signal ratio due to unxpressiveness doesnt make it easier to read. It's like chewing on show leather due to imperative style, sure it's nothing particular difficult, just what you read is kinda pointless and could have been expressed in one line without sacrificing any meaningful information. It's also makes it difficult to communicate through code hence damands to litter your code with comments. Go is ok language, good enough on performance, easy to learn, productive in a lot of use cases. But I just find it interesting how Go fans defend drawbacks of the language, namely, by appealing to incompetence to it's userbase just like you did with php. 
&gt;Sadly the last kind of error inspection does currently not work I think you should raise an issue about that in issue tracker. I'm not sure it's not intended behavior.
You can do something like B, but instead of defining the map in one place, use init functions that call a "register" function, mapping a name to a function. This is done all over the place, including the sql package to map database names to drivers. I probably wouldn't recommend C in some cases, as the plugin library has some downsides. Also consider using an embedded language (JS with goja, Starlark, lua, Tengo), or maybe hashicorp's go-plugin.
If you're only having one scraper running at a time, then A seems the way to go. There's no point building up a map if you're just going to pluck one value from it then do nothing else with it. Also C seems a bit hacky compared to A or B
As the scrapers are triggered by API calls (using the standard library HTTP server and handlers) many scrapers could be running at the same time. Approach A is how we have started but we are adding more scrapers every day and the list is growing (~30) at the moment so the code is *ugly* (in my eyes). &gt; Also C seems a bit hacky compared to A or B Would you explain why hacky please? I thought this type of scenario is what the Plugin API was for. Thanks
&amp;#x200B; Define "learn" !? My definition: 1. lookup or google , 2. paste and modify. 3. compile, run and test, 4. optional (if any time left): try to understand . 5. goto Step 1. For looking up (= step 1) I check normally: [https://gobyexample.com/](https://gobyexample.com/) and [https://yourbasic.org/golang/](https://yourbasic.org/golang/) &amp;#x200B; &amp;#x200B; &amp;#x200B;
In that case I'd go u/Bake_Jailey's answer.
Thanks for the tip about hashicorp's go-plugin! That looks like quite a promising solution for us as we grow the scale and complexity of the project. `init` calling a `Register` also is a new idea we hadn't considered... Will evaluate today. 
This is the best way to do it. If you’re going to be spamming it from different api calls, you’ll need to consider synchronization. I would suggest a sync.Pool to instantiate each scraper. And use an interface too, for obvious reasons. 
There are some efforts for running wasm outside the browser, including ports of nginx. https://medium.com/@syrusakbary/running-nginx-with-webassembly-6353c02c08ac
Yeah that seemed to fix it. However I tried it with a different project with an identical structure ( no go mod) and changed my configuration to files. What seemed to do the trick is having GoLand call “go test” rather than try to run the file isogram_test.go. Now I have to figure out how to get the debugger to work!
Version B is how I did it with a project of mine (automation like node red) except i added a global register for it because i needed them in multiple places. &amp;#x200B; &amp;#x200B;
&gt; It also has the productivity and **ease of use** of Python Bit of a stretch to say that. I think it **doesn't** have the ease of use of Python, but it more than makes up for it in not having to use python async io and the performance benefits
Syntax is not as easy to use but if you count everything around, tools, deployment, static checking at compile time, code refactoring, dependency management (with modules), no need to add C extension, goroutine, maintainability... It is actually easier to use than Python even for simple crud app. I currently rewrite a lot of small simple crud app from Python to Go. Not to gain speed, it's just a bonus, but for everything around. It's easy and the result is "confortable". What i found sometime difficult is when I miss a lib. Also to rewrite code that use generic and inheritance. It's difficult to think differently but when it's done the result is quite better, generally more simple.
Great tool, doesn't overcomplicate things.
It doesn't necessarily make it more stable; but updating the go server; switching between physical instances or IaaS becomes way easier. 
Refrain from using plugins. If you are predefining all your scrapers, you are basically building an RPC. Use a map to keep track of the different scrapers. The init-registration model is useful for semi-dependent libraries but obfuscates what is actually happing. Later on, you will regret overusing this model (I did).
To be honest, I wish the std library had refrained from using the init-register pattern. Drivers could be instantiated like this as well: ```go db, err := sql.Open(pg.New(pg.Options..., "$DB_URL") ``` This would have made the instantiating explicit and literally has the same amount of lines of code. A complete beginner would understand what is going on.
Go occupies an ease of use sweet spot for me. Often with Python, especially when using an unfamiliar library, I find myself slowed down by "when I call this, what the heck do I get back, and what can I do with It?". It is a cognitive drag that makes Python generally slower to read and write for me. The tooling is consistently more helpful with Go for answering these sort of questions quickly and directly. That being said, for pounding out scripts using specialized math/scientific libraries to solve specific problems, Python is unmatched
Just know that with hashicorp/go-plugin, you're spawning a subprocess for each plugin. That may become unwieldy the more plugins you use. I've also found that managing their lifetimes is a little bit tricky (loading, unloading, etc), and returning `error` is less obvious given they're not gob encodable. Personally I'd rate using an embedded language above it.
Yeah, if you wanted to rest a single file, I believe you would print to the file you wanted to test and not the _test.go file. By convention, Go’s test files are always _test.go. That goes for Example and Benchmark tests, too I believe. 
Well if you mean what's easy in it? A great API for web servers (what the Creator of nodejs said about it. https://youtu.be/M3BM9TB-8yA) and devops stuff like docker or kubernetes. ( So much so Microsoft is making stuff with it. https://azure.microsoft.com/en-us/services/kubernetes-service/) But I believe until you write some you won't see the magic in it's general API. Like the reader and writer interface. (https://link.medium.com/nnhRThJ6RT) Where you basically use packages and getting other types by the interface inside of a param, you begin to see a very amazing API created. It is reusable, efficient, and easy to read. I think this explains it best. https://tour.golang.org/methods/21 Then there are packages like runtime https://golang.org/pkg/runtime/ where you get low level control of your data to watch for errors, benchmarking, and state of your program. Some people don't like the error handling but I'd beg to differ. Exceptions are great in a small program but not so much in a big one. Even Google thinks so. https://google.github.io/styleguide/cppguide.html#Exceptions Then there is the best parts of readability being #1 and goroutines. Sure other languages can get the job done or go deeper but the point is for big projects. It was created out of frustration of big amounts of code. This "way" of doing things takes away much of the mental load when dealing with big code bases. It also however introduces a lot of figuring out. Mainly because it's new. So let's say just buffering strings into a file. This is not straight forward because you have such low level control. There isn't a general "write" method that does it all. So now you have to find out if you are writing bytes or strings?, how big is the buffer? So you have to cast your types? Does it have spaces in the string? Are their multiple lines? and so forth. You begin to realize quickly there's more then a few ways of doing things and it's not that simple to transfer data the way you want it. But in that lesson you get exposed to many things go has to offer. The many packages io, bufio, strings, runtime, fmt, ect. Sure in another language you can simply use a package and it might be a one liner with a flag but did you learn anything? Did you actually code? Node js there are packages for everything now but you may not have anyway coded and learned much. Many languages are adopting features that I believe go brought to light that others deemed necessary now. Like php stating types in the params also js and c# getting async await. The thing though that makes the language magic in my opinion are those interfaces that allow types to be used by their method on the fly. It acts as sorta a abstract class but with just carrying methods. 
https://www.google.com/search?tbs=sbi:AMhZZismoJi6BFYLK5ULBTA2opb2NY4CaZPlQbuMJZipVLKnV0lFMjZWmAeGrIi52Zi0NUmxlTORGPsG79D5Zf-omncmySM3ScR9eicYzeG02QWubGME5ecLRdMKHxRm9K5hEB95Pj2yMrBgs9XXO2jlqgUd0JlKwrHpg4EV91Hj0VNvL79mMuG9fcXOKcDBHi7HZBw5GzS4JPbcjdWxAgOETgBAaqNGtb6WpxIOvJvgIxvni2uQr7ukO4SHF6ovTgYilZ3mydrrxtTXFLKEKfDDHQK2LFxcb4RYYzyNie5C4kArT2FgJHeHr6d9GsuSHamN9cHPcDhk&amp;site=search&amp;hl=en&amp;ved=2ahUKEwjniqT4hJPgAhWHwbwKHW0yDNIQ9Q96BAgBEBQ
The first website is about not overdoing it with inheritance not generics
HTTP is a great choice for what you’re doing.
https://golang.org/pkg/net/rpc/ I use it to connect a cluster of different services together and it's working really well. I don't know if it's suited for your use case but it's rather simple and straightforward, but If you don't want a constant connection http may be the way to go
One more difference with TOML: the latter supports date and time (and even time offset) values. Dates are rare in configuration but still occur. Time and time offset are very useful.
now export it to web assembly!
https://github.com/cretz/bine has examples which reference the process embedded package, which has those links. Yes, show-libs tells you what to link.
I feel like this quickly went from us having a debate about our stances to you taking opportunities to bash not only on Go but now on me personally. Honestly man that's disappointing, as the conversation surrounding generics is a very interesting one to me. Thank you for the time you spent providing legitimate arguments to your perspective. I think you'll see more conversations like this from the Go community and if you're going to resort to name calling I'd argue it's in your best interest to simply leave it be.
What I meant is if there's a tutorial on how to create a stand alone binary with your library and using mine code
Not exactly a tutorial, but if you have `$GOPATH/src/github.com/cretz/bine` and `$GOPATH/src/github.com/cretz/tor-static` checked out and you follow the README at https://github.com/cretz/tor-static to build tor-static, then you can go-build the simple example at https://github.com/cretz/bine/tree/master/examples/embeddedfileserver to see how it works.
Gotcha. I'll try that out. I built `tor-static` and had no problems there, so I'll try to build the example and see what happens.
This gives me hope haha. I'm in my second semester of school working towards a CIS or computer science degree. In my first semester I learned python. Now we are learning Go. I feel like I was spoiled by the ease of use of Python, though it was difficult sometimes to try and research how to do things. 
true, I'll add it shortly to the comparison
I just wish it worked on windows.
Unfortunately not possible using Pixel as of yet. For a 2D game library with WebAssembly support you can look at Ebiten: [https://github.com/hajimehoshi/ebiten](https://github.com/hajimehoshi/ebiten)
For sure. Make your own. It’s not that hard. Most frameworks are massively bloated for what they provide anyway. 
With need for middleware like authz and authn, is it still better to do it using these frameworks ? 
That's the exact modus operandi of SAP: build shit, make devs pay for training and certificate, make a technology that suck so much that you are simply stuck with it.
The Rust side needs more turbofishes
Readme.md It’s what most git repos use and has some decent formatting. When someone cracks open the repo on github or whatever, you have a ton of usage info related to the application or library that’s often difficult to explain in godoc. 
Name calling? Can you state the single name being used? How about you reinvestigate your train of thought before trying to play some sort of victim here. It is you who suggested that Go unexpressive syntax is beneficial as it supposedly prevents messy code implying that if that was not the case gophers would write it such. And it's you who equated that messyness to php. When in fact modern day php is very clean. "Disappointed" my my. 
On the flip side, I personally find Go *easier* to use than Python. I've spent years working professionally with Python and it's a great language, but I also regard it as virtually unusable without a good linter, and large projects seem to often have dark corners that bend the language in ways that absolutely befuddles autocomplete engines.
&gt; That being said, for pounding out scripts using specialized math/scientific libraries to solve specific problems, Python is unmatched That's an important quality--but it's not an *inherent* quality of the language. If those scientific libraries were also available for Go, those scripts could be pounded out just as quickly in Go. Python is way ahead of Go in that area right now--and realistically it probably always will be just from momentum--but it is not *necessarily* true that it will always be ahead.
*Scraped
Has anyone seen an explanation of why it’s not done this way? Interfaces are a core part of Go so leaking driver.* wouldn’t had been such a big problem imo (and as you said a beginner would understand what’s going on). Plus: it would make database-specfic method access so much easier, (Cf the suggested roundabout workaround in https://github.com/golang/go/issues/29835)
Interresting idea. I will try this out in the near future.
[removed]
The footnote 1), 'this is still not correct'. Anyone solved that?
Depends on what you mean by application level documentation. People do use godoc to produce documentation for command binaries: https://godoc.org/golang.org/x/tools/cmd/benchcmp For documenting command line parameters, a number of the common libraries include support for having the program itself produce a usable set of documentation in response to --help or a similar command (though this is usually based on documentation in the code itself, not parsed from comments). In fact, even the base library's 'flag' package sort of does this - it constructs a 'Usage' message that is printed when there is an error parsing flags, and while it does not inherently respond to --help or -h, it does include a simple way to attach a response to them. 
Can someone kindly explain me what's the point of Go wasm? From where I see it looks more like interesting curiosity. To compare to something, much like NodeOS. Interesting experiment of engineering but what's the preferred use-case exactly? I mean if you're going for performance, when you go C++ / Rust, the latter having exceptionally well developed toolkit to do it. 2-3 times faster and while requiring approximately 30% less memory depending on multiple bench marks. Now if you believe in picking the right tool for the job, the choice seems to be quite obvious here. Not only that, Go due to necessity to pack it's runtime with it, ends up in bloated module sizes of 1,5-2 mb, which is really unacceptable at front end, and even if Google decides that Chrome will support it, you will still have other browsers businesses needs to support to make it irrelevant. Another case as I see it more calibrated towards the future when wasm will allow easy ways to manipulate with DOM directly. But that doesn't seem to make much sense either, imperative style languages are pretty awful at doing UI's. I mean, why React is so popular? It embraces declarative / functional patterns which lends themselves immensly when it comes to UI's and you can be dead sure if frontend development opens up to other languages, the ones which will be able to adapt to the same patterns and improve on them, will reign supreme in that area. Through 7 years we figured it out, and painfully remember how unfeasable and painfully unmaintable imperative code is in the frontend. Now the post at hand addresses Electron. As I suppose a way to easily port Go as native application in different OS'es? And that's the only place I'm not as much aware. Can someone enlighten me please? What's the benefit?
Agreed -- it will stop the churn in the central code. You just add the new scraper's code and that's it.
Hey, man! Thank you for this! I purchased his course yesterday and I’m almost halfway of it. It’s really noob friendly. I’m enjoying the lessons so far and I became a fan too.
Glad to hear it! 
The community thinks chi is fine, and the standard library is also fine and sufficient. (gin also fine).
For gRPC, take a look at https://grpc.io/blog/loadbalancing
Thank you very much for the explanation.
Thanks for the suggestion 👌
&gt; it's slow to develop, sure, This is exactly my use case: I _already_ have the go code working and tested, raw performance is _not_ critical and given it's an electron app, download and runtime sizes are a marginal issue at best. I agree with your points on DOM manipulation: react feels much better than trying to cram your DOM-updating logic in another language via wasm.
What s your email? 
Came here to say this. Lots of balancing options. 
Title/Name was confusing for me. Thought this was about the [long-lived](https://en.wikipedia.org/wiki/Scanner_Access_Now_Easy) (1996) [Scanner API](http://www.sane-project.org/) also named [SANE](http://tldp.org/HOWTO/Scanner-HOWTO/sane.html)
In what way do you consider TOML an ugly format?
Is this hatred driven development?
&gt; Go makes it easy to create safe, reliable and efficient software. Go is very much a "get shit done" language, but "safe" really isn't an adjective I'd use. Rust is safe. Haskell is safe. Go is pragmatic; the type system is pretty lax _by design_ (there was just an article about this either here or on /r/programming). Just having static typing, GC and channels as primitives doesn't make it safe. I really don't get where this "Go is a safe language" thing comes from.I mean, it's safe compared to dynamically typed languages, but that's not saying a lot. And I'm not saying this is necessarily bad, i just think it's weird people think Go is "safe"
Really curious how this works. What contract does someone have to implement for creating your own expressions etc? 
I like it. I've seen lots of attempts to do better than current options, and this is one of the few I'd consider using.
ooops, wasn't aware of this project.
&gt;Scraped Thanks
sorry, ugly wasn't necessarily the good word, but we had very hard time using TOML (like for large traefik configuration files), it's not very straightforward and his \`\[\[array\]\]\` and \`table\` syntax feels very weird. &amp;#x200B; Furthermore it has some flaws which discard it has a serious configuration format like [a] suba = 1 [b] subb = 2 # ..200 lines [a.other] c = 3 if your are not attentive, you can end with really inconsistentfiles, which is hard to debug, while in SANE you have no other choice than to declare `other` in the same block as `suba` a = { suba = 1 other = { c=3 } } b = { subb = 2 } Or other things like allowing both tabs and spaces as whitespaces which cause a lot of pain for users who does not configure their editor correctly. Or the hazardous indentation style, while as SANE is `{` based, you can easily apply tools like linters / auto indenters...
Maybe it’s just the fact that Golang doesn’t give you pointers to shoot yourself with?
It does give you pointers, though.
Not the buffer overflow kind.
What makes a safe language then?
I feel you. [Naming things is hard](https://martinfowler.com/bliki/TwoHardThings.html)
He is talking about type safety. In that, go comes with some sort of type safety, because its statically typed, but you can easily make it not really type safe anymore by using interfaces and concurrent go functions.
but they're the best kind!
Thanks for the reply. That's quite a number! What host OS are you going to use, if you are going to use Kubernetes?
Yeah, it's just that I've encountered a lot of people who seemingly hope for "fix" the frustrations we have in UI development. And while at first it sounded somewhat plausible, after witnessing how C# implementation, known as blazor looks like it dawn on me that it's not javascript people are really having big trouble with. But UI development in general. And that.. well, that ain't gonna change no matter the language unless we experience some profound paradigm shift, which can only probably be brought by change in hardware - namely gadgets people use. View libraries like react with all it's faults is probably the most ergonomic way to do UI's, that's why Blazor imitates it, and rest will probably follow. Question is that some languages syntax won't make development in that pattern easier. It's not just Go, many languages seem quite unfit in their current state. But I'm getting ahead of myself. What other ways there are to write desktop Go applications at current state of things? Recently I've seen a job posting in my area, looking for Go developer to develop desktop applications for Ubuntu which left me wondering, how it's being done in 'idiomatic' way so to say.
It is an interpreter, the user only needs to write the "script" on the struct tag
Wouldn't this be solved by generics?
I bet there's a way or two to fool the compiler out there
I ended up using gRPC. The performance is super good, and having protocol buffers as the wire format is a major gain in my personal opinion. I’m currently using gRPC-gateway for JSON endpoints, but working towards gRPC-web for browsers.
Which timezone?
It’s really easy to build middleware into the standard library net/http package. Go does this with HTTPHandler wrappers. 
Go is a compile-to-native language that is safer than C and C++. That by itself is probably good enough for me to call it safe. I can understand how if your background is mostly Rust and Haskell that might be unsatisfying. Some other concrete notes: many people will cite the error handling patterns in Go as a reason it’s safer than typical C# or Java code. Many people will cite the requirement for explicit size casting on number types as safety. I was hesitant to accept this myself, but after translating a few personal projects from C# to Go and discovering some bugs I didn’t even know I had when the Go compiler complained about things the C# compiler quietly allowed (assuming—incorrectly—that I knew what I was doing), I have become a definite convert to the “Go is safe” camp. 
Sure, Thank you Also, PR's for the same is appreciated
I got really excited but I cannot use it in development. I wished it used openCL instead of CUDA. 
Upvoted for assumed sarcasm. 
I just thought I'd let you know that this has stuck with me ever since, and I'm now starting to migrate the application over to this model. Wish me luck ;)
Load balancing is difficult. I wrote about it in my article on consistent hashing: https://medium.com/@dgryski/consistent-hashing-algorithmic-tradeoffs-ef6b8e2fcae8#4e8a
This might be a stupid question but still. How does one "route" some requests to different server with gRPC. With HEATOS it's simple.. You provide a different link which the app then follows.
I get a parse error in my head every time I have to parse the [[foo]], [a.other], I find Yaml's basic syntax which is in 99% enough for configurations easy to read. Now sane is interesting but I'm not convinced yet to switch..
This is already ok https://play.golang.org/p/ZqrQPasLLkZ Left for you as an exercise for finding how this would work ;)
https://play.golang.org/p/DAUwn-sG4KN Slices are already pointers. No need to define a method on a pointer to a pointer when a method to a pointer works much simpler. https://research.swtch.com/godata
Is there any specific reason to using a receiver? Feel like you could make it a bit easier to read by just passing in the slice of thing as a value. [https://play.golang.org/p/pILUPkfbJyB](https://play.golang.org/p/pILUPkfbJyB)
On mobile. Bad formatting. You’ll get the gist. type things []*thing for _, item := range t {} Now item is a pointer to the thing. 
This feels like it would be much easier if you defined an array of references to the objects themselves instead. type things []*thing func (tSlice things) updateAllValues(newValue string) { for _, t := range tSlice { t.Value = newValue } } &amp;#x200B;
Thank you for clarifying. I was not aware of the traps that a seemingly simple format like TOML can set. Guess I have to give SANE a closer look, esp. as an alternate config file format for my CLI package.
Not sure how to understand your question. Where do you see any hate?
Agree on the "fair" bit. Worker pools are only useful if you're handling a lot of slow tasks. There's not really any gains from using a pool if your tasks are completed nearly instant, it's just overhead.
What's the appropriate way to append to the slice? This doesn't work &amp;#x200B; \`\`\` func (tSlice things) add(item thing) { tSlice = append(tSlice, &amp;item) } \`\`\`
I would try running it before posting. 
One part of it is type safety, as /u/littlebluebrown mentioned, but languages can give you other tools to write safer code. To use Go as an example, I think channels enable safer concurrent programming as they make it harder to shoot yourself in the foot with unsafe concurrent modifications. One thing about goroutines that I find unsafe is that you don't get any sort of "handle" to them when you spin them up, analogous to eg. the Erlang process ID that you get back when you start a process (that are closer to goroutines than actual OS processes, i.e. they're green threads.) This means that it's harder to build for example supervision trees (so goroutines that watch over other goroutines and restart them if they keel over etc.) in Go, and it's easier to accidentally leak goroutines. This can (and has) been worked around with "userland" solutions like this package's [`ConcurrentExecutor`](https://github.com/modern-go/concurrent#concurrentexecutor) or [tombs](https://github.com/go-tomb/tomb), but it'd be ideal if this mechanism was built into the language (like in Erlang/Elixir). Type safety is definitely a part of safety, but there's other constructs as well that can help.
My point sort of was that if the best you can say about a language is that "it's safer than C/C++", then it's not all that safe. Don't get me wrong, I'm not saying that Go doesn't have features that make it safer than C(++) or even Java/C#, but I'd still say that claiming it to be a *safe* language is stretching it a bit. I gave an example related to goroutines [in another comment](https://reddit.com/r/golang/comments/al3hz5/_/efc7iw7/?context=1). I actually don't know Rust or Haskell all that well (although I do know the basics of both), just that they're – with Ada – languages I'd consider calling safe.
*Everything* can be solved by generics. This includes world hunger, finding that other damn sock, and making dinner when you get out of work after 8pm.
Won't works as well. It has type "pointer to the thing" but in fact item will be a local copy. 
I'm not sure what the rest of your code is, but it seems to work fine for me. [https://play.golang.org/p/reyraHLm2AU](https://play.golang.org/p/reyraHLm2AU) type things []*thing func (tSlice things) updateAllValues(newValue string) { for _, t := range tSlice { t.Value = newValue } } func main() { tSlice := make(things, 0, 2) tSlice = append(tSlice, &amp;thing{"1", "Value1"}) tSlice = append(tSlice, &amp;thing{"2", "Value2"}) fmt.Println(tSlice[0].Value, tSlice[1].Value) tSlice.updateAllValues("hello world") fmt.Println(tSlice[0].Value, tSlice[1].Value) } &amp;#x200B;
Yeah, talk about marrying the architecture. OpenCL would have been a better alternative or use both. If miners can implement both, Uber should have been able to as well.
In a `mocks` package, as suggested in the Standard Package Layout article: https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1
Away from my codebases :D. I usually prefer fakes or inmemory-implementations. For error handling tests I write a wrapper for the fake/prod instance and return an error that way. However, when absolutely inevitable it's a subpackage to the package that it mocks. e.g. `db` and `db/mockdb`.
I think I'll be staying with any version of Go that doesn't include this...
I've written a couple of small apps using GTK 2. I'd say that desktop, UI-heavy apps are still an open problem for go.
Please, why not JSON5? A good JSON5 parser and the "flaws" of json are gone. Even if that isn't good, I've been using this project for config files: github.com/DisposaBoy/JsonConfigReader 
Tests may import between themselves, so that is incorrect; mocks however are useful for users of your library as well, so you want to put your mocks in a nested directory, in a package named mock. ``` ... import "github/my/lib/mocks" func TestSomething(t *testing.T){ db := mock.NewDB(t) 
I am not sure. There are some weird quirks in the earlier code of the std lib. After all, even Go takes years to fully master. 