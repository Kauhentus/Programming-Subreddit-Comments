Depends on what you're used to. Most of the "small" servers I run stuff on are 24 core with 48G of RAM.
I implemented an [mmapped minimal perfect hash table](https://github.com/alecthomas/mph/blob/master/README.md) for similar problems. It might solve your issues.
Yeah that's also a really great idea. It strikes me as particularly good if you're having trouble getting an index function from your ID to a slice offset. In my case, most of my ids are just strings, so I use a simple string interning approach. (And this is really only appropriate because the size of the data set is due to doing some computation on *all pairs* of data items, so the storage requirements for string interning are modest.)
When we wrote SmartyStreets' auto complete service in Go, we had to figure out how to implement the functionality of a prefix tree (trie) and have it fit in just a couple GB of memory. The data set was several hundred MB on disk, and a trie or a map uses a lot of pointers under the hood. 64-bit pointers are 8 bytes. That's huge. We ended up implementing a fast typeahead lookup by using a large array with a special index (kind of similar to a perfect hashing table). Every word we store in memory is de-duplicated and we save several GB of memory. Plus, most lookups are completed in under 1-5ms. It takes some significant time and space to build the index but it's quite optimized when done. This is just one way to do it; it just depends on your needs and your data. At a low level, OSes use multiple levels of paging tables to manage virtual memory. These tables are just arrays, and have basically no overhead. The key is multiple levels of indirection and de-duplication. Maybe that'll help give you some ideas. (When I say we use arrays, I actually mean slices.)
The way virtual memory works, there will _always_ be a space in virtual memory to put it assuming there's enough physical memory on the system: https://en.wikipedia.org/wiki/Virtual_memory .
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Virtual memory**](http://en.wikipedia.org/wiki/Virtual%20memory): [](#sfw) --- &gt;In [computing](http://en.wikipedia.org/wiki/Computing), __virtual memory__ is a [memory management](http://en.wikipedia.org/wiki/Memory_management) technique that is implemented using both hardware and software. It maps [memory addresses](http://en.wikipedia.org/wiki/Memory_address) used by a program, called *[virtual addresses](http://en.wikipedia.org/wiki/Virtual_address_space)*, into *physical addresses* in computer memory. [Main storage](http://en.wikipedia.org/wiki/Main_storage#Primary_storage) as seen by a process or task appears as a contiguous [address space](http://en.wikipedia.org/wiki/Address_space) or collection of contiguous [segments](http://en.wikipedia.org/wiki/Memory_segmentation). The operating system manages virtual address spaces and the assignment of real memory to virtual memory. Address translation hardware in the CPU, often referred to as a [memory management unit](http://en.wikipedia.org/wiki/Memory_management_unit) or *MMU*, automatically translates virtual addresses to physical addresses. Software within the operating system may extend these capabilities to provide a virtual address space that can exceed the capacity of real memory and thus reference more memory than is physically present in the computer. &gt;==== &gt;[**Image**](http://i.imgur.com/WyIwggo.png) [^(i)](http://commons.wikimedia.org/wiki/File:Virtual_memory.svg) - *Virtual memory combines active RAM and inactive memory on DASD [NB 1] to form a large range of contiguous addresses.* --- ^Interesting: [^Trinity ^Broadcasting ^Network](http://en.wikipedia.org/wiki/Trinity_Broadcasting_Network) ^| [^OpenVMS](http://en.wikipedia.org/wiki/OpenVMS) ^| [^Paging](http://en.wikipedia.org/wiki/Paging) ^| [^Operating ^system](http://en.wikipedia.org/wiki/Operating_system) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cfybnhg) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cfybnhg)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
The function you pass to sort.Search() is of the wrong form. Look again at the example at http://golang.org/pkg/sort/#Search . You will need something that looks more like your implementation of Less(). 
Yeah, I've been considering that. Might steal your idea.
Good idea! Done - https://godoc.org/github.com/apexskier/httpauth
How about either redis or a memory mapped trie? 
But if golang runtime cannot make use of virtual mem wisely, it will request more mem from os. So, most physical mem taken by golang runtime might be wasted.
I am puzzled after I know even slice does notwork. The pure data should be around 0.5 GB in mem, but "top" tells me it needs more than 6GB. (golang just panics around this time) Is there some hidden cost of slice?
A nitpick, but "epoch time" means the start of Unix time, which is 00:00:00 UTC on 1 January 1970.
I think you're probably overdoing it if you're creating separate packages for all these structs. Without some example code, it's hard to give you a definitive answer. I'm assuming you're creating a web application and that one of your main goals is high scalability. If you have data that you want to represent in memory, a struct is a no-brainer. If you have functions that will directly manipulate that data, it should probably be a method. If you have a function that will access that data, it could be a method. It's reasonable to put these functions and the struct in a dedicated file, since all of that code is related. In other cases where you don't necessarily have a single data structure that you're manipulating, a struct might not be necessary/appropriate. You should probably keep closely related code in the same file, and slightly more loosely related code in the same package. Exactly how *related* it should be is up to you. But ultimately, you don't need a struct to do all of your encapsulation, a package can do that for you. Typically, having a package with only one struct and no functions (other than that struct's methods) is not the *Go way* of doing things. However, there are no hard rules about this type of thing. Try it out without a struct. Go case by case; if the code is centered around some data structure, then methods would make sense. If not, and the namespace is getting crowded, use a package.
Very nice article. I have always thought that learning a language should start from testing.
Go isn't exactly object-oriented, so don't think in terms of classes and inheritance. A struct's un-exported ("private") fields can be seen and changed by methods and functions that don't receive that type, as long as they are in the same *package*. So think instead in terms of *package scope*. Use as many files as you need or want to in a package: it's all the same to the Go compiler. My preference is to keep each type, along with its methods, in its own file. If the type has no methods defined for it, then I try to just define the type in a file where it's used. That it's in the right package is the important part, though.
Read the code for the packages in the standard library. It's the best way to get a sense of what real-world idiomatic Go code looks like. https://code.google.com/p/go/source/browse/src/pkg/ Get a sense for when interfaces are used effectively, when structs are used effectively, how they're organized into files and packages, how they're tested, etc.
&gt; I put in its own file That's not OO. It's just a design flaw in Java.
 type Vehicle interace { Go(Place) Load(Item) Unload() Item } type Car interface { Vehicle Honk() string ChangeTire(int) } type Fiat interface { Car Breakdown() }
Nitpick: [there are no unbound functions in ruby](http://banisterfiend.wordpress.com/2010/11/23/what-is-the-ruby-top-level/)
If you're still really stuck and our advice didn't help with that, then I think it's time to try to come up with some minimal example that reproduces your memory usage and show us your code. Also, I don't know if you're storing pointers, but keep in mind that they are a whopping 8 bytes on 64 bit machines...
How bout that! Ford implements the Fiat interface!
the code http://play.golang.org/p/QYc2EwBmCS I used struct in slice not pointer to struct
One of the joys of go, the std library is so approachable in readibility and is a wonderful source of good design.
read [this post on interfaces](http://jordanorelli.tumblr.com/post/32665860244/how-to-use-interfaces-in-go) which maybe I wrote
Ha! Already found and read this, maybe. Great post. 
Why is this thread marked nsfw? Lol
While its annoying to *have* to separate classes into different files, I find that in Go, people tend to pack too much into 1 file. As a beginner of go, I am frequently confused as to whats actually going on in each file (usually have several structs, interfaces, and functions, all spread out around the file). 
There are already responses to the putting structs in their own package, so I'll comment on file structure for ONE package. The beauty about the Go package system is that all files under that package get compiled into one "class." This allows you to structure your files however you see fit. I do warn you though, keep readability and productivity for the public eye in your mind when creating your files. 1000 tiny files is no better than one humongous file. My projects are fairly small, so I separate my packages into: structs, conts, functs, main logic. Find a style that fits you. 
Strict mapping of types to files may not the way to do it, but I do find that the Go community is far too eager to multiplex many concepts into a single source file, largely, I think, because of the inadequate relationship between packages and the `GOPATH`. This is my biggest beef with Go. It seems to fight you on organization of concepts with even stronger opinions than Java has (and that's saying a lot). I have to choose: 1) Pollute files with multiple loosely-related concepts that make sense on their own, in separate files; 2) Pollute a package directory with dozens of files; or 3) Include packages that implement components of the application, which forces either a fully qualified import that breaks forking, or a relative import that breaks `go build`. These all suck. (1) Makes it slower to grasp the extent of a single type or other concept. (2) makes it harder to locate one; and to understand the relative importance and the hierarchy of different concepts; and (3) sucks because forking on github and `go build` are both things I'd like to be able to support.
For some reason I feel like this problem is like a modern version of the first problem in "Programming Pearls" where someone needed sort a list of 7 digit integers. It turned out that a more thorough explanation of what was needed and why resulted in a much simpler and faster approach. Can you tell us more about your problem domain? It may be that a much simpler approach is possible in your case. Why do you need so many keywords, and how are they chosen? Is there a difference between keywords and labels? Is the number of keywords actually variable? Do the documents need to exist in the same map, or can they be split up? As an aside, rsc is in the acknowledgements in the 1999 edition.
Go is absolutely an object-oriented language, however it emphasizes [embedding](http://www.drdobbs.com/open-source/go-introduction-how-go-handles-objects/240005949) rather than inheritance. 
doesn't turning them into a struct work? type K struct { docId int keywordId int } and then... m = make(map[K]int) m[K{1,2}] = 3 
Virtualization and JITs are completely unrelated. Virtualization causes overheard which will affect any code regardless of whether it was statically compiled ahead of time or JITted.
Your package implements a map[[]byte][]byte. Serializing uint32 and uint8 into strings can solve the problem, but it would be inefficient both memory-wise and CPU-wise. Maybe you can expand your package to implement map[KeyInt]ValueInt where KeyInt and ValueInt are integer types defined in your package, whose definitions can be replaced by users (by uint32 and uint8 in this case).
In case you haven't noticed, OP says "Unfortunately, with 8Gb of memory, the data does not fit in it." and a single entry is 178 bytes + map overhead. It's clearly *much* more than 100 entries.
Probably the overhead of the map implementation in Go.
The OP said each line was ~30 keyword/count pairs, being kept in a map[uint32]uint8. That was the structure I was attempting to replace.
Try this article http://attilaolah.eu/2013/11/29/json-decoding-in-go/
What I did in a case like that is using 2 structures, an array and a single object and run json.Unmatshal twice: first using the object as the destination and then the array of structs. One of them will have the correct value/s
For the record, the structs in Go are *not* packed. On amd64, Entry will use 12 bytes. In addition, in case you have too many slices, beware of append: each time it allocates, it will double the underlying slice (cap), whether you use it or not. In terms of memory usage, it will be better to use a single slice per all keywords, counts, labels and ids. This way, you can also use mmap straightforwardly as well (one file per slice, of course you can choose to keep some of them in memory instead of doing mmap), and don't need to worry about memory anymore. You can also consider merging keyword and label into a single 64-bit value.
I'd call your attention to json.RawMessage; if you use that, you only have to unmarshal the part you're not sure about twice, and for that matter if you can tell just by the type you can even examine the first byte of the JSON to see if it is a `[` or a `{` or what. (JSON is sufficiently specified that that is safe, even if it feels weird.) If you're doing a little tiny thing double-unmarshaling is no big deal, but if you've got something larger this may be helpful.
I think the implementation would be pretty straight-forward: for multiple queues, group the queues together in their own `select` blocks, by priority. // Top priority select { case msg := &lt;-queue1: ... case msg := &lt;-queue2: ... default: break } // Medium priority. select { ... default: break } ...and so on, and so forth. EDIT: Ohhhh, sorry, I re-re-read your comment. Hmmm...weighted work requests. I may need some time to stew on this, and I will see if I can fit in some time to write another blog post. 
We had the same problem. We create a single structure for each call with each potential structure that could be returned embedded with the json tags. Then we run that through a single json.Marshal call or through a single mapstructure package decode call. Then we check to see what was populated by the marshal or decode. It works really well.
One great resource for how to manage packages and stuff, ironically, is the book The C++ Programming Language. Its introductory stuff to namespaces and abstraction in the beginning of the book are pretty solid, even if the language itself is an unholy mess.
@scoith What do you mean? Like a data source?
You could concatenate the two `uint32`'s and just use a `map[uint64]uint8`. That way you're only paying the map overhead once. Alternatively, use a `map[uint32]*[]struct{keyword uint32; count uint8}` if you need to be able to enumerate by the first key. I use a pointer to a slice here because it allows you to append to the map entry without reassigning it every time. e.g. entry, _ := table[key] if entry != nil { *entry = append(*entry, item) } vs this for the non-pointer to slice version entry, _ := table[key] entry = append(entry, item) table[key] = entry
Some other fun finds: 1) If an artist, album, song, etc has an all-numeric title (e.g. Black Sabbath's "13"), it's returned as an integer. Have to add more type switches to convert these properly to strings as they should be. 2) There is one instance where when a track is not playing, the API returns an empty string ("") instead of an empty object or collection. Not exactly a pleasure to work with in a statically-typed language.
If he knows the maximum number of keyword/count pairs, he could also specify the capacity of the slice, to avoid growing it too far.
Ah, I see, thanks for the clarification.
I think that would unnecessarily complicate the interface (if Go had generics it would of course be much simpler).
I had a similar problem to this a while back - If you don't mind some shameless self-promotion I done a blog about it: http://mattyjwilliams.blogspot.com/2013/01/using-go-to-unmarshal-json-lists-with.html. The summary is you can use the json.RawMessage type to delay the evaluation of the musicFolders structure and use type assertions to get you the rest of the way
Does we have access to the Android API with this? Like using wakelocks. Are the APK huge? Is a hello world app like 5-10 megabytes?
You can convert the integers to their binary representation using the [binary](http://golang.org/pkg/encoding/binary/) package. This will have no memory overhead.
obj-c integration coming 1.3 should open up iOS/OSX cocoa API access. Can't wait.
This looks interesting. Has anyone used it and if so, could you share with us your thoughts on it?
It doesn't seem to have any integration with the Android apis, just low level drawing and input
People who think that Go is not object-oriented haven't really grasped the paradigm, just a specific view of it from another language's perspective.
I've had this idea for a while now, but I finally had the time to work on my Subsonic client library (https://github.com/mdlayher/gosubsonic) and make it happen! This is an experiment for me to learn more about using FUSE with Go, and so far, so good! When you pass the appropriate flags, subfs will connect to your Subsonic server, and expose it as a read-only FUSE filesystem. From here, you can browse the directories, and perform filesystem operations to pull audio files from Subsonic. Let me know what you think, and if you find any bugs or have any ideas for improvement! I really appreciate your thoughts!
No idea, but it's not anymore.
Isn't pointing your import to a git tip something you're **not** supposed to do in anything but toy code?
As a Rubyist, I miss version numbers for dependencies.
Do you have more info about this? Not trying to be argumentative—I'm still a Go noob, and I've yet to see anything saying not to do that. I'd like to learn if I'm doing something wrong.
You're not doing anything wrong. It's just common sense. By using *github.com/foo/lib* directly, your code will work fine until they **delete their repository**. This is okay for toy code but for production code you should vendor dependencies or clone them to a repository you maintain. In most cases repositories aren't deleted. Instead the library maintainer may make changes that alter the behavior of your code or break it outright. Go doesn't provide a method to import a specific commit or tag automatically. However there [are many tools](https://docs.google.com/document/d/1k-3mwBqAdTIKGcilWZPuKSMy3DWtfNRFDs9o98lcwHY) aiming to solve this problem.
If you have some websites to suggest, please send the suggestion.
https://github.com/beego/wetalk/tree/master/modules/mailer
Thanks for the link. Anything for Martini? I am already using Martini in the webapp.
Can't write much now but the general process is not really language dependent. Typically you have a URL that looks like this, http://yourwebsite.com/confirm-email?token=abcfbcffbabcfcfbbcfaa282bfc8 In your application when request comes in to that URL you grab the token value and check if it is valid by looking up the relevant table in the database. The table might look like this, user_id, token, date_generated, date_expires, date_used 1, abcfbcffbabcfcfbbcfaa282bfc8, 2014-03-12, 2014-03-14, NULL When the link is viewed you must invalidate the corresponding token. user_id, token, date_generated, date_expires, date_used 1, abcfbcffbabcfcfbbcfaa282bfc8, 2014-03-12, 2014-03-14, 2014-03-13 The token is of course generated randomly at an appropriate time such as after user registration form is submitted. An alternative approach is to create some sort of deterministic hash using the user data and use that as the token to avoid having to store tokens. But I highly advise against that particularly for more sensitive stuff, sometimes you can get away with that method for a simple "unsubscribe" functionality. Things to watch out for: * Token must be long (particularly if for pass reset and the like), I'd suggest 24 characters case-sensitive 0-9A-Z * As soon as the link for a token is viewed, it must be marked as used (regardless of the outcome) * Token should have some expiry date, you can adjust this to appropriate value to not annoy users, and depending on the sensitivity of the application, email validation could last 21 days, but pass reset should probably last less than 72 hours. * Be careful to ensure that the token column is unique across the table that's as much as I can think right now, good luck
Thanks, it will get me started to see what I can do. Thanks!
Check out this official video by the Go authors: http://www.youtube.com/watch?v=XCsL89YtqCs
My only gripe with Golangs JSON package is that you can't directly import into an array type object without creating a struct. But that is what you get with a type safe language.
This is an excellent article, especially with regards to how it handles `interface{}` and type coercion.
If you can process the POST data, you can use my [```email```](http://github.com/jordan-wright/email) package to handle sending the email easily.
A language-independent tip: You can encrypt the email address into a confirmation email token. When the user clicks the email confirmation link in their email, your server can decrypt the confirmation token into the original email. Wala, no database!
I guess my perspective is that *even* the toy code gets a package name as if it were in a published repository.
This is why we commit our entire GOPATH for each project. It is annoying, but the safest way.
http://play.golang.org/p/ZgqNX3J-zR Works fine there.
It's when dealing with consuming API's from the web. So therefore, I must define a struct for it. 
In JavaScript I can do: var obj = jQuery.parseJSON('{"name":"John"}'); alert( obj.name === "John" ); To be able to do the same in Go: type Person struct { Name string `json:"name"` } var person Person blob := []byte("{\"name\" : \"John\"}") json.Unmarshal(blob, &amp;person) fmt.Println(person.Name) And once you get into different API calls, it becomes combersome to create more structs. 
&gt; state is mutable by default I've been thinking about this. In Go, by default arguments are call by value. To use the same object, you need to use *. It's not a lot, but it is something. 
ruby basically does map[string]interface{}-style decoding, into hashes, arrays, numbers and strings
http://play.golang.org/p/CJP40pqhRr var person map[string]interface{} blob := []byte("{\"name\" : \"John\"}") json.Unmarshal(blob, &amp;person) fmt.Println(person["name"])
This is quite old news. As put elegantly by the Go authors: &gt; Do not communicate by sharing memory; instead, share memory by communicating. http://blog.golang.org/share-memory-by-communicating Also http://talks.golang.org/2012/concurrency.slide#1 http://talks.golang.org/2013/advconc.slide#1 
Can you elaborate a bit more on that? Are you proposing, say, to store all keys into a single []byte and pass the sub-slice each time? I'm not convinced about this: we would then be storing an *extra* 8-byte hash per 4-byte integer, which is 8-bytes overhead per uint32. The efficiency is even worse for uint8. Further, len, cap and pointer used for each slice (both for key and value in the Entry struct), meaning further extra 48-bytes. Not to mention the CPU overhead, of course.
Fair enough, but in that case, it definitely won't solve OP's issues.
I think it is bad design to have a program that concurrently accesses a sensitive resource. The developer should know what parts of his/her resources are mutex, and not allow concurrency there. At least Go gives you a choice to make those decisions in a low-overhead way. No language can mitigate a flawed program design.
This is pretty cool and quite possibly may be of use for me. If your systems running halfshell have ram to spare, consider using Varnish in front of it. While cloud front can and will cache them, there are 30-some locations that may need to request each image. 
Quite possibly. I did a lot of self-dev work in node before finally switching over to Go. 
&gt; The simplifications and fixes made possible in the runtime by assuming Windows XP outweigh the few potential uses. I would be very interested to hear more about the benefits. Maybe some before and after benchmarks, or a write-up about the simplifications.
I have tried a bunch of them, but dumped them all for sqlx. It is simply the right trade off IMHO. 
take a look Beego orm http://beego.me/docs/mvc/model/overview.md
I expected and found: &gt;generics &gt;function overloads I don't get it, why is there such a huge demand for these? I've programmed all sorts of things and only have had to copy-paste some funcs for different data types.
Go supports Windows 2000? Go supports Windows XP? Is there a reason Go runs on XP? Were the Go team hoping we'd see ATMs written in Go in 20 years' time?
oh my god, you had to COPY and PASTE code?!? That must have been so terrible! Go is such a terrible language, why cant it have messy ugly templating like REAL programming languages! &lt;/sarcasm&gt;
In the professional world generics and function overloading are things you have to handle carefully anyways, so carefully that it's easier avoiding them. Maybe it's because most people who program don't work in a place where you have to stringently test each piece of code as it's own little module... I don't have to do but my boss likes the software being extremely well defined.
I don't think there are any performance benefits aside from the ones Go is already moving to, like precise GC etc. But supporting Windows 2000 was causing difficult fallback code paths to be maintained which was tedious and wastes developer time better spent elsewhere.
Lots of people are still using XP (many more than 2000).
http://upper.io/db Very simple, yet powerful. I use it for a few projects.
As much as I like Go, choosing a programming language often is choosing what you micromanage or in general, what you have to care about yourself. If you take a dynamic language and want to type check, you have got to check it yourself. If you choose a static language you have to write generics, typecasts, etc. yourself. It's always some sort of micromanagement. What good defaults are changes a lot with the type of application you write, but it's even a bit of a fashion thing, even Go being written by people that have a long history doesn't seem to be affected so much by it, which in my opinion is Go's biggest benefit. Node's and JavaScript's biggest drawback is that it tries to look like a language that it really isn't which means many people adopt it, but since the syntax looks similar they use it like C. If JavaScript would look like the majority of functional programming languages for example, people would most likely write better code, but nobody would bother getting into it.
&gt; Truthiness hell in all places. I kinda agree, but let me state that most of this boils down to using `===` instead of `==`. It's ugly, I agree, but it's not as hard to get used to as many other things. But if you want static typing you simply should use a static programming language. What's kinda sad in my opinion is that optional strong typing programming languages somehow never made it. In many cases this appears mainly due to bad marketing, as (and I might be wrong) many of them didn't have any major drawbacks. I think these days you really need to be famous (Google, inventor of C, maybe Mozilla, though the have a tough time with Rust) draw attention to a programming language, else we would probably see more use of Nimrod, Pike, Falcon, D, ... which while certainly not as mature (with the exception of D maybe) are really fine programming languages.
That's true, but all the stuff I see being written in Go is either for developers (and I assume most Windows developers are using 7 or 8) or it's meant to be run on a server. At least that's what I see in /r/golang and on [GitHub's trending Go repos](https://github.com/trending?l=go). I guess those two sources of information naturally skew towards development tools and Web frameworks though.
Nice answer, thanks. What about Fedora instead of Ubuntu? I prefer it because of systemd.
Any supported Docker host-OS should do. But yeah, systemd is nice. I will settle for Upstart until [Ubuntu upgrades](http://www.zdnet.com/after-linux-civil-war-ubuntu-to-adopt-systemd-7000026373/) :)
I don't see static typing as a entirely drawback - although I work most with Python which has a dynamic type system. I think Go has a really great balance of all the factors I want in a modern server development language. It's fast, it compiles fast, it handles concurrency well, it automates a lot of tasks, has a simple syntax, protects you from making stupid mistakes even when using pointers, and keeps things simple. Sure, it doesn't have generics and macros. But compared to all its advantages it's a great compromise. As for Node - I never really liked it because I hate JavaScript's promiscuous type system and scoping, and the callback mess it creates.
Excuse my ignorance but what is the point of Docker? I don't see how it is any more useful than just deploying a binary to production. I've seen a lot of articles on how to use it, but none on why to use it. Is it beneficial for security? Does it have any downsides?
 import ( "git-go-websiteskeleton/src/home" ) No, don't do that. Use [workspace](http://golang.org/doc/code.html#GOPATH)
Docker runs your app inside its own little linux container. So, a simple example might be this: You want to run 3 apps all on the same server. Each one has a Postgres database, but they've been developed over time, and each version of postgres is slightly different. Docker makes this setup trivial, while doing it on your raw server can be painful. Now imagine that in addition to postgres, you have 10 other dependencies in common. Now your seeing where that can be useful. Edit: As far as downsides, I actually don't know. I have only used it for a small app, so I'm not an expert here. 
Thanks for the tip!
It's a very good question. What is the point? (Sorry, this is a long answer) Think of Docker as a tower, built of Lego and you can always copy the tower, throw away an upper layer and replace it with your own. Docker also offers you a consistent environment between development, testing and production. If you only have one binary to worry about, you shouldn't use Docker. But most of us have databases, web-servers and other stuff to worry about. Think of it as an application oriented package system. You can tell it to use RHEL 7 container, because your Java Enterprise application needs it, without the work of setting up one and still host it all on your Debian box. Many Open-Source projects use Docker or Vagrant for developers so they can have working development environment up in seconds. As for security, it offers isolation; much like running stuff in chroot. Downsides. Well, I've written this response about 5 times now and I am struggling to keep it short. Docker can do a lot of different things and is essentially just a wrapper for layered filesystems and Linux containers. So there is a pretty steep learning curve. It's not for me to decide if Docker is the tool for you. I love that I can handcraft environments for my systems and deploy them in seconds - but not everyone needs that.
I found this links helpful http://stackoverflow.com/questions/22105368/how-docker-is-better-than-vagrantlxcchef http://www.slideshare.net/jpetazzo/introduction-docker-linux-containers-lxc http://www.sitepoint.com/docker-for-rubyists/ http://www.slideshare.net/strbalaji/docker-26650285
Eventually you are going to need to integrate with a database, maybe other components like Redis or a queuing system. In my app I've been putting that functionality into separate packages, defining interfaces, and doing mock implementations to make testing easier. For example, I have: * example.com/myproject/database * example.com/myproject/database/test * example.com/myproject/database/postgres * example.com/myproject/database/mock In **database** are interfaces and common types (errors, mostly). In **test** I have the bulk of the database tests. These are backend independent and run against both the postgres and mock implementations. I also have code in there for populating test data. I like using gocheck for this (http://labix.org/gocheck) because I can define all my tests on a `gocheck.Suite` and have my postgres and mock test suites embed my generic `Suite` so I get all the tests run against both backends for free. My Postgres test suite literally has one test in it in addition to the common tests. In **postgres** is the postgres-specific SQL code. In **mock** I've created a simple in-memory database. Basically it's just a crapload of maps for the various things my app queries by. `map[int64]*User` for ID lookups; `map[string]*User` for username lookups, etc. Obviously this is pretty simple, but it's code too and it needs to be tested. That's why I have the backend-independent tests. Then, in the rest of my app when I am testing other functionality (the API, for instance) I instantiate a mock database so I can test the API quickly without needing a live Postgres instance.
Hey, these are some great ideas, thank you. I was thinking of adding some db interfaces and possibly a connector, but was planning on looking at other implementations first (my go db work is rudimentary, if I'm being honest). I'll add this suggestion as an issue. Thanks again for the ideas!
And not to belabor the point, but the main thing I learned from doing that is that breaking your app up into separate packages is really helpful for solidifying the architecture of your app in your mind, because you can't take shortcuts by poking at unexported members in your code or exploiting particulars of a single implementation. Because I have different packages for DB stuff, all my database access filters through the `database.DB` interface. I don't "drop down" to SQL anywhere else in my app. I had to think about how I was going to query my data and design an interface for that, etc. Unfortunately my app isn't open source so I can't show you the code, but here is the package structure: * api * config * database * database/mock * database/postgres * database/test * model * queue * queue/mock * queue/sqs * state I think I first saw this approach in the Docker source code, and I've found its architecture a helpful reference. I also found jerf's [Environment Object Pattern blog post](http://www.jerf.org/iri/post/2929) and [this post on Gopher Academy](http://blog.gopheracademy.com/moving-to-go#TOC_1.4.) helped reinforce my thinking about this.
All of this talk about Docker but I stumbled upon this on their site (maybe it's not been updated recently?) &gt; Please note Docker is currently under heavy development. It should not be used in production (yet). 
When each of your services runs in a separate container -- app, database, memcache, redis, etc. -- it's fairly easy to compose these together to create your environment. These can either all be run on a single host (which is useful for development environments) or separately. Because they're fairly well-sandboxed you don't need to worry about different services trampling on each other, having conflicting dependencies, etc. To use a Go analogy, each container is like a Go package, and you can compose them together to make a cohesive environment like you compose packages and types to create an application.
Ah ok, that explains it. Thanks - you have really been helpful in giving some perspective. :)
How about this: https://code.google.com/p/go-wiki/wiki/GoUsers
C'mon man...google: "golang + list of companies" First result: https://code.google.com/p/go-wiki/wiki/GoUsers
If you wanted a workflow in which you did a git-push to deploy code (e.g. like Heroku, etc), you could use [Dokku](https://github.com/progrium/dokku). This allows you to not worry about your infrastructure and focus more on your app. Dokku should also have [a plugin](https://github.com/progrium/dokku/wiki/Plugins) for PGSQL. Behind the scenes, all of your stuff is built into a Docker container, and this doesn't require you to have any additional build steps or weird stuff like building debs. I have [a tutorial here](http://www.andrewmunsell.com/blog/dokku-tutorial-digital-ocean) on how to set this up on DigitalOcean, though the steps can apply to any VPS provider really. Just replace the Node.js app example and use your Golang app instead. The Go buildpack is built into Dokku.
&gt; Deb? Isn't it better to have some git hook to just built binary and send it? The advantage to doing a native package for the platform is that it can integrate dependencies. You can depend on the platform's go (instead of building your own as part of your provisioning process), or any library you want to use via cgo, or whatever you need. Your deb/rpm just contains your app and you can keep multiple versions of your package on hand to do instant rollbacks. If you version your builds carefully, it's clear whether you are looking at a newer or older version at a glance. Git only provides that if you deployed based on tags. The _disadvantage_ is that if the packages with your system don't provide something you want, you have to maintain a package of your own for that, too. This can add up rapidly on things like CentOS where they're going to ship the same version of things for a decade. (Other projects of mine have run into this with perl and php shipping 5.10.1 and 5.3.3, resp.) In summary, I'd have a git hook that builds a new release when a tag matching `^v\d+[.\d]+` is created, and deploy those through a separate process that would also record (and show) history of deployed versions. (My users tend to let things go until they finally ask, "So... about 3 months ago, X changed... can you change it back?" The log is helpful for narrowing down what set of commits to check, in this case.) I don't have much specific about Docker, except to note that it's container-based so it runs anywhere with a compatible Linux kernel, even paravirtualized environments. Linode added Docker support recently, and on Amazon EC2, the Ubuntu images have supported it for a long time. I would not be surprised if other images also support it, now that Docker runs on more systems.
The src folder is not supposed to be in your repository. It's supposed to be on your local GOPATH and your project be on the $GOPATH/src/github.com/jdadekler/git-go-websiteskeleton
Honestly, VPS hosting is is cheap these days (between $10, and $15 a month for a whole os), that it doesn't really make much sense to do anything else. Traditional shared hosting is rapidly going the way of the dodo. 
I like and use both. Basically choosing between Node and Go is choosing between expressiveness and simplicity.
It is that way intentionally. The project src folder provides a container for go-specific things, in the same way that static provides a container for html-y things. So, to be clear, src lives at $GOPATH/src/jadekler/git-go-websiteskeleton/src. Do you have thoughts on this, or perhaps a better naming for that container than src? Thanks for your feedback!
I am personally a big fan of the Django model (tried, tested, and true). Break up the web app into modular components that you can then turn on and off to isolate speed issues and other problems, as well as for easier re-factoring. ***Structure of all minor apps/modules*** * projectName/app/auth/model * projectName/app/auth/view * projectName/app/auth/controller * projectName/app/auth/templates * projectName/app/auth/routes * projectName/app/auth/middleware * projectName/app/auth/tests * projectName/app/auth/api * projectName/app/auth/static ***Main app that links all other apps/modules*** * projectName/database &lt;-- main db connection setup goes here, imported by all minor apps/modules * projectName/routes * projectName/templates * projectName/middleware * projectName/tests * projectName/static * projectName/config However, having said that, I like AngularJS's thoughts on this: Stick with the structure that is most prevalent and majority of developers would be familiar with, for the technology you are using. 
Please don't misunderstand me. I don't think static typing is a drawback. Sometimes you want, basically it, sometimes it can be a bit burden. I actually just wished JavaScript had optional strong typing for variables. Some of the less know programming languages have that. I also love how Go makes typing really simple. About Python - I really hope I don't get down votes for that, cause it isn't meant to be bad - I always think it's for people who kinda want to use a dynamic or static language, but not quite. Of course Python is a dynamic language, but compared to many others it feels like a static language. For example most dynamically typed languages have a stronger focus on abstract types, like objects, sets, lists/array, etc. I have seen people switching from dynamic languages, everything from Smalltalk, LISP, Ruby, etc. finding things confusing, cause they are used to a high level of abstraction. On the other hand people coming from Java for example enjoy it a lot, compared to other dynamically typed languages for this very reason. I actually think that one of the main reason for Python being so famous is that most people learn Java as their first language and so their brains are wired in a certain way making Python way easier understandable. Also Python itself is a famous first language. I agree on your criticism of JavaScript, but to its defense one has got to say it came off a really long way. I never was a fan of JavaScript before node.js appeared. I actually hated it, especially because it was mostly used by people calling themselves programmers and aren't really, people trying to work around the right way of using CSS, etc. I however really like where things develop. I really love Node's streams. They are a bit like Go's channels, only that you can really use them like Unix Pipes: steamA.pipe(streamB) But also in RPC-Style (streamB handles RPC, while stream A is incoming and outgoing HTTP/Websocket/TCP) streamA.pipe(streamB).pipe(streamA) That makes things way less callback style and it comes with many things built-in that require quite some effort in Go. Also I think EcmaScript 6 (and 7) will make JavaScript more of an application programming language. JavaScript is actually really great, when you consider it was mostly a domain specific language for scripting websites. I think there is more to come, but I also think Go and JavaScript are really hard to compare, as dynamic language vs static languages is an endless topic on its own.
But... which is which? Go is simpler because you don't have callback hell and because you don't need to spin up multiple instances and proxy them in order to use multiple cores, but Javascript is more expressive somehow? Can you give an example of when you'd use one over the other?
Go is simple and JavaScript expressive. I think JavaScript is nicer for prototyping, so if I want to do a weekend project I am more likely to use JavaScript. Also I would use node for things that are more like web projects and go for other kinds of servers. JavaScript or dynamic languages tend to be nicer for rough stuff, where you just want to play with your thoughts, not defining precise structures for everything. That's a bit why people (including me sometimes) use MongoDB (even though I really don't like it too much). Basically I tend to use JavaScript/Node when I have a wild idea and Go when I have a precise idea. You know, the projects that are more like brainstorming/prototyping vs the projects where you basically write down a specification of every little thing, probably need a map and write the code afterwards. Other than that: It's a lot of personal taste. Some people simply love expressiveness vs others love simplicity. See the cat-v people. Simplicity is there greatest value. But then you sometimes have things where you simply want abstraction. Sometimes weak typing just makes sense for a project, because it greatly reduces the amount of work to get to a first version. But yeah, it's hard and really depends. Also for my website project using multiple cores a matter of importing the cluster core library, probably getting the numer of cores, which is another line and then calling fork. Yes, JavaScript is more expressive, by far. Go on the other hand is the complete opposite. It tries as hard as possible to avoid it to keep things simple. Actually for me I think it actually is a mood thing, really, but I think that's the reason for so many programming languages even existing. Go isn't the first programming language threading that way and one could argue Rust is better for doing that, plus avoiding null pointers, or Nimrod is better cause it supports real time applications. I think it is nonsense. Go has great benefits over many other programming languages, but so do others. One of the main decision points I think is the brain/mind of the programmer in relation to a problem. If I have a task that's more than a simple function I usually can tell from the knowledge about a set of programming languages that it will fit perfectly and not get in my way. Other than that there are of course many more things to consider, like whether certain libraries exist for it yet, whether I can find employees or performance. Go has certain parts that simply aren't optimized yet, cause nobody felt the need to. If my project relies on the performance of it I'm inclined to use an alternative. Giving examples is really hard, because they tend to be really small and of course it's not impossible to do with any other programming language and you will always find things you know how to do easier. Also my comment about simplicity and expressiveness wasn't exactly meant to be "the right tool for the task", at least not solely. It's a personal preference. Like people who use minimal window managers, while others use Mac OS X, Gnome or KDE. I have been switching back and forth between those too until I settled for one I really like. But if you really want an example I'll give you something from real life: MySpace switched to node.js/express. I think it's a perfect choice. They went to beta again, doing something completely new and use a system that's proven enough for rapid prototyping. It's a web application, which is what node is basically made for. They wanna be able to quickly try something new, do lots of async webstuff. Node is perfect for that. They can be quick. Currently Facebook is the big thing. Their main thing is to be flexible and be able to implement and try out new ideas rapidly. The current Go with its current ecosystem would just not work for that, because it is focusing on few, simple primitives, just enough to be able to do everything. However, if you want to do more abstract things you have to put quite some work into it. There are no big frameworks where you basically make a web App through configuration. They want most of their time into finding out what color that button should have, where it should be and while it's great to write clean, easily understandable, well performing code that's not their focus. In many web applications IO, disc or network IO is the limiting factor not the programming language (that's why PHP, Ruby, Perl, Python, ... all computing way slower are often fine). All they do is moving stuff in and out databases, displaying it to the user, etc. No need and time to care for something being a bytes or Unicode characters. They need to prototype and that quickly, making things work in over 90% of the cases not guaranteeing 99.9999%. CloudFlare and dotCloud are basically about infrastructure. They want to deploy solid stuff, if something doesn't work somehow that's always a really big deal. They also go deep down into stuff. They want a language where they don't talk about some string, but about actual bytes. For their applications they want to talk about and use primitives, simple building blocks to build the big. They don't want their language to hide complexity, because every little thing makes a huge difference. There is no way the node of 2013/2014 is the right thing for that kind of stuff. Also they both build most things from ground up. I am sure they frequently want to reinvent things just to squeeze out performance or behave better under huge loads. Making things work for 99% of their customers just isn't enough. If the uptime of so many, small and huge businesses and private people depends on yours it just doesn't work with that.
Yes. 
Have a look at https://github.com/jinzhu/gorm This should be the most fancy ORM aims to be developer friendly. ( and it is written by me ;) )
You could also use an anonymous struct var person struct{Name string} blob := []byte("{\"name\" : \"John\"}") json.Unmarshal(blob, &amp;person) fmt.Println(person.Name) http://play.golang.org/p/RJgwzvurlE
Thanks. Any tip on Go is useful. My main issue with Go is that there is simply not enough intermediate to advanced material (books, cookbooks...) for it. As far as I'm aware of there is no new book published in the past 7 months and all the current books are too basic. I'm putting this rather simple website together that could take advantage of many of Go's nice features (especially channels) but after some experimenting I decided to pick python/django plus celery for it. I wish there was a website that people could gather their tips/recipes there and others vote on them so people like me would get a better idea of idioms and best practices and tricks. 
If you refactor an interface or struct definition, it's nice to build everything in your tree to find all the other places that need to be changed.
&gt; You first pre-fill the semaphore with 100 tokens. Each time you want to start an HTTP request, you must first withdraw a token. I never understood why some people do semaphores this way around instead of the opposite: if you instead let the worker process fill one token into the channel before starting its work, it will block when the channel is full, and you don't need to initially populate the channel with its maximum number of tokens.
You might not want to install a possibly broken software. Especially if the software is something you use. For example when I wrote [stalk](https://github.com/rce/stalk) I actually used it as a part of my workflow right from the beginning. When I wanted to build and test it, I did not necessarly want to replace the working version with it. With `go build` I could run the old good version with `stalk` and the development version with `./stalk`.
I use Vim. I love it and Go has a nice syntax file for vim :) 
Vim.
Sublime Text and the GoSublime plugin using goimports instead of gofmt.
So far I've used SublimeText together with GoSublime. But as I'm also using since years vim on console I now switched to MacVim and GVim. So I've got the same editor everywhere. And nice plugins are available.
Not just syntax file, but formatter, goimports, integrated documentation, tags, 100% working auto-completion, and a nice workflow to build/run/test. The only thing you won't get is VisualStudio style debugging, but the rest is top notch. Vim 4lyf.
I've found that the language is quite uncomplicated by nature and question the need for higher level books. I've now written a web proxy, a full app level SMTP server, and a couple of other &gt;10K LOC projects and I've found the code isn't significantly more complicated than what I was writing initially, albeit a bit more logically organised.
Out of interest, how do you get your auto-completion working nicely? Are you using gocode for it?
This is a good post, but I would also observe that the default ulimits are quite conservative for highly concurrent servers, and Go programs are often the exact sort of programs that will legitimately blow right through the limits. While you can't afford to just leak file handles like a sieve, don't be afraid to up them if you need to. If you've never done it before, run `ulimit -a` once, just to see what is in there. It may save you hours of debugging someday, to know what the default limits are.
Emacs. I think the only thing I haven't put in is autocomplete, since I personally dislike it. Otherwise, I've got jump-to-definition, gofmt (actually goimports, but that is a drop-in regardless of editor), syntax highlighting, online syntax checking via flymake, everything I want. There's more you can get but I find myself a bit of a minimalist at times. (I don't try, I just don't seem to like things like a big folder display. YMMV with my blessings.)
vim + gocode plugin
Assuming you're actually interested in understanding *why* they do that and not just being snarky; start (and end) here https://groups.google.com/forum/#!topic/golang-codereviews/i5qLHMQUnw8 
Sublime text beta
Yes, and than auto-completion is handled by these: &gt;Bundle "Shougo/neocomplete" &gt;Bundle "Shougo/neosnippet" &gt;Bundle "honza/vim-snippets" &gt;Bundle "Shougo/echodoc.vim" 
I use [YouCompleteMe](https://github.com/Valloric/YouCompleteMe) with gocode.
YCM works too, confirmed, but doesn't give you `echodoc` style helper or show types.
What does that mean? I've never heard of it before.
+1 for GoSublime. That with goimports instead of go fmt is great.
"Real editors" are whatever enables *you personally* to do *your* job the best. That for me is often vim, but nerd bravado and shaming someone for what doesn't work for them is silly.
Wow, thanks for the heads up on goimports!
IntelliJ with the Go plugin is pretty amazing and does a lot more than any other editor I've seen in terms of Go support.
&gt; and I can't directly cast a byte slice into an C array unsafe.Pointer(&amp;slice[0]) – done. I don't think I really got the article or why there's memory allocations all over the place.
Acme
Vim + [SPF13](https://github.com/spf13/spf13-vim) [LiteIDE](https://code.google.com/p/liteide/) for debugging.
Emacs go mode is pretty nice. Makes it easy to run gofmt on the buffer as well as work nice with indentation. 
I am an emacs users too. I get harassed at work but what can you do? I've set mine up to do some other cool things. I have shortcuts to build or test the current file/package, use the cover tool to highlight untested sections, run the race detector, etc. I like it because I never have to leave emacs. :)
Notepad++
How does YouCompleteMe compare to vim-gocode? Looking over my vim plugins I guess I have a number of language-specific plugins whereas YCM is trying to be an all in one? Until now I've been using gocode+vim-gocode and it's worked fine, but I'd be open to alternatives.
I agree, there's a few mid-level tricks, like using channels for controlling the lifetime of goroutines, but past that, there's really not much to be "advanced". That's one of the nice things about the language. Anything higher level just becomes a software engineering problem, which is above the level of the language.
I use the vim-gocode repository as well. I mainly use YCM because it autocompletes without having to press any extra keys. It has made me very lazy. I can barely remember the API of the small package I'm working on.
Kate is a good counter-point, because kde's fish://protocol lets you seamlessly edit remote files over a ssh connection, but running another editor inside of it is kind of silly.
If being able to run an editor on a remote server via ssh isn't a requirement, openoffice writer is a very feature rich editor. Being able to work on remote files is a key feature, regardless of your bravado and shaming.
You probably confused subreddits, Sir. Let me escort you back -&gt; [r/nodejs](http://www.reddit.com/r/nodejs).
No, that's definitely Go. Why would you say that?
The code style ( lots of interface{} and callbacks ) seems like it's attempting to write nodejs style multi-processing code in Go.
There is no need to be rude. I looked at the example and yes, it does look painful, but why don't you offer some constructive criticism instead of being an asshole?
Since when pointing to r/nodejs meant to be an asshole? And example doesn't look painful, it look javascript'ish ;)
I do not intended to be rude or an asshole - just to bring a smile to your face, Sir :) To be honest I tried to do what you say in the first place, but I could not come up with anything different than "stop what you're doing". :D
This has been on my list of "would be nice" for a while. Eagerly watching to see how this progresses.
I don't quite understand the *struct {}{}* stuff. Is there any reference?
When I tried goimports, GoSublime stopped working -- autocomplete disappeared. 
From the article, "The value type of done is the empty struct because the value doesn't matter..." I tend to use a channel of type bool, and I send `true` instead of the `struct{}{}`. If it is the syntax that is getting you, all you are doing is creating a new empty struct. You could also have put `new(struct{})`. 
+1 for vim + vim-golang
Unless I misunderstood, isn't the takeaway from that thread: (a) "acquire sem = send, release sem = receive" has always been intended to work (b) the MM will likely be changed to make that official?
Not sure if this was to me or not. I'm already a Go developer. I just wanted integration with Dashing.
Ah yes, I remember reading this about a year ago; it's still the article I reference when refreshing myself or others about limiting goroutines, because this FD problem comes up a lot. The worker pool pattern is very simple and effective, provided each goroutine is fitted to do an arbitrary number of tasks. The semaphore pattern is still pretty simple, but allows you to make your goroutines cleaner: instead of looping in your goroutine to perform an arbitrary number of tasks, each goroutine just performs one task, then finishes, signaling the semaphore that it's ready for another task.
Thanks, very interesting. Indeed, I might have been half-snarky, but also wary of the possibility that there might have been a valid reason to do it the other way around that I was missing.
That's how I understood it as well.
OP here...So did you actually look at any of the underlying code or did you just see a chaining syntax (which can obviously be written a different way) and write it off as javascript patterns being imposed on go code? The point of the package is to simplify sending/receiving on an arbitrary number of channels across an arbitrary number of goroutines. While I only showed the high level Multi.Stream type there are 5 other classes in the package to do this. The point of the Stream class is to let you produce, process, and consume data concurrently without having to worry about synchronization
OP here...I used interface{} because i wanted to make this for the general case. It would be trivial to take this and make it for any specific data type. As far as callbacks go, it is common practice to use closures to start goroutines so I am not sure what the aversion to to passing them to a function is. Also this is all concurrent code in a single process unlike nodes multi-processing
Acme
Actually I did. My point still stands. Did you try to debug a code that use your library? Another point that I may have is 99% of the use-cases are fine with http://blog.golang.org/pipelines only, not needing any abstractions over channels themselves. I could say you could at least: * do not keep binary files in a repo * make your lib go-getable * drop the snake from the camel-snake-case you use to make it look like something. On the other hand I have just imagined me being handed a code written in concept as yours and being said I should maintain it from now on... [hell no!](http://www.youtube.com/watch?v=umDr0mPuyQc)
Not sure if noob or troll, but I'd like to take this time to bring to your attention https://en.wikipedia.org/wiki/SSHFS
Always *intended* to work and AFAIK always has, but since it wasn't guaranteed by the memory model you were basically relying on an implementation detail (i.e the reason why Effective Go was changed).
Hmm.. That's weird. For me I just had to change the fmt cmd setting in gosublime. 
Oh yes, it's brilliant. You'll always be set as long as you have a linux box in front of you. In literally every other circumstance, you'll have to use something else. You sure showed me!
The hate for nano users is strong around here.
You're welcome to take a look at the structure I'm using for [gophish](http://github.com/jordan-wright/gophish).
&gt; The point of the Stream class is to let you produce, process, and consume data concurrently without having to worry about synchronization The problem is, the point of a channel is to let you produce and consume data without worrying about synchronization. With all due respect, I don't think you really get how channels work here, and with all due regret I don't think this code has any use cases. You appear to be "solving" the problem that a lot of producers producing simultaneously might try to send two things "at once", and then you write a lot of code that seems to be trying to helpfully provide a second channel to use in that case. However, that's extremely unlikely to be helpful. In that scenario, you should just use one channel for everything. Channels basically _already_ solve that problem; they are fully capable of being multi-producer and multi-consumer at the same time out of the box. Sure, you shouldn't try to run the entire universe through one channel, but I don't see this as a very big problem in practice. Unless you're moving fairly large objects through the channel and then doing absolutely trivial computation on them, it's unlikely (though not _quite_ impossible) for this to actually be the bottleneck in a system. (And buffered channels may even alleviate that, though I'm not intimately familiar with their internal details enough to know if they solve that. Regardless, this is definitely the sort of problem that you should only try to solve after you have a concrete profiler run in hand that says your program is too slow because it spends too much time blocked on channels. You may go entire careers without ever seeing that.) And once you're doing that, you don't need a "framework" any more, you just pass a couple of channels around. Go _is_ the framework for this problem you're trying to solve. Take consolation in the fact that you learned a lot of useful stuff in the process (work groups, reflection, etc). Consequently, I think the library is designed to attack a problem that doesn't exist. Sorry. I know this feedback sucks and is demoralizing, but it's better than not getting it.
What about differences between io.Copy and io.CopyN? May be better recommend CopyN? Both io.Copy and io.CopyN returns number of copied bytes but io.CopyN made it through buffer. Fix me if I'm wrong.
I noticed that in the go tour many of the pointer examples could be done just fine without pointers (for example leaving the function alone in the tour, but passing it the slice instead of a pointer to the slice). Is that an abuse of the language or what? I am way to tired to talk about this more, but hopefully there can be some discussion on this because it had me baffled.
Kate. Haters gonna hate.
~~Passing a slice and passing a pointer to a slice will have the same effect. Slices are a bit special because they're passed by reference, not by value. I think the main reason they chose a pointer is to demonstrate that a slice/array in Go is not the same as a pointer, unlike C/C++.~~ ~~Although it wasn't necessary to use a pointer, I wouldn't say that it's an abuse of the language. Not everyone is aware that slices are passed by reference, so using a pointer makes it explicit. When you use a pointer, there is no doubt in anyone's mind that the function has access to the original data.~~ ~~Some notes about slices and pointers in Go:~~ * ~~A slice pointer can be compared to another slice pointer using `==`.~~ * ~~A slice can't be compare to another slice using `==`, but~~ * ~~A slice can be compared to `nil`.~~ * ~~An empty slice `==` nil. But `len()`, `cap()` and `append()` will still work.~~ EDIT: Refer to C-G-B_Spender- 's reply, it fixes some misconceptions I had and is overall more complete.
I use this for vim.
Can you share a link or elaborate on your point? I skimmed http://tour.golang.org/ (perhaps, too quickly) but couldn't find any function taking a pointer to a slice.
&gt; Passing a slice and passing a pointer to a slice will have the same effect. It depends on what *effect* means here. If you're changing individual items in the slice then that's ok because slices contains no data themselves, you're just modifying the data in the underlying array. If you don't pass a pointer and you want to append to the slice, then you *must* return the *new* slice, because you're actually working with a *copy* of the original slice, therefore any changes to its length has no effect on the original slice. &gt; Slices are a bit special because they're passed by reference, not by value. No, they aren't. Slices, like everything else in Go is passed by value. This isn't a nit-pick, the distinction is *very* important. As I tried to explain above, if you append to a slice, but you don't return it then you might lose your modifications because you're actually working with a different slice. It might not seem that way solely because they refer to the same underlying array. &gt; I think the main reason they chose a pointer is to demonstrate that a slice/array in Go is not the same as a pointer, unlike C/C++. &gt; Although it wasn't necessary to use a pointer, I wouldn't say that it's an abuse of the language. Not everyone is aware that slices are passed by reference, Sorry to be annoying, but I feel that it's important to re-enforce this: Slices are passed by value, not reference. &gt; so using a pointer makes it explicit. When you use a pointer, there is no doubt in anyone's mind that the function has access to the original data. &gt; Some notes about slices and pointers in Go: A little bit of a nit-pick... but if you pass a slice to a function, whether by pointer or by value, it has access to the original data because both slices point to the same array. &gt; * A slice pointer can be compared to another slice pointer using ==. FWIW, this applies to all pointers &gt; * A slice can't be compare to another slice using ==, but &gt; * A slice can be compared to nil. &gt; * An empty slice == nil. Nit-pick: it depends on what you mean by *empty*, if it means that `len() == 0` then this statement is not true. See http://play.golang.org/p/YSMKQoEO2M &gt; But len(), cap() and append() will still work. 
Sorry, in the tour (52 and 54) they use a struct as the example. In the code for main you can remove the "&amp;" and the code functions exactly the same, and the function has full (read/write) access to the passed variable, not a copy. So what is the point (harhar) of passing a reference instead of the variable?
I can see you didn't bother to read the wikipedia article. You know how? There is a windows implementation of sshfs, and there is a mac one as well. Those are just the client parts, for the server part, all you really need is the ssh server. Are you suggesting there isn't a mac or windows implementation of sshd? Really?
Read: * https://codereview.appspot.com/74790043/ * https://code.google.com/p/go/issues/detail?id=7325 
Note the consistent user interface and error reportage. Ed is generous enough to flag errors, yet prudent enough not to overwhelm the novice with verbosity.
[You don't need to :)](https://github.com/pote/gpm)
Sort of off topic: Anyone know the state of ldap / active directory libraries in Go? More on topic: what about token auth? Is that what the cool kids are using now? 
You pass references when you don't want to copy the entire variable to the stack. If you are calling a function recursively, there is overhead to copying the variable on each call.
&gt; Anyone know the state of ldap / active directory libraries in Go? There's LDAP modules out there. I picked https://github.com/mavricknz/ldap at random at work to do login with Bind() on a LDAPS server. &gt; what about token auth? Maybe check http://godoc.org/?q=XSRF
When it comes to slices in particular, they are always references. A slice is a reference to an array. It is done, I believe, so that you can do things like items[2:5] to create a new slice. Also, if you go into the implementation of the append function, you will see that it reserves the right to reallocate the memory if needed. It can copy the values over to a new memory allocation that has a larger capacity when you run out of capacity. Edit: Clarity about append
Has to be vim for me with the Golang provided syntax and Fmt plugins. 
What would be the best way, using gorm to create special types like hstore/json which are supported by postgresql?
Have you considered using UDP datagrams to a single port, with message type indicated in the packet? 
Have you looked at the [Example (Interface) on the gob documentation page](http://golang.org/pkg/encoding/gob/)? You need to declare an interface that all your messages conform to. Don't miss the `gob.Register` call requirement. If you can find something useful for that interface to be, use it; otherwise, don't be afraid to do [something like this](http://www.jerf.org/iri/post/2917) and just declare a trivial interface for all your elements. (You could use `interface{}`, but I feel that all uses of `interface{}` should indicate that there really is _no_ restraint on what the value could be; I personally prefer to categorize them cleanly.) On the receiving end, use a type switch to determine which concrete type you received, as gob will handle giving them the correct underlying concrete type, and go from there. You should definitely not need more than one connection to send different types of messages.
No, but thanks for the tip. I was hoping to stick with TCP though UDP should be fine for this.
Great, thanks jerf! The interface example is exactly what I needed.
Try: https://github.com/go-distributed/message? We implemented this for our epaxos. 
Why paxos ? Have you seen [RAFT consensus algorithm](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf) titled *In Search of an Understandable Consensus Algorithm* [implemented in golang](https://github.com/goraft/raft) already and used in a lot of projects including [etcd](https://github.com/coreos/etcd)
It's an assignment I'm working on for a course that I'm taking for fun. I just knew that all of my individual connections solution "smelled" so wanted advice for getting the connections cleaned up. I try to learn a new language a year, and this year it's Go!
I like having that cute little gopher in my address bar. Now can you make it work from anywhere within the repo (wiki, pull requests, issues, etc)?
This looks really interesting :)
You're absolutely right. That's definitely come up as a factor for people moving over from Ruby, but hasn't seemed to be as large as a problem for people coming from other languages.
First of all, he sounds to be perplexed with the concept of error in Go. In Go, an error is not an error code, it's an interface. He first goes on says &gt; There are literally hundreds of things that can go wrong here. and then claims that the solution is &gt; The list of possible errors raised is an *essential* part of a functions contract, and must be documented. According to "*The* Solution" he presents, all functions in Go should "literally" list hundreds of possible errors. Seriously? Back to his particular problem itch "how do I recover from http.Get?", the doc says &gt; An error is returned if the Client's CheckRedirect function fails or if there was an HTTP protocol error. Clearly, you're not expected to recover from error with Get. You can try again a few more times though. If you nevertheless want to, however, the code is out there, good luck tracing all potential errors that can come out of http.Get. &gt; A non-2xx response doesn't cause an error. In which case you can check the HTTP status code and try to recover. And this problem he's complaining about is nothing specific to Go or Python. It's everywhere and is part of the reality. Almost any function doing non-trivial amount of work calls many many other functions, which in turn call other, and it's not practical to compile a list of possible errors that might occur during the *whole* call-tree for *all* functions. Neither it makes sense to maintain a list of functions in a particular function, along with the errors this particular function can return on it's own in the documentation (and expect the whole world with adopt this thing, so that by tracking the call-tree, one can compile a list of possible errors). In practice, you can at most hope to learn about the *class* of error, which is represented by the error type in Go (in Go, you can try to check the contents of the error string (Error()) then). In fact, with Go, this is impossible to put it in the docs. Take the simplest case a function expecting an io.Reader (could be gzip, hashers whatever). The function only knows io.Reader will return an error, which itself is an interface. It has no idea what kind of error that would be. Similarly, what kind of errors you can get depends on the underlying RoundTripper.
Speaking as a beginner, Go is the first language with which I was able to easily grasp concurrency. Goroutines and channels, so simple, even fun, to work with.
Omnibus. It's what I currently hate about the hipster programming scene.
This is too clever by half. Are you a wizard? 
I've used https://bitbucket.org/liamstask/goose on a few projects for doing migrations, still looking for a way I love though.
Thank you for the links
That looks pretty good, though a little awkward.
I've used goose (probably on some of the same projects as /u/alakriti) and it works, but yes, it is awkward. 
https://github.com/tanel/dbmigrate
This looks straightforward and promising. I dig it 
The latest Zeus beta makes it to integrate the goimports into the save and compiler actions of the Zeus IDE. For more details on how to do this setup refer to this link: http://www.zeusedit.com/zforum/viewtopic.php?t=7111 **NOTE:** Zeus is shareware, runs natively on the Windows and can run on Linux using Wine. *Jussi Jumppanen* *Author: Zeus Editor* 
I got this error with the prior version, trying to run it on Debian testing. The problem is the tarball has some of its own Qt libraries, but not a full set, and it doesn't mix with the slightly different versions on your machine. To fix it, there's a subdirectory in LiteIDE full of .so files that you need to empty out. I'll try to remember to post a link once I'm to my PC.
It's weird since up until recently, liteide was hosted on [code.google.com](https://code.google.com/p/liteide/) (it now says to go to github, from which there is a link to binaries hosted to sourceforge). I thought github introduced the option to host files for download (outside of the repo itself) last year?
I agree. Ever tried downloading something from sourceforge using curl ?
FWIW Windows supports SO_REUSEADDR which I think provides similar functionality. However it then becomes harder to define (let alone enforce) the desired and correct behavior if there are differences. You can't just assume it works like Linux' SO_REUSEPORT on every platform. It's a cool package nonetheless!
This submission doesn't seem to be getting any traction, but it was eye-opening for me: I didn't even know that you could compile Go to ARM, much less run the executable on an Android device, or to package and use that from your Eclipse project.
Thank you very much! 
Yeah, but it's easy to pass the flag in and get an error back if it doesn't work. It's not like it's a brand new API call that if you try to use it on an old kernel, it entirely crashes your process or anything; it's a flag. There's _already_ plenty of corner cases being smoothed over in _any_ cross-platform net package; this isn't that bizarre or unusual, and it's already supported by many similar cross-platform environments.
Yes, github allows you to upload release binaries. And no ads.
Ugh, yes. I remember writing build scripts that had to pull from SourceForge back in the day. It was pretty annoying.
I copy the adress of the direct link and remove the suffix.
Yeah, I've done that sort of thing too, but don't you think it could be easier ?
SO_REUSEADDR is something completely different, and also supported in Linux and *BSD. 
I stand corrected then.
I really hope this becomes widespread knowledge as it's a subtly different forking flow than other languages. I've helped a number of newcomers to Go figure this out. Glad to see it written up.
I always hoped google had plans of making Go a first class language for android use. It's nice to know that even now, you can involve Go in your workflow for android. Still not where we'd all like it to be, but definitely interesting.
Well. That's a bit too obvious, don't you think? Thanks. 
Adblock really is mandatory on phones.
I tend to cast all stuff server side that isn't an integer to string, kinda makes it "safe" and a client side problem; floats and decimals are a real pain eg 12.333 
What if I wanted to do sorting on that data in a DB. Do you encode the string back to int64 when inserting into the db?
done :-)
That looks like the godoc Bookmarklet, right?
This works but seems odd ("hacky" perhaps?). Nothing is odd with this technique but rather that such a technique is needed in the first place. I find it very strange that we have to hardcode github.com/username into our imports. Love go but rarely use go-get because of this. Only use it if there's absolutely no other option. git clone usually suffice. Regardless this tip is awesome.
These zeitgeist-type posts are great. Here are other ones I've read over the past year: http://www.talyarkoni.org/blog/2013/11/18/the-homogenization-of-scientific-computing-or-why-python-is-steadily-eating-other-languages-lunch/ http://devopsanywhere.blogspot.com/2011/09/how-ruby-is-beating-python-in-battle.html
Symlinks are completely unnecessary. Let's say I'm making a contribution to github.com/jerf/coolproject. I fork it to github.com/skelterjohn/coolproject, and run $ go get github.com/jerf/coolproject Then I add the remote to my github repo, and pull it into a separate branch "skelterjohn-master". When I want to work on my changes, I have the "skelterjohn-master" branch checked out. Otherwise, I have the "master" branch checked out.
It's only hacky because github misuses the word "fork". What they should really have is an additional button, "contribute", which creates a special branch on that original repo. Then, you have a "merge request" instead of a "pull request". The UI should hide that branch when people look at the original project, except in the context of a merge request.
I met the problem before, go build just build the source, try go install
I know go can run on ARM, but never know .so tricky. thanks for share.
Perhaps "go build -a &lt;package&gt;" in your project See "go help build"
[Mandala](https://github.com/remogatto/mandala) is also a library to help develop go applications targeting android.
The go run command does not rebuild imported packages and go build does not keep objects that are not main packages. So by doing what you are doing are not allowing changes to propagate into the temporary binary you build. Either go install each of the changed imports, or more simply, just go install your server main package.
Check out this page: http://dave.cheney.net/resources-for-new-go-programmers I started with skimming through couple of books, then went to coding. Go is a language which excels when used :)
Two questions: 1. Could you clarify "the path on disk"? Do you mean the package paths inside the project pointing to other packages within the project, or do you mean the github project pointer? 2. In a project with multiple packages, how would you solve the problem of renaming the paths to these packages? e.g. if I fork github.com/&lt;your username&gt;/fooProject to github.com/&lt;my username&gt;/fooProject, all the paths inside my code are still pointing to github.com/&lt;your username&gt;/fooProject. (in other languages I've seen config files and variables holding the value of the path, but I've yet to see that in go)
My only problem with this is you can no longer use "natefinch"'s original version. Why not just clone it to `$GOPATH/src/github.com/&lt;YOU&gt;/gocog` and modify your imports until your pull request lands in the original repo?
I prefer [Francesc's way](http://blog.campoy.cat/2014/03/github-and-go-forking-pull-requests-and.html). You can easily keep the two forks separate as remotes. And it works better if you use the awesome [gh tool](https://github.com/jingweno/gh) (or its slower ruby version, hub). $ go get github.com/foo/bar $ cd $GOPATH/src/github.com/foo/bar $ gh fork `gh fork` will create a fork if it's not already created, and set up a remote for you. Then you make changes, and: $ git commit -m "here is my awesome commit" $ git push yourname your-feature-branch $ gh pull-request 
That question seems loaded with so many assumptions I hardly know where to start. But, two points that seem pretty likely to be solid: 1. Put in the DB whatever it is you need to put in the DB. 2. Using a serialization that doesn't support the data formats you need is dangerous, especially if you don't really understand the issues involved in encoding. If you make that mistake, expect to pay for it somewhere... and it's important to correctly account for the mistake. In the case I think you're trying to implicitly argue for, the error occurred when you tried to use JSON for something it isn't meant for, not when you tried to insert the data that travelled through JSON when it shouldn't have into the DB. Data is really fragile, far moreso than most developers understand. When you destroy a chunk of it, you can't get it back. You can often do things that will briefly convince you otherwise, but in the end it always that you merely moved the problem from somewhere you can see to somewhere you can't. This is, in fact, a mathematical inevitability. (No joke.) Once you've lost data, it's _gone_. (And, again, let me highlight that I said using a wrong serialization is _dangerous_. Not "wrong". Not "impossible". I've done it before, and I'll do it again; we don't always get to make the "right" choice, sometimes our hand is forced by other considerations. But it is always _dangerous_, and needs to be handled with care.)
If you're just doing local development, you can keep the checkout in `$GOPATH/src/github.com/natefinch/gocog` pointing to your fork of it without updating your imports. Only if you do `go get -u` will it update the git repo. If the pull request is quickly merged, it's handy to not need to update the imports. When you have multiple packages involved, it gets pretty painful. Of course, if you have to maintain your own fork or the pull request isn't merged quickly enough for you, then you'll need to update imports.
I believe GopherAcademy is working on a new job board. Also, http://golangprojects.com has the largest collection of Go jobs at the moment.
It's a systems language. "Cloud" is a pretty stupid buzz word, but Go makes it a good fit for orchestrating systems. Go is "cloudy" in that regard.
my first reaction https://www.youtube.com/watch?v=31g0YE61PLQ
You sir, are a monster.
I had never heard of it... are those most recent submissions 3 years old?
I think this could be a cool learning tool for someone coming from a ruby/python background, but thats really about it. More of a crutch just to get started, see the generated code, and maybe go from there.
:(
Sic?
I would get rid of it, the absolute newest content is 3 years old.
This plus $ git checkout -b your-feature-branch is exactly my workflow. I like having the feature branch so that when my change gets merged, I can just `git fetch &amp;&amp; git checkout master`.
If you end up maintaining an actual fork, changing import paths really isn't the thing that's going to take up most of your time. Rewriting import paths will take a couple minutes (with sed, or Go-specific tools) out of your life. Tracking upstream, merging back changes and maintaining your fork will take a lot more time. You're optimizing the wrong thing.
The Go tool does not officially support symlinks within your GOPATH.
Hey, don't let this thing hatch, we have to kill it with fire asap. We don't want another Coffeescript to happen, do we? Think of the children.
Hardly anything does... officially.
Changing import paths isn't that big of a deal, but it *is* annoying, and I mention it because forking is pretty common in open source projects. However, there *are* other problems with the import system that I feel is a bit unfortunate. For example, if I'm working on two different projects that need two different versions of the same dependency (not unheard of in large projects), I can use virtual environments, set the GOPATH in my build script or check out rebuild dependencies each time I switch projects. I personally prefer the `npm` way of doing things, but I do understand why `go` has chosen to do it the way they do. However, having relative imports would go a long way to easing the pain with a static GOPATH. I'm certainly not going to leave `go` over something so trivial, but my point is that the current import system is more annoying than it needs to be and it makes working with projects hosted on sites like github annoying.
If you prefer learning by watching videos, this might be interesting. The Go team has given several excellent talks over the last couple of years, and I've made a list of them here, sorted by difficulty - https://gist.github.com/nindalf/9624097
amen
[gocasts.io](https://gocasts.io/) [gophercasts.io](https://gophercasts.io/) Clickable links :) ps: Good resources, thank you.
https://code.google.com/p/go/issues/detail?id=3032
Personal problems of the troubled author who attempts to refuse a new syntax aside by clinging on to some scripty-syntax, this can actually be quite bad for community. igo, I wish an early, horrible and silent death for you.
Maybe it is past time this sub-reddit is moved to /r/go.
ORMs are considered harmful. You don't need one.
Lol, butt development in the butt. Edited: because I just got home from work and can't stop laughing at how increasingly fun it gets as I keep reading.
Thanks for the info!
My review: why?
&gt; looks like the days of standing up a central repository for a new language are over I'm not entirely certain this is correct. The Rust guys are setting up a central repo with a package tool called Cargo. Its being built by the same guys who created Bundler for Ruby. I didn't follow the drama around npm a while back, but was it bad enough that the people are against the concept of any central repo? I think they've made a big difference to Python and other languages, and would be helpful to Go. 
Actually, some kind of transpiler for instantiating generics could be an interesting project.
To me it did look like it was posted by the author. But don't be sad about the downvotes. They're merely internet points that mean nothing in real life. They're given or taken away by people and people tend to make quick judgements. Especially on the Internet.
Worth pointing out that Dave could well agree with us here, but just gave the perspective of others in the discussion. Either way, I think it would really help the Go eco-system if we could have a package manager that had the blessing and the backing of the entire community. 
Perhaps for "compatibility" with utf8. It makes it easier to do stuff like: http://golang.org/src/pkg/unicode/utf8/utf8.go?s=10322:10349#L423
Do you know why the range 0xD800 - 0xDFFF is invalid utf8?
It's range for UTF-16 surrogates http://msdn.microsoft.com/en-us/library/windows/desktop/dd374069%28v=vs.85%29.aspx
i tried to like it, but given it not working on windows xp stopped me from working more on it - believe or not, xp is still being widely used in large 'modern' organizations....
The more important a dependency is to my app, the more likely I am to be running a fork of it at some point. Everything gets pull-requested upstream of course, but maintainers don't always agree with the changes you need or they just take forever to merge the PR. Either way, the more dependencies you have that look like this, the more valuable distributed package management becomes. Bundler's Gemfile.lock file is the most flexible solution I've seen to giving you a reasonable middle ground. You either choose to check it into source control or not, depending on what you're writing. With centralized package management, people ask me all the time to cut releases of libraries I maintain that aren't at a good release point. With decentralized package management, they can switch the branch, tag, and even repo transparently without the need for awkward and insufficiently baked point releases. Decentralized may have its share of problems, but that doesn't mean the best answer is going back to centralized solutions.
Who better to know this than Rob Pike, who created both UTF-8 and Go :)
I agree that the semicolon is probably a holdover from C. That said, how would you implement fallthrough if each case was a basic block ?
No, you'd have to check for r &gt; {some really large constant} instead.
That's covered by the `r &gt; maxRune` check that's already there.
Thanks for clarifying this. I didn't do a good job of explaining what Cargo was. Here's the link to the Rust mailing list where they discuss it - https://mail.mozilla.org/pipermail/rust-dev/2014-March/009090.html
At the very top of your document you're explaining "Soy" in terms of "Tofu" without an explanation of either. Don't provide a usage example without explaining at least the high level idea you're going for. It just makes for confusing documentation. Starting from scratch, I have no idea what's going on, but if "mode == dev"... that means something? What? But apparently you really mean `mode == "dev"`. Well, what's `mode`? Am I supposed to make that comparison every time I use WatchFiles? Why doesn't that function take a string instead of a bool then? Also, the whole pattern of NewFoo().Set().Thing().Other().Blah().DoThis().OneMoreThing() feels very un-Go. 
This question has been asked before and is in the FAQ document: http://golang.org/doc/faq#get_version
Here's an implementation I did some time ago: https://github.com/fzipp/astar I used a priority queue and graph is an interface.
`-1` is sometimes used as a "no character" value, e.g. in `src/pkg/text/scanner/scanner.go`: type Scanner struct { … // One character look-ahead ch rune // character before current srcPos … } … // initialize one character look-ahead s.ch = -1 // no char read yet 
Go uses the switch syntax that C uses. C uses that switch syntax because every case-label is in fact a label when you translate C to assembly in the obvious way (i.e. without changing any control flow). C was designed in a time where people mostly coded in assembly; the design decision makes sense very much.
https://code.google.com/p/go/source/browse/cmd/oracle/oracle.vim?repo=tools
As the author of a program with just two dependencies I agree this is a problem. Several times a year I find out a released version is broken because of upstream changes. If I could at least peg my program to a particular version (e.g. tag) then I could at least be confident that when I've released something it will continue to compile indefinitely.
&gt; any arithmetic on utf code points Arithmetic on unicode codepoints is bogus. If one really needs something like it, explicitly casting to/from a true integer type seems perfectly reasonable. Frankly, I think the correct "defensive programming" thing is to make `rune` an actual unicode codepoint (i.e. storing any non-codepoint is an error, rather than just a convention thing), with only comparison operations, no arithmetic. But then this level of compile time guarantees doesn't fit with the rest of Go (e.g. strings are valid unicode also just by convention) so the current behaviour is fine... other than the arithmetic.
Even better
1. Too late for a syntax change. 2. A form familiar to C/C++ programmers (and many other languages like Java and C#) makes more sense. 3. One less symbol to type. 
Similarly to \_fz\_, here's an implementatino of a graph + A* I did some time ago: https://github.com/sauerbraten/graph Also, priority queue was used.
First of all, I love simple editors. I wrote my thesis using Vim and LaTeX. I use emacs (yay for org-mode) for my personal notes, which lets me keep 10 years of notes in one file (searching becomes dead simple). Whenever I hear about people preferring Vim over Eclipse, I imagine they are either programming geniuses (your name is recognizable outside your circle), or they are working on a pretty small code base (less than 100k lines of code plus whatever additional resource files). Go-Oracle exists precisely to bring existing IDE features into editors, so editors can deal with large code bases. The ability to ask questions like -list all calls to this function, -list all places "new" is called for this object, -rename this method, whereever it's used, are incredibly useful things. Of course you don't **need** them. If you were brainy enough, you can keep 200K lines in your head and remember where it's used. If you are not that brainy, then maybe you're only dealing with tiny code bases. Go see how many lines your code is: $ find . -name "*.cpp" | xargs cat | wc -l
Post says this is an issue for 2 reasons: &gt; 1 Developers assume this is a solved problem, not something they have to deal with while also learning a new language. This is wrong. Go FAQ says: &gt; Versioning is a source of significant complexity, especially in large code bases, and we are unaware of any approach that works well at scale in a large enough variety of situations to be appropriate to force on all Go users. &gt; 2 Those new to development get the double whammy of having no idea where to even start with this problem. Education is a good starting point. You can suggest reading a book.
What if you have a dependency you can't include with your code because of licensing reasons?
This sounds pretty similar to the gopkg.in solution as mentioned in the article.
I think Go is a really good choice, even better than Python for a first language. There is less wizardry involved than a "dynamic" language, and the compiler errors can help prevent you from falling into deep traps (especially when refactoring). I wouldn't worry about concurrency too much (the go keyword, the sync package) starting out, Go is perfectly serviceable without it. (One of the huge advantages of Go is that concurrency is built into the language, so you'll want to take advantage of it at one point...) Some other points: 1. Use gofmt always, default settings. 2. Check out the style guide: http://code.google.com/p/go-wiki/wiki/CodeReviewComments 3. The newsgroup is another good source of discussion: https://groups.google.com/forum/#!forum/golang-nuts 4. glhf :)
If you don't have a Content-Length, then it must be a chunked response (or an HTTP/1.0 server). This means there is no size available until you've read the entire thing. Why do you want to switch to using io.ReadFull instead?
Then you also shouldn't be `go get`ing it.
I wanted to use something that allocates immediatly the whole size of the []byte that is needed, instead of using something that has to grow the used buffer everytime the current buffer is full.
The restriction might only be on distributing it with your source code. With something like Python's package management solution I just specify a dependency and version and when they pip install they get the library independent of my distribution.
Simple is the Go way. If a project starts becoming overwhelmingly complex, the design is probably wrong. If you start using `reflect` or `unsafe`, think again. Not that they shouldn't be used *on occasion*, but way more often than not, those packages are unnecessary. `reflect` is slow and `unsafe` is... well, ... unsafe. Think in package scope rather than object scope. In other words, think of *packages* more than *classes*. (But typically, don't create as many packages as you would classes.) `go fmt` all the things! I'd recommend putting your important code under test. My personal preference is GoConvey, which integrates nicely with the standard `testing` package. Finally, keep having fun! The Go community is rich and vibrant, but some gophers have really strong opinions. Don't let that deter you; just keep Go-ing. Go has lots of little tricks and secrets (or less-documented or less-well-known features) to discover, so see how many you can find. (For example, I'm still learning lots about the `go` tools.)
Stockholm syndrome
It does read like a lot of rationalization. Overly concerned with hypothetical problems (centralized repo's "agenda", whatever that means) while hand-waving much more real problems (the incredible ease at which an upstream repo can completely destroy your ability to deploy your application).
Thanks very much for taking the time to respond. I'll be sure to take this on board!
Great stuff! Thanks for the response, I really appreciate it. 
Relying on 'go get' to find the correct library for anything is a bad idea. http://gowithconfidence.tumblr.com/post/63648535238/effective-production-management-for-go
Cheers for all the comments. My aim was to get some feedback on whether this was in fact an issue for those new to golang, and was it affecting others using golang. On review I have noticed quite a few golang libraries don't even tag their releases, especially the smaller ones, this in my view highlights the need for some tools to assist with versioning. Education would also be needed of course, new developers are mostly going to do the least amount of work to get their stuff published. I do agree doing nothing and just whining is part of the issue but I totally disagree with the view nothing is an ok situation. I am hacking on a tool to at least make it easier to maintain version tags in a go project, just as a starting point. Retrieval will still need to be manual while go get remains ignorant of versions. One last thing to note is I have had a lot of feedback from those who skipped golang due to the lack of a package manager, I think this is really the point. Having people leave before they even get started is disappointing. Thanks again. 
Can you show us the profiling run that says you need to optimize that?
That's still just a workaround for a silly problem that should not exist. Few other modern language communities would consider "manually keep a copy of all your dependencies" as a reasonable management strategy.
"Overly concerned"? That idea merited one sentence in the whole post.
If the other side doesn't send a Content-Length header, there's no way to know in advance how big the body is. Just use ioutil.ReadAll. It'll most likely be efficient enough.
It's mainly for the same reasons that len(x) is an int instead of a uint (and many other similar situations): You get a numeric discontinuity somewhere (because any integral numeric type chosen is going to have a finite range), so the two natural choices are to have that discontinuity at 2&lt;&lt;31 (for an int32), or at 0 (for a uint32). The latter is much more likely to cause nuisances with overflow, etc.
If you put your etl.yaml file in a separate directory, and put the code for that module under that directory, then you'll get a separate app binary when you upload that module. If you do that, you'll also want to put your app.yaml in its own directory too.
This is pretty key. Alternately you can use a doubling method for the byte size allocation.
In your particular case, you don't need to `ReadAll` of the body, just wrap the res.Body with an XML decoder: res, err := http.Get(...) if err != nil { ... } defer res.Body.Close() dec := xml.NewDecoder(res.Body) // use the decoder http://golang.org/pkg/encoding/xml/#NewDecoder Also, you're doing network calls, which is way slower than any slowness that could be incurred by not allocating your read buffer all at once. Which means you should not expect noticeable speed gains by using `ReadFull` instead of `ReadAll`.
There's also no guarantee that `Content-Length` will be correct.
That's very similar to what I normally do, but with just a small tweak. res, err := http.Get(...) if err != nil { ... } defer res.Body.Close() decodedResp := YourStruct{} err = xml.NewDecoder(res.Body).Decode(&amp;decodedResp) if err != nil { ... } // now you can use decodedResp
Wow, this is cool. Vim built in will get more use, but still awesome. 
Eclipse is bloated but there are other IDEs out there that are slick, snappy, and a joy to use.
Decoupling these type of things from the big IDEs is something to be celebrated and an amazingly good thing for open-source in general. This already has 4+ interfaces, from web to vim to sublime to emacs and I am sure many more. This is only possible because it was created decoupled. Remember, this means it can be used by fancy IDEs as well. Decoupling is good!
If you know Java, Id suggest writing it in Java. Try Go on a smaller, personal project.
It is wherever you spend your time. I assure you that the command line becomes just as comfortable as your IDE if you invest in it. Google for "unix as an ide". Additionally, I put forth that it comes full circle. As you get to really huge projects... you will end up back in the console, because IDEs don't scale. Huge projects break IDEs. You start to deconstruct your project in stupid ways just to make the IDE work properly, you start intentionally doing dumb things hoping the IDE will carry you forward. Once you are in the 1M+ LOC range, IDEs start to be a hindrance more than a help... simple things like autocomplete completely break down, you start writing custom tooling for everything from tags to build to deploy... your IDE becomes the worlds biggest text editor -- because asking it to do more cripples it, and you. I have worked on ~2M line codebases, I have shipped products that go to 50M+ people, and I have built products that do well over 1B+ responses a day (in under 30ms to edge of our network no less). You know the one commonality between them all -- console tooling, generally a mix of custom and off the shelf... but all console based and completely separated from IDEs and editors. Because IDEs break down, and large projects have lots of people who are very in love with their editor and flow -- and they would rather not work for you than use Eclipse, or Visual Studio, or X -- they will just take one of the other 2 dozen job offers they have in front of them. I suspect that Go is just a good bit ahead of the curve, why spend all that (generally useful) effort on one specific editor, when you can build fantastic decoupled console tools that support ALL the editors and IDEs.
So your mobile app will be connecting via websockets (why websockets and not just a raw TCP connection or a REST interface?) to a server and writing some data, maybe encoded with JSON or msgpack or something else, and said data should be saved in a MongoDB collection as a document? That's it?
Actually the various versioning package managers typically fail to solve vendoring and vendoring is needed for real world critical applications. There are go tools to do vendoring, but they are not package managers.
I tend to find the cli has a cliff edge of a learning curve, and still goes on for years.
I don't know if this will affect your timings but if you only care about membership (using a map as a Set), then you should be using map[type]struct{} as bool takes up one byte but empty structs take up 0 bytes.
Yes, that's about it. I would prefer to implement it using WebSockets for 2 reasons: - I need to keep track of the number of concurrent connections to limit them to a defined number - WebSocket are full-duplex and I need the those capabilities for further implementation (mobile/web apps that connect are going to behave like game controllers)
Yeah, I'm just going to end up doing it in Java if I don't easily find someone - I thought I might as well ask. I just got a bit excited about Go :) Java is annoying to write though because of tons of boilerplate code + I would probably have to use a framework and that's such an overkill for what I want to do.
Agree, see the "Set" package which is build around this idea: https://github.com/fatih/set 
This is one of the few things that bugs me about the syntax of Go. I know it's an artifact from C and other languages. Since switch statements of Go are different from those of C in many ways, keeping the syntax doesn't seem as important. I for one would welcome a change of syntax for Go 2.0.
The code is in the linked gist. You can make the change and rerun the benchmarks. I'd be interested in how much of a difference it makes.
Thank you for the suggestion and the link to your project - I will have a look at it. I'm aware that Python is a practical and much liked language but I just haven't had a chance to learn it. I am asking about Go because it is a language I am learning now and would like to do most of my work in. I would also be able to make at least some changes in the project code if I ever need to. I will play around tonight with Python and Flask and see what I can do. Even though a lot of programming languages are quite similar on a basic level (an if else statement is almost the same everywhere) there are some fundamental coding practices that I might not know so switching to another language just like that might not work out. But I will have a go! :)
I would imagine a naive `mySlice = append(mySlice, more, elements)` would automatically do that for you. It's such an obvious implementation that I'm not even going to check the source for it right now, I'll just blindly assert that yes, it is not reallocating a slice per append.
The last thing to consider is that in your tests, you probably had huge swathes of your data set already in L2 cache, if not L1 in some cases. Slices are contiguous in RAM, so in the "best case" for slices, if you're checking to see whether a given byte is included, it may much faster to check a small slice, because on the first check, you'll pull in a huge chunk of the slice into L1 from RAM and iterate through it faster than you can do a map lookup, and the map is more likely to sprawl across multiple cache lines. That said, your measurements are certainly more in favor of maps than I would have expected under the circumstances you were testing, so hats off for actually testing it.
Check out http://godoc.org/github.com/gonum/graph I was absolutely impressed on my first scan of the project.
By "use gofmt" always, I'd include _run it when you hit save_. There's really no reason not to. Your editor should be able to be configured with some sort of hook to do that; if not, change editors. You may also want to consider adding `-s` to gofmt. I'd also recommend setting up some sort of syntax checker, like flymake for emacs, that does live syntax checking. That's incredible helpful for learning.
It's not quite doubling, I believe it's n/4, but the complexity is the same.
I do write much client code in Go, of course with GUI wrappers in a different language communicating with a Go daemon via sockets. Go is a really good language for client-side network stuff as well. Lots of my users use XP (China!).
webstockets from mobile device are gonna be a pain in terms of battery life and other things.
where can i find the sublime interface?
This is the same article I published a few weeks ago on the blog. The great people at MongoDB said it was ok to do that. Originally the post was going to be released at the same time on both sites, but life happens. Since people outside of the Go community will now see the post, it was good to get feedback and corrections before. Thanks!!
Another interesting use of empty struct is in emulation of set structure using map. It saves memory by storing empty struct into map values. 
Hm, thanks. I couldn't find it distributed with Go, so I wasn't sure. The license distributed with Go only mentions the source code and binaries, not graphics.
Damian Gryski posted this on twitter by Brad Fitzpatrick Package iter provides a syntactically different way to iterate over integers. That's it. https://github.com/bradfitz/iter/blob/master/iter.go
Which gopher?
Seeing the gopher remix with a tie instantly reminded me of [a very old gonuts topic](https://groups.google.com/d/topic/golang-nuts/JZ-gUROfB5A/discussion) where someone complained the logo wasn't "professional" enough. Somehow that turned into a discussion about the mascot instead. Some people expressed fear that management would never take the language seriously with a silly mascot like that. Gustavo Niemeyer, ever the helpful chap, [had a humble suggestion for a quick fix](https://niemeyer.s3.amazonaws.com/professional-go-logo.png). I thought it was a great suggestion, but the complainers did not seem satisfied, so I [tried to make it appeal even more to upper management](http://i.imgur.com/43wQr.png). Oddly enough, the Go team decided to stick with the original mascot. Imagine that.
Interesting bit of history! Ha, the "professional gopher" has the tie over his shoulder... I think... :)
http://wiki.minix3.org/Mascot
The [cowboy gopher](https://rawgithub.com/ianremmler/atxgolang-logo/master/atxgolang.svg), vectorized for your enjoyment. https://github.com/ianremmler/atxgolang-logo
So kids these days think that's twitter notation, huh?
I tried it with an empty struct, the results are not different. Or if they are, then the difference is negligible. But indeed, memory wise, for a set there's no point using `map[type]bool`.
What would you suggest I should do to nullify this possible effect?
I'm a rails dev in my day job, and I really just don't find the Go language lending itself to that kind of organization. As much as I'm comfortable using rails, I find myself forcing Go into that archetype, rather than the language writing itself into it.
I'm somewhat biased because I'm a Revel maintainer, but I think it's a fantastic framework. Its one downside in my opinion is the use of Go's `http/template` package. I'd like to one of these days rip apart Martini and see what its benefits are.
Maybe part of the reason is that Revel and Beego are kind of half-baked Rails imitations. So people rather choose smaller components and glue together their own stack. So if one component is deprecated, its easy to replace, while if Revel dies, than dev is screwed. Maybe what you guys need to do is, instead of trying to be like Rails, take good parts of Rails design + build on top of the design with some new innovation and re-purpose yourself as modern stack. Like what sails.js in Node.js world is doing. They took MVC as base, but decided to build a framework for creating RESTful JSON API's + some RealTime stuff with WebSockets. So maybe you could try making a fullstack Go framework that would be great base for building JSON API's, where the View part is json templating. Do nice, coherent error handling, logging, integrate with profilers, create a pattern for deferred processing, etc etc. 
With "struct functions" you mean methods? You need methods when you want polymorphism through an interface.
I don't really know Revel (just looked into docs few times briefly) or Play!. I'm just somewhat upset with Rails right now, as I'm trying to do something it won't let me xD
Thanks for the recommendations. I've already implemented syntax checking with vim, I have vim set to compile with Go upon write to pick up any compile time errors and highlight the issue, so I'm sure gofmt will be easy to implement :)
I completely agree. Martini seems like the way to go if your just starting in on a project, but the one thing I do like about revel is that it helps you a bit with code organization. I still havent quite figured out how to structure martini (or just go projects in general). The MVC way is pretty clean, but I agree with Jan, its just not really how the go language works 
You should *not* `defer conn.Close()` until *after* you've verified that the connection was successful. Less importantly, FWIW, I think it's far simpler to just do `c, err := net.ListenPacket("udp", "127.0.0.1:9229")`. If you actually need or want the `*net.UDPConn`, just assert it `uc := c.(*net.UDPConn)`. 
I don't know how to do it reliably. I'm not sure it deeply matters, your numbers still have significant validity; it's a valid use case, after all.
google () { google-chrome "https://google.com/#q=$(IFS=+ ; echo "$@[*]")" &gt; /dev/null }
I'm glad to see development on llgo like anyone else, but just because one developer who has a job at Google is working on a project hardly means the entire company is backing it. It's not even obvious if he is working on it /at/ Google or just in his spare time.
You should write methods when you want [object-oriented encapsulation](http://en.wikipedia.org/wiki/Encapsulation_\(object-oriented_programming\)). Keep in mind that you can make your struct's members lowercase, which limits access to your own package. This is a little like making members "private" in C++, Ruby, etc. Then you can add uppercase methods, which are "public" in C++, which provide restricted access to your private members, such as by ensuring they can't be changed by code outside your library. 
Your title got my hopes up that someone was picking up the [googlecl](https://code.google.com/p/googlecl/) project and porting it to Go... sad times.
you have an extra pair of parens after the `func` keyword in your `remind` definition. Edit: the reason for that particular error message is because parens after `func` are used to declare the receiver for a method. For instance, if you have a type `Foo`, you can declare a receiver method on it with func (f Foo) Do() { ... }
Thank you! At least that error is gone now :)
Thank you! At least that error is gone now :)
More and more I'm getting tired of the "this isn't finished yet but give us money so it'll maybe get finished someday" approach.
30 bucks for an ebook? What a scam.
Sounds interesting. Could you perhaps show some snippets of the code and/or how you structured it?
I believe Manning doesn't do this for the money, they do it so people can get their hands on it early and contribute feedback that leads to a better book.
You could just wait until the completed book is published. MEAP buyers get chapters as they are completed, but everyone can purchase the retail edition at the same time.
Is an ebook less valuable than a printed edition? You do save 8 bucks for the paper, printing, and distribution costs. 
Here are links to the book and the first chapter: http://www.manning.com/ketelsen/ http://www.manning.com/ketelsen/Go_in_Action_MEAP_CH01.pdf
What would an experienced developer learn from the book?
The goal is to release 2 new chapters every 4 to 6 weeks plus edits to chapters that are released. This is a lofty goal but what we are working hard. I really hope sometime by the end of the summer/fall we can be in print. As for the discount code, I don't know. I will find out. 
This discount code is valid until tomorrow. There will be others, but not likely this level of discount.
I think I will buy the ebook. I prefer printed books, but shipping from the US to Europe is so expensive. :-( Looking forward to reading the chapters as they become available.
Ok, my fault. Didn't notice that.
How do you mean? I think the answer is that it isn't something you do on purpose, it's something that just happens. If you start iterating along a slice, it'll be pulled into the cache, sequentially. I specifically said "byte" slice because that gets you the most elements pulled in in a cache line.
Thanks been waiting for it. Even if you know Go its always nice to read a few books because you learn new ways to do the same thing old thing.
It is interesting to see a value proposition and human psychology meet. The internet has trained ebook purchasers that an ebook is less valuable than a printed book. User /u/jan1024188 is most likely trying to articulate that the pricing variance between print and electronic versions isn't great enough. Instead jan1024188 fails by claiming this is a scam, which it isn't, it is an offering to buyers. I would further argue that Manning is failing to offer a pricing experience that book buyers expect, which is potentially hurting their conversion funnel. edit:words
Could you comment a bit more on what will be in chapters 7 and 8 (Standard library and Network applications)? Thanks.
Also, after the discount the price is 15.99 USD.
Those chapters aren't yet written, but they will bring specific learnings from our experience writing and evolving several large network applications. One application we manage services millions of API requests per day, each firing off several dozen Go RPC calls. We had a lot of learning opportunities putting that in production. 
We fear the HN beast :)
Probably with a GL context/windowing library like GLFW or SDL. If you know OpenGL, then it should all be familiar from there using a package like http://godoc.org/github.com/go-gl/gl. I personally use http://godoc.org/github.com/go-gl/glfw3 for windowing, but SDL is also a good option. Have a look through http://godoc.org for an existing Go package, but note that many results are going to be github forks. Edit: If you are on Windows, things get messier just because dealing with MinGW is usually not straightforward, especially when you get into the Win64 forks, and then you need to download and build the source of GLFW/SDL . Also the -Hwindowsgui flag. I think your windowing package should explain that...ideally. If you are on Mac OS X or Linux, then you just need to install the developer libraries for your windowing library of choice using your package manager (or build from source), as well as GLEW which the github.com/go-gl/gl package uses. If you are not familiar with OpenGL, this will all be a bit daunting, but there are places you can go for help with that such as http://open.gl/
If only you could just not buy it :/
Awesome! Going to have to give this a try. Does sockJS fall back onto AJAX/flash like socket.io does? 
That's a great idea. We don't get to choose our cover, but I will suggest it.
I see. On OS X, you will need to make sure you have the clang toolchain setup if you haven't already, aka "Xcode Command Line Tools". With Mavericks I think you can just enter `xcode-select --install` in your shell. Actually, I forgot there are some GL examples that you can build to at least verify your environment is good: https://github.com/go-gl/examples/tree/master/glfw3/gears
It doesn't really apply to Go as Go doesn't really follow the "let it crash" paradime.
This looks really cool. The biggest downside I can think of so far is that as a Go developer, you really want your public libraries on Github and the like. Private repos would live nicely here.
I'll try my best.
Thanks for the discount!
you might find this interesting: http://www.gocircuit.org/ It's kind of like OTP with the message passing with channels over the internet.
I'll rather buy clean and DRM free Ebooks from Oreilly than the watermarked stuff from Manning.
I fear the reddit monster, personally. :P
I am very familiar with that documentation. It's not so bad.
I don't know whether Peter is working on company time or not (I haven't asked), but I'm glad for the help and very excited about having a solid runtime behind llgo.
What? All you need to do is make sure a `.git` is somewhere in your URL, or have a `go-import` meta tag on your page. That doesn't seem difficult at all.
I'm working on it. Unfortunately, at the moment I'm currently spending my evening and the past several days resuscitating the Erlang service that my Go implementation is supposed to be replacing. (It isn't Erlang's fault per se in this case; all systems have limits and we exceeded ours.) I'm glad I haven't published any of the clustering and messaging stuff on github since I've had to completely rework the interface twice now. If you want to see when it goes up, [subscribe to my Github](https://github.com/thejerf). (And unsubscribe as soon as it does for all I care; I'm not looking to collect subscriptions or anything. It's just, that's where the news will show up first.) The supervisor tree translation can't be perfect, but it can be useful. The clustering is somewhat more useful, though there's a bit of an impedance mismatch between channels and mailboxes. On the other hand, mailboxes _do_ work better over networks than synchronous channels.... The purpose of what I'm building is precisely to make porting Erlang stuff easier. That means it isn't necessarily the best choice for a greenfield project, but I may be able to help you out with porting. I hope to have it up within the next couple of months.
We have five chapters written, 4 chapters reviewed externally, and 2 chapters released in this MEAP.
Go as a language is moving very quickly. Are you planning on sticking with the most current stable release at the time of writing, or are you planning on updating the book as the language evolves? Regardless, I bought the e-book. I like seeing seasoned developers writing books over real-world applications. Keep up the good work!
Thanks for the discount. I just purchased it. Good job, guys! Virtual beer for those that authors that virtually sign it. ;-)
Come to GopherCon and we'll sign it for real. And drink that beer.
I'm curious - can you elaborate on the Erlang limitations you've hit, and the rationale to port to Go ?
I just implemented this at work for Github:Enterprise. The biggest problem was intercepting requests to Github not generating the meta tag.
Don't know if it's very Rails inspired, but I'm using a pretty basic MVC architecture for my project [gophish](http://github.com/jordan-wright/gophish). I'm splitting up the work into ```models``` and ```controllers``` packages, with basic templates to serve as the main views. This makes it easy to put a REST API behind everything.
Honest question: what's your issue with watermarking? I'm not looking to start a flame war. Just curious
Can those of us with ebooks get pdf signatures ;)
Who clicks on a book announcement to tell the world they aren't going to buy it? 
I haven't used Allegro before, but it might be worth looking into, I suppose. Is it possible to use OpenGL together with go-allegro?
Looking forward to picking up a plush Gopher for my son at Gophercon. It would be nice if the next gen plush design gets the eyes more correct. They look like spaced-out fish eyes on the plush but the drawing looks smart, happy, and busy. 
Looks nice and promising.
I like your email package.
My name and email address don't belong on every page of a book I buy. First: Having a book with a watermark forces me to be super careful to disallow access by anyone else than me, because any other person could possibly leak the book to the net and then it's out there with my name on it and I will be accused of leaking it. Second: I feel insulted by watermarks. When I pirate a book I get a clean version, when I honestly buy it I get a mutilated version with ugly watermarks on every page. Companies must realise: Putting watermarks in your books is like pissing on your loyal customers. Your books will get pirated anyway, so don't dispell the people who want to pay for them, by making the bought product worse than the pirated one.
So I noticed a traffic spike from two weeks ago, just to realise that someone has enredditted my article :) Thanks @babawere! By the way, https://github.com/benbjohnson/megajson is also interesting, for those seeking to do even faster JSON decoding.
&gt; I would like to see if there are any other options that we (i.e. Google) may be able to offer. This *might* indicate that, hence the "(?)" in the title. Also, the progress in his repository *suggests* it's not just a spare time project. Again, these are just some indicators, not hard proofs.
There's GoSFML2 bindings for the SFML2 graphics library: https://bitbucket.org/krepa098/gosfml2 I am trying it out and it works pretty well (at least for now)
GoPorn
I'm doing precisely that these days. I use the gl and glfw3 packages from go-gl: https://github.com/go-gl/gl https://github.com/go-gl/glfw3 GLFW3 has a weird quirk: For some reason, it canNOT be statically linked, only dynamically. I can help if you need assistance with that on Linux. I do not know how annoying it will be when trying to ship the game. I use the core 3.3 functions and they're almost all available (and if not, it's super easy to add them). The go-gl/gl package wraps most of the OpenGL calls into object methods; it is a pretty lightweight and low level wrapper which does not get in the way. One BIG trap: make sure all your OpenGL and GLFW calls are made from the main thread (or at least always the SAME thread). A runtime.LockOsThread in the init() of your program is sufficient. You may spawn other goroutines if you like, but all the rendering code must be in the main thread. If not, OpenGL will silently ignore half your commands. I have not tried rendering text yet. go-gl has a gltext package. The image package in the go standard library can load your jpg and png files to fill your textures, but it is not fantastic. The image package thinks that everybody wants premultiplied alpha, which is definitely not true in many cases when doing 3D since any channel can represent anything. I have a small workaround to prevent Go from multiplying my rgb by alpha (I make go believe the data's already premultiplied). The Go image package does read 16 bits PNGs though, which is good when you use a HDR pipeline. So far, so good, I'm very happy with the Go/OpenGL combination. My code is horrendous because this is the first OpenGL program I ever write so I'm learning everything. My undocumented dirty experimental mess can be found there: https://github.com/Niriel/daggor . 
Not having to deal with the gitlab installation is itself a giant selling point 
There's no denying that o'reilly's model is better. Thanks for your explanation, I agree with everything you've said - but at the moment I don't feel put off enough to not buy from manning
true dat
Once you get going, look out for the GC. Small things like passing a stack pointer to a OpenGL function causes heap allocation. All of the allocations build up until your game pauses every few seconds to clean up garbage. Try to keep testing.AllocsPerRun at zero during your main loop.
Please add advanced stuff. Lot's of people would benefit from it.
Thanks! Glad you like it. I was working on gophish, which needs the ability to send convincing phishing emails, when I realized there weren't many solid email packages out there. So, I made one :D
Thanks! :)
The proximal problem was simply that I've blown out the target machine's memory bandwidth via pervasive (and required) encryption, which isn't a specifically Erlang issue. However, the thing I will be doing when I get done typing this (quick break) is ripping Mnesia clustering out of the product in question, having already ripped out my most important table and put it in Cassandra. The second most pressing issue is that my Erlang cluster just isn't stable, despite sitting right next to each other in the datacenter, and, frankly, seeing levels of load that really ought to be perfectly handleable by MNesia. The nodes just partition for no reason I can see. When Erlang clustering works, it's cool, but when it fails, it's just so _opaque_. For me, this is a key feature, and despite the fact it really seems like it ought to be solid, I just can't seem to keep it so. I'm not exactly sure how to interpret the fact that I can't seem to Google up solutions to the problems I encounter; either I'm doing something quite wrong (but _what_? after several years of this I ought to know, but I don't, despite heavy research... at some point I've done my due diligence), or there's something wrong in the core, and at this point I've run out of concern for which it is. YMMV. The biggest reason is that as flexible as the company I work for is about language choice, nobody likes Erlang. My team has gamely agreed to learn it, and generally agree that it does have some virtues, but nobody ever gets to the point that they _like_ it. Frankly, I don't either... I like the execution model, I like the VM (when not using it in a cluster), but the language is just klunky as all hell. Crazy punctuation rules, a complete failure to take deep advantage of functional programming (it's a very surface FP, if you're a Erlang master do _not_ learn Haskell or you'll cry... and I mean, you don't even have to learn all about the "monads" or other "crazy" things, just the _syntax_ for the same things you do in Erlang will make you cry that Erlang can't do that), it's a very ground-breaking language that should be remembered for a long time, but it's so _klunky_. Fortunately, I've always had a policy of minimizing what's in the Erlang, so porting is feasible. Once we _do_ have Go, there's other features I'm planning on putting in that I was always reluctant to put into the core system, because it is so klunky to work with. Frankly, Go is not exactly a paragon of elegance syntactically, but, well, it does _work_, and it isn't constantly getting in your way, either. It isn't a miracle cure, but it's better. Since the system is designed with Erlang, and I'm trying to create a drop-in replacement rather than a "change everything!" rewrite, I'm also writing the aforementioned OTP translation layer, which is deliberately designed for the purpose of porting Erlang. It won't come out of the first github commit with _everything_ you need, but it'll be a great deal closer than what you can get with stock Go or any libraries I know. In particular, it is an absolute requirement that this server be clusterable, so I'm just taking the clustering system that Erlang has, except I will also be fixing it to be a great deal more verbose about its problems.... introspection is harder, too, since I don't get the free Erlang stuff, but I've got some plans to make it possible to introspect live systems in at least moderately comparable ways.
Thanks. Very nice of you to share your code also.
I think this is one of the best descriptions of segmented vs. contiguous that I've seen so far. If no one's X-posted this to /r/rust, yet, I will snag it and reap the karma.
thanks for the discount code!
Default gitlab instance requires *at least* 512Mb of RAM. Seeing how I only have a 512Mb of OS ram and need to run other shit on that VM, i'll take anything with nice interface that can fit in 100Mb or less :)
So new segments need to be allocated whenever you can't ask the OS to extend the stack down? Can't the OS just pick a physical page wherever there is memory to always grow a stack? How does C/C++ handle the problem?
I know this thread is old but for posterity's sake, it's worth pointing out that the second example is totally valid Javascript and WILL run in Node. "Pseudocode" may have been a poor choice of words, though I assume it's because he didn't actually implement the sendEmailAboutData function. Re: callback hell. Promises, 'nuff said. It makes the code read just like synchronous code, and if you indent according to (perfectly reasonable) standards, you don't suffer from rightward creep in 99% of cases. Re: Javascript is ugly. Javascript is perfectly readable, and CoffeeScript even more so. You just have to, you know, be a good programmer. Re: CoffeeScript npm modules. I've never seen a module that only exposes CoffeeScript. It may be written in CoffeeScript, but every CS module I've ever seen exposes the compiled Javascript to the module system. Re: Server/client code reuse. Never happens, unless it's talking to a library like Moment (time parsing), FormWarden (validation), etc. *However*, not having to context-switch is beautiful (especially between two C-like languages). Javascript is my favorite language of all time, I've used it for years and here's why: the flexibility I get means I'm empowered to solve ANY problem I'm presented with in day-to-day web development [1]. By using a little common sense, I'm able to avoid creating performance bottlenecks in most cases; and *if* a problem arises, I can devote specific attention to solving it. I find static typing cumbersome, and because my job requires me to rapidly develop MVPs (that we will later develop into complex systems), I choose a language and environment that empowers me to do that. Next to the core application, of course, is the amazing web development tooling built around Node. Bower for front-end dependency management is great once you get used to it (took me a while to *get* it). Personally I'm a Foundation/SCSS fan, but we use Bootstrap/LESS at work, and LESS is compiled by Javascript. gulp makes a FANTASTIC build system for compiling my assets as I develop, and effortlessly integrates with LiveReload, so that I can see style changes pushed straight into my browser (a godsend with my 2-monitor setup). Also, my server-side code changes get picked up by nodemon and my server is reloaded, and thanks to JS being interpreted, I don't have to compile my whole app every time I make a typo; it just gets restarted, and often I can test my changes by hitting F5 (assuming it isn't covered in my tests, that is - p.s. jasmine + CoffeeScript == pure awesome). As far as I can tell, by switching to [not Node], I either have to A) give up all my amazing full-stack tooling, or B) switch contexts between client-side JS, server-side Go, and toolchain JS (which does not sound fun). If I'm wrong about the Go ecosystem and there is this level of full-stack tooling built around it, I'd love to be corrected. I understand that I can still use Bower with Go, but since I'd still need Node to use it, there's now a HUGE second dependency on a project that 5 other developers may touch at some point. I just don't see the value in switching right now. That said, I'm actively learning Go right now because I think that, while it doesn't make sense right now, Go has (and is continuing to gain) enough steam that it will be a force for some time. [1] I work at an agency, so my definition of "day-to-day" may be different from yours
Could someone enlighten me as to why this would be practical enough compared to something like [][]int{} to offset the bloat it would add? I know initialising multidimensional slices can be a bit of a pain, but there's a lot to be said about keeping the core syntax simple.
See the "language workarounds" section of the proposal https://docs.google.com/document/d/1eHm7KqfKP9_s4vR1zToxq-FBazdUQ9ZYi-YhcEtdfR0/edit
It feels to me that systemd (or some such) should be in charge of that, not the language implementation
This fails on 32bit architectures. Say one reserves 4mb and the kernel lets the userland use 3gb of ram. This means there is stack space for 750 go-routines before the address space is exhausted. This *is* a problem in C/C++.
Ah, I see. But we don't expect that many stacks in a C/C++ program, which are usually thread-based.
You can switch to vim. &lt;/Obligatory harassment&gt;
Off topic I know, but what were you trying to do with Rails?
Why was Zen Coding or whatever it is called now so impressive for the Visual Studio 2013 then? It was available for nearly all editors and IDEs since many years. But still, MS did a 90 min promotion and demonstration and all guests applauded like crazy.
My dependencies are all versioned with my projects. Of course this approach only works when you're not planning on releasing open-source libraries. "go get" along with the GOPATH structure is a stupid, stupid idea. I don't know what the GO team was thinking when they came up with this. It's an active hindrance when it comes to writing open-source libraries whose purpose is consumption third party projects. If you think into the future and envision a growing ecosystem where every library relies on "go get" to manage their dependencies, one breaking change in an important library can cripple the development process of a huge amount of other libraries. Think of the ecosystem as a graph and the important library as a node with high centrality / influence. GO's official guidance is also laughable: &gt; If you're using an externally supplied package and worry that it might change in unexpected ways, the simplest solution is to copy it to your local repository. (This is the approach Google takes internally.) Store the copy under a new import path that identifies it as a local copy. For example, you might copy "original.com/pkg" to "you.com/external/original.com/pkg". Keith Rarick's goven is one tool to help automate this process. This means you have to not only rewrite your own import paths but those of third party packages if they're relying on other third party packages. 
It can certainly pick a physical page from wherever, but it has to map that to the virtual address space, in which case there might not be room for it adjacent to the existing piece of the stack if the stack must be contiguous. For a segmented stack, you're right, there's no issue with doing so. C/C++ runtimes typically deal with this by allocating huge stacks, crashing if you run out of stack space, and failing to create new threads when you run out of virtual address space. (i.e. you can't really create a lot of threads on e.g. 32 bit platforms that have a rather small address space.)
I'm afraid the code won't help much since it's still a badly abstracted ball of duct tape. But who cares?
Build a web service that can be used from native mobile and SPA style independent web app. The Rails stack is too intrenched with old way of doing things, and therefore I was unable to get rid of all the overhead to achieve my goal (remove lots of Rails/Rack crud thats not needed) and build a pure API. node.js, PHP and Java stacks all offer what I need, but no, Rails is making it super painful. So I've started looking into Go again. Its an emerging technology, so library support is weak, and maintenance debt is to be higher, but it may be worth it anyway. I have 2 small Go projects in production, my next project will be quite a bit bigger tho.
Indeed it is. My personal experience with language design has shown that a language quickly gets messy when you include half-baked features and try to expand them later on. If there is no strategy to implement arrays with even more dimensions, there will be a mess when people try to do so anyway.
Things to keep in mind: * Read others' code as often as possible, and don't get discouraged when you see that theirs is superior to your own. With a little practise, you'll be coding as well as the best of them so treat these repos should be a source of knowledge and inspiration. * The docs are very good, and should hold you in good stead. You won't find that many StackOverflow questions in the search results when you run into any issues so you'll have to dig deeper, into the docs, blog posts and repos. This is actually a great thing because you won't get used to having answers served on a platter by SO. * Build things. Its the best way to learn and its immensely rewarding. I feel Go is simple to learn and easier to master compared to older languages that have had many features tacked on ad-hoc over the years. Have fun coding! :)
There has been a proposal to add multidimentional arrays for a while now: https://code.google.com/p/go/issues/detail?id=6282
One way in which I am definitely not using Erlang as "intended" is that my system tends to send a few large messages every so often, rather than lots of small messages all the time. I fought with the GC on that but we eventually came to accommodations (plus it just plain improved over time). I have a hard time imagining that's the root cause of anything else, though. (For instance, said large messages never hit Mnesia, so that shouldn't be it.)
Okay, so full-disclosure, even though I work as a web developer (ruby) I don't have a CS degree, so I'm behind on a lot of concepts. What is a table, and how is it different from just a two dimensional array? Thanks.
So then I'm still confused, isn't that already available in golang?
From the readme, your project looks like a less-mature version of [Webfront](https://github.com/nf/webfront) by Andrew Gerrand. Webfront supports reverse proxying and static site serving over http and https. Does Mist support proxying webapps that use websockets?
In go, a two-dimensional array has dimensions which are known at compile-time. For example [5][5]int will make a two-dimensional array. A slice has a length (and capacity) which is known only at runtime (a dynamically sized array). []int for example, has a length which is not known at compile time. One cannot create a multi-dimenisional slice ("table" in the proposal), where the data has a specific number of rows and columns and the sizes are not known at compile time. 
Have you looked at the [rails-api](https://github.com/rails-api/rails-api) fork championed by, e.g., Klabnik and some of the other maintainers?
Kinda irrelevant, but have you seen my [poll](http://strawpoll.me/1377417)?
Yeah thats what I'm using. Its just that none of the nice libraries work with it.
I have now. Gave me a few more things to google for, thanks :)
I wrote a library to let you do this flexibly that might help you: https://github.com/inconshreveable/go-vhost It also supports SNI multiplexing of TLS connections which is the foundation of this project: https://github.com/inconshreveable/slt Maybe I'll submit a pull request to you.
I really like Martini, although standard net/http is pretty good. Maybe add gorilla mux if you need more routing options. Writing middleware for both net/http and Martini is pretty straight forward, so I don't wonder why its the 2 most used things.
This is all great! Thank you for taking the time to comment, I'll be sure to take this all on board along the way :)
Wouldn't copying the whole stack to grow it be kinda expensive? Why not wait to deallocate the stack segment till when the stack below becomes empty? 
My personal view is to only have core methods that access the struct and only a few of them. These are methods that essentially get and set values in the struct but from the point of view from users of the package. The core methods are the only way to access the struct and maintain invariants of the datatype. It doesn't mean you simply create a getter/setter for every field. Think about it from the package consumer's point of view. Some struct field may be private to the package. I then create functions that call the core methods that do other things I need to do. This allows me to freely change the struct and only have to update a few core methods. 
I don't think you will find anything as comprehensive as Scrapy but I've had some success using net/http with goquery for relatively simple tasks. Crawling and such shouldn't be *too* hard for you to piece together the logic yourself. Goroutines/channels and go's built-in libraries will also do you well here as they are quite thorough for a language as "low-level" as Go. Persistence-wise, you have a lot of options available. You could use something that is a database/sql driver such as for MySQL, a full-blow "ORM" such as gorm, or just do JSON dumps into Redis, RethinkDB, Mongo etc. The (scraped) data you will get is probably highly relational so you may want to account for that somehow.
I've used [go.net/html](http://godoc.org/code.google.com/p/go.net/html) with some success
you don't know beego. so many real world example. all of them are high performence. http://beego.me.
How the fuck has this guy never ran into a breaking change?
I looked at those as well as this one: http://godoc.org/launchpad.net/xmlpath and yes you are right the concept itself is trivial to be implemented in go, but there is A LOT of boilerplate I just dont want to write. That was my idea to get some basic scraper thats build and just focus on optimizing and implementing the features i need, I dont want to rewrite everything from scratch, since if there isnt anything in go I guess I'll stick with Scrapy...
Oh yeah, it's a pain in the ass, it just happens to get the job done in my case. You can always write something in Python+Scrapy and talk to it over some sockets, if you'd still like to use go.
 Here's something I wrote awhile back: https://github.com/dmuth/cat-crawler Contributions welcome. :-) 
Have you tried https://github.com/PuerkitoBio/gocrawl ?
systemd + etcd?
We're building an enterprise SaaS webapp using both Gorilla and Martini. Happy to share our learnings in due course if people interested...
Both Martini and Gorilla? Just curious, what's the need for both?
Martini and net/http does indeed seem like a killer combo!
My contribution: https://github.com/fern4lvarez/go-metainspector Hope it helps.
Webapp layer uses Angular + Martini. API layer uses Gorilla. No views. 
I've got not much time, but I would contribute changing the README and description: it's Go, golang, #golang, as you want, but NOT Google Go. 
I've changed the code, so that the proxy is more transparent between the client and the proxied endpoint. In theory, it should now support web sockets. Feel free to give it a go and see if it does. I'll give it a test myself later today.
Would you say there is much to gain by using Martini for website and gorilla for API? Couldn't you use one of the two without loosing much?
[**@wefreema**](https://twitter.com/wefreema): &gt;[2014-03-28 02:08:55 UTC](https://twitter.com/wefreema/status/449367497796763648) &gt;My wife made me a traveling companion for [@GopherCon](https://twitter.com/GopherCon). [#golang](https://twitter.com/search?q=%23golang) [*pic.twitter.com*](http://pbs.twimg.com/media/Bjx5Wy3IQAAnwE-.jpg) [^[Imgur]](http://i.imgur.com/7DQV2GS.jpg) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/21lo2v%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
when i've had a need for super fast scraper (ported from Python Scrapy because of performance issues) i took GoQuery (https://github.com/PuerkitoBio/goquery) and a bunch of channels. was very easy to query the page and performance is awesome.
Credit to the pattern creator as well, although I think it wasn't followed exactly! http://jteeuwen.nl/posts/2012/10/08/golangs-gopher-mascot.html
Genuine question. I often see people calling Go's type system unsound or dated. But what exactly is wrong about it? As the author of the article put it, it's like C's sans much of its headaches. What is this thing that any software developer needs that Go's type system is lacking? (Apart from generics/templates that are indeed useful and convenient, but not indispensable.)
As someone who has written a fair bit of Go code, I also find myself keeping a close eye on Rust. The things that really appeal to me are the possibility of immutable (by default) types, thread-local memory (ie. owned pointers), no null pointers, and generics. These are all basically aspects of the type system that make concurrent programming safer and more predictable.
Anybody else thought the author said "Go is better in a lot of ways, but I'm betting on Rust because it's functional"? Most of what he likes about Rust involves confusingly, not pleasantly, concise syntax.
As a C# developer by trade, I like the simplicity of Go, I really do, but it is sometimes frustrating having to write boilerplate 'contains' code, and the like, because of the lack of generics. This means that sometimes in Go what the code is doing is less concise than it could be which affects readability and therefore maintainability. It's a pity as otherwise Go code is incredibly readable. I don't think the Go authors are adamantly against generics. From what I've read they want to solve the problem in a compelling way rather than just bolt on a half-baked generics facility.
Not having tables has been such a tiny issue I forgot they could be useful to have. Anything you can *really* easily live without should be avoided to keep the language as small as possible.
While there may be valid points, some aren't imho: convert.AppendBool(...) vs strconv.AppendBool(...) Which one tells you more about AppendBool?
Yup. I think it's a matter of what you value. Go tends toward explicit, consistent, and simple code such that it reads easily and compiles quickly. Though I've never used it, Rust seems to lean toward more features. I suspect the author is pre-disposed toward Rust. Rust may be a fine language, but I had a hard time reading his last two code examples. And, quoting Jared, "Not that this has to be a competition" -- but the article is titled "Rust vs. Go."
I think Rust is promising - I like it that right now Rust seems to generate faster binaries than Go but I have a feeling that eventually its expressiveness will become its pitfall when it becomes almost as messy as C++.
I wish unused variables would give warnings instead of compile errors...
"Your task is to look at the first line after the function signature in order to discover what the variable named nn represents. Ready, Go!" That's not fair, because nobody sees only that line alone. Even the author gave us the line in context. That said, I should mention that Mike and I work together, and we've have had these discussions before, along with Jonathan (jonathanoliver.com) -- multiple times. Annnnnd... I still disagree. (Though we do understand each other better.) I just don't have his thought process very often when reading "brief" Go code. I dunno. I don't think that using longer variable names is bad. But I do think if it's done, it has to be done *very* carefully so as to not mislead the reader or leave any room for misinterpretation. Then your names are just as much "documentation" of the code as your comments and external docs are.
go had breaking changes before 1.0 so does rust
I think (and hope) Rust will eat into C and C++. I think Go can eat into the Python/Ruby/Perl space. I won't say they aren't competitors at all, but I don't think they're going for the same niche. Rust is likely to be overkill if you don't need that much power, and you often don't. But if you do, it looks like a good choice. I think it is quite likely they will coexist nicely.
The two languages had very different design decisions. Go was designed with a mindset of "Lets keep everything as simple as possible, features only get in if every agrees that they are needed" Rust, on the other hand was more designed with the idea of "Lets provide a lot of the features that people seem to like and play around until we get the right mix". Go's syntax from beta has been pretty static, it really hasn't shifted a lot. Rust, on the other hand, has had syntax changes all over the board. Features have been added, removed, re-added, shuffled, etc. As for the space they are targeting, those are really different. Go isn't truly trying to compete with C or C++, it is trying to compete with Java. Rust, on the other hand, IS trying to take on C and C++. It isn't particularly trying to take on Java. The types of programs written for those spaces are pretty different. Those have lead to different decisions. The biggest being that Go is GC and rust isn't (though it does strive hard to make it hard to memory leak). The languages are just different. They target different audiences and different application spaces.
Go also had the sense to include an automated source fixer. Which I was alluding. 
I'd argue that Go and Rust are different languages completely. You don't compare C and Java - Rust is more akin to C and Go to Java than Rust is akin to C.
Rust looks fascinating but right now it is changing too fast for my tastes. I plan to give it a shot once it hits 1.0, just like I did with Go. Who knows how long that will take or how much Go will have evolved in the meantime.
+1 for the detail, but I don't think Go's creators are "ignoring type system research from the last 20 years" -- they certainly have done the reading. They just chose a specific feature set for Go.
Go's first public release was a lot further along than Rust's, which has been public since it was very very young; and so the sort of changes that happen in Rust are like those that would've happened before the very first Go release (if they did in fact happen), in particular, Rust is changing so fast that keeping a tool up-to-date would be hellish.
Go has been spreading like wildfire in the San Francisco Ruby community. 
Django/Pythonista here. I've enjoyed Go and have already found it to be a productive replacement for some simple pieces.
&gt;*Rust is more akin to C* and Go to Java *than Rust is akin to C*. It makes no sense.
Nearly all the Go jobs that have come my way have been Ruby shops. Not sure why Ruby shops seem more open to it, but they do. 
I like the phrase. I take admits to mean that it allows it in - it doesn't have to come in, it's not always prudent to let brevity in, but with familiarity, brevity can be allowed in to try to do reasonable things.
More Hellish than keeping an extensive standard library up to date?
Yes, because keeping Rust's "extensive" stdlib up-to-date is automatic (i.e. the compiler won't bootstrap without doing it), and only requires knowing the current syntax. A fixing tool would be *really* nice, but it would require encoding the syntax/features of older versions, along with their replacements in newer ones (including all library changes/movements)... and many breaking changes are removing things that don't have a sane replacement (i.e. the replacement is to do something completely different). Rust is definitely not a language for people who want stability at the moment.
I wouldn't say *completely* different, but it certainly feels like they did go (pun intended) for a bit of the Java space – Go is always garbage-collected, doesn't have very expressive syntax / functional programming stuff… Rust is, like, the Scala of LLVM :-)
I can see that the haskall &gt;&gt;= operator is really nice, but without that operator it seems like the option types and the error types are more or less equivalent. Am I missing something? Errors are nice because you can read what they output, and actually do error handling (if the error is X, do Y). How do you do that with an option type? I also don't understand inferencing. In real go, you can do var x []int if (flag) { .....x = []int{1,2,3} }else{ ....x = []int{4,5,6} } But I'm guessing that's missing the point somehow. Is the following code okay var x if flag{ .....x = []int{1,2,3} }else{ .....x = "string" } If so, could you then end with a "return x"? What would the signature be? Thanks.
You have Option (with Some(x) or None variants) and Result (Ok(x) or Err(err) variants). You use first when you dont care about the reason something failed and the latter when you need to provide some error value (like IO errors)
It forces you to write good readable code. Never a bad thing in the end.
&gt; I can see that the haskall &gt;&gt;= operator is really nice, but without that operator it seems like the option types and the error types are more or less equivalent. Am I missing something? Errors are nice because you can read what they output, and actually do error handling (if the error is X, do Y). How do you do that with an option type? You're completely correct. If you want to know how something failed Haskell uses another sum type called `Either` which this [post][et] goes into more detail. However as /u/aarjan has pointed out, we can declare our own sum type `Result`: type Result a b = Success a | Failure b func DoFoo(foo Foo) Result Cat { ... } If there is a success we use the same behavior as before. If there is a failure, attach an error message and return `Failure`. The behavior is the same as before after implementing the `&gt;&gt;=` operator for our new sum type. You would decide where it's appropriate to handle errors instead of propagating it up. func foo() ??? { var x if flag { x = []int{1,2,3} } else { x = "string" } return x } This is a compile error because the type can't be determined at the time of compilation. In an OOP language, both branches need to have the same parent class. In Haskell / Rust, both branches need to belong to the same ADT / [enum](http://static.rust-lang.org/doc/master/tutorial.html#enums). In C it'd be a union. [et]: https://www.fpcomplete.com/school/starting-with-haskell/basics-of-haskell/10_Error_Handling
Mention a variable that never gets used could become confusing especially if the name is similar to another. Cleaner is better IMHO
No warnings. Ever.
There are a lot of Rubyists into go, and a small but significant minority of Rubyists that are into Rust.
I don't quite agree with the author here. For one thing, the terser form is easier to read for non-english speakers. In addition, just like comments may fall out of sync with code, the name of a variable can be deceptive, especially when looking for bugs. You are going to have to read the whole function in depth anyway, when you're hunting for bugs. It's more important to look at what the function is actually doing, rather than what its variable names imply. Then again I'm an APL user so I may be biased :)
4 spaces for code.
I recall that there is a flag you can pass to the Go compiler to allow you to have unused variables. 
I've been testing this for just over a day now, and I have to say I love it. It's not missing anything I need from a Go dev editor.
In the last few weeks, I was considering creating exactly a plugin like this. I think there was a clear need and it's great to see someone was faster than me:) I'll start testing/using it right away and try to help the development.
When you have a huge list of data types you have to implement having to put in padding for the damn thing to compile is a pain. You're working around it one way or another.
Either way this isn't likely to change any time soon.
Hey man, I wrote a pretty simple skeleton app here: https://github.com/jadekler/git-go-websiteskeleton. I wouldn't call it a framework - just an idea what makes sense to me coming from a django/zend/maven framework history. I'm are working on an app that uses this template and it is going great - https://github.com/jadekler/git-go-d3-concertsap, which uses gorilla (which comes with the skeleton) for routing and gorp for db. Check it out if you want some ideas on how to go about things.
Good choice. I've already attempted to pickup rust 3 times at various versions before getting frustrated at the next release breaking all my stuff.
Happy that you liked it!
All contributions are welcome. Just open an issue for any suggesion/improvement :)
heh, just got my .vimrc healthier thanks, it was full of stuff from unrelated places for go.
My take is that Go is a lot like Objective-C with better multi-threading and a syntax that is more appealing to someone coming from any C-based language except Objective-C. Rust is more like C++ with better multi-threading and much nicer syntax. I'd rather write a server in Go and a game in Rust. Go is easier to use, but Rust is much more powerful. It will be interesting to see how each language evolves.
It sounds to me that they are really looking for Rust. Go is a great language, but it is really a next generation replacement for Objective-C, Python, or Ruby rather then C or C++. It would be nice to see Rust-style metaprogramming in Go, but otherwise I think it is a great language.
Great! Thanks for including errcheck.
Hey there, I'm looking for comments. I wrote that as part of making `rubyobj`[1] faster for big dumps. When I was profiling `rubyobj`, after parallelizing the decoding, I found that decoding JSON was the next bottleneck. I tried to use megajson[2] but it didn't work because of the `[]uint64` field in `rubyobj.RubyObject`[3]. As I was getting started writing my own JSON parser, I realized that megajson's scanner was pretty easy to use and would fulfil all I needed. So I came up with fatherhood (name is a brainfarted wordplay on json-&gt;son-&gt;father). By the way, if the name is somehow offensive to someone, I'm fine with changing it. Thought I don't think it is. [1]: https://github.com/aybabtme/rubyobj [2]: https://github.com/benbjohnson/megajson [3]: https://github.com/aybabtme/rubyobj/blob/master/ruby_object.go#L20
Thanks, great to see a 'full example' showing how the different parts can be used and combined!
Because if I'd use branches, you couldn't use go get to fetch a specific version of the code.
&gt; Go lacks type inferencing. := is an improvement, but it is properly called type deduction. Do you have any references that describe this distinction between "type inference" and "type deduction"? To my knowledge, they are synonymous terms in general, though I would be interested to see reference material that makes a definitional distinction between them. As far as I can determine, "type inference" means following a process of logical deduction of types omitted in the program text via application of deduction rules to the type relation environment described in the program text. It is a component of many type systems, and can behave very differently in those systems depending on the features of the type system and the deduction rules available to the inference engine. I think the definition I gave earlier fits what Go does in the case of :=.
No prob. It's still a work in progress =) Give a PM if you need anything.
I wouldn't call the name "offensive," just non-obvious. Maybe "jdad" would be better. 
 Oh, good catch! That was my first Go project, and I wasn't sure what the "proper" name was for the language. I fixed that now. 
Jdad sounds like a Java lib
Installed plugin with Vundle, and Ctrl+x/o still give me Omni Completion: Pattern not found. YCM works fine with Python before. It's the same issue for me with vim-gocode and now vim-go.
Hi, I would like too! This doc: http://golang.org/doc/contribute.html is the only thing I need I guess right? Let me tidy up most of the things first.
Nope. It's been suggested on the mailing list a number of times, but it's unlikely to ever happen.
Yea. This style is so readable. I'd say that it got absorbed into my style from reading all the go std library code.
This is the core observation that drives Dijkstra's famous Goto Considered Harmful. The reason why goto is considered harmful is not simply that it creates convoluted code of its own accord, it is that it throws away vast amounts of useful information when it comes time to debug the program. Recall that in his time, "goto" was not a limited construct as it is in nearly every major modern programming language, one allowed only to leap around safely within the current function, but often the _only_ flow control; a modern programmer can hardly imagine a world where a "function" barely exists and is manually implemented, but at the time that was still a major programming style, especially if you were a "I'm a Real Man and I use Nothing But Assembler" type of programmer. The sort of programming that allows you to capture this information and use used to be called "structured programming". Today it's so ubiquitous it doesn't even have a name... it's simply how programming languages work. But if you've ever heard that term and wondered what it really meant, what it really means is what you're describing here. The use of "for loops" and "while loops" and "if blocks" etc etc are the tools, the desired goal is to give the programmer these tools for structure the code, understanding the code, and debugging the code. The modern closest equivalent to spaghetti code is the world of "event-based programming", where for each event you live in a little structured programming world, but at the end of each event, you throw all of this information away and re-enter the world of flat, goto-esque spaghetti code. Attempts to recover from this problem with promises and various other techniques can generally be understood as attempts to recapture the advantages of structured programming from the unstructured bit that lives at the core of "event-based programming", but generally speaking this turns out to be very difficult; having a system that forces you to throw data away at the core, it is fundamentally difficult to build structure around it to repair this problem at higher layers. (General programming rule: Fear anything that discards or destroys data, it is always difficult and often impossible to get it back.) The Go-like way of doing it is actually very solid (as other languages have as well), as it retains the advantages of structured programming, which, as you may recall, is that thing that was so good that there is effectively no longer anything still surviving that is unstructured. If I am sometimes harsh on the event-based world, or at least the part of it that brays so loudly about how much better their approach is (rather than those who are merely forced into it by local considerations; I have my own event-based code I have to maintain because I'm stuck in Perl in that particular place and that's the only choice I get, for instance), it is because they thoughtlessly throw away structured programming without understanding the full horror of what they just did, and think it _virtue_. I think this is because structured programming won _so thoroughly_ that the memory of what it is like to program without the benefit of structured programming has faded from living (or "practicing", if you prefer) memory.
I just replaced vim-godef, vim-golang and vim-gocode with this one plugin. The quickfix fix integration is really sweet.
These are the gotos and embedded ifs you are looking for. https://github.com/astaxie/beego/blob/439b1afb85af7d7827306b75fc048f7fe857649f/router.go#L428-L834 
Great! Simple and effective!
Thank you
Yeah, errcheck is simple but neat :)
I'm not sure what you're trying to say. I know Go has "goto", most imperative programming languages do, but it is constrained to fit within the structured paradigm. You can't "goto" a block not in your function, for instance, or leap into a block skipping over variable declarations. It's a tamed version, not the one Dijkstra warned against. (And just to say it again, I really am not sure what you are trying to say. The previous is a response to my best guess at what you are trying to say; if that's not it, let me know.)
Do you have a blog? It would be interesting to see more in-depth treatment of this stuff than the average reddit comment provides for. I get the sense you're talking about _needless_ event-based programming, and not so much GUI development--especially not any cooperatively-multitasked environments. But it's kind of a hidden implication, since we don't know much about your parenthetical project beyond that it's Perl, which has basically no bearing on the paradigm.
&gt; I get the sense you're talking about needless event-based programming, and not so much GUI development. Yes, "event-based" programming induced by the inability of the underlying language to handle proper context switching, such that every time you do something "slow" you have to handle it somehow with events. When you truly have a stream of events coming in, you're a bit stuck. There's actually some ways you can try to route them into goroutines, but that has its own issues (code complexity, lack of nice library support, etc). GUIs sort of suck in general, by which I mean, it's a hard problem and so the solutions tend to be irreducibly hard. It's a bummer, but dealing with humans is hard. Edit: And yes, [I have a blog](http://jerf.org/iri/), though this has not featured on it yet.
Nice. Although I haven't seen anything shorter on a system with python installed than: $ python -m SimpleHTTPServer Serving HTTP on 0.0.0.0 port 8000 ... Or $ python -m SimpleHTTPServer 1234 Serving HTTP on 0.0.0.0 port 1234 ...
This may be the wrong place for this, but I'm very interested to know which libraries don't work with it.
Actually yes I did. One of the things I did was try to reuse function signatures anywhere it made sense. I found that using different dependency injection all over my code made it difficult to find errors. I think I ended up with only two signatures for the last functions in each route. I also disabled the martini recovery module during development so that I can get stack traces out. The default recovery system does absolutely nothing useful on Google app engine since logging is different there. 
I'm curious, in what ways is the programming style of Go similar to Python and Ruby? Do you mean syntactically or paradigmatically or what?
http://play.golang.org/p/4iQT9EyNmF illustrates this by showing the &lt;nil&gt;
Syntactically (kinda). The time required to develop an application in Go is similar to Python and Ruby, you would also use Go in similar situations.
I've done a ton of programming in Python and Perl over the years. In theory, Go is a greatly less powerful language than those two. That is, it is missing tons of features, even if it does have a concurrency advantage. In theory, that ought to result in a significantly greater development time in Go than in Python or Perl for the same feature. In practice, it's only slightly slower. I do miss a couple of things that do matter, but it's far less than you'd think. And you approach the problems in much the same way you would in those languages, or at least, the way you would if you also had concurrency available to you. I honestly did not expect this in advance. While I still quibble with some Go design issues (I still want some generics), it's way faster to develop in than I thought it would be. On the generic note, I'd have to disagree with the author. Every mainstream language I can think of has some equivalent of `interface{}`, and some even have as much protection as Go does against you falsely casting it into something it isn't.
And how speed compare to https://github.com/mreiferson/go-ujson ?
I use a normal function for factory functions. e.g. `NewFoo(..)` If a function is specific to a type, I make the type the receiver. That way, IDEs can fold (in a UI sense) all functions belonging to that type. 
Maybe it's because I'm new to Go but I write Python much faster than I write Go. Python does have concurrency though, via the threading package, and parallelism via the multiprocessing package.
Very, very useful, thank you.
If you want a more Go-esque experience in Python, use gevent. I hesitate to recommend it for any sort of industrial-strength deployment, but for anything else it's darned useful and very effective. You can tell it's really pushing Python to the limits, and I've broken it in weird ways a couple of times, but it's overall a pretty decent experience if you really like Python. Threading really gets back into the old-school threads &amp; locks world, which I stay away from, and multiprocessing is something else entirely. It doesn't fit my use cases for Go at all, which involves a lot of message routing at speed.
Do you miss exceptions?
Not in particular, but there's a Coursera course on NLP that covers this topic, if that helps... https://class.coursera.org/nlp/lecture
No, not even slightly. Returning errors is a little annoying at first but after a while you realize it's great as it makes you think about handling errors, rather than just letting them bubble up. So where in Java a method will throw an IOException and you have to handle it in an awkward block way down your code, and in C# where you let them ripple up either intentionally or because you forgot to handle it, in Go your call will return a result and an error. You can then handle that error immediately after the call that caused it where it makes sense, or you can choose to ignore it if that makes sense or you can explicitly ripple it by returning the error. Java: Chicken SomeMethod() throws SomeException { try { Chicken c = RearChicken(); return Process(c); } catch (ChickenException e) { throw new SomeException(e); } } 0. Even though Process doesn't throw, the typical programmer included it in the try block as otherwise the variable shopping is awkward. That means you end up with loads of shit in the try and the exception handling in a catch that's miles down the page. 0. Because Java has checked exceptions you're forced to 'handle' then, though quite often that means just wrapping it up as another exception and rippling it up. 0. If the try I'd big then it becomes hard to work out what may actually have thrown. C#: Chicken SomeMethod() { Chicken c = RearChicken(); return Process(c); } 0. C# uses only unchecked exceptions so you don't have to catch any of them. But this makes it easy to forget or to be sloppy and just let everything ripple up to some high level routine that has no context. 0. Typically the exceptions are left to ripple until they become a problem in production, which is not ideal. The fix is then to add in the try block so it's then pretty similar to the Java example. 0. It's even less clear what methods produce errors at all. Go: SomeMethod() (Chicken, error) { c, err := RearChicken() if err != nil { // handle the error or ripple it up return nil, err } return Process(c) } 0. A method may return multiple results and the convention is to put the error one last. 0. The error handling is normally immediately after the site where is was raised as it's the most natural place to do it—to get it out if the way. 0. You can explicitly ignore an error by assigning the returned error to _. 0. You can explicitly ripple an error by returning it from the method, as in this example. 0. You can't forget to handle the error as the program won't compile if you don't use an assigned variable.
You can write that same code a third way, where you nest based on "err==nil" but just don't nest. Eg. http://play.golang.org/p/DHud_fIaHB It doesn't necessarily fit this specific code, but sometimes when you are doing a set of logical steps it can read better than all the returns. It also has the benefit of only the 1 return at the end which I think makes the code more readable.
Damn, I was looking for something like this yesterday and ended up writing it myself. https://github.com/zhemao/hodgepodge/blob/master/servehttp.go
hmmm interesting.Thank you.
rsc has a [good response](https://groups.google.com/d/msg/golang-dev/CGGiLKunggo/2z051XlQO1EJ) to this post on golang-dev.
I made gposttl into a library (basically I compile all files but the "main") and wrote a Go wrapper around it and it works pretty well: http://gposttl.sourceforge.net/ Or you can just run your text through the gposttl executable via popen.
This package is built on html/template, it adds functions to stash bits of templates (after they're rendered) and replay them later in other templates, along with two parsers that will output trees that are put into an html/template Template. EDIT: just realized I didn't mention this anywhere, oops.
Is there anyway you could provide me with the Go source?
A very important take away. The Go stdlib talks exactly the same way to most developers. Its awesome.
Really awesome that you wrote how to go get it integrated with Revel. I'll have to give this a try. html/template has been bothering he lately.
[golint](https://github.com/golang/lint) can be used to harass yourself about documentation. It will help enforce the common conventions, and highlight where you still need to write documentation. I have even found it helps you find dead types and functions; it can bring them to your attention, then when you go to document them you can notice they aren't used anymore. Documenting your entire package before putting it up on github (or whatever) can be a convenient check for that sort of thing. (Coverage analysis can also help find dead functions, but golint is better at finding dead types.) You will grow somewhat irritated when you have a type that implements some interface, and there's nothing much else to say about the function. I think there's nothing wrong with writing `SomeFunction implements the package.Foo interface on ThisType.` a few times. golint will be quiet about it, and it becomes unambiguous to all readers exactly what that is, and where they can find the relevant interface if they need to. I _strongly_ recommend running godoc locally, rather than using golang.org. Local godoc is guaranteed to match what you're currently using, has all the godoc for all your libraries that you have in your workspace right there, and can also be used to verify your own documentation. Note that while local godoc will pick up changes to your documentation within a package, if you create a new package, you'll need to restart godoc. I've gone so far as to systematically purge all golang.org references from my history bar in my browser (highlight them and shift-delete) so I only get my local godoc, because then I would get confused when my packages aren't in the package list.
Isn't the compiler changing for 1.3 and 1.4? Wouldn't this be the best time to introduce dynamic linking in gccgo?
There are lots of jobs posted at http://golangprojects.com/ , which is also powering the GopherAcademy job board. 
Yes, I have some amount of code written in Go in our project. Probably you should not find any job to write in Go, just start write some code in Go in your project. Years ago I brought Erlang in company in the same way.
dammit, looks like my cron script isn't pulling new jobs. Glad you reminded me /u/dgryski
I'll help with some of the explanations, although I have not used his Go package for the templating system. Soy is what the templates compiler to javascript is called. You give it a soy file, it spits out js. Tofu is what the serverside runtime is called (this is on the jvm at least), here you load a soy file, hit it and then push data to it to get plain text back. 
at my company we use Go to power backend processes for telco industry
I tried adding Go as a skill on LinkedIn last week but couldn't find it under go or golang. It seems you can only add skills from their predefined dropdown menu; I couldn't find a way to type one myself. Any ideas? 
You just type Go or GoLang and hit add, you don't have to match it to a predefined category; [image](http://i.imgur.com/lBdqY25.png) and [live](http://linkd.in/incendiarymedia)
You can create a slice type that does work with database/sql by implementing the Valuer interface (http://godoc.org/database/sql/driver#Valuer). Make it return Postgres's array input syntax, and then use the ANY function instead of IN. 
Great advice, thanks. I keep meaning to check out golint, and haven't yet. I'll definitely do that asap. I totally think that documenting a function that only exists to fulfill an interface as Foo implements Fooer.Foo as being totally valid, as long as it's obvious what it would do. Usually you need a little flavor text about exactly how it is going to fulfill the interface, like what specific text String will return... but yes, it's good to give people that hint that your type can be used as that interface. I think godoc.org is handy for scoping out the API of code before you just go get it. Sometimes I don't really have a use for the code right now, I just want to see what the code does.... and that way I don't have to remember to update the code if I decide to use it 6 months later. But I do think it's a good idea to use local godoc when you can, since you do get the handy index of "all the stuff I am using right now".
I specifically only removed golang.org. Looking at the docs for modules you haven't gotten yet is a crucial part of vetting whether you can use them at all, of course.
Thanks... the thing I liked about writing it in godoc is that instead of talking about what godoc does, you're actually looking at it, which makes it a lot easier to grok, in my opinion. Plus, it gives concrete examples in the code of how it works. One thing I forgot to mention that the blog post you pointed to mentions is the use of BUG comments.... I meant to add it in, and forgot about it. I think that blog post is actually really good as-is. It's a lot shorter than my repo-post is. It's more of an overview, whereas I tried to make mine down to the nitty gritty of how it all shakes out.
Yes! We're looking for a backend engineer who loves writing Go at pressly.com. Please send CV to hello at pressly dot com if interested.
I work on a project which uses Go, but we're the only project that uses it in my company, at least to my knowledge.
Well... You must be in Paris because in Lyon startups are recruiting PHP developers.
Relevant: [twik](http://blog.labix.org/2013/07/16/twik-a-tiny-language-for-go) glisp looks more ambitious, and I like the more clojure-esque syntax. 
LISP dialects implemented in Go are nothing new, of course. I saw several posted in this subreddit before deciding to start working on my own. I suppose mine is a lot more similar to twik than the other implementations because it is designed specifically with embedding in mind. 
That sounds like a much better solution than what I cobbled together. I'll see about fixing up my code tomorrow and update my blog post :) Thanks! 
Everything you create.
The tl;dr: &gt; I think we should solve the shared library issues. I think we should make that a priority for the 1.4 release. - Ian Lance Taylor
You want sourcegraph: https://sourcegraph.com/search?q=GobDecode If you just care about the standard library, the Go Oracle and https://github.com/fzipp/pythia are probably sufficient.
Check out http://jmoiron.net/blog/built-in-interfaces/ He describes how to use the Valuer and Scanner interfaces when working with Go.
We're currently working on a wireless router project. The system is basically a MIPS processor running openwrt. One of major job is reimplementing its web interface with Go's Martini.
It all depends on the amount of memory you will uses and how much garbage you will generate. Since Go gives you the choice of how to transmit your data, keeping it on stack and copying or using pointers, you can manage the amount of garbage you create much more easily than with other GC'd languages. 20ms pauses seems like a pretty reasonnable requirement but in the end, it all depends on the amount of memory you use and allocate. The common answer I've seen to that kind of question if to avoid creating garbage, thus helping the GC.
&gt; It all depends on the amount of memory you will uses and how much garbage you will generate. The current engine seems to have a working set footprint of something like 1.5GB for ~150 users. It's written in a JVM based scripting language, so that's quite likely to go down &gt; 20ms pauses seems like a pretty reasonable requirement The VisualWorks Smalltalk VM had a pretty kickass generational collector. 2ms pause times were typical out of the box. (Not a full stop-the-world, but the common case.) I'd love to see something like that! A 20ms pause once a second would be doable but a bit on the high end. &gt; The common answer I've seen to that kind of question if to avoid creating garbage, thus helping the GC. Which involves caches/buffers which increases the number of roots the GC has to scan from. 
Thanks, sourcegraph works pretty decently. And I'll probably set up Pythia on a public server to track the go stdlib, unless someone else already has. 
+1 to the idea of a 'just-in-time' static linking.
The problem isn't really the lack dynamic loading, but including external libraries - mostly un-versioned, unless using something like godeps. This causes a few issues for distributing software at a larger scale like linux distributions do: - assuring stability. And don't think "unit tests" are the magic silver bullet here. They only get you that far. - provide security updates. Both things are hard to do. Yes I built program X version 1.0, but what versions of what libraries did I exactly use to build this? Most libs are just checkouts of the master on github at a certain point in time. Godeps can solve this, but this is still an issue. It's also a linux distribution's job to send out security updates, and the current Go model makes this very hard. Just adding "dynamic linking" will not solve the problem of one commonly used library having a serious security issue unless go throws out all static linking. 2 other approaches have been proposed there which seem interesting: - Install-time static linking. Can be a problem for ABI compatibility, but you would still get the current benefits of Go. The go development model and distribution however would have to drastically change. - Create a source package per go library on linux distribution level, and when it updates - do a reverse dependency lookup of all packages and rebuild them. Of both approaches, I'm afraid the second is the most feasible, both long and short-term - but it makes packaging software for different linux distributions a mess.
I'm really happy to see a discussion about soft (and I'd be happy to see it for hard, too) real-time software in Go. While having a GC is a fundamental design choice in the language, I feel something could be done in this direction. I mean, people did it for Java, and it has basically `System.gc()` alone... However, don't hold your breath for official tools, since we're still waiting for Generics/templates/whatever-allows-sane-type-safe-ADT-code-reuse, and virtually everyone agrees the language needs such a mechanism. I'd be *really* glad to see Go move in the direction of game programming because to me it seems like Go offers a good trade-off between complexity and performance, even if we put aside the "free" (or at least cheap) concurrency provided. Unfortunately, I can't be of any real help, so I can only wish you luck.
And https://github.com/benbjohnson/megajson
About the 20ms requirement, What I wanted to say is that this is big enough that you shouldn't have problems staying under that. &gt; Which involves caches/buffers which increases the number of roots the GC has to scan from. Or simply avoiding pointers where you are not forced to use them, which will reduce the work for the GC. This is a choice you don't have with most garbage collected languages. Also, I apparently missed the last two paragraphs of the original post, you can manage your own memory outside the garbage collected heap using direct system calls to allocate some memory yourself and manage it using the unsafe package. This approach can be tedious but it's doable if you run against too high pause times.
Thanks! What about enforcing that for a package to be included in Ubuntu it has to have version tags in Github?
The [`sync.Pool`](http://talks.golang.org/2014/go1.3.slide#9) primitive that is planned for Go 1.3 might be useful. If it does not fit your needs, could you explain why it does not? I'd be interested to learn more about this.
This is by far the best talk on Go that I've seen.
Interface may be slower than primitive type, however interface is a lot faster than map[string]interface in json workloads. 
So, is this just an interpreted lisp written in go? or lisp that compiles down to go? I would be super excited about the latter.
How secure is this? Is PlainAuth to smtp.gmail.com:587 sending the user and pw in plain text?
It is, though it looks cleaner. Why do you feel its not a good fit for you?
Erlang or Elixir and you can concentrate on writing stuff, not on trying to tame GC in Go. 1000 concurrent connections it's a toy for Erlang VM. Wooga used it for their several millions online users games.
The general approach to not having large GC pauses is not to generate garbage and avoid too much nested pointers. Also ask on [golang-nuts](https://groups.google.com/forum/#!forum/golang-nuts) you'll get probably more answers there; before posting [read this](https://code.google.com/p/go-wiki/wiki/HowToAsk).
Similar functionality is provided by the standard "expvar" and "net/http/pprof" packages.
Good talk! You should see it even if you are not programming in Go (like me) — the concepts applies to programming in general.
Technically, you still deal with GC pause in Erlang, it just happens per Erlang process. This can be as good (or as bad) as your application is written. 
Yes, that's where I got the idea. I'm coming from erlang and miss the REPL, but this is something. I don't claim this is special or unique, just convenient since I had it just lying around.
I don't know that I like that blogpost - partly because of the guilt trip to get me to pay him $6, and partly because a decent chunk of the code is pretty extraneous. Here are two simpler and (I think) better implementations of the gmail tutorial: http://nathanleclaire.com/blog/2013/12/17/sending-email-from-gmail-using-golang/ http://code.google.com/p/go-wiki/wiki/SendingMail
Here's a list of implementations of gob.GobDecode: https://sourcegraph.com/code.google.com/p/go/symbols/go/code.google.com/p/go/src/pkg/encoding/gob/GobDecoder:type/.implementations (Searching for "GobDecode" will yield similar results, but this list is a bit more precise because it was actually generated using Go's interface implementation semantics.)
There is a python-based tool named supervisor at http://supervisord.org/.
We're just starting to use it in places where the pain of managing ruby versions has the least payoff. Works well so far and I've got high hopes for it.
implementing runit should be quite simple, recommended! 
Having metrics exported via expvar and net/http/pprof are very useful. If you can get them imported into graphite (via https://github.com/peterbourgon/g2g or equilvalent) even better. You'll want nagios or something similar providing liveness checks (or as mentioned something like supervisord or upstart). Capturing stderr will give you panic output, and if you can configure your liveness check to send a SIGQUIT if your application is unresponsible you'll get stacktraces of all the current goroutines. Vital for post-mortem debugging. Not sure if this is what you needed, but this are things I've come up against with the apps I've deployed to production. 
that's a nice one. I never run into it so far. thank you for sharing. I've run into this one: https://github.com/rcrowley/go-metrics, never tried it but it looks interesting too. Even though, I guess monitoring is a very broad term.
It's the former. I think there was an instance of the latter posted on this subreddit a while back. Try searching for it.
I look forward to seeing this example when you do it.
It is worth mentioning that Go regexp is actually slow (vs refined regexp libraries in C). I wondering if he set GOMAXPROCS=4.
I think I see where the confusion is. OP is benchmarking two things at the same time: 1) using concrete types (zero overhead) vs interface{} (non-zero overhead) as arguments to a function 2) using channels vs `atomic` package for synchronization. If you separate these two out, you'll find that interfaces will always be slower than concrete types and `atomic.AddUint64` is pointless overhead when running on a single cpu, while channel send/receive across multiple cpus is pretty slow actually and should be kept to a minimum.
systemd anyone? supervisord if on ubuntu box.
But the Python regexp library is a lot slower than the Go library.
This is exactly what I need and then some. Thank you! 
And that is why golang will always be a toy language. Java and python rule the day. I had hope for golang but now it is just a dream passed by.
Upstart/daemontools/runit/god/systemd/init all solve this problem. I personally am a big fan of daemontools once you have it configured it has a very nice simple (shell) api for doing things.
Interesting. If I were to do this, though, I'd consider maybe using gogs instead of gitlab. Gogs is much less mature, but it's written in Go, so if you like Go, it might be worth checking out. http://www.reddit.com/r/golang/comments/21celb/gogitsgogs_a_selfhosted_git_service_written_in/ https://github.com/gogits/gogs **edit:** A CI platform built on Docker and written in Go was mentioned by someone in comments on OP blog post. Adding this here for myself and others. https://github.com/drone/drone
I'm OneOfOne, and I forgot to mention that I had export GOMAXPROCS=4 in my .bashrc.
I tried to transcribe and distill the very nice definitions he gives early on: &gt; Concurrency is the composition of independently executing things (often functions). &gt; Parallelism is the simultaneous execution of multiple things; possibly related, possibly not. &gt; Concurrency is about *dealing* with a lot of things at once. Parallelism is about *doing* a lot of things at once.
Disclaimer, I work at SendGrid. If the goal is just to send email, SendGrid has that covered. https://github.com/sendgrid/sendgrid-go
Cool! I'll take look at them!
Yes, but the Actor pattern is difficult when it comes to an absolute occupancy grid, like a huge checkerboard. I have given some thought to how I could adapt my architecture to it. I suspect I may have a way to do 1000's of users with such a grid, with something that resembles a conventional game loop. 
In fairness, that Waza logo on the wall is pretty epic.
I know. Benchmarks are really annoying when source isn't open.
Yesterday, you posted "Concurrency is not parallelism" and today its CSP. It feels like you're trying to reap easy karma by reposting. If you have a bunch of these links, why don't you make a self post with all of these links in one place? The advantage of this - most of the people would have seen a majority of the good links already, so there's no sense in spamming the sub with each one. 
As you can probably tell, I'm new to reddit, and comments like this aren't exactly welcoming. I've posted a whopping two links to things that I've found personally interesting over the past few days. And also, why do you care? Please don't answer that.
Isn't python's library actually implemented in C though? Also, Go uses a different algorithm in order to perform MUCH better in certain situations. Unfortunately this means that in general it is a bit slow compared to c. More info: http://swtch.com/~rsc/regexp/regexp1.html
I figured someone must have posted it before. I just thought it was interesting.
Don't worry about it. You've made 2 submissions in 2 days (i.e. not many), and they are being upvoted, so clearly some people are finding them interesting. Not everyone has seen everything on the internet, e.g. I personally hadn't seen the "Concurrency is not parallelism" one before, and have heard of, but not read the CSP paper... but there's always a noisy few who are on a crusade against "reposts" of things they have happened to have seen before. If your well-meaning posts happen to be inappropriate for this subreddit (rather than just something a few people dislike), a moderator should either make a polite comment to that effect (and/or remove it).
(My comment is agreeing with what you said, if that wasn't clear.)
&gt; most of the people would have seen a majority of the good links already Not really. 
I wish there was a way to search through those jobs.
There are lot of type switches in this code. Until Go implements generics it's pretty much the only way to have something approximating an ADT. As for car/cdr vs. first/rest, [this one's for you](https://github.com/zhemao/glisp/commit/9b6959c6ed3b303ee12bda87c5a8a0433c3020e6).
The examples in the paper implemented in Go: http://godoc.org/github.com/thomas11/csp
It's not what it's written in, it's the algorithm that's used to write it. Go and C use Thompson NFA and Python uses recursive backtracking. I'd assume that the regexp library in C is using the same algorithm as Go, but has 20+ years of optimization built into it whereas Go has maybe 5.
Well, doing web scraping with regex is usually not a good idea. Python has excellent libraries for this task, e.g. BeautifoulSoup4, lxml, etc. Is there somethign similar for Go?
Go is not really mature and sophisticated compared to Python in the areas of web scraping and parsing. There is a basic HTML package available, but its not good enough.
What's package is this, and in what way(s) is it not good enough.
https://github.com/PuerkitoBio/goquery
Definitely check out that jmoiron link. Scanner and Valuer are the way to do it. In my app I use string_agg to convert rows into a comma-separated string and join it into another table. In my particular case I don't need to implement the Valuer interface (although I have done that previously), just Scanner. Here is what it looks like: type idArray []int64 // Implements the sql.Scanner interface func (a *idArray) Scan(value interface{}) error { if value == nil { *a = []int64{} return nil } b, ok := value.([]byte) if !ok { return fmt.Errorf("Unable to convert %+v to []byte", value) } for _, slice := range bytes.Split(b, []byte(",")) { id, err := strconv.ParseInt(string(slice), 10, 64) if err != nil { return err } *a = append(*a, id) } return nil } It's probably not *exactly* what you want, but gives you an idea of how to start.
slides: http://talks.golang.org/2012/waza.slide#1
I had written quite a bit of go code trying to build a whatsapp kind of application using websocket for communication on an android device. I had it working as well and can give you more details if you want.
Just came across https://github.com/jessevdk/go-assets which might be better than go-bindata for the use case of serving embedded assets.
In order of professional experience: C#, Python, C++, C, Java, Haskell... I find it to be generally quite nice and am developing an open source project with it (http://github.com/nfleet/via), but there are some limits. The scheduler needs improvement (which it has gotten a lot recently), and debugging is painful. I'm used to IDEs such as Visual Studio or Eclipse for debugging, navigating the stack trace with gdb is oft so horrid I have to resort to log.Printf messes. That said, I do not need to debug that often compared to say, Python, which I would no longer use, in favour of Go.
**Upstart** If your go app doesn't fork or daemonize, using upstart is extremely easy. Upstart is used on Ubuntu, a sample script would look like this: # /etc/init/mygoapp.conf description "My awesome go app service whatnot" start on runlevel [2345] stop on runlevel [06] respawn respawn limit 10 5 # Environment Variables env DBNAME="mydb" env DBHOST="localhost" chdir /home/myuser/mygoapp # If you want to log stdout and stderr exec /home/myuser/mygoapp/app &gt;&gt; /home/myuser/mygoapp/app.log 2&gt;&amp;1 # If you just want the app to run exec /home/myuser/mygoapp/app you would start/stop it on ubuntu like so: sudo service mygoapp start sudo service mygoapp stop sudo service mygoapp restart or this works with _only_ upstart scripts sudo start mygoapp sudo stop mygoapp sudo restart mygoapp Hopefully that gets you at least headed in the right direction.
I come mainly from Python and C++ (let's not talk about a dark past of PHP and occasional Java). I find Go to have a really good balance, no longer forcing me to choose between interpreted languages and compiled languages. Getting stuff done almost as fast as in Python, and getting it to run almost as fast as in C++, is what I love about it. That and concurrency. BTW to really understand your poll results, I'd normalize by the overall popularity of the languages. 
What do I use as normalising factor? TIOBE, Github repo count, Stackoverflow tags, jobs? 
I come from a java/objective-c background, and what bent my mind the most about Go is how general purpose it is. I have always kind of split languages into application languages, and server side languages. It's cool how languages seem to be becoming more general purpose (Javascript, Go, etc) 
The issue with the program is that it could terminate before the last print happens. When the main() function exits, all goroutines are terminated. So the race you have is that after you send the last value on the channel (11) it's possible for the channel to be closed and the program to exit before the Print goroutine gets the opportunity to print the value out. There are a few things you can do about this. You could use sync.WaitGroup to wait until the Print goroutine ends. Or you could use a "quit channel" that the main goroutine blocks on and close() it in the Print goroutine.
Do you think that the solution in my comment solve this problem? Then the channel ch wouldn't close until &lt;-sync, right?
Yep, that'll solve it. That's essentially the "quit channel" I mentioned in my other comment. EDIT: Actually, on second thought this won't work, because you're closing the channel on the same goroutine as you're waiting on it. The same race is still there. I think a better way to organize it is like this: http://play.golang.org/p/GlWTXv7XEa
Great, thanks for the help! It's hard when I can't really test the program to see if the solution will work. All this stuff about channels and goroutines are kinda confusing right now but they seem really useful and effective.
Here is a version that uses a struct channel. I thought about mentioning using a struct{} instead of bool, but figured bool is easier to understand when just starting out [struct{} return channel](http://play.golang.org/p/OW-xN_yzDZ)
I edited my earlier comment, I don't think this is safe, actually. Because you're doing a lot more work, you're less likely to hit the race (similar to the suggestion to `runtime.Gosched()` above) but I wouldn't rely on this.
It's funny that language from Google doesn't have a search feature :D 
Hmm... Why isn't Perl list in the set of languages you list. Also, I'm proficient in multi languages; yet I'm only allowed to pick one?
Your main synchronizes when you're writing to ch. Because it's unbuffered it will wait until Print reads from it, so on the last iteration you're writing to ch and then exiting before Print reads the last value from ch.
Pick the one you're most proficient in.
Ruby and C. I was never a major Rails guy, but I have built a couple small sites with it. C has always been my go-to for SPEED but I'm starting to use Go some. I also dabble in Fortran for my day job, but that's not going anywhere.
I've mostly done PHP and Ruby web development professionally, but my most interesting projects have been in compiled languages like C, C#, and Go. I'd love the chance to write Go for a living, and so I've been trying to find jobs that will allow me to do so.
&gt; Currently, most go packages/libs have no version numbering indicating API changes - or even if they have, hardly anybody uses them Fingers crossed that people will realize that this stops people from taking their packages seriously, and will start building in a way that plays nice with semantic versioning/gopkg.in/whatever else system comes out on top. I know this problem has bitten me in the ass (coreos/go-etcd changed its API and made my project unbuildable) so now I'm very selective about what dependencies I use. &gt; having to rebuild or at least re-test all packages using that library is risky, and adds a lot of overhead and responsibility when things go wrong Isn't there other statically linked software packaged with Linux distros? Genuinely curious.
C, PHP, Python, Javascript (I still find it weird that people consider this a programming language, but I guess with the advent of Node it's legit...) and a few others. Go is my favorite language now.
Why no Perl in your list?
Why wouldn't JavaScript be considered a language? jQuery isn't a language, if that's what you mean...
i agree with the decision to pick one, i think the data would be too noisy if you could pick multiple. also so far my intuition about go programmers mostly coming accross from python and ruby seems on the money.
Erlang is missing. Wouldn't put it up there in general, but in this context it's worth it.
I use it at work in places where I would have previously used python.
Make a slice of the object type you're creating a lot of garbage with, then manage memory manually with the slice. 
If you switch the goroutine to be the generation of numbers, it works nicely since the range statement waits for the channel to be closed: http://play.golang.org/p/GlWTXv7XEa
Coming from C++ and game development here.
I have started with Java, then went over to Haskell, then assembly and C and now mostly C and Go.
Are you the author?
I have done lots of work in Python, along with a bit of Java/Obj-C for mobile platforms. Really liking Go so far.
No.
I can hold a negative opinion on a lang/framework and not have it be a "wars" thing thanks.
I was about to write something like this today. Although I'd use big.Rat as the underlying type. I would also implement the Marshaler and Unmarshaler interface of encoding/json for convenience.
hopefully open source? I started something similar as a new data type for the ODBC driver because my most useful databases have decimal fields. Unfortunately I stalled due to other projects. 
I feel like I'm (specially) proficient in no language. My main takeaways use(d) to be Python, Lisp and C (in no particular order), but it has slowly gotten to awk (yes, seriously,) go, python and R (again, in no particular order.) I can most of anything, but don't consider myself "proficient." I just get things done :/
I believe we're in the same situation: retrieving decimal fields into your program retaining their full precision seemlessly. This is my biggest issue with Go for business application developpment (that and report generation). Coming from C#, its decimal type is a blessing. And it's built-in, not an afterthought. Were you to add full support for numeric, money and decimal types in an ODBC driver, you'd have to "map" it to big.rat or force the user of the driver to use a provided type, on which the model layer will have to rely. That means your model would depend on something provided by a driver. Less than ideal I'd say. I wish there was an interface provided by database/sql to unmarshal from a sql.Row. It would at least isolate such problems. As for the open-sourceness of my work, It'll depend if I do it at work or at night not being paid for it.
Disappointing to not see a python test using gevent, or by running celery workers. Or the source to any of these tests. 
On the go-nuts board there have been a few discussions suggesting Go's use of multiple return values to extend addition, multiplication, etc. to allow for the following special operations: result, remainder = a / b result, highproduct = a * b result, carry = a + b //etc... ... which would simplify certain cases and also expose functionality built in to practically *every* CPU anyway, allowing for more efficient overflow checks.
how.dare.you.
Have you checked out the [Lexical Scanning](https://www.youtube.com/watch?v=HxaD_trXwRE) talk by Rob Pike?
Thanks for pointing out my typo. I meant "come on." +1 brownie point for you
This is a very nice way to do argument parsing. The Cargo package manager for Rust is using a similar library for argument parsing called Hammer: https://github.com/wycats/hammer.rs
What do you mean no? Do you have a source? [Netscape Enterprise Server](http://en.wikipedia.org/wiki/Netscape_Enterprise_Server) came out in 1994 and was an early implementation of [Server-side JavaScript](http://en.wikipedia.org/wiki/Server-side_JavaScript#Server-side_JavaScript). All I'm saying is that JavaScript has always been a real language. By real language I mean a Turing complete language that also has structure; variables,, flow control, functions, etc. I'm pretty sure the first versions had anonymous functions, prototypes, closures and most of what we work with today. Don't get me wrong, in the early days people didn't take it seriously because it was used for cute tricks and maybe some basic form validation, but that doesn't mean the language itself wasn't real. You are right that the DOM has improved and it is more useful in the browser.
- There is no way to know which field has been set a value and which field is left out. In cases when you need that information, for example when you have alternative configs that fill the same role like "TemplateUrl" and "TemplateFunc" that specifies the template, you don't know what to go for. - You cannot create options on the fly, you have to initialize the struct then set each field. This one is a matter of taste, it just doesn't feel right. Of course for simple needs you may not need this package and a struct might be ok. I created it for my own use, it fits some of my needs. If just a struct is enough all the time then Rob Pike woudn't need to go to great lengths with this http://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html, and I woudn't need to go to waste my time for this.
That's actually pretty helpful! As a new go developer, the hardest part hasn't been learning the language itself, but instead good ways to design your code and encapsulate things. It is hard, coming from other languages, to think to spawn a controller thread. Thanks :)
I dunno, I just went from memory. There were better terms that matched the names used in ASM context more closely.
Maybe division could be result, remainder, err. 
Thanks for your feedback! You are right! In this case simplicity wins! But please also note that post doesn't advocate certain approach; it just describes it. My next post will elaborate on which approach to choose and when.
The code Example contains some basic typographical error Change: func NewLockingAccount(balance) *LockingAccount { return &amp;LockingAccoun{account: NewSimpleAccount(balance)} } To func NewLockingAccount(balance int) *LockingAccount { return &amp;LockingAccount{account: NewSimpleAccount(balance)} } Finally i think i would take my chances with `LockingAccount` due to speed PASS BenchmarkLocking 10000000 296 ns/op BenchmarkConcurrent 1000000 2269 ns/op ok command-line-arguments 6.262s Benchmark Code Used func BenchmarkLocking(b *testing.B) { balance := 80 account := NewBank(NewLockingAccount(balance)) for i := 0; i &lt; b.N; i++ { account.Withdraw(30, "GF") account.Deposit(30, "GF") } } func BenchmarkConcurrent(b *testing.B) { balance := 80 account := NewBank(NewConcurrentAccount(balance)) for i := 0; i &lt; b.N; i++ { account.Withdraw(30, "GF") account.Deposit(30, "GF") } } 
Well not completely ..
Thanks for pointing out typo. Yup, next post will be about picking the right concurrency model. Thanks for feedback!
i cannot select more then 1 langauge :/ i use to programmer in PHP, Ruby, Python and i still do. then i moved to **go**. after go i'm looking foreword to haskell, (or clojure racket lisp), and assembly maybe some c.
Pass in your current pipeline {{template "Content" .}} Note the extra "."
Why didn't you stop at Haskell?
Because the Haskell standard library is a mess designed by people who want to have something technically correct instead of something actually useful and also because I wanted to understand how the machine works that I am programming on.
I'd like to also mention the [email](http://github.com/jordan-wright/email) package I wrote. It makes sending emails in Go dead-simple.
http://golang.org/pkg/bufio/#Reader.Peek
bufio reader still reads underlying io.reader.
https://gobyexample.com/ is of a similar caliber; I've seen some of the Go authors recommend it as a good place to learn. (Now that you raise this question, I need to spend more time there myself...)
Thanks, I was looking for this, saw it before but didn't save the link.. Cheers. 
cool!
OCaml is one of the earlier languages with a structural type system: http://en.wikipedia.org/wiki/Structural_type_system Go's notion of an interface definition (not regarding the structural type system aspect) is from Java. And Java's inferfaces [came from Objective C's protocols](http://cs.gmu.edu/~sean/stuff/java-objc.html).
You'd probably be better off using a tiled approach, which is what most image editors use at the source, and spawn a goroutine only when you cross into a particular tile. You'd probably want to sync the creation of a goroutine for a a tile so you don't accidentally spawn a goroutine for the same tile twice (which could still be made to work, but is a waste). As cheap as spawning a goroutine is, it's still more expensive that just grabbing a byte, doing a simple comparison on it, and setting or not. I wouldn't have been surprised if you said this didn't come out to be much faster than PHP. You're also going to have a hard time with that approach getting a lot of good _multiprocessor_ speedup, because your processors will spend a lot of time fighting over the cache lines. If two processors try to write two pixels that are right next to each other at the "same time", that's going to be a relatively expensive cache conflict.
That actually help me understand upstart works. This might be the simplest and cleanest upstart example I've ever see. Personally I've mainly used daemontools, but there's a lot of good things having everything on your server start using the same start up system.
amazing article. That's some serious attention to detail.
Fantastic - Go programmers of any skill level will learn something from this article
yeah that probably was a strong intro phrase, but what I tried to underline is the sense of the question, smalltalk gived a boost to that sort of design and now so many languages inherit (no pun intended) something designed that time. Your answer doesn't really responds to my question but I'll upvote for the effort :)
One of the underrated factors of Go is how it cleans up years of programming language practice. A small example is the use of names like int8 instead of short. This article shows another great example: Go gets rid of implicit conversions (a source of tons of undetected errors) without losing the convenience of implicit conversions by making constants exist in a parallel type system. 
Is it possible to do it using both? In your implementation of the Observer pattern, the observer register a channel with the server that's receiving the messages. When a new message is received, the server sends the value to all the channels that are interested. This is still the "event-based" pattern that you're familiar with. If you think this is a good fit for you, let me suggest an improvement. The server should write the value to a single channel. A separate goroutine is responsible for the fanout operation from an input channel to an arbitrary number of output channels.
Ah, yes. I spend lotsa time on godoc.org and golang.org/pkg/... but the live search (as-you-type) feature of devdocs is a one-upper for me.
this is great!
Would be cool if I could type `pkg.Function` instead of only `type.Method`
True, but typing just the `Function` name works pretty well anyway.
&gt; The only exception I know, and thus the thing that is in some sense the "true essence" of object orientation, is that you must have some sort of data structure that is considered to "own" a particular function, which we call a "method", and there must be some way to have two different data structures have the same "method", such that you can pass either one to some code expecting to call that method and it works, and finally and importantly, this is an important aspect of using the language correctly and the machinery and structure to do this are provided by the base language and core runtime. Check out CLOS, I believe this does not abide by that principle. 
Another Norwegian using Go, awesome! Maybe you could try using something like [git2go](https://github.com/libgit2/git2go), seems like that would be a more robust way of using Git inside an application like this. I haven't really looked over it closely, but some nitpicky stuff as not using camelCase everywhere (default_host, etc.) and some exported names being commented wrong (for documentation). Just stuff my linter nags me about, good practice, but nothing that will break your program if not done.
Wow, this entire site is great! Good find!
This feels similar to rob pike's doc command. Looks useful.
Agreed :) Seeing that this is written in Ruby, I also think that your suggestion is much more viable to get what I asked for.
You can use space/shift+space or alt+up/down to scroll the page :) See all the shortcuts here: http://devdocs.io/help
Awesome, that works. /u/ThibautCourouble, are you the author? If so, great job!
Yes I'm the author. Thanks :) The project is open-source by the way: https://github.com/Thibaut/devdocs
First of all: great work! Thanks so much! Love the format on save, error reporting, goimports integration, and godef integration. * The highlighting is too aggressive for my taste. Methods, operators, etc. just don't need to be so bright and bold. The method highlighting at least seems to cause a slight lag on my machine as well as it detects methods. Would love a way to revert to the default highlighting. * I don't normally use autocomplete, so maybe this is a vim shortcoming, but it's very slow. * What's the scratch pane at the top that autocomplete opens? 
In general, I get the idea. Some companies already use clusters to compile. In the specific case of Go, it seems like it would be incredibly difficult for this to be a win. Compiling my entire (non-trivial but admittedly not enormous) application from scratch from an empty disk cache took 4.5 seconds. With the cache warmed up, it was 1.5 seconds. Compiling after a one-file change that was a "leaf" file was one second. That's clocking in at about 25000 non-comment lines of code. Running`cloc` over the code took .75 seconds on a warm cache... the go compiler is pretty quick. By the time I've uploaded my code, I could have been most of the way towards compiling it myself. Are there plans to compile a different language with the same infrastructure, maybe?
One perk of libgit2 is being able to use stuff like memcached and RDBMs as backends for storage. So it's worth a try, even if it's just as an programming exercise. The dependency on libgit2 is kinda a moot point since you now depend on having a seperate application installed on the system. Adding libgit2 would remove that dependency. So it's pretty much just replacing Git, not an additional dependency.
I was totally into Sailfish but as far as I can tell the entire stack is not FOSS like Android is - it's built on a lot of FOSS stuff with a proprietary interface.
Interesting. I would love to know more about the Cocoa/OSX integration. I wonder if it deals with UI.
I believe the specific thing that caused a bunch of headaches was it would crash (but only sometimes) when a callback from detecting an application switch would attempt to actually do something. We don't use Go for the UI portion - there may be a future blog post about that at some point.
As of Go 1.2, you can link C++ code directly without using SWIG. You still need to prepare a thin C wrapper for use with cgo.
The compiler itself is not open-source, I infer.
That would be awesome. Yeah, I wouldn't expect Go to be used for the UI portion, but it would be interesting to see how it would send messages to the UI code in Obj-C to see how the two would interoperate.
The compiler isn't intended to compete with the golang.org compiler in terms of compile speed. The primary goal is performance of generated code. Acceptable compile time is several seconds per 1000 lines of code. Different languages: There is plan to support other languages. The next language after Go will probably be Python.
Hey, * There are settings to disable any syntax flavor, look at it: https://github.com/fatih/vim-go/blob/master/syntax/go.vim#L32 These are not documented in the docs but I'll add them asap. You can disable for example method or operator syntax highlighting, it's completely customizable. * The slowness might due gocode completion. Vim-go only parses the result of gocode. * That scratch plane is not vim-go related, it might the default vim preview window. I think you can disable it with: set completeopt-=preview see here for more info: http://stackoverflow.com/questions/15962421/how-can-i-disable-scratch-preview-window 
I think the point is "why do you need images of equations"? If it is for web, MathJaX works better (graphically.) If it is *not* for web, and so, not dynamic, probably calling LaTeX directly (as a shell process) is far better. In any case, I agree with scoith: the rendering *is* crappy, but the amount of work needed to get to a crappy level is huge. One thing does not demerit the other.
BTW, you can run godoc locally on a Windows machine to get the windows-specific godoc. 
Also, you don't need interfaces to deal with OS versions needing platform specific code. You can write this in execute_windows.go: func ExecuteCommand(command string, args ...string) error { // windows-specific stuff } and this in execute_nix.go: // +build !win func ExecuteCommand(command string, args ...string) error { // non-windows-specific stuff } Then the rest of your code can just call ExecuteCommand and it'll do the right thing on the right platform.
This is wonderful, thank you. One feature request: index constants and variables too. Try searching for "StatusOK" or "DefaultServeMux".
Thanks for the feedback. The linked page was originally intended for the golang-dev discussion group. While writing the page I was assuming the intended audience knows about the compiler more than the general public.
I also noticed two more things: * it will not be free when it is feature-complete. (I expect this will attract enterprise users mostly) * we have to hand out our source code to "cloud" (I expect this will put off enterprise users mostly). 
I know I've said this before, but I agree and really strongly recommend running godoc locally and not looking to golang.org at all. It gives you all the golang.org docs, guaranteed to be the version you're actually working with, all local docs for libraries you may be using, and your own library's docs, which you can either revel in the glory of or perhaps be embarrassed by, as appropriate.
Sure, you can do that but it's a few extra steps every time you want to look at documentation. Also, the fact that the godoc command is included and compiled with go but the libs required to use it aren't included by default is really dumb.
For my type of freelancing, I don't usually indicate what language I'm using. But for go, like any other language, I charge $50/hr (thats my quote), maybe slightly more or less based on the situation. Point is in terms of getting things done, Go as a language is your choice. However, I do think that Go experts will have a great salary range in the next 3-5 years.
Fantastic! Thanks for the help!
&gt; Go only supports simple numeric constants to implement enums. That works ok, but it's awkward for debugging because if you print them, you just get a number. [See this](http://play.golang.org/p/hhs7InKCx-). You could also collapse a great deal of the case down by defining a map with the simple cases (`'@': AT`), and falling through to the cases like `&lt;` only if it isn't found. It could be faster or slower to execute, though. (Not sure which. It depends on how clever the compiler is. It could even change between versions of Go.)
&gt; type IExec interface { It's not C#.
Is this what you do full-time? Independent? Or is this just free-lancing in spare time outside of full-time job? Reason I ask is, if you are your own boss ... than that is way too low of rate in my opinion for a skilled software engineer/developer. Triple it. Otherwise, after considering/calculating that you have downtime between gigs, your cost of doing business independently (cost of marketing yourself, , business insurances, all other business expense, forgoing employer subsidized healthcare and retirement contributions, etc) is going to be significant. Just my personal opinion. I know that the business domain in which you work makes a big difference, but even as a generalist it is still low. I make way more than you working for "Initech" doing that work. If I'm going independent (and I've considered it / done the math), then I'm tripling what you are charging for it to be worth it. This calculation is just the financial one too and doesn't even consider the other angles (do you get paid for your vacation (nope)? do you stress about your next gig? do you like a normal 9 to 5 schedule, etc.)
Standard contracting rate - language doesnt matter. $150/hr
Just the usual $85 an hour. The hourly rate is the same no matter what language I code in. The choice of Go just results in code that can stand up to more use.
Good idea. Could you open an issue here so I don't forget: https://github.com/Thibaut/devdocs/issues
Yeah, you'll see in the code I do that, although only for some of the values. But it's verbose and a lot of duplication. (!DRY) If you add a token you have to remember to add it to the String method as well. It's not a huge problem, just a nuisance. I'm not sure how'd you'd fix it without adding undesired complexity to Go. Good point about using a map, thanks.
FYI, Rob Pike's Youtube video (linked in the article) is great.
Thanks for the tip. I will definitely give that a try
peolple that answer, where are you from? that would be maybe handy for other pople around the world to compare fees. thanks.
The discussion in the comments about implementing DRY enum to string for debugging led me to write this abomination: http://play.golang.org/p/Dbud_6gHqf package main import "fmt" import "reflect" var e = enum{} var ev = reflect.ValueOf(e) type token int type enum struct { One token Two token } func (t token) String() string { return ev.Type().Field(int(t)).Name } func main() { fmt.Println(e.One, e.Two) } func init() { v := reflect.ValueOf(&amp;e) for i := 0; i &lt; ev.NumField(); i++ { v.Elem().Field(i).SetInt(int64(i)) } }
I don't know anyone who contracts for less. I guess it depends on your skill level, previous work and how much you value yourself.
Or how many people will undercut you for $11 an hour.
It really depends on where you are, what industry you're in, and who you know.
The rate is regardless of language. Projects are always quoted at 125€/h - I don't know why I would change that based on language used. If the work is on an existing project in a language that I don't feel comfortable using, the client should get someone else. [edit: s/ject tha/ject in a language tha/]
Very nice... Go go :)
&gt; $ go get github.com/monochromegane/the_platinum_searcher &gt; &gt; $ cd $GOPATH/src/github.com/monochromegane/the_platinum_searcher &gt; &gt; $ go build -o ../../../../bin/pt :/
If you can actually be replaced by someone who bills at $11 an hour, you won't get $125. If you can't clearly show a demonstrable difference between yourself and someone who bills at $11, you won't get $125. If the customer doesn't understand that there is a difference between you and someone who bills at $11, you won't get their business, but that is good news. It should be clear to the customer that they get what they pay for. If it isn't they deserve their punishment.
&gt;It should be clear to the customer that they get what they pay for. If it isn't they deserve their punishment. This happens a lot.
Does it use the regexp implementation in the Go standard library? As it uses a Thompson NFA implementation, it should avoid exponential-time corner cases.
personally, I go to a ton of startup-ish meetups in my city. I'm not even in a huge city but I can still pull a ton of business from it. I use it to my advantage, in fact, and position myself as the go-to for serious development needs
NYC based. Not exactly sure what you mean regarding industry. Broadly, I work in tech. My clientele are typically startups, but I've worked for a lot of companies of varying size.
Consider filing a bug: https://code.google.com/p/go/issues/entry That doesn't sound right. 
Counter-example: if err != nil { return err } all over your code. But still yes, it is nice.
How about ... if err == nil { more logic here that could change err } if err == nil { more again... } if err != nil { handle err once at end } Try it. Seems counter intuitive at first but it reads much cleaner. 
SEK1000/h (~USD155/h), subject to bulk discount. More or less normal for Sweden.
Combined with named return parameters, I find it actually a very handy pattern for "bubbling up" until I hit a point that reports back to the user or whatever... if result, err := doFoo(); err != nil { doLog(err) } func doFoo() (result string, err error) { if result, err = doBar(); err != nil { return } err = doBaz(result) return } func doBar() (result string, err error) { if result = checkBaz(); len(result) == 0 { err = errors.New("Empty Baz") } return } func doBaz(r string) (err error) { if err = processBaz(r); err == nil { furtherProcessBaz(r) } return } In effect, it's try/catch, but a lot cleaner, I think. 
&gt;They were not posting You're right, it's purely insiders getting those things. I've never got over $120 on an open market.
235% CPU vs ack 99% CPU, does this simply mean that ack uses 1 core and pt and ag use multiple cores and are thus faster?
But then all of the logic you actually care bout is nested 1 level deeper, right? I'd rather avoid that.
he writes a "this code is not clean nor production worthy" disclaimer in the readme. Sounds like he hacked it out to get his site running ASAP
You can do that in F# though. The compiler would infer that the T type must have a infix + function defined for it. It's interesting that the inventor of F# Don Syme, was the guy implementing generics in C# way back in the start 2000s.
You need to look into lazily implemented sequences or generators if you think chaining functions over a sequences produces intermediate results. Each of the operator callbacks for map, filter, etc are called in succession so no intermediate lists/arrays whatever exists. Only the final realized collection is instantiated.
Correct, pt is achieving higher parallelism than ack, so the wall-clock time is shorter. Although the total user time is much more efficient as well -- 6.24 vs 1.09. 
Tried it, only one plugin, and no `gocode` support yet. Don't see any advantage over sublime, especially as both would be closed-source, propriety software.
I am the author of the go-plus package for Atom (http://atom.io/packages/go-plus / https://github.com/joefitzgerald/go-plus). It currently provides the following functionality: * Formatting source using gofmt * Formatting and managing imports using goimports (change the Gofmt Path preference to target goimports) * Code quality inspection using go vet * Linting using golint * Syntax checking using go build and go test Gocode support is planned but requires some modifications to the built-in autocomplete package. Also: * @rubyist is working on brining oracle support into go-plus * I am working on godoc integration right now * If there is anything else you need, please log an issue in the GitHub repo
I tried it for a bit, but I am an old man and just cannot shake Emacs. You absolutely must install the ["Go Plus" package](https://github.com/joefitzgerald/go-plus). It allows you to run `gofmt` (or better yet, `goimports`) at save time. It also offers you the ability to run `go vet`, `golint`, and `go test`. I do fire up Atom when I am writing markdown... I love the preview functionality with GitHub-flavored markdown.
There is no way I'd even consider using anything but Vim for Go. Specially now that we have `vim-go` plugin.
why recompile the regexp more than once?
Could it be possible to add debugging and breakpoints? Or is that something that Atom's architecture does not allow? 
Thats exactly why I lost interest in Atom. Maybe if it ends up with better features than sublime without becoming too slow I'll start using it, but if it wasn't proprietary software I'd be much more inclined to switch now and try to start improving it and making it fit my work flow.
Yep, it's possible - we'd need to integrate with GDB and also provide the ability to launch a go program, a test, or all tests. Can you open an issue for it in the Github repo?
Putting the commercial intent of Atom aside, I would very much welcome additional contributions to go-plus, or any input regarding desirable features. I can attest that perhaps the most compelling thing – for me – about Atom (vs. Sublime) is the ease of [package] development and the fact that I can inspect the source of even the proprietary bits as it's all just CoffeeScript/JavaScript. Editors can be a somewhat religious thing so I fully respect that others have strong feelings that differ from mine. I'm also a GoSublime user, and have spent large chunks of my career in vim. While I have not used vim-go, it sounds awesome!
I think Go support is ok, especially if using something like go-plus (I rely heavily on compiler feedback and not having that in the default package slows me down). I tried Atom for a little and it was fun, I really like the markdown preview but I went back to vim to write Go.
The only advantage to pt or ack or ag over grep are performance. If grep is running slowly (like you are looking through gigabytes of files), these are a good alternative. Otherwise I'd stay with grep. With that being said, I quite like ag, as it's mostly a drop-in replacement from grep (still supporting many of the same arguments).
If there's anyone out there using Martini, I'd appreciate any feedback on this. I was reading [this article](http://0value.com/build-a-restful-API-with-Martini) when it occurred to me that some common functionality might be missing from core Martini that could be useful in APIs. Like the Method Not Allowed response, which is not returned by default.
It's nice to hear some feedback from someone who IS doing the actual hardwork that needs to be done in any editor to go from "editor" to "good code environment", so thanks both for the feedback and the work you do. I'm sure when Atom supports a platform I use I'll be giving it (and your code) a try. 
I don't know if you follow golang-dev, but the GDB support will be changing for 1.3
not even close to being on topic; did you even read the OPs post before deciding to reply?
What constitutes a bug is between you and the expectations for how the function should perform, however returning a timeout if the page was available would probably constitute a bug by most people's expectations. With a function of this size you may find it more productive to re-write in a way that has fewer opportunities for mistakes. Hint: Why pass a flag to indicate something is ready instead of the thing itself?
See recv(2) and the MSG_PEEK option. I believe the original question is about doing that in Go.
What will happen to the goroutine after timeout?
garbage collected I guess?
Yeah this looked awesome until I realized it's closed source.
I think it's probably referring to the race conditions in the function. As a hint, consider what the returned value might be, especially since it's a pointer, for all possible orders in which the main and new goroutines might finish. For example, what might happen if the created goroutine finishes after Read() has returned?
Here's a mocking library I've been working on: https://github.com/maraino/go-mock
Thanks! I'm waiting for his feedback now, I'm hoping to get it added to martini-contrib too.
I think that's one of the most annoying thing in Go. For example, if I have a function with a fmt.Scanln function call, I just can't test it. I need to pass then a io.Reader and use Fscanln instead (http://golang.org/pkg/fmt/#Fscanln). This means programs using Scanln can't be fully tested. While this example is obvious, it's becoming a bit harder to evaluate for other packages. I often use this technique to simulate read/write from/to a file (a config file for instance). I create a buffer (bytes.NewBufferString("")) and then pass it like it's an open file buffer. Another problem for beginners: Mocking is almost undocumented in golang world. go-mock seems like a good start, congrats!
You're exact example was shown in a google I/O talk. see time 31:58 for the answer and time 25:11 for the slide with your code (corrected) on it. https://www.youtube.com/watch?v=fc25ihfXhbg#t=1916
You are duplicating the name and the functionality of an existing, mature GoMock, which has been around for years: http://godoc.org/code.google.com/p/gomock/gomock At least change the name of your package.
I started out using that approach, but in the end I've found it preferable to actually pass in the correct function. Global variables are still bad, even before concurrency gets involved, when they become even worse. There are ways of mitigating the pain involved down to where it's hardly noticeable, and certainly less painful in the long run than global variables... which _will_ come out and bite you. Maybe not on your first one, maybe not on your second one, but one day you'll wake up and realize that you want to do something and can't because of the 40 global variables you have, each of which individually seemed perfectly reasonable....
I almost never return the err that I get from a function call. I tend to make a new error that says something like ("%s failed to open file %s: %s" , __FUNC__, fileName, err.Error()) this isn't great but it at leasts lets me track down the error to the point my code failed.
This is where exceptions are supposed to be used. In many scripting languages like Python they tell you exactly where the error happened and show the stacktrace. That is the default behavior, now you can catch and regenerate but then you have to re-run (reproduce!) the error the number of times you re-format/re-generate it. 
Exceptions work exceptionally poorly in a multithreaded environment. go func() { f := foo() if f == nil { panic(errors.New("What now?")) } } Is that panic (exception) useful? It doesn't have any information about the code that started the goroutine, all it'll do is crash the application with a useless stacktrace. Now, if it were instead an error, you would realize you need to pass it through a channel to something that can handle it, which is what most go applications will do. Also, by not having exceptions, Go code is a hell of a lot more straightforward than languages where you never know if the control flow of your application is going to spontaneously jump around. I've written code in languages with exceptions, and it is incredibly hard to write correctly. f, err := os.OpenFile("foo.txt") if err != nil { return err } // do stuff // do more stuff f.Close() I know that I will *always* get to f.Close, unless the application crashes. I don't need to remember to wrap the whole function in a try/finally, it just works. (of course, the preferred way is defer f.Close() which just calls f.Close() when the function exits, which in itself is an awesome way to make sure you don't forget to close something, since you can put that line right next to f.Open()) 
btw, save yourself a little typing, do %v for the error like this: fmt.Errorf("failed to open file: %v", err) fmt will automatically call .Error() for you.
This will also work with just plain old `%s`.
I did that for a while, but that can cause its own problems when you start trying to analyze errors. For instance, I've got code that tries to initiate a TCP connection a couple of stack layers down, and it does something different depending on whether it gets a "connection refused" error coming out of the function or not. Wrapping it unexpectedly would be very annoying. Unfortunately, `.Error()` can eliminate a lot of information about the error. I _hate_ trying to determine what error I've got by analyzing the error string; Perl taught me how safe that isn't. Possibly a better approach is to define a new object and return that explicitly, then implement `.Error()` on it, so at least then the signature makes it clear what is going on. Just for concreteness, here's the somewhat annoying code to determine if an error is a "connection refused" error: if err != nil { netErr, isNetErr := err.(*net.OpError) if isNetErr { errNum, isSyscallErr := netErr.Err.(syscall.Errno) if isSyscallErr &amp;&amp; errNum == 0x6f { // do whatever ... return } } // do whatever else } Errors are more than just strings. (Presumably I really ought to give the 0x6f either a nicer name or find a const to import. This is in test code, so, alas, despite my better judgment I treat it a bit less respectfully...) Additionally, if you define an error in your package, export it, and consistently use it, users can compare == usefully. Wrapping it somewhere in the middle breaks ==. Unfortunately, everything you say is still true. I don't have a perfect solution, but in general I'd rather just have the error than a wrapper around it. __Edit__: Further followup, I note the `net.OpError` is already wrapping an internal error (`syscall.Errno`), and you can see the sort of annoyance that can result. At least in this case the `net.OpError` is adding information, and not squishing it down with a `.Error()` call on the underlying `syscall.Errno`.
I wrote deep error for this exact purpose. https://github.com/amattn/deeperror I use it all the time and the error chaining is particular useful.
Yes I was just commenting on the example the blog was showing. When I make a package I never just wrap an error this way. Good notes though :)
Error handling is one of my pet-peeves in Go. Every function I write looks like this: f, err := OpenFile() if err != nil { return err } reader, err := ReadFile(f) if err != nil { return err } parser, err := ParseFile(reader) if err != nil { return err } And so on. ¾ of my code is error handling. And of course, it's not always “return err”, sometimes it's “return nil, err” or “return MyObj{}, err”. The error handling obscures what's really going on: parser := ParseFile(ReadFile(OpenFile())) I don't know what the “right” answer is, but I often find myself wishing for a construct like this: f, {return} := OpenFile() Obviously problems with that, but some way to indicate, in the same line as the call, that I want to return the error, if there is one. A variant of perl's “or die”.
I think many people did it but I've wrote another similar library as well :) http://godoc.org/github.com/divoxx/stackerr
What I'm currently doing is simply having an accessor method hand back a DB object, which is very similar to what you do but has one central place to instantiate and maintain the connect. For example: package data var db *sql.DB func GetDB() *sql.DB { if db == nil { db, err = sql.Open(...) if err != nil { panic(err) } } return db } Here's another post with a nice pattern that I've used before as well: http://www.jerf.org/iri/post/2929
When you say database, it looks like you are referring specifically to SQL databases. There's a few ways I usually use, depending on the size and scope of the application. In each case, I typically I have a `db` package that holds the connection. I find it helpful in avoiding circular imports. That package may also hold database-related functions such as my own layer of abstraction over common SELECT, INSERT, and DELETE queries, and also transactions if you use those. In larger projects where the structs are more involved, I have methods on them which perform database-related operations specific to what they contain, do, or represent. They in turn call the functions in my `db` package for the more rudimentary database calls. (I haven't mentioned use of interfaces specifically, but they're important for testing, so look at joeshaw's comment for good ideas on that.)
I pass it around places as I need it, but I embed the `*sql.DB` inside a type that implements a `Database` interface that includes all the methods I need, such as `GetUser()`. This gives me a higher-level (and backend-independent) interface. This makes testing easier too, because then I have a mock database backend which implements the interfaces using only maps. (Although I am thinking about swapping that out for [ql](https://github.com/cznic/ql) and exposing SQL concepts like transactions at a higher level.) 
so, in general, interfaces make this a lot easier. Have a general function that just takes an io.Reader and uses Fscanln. Pass it os.Stdin during production and a strings.Reader during testing. Nothing says you *need* to use fmt.Scanln to read from stdin.
Would it be possible to take care of handling in user space by way of a monadic interface? Given that functions possibly returning errors have a common (result, error) structure, it should be *almost* straightforward to wrap this behavior into an Option/Maybe/Either type. Of course, there are two caveats: library code would need to implement this and the lack of parametric types would need to be worked around. I haven't used Go in over a year and am not sure what the current state of affairs is regarding parametric types.
You get used to all the error handling after a while. I honestly don't think it's a bad thing to have parse, read, and open on separate lines. And honestly, if you do that a lot you'd probably just want to wrap it up in a helper function, so you'd just have parser, err := openAndParse(filename) if err != nil { return err } I think this is actually a common fallacy among people writing go code. If you have 10 things that can all error out getting called in the same function, you're probably doing too much in that function. To be fair, it doesn't reduce the overall number of error checks, but it reduces the number per function, and thus the cognitive load associated with them. 
Note that making a stack trace for every error you encounter is bound to slow down your program. Also..... you really really need to document your API.
Ahh, right, thanks for pointing that out.
Goroutines don't have any kind of identity, id, etc. The Go team specifically did not want to implement that kind of feature because it tends to get abused. However, there are already packages out there that help with goroutine maintenance, Juju (which I work on), uses a few different techniques. One is the tomb package (http://godoc.org/launchpad.net/tomb) which gives you the ability to check the liveness of a goroutine and get the error that ended it (and also kill it if you want). Juju also has packages for maintaining long running worker goroutines, with the ability to restart them if they die (built on top of tomb). This kind of thing is not really needed in smaller programs, which is likely why it's not in the standard library or in the runtime. However, they're not too difficult to build (and luckily, already have been built). The problem with most exception handling is this: try { ... f = file.Open(foo) // do a whole bunch of stuff, any of which can fail s = socket.Connect(url) ... } catch (exception ex) { // something failed, we have no idea what action caused the // exception, can't really do anything about it, might as well just // let her fly } By putting all the happy paths together, you obscure the source of the error. If you get an UnexpectedEOFException.... what did that come from, when you read the file? When you made the socket connection? In order to properly handle every exception from every call you end up doing exactly what Go does, which is to wrap every call in error checking: ... try { f = file.Open(foo) } catch (exception ex) { // handle file error } // do a whole bunch of stuff, any of which can fail try { s = socket.Connect(url) } catch (exception ex) { // handle socket error } ... 
Why would you do that, instead of initializing the db during an init()?
`f`, `reader` and `parser` will be out of scope at the end of that block. It probably wont matter for `f` and `reader` if they were only used for building `parser`, but presumably `parser` will be needed after this, so I don't think your shortened code will work as desired.
That was my first thought as well. But that's actually somewhat desirable in some cases. var parser Parser if f, err := OpenFile(); err != nil return err } else if reader, err := ReadFile(f); err != nil { return err } else if parser, err := ParseFile(reader); err != nil { return err } leaves it in scope, but not any of the ancillary variables used to create it. I think like it at least for some forms, maybe not others.
While that's better than what the parent posted it's still pretty ugly. Not javascript callback ugly but its up there. I agree with the blog author, error handling in Go is simple but the code is overly verbose.
Sum types (unions) would be a great addition to Go, but you'd have to rethink a lot of other stuff to make them fit in with what's already there. For example, all interface types would need to be in a union with the Nil type. 
Here's an alternate handling approach using type switches. I'm not sure if it's better or worse. if err != nil { switch e := err.(type) { case *net.OpError: switch wrapped := e.Err.(type) { case syscall.Errno: // do whatever ... return } } // do whatever else } 
Hi tarrsalah. I create a database class that gets used by models. Check out the app I'm working on at https://github.com/jadekler/git-go-d3-concertsap. You'll note that each model will create an instance of the dbmap when it needs it, and then fires off a command defers close. Hope this helps! pm me if you have questions
It worries me a bit that the 'best' / official debugging tool is considered an impractical solution to the majority of use cases it's designed for. I hope we find a better alternative.
Why do we have to choose just one? :)
[This](http://godoc.org/code.google.com/p/biogo/errors#Make) does something like that. As /u/jerf notes, the perl world (where I originally come from, uses this kind of construction, I now don't use this at all (I'm the author of that package).
Except in rust it just ends the task. You can't do anything in the scope the error happened in. Then you end up with crazy nested matches. It is loosely functional programming without good constructs for handling errors. Needs a monad or something similar 
I can't believe I'm aiding and abetting this monstrosity (:P), but you're better off storing a map of the names (maybe even as a non-exported field of the "enum" struct) at initialization-time, since reflection tends to be a little expensive and you don't want to be using it every time you call String()
YAGEHP (Yet Another Go Error Handling Package) http://godoc.org/github.com/flaub/ergo
&gt; parser, err := openAndParse(filename) Presumably `openAndParse()` will still have those error checks though, and now you have to check *its* return for an error too. So you've gone from three checks to four. If anything, Go's error-handling strategy *discourages* helper functions, since you have shuttle the error along yourself at every level of the callstack.
How would you than use types defined by library if they are not exported? It seems like you would just end up with bunch of duck typing definitions without any accessible/usable code.
`try!` isn't `fail!()`. `try!()` is a macro that takes a value of type `Result&lt;T, E&gt;` and returns the error if there was one, and unwraps the success. (`Result` is an algebraic data type representing success as `Ok(T)`, and failure as `Err(E)` (it's generic so `T` and `E` can be anything)). That is, `let parser = try!(parse_file(reader));` expands to let parser = match parse_file(reader) { Ok(x) =&gt; x, Err(e) =&gt; return Err(e) }; i.e. pretty much exactly equivalent to `parser, {return} := ParseFile(reader)`.
It's completely possible to have an exported constructor and return unexported structs from it. [This blog post]( https://functionwhatwhat.com/go%E2%80%99s-type-system-is-an-embarrassment/) illustrates (and criticises) that ability.
I think this code won't find the biggest member if it's negative or the smallest if it's positive, as int variables are automatically initialized to zero.
The general solution used in the Go libraries is to export structs with non-exported fields. This also has the advantage of letting you expose some fields and not others when you want to give external users some but not unlimited visibility.
Okay I misspoke, it doesn't fail. But it does return. I don't get a chance to do anything before returning. While this is great for propagating, I don't want to propagate. I just want a try catch 
Thanks so much! 
Ah, yeah! I knew there might be an issue because of the default initialization, but I didn't think it through. Thanks for adding a fix!
If users of your code want their code to be more testable, they can (and should) make their own functions take interfaces... but they can create the interfaces, there's no need for you to do so. This is one of the differences between Go and other languages with interfaces. You don't have to create interfaces for your objects, your users can create interfaces that your objects implement. Just try to make sure that important functionality on your types is done via methods, not setting fields in the struct. However, if you have functions in your package that take your types, if you can make them take interfaces instead, this can help users who want to send mock objects into those functions. This is where you can do the most good for helping users of your package, because not only can they send mock objects, they can send real objects that you don't even know exist, as long as your functions are general enough to handle them (consider ioutil.ReadAll, for example).
Better solution: http://play.golang.org/p/vhHmjhOMEo Only one loop run instead of two, one temporary variable less.
https://github.com/skelterjohn/go.matrix :) The code looks a bit odd when I go back to it, sometimes. (Originally https://code.google.com/p/gomatrix/)
https://github.com/bketelsen/crypticmysql - not my first, but the first package I released. I posted it on the Golang-nuts mailing list and it was promptly panned, then corrected by helpful gophers. https://groups.google.com/forum/#!searchin/Golang-nuts/crypticmysql%7Csort:relevance%7Cspell:false/golang-nuts/31cTwfAGEUw/UX7FTagKoFEJ Pretty standard for Go. "It sucks!", "but here, I fixed it for you" Overall I love the Go community. Honest and helpful at the same time.
Haha, old habits die hard. :) You should add some stuff to the README, by the way. At least a link to this: http://godoc.org/github.com/skelterjohn/go.matrix, which is a helpful start to understanding the library :)
What happens if the slice is empty?
Re speed, certainly won't use deeperror or anything that generates a stack trace in a line that gets called often. It's not true for all errors but many are edge cases Re doc, yeah I know. Thanks for the reminder. 
The semicolons were necessary at the time! This was 4 days after the language was publicly announced.
Ahhhh, ok. I don't think I looked at Go until almost all semicolons had been made optional.
I think the behavior is fine. It is how Go does opaque types. I agree on the type system being inadequate when a dynamic type is consistently used as a particular static type. I've used Objective-C heavily–it has the same problem–and I know this is a significant source of bugs. I'm not sure that C++ or Java style generics are the right tool for Go because Go isn't really a systems programming language (despite what the core developers say) and those systems are a bit too heavy for what Go is used for. Go is a scripting language that has better performance at certain tasks that are important for network programming and a much nicer deployment model then other scripting languages with static compilation. Go is very similar to Objective-C (which was first used for network programming in NextStep) and used in much the same way. I think in the future Go may also be nice for GUI programs. Maybe something that can put static decorations on dynamic interfaces–sort of like Typestate–would be the right way? That said, maybe the core developers really want to make it a systems programming language. In that case we may end up with something like Objective-C++ where there are essentially two programming languages in one. That is nice where you want the power of both types of programming without writing bindings. This would be great if Go tries to go after game developers or certain classes of applications (like a web browser or photoshop). I think it is interesting that we have Go taking a more modern Objective-C route and Rust taking a more modern C++ route.
A slightly more generic solution - https://gist.github.com/nindalf/10551842 I made two functions `Min` and `Max`. Each accept an input array and a function called `criteria`. The `criteria` function decides which of 2 values is "better". Its generic because you can change the criteria later without affecting `Min` and `Max` at all. Today you might feel that bigger is better, but there might be further constraints in future, and in this case you would just pass in a different `criteria` function. Its simple to adapt `Min` and `Max` to take any type other than int as well - you merely need to change the types in the function definition. So you can have almost the same function decide the Minimum and Maximum strings, or dates, or your own types. 
Good tutorial. I think it would help if you listed the steps at the beginning, like an index. It helps following along and anticipating what comes next.
Should be using https://github.com/howeyc/fsnotify at least. This solution seems to be ad-hoc :(
Actually I'd say the worst of it was when more than one thing was trying to screw with the backtrace at once. Presumably we'd dodge the problems where that could segfault Perl, since Go is an order of magnitude or two simpler and doesn't have the major issues I've encountered with Perl over the years with features interacting poorly, but we certainly would potentially encounter problems with composing the stacktrace-mungers correctly. Plus there's the times where the stacktrace munger was _itself_ part of the problem, but it erased itself off the stack so it wasn't visible in the crash trace. Again, possibly Go wouldn't permit that sort of thing in the first place, but it's the sort of issue you run into when you start mucking with the stack trace on its way out.
You hunt flies with a shotgun. I can tell. On the other hand that approach would work really well if you're dealing with an infinite stream of values. So there is that.
Interesting.. so you can `gcc helloworld.go`? i wonder how this works with GOPATH's and how well it performs with scheduling goroutines etc. i also wonder who this improves support with gdb (seeing the recent divergence of the go team continuing the improvement of gdb support)
WOW. That sounds so interesting! Being a beginner in Go, i'd like to see the discussion around this
You requested feedback, so here goes - I don't think the directory structure is optimal from a Go perspective. Its the convention in Java to have a `/src/com/name/space/actualcodehere` but Go projects in general put the *.go files in the root. I think this simplifies importing the project into another one. Nice work by the way, your code looks neat :)
I was reading Effective Go today, and the article about [Generality](http://golang.org/doc/effective_go.html#generality) confirms OP's thesis. I was wrong.
You use go build -compiler gcc. gnugo support is integrated in the go binary.
This is misleading, GCC 4.9 has *not* been released yet. [It's just RC1](http://gcc.gnu.org/ml/gcc/2014-04/msg00091.html). According to the e-mail, gcc 4.9.0 release is expected to happen on 21 April.
Woah :/
It's the default gccgo in Ubuntu 14.04 releasing within a few days! Tried it on some of my projects, not a problem.
Might be kinda late to recommend this but if you could open up registration a bit on Wednesday afternoon/evening it would probably help to alleviate the inevitable Thursday morning traffic jam.
Yes, that's exactly my point. So fmt.Scanln is just for untested functions? ;)
Where are you located? On the coasts where salaries are 6 figures, it doesn't make a lot of sense to work for less than $100/hr. Seems like salaries in the mid-west are more like half that. Also, if you are in a college town you are competing against a constantly refreshing pool of cheap talent.
The domain is different.
I'm in Los Angeles. Is it because I'm in web dev when I should be working on other stuff or do I just not know where to find decent contracts?
&gt; Verifiable go or vgo for short is a subset of the go programming language introduced by Google that has been extended Is it a subset, or is it an extension of Go? They're sort of the opposite. Also, the way this is phrased makes it sound like Google has introduced vgo, which I highly doubt.
Written by a systems engineer at Cloudflare, this book serves to provide "practical ways to use cryptography in your projects". However, it's also worth reading Thomas Ptacek's response and review (he's the founder of Matasano). You can find the response [here](https://gist.githubusercontent.com/anonymous/3cc34251e501c2c8ffb7/raw/cf9ff4e7ce13985458b240980e91202ac732b4e6/Practical+Cryptography+in+Go+).
Still missing some key features like completions, but I think a good start on 100% golang implementation (not a fan of wrappers around C counterparts). Based on terminal handling in [linenoise](https://github.com/antirez/linenoise/blob/master/linenoise.c) and only supports a subset of the most common terminals. Edit: [Added history support](https://github.com/nemith/go-goline/commit/50fb85fbecd5f4117a234a995b88154806cb825f) all without really touching the core components which was one of the major goals to make it very flexible. 
Somewhat related, I think it would be cool if Go added a typestate system. I think it would be a good compliment to duck typing and would integrate nicely with existing features. Basically you can add a compile-time state (probably the name of an interface) to a type that represents the types state statically. The state can be changed in the return types of a function or initially assigned in a struct definition. When a type is in a state, you can only call methods from a particular interface. Unlike duck typing, the state is static and state changes are constraints that are completely validated at compile time. For example, you could put a `path` state on a string to indicate the string is a path and call functions from either the path interface or generic string functions. Another example would be to have an open state and closed state on a file each represented by an opened and closed interface. An interface could also have a state. In that case it would be represented by a particular sub-interface. I'm not sure how extending states you didn't write would work or passing an existing state through in a function that doesn't specify state since that may feel too much like generics with type parameters. I suppose you can already do most of this purely with interfaces, but it would require fat pointers and dynamically looking up types at runtime. A typestate system could do this at compile time with a standard pointer, no virtual function calls, still allowing access to struct fields, and more clarity. I'm not sure if I'm clearly explaining this, but there is a lot of information on various typestate systems out there.
Good question. Looking at the source I think it is just a preprocessor because it imports the AST package. I assume they mean it will only extend a subset of the language.
What is the &lt;- notation being used there? I've not seen it before.
It's an operator for sending to and receiving from channels. http://golang.org/doc/effective_go.html#channels
Ah, so a means for which to maintain sync? That is very cool. I haven't jumped into that part of go yet =)
This is what I use: https://github.com/peterh/liner
Nice! Just a heads up, it looks like RemoveHandler is currently typoed as RemoveHanlder.
Crap. That didn't exist (or I couldn't find it) when i started this project a long time ago. Looks like the same goal. I haven't dug into his code yet.
Thanks. That isn't my first Hanlder typo. Fixed :)
I always think that go-tool must be extended with static analysis tool, like coverity or fxcop. And this is quite the opposite.
There's "not agreeing with something", and then there's "explaining why something is badly wrong". With something like crypto, it's quite important to get it right, really. Personally, I thought final comment ("the book *at no point* discusses NaCl...which is the single most important recommendation a book on crypto could have made") was spot on.