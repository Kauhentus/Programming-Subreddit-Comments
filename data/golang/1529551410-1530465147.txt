&gt; It‚Äôs better to have a ‚Äúgood enough‚Äù implementation rather than don‚Äôt have it at all. Does "good enough" mean false positives or false negatives? Because false positives are a big issue for linters and drastically reduce their usefulness.
I don't think they meant the interop is complex, it's the architecture of Kafka. It has quite a few knobs and dials, partitioning, zookeeper, multiplenodes, etc... Or you could GRPC point to point, where there are only two points. Event easier you could put up a normal HTTP RESTful endpoint. As long as the core logic is the same, you can add a more complext transport layer later
Thank you for posting!
Hey! I am not OP but I am the creator of Liman. Liman is not a managing tool. It is writted for monitoring. So comparing with portainers doesn't right.
Hey! I am not OP but I am the creator of Liman. I wrote it for to be light. It proabbly won't give anything more then Kimematic. I never used Kitematic. But I like the idea of being web application and can reach it from everywhere.
In the specific context "good enough" might also mean to start with only a small set of tests rather than attempting to write a "feature-complete" linter from the start. (But I am only guessing.) A better answer is possibly this rule in the "Adding new tests" section: &gt; To test absence of false positive cases we can (and should üòâ) create negative_tests.go where check must not be triggered. So if every contributor of tests obeys that rule, your concern should be addressed.
[Prior discussion](https://www.reddit.com/r/programmingcirclejerk/comments/8py4q6/learning_gos_concurrency_through_illustrations/?ref=share&amp;ref_source=link) (to avoid redundant comments).
Hi Ben, A question here - I have tried both the constructor approach and the config instantiation approach. The only problem with the constructor approach is that when your app becomes big, the params keep on piling and then the `New()` call becomes a mess. I have this line currently in my app - `package.New(logger, callInterval, someType, someString1, anotherString2)` Converting this to the config instantiation looks much better - cfg := package.Config{ logger: logger, t: someType, str: someString1, str2: anotherString2, } obj := package.New(cfg) 
I'm not even sure you read my post. I never talked about what makes code "object-oriented"/OOP: it is a lousy term and I completely agree it is a property of programs and not languages, I've written "object-oriented C" code too. I was talking about what makes an *object* in programming languages different from a regular *struct*. And the only difference is open recursion: the ability for `this.foo` to be dispatched depending on the object. This is not about OOP but about late binding of mutually recursive functions. And of course, as you and I agree, it is a property of programs, not languages, and can thus be implemented in any program. But Go's type system doesn't have that feature, so Go structs are not objects in the theoretical sense. (In fact, you'll see a lot of OOP proponents avoiding the use of it too: OOP these days has few to nothing to do with the theoretical concept of an object, and a lot to do with abstract data types, which predate OOP. Food for thought.) But that's why I said I understand people who don't want to call them objects: even if they can't exactly pinpoint why, they feel something is missing. Although I also said I personally believe it's ok to call them objects for other reasons.
Honesty is good. Open source is hard when people are demanding help now now now and you just don't have time to do anything about it. Better to put this disclaimer on it and show what you have then to just never release it at all.
Hey Gophers! I work in/around video stuff, and have always found myself jumping through too many hoops when building stuff in Go and working with WebRTC. pion-WebRTC is a simple WebRTC implementation, recv is working (and working on send) would love a review/thoughts! Also if you are thinking of building something would also love to chat! If you have a cool idea would love to help (open source or not) really would just like to have users to make it better. I am hoping to see people build cool things with it, some of the things I have wanted to try * Send a video file to multiple browsers in real time, perfectly synchronized movie watching. * Send a webcam on a small device to your browser, with no additional server required * Securely send video between two servers * Record your webcam and do special effects server side * Build a conferencing application that processes audio/video and make decisions off of it Also if you have used other WebRTC libraries this one tries to be a little different like not being tied to an encoder. I have seen a few times where people want to share pre-recorded content via WebRTC, so wanted to give people the best of both worlds. Well thanks for checking it out, and hope you like it!
Ehm, I really don't think you have a correct link there üòâ
I'm well aware of that. I'm not the one who created Telegram's protocol - I just needed an IGE library to interact with it.
Everyone knows IGE is weird. No one knows why Telegram's protocol uses it, but they do. 
Then you can use option function types.. It can be very beneficial to hide a lot of struct fields packages from other packages to control the state of everything. Something along the lines of this: https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis
https://github.com/vektah/gqlgen could be worth a look.
Okay, you've convinced me; I'll check those things!
&gt;Does "good enough" mean false positives or false negatives? I think it also depends on the checker itself. False positives are treated as bugs and hopefully, they'll be eventually fixed, but it's hard to claim that "there is no false positives", only that we remedied ones we have discovered. The plan is to use "experimental" flag carefully to avoid negative user experience with checkers that are not "good enough" yet. 
I can agree it is, but I also think that developing an application starting with Docker is a bad idea. From my point of view is better to create the application that can run on a standalone server, like a VPS, and only then start thinking about the microservices and scaling with Docker.
Seems to be a FTE: https://draftcode.github.io/
Hello, /u/dlsniper! Actually my problem was being myself very greedy, hahaha! What I did is to put all the custom tags of the project in the *Custom tags* of the *Build tags*, so the IDE understood that it's necessary to build all the files, giving me that warning. I understood you need to define only those tags you're working with on your machine, allowing you actually avoid any redefined code. Thank you very much for taking care!
Hi, thanks for the update. We'll see what we can do to make this a bit more clear in the future.
You can use https://github.com/utrack/clay HTTP endpoint generator of you don't want to support separate instance of a gateway :) 
Why not stderr?
It's a personal project on the person's own to learn more about the protocol.
Use what makes more sense at the time. I had a program where I used constructors extensively until it caused more work then it helped. Now I only use constructors when I need to perform some setup work before the object is created. For example, I have a database migration manager object that has to check the given database to see if a migration table exists before the manager can be created. One popular project [Cobra](https://github.com/spf13/cobra) used by big projects like Kubernetes uses config instanions moreso than constructors.
It's an interesting. Thanks!
Open source licensing places limits on how people can use the code. It doesn't place limits on people talking, reading, or commenting the code. The situation you're describing is like if your aspiring author friend wrote a book, asked you to read it over, and you found a grammatical error. They have no legal grounds to sue you over finding that grammatical error, especially since no contracts were involved before looking over the source material. They WOULD have legal grounds to sue if you tried selling that book. That falls under copyright law though instead of open source licensing. Hell right now you could literally steal OP's code, sell it, and there would be very little he could do legally since it doesn't currently have an open source license. The most he could charge you for would be copyright infringement, but if you make a few changes to it you could claim it was transformed enough to be filed under fair use.
Some apps maybe write something to stdout and have a dedicated log file for other stuff... Maybe just include a command line argument, eg: program --log-to-stdout
You dont have to address all the issue immediately. Put up SLA for response time that suit your workload, and contribution guide. Pull request template and issue template also helps a lot. There is a big difference between not being able to support well and not supporting at all. In case of no support provided, I dont think there is any reason for anybody to use it except for the owner of the source code.
The best "best practices" post I have found was this one [https://www.vinaysahni.com/best-practices-for-building-a-microservice-architecture](https://www.vinaysahni.com/best-practices-for-building-a-microservice-architecture) (Also in a different format at [https://github.com/katopz/best-practices/blob/master/best-practices-for-building-a-microservice-architecture.md](https://github.com/katopz/best-practices/blob/master/best-practices-for-building-a-microservice-architecture.md)). I have found that people differ greatly on what they consider the best way of doing microservices. I believe every design decision you make should be made to lower development cost (and cost is time mostly) and operational cost (hardware costs, time finding bugs, time deploying) and improve performance (response times, number of concurrent requests etc) So when considering something like kafka vs grpc take the total cost (or your best guess) into account.
Any feedback welcome. One question for advanced GO devs: Is it possible to refactor the ***Call*** function to accept a struct instead of a pointer for the ***Aggregate*** parameter ? Here I wasn't able because **Aggregate** is an interface and gorm need a pointer. So you can't **Save** an interface because it's not a concrete type.
Thank you very much! We have updated the post.
This is great. I look forward to the removal of OpenSSL. Does it have data channel support?
Hi qu33silver, I just use constructors to set default values and not typically to pass a lot of options. e.g. t := myapp.NewThing() t.Logger = logger t.CallInterval = callInterval ... 
&gt; The argument against Functional Options is pretty weak. You can just as easily expose the fields on the struct they are modifying. If you expose the fields on the struct then what is the point of using functional options? It seems like overkill for what could be replaced with a simple assignment. &gt; Structuring code to make the intent obvious does a lot more to help developers use it correctly than writing long comments on every field. I'm not sure I would agree that `"Set X before calling Open()"` is a long comment. &gt; The only argument against a Config struct is that it only has a single advantage over not using one. I'm not sure I follow this. Perhaps my explanation was too concise. The benefits are 1) less code, 2) reduces complexity of the API, 3) provides cleaner documentation.
But then you have to use JS (or wrap your brain around Gopher, or try the new Waters of webasm). I'm a big fan of Google's office productivity tools, and their applications are among the most complex in the world. However, they also demonstrate quite well the limitations of web based UIs. A non trivial spreadsheet in Google Sheets will bring a reasonably powered laptop to it's knees, taking tens of seconds to open and causing Chrome to push the OS into swap cycle because of memory use. Excel exhibits none of these behaviors opening an export of the same spreadsheet. The rest of the productivity tools demonstrate similar behavior. Web apps are adequate for small applications; I do not believe they're a suitable replacement for native apps, and nor is HTML+JS a panacea for all application UI development woes. I believe that the knee-jerk response of "just use a web interface" is only because there isn't a strong defacto standard UI library for Go.
Awesome article. Concurrency and web dev are the primary reasons I love Go, and this article does a fantastic job of describing why Go's concurrency model is the way that it is, and why it's so handy.
I've spent the last couple of mornings reading graphql docs and gqlgen tutorials. It looks very nice. Beware that there are a few issues with differences between the code and tutorials: https://github.com/vektah/gqlgen-tutorials/issues/2. I think most of the problem is me learning to think in graphql.
I found https://github.com/deltaskelta/graphql-go-pets-example to be slightly too simple (everything in one package) and https://github.com/tonyghita/graphql-go-example to be a little too complex/‚Äúproductionized‚Äù ‚Äî it's clear they factored everything out into separate logical packages, but without a bit of narrative, it's difficult to understand _why_ without investing some time. eg. what is the `swapi` package for? The simple example is probably a good starting point if you're aiming to build something simple (I'm not). I'm now gravitating towards `gqlgen` as mentioned in another comment. As for MySQL vs Postgres, it's a bit of a holy war. As I understand it, Postgres has a history of being more correct, and MySQL has a history of being easier to manage and understand operationally. Both have made big recent strides in implementing the aspects they lacked compared to the other. I would use whichever one you feel more comfortable with and/or whichever one most people you would ask for help are more comfortable with. At work, we use MySQL almost exclusively, and recently ported an app from Postgres to MySQL, but that's mostly because our DB folks are magic at maintaining MySQL and building tooling for it, and our institutional knowledge/skill running Postgres is very thin.
&gt;Again, this hides the configuration field on your Client type but provides no other benefits. The benefit is that this client := lib.NewClient(lib.Config{ Host: "localhost", Port: "8888", SomeBoolOpt: true, SomeOtherBoolOpt: false, SomeIntOpt: 123, }) reads better and is less error prone than this client := lib.NewClient("localhost", "8888", true, false, 123) when you start having a lot of arguments. Functional options imo is just overthinking it.
&gt; If you expose the fields on the struct then what is the point of using functional options? It seems like overkill for what could be replaced with a simple assignment. It depends on how many fields you have. If you have a small number of independent fields than assignment is fine. Function options become really useful when you have a large number of fields, or when those fields' types are themselves struct types. &gt; I'm not sure I would agree that "Set X before calling Open()" is a long comment. It's not, but your example was also a pretty simple struct. Why rely on documentation when you can make the intent object from the structure and design of the code? &gt; The benefits are 1) less code, 2) reduces complexity of the API, 3) provides cleaner documentation. I think these are fairly subjective benefits. Less code is not always a benefit, sometimes more code is better if it makes it easier to understand the purpose or behaviour of the code. How do you define "clean" documentation? Fewer types or easier to understand? I think my primary argument is that your recommendations are fine for simple types. Don't go creating function options for a struct with 3 fields, I completely agree. But I think there are times when function options are the correct solution.
You're allowed to learn and work with both of them. They are not mutually exclusive.
I see. So you suggest that I use Go to broaden my experience as a developer in general, instead of focusing on a single language in particular?
This is from 2015.
Learn both, add Python to the mix. These 3 languages are not going anywhere anytime soon. Go is a very capable and well thought out language. It's already quite popular and used by many companies and startups. Definitely worth learning.
In general yes. Tech is faddish, and what's hip and well supported one day may not be the next. Get good at learning new things. This means being versed in a variety of tech.
To expand on this from examples from the std lib: - If your package is exporting one concept, or exporting it's concrete purpose, use `New()`. - ['container/list'](https://golang.org/pkg/container/list/): `list.New()` - ['crypto/hmac'](https://golang.org/pkg/crypto/hmac/): `hmac.New()` - If your package is exporting something that fulfills a certain (especially if it's common) interface, use `New[Doer]()`. - ['archive/tar'](https://golang.org/pkg/archive/tar/): `tar.NewReader()` - ['bufio'](https://golang.org/pkg/bufio/): `bufio.NewScanner()`, `bufio.NewWriter()` - ['bytes'](https://golang.org/pkg/bytes/): `bytes.NewBuffer()` - ['encoding/base64'](https://golang.org/pkg/encoding/base64/): `base64.NewEncoder()`, `base64.NewDecoder()`, `base64.NewEncoding()`
I don't think that you'll find any programmer worth their salt in this day and age that focuses on a single programming language. Every god damn framework comes with its own programming language. Aim to learn at least three or four especially if you are in comp sci. I recommend Go, Python and C in addition to Javascript/node. And maybe a little Java....
I am simply worried about spreading myself too thin, and knowing multiple languages at a mediocre level but not being proficient enough in a specific language. I'm pretty much scared of being in a jack of all trades, master of none type of situation.
I see. I have already completed the Java coursework for my degree, and I am taking a class next semester that teaches C/C++, Prolog, and Scheme
I've heard a lot about Python (and I helped my brother with it when he was taking a class at his school) however I've never taken a deep dive into learning it. I'll have to take a look into it at some point.
you'll be fine, bro. just play with it when you have free time, and soon you'll be up to speed.
If your goal is to optimize for a job then Go is no the best choice you should learn JavaScript and maybe Java because those are the languages that are mostly widely used. If you live in SFO or NYC then you can probably ignore market trends because of the law of large numbers. I would recommend Elixir over Go at this point if you're looking to broaden your horizons. 
I think learning more than a single environment in depth is a good idea for *everyone*. In fact, I got hired as a Go developer with no previous Go experience exactly because I had a background in several different environments. Demonstrating a varied background on its own looks good on your CV, even if you're not actually applying for a job that needs that specific experience. All other things being equal, I personally would sooner hire someone with 5 years of NodeJS experience and 3 years of Go experience than someone with 8 years of NodeJS experience, even if it was for a NodeJS job. You don't *need* to use Go, of course. Pretty much any other environment will work for that as well.
I'd be looking for a job in Arizona, most likely near Tempe.
Oh wow, I didn't realize how important it is to demonstrate a broad level of knowledge of languages. Now that I think about it I guess it makes sense because languages share similarities that would make certain languages easier to pick up depending on what you have experience with.
[https://divan.github.io/posts/go\_concurrency\_visualize/](https://divan.github.io/posts/go_concurrency_visualize/)
Only if you find Go more appealing. They are both important and widely used languages with robust ecosystems, whose concepts transfer to other languages. Additionally they both have a solid concurrency story (Node's non-blocking I/O, Go's actual concurrency) and set you up nicely for understanding how to write high performance servers. If you just want a taste of Go's more powerful concurrency model, check out [https://gobyexample.com](https://gobyexample.com/goroutines) and follow the "goroutines" to "stateful goroutines" section. In particular, if you understand the "Worker Pool" part you can mostly transfer that to Node. 
Gotcha, thank you for the resources!
Once i switched to go primarily about two .. two and half years ago (when I started working on/with kubernetes) I now have 0 desire to program in node.
In general, employers will not particularly count "experience I had while at school" as real experience, because they assume you did it with coursework. Since not many schools, if any, use Node, I'm assuming you're doing non-classwork projects, but don't count on most interviewers making that leap. I had similar problems when I first came out of school explaining that I'd actually been doing real work on a critical system for the university, and it wasn't just coursework. Probably the best solution for this is to go ahead and spread yourself wide right now. A resume for a fresh grad that has Node, Clojure, and Go, for instance, gets my attention real quick. There's a lot of employers who will see that and go "meh, I want a Java dev", but they're the ones you don't want to work for anyhow. You want to work for the ones who see that resume and start drooling. Tune your resume for the job you want. Moreover... don't worry about knowing too many languages at a mediocre level. It actually works the other way around; the more languages you learn, the more you understand computation in general, and the better you become at all of them. In fact I _strongly suggest_ making sure you spread wide... Go and Node are different enough that you're doing OK, but make sure you get something really different in there too. The time to focus is when you're employed somewhere... and even then, keep your eyes out and fiddle with things every so often.
I've started to work with Kubernetes now as of a few weeks ago. Does go have any specific benefits when working with k8?
Thank you for the words of advice! Yes, I do Node.js development on my own time (I have several projects that I have worked on, and have code on GitHub). I also have had multiple internships which I can list on my resume. I will definitely begin to widen my interests and try to learn as much as possible!
From my personal experience, being able to program in multiple languages -- even just a little -- is a big benefit. In most companies, the only people expected to drop in and immediately start coding with no ramp-up time are contractors. My employer, for instance, has code in C, C++, Go, Elixir, Java, Javascript (Node.js, Express, React, vanilla), Kotlin, Perl, PHP, Python, R, Ruby, Swift, etc., and we can be expected to jump in on any of them that need audits and security reviews, development help, fixes and updates, or rewrites. Being a polyglot isn't necessary but it helps! We've got a team of people who almost exclusively work in Javascript and React and they're one of the busiest, best organized, and most productive teams in the company. We've got a lot of critical apps that are owned by a single person too. The key thing here is to be flexible, and one of the best ways to do that is to know how to program in multiple languages: each one will expand your understanding and teach you new techniques you can apply to other languages.
Wow, so you aren't expected to have perfected a specific language/framework in order to be seen as a viable applicant?
&gt; I got hired as a Go developer with no previous Go experience exactly because I had a background in several different environments Me too. Been in the industry 20 years now, used everything from bash / perl / c to golang / python / ruby. No need to anchor your ship to any single language or platform... 
&gt; a broad level of knowledge of languages The value is not so much knowledge of multiple languages, as it is a knowledge of why there are multiple languages, and show awareness of some of the details of how languages work: how do they use memory? How are they executed? How do they handle concurrency, etc. Realize that a language is just a tool to get a job done. You don't find jobs for "screwdriver expert" or "hammer specialist" so much as you do "electrician" or "carpenter". Hopefully that puts a better perspective on your job search...
That really does put it into perspective for me. If our job is to build things, we are better of knowing which tools are the best to use instead of using of trying to use a hammer when a screwdriver would be better. Thank you!
Yes and no. Most jobs, you won't get a choice of what language to use, since the tech. stack is chosen early on in a project. Thing is, if you're solid on your comp sci fundamentals, it doesn't matter if you know the language or not, you can learn it after being hired. So get solid on your fundamentals. As I said, know how languages work in general, and be solid on one language. If its Node.js, that's fine, just know it very well: how exactly does it use CPU / memory, what are its limits, strengths, etc.
I will certainly keep that in mind. I believe a lot of these more advanced topics will be covered in later courses during my degree.
Don't learn 10 things at once obviously, spend some time with whatever you pick, but also understand that once you learn a couple, the language stops mattering so much, and you'll be able to switch around easily enough.
I see. Thanks. Although I dont think exposing loggers are a good idea. I have done this several times and don't like it. Guess we will have to find a middle ground between convenience and security. 
I have used probably 20-30 languages over the last 22 years. I am a "Jack Of All Trades" and have no problem getting jobs. The thing is, I know how to program, and I know how different paradigms work. Depending where you are in the world, the language and platform in demand might be different. For instance, node.js in my area is fading fast, Go is picking up, but if you always want to have a job, C#/.Net and Java/Spring are the ones to go with. There are only two companies here that use Ruby on Rails. But, that is where I live, we don't have a lot of start ups, we have some really major insurance and credit card companies. Where you live, will be different. Investigate what is in use, what the demand is, and learn everything you have time to learn. Knowing the strengths and weaknesses in each platform will be very beneficial to your career. More than anything, keep building stuff. If I interview you, I want to see what you have built. So many people come to me and say I know node.js but don't have anything to show for it. 
Yeah, good points, but he really couldn't sell it as there are so many public IG turbo's. I am open sourcing it because I failed to sell it haha.
I hope people also notice the godoc example at https://godoc.org/dmitri.shuralyov.com/gpu/mtl#example-package--RenderTriangle (and its output). I'm quite happy with how it turned out.
The best presentation describing the mindset behind vgo. And Russ is a great guy.
There's a time and a place for both and I work in both environments almost every day. That being said-- I have slowly gravitated more towards Go and have lately been rewriting many Lambdas (AWS) from Node.js to Go, and I am quite happy. Go is also my "default" when I start something new. So I will first think, "ok, this is going to be written in Go, but would Node make more sense here?", instead of the other way around. YMMV, but I have come to really love the safety of Go.
You'll be switching technologies, languages, libraries, frameworks etc so many times in your career that you wouldn't even believe it. Or at least should, because if you don't, you'll find yourself unemployable in 15 years with nothing but node on your resume.. It's worth seeing different approaches different tools take to the same problems and learning to solve them with those different tools - that's what I personally see as programming skill. Hell, I'd even recommend picking up something completely alien to you now, just for fun, to see how it is and to get yourself acquainted with all the different ways.
That‚Äôs not the best way of thinking about it. I hear that a lot and it‚Äôs kinda funny. You aren‚Äôt spreading yourself thin. It‚Äôs not like you hit some limit here and have to decide where to allocate pieces of your brain. Learn multiple languages because it helps you learn new ones in the future more easily and faster. If you don‚Äôt use a particular language (or API or framework or tool) for a while you forget parts of it. That‚Äôs fine and natural. That‚Äôs the thing too. People think they should somehow memorize an API or something. That‚Äôs silly. In fact, I can‚Äôt tell you all the string functions Go has right now. I just know when I need to use one, I can lookup Godoc.org and see. Failing that I can find a package. Failing that I can write my own function. So you can‚Äôt ever expect to memorize it all. First off. Second - it changes. Go is really really good with stability and backward compatibility. JavaScript frameworks and packages? Not so much. The things you use most often will get committed to your memory. The rest you know how to look up. However. There are recurring themes and design patterns to memorize. Think about it another way. If you learn react.js ... in 5 years time (or less) will you consider it being spread too thin when there‚Äôs a new JavaScript framework that you need to learn? Will you want to use React forever? On the web, the only thing that‚Äôs constant is change. What you need to learn is how to adapt and learn new tools, languages, and frameworks quickly. For example. I did not know React at all for my last job. I had an interview coming up and learned react in about a week or so. I answered all the questions during the interview just fine (it was not a horrific whiteboard style one). And, yes I knew enough react within a week to build stuff. Months later I had scenarios where I had to delve further into its internals to solve specific problems as they came up. That‚Äôs how you have to approach the web. That‚Äôs also why interviews that test your memorization of an API are absolute rubbish. 
I am really looking forward to the removal of OpenSSL as well, it is a tough nut to crack (crypto is not my background at all) I barely got SRTP working :) It doesn't have datachannels support (yet) I am going to start adding it right after I finish getting it sending video, which should be done this weekend. It should move pretty quick, I am going to use cgo for the MVP (on a branch) and then slowly work on getting my own implementation of SCTP. That way people can use it as soon as possible. I am really excited to see what cool things other can build once Go has datachannels. STUN will be pretty easy expect that in a month or two, TURN I don't think will be done for a while. I might get lucky and get outside contributors, but if it is just me probably won't be done for a while.
Without trolling intention, Nodejs is everything a developer doesn't want. And Go has *almost* everything a developer wants. Just switch.
Thank you for your insight!
I really like your example of carpenter vs hammer expert. I‚Äôm going to shamelessly steal this. Another big value of at least being functionally familiar with a language is demonstrating learning and the ability to apply that knowledge. Not all companies look for or use this as a qualifier but many will, especially for senior / non-entry level (and let‚Äôs be honest nobody hires entry level explicitly) positions. 
Depending on the type of job you want and the sort of industry, at least being familiar with several languages would be good. Go probably takes a bit more effort to effectively ramp up on than python, but both are generally good to know. I wouldn‚Äôt actively stop writing JS/node to learn go, or another language. I would suggest picking a project to implement in Go, or another language though.
From a pure language perspective, probably. But from an economics perspective I think Node wins. A larger userbase, plethora of packages (albeit of highly varying quality), an established ecosystem, and of course lot of jobs. 
To echo what others have said, if you know Node learning Go will only make you a better developer and open up doors on the job market that you might not be able to right now. I don‚Äôt think give up Node or ‚Äúswitch‚Äù. Just do both. 
That's a lot of stuff, but I learned today that `new` and `make` do not necessarily allocate variables on the heap.
\+1 to the software revolution! :)
For the love of all things holy, please don't use platform specific APIs (graphics or otherwise) unless you have a good reason. We have a standard for this. It's called Vulkan and it works everywhere [including iOS and macOS](https://moltengl.com/moltenvk/) (no thanks to Apple). https://github.com/vulkan-go/vulkan and https://github.com/vulkan-go/asche
Agreed. Then it's all about the quality of the job you want to apply for. Generally, less "popular" languages mean a more interesting job. e.g. you can get plenty more php jobs, but then, what are you going to do in this job?
all of k8s is written in go all their libraries are written in go.
&gt;a class next semester that teaches C/C++, Prolog, and Scheme Is it some sort of survey of programming methodologies? I'd think each of those languages would take a class of their own to fully grasp them.
It is a class concerning different types of programming languages. Here is the syllabus: http://www.public.asu.edu/~ychen10/teaching/cse240/SyllabusInfoCSE240.pdf
u/izuriel \-- i completely agree.
I see. So I could pretty much take an alpine container, install go and my dependencies, build the application, and the delete go and the dependencies to have the smallest image possible?
&gt; please don't use platform specific APIs unless you have a good reason I agree with this. Vulkan can be a good choice if you want to use a low-level graphics API (rather than something higher level like Unity, UE4, bgfx, etc.) but don‚Äôt have the budget/motivation to implement custom backends for Windows and macOS. Depending on your goals and how serious you are about low-level graphics APIs, it‚Äôs probably good to be familiar with them all.
Precisely. And while finding Go work is harder, it generally is higher paid. I am making 2x per hour on my current gig (Go API + Vue front-end) than I was doing Laravel/Lumen+React.
The builtin `error` interface is the greatest bit of design as it showcases gradual abstraction. Any erorr is valid, but some errors may be more descriptive, if you care to assert/type-switch it. `reflect.Type` is also a fantastic example of a large interface, though not as easy to explain. `sql` may be the greatest fully-fledged example. The domain of a SQL client is so precise and well-defined that a library can require a huge (progressive) interface and automatically provide more power to the user, transparently. `time.Time` is a great example of the inverse - satisfying interfaces. Of all the time libraries, Golang's is one of the best. The `time.Time` type works flawlessly in almost every use-case. One of bad implementations in stdlib is `log`, because they chose not to include progressive interface definitions. In theory, `log.Logger` should be an interface type composed of `log.Printer` and `log.Errorer`, and the default logger should satisfy it by logging to stdout. In practice, everyone has to redefine the logger interfaces.
Type assertion. var myInterface interface{} myInterface = "hello" myNewString := myInterface.(string) + " world" fmt.Println(myNewString)
Thanks a lot for the detailed replies man, really insightful. I spent the afternoon experimenting and learning more about NATS. I have one more question though, how are you guys managing your `.proto` files, I looked around and a lot a of people say they just group all the definitions in one repo, is that what you are doing? again thank you so much üôè.
Not a single test.. How could one contribute to this project, if it goes open source, without the fear of adding regression?
You don't just stop knowing Node because you learn Go. And learning go will set you up to quickly pick up other statically typed languages like C or Java. It will be good for you.
Looking ahead I would suggest you add Go, continue w/Node and add an ND language like Prolog. Then you will be exposed to a good range of expressions. My work has always been in multi-language environments. I call myself a plumber. Everyone needs a plumber! For bonus points I would seriously look into R.
Interesting. I wonder if I've shot myself by using the builder pattern. The struct the builder creates is named the same as the interface, however, it's un-exported. I was thinking, okay, just change the name. However, doing that causes compiler errors: impossible type assertion: models.IssueSummaryStruct does not implement models.IssueSummary (BugRejections method has pointer receiver) Thanks for the Suggestion!
You are discussing building in a container. Use a multi-stage container build. Deleting things in a container doesn't quite work the way you think it does. https://docs.docker.com/develop/develop-images/multistage-build/#use-multi-stage-builds
&gt; I also think that developing an application starting with Docker is a bad idea We‚Äôll have to agree to disagree. üëçüèª
Oh wow I didn‚Äôt know that was a thing. I‚Äôm fairly new to Docker. Thanks!
Far worse to be a one-trick pony. To a large extent, coding is coding. New languages teach you new paradigms, and that makes you better at the languages you already know. 
True. The ability to learn one of the core skills required in tech. The principles of sound software development still apply regardless of language. So, developing those is key.
Fair enough. There's nothing wrong with learning for learning's sake or having platform specific optimizations as implementation details underneath an abstraction layer like a game engine. That said as a linux gamer who lived through the Microsoft/DirectX era, watching Apple pull the exact same vendor lock-in crap with Metal triggers me a little bit. What Apple is doing now is arguably even worse, because they are actually deprecating the old open standard. That's further than Microsoft ever went in some ways. I'd like to think that we, as an industry, have learned enough from history to reject vendor lock in whenever we can. I don't mean to say that this is a bad article, or that it won't be useful to people who are interested in learning and using metal for good reasons. I'm just sad that it provides free good PR for Metal. Apple's behavior here is NOT OK, and IMO, the programmer community should discourage that behavior by ignoring Metal as much as possible.
Great additions. I think a lot of people miss what you said about the built in error interface. I also agree with your points about log.logger. Interface composition (or as you call it progressive interface definitions) are beautiful. I probably should have pointed out `io.WriteCloser` an example. 
That is the gist. I write predominantly in python and go. But am learning rust and node. I find there are good cases for the different languages and the work I do is better off for learning more then 1 language. 
Word. There are a couple pure go [dtls](https://github.com/maufl/dtls) [impls](https://github.com/bocajim/dtls) out there, but not sure about their quality.
I think that you might eventually find that learning languages is the easy part, and that the stuff you're learning in school for CS is the hard stuff, especially Javascript, which is a rather elegant language.
Your mistake, I think, is in returning an interface in the first place. Accept interfaces, return structs. If you are defining the interface that your struct satisfies *next to* your struct, you're probably doing something wrong. If you're returning the interface, you're **definitely** doing something wrong.
That depends on the position. Are you being hired as a Javascript front-end developer with two years of experience? Or are you being hired because you're going to be a good technical fit and are expected to do a lot of different things over the years with your company? People doing the hiring, especially recruiters, rarely understand the requirements listed for any position. You'll find your resume gets rejected just because it doesn't match some arbitrary search criteria, even for jobs you could easily do. Don't lie on your resume, but feel free to tailor it for the position to get into an interview with a person. If the employer's position is asking for a specific language or library, emphasize that in your resume for that application. Again, recruiters don't actually know the languages: it's the technical interviewers you have to impress.
# well for the 3rd question: it's better to store the token in redis/memcache cause the session token has an expire date, so it's more of volatile data. as for the other question i m also curious how devs handle the refresh token.
`hash.Hash` -- particular the `Sum` method, which appends to its argument instead of allocating a result. Makes it really easy to eliminate allocations, but you can also pass `nil` if you don't care. `bufio.Scanner` demonstrates a non-standard error handling pattern that lets you avoid polluting your scanning logic with error handling. `bytes.Buffer` and `bytes.Reader` offer clear and convenient ways to convert between `[]byte` and `io.Reader`/`io.Writer`. I use them all the time. the `(bytes.Buffer).Next` method is especially nice for iterating through data in chunks. I actually don't like `filepath.Walk` very much because you can't pause and resume the iteration. For example, I have a program that walks a directory structure and accumulates files, processing them in batches once a batch grows large enough. If I could pause and resume iteration, the batch processing code would be pretty straightforward. But because `filepath.Walk` takes a function that only operates on a single file at a time, you need to pull some closure shenanigans to make this work. I ended up writing passing a shim function that just passes each file down a channel, but this has its own issues (specifically, if you want to exit early, you need to drain the channel in order for `filepath.Walk` to return).
Just a thought...we have been moving our application from node.js to golang. It's been great! golang is extremely capable and scalable. However, I agree with most here; just add it your repertoire of languages. It looks good on resume, and will even help with learning other programming/scripting languages. Go for it!
Dude, no problem. Feel free to DM if you have any other questions. Yup, we group them in a single repo. I have a friend who‚Äôs team started off by copying proto definitions but are now moving to a single repo because updating one file could mean updating 5 or 6 other projects. Just a single data point though. I‚Äôm sure others have found other methods that work well for their team. 
I'm not sure what you mean by session token. There's not really a compelling reason to use sessions anymore when you can use a jwt if you're referring to traditional sessions. That lets you securely transfer state, and the jwt itself contains information about its expiration without having to store session data anywhere server side. It obviously depends how sensitive your data is, but I think tokens lasting for an hour is pretty common, saving you at least 1 database call per request, and oftentimes multiple calls. [https://jwt.io/introduction/](https://jwt.io/introduction/)
The first is probably better. As a rule, avoid the empty interface unless you have no other option.
I see your point about `filepath.Walk`, however I still feel it is a good example to draw from. 
Thanks @peterbourgon. Initially I thought of the type switching idea based on this section from Effective Go: https://golang.org/doc/effective_go.html#type_switch Also, do you think there are any inherent performance differences? 
1. Not refreshed on every request, daily should be fine unless theres big money involved (bank or shop). 2. It's generated through login or auth middleware. 3. There is no need to store it in the server, just [store the date in the token](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-20#section-4.1.4), to avoid storing it, then check if it's expired through a middleware. To draw a picture, here is what I do in a personal project: 1. User logins -&gt; gets a token with expiration date + hash(ip+user agent). 2. Token is stored in localStorage (client's browser). 3. On the next request it's sent to the server through the auth header. 4. Then it's checked by the auth middleware through the following condition: hash stored in jwt equals to hash(ip+user agent) with data from the request, which determines if the token is valid or not, or expired. - When expired: if the hash(ip+user agent) equals the jwt's hash(ip+user agent) then adds a new token into a header and continues to the request. - When invalid: returns error requiring the user to re-authenticate. - When valid: gets data from it and inserts into the context (like the user's id)... then continues to the request. 
Also wanted to say I'm a big fan of your posts and material!
Hi. I direct technology at a financial services company, including managing and hiring my own staff. I would almost certainly turn away an exclusively Node.js developer, even if I needed them for Node.js work today. Through the course of your studies, you will learn about hardware architecture, and how software really works with hardware. That‚Äôs the foundational knowledge you can‚Äôt find in bootcamps, and that knowledge is truly required for a real systems engineer. You won‚Äôt learn much about threading models and concurrency‚Äîwhich is fundamental for architecting fast and reliable systems‚Äîwith node, ruby, python, etc. You cannot be a ‚Äúfull stack engineer‚Äù only writing in interpreted languages, no matter what someone tells you. Go is the new hot language. You don‚Äôt need Go to be attractive as a developer, but if you can learn Go, your employer knows you can learn and handle anything. Go discover everything that interests you in tech outside your course work, that will distinguish you and that‚Äôs what will help you the most in interviews. Either way you will almost certainly learn lessons Go would teach you obtaining your degree. Good lucj
I can affirm you should not worry about this. Learning about other languages tends to strengthen your knowledge of programming overall, and makes you look at the languages you do know intimately already with new eyes. It also opens you up to seeing the shortcomings in the patterns and ideas you're used to, because every programming language ever was created to fix a real problem the author had with another language (or class of languages).
What's the hash(ip + user agent) for? I mean, the signature is enough for checking validity and the hash isn't unique at all (lots of users in some office will share the same public IP address and user agent).
Hey. I am a professional nodejs developer. I am full stack with a heavy penchant for the backend. I love nodejs, and I think that in what it does well no other language gets close. That being said my secondary language is Go. I don't get the opportunity to use it at work as much as I would like, but it's important to know other languages that are so radically different, static vs dynamic, multi threaded vs single, pointers, mutexes, interfaces... the list goes on. I doubt i will ever get as proficient at Go as I am in nodejs but I maintain myself as decent. Point being, it's good to be more than just a one trick pony. Nodejs and Go complement each other very well. It doesn't have to be a "switch" to golang. If you have any questions feel free to ask. 
It limits the possible impact of the token getting stolen and then used by someone outside the office, for instance. Personally, I don't think JWTs are a good strategy for auth. A random session token should be generated for each logged in device and stored in the database. If the user wants to log out all of their devices, you can't do that with JWTs.
As danredux says, your design seems odd. However if you want to get past your compiler error then you have to cast to a \*models.IssueSummaryStruct, since that is the type it seems you are wrapping in the interface in the first place. 
 Usually good practice to generate a new session token if the user has just logged in or out. (Essentially any change in privilege) I take it a stage further, in that generate a new session id if any server side session state changes. Good reading: https://www.owasp.org/index.php/Session_Management_Cheat_Sheet#Session_ID_Generation_and_Verification:_Permissive_and_Strict_Session_Management 
I know very little go. Goland is incredibly helpful. 
Your const example should be written using a traditional switch. It works the same as your example, but because you're testing the same value in each block it's much more succinct this way. You also need to be using the constants you declared here, otherwise what's the point? switch op { case A: fmt.Println("A") case B: fmt.Println("B") case C: fmt.Println("C") default: fmt.Println("wrong!") } Using a type switch like you suggest, where the type is a signifier of an enumeration, doesn't really make any sense. Type switches are used when you care about the value of something but the something can take on multiple types. Here's a good example of how type switches are used: https://github.com/streadway/amqp/blob/master/channel.go#L274 You have a function that takes a generic interface type `message` that can take on a number of different concrete types, and depending on which type it is you take different paths each of which does something useful with the value. If you don't have a value then it doesn't make sense to use a type switch.
Alternatively, there are a few compelling reasons/things that are very easy when you use stateful tokens. And of course, your stateful tokens can _still_ be a JWT underneath. 1. tracking what sessions currently exist (think of how github shows you all your current active sessions) 2. sessions stored in some kind of datastore are damn easy to revoke Additionally, you don't neccessarily have to make an independent query for sessions on every request `WHERE user_id = (SELECT user_id FROM sessions WHERE api_key = $1` does the trick just fine, generally.
I'm a node js dev through and through. I'm picking up golang and probably will make the full transition to golang when I can. For these reasons. 1. The market - More and more companies that are worth their salt are moving to golang becuase of the performance reasons. And the golang jobs are higher paid 2. Speed - Golang is simply quicker and does what node js does but better. Higher max IO, faster arithamtic faster general opperation 3. Evolution: php was king, got overthrown by node, now its seems like the advent of Golang. Its exibiting the signs of a new paradigm shift. Its does what node did to php. Golang is simple, quick and with the advent of microservices more compaies can port partial components of their apps to golang so adoption is going up.
Yeah, I was too young to be a part of the PHP community when it was big. By the time I began working in development when I was 13 (Around 2013ish) Node.js was a major player and many of the people I talked to online were node developers. However, like you said, I‚Äôve begun to see a lot more people switching to Go, and a lot more of the major frameworks seem to be written in it nowadays.
I was too young as well. But this is what i can gather by talking to people and reading. If we are talking about marketability more and more companies want engineers that understand infrastructure and architeching apps at scale. You shoudl learn about containerisation, microservices, scale and AWS. This is going to be my next move. Getting AWS certified and learning indepth about scale.
&gt; Worth switching from ___ from node Yes. The answer to that question is almost always yes.
Thanks @gxti, excellent points. Your const switch is very clear. For the struct field type switch, I should have written the example using Case nil, Case int, Case string, and Case rune as those are the actual types being switched on, not the field names A, B, and C. However, switching on the struct field types allows for overlap and potential errors on repeated types within a struct (two int fields, etc). Ideally a data structure field name identifier like DataStructure.(name), similar to the existing DataStructure.(type), would be useful for doing switches on field names, but I do not believe that is currently possible without using the reflect package to do a switch based on the string representation of the struct's field's name, as opposed to the struct's field's types.
Pros and cons to both methods. It's similarly easy to store active jwts when they are generated if you need to know about them, and if you are that worried about revoking privileges, you can also set the token refresh to be 5 minutes or whatever length you're ok with.
There's insanely broad. Go is in many respects a wonderful language, and it's tools are probably even better. However there is a place for node's exceptions, (at least kind of) parameterized types / generics with typescript, dynamic objects when you want them, sharing code across server and front end. I could keep going My primary language is neither of those two, btw
What's an ND language? If we're going the declarative route instead is procedural / imperative would you really put Prolog before Haskell, F#, a lisp, or some functional language? 
Learn many languages, platforms, APIs, and practices. That‚Äôs the only way to become a truly well rounded developer.
Make them pointers in the struct, test for not nil in a switch
I started in C++, then did python for a few years in web development. The language was a breath of fresh air after C. I don't know how it compares to node.js, but I much prefer python to javascript just because of the syntax. Programming wise they both do a lot for you I guess. Go I started learning last year...both because I saw it having a future, and I was getting a bit frustrated by python's slowness / lack of easy threading. It's cool as shit what you can do with concurrency and channels. I'm still trying to get my head around interfaces, but the simple syntax (what I loved about python), and the fast compile make it almost as good as python from that perspective. The only thing I miss is actually having an interpreter when you just want to figure shit out on the fly. It feels very much like a hybrid between C and Python. 
Non-deterministic. It's coming up in OP's survey class, right? So OP will have a leg up on the introduction to the surrounding concepts. Additionally I bet the class will mention parallel approaches during that segment. Might as well go with the flow for the semester. Functional languages are fine too, but I would put breadth in at this point.
Your last paragraph, about filepath, intrigues me. I can understand the problem you were faced with, but both the closure solution and channel solution don't seem optimal. Technically, the best solution I can see would be a `BatchedFiles` struct with an `Add` method. Initialize and pass it in to filepath.Walk, and it can handle all the batching semantics. Example here: https://play.golang.org/p/ike4ZlnKIC6
Writing an Interpreter in Go is the most important go book to date. 
So `encoding/json` sets a bad example? As it could use something like... type JSONValue struct { *string *float64 *bool *map[string]JSONValue *[]JSONValue }
&gt; let‚Äôs be honest nobody hires entry level explicitly Entry level, as in off the street with zero skills, sure. But entry level, as in first job out of school, those folks can get jobs all day long. The demand is that strong.
You might overestimate the importance of a certain language/framework. Don't take this as an offense but you seem to be 10 to 15 years away from being a professional. In this time you will not only learn new languages, new frameworks, new ways of connecting machines, new algorithms and new tools but also learn how to organize teams, plan large scale work, manage money, cope with being scream at and threatened by some psychopath with MBA and learn how to talk to marketing people (even more challenging for me than psychologists). Of course organizations like to hire "Node developer with React experience" to quickly replace a vacancy in a project. Especially as this type of vacancy filler is much cheaper than some grey-beard who costs twice as much but needs 6 weeks longer to be productive (because he needs to learn React). Most probably you do not want to stay a Node/React vacancy filler the next 40 years. Especially as the actual vacancies in 15 years will be for Foobar/Wuz. So yes: Learn new stuff. As much as you can. Learn bash and std tools like awk, sed, grep,... first, it is the main glue: Available everywhere, convenient and well understood by (well, almost) everyone. Learn Go. Learn R (at least a bit), learn Python. Discover function land, whether through F#, Haskel or even Lisp. Learn Rust. Learn enough Lisp to configure your Emacs. Learn vim. Learn relational databases and SQL. Learn everything. 
&gt;I have used probably 20-30 languages over the last 22 years. I am a "Jack Of All Trades" and have no problem getting jobs. The thing is, I know how to program, and I know how different paradigms work. I don't think I can name twenty programming languages, in the last 18 years I have programmed in ~6. I think learning two or three languages* is near the sweet spot of not spreading yourself too thin and broadening your horizons. \* Different languages, if you know typescript, don't count javascript 
If you have multiple types in your package satisfying a common interface and a function can return any it is fine returning an interface (not necessarily good design though). If you know however you will return a concrete type (exported or unexported) return it directly but document the interface it implements (especially if unexported). In general it is better to let the user define interfaces so that they are implementation independent.
Take a look at [API Foundations](https://leanpub.com/api-foundations) and the [free sample](https://leanpub.com/api-foundations/read_sample). I especially target people that are coming with pre-existing knowledge from PHP and Node.js environments, explaining some new, Go-specific things. It should be a good start for anyone :)
`encoding/json` is obviously fine.
First, I could also add "me too" to this subthread. Even though I did have reasonable Go background when came for the interview for my $dayjob, it had not much to do with so-called high-load, and here we do exactly this, and more. Now I would add a couple more pieces of insight. * Go is considerably more "close to the metal" than Node. And that's one of the chief reasons to pick it for critical projects: you have more predictable behaviour and it's actually possible to dig performance problems right down to the OS and H/W, which is hardly possible with None (ATM at least). What this means for you, is that when we interview potential hires, 80 to 90% of the questions are about OS and H/W level, rather about algorythms (well, of course, we ask what that "big-Oh" is and why binary search is faster than linear and stuff like that). We ask exactly zero questions about Go syntax or standard packages. But we, say, ask the candidate to explain the entire dataflow involved in, say, `curl` performing an HTTP POST request to a web server and that receiving it‚Äîthe more details the person delivers, the better. The reason is simple: when we hit some performance problem, we need to be able to actually track it down, and that means knowing how stuff works *under and around* your code. This means being familiar with HTTP and TCP/IP‚Äîon the transport/network level, and with some details of how operating systems work and how hardware works. JFTR, [here](https://www.reddit.com/r/golang/comments/8d2w5j/what_is_considered_senior_level_in_go/dxk5lnf/) is a Reddit thread which might be of interest to you. * *Go has different approach to concurrency* than Node, and this is a thing which is not to be underestimated. A good overview of this stuff is given [here](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/). What this means for you, a programmer, is that Go lets you write *sequential* code‚Äîas opposed to the callback-style code of Node (it doesn't really matter whether one hides callbacks behind "futures" or "promises"‚Äîthey are still callbacks). While I'm not going to discuss which model is better (I think Go's but that's beside the point‚Äîof course, the Node's model works, too), the fact is, learning Go will allow you to make yourself familiar with *a different perspective on concurrency,* and in my book, the more perspectives you have for a given aspect of the field you work at, the better. To recap, it's not the multitude of languages you know which by itself makes you a better programmer, it's the fact *they approach the same problems in different ways,* which makes you one. To reiterate on the key points of my advice: * Learn *different* languages to see how they use different approaches to solve the same problems. This widens your world-view greatly. * Know *the environment* in which your code works; without this, you will only be a coder (not to say "code monkey"), not a programmer. If you'll not work toward equipping yourself with a knowledge of how the whole stack works, you'll latch yourself in the state of being a typist for typing in API handlers, which, I presume, it far removed from being fascinating. ;-) 
Use the right tool whenever you can. I'm working with node &amp; golang at the moment. Some parts are made in node. It is great for streaming io, fast prototyping, as a backend for rich UI apps. Some parts are made in Go. Golang shines when you need to do heavy computing, process a lot of data, scale over multiple CPUs and so on. I'm using golang for counting millions of events and generating heavy reports. I would say I'm pretty happy. So again use the right tool, build modular backend (micro services and stuff) and you would be ok. You are even not limited to these two if you bould apps this way. I'm looking now at Julia and Elixir for some upcoming microservices. I love my Zoo!
&gt; I miss is actually having an interpreter when you just want to figure shit out on the fly. I routinely use https://play.golang.org for such gigs.
Please, the language is called Go. "golang" is a token implemented by a popular Internet search engine to alleviate looking for Go-related material. As they say, you do not call C "clang" and Java "javalang", right? Sorry for the nitpicking, hope you'll understand.
That's cool, but does it work with non standard libraries?
I would also look at the responsibilities of the thing itself. _Any_ function which has lots of parameters should be a call to think about it's responsibilities; is it doing too much? 
Unfortunately, it doesn't. It also has quirks which make it impossible to test out complex scenarious involving `time`, and the network access is undestandably stubbed out.
One technique is to use a sliding window to refresh the token. You refresh the time if you are within some time limit that is close to its expiration. 
I think it's just the case where you have to weigh the intent of the 12FA guideline, and don't follow it to the word. The intent is, don't use local storage to produce logs. The path of least resistance for a PaaS that is sort of agnostic as to what you're running there, is to pipe the stdout stream through some logging facility like funnel, but it's far from best practice when you actually deal with a very narrow stack in comparison with a anything-goes PaaS like Heroku. With Go, you have options: - [stdlib log/syslog](https://golang.org/pkg/log/syslog/) for local or remote syslogs, - you can use cloud syslog providers like [papertrail](https://papertrailapp.com/) with stdlib package, or even with a sideload/piped app (docker), - there are destination aware loggers like [apex/log](https://github.com/apex/log) which are great - you can still pass your stuff to stdout if you like, but take frequency into account (less is better). People really write introspection APIs to filter out volume. Some of these options handle logging output better than what 12FA imagined as the guideline. The big thing to take into account however, is the volume of your log output. Things like tracing logs may be *very very verbose*, which means that you definitely don't want to treat them as event streams, don't send them to stdout, but use a dedicated backing service (12FA chapter 4). In fact, one could even argue that HTTP access logs could be a special case which shouldn't go to stdout either, at least I know that tailing access logs from my load balancers is pretty much useless without some sort of map/reduce aggregator on top of that.
package main import ( "encoding/json" "fmt" "io/ioutil" "net/http" "os" ) type poloniexData struct { GlobalTradeID string \`json:"globalTradeID"\` TradeID string \`json:"tradeID"\` Date string \`json:"date"\` Types string \`json:"type"\` Rate string \`json:"rate"\` Amount string \`json:"amount"\` Total string \`json:"total"\` } func main() { // Build the request url := "https://poloniex.com/public?command=returnTradeHistory&amp;currencyPair=BTC\_NXT&amp;start=1410158341&amp;end=1410499372" res, err := http.Get(url) if err != nil { panic(err.Error()) } body, err := ioutil.ReadAll(res.Body) if err != nil { panic(err.Error()) } // fmt.Println(string(body)) var data poloniexData json.Unmarshal(body, &amp;data) fmt.Printf("Results: &amp;#37;v\\n", data.Rate) os.Exit(0) } 
I am using this code
I prefer \`Chi\` since i figured out that Gin doesn't support root routing. It's really stupid while you can't use \`domain/article-slug-id\` because you already had \`domain/admin\` Chi supports regular expression in routing. Its a must have feature.
Think about it this way. Your trade is programming. Not programming in a specific language.
The Practice of Programming has aged really well. Programming Pearls vol 2 
in this case your trigger the refresh event from the client? because the server wouldn't have a way of knowing this right?
Of course it did, it was about people not tech 
Unless you‚Äôre needing some of the functionality with go, I wouldn‚Äôt say it‚Äôs ‚Äúworth switching‚Äù but it‚Äôs definitely worth learning. I never needed Go until recently when I decided the project I‚Äôm working on is a good opportunity for me to try it out, and frankly I think it was a good move. Go can easily handle turning my 7 year old laptop into a mini web server with very little CPU usage. That was my intention. That was my reason for using Go, along with the whole building thing and networking stuff. It‚Äôs always worth learning another language, even if it‚Äôs just the introduction. Once you can learn to be versatile and you can show you can catch on to new things quickly then you‚Äôll be more valuable as a possible employee. Also. It‚Äôs worth at least trying out, because who knows...you may just fall in love with Go. On that note, just gonna throw this out there. I usually try languages out by taking a small project, or a small component of a project, and building it in the language I‚Äôm trying so I can compare the experience and result side by side. 
Actually from the server. If the client doesn‚Äôt communicate with the server quickly enough, it gets logged out at the intended time. 
What is the response you get?
Damn, that's really neat! Can't wait!
This is fucking insane. All these optimizations dropping for go1.11. 
That's great! Go continues to be super stable (compare Rust, Python, JavaScript, C++) but improves on tooling and performance. I'm curious how much these optimizations slow down the compiler, if any? I remember something about Go only adding optimizations if the amount they increased the speed of the binary meant that compilation speed was sped up too (but don't have a source for that right now, and doubt it's generally true).
I guess one could do compilation benchmarks (1.10 vs 1.11) on a relatively large project like Docker or Kubernetes...
Hi! I'm the author of [gortc](https://github.com/gortc) project which is also an ongoing implementation of WebRTC (and tools for it, like STUN/TURN servers and clients). Very excited about your implementation, but I'm quite confused with why [my stun implementation](https://github.com/gortc/stun) not being used. I've started it quite a long time ago and it was already available on pion start. I've taken a look at your [https://github.com/pions/pkg/tree/master/stun](https://github.com/pions/pkg/tree/master/stun) implementation and some code parts look suddenly familiar to me. For example: [Screenshot_from_2018-06-22_17-03-56.png](https://postimg.cc/image/7qh1z6uaj/) From my point of view it does not look like a coincidence :/ You can just add me to "AUTHORS" if you pick any code from my project, I don't mind.
I wouldn‚Äôt mind if compilation slowed down if the binary generated sped up. 
Try sending `Accept: application/json` header field in your request.
That's great! I'm curious how much these optimizations slow down the compiler, if any? I remember something about Go only adding optimizations if the amount they increased the speed of the binary meant that compilation speed was sped up too (but don't have a source for that right now, and doubt it's generally true). 
I like the fast compilation times in Go though, it allows us to test rapidly without the need to wait on a build
Did you just copy-paste a portion of u/benhoyt's comment?
nothing. its blank. if i print the body. it shows the html page
tried
The HTTP response status would be helpful. it could be that you are hitting a 4xx response and the web server is serving a default page back to you.
Languages and syntax aren't that important to being a good developer. Problem solving, efficient solutions and the ability to adapt are what makes you a good developer and all of those are language agnostic. 
Those are some nice improvements!
yes it's 403
I‚Äôm curious to see what performance gains those optimizations would get on large go apps.
lazily grabbing a quote from a stack overflow post: &gt; Receiving a 403 response is the server telling you, ‚ÄúI‚Äôm sorry. I know who you are‚ÄìI believe who you say you are‚Äìbut you just don‚Äôt have permission to access this resource. Maybe if you ask the system administrator nicely, you‚Äôll get permission. But please don‚Äôt bother me again until your predicament changes.‚Äù original post: https://stackoverflow.com/questions/3297048/403-forbidden-vs-401-unauthorized-http-responses#6937030
It looks like most of those would yield little to none compilation time increase. In any event, the compiler itself would be benefited from those optimization potentially offsetting the added compilation work.
[https://poloniex.com/public?command=returnTradeHistory&amp;currencyPair=BTC\_DCR&amp;start=1514764800&amp;end=1514851200](https://poloniex.com/public?command=returnTradeHistory&amp;currencyPair=BTC_DCR&amp;start=1514764800&amp;end=1514851200) i am using this url for the same, seems like I am missing out on something surely. i am
"should start" ... ha! Some of us have been doing that for more than twenty years using [tooling](https://cr.yp.to/daemontools.html) that encouraged it.
@danredux, thanks for pointing out the \`encoding/json\` example. I noticed that the first example from \[\`encoding/json\`\]([https://golang.org/src/encoding/json/example\_marshaling\_test.go](https://golang.org/src/encoding/json/example_marshaling_test.go)) called "Example CustomMarshallJSON" seems to use a switch based on consts: type Animal int const ( Unknown Animal = iota Gopher Zebra ) func (a \*Animal) UnmarshalJSON(b \[\]byte) error { var s string if err := json.Unmarshal(b, &amp;s); err != nil { return err } switch strings.ToLower(s) { default: \*a = Unknown case "gopher": \*a = Gopher case "zebra": \*a = Zebra } return nil } In terms of where the field name gets stored in a data structure, the \`encoding/json/decode.go\` file seems to use a few different methods for storing it: 1. The \[\`decodeState\` struct\]([https://golang.org/src/encoding/json/decode.go?s=4062:4110#L2](https://golang.org/src/encoding/json/decode.go?s=4062:4110#L87)69) seems to be capturing the field name as a piece of the struct. 2. The \[deprecated \`UnmarshallFieldError\` struct\]([https://golang.org/src/encoding/json/decode.go?s=4062:4110#L140](https://golang.org/src/encoding/json/decode.go?s=4062:4110#L140)) seemed to use reflect to capture and store the field name. 3. The \[\`UnmarshalTypeError\` struct\]([https://golang.org/src/encoding/json/decode.go?s=4062:4110#L123](https://golang.org/src/encoding/json/decode.go?s=4062:4110#L123)) stores the name of the struct field in a struct field of type string. Also, the following three functions from the \`encoding/json/decode.go\` file all seem to use type switching: 1. \[\`func (d \*decodeState) valueQuoted() interface{}\`\]([https://golang.org/src/encoding/json/decode.go?s=4062:4110#L417](https://golang.org/src/encoding/json/decode.go?s=4062:4110#L417)) 2. \[\` func (d \*decodeState) addErrorContext(err error) error\`\]([https://golang.org/src/encoding/json/decode.go?s=4062:4110#L311](https://golang.org/src/encoding/json/decode.go?s=4062:4110#L311)) 3. \[\`func (d \*decodeState) object(v reflect.Value)\`\] ([https://golang.org/src/encoding/json/decode.go?s=4062:4110#L619](https://golang.org/src/encoding/json/decode.go?s=4062:4110#L619))
Here is my solution: [https://gist.github.com/yubing24/f836ac55325ada76feba37bd5d1ebc54](https://gist.github.com/yubing24/f836ac55325ada76feba37bd5d1ebc54) When you try to get data from a web services like this, you need to pay attention to the response. First of all, the returned json data is an array, which should be translate to slices (instead of a single struct). Secondly, the type of your struct should match the type of the Json data, such as using `int` instead of `string` for globalTradeID.
Quick note: You don't need to set GOROOT anymore. Just compile using the tip binary and it figures everything out.
Yes well I would have to use the access keys! Thnks
I wouldn't consider it as a "switch". Instead of saying you switch to Go from Node.js, we can say "I know Node.js. Now I learn Go to boarden my skills".
&gt;ote: You don't need to set GOROOT anymore. Thanks!
On the item _Iteration Variables and Closures in "for" Statements_, the last code block makes use of `data := []*string{"one","two","three"}`, which eliminates the gotcha. He leaves the solution to the reader... But I have no idea why using a slice of pointers work differently than a slice of non-pointers.
Echo or Gin doesnt support root matching, it means you can't use `domain/article-id` along with `domain/admin` It makes URL longer and not good for SEO.
Such a great work has been done on this version. Can't wait to use it.
I honestly don't know why you'd do anything BUT write to stdout. With stdout it's trivial to redirect output into a file or some other permanent store. It also works by default when containerized. Writing to a file you pretty much just get the file and everything else is more difficult. 
I get it now. It its explained on the first part of this [blog post from 2013](https://www.ardanlabs.com/blog/2013/09/iterating-over-slices-in-go.html)
Thanks for documenting your findings Brian, it's great to be able to follow along. I can really relate to your excitement and enthusiasm. :) It's exactly how I felt about GopherJS and what it has allowed me to do over the years, without having to write JavaScript. It's just very a empowering and pleasant feeling.
Dup of https://www.reddit.com/r/golang/comments/8t0pjd/performance_patches_in_go_111/.
Don‚Äôt forget that compile times are significantly faster than most languages (like orders of magnitude not just 2x or 3x). This is due to some design decisions about how they build dependencies. Watch Rob Pike‚Äôs original launch presentation and he talks about this a lot. I could certainly see the core developers taking the stance that if an optimization forced a short circuiting of this design it wouldn‚Äôt be implemented. 
I'm working on a Go+WASM web framework atm, and posts like this get me really excited to continue experimenting!
share share share!
It would be cool to add a compiler flag letting you do builds that skip a lot of compiler optimizations.
Wow! I am especially excited about the ARM improvements. Go was a bit slow on it due to lacking optimization. Great job!! 
If Go becomes faster the compiler does as well (because self-hosted). But you are right the speedup does not compensate the additional computations. The Go-Team however is very cautions about compile time and to slow optimisation get rejected.
The Go compiler uses BigInt for constants, so any speedups to BigInt will speed up compilation in general. 
I wrote a small bot several years ago using go-ircevent. Works fine. 
I've written a [few](https://github.com/jamiemansfield/CommitBot) IRC bots using Golang, and I'm yet to find a library as complete as those I've used with other languages (e.g. [kicl](https://kitteh.org/irc-client-library/)). I've often considered writing a library myself, though I would need to do a lot of research on the IRC protocol beyond the little I know (I've written toy client libraries before, with Dlang).
Consts are set at compile time not run-time. What you are effectively trying to do is set a const by the result of a function which is a run-time operation. You could achieve the same thing by doing simple concatenation. package main import ( "fmt" ) const my_name = "Sick" const my_full_name = my_name + " Spider" func main() { fmt.Println(my_full_name) } 
Hi, Yup, that makes sense... :/ Always.. so simple. Thank you very much !
What's your usecase of using Go for arm?
Is it possible that we can specify an initial stack size for new goroutine to be created? Which would be more efficient than auto-increased stack.
Thanks for that yeah. After some more research, it turns out that you should use stdout for output you expect to be piped and transformed. That isn't the case for diagnostic output like logging, which is why it goes to stderr, ready for archival.
chat bot for whatever chat service you use regularly.
Can anyone find any info on the database that he works on? &gt;Now I work on the fastest time series DB - VictoriaMetrics. It is written in Go 
I recently got back into Golang having not used it in a little while - wrote a Little Man Computer emulator to get back into the style if procedural programming and back used to the syntax.
I can wait until we can full stack go!!! I said this the last time but we need a go port of Vuejs ASAP.
I'm super excited about the prospect of writing font ends in go, but IMO vdoms are old news and [html template](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/template) based approaches like [lit-html](https://github.com/Polymer/lit-html) and [hyperHTML](https://github.com/WebReflection/hyperHTML) are much more promising. Are there any go projects working this angle?
[removed]
Personally I was running a webserver on a raspberry-PI. And with ARM servers also becoming more popular and the new Cortex-A76 cores ARM is reclaiming some popularity in general.
I use golang on a distributed arm server. Each node has has about 80 arm cores and go routines allow it to scale evenly so we get the most use out of the server.
I've written a bunch of IRC bots in Go. I never used a library for it though. The IRC client protocol is simple enough to implement yourself. The only potential downside a Go bot might have, is iterating through development of 'plugins'. Writing a plugin requires frequent rebuilding. Since Go is statically linked, I prefer compiling the 'plugins' directly into the bot binary. For an IRC bot, the main concern with this approach, is that you have to disconnect the bot and reconnect it, every time you rebuild a plugin. This creates a lot of part/join noise on whatever network the bot is active. However, I found a good solution to this problem in my bots, by having the bot fork itself in response to a SIGUSR1 or SIGUSR2 signal, while passing along the open network connection to the child process. This allows binary upgrades with zero downtime.
op did want something challenging. also, i tend to learn more if i can't just copy or use an existing library. also, not really sure how much programming experience the op has even if s/he is new to go.
ARM is great for cheap, low-power servers
We've used https://github.com/sorcix/irc for a number of years very reliably. It's a very thin wrapper of the protocol in very idiomatic Go. You have to have a working understanding of the protocol to make use of it - but honestly IRC protocol is really simple and easy to understand.
How do these affect binary size? Eg. Custom algorithm for 14% of primes costs some code size in the final binary.
That‚Äôs a really interesting prediction to state that 1/3 of web dev will be in backend languages. For me, I think the most exciting part of WASM is the prospect of creating a new language or competing languages that address the needs of writing application in modern browsers. I‚Äôm not sure repurposing system level languages to be used in browser makes the most sense. I‚Äôm looking forward to seeing where the industry goes in the next few years!
i think a tcp chat server/client is a fantastic use of Go. You wouldn't have to get into the specifics of any service's api or protocol, and there's plenty of things to use channels for.
Exactly
You can disable them all by passing `-N` flag to `compile` from the [go cmd](https://golang.org/cmd/go/) like so: `go build -gcflags="all=-N"` 
VDOM has been replaced by lit-html
Yeah, can't find any info on that either.
Not looked into it, but I've heard good things about: https://www.keycloak.org/ (this proxy also seems to be a project which offers integration: https://github.com/gambol99/keycloak-proxy)
Is there a hosted sample for demonstration somewhere?
Go doesn't really have the features for something like vuejs. Specifically, there isn't a language feature to watch a field for changes. A react-like setstate function is way more golike.
Have you considered AWS Cognito?
&gt; Test files that declare a package with the suffix "_test" will be compiled as a separate package, and then linked and run with the main test binary. ‚Äì https://golang.org/cmd/go/#hdr-Test_packages
Oh hell. This question. Okay. This is a good question to ask. It's like a iceberg though. Looks small on the surface, but 80% is under the surface. You need to dive in to see it. Here's this. Read this. Then implement your security and read it again. If you've made any of the mistakes outlined in there, fix them. Do your best to commit it to memory. https://www.owasp.org/images/1/19/OTGv4.pdf Security is hard. An attacker really just need one single mistake to gain full control of your server. But the fact that you're asking this question puts you a step ahead of most people. Some of the topics covered in that guide are about as clear as mud. If you have any questions on it, or if you want an extra set of eyes on your security, feel free to PM me. I used to do security audits for a living, now it's just a hobby of mine.
I will! üòÄüòÄ
I probably should have outlined that I have done some work with java/spring/oauth in the area. I was looking more for the right way (or most common way) golang developers secure their rest APIs with oauth2... if there is a ready made well tested library often used by golang API developers to secure their APIs. For example in Java, with Spring/Oauth, it has a fairly easy/robust framework out of the box (or with a few dependencies) and some minor configuration to secure your API with oauth2 where by you can "plug in" how you decode incoming requests.. e.g. username/password, etc and generate a token that goes back to the consumer making the request. It then ensures that all APIs can not be accessed without a token.. and more so that you can lock down specific API resources with a token based on roles/groups/permissions. I was hoping there was something that is pretty solid, tested and not too difficult to work with in Go by now. That link you pasted has a lot of info, but my initial look through didnt seem to indicate an oauth2 (or other security) library to use for golang.
&gt;This creates a lot of part/join noise on whatever network the bot is active use a smart filter which hides them unless appropriate and this is a non issue
Uhm, thanks for sharing those libraries! lit-html actually looks great.
JSON Web Tokens are probably your best option. https://jwt.io https://github.com/dgrijalva/jwt-go
It creates the noise for everyone else in the channels. You can't control their clients.
Hey ernado! I am really sorry about that, I am not the author of the code [original commit](https://github.com/pions/turn/commit/907e04c90691b506fc2e454971175463bb07cb7c) but I will fix this! At the time I was working on the [signaler](github.com/pions/signaler) I was planning on building something else, but the people who I was working with didn't follow through. I agree it looks the same. I will add you to the AUTHORS file, I am really sorry about that. Personally I am doing this to learn/get better so I like reading the RFC and reverse engineering stuff. If you look at my work in pions/turn and pions/webrtc you will see a lot of guesswork/debugging. Also I am afraid to use libraries because then I depend on others. If I have a bugfix/change I have to discuss it with others, and sometimes in Open Source people aren't receptive/what I want is different from what they want. If are ever interested in working together email (on getting native WebRTC for Go or anything else) me sean@siobud.com I don't check reddit very often, but respond to email right away!
I‚Äôve been playing around with a VueJS like frontend framework that uses wasm instead of JavaScript. Still experimenting with the templating engine on the server. But it‚Äôs coming along slowly. But this post helps so much in my research. Thanks for that. I haven‚Äôt begun to look at the client side yet. And also finding lit-html through here was excellent too. WASM will hopefully make a huge dent in JS. But either way I‚Äôm hopeful that finally we can walk away from Full Stack JS. 
https://gophercises.com/ has a bunch.
Did you try proposing these features to godoc.org? It's an open project: https://github.com/golang/gddo
Have you checked Auth0 for GO? https://github.com/auth0-community/go-auth0 I've been using for some applications and it's pretty good and easy to use. You just need to know about OAuth 2 (it seems you already know it) and just config your apps + apis in order to allow or not the access in their platform and then config your api to allow or not the user depending on the roles, scopes, etc.. you define 
There are different ways that you can manage authentication and authorization in Go and for that matter using any language. I would like to show you my approach which has been working great for me so far: a. Casbin policies are used to protect certain routes based on the route/role which is supposed to access/http method. b. Casbin config (I have used pretty much the model from official website ACL model, check the official website for more details) c. Middleware (This is the most important part which connects your casbin permissions with http method,route coming from request as well as role (coming from jwt Authorization header from the client). I just added the files in the following gist. Its just to give you an idea but I extracted it from a larger project so it may not compile :). But thats is pretty much it. Let me know if you need any more info, or if you cant manage it to work I will try to push a sample project as a repo on Github. Code: [secure restful api using casbin go source code](https://gist.github.com/erkidhoxholli/b8fddbb8699a4f39c2fbb80c3e675d0b) 
Thanks for submitting. I'm the author of the blog post. Please let me know if you have any questions or feedback, happy to answer them :) 
Well, they are something, but not anything about security. They are just a signed data tuple without any means to invalidate them easily. There is no difference if you capture a JWT or some kind a session key. The only difference is that its one way to do something that implements a specific RFC. Is JWT the best way to represent an auth token towards an REST api? For me its not. It exposes information, it is a huge payload, it offers no additional security and requires me to implement additional layers, like device IDs, into it to come up with the same functionality that normal server side sessions offer.
try joining ##linux or similar large channels having a bot joining once a week will not have any impact on the "join spam" whatsoever
It doesn't look like there's a standard oath2 server library available from the golang devs themselves. However, this one looks secure and stable: https://github.com/go-oauth2/oauth2/blob/master/README.md I've personally never used it, but I looked through it a bit. It should work well enough.
Couldn't you set up user inputs on channels and then handle changes via a select statement? 
Do note that if you don't supply a type it will be an untyped constant.
Pretty sure they're resistant to making changes. IIRC they weren't even willing to decouple it from appengine a few years ago.
Everything you point out is true and sensible, though to be fair the OP calls the language "Go" and the community itself "Golang", which seems reasonable considering that, well, that's what it says on the masthead and the reddit address. Still, your point seems worthy of being made every so often to keep the name from degenerating. "Go" does convey simplicity, but sadly is hard to track. I really like the name Clojure because its unique spelling can't be confused in search engines, leading to clearer statistics and search results. (I also wish Clojure transpiled to Go, though that's another topic.)
Nitpick: ``` s/buf := bytes.NewBuffer([]byte{})/buf := new(bytes.Buffer)/ ``` 
Being stateless is a big advantage for some applications.
good catch!
That's actually a very nice approach, definitely be using that when I update Mana.
So many tutorials show gorilla/mux..would be nice to see some using go-chi, gin etc
I agree. I‚Äôm a big fan of Gin myself
If you like that, you should also check out and [polymer 3](https://www.polymer-project.org/3.0/docs/about_30). You don't have to use polymer3 to use lit-html and visa versa, but they were designed to complement each other.
Yeah but its not JWT is not what provides the stateless-ness, it's always the backend implementation. You can develop simple stateless authentication with any kind of identifier. I'm personally just not a fan of having and exposing this identifier in human readable form on the client side, even if it is signed by HMAC SHA256. I see the need and the benefit of RFC 7519 in inter-company-communication when it comes to industrial API access and trusts, but not on a front where we have browsers. It's just not complete and uncontrollable. Every half-way-secure web frontend application sports some kind of device, logged-in-session or API key managment, something that JWT does not solve. The simplest JWT token might only contain the account ID and yet it becomes un-invalidatable. If you want to introduce this concept you have to go the extra mile, as with any other tech, except JWT exposes the internal identifiers and you can simply copy them like any other tech.
[See also](https://www.reddit.com/r/golang/comments/8hn828/tired_of_clumsy_online_tools_json_prettyprinter/).
[See also](https://www.reddit.com/r/golang/comments/8t85s1/fxlike_commandline_json_processing_tool_an/).
I had to read too many rfcs in the past days so i wont use this in the forseeable future but the idea is really nice :) 
&gt; https://blog.golang.org/gopherchina It's good that you come up with some examples but no Qiniu is not a big website. When we talk about big website, we means handling +200 req/sec. The blog states that GO is used widely in China as 3rd party. Again I don't see any source stating that a big website is using Go lang for backend services.
u/andrewxhill I really liked your articles! When I first starting using the Go implementations of IPFS and libp2p, I was really confused, and subsequently annoyed, by gx because it wasn‚Äôt following the easy-to-use paradigms of go‚Äôs existing package import system. Your articles provide some great insight on the advantages of distributed source code and how gx makes it a little easier for developers to start working and being productive in this frontier. Thanks for challenging my centralized way of thinking :)
:DD Thanks very much. :)) I find that reading and implementing RFCs is a great way to learn programming and about how things work that hold together the internet and the world. Like, I learned a lot about C++ and AES encryption while implementing the TOTP RFC here: [TOTP CLI](https://github.com/Skarlso/totp-generator). Good stuff. :)
VictoriaMetrics is in development and isn't published yet. I'm planning to open source a single-node solution when it will be ready for production use. Cluster solution will be provided as SaaS. Initially it will support [remote storage API for Prometheus](https://prometheus.io/docs/prometheus/latest/storage/#remote-storage-integrations), later more sophisticated solutions will be built on top of the core engine.
Only by changing `_StackMin` const at [runtime/stack.go](https://github.com/golang/go/blob/be36bd996eb120741ed866396e607fcd5e0b702a/src/runtime/stack.go) and re-compiling Go runtine :) 2Kb stack is enough for certain use cases such as highly loaded web(socket) server serving more than 100K concurrent connections. Bigger initial stack will result in memory waste for these use cases.
I feel the principle of Go for each specific detail implementation is to satisfy 99% needs. However, there are the situations that which only need a very small stack or will grow and shrink the stack frequently under the current implementation. Such situations are not common. But if Go runtime can provide an API like `runtime.CurrrentGoroutine().SetNextGoroutineInitialStackSize(int)`, then it would be great for the 1% situations. A code example: ``` runtime.CurrrentGoroutine().SetNextGoroutineInitialStackSize(1 &lt;&lt; 20) go f() ``` 
Yeah to me it seems that you aren't supposed to have a 1:1 alternative but rather an idiomatic way of doing it with Go. Callbacks? Setup up a goroutine waiting on the channel output. Done. Channels and goroutines solve most of everything you have in other languages and with a concise manner of doing so that's understood by anyone familiar with Go. A main point made about Go off the bat is another language simply translated to Go isn't going to be more effective necessarily. Do the it the Go way. Make use of the powerful mechanisms delivered in this language rather than immitating others. 
+200... Umm that's like a few goroutines..lol joking. It's always a few! Get it? Anyways here's a company suggesting 10,000 per second "concurrently". https://qarea.com/blog/8-reasons-you-need-to-go-golang And here are some more from China. https://github.com/golang/go/wiki/GoUsers#china Alibaba uses it as well for devops. 
What API has a captcha? It's not an API, if it has a captcha. 
Just found out micro as well. https://twitter.com/chuhnk/status/1009753282598854656?s=19 https://github.com/micro/micro/blob/master/README.md
Exactly. JWT is not an answer as long as you don't know the threat model or usage of the API you're creating. Is it a service for looking at memes? Probably ok. Does it involve any PII where you may need to revoke access asap? JWT is no good as to implement the revocation you'll likely need a synchronised db backend anyway, at which point JWT gives you nothing.
Auth0 is a third-party service isn't it? Isn't it better for OP to learn how to do it correctly themselves before deciding to use this?
Yes it's a 3rd party service, but he said that he knows the use of OAuth2, just wanting to know how work with it, so I posted the service from a trusted company like Auth0 (creators of JWT), but maybe could be better to create service from scratch implementing the OAuth2 and then decide if it's enough and can be maintained for him or switch to 3rd party service 
Just as a side note on docker and go: You can use the golang image to build your static binary and just copy it over in a multistage into a much smaller container image using the scratch image base.
[removed]
can you emphasis on &gt; Writing an Interpreter in Go is the most important go book to date I just bought it based off of your comment after a quick look and it looks interesting, but what makes it better than something like 'The Go Programming Language' ?
Thank you so much!
It's already doing that. :-) called a multi stage build. :-)
The Go Programming Language is a great reference. Writing an Interpreter in Go is a very practical book that teaches you more than just loose syntax. You build something significant and you learn much more than just the language as a byproduct. 
oooo sweet, it arrives later today 
So the Go binary produces static files that are served by nginx? Super interesting, but why not let Go serve the requests and produce the HTML then, is there a reason? Also, your "store" interface is in the wrong place. You should define `Store` where it's used, not where it's implemented.
Gin is much more heavyweight than just using gorilla mux, since it also has logging and what not "built-in". While I've used Gin myself several times, it is important to know that these packages are not equal in terms of dependency weight. 
You are right about the store. Thanks. So, this is a basic semi static site. Nginx is perfect for serving it. I was starting out with go serving it but to be honest it's not needed at all. And with nginx I have caching and HA. Also I'm setting up php fpm as being socket activated so this consumes so minimal amount of resources as possible. That's why I choose to opt out of having a Go service and routing to it with nginx to serve on port 80.
Sure, but what I'm saying is that an idiomatic go front end framework would look much more like react than it would look like vue. So asking for a go port of vue is weird. It makes more to say that we just want a good go SPA library/framework.
The router doesn't really matter, as long as handlers are compatible with http.handlerfunc
I know that much, but giving others some exposure would be (refreshingly) nice :P
Configuring Go to handle internet traffic without a proxy is nontrivial: https://blog.cloudflare.com/exposing-go-on-the-internet/
So maybe httprouter? 
ElastiCache would prob be the go to on AWS
I‚Äôve just written a couple of production sites using http.ServeMux from stdlib, and it was quite refreshing. It‚Äôs a solid router, with very little magic - and my code was much clearer / more maintainable than other go web apps I‚Äôve written. I‚Äôm still going to choose an appropriate router for an app in the future, but I think everyone should use the standard library for routing at least once.
&gt; https://qarea.com/blog/8-reasons-you-need-to-go-golang This websites shows google, facebook etc.. using Go lang for microservices and not for backend services. My questions was "what big websites use Go lang for handling the web network server ?". Alibaba &amp; Baidu indeed use Java and Python we all know that, but devops made in Go doesn't make a significance. 
SSL termination in nginx is more than sufficient. There is no need at all to implement HTTPS in a Go server.
This certainly proposes the kind of abstraction that programmers fight with, more than benefit from. I recommend you try writing a simple Todo app, accessible from HTTP and CLI, that can save to disk or to a third party site. This is basically the minimal realistic emulation of a real production golang service that your ideas are aimed at. I predict you will find your abstraction to be quite difficult to use, in practice. However, if they turn out to be very elegant and helpful, then you will have a good showcase and proof of your idea.
I am not really following the WASM stuff that seems to be gearing up, but is WASM Javascript? (or somehow using JS?) 
Maybe check out API gateway solutions like Kong. The idea is your authentication is handled at the gateway layer, that way you're not reimplementing auth in upstream services.
Except for all the Docker stuff, this is how Caddy started. Then I wrote a `for` loop that "compiled" middleware from a `[]func(http.Handler) http.Handler` value. [It still basically does this today, and is some of Caddy's oldest code.](https://sourcegraph.com/github.com/mholt/caddy@e2635666730e24bfbc2408811be089502338cbc4/-/blob/caddyhttp/httpserver/server.go#L147-150). (The outer loop builds the middleware stack for each site on that listener, or 'group' of sites.) Then it was time for handlers to return errors, so that error handling could be more easily coordinated among dynamic middleware stacks. So [I modified the http.Handler interface to return `(int, error)` values](https://sourcegraph.com/github.com/mholt/caddy@e2635666730e24bfbc2408811be089502338cbc4/-/blob/caddyhttp/httpserver/middleware.go#L60:1). A simple change, but by far one of the most profound effects on Caddy: it became easily extensible, and with a simple convention, balances correctness and usability. Building it all from the ground-up with the Go standard library was a lot of fun.
I'm quite busy so I only really have a casual glance at things in the morning while waking up before working. I had a quick glance through the readme and a couple of files, but that's it. I really recommend having some examples, to help busy people quickly understand "at a glance" what it's about, before deciding to jump further in. If you do this, feel free to DM me and I'll take another look.
Thank you both for honor me by reading it. Actually I made this as a side project while I was working on my friends website that will be present, but due to that my daughter is so little and I want to spend as much time with her as possible, I wanted to create something for my friend that requires the least necessary energy to pick it up and continue work on it. I found that if components require minimal effort to load the necessary mind model than it's a lot easier to me to to create small task that I can do in one sitting. But now that you helped me realize that I also lack publicly available example, or a poc repository, today I will create one based on my friends project while my daughter sleeps. And again, thank you so much! :)
I run a bouncer and connect my bots through that, so the bot doesn't generate any join/quit spam.
Looks very powerful but why checking errors through globals (func)?
The specific point of a Captcha is to prevent this. It's a bad sign if what you want to do requires you to do this - it means what you are doing it is likely illegal.
Really like the versioning idea. With vgo it will definitely become necessary.
As it is chaining methods, so an Error method is used to catch the last error. BTW I'm also trying to get a better idea/suggestion for the error handling. Thank you very much for checking the package :)
I like the strategy of having a Query function which returns a query for chaining but then having to call Do() when you‚Äôre done chaining queries which results in (res, err). It might not be the best example because they use a context but https://godoc.org/github.com/olivere/elastic uses this strategy to allow things like ‚Äòdb.Search().Query(q).From(1).Size(100).Do()‚Äô
I have thought about the idea, but I'm not sure about this. At this point we can add a `Do` method which will wrap the result and error. Okay lets try to add the Do method (Y)
I like go-chi examples...
Cool. At first I thought this was based on JSONPath but I guess that‚Äôs not the case? 
This is a great series man. Kudos!
Thanks! It's the warm comments that keep me going with it :) 
I think this is awesome but I do have concerns about performance. Have you done any performance/stress testing on concurrent hits and different JSON types and sizes to find where the limits are?
An excellent read - https://hacks.mozilla.org/2017/02/a-cartoon-intro-to-webassembly/.
Author here. This is very much a not-yet-working work in progress!
I've done a basic [benchmarking](https://github.com/thedevsaddam/gojsonq/wiki/Benchmark), the performance will depend on the size ofJSON document. It basically Copy the `Unmarshalled` JSON data to the new object when we do some concurrent operation. But we should try more performance testing. Thanks for the question :) 
Yes, it's not based on JSONPath 
Go N00b here! Can you please explain the difference? TIA!
Ah I see, jq implements error. So that is actually a decent compromise.
So set a TTL for the user in redis store. Then you send back a cookie with the uuid token and the key for the user in redis. When another request comes in, parse the cookie and look up the value in redis. 
Yes, basically there are two methods `Error/Errors`. It's look like something [GORM](http://gorm.io/docs/error_handling.html), though it exports `Error` property to access last error. But we can think something more suitable for error handling for this package.
A solution would be to use a jwt token and sign it instead of using a uuidv4 token. You can store data inside the jwt token that a user would be able to read but not change (because they cannot sign it). Therefore it is safe to store his id, and maybe his permissions inside the token. Then on request you just check the tokens' signature to verify you made the token, and then read its contents to decide what the user is allowed to do. 
I use gorilla securecookies and use a middleware to check for the user id cookie on every request. It is encrypted so can't be faked and using a middleware makes it easier so you don't have to write code on every function that should be secured. http://www.gorillatoolkit.org/pkg/securecookie
They are doing mostly the same thing (initializing a buffer of bytes) except the original way was a bit convoluted: creating an empty slice of bytes that's being used as an initial buffer for the final buffer. The alternative I suggested is just creating the zero value of a 'bytes.Buffer' on the heap (ie: with 'new'). So... Less work (for the compiler and probably also at runtime) and less typing. For the same semantics. And slightly more idiomatic Go code.
https://stackoverflow.com/questions/46312734/golang-import-path-best-practice Create a vanity import URL if you want to be independent of Github v. Gitlab v. whatever. 
As mentioned by others, you just need signed cookies (use Gorilla, don't use JWT unless you have a need for it). While I was reading this question, I kind of wondered about replay attacks. I guess the protection here is TLS so no one can steal the cookie. For the request password on sensitive pages I think it makes sense to only request the password if you have been logged in for a while, or were logged in via a method that's less secure. What's the point in logging in with a password, go to settings and have to enter the password immediately again? I use the concept of half-auth, so when the get "remember me'd" they enter a state of half-auth and anything that requires full auth should redirect them to the login page if half-auth is in their session. Also consider not having to deal with *some* of these problems by using something like (disclaimer: am author) https://github.com/volatiletech/authboss/tree/v2
&gt; Go runs on all desktop platforms and also runs server side (Linux). I LOL'd.
I think one of the worst parts of Go is that it tries to force this directory structure on you. I believe that part of the `vgo` changes will fix this problem. I have my own way of organizing my projects and it predates Go. I checkout everything into my projects directory (`git clone` not `go get`), then I create a symlink from `~/go/src/github.com/&lt;them&gt;/&lt;project&gt;` to my checkout. Running `go` commands in a container where you bind mount the directory to `/go/src/...` is another option. &gt; What happens if the author (even if it's yourself) moves the project from github to some other host `sed` or if the project adds canonical import comments (https://golang.org/doc/go1.4#canonicalimports) you can use https://godoc.org/golang.org/x/tools/cmd/fiximports
Out of curiosity, why avoid using jwt? I use it everywhere.
Anyone know of a good "`reflect` under-the-hood internals and compilation implications" sort of article? Ie. does the compiler create metadata for all types/fields in the binary (always, or only on `import "reflect"`? for all types/fields or only chosen ones?), do the types all implement some hidden internal interface when `reflect` is active, etc.. It is always said that `reflect` means slowness-overhead, but OTOH (overhead often back in the day when Go was young and this was often compared) faster than say JVMs/.NETs/some-other-bytecode-VMs reflection. I'm wondering how much extra codegen (if any) is involved by the compiler when "magic pkg `reflect` is imported", and if so, what would make it slower than the many handrolled codegen use-cases people do implement on the daily to expressly "avoid reflect and interfaces" (let's generously assume they did benchmark and do it for the hot paths to not derail here ;)
1. when you are working on your "fork" (which is really a temporary "fork" to work on your pr, not really a "fork" in its traditional meaning), you shouldn't clone it from your fork. instead, you should clone the upstream version, then add your fork as an additional git remote (`git remote add ...`). this way you won't break the import path. 2. for your concern that the upstream might disappear/move, vendoring is the way to go. 
It solves few problems over server sessions and introduces a few itself. Invalidation of a jwt is a common theme around dissenter opinion. It's spec also allows for insecure configurations so you have to be careful to understand the crypto primitives that you use via the libraries that implement it since most of them allow the full gamut of insecure crypto options. In return for these problems we don't get much over a signed cookie, they're almost the same thing anyway, just the server has more control over the latter and it shows up in a different spot in the http headers. It's just my opinion in the end. There's no crippling reasons why it should be avoided. It can be used correctly for a given purpose just like server sessions. I'd probably even favor it in more distributed architectures to avoid running a redis cluster (though it's so damned useful you'll probably have one anyway!)
Out of curiosity, why use a CC0 license when Creative Commons does not recommend it for software?
Basically, the package comes from a PHP package [jsonq](https://github.com/nahid/jsonq) , which used the license https://github.com/nahid/jsonq/blob/master/LICENSE. BTW I'll change the license to MIT
&gt;Out of curiosity, why avoid using jwt? I use it everywhere. As Thomas H. Ptacek put it, a lack of misuse resistance and a kitchen sink design: [https://news.ycombinator.com/item?id=14292223](https://news.ycombinator.com/item?id=14292223) For most use cases, TLS + bearer token will be sufficient.
&gt; It's spec also allows for insecure configurations so you have to be careful to understand the crypto primitives that you use via the libraries that implement it since most of them allow the full gamut of insecure crypto options. That seems to be the case with most things crypto. Its possible for the developer to completely break the security provided by particular technologies, if they implement the tech without understanding how it works and why it's useful. I absolutely see your point, though. And there are very few real-world problems to solve where the extra hassle is offset by the benefits provided. Definitely gives me something to think about. 
Awesome, thanks! Yeah, definitely had some stutter-starts with GX myself. Really happy the post was useful.
Interesting timing. I was just thinking yesterday that I would kind of like a package for this.
Do you go through all the dependencies and manually clone them too? Must take ages
Great package!!, it would also be nice if it followed a "builder" pattern where instead of having to check the error using a global function call it is done when the method is called on the "builder", i.e.: jqValues, err := gojsonq.New().File("./valid-file.xson"). From("items"). WhereNotNil("id") checkErr(err) res, err := jqValues.Only("id", "price") checkErr(err) 
There is no one size fits all. Do you want your users to be handling connections? This depends on who your users are and what they are trying to do. 
No, why would I need to do that? Almost every project either includes dependencies under `vendor` and/or includes a dependency management config (`Gopkg.toml`, `vendor.conf`, `glide.yaml`, etc). If the dependencies aren't already under `vendor` I just run the dependency management tool and it downloads them all pretty quickly. If a project doesn't do either of those things I would run `dep init` to get the dependencies and contribute the `Gopkg.toml`.
It's good that you've figured out a reliable and mostly automated system. I suppose my question becomes why? What is it about the standard package directory you don't like?
We need a pure Go package for zstandard, if you still want to write a useful compression package. :)
Everything. I don't see any advantage to putting every package in the same gopath and having them know about each other. It seems like an artifact of how google manages code that doesn't make any sense outside of that organization. If the project is going to be used by anyone else you will most likely need to use vendor, and with the addition of vendor the global gopath is basically unnecessary. Thankfully `vgo` should remove it. What advantage is there to putting everything into a single gopath? 
https://godoc.org/golang.org/x/oauth2
Firebase auth does it for free. 
You're basically asking how to serialize and unserialize objects, or more precisely, where that behavior belongs. There's one important question: do you want to be able to handle *any* type, or do you want to handle only specific types that have opted-in to serializability? Another question you need to ask is: when deserializing, will you know the destination type or not? JSON is an example of a typeless serialization, because to recreate it's value, you need to know the type it was derived from. However, you can include a "type" key and use that to determine what type to deserialize into. In other words - what is the problem you're trying to solve? Storing and retrieving a value is an age-old, and solved, problem - you just need to choose one that fits your requirements. Do you need to encode the type information into the format? Do you need it to be backwards-compatible and versioned? Do you need to include the schema itself in the format? Do you want to handle any type, or just specific types? Do you need to encode length, or can the format itself have a natural terminator, like `}` in JSON? Almost any codec would work, but some will need more or less custom handling to get what you want, so answer these questions first. Finally, generally, the types won't need to define their own mechanism for encode/decode, as reflection allows a marshaller/unmarshaller to work with types generically. The JSON/Text methods are dynamically checked for, as an emergency hatch for customizing the encoding, they are not required.
That's a client library
It says `after a while a much smaller file will appear`, but we all know that's not true for the overwhelming majority of hypothetical files, for any encryption. Yes, this comment is half joking, but also it's worth providing educative links about compression when offering a compression library and app.
I once tried to import a library that was using a vanity url. It was broken. Because the location you get it from, the file structure, and the the namespace are all tied together as an import path, that meant I had to manually change every import path in every single file to fix the issue. It also meant that I was forced to commit my modification and make sure that I comply to their license because I could no longer just add it to my dep management and forget about it. It's terrible. You can't even just start a project and assume that it works because it compile. Commit, delete everything locally, try to go get your own project to see if that works. If not, fix it. ugh...
The consensus across the Go community is to use the [net/http](https://golang.org/pkg/net/http/). The standard library already offers a good set of features that you can leverage and extend by yourself. Some times. The most common approach is to include specialized packages as middleware to provide cache, routes, authentication, etc and avoid convoluted frameworks from early development. If you search the same question on the Internet and/or ask professional Go developers, you will get, most of the time, a similar answer.
Any particular motivation to avoid TLS? It's reasonable to avoid x.509 and the WebPKi, but at least DH key exchange would add forward secrecy.
`M-x web-mode-set-engine RET go RET` For an automatic approach, see `Associate an engine` in http://web-mode.org/
The way of handling error will be better in next major version
Without having looked into your code: In general, if all the types that implement the interface are known to the Call function, it can use a [type switch](https://tour.golang.org/methods/16) to reveal the actual type behind the interface parameter.
They may have had reasons for not decoupling the code from appengine. This does not necessarily mean they are not open for other changes. I would suggest giving it a try. 
The only two things I've found `net/http` lacking in: - Restricting a route to one HTTP method / using different handlers for each method instead of a single handler per route + dispatching to other handlers on the method. - Automatically parsing the request body into an appropriate struct. Those two things end up causing a lot of boilerplate, and can be solved with really simple APIs. That being said: I'd still rather use `net/http`. Its just the lesser of two evils.
https://github.com/go-chi/chi looks good. 
[buffalo](http://gobuffalo.io/) is pretty good for short projects. 
Like this? ‚Äî https://stackoverflow.com/a/13131806
Thanks for the quick response! Actually I have tried that, unfortunately I‚Äôm not sure I‚Äôm missing something or else the gzip is complaining it has an unexpected EOF encountered when trying to uncompress it... Can view the page normally in browser though. I suspect if the site was trying to send content in chunks.
The HTTP client from Go's `net/http` handles chunked encoding just fine all by itself (unless, of course, if something has gone awry on the server side).
Does querying a resource from that server *without* using `colly` works OK?
&gt; However if I accept gzip for content response the http client underneath would not help me to handle the uncompress stuff automatically(By net/http client design IIRC). It's a bit more complicated: the HTTP protocol has *two* places where compression may be used: * The "transport" layer‚Äîthe sender and the receiver may agree on compressing the message being sent all by themselves. In this case, the compression and decompression happen completely transparently to the client. In this case, the `Transfer-Encoding` HTTP header field is used. * The message layer‚Äîthere, the client of the HTTP stack itself ("the application") may ask the server that it wants compression. It communicates this fact using the `Accept-Encoding` HTTP header field, and the server, if agreed, indicates the encoding in the `Content-Encoding` HTTP header field. In this case, the message compression is explicit to the client ("the app"), and has to be dealt with explicitly. But note that `net/http` client-side code goes rather creative with `gzip`: ~$ go doc http.Transport.DisableCompression type Transport struct { // DisableCompression, if true, prevents the Transport from // requesting compression with an "Accept-Encoding: gzip" // request header when the Request contains no existing // Accept-Encoding value. If the Transport requests gzip on // its own and gets a gzipped response, it's transparently // decoded in the Response.Body. However, if the user // explicitly requested gzip it is not automatically // uncompressed. DisableCompression bool This means, by default client requests will ask the server for gzipping of its responses automatically and will decompress them automatically as well. As you can see by running `go doc http.DefaultTransport`, in the default transport object the `DisableCompression` is left at its zero value, `false`. See also: * https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Transfer-Encoding * https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept-Encoding
Chi is really great. Small, good performance, and fully compatible with http.Handler. What's not to love?
I‚Äôm not very sure what colly uses in the transport when initializing the http client(well the doc it says it is using the default settings), I‚Äôll try again when I have access to my PC later today when I can use net/http to access the website without colly. Thanks for the info.
This will not build tensorflow, it will just build the bindings and the linker will look for tensorflow to link against. You probably need to specify additional linker/compiler flags adding -Ldir/where/tensorflow/dll_or_archive_file_is. You might need to add that as #cgo directive in a file as I am not sure you can specify this on the go command line so that it would pass it the mingw 
Why the hell is this marked NSFW?
My bad. Sorry!
Is there any accessible sample somewhere?
[https://gokit.io/](https://gokit.io/) A toolkit for microservices
Requests p/minute is an unusual measurement, most would consider requests p/second to be the more standard benchmark 
That's a good point. I ain't got the foggiest about this. Thanks for your comment!
Depends, services like New Relic or DataDog show requests in req/min
It could depends on what you're going to achieve then (I guess) 
Regex routing (eg parsing an ID which is variable from a path) can be a little annoying at times with net/http's servemux. Not impossible just not simple. 
That's most likely because they don't have the infrastructure to support metrics at lower than 1 minute resolution. Time series is hard, I know, been there done that. 
Since you asked, my pet peeve is that with `Route` and `Group` there's a lot of potential for user error, due to variable scoping. It's typical to use `mux` or `r` as the router variable, and it's relatively easy to reference the wrong one (ie. pass `r` to inner func, but use `mux` in the func). I do consider this to be a bit of an API issue. Comparatively, gorilla/mux: ~~~ r := mux.NewRouter() s := r.PathPrefix("/products").Subrouter() // "/products/" s.HandleFunc("/", ProductsHandler) // "/products/{key}/" s.HandleFunc("/{key}/", ProductHandler) // "/products/{key}/details" s.HandleFunc("/{key}/details", ProductDetailsHandler) ~~~ I can't say that I love their API, but it does avoid the possible scoping issue. That being said, I do prefer the readability of the chi API's in this case. It's absolutely valuable to distinguish what Route and Group are meant for, especially Group. You don't get this visibility with gorilla/mux. p.s. if some of you don't know about group/route go-chi functions, I wrote two articles on the subject: [Handling HTTP requests with go-chi](https://scene-si.org/2018/03/12/handling-http-requests-with-go-chi/) - Route, [Protecting API access with JWT](https://scene-si.org/2018/05/08/protecting-api-access-with-jwt/) - Group.
ioutil#ReadAll might be a bad idea
With `vgo` you can use the `replace` directive to use your fork instead of the original. But i believe this issue will be solved with proxy servers https://research.swtch.com/vgo-module
You can put a JWT into the Bearer header. I've seen so many API's that do that, and go-chi supports it [in their jwtauth package](https://github.com/go-chi/jwtauth). As the end client might be a browser, the malicious attacker has the full capacity to inspect request headers, even with TLS. The points are: - use database checks to perform second-step validation of the JWT - use database checks to perform invalidation of JWTs - use whatever message signature is most secure currently so you limit request forgery As long as people are aware of this, the JWT can be used as a bloom filter. You will never pass invalid JWTs to the back-end, and if some JWTs are forged or invalidated, you should check for that in your back-end service. A reasonably short expire time also helps with validation/invalidation of tokens, if you want to be reasonably sure that your requests are valid, don't set a 30 day TTL :).
&gt;ReadAll What's the restrict? What can I use instead?
ReadAll would load the entire buffer into memory.. So depending on the size of the request body (or file), it might be the right solution 
This one is tricky because a beginner might think this is what he needs for his small project if he wants web scale...
You can use ‚ÄòJSON.NewDecoder.Decode‚Äô instead I am not mobile, cannot format it properly 
Less fancy, more capable [alternative](https://github.com/cznic/plot/blob/6ffec16ad76e7e546c1be36786bf7b9ef195354a/all_test.go#L273).
Gotcha! Thanks!
And that will be slower than using something like chi, because they don't use regular expressions, they use a radix tree I believe - like some other routers.
cool üëç
But it depends on having gnuplot installed which is a major downside.
Does it plot data in real time? As in can I stream data to it continuously and have it refresh in real time? Can't really check ATM, on my phone. Will definitely take a closer look when I get on my computer.
It would be cool if there was a standalone binary for this as well so you can just pipe the data in for simple graphs.
Yes. That's the price for the zillion features gnuplot has.
Just tried with the vanilla http client, everything works out OK. Maybe it's colly to blame?
Quite possibly. May be it's time to reach for that project's issue tracker. 
currently it don't, but that'd be a really cool feature :)
Please also use these resources before devling further: * [Blake Mizerany - Three fallacies of dependencies](https://www.youtube.com/watch?v=yi5A3cK1LNA) (from dotGo 2014). * [How to not use an http-router in go](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html).
Does this allow you to have an x axis with names? I'm looking for a way too make an xy graph
It's looking for the library to link against, drop the dll into your ...\msys64\mingw64\lib folder.
I might be missing something but I don't understand the use of the above library. The http server spawns a new goroutine for each http request, what does creating an additional worker pool accomplish here? 
Currently for x-axis you give caption.
great idea üëç
My favorite part is that your example can have the output (sine wave) in the comments: https://github.com/guptarohit/asciigraph/blob/master/examples/SineCurve.go
No, so far I've only run it on my desktop for development.
No, I've only run it on my desktop so far.
I'm glad you liked it :)
[removed]
Security is a kinda a messy thing to talk about, so to be clear‚ÄîI'm approaching this is good faith! &gt; As the end client might be a browser, the malicious attacker has the full capacity to inspect request headers, even with TLS. I'm _not_ really convinced that this should be the responsibility of a service owner‚Äîif a customer's machine is compromised, they've already got _far_ larger problems. Inspection of request headers is the least of the customer's worries. My employer (to the best of my knowledge, is no slouch when it comes to security) doesn't try to build for that use case! &gt; The points are: &gt; * use database checks to perform second-step validation of the JWT &gt; * use database checks to perform invalidation of JWTs &gt; * use whatever message signature is most secure currently so you limit request forgery Nothing stops you from doing similar checks with a bearer token pulled via `cat /dev/urandom | head -c 30 | base64`! Like, you don't _need_ JWT to express TTLs and token invalidation. My issue with JWT is that it exposes too much surface area to mess up. Security standards and tools should guide the user to do the right thing by default.
There is effectively no situation in real world programming where the speed of a request router will have any effect on latency. Please kill this pernicious myth.
"‚ïÆ" is not ASCII.
"‚ïÆ" is not ASCII. Did you just assume my code page?
Currently it doesn't* I'm not trying to be an ass. I noticed that you are from New Delhi and assumed English is not your first language. I figured a small correction could help you out in the future :). Also, awesome library! I'll check it out a bit more later this afternoon
your listener should have code something like: ln, err := net.Listen("tcp", ":8080") if err != nil { // handle error } for { conn, err := ln.Accept() if err != nil { // handle error } go handleConnection(conn) }
As others I recommend you giving [net/http](https://golang.org/pkg/net/http/) a shot first before diving into other frameworks. It should be sufficient for small to medium projects. Let's look at github-stars: 1. [gin-gonic/gin](https://github.com/gin-gonic/gin) 18.2k 2. [mholt/caddy](https://github.com/mholt/caddy) 17.6k (I actually haven't heard of it) 3. [astaxie/beego](https://github.com/astaxie/beego) 15.8k ( 4. [labstack/echo](https://github.com/labstack/echo) 10.8k 5. [kataras/iris](https://github.com/kataras/iris) 10.7k 6. [go-martini/martini](https://github.com/go-martini/martini) 10.2k 7. [revel/revel](https://github.com/revel/revel) 10k All of them are production ready. Depending on your use-case there are several more specific servers maybe you are just looking for a more advanced router. But as you question is very general you get a general answer.
so if my nodes send a Message of type: type Message struct { nodeName string // Some other information } Where one node, called X would send: Message{ nodeName: "X", // Other crap, } The server in the Accept Handle loop: for { conn, err := ln.Accept() if err != nil { // handle error } go handleConnection(conn) } then add to that for loop something to map the receipt of the name as a key to the conn instance for each connection. My loop looks like (obscured a little bit): for { if someCondition == true { break } conn, err := ln.Accept() if err != nil { // Handle Error } go func() { Handle(conn, someConditionChannel) }() select { case &lt;-someConditionChannel: someCondition = true } } Would I just change that to having the handle function pass some node name through a channel to the loop such that when receiving the first message ping from the node the name is passed, and then I can use a map (of course using a mutex since they're not thread safe since conceivably there'd be a writer and multiple readers at once) along the lines of connectionMap := make(map[string]net.conn) // such that a map entry for "X" would be initialized in the for loop as: connectionMap[&lt;-SendTheNodeName] = conn Sorry again if I'm just an idiot! I'm fairly new to golang (only having written a couple thousand standard issue lines).
May I ask, why `config` is a map? func Plot(series []float64, config map[string]interface{}) string Why not take a proper struct? Looking at the code this should do the job: type Config struct { Width, Height int Offset int Caption string }
All these answers to use net/http is why I love go so much. Python could've been just as great if the community had the will
 package main import ( "net" "sync" ) type node struct { Name string conn *nodeConn } type nodeConn struct { net.Conn } type HelloMessage struct { Name string } func (this *nodeConn) ReadMessage() interface{} { } func (this node) Handle() { for { // do something with the conn } } type nodeStore struct { m map[string]*node sync.Mutex } var store = &amp;nodeStore{ m: make(map[string]*node), } func (this *nodeStore) handle(conn net.Conn) { nc := nodeConn{conn} hello, ok := nc.ReadMessage().(HelloMessage) if !ok { // log failure return } this.Lock() defer this.Unlock() n := &amp;node{Name: hello.Name, conn: &amp;nc} store.m[hello.Name] = n go n.Handle() } func main() { ln, err := net.Listen("tcp", ":8080") if err != nil { // handle error } for { conn, err := ln.Accept() if err != nil { // handle error } go store.handle(conn) } } 
I like gin-gonic or plain old net/http
That's good stuff, here's a few additional tips from my years of writing this sort of thing: * Femaref already showed this correctly, but I want to emphasize how the connection tracking needs to be concurrency-safe. * You'll probably want a pinging functionality built in to the connections, to be sure they're alive. TCP guarantees that the bytestream will be delivered in order or not at all, but the TCP-level guarantees about time outs are virtually useless and you'll need to implement something more useful yourself. You can combine some sort of mandatory ping with deadlines to ensure a reasonable cleanup of dead connections. It is really easy for connections to go dead, and it seems for security reasons we're getting more of them all the time on networks that don't want to send packet types that reveal the existence of open ports or whatever. * You'll also need to ensure that you are ready for receiving a new connection from a node that you thought was already connected. Make sure that you don't just overwrite the old connection, but actually _tear down_ the old connection first; at a minimum, closing the socket, and as necessary, cleaning up any messages that were going to go to that socket or whatever. * If you ever find yourself tempted to write code where the message can be sent on one TCP socket, but if the socket gets lost, the message can be received on a later socket, you don't want a TCP connection. You want a message bus. There are many good ones now; zeromq, various cloud offerings, all kinds of things. Honestly you may want one anyhow.
Sure, you'd probably have to be handling thousands of requests per second to get to save maybe a few milliseconds overall from switching from something like Gorilla Mux and Chi; but when something like Chi actually has a great API, has all of the features you'd need, and is (albeit practically negligibly) faster, why even bother spending the time writing something yourself that's probably more difficult to maintain? For something like a router, I'm more than happy to defer to a well battle tested library that just handles it for me, and is already proven to work. Hell, Gorilla still satisfies that, but between those, if the only discernible difference is the speed why wouldn't you use the faster one?
[https://github.com/volodimyr/1million/commit/50713f00692bf0042d421762b33f450af828f612](https://github.com/volodimyr/1million/commit/50713f00692bf0042d421762b33f450af828f612) I've done this. Thank you!
There is a good one I use with a friendly community called ory/hydra it solves the OAuth2 problem.
You're correct, but 'asciigraph' will be a good search term when looking for this kind of package. And given the pervasive Unicode support, I guess this won't be a issue.
Thanks for correcting :)
Totally, one of the issues that I'm concerned about with connection tracking is the fact that using the map is going to require the headroom of locking when reading from the map. Time-outs aren't really too much of an issue, but a heartbeat ping is something that would be important to implement (and would be part of this implementation that Femaref recommended). Perhaps taking a step back might be a good idea since I might be approaching this wrong. Each of the nodes are doing very high rate updates on physics for objects residing on their node. I'm currently using TCP and gob because of the high rate of updates 100hz - 10khz per object per node, with roughly 50-100 objects per node, and the fact that 90&amp;#37; of the message per update is a float, so sending a struct seems more efficient than json (not needing to parse each message from a string to float), added with the extra per-message size compared to gob due to needing the field names. It's a soft real-time setting (no need for hard real time, so go is alright even with garbage collection) so latency is a concern.
&gt; Totally, one of the issues that I'm concerned about with connection tracking is the fact that using the map is going to require the headroom of locking when reading from the map. think about that problem once it actually occurs. I'm pretty sure you are overestimating the impact. 
For sure, I tend to over think things sometimes so that's probably true!
IME people from around there have excellent english. Their rich vocab would surprise me sometimes. 
Please don't do this. Literate tests and autogenerating mocks are code smells. Go is not Ruby; Go is not Java. 
No-no! You were absolutely right. It's useless for this particular case. I just receive and log an event message. You can approach to this as a homework which leads you to be confident with workpool pattern. Imagine we have requirements to interact with third party application within `DoWork` method which is obviously can be very painful in scope of time consuming. Hooray! I believe it solves our issue. I just leave it here in case you're interested in: [https://brandur.org/go-worker-pool](https://brandur.org/go-worker-pool) \---&gt; Goroutines are lightweight enough that that‚Äôs not a problem in Go, but a worker pool can still be useful in controlling the number of concurrently running tasks, especially when those tasks are accessing resources that can easily be saturated like I/O or remote APIs.
I wouldn't use it in production (didn't even put a license on it). It's just something I had to implement during a job interview and thought I would share in case anyone found any of the code interesting.
This is a great blog post. Super informative yet concise. 
&gt; I wrote a script (in Go) I see a lot of people using the word script in reference to Go. It‚Äôs not a script. Go is not an interpreted scripting language. It‚Äôs an application. When you use go run, the source is compiled then run on success. It‚Äôs just a quick way to test/run your application instead of: go build -o app . &amp;&amp; ./app.
I think you can just use \`AT TIME ZONE\` in your query to convert your timestamps to a different timezone. See section 9.9.3 at [https://www.postgresql.org/docs/9.2/static/functions-datetime.html](https://www.postgresql.org/docs/9.2/static/functions-datetime.html) To answer your questions: 1. No, do not open a DB connection for every request, database/sql does connection pooling automatically. 2. If you're modifying multiple records in 1 go, then you will need a transaction, otherwise no. 3. This is also a possible option. 4. Use \`AT TIME ZONE\` to convert the timestamps in Postgres.
[removed]
What does this mean?
'Modern' scripting languages, like Perl, python, etc are generally not line interpreted (unlike bash, etc). They are all compiled and run. There is hence no real difference to go scripting.
I gotta say, I'm not fond of this flow at all. For dev, storing default config in build tagged files I suppose is fine. But the moment you step beyond that, you're looking at either storing things like db passwords in version control, or your back to the square 1 issue of having to give your users instructions on configuring their environment - which means you haven't really saved yourself any trouble.
Scripted languages require an interpreter to execute the compiled bytecode generated before runtime. Go compiles to statically linked binary, executable on the platform you compiled it for *without* an interpreter. So yes, there is a real difference. 
Thank you! We will keep up with quality posts !!
Looks like it‚Äôs a bit like `cat` + `tee` but with support for a bunch of different protocols
Something I don't see alot of, but is fascinating to watch is a "Lets write an X" format meetups - probably because its incredibly nerve wracking to write code in front of an audience. I remember one of the first videos that got me interested in Go was this video: [Building a container from scratch in Go by Liz Rice](https://www.youtube.com/watch?v=Utf-A4rODH8) Another great informative format is picking a feature or design pattern of Go and going into depth - Bill Kennedy is great at this: [Bill Kennedy - Behavior Of Channels](https://www.youtube.com/watch?v=zDCKZn4-dck) Something that in my opinion would be SUPER cool to see would be a Go meetup from contributors to widely used libraries/tools e.g. a deep dive into Kubernetes or the go client. So far most of my experience in this field has just been trial and error and playing with things myself e.g. I wrote this simple tool a short while ago: [kubehealth](https://github.com/arehmandev/kubehealth). TL;DR - people want to jump into code and write something, people want to feel adequate! Its why things like codecademy is so good for beginners, it throws you right into writing code with minimal prep.
Yes, i agree. To sensible data like passwords the best solution is a mix between build tags and env vars or a more complex storage.
Perhaps a real difference yes. But not one that really matters. Go just builds its runtime in. 
didn't thought about it, nice idea üëç :) 
Using intermediate language and a runtime vm has nothing to do with if it scripting language or not. Compare Java, .net, etc which uses the same technique without being typical scripting languages. Having a runtime environment means you can do stuff like JIT, etc. Also IL can sometimes be executed directly. It depends on your hardware. I know there's at least hardware which you can run Java IL directly on without the JRE. You can of course also design your own ISA which supports the intermediate language of your choice if you really want to. IIRC you can in atleast Perl also decide what you want to generate and say that it should generate machine code instead of it's normal IL. Go also supports a limited set of architectures machine code, so if you'd want to run on any other architecture you'd also need a runtime environment (possibly an emulator) to be able to run the 'intermediate' code on your hardware. The gap between scripting and programming languages have really been closed for many years now. Both have borrowed from each other. The only remaining thing in my view to call something a scripting language is in the user experience. Is it convenient to be used as a tool for scripting or not. If something is a go program or a go script is thus mainly defined by how it's intended to be used/handled by the user as it can be used by either. This discussion is completely offtopic here though....
Even for the development environment, there are plenty of things any reasonable company would still classify as "secret". For example, if your app sends emails you'll probably have some sort of SMTP configuration. Most of the time you aren't sending emails in development, but if you're specifically testing those systems then you'll need them. 
I was able to install and run it with success. But I wasn't able run: `gimage get "First Last" mydir` Code looks good.
`unicode.MaxRune` is *not* declared in `utf16_test.go`, it's declared in `src/unicode/letter.go`.
Our company stores developer configuration in S3. We have a small `make` (or `npm`, or whatever) script in every project which does an `aws s3 cp` of a dotenv file located up there to pull down to the development environment. Then all the app does is load from dotenv. Clean, secure, easy to deploy, makes onboarding very easy. Developers can then edit their local config as they need. For any other environment, that's all through environment variables directly. Personally: While its interesting to think about, I don't like this. 
We've tried doing that in the past. Attrition rate is quite high. About halfway through we went from 100+ participants to &lt; 30. (I run the Sydney meetup)
Thanks! What did the error message said? Tomorrow I'll try reproduce your error to fix it.
Is that considered high? I'd be curious to know the attrition rate of different talks... People leaving if the material is too advanced, or too simple, makes sense, and my intuition says that any given topic would probably be relevant to about 30% of attendees (less in the wild).
Silent failure Maybe needs a urlencode 
These function calls inside `img/img.go` are redundant: if _, err := os.Stat(fmt.Sprintf("%v", folder)); os.IsNotExist(err) { err = os.Mkdir(fmt.Sprintf("%v", folder), os.ModePerm) } Variable `folder` is already a `string`, you can pass them directly: if _, err := os.Stat(folder); os.IsNotExist(err) { err = os.Mkdir(folder, os.ModePerm) } This code here: err = jpeg.Encode(f, img, nil) if err != nil { fmt.Println(err) return err } return nil Can be simplified with: return jpeg.Encode(f, img, nil) It seems that you are not using `img/files.go:RemoveContents(dir string)` for anything.
Go has great time APIs, so I'd just get/keep the times in UTC from the DB and only convert them to the user's timezone within Go when you display them (or do UI like things with them).
 I tested and this works: ``` $ cat go.mod module gotest $ cat foo.go package foo const Foo = 1 $ cat foo_test.go package foo const Bar = 2 $ cat bar_test.go package foo_test import ( "testing" . "gotest" ) func TestFoo(t *testing.T) { t.Errorf("%d", Foo) t.Errorf("%d", Bar) } $ vgo test . --- FAIL: TestFoo (0.00s) bar_test.go:10: 1 bar_test.go:11: 2 FAIL FAIL gotest 0.006s ``` So I think the trick might be it's ok if it's under the same directory?
Not sure what this brings new compared to socat
It seems they are specified, but not obeyed correctly by gccgo... Has this been files as a bug on gccgo?
What about doing that s3 copy in the config.go? FWIW, I've written a few tools that do similar things like the Makefile script does and the hardest part is getting adoption as it involves updating a ton of team build and project management scripts. Having a lib to pull and push config seems like it could be helpful. It also might allow an opportunity to iterate on the process such as moving to different data source or using multiple data sources to pull together config. There are clearly downsides in that you need to consider build flags for different binaries. But just having a dev vs. non-dev seems valuable as it still gets around a lot of options for flags vs. env vars vs. config files vs. consul / etcd, vs. etc. The caveat with this technique is that you'd likely want to be sure you have a clear mechanism for accessing secrets safely. The flipside is that you could likely do clever things like `config.SafePrintEnv()` or something similar that could intelligently sanitize the config. In any case, while I can see a lot of people thinking this is a bad mechanism, I think there are use cases and development cultures that would benefit from this sort of workflow. I'm curious for folks that have tried this sort of thing what sort of snags you hit. 
&gt; Go is not an interpreted scripting language. Programming language and implementation are orthogonal. The main Go implementations use native code compilers, but that doesn't preclude people from [writing Go interpreters](https://github.com/go-interpreter/ssainterp).
Typically by the end of meetups we'd have about 70% remaining
Didn't Google remove permalinks to the images ?
&gt; writing Go interpreters Which is *not* what this article detailed. Because obviously I didn‚Äôt consider every possible edge case in the known universe. My bad. 
I agree with you that this isn‚Äôt Ruby or Java. However, I do have places where I‚Äôll use mocks. How would you test against external APIs from a vendor(cognitive services)? I use mocks, counterfeiter generated, to return the example responses. Reduces boilerplate and provides some extra recording functionality. Super easy to work with. It‚Äôs cost prohibitive and very slow to hit tons of cognitive services in all our unit tests. I write tests against those vendors but those are pretty small in quantity. Curious how you would approach the scenario as I truly respect your opinion?
No, just the UX button that makes it easy to get to. You can still right click and view image from the search results.
I assume OP is objecting "auto" mocking rather than just mocking
The general advice is: Use real implementations, until you hit the network. At that point, prefer fakes over mocks. It's in accordance with that advice, to use a simulated service with something like `httptest` :)
I don't like the idea that changing a parameter requires rebuilding the app. Seems impractical as well for the motivating example mentioned where you don't control the environment; if you don't control it, how do you know the value for that MONGODB_HOST constant? Presumably whoever does control it would much prefer having a flag or some other config to it being hardcoded.
I was responding to you referring to "interpreted scripting language". Programming languages aren't inherently "interpreted" or "scripting." Those are just particular applications/implementations of them. You're complaining that someone used "script" to refer to a "program," when the difference isn't even that meaningful, but then you referred to "interpreted scripting language"? If you're going to be needlessly pedantic on the Internet, at least be consistent about it.
I think it‚Äôs kinda cute when you start thinking about Go in that way however. It‚Äôs so simple to write programs that you start writing throwaway *scripts* in it. Bye bye bash, Python and Perl Also with stuff like `go-macro` and `neugram` that gap is closing further. But technically yes, you are right. But still, it‚Äôs cute ;)
Right, I know it works for custom external test packages too, sorry that that wasn‚Äôt clear. But I‚Äôd have the same parser error trying to parse them too.
Order of evaluation is one of the most complex aspects of imperative languages. Go let it undefined for a reason. Don't write code which relies on this.
This is reported and confirmed as unspecified. [https://github.com/golang/go/issues/25609](https://github.com/golang/go/issues/25609) For this last example, gccgo does it wrong: [https://github.com/golang/go/issues/24448](https://github.com/golang/go/issues/24448)
Why didn't you used Gob encoding?
You are right. But at this stage I wanted to establish the idea and gather some feedback. Maybe the marshalling/unmarshalling part should get generalized later. But I am not sure if this is the best idea. Go has some utilities for developing plugins but I've been advised against using it.
Nice job! Maybe also link to [docs](https://godoc.org/github.com/gabrielSchneider100/gimage)?
Huh, nice find!
could you also add a section about "how much to test"? I'm trying out TDD at work and with projects, and for me it seems that the amount of time I have to invest into writing tests is becoming a deterrent for me to have fun when programming. It does lead to the most beautiful code I've ever written, but it's painstaking for me to write.
I touch on it at times, and have ranted about it many times :) If I am brave enough I might speak at a meetup about it because it comes up a lot. Here is a brief summary of my thoughts on it: https://dev.to/quii/comment/403f
[Named pipes](https://en.wikipedia.org/wiki/Named_pipe) might be interesting to you.
Thanks for the reminder! Can they be used in a cross-platform Go app? (\`glue\` is just a test-bench for the idea of extending an app using command line - a bit like Erlang ports.)
Hi Martin, It's a super opportunity. You can teach your friends how to code in Go. Find some small problem in your area and solve it together on meetup event. Also, maybe help: [Running Go Meetup](https://github.com/corylanou/go-meetup) from [Cory LaNou](https://www.reddit.com/user/corylanou) Don't be discouraged by number of people that come to meetup, it's more important that you meet on regular basis (in Croatia we meet once a month). Good luck.
low lvl sockets are cross platform
In theory, yes, Windows has named pipes too. But I've never used them on Windows personally.
I think there should also be some sort of "style" option in the config, ie, "thin", "thick", "bar", just to keep the door open for different rendering styles (a-la "figlet" fonts).
Thanks for this. Yes, I'm planning one for Cape Town, South Africa. We will probably do it monthly
set a rate limit or API key or both
Why not github.com/hashicorp/go-plugin ? Easy and works well in production.
Use a queue system like rabbitmq? 
Sounds interesting, what is the flow? save each insert? and then?
The obvious solution is to fix your database. You can, of course, throw a message queue (ActiveMQ) in the middle and pretend this is a good idea, but it isn't.
There are a few Go libraries for reading .wav files (google golang wav file). But they don‚Äôt do resampling. You may have to implement that part yourself. It‚Äôs not particularly hard. 
Basically you push messages on to the queue and then pull the messages off the queue with consumers... Rabbitmq is capable of very high throughput. You could for example pull off 25 messages at once and do a batch database insert, which may be more efficient 25 separate inserts. 
https://godoc.org/github.com/faiface/beep#Resampler
It depends on your consistency requirements. If you can live with lost writes (e.g. sensor metrics) and prioritize availability over consistency, go for an "eventually" consistent solution like an in-memory message queue. If you need linearizability / serializability and favor consistency over availability you'll need some kind of replicated WAL (e.g. Raft / *Paxos).
Fixed it! [https://github.com/gabrielSchneider100/gimage/commit/def1582f1e58f84c55c4340ec74f319bc9e81377](https://github.com/gabrielSchneider100/gimage/commit/def1582f1e58f84c55c4340ec74f319bc9e81377)
Great ideas here. Can you elaborate/refer to "in-memory mq"? can you exemplify which product provide that? does it stay in the queue or being ported to other medium?
Why isn't it a good idea?
&gt;github.com/hashicorp/go-plugin Nice package indeed! Technical: easier model compared to \_glue\_ (v0.1.0, so it can change) because it is just an interface and plugins can be written in any PL that supports gRPC. Personal: I never managed to like gRPC or protobufs. Thoughts: \_glue\_ is very much like an Erlang Port, so the plugins theoretically can be written in any language (by implementing the protocol - a simple JSON tuple (id,payload)). 
Thanks! Nice call. [https://github.com/gabrielSchneider100/gimage/commit/95bce4f029a451e60950105607c0375fb9ac11c0](https://github.com/gabrielSchneider100/gimage/commit/95bce4f029a451e60950105607c0375fb9ac11c0)
Because the database shouldn't be your bottleneck unless you're operating at Uber/Google scales. If you can't get the database setup right, what's the chances you'll get the message queue right?
Right on right on
Right on right on
Yup yup, totally agree
There are three basic ways, off the top of my head, that this can be done. Method 1: along the lines of CLI progress bars in wget and similar apps, or graphs in htop, etc, using ANSI escape codes, terminal escape codes, etc, to dynamically update characters in the same relative positions on the screen. This is visually cool, and there are go libraries out there for this kind of dynamic terminal magic. But it depends on the capabilities of your terminal. Method 2: This works with the code as it exists now, and is a little Unix thing called 'watch.' What it does is call some other program on a regular basis; effectively, it turns any program that has a single-screen worth of output into something you can monitor semi-live. Method 3: This requires that the code have a vertical mode in additional to horizontal (I haven't checked whether it has this already or not), and simply involves the time component of the graph going down the terminal instead of across. Then you just need to keep taking in data and outputting graph - this works on pretty much all terminals, AND works on printers. Picture it as being akin to a continuously scrolling seismograph. This might need some code support to do a properly continuous feed, but if the code currently has vertical graphs at all, then you could simply print a new vertical graph whenever the data feed exceeds a threshold to implement it with the existing code.
hehe, thank you, I just saw it, didn't searching document before, thanks again :)
Thanks for suggesting possible enhancements &amp; reference examples :) , pull requests are always welcome ‚úåÔ∏è
TCP has built in backpressure. Use GRPC if you're looking for something more high level.
[removed]
socat is lower level with a more complicated interface. This is written in Go instead of C and can be used as a package beyond the CLI interface.
If ppl were always right the first time there would be no questions, and no experienced dev to guide others...
A little style suggestion: This code if req.Method == http.MethodPost { dec := json.NewDecoder(req.Body) var event WorkRequest err := dec.Decode(&amp;event) if err != nil { http.Error(w, "Couldn't parse body", http.StatusBadRequest) return } go wp.Run(&amp;event) w.WriteHeader(http.StatusCreated) return } http.Error(w, "POST method only", http.StatusMethodNotAllowed) can be rewritten as if req.Method != http.MethodPost { http.Error(w, "POST method only", http.StatusMethodNotAllowed) return } dec := json.NewDecoder(req.Body) var event WorkRequest err := dec.Decode(&amp;event) if err != nil { http.Error(w, "Couldn't parse body", http.StatusBadRequest) return } go wp.Run(&amp;event) w.WriteHeader(http.StatusCreated) This reduces the level of indentation (one level is not a problem, but imagine 6 checks) and brings the handeling of the error `http.Error(w, "POST method only", http.StatusMethodNotAllowed)` closer to the error check `req.Method != http.MethodPost`.
I feel like there must be some kind of misconfiguration here that needs to be addressed. Alternatively, perhaps a relational database isn't the right tech for the job at hand. Ignoring those, I would look at Kafka to queue inserts to the database
Why not use `sync.WaitGroup` for the shutdown/waiting of your workers? If you want to do the shutdown yourself, why close `wp.shutdown` and then push messges to `wp.kill`? Why not just close `wp.kill`. Your increment at `server/work.go:76` is not atomic. For speed, rather use `github.com/google/uuid` for uuids, then create a new random generator (from `math/rand`) for each client goroutine, and use that in `MakeEvent`. This eliminates any shared variables among the goroutines (as a side note, I would not do this if the randomness of the uuids are important to security). At `client/client.go:87`, why not use `atomic.LoadUint64`? 
stumbled across your project as I'm trying to learn go and start a similar api project. I like the structure, just wish there were example tests; as others have pointed out, I'm not sure how testable it is. I found this resource to provide a decent testable starter, but it lacks structure (everything in main), orm (&amp; mocks), and jwt... so I'm trying to marry with yours... [https://semaphoreci.com/community/tutorials/building-and-testing-a-rest-api-in-go-with-gorilla-mux-and-postgresql](https://semaphoreci.com/community/tutorials/building-and-testing-a-rest-api-in-go-with-gorilla-mux-and-postgresql)
Hi, for example [redis](https://redis.io) implements a fast in-memory queue that may [lose writes](https://redis.io/topics/replication) during failover. On the other hand, [CockroachDB](https://www.cockroachlabs.com) is an ACIDly replicated implementation of SQL.
I don't think peter is arguing against using Chi or whatever else. He is simply stating that the speed argument isn't a good one. It would be like me trying to sell you one phone because it weighs 0.00001oz less than another. Yes, it may be a true statement, but for all practical purposes you aren't ever going to notice the difference so this shouldn't affect your purchasing decision. The same is true with Chi, so your decision should be based on practical things like which API is easier to use and maintain, which has better support for features you need, or which is going to be easiest to get through legal review (some corps have weird policies on third party libs). All of these will vary from situation to situation. To be clear, I think Chi is an awesome package and I'm not suggesting people shouldn't check it out. I just wholly disagree with the premise that speed on the magnitude of nanoseconds should be a factor in your choice of router. I should also note that I am biased. I dislike seeing arguments like this because they have unintended side effects. For instance, I work with a lot of newcomers to Go and when they keep reading things like, "use chi because it is faster than x" they start to think that speed on the order of ns actually matters. This leads to writing code specifically designed to shave ns at the expense of readability, maintainability, etc, or choosing more libs based solely on benchmarks and this almost always comes back to bite them in the ass unnecessarily.
It's completely irrelevant, it's still a script and it is the correct use of that word here.
&gt; Scripted languages require an interpreter to execute the compiled bytecode generated before runtime. so does Java.
You might want to read these: https://neugram.io/blog. A Go interpreter requires fundamental deviations from existing practices in one way or another. Also, for the Nth time; what's going on with Neugram? I'd be quite excited to use GoScript/Neugram.
I can absolutely understand both of your points of view. Like I said in the comment you replied to, when the performance is pretty much the only factor left to care about it, you might as well pick the faster one - because why not? It's funny how much of a contentious point routers can be amongst the Go community.
Don't follow what these people tell you, do what is best for you and your team. These people don't know your constraints or your use cases. Both the parent and the other guy that responded you are highly opinionated about programming, often clashing violently with other individuals, I wouldn't take their advice seriously.
Thanks for the reply, unfortunately the case is the **Call** function does not have access to concrete type of the interface, thus it's not possible to use a type switch
Yeah. Catch the inputs in a fast nosql solution and then periodically pop the nosql inputs into the relational dB. 
You can, indeed, use a slice of function pointers [https://play.golang.org/p/NQ5U7OhVq-2](https://play.golang.org/p/NQ5U7OhVq-2)
Awesome. Then bring something relevant to the thread instead of continuing this circlejerk of my ‚Äúout of place‚Äù comment. I think that it is not a script. You do. I get that my comment was not cool and out of place, but I stand by it and I guess I will continue to feel the burn from it. I‚Äôll just keep it to myself in the future.
yeah but the point isn't about not being right the first time, it's about compounding failures to bandaid over previous ones.
OTOH, there'd also be no need for them‚Ä¶
Well you know I teach kids, since you behave like one : http://www.dictionary.com/browse/script?s=t script : Digital Technology. an executable section of code that automates a task: Your comment is irrelevant to the subject. Your unnecessary pedantry isn't even warranted in that case. The author is right to call what he calls a script. 
&gt; a fairly low level language that feels a lot like a dynamic language like python You mean the same level on (absent) type safety?
Check for the values you're expecting to be set. How are you validating your form input? Faced with an empty form, validation should be failing long before you start talking to the DB. 
&gt;Check for the values you're expecting to be set. It's more of an update form, so it can be anything. I suppose I can check if it currently matches everything on the database. Before, I was changing the url to end with "chng" when the form was submitted and only then would the database be accessed. However, we decided we wanted the form to redirect back to the previous page upon submission, so now "chng" is no longer there. There is no URL to compare it with. 
Because [queues don‚Äôt fix overload](https://ferd.ca/queues-don-t-fix-overload.html) and you‚Äôll need to address the real bottleneck at some point. 
How about setting separate handlers for POST and GET?
What I always do is, to register two HTTP handlers, one for the view which will handle the GET requests, and one for the form submission, which will handle the POST requests. Then, you can check if `r.Method` matches the HTTP method that you are expecting, in this case `POST`, and proceed with the parsing. Here is an example, where "middleware" is a custom HTTP handler. func main() { var app Application router := middleware.New() router.GET("/contact", app.ContactView) router.POST("/contact", app.ContactSubmit) router.ListenAndServe() } func ContactView(w http.ResponseWriter, r *http.Request) { w.Write([]byte("&lt;form method=\"post\"&gt;")) } func ContactSubmit(w http.ResponseWriter, r *http.Request) { if r.Method != "POST" { http.Error(w, "bad request", http.StatusBadRequest) return } r.ParseForm() ‚Ä¶ }
This is my guesswork. In the utf16 package case , both utf16 and utf16_test packages live in the same directory resulting in the same archive file with two namespaces. Even if you build the tests, _test.go files from a non-test package are compiled and included in the resulting archive. If you compile cross package, (like you do with foo and bar being in separate directories), anything with _test.go or in _test package is ommitted from the resulting archive file for foo, so when linker tries to link it with bar, bar contains a reference symbol that is not in the foo package as tests were excluded when compiling foo.a.
&gt; It's more of an update form, so it can be anything. I suppose I can check if it currently matches everything on the database. For an application setting data into a database, this is a scary statement. You need to set explicit expectations on the data you receive, validate that data, and reject anything that doesn't conform. Trying to do things like this is how you get massive database breaches.
Simplest way would be to write CSV files and ingest them in batches
&gt; I would look at Kafka When you need to get to the grocery store, do you take a 747? 
&gt; It depends This. OP hasn't exactly described the problem very well. Could just be a problem with his DB schema, we'd never know...
Isn't the Python resolver is C based?
Yes
Batch together transactions. Every second or three, begin a transaction, insert your rows (never do updates if you're worried about speed) and insert them together. Don't use a fancy queue or other such stuff. Use the database. If it really is a problem, figure out how to tune your tables, do insert onlys, keep your indexes small on the table you insert into.
&gt; would I see a performance gain with golang over python for this? Implement a basic solution in both languages and benchmark them. The only real way to tell which of two things will be faster - actually try it and see. I suspect GoLang will be faster as it is better at concurrency and is generally a faster language but there are a lot of other factors that can come into play and you might hit a limit on external resources before the difference in language makes much of a difference. At the same time a lot of pythons libraries are written in C so if you are not doing much processing on the python side things might be closer then you think. The only way to know for sure is to try both and see.
check this [ I came for the easy concurrency, I stayed for the easy composition](https://github.com/cloudflare/jgc-talks/blob/master/dotGo/2014/EasyConcurrencyEasyComposition.pdf)
If you‚Äôre using oracle db you can have the DB handle this - add the WRITE BATCH NO WAIT options to the commit. The commit will return immediately but you may not receive an error if it fails.
Ok, so I conclude the concrete types are user-supplied. But then, your code does not know the internals of those types, so how can it save them to the database? What I would do is have the user-supplied types explain how to save their content. That is, they would have to supply a method that either returns a standardized struct of data or else receives a db object to save themselves into. (Just a rough idea.)
You could put the arriving inputs on a blocking (non-buffered) channel, and have worker go-routines receive from that channel and write to the database. Start just enough worker go-routines so that the database doesn't get overloaded. The part of your system that consumes input will block on the channel. Ta-da, back pressure! You will next need to reason about what that input is, and what will happen when that input blocks.
The absurdity is the point. Kafka requires substantial hardware and incurs significant operational complexity. Why would it be the first tool you point someone at, when there are so many other ways to solve the problem? If all you need is a queue, you can run something very lightweight on the same instance as your application (ex. ZMQ, RabbitMQ)
You are right Pull request template and issue templates **help**. However, somebody still needs to look over the PRs and over the issues, this costs time, time that I don't have. Open Source projects can make an impact for other creators to create their own tool, or even better maintain the old one.
What's the best way to protect this? Right now, only admins can access it on the site. Is this enough?
You have to save the data persistently somewhere - a DB would be great! Joke aside, queuing must be persistent, and that means your db should succeed, too. Do only insert into a narrow table without fancy (lob) columns, no triggers, and commit on every second.
I suspect it shifts to few/min because larger numbers make people happy. üôÇ
It's also my first ever Go app, so all (constructive : ) criticism is welcome!
The advantage is that you get to respond quickly (albeit differently) and potentially release the TCP/IP connection more quickly. Asynchronous processing is very useful in high volume situations.
[removed]
Well, if they really are hitting the limits of their RDBMS, then Kafka is not overkill. I‚Äôm going to guess that this is a misconfiguration, though.
A single Go file in package main can easily be thought of as a script if distributed as source, since you can run it with `go run script.go` in the same way you might run `python script.py`. In fact I've done this many many times with build scripts that run `go fmt`, `go test`, `go build -o /tmp/binary`, and package the output in some way. Then my build (and CI/CD etc) is just `go run build.go`. This is a script.
[removed]
You could do that by calling another simple go routine inside the handler function and then return from the handler function.
To start, what is the DB, topology, table structure, and the throughputs that you are experiencing (needed and observed limits)? We've had to do all kinds of tricks scaling our MySQL setup at work. First and uniformed suggestions: If the problem is that the DB is consistently slower than your input stream, I would start with batch inserts (time and/or payload size), then look at sharding the DB or tables, then look at worker queues. Also, if your DB is overloaded due to reads instead of writes, look at caching reads or replicating to a read slave and having all reads come from there. There could be configuration updates you can do depending on your DB and/or schema design. Often, bad schemas can result in very poor DB performance. If you give more details, we can give more nuanced advice. :) 
The golang one is C based as well, unless `CGO_ENABLED=0` is set at build time, if I'm remembering right.
I'd use Go, tbh. Everything you need is in the standard library. To get the same levels of parallelism with Python, you'll need to use asynchronous IO and third-party libraries. That said, I don't think you'll see significant differences in performance, so you should also consider what else the program has to do.
That depends on which Python resolver you're talking about. The standard `socket` module is basically out, as you're gonna need to use asynchronous IO to get the parallelism you'd need to approach Go's speed.
It really needs more context. I.e. if we are talking about short bursts then you need rate limiting (google 'rate limiting in golang' and pick your implementation, or roll your own). Now what's long and what's short also depends on the context, available hardware, etc. What you definitely need to do is specify performance and measure the shit out of everything. I.e. you have to be able to answer the question "What is the memory cost of rate limiting (which comes down to internal queueing) a 3 minute burst of data incoming at rate such-and-such?", and similar. Establish the real bottleneck - is it the database processing, or actual physical storage? Start here: https://github.com/binhnguyennus/awesome-scalability
There are also more robust state of the art message queues that deserve a mention, notably [RabbitMQ](https://www.rabbitmq.com/) and MQTT ([Eclipse Paho](https://www.eclipse.org/paho/) being a java implementation that's received some adoption, and the [go client paho.mqtt](https://github.com/eclipse/paho.mqtt.golang)). If OP is thinking about the cloud, [AWS Kinesis](https://aws.amazon.com/real-time-data-streaming-on-aws/) might be a contender. It is mapped to Google [Cloud PubSub (ingest data)](https://cloud.google.com/pubsub/) and [Cloud DataFlow (processing)](https://cloud.google.com/dataflow/). Obviously there are other message queues/job servers/databases which might be chosen (zeromq, faktory, sidekiq, resque, mongodb, couchdb,...) depending on the actual use case, but I wanted to expand on your suggestions a bit.
I can't tell you more than this because I have no context. You must validate any data you put into the database. You must sanitize everything. Even if only admins can access it, 1) that might change in the future, 2) they're credentials might be compromised, etc etc.
In addition to that, dep also has an [override](https://golang.github.io/dep/docs/Gopkg.toml.html#source)\-feature which allows you to define a different source for a specific package: &gt;A source rule can specify an alternate location from which the name'd project should be retrieved. It is primarily useful for temporarily specifying a fork for a repository.
I really appreciate the thumbnail on this post with the name. 
LOL Wouldn't MQ present better throughput than RDBMS/noSQL?
I used sqlboiler with a couple projects, but with your very vague post I can't begin to help you. What issues are you having? What do you mean by integrating?
Benchmark it. SQL databases are super fast. Raw inserts or raw selects with sub-query where clauses (no joins) are also super fast. I would be highly skeptical that a MQ would improve things. /u/tgulacsi knows what he's talking about.
Well, that was easy :-)
That would be bad for entity creation endpoints. You should never return a 202 Accepted response ‚Äî as is correct for asynchronous endpoints ‚Äî until you have written the request to something durable.
We have some legacy code that does parent-child comms over stdin and stdout. I'd recommend against it as you get into issues debugging due to not being able to use stdout. 
Author of the library here. Happy to help out. Open a github issue, post on the mailing list or come on Slack and we'll hopefully be able to get you going. Reddit's definitely not the place for this. Hope to hear from you soon.
For those interested, this beta doesn't contain vgo support, but it will be in later releases.
&gt; A Go interpreter requires fundamental deviations from existing practices in one way or another. Agreed, interpreters are implemented differently than compilers.
C‚Äômon, you mentioned everything except kafka!!!
&gt; How would you test against external APIs from a vendor? By default, I would create downscoped interfaces and data types for the specific functionality I need from the external API, and create real and mock implementations of those interfaces, for production code and tests respectively. If I needed a lot of functionality from the external API, and the interfaces/types I'd need to create would be close or equivalent to the complete interfaces/types provided by the third party, then I would record a fixture or golden master response from the API, and use httptest (or equivalent) to serve it on a separate webserver in my unit tests. I'd use the client lib to talk to that webserver as if it were the external API; or, if there is no client lib, I'd create a thin one. I would try very hard to make the first approach work, and only go with the second approach if it would be very, very difficult.
In fact it's mentioned in the AWS article (Kafka vs. Kinesis) :D
Good heads up!
Curious to see some benchmarks from you guys
That is a lot of code. Here's an in-process, single-focus, watchdog, in 50 lines: https://github.com/tv42/didyouseethis/blob/master/watchdog/watchdog.go
Soo one go book and 2 Uncle Bob books even though he said go prolly wasn't worth the time... 
Neat. I recently found that Vault can generate certificates (see https://www.vaultproject.io/docs/secrets/pki/index.html ) and was planning on using that for local dev, but this seems even easier.
Interesting list. These ten to be quite personal. It depends a lot on what kind of programming you do. Personally I'm not sure Elixir or Seven Languages are worth the time, and grokking algorithms you may have covered in college. Head First Design Patterns is lovely. My personal top four list would be: 1. "Code Complete" by Steve McConnell. An alternative to "Clean Code", which IMHO will make your code better than "Clean Code". I wish for a new edition. 2. "The Art of Unix Programming", Eric S. Raymond. Free online version: [http://www.catb.org/esr/writings/taoup/html/](http://www.catb.org/esr/writings/taoup/html/) , but the print version is very much worth it. Unix is the only constant in our world. The programming language you use will change many times, the tools you use will change all the time, and even SQL is not as much of a constant as it once was. But Unix will always be there for you. Improving your Unix knowledge is the single best investment you can make as a programmer. But this is not just a book about Unix. It‚Äôs a book about the philosophy of Unix, about The Way, and it intends to bring you enlightenment in the Zen Buddhism sense. 3. "The Linux Programming Interface", Michael Kerrisk. This is the Linux grimoire, the spell book with *all* the spells. It‚Äôs over $60, 1500 pages, and you must never get it wet or read it after midnight. Pretty much everything interesting you do in Linux (open a file, write to a socket, start a process, sleep, allocate memory, *everything*) is a syscall. This books is all the syscalls, and extensive information around them. It will answer all your questions. 4. "Growing Object-Oriented Software Guided by Tests", by Steve Freeman and Nat Pryce. I preferred it to Kent Beck's book because it is more practical. Less about testing Fibonacci, more about testing a real application. Full of solid-gold off-the-cuff advice too. [http://www.growing-object-oriented-software.com/](http://www.growing-object-oriented-software.com/)
Yeah true most languages are now wrapped in a go container and soon with kurbenetes and providers. Seems like companies are slowly realizing the benefit but instead of just using go they pay for all these add-ons with the cloud. Like cloud functions so they can throw their unreadable functional languages into them and disregard everything with maintainability and speed for paying cloud functions. I'm just not a fan of people though saying they can use a tweaked compiler or interpretor that's faster.... Cause In production people tend not to. 
Any idea what the loader package is doing to load those external test packages that a straightforward invocation of the parser doesn't do?
I saw a presentation on some of the performance improvements going into Go 1.11. Looking forward to playing with that. 
I think i used a wrong example in the post. MONGODB_HOST is a bad example. Thanks for your feedback. I will change the post
I'm hoping the general sense of dismissiveness is unintentional; While many scripting languages can be compiled, any language which does not enforce line by line interpretation exists outside of the nature of scripting. Line by line execution is not a concern in Go; New bounds are required before Go could qualify as a scripting language. One may create a compiler-based pseudo-interpreter, but that only hides the true method of execution. One may restrict their expressions to script-like code as required by an actual interpreter, but that belies the nature of the language. I understand that it's tempting to downvote the first post in this thread as it points to a sort of limitation to using Go, but the statement is true: Go is not a scripting language.
Another definition along with the historical development of the word disagree: "A scripting or script language is a programming language that supports scripts: programs written for a special run-time environment that automate the execution of tasks that could alternatively be executed one-by-one by a human operator." Go does not fit this model in nature and that's OK.
Agreed. I've replaced many little BASH scripts over the years. Clean error handling alone is worth the time spent. No more $? ish, and you get multiple return values as well!
How does go to web assembly work considering web assembly doesn't support threads (yet). Do goroutines just run synchronously or are they interleaved on the one CPU?
Something like this? https://play.golang.org/p/1RtSL1O9CGe It simulates a union type by embedding each of the API response types into a struct, and then it merges all of the results into a map using the common field as a key, and a slice of the union type as a value.
Thank You 
Use a queuing system like AWS-SQS. Retrieve the messages every x seconds or minutes. Batch insert the data retrived from SQS
Interleaved, just as if you ran with GOMAXPROCS=1 or only had 1 CPU on your local machine or used play.golang.org or used early App Engine.
The idea is similar to [Dead Man's Snitch](https://deadmanssnitch.com) which focuses on cron job monitoring with a couple added bells and whistles to get more visibility into problems and job behavior. The timeout approach you're using is interesting and can work well enough for some use cases. Things can get tricky when you start adding in variable run times for jobs and using splays to try to spread out load which a bunch of recurring jobs. As a first release it's pretty night, good job! Full disclosure: I'm the lead developer behind Dead Man's Snitch and we use Go for most of our backend with Ruby and Rails for our frontend. 
To be persistent, essentially you have to write than fsync, that's all. This is what a heavily optimized RDBMS do under the hood if you use only INSERTs. I don't think that a speed-optimized(=memory-first) MQ can be as safe as an ACID compliant RDBMS, or as fast if they are both safe - see https://www.sqlite.org/fasterthanfs.html for example. From another point of view: to be persistent, you HAVE to store the data on disk. And as this is a write-only use case (given that you read it only later, in another eon), storing the data in memory is useless, does not speed anything up.
Could you be any more vague?
Good point indeed!
I‚Äôve been a bit busy but that‚Äôs my next main item to tackle. Shouldn‚Äôt be too hard to abstract away for testability! Feel free to contribute 
So that pdf is nice, since it shows the ease of use of go, but it does not say how fast go was compared to has bash solution (and that really was the question here, can you get a x1000 speedup using go?). Also the code does not defer `wg.Done`, and that can make for fragile code (but I guess that is irrelevant to this question ;).
I don't think it does anything different in cases of your packages versus standard library packages. I think you have some misunderstanding if you think otherwise, as your std lib example is all built from the same dir. Then you test package A (where a package is a directory rather than package keyword), it builds all files in the package, and runs the test. When you build package A that depends on package B, package B is built in release mode as it's a dependency, hence contains no test filez and package A is built in test mode as thats the package being tested.
Considering high throughput, don't you think it's a huge overhead to issue http request per row (aws sqs)? Network might become exhausted. Wouldn't we prefer tcp level mq like rabbit? 
Nice job. FYI: I ran into a couple interface casting issue at run time. Ideally you‚Äôd fail gracefully if you can‚Äôt cast to your desired type. Thanks for sharing!
Are the tests grouped on the same struct? i.e ``` type tests struct {} func (t * tests) TestA() error{ ... } func (t * tests) TestB() error{ ... } ``` If so, then you can use `reflect` to get a list of functions. On the other side of the spectrum, you can use `go generate` and `go/parser/` to generate a list at compile time (in stead of typing it out by hand). 
For several years I have been using [plist](https://en.wikipedia.org/wiki/Property_list) files in binary format. If I need to allow the configuration file to be manually edited, I convert them into either XML or JSON _(there are some cases where this is not possible, but there are workarounds)_. Many of my colleagues in other companies stick to JSON or YAML. And depending on the amount of data, if it is too much, I put them into a SQLite database.
https://github.com/golang/go/wiki/SQLDrivers
I'm waiting to try Webassembly.
A point release or 1.12 ?
In the main 1.11 release. Not in beta versions.
If there's a need for a config (apart from standard "flags" or "namsral/flags" package usage - environment and arguments), I usually resort to JSON. Being able to ingest the JSON with `jq` actually gives me a nice flexibility when it comes to cli apps that take arguments and don't know anything about your config. It also means that I don't need to fix those apps, in case the json config structure changes - I'd just fix whatever wrapper is reading and passing along the configs. For example: ```bash SERVER=$(cat $CONFIG | jq -r .pools[0].url | awk -F":" '{print $1}') PORT=$(cat $CONFIG | jq -r .pools[0].url | awk -F":" '{print $2}') USER=$(cat $CONFIG | jq -r .pools[0].user) PASS=$(cat $CONFIG | jq -r .pools[0].pass) ``` This kind of config is usually involved. From it, I could build a DSN for a database connection. I usually don't put DSNs into the config, because not all apps understand DSN connection strings, some don't even understand `$HOST:$PORT` and you have to split that (`ssh host -p port` for example). Anyway, start with flags, pass an argument, then grow from there.
I don't think the number of people coding go in South Africa is high, so most people that will show up for the first few will probably be there because they have heard good things and would like to learn more. I don't think an in-depth dive into the inner workings of channels will really be applicable to most attendees. Maybe take a hyped up topic (like blockchain) and show how that would look in go. Or talk about basic concurrency patterns in go in a Q&amp;A kind of session. 
Any plans to implement some kind of filtering or processing these streams? 
I've used [github.com/jsha/minica](https://github.com/jsha/minica) in the past, but this looks even nicer.
More advice from a colleague Pretty easy. You just pick a name, create the meetup on meetup, pick a venue, invite one or 2 friends so you're not alone. Then get it published it on ZaTech slack announcements and share it via twitter with appropriate discussions. I'd recommend a LEAN coffee type discussion about go for the first one. More long term: Get offerzen to sponsor some swag (they send t-shirts), and get actual speakers
Do not ignore possible error [here](https://github.com/ishuah/bifrost/blob/master/keyboard.go#L35). If I run `bifrost ... &lt;/dev/null` it will fail *in a strange way*‚Äîpossibly with a `nil`-pointer-dereference panic. I'd say the best for a program which wants "real terminal" to work is to do the necessary perapations up front‚Äîin an `init` function, or in `main()`‚Äîsomewhere near the top.
GOPATH should point to go, in which src, pkg, bin are.
You should probably compare actual error [here](https://github.com/ishuah/bifrost/blob/master/connect.go#L67), instead of comparing string value from Error(). So: `if err == io.EOF {`.
Not sure how much this affects behavior, but you are also ignoring error on `Write` [here](https://github.com/ishuah/bifrost/blob/master/connect.go#L78).
Right! Having an init function will make things much cleaner. Thanks for pointing out the ignored error.
Thank you for pointing this out, I'm on it!
Doesn't affect behavior much but I should catch that error. 
https://github.com/golang/go/wiki/SliceTricks
Thanks! Hm, I don't think I ever got those, and I think the only type casting I do is [here](https://github.com/pawelad/just-scored/blob/master/just-scored/goals.go#L97-L101). Could you provide me with a stacktrace / error / log so I can look into it more (probably best to do in a GH issue)?
There is youtube video where the guy explains everything, i think which includes time taken. &gt; Also the code does not defer wg.Done, and that can make for fragile code You don't have to defer wg.Done . Its a good practise not a necessity.
The easiest way is to pipe through a local program like: `hookah -i some_input | my_program | hookah -o some_output` And have that program filter/process stdin to stdout. But I've thought about implementing a small Go helper method so you can write a function that's responsible for moving data from a reader to a writer. The helper method will handle the CLI interface and setting up the input/output streams.
Are you contradicting yourself?
Was it a video presentation with a link you could share? I would be interested in seeing this.
Neither is correct. And it works the other way around: You set GOPATH to whatever you want and place your code below $GOPATH/src.
You cannot as there are no references in Go. But maybe you could show some code?
You shouldn't set GOPATH at all, when starting fresh with Go. If unset, it'll default to `~/go` and go-get will fetch sourcecode to `~/go/src/example.com/myproject`. These defaults should be fine.
Not just another Go JSON library, jstream takes an io.Reader input and streams out *only* the decoded values at a specified depth; i.e. you can extract arbitrary inner values without decoding and allocating for the entire parent structure. Additionally, each value is wrapped with metadata, providing the depth, and byte range in the doc where the value exists. Any feedback and/or PRs are most appreciated.
Check out gobuffalo and their generator. When you create your new buffalo project, there are flags to skip front end creation. Then generate resources and it creates the CRUD stuff for you.
Idea set Go standards for sake new team members join your company. It will be nightmare for new devs have to know all DSLs where Go standard library is rich with tools to achieve what you want. I‚Äôd rather read that framework code and rewrite it rather then importing package. Rob Pike Go proverbs must watch all gophers https://go-proverbs.github.io
Currently all I am reading from your post is that you prefer not to use gin, which doesn't really give me a good idea of what you're looking at. What's your ideal "stack" for your API implementation(s)? - If you're looking at very basic CRUD APIs, write them by hand, - If the volume of the various APIs is significantly large, you might as well take apig and produce a http standards compliant lib output and bring your own choice of router in the mix, - Or just produce proto files based on your gorm structs. Or generate [gorm tagged structs from proto files](https://github.com/infobloxopen/protoc-gen-gorm), - Obviously, gRPC APIs could be a valid option too (see previous point). 
How does it deal with malformed Json?
Perfect, thanks.
[https://docs.google.com/presentation/d/1tpeJZFObkeick4CF-mx0L3CeCgvT15B96aJeRpxEPcE/edit?usp=sharing](https://docs.google.com/presentation/d/1tpeJZFObkeick4CF-mx0L3CeCgvT15B96aJeRpxEPcE/edit?usp=sharing)
He said the go version took about an hour and a half to finish. So the difference was over an order of magnitude. [Here](https://www.youtube.com/watch?v=woCg2zaIVzQ) is his talk explaining it.
I'd tell you to use [sqlboiler v3](https://github.com/volatiletech/sqlboiler/tree/v3) over gorm. Not only is it a simply better ORM in general (subjectively, disclaimer I'm the author ;), much faster (objectively, see benches in readme), but you can use the new features in v3 to not only generate your database models but also generate CRUD handlers from your database models by writing some text/templates. Since it's just text/template you can literally write whatever you want in there, so it could use buffalo, it could use just chi, anything really. Downside of this approach being: you have to write more code since there's no predefined templates for API CRUD handlers and the folder structure is a bit rigid so you'll need to mv your generated crud handlers to their final destination. You'd also only really want to do this once probably, whereas the idea is regenerate every time the database changes. Though you could gitignore the CRUD generation folder and that way when you change your database and add a new table, you can just copy out the API CRUD boilerplate for only that new model. Anyway, it might work for you it might not. Just thought I'd throw it out there.
It's not in *this* beta version. The release notes mention that future betas will include it.
I very much like toml for configuration so I'd continue down that path. It has comments, and it has less song and dance for the same amount of data (less {}""). I use it in conjunction with [spf13/viper](https://github.com/spf13/viper) to do configuration. If you set viper up correctly, you can take configuration from environment variables, flags, and a config file which I find nice. This helps you with the whole [12 factor](https://12factor.net/) thing. To use flags with viper, it's easiest to use [spf13/cobra](https://github.com/spf13/cobra) which also supports both BSD and AT&amp;T style flags, my preference is to have the --double-dash so I usually use cobra for flags and subcommands even when I don't use viper. Once you have your configuration options use your mysql driver just open the handle to the DB with a DSN. The most popular mysql driver supports a Config struct that you just slap values into then call FormatDSN on it to get the DSN string which is a nice approach. So you do that, and pass that to sql.Open() and you're ready to mess around in the database. You asked about database access in the title, but not so much in your actual post. If you're also curious about libraries to help retrieve data and shove them into structs check out [sqlboiler v3](https://github.com/volatiletech/sqlboiler/tree/v3). Side note: It's hard to judge where you're at with Go given the question. All the libraries I mentioned are past the basics and into hardcore territory so it might be overwhelming. If you're looking for something simple just use toml, and manually Sprintf() your DSN into sql.Open. It'll take you 1 struct, and like 5 lines of code and you'll be done. You don't have to learn anything more than that and you can start querying your database, albeit a bit painfully. You could use [sqlx](https://github.com/jmoiron/sqlx) to help alleviate that pain for a more "lightweight" approach over sqlboiler.
Here's an example of using hookah as a package to do filtering and processing: https://gist.github.com/wybiral/118f0ce89fa3435ab3e2e9a5d7111081 It reads the CertStream WebSocket API, filters out the heartbeat messages, reformats the JSON, and then writes the results to stdout. 
around 15 minutes in I show how to set up VSCode as a nice development environment for Go, you may like it: [https://www.youtube.com/watch?v=9D4yH7e\_ea8&amp;list=PLDZujg-VgQlZUy1iCqBbe5faZLMkA3g2x&amp;index=1](https://www.youtube.com/watch?v=9D4yH7e_ea8&amp;list=PLDZujg-VgQlZUy1iCqBbe5faZLMkA3g2x&amp;index=1) However there is nothing wrong with using Notepad++ and a command prompt, this is how a lot of serious work is done in the linux world. So if you like that workflow, you can keep at it. The way I set up VSCode isn't too different, thought the command prompt is integrated into the editor.
You are ignoring almost all returning errors in the bellow [code](https://github.com/ishuah/bifrost/blob/e6eda0f312475dd43f0db626f3a9906df6d93b32/keyboard.go#L34). Another suggestion is to call `t.Restore()` and `t.Close()` using `defer` statement. func pollKeyEvents() Key { t, _ := term.Open("/dev/tty") term.RawMode(t) buff := make([]byte, 2048) size, err := t.Read(buff) t.Restore() t.Close() if err != nil { return Key{} } ...
It depends on what you want to learn. I personally love liteide because everything is automatically setup but problem is intelligence sucks and it's a dead project but great for learning. I would use vscode but to be honest I don't code natively anymore. I use a chrome book and codeanywhere. But usually you have to pay for it. They did a lifetime freelance subscription for $80 before but it's gone I think. It's nice cause you can start a digital ocean droplet right in the ide. The intellisense sucks on it but it's really nice to not wait for loading, viruses, initialization, error screens, updates, or anything ever again. Supposedly the pixel books are going to get Linux app support on nondev channels soon and hopefully to other Chromebooks. Then you can have the best of both worlds. But personally I just like to always connect to my ide and app in any device.
It would make a lot of sense if I opened the term session in an unit function rather than each time the pollKeyEvents function runs. Thank you for the feedback!
Here's what I'm looking at; the databases already exist so I was going to use [https://github.com/smallnest/gen](https://github.com/smallnest/gen) to generate the gorm models. From there about 80&amp;#37; of what I need is just basic CRUD so if I could generate that, it would speed this up a lot. My preference would be something that just generates funcs that fulfill [http.HandlerFunc](https://golang.org/pkg/net/http/#HandlerFunc).
That's cool. Unfortunately it's not a great fit for this project, but I do have another where that may be exactly what I need.
unshift seems like it should have a more efficient second version (like insert).
&gt;It would make a lot of sense if I opened the term session in an init function rather than each time the pollKeyEvents function runs. Disagree, defer statement makes total sense in your code. Anyway, it your project. 
Neovim + fatih/vim-go plugin. No exceptions. Easy to setup, already configured bunch of linters, formatters, analyzers, bunch of useful functions and all in one place with very easy tutors + manuals. [https://github.com/mhinz/vim-galore](https://github.com/mhinz/vim-galore) [https://github.com/fatih/vim-go-tutorial](https://github.com/fatih/vim-go-tutorial)
I write Go all day in VSCode too. The Go plugin is great!
Stick with Goland it is really good. Ignore the guy saying vim.
decoder is halted, output channel closed, and resulting error (with location context) is made available via [Decoder.Err()](https://godoc.org/github.com/bcicen/jstream#Decoder.Err); e.g: invalid character after object key: 't' [1,12] // [line, column]
This doesn't do everything your code does by any means, but are you aware of [the ability of the encoding/json library to do your first example with the built-in library](https://play.golang.org/p/ODR43KEKu2u)? I actually do a lot of JSON streaming, both encoding and decoding, with the built-in library. It doesn't go down three levels deep off the shelf, of course.
Right on, we‚Äôre on the same page. You basically described my entire workflow. Thanks for the thorough response. 
Agree, the mocks listed in the blog are not pleasant to work with in my experience. The pkg counterfeiter creates some very useful mocks without requiring you to learn a DSL. Can be very useful from time to time.
I agree, defer makes a lot of sense. I had the idea of having an init function that returns the Term type and then have the defer statement on that. Am I making sense?
Looks cool! For desktop stuff looks very promising! The game I have in mind though, I'd like to bring it to Mobile, atleast Android. &lt;3 
After some more research, yeah Unity client and Go Server seems to be the way to go for now. Which is totally cool, I appreciate your input :)
Set the timezone to UTC when you connect to PostgreSQL, then use either `AT TIME ZONE` or Go's time zone handling to adjust the values for display.
Yes, too many people view JavaScript as [a golden hammer](https://en.wikipedia.org/wiki/Law_of_the_instrument), though it's at least a little better than the [PHP hammer](https://imgur.com/gallery/RH2w0).
LiteIDE and Vim, mostly Vim, with vim-go.
Hi /u/Maxiride, sorry to hear you have issues with GoLand. Can you please either DM me on Gophers Slack, or Twitter (@dlsniper), or send me a mail to florin [at] jetbrains, to see how can I help make your experience better? Thank you.
Seems Unity for client and GO for server is going to be my approach too. Starting to look into LumberYard as well. Though, for game development I feel c# is a little more geared towards rapid development than c++...
To quote [the creator of NodeJS](https://www.mappingthejourney.com/single-post/2017/08/31/episode-8-interview-with-ryan-dahl-creator-of-nodejs/): &gt; That said, I think Node is not the best system to build a massive server web. I would use Go for that. And honestly, that‚Äôs the reason why I left Node. It was the realization that: oh, actually, this is not the best server-side system ever.
VSCode for all your needs outside of a fully fledged gaming IDE. I use it for web development, go development, python, etc etc etc
[removed]
Just to be specific, /u/8lall0 should use "Filtering Without Allocating". If by reference you mean you have a `*T` and want to remove it from a `[]T` or `[]*T`, you would need to build a new slice that doesn't contain your `T`. https://github.com/golang/go/wiki/SliceTricks#filtering-without-allocating
But cmake and ninja?
Try a text editor and the shell. There is no need for an IDE.
check the updated package, [dmke](https://www.reddit.com/user/dmke) added a simple command line interface. 
yw, see /u/danredux reply and there's this informative post about slice internals https://blog.golang.org/go-slices-usage-and-internals
Go extension plus a few other Git and Github extensions! And not just Go, I also program Python and C++ with VSCode on my PC (Windows) and laptop (MacOS). Setting up Git Bash as the integrated terminal really makes the experience identical across platforms. Funny how Microsoft makes the worst web browser(s) but the best code editor!
Goland use Eap version if you don't want to buy it yet
Default GOPATH will suffice to work on go. If you are creating any non main package in your project, put the package related to code in vendor folder. 
It boils down to: queue input stream (buffer), consume queue and insert into DB at the rate it can handle. What you use as a queue depends on what are your requirements (persistence, throughput, ordering and so forth). It can be a simple in-memory queue (using a buffered channel for example), a standalone queue (redis queues, rabbitmq, kafka and many more), a hosted one (Amazon SQS for example).
so something roughly similar to https://stedolan.github.io/jq/ ?
 Is there more to your domain model than just the keys you provided? If no, why have \`dates &amp; times\` as a key at all? Wouldn't it just be easier to have something like: \[ { userId: 1, dates: \[150, 165, 180\] }, { userId: 2, dates: \[140, 150, 160\] } \] If this JSON is under your control, I think a better first step is figuring out a more reasonable way to structure it, so that serializing becomes a no-brainer. something like type UserDateInfo struct { UserID int Dates \[\]int } and then serialize/deserialize your JSON with a \`\[\]UserDateInfo\` slice.
What is not ambiguous is that if you're using the pattern of assignments covered in the article you probably shouldn't be writing code at all.
Maybe, but less ambiguities, the better. After all, less unspecified scenarios is an advantage of Go to C.
&gt; What do you expect the above program will print? [5 6] or [3 6]? FYI, gc (the standard Go compiler) prints [5 6], however gccgo prints [3 6] For context, when are people using gccgo vs gc? Is that statement as terrifying as it sounds? Don't get me wrong, the article code is terrible.. but order of execution shouldn't change so drastically.. should it?
But is jq a go library? 
Go's standard JSON library being not streaming friendly did [bite me before](https://wang.yuxuan.org/blog/item/2017/02/some-go-memory-notes), so I'm glad to see some streaming friendly implementations. This probably won't solve the problem in the blog post, but that is OK. One thing that bugs me is if the level is greater than 0, it will only emit values at that level. Why do you make this design choice, instead of something like emit values at or below that level?
If the order is not specified, then nothing is weird.
Go should just make it a compile-time error to do this sort of stuff. I'm not sure the specific rule, but anyone actually relying on the behavior of multi-value assignments to the same underlying data is doing something way too clever to be useful or acceptable.
[When I said you should post this in this sub](https://www.reddit.com/r/C_Programming/comments/8txq4j/mkg_makefile_generator/e1dx0ok) I meant that you should indicate that you're looking for feedback and areas that need improvement. As it stands, I think most people who see this link without any context will suspect you're trying to garner more users for a tool that is still in its infancy.
technically, the values being emitted at level `x` (if object or array) will already include everything `&lt;x` within them; specifying a static level prevents,for example, emitting both an array of strings and every string within that array independently.
Have to agree even though vim is still better if you‚Äôre lucky enough to work in non-windows environment. But yeah git integration, jira, gerrit, jenkins plugins +ssh sync makes development in corp env great. Also the rust plugin seems very nice and there‚Äôs one for vue if you fo frontend. I do think that vscode is more intuitive with shortcuts but i left that camp after poor and buggy plugin performance (especially the vimmode plugin drove me crazy). Would wish goland had same kind of command bar that lets you run stuff fast since learning the key combos can take some time especially when feeling a bit unintuitive. I do miss coverity reports like in vscode where you can see the source heatmap. Maybe it‚Äôs there but I have managed to miss it. Also bonus for being able to configure test params so it‚Äôs easy to ignore for example integration tests that require external components when you run from IDE instead of cmdline.
The project is still in its early stage. I want to make a project generator for tools that own no builtin package manager like LaTeX by utilizing GNU Make. Currently, I wrote for C (or C++) first. Any comments and feedback are welcome.
Yeah, it is a bit duplicated work when applying GNU Make to C (or C++) projects. I prefer GNU Make than CMake; hence, the tool is based on the former.
I said "at or *below* that level", not above. In the example in the README, it doesn't emit `RGB` when you changed the level to 3.
https://play.golang.org/p/aaNIHuuH4ZX
Nothin wrong with that Have you considered offering BSD make support as well? Prolly not as important, since even the BSD distributions tend to have solid support for GNU make. Just a thought.
I can use a free student license for now but thanks 
I've been using notepad++ so far and found myself comfortable but I also wanted to try something more advanced than that.
Vscode seems indeed a great choice. I've decided to install both vscode and lite ide to compare them. Some however say that lite ide is a dead project but I see continuous commits on the repo ü§î
&gt; when are people using gccgo vs gc? gccgo supports more architectures and apparently may optimize code better https://blog.golang.org/gccgo-in-gcc-471
I've already chatter a bit with a guy called Alexander from the support with scarce success. Nonetheless I honestly found the documentation about the IDE not lacking of anything but it assumes that the reader already knows A LOT about programming. Let alone I spend half an hour to understand how to generate a package .a while from console I could just run to build go install.. I know it is a good product or at least the other family from intellij is but didn't found it very noob proof. This isn't a dowsidt of course, it all depends on the target audience after all
I've used vim long ago while I was an Arch user and while it is indeed very powerful it's one of not THE one with the steepest learning curve even to simply navigate the text 
Yeah I'll try it along with vscode. I've decided to try these two alone
Totally trying it! I've decided to give a go (pun not intended XD) to vscode and lite ide but before seems promising. Feels like Atom for certain things 
VSCode + VSCode-go imo.
But who nannies the Nanny?
I started with LiteIDE. Honestly, it's very handy for a beginner. However, after months and months of seeing everyone and their grandmother using VSCode, I had to see what all the fuss is about. At first, I didn't like it. I forced myself to keep using it for a week or two. Now, I will never use anything else. Don't make the same mistake I did. Just start with VSCode. Promise you'll love it.
correct; however, a depth level of `2` yields: `# cat test.json | ./jstream -v -d 2` `depth start end type | value` `2 018 023 string | "RGB"` `2 010 023 kv | {"key":"desc","value":"RGB"}` `2 039 065 array | ["red","green","blue"]` `2 029 065 kv | {"key":"colors","value":["red","green","blue"]}` `2 087 093 string | "CMYK"` `2 079 093 kv | {"key":"desc","value":"CMYK"}` `2 109 149 array | ["cyan","magenta","yellow","black"]` `2 099 149 kv | {"key":"colors","value":["cyan","magenta","yellow","black"]}`
You suggest vim for beginners? For real? I love vim but it takes people months/weeks to get proficient. Most vim users have spent hours customizing their .vimrc. Vim, like emacs, is powerful but arcane. It's black magic. When someone is learning a language for their first time they want an easy editor that just gets out of the way. They can focus on the programming concepts, then worry about editor efficiency later.
If you can't be bothered to type your question out, why should we be bothered to click some links and guess what you want to know? http://catb.org/esr/faqs/smart-questions.html
I‚Äôm not understanding your question, what‚Äôs your objective here? Are you looking for Auth service that signs a requests with a secret key?! 
It's called check the shit out of it. https://play.golang.org/p/ZPzAgeM_zwS 
I see a JSON array in the example, but how does it handle newline delimited JSON documents? That is also known as "streaming JSON"
Please send me the parts of the documentation where you had issues with. Also, you are probably the first person to ask us what needs to be done in order to generate a ".a" file. So I'm interested to know your use-case and see if we can do better to document the IDE.
That article is from 2012 and since then the compiler has been completely rewritten, and they've added dramatically more architectures. I'm not sure of the current state of the world, but definitely wouldn't trust that article.
This is the real answer
In GoLand you can use CTRL+SHIFT+A or SHIFT+SHIFT and it will basically allow you to search for any function or setting of the IDE. And if you install this plugin, then you'll be able to have mutilple run configurations each with their own shortcut, https://plugins.jetbrains.com/plugin/9448-run-configuration-as-action By coverity reports you mean test coverage reports? Or is this something else? As for the last point about test configuration, maybe having two different run configurations, together with the plugin I mentioned above, will make it easy to support these cases? To configure the parameters of the Run Configuration, head to the Run | Edit Configurations | select your configuration and that's about it.
With anything like this, the time input is worth accounting for. How long have you put into researching codegen when you could have just been writing it manually? Unless the schema is going to me changing constantly, and it's always going to be super basic CRUD (and validation!) a third party code gen library probably isnt going to cut it. There have been SO many times, espeically in go, where I try to rig a third party setup into doing what i want, but rolling my own would have been so much faster.
It was just an example, I have like 10 fields inside the user field. 
Vim is not black magic, sorcery or rocket science, it's just text editor. One evening for vimtutor, another for minimal configuration (folding, indenting etc) and installing one plugin. Not that hard, considering you save a lot of time on actual text editing with notepad-like experience. Main case of this setup is low abstraction level to actual golang tools, vim-go is just a bunch of scripts with great configuration. You will know your environment for development.
Emacs of course. Well, it does not matter and I doubt that thinking of an IDE as "something more advanced" or "more serious" is not really the right way forward. Nothing is advanced or serious here. Some people find it more comfortable to write, debug and manage code with an IDE and which IDE is a personal preference only. I really like emacs as I'm used to it since 25 years and running test and jumping to compile or test failures or jumping around in code with a keystroke is nice for me. For git I just use the cmdline because I'm too lazy to learn magit and I do not see a large productivity gain here. Use what makes _you_ productive.
Unmarshal into a `map[string]Stakepool{}` ?
Dude you just dumped the raw json into the post text and expect us to work with that? What kind of database? Mongo, Postgres, etc? You can marshal that into a map[string]interface{} and transport it around... most databases will have a type that can work with raw json too. Again, you've given no info besides "put this random data into a random database"
Yeah, you can just unmarshal into a `map[string]string` 
You can run another nanny that monitors a nanny :) It is not in the README, I forgot to add it there.
https://github.com/tidwall/gjson
Or use gorm? Define a struct witch matches your data mark it up add connection info and you are basically there + you can pull it back and query it
Gitlab can do that: https://docs.gitlab.com/ee/topics/autodevops/
https://www.spinnaker.io
Especially when it's [the second](https://www.reddit.com/r/golang/comments/8ucgxt/how_to_store_such_json_data_is_a_database_with/) such no-effort post.
I built something similar to this, but a little more complicated: * https://github.com/skx/purppura/ In short it is a system that centralizes the collection and storage of "events". Events can be in three states "raised" (i.e. a human has been notified), "pending" (they will raise in the future), or "cleared" (they'll go away shortly). You can send events like: * Alert in 5minutes unless you hear from me again * Raise an alert IMMEDIATELy * Clear an outstanding alert. There is a web-UI which shows the alerts currently known about. I have a [monitoring tool](https://github.com/skx/overseer/) which performs IMAP, PING, SSH, and HTTP-fetch tests, etc. All the results are fired off to my alerting system - such that if a site/service fails I get a notification. This kind of central alert-collection system can be _very_ scalable and robust. 
I forgot to mention one change you might consider: * Allow names to be non-unique. This way you can name an alert `heartbeat` and add a 1-minutely cronjob on N hosts eahc running: curl http://nanny.example.com:8080/api/v1/signal \ --data '{ "name": "heartbeat", "notifier": "stderr", "next_signal": 65 }' That way if a host dies you get a notification 5 seconds later. (Assuming the HTTP-POST doesn't fail.) How do you differentiate if names are not unique? Use the combination of Source-IP + Name. So `10.0.0.10` can post with a name of `heartbeat`, and that is different to the name `heartbeat` coming from `10.0.0.11`. 
Good idea. I'll add it :)
After a quick search I found [this](https://gitter.im/go-authboss/authboss/archives/2016/08/09). Check out the comment there's a link to an example of a mysql storer. I haven't tested it but I'm sure it would put in the right direction.
&gt; Automated re/configuration of Vault based on a YAML/JSON file like: Auth backends, Secret backends and policies I've actually been working on the same thing just as a standalone CLI (my company doesn't use k8s). Ill have to check this out!
One quick thing from skimming the readme, the word you're looking for is "opinionated", not "opinioned".
We have a CLI as well - does all the above, the same Golang package is shared by CLI, operator or API. Chech it here: https://github.com/banzaicloud/bank-vaults
Hello, WASM &lt;3
So... I haven't tried it myself, but I believe gocd should do this.
Some information in that article is outdated, but some viewpoints in it still stand.
I think [gocd](https://www.gocd.org) does this. I haven't tried it myself yet, but have heard people who are quite happy with it :)
Goa is a generator for which you design the api in a Go like SDL. Then it generates the Go code. Optionally it can use the Gorma plugin to generate all db code using Gorm. I use it for my current project and am very happy so far. https://goa.design/ https://goa.design/extend/gorma/ 
I've been using Sublime with some fo plugin and it's great. It isn't full IDE-level when it comes to some lookups or refactoring, but I'm fine with that. VS Code was way too slow. Like, it can't handle syntax highlight when I scroll slow. Goland felt overwhelming, but I'm sure it's great with their history. So if you are not used to any environment, I would give it a try.
Yeah, the license for LumberYard is tempting, but it's filling a confusing role in the industry now that UE4 + source is free to start building. Unity is probably best at lowering the barrier to entry for something playable, and it's perfect for prototyping. Unity is also the least risky move for mobile, with plenty of games released on it. I'm waiting to see if Epic releases Fortnite on Android before I try it.
I mean the html view you see when you run coverage on vscode or vim. They will both display the source code and color it depending if there‚Äôs tests or not. It makes it fast to see what‚Äôs missing instead of seeing % and having to find ou yourself what‚Äôs covered and what‚Äôs not. I know I could just open it in a browser but it‚Äôs convenient when it‚Äôs in the editor.
Thanks for correcting a wrong wording.
Ah, I see. There's no need for that. The IDE already has a feature to display the coverage, see this on how to use it: https://youtu.be/v09S9caA9IA
Hey there. I'm the Author of this library. First off I want to make sure you're using v2 of the library. Check which branch you're using, it should be the v2 branch (the master branch Readme mentions this). Secondly reddit isn't the place for asking questions about a specific library. On our Readme there's a mailing list (Google groups) that you can use or you could open a github issue to talk to us directly about problems. In v2 the ServerStorer (which replaces the v1 storer) is a lot more obvious how to implement. Both of them however can easily be implemented with an sql database. Try that out and post on github/mailing list if you still run into problems. Thanks for trying out Authboss :) 
Now you have to support both MQ and the database in a high perfomance setup. Unless you already optimized your database this is premature optimization. As you can purchase database optimization as a service of the shelf (bingo!) you could just do that at the end of the year with left over consulting budget. Your ops team does not have to learn how to run yet another system in a high performance setup. So measure actual performance/bottlenecks, optimize your database schema to the task, use prepared queries, batch inserts, persistent connections, fast storage. Run mysqltuner.pl or the equivalent for your RDBMS. BTW some context, like events per second, would be helpful to understand the scale you work on.
Thanks for helping out SpecialGoat. The [sample](https://github.com/volatiletech/authboss-sample/tree/v2) is a good place to start for sure. It's v2 branch includes the version that works with v2. Did want to also mention that we've stopped using gitter just so people are aware.
Oh I don't expect authors to appear in my post, what a pleasure! Well I didn't realize the the difference between the master branch and v2 branch. Does master means v1 currently? I should have just installed authboss using go get github.com/volatiletech/authboss So is that v1? And I should uninstall it and install v2 again? As for the implementation of the database approach, I think I will repost it in github. Thanks for the guidance ;)
Yep. That's correct. Currently v2 is in rc stage which is why it's not in the master branch. Which means some things may break yet, but it'll be as small as we can manage, for example the Flash message interface is probably going to change soon to be a separate interface and separate cookie. However the effort in moving from v1 to v2 is non-trivial so even if you have to change a little bit of stuff you'll save a lot of headache in general. You can also pin to a specific tag to avoid dealing with the breaking changes (current latest rc is v2.0.0-rc4) until you're ready. So lastly because it's a branch and not in master, generally you can clone like this (keep in mind this assumes your GOPATH is a single directory and not multiple): mkdir -p $GOPATH/src/github.com/volatiletech git clone --branch v2 git@github.com:volatiltech/authboss.git $GOPATH/src/github.com/volatiletech/authboss One more problem is that godoc.org doesn't support branches, so you can run your own godoc server (it's pre-installed with Go): godoc -http :8080 Now you can see the v2 godoc documentation if you browse to http://localhost:8080/pkg/github.com/volatiletech/authboss/
What is it you're trying to do? Sounds.. weird.
Why would I choose a custom protocol when HTTP(S) is available?
Our team is experimenting this week. So far, 9 of us ‚Äî myself included ‚Äî are blown away. üôÇ
Yep, that code is ugly! But the voice in on point, brings back memories of making my C64 say cuss words.
It worked on my system for basic test cases. I tried to feed it the lyrics to Stay Alive and I got a panic. But it does work. And man does it sound 8-bit. If nothing else this would make a good thing to mix into some chip tunes.
Most typically that durable thing is a queue/bus of some sort, but yes, we largely agree.
It looks like it uses http/s for transport. It all about code generation so you don't have to write code to handle a protocol. 
Linux users don't use notepadd++ but they will often use a non-ide editor like Vim, Emacs, or sublime along with terminals. Unix systems have enough useful commands that this workflow can be very similar to an IDE. Most of those editors have go plugins of various levels of quality, I'm not sure how good I haven't used them. But yes VSCode is a very nice way to work, and runs well on all 3 desktop platforms. 
This implementation can't handle long phrases (neither could the original C one), so maybe that was the issue with lyrics. I'm also not sure if it can digest newlines etc. And yup, this is extremely 8-bit!
Hi! Your question is not related to net/smtp directly. You need to make some research regarding RFC 822: the format for email messages. You need to properly encode your email parts according to RFC822. Go has net/mail, but unfortunately it only allows to parse (and is not nearly reliable nor full enough for emails in the wild). 
Cheers! I'll give that a look tomorrow
You are technically correct, the *best* kind of correct.
This https://golang.org/doc/code.html#Library 
Sorry if this is not the right context to ask but, since the opportunity is here... What options are there for password-less login with AuthBoss, if not, are any plans for it in the future?
Go, as a language, is currently in the cargo-cult rush. Many people and companies will be trying to push specific coding styles, package layouts, etc. It's up to you if you want to follow the rigid structures being proposed, but don't worry, all that matters at the end of the day is what your API signature looks like. If you're writing a library, just make sure a single package holds an entire domain. If you're writing a command (binary), just make sure a single "go get" will build and install a usable working binary. How you work inside those requirements is up to you. Personally, I still like having a flat structure. If my package is "supdock", the top level would be the "main", as you have done, but it would also hold most of the domain of this app. Sub-packages are mostly useless if you're building a binary. If there is some slice of your domain that you think could make a good general-purpose library, pull it out into another package. Or don't. It's up to you, and no one will punish you for it. The individual opinions are so easy to understand and inconsequential, you can be productive in a new one in seconds.
You don't really say what state each goroutine needs to manipulate. Of course you can use one global mutext (or 3) and synchronize the access to those lists/maps. But if all the goroutine need is to manage their own users (remove user from users list when the connection is closed, etc.) you can also for example have a "command" channel (add user, remove user, other command) and the main app or a separate goroutine getting commands from that channel and modifying the appropriate structures. 
Oh wow I remember this!! Was it Broderbund Software? Either way, awesome.
sounds great :)
Dramatically more architectures? I only see x86, amd64, ARMv6, ppc64, and S390X. That's only 2 more than when the article was written and 5 in total. The GCC standard release supports 21 architectures and many more through modified releases. I'm not sure about how big the optimization difference is now compared to 2012, but GCC still leads by far in architecture support.
Might it be wise to not market an article defining a TodoAPI as 'production grade'? This post doesn't go into most of the "difficult" things to get right about REST APIs, things like database connections, testing, reusable functionality, etc. This is literally just a "Glue this router to some static http handlers." It doesn't even bring up returning non-200 status codes.
[removed]
Thought it was idiomatic go to just use `int`. 
Worked on my Mac, straight out the speakers. I'm sure I can come up with some uses for this :) thanks!
Builds and works fine on macOS, including direct audio output. My computer is now very happy.
Do you mean `GOROOT`?
I'm guessing you have a content-encoding problem (e.g. invalid quoted printable encoding), but it's hard to say without seeing the details of what you're doing and maybe the payload of the mail as received.
`sam Shall we play a game?`
It was sold by Don't Ask Software. I had it for my Atari 8-bit back in the 80's when I was in high school. I had fun with it until I replaced it with a homebrew project using a speech synthesis chip from Radio Shack. Good times. 
Can you compare it to VSCode and its Go extension please?
Gogland has everything built into it. It is an actual IDE. Vscode uses go libraries and plugins. For example, Gogland has a debugger built into it. Vs code you would have to install a plugin for it. You will get a more complete experience with Gogland than VS code. 
Use the size you need. If you need 64 bit integers, use `int64`. If you don't care, use `int`.
One thing I dont like about Jetbrain's IDE is they tend to be heavy to run.
I agree with the article, from experience. Use specific types always for data, use int only for indexes. Then you won't get any surprises if you do need a 32-bit exe for some reason. This would be a good lint checker, actually. 
This would be a good time to learn how to use the unit testing support, and write yourself up a table of input to output that you want, and check versus what it actually does. I'm not trying to deflect... I don't know the answer personally off the top of my head, and this is what I would do to figure it out. Honestly, anytime you've got a parsing task like this, you want to start building the table of expected input to output asap, because this type of code is _extremely_ prone to regression as you try to fix bugs, it even just deal with unexpected input. Not building up that test table from day one is virtually guaranteed to come back to bite you.
There are multiple methods in Go called "Scan()" which one are you referring to? ‚Ä¢ The one from `fmt`? ‚Äî https://golang.org/pkg/fmt/#Scan ‚Ä¢ The one from `bufio`? ‚Äî https://golang.org/pkg/bufio/#Scanner.Scan ‚Ä¢ The one from `text/scanner`? ‚Äî https://golang.org/pkg/text/scanner/#Scanner.Scan ‚Ä¢ The one from `go/scanner`? ‚Äî https://golang.org/pkg/go/scanner/#Scanner.Scan
There are multiple methods in Go called "Scan()" which one are you referring to? ‚Ä¢ The one from `fmt`? ‚Äî https://golang.org/pkg/fmt/#Scan ‚Ä¢ The one from `bufio`? ‚Äî https://golang.org/pkg/bufio/#Scanner.Scan ‚Ä¢ The one from `go/scanner`? ‚Äî https://golang.org/pkg/go/scanner/#Scanner.Scan ‚Ä¢ The one from `text/scanner`? ‚Äî https://golang.org/pkg/text/scanner/#Scanner.Scan
If you know the size of your data, sure, `int64` makes a lot of sense. It doesn't make much sense when your data is quite small, like the population of a city. If something can possibly be large legitimately, use `int64`. However, if `int64` is used everywhere, it distracts from the variables/fields that need to be larger. If `int32` weren't so annoying to use (needs to be casted to `int` quite a bit), I'd probably use that as my default unless something needs to be large. There's no sense in making structs larger than they need to be.
I've never used a go-aware editor (apart from syntax highlighting) -- just Vim. Never had any issues :)
Holy shit! I had this for the C-64. Makes me feel old. Oh wait...
Especially on a Macbook where RAM is pretty much restricted within 16 GB, not mentioning that System + Chrome + JVM devour 8+ GB of it. Then Jetbrains' IDE just consumes more RAM. I personally like GoLand a lot. VS Code feels really weird to me (mostly menus, key bindings, etc). Maybe it's because I have been using JetBrains for 4+ years and really just got used to it.
use a reverse proxy like nginx
You can read the changelog and see from that how it compares with the features vscode or another editor has. If you decide you want to try it, there's a 30 days trial which should allow you to test it. OSS contributors, students, teachers can receive a free license if they ask for one.
You can read the changelog and see from that how it compares with the features vscode or another editor has. If you decide you want to try it, there's a 30 days trial which should allow you to test it. OSS contributors, students, teachers can receive a free license if they ask for one.
Indeed, probably because it's written in Java?
The article appears to be the beginning of a series. We might eventually see the missing bits in one of the upcoming episodes. 
My humble opinion on this. 1. You should not feel urged to fit your project into some pre-determined structure. If you feel your code is easier to work with in a single main.go file, stay with that. If your main.go gets too large, split it into multiple files under package main, and if you find that some of the code would make a nice reusable library, make a package out of it. 2. Speaking of packages, "utilities" packages are certainly ok for private use. When publishing packages, it is preferable to have packages provide just one specific functionality, and have the package name reflect that (see [this Go Blog post](https://blog.golang.org/package-names)). 
I did check all the encoding was correct, but it's worth another look. Cheers! 
I suggest you looking in the documentation assuming you're using fmt.Scan. https://golang.org/pkg/fmt/#hdr-Scanning The documentation is quite exhaustive and provides good examples and covers even corner-cases. It is also available offline via godoc.
If you're looking for a concurrency-safe map, there is one in the sync package: https://golang.org/pkg/sync/#Map However it is a bit annoying to use at it is map[interface{}] interface {}.
So it looks like it actually was/is an encoding problem after all, I decided to go straight to the source and send the emails straight from the SMTP server and the issues were exactly the same. The code that seems to be causing the issues is: ``` Content-Type: text/html; charset="ISO-8859-1"; Content-Transfer-Encoding: quoted-printable; &lt;html&gt; &lt;body&gt; &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt; &lt;/body&gt; &lt;/html&gt; ``` specifically the `Content-Transfer-Encoding`. When I change this to be `7bit` then everything starts working again. 
Isn't that what stderr is for, or am i nisunderstanding?
It's *Goland* for a long time already!
Yeah, sorry I was using fmt.Scan just wrapped. forgot to take it out for my example. Definitely pulled out some detail there that I missed on my first read through though thanks so much
Hi! Sorry if i‚Äôm offending anyone with this stupid question... but how would I be able to write a debugging table for this? My knowledge of Go still is restricted to a bare minimum of ‚Äúgo build file.go‚Äù and ‚Äúgo run file.go‚Äù (if I even remembered correctly)
For configuration I prefer YAML most of the time, mainly because TOML gets really ugly with nested data. TOML works for flatter structures, like slightly more complex ini files or something.
Yep, fixed.
How does that work? Don't you need to push the image to a registry first?
Glad it could be of use :)
Maybe it's not a starter/framework but it's definitely worth getting familiar with templates in Go. This resource might be a good start: [https://www.calhoun.io/intro-to-templates/](https://www.calhoun.io/intro-to-templates/)
Thank you! I had it on the Atari, too. I miss my 600XL and 130XE, best introduction to programming ever.
Awesome. Like this guy üòó
oh yeah, so much fun back then :) I started on a 1200xl and then got a 130xe later. Never got into the ST line though. Instead I made the leap to PCs.
Does your case looks similar to [https://github.com/golang/go/issues/24232](https://github.com/golang/go/issues/24232) ?
[removed]
Most likely. Thank you so much, could not google this onie.
This assumes that you have a local-registry based Kubernetes running on your machine, for example Docker for Mac.
I wasn't encoding it to use quoted printable like an idiot. So it's sorted now. Cheers :-)
What is the purpose? With os/exec, I skip the shell, call the underlying executable directly. This way I don't have to escape shell-magic chars ('";...)
So in theory I should be better of using something along the following lines: ``` . ‚îú‚îÄ‚îÄ README.md ‚îú‚îÄ‚îÄ bin ‚îú‚îÄ‚îÄ commands.go ‚îú‚îÄ‚îÄ docker.go ‚îú‚îÄ‚îÄ glide.lock ‚îú‚îÄ‚îÄ glide.yaml ‚îú‚îÄ‚îÄ gorelease.sh ‚îú‚îÄ‚îÄ init.go ‚îú‚îÄ‚îÄ main.go ‚îú‚îÄ‚îÄ update.go ‚îî‚îÄ‚îÄ vendor ``` Where everything is in one `main.go` package and not spread along multiple packages like `github.com/segersniels/supdock/cli`?
In fact the main (and only?) interest is for tools like my task runner ([Orbit](https://github.com/gulien/orbit)) which accepts user defined commands. As a user will certainly copy/paste a command the same way it enters it in its command line interpreter, that's the only way I've found to make sure the command is ran as expected.
I'd rather name it `go-shellexec`. Or may be `go-shex`? ^_^ I would also try to make the README more clear: the problem with it‚Äîas I perceive it‚Äîis that the term "external command" _implies_ the shell; IOW, all commands _in a shell_ may be divided in two groups: built-in and external. When you look at a package which name mentions `os/exec`, it's hard to comprehend what "external command" is meant to mean as anything executed by `os/exec` is "external".
Does it generate go functions based on all the indexes? Eg given the employee table on the front page Does it generate go funcs to select an employee by employee_sn, by user_id, and func to select multiple employees by superior_id 
The fix is part of current Go repository tip. So you could get it by building current Go version from source. It will be part of go1.11.
Hi, currently for each unique key, a go func is generated already, like: ``` // EmployeeByEmployeeSn is used to select `employee` row by `employee_sn` index. func EmployeeByEmployeeSn(ctx context.Context, q Queryer, employeeSn string, lock bool) (*Employee, error) { // ... } // EmployeeByUserId is used to select `employee` row by `user_id` index. func EmployeeByUserId(ctx context.Context, q Queryer, userId int32, lock bool) (*Employee, error) { // ... } ``` For non-unique index, now no function is generated. But it should be easy to add in template.
Comparison with Protobuf and others would be awesome.
I like `go-shex` :D Indeed, the README is not clear enough and maybe even misleading. If I rewrite the README around the notion "a package for creating commands which use command line interpreter", would it be better? Thank you for the inputs :)
Have you changed your directory to the folder that contains main.go? If main.go is stored in your src then do this: $ cd /Users/myUsername/Desktop/gocode/src $ go run main.go
Chi has very good middleware support imo, being able to define per group or per endpoint middleware, as well as coming with a host of good middleware already
I think nobody could expect great performance on first release. In fact webasm will never reach native speed even when highly optimized.
I'd recommend Chi because it isn't a framework.
There's no performance impact, packages are purely a way to organize your (and other people's) code.
I'd recommend Beego.
I like this -- hopefully it's the beginning of a series which goes into databases &amp; testing. As someone trying to build a production API for the first time, there was some really valuable stuff in here, and I'd be keen for more info.
Vim really isn't arcane if you know regular expressions and have played Nethack -- once you've mastered the idea of there being two modes and are used to `hjkl`, you're over the toughest part. Your regexp knowledge tells you that `^` means start of line and `$` means end of line and `/` means search, and you can do search and replace using `:` mode and the `s` search-and-replace command and regexps. Most of the other commands you need to know for basic vi/vim have really simple mnemonics: `Ctrl-D` to go down, `Ctrl-U` to go up (or `Ctrl-f' for forward, `Ctrl-B` for back). `G` to goto a line (after typing its number). `{` and '}' to move to start and end of curly bracketed code blocks. `d` to delete, `c` to cut, `y` to yank a copy without deleting, and then the thing you want to operate on: 'w' for a word, `}' for a block, or repeat the character for a line (e.g. `dd` to delete current line). `p` to paste the results of your cut or yank. `i` to insert, `Esc` to escape back out of insert mode. `u` to undo. `J` to join the current line with the next one. `:` to operate on the entire file -- `w` to write it, `q` to quit, '!' to say yes I really mean it. There, that's all the vi you need for basic proficiency. In fact, one of the reasons I switched to vi was that it was so easy to remember the basic commands.
LaTeX has a package manager. It's called `tlmgr`.
[removed]
You should also pay a lot of attention to the caveats presented on that map.
[removed]
Never? ;)
It depends. It is good for a start, but as said, when you notice you have created some reusable code, refactor it into its own package. Or when you notice your main.go gets too large, split it up. A package can consist of multiple files. And as /u/metamatic wrote, cross-package calls have no performance penalties. Of course there are definitely some opinions about good package layout out there. Maybe the most popular, or at least the most cited one (don't quote me on this, it is just my personal feeling) is [Standard Package Layout](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1) by Ben Johnson. In fact, I like that approach, maybe it fits your needs.
I'm thinking that to be JS-independent is a more important thing then performance...
www√§qm√§√∂qq√§√§√§qqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq√§ qqqqqqaaa√Ñm
Non-unique indexes would be nice. And for composite indexes, eg index on columns (a, b, c) would be generate funcs to select by a, select by a, b and select by a, b, c. 
I often put together bits of code as mini projects with everything in 'main', and then when they're somewhat clean and ready for use I'll pull them into a new package in the project I actually want them for, or even put them in a clean new repository with its own package name for reuse.
&gt; there's a 30 days trial So it's not FOSS?
No, the IDE itself is not.
Something I was looking at making - don't have to now.
What is the advantage of js independence besides performance? To play devil's advocate, if you're writing go and compiling it to some other language that you never look at, why do you care if it's called JavaScript or wasm?
Chi is great but it isn't a framework. It's simply a router with support for middleware. It does include some very basic (think logging) middleware. Outside of that, you'll still be writing most everything yourself. That said I really like using Chi because its compatible with the stdlib so I could swap it out at any time. I haven't personally used Echo but I've heard good things. If you want a framework with more things built in, it's your only option between the two.
Thanks for this info. I will check how to avoid duplicated work.
There has been a lot of resistance to adding goto to webassembly because they are (justifiably) worried about implementation complexity. I think Gophers should try be a little noisy about this to show them that a lot of people would be interested. Giving a thumbs up to the linked GitHub issue would probably be helpful.
Don't set GOROOT. Not needed here. GOPATH doesn't need a manuallly created pkg or bin directory. That was more work than you needed to do. If your goal is to use the simpler "go run main.go" command, then main.go could technically live anywhere but make sure you are passing it the full path. It won't be searched for in your GOPATH. That is not how the "go run" command functions. Normally though, you would use proper project structures with a go project so that you can use "go build". That is, creating something like $GOPATH/src/github.com/user/project/main.go or $GOPATH/src/project/main.go and letting the Go tooling find it on the Go path. Or you can change directory into that location and just run "go build" with no path argument. 
One suggestion is to put the code into embedded gist's instead of pictures. The pictures may be pretty, but make it needlessly more difficult to read the code. For me, the first picture of code fills up the entire screen, so I have to scroll back and forth if I want to read the article and go to the section of code that it's referencing.
is the main package multifile? If so then run it like so 'go run \*'
IME it matters what the lower level language is. I've learned (painfully) that when language A is implemented in language B you end up having to know both A, A's implementation in B, and B in order to debug everything. The simpler B is the better. IMO JS is not simple.
I could not find an obvious answer, but maybe it was written somewhere: How are you proving that the code I get from Athens is the same I would get from the upstream repo (e.g. on github)? Are there any signatures involved? Are you a Git hosting service (in that case I could rely on the commit hash) or are you providing static ZIP files?
Getting the shell from what the user ran is going to be terrible for everyone when a developer starts getting users running tcsh or fish or whatever.
Any idea why they're doing this? Do they want to run it on arm32 blades in Azure or something similar?
The way Microsoft has gone about things over the past few years I'd assume they want to be devs choice of platform. I.e what they did with Unity, subsystem so people can use Unix albeit not the best but they're trying.
The global variables are a code smell. You should 
Dude who‚Äôs doing the port calls it ‚ÄúGO‚Äù. ‡≤†_‡≤†
Windows on ARM was starting from ARM32, I guess they still want to support the old apps now.
I'm reasonably confident that vim **can be** go aware. To the extent that you've not configured vim to be go aware, and/or used a go aware edit, I have very high confident that it would be well worth your time to do so. Just my 2¬¢ of course...
I'm a Linux user and have zero disagreement with your statement.
Which is kind of what HTTP(S) is about as well. üòÄ I cannot begin to image why you'd run a non-HTTP(S) protocol atop HTTP(S)...
Echo is New, lightweight, and easy to setup. Suitable for smaller backend app. I have not used Chi but as my colleague recommended, it seems like a much bigger choice than what I was looking for. It support templating for frontend in gola g as well, which was what attracted my friend
shouldda called it G0?
‚ÄúGo‚Äù would be most appropriate.
awesome
‚Ä¢ Use `go env` to check if GOROOT and GOPATH are correct ‚Ä¢ Use `cd $GOPATH/src` to navigate to your workspace ‚Ä¢ Use `go run $GOPATH/src/main.go` to execute the program
that first reply in the issue comments is cracking me up. "hey we ported a whole language to a new platform" "please read the contributing readme"
&gt;We were under a tight deadline What DoD contract is this for lol
Windows 10 IoT supports arm32 boards and Microsoft a couple of months ago released .Net Core for arm32. And yes the want to support developers but more importantly it‚Äôs all about azure. You may develop an IoT device on arm32 but have it connect to azure
For real, even minimal attention to ‚ÄúGO‚Äù would reveal that they missed 1.11 and have a six month wait for 1.12. So why now?
I think AWS SAM belongs in that article as well -- it's great for running your lambda locally, or even in instance if needed for some reason. You can debug with your favorite IDE and choice of language debugger, generate lambda projects to start with, and start a local api-gateway as well. [**https://github.com/awslabs/aws-sam-cli**](https://github.com/awslabs/aws-sam-cli)
How much Go does Github write?
[removed]
this can be implemented explicitly, for example check: ```go package main import ( "os" "os/exec" "math/rand" "runtime" "time" "github.com/guptarohit/asciigraph" "fmt" ) var clear map[string]func() //create a map for storing clear funcs func init() { clear = make(map[string]func()) //Initialize it clear["linux"] = func() { cmd := exec.Command("clear") //Linux example, its tested cmd.Stdout = os.Stdout cmd.Run() } clear["windows"] = func() { cmd := exec.Command("cmd", "/c", "cls") //Windows example, its tested cmd.Stdout = os.Stdout cmd.Run() } } func CallClear() { value, ok := clear[runtime.GOOS] //runtime.GOOS -&gt; linux, windows, darwin etc. if ok { //if we defined a clear func for that platform: value() //we execute it } else { //unsupported platform panic("Your platform is unsupported! I can't clear terminal screen :(") } } func random(min, max int) int { rand.Seed(time.Now().Unix()) return rand.Intn(max-min) + min } func getData() float64 { return float64(int64(random(1, 15)) * int64(random(1, 15)) / 15) } func main() { data := []float64{5, 3, 5, 7, 9, 1, 11, 5, 2, 5, 3, 5, 7, 10} for i := 0; i &lt; 100; i++ { CallClear() // this clears the content of stdout d := getData() data = data[1:] data = append(data, d) graph := asciigraph.Plot(data, asciigraph.Caption(fmt.Sprintf("Dynamic graph. New data point %.2f", d))) fmt.Println(graph) time.Sleep(500 * time.Millisecond) } } ``` 
https://golang.org/doc/code.html#Testing
5 paragraphs a day. Give or take.
What is ARM32? I can't find it from https://github.com/gcc-mirror/gcc/blob/master/config.sub . Are ARM32 and armv7 same??
Honestly, either way you go, you‚Äôll accomplish what you are after. It‚Äôs super simple to write middleware for each one. I will say one of the nicer parts about Chi is it doesn‚Äôt have any external vendor dependencies, which is super dope.
Thanks for your feedback~ I've added these functions now.
Presumably 32-bit ARM (as opposed to 64-bit ARM/arm64/aarch64), which Go just calls "arm" in its supported architectures.
They created &amp; maintain Git LFS which is written in Go, not sure if there's any other public facing projects they have in Go or what they're running in their backend beyond Ruby on Rails.
No, GO.EXE, obviously.
Top tier post mate üëå 
I try üëçüèª Erlang is the language you want.
The garbage collector doesn‚Äôt collect objects that are still in use. As long as people keep using it, nothing will be collected.
/r/stopdrinking
Hi /u/Emac24, Here's a few things that could make your life with the IDE better: &gt; 1. GoLand looks so-so. The worst IMO is highlighting setup: it is just stupid. For instance, there's no way to set some formatting for types of function parameters. You should set up formatting for local types, for exported types, for package names, etc instead separately. You can enable "Settings (Preferences) | Editor | Color Scheme | Go | Semantic Highlighting" (or "Language Defaults" instead of "Go if you want to control this for all languages) which will automatically assign a different color to every parameter, return value, or variable inside the function. And if that's not what you need, then there is "Settings (Preferences) | Editor | Color Scheme | Go | Declarations | Function parameter" and "Settings (Preferences) | Editor | Color Scheme | Go | References | Type reference | Type specification" which allows you to control this individually for types and for parameters. &gt; 2. As you probably understand, JB are not UI kings: you will probably need special setup do disable their poor animations. It is a shame they activated them at all: they are totally out of place in most platforms and just look poor. Please send us some feedback on this. Including a way to reproduce the issue and even a screencast would make it possible to understand where you have issues. Unfortunately I've been using our IDEs for so long I can't find any animation in the IDE that I can't find in any other application, so I'm clearly biased on this. Your feedback would help us understand what's going on. &gt; 3. Startup time is slow. Please follow the instructions here in order to send us a profile of your IDE startup and see if we can fix anything https://intellij-support.jetbrains.com/hc/en-us/articles/207241235-Reporting-performance-problems We've also made a number of improvements in the Platform for the upcoming 2018.2 with more to come in next iterations. If you have issues generating/submitting that profile, please feel free to ping me either on Gophers Slack or Twitter at @dlsniper or send me an e-mail at florin [at) jetbrains or open the issue on our tracker https://youtrack.jetbrains.com/issues/Go and I'll do anything I can to help you out. &gt; 4. Need special setup memory setup to avoid horrible lags when it exceeds 4Gb limit. Can you please explain why would you need to allocate so much memory to the IDE? I'm running with the default configuration (which allocates 750MB not 4GB+) and even in projects the size of Kubernetes or Moby I haven't had any issues with the IDE. We've also not received any complaints about this so far so your feedback would be very useful to trace and fix this issue. &gt; 5. Community linters are much better than GoLand's inspections. I don't actually know if you can run linting in VSCode on the fly - I have flycheck in my Emacs go-mode setup and this is the #1 thing I miss in GoLand. Their inspections are barely acceptable and nowhere near the quality golint, errcheck and other less known linters provide. We chose to add only the inspections that will not generate needless noise for users, much like `go vet` has a high entry bar for this we have ours. Also some of the checks are disabled by default but you can enable them as needed. Please let us know what checks are missing and you deem as important in order to prioritize them. You can setup `gometalinter` or any other linting tool you need via the File Watchers functionality via "Settings (Preferences) | Tools | File Watchers | + | gometalinter" (or use this as a template for other Go tools to run on save).
Thumbs up for the imitative. Thumbs down for the old Microsoft way of behavior. Tight deadlines do not override Go's internal development process. Sorry but I am not sorry, again Microsoft being the bad kid in the playground. 
Unless you are using cgo there is no Procedure Linkage Table overhead as Go binaries are static linked.
Thanks for the comments I managed to run the main.go file with this command: `cd ~/Desktop/gocode; go run src/main.go`
They're just sharing code, it's fine to call them out for not doing their homework but attributing it to malice is reaching.
Keeping the analogy, sometimes the bad kid has a disorder. But let's be honest here, Microsoft's recent change of heart is not due to enlightenment. And their port of Go to Win/ARM32 says nothing. If any I would expect more engagement into the overall development process. That's not what I see: Number of MS contributors as of Jun 30th: 1 (Paul Meyer) (check https://golang.org/AUTHORS and https://golang.org/CONTRIBUTORS) Intel? 12. Cloudflare? 6. RedHat? 5. Then suddenly, a random Joe pops up in the GH saying: "Hey I bring good news, I just ported Go to Windows/ARM32, look how good it is!". He didn't talk to anyone before, he does not participate in the ecosystem (the only issue he ever filed was this announcement: https://github.com/golang/go/issues/created_by/jordanrh1) and when called on the fact that he has done it the wrong way, what does he say? "tight deadlines." I mean, _frankly_, I cannot even begin to understand how "tight deadlines" have anything to do with actually being a citizen of the ecosystem. But hey, let's praise the good things too. I wouldn't be surprised that in the years past, Microsoft would have just made a private fork and used it internally without giving it back. Now it does. Also, I do not see any attitude in the direction of Embrace, Extend and Extinguish (although an MS controlled port could be the opening gambit). Microsoft still has a very long way to go to prove its change of heart is genuine. For now, all recent MS actions (including GH deal) are just marketing and misguided developer acquisition. Issues like this one are the reason that people loses trust in MS: they do the right things the wrong way or for the wrong reason. 
&gt; Remember when go-bindata disappeared Show me some evidence that Athens won't disappear ^^ 
"Stupid language for faggots" I'm pretty sure homophobia and intolerance should be garbage collected before Go. Whatever persuaded you to post on this subreddit? 
&gt; I mean, frankly, I cannot even begin to understand how "tight deadlines" have anything to do with actually being a citizen of the ecosystem. You are paid to do a thing: port Go to another arch. You have 6 months to achieve this. You have to do all the work and you are a newcomer to Go. Now keep in mind that to start engaging the community you have to ask smart questions (meaning you have to already know your shit to some degree) and wait for responses from busy people (meaning it takes time). Now you start writing code and it has to be a back-and-forth, with frequent code-reviews, rewrites, throwing out ideas, refactoring somebody elses code until you arrive at the code quality Go requires (not too stringent admittedly and a friendly process but it still takes time). OR you have another option: see how others did it, and just start writing code and in the process you will get to know the code-base and conventions organically without bothering anybody else. You make it work, you immerse yourself in Go, you are done with the job, your livelihood is safe and no chance of being sabotaged (with good reason usually) by other 3rd parties outside of your organization. Now you feel comfortable engaging the community and willing to do the work to get it actually merged which might require you to rewrite the whole thing. Next time you start on something you will choose to engage the community first, but you had to get comfortable first. Would it be better to start by engaging the community? Sure, in the end it would actually save time! Are you comfortable with the unknowns and worst-case decisions it might bring with it? TL;DR: When something needs to be done and quickly, you might not be willing to risk the unknowns of open-source software development. 
Lol, then half the world using Kubernetes and Docker must be faggots since both are written in golang. Besides, have you ever looked at any project on the [awesome-go](https://github.com/avelino/awesome-go) list?
There is a cause-consequence inversion. You engage with the community _first_ then make big changes later, not the other way around. The proof is that they've been told exactly that. Read the contribution guidelines, split the CL and work in the tree. They put the cart before the horses in the name of their internal problems. It is _their_internal_ problems. Not Go's - and although Go community is undoubtedly one of the most welcoming ecosystems I've ever seen there are still rules to follow. That's valid for everyone. Including Microsoft. Microsoft has really smart engineers. People that know the rules. If they are not following the rules you have to stretch a lot to not assign malice to their actions. 
If you want to see what this port looks like, check: https://github.com/jordanrh1/go/pull/1 and https://github.com/jordanrh1/go/commits/prepare-upstream
‚ÄúPlease call it Go, not GO‚Äù haha
&gt; If I rewrite the README around the notion "a package for creating commands which use the current command line interpreter", would it be better? Um, no ;-) A "command-line interpreter" is something that interprets a command-line (or command-lines). But you're really talking about what is called "a shell". The term "shell" is not too good by itself (say, Windows calls the Explorer‚Äîthat thing which manages the Desktop (and the icons on it), displays those file management windows when you hit `Win-E` etc‚Äîalso "the shell"; so it really means for the user what the shell means for a clam‚Äîsome safe place you dwell in). Both [Windows](https://docs.microsoft.com/en-us/windows-server/administration/windows-commands/cmd) and [the POSIX standard](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_01) call their respective shells in a rather similar manner: "a command \[language\] interpreter". So I would write in the README something like &gt; a package for executing commands by the current command interpreter (the shell) Have fun ;-)
It would be trivial to send an email to a couple of key Go devs to put this on their radar and get basic pointers for how to proceed before you start the project. 
Several weird formatting things suggest gofmt is not being used. 
So like rubygems.org? Still, forking the deps to your own github is the safest way.
[removed]
Dude this is Golden! I like the ZaTech idea and having a small coffee kind of conversation first
Many people use CGo without realizing it; DNS is the primary reason. But as the conversation around it shows, that PLT avoiding JIT trick is likely to down in the noise in a macrobenchmark. It was just a convenient example of JITs being faster than "normal code".
I personally like liteide cause it's all setup for you but doesn't do other things well. https://github.com/visualfc/liteide Or vscode but im not a fan of a company that charges for everything else and puts a license on something close to power of attorney. 
You probably need to specify your platform &amp; OS (e.g. Linux, Windows, MacOS). The instructions are basically the same for each platform but differ in the details.
This webpage is helpful. [https://gobyexample.com/hello-world](https://gobyexample.com/hello-world) It shows the Hello World program you can run from command line (Terminal, iTerm on Mac, Cygwin on Windows). Atom is a text editor (doesn't run programs by default) so you could write the Hello World program in Atom and save it (naming the file hello-world.go and saving it in $GOPATH/src/) before running it from the command line (go run hello-world.go). Hope this helps. I recommend Todd McLeod's online course on Go if you're committed to learning Go. [https://greatercommons.com/learn/golang](https://greatercommons.com/learn/golang). An alternative Hello World tutorial is here: [https://www.golang-book.com/books/intro/2](https://www.golang-book.com/books/intro/2) Keep at it! 
So for this set: https://github.com/go101/go-benchmarks/tree/master/benchmark-orders-matter where the middle benchmark is most efficient. Did the author remember to disable cpu scaling as shown in https://blog.golang.org/profiling-go-programs ? If that wasn't done, that's a reasonable explanation for why those results were happening. And aren't reliable. If it was done, then it's an interesting case.
thank you, that was helpful it was a bit frustrating to fail at the first step but i will keep it going
okey - its windows thanks
[removed]
You have to get used to fails when learning programming. Only learn through the fails ;)
I for one absolutely do NOT want any centralized registry. If you want to make a mechanism that stores copies of vanity.example.com/foo v1.2.3 etc, and a local proxy that knows how to use that extra store when the primary location is down or slow, that's fine. But please don't make a "registry".
Uninstall Atom and use VS Code https://code.visualstudio.com/
1 more question - how do i run something from the command line? 
In compiled languages like go with goc is you need to write your program to a file. You then need to compile it and then execute it. With `go run &lt;file&gt;` you compile and execute it in one go. On windows you probably want to use Powershell as executing it with right-click will close the terminal as soon as the program finishes. You could use a Scanln at the end of your program but that's a shady trick. In Powershell you basicly need to know only `ls` and `cd` and ofc the go compiler commands.
thank you very much :)
https://www.lifewire.com/how-to-open-command-prompt-2618089
If you're on Windows, download Cygwin [https://www.cygwin.com/](https://www.cygwin.com/) and then in Cygwin you can run Unix commands like pwd (print working directory) and ls (list files). If you have Go installed and environment set up you can then run Go programs too.
Ooh, takes me back to my earlier simpleton bytecode-VM explorations such as porting Wirth's (Pascal's) P-code https://github.com/metaleap/go-machines/tree/master/1970s-wirths-pcode --- good fun to fool around with such things! Once one writes a Go-asm (`.s`) version of one's interpreter's "main loop", I suppose things could be made mighty fast as/if one could utilize jump-to-(variable-addr) functionality, which isn't possible in Go (but is in most C impls IIRC).
Keep up the good work. I will use this as a resource. People forget teaching is learning too.
I've found that running them in a docker is the closest I can get to the proper AWS lambda instance. https://github.com/lambci/docker-lambda Though the only difference is that lambda doesn't have /dev/shm while docker will.
Udemy is a great course by Todd McLeod for people who have no knowledge of programming to start with go. You can get it for $10 and it will take you from the very beginning, including what text editor to use and how to use git. I think you would save yourself a lot of trouble by going through an organized course 
For code editor, I recommend Visual Studio Code: [https://code.visualstudio.com/](https://code.visualstudio.com/). It works cross-platform (Mac-Windows-Linux) and supports cross-language (Go - C++ - Python - R...). The UI/UX is awesome. VSCode is open-source and the community on vscode GitHub is very dedicated and helpful with their support and updates.
The results are a bit different, the middle one is not always the most performant. But orders are still matter. ``` # for i in /sys/devices/system/cpu/cpu[0-3] &gt; do &gt; echo performance &gt; $i/cpufreq/scaling_governor &gt; done # exit $ $ cd 1 $ go test -bench=. -benchtime=3s goos: linux goarch: amd64 Benchmark_RangeSlice_TwoIterationVar-4 200000000 29.3 ns/op Benchmark_RangeSlice_OneIterationVar-4 100000000 30.8 ns/op Benchmark_LoopSlice-4 100000000 51.0 ns/op $ $ cd ../2 $ go test -bench=. -benchtime=3s goos: linux goarch: amd64 Benchmark_LoopSlice-4 100000000 30.7 ns/op Benchmark_RangeSlice_TwoIterationVar-4 100000000 43.3 ns/op Benchmark_RangeSlice_OneIterationVar-4 100000000 50.9 ns/op $ $ cd ../3 $ go test -bench=. -benchtime=3s goos: linux goarch: amd64 Benchmark_RangeSlice_OneIterationVar-4 100000000 30.7 ns/op Benchmark_LoopSlice-4 100000000 51.0 ns/op Benchmark_RangeSlice_TwoIterationVar-4 200000000 29.3 ns/op ``` Looks, the results of 1 and 3 are the same, but 2 is different.
It doesn't work pussy. 
Thank you for reporting this issue. It's now fixed :) See https://github.com/albrow/fo/issues/14.
definitely interesting. If you by chance have more than a quad-core machine (rarer, but getting more common) then you have to change the scaling governor command to account for that. Order seems to still be playing a role.
Microsoft wants that IoT market share and doesn't want developers to not choose Windows for lack of tooling/languages. 
I created an example folder in the project where I will building a example application. Currently because I lack time, I only made a cli app, but the web channel should be the same effort but with templates. It's currently using a local storage as how it was requested. :)
No worries on formatting. I got the gist. That's a good point. I obviously don't have evidence it's not gonna disappear because it's impossible to predict the future and there's no technical design we can build into the thing that makes it impossible to destroy, except skynet (can someone make a terminator gopher??) Instead of coming up with a bunch of "but this time will be different!" things, we're asking ourselves (and you for your opinions on) what can we do now so that the community can recover quickly and easily if that happens? Here are our answers so far: 1. Making the thing open source (probably obviously) with good instructions on how to run a _real_ registry yourself. This is the part where you can own your own dependencies 1.1. At this point in the project, I'm personally ensuring that these instructions stay simple, especially when the system gets more complex 2. Talking to the community a lot (like in this article, and the weekly ones to come) so that folks know that they can run this thing themselves for real, not just as a little toy. Any proxy can use the central registry as an upstream, but it doesn't have to We're also trying to hedge against the project completely disappearing by making sure it's owned and run by lots of different "big" entities. If you want to go fast, go alone. If you want to go far, go together. Hope that helps.
I added a web example as well
Sorry for late reply, got my hand full with other things. I made the example you requested. :) The truth is that in practice, this was easier to me, because creating the idioms was the difficult call. I had to keep challenge myself with each step, to see if its worth it. But I have to be honest, this whole project is just my personal opinion on this subject, and I share your opinion, that most commonly abstraction leads to bigger mind model. 
Years ago I started programming in BASIC, then moved to z80 assembly. Not often I get to think about things like that these days The biggest problem with is project, and the initial one, is that the opcodes are a little ad-hoc. I knew well enough to avoid trying to handle the instructions from a real processor be it z80, 6502, or 8086, but I think if I had to do it all over again I'd start by trying to port something like [sweet16](http://www.6502.org/source/interpreters/sweet16.htm), or some p-code-like system. Something that would let me know it worked, without having to write my own programs.
Neat, there definitely needs to be more of these. Some feedback: most open source status sites seem to suffer from the fatal flaw of not integrating with existing monitoring mechanisms that are used, be it Prometheus, Pingdom, Uptime Robot, Nagios or whatever. Having a status site that is in-sync with the organization's own view of whether their services are up, down, degraded or under maintenance is important. We see that a lot of tech companies very obviously have their status sites be manually driven, because they will either suffer from false positives (which a simple dashboard simply can't account for) or they can't integrate with the company's actual monitoring systems in any meaningful way. I'm not sure why it happens, but it does. If you would like a direction to differentiate yourself with, consider allowing the dashboard using external datasources. I'd probably use it an abandon the ones I constantly make for myself to cover this need.
Very cool, but it seems to suffer the same fatal flaw as most open source status pages: it tries to be responsible for monitoring. We already have Prometheus, Pingdom, Uptime Robot, Nagios running! They are our truth of source for the status of our systems. A web page simply can't do the same job at any acceptable level. If you could allow this status site to be driven by external monitoring systems, I'd abandon my own self-made status pages in a heartbeat and use your own project instead.
&gt;great comment, many Status Page's i've tried have some fatal flaws when used long term, for example Cachet won't load after 1+ month of service issue records in database, page won't load in time for web server to respond. &gt; &gt;This project was built in Golang and requires no extra setup or dependencies, simple precompiled binary that has all assets packaged inside of it. (which can also be dumped locally for editing) This app works great on running from a small t2.nano EC2 instance, unlike other Status Page providers charging $5-7 monthly for 2 website checks. Statup lets you add unlimited, as long as your micro instance can support it. &gt; &gt;You brought up some good points though. I love Prometheus, but there has to be an application running for prometheus to scrape, but I will look into the idea of fetching data from prometheus. &gt; &gt;The idea here is to have a free Status Page under your own control, while maintaining long term availability. 
What does CL stand for?
I recommend you to sign in to the official Gopher's slack. There, you'll find some channels (like #golang-newbies) where you will be able to ask any questions you have and there is a lot of others interesting channels (#dep-users, #awesome, ...).
https://blog.golang.org/error-handling-and-go
&gt;Secretly that compiles the program then interprets the bytecode, but the illusion looks good! Same with `go run` command! Good work.
Some helper for error handling: https://medium.com/benchkram/less-verbose-error-handling-in-golang-10e2679707a2 I'm the author.
Using panic/recover in the manner you're suggesting is generally considered bad practice.
So does the command not execute with Start/Wait? Do you get any output in your file f?
It works properly as long as I don't check errors of Wait(). Why?
There's nothing bad in having a large portion of your code handling errors. In fact, if you think about it, that's actually a good thing. You can have a look at [the Go blog]https://blog.golang.org/error-handling-and-go) for further info on this and some idiomatic tips.
Don't panic
Agreed, it's bad practice, however the following is not true: &gt; Additionally a panic can only be passed a string. [https://play.golang.org/p/YgQd20Bervq](https://play.golang.org/p/YgQd20Bervq)
If you're doing a monorepo have you thought about Bazel? https://bazel.build
Great article
TIL, thanks! I'd always seen it passed strings in quick and dirty one-off tools in place of error handling like `if err { panic l("oh no") }` and hadn't checked the signature.
Thanks for pointing this out, will surly look in this to find where all i can use it. Currently i am working alone on this golang project so not needing much of a build system.
Well if you are using AWS Lambda, you can check out https://github.com/tmaiaroto/aegis ... since Lambdas run concurrently, keeping handlers all in one repo and binary is reasonable. Or grouping by some sort of strategy. You could use subdirectories with this framework too, but you‚Äôll have to write a script to run commands within each directory. Not using Lambda? Well the same ideas apply really. You can always use subdirectories and some sort of script or tool to build separate binaries and deploy. Honestly a makefile is probably enough here. Go makes it very easy to reuse code so I don‚Äôt know of any benefit to a mono repo other than convenience. I often structure my Go apps with subdirectories for common/shared stuff anyway. So another thing to think about here is are you looking for a mono binary? Or a mono repo?
Very nice. Solves the same problem [a small library I built does](https://github.com/mhoc/enveload), but much more powerful and extensible. I'm going to update the README in mine to just take a look at your's.
Thanks for all comments. Currently not using lambda, but can use it as need comes. Main reason for mono repo is convenience so i can have all code at one place to change. Wrote main.go in root project which help different binaries of each service. Mono binary is interesting to think with mono repro but multiple services, currently not thought anything in this side but any comments welcome here. I am thinking, i need to write routes in such a way that i can merge them for mono binary and based on config use same binary for different service. Did similar in java but for go still exploring. Please share if you know any mono repo microservice examples which can help as a guide. Trying to keep utility function, core library integrations in common/shared part.
Nice. There a lot of library trying to solve this perticular problem. Will give it a try. A quick note I would prefer something which try all backend and choose the prefered method. Reverse logic. 
The build system needs to be thought out at the beginning like this or else it will become hard to use one. My main issue with a mono repo where I work was getting your build tool to know when to build which service, because it's dependancies have changed. While you can easily do this as a human an automated tool becomes combersome as you add more and more services or your team gets larger and larger. Where I work we chose to use a central library of code and make each service an independent repo / build (making sure that the version of the central library is in the dependancies for each service and it's upgraded over time. Hope this helps! 
Valid and thought provoking point, will look in build system. Currently i have wrote a main.go in root folder which does binary creation for a given service. We have a small team at work and have both models, having different repo and doing changes in multiple of them at the same time is pain, as you need to add code in all repos, but while have all in one repo is little easy to do as you can do them in single go and reuse some of the code.
Mage is a make-like build tool but in go. I like it. One thing about go that is both good and maybe bad is that you‚Äôre entire local GOPATH directory acts a monorepo. I.e, if you change code in a different project and rebuild another the changes are reflected immediately UNLESS you‚Äôre vendoring everything. You could try various libraries and mix a vendor/not vendored for prod/dev. I was recently trying to convince my colleagues not to use a monorepo because of all the trouble it causes with conflicts, errors, in unrelated code and undisciplined coders (push permissions). 
I've just found out what is causing this is nothing but `signal.Ignore()`. It is supposed to handle the incoming signals to the program itself. In my case, it is affecting an externally executed program's progress. I've created an issue: https://github.com/golang/go/issues/26172 
I mainly work in java at work (starting go for personal projects), there we found that if you don't let any code merge in main branch without review then you are good with mono repo but if anyone can push anything then single bad push can block everyone. If small team working on many repo, i found mono repo useful or else different projects for each service is good.
Are you control-c or otherwise sending a signal to the program? If so, the signal handler is killing all the children and could be causing your race condition.
No, I am not sending any signal to the program. The mere existence of `signal.Ignore()` causing this. 
Thanks for adding doc snippets, just saying "RTFM" is not a good experience for people new to any topic..
[removed]
[removed]
Confita tries all the backends actually, it tries all the backends one after another until it finds the key. If you want it to call only one backend for a particular key you can also do that. 
FYI cddy is a webserver like nginx not so much as a framework.