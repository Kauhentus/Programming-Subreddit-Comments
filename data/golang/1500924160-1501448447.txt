I set an HttpOnly cookie but when the callback returns the cookie does not exist in the request.
You're doing something wrong then. Setting the cookie expire time correctly?
I've tried with no expire time, with 1 hour and 5 minutes but still the same. What's a good expire time to set for this? Could it be that the cookie does not "survive" the redirect?
&gt; Go on the other hand, is simple as a language, because there is quite a lot of magic that's going on behind the code which maps the simple code to the complexities of more low-level computing. Go's runtime is substantially more complex than that of C, C++ or Rust (they basically have none). That's the reason the programmer doesn't have to think about so many complexities, the runtime and language does it for him. Did you watch the video? That's what Rob Pike says. That's why simplicity is complicated.
`for i = 0; i &lt; len(v); i++ {` This for loop will also have the last loop at i == len(v)-1 you kinda need `for i = 1; i &lt;= len(v); i++ { ` Alternatively you can use a two item range loop. for i, v = range vs { if v.str == ... { break } } // then look at this after the loop? if i == len(v) { // never executed }
Is there a reason you don't do: ``` for _, val := range v { if val.str == ... { break } } ```
This was probably a missed change after 1.2, as I'd expect bytes.Split() to do a recap() on all but the last slice like: https://play.golang.org/p/9NLRB-ei1S Edit: Thinking about it another minute, it's possible the change was rejected due to backward compat?
Operator overloading example is not a good one. Why is `keyVal["bar"]` better than `keyVal.Value("bar")`? This solves 0 problems in Go programs right now. Support for `range` would be nice but it doesn't need operator overloading. As the author explained, it can be extended by implementing a "ranger" interface perhaps with eventual generics but operator overloading is not really needed at all here.
I guess this is also meant for u/porkbonk The *best practice* is to serve files with a completely new url i.e. change the filename e.g. `example.com/myfile.$hash.png` or add a cache-busting query string e.g. `example.com/myfile.png?$hash` - preferably the former. Here `$hash` could be a md5 hash of the file or hash of the filename and the last modified date if that's too expensive,. EDIT: you'd then set the appropriate HTTP headers to tell the browser that it can cache these files forever.
&gt; I've heard it would require an entire rewrite of the compiler, and would require a lot of changes to the tooling and even standard library. That doesn't really match with your original comment; you do say that complexity will be involved, but you don't specify how, which is pretty significant. I'd be curious to know what exactly about the compiler itself would make it require a rewrite. &gt; You also seem to be under the impression that I'm oblivious to the "cargo cult-tier justification" in the article. Nope, any mention of cargo culting was solely at your initial comment and had nothing to do with the article at all. &gt;Perhaps if you actually read the article, you might have realized that the main pro-generics argument could also apply to weakly typed languages, and you might have noticed my sarcasm when I misquoted the original article. Perhaps. However, your assumption that the article actually needs to be read as far as this debate is concerned is false, and using my lack of reading it as an argument is fairly weak to be honest, because what I said to you had absolutely zero intent of being correlated with the article itself. Your interpretation of it being that way is at most coincidence, but it isn't my fault. &gt; My point is that those who actually work on Go might not feel that generics are sufficiently beneficial for them to actually implement and maintain them. And that would be a valid justification for them not to implement them. I still think it's a flawed argument. Those who work on Go have a considerable amount of resources that exist far beyond just a few academic oldies sitting around with limited funding - this is Google we're talking about, after all. Separate teams have existed in the past for this kind of rewrite: you have developers who continue to maintain the stable branch, and developers who go off and do whatever is necessary to produce a working version of the compiler with Generics support. Which also leads me to this, &gt; Cheney worries in his article that the transition to a Go with generics risks fracturing the community. This makes absolutely no sense, considering that feature addition like Generics can be implemented in such a way that it doesn't break backward compatibility. &gt; Claiming otherwise just reeks of entitlement because you're free to implement it yourself. Actually it doesn't, because I'm fully aware of my lack of entitlement: I really don't care whether or not Go has generics, because I'm not a Go programmer. That said, my whole point is based on the premise that Generics being implemented _as an official language feature_ are what's important. The reason for this is because it's guaranteed support and maintenance by more than just one person in the future, _and_ that support is coming straight from the horse's mouth and not some ragtag group of coders who don't have time to commit 40+ hours a week towards Go in general. I've already heard of people who have forked the Go repo and hacked on some ghetto implementation; obviously, these haven't made it upstream. Which implies that there's no guarantee that forked, unofficial implementations with Generics are particularly worthwhile in the long term. 
Gom, nom, nom, nom, nom, nom, nom
Cool, I didn't know about the third slice argument! I'll create an issue for this tomorrow with that as a possible solution. I doubt backwards compatibility comes into play here. This behaviour is extremely surprising and when appending too much at once a new slice will be created anyway, because then the full capacity is exceeded. EDIT: I created the issue: https://github.com/golang/go/issues/21149
OP is looking to use the index value after they complete their loop. Eg, to maybe so they know what items haven't been processed by the loop to handle the leftovers separately. The issue they ran into is that using *range* does not give the same ending index as using a simple incrementing *for* loop comparing vs slice length. So if you have a slice of len(v)=5: * *for i = range(v){}* over the entire slice will end with an index of **4** (len(v)-1). * *for i = 0; i &lt; len(v); i++ {}* over the slice will end with an index value of **5** (len(v), after the conditional fails and the loop exits). More info about the behavior for range is specified in https://golang.org/ref/spec#RangeClause &gt; the range loop produces iteration values from 0 up to len(a)-1
An HttpOnly cookie will survive a round trip to an OAuth authentication endpoint. You'll have to use the browser debugging tools to work out what's going on.
[GopherCon 2017: Fatih Arslan - Writing a Go Tool to Parse and Modify Struct Tags](https://www.youtube.com/watch?v=bUznDnBboCs&amp;list=PL2ntRZ1ySWBdD9bru6IR-_WXUgJqvrtx9&amp;index=5) -- watching now , seems like a really useful tool
I am already using the dev console. When I get the callback back from github the cookie is not set. If the cookie survives the round trip then I am suspecting that since I am working on localhost, the cookie does not survive changing protocols from HTTPS on github to HTTP on localhost.
Ah, now I see the problem. [You can't set cookies for localhost](https://bugs.chromium.org/p/chromium/issues/detail?id=56211).
It's the same on Firefox. I can set the cookie just fine, it just disappears after the round trip. I think it might be the change of protocols issue.
&gt; On the other hand, the horseless carriage can only reasonably provide carriage – you're going to have a bad time pulling a plow with it – but with minimal maintenance it can do that one job really well. Sigh. The metaphor is strained to start with, but the above is just flat out wrong. Farm tractors have a power take off that can drive all sorts of accessory devices. A tractor can't help with every job on a farm, but it comes pretty damn close. Likewise there's plenty of rural folks with an old farm truck with a hitch and PTO for the same reason. This idea that a horse is generic and a combustion vehicle is single purpose is purely your own. I also guarantee you've never had the task of convincing a horse to do a job it didn't wanna do.
Okay I deployed the program in a production server so now it serves HTTPS. The cookie now survives the round trip and works fine! Thanks a lot for the help! Do you happen to know how safe it is from a security perspective to store that state token in a cookie assuming HTTPS? I am using an HttpOnly and secure cookie and an expire time of 5 minutes. Any recommendations or best practices for security? 
And now with parameterized middle-ware……………… Why not just? func DontCache(next http.Handler) http.Handler { return http.HandlerFunc(func(res http.ResponseWriter, req *http.Request) { res.Header().Set("Cache-Control", "max-age=0, no-cache, must-revalidate") next.ServeHTTP(res, req) }) } func Timer(next http.Handler) http.Handler { return http.HandlerFunc(func(res http.ResponseWriter, req *http.Request) { start := time.Now() next.ServeHTTP(res, req) log.Printf("%d %s", time.Since(start).Nanoseconds() / 1e3, req.URL.Path) }) } func main() { var h http.Handler = Server{} h = Timer(h) h = DontCache(h) http.ListenAndServe(":80", h) } It's the same effect, you save a type, it's the same amount of code and you are more flexible. E.g. func Delay(next http.Handler, d time.Duration) http.Handler { return http.HandlerFunc(func(res http.ResponseWriter, req *http.Request) { time.Sleep(d) next.ServeHTTP(res, req) }) } func main() { var h http.Handler = Server{} h = Timer(h) h = DontCache(h) h = Delay(h, time.Second) http.ListenAndServe(":80", h) } By putting the chaining logic into a type, you are restricting the possible things people can express unnecessarily; http.Handler is a powerful interface, just use that and wrap it, like you would an `io.Writer`.
Ah, thanks for the explanation!
There are no default fine grained latency heuristics for method boundaries.
To the other person that posted a message here: you appear to be shadow-banned.
If you use bytes.Split, as the returned slice is not a copy. If you create a definition of the slice by hand, you'll see that your example starts working as expected. [ref: go playground](https://play.golang.org/p/vh7XVgXH4S). This is because each index is now it's own, independent slice, with it's own array of data. As `bytes.Split` says: &gt; Split slices s into all subslices separated by sep and returns a slice of the subslices between those separators. If sep is empty, Split splits after each UTF-8 sequence. It is equivalent to SplitN with a count of -1. So you're getting subslices without allocating or copying to a new slice. This is documented behaviour of slices [ref: slice internals](https://blog.golang.org/go-slices-usage-and-internals#TOC_4.). Effectively, you're doing the same as here, without the bytes import: [ref: playground](https://play.golang.org/p/sbL_vXaQeT). Each index holds a slice which is a triplet with a pointer to the original array. This is well documented in slice internals, but I do agree, it's a confusing and tricky gotcha, if you're not paying attention :) I have a post about it lined up on https://scene-si.org in the following days, with some additional gotchas :)
Yep, profiling is a sample. Perhaps this can be obtained from trace data? Maybe not. I'm with you on this 100% :(
&gt; Go is not complex, because there is very little magic between what the code says on the screen and what the code does at runtime. Thus the programmer maintains less complexity in his/her head. It is by no means so clear cut. For example in languages that support general collections and a map/fold/reduce api, I can write code that is extremely clear, succinct, and written in a largely side effect free functional style. In golang instead I have to use more boilerplate, and the intent becomes obscured with irrelevant details and choices like what names I pick for loop indexes, etc. While I am very aware of the problems of "too much magic", there's a HUGE middle ground between that and where golang is today, and there are many changes we could make to golang that would significantly reduce the mental workload of golang coding.
Add the file timestamp or a checksum into the URL, either as a query parameter or part of the filename. This is basically how it's worked for decades. The advantage is that then you can tell the browser that it never has to check the file again by setting a far future Expires or very long Cache-Control max-age.
If you look at the issue on the bugtracker you can see that the proposed solution still uses slices. The only difference is that it doesn't let the capacity overlap the difference slices: https://play.golang.org/p/VonjdLUymU
I'm sorry, I don't pay much attention to Starwars-style wisdom :)
Depending on how accurate your server clock is going to be, you might want to set the expiry time shorter. I assume you're already keeping a server-side list to prevent the cookie being accepted twice (replay attack). You could encrypt and sign the CSRF token for added security, but assuming you've made your tokens hard to guess and you're preventing replay attacks and using OpenID-style OAuth2 token exchange, it's probably not necessary.
does `FromString("00000000-0000-0000-0000-000000000000")` not work? Or just `var myNilUUID uuid.UUID`?
Borrowing and lifetime annotation are particular to Rust's memory model. Go is a GCed language, it wouldn't have anything of that even if it borrowed (pardon the pun) most other things from Rust. And it's that memory model that causes that mental overhead you speak of. Having most data as immutable eases concurrency tremendously, but obviously, the keyword is most, not all. Immutability makes handling data easier, not harder, as it drives you to treat your application as a data processing pipeline rather than a coordination of subroutines, mutexes and so on. I'd suggest you try out a pure FP language if it's hard to see the benefits. I've always heard about FP concepts but never understood how it really helped application design and development until I started learning Elm. It also makes React+Redux, Vue.js and other modern frontend frameworks easier to understand since they all sit on functional programming paradigms.
Hmm. Looks pretty similar to when I wrote this, except more in depth: https://github.com/alistanis/st
Looks pretty awesome. Will download and use to remotely track files on the NAS
&gt; And it's that memory model that causes that mental overhead you speak of. No, it really isn't. But your mileage apparently varies. &gt; I'd suggest you try out a pure FP language if it's hard to see the benefits. I did. I found it unbearable. That is literally why I don't want these kinds of "features". And I still don't understand why people are trying to make go a Haskell. We already have a Haskell, we don't need another.
You should use a flag to make the intent clear... found := false for _, e := range v { if e.str == ... { found = true break } } if !found { // the element was not found }
&gt; No, it really isn't Why would you bring it up alongside immutability then? They are not married to each other. &gt; And I still don't understand why people are trying to make go a Haskell Haskell is a lazy research language with a lot of legacy that embraces complexity, they could hardly be farther apart. I may be wrong, but I get the impression you tried to learn Haskell which is a huge departure in every corner (syntax, purity, immutability, operator-heavy and so on) from traditional C-inspired imperative programming and associated its difficulty with functional programming. Adding immutability would bring Go closer to OCaml (or Facebook's Reason, if you want to skip the syntax difference) if you had to choose one language, except OCaml also has its share of legacy, is far less opinionated and doesn't even have a parallel concurrency implementation. Go is in a very particular situation where immutability would help it follow its concurrency model (CSP) tremendously, and follow its ethos of simplicity. Haskell makes it hard to see how this fits in, but look into Elm or look into Clojure and you'll see how much simpler things become when mutability is opt-in, rather than having to deal with the mental bloat of mutability where you don't need it.
Thank you! If you have any suggestion, I'll really appreciate 😀
One difference is the order of the middleware which is often important. For instance in your last example, the timer happens after the delay for each request which may be intended but isn't immediately apparent given the order of the statements. I do like the http.Handler references and prefer them over the (ridiculously) verbose function signatures of the original code
&gt; and does not index into the array or slice itself. What does this passage mean?
&gt; https://www.jetbrains.com/help/go/faq.html I understand Gogland is more than just the go plugin. But its built on top of Intelli J too, right? Will some of the Gogland code be available to install in other Jebrains IDE from the JetBrains Family? Much like the plugin has been, and the other Jetbrains IDE's tend to do (to some capacity)
If you have only 1 variable on the left side, `range` will only give you the indexes into the slice, not the actual values. To get the values, you need to supply 2 variables on the left side - one for the index, and one for the variable. Hope that was clear.
Were you expecting range to go past the end of the slice? Remember, the last element in the slice is at index `len(v)-1`, not at `len(v)`. 
I see no issue with this. They have a competing product that they can make money off of - remember, they are a for-profit company. They fact that they have open sourced the older plugin and will accept PR's is above and beyond, IMO. 
As mentioned in the FAQ, yes, it's possible to do it since the end of March, see https://blog.jetbrains.com/go/2017/03/22/gogland-eap-7-faster-completion-package-rename-2017-1-platform-features-plugin-and-more/
&gt; For instance in your last example, the timer happens after the delay for each request which may be intended but isn't immediately apparent given the order of the statements. I'd say, quite the opposite. The chaining in my main makes it very much immediately clear what the order is in which middle-ware is applied. When reading the code, I'll see that `h` is passed to `ListenAndServe`, which is set to `Delay(h, time.Second)`, so the Delay middleware will be the outermost layer and wrap the previous value of `h`, which was `DontCache(h)`, so that'll be the next layer and so on. As the functions explicitly wrap handlers, they make an enforced dependency-order clear. Compare that to your custom type; from `main` it isn't obvious what the order is, that the defined middlewares are applied. It *could* be source order, it could be inverse source order, it could be alphabetical order, or random order or… To actually *know*, I have to look at the definitions of `Attach` and `Finalize`. The latter even has contrived logic, further hiding the actual order used. You are iterating backwards, what does this mean? In what order where the things appended again? And how does the chaining then order the handlers? Your code, at the very least, will require a doc-string explaining the order in which middlewares are applied, to clarify it (or, alternatively, readers of your code will have to *guess* an order). These are very similar arguments that I am making [against using routers/muxers](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html). Putting this logic in its own type is an unnecessary, leaky abstraction. Just another moving piece whose logic I have to understand when reading your code, when I also could just look at obvious imperative logic in the programming language I understand anyway. Leaky, as it is forced to restrict what logic is expressible, so as soon as I need something even slightly more complicated (like configuring my middleware) it falls apart. Unnecessary, as it doesn't even reduce or simplify the code you are writing. YMMV of course. There is no accounting for taste. But I very much prefer using simpler tools if I can.
Went to last years, thought a couple of the talks were very good. Anything stand out in anyone's opinion for this year?
&gt; https://blog.jetbrains.com/go/2017/03/22/gogland-eap-7-faster-completion-package-rename-2017-1-platform-features-plugin-and-more/ Sweet. installing.
I have done this where I had complicated templates to generate some fairly abirtatry json. Then wanted to modify it. The code to take that and remove the pieces I didn't need this time where a pain. Now maybe I should of done something different but it being so hard to do anything is painful. Other languages have easier ways to do things like this. C# for example has JObject, which made similar things much easier.
You can also use the IDE if you want, it's tailored to Go projects. 
Abstractions often appear unnecessary when reduced to their simplest possible use case. I agree that your example is the simpler solution. I purposefully chose the title "Easy Middleware in Go" and not "Simple Middleware in Go" because I was pretty confident that what I had created was not as simple as it could have been. Thoughtful responses like yours are part of the reason I created this post. To (in?)validate my approach and learn from people who might have more experience building and maintaining large golang code bases professionally. This type was created in order to allow other parts of the code to attach middleware from outside of main, so this DispatchHandler reference is being passed to a number of plugins that might want an opportunity to attach middleware during initialization. The same effect probably could be achieved by passing a reference to the http.Handler instead, but the abstraction was intentional. I wanted to remove any specifics about how the middleware is composed from areas of the code only concerned with ensuring their middleware gets popped onto the stack. Should one of these plugins need to be initialized before another, I wanted to make sure that the attachment of middleware happened in the same order as plugin initialization. I'm not sure this justifies the abstraction, just wanted to give some background on why the type was created. PS. I read your mux article when it came out. Switching on path prefixes allows extraction of data within a URI path but I chose to remove data from my URI paths entirely and just use a map. The code for the app is up on github in case you ever feel inclined to give it a read. https://github.com/teambo-org/teambo It's 5,000 lines of Go and it only includes 3 external packages (gorilla/websocket, a javascript minifier and a database driver (goleveldb)) 
Ohhh, that. I knew the spec was doing that but the words just wasn't making sense when I was reading them. Thanks for the answer.
I agree. I'm going to binge-watch these like they're Battlestar Galactica.
Yeah, but it is going to go commercial. I don't want to get used to or spend time learning something I'm eventually going to have to lose access to. I already paid for rubymine.
Some examples would be nice.
Yes, they would be. Reading the code would be better, especially since there is an example of sorts in the tests which is just as good.
Hi, I noticed [this](https://github.com/hacdias/filemanager/blob/master/auth.go#L153) in a auth related file and that hints something may not be implemented properly. I am on mobile though so can't really search for where it is used right now, but if it's for something like a session token it's insecure. Next up I see [this](https://github.com/hacdias/filemanager/blob/master/filemanager.go#L374) which appears to default to true which seems like a possible mistake. Next [this](https://github.com/hacdias/filemanager/blob/5f883a629e1eb453978a2c946b554d80ec5e7107/resource.go#L124) appears to have even worst consequences if a user who try's to delete path such as ../../ etc. From what I could see most your file system checking are not safe and I see no tests to hint that you are covering things through extra indirection I can't easily track. At the end of the day you should have a single method that has a single invariant under any circumstance: ensure file system access is always rooted to a base directory. From there you can add methods to maintain the same guanrantees on a per user basis. But as it stands it's too hard to audit with strings checking for slashes all over the place and what not. I have a lot of reviews for security related stuff for fs and auth in my post history if you want to take a look or if you want me to look further just ask.
We're using gRPC error types to classify our errors https://godoc.org/google.golang.org/grpc/codes
nice to put voice on what was before just a fun Twitter account! my infrastructure is a mess right now of custom systems for deployment, orchestration and monitoring on top of LXC and we're interested in moving everything to kubernetes+docker. What would you recommend me, both as a way to learn about what kubernetes does and how to use it, as well as dig deeper on its internals and on _how_ it works? Something like, halfway between reading an introductory book and actually reading the kubernetes+docker codebases line by line. Is there anything like that?
Because Go is designed for Google and only incidentally is it useful to others. 
Yeah!!! thanks!!!
https://github.com/kelseyhightower/kubernetes-the-hard-way
Antipatterns was so packed I couldn't go in.
YES! thank you!
Yes, this is entirely an intellectual endeavor on my part. I've probably learned more from this project than any other I worked on. The algorithms in computer algebra are fascinating to me. I've seen recursion in places I never would have expected. I've realized that expressions can and must be hashed into integers for efficient matching. I've seen that a huge fraction of derivatives can be solved with less than 10 rewrite rules. But don't get me started on integration. There are many other things that I've learned. I haven't thought about writing a blog but it would be nice to put my findings down for other passers by in the computer algebra space.
Yep - Kelsey removed the AWS things.. but my blog is not a half bad starting place for k8s on aws https://nivenly.com
yeah I saw a video of kubicorn running two days ago - very nice! too magic for me right now though, I'm interested in learning how things work lol I do follow your twitter, so looking forward for more lower-level stuff!
Pointer types allow you to differentiate zero vs missing json values.
tight
This taught me a lot. Thank you. Maybe also example of testing HTTP client?
Note that the author did NOT write "We are not interested to solve (1)". 
Sometimes there is no choice. 3rd-party services impose JSON onto you even if you would rather prefer something like gob, protobuf or flatbuffers.
...but mitigated through struct tags.
...ok?
Did you really start r/golang to act like stupid people 24/24?
read that as "bug that caught me with rage" :D
I conclude you misunderstood the cited statement as "We are not interested to solve (1)", because otherwise your allegation would not make sense.
Hello epiris! Thanks for your reply :) 1. So, the function 'randomString' is used to create the variable [key](https://github.com/hacdias/filemanager/blob/master/filemanager.go#L30) which is used to sign JWT tokens. It is generated only in the first time when there is no database file. 2. The user is allowed by default to access every directory, so it is correct. That function first checks the rules and then returns true if no rule matched. 3. User.FileSystem is of type webdav.Dir which, I think, does that check in its own [code](https://github.com/golang/net/blob/master/webdav/file.go#L58) so I won't need to repeat it. I have tested doing requests for those kind of paths (../../) and it didn't work. Correct me if I'm mistaken :) And tell me if you think I should improve something, either about the security or something else. I still have to do tests: I haven't seem much how to test this kind of functions and http handlers but I know it's possible. I have to do that.
The slides (extended version with code examples) can be find here: https://speakerdeck.com/farslan/building-a-go-tool-to-modify-struct-tags And here is the repo for the tool itself: https://github.com/fatih/gomodifytags Let me know if there is anything else, happy to answer them :)
Excellent suggestion. That would indeed be more readable. I'll remember that solution. 
Maybe, I don't see what you imply. Why is this relevant? Also I don't why that could change (if it was a problem).
Key needs to come from crypto/rand and not math rand, or all someone needs to do is guess when the server started. For the third, good job if your using those methods everywhere safely, I didn't see the WebDAV fs. I think tests would help show any areas ya may have missed, httptest will make things pretty easy when your ready to take it on. Good job though on the file system access, first project I've seen in a while that even tried to :-) have a good one.
I didn't knew that. Do you know why it's like that ?
You are right, but I wanted i to iterate from 0 to len(v) while looping. This is because I'm scanning the elements of v to find something. When the loop ends, and we use the C like for loop, i is incremented and equal to len(v). I use this condition to determine if nothing was found. Otherwise i &lt; len(v) because of the break instruction. The suggestion to use a found bool would make the code more readable and the intent clearer. I could also have written this itemPos := -1 for i := range v { if v[i].str == ... { // item found at i itemPos = i break } } if itemPos == -1 { // item not found } I also didn't want to use the two item range because v is a slice of struct with four fields. It would have copied the struct just to test one field. That is why I use only the index. If v was a slice of pointers to the struct I would have done as you suggest. Thank you for the help. 
Actually, it's quite easy to create/build/start docker containers using docker API. See: https://divan.github.io/posts/integration_testing/ and I now use this package a lot: https://github.com/ory/dockertest 
Is copy-pasting code and spamming `if(err != nil)` like an idiot are simple/genius now?
Nice. Just to share that too, I also implemented something like that some time ago. Main difference is that the reader supports seeking, it's based on AEAD and defaults to using ChaCha20 (but can use AES too). Sadly I was too lazy to make it an own library. Here's the code anyways: Writer: https://github.com/disorganizer/brig/blob/master/store/encrypt/writer.go Reader: https://github.com/disorganizer/brig/blob/master/store/encrypt/reader.go I might take a more detailed look into your implementation later. :)
Your message has helped me realize something... there are two kinds of complexity and we might be talking about different ones. Take the line "a[i] += 1". For the programmer who is trying to read it and construct a mental model, there is very little magic in that line in Go: it says, "go to the ith element of the slice or array called a and if the types allow it, add the constant 1 to it". But for the compiler and the runtime, there is a huge amount of magic there. First, a is probably a dynamically sizable type, so there is type info in the runtime allowing the garbage collector to treat it correctly. The index has to be range checked, which might happen in the compiler if it manages, or it might need to delegate that to the runtime to happen later. And the compiler needs to find out if the add is even defined, and if so, it needs to coerce the constant that appears in the text of the program into the constant that will be needed at runtime. If we look at that line from the point of view of a C++ compiler, there's no memory management magic, nor any runtime bounds checks that it needs to arrange for. The compiler does have to analyze the types and Do The Right Thing with them (i.e. apply overloaded operators and convert the 1 to the right constant in the program text). The human who wants to build a mental model of that line in C++ needs to think about all the things the compiler is excused from ("does a still point at usable memory?", etc) and also they need to be aware of the overloading in effect, if any, for both [] and +. Anyway, thanks for helping me see those two different kinds of magic that effect programmer productivity differently. 
&gt; Depending on how accurate your server clock is going to be, you might want to set the expiry time shorter. I don't know how accurate a server clock is or how to check that. I am currently deploying on Ubuntu 16.04 but I suppose it could be deployed on any other server. How short are we talking about? How about 30 seconds? &gt; I assume you're already keeping a server-side list to prevent the cookie being accepted twice (replay attack). I have no such mechanism. I am using HTTPS and an HSTS header. Could you elaborate on this please so I can implement it? Right now there's a login handler and a callback handler. The login handler generates a random string (the oauth state token) using [this method](https://elithrar.github.io/article/generating-secure-random-numbers-crypto-rand/) and stores it in a Secure, HttpOnly cookie. Then the callback handler searches for that cookie and checks if the state token returned from github matches the cookie value. What kind of list do I need to keep on the server side? What should it prevent? &gt; assuming you've made your tokens hard to guess They are generated using `crypto/rand`. Does that make them sufficiently hard to guess? &gt; and using OpenID-style OAuth2 token exchange, it's probably not necessary. I am using https://github.com/golang/oauth2 to do the oauth2 exchange with github. Is that OpenID-style? Thanks!
Hey! Thank you again. I just [changed it](https://github.com/hacdias/filemanager/commit/eb0126764317528cca76175a4bb20a881a50ecc2) to use crypto/rand. I'll try to start doing the tests later today. Thanks for your feedback! :D
Hey, I briefly skimmed through your code, and a couple of things jumped out at me: * The ciphertext here is not authenticated. That is to say, an attacker can mess with the ciphertext, and your program will still decrypt the data successfully (with the plaintext being garbled). This is generally not what you want, since the common standard for cryptography is confidentiality *and* authenticity. I would build a construction out of an AEAD instead, as its more fool proof. Also, this is prone to truncation attacks (i.e. if your encrypted data is N blocks, the attacker can drop the last block, and it'll still decrypt successfully). * If you really want unauthenticated encryption of this form (and you almost definitely do **not**), I would instead use cipher.Stream(cipher.NewCTR(...)). * You need to check more errors. In particular, in Close(), you need to check the error on the final write, otherwise a client will not be aware of errors writing the padding. * Go generally uses just regular "//" comments, not Javadoc style "/** ... */". Also, the convention is to just use prose, not tags like "@param". * If I were you, I'd add tests. At the very least, a "round trip" test, which checks that Decrypt(Encrypt(e)) == e. There is enough relatively intricate code here, dealing with buffering and other concerns, that I would classify this as a home-grown crypto. This either needs to be simplified greatly (compare this with something like https://github.com/gorilla/securecookie/blob/fa5329f913702981df43dcb2a380bac429c810b5/securecookie.go#L390 for instance) or add a prominent warning that this is unreviewed, untested crypto. I'm sorry, I really don't want to be discouraging :( If this weren't crypto-related, I probably wouldn't have taken the time to comment. But, this is a relatively dangerous arena, and I think you want to tighten your code significantly before encouraging anyone else to use it. Good luck!
&gt; Is copy-pasting code and spamming `if(err != nil)` like an idiot are simple/genius now? Error handling is part of programming.
Hey, thank you for your great talks and your amazing work on vim-go. Do you know of any good resources (Books, papers, blogs, other code-bases..) for language-tooling and code-analysis in general, in order to dive deeper into the topic?
Just like logic.
I liked the Antipatterns talk as well. Talks of this kind tend to repeat themselves over time, but I think they are a great resource to remind one, in certain intervals, to re-check some assumptions and practices. :)
I like the light-weightedness of editors and have found the go toolchain to work quite well even on the commandline. Could someone who uses an IDE (instead of an editor like vim/emacs/visual studio code) for Go explain to me the perceived benefits of their preference?
I have a switch (actually a zero length file with a special name) to always have tests run with the sqlite driver, instead of a remote driver. Reseting with test data for every test and still all tests runs in a very, very short time.
Hi, thanks a lot.. I don't panic in real life code, I figured every one should get that part, maybe I was wrong.. Thanks a lot. I would update the post as per the panicking.. And the `Clear` method also..
Thanks! I've gave another talk that is more in detail and shows how to start writing a tool. Here are the slides of the talk: https://speakerdeck.com/farslan/how-to-write-your-own-go-tool and here is the recorded video: https://www.youtube.com/watch?v=oxc8B2fjDvY Besides that the best way to dive into this kind of thing is to look into existing tools and how they did. For example gofmt. Unfortunately there are not much documentation around this. 
Video linked by /u/farslan: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [GothamGo 2016 - How to write your own Go tool? by Fatih Arslan](https://youtube.com/watch?v=oxc8B2fjDvY)|Nation Conferences|2016-12-10|0:23:19|37+ (97%)|2,406 &gt; How to write your own Go tool? Go tools are very powerful... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/farslan ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dkos3qg\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.3b
Downvotes on youtube don't mean anything, other than that the internet is a stupid place full of stupid people. (Except you and me, of course.)
Here's a really great book I always recommend to anyone who's never read it: *RESTful Web Services* by Leonard Richardson and Sam Ruby https://www.amazon.com/dp/0596529260
I agree with shoegaze. Your behavior might be forgivable if you participated in the posts you create but from what I can see you typically post a question and often don't respond to comments on the thread from people willing to help. It also sounds from your other posts like you might be better off taking a course in basic programming rather than asking simple questions one at a time on reddit. &gt; -3 comment karma That gave me a laugh. I've never seen a reddit account with negative karma.
Indeed. What is your point?
Wow, that *is* actually unexpected. Even if it's what's in the spec. I wonder why it was done this way, I would've expected the range to compile to the equivalent of `for i = 0; i &lt; len(v); i++`. Only thing I can imagine, is consistency with maps: For a map, there is no index "one past", so it makes sense to leave it at the last defined one.
Update --&gt; I already fixed those... Thanks a lot
The one about moss k/v store was extremely high quality - loved it. GRPC talk was pretty good as well (if you haven't yet had the chance to work with it).
&gt; A special case of the above is the catch-all interface{} The empty interface is not a special case. It's the logical consequence of interfaces with n, n-1, ... 2, 1 and finally 0 methods. There's no special code in the compiler for interface{}.
It might be worth looking at the project I've created to solve project based architecture: https://github.com/GetStream/vg I'm almost finished with my pull request, which should add capabilities to work on projects outside of your GOPATH: https://github.com/GetStream/vg/pull/8 Would be cool if you can try it out. If you try the PR be sure to read the new README from there as well: https://github.com/GetStream/vg/blob/workspace-settings/README.md 
The `interface{}` is special in that it cannot be used for dynamic dispatch. The purpose of interfaces is dynamic dispatch. Usually dynamic typing is also supported, but is typically not used unless unavoidable (as that kind of beats the purpose of dynamic dispatch). On the other hand, the only thing you can really do with `interface{}` is to try to cast it. 
That copy-pasting instead of generics and spamming `if(err != nil)` instead of exceptions/monadic error data types are borderline retarded, not "genius" or "simple". Just because it's easy to learn it doesn't mean it'll be easy to write, maintain or read. Take for example beginner vim users - they spam the arrow keys like chickens and it seems convenient to them. They need to disable them along with hjkl to actually learn the motion keys efficiently. r/golang is getting similar to the [trump fanbase](https://www.youtube.com/watch?v=glUOprx56sU) - the echo chamber is *really* strong and the admiration of the Commander is so deep that the fans throw aside logic.
That was actually very fun.
&gt; That copy-pasting instead of generics and spamming `if(err != nil)` instead of exceptions/monadic error data types are borderline retarded, not "genius" or "simple". Just because it's easy to learn it doesn't mean it'll be easy to write, maintain or read. Take for example beginner vim users - they spam the arrow keys like chickens and it seems convenient to them. They need to disable them along with hjkl to actually learn the motion keys efficiently. r/golang is getting similar to the [trump fanbase](https://www.youtube.com/watch?v=glUOprx56sU) - the echo chamber is *really* strong and the admiration of the Commander is so deep that the fans throw aside logic. I prefer the way Go does error handling. Errors are just values so you can program with them. If you are not happy with the repetition of error checking then you are free to program and abstract it away. And you have the whole language at your disposal to do that. You cannot program with exceptions.
&gt; I prefer the way Go does error handling. Errors are just values so you can program with them. Go ahead and program with a stack-overflow, an out-of-memory or a divided by zero error ;) Btw, if you want to program them as values then get better tools to handle them - look at how elegantly does FP handle errors. &gt; If you are not happy with the repetition of error checking then you are free to program and abstract it away. If you're happy with that then probably you're not programmer-material. &gt; You cannot program with exceptions. Excuse me?
&gt; Go ahead and program with a stack-overflow, an out-of-memory or a divided by zero error ;) Btw, if you want to program them as values then get better tools to handle them - look at how elegantly does FP handle errors. Go has a [mechanism](https://golang.org/doc/effective_go.html#panic) to deal with those already. &gt; If you're happy with that then probably you're not programmer-material. It really depends on what matters for each person. Some programmers are happy only when they can create elegant abstractions and pure functions. I am happy when I can write simple and boring code that solves my problem so I can move on. I don't believe either of these views make anyone less of a programmer material.
Nothing IMO. I also agree in your points in your talk. Kudos for taking the jump and actually taking the time to refactor your stuff instead of "yeah - it it would probably be better in code, but now it is YAML, deal with it". For me personally, I have also had this transition, mostly coming form C/C++. Since setup/recompilation can be such a pain to test small thing, I tended to have data files describing some behavior. They were just easy to edit and no re-compilation necessary. With Go you get the best of both worlds, and it also has the added bonus of being much easier to test, and you can do basic sanity checks on startup.
Plus one for goth, these days most customers prefer some level of external authentication. In the SaaD world this mesns SAML, for everyone else its usually login with google/facebook. Auth0 gives you all that out of the box along with the nice to haves such as logging in as a customer etc. And goth makes it easy to use auth0. Also worth noting thar if you're looking to build a webapp in go it may be worth checking out http://gobuffalo.io/docs/getting-started which is ny the same author as goth.
Awesome as always! A good introduction to tests. It took me a while to figure out why the `/doulbe?v=2`worked, but you got the routing test in there in the end. :) You might consider splitting larger topics into smaller ones. This one for example could easily have been split into "Go tests" and "Go http server tests". It is a bit easier to consume when episodes are below 30 minutes, 20 is the sweet spot for me :) PS: Link in description for code is b0rked.
&gt; Go has a mechanism to deal with those already. So, go has two half-assed ways to handle errors... And you need to use the 2nd one *explicitly* each time... &gt; It really depends on what matters for each person. Some programmers are happy only when they can create elegant abstractions and pure functions. Shit code is shit code. Honest and good work requires sacrifices and knowledge. &gt; I am happy when I can write simple and boring code that solves my problem so I can move on. Correction: you're happy to waste time copy-pasting code and writing boilerplatish garbage because you're too lazy to learn new programming concepts because you're just here for the money, right? To "move on" to the next "big thing"^^money-cow. &gt; I don't believe either of these views make anyone less of a programmer material. Yes, it does. We automate tasks, so users don't need to do repetitive/hard tasks. Elegant and intelligent design are the modern world's ways.
Math. Take the slice with elements `a, b, c, d`. It's length is 4 and the last element is at index 3, ergo `len(v)-1`.
&gt; So, go has two half-assed ways to handle errors... And you need to use the 2nd one explicitly each time... Regardless of what you think about it, that's how Go does error handling. &gt; Correction: you're happy to waste time copy-pasting code and writing boilerplatish garbage because you're too lazy to learn new programming concepts because you're just here for the money, right? To "move on" to the next "big thing"money-cow. The fact that I am writing Go does not mean that I do not learn new programming concepts or that Go is the only language I use. Also people are getting paid to do their jobs. That's how the world works. &gt; Yes, it does. We automate tasks, so users don't need to do repetitive/hard tasks. Elegant and intelligent design are the modern world's ways. It seems you are agreeing with Rob Pike then (in case you didn't watch the video). A good example mentioned in the video is Go's garbage collector. There's a lot of intelligent design behind it so that the users don't need to do hard tasks especially when it comes to memory ownership and concurrency.
Not really: nil is the zero value for a pointer, and JSON null will unmarshal to nil. You cannot differentiate between no value provided and null provided.
Some interesting quirks... and then we dive off the deep end into a thinly-veiled rant about how white people just can't get a break or something.
This is really great. I'm looking forward to watching the rest of your videos. Thanks for sharing. 
Most answers here are wrong. Browsers, all caching clients in fact, when faced with the last-modify date and no other caching meta directive, will use a heuristic to decide whether they ask the server for confirmation or not. This is the specified behavior. Read the HTTP caching sections of the relevant RFCs, then inject your desired caching meta directives in the headers of the response. Edit: search for `must-revalidate`.
You want `must-revalidate` in the header. Then you can dispense with the dynamic URI nonsense.
You might think you're being a good samaritan, but did you ever consider that they're shadow-banned because they broke the rules? Maybe they're... *shocking, I know* Not a nice person?
&gt; Regardless of what you think about it, that's how Go does error handling. Marvelous. \s &gt; The fact that I am writing Go does not mean that I do not learn new programming concepts or that Go is the only language I use. If you'd, you wouldn't use golang by will. &gt; Also people are getting paid to do their jobs. That's how the world works. And if you don't like your job enough to improve or if you're wasting your employer's time then you should quit your job or educate yourself. &gt; It seems you are agreeing with Rob Pike then (in case you didn't watch the video). I said "We automate tasks, so users don't need to do repetitive/hard tasks. Elegant and intelligent design are the modern world's ways." - *and not* "Children, copy-paste like an idiot and check your errors with `if`s because we're too dumb/lazy to implement a sophisticated compiler". &gt; A good example mentioned in the video is Go's garbage collector. There's a lot of intelligent design behind it... Like not having a *generational* gc in 2017? So intelligent... &gt; so that the users don't need to do hard tasks especially when it comes to memory ownership They didn't invent GCs. In fact, they made an outdated GC. &gt; and concurrency has nothing to do with your GC. And to be correct, golang's gc won't save you from data races. It's just a dumb incremental gc from the '70s which gives up performance to consume less memory so it looks like it's fast when you write small programs.
[Zero based indexing ](https://en.m.wikipedia.org/wiki/Zero-based_numbering). Remember that the first element is at index 0, not 1. The same holds for all the elements - up to and including the last one.
If you care about speed, you may also want to add `--tmpfs /var/lib/mysql` to your `docker run` flags. On MacOS, it'll probably cut your query times in half.
I am looking into goth right now and to using it in conjunction with Auth0. However, I am very new to both (and to Go in general); the impression I get is that goth is not suitable to my specific needs because it is specific to *web* client authentication, whereas the current interface to my go app is CLI (and that is also how I have set up my Auth0 client). The first issue I already ran into is the fact that goth requires a "callbackUrl" when registering a new provider, which it seems Auth0 requires for web clients but not CLI clients. However, for web interfaces goth does come highly recommended. So what I am thinking is having authentication plugins for different interfaces - loading the web auth plugin which uses goth from the web interface (which I will later have), and writing my own Auth0 implementation for the cli interface. Not sure if this is at all a great solution yet, or if I've missed something and could/should be using goth for both after all; I'll just have to experiment. Edit: typo
&gt; If you'd, you wouldn't use golang by will. But I like Go. :) &gt; And if you don't like your job enough to improve or if you're wasting your employer's time then you should quit your job or educate yourself. I like my job, thank you very much. :) &gt; I said "We automate tasks, so users don't need to do repetitive/hard tasks. Elegant and intelligent design are the modern world's ways." - and not "Children, copy-paste like an idiot and check your errors with ifs because we're too dumb/lazy to implement a sophisticated compiler". One of the people involved with the Go's compiler is Ken Thompson. &gt; They didn't invent GCs. In fact, they made an outdated GC. When did I ever say that they invented GCs? It might have been outdated at the start but not anymore. &gt; has nothing to do with your GC. And to be correct, golang's gc won't save you from data races. It's just a dumb incremental gc from the '70s which gives up performance to consume less memory so it looks like it's fast when you write small programs. One of the strongest points for the inclusion of a GC in Go was because of concurrency. When you write concurrent programs it is very difficult to know who owns what in terms of memory. A GC solves that problem. There's a lot of sophistication behind it and zero API for the user. That's the definition of "Simplicity is complicated".
https://github.com/golang/example/tree/master/gotypes is a good tutorial for the go/types package. Algorithms that are used by go/types and go/ssa that you could read up on are SSA and Andersen's algorithm. More general concepts are control flow graphs, data flow, taint analysis, value range propagation, decision problems, the very relevant halting problem and about a dozen others, depending on what you're trying to do. I've forgotten half the things I've looked at. A lot of static code analysis for finding bugs overlaps with the work done by optimizing compilers, so you could look at what gcc and clang do (you'll find old friends such as value-range propagation.)
thank you for the direction! :)
I know that pain all too well too haha. It's a shame JSON managed to take the spot it occupies right now. Not that I miss XML.
&gt; many of us, and so few of you This attitude of mentally splitting a community into two sides is toxic. As is thinking the majority is automatically correct.
You know what... some of them were funny some of them where meh, it was an average comedy article that deserved no mention... until the fucking code example at the end, that shit required dedication and made me giggle for a few minutes, this article warrants a bookmark. ... well done
&gt; But I like Go. :) Which is irrational. &gt; I like my job, thank you very much. :) That wasn't the point. I was talking about your *profession*. &gt; One of the people involved with the Go's compiler is Ken Thompson. I don't care. He never made any language with generics. He never worked on high-level languages before. Btw, with this in mind if you do one thing well - partially - in your life does that make everything else perfect later? &gt; When did I ever say that they invented GCs? When you were talking about memory ownership. &gt; It might have been outdated at the start but not anymore. Proof on that? &gt; One of the strongest points for the inclusion of a GC in Go was because of concurrency. Nope, the inclusion of the gc was because *it manages memory automatically* and because you wouldn't touch malloc/free when doing web programming. &gt; When you write concurrent programs it is very difficult to know who owns what in terms of memory. A GC solves that problem. Man, this bullshit... **your GC doesn't handle data races because its purpose is to automatically manage your memory fields**. Concurrency has **nothing** to do with golang's gc. &gt; There's a lot of sophistication behind it and zero API for the user. Now go and read about GCs and concurrency in general. &gt; That's the definition of "Simplicity is complicated". No, it's the definition of "No education will get your comments posted to r/programmingcirclejerk".
Another wonderful JFF - Thanks for these, they are always fantastic!
Mods of subreddit cannot shadowban users - only Reddit admins can do that. And some of those bans are actually unsanctioned. 
I know your talk, it inspired a blog post i wrote recently (https://zupzup.org/go-ast-traversal/). :) Looking at tools and reading their source (especially in the go world, where such code is readable) was on the top of my list as well, but I like to have some "theoretic" material accompanying me. ;) Thanks anyways for your great contributions and help!
interesting, I added the original auth0 provider to goth. While the code requires a callback URL today it should be reasonably possible to setup something to support PKCE clients. Are you following https://auth0.com/docs/tutorials/using-auth0-to-secure-a-cli#how-pkce-works for using auth0 with the CLI or something else?
&gt; I don't know how accurate a server clock is or how to check that. I'm assuming GitHub will be using NTP to sync their servers to atomic time, you should do the same on any server you deploy on. Then you just need to make the expiry period long enough for a reasonable logon; say, a couple of minutes. (Worst case, to log on I might have to find my phone for my 2FA app.) &gt; I have no such mechanism. I am using HTTPS and an HSTS header. Could you elaborate on this please so I can implement it? Every time you issue a one-time token such as a CSRF cookie or OAuth state token, you should give it a unique ID. You then need to keep a server-side list of the tokens which you've seen returned to you and "spent". Otherwise, if someone sniffs a valid cookie from a browser, they can pass the cookie to your app's login endpoint, and hammer you with repeated credential guessing attempts. Or, they might leverage some other attack using the cookie. This happened [in some popular forum software](https://blog.qualys.com/securitylabs/2015/02/19/how-a-missing-security-check-enabled-a-csrf-attack) -- the CSRF cookie was constant for an entire session, and could be used repeatedly, which allowed session hijack. Since the problem is repeated cookie submission, it's generally sufficient to keep a list in memory of recently "spent" cookies, and purge the oldest elements from the list when it gets too long. &gt; They are generated using crypto/rand. Does that make them sufficiently hard to guess? Probably, assuming they're long enough. &gt; I am using https://github.com/golang/oauth2 to do the oauth2 exchange with github. Is that OpenID-style? Not necessarily. OAuth2 is a complicated standard with lots of possibilities, unfortunately, and it's tough to make sure you do everything right, as you've discovered. OpenID Connect is a subset of OAuth2 with guidance on best practices. It's probably worth looking over the OpenID Connect spec and following its advice where possible. Often endpoints saying they offer OAuth2 are often effectively offering OpenID Connect.
&gt; Which is irrational. Well, I am not a robot. Never heard of the saying "beauty is in the eye of the beholder"? :) &gt; Proof on that? Check out these [tweets](https://twitter.com/brianhatfield/status/634166123605331968?lang=en). &gt; I don't care. He never made any language with generics. He never worked on high-level languages before. Btw, with this in mind if you do one thing well - partially - in your life does that make everything else perfect later? Inheritance has been a staple of many programming languages for a long time. Yet only recently we learnt to see it as a potential anti-pattern. The Go team carefully chose which features to get into the language because once something gets in, it can't get out. They only chose features that had proven themselves through the years. &gt; Nope, the inclusion of the gc was because it manages memory automatically and because you wouldn't touch malloc/free when doing web programming. We are saying more or less the same thing with different words. So I am going to agree with you on this. &gt; No, it's the definition of "No education will get your comments posted to r/programmingcirclejerk". Thanks for making me famous I guess? :) P.S. Hi everyone!
I haven't gotten far into it yet as I have been learning about how to best set up and load the plugins, setting up the auth package and configuration, etc. After this I was planning on starting with the Go example provided by Auth0 in the CLI client "Quick Start" to get an access token and going from there. The example it provides to get an access token is as follows: package main import ( "fmt" "strings" "net/http" "io/ioutil" ) func main() { url := "https://domain.eu.auth0.com/oauth/token" payload := strings.NewReader("{\"client_id\":\"idstring\",\"client_secret\":\"secretstring\",\"audience\":\"https://domain.eu.auth0.com/api/v2/\",\"grant_type\":\"client_credentials\"}") req, _ := http.NewRequest("POST", url, payload) req.Header.Add("content-type", "application/json") res, _ := http.DefaultClient.Do(req) defer res.Body.Close() body, _ := ioutil.ReadAll(res.Body) fmt.Println(res) fmt.Println(string(body)) } With the expected response being as follows: { "access_token": "tokenstringhere", "token_type": "Bearer" } 
&gt; Well, I am not a robot. Never heard of the saying "beauty is in the eye of the beholder"? :) It's a tool. We're talking about a tool... &gt; Check out these tweets. Those are small latency tests in a small library... &gt; Inheritance has been a staple of many programming languages for a long time. Yet only recently we learnt to see it as a potential anti-pattern. Inheritance is not an anti-pattern. &gt; The Go team carefully chose which features to get into the language because once something gets in, it can't get out. Yet, they let in `interface {}` and a bunch of half-assed "solutions"... &gt; They only chose features that had proven themselves through the years. They only choose what they can implement. &gt; We are saying more or less the same thing with different words. So I am going to agree with you on this. Definitely not. &gt; Thanks for making me famous I guess? :) That was OP, not you btw. Wanna be Trump-famous?
I'm in the procrss of creating passport.js like system to golang. Will keep you up to date when I finish it
That makes it doable, just annoying. I now have to add a struct tag in for every exported field. It feels like declaring everything twice. If I'm in complete control of everything, I can just have weird looking json with capital letters.
I was considering Auth0 for a second there, but in the end decided to write my own identity provider service (registration, activation, login/logout, recovery). Authboss felt too complex and some things were redundant for my needs (OAuth2 endpoint, Rate limiting/locking users, etc.). I also didn't find anything else that was reasonably developed (or understood). If Auth0 would have a docker container so you can host your own data, I would probably go with that. Or if authboss had an implementation which you could run for yourself and that would be production ready. I know there's a free tier in Auth0 but I'm writing my own SaaS identity provider for subscription purposes, and I don't want to depend on external providers for core functionality, at least not exclusively. There are at least two projects for Angular and Vue that provide some sort of authentication layer for those front-end frameworks (that would be [vue-authenticate](https://github.com/dgrubelic/vue-authenticate) and [statelizer for angular](https://github.com/sahat/satellizer)). I chose not to use either because of lacking API endpoint documentation (swagger would be enough), and because it seems very much coupled to the frameworks of choice. While I like and use Vue, I didn't want any authentication solution that would be coupled to it, or the Node runtime. And, a simple API [like this which I wrote in the past](http://api.rtvslo.si/console/users) goes a long way. It (and several companion APIs) are used by several CLI as well as Web and native mobile and TV device (I guess embedded?) clients. If somebody shares this opinion, feel free to leave me a DM to see if we can work together down the line. Edit: some clarification about authboss/SaaS identity provider. Words.
https://github.com/golang/go/wiki/CodeReviewComments#initialisms
The linter has a bunch of common acronyms it searches for, which is probably why it misses 'Guids'
better share with the class before you finish it :)
Thats why I wrote "mitigated", not "solved" :) BTW, [JSON-to-Go](https://mholt.github.io/json-to-go/) might turn out helpful.
Agreed with everything, are all stupid people (except you two). Someone works on a useful project, decides to do a presentation and share some knowledge for free. Then the internet people go downvote it and don't leave feedback. I'd not worry about it. Also, I bet the people that paid to be in the event didn't complain at all.
&gt; But I digress. The point is that the Go team should not pay any lip service to the generics discussion if they are not going to fully commit to addressing the problem. If you think they are merely paying lip service, you must have a low view of the Go team. Either that or you don't have a full picture. &gt; That is, the mere existence of channels, maps, and slices seems like a contradiction to the argument against generics. I am not quite sure how you can claim to understand channels and slices in Go and make this statement &gt; ”I’ve never experienced a need for generics, so anyone who has must be wrong.” This would have been a much stronger statement without the latter part. However, it's still weak. This experience is very much shared across a wide range of developers (myself included). If this anecdote keeps popping up, at what point does stop becoming "anecdotal" and start becoming "evidence" &gt; Certainly, I think the debate is worth having though, but the hero-worship and genetic-fallacy type arguments do not further the discussion. And blindly throwing out logical fallacies without given thought to if they are actually fallacies in the given context also do not further the discussion. No one is hero worshipping. Appealing to authorities (experts) is not a fallacy when the given authority has relevant, pertinent experience and is widely recognized as an expert in the field. 
or there is no consensus in the team yet. https://www.airs.com/blog/archives/559 if you read that you can feel that. also Ian is a go team member who has been writing proposals to add generics from some time.
In that case you can use a custom type. If its unmarshal gets called, set a flag saying it has been set. If I recall, you can also just use a double pointer. If nil, it's unset. If pointer to a nil pointer, it was null.
https://github.com/vishvananda/netlink/blob/master/route.go#L35
&gt; Netlink is the interface a user-space program in linux uses to communicate with the kernel. That's Linux only.
Please stop "demanding" features and quit being so agitated. Provide use cases and convince people _rationally_ why generics saves your problem.
Lol. I mean that usually an iteration has the C form like this `for i=0; i &lt; len(v); i++ {`. In this case i will have the value `len(v)`. 
This is an early-stage project, but it now works on my sites. It was my “weekend” project for learning Go, that got out of hand. I'm sharing it now in case it's use to anyone, and to solicit constructive criticism. [Yes I know about – and admire – Hugo. I wanted something compatible with GitHub Pages. Also, I like Liquid as a templating language, although maybe that's just because I'm new to Go.]
I know what generics can do and I do miss them in Go, but I believe that there can be a certain degree of generics and it doesn't have to be as complex as in C++. I feel that a few small language changes might solve most problems that require generics. The only way forward is to investigate and describe use cases precisely, so that a rational decision can be made. Give the Go team and community some time.
If the JSON always has that format there no need to use map[string]interface{}. Here's a way to do it with a struct: https://play.golang.org/p/-nYYNLAZqS You can change the struct to make it cleaner. I just copied it quickly from https://mholt.github.io/json-to-go/.
https://github.com/jackpal/gateway
**EDIT** - thanks for the great comments, everyone! First, let me say that I do not have a degree in computer science, so this question may be a bit uninformed. What are the benefits that would be solved with generics over and above the reflect package? For instance, here's how I currently solve writing generic functions in go with reflect: func takeArg(arg interface{}, kind reflect.Kind) (val reflect.Value, ok bool) { val = reflect.ValueOf(arg) if val.Kind() == kind { ok = true } return } func Distinct(arr interface{}) (reflect.Value, bool) { // create a slice from our input interface slice, ok := takeArg(arr, reflect.Slice) if !ok { return reflect.Value{}, ok } // put the values of our slice into a map // the key's of the map will be the slice's unique values c := slice.Len() m := make(map[interface{}]bool) for i := 0; i &lt; c; i++ { m[slice.Index(i).Interface()] = true } mapLen := len(m) // create the output slice and populate it with the map's keys out := reflect.MakeSlice(reflect.TypeOf(arr), mapLen, mapLen) i := 0 for k := range m { v := reflect.ValueOf(k) o := out.Index(i) o.Set(v) i++ } return out, ok } And then the function can be called as so, with any input slice type so long as it's a slice... var a = []int{1, 1, 2, 3} z, ok := Distinct(a) if !ok { fmt.Println("Cannot find distinct") } slice, ok := z.Interface().([]int) if !ok { fmt.Println("Cannot convert to slice") } fmt.Println(slice, reflect.TypeOf(slice)) // [1, 2, 3] []int [playground](https://play.golang.org/p/fkF4SWRPNX)
[removed]
&gt; This would have been a much stronger statement without the latter part. However, it's still weak. This experience is very much shared across a wide range of developers (myself included). If this anecdote keeps popping up, at what point does stop becoming "anecdotal" and start becoming "evidence" I think we should hold people relaying this experience against generics to the same standard we hold those who claim they need generics. The point they stop being "anecdotal" and start becoming "evidence" is when we can provide good solutions to what are classically generic problems. This has happened to some extent already, but more work needs to be done on this front.
* It is not compile type safe. * [Reflection is never clear](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=15m22s)
oh cool, thank you very much. this helps alot. That is also quite a cool tool.
&gt; What do you think I did wrong? It's got 5 down votes! Grow a thicker skin?
And the tweet: https://twitter.com/golang/status/889885828574347264
The fact that you consider being "genuine" to be equivalent with "confirms your opinion" (even though Ian says literally nothing that literally every other member of the go team has not already said) exposes how your personal biases are coloring your perception of the debate.
I have to disagree. Computer science has already proved the case for generics. Just say "no generics in Go - end of discussion - executive decision" and stop trolling people with this will we/won't we bull.
[removed]
The article talks about a silly notion of "most powerful language". Programming languages are tools. Use one that fits specific task. A language doe snot have to include all conceivable features to be powerful and efficient. When I need generics, I use C#. When I need desktop UI, I may use C# or Free Pascal, for instance. I use Go in projects that do not benefit from generics and it rocks for the purpose. In C# i do use LINQ (because I work in a team) but consider it a gimmick. Most of generic IEnumerable&lt;&gt; stuff could be modeled simply by slices (synchronous) or channels (asynchronous) in Go. Anyway, if Go gets generics eventually I would not refuse it, of course. Whatever... Edit: Instead of full generics what I would like to see is something like adding implicit interfaces Comparer, Cloner, etc. to builtin numeric types that compiler is aware of. That will allow users to write "generic" functions over these interfaces for mathematical functions. The current proposal for multi-dimensional arrays also plays into math strongly. Look for any ways to speedup `cgo` ABI to leverage existing C/C++ libraries. That will give a greater return on investment, so to speak. 
How do you "prove" the case for generics with Computer Science? Has the case for dependent types also been proved? What else did I miss since yesterday?
&gt; Computer science has already proved the case for generics. It had also proved the case for inheritance.
Turns out Chris Hines beat me to it by about 2.5 years: http://cs-guy.com/blog/2015/01/test-main/ Other good uses for TestMain in there also.
* It's not performant, either. `ValueOf` is boxing the internal value.
Your `Distinct()` implementation will actually panic on certain values that are not permitted as map keys. For example, you can't use a function, a slice or another map as a map key. So it's not type-safe at compile time, and neither is the function itself, since you have to cast its output via a type assertion. It's also not performant. `reflect.ValueOf()` boxes the internal value.
&gt; I wanted something compatible with GitHub Pages ? You just set the repository to the public folder and push
If you don't need local builds as part of your site development workflow, then this project is of no benefit to you. This is aimed at a site developer who is building a complex site that makes use of site data, includes, or site variables, and that takes a long time to build in Jekyll. For me, developing and then updating a complex site generally requires a large number of iterations, and the edit/push/view cycle is too slow (more than a minute for a large site) to want in the inner loop of my workflow.
&gt; This is aimed at a site developer who is building a complex site that makes use of site data, includes, or site variables, and that takes a long time to build in Jekyll. Hugo does that too, you can even import a jekyll site.
&gt; And blindly throwing out logical fallacies without given thought to if they are actually fallacies in the given context also do not further the discussion. Slightly off-topic, there's a subreddit called /r/programmingcirclejerk who seem to do precisely this, and jump in on anything they see as "stupid". They come with these fallacies you mentioned and refuse to either be civil or give suitable examples that would further the debate. They seemed to jump on a thread I was contributing to and began a lot of name-calling and elitism that genuinely made me feel awful for quite a long time after. Unfortunately, that seems to be pervasive within internet culture these days :(
Probably on the next testing episode!
Yeah, I've been trying to reduce the length of the videos, but it's hard to predict how long the episode is until it's too late haha
&gt; but I believe that there can be a certain degree of generics and it doesn't have to be as complex as in C++ What you're referring to is not simply generics but *template metaprogramming* - that's a whole different *beast* and it's needed in cpp because it can do miracles with optimizations. &gt; I feel that a few small language changes might solve most problems that require generics. Just add simple generics. There's no solution which would be simpler or easier. Seriously, if generics are "hard" I don't know what is easy...
Ignore them.
Although the for statement with a init and post statement can be used to iterate slices, it's just one possible use. To add an implicit increment operation ONLY when iterating a string or slice in conjunction with a range clause and only when the initializing for statement did not assign a new value in the name of symmetry for an often asymmetrical relationship would be unusual in my opinion. It would also break a much more common pattern people use for finding a index of a rune in a string, leaving potential OOB panics. I can't think of a use case where I would want to iterate an entire slice to find a relationship between the last item and it's length. I would just check s[len(s)-1] == search or iterate in reverse order if I wanted to do something special if the last item was a specific value otherwise do other things so I could short circuit that case.
If I had to guess... it's... "Microsoft". I bet a lot of people went to/found goLang in search of a .NET alternative. I was one of them. I'm not anti-Microsoft (yet), but I'm getting there. However, that's my personal belief and opinion, and wouldn't have personally downvoted your video because of that. I think your video was great.
shameless plug :) I write Go tutorials at https://golangbot.com/
I would expect the compiler to do the opposite if anything at all: that is on for statements with init and post statements to omit the final increment operation in some cases as the post decrement the operation is extraneous when the condition will not be met. For example if a loop was unrolled as the value was a small array with known bounds, it would be reasonable to generate assembly that skipped the final post statement if it's value fell out of scope directly after. 
 &gt;They seemed to jump on a thread I was contributing to and began a lot of name-calling and elitism that genuinely made me feel awful for quite a long time I recommend developing a thicker skin, because in reality (especially on the Internet) people don't really give a shit about your feelings. That's just how it do. A lot of the arguments being used against generics in Go are pretty easy to decimate. When people see a lot of these laughably false claims coming from a single group of people, that group is bound to be stereotyped. It has very little to do with PCJ doing what it does and more so with typical group-think behavior and established patterns over time, as well as assertions made which seem to have little thought behind them or are blatantly hiding important information. 
&gt;&gt;That is, the mere existence of channels, maps, and slices seems like a contradiction to the argument against generics. &gt;I am not quite sure how you can claim to understand channels and slices in Go and make this statement Channels, maps and slices are 'generic'.
I chose to use Go because my company decided to move certain projects to Go, and I had a choice between quitting and using it. With the tasks I was working on, Go was a little better than the proprietary language we had been using and didn't have many visible warts. I switched to a different company, and I chose to use Go because my manager decided he wanted to play around with it, and though I tried to dissuade him, he didn't listen. (We'd just moved a lot of the company from Ruby to Java, and most of the devs were having trouble with it. Adding Go to the mix didn't seem wise.) That manager left about three weeks into the project, at which point I had had enough problems with Go that I asked my new manager for permission to switch to Java. My experiences with Go are similar to my experiences with Python: it's fine for a very simple project but becomes troublesome for larger stuff. Google's experiences were similar, with the added caveat that small projects become large. But hey, if you want to add another programming language to your CV, Go is probably a better option than PHP or Perl. If you're not seeing problems using it, more power to you.
Easier said than done, unfortunately. I don't care if someone says I'm wrong -- in fact I relish it, I learn something. However, these people were just so anti-Go it was clearly just fun for them. I tried to ask them for examples, but they just weren't willing to engage in civil debate. I don't even know why they read /r/golang if they're so offended by what we say...
Let me guess, D?
Here, this is a non-throwaway account from someone else. Go is a problem because, like Node.js, its rationale is only hurting the software industry. In this case, the rationale making people think that modern language features are bad has proven to be fallicious in terms of common idioms such as exceptions and generics. Furthermore, the justifications for lack of these features have easily been rationally refuted time and time again, getting to the point where Go programmers are countering with support for programming anti-philosophies (Do Repeat Yourself, for example). The level of rationalization has about as much merit as trying to argue that we all hand code our programs in assembly language. Different software ecosystems are interconnected, hence the significance of this debate, and while idealism is to be avoided there is benefit in arguing against Go's philosophy until something is done about it because Go's popularity implies that a significant amount of software will could very well be written with a language which has thrown 40 years of programming language evolution out the window. Go does provide modern features such as package management and modules, in addition to a syntax which is somewhat more standardized than C. The concurrency features are nice as well, but that alone isn't enough to convince me the language is worth investing in. Plus, admittedly, debating Go advocates is fun.
Yup. More features != success.
&gt; In this case, the rationale making people think that modern language features are bad has proven to be fallicious in terms of common idioms such as exceptions and generics. Has it? Where is the proof?
downvotes? probably because emacs :-)
I love static typing, but I've also never had any issues with using `interface{}` in my reusable data-structures. Some people have OCD about having to use type assertions on the rare occasion. Get over it.
You can do it on top of [this](https://github.com/alexedwards/scs) package.
Whether or not the compiler optimizes away the final increment is not particularly interesting, though, as this is about semantics, not compiler internals. The compiler can't optimize away the final increment (loop unrolling or not), if its side-effects can be observed. I'm also not convinced that you can actually elide the final increment, unless you can actually fully unroll the loop (which should be pretty rare).
That's just silly. If Go code is not reusable then you probably have bigger problems.
&gt; I don't even know why they read /r/golang if they're so offended by what we say... Maybe they just want a laugh?
&gt; I am not quite sure how you can claim to understand channels and slices in Go and make this statement Unless you are making an argument in a similar fashion to that which you are criticizing please explain. Golang employs a mechanism unavailable to the coder to allow the current usage of arrays, maps and channels (and subsequently slices), whether you want to call that generics of not is up to you, but a 100% similar implementation could presumably be achieved using generics and other language use generics for such types, so I'd say calling those types generic types is a fair assessment. 
Begins with an [ad hominem](https://en.wikipedia.org/wiki/Ad_hominem) attack: &gt; I am not quite sure how you can claim to understand channels and slices in Go and make this statement And then: &gt; And blindly throwing out logical fallacies without given thought to if they are actually fallacies... That's an interesting comment to follow an ad-hominem attack with.
Which is fine, but then trolling afterwards... That's just uncalled for.
Apart from the readability and compile-time checks, generics (usually, excluding Java) compile to type-specific code. All the reflection and casting goes away, leaving you with something just as fast as if you had rewritten it for each specific type. Edit: I can imagine a scenario in which a compiler could specialize functions that take interface parameters when types are known at compile-time, turning one general function into many strictly typed functions. That would alleviate some of the frustration, though I'd want some control over which functions, since it'd add a lot of bloat to apply it needlessly.
Sounds great! When will it be ready?
Ever written general purpose data structures before?
I was curious, so I went and found this page which links to a living document which seems to collect use cases and problems people have faced along with their alternative solutions where available: https://github.com/golang/go/wiki/GoVsGenerics Posting it here in case others might find it interesting too :-)
Java started without generics. Probably because `Object` was thought to be enough. That mistake has since been corrected. For some reason, Go did the same mistake. You can tell it's a mistake because like Java did in 1995, Go *has* some generic data structures. They're built in however, resulting in a bigger language. With generics, they would have belonged in the standard library. A thorough solution have to allow users to write data structure that are as generic as the array (or slice). Good luck doing that without generics. 
Concurrent map, nice!
This is not an experience report as requested by https://github.com/golang/go/wiki/ExperienceReports: &gt; The best experience reports tell: (1) what you wanted to do, (2) what you actually did, and (3) why that wasn’t great, illustrating those by real concrete examples, ideally from production use The article does none of these, and merely tries to assert authority (“You don’t need user experience reports to clearly see the problems people are facing using Go. You just have to open any Go discussion on the internet”). I don’t see what this article adds to the discussion, aside from making people with a different opinion feel bad (am I too stupid to see why generics apparently are a no-brainer?).
&gt; am I too stupid to see why generics apparently are a no-brainer? Did you not see the list? The various things that Go simply isn't equipped to do.
Semantics are already clearly defined for each form of the for statement, I was just trying to provide a example why your expectation of compiling differently may not of been a reality. I'm not sure what your last sentence means, loop unrolling happens when the condition phi is able to be analyzed in some form, a known multiple of N, const size, etc, which always implies the increment is extraneous.
You list abstract concepts. I’m asking for examples, anchored in real-world use-cases. I haven’t had the need for any of the techniques you listed in my projects so far. Apparently you have. Please help us understand by following the format outlined by the ExperienceReports wiki page.
&gt; I’m asking for examples, anchored in real-world use-cases. Here's a couple from the Go team: https://www.airs.com/blog/archives/559 &gt; The point I want to make here is that because we had no way to write a generic Vector type with an Append method, we wound up adding a special purpose language feature to implement it. A language that supported parameterized types with methods would not have required a special built-in function that only works with slices. An append operation makes sense for other sorts of data structures, such as various kinds of linked lists. The built-in append function can not be used for them. - Ian Lance Taylor Plus they are not abstract concepts. They are real world use cases.
To those asking for examples, Ian Lance Taylor (core Go team member) has already thought of generics since way back. See: https://github.com/golang/proposal/blob/master/design/15292-generics.md. Clearly the core team has already seen/imagine numerous use-cases already.
A language which advertises easy concurrency as it's main feature and not providing thread safe data structures after 5 years ... yeah.
I'll admit I don't have much of a handle on generics, having never used them (I came to Go from a Python background). I get the general idea, but not really what the "big deal" is. This article hasn't enlightened me in any way. Lots of assertions about how you can't do this or that thing (many of which I have already done), but not a single concrete example that makes me think, "oh yeah, that's a feature I never knew I needed." 
&gt; I’m asking for examples, anchored in real-world use-cases. Use Go without append, len, slices and maps because they all use build-in generics in the Go compiler. Have fun.
Have you ever used maps, slices, append or len function in Go? Then you already used generics.
Neither does erlang. Mutexs are hard to reason about and aren't the paradigm go promotes.
Read the boiler-plate section here: http://nomad.so/2015/03/why-gos-design-is-a-disservice-to-intelligent-programmers/
That’s the concept of a circlejerk. Golang is a recurrent target of PCJ, but there is a lot of trash talk against Rust, JS… I regulary go on PCJ to have a good laugh, but if you want to know how generics would be beneficial to Go and its community, it’s because it would improve type-safety of the language by allowing to create fully type-safe, generics data structures. For instance, one could make a general purpose b-tree data structure, and redistribute it as a library on the Internet. We can achieve this today with `interface{}`, but it’s not type-safe, and you have to make a cast to get back your data, check if the cast was successful, and handle errors gracefully, hence resulting in more verbose code. No need to do that with generics – type safety would be enforced by the compiler. If you don’t want to use generics, you would not be forced to use them.
I am running gomobile Code on Android O without issues on 1.8.3
Thanks for being open minded!
Because they are completely different languages and this proposal is tailored to Go.
I'm not sure I follow your reasoning, because it sounds more like you're after shortcuts when marshalling data than generics per se... However, I'm more than willing to admit that my (lack of) experience in this area may cloud my judgment here. Someone may choose to respond better than I have!
They are just upset about that Go is more popular than it *deserves*, and the popularity keeps growing. Gophers, you are the villains in the programming world. Everyone else fears the world is about to be taken over by you gophers and is anxious about their coming miserable, inevitable fate to program in Go eventually.
Use cases serves at least two purposes: * That there exists a real problem that generics can solve (I don't think anyone is contesting this) * What type of use cases should a design of generics handle? (A vast number of "use-cases" are not sufficiently detailed that they help answer this question). Generics is not some feature where Go either "has generics" or "does not have generics". There is a spectrum over which the design of generics can be made to be simpler (i.e., handle some number of use-cases, but not others), or arbitrarily complex (i.e., it handles every use-case under the sun). For this reason, the flavor of generics in Java is very different from generics in C++. Russ is asking is for use-cases to help answer, where in the design spectrum, generics should target. Quoting from his talk: &gt; For example, I've been examining generics recently, but I don't have in my mind a clear picture of the detailed, concrete problems that Go users need generics to solve. As a result, I can't answer a design question like whether to support generic methods, which is to say methods that are parameterized separately from the receiver. This is not just "idea parking", but a plea for well-constructed use-cases of exact sub-features of generics that help guide design decisions. It's not helpful to the community to simply assume that "there is no debate".
That's fine. Go decided not to have full inheritance, and said they won't do it. Unlike generics, where we've had years of "umm, ah, I dunno lol". ~~Just make your mind up about generics and do it fast.~~ They aren't some fancy new alien concept.
If you have a CS degree you understand the advantages and disadvantages of generics, and you have probably used and/or loved/hated C++ templates or Java collections before. I don't need to justify this if you have that qualification. If you could please just make up your mind about generics, and either say "No, go away" or get on with determining the syntax, then we can all get on with writing code?
Eh?
Erlang ist old, really old. Also you mostly use immutable data structures in Erlang because that's what makes sense on telephone systems. Go is C with green threads and C was already outdated on a technical base on release, now it's over 30 years later and it's quite sad.
Sorry, maybe I was unclear. It’s been a long day, I’m tired, and english is not my primary language. Still. Say that I want a tree that stores Int, and another that stores String. Without generics, either I duplicate the code (which is not really the best option of all), or I use `interface{}` to store the data. In this case, when I get my data back, I have to check the type before anything else. Then I have to handle errors gracefully, just in case I didn’t got what I expected to. With generics, no need to do that. I create a data structure that contain one or more undefined types, and the compiler will duplicate it at compile time as I need it. I ask a tree that can store Int, the compiler will replace the type of the field by an Int. Same for the String. I hope I was more clear.
If people who want generics put their money where their mouth is, they would have forked the Go repo and bolted generics like yesterday. Lesser agitated ones would have moved to better languages. So IMO all those who are left are either happy or not unhappy enough.
Go has long had an android builder: https://build.golang.org/ (scroll right to the Android column). This is just noting that they have preliminary support for Android O, not just priro released versions.
&gt;It's doubly sad that JSON is not only annoying to work with but also exceedingly unperformant. Is that true, though? I'm also not a fan of JSON in general and dealing with arbitrary blobs is annoying. I thought that for a text-based, human-readable format JSON is a pretty good compromise. It's also relatively cheap to parse compared to XML, for example. What's the alternative?
There isn't a debate, the only choice is whether the maintainers add them willingly or if we are forced to fork and ditch them so that we can have an actually usable language.
It is, thank you! I've not hit this problem personally, as typically I really do want a strict type structure, so that a value is always able to be mutated in a particular way. Having a generic, like having exceptions, does cause more code, you are right... It's just that (as I understand it) most current implementations of generics (and exceptions) make it too easy to produce "lazy" code that doesn't handle all the eventualities. Hopefully once all the dust is settled, there can be a language internal way to deal with these cases, rather than relying on third party libraries/tools. I'm not convinced that carbon copying the Java/C++ way of generics is necessarily the best way to solve the problem though. Generic programming, inheritance, polymorphism... These are all things that simple Google searches produce a lot of confusion, the "Go" way is supposed to be a trivial to understand, trivial to implement system language. I think a lot of the angst comes about because people struggle to explain themselves well. However, I now understand your situation better, thanks to you for explaining it so eloquently! Thank you!
&gt; I was just trying to provide a example why your expectation of compiling differently may not of been a reality. I was talking surprising semantics, you can't really explain those with compiler internals. Let me rephrase my original statement: "I would've expected the loop to be syntactic sugar for `for i = 0; i &lt; len(v); i++`". &gt; I'm not sure what your last sentence means I mean that there are two cases: a) you can unroll the loop completely; in that case, you'll end up with without any jumps, so sure, that'll not need any conditional and the extra increment is superfluous. I'd consider that pretty rare, though, it would require a very small array with statically known bounds. I wouldn't really base a spec on making that efficient, in any case. Or b) you unroll some increment, that is, you replace the `i += 1` with an `i += k` loop for some `k`, but I'd argue, that'll still be the same basic loop, thus it doesn't really change the situation. In the end, you'll end up with some loop with some kind of data-dependent branch, so you won't really be able to optimize out the side-effects. But anyway, that is, at best, a rough guess; a hand waving argument. I'm not a compiler person, so actually arguing this is well beyond my area of expertise (or interest) :) FWIW, I looked at the actual code generated for [this program](https://play.golang.org/p/amh4JkXxY-). I compiled it with `go build -o test test.go` and then ran `objdump -d test` to see the disassembly. From that, without knowing a whole lot about assembly, I do conclude that a) byRangeWithoutSideEffect and byForWithoutSideEffect compile to exactly the same code, as I would have expected and b) byRangeWithSideEffect and byForWithSideEffect seem to differ in one instruction (an `inc` is replaced by a `lea`) - which makes sense, given that they do actually behave differently. I don't really understand what `lea` does, but it is one byte longer, so strictly speaking, the defined semantics of `range` *do* generate less efficient code, than if it was defined as semantic sugar for the obvious for-loop, even if imperceptibly so. But, again, I'm not an expert. Indeed, I don't understand probably 80% of the generated code either way :) I would still be interested in some form of explanation of why those specific semantics where chosen. I consider them surprising and I don't see how they improve codegen either.
&gt; It would also break a much more common pattern people use for finding a index of a rune in a string, leaving potential OOB panics. Can you explain that some more? I never use range on strings, so this pattern is unknown to me and I can't come up with any pattern that would be broken.
I believe, the expectation was that `for i = range v` is syntactic sugar for `for i = 0; i &lt; len(v); i++`. Indeed, `for i := range v` *is* just syntactic sugar for `for i := 0; i &lt; len(v); i++` from what I can tell. That is, if you don't save the variable outside of the loop the generated code will actually do the increment (see [here](https://www.reddit.com/r/golang/comments/6paqc0/bug_that_caught_me_with_range/dkptqz5/) what I base that claim on). I share this expectation of range being syntactic sugar for the for-loop and would be very interested to know, why it was explicitly decided against. Because this decision *does* need special code generated, to skip the increment in the last run, from what I can tell.
&gt; Having a generic, […] does cause more code, you are right... Pretty much the opposite, in fact. You don’t have to handle errors, nor to duplicate the code. Anyway, you’re welcome :)
Downvotes are abundant on the Internet. Don't spend too much time reading into a small number of them, because you'll never be done. The main point of your talk- Turning 1k lines of YAML into 10 Structs with methods is the key take-away for me. Trying to be clever, trying to be overly flexible, trying to anticipate behavior before it exists or is requested is almost always a terrible idea that leads to the downfall of many projects. I'm not trying to pass judgement on the original authors, or the original idea. But it's one we're all familiar with at some point in our careers. Clean, concise, simple code is always going to be more predictable and stable than a behemoth of a project that attempts to "do it all".
`range` is more than just syntactic sugar, though it looks like it from the outside. (not a lot more in the case of single variables over a slice) From [the spec](https://golang.org/ref/spec#RangeClause): &gt; The range expression is evaluated once before beginning the loop And &gt; 1. For an array, pointer to array, or slice value a, the index iteration values are produced in increasing order, starting at element index 0. If at most one iteration variable is present, **the range loop produces iteration values from 0 up to len(a)-1** and does not index into the array or slice itself. For a nil slice, the number of iterations is 0. I would recommend reading the spec. It's not as difficult a read as you might expect, and may give you valuable insights into the language.
I think you greatly misunderstand the purpose of C. It's not outdated because it doesn't need anything new. The domain where C shines the most - low level programming - doesn't need any new "magic", language is finished. The build system, dependency management can be improved further, but language is done. Go's main goal was to be simple. And it is. I don't need over 100 different data structures like there in Java etc. I need a language that doesn't force me to use them when I don't need them. I can write them myself the way I need with my specific requirements. More code isn't always worse. 
1. Type assertions don't enforce a compile-time contract, so any misuse will happily compile but potentially fail at run-time. 2. Boxing &amp; unboxing interface{} values is costly. 3. Even using non-empty interfaces, dispatching an interface method on an unknown concrete type is a costly procedure. In tight loops, like what you may encounter using a sort.Interface implementation, must repeatedly call out to the same method without being able to inline. This is often negligible, but sometimes not. I wouldn't complain about these things in a language like Ruby or Python, because those languages don't market themselves as fast &amp; type-safe. Go does make those claims, yet doesn't provide a reliable way to assert type contracts in a generic way, and so I'd think it would be a natural progression to add generics. The argument has never been "interface{} doesn't work", but "interface{} is not the best known solution" 
Just a bad joke, in case you are confused ;)
To get around the issue of copying each element in the slice, you can use a slice of pointers-to-structs. Bill Kennedy discusses this in [this article](https://www.goinggo.net/2013/09/iterating-over-slices-in-go.html) 
Ugh, NOT having a generic causes more code... I'm the native English speaker, and I can't even express myself as well as someone in their non-native language ;)
I think they also want to see and discuss cases where someone thinks that a particular problem ought to be solved by generics, but instead existing language mechanism can be used instead. I think (I hope) the idea is to collect a definitive set of use cases where the existing language mechanisms really don't do enough, and generics are the best alternative.
Sure, anytime you want to iterate a string for utf8 safe comparisons but need the byte index which is used for slicing. The standard library strings package I'm sure has at least a few examples of iterating a string in this form and returning the index directly to the caller. In the event the index was the last item found .. only if the variable wasn't local to the for block, and.. in range form would it cause the byte index to exceed the start of the utf8 code point. For a multibyte width code point it would return a invalid rune, otherwise panic from oob. I personally feel having such behavior would surprise many more than the way it is today. 
I never read JSON, I never found the human readable part to hold up. Nor do I see the point in it being human readable, the usage of it in web APIs is all automated. You get thrown to a documentation page anyway, might as well have a custom binary format at that point. Of course the network is very slow so one doesn't notice how slow parsing JSON is but still. Note I come from an enterprise networking background so I'm very biased on this topic. I simply never found it enjoyable to deal with handling a blob of JSON thrown at me. If people properly specified their format a binary format is easier.
FYI I didn't downvote you. &gt; That doesn't really match with your original comment; you do say that complexity will be involved, but you don't specify how, which is pretty significant. Yes I should have communicated better. &gt; which is pretty significant. What? &gt; I'd be curious to know what exactly about the compiler itself would make it require a rewrite. Go ships with a lot of built-in developer tools and the compiler can't be seen in isolation from those tools. It's possible that they impose requirements on the compiler that can't be met with the current architecture without significantly impacting performance and stability. Sure the lexer won't be a problem, but that's as far as my knowledge goes. I was aware of the fork but can't seem to find the repo. Since you mentioned it, perhaps you could point me in the right direction? Would be interesting to see what works and what doesn't. &gt; Perhaps. However, your assumption that the article actually needs to be read as far as this debate is concerned is false, and using my lack of reading it as an argument is fairly weak to be honest, because what I said to you had absolutely zero intent of being correlated with the article itself. Your interpretation of it being that way is at most coincidence, but it isn't my fault. Fair enough. &gt; I still think it's a flawed argument. Those who work on Go have a considerable amount of resources that exist far beyond just a few academic oldies sitting around with limited funding - this is Google we're talking about, after all My argument is that those who actually work on Go might not feel that generics are sufficiently beneficial for them to actually implement and maintain them, which would be a valid justification for them not to add generics. You're saying that this argument is flawed, but it's actually the nil-hypothesis from both a legal and an economical perspective. The main difference between the few academic oldies, and Google, is that Google is a publicly traded for-profit company. A publicly traded for-profit company shouldn't spend money on things that don't ultimately contribute to it's profit. This includes charitable donations. Also, implying Google should foot the bill simply because they have a lot of resources is lotter-winner-faux-friend kind of justification. &gt; Separate teams have existed in the past for this kind of rewrite: you have developers who continue to maintain the stable branch, and developers who go off and do whatever is necessary to produce a working version of the compiler with Generics support. Of course it's possible to add generics, but why should Google be the one to foot the bill? &gt; This makes absolutely no sense, considering that feature addition like Generics can be implemented in such a way that it doesn't break backward compatibility. What about the reflect package? What about all of the third-party tooling? &gt; Actually it doesn't, because I'm fully aware of my lack of entitlement: I really don't care whether or not Go has generics, because I'm not a Go programmer. I never said you were entitled, I merely pointed out that your argument came from a place of entitlement. &gt; That said, my whole point is based on the premise that Generics being implemented as an official language feature are what's important. The reason for this is because it's guaranteed support and maintenance by more than just one person in the future, Exactly. &gt; and that support is coming straight from the horse's mouth and not some ragtag group of coders who don't have time to commit 40+ hours a week towards Go in general. Exactly.
I read the spec. I did not say that the code was violating the spec, but that the behavior from the spec seems surprising and that it disagrees with my expectations of obvious behavior. I *did* acknowledge that this was a conscious decision and I *did* say that I would be interested to know the reasoning behind it. So I think I made it fairly clear, that simply restating the decision isn't really a satisfying answer…
&gt; but then trolling afterwards... That's just uncalled for These things take commitment, m8. No one ever said it was easy.
I was addressing your second sentence - "Indeed, `for i := range v` is just syntactic sugar for `for i := 0; i &lt; len(v); i++` from what I can tell." I did a quick search to find out why, but found nothing.
True. Features as far as D is concerned have little to do with its success or lack thereof, though, in the long run. The reason D isn't successful is because their execution in terms of adoption has been poor. In fact, I'd say that D's only real fault is that. It's a language many people want to adopt because it really is a great language, but the ecosystem makes it incredibly difficult to commit to that. Furthermore, you seem to be coming from the case that more features somehow implies features that are significant, and have been proven to be successful and useful in other languages of similar paradigms. Not every language feature ever devised is good, yes, but that doesn't by any means discount or imply that quality features != success. In other words, my argument has nothing to do with quantity of features - it has everything to do with quality of features. And while more features != success, C++ has nearly as many features as D does. C++ may even have more features than D does. And C++ is a _lot_ more successful than Go is.
&gt; Sure, anytime you want to iterate a string for utf8 safe comparisons but need the byte index which is used for slicing. This isn't really helping. Do you have some code to illustrate? It's legal to slice `v[len(v):]`, so slicing wouldn't panic. And I also still can't imagine when you'd do var i int for i = range s { // stuff } s[i:] in a way that would make sense, if the range runs to the end of the string… &gt; The standard library strings package I'm sure has at least a few examples of iterating a string in this form and returning the index directly to the caller. Nope, all occurrences of `range` in the strings package use the `:=` form, so can not be affected by OPs question.
None of these issues have affected me in any real life scenarios.
The proof is in the pudding, my friend, as well as sheer history. Before Java had generics their method for dealing with type safety was by relying on inheritance hierarchies. This was useful in many respects, but it also provided erroneous results in situations where you'd have, say, a container class with 300 Object references, each of which could very well be a reference to any kind of class instance. Initially this isn't really a problem: you just cast the result to what you expect. As your system begins to increase in complexity, so do the requirements that need to be handled, however. Consider the situations where you find yourself realizing that your data structure which contains a list storing Object references needs to be reused in other areas; each of these areas may have multiple types of objects needing to be stored. The amount of organization and boilerplate needed to do otherwise simple operations when generics are involved is actually quite a bit. The more code you have to write for a repeatable operation is always going to introduce more maintenance overhead as well as proneness for error. Of course, this also implies more time necessary to finish tasks. Exceptions are of a similar nature: you're mixing error handling with return types, and limiting those return types to different kinds of enumerations. So, when you want to return a non-error-related value from a function you're either forced to resort to passing pointers to the data you want to fetch or a pointer to the error value itself. Now imagine you've got these functions called in, say, 100 different locations. That doesn't really sound like a _brutally practical_ way to handle maintenance of sufficiently complicated _systems_, which Go is supposed to be designed for, does it? With exceptions you bury the maintenance burden using inheritance and polymorphism, and you also have the option to handle all generic cases in _one_ catch block and add additional blocks for situations where specific edge cases really need to be taken into account (and this is often rare). Like I said in my previous post, this is the result of 40 years worth of mistakes and iterations which have been tossed aside. If I want that kind of low level control I'm going to be using C, because that kind of low level control is really only useful today for situations where real-time performance is significant...and a GC obviously isn't really desirable for real-time performance constraints. But, don't take it from me: the language designer was smart enough to be one of the main programmers of an operating system which is only mildly more important than GNU's Hurd. 
According to the release notes source ([in an HTML comment](https://github.com/golang/go/blob/44275b8569085e405bd50f6373f201167c1850ee/doc/go1.9.html#L850)) it's referring to [this change](https://go-review.googlesource.com/c/43641).
I have used D for years before giving up on it. There were more than one problem IMO: 1. They made The Mistake from the start - they wanted to make C++ replacement by making language with GC. Big no no. Many languages made same error, including Go, but Go have lot of qualities so it attracted different kind of folks, just not C++ guys. Lesson: if you want to replace most popular managed language, don't force GC down peoples throats. 2. Devs didn't cared for user feedback. This lead to big problem down the road (two "standard" runtimes/libs) and huge fragmentation of community. Lot of people quit. 3. D suffers of "authors favorite toy" syndrome. It is fun to add new fancy features (and they keep adding and adding...). Constantly change and break things. Fixing bugs not so much. Adding boring but required tools that help with every day tasks is not a priority. Standardizing one of many community provided tools was too slow. Listening to people too (see 2). Maintaining backward compatibility with language? Please, we are in the process of making best language, you just have to suck it up for next 10 yrs. 4. Bottom line, lack of clear destination and design. Trying to make "better C++" produced language similarly complex and with comparable number of warts that keeps on growing like a tumor (adds features), but it lacks sizable community to be able to carry its weight. 
Shade aside, there's lots of excellent content there (Standford CS material). 
Its Go's philosophy to provide you good tools to make it quickly yourself. There isn't one size fits all solution. Even concurrent maps will not be as popular as they may seem.
I know what you are doing here and responding will provide no value to either of us. Post on the mailing list or slack if you want justification for this I have other things to do.
&gt; I am not quite sure how you can claim to understand channels and slices in Go and make this statement I am not quite sure *you* understand channels, maps and slices in Go and fail to see that the runtime "cheats" by using generics for a few well-known built-in types using mechanisms that aren't exposed to programmers using the language. If I'm wrong, please provide a type-safe red-black tree data structure in Go that can work for *any* type I instantiate it with while ensuring that I only store/retrieve objects of that particular type. Without using reflection. 
Agreed. I have seen people complain about having to use map[string]interface{} because of "lack of generics", when what they really want are discriminated unions (http://golang.org/issue/19412). That is, the ability to say that the value is one of several possible concrete types. I other cases, people blame generics when the problem cannot be solved with generics (because the type is fundamentally unknown at compile-time) or it cannot be solved unless the generics type system was incredibly complex. For example, in the Context type, you would not be able to get rid of the interface{} type in Value(key interface{}) interface{} unless you could somehow encode at compile time that the type of the value is dependent on the type of the key. I personally hope Go never allows this. Generics is not an end-all to getting rid of interface{}.
It's currently not even on the milestone... https://github.com/golang/go/milestones So, anybody's answer would just be a guess.
Seriously, just watch the talk. Russ is saying we need a way to plan for go2. Like in most things, one must define the problems before jumping into a solution. 
Good for you However plenty of others *are* affected
&gt;They just don't want generics. What I find funny about that is that they *already have* generics for 3 "blessed" data structures. Also overloading the "+" operator for strings and nothing else, but....I can live with that. If they didn't see the value of point of generics, why are slices and maps (and channels) generic ???? Clearly having compile-time safety is understood and clearly having type safe maps and slices was seen as important from Day 1, but somehow - nothing else. It's just strange. Maybe slices and maps are the only "real" data structures we need to care about since they probably cover 80% of use cases? That's fine. But come out and say it - "We, at Google, have never encountered the need for a type-safe btree. Ever. So we only did maps and slices". But *having* no fewer than *three* built-in generic data structures and requesting people provide "real use cases for generics" - that I don't get. 
I watched it lol. I agree we need a plan. Part of having a plan is having a timeframe in which you intend to execute the plan, hence the question.
Unless I'm misunderstanding you, this is trivial in any reasonable approach to generics. In pseudo syntax: type Context&lt;Keytype, Valuetype&gt; interface { Value(Keytype) Valuetype }
Russ did mention that if Go 1.20 is good enough to be called Go 2, it'll be called Go 2... Go 2 as such, isn't really much of a concrete goal, IMO
I doubt it 
What exactly are you asking for here? All data structures to be thread safe or alternative implementations of all data structures that exist in thr std library that are thread safe? 
I mean, that's fine. I'm glad that Go is a good fit for your use cases, but being a general-purpose language, it may not be a perfect fit for the use cases of others.
The exact value type is dependent on the what the key is. For a given instance of Context, it is not the same value type that is retrieve. For example, when the key is http.ServerContextKey, the value type retrieved is *http.Server, but if the key is http.LocalAddrContextKey, then the value type is net.Addr. Your example does not encode that information. 
If it's not a good fit for you, then don't use it.
You know what... I'm disengaging. You're not being reasonable, engaging in discussion, or contributing anything of value here. A tool can be great at 9/10 things and that makes it a good tool, but sometimes you realize you need a 10/10 utility tool to get a job done right. That doesn't make your 9/10 tool bad, just imperfect for the task at hand.
Maybe that 1/10 makes the tool shittier in other ways.
That's a mis-design of Context due to the limitations of the type system in my opinion. In a future golang with generics to keep that aspect and gain static type safety you'd need to use a wrapping sum type (which is something else golang desperately needs). If you wanted to avoid the need of a sum type you could do that with dependent types, but I personally think that would be a step of complexity too far for golang. Alternately, just because we implement generics doesn't mean every single current usage of interface{} has to change. My motivation for generics isn't to change the api of Context for no clear benefit, it's to do things that are impossible to do today. Like write a type safe reusable version of basic data structures such as btrees, priority queues, etc without resorting to codegen.
I'm not sure I've seen Go code that sucks because there are not generics in the language. Can anyone provide some?
Hold your breath :) 
How does a sum type help? You don't know what the type of the value is. It could be a type defined in any arbitrary package. &gt; Alternately, just because we implement generics doesn't mean every single current usage of interface{} has to change. I absolutely agree. &gt; My motivation for generics isn't to change the api of Context for no clear benefit I agree as well. I would love to see some form of generics, my main original point far above is that I would like to see some generic type system that does most of what we want without being overly complicated. And like you said, it is totally okay that some APIs must still use interface{}.
I'm going to use the concurrent map and I'm excited for it to land in a stable release! But meanwhile I'm using a different data pattern that doesn't require a concurrent map. Sharing by communicating is a great model to follow.
https://blog.golang.org/share-memory-by-communicating
[removed]
Would anyone here mind if you downloaded production software that was built on a Go release candidate? I ask because I'm seriously anxious to get some of the goodies from Go 1.9 into Caddy, and I'm slating a Caddy release for later this week... sooo...
You should probably ask your users, not us. If I were starting up a Caddy project in an hour I'd probably go for the based-on-1.9 thing because It's The Future™, but I don't know how twitchy your users would be. Edit: Can you think of anything that you would add that's new in 1.9 that would make some user running Caddy in production (instead of nginx, say) that would accidentally break something he depends on to keep his site running?
&gt; Caddy Google is using 1.9rc1 in production: https://twitter.com/bradfitz/status/889898218573766656
Thanks. My question was meant to be "in general" but how the answers apply to me specifically is usually Caddy. Do people build their distributions on Go RCs, and if not, is it because people don't like the idea of it? (I think it's usually fine, but I want others' experiences.) &gt; Edit: Can you think of anything that you would add that's new in 1.9 that would make some user running Caddy in production (instead of nginx, say) that would accidentally break something he depends on to keep his site running? No, but, it's always the unforeseen problems that bite.
Yeah, I saw that, which is why I'm asking what the rest of Go-dom thinks. (I'm all for that as well, but I don't want to alienate users. If there's a perception that RCs are not good enough for production, then maybe we can change that by making production builds on RCs.)
If Google is using it in production... Also, you can look at historic RC1 releases and compare them with final releases. Sometimes, it's a few minor breakages or problems with new featured in rare edge cases or environments. Mostly doc fixes, etc. The bigger issues get caught in betas. Or RCs only if people never try the betas. However, you will want to be able update to newer RCs as soon as they come out. I've been using the betas in prod since beta 1, but had to go back to 1.8.3 because of a critical html/template regression I quickly ran into. I've reported it and it was fixed for rc1 (it was one of the blockers for non-beta release). See https://github.com/golang/go/issues/20842. Now I'm using rc1 and not seeing issues so far.
If I knew about Google's policy re: Go RCs I'd be fine with Caddy using RCs to build things for production use. Otherwise I'd be twitchy (you saw my other comment saying as much).
Also, for anyone also using the GopherJS compiler, you can start using its `go1.9` branch with this Go 1.9 RC 1 release. See https://twitter.com/GopherJS/status/889948789037047809.
The biggest issue is that interfaces don't give enough compile-time control to the end-user, making it harder for the user to use a library in a way that the author didn't forsee. Interfaces help, definitely, and the way they work is a massive improvement over, for example, Java's interfaces, but there are areas where they just simply don't do enough. In general, the places where `interface{}` can be used could probably be argued to be 'good enough', by and large, although there's definitely quite a bit of grey area. But a lot of places where you have to use `reflect` is where things start becoming quite a bit more problematic. Try writing a reusable `sum` function that works on every number type. You basically have three options: Require the end-user to convert numbers to something that'll probably work for most cases, like `float64`, introducing possible loss of precision, use a massive type switch, which is not only tedious and annoying but, again, limits the types that can be used and also removes compile-time type safety, or use `reflect`, again removing compile-time type safety, making the code much harder to read, and also introducing a pretty big performance loss. Those problems are not in any way unique to `sum`. The entire standard library suffers from it pretty heavily. The example of `sum` could be applied to darn near every single function in the `math` package just as a start, but there are also packages that can't even be written because of it. Wouldn't it be nice to have a `chans` package as an analogue to `strings` and `bytes` with utility types and functions for channels? And you're right, badly done generics could cause the code to read like C++, Java, or Rust code, which would certainly be a disaster, but I think that it's worth the risk for at least some type of generics. The Go team has come up with nice clean solutions to existing problems before; maybe they'll be able to solve the problem of unreadable generics this time.
Ian Lance Taylor's proposal on [type parameters](https://github.com/golang/proposal/blob/master/design/15292/2013-12-type-params.md) is closest to how I see generics happening in Go. The limitations of the current proposal are discussed at the end, so I suggest giving it a read.
Don't feed the troll.
&gt; If you or your team already knows SQL and prefer it, then using an ORM is a bad idea. Working with relational databases without knowing SQL is a bad idea. Mind you, I do believe that ORMsm when done well and used to remove boilerplate from simple, repetitive operations, are a great tool to keep around. But there is no excuse for a developer working with databases to not know the basics of database interaction.
See [Summary of Go Generics Discussions](https://docs.google.com/document/d/1vrAy9gMpMoS3uaVphB32uVXX4pi-HnNjkMEgyAHX4N4/edit). tl;dr; performance and type-safety are hard to accomplish (in some cases) without code generation or duplication.
Interfaces can't guarantee that you are using the same type in two places. Take this example binary tree code: type Node struct { value interface{} left *Node right *Node } type Tree { compare func(interface{}, interface{}) bool root *Node } func (t *Tree) Insert(i interface{}) { // use t.compare to insert i } func main() { compare := func(l interface{}, r interface{}) bool { return l.(string) &lt; r.(string) } strTree := Tree{compare: compare} strTree.Insert("string1") strTree.Insert(1) // compiles, but panics in comparison function } int and string both implement the interface, but the comparison function only makes sense if it compares apples with apples (i.e. the concrete type behind the interface needs to be the same). Generics or parametric types allow you to prove this in the type system. E.g. type Tree&lt;T&gt; { compare func(T, T) bool ... } func (t *Tree&lt;T&gt;) Insert(i T) { ... } func main() { compare := func(l int, r int) bool { return l &lt; r } intTree := Tree{compare: compare} intTree.Insert(1) intTree.Insert("bad") // compile error // intTree has type Tree&lt;int&gt;, so intTree.Insert takes an int, not string } There are a small number of cases where you can work around this issue with minimal boilerplate (e.g. the sort package), but sometimes it really sucks.
I was pretty excited about them until one of our developers tried them in the RC. Turns out they're slower than the access lock RWMutex pattern we were using around our non-concurrent maps :/ Caveat: I'm sure this is not true for all use cases or usage patterns
In order to deploy Go1.9 RC1 as the default inside Google, we do a significant amount testing to make sure the transition from Go1.8 to Go1.9 is as smooth as possible. Sometimes this means fixing regression bugs in the toolchain (e.g., https://golang.org/issue/21120, https://golang.org/issue/21121). However, oftentimes it means fixing brittle code inside Google that made unfounded assumptions about behavior of the Go toolchain that changed in Go1.9. At the time that we cut RC1 it means that *Google* is not aware of issues (either in the Go toolchain or in the Go code at Google) that prevents RC1 from being production ready *for Google*. Now, to a degree it is reasonable to assume that the vastness of Google's Go code is a representative sampling of how the world uses Go, so regression bug discovered by Google also benefits the world. However, any sufficiently large code base may still use Go in a way that triggers a regression bug that did not affect Google. I don't know if Caddy has a set of canaries that thoroughly test Caddy in a production setting with production-like load. If so, I recomment building Caddy with Go 1.9 RC1 and send it through the canary for a bit and make a judgement for yourself of whether Go1.9 RC1 is production ready for you. My talk at GopherCon was essentially about this subject: https://www.youtube.com/watch?v=OuT8YYAOOVI P.S. I mention above about the regression testing Google does, but I do want to acknowledge and thank all those who do regression testing themselves during the betas and RC1. P.S.S. We're also heavy users of Linux, so we do rely on the community at large for discovering regression bugs for other GOOS.
Thanks for filing #20842, that was an annoying regression bug that was affecting us at Google too. It saved me the time needed to root cause it :)
The big real world example I've seen is the lack of robust third party libraries in the ORM and testing spheres of development. There's no easy way to achieve 100% unit test coverage in Go, because the code has to be written in a way that it can be mocked. Languages like Java have test frameworks that handle all the dependency injection for you, and generics make this easier to build out. Also, if you look at libraries like gorm, there are tons of uses of empty interfaces to hack around the lack of generics. There's no way of getting around it. In Java I can use Spring Data and write a single interface which defines my entire repository API which is generated at runtime by Spring. In Go I have to write every line of code to do that for me, and use hacks like empty interfaces to avoid writing tons of duplicate code. It's fine if you don't have these issues, but don't just shrug off what others bring up because you didn't personally have that problem.
Updating quickly as new RCs come out is a good point. If your project aims for reproducible builds, it means a new version of your project for each new RC, and then yet again for the stable.
These are amazing insights, thanks! I'm gonna watch your talk soon. :)
You keep making this argument, but it doesn't make any sense. You can't use the fact that people already make use of the existing non-user-level generics as proof that user-level generics should be a thing (we all know generics is useful). That's like saying: you've used an electric screw driver, therefore it should be obvious that you need a drill with generic/interchangeable bits... There's a reason that we're being asked for well formatted real-world experience reports instead of vague opinions that everyone's heard a thousand times over the last 5+ years. Some people write programs that are just fine with the limited support for generics we already have so it should come as no surprise that these people have no need obvious need for more generics. If you want to make any progress, then you need to start talking about the problems you're actually having... 
Interfaces are great when you only need to perform operations on individual values polymorphically. The problem is when you need to perform an operation involving multiple values, where you often need the types of the values to be related in some way. For your Comparable example, you actually can't do that without generics, since you need to operate on all lists whose elements implement Comparable, not just lists of Comparable. Even the idea of having operations on lists of different kinds of things requires some form of generics. If you're relying on the hypothetical ability to say "List&lt;T&gt; where T implements Comparable is assignable to List&lt;Comparable&gt;" so you can write functions in terms of List&lt;Comparable&gt; instead of making them generic over all such List&lt;T&gt;, that requires the generic type List with the type parameter T (and is unsound if the list is mutable and the original List&lt;T&gt; can be used after the assignment). This doesn't work in Go even for its built in generic types because different types of slices (for example) have different layouts in memory. The way Go solves this is with sort.Interface. You have to create a named slice type and add some methods to it so that the sort.Sort function can operate on it using only indices, preventing it from having to interact with the elements directly, which would require some form of generics. This technique isn't generally applicable, though. You can come up with ways to create a single value that provides methods that allow calling code to manipulate multiple values indirectly whose types need to be related, but this gets convoluted fast and creates stilted, error prone code.
I'm not sure what your point is... I lost count of the number of times I've apparently been shadow-banned for no other reason than the fact that I logged in over the Tor network or a VPN. 
The C-form for loop runs until i &lt; len(v) becomes false. This naturally means that i must be len(v) at the end (but at this point, the loop body is not executed anymore). An equivalent loop: for i := 0; i &lt; len(v); { fmt.Print(i, " ") i++ // this is the place where the C form executes the i++ } The Print() statement would not catch the last increment as the loop exists at this point. The range loop only delivers the indexes that belong to an actual execution of the loop body. Thinking about this, the behavior of range seems more natural to me than that of the C form loop.
No problem, glad to hear it wasn't just me being affected. :) Finding a minimal reproduce case was trickier than I anticipated. But [fun](https://www.youtube.com/watch?v=ydeTUaJbPHE)!
i thought slices, maps and channels are all i need /s
The quote you pulled is a bit out of context. If you read like 2 sentences further it becomes pretty clear that I'm assuming that most developers fall into one of three categories: 1. Know SQL well and prefer it 2. Know SQL well but still enjoy/prefer an ORM/SQL building library 3. Don't know SQL very well My point was people who fall into the first category will pretty much never enjoy using an ORM, but for those who fall into (2) and (3) an ORM is a good option to consider. I don't believe I ever stated that you shouldn't learn the basics of SQL, and if I did it wasn't intended. Even newbie developers should try to get a rough understanding of SQL and how relational databases work, but that is VERY different from knowing SQL well enough to prefer using it over an ORM. And in my opinion the argument of "why are we learning a new tool when we know SQL?" is only applicable to developers who fall into the first category, making it a preference based on experience, not a reason why ORMs are a bad idea for everyone.
Video linked by /u/sh41: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [issue 20842 timelapse](https://youtube.com/watch?v=ydeTUaJbPHE)|Dmitri Shuralyov|2017-06-29|0:00:17|0+ (0%)|78 &gt; See https://twitter.com/shurcooL/status/880266223103168512... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/sh41 ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dkqdktq\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.3b
I think the point is to get a) the possibility to have github build the page for you (so, don't push the built HTML, but push the source) and b) get quick builds. As someone who is constantly frustrated with jekyll and its breakages on updates, but can't replicate the structure of their site with hugo (so moving to that would break existing links and feed-subscribers) I welcome this effort :)
Exactly. More of those please, instead of op-eds and opinion pieces.
Assuming this is a genuine request - see &lt;https://golang.org/pkg/container/heap/&gt; Try to use it. Then try to use a [Priority Queue in Java](http://docs.oracle.com/javase/7/docs/api/java/util/PriorityQueue.html) which is their equivalent. 
Sure, why not. Here's a partial syntax I put almost no thought into, thus guaranteeing that it's better than any of Ian Lance Taylor's extremely long and well thought out proposals: type T generic { oper T + T -&gt; T // Could also be things like: // oper append([]T, T...) -&gt; []T // func (T) Less(T) bool } func sum(args ...T) (s T) { for _, a := range args { s += a } return s } 
Of course using some binary format will be faster but there are advantages to both. It just completely depends on the use-case. One big plus for JSON is it's simplicity. You can parse JSON in any language. It's also a great choice for web stuff because it's natively supported by the browser.
Just because there's built-in data structures using generics, does not in any way mean that their design of the language requires it to be exposed to its users. The language is obviously far simpler without it, and plenty of other languages are available if you require generics (I use Rust if the use-case requires it). Every language doesn't need to be the end-all to programming languages. In terms of everything else in your post, [this reply](https://www.reddit.com/r/golang/comments/6pgcqz/are_we_there_yet_the_go_generics_debate/dkps51g/) will hopefully explain the reasoning behind requiring as many use-cases as possible before thinking about the implementation details.
&gt; I know what you are doing here and responding will provide no value to either of us. o.O What am I doing? I was legitimately asking a question. You talked about this breaking some utf8-related things. I don't understand how it would. I just *really* don't. But you where specific enough, that I assumed there was a specific problem to understand here. You are making me think there isn't. &gt; Post on the mailing list or slack if you want justification for this I have other things to do. I did. I got [a really good reply](https://groups.google.com/d/msg/golang-nuts/Xi6W3H5mlto/c83R7btFAwAJ). Just to demonstrate that I'm not trolling, if I get a good reply, I'm satisfied. I'd still like to know if there was something specific going on with slicing and utf8 that I don't understand. *Honestly*. Not trying to trap you or troll you or anything, just genuinely want to understand what you where thinking, because I can't figure out the problem from what you said so far.
Having knowledge of a few languages which cater to different problems immensely helps being able to engineer solutions properly, and should guide tool (programming language) selection. I'm always shocked when developers don't include this step as part of their solution process.
For reference: I asked on golang-nuts and I got an argument for this behavior that convinced me that its a good thing: https://groups.google.com/d/msg/golang-nuts/Xi6W3H5mlto/c83R7btFAwAJ tl;dr is, that there would be no way to both be consistent with `i, v = range arr` and have `v` be something meaningful.
That is fundamentally misunderstanding what Context is designed to do, which is to pass data through APIs without that API having to know about this. If the type of a context argument would carry *any* information about what is contained in it, it wouldn't fulfill this purpose anymore. (the real solution to a type-safe context would be dynamic scoping. I intend to write that down at some point, but not now)
Look at the second example [here](https://golang.org/pkg/net/http/#FileServer).
&gt; If they didn't see the value of point of generics, why are slices and maps (and channels) generic ???? As I said in the comment-section of that blog post: This is a weird argument. It's like saying "if imperative programming and side-effects and mutable data are bad, why does Haskell have an IO-Monad?". It is not contradictory, to both believe a feature to have some use *and* believe that it should be limited to isolated use-cases.
Please fork. For everyone's sake. Just fork.
I'm not convinced the functionality/utility of Context requires an inherently untyped interface. For example, I don't think it would be totally horrid if Context was just KV or EAV data of uniform type, or even only specialized on the value type. I'm intrigued by what you suggest about dynamic scoping as a solution.
I used it a bunch of times (whenever I needed a heap, probably ~3 times in just as many years). Don't see any problem with it.
&gt; but potentially fail at run-time. Will it also practically fail at run-time? I.e. is this a practical problem, or a theoretical concern? Note, that I'm not saying it is *not* a practical problem. Just that pointing to practical problems that arose from the usage of interface{} is a *lot* more useful than stating it as a theoretical issue (and so far, I have completely failed to get anyone to even point me to a single bug caused by a type-assertion on an `interface{}` from a generic container failing). &gt; [2. … 3.] Practically, or theoretically? Again, not saying that neither is the case (I actually could probably write down an experience report about the image package for this, which has exactly these problems), just that *specific instances* of this problem from practice are much more useful to base engineering decisions on, than broad statements and abstract assertions.
I'm especially loving the footnote. 10/10 for showing previous proposals. I mean, that's what revision is for, improvement. It gives lovely insight into the improvements over time, considering the pitfalls of each proposal vs. the next proposal. A lot of people zero in into one or two bad practices/key notes, and try to discredit generics as a whole, because some of the proposal doesn't make sense/could be better.
&gt; How does a sum type help? Generic sum types need not be closed. It's hard to imagine golang would implement generics that way considering it's already all in on structural interfaces.
Could you write this down structured as an [experience report](https://github.com/golang/go/wiki/ExperienceReports) and link it in the wiki? ORMs seem like an interesting use-case to keep in mind when thinking about if and how to add generics to go.
As the ROFLLOLSTER example shows, the FileServer will use the URL path to look into "./static". So it will look for "./static/test/index.html". You thus have to remove the segment of the path you don't want to be part in the file lookup. 
You made my day :)
Why can't they all be part of the same package?
Something that the article does not fully address is maintenability which is paramount for projects. Frankly that's a gray area. Will a project be more maintenable in the long run if it uses an ORM or plain SQL? It's a hard question since maintenability is not something we can easily measure. It's probably faster to add new features that require the database with GORM but it's probably easier to debug a problem with plain SQL. How about changing existing code? That's a really gray area. I tend to favor SQL when it comes to maintenability but only because I've been badly bitten before by Hibernate and Active record. But I do not have any measurements and frankly GORM is not Hibernate and it's not Active record. Still the article assumes that GORM is by default more maintenable than SQL. I would appreciate it more if it had a section on maintenability even if the conclusion was that "it depends" or "We can't really tell so we went with GORM".
They can be, it just moves a lot of mostly unrelated code together which I was trying to avoid. Definitely works though.
If think we can build caddy alone if we want to test it with 1.9, but it should not be a release. Google is different, if they find a bug in Go 1.9 they have the possibility to repair it immediately, not us... I think it's good to test 1.9 in production but not for a public release.
They are not really unrelated. If your project was named `foo`then it makes total sense to see in the code `foo.Character` and `foo.Action`. The package name becomes very descriptive. On the other hand `character.Character` what does that even mean? We have to go up and look at the import to see that `character` belongs to project `foo`, not to mention the stuttering. Check out the article [Standard Package Layout](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1).
It could look like this using generics: func Transform(arr []$T) []$T { m := make(map[T]bool) s := make([]T) for _, v := range arr { m[v] = true } for k, _ := range m { s = append(s, k) } return s } Not only generics version is type safe (won't crash if you input wrong data type, ...) so you don't have to check for anything at runtime. If it compiles it is good. Also it is MUCH more readable.
I like your joke. Especially because of another which is: "There's a grain of truth in every joke" ;)
Nobody asked for how to implement generics. Assume that the Go team can handle this. They explicitly said they need use-cases for where generics are needed, would improve the quality of life and so on. Let them handle the design of the feature and you make sure you send your use case where generics would be better than any other solution. Nobody needs yet another spurious thread about how someone who doesn't understand the complexity of the problem would solve it. No, we need to understand what's the problem first, the solve it. That's how good engineering is done and that's how the language we have today was born. So please, stop with this nonsense. 
Aww, thanks :)
Thanks, I think that is the approach I'll take. Edit: It ends up being a lot of code in one package because most of the application in this case is methods on those types rather than things that have external dependencies. I guess that's not too bad.
It's official! Half-Life 3 confirmed! 1.20 means 1 2 0, means 1+2+0, means 3, right there! And since we know Go 1.20 will be released in 2022 that's another hint right there: (2+2+2)/2 = 3 and there are 3 2's in 2022. So Half-Life 3 is confirmed for 2022!
I agree, that maintainability is a bit of a gray area and depends on the specific situation. For the "general" case, I would say that SQL is more maintainable, as it's the older/more established standard than any libraries (even hibernate, AR) and the knowledge people have transfers well. If there is however an established and battle-proven ORM library the whole team knows well (or which is easy enough to learn), then I don't see much difference in terms of maintainability. You can create bad code with and without an ORM. ;)
With the (imo very sane) approach to Go 2.0 suggested by Russ Cox, is the timeframe even relevant? If the transition is smooth and step-by-step with community inclusion, there should not be a "switch or get left behind"-period.
In my opinion these methods belong in the same package unless they call database code or something.
I love to watch these "best-practices" / "idiomatic go" / "antipatterns" talks regularly to keep myself honest in day-to-day coding. Great talk!
One issue with allowing user-defined generic data structures in a language like Go is memory management. While we may benefit from code reuse and type safety, we won't have explicit control over how our data gets allocated/freed. The implementations of slice, map, string, and chan all get away with using [runtime.mallocgc](https://github.com/golang/go/blob/master/src/runtime/malloc.go), where being close to the runtime allows them to performance-tune for different types/situations. For user code however, it is largely a guessing game to be sympathetic to the runtime's behavior. *On the other hand*, rarely will a user-defined data structure look as simple as the following: type Node struct { Data interface{} Left *Node Right *Node } func (n *Node) Walk(n Node, visit func(Node)) {...} If a tree is being used in a program, it is usually specific to a context, such as a B-Tree for filesystems and databases, a BSP-tree for binary space partitioning, or an AST for parsing. For example, take a look at ast.File (which satisfies the ast.Node interface): type File struct { Doc *CommentGroup Package token.Pos Name *Ident Decls []Decl Scope *Scope Imports []*ImportSpec Unresolved []*Ident Comments []*CommentGroup } I guess the assumption that is made here is that your data structure is either so complex and performance-critical that its implementation is dependent on the data you're working with, or you're willing to eschew type-safety for a more generic implementation. That being said, I agree that this assumption breaks down in many situations, especially in specialized domains like lower-level systems programming, research, university curricula, etc... I personally think that the [sum types proposal](http://golang.org/issue/19412) would have many tangible benefits to Go programmers who want to impose a stricter constraints on types, without implementing tons of unexported methods to satisfy an interface.
I would say that people in category 3 should not use ORMs. They will shoot themselves in the foot. People in category 1 can use ORMs, they might not enjoy it, but they will be able to use one effectively. ORMs do not help with complexity, they make the simple stuff easy at the cost of extra complexity. The complexity may often be worth it, but I wouldn't use it when teaching. Learning is hard as it is, no reason to introduce too much new stuff at once. 
&gt; All data structures to be thread safe Yes.
Channels are slow and use mutexes under the hood, the theory is nice but in reality it's not always the best thing. Also channels don't have a flexible buffer = not useable in every case.
I agree with your statement that ORMs don't necessarily reduce complexity, however, from my experience teaching at university over the last few years, I can't 100% agree with your second statement. If the goal or focus is to teach interaction with Databases, then I agree, ORMs shouldn't be used. Keep it simple. If, however, the goal is to teach high-level things such as "How to build a web-application in Language X" there is already quite a bit of complexity to consider without thinking about a database layer. In such a case, I find it reasonable to "abstract away" SQL, as the interactions won't be complex in any way. But in general I definitely agree, that ORMs rather increase complexity, especially when learning.
nice. Have you written anything about ECS vs Kubernetes on AWS? 
Thx, didn't found it. I usually prefer not to rely on an exec of a binary which might not even be found and than parse it's ASCII output, but for my use case it's sufficient. Case solved. :)
Very Interesting article. As someone who has been poking around ORM's for a while I have come to rely on ORM's to help mapping the results of the queries rather than building them. Some people who hate gorm( I used to be one of them) is the fact when you are advanced user (You know SQL well and Golang well) you tend to be careful on which libraries you use, and most often you check the source just to be sure what is happening. The gorm source is not that attractive, It took me a whole month just to understand and track things down, and I started submitting patches due to vision differences with the project I had to fork it and refactored a lot of the underlying code implementation but keeping the API here is the project https://github.com/ngorm/ngorm Can't say much about other ORM's though. But mapping query results to go types by hand is painful.
Generics!
Each time the discussion about this topic in this sub feels like: — If they wanted to implement generics they would have done it long ago. They just don't want them. — No, the core team went to numerous discussions about them and their implementation in the past. Generics is a difficult topic. — What so hard about them? Just implement them already. Rust have them. C++ have them. Haskell, D, Java, C# and most of other strong statically typed languages. — You named at least 3 conceptually different generics implementations in your previous sentence. Each one have advantages and disadvantages. Which one should we chose and why, when applied to Go? — ... — So? — If they wanted to implement... — F***! I mean - for something sake - Go team asked about user experience to help them decide on what should be covered by template types and how. Instead of saying "duh - concurrent maps" think about what kind of constraints said map should have on container type. How those constraints should be represented? Should this map support T-&gt;Y transformations and why? Should we have overloading based on constraints? 
I recall doing something similar with my RSS reader (as there's a few formats kicking about), nesting each unmarshal so the next one would be attempted if there was an error.
With Go 1.9 shipping in mid-August and the 1.10 merge window opening shortly thereafter, is the plan still to merge some or all of dep into the main toolchain in 1.10? The last response from the Go developers (Russ Cox in particular IIRC) seemed to indicate that dep being merged was far from a sure thing, but that was quite a while ago and the recently updated roadmap seems to indicate that 1.10 is still the target. I hadn't seen anything on golang-dev or go-package-management about it, but it's quite possible that I just missed it. But even outside the standard toolchain, it's still a very useful tool, and all the effort going into it is greatly appreciated!
Sure, I can do that. It's a pain point when you see these things as solved problems in other languages, but not easily solved in Go.
I would like them to finally say that they don't want them. Then I will be finally able to simply get angry and that will be the end of that. I don't understand why they don't want to have compile time type safety though.
You think C++ and Haskell are closer than Go is of any of those language ?
For the curious, here is golint's list of common initialisms: https://github.com/golang/lint/blob/c5fb716d6688a859aae56d26d3e6070808df29f7/lint.go#L742
I know this is pseudo code, but I cringe at some things here. Create `s := make([]T, len(m))` so append won't do multiple allocations. I would even consider the same with `m := make(map[T]bool, len(arr))`. That way you're at least left with only one possibly unoptimal allocation for `m` (if the slice is of reasonable size). Sorry if I'm being a pedantic PITA &amp;&amp; I undestand this has nothing to do with generics :)
It looks like docs have quite a long way to go still before anything could be released. That's an area I'm probably able to assist, but I haven't been able to play with it enough to feel like I understand how to use it yet myself. **EDIT:** The docs have improved a lot. I'll need to revisit dep this weekend. :)
I really like the idea of templated package. I would just use them differently. Instead of specialize them inline, I would specialize them in the import section like this import "foo/bar/hashmap"&lt;hashmap.String, int&gt; (actually I would prefer this syntax : import "foo/bar/hashmap" {key: hashmap.String, val: int} , but that's bikeshedding) Note that's is possible to have multiple specialization like this : import mapStrI "foo/bar/hashmap" {key: hashmap.String, val: int} P.S. I'm not a native speaker. I feel my usage of the word specialize is very odd, I am using it correctly?
Just how much vastness is there of go code at google?
The reality is ... Some of us have real work to do.
A package local interface in item that corresponds to the behavior of action.Action.
I looked up must-revalidate and it says that its behaviour is only activated once a cache is stale, but this seems like a chicken and egg type problem. If the browser doesn't check for validation from the server until it detects the cache is stale, it will never check that the server has new version, so it wont know cache is stale, so it will never get new resource. Unless I am mistaken in what I read.
Put them in the same package but different files, brother.
hi! so, i have to nitpick wording a bit, but we've been avoiding saying "merge," because that suggests some kind of direct 1:1 moving of dep into the toolchain. that's not what's happening. the best thing i can do is point you to my explanation of dep, and its relationship with the toolchain, in my talk from Gophercon: https://youtu.be/5LtMb090AZI?t=15m21s (i've skipped the intro and history bits with that timestamp) i realize it's kinda poor form to link to a video for something like this, but this is a very complex, difficult process, and i put a lot of effort into getting the explanation right in the talk. so, it's really the best thing to watch if you want to understand how we're approaching the toolchain.
&gt; but can't replicate the structure of their site with hugo How so? Not being a Hugo evangelist but saying untrue things about a project shouldn't happen. 
You can also tell the client, via another pragma, to check if the ETag of the remote file has changed. Still involves a GET If-None-Match from the client, but I guess that is exactly what you want. https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching The trick goes like this: if your server serves an element with an ETag, then the client's next request for the same element will include a If-None-Match header. The server should be clever enough to know to serve a Not Modified response (about half a kilobyte total) if the element hasn't changed, or the full element if the element has in fact changed. Read line 119: https://golang.org/src/net/http/fs.go That's the trick.
I don't really like this approach for a few reasons despite it being best practice. I genuinely understand the logic of the approach and yet it is kind of messy in my opinion. 1. Hash values or timestamps need to be saved for every image and injected into every view to allow the correct images to load. 2. Over time a user's cache will fill up with several obsolete versions of the image unless they clear their cache. 3. In my case, the old image versions are obsolete and will need to be removed from server once the new file is successfully saved to server to avoid disk usage bloat. 4. When using hashes or timestamps in filenames, the filenames are not static, making it more difficult to embed links to given images (not impossible, just more difficult) To me, the ideal would be that I can overwrite the files on each new image submittal, and the client's browser by default always first checks if it has latest image, if so- serve from cache, if not- load from server. 
Would you like to know why that would be a fatal design decision from an engineering perspective or would you prefer to stay uninformed?
Yes. In a more serious tone, "fatal design decision from an engineering perspective" if you would be so kind, everyday is learning day.
&gt; but don't just shrug off what others bring up because you didn't personally have that problem. I did nothing of the sort. I just said that the article doesn't give a single concrete example of a problem that generics solve. As such, it doesn't say anything to someone like me, who can't fill in all the blanks for themselves. &gt; the lack of robust third party libraries in the ORM Thanks. I've not yet used an ORM in Go, as I've not written a webapp in it. I only know BoltDB. 
A new problem would emerge as soon as someone built a real application in such a language. They have single threaded performance in a multi threaded environment. You would end up using a vast majority more local data structures than you do thread safe ones, like you do today in well designed applications.
IIRC, it had something to do with how hugo makes foo.md into foo/index.html and jekyll making it foo.html. hugo has an option to switch that but AFAIR there was something wrong with that too for the way my site was set up. hugo's feed-generation also had differences to the one I'm using with jekyll. In particular, I have both RSS and Atom feeds and hugo only supports one of the two - and the one it does support uses a different schema for IDs, which would have confused feed readers. AFAIR I couldn't get it to render a custom template that would account for that either. &gt; but saying untrue things about a project shouldn't happen Curious assumption. All I can say is, that I tried for a couple of hours and couldn't get it to work. You are welcome to prove me wrong. The site is [here](https://github.com/Merovius/merovius.github.io), feel free to send a PR to make this a hugo-page which doesn't suffer from these issues.
You want ugly urls, in your config file: uglyurls = true edit: I see you have the option but set it up wrong. I have no knowledge of the rss formats though. 
&gt; developing lol
&gt; either be civil or give suitable examples that would further the debate Do you know what "circlejerk" means?
 type MmapWriter interface { WriteByteAt(value byte, off int64) error A huge part of the point of an mmap is to not need this.
Well, then normal data structures and threadsafe data structures like most languages have (either by stl or 3rd party lib).
&gt; edit: I see you have the option but set it up wrong. No, I don't have it "set up wrong". I have it set up the way jekyll does it, by default. Which, apparently, hugo is not compatible with. Which was what I said in the beginning, that I couldn't move to hugo, because it would have broken my site. (To be clear, it's hugo's prerogative to not support this, but implying that the fault is with jekyll or my usage of it is misleading; when I created that page, hugo didn't even exist. It axiomatically can't be wrong to have it set up like this when it comes to hugo-compatibility) [edit] turns out, I was incorrect; hugo's first commit predates the creation of my site by ~2 months. Still doesn't change the fact, that at the time, compatibility with hugo wouldn't have been a reasonable consideration *at all*.
&gt; IIRC, it had something to do with how hugo makes foo.md into foo/index.html and jekyll making it foo.html. hugo has an option to switch that but AFAIR there was something wrong with that too for the way my site was set up Was referencing this
[quicktype](http://go.quicktype.io) infers types from JSON sample data, then outputs typed code for unmarshaling and marshaling in Go (and C#). This is a new project, and we would love to read your feedback. Is this useful to you? What can we improve?
Oh, same for sure. Interesting though how I can accomplish both at the same time.
Looks pretty similar to this: https://mholt.github.io/json-to-go/ What's the purpose of wrapping the marshal and unmarshal from the standard library?
pcj is a satire sub &lt;3
We have a couple of features that existing tools don't support, most notably: * We detect dictionaries (see the `us-average-temperatures.json` sample) * We can handle cases where the types are ambiguous (for an extreme example, see `unions.json`) And there is more planned. The only purpose of wrapping marshal and unmarshal from the standard library are convenience. We might remove that again.
The article is right that an ORM that hides too many details is the wrong approach, but there is a middle ground out there. My opinion is that database/sql is enough for what a stdlib should offer, but it doesn't solve all patterns and conveniences needed to be productive when interacting with a sql database, without reinventing the wheel. Hence why Jason Moiron built the very popular https://github.com/jmoiron/sqlx as an extension on top of database/sql to easily map a result set to a struct with `db:""` tags. Others then wrote sql query builders such as https://github.com/Masterminds/squirrel (among many others) to instead of manipulating strings, you're changing data structures that are just like SQL, and interpolate to SQL strings. The approach we took with https://github.com/upper/db is to provide a set of libraries for database interaction, essentially a combination of sqlx ideas and squirrel, that are designed to work together. We make query building easier (with a good option for joins), result set iteration, pagination, cursors, Scanner/Valuers for JSONB, among many other libraries designed to fit together. It's not an ORM, but its somewhere in the middle and its been very helpful for our team when working with databases.
[removed]
I'm honestly not sure if you are trolling or not. I have never heard anyone who has used the heap package say they "Don't see any problem with it." Assuming you are being genuine... do you find your code using the heap package to be clear and easy to follow? Have others ever tried to use the code you wrote afterwards? Right now when you implement a heap you have an interface with a `Pop` and `Push` method (among others), and then the `heap` package itself has both of those functions. In most packages when you have a type with a method, the safe assumption is "I can call that method!" Eg when using an `io.Reader` you can call `Read()` if you want to read data. With the heap package this IS NOT true. You have to instead call the `heap.Pop` function and pass in the interface you want to pop data from. This is counter-intuitive and really isn't clear unless you have read the heap documentation, and it leads to bugs/incorrect code all the time. As a developer I now need to document all of my heap implementations with something like "See the container/heap docs to learn how to use this implementation" or I have to repeat what is already stated in the heap docs, otherwise I end up with code that is easy to misuse. Another issue is the loss of type safety, at least until runtime. Sure, you can't always avoid this and sometimes you have to live with it, but in the case of heaps it could be avoided with generics. To me, those all sound like problems that could be resolved with generics. Not to mention the heap package would be much easier to use since you wouldn't need to write nearly as much code - just a comparator function basically.
[you probably want '[specify](https://en.wiktionary.org/wiki/specify)' instead of 'specialize']
Finally, dep itself has a release I can pin to. 
That's just a convenience function if you want to use it. The primary way I expect it to be used is through the ReadAt/WriteAt pair. One thing I couldn't figure out was how to get the file to update using just the slice returned by ReadAt. When I started down this road, I assumed that I'd just be able to return that slice, manipulate the slice elsewhere, and the file would be updated after a sync. But that wasn't the case. One thought I had was to make the ReadAt call like this: ReadAt(off int, size int) ([]byte, error) But that doesn't match the io.ReaderAt interface. I don't know if that's important or not to support, but the `golang.org/x/exp/mmap` library seemed to indicate it was important. I could also have both, I guess. Maybe the MmapReader and MmapWriter types don't need to be interfaces. Have them be structs with methods and not worry about what interfaces they support.
I was trying to use NullUUID, which doesn't have the FromString method (only a Scan and a Value method). I ended up creating a NullUUID variable, then assigning the UUID value for the NullUUID to the string. Its not clean, but it works. For anyone else with a similar problem: uuidVariable := &amp;uuid.NullUUID{} uuidVariable.UUID, _ = uuid.FromString(r.PathParam("uuid")) uuidVariable then looks like: {UUID: Stringified r.PathParam, Valid:true}
&gt; With the heap package this IS NOT true. You have to instead call the heap.Pop function and pass in the interface you want to pop data from. All this means, it that you would prefer the API to be (and it is trivial to do that wrapping yourself): type Heap struct{ h heap.Interface } NewHeap(h heap.Interface) *Heap { heap.Init(h) return &amp;Heap{h} } func (h *Heap) Push(v interface{}) { heap.Push(h.h, v) } func (h *Heap) Pop() interface{} { return heap.Pop(h.h) } I mean, yeah, I can understand how you might find that preferable (even though it has never bothered myself much). IMO it has very little to do with generics, though. &gt; Another issue is the loss of type safety While it is true, that container/heap isn't statically type-safe, I have never experienced that to be an actual problem (as in, leading to a bug), neither with container/heap nor with any other container. If you have, I encourage you vehemently to write up an experience report.
Based on some thinking in response to /u/tv64738 I refactored the code. By early stages, I mean I started today. :) I've been experimenting with mmap code on and off for a few weeks, but only really felt I was ready to try to put it into library form yesterday. So the methods for a MmapReader are func (r *Reader) Len() int func (r *Reader) PageCount() (int, int) func (r *Reader) ReadByteAt(off int64) (byte, error) func (r *Reader) ReadAt(p []byte, off int64) (int, error) func (r *Reader) Close() error func (r *Reader) Closed() bool And the methods for a MmapWriter are func (w *Writer) WriteByteAt(value byte, off int64) error func (w *Writer) WriteAt(p []byte, off int64) (int, error) func (w *Writer) Region(off int64, ln int64) ([]byte, error) func (w *Writer) Sync() error func (w *Writer) AddPages(count int) error func (w *Writer) Close() error Again, thoughts are appreciated while I add docs and tests.
But can it tell me the difference between a hedgehog and a filthy rat?
I know those functions are a bit magic, but that doesn't really help explain to me why generics are important. What are you saying, exactly? I'd have to implement my own `Len()` and `Append()` methods? Like I said, I'm a Python programmer. I'm used to writing my own `__lt__` and `__gt__` "magic" methods. Is that something generics make unnecessary? Which problems would they help me solve? 
&gt; All this means, it that you would prefer the API to be (and it is trivial to do that wrapping yourself) I'm aware of how to wrap it. I have written about doing that + code generation (in order to automate the type conversions) here - &lt;https://www.calhoun.io/generating-data-structures-that-need-additional-functions/&gt; The problem with this is that you have to write even more code, and all of this is more complex than the generic counterpart. &gt; IMO it has very little to do with generics, though. I'm not following you. Do you not see how generics make this simpler and easier for developers to create and use heaps? The generic equivalent to the heap package (in java) is: ``` PriorityQueue&lt;Integer&gt; pq = new PriorityQueue&lt;Integer&gt;(); pq.add(123); pq.add(321); pq.add(100); while(!pq.isEmpty()) { System.out.println(pq.poll()); } ``` It is type-safe and it is easy to use. If Go had Generics we could use a heap with some code something like: ``` // This isn't real code and is a fictional generic impl, but it shoudl illustrate the point // despite the madeup syntax that could change var intHeap Heap&lt;int&gt; = heap.New(func(a, b int) bool { return a &lt; b }) intHeap.Push(123) // this is type-safe intHeap.Push("blah") // this is a compile-time error for intHeap.Len() &gt; 0 { fmt.Println(intHeap.Pop()) // Pop values are already ints } ``` This is significantly clearer and simpler to both me and many other developers. And this is just one data structure. There are plenty more that could benefit from this (see &lt;https://github.com/emirpasic/gods&gt; for a few examples)
Why the downvotes? I asked an honest question and I get downvoted. Makes me sad for our community...
Which is exactly what Go did. You have sync primitives and channels built in, I've never wanted a thread safe generic anything. I synchronize where I need to and I believe most developers feel the same and you will to when you become more experienced.
There are three issues you mentioned: a) confusion between package-level functions and methods of heap.Interface-implementations, b) need to implement heap.Interface and c) type-safety. What I was referring to, when I said it has very little to do with generics, is a; that is solvable by better API design or a trivial wrapper-package. For b and c, yes, I agree that they are mild annoyances. They have never really bothered me, though. I spend most of my time solving problems; having to add a couple of lines of trivial, obvious code never really bothered me a lot, even when it is repetitive. YMMV, obviously. On the other hand, in particular the type-safety is often invoked as a strawman, though. I agree that writing the type-assertions is mildly annoying and I also agree that I would prefer the accesses to be statically type-checked. But it is not as if having a couple of `interfaces{}` for containers would noticeably impact the overall safety of your program (and if people experienced that differently, again, an experience report would be great). &gt; There are plenty more that could benefit from this (see https://github.com/emirpasic/gods for a few examples) And with that we are at the point where we simply come to different conclusions based on the same facts, because of personal preference. I view the existence of that package and the fact that it's used to demonstrate the need for generics as a powerful counterargument to them. I find nothing more convincing of the harmful effects of generics on readability and usability of a programming language, than the prospect of go turning into another java, where instead of writing code, you instead spend your time deciding what implementation of an Iterable&lt;&gt; to choose today (and instead of *reading* code, you spend your time parsing nested brackets). To me, hash-maps, slices and channels seem plenty good. And again, you might have different experiences about that, that's fair, but that needs to be put into experience reports (What business-problem did you need to solve? How did you solve it using the existing data-structures? Why wasn't that good enough?) instead of broad assertions about how they are needed and everyone who doesn't think the same way just doesn't have enough experience.
This is the correct way. There are various ways of adding type safety. 1. You could create a named interface and have this as the "Function" field type instead, and then add an aribtrary method on your assignable structs that satisfy this interface. 2. You could create a method on "Content" that does the assigning. The parameter to this method could do the same as option 1. Or you could do some type assertations/checks and return an error if the argument is not of the right type. 3. You could use reflection. Personally i would just stick with interface{}, but be very explicit about naming the field and the struct types that can be assigned to it.
Thanks. I started going down path #1 and it felt a little convoluted. When I really think about it, this stuff is going to be buried in the internals of the package, and certainly not exposed in anyway to a consumer. And internally, a developer would have to go really far out of their way to break this. I think I will indeed stick with interface{}. Cheers.
Well, at least you know your developer doesn't suck. I'd be surprised if a general purpose concurrent map ever outperformed a tailored implementation using a non-concurrent map and a mutex.
"Tiny Package Syndrome" amuses me. I just finished some major refactoring to get around the opposite problem. My package was so huge and broad it was practically bursting out and frightening the horses.
&gt; I'd have to implement my own Len() and Append() methods? Yes, for every data structure you use. And your own maps and slice methods as well.
I wouldn't call mutexes "build in threadsafe data structures". Channels are slow as fuck and use mutexes too under the hood. Also no flexible channel buffer = useless in my use case.
It is cute, and would save a bit of time over doing it by hand dito. https://mholt.github.io/json-to-go/ which I hadn't seen before either. Maybe slightly better overall as it gives all the code to have it work, and pulls out the object definitions giving them names which would make it easier to refactor. It picks float instead of int by default, which seems weird. It doesn't use the std. names, Eg. foo_url =&gt; FooUrl instead of FooURL dito. Id instead of ID. Would be nice if it also spotted foourl. With the a lot of names you don't need the remapping if Unmarshall spots it by default ala. "Foo string `json:"foo"`" is there a performance difference for including it? Using interface{} whenever it sees a nil is annoying. Can't spot map =&gt; object and does it as N different objects of the same type. Maybe have a way to paste 2 (or more) replies and have it generate code that can paste both?
 // package action type ActionTarget interface { // Necessary interaction methods } type Action struct { Names: []string, Action: func(*ActionTarget) int } // package character type Character struct {Inventory: []item.Item} // implementation of action.ActionTarget for Character // package item type Item struct { Name: string, Actions: []action.Action } This has the added advantage of being able to implement actions that affect other items or even other actions, rather than being limited to affecting characters.
See [mmap-go](https://github.com/edsrzf/mmap-go).
Wow, that is a lot cleaner :)
Pass a URL param like: mysite.com/search?q=myquery&amp;page=2 Some sites also include a numResults param which can be used to increase the number of results. In your handler, query the DB with an offset of numResults * (page-1) 
&gt; We detect dictionaries (see the us-average-temperatures.json sample) I have: Tasks struct { Rpms map[string]Rpm } ...your code didn't detect it on (or other builds): https://mbs.fedoraproject.org/module-build-service/1/module-builds/32
&gt; By popular request, `./...` no longer matches packages in vendor directories in tools accepting package names, such as `go test`. To match vendor directories, write `./vendor/....` So much yes! 
&gt; potential employers look at your post history man Lol sure, employers ask for social media accounts ... are you living in north korea?
Thanks for the feedback! Our current heuristic switches from objects to maps when there are more than 20 properties. We have other heuristics planned, such as looking at the property names and figuring out whether they look like "real" properties or map keys.
This is an awesome presentation of the problem and possible solutions. 
Thank you, detecting name parts like "url" and "id" for capitalization is a good idea! I don't know whether there's a performance difference when providing the attribute vs not. We just do it by default. What would you expect the type to be where the only value we see is `null`?
That's a really good idea. Thanks.
 from nowhere import thick_skin thick_skin.deflect(PCJ.Attack())
Is this an open source project? If not, is there a company associated? Looking you up, you seem to work on a [million super cool projects](https://github.com/schani) but I didn't see this one (but followed you while I was there).
&gt; I watched it lol. Probably because you said you watched the talk and yet in the talk Russ specifically mentioned Go 1.20.
Awesome! These are some welcome additions to an already useful library that I make extensive use of. Thank you for working on it and open sourcing it! 👍
Using float by default actually makes sense as Javascript's `Number` itself is a float64/double. http://www.ecma-international.org/publications/files/ECMA-ST-ARCH/ECMA-262,%201st%20edition,%20June%201997.pdf Section 8.5
&gt; typically I really do want a strict type structure Generics will not infringe on that. You still define your types. It's just that they are parametric instead of fixed at the struct/function definitions. &gt; It's just that (as I understand it) most current implementations of generics (and exceptions) make it too easy to produce "lazy" code that doesn't handle all the eventualities. Generics mean that any unhandled eventualities can be discovered at compile time. Consider a use case like the prototype [sync/syncmap](https://godoc.org/golang.org/x/sync/syncmap) -- it relies on the programmer to use types used for keys and values in it correctly. IMO that's fine, but could introduce run-time errors when the programmer eventually makes a mistake, whereas generics would mean that code is compiled for each used type combination and thus checked for errors at compile time. It's a use case that begs generics. Generics make it easier to re-use library code and apply it generally. This is already common in Go, but typically via interfaces, at worst via empty interfaces. &gt; I'm not convinced that carbon copying the Java/C++ way of generics is necessarily the best way to solve the problem though. I don't think anyone suggested that it is. The template system in C++ is overkill. Even a generic macro pre-processor (like C, which does solve the problem) is an overkill solution. In Java it's not half bad. &gt; Generic programming, inheritance, polymorphism... These are all things that simple Google searches produce a lot of confusion, the "Go" way is supposed to be a trivial to understand, trivial to implement system language. I don't think it's fair to bunch these concepts up. Generics is not necessarily a very complex feature to the user, and a bare-bones yet useful implementation could simply work as a pre-processor. Polymorphism is already supported in Go via interfaces, which is elegant and has a very high usefulness-per-confusion ratio. Inheritance is not so useful when you have interfaces and composition.
Nothing at all. It's a great talk.
Consider watching this talk by Bryan Mills, who wrote sync.Map: https://www.youtube.com/watch?v=C1EtfDnsdDs&amp;list=PL2ntRZ1ySWBfhRZj3BDOrKdHzoafHsKHU&amp;index=21
I think most gophers would say to write this yourself. The less you depend on the better, generally. Take a look at some popular API's for ideas about how to implement. Twitter API e.g. 
Thanks for the link. It confirms the conclusions we already reached, that our particular use case doesn't make it optimal
I read that article when it was published. It's hard to differentiate the valid arguments from the "your language is too stupid for r/iamsosmart me" ones.
**Here's a sneak peek of /r/iamsosmart using the [top posts](https://np.reddit.com/r/iamsosmart/top/?sort=top&amp;t=year) of the year!** \#1: [Defending lack of self awareness by doubling down on narcissism](https://i.redd.it/pe0rq3t45ywy.jpg) | [2 comments](https://np.reddit.com/r/iamsosmart/comments/6ang2b/defending_lack_of_self_awareness_by_doubling_down/) \#2: [r/teenagers discord](https://i.redd.it/zkvvl2pccefy.png) | [4 comments](https://np.reddit.com/r/iamsosmart/comments/5tkm9j/rteenagers_discord/) \#3: [I am so bookish I don't need exercise](http://imgur.com/vcBYpvd) | [0 comments](https://np.reddit.com/r/iamsosmart/comments/5m9pg2/i_am_so_bookish_i_dont_need_exercise/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
Yup, [here's an example of how to paginate in MySQL](https://stackoverflow.com/questions/3799193/mysql-data-best-way-to-implement-paging) (should be applicable to MariaDB or nearly any SQL database for that matter).
Not everything is binary logic.
reflection requires interfaces as well. reflect.TypeOf and reflect.ValueOf take an interface{}
Thank you! No promises yet, but we're hoping to open-source it.
&gt; Because there is only one way to find someone's Reddit account- if you give it to them! That's true. Especially if you live in a country outside of the US and nobody gives a fuck about reddit or social media accounts at all.
We're currently switching over to HTTPS. If the link doesn't work in the mean time, use this one: https://quicktype-174421.firebaseapp.com/
It looks really nice!
Summary: Looks to be a basic unstructured levelled logger, taking interface{} (see https://godoc.org/github.com/kataras/golog#pkg-index). Unsure of its exact value over other loggers. Edit: spelt unstructured correctly.
Another kataras rip-off? 
What would you suggest as an alternative?
The same as in any other programming language. http://use-the-index-luke.com/no-offset
 I'm spoiled by Django. I don't know how it is done in other languages. 
There are some advice against using offsets, as explained in http://use-the-index-luke.com/no-offset
Yeah, I've seen a lot of these generic 'go figure out how to do it yourself' in go community. I think it's simple arrogance and discouraging newbies, not help. 
Have you considered renaming to `Reader` and `Writer`? Otherwise the types "stutter": `mmap.MmapWriter` vs `mmap.Writer` Also, you're using syscalls. You should always guard syscalls with build tags. 
Hey look, generics!
I'll check it out; this looks neat!
No true gopher could ever want generics. If someone is using Go without generics, they have not demonstrated that they truly need generics. If they have moved onto to another language with generics, they have not demonstrated that they are a true Go user. QED
More generic builtins != generics.
Slow is relative and flexible buffers seem like a result of poor planning.
Hey @gar44, I know you're using sqlx but maybe you could consider upper-db for your next project, this is how'd you do pagination: https://tour.upper.io/queries/04, you can create a simple LIMIT/OFFSET pagination or a cursor based one. 
Nice, but please don't put hyphens in Go package names, having to rename on import is just annoying: import css "github.com/napsy/go-css-parser"
They're not saying you have to work it out yourself, they're saying you should build something as opposed to using a pagination package. You'll still get suggestions on how to approach it.
Fucking what? 
Who talks about golog is a structured" logger? It's a good levelled logger. With golog you can scan from any input source, use multi output targets, install loggers like logrus, intercept the log messages, inject the printer and much more
Please, get some help
Well done! Rather than writing hand-wringing Medium thinkpieces you're actually experimenting with modifying Go with some limited generics and seeing how it feels. Experimentation through prototypes is a great way to make a better argument! If only more people had the gumption. I applaud the effort.
I was just summarising some of the features of golog as I saw them for others to quickly see.
The package name is actually named "css" in the code, so import css "github.com/napsy/go-css-parser" is redundant. That is, import "github.com/napsy/go-css-parser" has the same effect. There's no problem having hyphens in the import path --- in fact "go-*" is a common convention --- but consistency between import path and package name is a good idea. Eg, "github.com/me/go-blag" should contain a package called "blag". Maybe the author might consider renaming the package and repo for clarity.
This reminds me a little bit of [Oden](https://github.com/oden-lang/oden) ([RIP](https://wickstrom.tech/programming/2016/10/10/taking-a-step-back-from-oden.html)).
I was pleased that Oden was functional, and would prefer a similar solution to also be so. A functional "space" (DSL?) for handling generics seems quite prudent. Then throw union types and immutability into Go proper and there'd not be much left to complain about.
There's a couple of ways you could have gone about mentioning the linter or referenced the initialism post and helped the author learn something. Instead you judged his experience and commitment to idiomatic code based on a single freaking capitalization rule I wouldn't even correct in a code review and which is completely unique to Go. Sorry.
&gt; Unfortunately go does not allow do it also as simple as it can be done on C. Have a look at [`encoding/gob`](https://golang.org/pkg/encoding/gob/). It's super easy. (I used `gob` in [this blog article](https://appliedgo.net/networking/).) (Edit: link)
This is another, encoding/gob, and other similar encoders, serialize struct to bytes with additiontal data, such as field names, size of variable, etc, etc... Stob not quite serializer, it write to bytes only data, and restore struct from RAW bytes. It takes less data size. Example: Ethernet frame - with stob can easy parse network package, and get dst ip, src ip, and all other information. Or fill struct with your data, and send this bytes how network message to the internet. Headers of any file formats. etc. 
For a PDF library the code needed to create the report actually doesn't look that verbose. However, if I ever need to create pdfs with go (which I hope I don't) I think I would port my python LaTeX library: https://github.com/JelteF/PyLaTeX I've found that generating LaTeX and then creating a PDF from that is much easier than generating a PDF directly. Especially because you can make use of all the LaTeX packages for fancy stuff, like multi page tables. 
True but I would still call the repo "github.com/me/blag" in this case so the repo name matches to package name, it's just nicer that way.
Great article. &gt; type withStack struct { &gt; wraps(error) &gt; *stack &gt; } &gt; &gt; In this situation, the wraps keyword would be picked up by the err.(temporary) type assertion and resolution would chain down to the wrapped object. You lost me here. What is the `wraps()` keyword/function exactly? How does the type assertion "pick up" the `wraps` keyword?
That's the difference I missed. Thanks for clarifying.
What do you suggest instead? (Edited)
&gt; in my post, I was talking more about a property of Go than this particular post. ... and that is exactly why your comment doesn't belong here, because it doesn't add anything to the discussion.
The fact that they import each other contradicts the claim, that the code is unrelated. It's related, it belongs in the same package.
Great post :) I am just a tiny bit disappointed, because I have a draft for a post to be released this week, that contains much of the same things and you beat me to it and obsoleted a bunch of work with that ;)
there is truth in satire 
Good job on following through a step by step improvement. I'm usually not so precise to document individual optimizations! :)
&gt;As Russ pointed out, generics are a trade off between programmer time, compilation time, and execution time. Could somebody elaborate on this? I thought that `interface{}` is already a boxed type (`{type_ptr; value_ptr}`) so interfaces already bring you runtime overhead + overhead on dispatching, which means that even execution time parametric polymorphism will lead you to far more fast and safe code (i.e. you can throw away type field from `interface{}` structure and check types in compiletime).
This uses TuneFind.com as a source, which only lists tunes that are used in movies and tv shows. A total of ~ 110.000 it says. Where as services like Spotify have 30+ million tracks. Does anybody know a public db that covers a wider range of tunes ? 
*throws spear*
*Flips the bird*
Thanks for the feedback, I'll think about renaming the project. I've added smaller features, like verified CSS properties.
Oden was really exciting for me back then. Sad it ended like that.
It's a nice post, but I don't see what /r/golang has to do with it, the only mention of Go in there is just installing it.
Th 27 July 2017 Golog is now two times faster, run the benchmarks by navigating to https://github.com/kataras/golog/tree/master/_benchmarks
As soon as possibile, but I need to do testings as well ;)
It provides session support but not authentication. 
This has been an annoying problem for me as well.
I really don't see why "don't know SQL very well" should prompt someone to learn a huge library like GORM. Learn you some SQL instead. If you spent that time reading up on SQL (which is easier, given the vast amount of resources available compared to the half-assed godoc and learn-by-example guide of GORM), you'd be able to cover the trivial use cases that GORM isn't a complete headache for. You're replacing a well-documented and complete language for relational queries with a poorly documented API, with no less than 75 uses of `interface{}` in its public function headers, where you still end up writing unchecked query strings that [can't even be trusted to generate proper SQL for trivial cases](https://github.com/jinzhu/gorm/issues/1519) when used correctly.
Yes, this is correct way to handle unmarshaling variable data structures. "Be very explicit" means good comments and/or public documentation around this point, and using a switch on the runtime-observed format of the XML to get this back into a typesafe struct again as soon as possible. Another possibility, if you've got the freedom to do so, is to negotiate with the producer of the XML, explaining why what they are doing is making life difficult for you, and get a different API endpoint to use with a cleaner XML schema. Sometimes a bigger systems view is needed to ensure less maintenance costs globally, even if you take some up-front costs to achieve it. -jeff
Great to hear the library is proving useful. Looking forward to getting comments on the API to create reports. Happy it is not too verbose, tricky to get the right balance of ease of use and flexibility :)
Here's some thoughts from Google's API design guidelines: https://cloud.google.com/apis/design/design_patterns#list_pagination
I totally agree of current limitation. Two things... * this is only the first source that I've included * not a replacement for Spotify, that's a commercial platform 
I don't understand why this isn't valid user experience report: (1) I wanted to store several different types in a specialised tree structure and preserve type safety. (2) I used a code generator (a bit like the C preprocessor). (3) It wasn't great because I had to expend extra time on the project, and add a dependency which requires additional education for new hires, and additional testing. Edit: What additional information do you require?
&gt; flexible buffers seem like a result of poor planning It would be necessary by design. A web crawler that takes a site, extract the urls from it that link to the same domain and put the filtered urls back into the channel for the worker pool. It's a circular design and therefor I need flexible buffers because every site has different urls (10 up to 3 million or so). In-memory access so no DB possible. I've set my channel buffer to 1 million but there can be a site which breaks my crawler and that is shit just because Go does not support flexible buffers.
If I remember well, Gary is an expert in D programming and thus know all the very good ideas of D. When he talks about generics, he know what it is and what we miss without it in go. D is a modern high level language with very good and well thought out generic support and even static execution. D has another very impressive and powerful feature that we owe to Andrei Alexandrescu. It is the iterator interface. It is simple, elegant, and very powerful. The only point I would like to make, after spending a significant amount of time to learn D, is that it all makes D code difficult to read because there is a high load on the brain. There is a lot of context information to know in order to understand such code. In Go we have three main types of containers, maps, slices and channels. Because of the interface constrain, there is no incentive to create all the other containers described in computer science. So the choice is limitted and coding is simple. Code is readable. If we had rbtrees, btrees, bplustrees, and whatever domain specific container type, and see this in code, we would have to know them (their properties) in order to understand what the code is doing, what mistake might have been done, etc. When programming we would have to make a decision on the most appropriate container type to pick for our application. This is what I dislike with D, C++ and Java. This stress has all been removed with Go. Go is a breeze of fresh air. I wish that Go can remain as simple as it is today. Being simple is difficult as said Rob Pike, and one difficulty is to resist the pressure of feature addition. Simplicity is what characterize Go regarding other languages. It's also it's strength. It's why I want to program in Go. If you want generics, there are plenty of other languages to pick from. I don't mind if you consider it a toy language if it doesn't have generics. What I've learned from 35 years of programming is that simplicity is trump. It affects mind load for reading or writing, it affects efficiency in reading or writing and in the end it affects security of the code and the developped system. You'll get more people to write correct code and checking will be easier. You want generics because of efficiency ? You should get into writing smarter compilers, not push more stress on the programmers! Keep the grammar lightweight. Go has reached its actual impressive level of popularity and success without generics. It simplicity is an important ingredient of its success. Looking at the modern language familly, Go is actually in a niche of simple programming languages yet powerful enough to create production ready code. I would suggest to let the experiment continue a few more years and see how far Go can get by staying simple and enforcing simple code. Writing smarter compiler should be simpler with such a simple language. So there is room for improvement there if you want. Let Go stay the minecraft of programming. 
this is not true anymore.
i am a faggot
Channels with flexible buffers. And the same speed (if technical possible) for channels and self used mutexes.
I really want Gonum to take off. Go is the perfect language for math/scientific people who are not programmers first, but scientific libraries have to be in place before they'll really rush towards the language.
There's also [composed serialization](https://medium.com/@egonelbre/specification-types-ed9ddf35ec8f).
A bit off topic, but if you have to link to a definition of a word you are using in your post, why not just choose a more common word? Even better, just rewrite the sentence to more clearly convey your meaning to the reader, rather than sending them off to Wikipedia to figure out what you are talking about. &gt; After two weeks of dogfooding this as my exclusive machine... vs. &gt; After using this exclusively for two weeks... And I'll echo /u/ZetaHunter 's comment that this doesn't really seem to have anything to do with Go, other than that it was installed...
Good catch. Change is done.
In March, we have seen reports of Android Studio possibly coming to Chrome OS. Android Studio would mean IntelliJ IDEA and the entire family of IntelliJ IDEs. That would make this an even better idea.
&gt; How does the type assertion "pick up" the wraps keyword? The author is suggesting a language change. With the change the compiler would effectively treat this: te, ok := err.(temporary) as if it was something like this (when the underlying type of `err` is `*withStack`): func modifiedTypeAssertion(err *withStack) (temporary, bool) { if te, ok := err.(temporary); ok { return te, ok } return err.error.(temporary) } In other words the change would have the compiler check the assertion as it currently does but on failure it would then look for any embedded fields marked with `wraps` and recursively re-try the assertion using that field/type. The author does not discus how this might be implemented, if that's your question.
Thanks for clarifying. Seems I did not follow the mental switch from existing language to suggested language. So `wraps` is a part of the suggested change and also `err.(temporary)` that obviously would have to have different semantics then.
Surely I was not expecting an alternative for Spotify :-) I was not refering to the playing part, only to the lookup part.
Maybe this is a better source for searching music: https://musicbrainz.org/ It also has a xml webservice. 
IMO as a Go dev, I appreciated this post and knowing there is a way to develop on a Chromebook
Are there any benchmarks for common matrix operations on large matrices comparing Gonum to things like NumPy?
Fantastic post! I've encountered this problem as well and agree that we need a way to handle it. As the Go ecosystem grows and matures this problem will come up more often.
If you're downvoting this, I'd appreciate it if you would let me know why. Thanks
Please consider adding this to https://github.com/golang/go/wiki/ExperienceReports, /u/cep221.
We have a bunch of benchmarks in the blas/gonum package and in the mat package. If you're using OpenBLAS like numpy is the differences are small for large matrices. If you're using pure Go then the differences are small for small matrices (&lt; 104 entries). For larger matrices the differences can be significant, and at that point using the cgo libraries is recommended. If you have a lot of calls with small matrices, using the native Go is significantly faster (one of my codes with that property slows down by 3x when I switch to cgo from Go). We may be getting better assembly soon, and I'm writing up an experience report to maybe get help from the standard library (but who knows what will happen on that front).
Thanks so much for your advice so far! Hope you don't mind my challenges as they are helping me learn the process. In the article you posted they still mention you must expire the cache first for this check cycle to be initiated. Therefore in order for this strategy to work I would have to set the max life to essentially 0 otherwise I would still risk the possibility of a user uploading a new image and running the report generator immediately afterwards with the non-expired cache of the original image (Which is actually pretty typical of their workflow). So in this approach I would essentially always have a stale cache but it would still use the stale cache's resources unless a newer version exists on the server? Not exactly how I imagined it but this could work if the browser continues to use the stale cache until a newer version is present on the server. Side rant: Seems like it would make sense to allow a cached item to keep track of expiry and freshness independently. Ie a resource could be expired but still fresh, and a resource can be not yet expired, but stale from the server's perspective. If they provided directives for it, I could specify whether a cached resource should check for expiry and/or freshness. In my case I could say that I want all image resources to check for freshness regardless of expiry state, and all other resources to only check for freshness once explicit expiry has been reached, and in all cases to never download unless the client has no version of the resource or the server has newer version than client's cache. Maybe that essentially exists in the current caching directives but I think it could be laid out nicer and with better semantics. Feels strange to have to mark a cache as expired just to be able to check its freshness. 
The title might be too long.
I am interested in this type of post as well, which is why I subscribe to other subreddits where it would be relevant to their subject matter.
Confusingly the directive 'no-cache' seems to be what I want here but I can't imagine a sillier name for it if I am not mistaking its function. From Mozilla Developer page: no-cache Forces caches to submit the request to the origin server for validation before releasing a cached copy. In the above, I read it as, if the client requests a resource, prior to using the cache, it will check with server to determine if there is a newer version, if not it will serve resource from cache. Assuming I am not mistaken, why on earth would this directive be called 'no-cache' considering it sounds like a cache is still in use. Wouldn't 're-validate' fit much better here as a directive? 
The unimportant change is done, yes, but the important change isn't. If someone isn't using linux and tries to pull this library or a library that uses this library there will be unexpected panics. Use build tags.
The actual size of GORM isn't a useful measurement because most people don't use all of it. They use maybe a few methods and that's it. Similarly, most newcomers to SQL won't be using a vast majority of the features available in SQL. The simplest answer to why I prefer to teach with GORM over SQL is that it has yielded better results than not using it, both in the long and short term.
1. Assume good faith 2. Defining a *problem* (not solution) is the first step to solving it properly 3. Generics could mean many things, go already has a limited form of it (append and cousins) 4. Adding generics in some other languages caused problems (see C++ templates), they'd like to avoid that and keep the language simple and performant. 5. If they didn't want generics, they'd simply say no to generics.
This is beautiful, but I my daily life (theoretical physicist, often numpy/scipy) complex is king. How could such a thing be possible including the corresponding operations like numpy.linalg.eigh? Rewrite everything for a different type? It is times like these where I would hope for generics. In most other cases I learned to love the simplicity that comes along with _not_ having them.
&gt; If you're downvoting this, I'd appreciate it if you would let me know why. Thanks I haven't downvoted and I don't mind the long title. But man am I tired of seeing HTTP routers being written for Go. Also why all this obsession with performance for HTTP routers? The HTTP router's overhead is going to be only a tiny fraction compared to the storage and network IO. So unless this is for learning purposes, why not use one of the many established and battle tested routers that exist out there?
you could use gstreamer or https://github.com/hajimehoshi/go-mp3 or https://github.com/badgerodon/mp3 for example
IMO as a Go dev and person who has a Chromebook already ... :)
I don't think generics would help here. The transpose operation is not the same for real matrices and complex matrices, in that complex matrices need the conjugate taken. You could code `eigh` to take `[]Conjugator` , where a Conjugator performs the necessary conjugate operation. It would be significantly slower than the call to the specifically float64 or complex128 function, which is what I imagine numpy does.
Hi! I've got a pretty cool audio library in the works, but it's fairly usable already: https://github.com/faiface/beep MP3 support is coming like today, or tomorrow. You can do streaming, audio processing, easily create your own effects, sequencing, mixing, and so on. The tutorial is pretty short so far, but that's because there hasn't been an official release yet, but that's coming (the docs should be fine). If you have any questions, please ask.
Why is Go the perfect language? Could you elaborate?
That *really* sounds like you want to just use Haskell.
It's fast (scientific programs often take a long time to compute), simple (science/math people don't often know about more advanced language features like generics, so tend to get confused when they encounter it), and it prevents spaghetti code as much as possible, which non-programmers are prone to write.
[sure](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html)
Igh, I doubt it will ever happen. There are editors which are based on Atom (Caret?), but far from a dev environment. It should be written in pure javascript (or cross compiled) and you're still missing things like an actual package manager for things like a local dev environment. This post bridges the gap a bit (compared to crouton which is awkward at the very least - did you know that to reset your machine from dev mode all you have to do is reboot and press SPACE?!?!? I mean, if you're not reading things usually space is the button which you press first, wtf).
That being said, there's supposedly some difference between ChromeOS and ChromiumOS (open source), and the latter might have something akin to a package manager. But since I need to push the chromebook into dev mode to install a new OS or run it live from an USB key, guess what I'm doing. I'm just using it as a thin client with a browser/ssh capability and very very shitty VPN support (l2tp and ipsec only).
Thanks for the tip. Actually I just followed the tips and modifed my queries to reflect that, so now I have queries like : err = Dbmap.Select(&amp;result, "SELECT * FROM comment WHERE post_id = ? ORDER BY created_at ASC LIMIT ?,?", pId, offset, numResults) This does the job, however, regarding that using offsets is discouraged for performance reasons, I'm not sure this is the optimal solution. 
I would rather write scientific code in Go over Python _any day_ because of Go's concurrency/parallelism primitives. That alone would sell me enough to dump Python, if we just had a huge selection of libraries for scientific computing in Go. Can't tell you how many times I've been sitting waiting, or letting an experiment run overnight, with dozens or even hundreds of cores idle, because matplotlib isn't threadsafe (and multiprocessing doesn't share memory, plus other sync complications -- don't worry about it, just trust me), for example. Also, running Go programs on my lab machine vs. the supercomputer would be a breeze. Right now it's an absolute pain to ensure the right versions of every dependency are loaded into the supercomputer environment before running a large experiment. With Go, the binary would (theoretically) be statically compiled, even cross-compiled. Ahhhhh.
if you have a sequential date, you could also use `WHERE created_at &gt; ?`so whatever, though I'm not sure on the performance differences. I say do it the way you have it and change it if it becomes a bottleneck. To me, this is the simplest, most obvious way to do it, so only change it if you have a good reason to.
&gt; regarding that using offsets is discouraged for performance reasons I wouldn't say that offset is discouraged. It is just different tools for different jobs. Offset is good if you need to implement pagination that requires to go to a specific page. Offset is not that good if you want to implement an infinite scroller.
Yes, this was interesting to me as well. It's "on-topic" enough.
There are a handful of wav decoders out there. You should be able to find them easily enough. Most of them will fail to decode some specific wav files that don't use a 44 byte header, because those files have a different format entirely. I've been working on a RIFF decoding format to deal with both of those cases, but it isn't ready. There are fewer mp3 decoders, but [go-mp3](https://github.com/hajimehoshi/go-mp3) is one I've found to be stable. The portaudio library is pretty low level, I haven't worked with it specifically though. If you want to use it and have error messages or code you could put to a playground link to look at, I could try to dig through it. And I guess we're plugging our audio libraries, so [this over here](https://github.com/200sc/klangsynthese) is the one I've been working on, that contains that RIFF work.
The solution for this in generics is called "specialization". Not all implementations of generics have it, but it's very useful in that it allows for a generic algorithm to be optimized for a variety of special cases, while being completely transparent to the user.
What you posted contains more details and follows the format. If you expanded with a couple of code examples, I think that would make a valid user experience report. The blog post in question doesn’t even mention the words “tree” or “generator”, though, so I’m not sure whether to interpret your reply as a follow-up to my post, or just an unrelated thought?
Your hypothesis about staleness is correct.
Point taken.
What subreddits would you recommend?
XEON-based/EPYC-based Supermicro Motherboard with 512GB+ RAM Workstation/Server with a real GNU/Linux distro such as Redhat, Debian, Archlinux or Ubuntu versus A TOY quad-core Chromebook with 4GB RAM with a pseudo linux shell installed via an Android Package running in a Gentoo-based Chrome OS. HAHAHA...don't make me laugh. Nothing to see here. Come back when you have Server hardware specs within a laptop at "One Laptop Per Child" Prices then maybe I'll reconsider. At this point it's a huge waste of my time. 
This would be awesome! Cannot wait for the mp3 support! Also consider listing your package on https://go.libhunt.com/contribute, it's so hard to find audio packages that aren't dead for Go.
Please don't make such large jumps in logic. I did not ask for thoroughly enforced purity when advocating for immutability. Likewise, union types do not necessitate a wholesale migration of paradigms. A DSL for carving out certain behavior could prove healthy, and maybe not. Oden could have given us some first hand experience with that, but instead I'm left simply positing the benefits.
I admit that a big part of this was to [learn how the wheel works](https://vluxe.io/golang-router.html). But when looking at the most common routers in use, you have a choice of full featured but slow or basic features but fast. After reading the article I linked, I decided to set out to build a router with these goals in mind: * Its handlers must only need to implement http.HandlerFunc * It must have very good performance for simple routes * It must provide regular expression routes without affecting performance of simple routes. I didn't know if I'd succeed, but I think I have. And that makes it useful to me and hopefully someone else as well.
Awesome-go has prerequisites for hosting code bases, one of which is that they have significant (at least 80-90%) test coverage, so they might not be posting it there because they haven't reached that yet, or otherwise they want it to be in a finished state first.
You mentioned Functional, generics, union types and immutability. To me, that is literally how I'd describe Haskell. I wasn't even being facetious. You just described Haskell to me.
thanks for the source :) I'll check and include
MP3 support done (uses awesome https://github.com/hajimehoshi/go-mp3 under the hood). Btw, do you want to stream audio through a server, or do you want to play it on your computer?
My Pixel library is in awesome-go and has like zero tests (but is tested manually very well). The main reason why beep isn't in awesome-go yet is that it hasn't been released yet, because a few features are still missing (such as a Resample decorator/"effect", help appreciated).
I've looked into go-mp3, but it can only handle local filesystem files. Though I'm sure if I had to use it I could fork and fix that, but I wanna explore the solutions in this thread first. &gt; If you want to use it and have error messages or code you could put to a playground link to look at, I could try to dig through it. Not particularly error messages. I have a stream of an mp3 file, I have a portaudio stream. I don't know what to do with the two, is what my issue is. As far as your library goes, it seems pretty nice. I see a ? next to linux playback, what's that?
AFAIK gstreamer is linux-only. I've looked into go-mp3, but it can only handle local filesystem files. Though I'm sure if I had to use it I could fork and fix that, but I wanna explore the solutions in this thread first.
Play it on the computer. And awesome! Gunna go check it out now.
Linux playback works for simple, one-time plays, but it appears that playing things rapidly doesn't play nice with the lower-level libraries. It's a little rough to test this because my laptop doesn't play nice with linux VMs and you can't test audio through automated tools like Travis CI, because those machines don't have audio cards. Klangsynthese also uses go-mp3 under the hood, so both libraries proposed in this thread so far are directing you the same way, sorry.
go-mp3 can handle any io.Reader, which doesn't have to be a local filesystem file.
Beep uses https://github.com/hajimehoshi/oto for playback, which is a collaborative effort with Hajime Hoshi. Recently I implemented ALSA backend for Linux for oto and that enabled really low-latency playback. Feel free to to do something similar for your library. We're working on such low latency for other platforms too.
The nice thing about chrome book is that dozens of shell tabs use virtually no local resources. It's light, goes everywhere, has great battery life, and is cheap. Used one as my primary dev environment for 2 years. 
Does anyone know when new developments on the plugin package are coming?
&gt; I would rather write scientific code in Go over Python any day because of Go's concurrency/parallelism primitives Except on those days where you need the expressiveness of a dynamically typed language with concise syntax like Python, which allow you to concoct a prototype quickly.
Gstreamer is Linux but you can use windows api to play audio too if you are on Windows. You can implement both and have your app to decide at runtime too
Klang uses ALSA, through an old library called alsa-go. I have a different pattern for playback than the one used by oto. It has low-latency playback, it's just that there's probably some maximum number of players that we aren't reusing or something on ALSA's end. I'm not in love with oto's playback because if you want to play multiple types of audio with different bit rates or sample rates you have to get a new player to do it. The pattern used by Klang attaches the encoding information to each audio sample, so they each act as their own player. That pattern of each audio acting as its own player causes the mentioned bug, as far as I can see. The same bug should be present in oto if you try to play multiple files very fast, because files need to each have their own player so you can make sure they are using the right encoding, or otherwise you're checking to see if you already have a player of that encoding type.
My very first Go project was a small PDF generation microservice based on gofpdf. I'd be interested in reimplementing with this :)
Those concepts are broad and common enough that I cannot recall any functional language which doesn't implement them. If the only language that came to mind based on that list is Haskell, your assessments of this topic are moot.
One question I had about PDFs (while you're here) is regarding the ability to sign a PDF with a certificate. I don't know whether this is proprietary to Adobe, but being able to sign a generated PDF, in a way that the PDF reader can understand, would be awesome for my purposes.
Beep implements its own mixing, so it can play arbitrary number of streamers simultaneously (as long as your CPU can handle it). It only ever uses one ALSA device/player.
&gt; I too want closure Go already has closures. Seriously now, there is a lot of people really, _really_ wanting generics and I feel like they should put it there if they want to call it Go 2.
What does beep do when presented with something of a different sample rate or bit rate?
I like this idea. That could be used to improve errors as well (which is another goal they have for Go 2). Like type result variant { string (or any type of a successful result) error } 
You set the sample rate of the speaker package and then everything you play through the speaker is assumed to have that sample rate. If it doesn't, you need to resample manually, which will be available by the (yet unimplemented) Resample decorator.
It also looks like you cast all audio to be stereo and 16 bit? Or at least the player assumes that's what it'll be playing?
Does gonum have anything for nonlinear convex optimization? Basically something that is similar to CP in cvxopt for python?
Take a look at the core Streamer interface. In the audio processing stage (outside of files and playback backends) everything is stereo float64. Then speaker package converts that to its internal format when playing, which is 16bit stereo, but it doesn't really matter.
maps and slices are already a special case in the language, so why not?
AGPL.... Thank you but no thank you
Cool! Let me know how you like it and whether you encountered any problems.
Are you planning on throwing the globals from the speaker package onto a struct, so users could have multiple speakers?
Why not just fork Go and add generics to the actual language and then we can all just move to that and forget the people who don't want generics and their depraved ways.
I'm not planning it, but if it turns out to be useful, I have no problem with it. The change would be trivial.
You can still have multiple beep mixers and so on, so it doesn't seem to useful to me atm.
It's a fair point, but acquiescing everyone's wishes gave us C++.
Yes, they are coming as soon as someone contributes to them :) Give it a Go, contribute them changes to 1.10 and the changes will come :)
It was not a direct follow-up. However I find it staggering that a code example is needed for something already so well understood by mainstream computer science. I am believing the issue is philosophical and not technical. Anyway I wish you good luck with Go 2 and I hope you one day build the language as you wish it to be. There is always room for more languages and I look forward to seeing the final spec for 2.0.
Well that's a completely different take. I'll have to think about it a bit. Thanks Edit: I [implemented his example](https://gist.github.com/weatherglass/229b8cb375dbd23468f0ed4bde0e377a) using my router. The central point of his argument is: &gt; Why do I believe that routers should not be used? I have three arguments for that: They need to be very complex to be useful, they introduce strong coupling and they make it hard to understand how requests are flowing. My response is that: 1. They're complex because they do complex things. By hand-writing each handler, he's reinventing the wheel each time. Each time code is repeated, there's an additional point for errors and therefore a need for additional testing. 1. I would argue the coupling in his example is even stronger than the coupling using a well-written router, just in a different way. In his example, the structure of the code in the handler has to match the structure of the api. During development, if the api changes, the code in the handler will need to be updated. In mine, you just change the path the router is given. The handlers don't need to know what the structure of the path is. They don't need to know how to parse parameters out of the url. They just know when they're called, they get the data they need and get to work. 1. Poorly written code is always harder to follow. But if you have a clear api, a clearly named handler for each method in the api, and the routes are added in a rational fashion, using a router can be much easier to follow - look at the url, look at the route it matches, go to the handler. One last point I'll make is about his helper function, ShiftPath. Part of the obsession with routers is getting as much performance out of them as possible. Memory allocations slow down routers. Every time his ShiftPath is called, there will be numerous allocations to deal with the string processing he does. If you're serving out a blog to a few dozen people, a few microseconds aren't going to hurt. But if you write microservices in go that handle tens of thousands of requests per second, you need every bit of performance you can squeeze out of it. I'm going to run some benchmarks, but I would bet my "complex" router will outperform his custom code. Edit 2: Good thing I didn't bet much. The two approaches are nearly similar in performance. Here's what I used to [benchmark the two approaches](https://gist.github.com/weatherglass/62bd8a704d4dfdc608fe5c5cb5a6980c). But really, look at the code in main_mux.go and main_app.go and tell me which is more maintainable.
The readme leaves a bit to be desired. I'd love to consume more information at a quick glance. I have a pretty simple readme template to follow. Shoot me a PM and I'll provide an example link. I'd post it here, but I don't want to distract and advertise one of my libs within your post. 
Fair point, but is there some design document that describes the future plans for plugins? I assume that they will eventually work on OSes other than Linux, but is it planned to also eventually remove the current constraints on plugins + main application being compiled with the same version of go and the same versions of their common dependencies? I tried and failed in finding something like that. I apologize if I am asking the wrong questions.
OK, but Go isn't a functional language. So if you want one, use one.
Now we are only missing a left pad library...
Found an odd one with the mp3 decoder; opened a ticket on the repo :)
It simplifies our codebase where we use a atomic values. It's a simple QoL abstraction that reduces boilerplate and increases code reuse. Some will find benefit, some won't. 
Thanks, I'll take a look asap when I get home. It seems to be a problem with go-mp3 I guess.
Come back when you try to take your xeon based cow of a server on a fucking plane. Or when it uses 60w or less, whichever is likely to happen first.
When I want to use a pure functional language, I do use a pure functional language. Your admonishment offers no enlightenment or increased freedom. As for what Go "is" (from https://golang.org/doc/codewalk/functions): &gt; Go supports first class functions, higher-order functions, user-defined function types, function literals, closures, and multiple return values. &gt; &gt; This rich feature set supports a functional programming style in a strongly typed language. Go already takes advantage of many borrowed aspects of the functional paradigm. Adding in the ability to ensure that a variable is not mutated does not restrict one to purity. Similarly, union types, while common in functional languages, are by no means some sort of basis for globbing implementing languages into a single category.
I'm fucked up about f key layout which makes it slightly awkward for development. But if you only use one machine (or an actual usb keyboard on it?) then yeah, fine. I have the toshiba chromebook 2 and i'm pretty happy with it even if build quality is sometimes noticably lacking
I whole heartedly agree. I'd like to see your template. I'll PM you.
This has nothing to do with Go. Solidity's compiler is not even written in Go, it's written in C++. You want https://www.reddit.com/r/ethereum or https://solidity.readthedocs.io/en/develop/
Sounds like you've never used Go. 
I used [moggio](https://github.com/mjibson/moggio) for some projects with audio which supports mp3 and wav decoding, and has cross-platform audio abstractions, among other things.
You could simplify the code a bit: type Int32 struct { v int32 } could be: type Int32 int32 
if(true) { Big }
Then you need type assertion when passing the value. The library used to use this approach, https://github.com/Path94/atoms/blob/4c08a635a142ea81217de780edfd4477da3dcf5d/int32.go
I've used both languages extensively. For scientific analyses (although not the type of simulations physicists/chemists do), Python is significantly easier to do than Go. Even if you have an equivalence of Numpy, it's not even close. 
&gt; How can I quicken the finer points of interfaces, methods and channels, bringing some understanding to idiomatic go. Read [effective Go](https://golang.org/doc/effective_go.html) many, many times. 
Added JSON support, so now you can include an atom value within structures which are marshaled and/or unmarshaled. type Service struct { Active atoms.Bool `json:"active"` }
My co-worker already committed code with some auto-generated structs! :)
You don't need unsafe. You can do a cast, which will most likely be a no-op in generated code: func (i *Int32) getIntPtr() *int32 { return (*int32)(i) } See https://play.golang.org/p/zS7qKfVRIF I would remove getIntPtr and do (*int32)(i) instead. 
Some people like to throw as much power at their wks as they can without needing it. Some people actually have justification for that much power. Some people would rather be able to take their workstation with them. Some people are just fine with a 4G workstation with a smaller CPU because they don't need more. Nobody's trying to take your hardware from you, nobody's isolating you out here. You do you - this seemed to work for the author - and tbh, I'm a bit interested to - but it's not for everyone.
I'll create a quick benchmark case and compare. One added advantage of the struct is you can avoid people doing unsafe actions such as: var ai Int32 i := int32(ai) // Not thread safe!
OK. I'll give it a read. Thanks. 
There's actually kinda an interesting theme touched on here. CPU's aren't really getting faster like they were back when clock rates doubled every 18 months. Also at the same time, the demand for mobile platforms often means less powerful systems. This flies in contrast with traditional point of view that program speed was largely unimportant. Go is well positioned for this world as a clean reasonably efficient language. This contrasts favorably with the interpreted languages that have grown common. Go is a 21st century tool in a world still largely populated with late 20th century tools. 
cvxopt is a special kind of system that is "disciplined" convex optimization. It doesn't allow you to write non-convex functions, and can use specialized solvers depending on the functions you do use. We don't have anything like that. We do have http://godoc.org/gonum.org/v1/gonum/optimize for general non-linear optimization. If your problem is convex, these solvers will work well and find the optimum. If your problem is really large scale and sparse, we don't have a good solution yet, though we're taking steps in that direction.
Yea, I suppose there are particular kinds of generics implementations that would be okay. Still, we would not want to write a matrix that takes a type `T` and can compute the eigenvalue decomposition for an arbitrary `T` (what does it mean to take the eigenvalues of a matrix of `&lt;-chan bool`?). Interfaces are a better mental model here, and interfaces with specialization could possibly work. This is effectively what we do today with matrix multiply and type reflection (not the reflect package). Allow `dense.Mul(a,b Matrix)`, where `Matrix` any type that satisfies the interface, and then call the specific implementation (dense-banded, dense-dense, dense-symmetric, etc.) depending on the actual types implementing the matrix, with a fallback if it's "none of the above".
&gt; but is there some design document that describes the future plans for plugins? Not as far as I know. I also couldn't find anything here: https://github.com/golang/proposal/tree/master/design or here https://github.com/golang/go/wiki/DesignDocuments. But you can ask more details on the mailing list and you should be able to get help there: https://groups.google.com/forum/#!forum/golang-dev &gt; I assume that they will eventually work on OSes other than Linux Afaik, macOS should receive plugins support in 1.9 but nobody offered so far to add support for the other platforms. &gt; but is it planned to also eventually remove the current constraints on plugins + main application being compiled with the same version of go and the same versions of their common dependencies There's one issue about that, but I'm not sure where to find it now, Github search is not the best one. There's also this issue: https://github.com/golang/go/issues/20481 as well. &gt; I apologize if I am asking the wrong questions. No need to, those are actually the right kind of questions.
We're very happy to hear that! :-)
&gt; I wouldn't be able to come up with all the words Naming is one of the two hard problems in programming. &gt; and syntax. How do I learn this? One compilation failure at a time.
Yeah you are
Added [generic value support](https://github.com/Path94/atoms/commit/161774a18e6581827f26636511066ab972785b07)! Edit - YAY! Cakeday :)
I got a Lenovo N22 for £100 last year (same N3060 CPU); there are lots of good things to be said about it, but also some annoyances. - I don't need a lot of performance for Vim + vim-go, but you *do* notice the lack of it on the N3060. `go install` or `go test` large-ish packages takes too long to be fluid, as do various other things (like autocomplete, running linters on save etc.) It will probably be worse with heavier editors/IDEs. - The environment is fairly constrained. Yes, you *can* run Firefox, and you *can* run your WM of choice, but it comes with various caveats and limitations; not to mention that it will take a part of the previous resources. You could also install Linux, but as your post already mentions that's maybe not a good idea. One reason I got a Chromebook is because I wanted a It-Just-Works-Including-suspend-And-Whatnot™ Linux laptop. Things like modifying keyboard shortcuts is also severely limited (you can only modify the location of the modifier keys). - Another example of limitations: no real way to run f.lux or redshift. - I've actually had quite a large number of crashes. Maybe about 15 in ~6 months. Not a huge number, but more than on e.g. my Linux desktop (I can't recall any recent ones). - You need to create a Google account and login with it to use the device. - The screen is the worst I've ever used on a laptop, ever. My 12-year old ASUS laptop has a better screen. The viewing angle is about 0.5°. - The keyboard is terrible. Describing in which ways it's terrible is an entire separate post on its own. Don't get me wrong, it's a neat little machine and I like it, but it's definitely a trade-off (which is what you would expect for £100). Some of these (like performance and the screen) are probably better on more expensive models, but at that point, you might as well get a "real" laptop?
I'm the moggio author. I had no idea anyone was using it for anything. It was written some years ago before most of the above packages existed, and would maybe be done differently now. But it does play vorbis, flac, wav, mp3 on linux, mac, windows, which is pretty good.
Thank you!
http://www.golang-book.com/books/intro
I wrote a short post on how I taught myself Go [learning golang](http://www.tysonmaly.com/programming/go/learning-golang/) The best thing I did was actually choose a [project](https://bestfoodnearme.com) to build. This by far was the best way I learned Go.
I've not gotten Termux to launch properly on my N22. Have you setup this environment?
No; AFAIK you can't run Android apps on the N22. I just use crouton+xterm.
Actually, you can. You have to switch to the beta channel and then run an update. 
Awesome thanks so much
Awesome I'll check out the blog and your project - Thanks so much!
The article and amazon description say SSD but I don't think that's correct. The amazon title and samsung's own website say it has eMMC storage.
Hi, author here. I was planning to submit this myself once I felt it was "ready" for a wider audience, but I guess delayed too much. Happy to answer questions here. Also, if you're interested in contributing to Ply, I'd love to offer you any assistance you need diving into the code. I've made an effort to write really good commit messages for this project, so hopefully that helps. :P Development has slowed down a bit because I've been working on other projects -- and because the improvements I want to make to Ply are becoming increasingly difficult to implement. But if one or two people start contributing seriously, I think we could build something really cool.
Awesome!! Now, all we need is a capable plotting library, like Matplotlib.
&gt; I'm sorry if this has been asked a bunch of times You're not sorry, you're lazy. Check the sidebar, there's plenty of fresh learning material there.
I feel your pain. Even with $200 chromebook 2 toshiba the keyboard is fucked. Well, mostly f keys but not only f keys. I tend to use those a lot in the terminal (midnight commander...) Edit: screen is way better tho, took the HD option.
A tradeoff for lower cost/performance seems acceptable. We're talking a sub-200$ laptop. For people who buy it the small form factors and price tag are more important than power/speed. It's like the whole RaspberryPi vs. PC debate. A low budget laptop of convenience (travel especially), doesnt need a xeon processor and the fastest of SSD's ...
Come on. https://www.reddit.com/r/golang/comments/6ovb2d/restful_api/dkkr4wq/ 
There seems to be some confusion here. Remember, type safety is one of the primary goals of generics, so of course the case of instantiating a generic type with an invalid type parameter is a solved problem: if you try to take the eigenvalue of a matrix&lt;&lt;-chan bool&gt;, you will get a compilation error because &lt;-chan bool doesn't have a scalar multiplication operator. Interfaces work fine, I agree. The only problem is performance, but if that's not a concern, there's no reason not to use them.
I'm only pointing out incorrect information so that nobody will be mislead.
You made an entire comment about helping him with his README with your lib. It's not distracting if you add your project. I and probably many others are interested and don't want to have to search for it ourselves or have to PM you.
Thanks. I didn't know how to do this. Could you please explain me what the last sentence mean ? &gt; For a method with a value receiver, one can derive a function with an explicit pointer receiver, so &gt; &gt;(*T).Mv &gt;yields a function value representing Mv with signature &gt; &gt;func(tv *T, a int) int &gt;Such a function indirects through the receiver to create a value to pass as the receiver to the underlying method; the method does not overwrite the value whose address is passed in the function call.
Google JSON and Go, and there is a really good blog post about it.
Do you mean something like https://github.com/buger/jsonparser ?
This is completely different.
Mine was one of the older Samsung models. It felt cheap but never broke in any way, until it had a seawater bath. Took me weeks to get used to a standard kb again haha. I replaced it with a Samsung 10.5 HD tablet and bt kb. It was ok but I reverted to a cheap 2 core celeron dell (299), and upgraded to 8gb ram and 500gb ssd running ubuntu. Golang compiles large programs and runs perfectly on it, but I still miss the chrome book sometimes for the size and convenience. 
Fair enough, [github.com/Path94/atoms](http://github.com/Path94/atoms) is a recent example 
That looks hard to read and understand. I don't think its a very compelling argument to ditch HTTP routers. It would be really hard to figure out all routes in an application if one applied his technique. You'd have to go to definition so many times. Sounds super annoying.
Some ultrabook models from Asus have the same convenience factor, with all the bells/whistles of a "standard" keyboard, and things like a better cpu/disk/ram config :) There's definitely some overlap between chromebooks and standard ultrabook laptops, considering the price tag of the pixel started was $1300, and there are several $500+ models available. If one is aiming for a better system config, it's definitely in the same price range, in a venn diagram sort of way.
am i also a fag?
With python it might be easier to prototype but with Go it's easier for a non-programmer to write a "production ready" program.
This is a complete program that decodes your JSON to a struct: https://play.golang.org/p/wMb9qY_t9t You might want to tidy up that struct because I generated it quickly from: https://mholt.github.io/json-to-go/
fantastic ! your auto generated is wonderfull, thanks :)
https://blog.golang.org/json-and-go
&gt; your auto generated is wonderful It's not mine. You might want to thank [Matt Holt](https://twitter.com/mholt6) who [made it](https://github.com/mholt/json-to-go). But it is wonderful I agree. :) 
FWIW, I think this looks like a great abstraction, not just for reducing boilerplate, but also for making it harder to do unsafe things with `sync/atomic`.
&gt; But really, look at the code in main_mux.go and main_app.go and tell me which is more maintainable. It depends on the scale. If you are one person writing all the routers then `main_mux.go` might be easier to maintain. But if you are got a medium-large team that each of them might be writing and changing handlers all the time then `main_app.go` is preferred in my opinion. Also it might not be obvious but `main_mux.go` seems lighter on the paper but hides a dependency of almost 1k lines of code. Meanwhile `main_app.go` looks more verbose but that's all the code there is.
&gt; I implemented his example using my router. Who is "he" in that example? Because it's not me. Your code does significantly less than mine. For example, your code only handles one method per path, completely side-stepping the main point of the post, that routers don't work well with "conflicting" routes. It also does not handle "/user/foobar/profile" correctly; it serves a 404, whereas it's supposed to serve a 400. You are, with this experiment, basically proving my point. Your simple router-code isn't simple, it's simplistic. It ignores 90% of the problem, to reduce code size. &gt; They're complex because they do complex things. They don't though. They traverse a graph. That has roughly the complexity of a half an hour interview question. It's not a "complex thing". &gt; By hand-writing each handler, he's reinventing the wheel each time. Each time code is repeated, there's an additional point for errors and therefore a need for additional testing. No. You don't need to put behavior into a type with methods, to re-use it. Using helper-functions works just as well. And it is better testable. Honestly, which API is easier to test, in your opinion: https://play.golang.org/p/lHqVqkaayy or https://play.golang.org/p/wKzrZ_BFNO? Which of these do you believe is more testable: https://play.golang.org/p/FTSAJPVBZN or https://play.golang.org/p/q2tp91Epdi? (this is just one of a gajillion ways to wire this up with the same idea. For example, using panic for the control-flow might be disliked by you; that's fine, you can also use returns and the like) The basic point is, that in the latter case of each, you split the logic up into small, clearly separated pieces that you can then test independently, while in the former case, you end up with a monolith, with few entry points that each branch out into a *whole bunch* of logic. What is more testable should, IMHO, be obvious. &gt; The handlers don't need to know what the structure of the path is. Because they ignore it. Now, imagine I am building something like `/debug`, a handler offered as a library, that people can use to access debug information about the process. That handler will have many different routes. But it doesn't know, where it will end up being hooked into the final service. What is the best API contract? * Register the following routes on your mux: "/debug/foo/bar", "/debug/foo/bar/:[a-z]+", ………… * Pass me a *router.Router, I will register my routes on it * Pass me a prefix-pattern, I will route everything below that pattern * I am handling "/" and doing my own routing internally so strip the path before delegating to me if you want to hook me to a different path I argue that the last one is the best, by far. The first puts a lot of work onto the user and every time, the structure of the debug-endpoint paths change (e.g. by adding a new debug page), there needs to be a change in every downstream. The second requires the user of your debug-endpoint to use the same router as you (and there are 15 million). The third, does that too, it just hides that behind a stringly-typed API. The last one is the *only* one, in which the debug-handler does *not* need to care about the general layout of all the paths in the service. It's perfectly reusable, you can hook it into any router the main service writer chooses at any path you want. And the main service owner doesn't need to know what the detailed paths of the endpoint are; it can just put the handler behind a handler that requires auth and it's fine. The last one is also literally what the pattern is, I'm laying out. Split your app into independent component, have them do their own, independent routing and delegation. Where you do the splitting and how the individual components route, is then secondary. You might even use a muxer for that. But I'd argue, in practice, you very likely won't feel the need to, if you do the splitting right. &gt; But if you have a clear api But [your API isn't clear](http://godoc.org/github.com/go-util/router#Router.Handle). Your API needs a whole lot of extra explanation and mental gymnastics to understand. Your API is stringly typed and I need to mentally parse the patterns used. I also need to understand the order in which your router tries routes; this isn't clear. You are just saying it "adds them", what does that mean? Compare that to the clear API of my helper functions above. Each has very limited responsibilities, so it is trivial to document and understand what they are doing. Each will just be a small handfull (1-3, probably) of completely obvious code. Muxers can't offer a clear API, because they necessarily implement their own DSL for routing (that's the point), so they need to document a complete programming language, which needs to be very powerful, to fulfill its designated needs. Muxers are, pretty much by their definition, hard to put into clear APIs and document easily. &gt; One last point I'll make is about his helper function, ShiftPath. Part of the obsession with routers is getting as much performance out of them as possible. Memory allocations slow down routers. Every time his ShiftPath is called, there will be numerous allocations to deal with the string processing he does. Leaving aside the larger point about how performance doesn't matter for http routers: It does zero allocations. Try it out. [edit: Actually, it does, I overlooked an obvious detail. See my reply to this comment for details and equivalent zero-alloc code] There are two parts to the function: a) `path.Clean` and b) a bunch of subslicing. b) trivially doesn't allocate. a) *does* allocate, but *only* if the path isn't cleaned. If you pass in a clean path, it will not allocate anything. And if you send a request with an unclean path to `net/http`, from what I can tell, it will redirect you to a clean version. But even if it wouldn't always, you would still only end up with a single call that does any allocations, because that would return a cleaned path that is then used by all the subhandlers. The existence of the `path.Clean` is purely to guarantee a clear and simple to use API, even *if* you have unclean paths (which you would have to manually introduce). So, in the end, the routing as I propose, is zero-alloc. Any allocations are problem-inherent and can't be done away by a router. On the other hand, your code *does* do string-processing including allocations, for things that are not problem-inherent. Because, among other things, you put parameters as strings into req.URL.RawQuery, even though they could also live as simple `int`s or whatever (see above). But to offer a generalized, monolithic API, you needed to have allocations. Which is why it's so important to friggin' benchmark. It's incredibly hard to argue about these kinds of things just by looking at them. &gt; If you're serving out a blog to a few dozen people, a few microseconds aren't going to hurt. But if you write microservices in go that handle tens of thousands of requests per second, you need every bit of performance you can squeeze out of it. I so hate this behavior. I am writing microservices of that size (even considerably larger sizes. I am oncall for services with over a billion users). I disagree with you not because I don't have the experience of running large services. I disagree with you because I have it. The performance of your router does not matter to a *very, very, very good approximation*. &gt; The two approaches are nearly similar in performance. Sorry, for the snark, but good thing you wrote a high-performance router, then, if I can literally fart out the first naive code that comes to my mind, which does more (see above. Your code is semantically less powerful) with the same speed. **Router performance does not matter** &gt; But really, look at the code in main_mux.go and main_app.go and tell me which is more maintainable. I did. Your mileage apparently varies.
What do you mean? I've used the same approach for BER, JSON, XML encodings and it wouldn't be a problem to support the shown problems.
No but you are.
I see what you mean. I'm a computer scientist working in a climate research institute and our go to tool is python. Python is not ideal for hpc systems and parallel execution. It is first most a scripting tool for first analysis and like others said, for prototypes. I don't think you can have the same productivity with python and go as a non computer scientist.
am i a gay retard?
&gt; It does zero allocations. Try it out. Ah, I was indeed wrong here. I call `path.Clean` with a concatenated string for convenience (I only benchmarked `path.Clean` itself). This equivalent code indeed doesn't allocate: func ShiftPath(p string) (head, tail string) { if p == "" { return "", "/" } p = strings.TrimPrefix(path.Clean(p), "/") i := strings.Index(p, "/") if i &lt; 0 { return p, "/" } return p[:i], p[i:] } Sorry for that. The point still stands, that the allocation isn't problem-inherent. With that change, the "app"-code now not only allocates less than your router (as it's supposed to), but at least on my machine also [measurably outperforms it](http://sprunge.us/MDbD).
With Python the first step is faster but when you refactor, upgrade or maintain your code (or the code of somebody else), with Go it'll become easier and easier. Though it will take some time to learn... Also it's important to use a good editor+plugin to gain a lot of time, thanks to type checking you have everything right under the finger.
The gayest. You're gayer than aids.
We do have a medium sized team (about 20 people split between the US and China). We use the main_mux.go approach, but each group of related handlers is split out into its own file. The router is created set up in a separate file that only gets touched when modifying routes. It is obvious that there's a dependency on a "hidden" kloc. That's why there's such an effort to write a high performance router. But I'm slowly coming around to /u/TheMerovius way of thinking.
https://godoc.org/github.com/gonum/plot
&gt; you will get a compilation error because &lt;-chan bool doesn't have a scalar multiplication operator. I guess that's my point. The actual idea wanted is better captured by interfaces than generics (in the typical sense). In this case we would need types that satisfy certain behaviors (like an interface), rather than needing to take an arbitrary type (like is desired new data structures, stack, linked list, etc.). I'm splitting hairs because of all the recent conversation around generics and how needed they are or aren't. &gt; that's not a concern, there's no reason not to use them. Except `float64` and `complex128` don't actually satisfy any (non-trivial) interfaces, so one would have to define their own special types to make it work.
&gt; Who is "he" in that example? Because it's not me. Your code does significantly less than mine. Sorry. Didn't put your username together with the website name. And yes, I see how it does less, now. I could argue that I could add a route like this (which would match if neither of the regex routes matched): mux.Get("/user/:invalid", mux.Error("400 Invalid User ID", 400)) But that's starting to sound like a cop out. &gt; But your API isn't clear. The rules that you linked to for routes aren't simplistic, but I would suggest less complex than other routers (and once you pick one router, you only have to learn how it routes once). But I was talking about the API of the application, not the router. So the API for my app is just three handlers: func GetUserProfile(res http.ResponseWriter, req *http.Request) func GetUserAccount(res http.ResponseWriter, req *http.Request) func NewUser(res http.ResponseWriter, req *http.Request) and (my implementation of) yours is: type App struct { UserHandler *UserHandler } func (h *App) ServeHTTP(res http.ResponseWriter, req *http.Request) type UserHandler struct { ProfileHandler *ProfileHandler AccountHandler *AccountHandler } func (h *UserHandler) ServeHTTP(res http.ResponseWriter, req *http.Request) func (h *UserHandler) NewUser(res http.ResponseWriter, req *http.Request) type ProfileHandler struct{} func (h *ProfileHandler) Handler(id int) http.Handler type AccountHandler struct{} func (h *AccountHandler) Handler(id int) http.Handler So each level of your code is like a mini-router (the helpers help, I admit) and the way the route is picked apart inside the handlers means that if the app API changes (as a contrived example) from `/user/1234/profile` to `/user/manage/1234/profile`, you're rewriting your handlers (which the helpers will help with) whereas I'm just updating two strings. &gt; your code does do string-processing including allocations, ... Because, ... you put parameters as strings into req.URL.RawQuery, even though they could also live as simple `int`s The rationale for using `RawQuery` is that the handler should not have to know about the router. So where does a handler get outside data from? Either the query string or form data; and the query string is the one that works for all HTTP methods. There are "zero-allocation" routers out there, but they require the handler to access the parameters outside of the way "regular" http handlers do. I wanted to avoid that, so yes, I do have allocations, but they're kept to as few as possible. &gt; The last one is the only one, in which the debug-handler does not need to care about the general layout of all the paths in the service. The handler calling the debug service doesn't have to care about the routes in the debug service, but the debug service has to act as a hard-coded sub-router. Yes, the router is a lot of code relative to this small example, but in a real app, having the routing spread throughout the application code will be a significant chunk of code that's not reusable. From your reply: &gt; With that change [patching the ShiftPath func], the "app"-code now not only allocates less than your router (as it's supposed to), but at least on my machine also measurably outperforms it. BenchmarkApp-12 200000 13666 ns/op 2440 B/op 20 allocs/op BenchmarkShiftPath-12 20000000 54.9 ns/op 0 B/op 0 allocs/op BenchmarkMux-12 100000 18167 ns/op 3321 B/op 28 allocs/op You got me there. EDIT: I just read your comment on the gist. I missed the differences between the work the two versions are doing. I'll update the code to more properly match the two. &gt; Your mileage apparently varies. It does, but I'm enjoying the discussion and learning new approaches. It's hard to change, and, at least at first glance to me, distributing the routing into the handlers seems like more work for little gain. The only way to convince myself one way or the other is to try your approach on a more realistic project, which I intend to do, and make a decision then. Thanks for keeping the discussion civil. Disagreeing without being disagreeable goes a long way.
&gt; and once you pick one router, you only have to learn how it routes once That is only true, if you're the only one to work on your projects and your projects are the only ones you are working on. In general, you'll have to read other people's code and other people will read your code and they will make different choices from you. Which is why you should, as little as possible, depend on complex external logic. &gt; you're rewriting your handlers (which the helpers will help with) whereas I'm just updating two strings. Handler. Singular. Only the user-handler needs an update, that is exactly the point. And it only needs one additional line. Even if you'd say that the *only* the profile-subtree goes out of the user-subtree, the rest stays the same, then yes, you need to update both the user-handler and the profile handler, as well as the wiring. I consider that both a good thing (because that changes corresponds with a difference in responsibilities) and a very rare thing. Your criticism is, that the structure of the paths correspond with the structure of the handlers; I'm arguing that most practical applications will follow that anyway. But I'm aware that it's hard to argue that (if nothing else, then because it's impossible to prove a negative; if I say "no X exists", you can disprove that by showing me an X, but I can hardly take *every single object* and show that it's not X). &gt; The rationale for using RawQuery is that the handler should not have to know about the router. So where does a handler get outside data from? Either the query string or form data; and the query string is the one that works for all HTTP methods. That is exactly my point. The allocations are inherent to the router-pattern, not to the routing. Thus, if allocations are your concern, the router-pattern is counter-productive, because it adds allocations where none where before. &gt; The handler calling the debug service doesn't have to care about the routes in the debug service, but the debug service has to act as a hard-coded sub-router. That is literally the last of the options I'm mentioning and what I'm suggesting in the post. Have components do their own routing, internally. I'm also claiming, that if you do this right, you'll find out that the debug service doesn't need a router or a muxer, because it will either be immediately clear how to do the routing, or it should be sub split in the same way *anyway*. &gt; Yes, the router is a lot of code relative to this small example, but in a real app, having the routing spread throughout the application code will be a significant chunk of code that's not reusable. I disagree. The more people are repeating this, the more I'm becoming confident that I can achieve the same goals as you do with your routers, in the same amount or less code; likely less. *Certainly* less, if we are taking into account the code of the router itself. My rationale behind that is, that all the functionality you are putting behind methods of your router, I can put in a helper-function; so at worst, I'll end up with the same amount of code (but better testable). Meanwhile, any lack of features will be easier to handle without a router. And I'm saving all the meta-code in the router, for the DSL and the setup and the like. For example, your router lets me extract regular expressions from the path, but it doesn't do the parsing of integers for me. Undoubtedly, that can be added (by extending the DSL you provide). But just as easily, I can add a strconv.Atoi to my own code. Similarly, it's easier to work around performance-bottlenecks. For example, one thing where my code still allocates, is by using closures. This isn't really a measurable effect, but if it would turn out it was, I could replace (or rather amend) `func (*UserHandler) Handler(id int) http.Handler` with `func(*UserHandler) Serve(id int, res http.ResponseWriter, req *http.Request)`. That would mean that call-sites that have the concrete type can replace `u.Handler(id).ServeHTTP(res, req)` with `u.Serve(id, res, req)`, thus saving an allocation. Compare that with what would happen if I'm using a router. Even if I could find such a replacement, it likely wouldn't be possible to do, because I'm bound to the router-API and the router-API can't easily be amended to take a `func(int, http.ResponseWriter, *http.Request)` (I mean, it *could*, but its contrary to the idea of a router, to provide enough general-purpose power. This wouldn't be general-purpose). Putting the routing-logic into the application handlers means *if* routing would ever become a bottle-neck (it won't, though) the fixes are relatively easy. Whereas if I am using a third-party router, it requires deep incisions into the router APIs. &gt; You got me there. But again, router-performance does not matter. If you look at [flame-graphs of the benchmarks](http://merovius.de/torch.svg), you'll notice that for either benchmark, the majority of the CPU-time isn't spend in routing. Of the rest, probably 90% or so are spend on writing the response to the buffers and other trivial stuff. So, we are talking about ~5% of the time *for handlers that do pretty much nothing*. They do literally nothing but write a string to the response. I mean, for crying out loud, a third of the CPU time of your handler are \*URL.ParseQuery calls. What do you think will be the time spent in routing for an *actual service*, that does *actual work*? Don't answer. Measure. Take your go-microservice in prod (or, if you have, your loadtest environment). Fetch a CPU-profile from /debug/pprof. Take a look, how much is actually spent in routing. I bet it's a very, *very* small percentage and it won't differ much based on what router you use. (Though you *are* using regular expressions, which are notoriously slow. Which is why you shouldn't use routers, they need slow regular expressions to express their API ;) )
We have a some `struct` and slice of bytes `[]byte{...}`. Required to work with this bytes. You propose to create an instruction on how to fill it in? The method you proposed, needed when from a large amount of data obtain certain values. Ex. from large xml file get specific fields. Stob not for this, does not work with text data. Example - simlified network package: type Package struct { DstHwAddr net.HardwareAddr `num:"6"` SrcHwAddr net.HardwareAddr `num:"6"` Type [2]byte [...] SrcIP net.IP `num:"4"` DstIP net.IP `num:"4"` SrcPort uint16 `bo:"be"` DstPort uint16 `bo:"be"` [...] } With **stob**, we may fill `Package` struct from byte slice `[]byte{...}`: //prepare struct var p Package ps, err := stob.NewStruct(&amp;p) [...] //end then in loop where we in our example listen raw sockets buf := make([]byte, 1500) for { n, _, _ := conn.ReadFrom(buf) ps.Write(buf[:n]) //fill p(Package struct) [...] } An alternative a stob is manual marking: var p Package p.DstHwAddr = buf[0:6] p.SrcHwAddr = buf[6:12] p.Type = buf[12:14] // etc. It`s faster, but uncomfortable. What do you offer? Write your own DSL for this? 
am i allowed to say nigger as a transnigger?
&gt; If you're serving out a blog to a few dozen people, a few microseconds aren't going to hurt. But if you write microservices in go that handle tens of thousands of requests per second, you need every bit of performance you can squeeze out of it. So, let's put out some fermi-estimations here, based on these numbers. ~~A good ballpark guess for QPS per core for a run-of-the-mill service is ~1K. Meaning, if you want to serve "tens of thousands of requests" (let's round that off to 100K), you need ~100 cores.~~ [edit: not actually important] Now, say you can save 1μs/query of CPU time by spending one day optimizing your router (conservative estimates, based on the benchmarks you posted. Again, fermi-estimation). That would then, based on 100K QPS, save you 0.1 seconds of CPU time per second, that is you would need 0.1 core less in total. On GCP, you get one core plus memory for $0.0475 per hour. Meaning you saved ~$0.005/h. The average SWE in the US earns $80K/yr, so a ballpark of $300/day. So it would take roughly 160 years, until that optimization paid for itself. And that's if you spend one day. Of course… yeah, I get it. It's going to be used in more than one service. My estimations are probably off by an order of magnitude, here and there. But, overall… it's *very, very, very likely* not going to be worth it. Computers are cheap. Routing isn't a significant part of the CPU-time of a query. Benchmark and then optimize the bottle-necks. It won't be your router.
To add to what others have said, paste the json into [json-to-go](https://mholt.github.io/json-to-go/) and it'll generate a struct you can use in your code for easy parsing. Also useful: [Go by Example](https://gobyexample.com/json)
Sure.
you're my nigga
Here's the blog post about Vice: https://medium.com/@matryer/introducing-vice-go-channels-across-many-machines-bcac1147d7e2
I had a use case for something just like this come up literally this week. Will definitely be trying it.
As i remember nats has its own netchan implementation 
Well that's quite the rabbit hole. Added `// +build darwin,amd64` as I've only tested on my laptop. I'll have to do some more digging to see how to get it to work on other os/arch combos.
You do know what BER/DER formats are? e.g. see https://github.com/egonelbre/exp/tree/master/ber Simplified DSL example for single data type https://play.golang.org/p/X4eJHA-mL9, if that is easier to understand. The encoding format doesn't matter, this approach can support multiple at the same time if needed.
Put them in a slice and run thru the slice as an alternative :)
Use Adapter (Decorator) pattern. Great article on that: https://medium.com/@matryer/writing-middleware-in-golang-and-how-go-makes-it-so-much-fun-4375c1246e81
https://github.com/jmespath/go-jmespath A query language for JSON with a Go implementation.
Here's my suggestion. Create your own helper to do this. I just got finished doing the same for a few shared projects I have: https://github.com/micromdm/go4/blob/e55c5245fedcdd8462e931c1cb2447f092b4456d/httputil/middleware.go#L12-L27 First, I defined a Middleware function type like so: // Middleware is a chainable decorator for HTTP Handlers. type Middleware func(http.Handler) http.Handler Next, I created the helper function which lets me do `mid1(mid2(mid3(app)))` // Chain is a helper function for composing middlewares. Requests will // traverse them in the order they're declared. That is, the first middleware // is treated as the outermost middleware. // // Chain is identical to the go-kit helper for Endpoint Middleware. func Chain(outer Middleware, others ...Middleware) Middleware { return func(next http.Handler) http.Handler { for i := len(others) - 1; i &gt;= 0; i-- { // reverse next = others[i](next) } return outer(next) } } Now I can chain a set of handlers. See example here: https://github.com/micromdm/go4/blob/e55c5245fedcdd8462e931c1cb2447f092b4456d/httputil/middleware_example_test.go#L11-L29
You can read [this article for more details on the Go scheduler](https://rakyll.org/scheduler/). The scheduler is basically similar to what a thread scheduler is in the OS kernel - it schedules work between goroutines. The performance hit is smaller than starting actual threads. I wouldn't know about a comparable thread executor, but the concept of 'coroutines' is well known in other programming languages as well. Perhaps this is a question for /r/java more than here. Edit: [this stackoverflow post might provide some info into the state of goroutines in Java](https://stackoverflow.com/questions/2846664/implementing-coroutines-in-java).
https://www.reddit.com/r/golang/comments/2gecvq/netchan_go_channels_over_a_network/ckix68f/
&gt; Is there a performance hit from starting goroutines like this ? Just to be clear, this is the only way to start a goroutine. You probably know this, but your question could imply that there are more ways to start goroutines, which is false.
Unfortunately in today's scientific world, where you are pushed to publish publish publish, only prototyping counts
So: You have blank types with whom you can do nothing. You don't even have equality. So you could build lists and linked lists and the only thing you gain over interface{} is maybe some "boxing/unboxing"? Do i miss anything?
&gt; In our days, net/http-based projects are slow and cost-ineffective, so I just write the basic version. Uhh.
Personally I don't completely buy jerf's argument that go channels lack a mechanism for when a message is received and not ack'd. No system has a way of detecting this situation, the whole point of the ack it because there is no way to detect receive. I'm not saying this is a good idea or not, I'd need to play with it to see, but there is nothing inherently wrong with it at a technical level. At least based on the post you referenced.
Thanks, now I have to buy a chromebook :)
Go right ahead and do that.
I'm sorry your reply makes no sense to me. A good network API returns completion when the other side reports success, and errors in all other scenarios (server, network, local); channels have none of that. Go channels are a communication mechanism suited to function inside one failure domain, and if you want the happens-before features too then within one memory coherent system.
This looks like another Iris or whatever that thing was called.
https://github.com/justinas/alice is pretty nice.
This is good, but you need to note it has a 1366x768 display. I'd rather spend a bit more and get a 1920x1080 display.
There is a negligible performance hit but it would be highly dependent on what's going on. If you're asking about memory penalties, this is a non issue on modern systems. Goroutines do not have the memory overhead of the full runtime. If you're asking about CPU penalty, you need to test. It's not clear what your goroutines will be doing but on modern multi core machines, you likely won't notice anything but I encourage you to use the excellent profiler. Even if the goroutine blocks, you're not likely to realize it as long as there aren't severe resource contention. When you will notice is when you do things in goroutines like tight select loops. I'm not familiar with java, but if the name hints to me what that is, you may want to look at the package sync.WaitGroup. Edit: side note, usually things slow down when you start using a mutex to coordinate things between goroutines. As a design principal you likely want to favor sending the data across a channel to avoid extraneous locks. 
Goth does handle storing/retrieving authentication within your application. It just wraps dealing with 3rd party providers to get information about a user. It's up to your application to keep track of your application's sessions, users, etc... The Goth session is only used to store information during the process of sending a request to an OAuth provider and returning back to your application. Here is some code, admittedly from a Buffalo application, that shows handling a Goth callback, storing/retrieving in a DB and handling the application's session. https://github.com/gobuffalo/gothrecipe/blob/master/actions/auth.go Hopefully that'll guide you in the right direction.
The answer is always "it depends", especially when you aren't telling us exactly how you're using the goroutine. Just your luck, there's a standard library that allows you to measure the performance yourself: https://golang.org/pkg/testing/ Wrap your code in a test, and run the test using `testing.B`. Tweak the code, re-run, bam, there's your answer. 
It's an 11", so... choose your own chromebook ;)
Nice article! You wrote that you're currently working on something that would benefit from generics. I'd suggest you write an article about that too, since that would serve as an 'experience report', which is what we currently need in regards to generics.
Good point, feel like I need more time to collect my thoughtd on it but will do and let you know.
The problem is that Go's channels _do_ have a mechanism for reliably detecting that the message has been received, not that they _don't_. They have a fundamental semantic that can not be implemented over a network. The buffered case is more complicated to analyse but still not possible to deliver over a network. Select is also impossible, even considering only non-total message order, even if the network is error-free. You can only get sorta similar semantics, with some sloppiness built in, not identical ones. 
Awesome! I'd like to clarify that I'm not on the Go team. Experience reports should be posted here: https://github.com/golang/go/wiki/ExperienceReports (and posting them here on Reddit as well is very nice too).
TIL https://github.com/thejerf/reign Given you posted about it 2 years ago, how usable is that now?
It's in production now. Master is pretty close to what is in production. Lacks back pressure at the moment and I haven't had time to brush up the docs for official release. (I'm on vacation right now.) 
Artist, huh. I guess I should ask a plumber.
If they've also been a lead dev then ya, they might have a fresh perspective.
Point is, "from an artist" is an appeal to an unrelated accomplishment.
As a licensed fisherman in several US states, I'd like to voice my support for /u/Abyxus.
Seems you got a bunch of underappreciated, bitter artists, bakers, carpenters and dog-walkers downvoting you. I'm in agreement -- I don't get the appeal of the title. There are more creative ways to appeal to the outsider's perspective, should ask an artist to come up with a better title... oh, wait.
IMO it is still possible to use channels as a network abstraction with the caveat that with channels you have control of when the channel is closed and with a "network channel" you do not. That they could close at any time and cause a panic. I'll freely grant that this is probably not the best abstraction for networked connections, but that if you squint right you could see how it would be done. Back to the original post, at a cursory reading the library doesn't really give you network channels. It gives you services that listen to channels and forward that onto an external queue and handles network issues with a separate error channel. So the grandparent linking to your post was not contextually appropriate anyways.
The linked to post was about how with any network connection it is possible for the message to have been sent but an ack not to have been sent in reply (the connection could have dropped in between). So it is not that good networks don't have acks, it is that networks are unreliable with acks. 
Not an author ;) The title is probably too lame and will make a more concerned effort with it next time.
I just disguise mine as a fat child
There is another alternative here -- which is to do your development on a remote host. When I travel I don't like to take my macbook, so I have an account on my wife's $200 chromebook with Secure Shell installed. This allows me to log into a remote dev box where I can do pretty much all of my work (this *does* require you to be comfortable with an editor in a terminal; I use vim along with tmux). I also have certain vpn requirements which are difficult to deal with on a chromebook. Finally, Secure Shell allows port forwarding, so I can proxy my browser through my dev host to get to sites otherwise locked down by vpn. I am also only limited by the remote hosts's hardware. In my case I use aws generally (because someone else is paying) and the instance is easy enough to enlarge -- but you could use whatever you like -- linode, digital ocean, whatever. This obviously isn't for everybody -- you *must* have an internet connection to use it and you need to be quite comfortable using an editor in a terminal, but for my needs it's pretty much perfect.
&gt; IMO it is still possible to use channels as a network abstraction with the caveat that with channels you have control of when the channel is closed and with a "network channel" you do not. I'm back at a keyboard now, instead of on my phone, so I can be a bit more complete. First of all, that is a HUGE change vs. how they work now. Note that channel failures can manifest as _panics_ in Go, not just errors. The channel API (built into the syntax) was not designed for this use case. Secondly, that turns out to not be adequate. The channel API implements a "send exactly once" semantic. If you send a message on a non-buffered channel, passing that line of code means you have a guaranteed sync point with the other goroutine that received the message, and there is exactly one goroutine that received that message. Buffered channels are a more complex analysis but it suffices to point out that they become very similar to non-buffered channels once they fill up, which is a case you must consider. Once you are on the network, you can not implement "send exactly once" semantics, a well known result in the field that remains true even though it strikes many people as counterintuitive and even though a lot of people "disagree" with it. It's true, because it can be shown to be true with mathematical precision. The best way to get around that is to have idempotent messages, which is great and all, but the Go channel API does nothing to help you with that. If you have to implement "safe channel sending" as a second layer above the putative "network Go channel", then you by definition don't have a "network Go channel" in the first place, because you do not need to implement that for non-network Go channels. Select screws with this even more. Select statements depend on all sorts of subtle characteristics of the channel API and the fact that all the channels are local. Even for sheer performance reasons, you have the issue that select is specified as non-deterministically picking from the available channels, but a network-based select is going to have a significant performance different between the local and network channels, to say nothing of the fact the inability to send exactly once to channels in general will screw with it as well. The problem is a lot of Gophers think of channels as a very vague pipe-ish thing; "I put it in this side, I can get it out the other, that's all a channel is". Even _that_ terrible weak specification of channels is actually not possible on a network because there's still an implicit "send exactly once" in there. But channels are a lot more than that, too; they are sync points between goroutines that can be used to satisfy the race condition checker, with all that implies. They have semantics related to multiple listeners and multiple receivers. When you mentally designed your network channel, did you specify what it means for a single channel to have multiple and multiple receivers, all on different machines? There are a lot of interactions with the select statement, its nondeterministic selection of available channels. There's the fact that as closing a channel is _optional_, it is not simply equivalent to say "if I lose connection to the other end, the channel is 'closed'"... and this combines nastily with the fact that channels don't actually have _owners_ and there _is_ no way of knowing whether a channel is out-of-scope in the entire network. My standard for "can there be Go channels on a network" is that I ought to be able to take these putative network-Go-channels and drop them into any correct Go program, and still have a correct Go program if I use network channels in the exact same code. For instance, if a library package current accepts a channel as an argument, that library ought to continue to be correct with the putative Go network channels. This standard is mathematically impossible to meet. So there can be no such thing as a "network Go channel". You can of course do all sorts of other things over a network. I've done all sorts of them. But they have fundamentally different semantics and could not be fit into the current Go channel API without massive, Go 2.0-level rewriting of the channel API.
Still, making no sense. Yes, if you don't get an ack fast enough that's one possible error scenario. All networks are unreliable, by definition. The part that makes networked services reliable is retrying operations that don't get acked. Channels have no mechanism for reporting lack of timely ack to the sender.
Does that count as submitting it to reddit?-)
The only mechanism for reporting the ack would be continued operation. An ack fail would mean a panic. And again, while something might be possible, it'd be ugly and a bad idea.
"Typescript’s generics with there ability to interface on both methods and data." I think you mean "their". Nice write up! 
That's offensive. I'm a black transgender in a wheel chair
If they're just convenience then could they just be functions?
It's a preview of what the text is going to be about, not an appeal to having a more important opinion because of artistry
I don't get it. h := app h = mid3(h) h = mid2(h) h = mid1(h) http.ListenAndServe("/", h) Now, adding or removing a middleware is as simple as it can get, delete a line, add a line… I don't see, how using a slice helps. Or how a package could possibly help…
That's fine. Let's at least build it.
&gt; I can't help but read all this--for how many years now?--and think of: What are you even talking about? &gt; For the generically obsessed Generics? If this is about generics then I don't see how the TV show quote fits. For some people using Go is their livelihood or maybe they would like it to be. 
&gt; Seems you got a bunch of underappreciated, bitter artists, bakers, carpenters and dog-walkers downvoting you. I'm none of these. I am a Computer person and literally nothing else. I am downvoting this BS because it's toxic and arrogant. It implies that your opinion (or even you as a person) isn't valued or important if you're an artist, which is false, condescending and ignorant. And this quote isn't better. The both of you need to pull your head out of your ass and realize that there are other professions than yours that are just as valid and that have something to contribute to your field too.
You gain compile time type safety around interface{} based types (the strongest argument against inerface{}) . And you can build functions like Map, Contains etc. and you can compose such functions. So pretty much any use case for generic types without having to deal with them.
&gt; The use of code generation tools that just makes the code way more unreadable for the end-user How exactly does code generation make code unreadable? We have `gofmt`. &gt; and creates confusion due to various functions with similar names instead of having just one. — Sacrifice code readability and API complexity for type safety So as I understand the author of the article claims that if the end-user sees an API like: * ParseInt64 * ParseUint64 * ParseFloat64 Then they are going to be like: "Oh dear lord what could those functions possibly be doing!? I feel so confused!". Please. Also the article only mentions 2 ways of dealing with generics. Code generation and `interface{}`. What about Go's primary mechanism for generics? I am talking about interfaces. Surely it doesn't work in all cases. But when it does it provides amazing code reusability. This [article](https://appliedgo.net/generics/) discusses even more ways but I digress. &gt; the pkg maintainers decided to expose 1 function and leave the hard work of type checking for themselves instead of exposing 44 different functions with similar names to the user. And all of that to add a simple handler. What? Just because the authors of some random package on GitHub decided that it's a better idea to write a function of 44 type assertions instead of using interfaces to chain handlers, you know like the rest of the world does, now we showcase it in an article as a good example of what could be solved with generics? Please.
So I start reading this article and I am like, "Finally! A good experience report". Then I continue reading in anticipation to read a concrete example and I only find this one sentence and nothing else: &gt; "Lately though I’m working on a project in Go where generics would mean less and clearer code." This article left me utterly disappointed. Maybe it wasn't meant as an experience report in the first place. But regardless, I believe that as it is, it brings nothing to the discussion.
The code of conduct is right there. I suggest you give it another read.
The "artist" part of the title does have a relevance to the article, and it made me curious enough to read the article. So there is absolutely nothing wrong with the title if you ask me. BTW, I like the comparison of the Go generics discussion to the Blender quit prompt discussion, you make a point here. I only wonder why the quit prompt discussion was not ended quickly by adding a preference setting to show (or not show) a quit prompt. Unfortunately, adding generics to a language is much more difficult and has much more consequences than a quit prompt, so I don't expect to see an easy solution in the near future. And as an off-topic, I don't get the "Blender is simple" part :) I once tried it and found the UI bloated and unintuitive. But I am not a 3d artist, and if a real 3d artist says that Blender is simple, this only can mean that other 3d tools are even worse... :P
I just met a simple code construct that would love generics. It's a growable ring container using slice. In summary, a container. I could have used interface{}, but the elements are two fields struct. So it is more efficient to use an array of struct instead of an array of interface. That would be two pointers (interface) to a two field struct allocated on the stack. I could have used a big channel but I don't need synchronization. Channels have some synchronization overhead that affect performance. It could be interesting if that synchronization could be optimized out by the compiler. I implemented the ring as I wished. Not a big deal. The positive thing is that I wrote exactly what I needed and not more. It wasn't much work to test. 
A great service. Any way of accessing beta and RC tags, too? (I am missing the 1.9 tags)
&gt; Right now the big debate is whether generics should be included in version 2 of the language. As much as it pains me, personally, but that's not really up for debate anymore. That discussion has pretty much been settled by Russ Cox' [go resolutions for 2017](https://research.swtch.com/go2017) post. go 2 will have generics. What's undecided, is *how*. That being said, yes, apparently the discussions around it are still devolving into the "if"-debate… Not entirely sure, why that is. One part is certainly people like me, who still doubt even the need. Another part is certainly that it's really, *really* hard to get their proponents to talk specifics (instead of generics, I guess ^^). Even after Russ said very explicitly, that he wants to add generics and what he wants from the community to decide the "how", we still don't get a lot of that. We just get the same old bickering…
Be careful with comparisons like this. The Iris project is associated with severe accusations (from several people against the author) of ignoring copyrights and claiming other people's contributions as the author's own contributions. I cannot tell how much of this is true, but calling a Web framework "like Iris" might trigger bad memories with many people in this subreddit and might thus cause unjustified damage.
Yes you're right. it's the trade-off that you need to choose to get the particular price point. I would even investigate the Chinese laptops, as screen resolution is a pretty important thing for me. 
Was trying to find a better name for this since my english is quite limited and boiler is a product of boilerplate and not other way around, boilymcboilerface?
Any specific brand which might be better than others? I have a bias towards older established players in regards to tv/laptop areas. Except Philips, those guys suck hard when it comes to their TV line.
+1. "instead of using interfaces to chain handlers", could you provide an example for me? Not that experienced with Go.
It's actually very bi-polar. It's advocating against generics in one example, and then immediately jumps on advocating typescript generics in the very next sentence. \o/ The only point I can take from this article is that the whole generics discussion can last for years and eventually when it's made, some people will be happy with it. Other people will do what they did before generics (which doesn't really change the language... much?). I.e. adding generics as a bolt-on has little impact.
The basic idea is that you use a signature like this to chain handlers using the `http.Handler` (which is an interface): func(http.Handler) http.Handler This [article](https://medium.com/@matryer/the-http-handler-wrapper-technique-in-golang-updated-bc7fbcffa702) explains the concept pretty well.
Well, it's a you pick your own poison thingy. What I'd recommend is you go through the reviews on the youtube channel techtablets.com . Edit: he has a good selection of low to high end Chinese tablets. Pretty interesting viewing.
Derp, i actually do this for middleware. I just didn't see the connection to generics here.
https://github.com/golang/go/wiki
- A little example `interface{}` is _not_ a replacement of generics. Interface with a real methods set, like `sort.Interface` are. - sync/atomic The implementations of the various functions are very specific sequence of very specific machine instructions per platform and per architecture. - math/rand The differently named functions in your example are not different because of types but because they do very different things. - math/big Float/Rat/Int flavors perform distinct, quite different tasks. 
Is the web-socket secure. Is it possible for an existing websocket connection to be hijacked after it's been authenticated?
Wow thank! This makes the whole thing much easier than!
hard to tell you what you're doing wrong if you don't share the code you used, your setup and how you timed things...
You can also set a cookie if you want to maintain the auth.
Thank you 🙏
Read about OAuth authentication flow and you will see why you need two routes to complete the login process. Goth does the communication with the OAuth providers for you yielding the user's information. Your job is to handle this data in the callback get request, i.e. creating the session and maybe saving user data to a database if needed by your app.
[But why?](https://media.giphy.com/media/1M9fmo1WAFVK0/giphy.gif)
I guess I didn't explain myself correctly nor gave a good non-stdlib example. &gt; Then they are going to be like: "Oh dear lord what could those functions possibly be doing!? I feel so confused!". Well, obviously those cases aren't confusing, but since I don't know anything about the world's code patterns, I've to assume that somewhere in the world someone's code looks different than that and that is more complex than that... At the end, I believe at least the post wraps up well, the whole point is: * minimize API's * generalize common behavior * let the pkg maintainers deal with the types and make our users happy That was my first post too, thanks for your opinion!
Yes, that is the correct name for it. 
No, as it still needs to operate on a mmap.Writer. The equivalent to value, err := m.ReadByteAt(offset) would be result := make([]byte, 1) n, err := m.ReadAt(result, offset) // check for error value := result[0]
You make it sound like it was an accident.
you're right, by "while playing around" I mean "please don't judge code, not sure if it is the right structure, etc" :) but Yes I wanted to mount gdrive before on a headless archlinux VM and the solutions weren't that viable (gvf-google [gnome, gtk], ocaml-fuse-gdrive[AUR + lots of AUR dependencies]), so indeed started playing with go+fuse and created GDriveMount, later organized code and added dropbox and I'm planning to add others as I see fit
thanks for support. I must to note that I've participated in those issues on github about iris author's copyright violations. here I'm doing it as fair as possible, some history is published in readme.
Other models of concurrency are normally designed to be implemented via a library. The model Go uses is already quite an exception to the rule in that it relies on language features. Why would a different model need to rely on language changes?
Kudos to the author for imagining what generics in go might looks like. We should be encouraging this sort of discussion, rather than trying to quell it. What do we have to lose? If we're open to discussion, maybe we can come up with an implementation of generics that reflects go's design philosophies. It could be much simpler than what C++ or Rust has or maybe it leverages go's existing interface system.
Am I the only one who feels like they are taking crazy pills when they read about async in C#/Python/JavaScript? It's so much less convenient than Go, but people act like it's great even though it's really just cooperative multitasking with a language keyword. It makes no sense to me. 
This leaves the connection potentially vulnerable to [cross-site connections](https://www.christian-schneider.net/CrossSiteWebSocketHijacking.html), it is imperative if you're authenticating using cookies to also validate the`origin` HTTP header, it's better to send the authentication data over the `wss://` connection and validate the `origin` HTTP header.
Great! Though I didn't find any visual examples. As far as I can see I can't do things like 3D plots? This is the kind of stuff I'm looking for: https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html
The benefit is in reusing chains on multiple endpoints and enabling flexible composition of chains. https://github.com/codemodus/chain Edit to add: Please note the TODO - https://play.golang.org/p/CLsIHRp9Ft Using a library like "chain" keeps nested handler composition clean and free while remaining simple and low-cost (sub-microsecond). Edit again to add: The same code as above using chain - https://play.golang.org/p/qdigQNJqyn
This being said I *would* like it if you could specify priorities that the scheduler could recognize. A la boost's fiber scheduler
The 70k is for junior developers who need to be taught the basics, anyone who's proficient in Go will be earning 100k+ depending on skill. I just wanted to clarify to address some people's concerns. 
I'm from Germany and I would never move to the USA for work because your labour laws are really terrible. Though honestly, I'm not really interested in the job offer either as I just started a new job doing research.
Then why comment on this post at all? I'm sure they'll find some great candidates here in the US. Regardless, golang is an awesome and great language. Hope you're enjoying it regardless where you are.
Understandable, best of luck at your new job! Best, John
I think I know why my thoughts made no sense to you. I was only thinking semantics, not implementation. That the semantics of a channel could do what I was describing, but it couldn't be implemented in golang without some change. For what I'm thinking to work there would need to be support for taking a value from a channel without releasing the block on the sending side. So you could send the packet and get the ack before releasing the lock. I know I didn't make this at all clear and to be honest I probably didn't have it straight in my head. I got stuck thinking in the semantics only mode and it didn't occur to be until later that what I was thinking would be impossible to implement in the language as is. My apologies for irritating you.
Yeah and the whole text is as bad as its title.
I am trying to show that they probably miss quite a few competent programmers by restricting their pool to the US.
&gt; I would never move to the USA for work because your labour laws are really terrible. What makes their laws terrible? Just curious.
I'm very interested to see how this thing works, so a README with some explanation would be awesome. 
You got a typo, you wrote peace of code instead of piece of code.
Hello everyone, I've added a proposal to the Go language, and I'd like to hear what other gophers think. I must say that I'm not a fan of changing or adding new stuff to the language, and really like the language as it is. but I feel like this feature is so much missing, because it simplifies the code and makes it much more readable than it is today (I've added an example there). please, check out the proposal and post your feedback here/there. It'll be really nice to hear what other gophers think about that. 
For example, you can get fired for no reason with very short (or no) notice (cf. right to work laws). Because they don't have to give a reason, you can be fired for all sort of inofficial reasons, like trying to form a union or going on strike. You do not have the [right to codetermination](https://en.wikipedia.org/wiki/Co-determination). You do not have paid sick leave. You get very few (if any) paid vacation days. You have very little protection from getting fired. For example, in Germany, to fire an employee you either have to prove that he did a mistake so egregious that further employment is out of question or you have to formally write him up three times. Write-ups are expunged after a certain time, so the employer has to prove that you consistently do mistakes. You can appeal each write-up and you can appeal termination. In the US, you do not gain job security for being employed longer. For example, in Germany, the length of the notice period when your employer fires you grows the longer you are employed. In the US, employers can make you sign non-compete agreements that hold even when they fired you. This is terrible. I don't want to work for a company who lays me off and then I can't even work somewhere else in the same field. In Germany, non-compete agreements are only valid if you get paid for them during the time they hold; the pay must be at least 50% of your gross salary and you can't be prohibited from working in positions that do not directly compete with your former employer. These are just some examples. The list goes on and on, i.e. when it comes to unemployment benefits and healthcare costs.
**Co-determination** Codetermination (also "copartnership" or "worker participation") is the practice of workers of an enterprise having the right to vote for representatives on the board of directors in a company. It also refers to staff have binding rights in work councils on issues in their workplace. The practice of board level representation is widespread in developed democracies. The first laws requiring worker voting rights include the Oxford University Act 1854 and the Port of London Act 1908 in the United Kingdom, a voluntary Act on Manufacturing Companies of 1919 in Massachusetts in the United States, and the Supervisory Board Act 1922 (Aufsichtsratgesetz 1922) in Germany, which codified collective agreement from 1918. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
All of the things you mention that we're lacking are not guaranteed, but are contractable. 
Very interesting information. Thanks a lot.
And which employers allow you to add that to your contract? Especially the part about codetermination?
Too many to enumerate? I suppose it depends enormously on whether you work for big or small companies, how in demand, etc.
If you believe that a company creates a work council because one prospective employee wants that in his contract, you are full of shit.
Am I full of shit if the employee is a founder and decides the only way they'll join is if a work council is put in place? In any case, all I pointed out is that you were wrong to say we don't have these things, you should have said none of these things are guaranteed, though many of them are extremely common.
Why the location restriction, when you are offering the possibility of remote? Wouldn't it make more sense to restrict based on timezone? Since I'm already reading it, might as well give you some feedback: &gt;Comfortable Open Social Work Stations This isn't a benefit. There is a large body of evidence showing that open plan offices are terrible for productivity for anything that requires focus. (might be ok for sales, maybe) &gt;Generous Natural Lighting Not a benefit. &gt;Company Laptop Not a benefit, but I guess it's the norm in the industry to list these, so let's say this one's ok. Otherwise it looks good. You might want to provide a link to some more information about the product, or is it a completely new project?
Panic on network errors is a pretty bad idea, for sure.
Is Google better place to work than coder? 
The important ones (protections against unjust termination, unlimited sick days, an acceptable amount of paid vacation days, healthcare) are not common at all, except perhaps for company health care.
Ty, fixed it!
It depends honestly on what you want. If you want to work on a small team alongside management every day on a cool tech stack, where you can literally stear the ship then Coder, or any startup is the place to be. If you like the big office, with slides and nap pods, then a place like google. At the stage we're at right now any extra money goes to our team, I know I'd much prefer that and a nice desk setup than a ball pit any day. * note I think google is a great company * Excuse any bias haha. Thanks, John
&gt; The important ones In your opinion... &gt; protections against unjust termination Employers get sued for unjust termination continuously &gt; unlimited sick days True, on that one I cannot argue. Doesn't seem sustainable, but hey, if you can get it, good for you. I have personally seen a company keep a severely injured (not on the job) employee on the payroll for more than a year. &gt; an acceptable amount of paid vacation days In your opinion. &gt; healthcare) are not common at all, except perhaps for company health care. It's extremely common here for full time employees.
&gt; True, on that one I cannot argue. Doesn't seem sustainable, but hey, if you can get it, good for you. So, in the US, if you get sick, you don't get paid. That's fundamentally wrong. In countries with sane labour laws, you get paid sick leave and that leave is unlimited. It isn't taken out of your vacation days either. The only thing is that you have to prove to your employers that you are indeed sick by bringing a doctors's note, so the employer doesn't get fucked over. If you are permanently sick, you can get fired with appropriate notice though. &gt; In your opinion. A minimum of four weeks per year is acceptable. Though, I would really like to have six weeks.
Yeah. I tried multiple times to grok asyncio on Py3 and just gave up. Either the documentation is that terrible or the library is that poorly engineered. 
Not saying some documentation wouldn't be nice, but the whole thing is like ~~40~~ 80 lines of pretty readable code.
Hey! Thanks for the feedback. We setup the space how we would want to work, so we would be excited to come in everyday and code. We spent money on getting great chairs, razer keyboards and mice. I included those benefits because those were the things our team love. I totally understand what you're saying, I just wanted to give an idea of the type of place and company it was. The restriction on location is purely because of legal issues. Contracts are very difficult and is very expensive to enforce in other countries. However I did call our council and was informed we can hire remote in Canada. I really appreciate the feedback, listening to what you guys want is the only way to build something great. Best, John 
&gt; So, in the US, if you get sick, you don't get paid No, that's not true and not what I said. You said "unlimited sick days" &gt; A minimum of four weeks per year is acceptable Says you. What else has the universe deemed you to be the prime determinant of? Should we remove the letter "K" from the english language because you deem it unacceptable? If you don't want to work here, that's fine, but you don't need to lie to make your point that workers have more protections in Europe.
You really have no idea about how the world works. Learn more.
Being able to stay at home when you are sick without fearing pay cuts is a protection of the worker. Having enough vacation days and the ability to take them without having to fear retalation or hindered prospects of career advance is protection of the worker too. Just because you think it's okay to only have one or two weeks paid vacation time doesn't make this acceptable to be.
&gt; Just because you DON'T think it's okay to only have one or two weeks paid vacation time doesn't make this acceptable to be FTFY
Hey would you please clarify a bit on a junior and someone who's proficient? Do we speak here about go language skills (only)? I am just wondering what is needed for a go job and I think people reading this post would be interested in that answer too :-) For example, a straight forward CRUD application is simpler to do than implementing several backends &amp; microservices and so forth. The follow up question is "**Bachelor's degree or equivalent experience in Computer Science or related.**", I am always wondering what's exactly meant by "equivalent experience in Computer Science or related". Someone who has done algorithm &amp; data structure courses on coursera and coded the algorithms etc., has software design &amp; a few years (let's say 2 - 5) programming experience in general, is a girl/guy like this considered as "equivalent experience in Computer Science" or not? If not what would it take? **(Other gopher's can also answer this question)** Thank you very much, nohoudini PS: I obviously don't have a bachelor's degree
They mean someone who got into google without a degree not someone who completed a coursera course and works in pottery
Meh. I think `case x &gt;= 0 &amp;&amp; x &lt;= 9:` is enough.
Absolutely, So let's start with how you're evaluated in the initial interview, which hopefully gives you a sense of how we evaluate the team. The first thing is experience, do you have experience in production level code. From there we look through your GitHub, this is really what matters. Is it clean, would it actually work, are there simple mistakes or inefficiencies. We treat it like it's going through code review before production, junior would need a lot of changes, Engineer would need minor, and senior would need none. In the interview we do a short code test (trust me no whiteboards). This is just to gauge your problem solving ability, there's 100 different ways to solve it, and we evaluate the way you did. A lot of us already know where we stand on the scale, or have a pretty good idea, odds are if you think you're senior, you're probably senior, etc. Finally, education. At the end of the day, it's not about the degree it's about what you know. A lot of us started out young, self taught, and know more about computer science than the professors. That would be example of "equivalent". A degree isn't necessary at all. Hope I explained and answered your questions, if I missed something or you want to know more shoot me an email jae@coder.com Best, John
Why would you hate hiring outside of the US for open source projects? I mean what's the difference between something open and readily available for the general public in a permissive open source license and at the same time having a company/startup built around it? It's a valid business model for many companies that contribute to open source (sentry comes to mind, ghost would be another,... not to mention that Uber contributes very much specifically to Go open source (go-torch, timer, etc)).
Thank you very much for your answer.
Right. Perhaps just some better wording would convey the atmosphere better. The difference between "not a basement, we promise" and "omg, this is amazing" can be a few adjectives. Sunny, airy, high ceilings, that kind of thing. If the offices look good, get some nice pictures online :) &gt;Contracts are very difficult and is very expensive to enforce in other countries. Not sure what you're saying, are you worried about people stealing your stuff? I'd expect the band between "not worth stealing" and "worth stealing and leaving the US" to be pretty small. Are you convinced this is your scenario? From what I understand, the usual approach is to have the people abroad handle their own taxes (i.e. they are self-employed on paper). Gitlab has people everywhere and are quite open about their internal processes, might want to look at their blog. (I assume you don't want to deal with visa sponsorship? If you can provide visa, you should mention that too. Folks from AU/Canada probably have it easier, but most of the EU still needs an H1B. My understanding is that you will need to deal with that even for people already working in the US, since it's tied to the company.)
Okay, cool, I can *kind of* see, why people would see a benefit [edit: But to be clear: That's not *really* what OP asked for]. Though it probably wouldn't be worth an external dependency for the same value as func Chain(end http.Handler, middle ...func(http.Handler) http.Handler) http.Handler { for _, m := range middle{ end = m(end) } return end } &gt; low-cost (sub-microsecond) Routing performance does not matter. Estimation time: From the benchmarks [here](https://github.com/julienschmidt/go-http-routing-benchmark) it seems a pretty safe bet, that tens of μs is a reasonable baseline for somewhat naive routing - even on relatively sizable APIs. [Google handles on the order of trillions of searches](http://searchengineland.com/google-now-handles-2-999-trillion-searches-per-year-250247) each year. If we assume something like each search actually making 10 HTTP-queries or something, we are talking 30 trillion queries a year, that's, conveniently, roughly a million QPS. Each query spends 10μs in routing, so that's 10 CPU seconds per second on routing. so Google search dedicates roughly 10 cores total to routing HTTP queries, if they use something relatively naive. 10 cores on [GCP](https://cloud.google.com/compute/pricing) cost roughly $250 a month (the actual cost will be *much lower*, because CPUs become much cheaper at that scale), which at an average salary of $80K/y for a SWE in the US (and given that the *cost* of a SWE is probably at least twice or three times their base salary) comes down to something like three engineering hours or so. So yes. If you are running at the scale of Google, it might be worth optimizing your HTTP-router. For one engineer, spending *maybe* one or two days a year doing it. So stop worrying about a microsecond. (that being said: I don't think there is an actual performance penalty of the naive, obvious approach over that "chain" package… But *who cares, because routing performance does not matter*)
You have no idea what you are talking about.
Haha you're totally right, looking at it now I definitely did a poor job explaining it. I'll add some photos of the office aswell! So we do have a lot of tech that we are very protective of. Our council is very adamant about not hiring outside of the U.S for anything that isn't open source. However I was just notified they had registered in Canada aswell, so we can hire Canadians. We do hire and do have team members outside of the U.S who work on open source projects. It's not that we don't want to deal with visa's, it's that it's been made so ridiculously difficult we just don't have the resources. Companies like google and Microsoft take over 90% of all h1 visas. That with the recent administrations limit, makes it very very difficult. I'm definitely going to check out their blog. Thanks, John 
I think I did a poor job explaining, we DO hire people outside the U.S for open source, we actually already have people doing so. We're also going to be doing more open source work to give the deserved opportunity to developers irrelevant to where they were born. Thanks! John
t. codelet
My post clarified the benefits of using a slice for managing nested http handlers and also noted that the penalty of doing so was low. No particular state of concern compelled which details were shared. Further, while tools like chain are often used with routers, I'm unsure about what it has to do with multiplexing. The external dependency is certainly worth avoiding; As mentioned in the chain project's readme: &gt; Nesting functions is a simple concept. If your nested handler order does not need to be composable, please do not use this or any similar package and avoid adding a dependency to your project.
JS promises are quite interesting and make a lot of sense for front-end code where you are waiting for some data to come in from the back-end.
That's pretty weak, son. Got anything better?
&gt; Further, while tools like chain are often used with routers, I'm unsure about what it has to do with multiplexing. You just mentioned the cost of "nested handler composition" (really, I subsumed that into "routing"), and you specifically mentioned it being sub μs. Like it mattered. The go community needs to realize that it doesn't (whether it's about "multiplexing" or "handler composition"), so that the proliferation of "high performance whatever frameworks" in the http-space stops. Getting your HTTP-request from `net/http` to your actual handler is going to be negligible. Stop talking about the cost of it like it is a thing. It's just not.
I thought there were no job posts/ commercial ads allowed on this sub.
This looks great for catching input that causes a panic. But is there anything for automating testing of Type II errors where the input is invalid but the program accepts the input? For example, testing that your validations accurately accept/reject, or do you just manually test as many edge cases you can think of?
Nice. As someone who's not actively working on NLP tasks, two notes: - `summarize` sounds like a thing that returns the gist of a longer text, like https://www.reddit.com/user/autotldr/comments/ - it would be nice to see outputs of the examples for all of the code samples in the readme; reusing `go test` `Example`s would be worthwhile
If you're looking for inputs that cause behavior X, just make behavior X trigger a panic. func Fuzz(data []byte) int { if myFunction(data) == 42 { panic("found a bug") } return 0 } &gt; To communicate application-level bugs Fuzz function should panic (os.Exit(1) will work too, but panic message contains more info). https://github.com/dvyukov/go-fuzz
We'll let's say I want to test an Email regex. Can I use go-fuzz to find invalid Emails that are accepted as valid by my regex?
Sort of similar to the `wrap(error)` solution would be to use (hypothetical) generics: type withStack&lt;err error&gt; struct { err *stack } This ("mixins") is a use case for generics which Ian Lance Taylor contemplated in his [draft proposal](https://github.com/golang/proposal/blob/master/design/15292-generics.md). Essentially, because you're embedding a concrete type constrained to the interface rather than the interface itself, methods other than those defined by the interface can be promoted.
If you have an independent automatable criteria for "valid email", then yes.
How can i build a Map or contains without a equality operator? Not all go types have equality defined (for example there is not equality between 2 slices).
I didn't see anything on the rules/code of conduct but if there is we'll remove it asap. Thanks, John
Agreed
I thought everyone here might enjoy this, as well as possibly give more specific feedback about Go-related things. Hope this is helpful!
X-Post referenced from [/r/programming](http://np.reddit.com/r/programming) by /u/adrake [Processing 22 Million lines per second with Go and a laptop](http://np.reddit.com/r/programming/comments/6qeo18/processing_22_million_lines_per_second_with_go/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
I thought it was great with C# but then I stumbled across cases where it would deadlock because of the *context* of where you used it. So basically it's doing a lot of magic behind the scene and you actually need to be aware of what's going on and where to use the async syntax. You can't just read the code and understand it anymore.
This is cool, I posted a gist not that long ago from a fastest possible atoi method I made. It uses a giant switch (it's a little faster than the lookup table) to delegate to a manually unrolled loop for that length, it's all crammed on one line because at the time I wrote it bounds checks were not as good so in a multi line expression it would generate bounds checks for each new line, this gets me by with one. I'm not sure if Go 1.8+ would compile the same code. Assumes well formed input. Might squeeze a little time out of your benchmark, might not. :-) [fast atoi](https://gist.github.com/cstockton/186a2e83d68cba221d3ced2eace6eef0)
I would update README recently, and show you how this thing works :)
That's some serious dedication! If I give it a shot, I'll let you know how if there were any improvements.
I work in the US and have unlimited sick days and 6 weeks of vacation. All of the things you're complaining about are fairly common for tech companies to offer.
Simplest thing is to just require that the first message on the socket is the JWT. Once we validate it, we enter the message loop like normal. If that first message isn't a valid JWT, close the websocket. 
Is it because of the get-off-my-lawn people who don't want generics?
yeah, but one thing about that is that you can't do it when the switch has an expression. i.e: this code is illegal: switch r { case 'a': case 'b': case 'c', 'd': case '0' &lt;= r &amp;&amp; r &lt;= '9': } and you need to change it to this: switch { case r == 'a': case r == 'b': case r == 'c' || r == 'd': case '0' &lt;= r &amp;&amp; r &lt;= '9': } and this one is more messy when you have many case clauses 
I have very never seen a reason why it can't be related as 0 &lt;= x &lt;= 9, but I also don't understand why compliers even allow assignment in an if check, it would make reading them much nicer.
Once I saw what the data you were parsing looked like I realized you could get by with visiting each index once and avoid allocs. So I took a stab at it for fun [gist](https://gist.github.com/cstockton/2fbfcaedd49b54f579d09db77da5e7b3). // Benchmark_processFile-8 2 564108121 ns/op 4144 B/op 2 allocs/op // Benchmark_processFileFast-8 5 204404921 ns/op 0 B/op 0 allocs/op 
Please use Pastebin, GitHub Gist, or at least proper Reddit formatting, so we can actually read your code.
I applied. I'd be a "junior" in Go as I am new to the language, and I've always wanted the opportunity to move to Austin, so I figured why not. You miss 100% of the shots you don't take. :)
Intro: https://github.com/nadoo/glider Download: https://github.com/nadoo/glider/releases Config Examples: https://github.com/nadoo/glider/tree/master/examples
I did a double take checking that this wasn't /r/zootopia at first.
Thanks for the feedback! - This is actually something I'm planning on adding to the package (my ultimate goal is readability + usage statistics, sentiment analysis, and some form of a TL;DR generator). - Good idea.
I applied as well. If you haven't, look at courses and video from Todd McLeod. I think most of his Udemy courses were fairly cheap, and he offers a lot of valuable information on his YouTube channel. "The Go Programming Language" is a great book too. https://www.amazon.com/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440 Worth it.
[removed]
https://www.quora.com/How-are-Akka-actors-different-from-Go-channels
Hey, thanks! I'll grab That book. I've been going through Go in Practice and it's been great so far. Udemy has a sale on Go courses, so I just picked up his Web Development with Go course. :)
Other models of concurrency: https://youtu.be/7AByMX76c_4?t=7m11s
&gt;[**Groovy and Concurrency with GPars [60:50]**](http://youtu.be/7AByMX76c_4) &gt;&gt;This session looks at using Groovy for writing multithreaded, concurrent, and parallel programs. It briefly discusses leveraging legacy Java techniques such as multiple processes, multiple threads, the java.util.concurrent APIs, and shared-state atomicity. Then it considers some useful AST transforms in core Groovy (Lazy, Synchronized, Immutable, WithReadLock, and WithWriteLock) before diving headlong into GPars, a comprehensive library for parallel execution that provides a menu of options to the developer. &gt; [*^JavaOne*](https://www.youtube.com/channel/UCdDhYMT2USoLdh4SZIsu_1g) ^in ^People ^&amp; ^Blogs &gt;*^539 ^views ^since ^Jun ^2015* [^bot ^info](/r/youtubefactsbot/wiki/index)
You mean the famous iris-go framework? Is this a joke? [edit] Ok, now [I see it](https://github.com/kataras/iris#-get-hired-with-iris).
Video linked by /u/srbufi: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Groovy and Concurrency with GPars](https://youtu.be/7AByMX76c_4?t=7m11s)|JavaOne|2015-06-08|1:00:50|4+ (100%)|539 &gt; This session looks at using Groovy for writing... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/srbufi ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dkx0rak\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.3b
Indeed, 3d isn't doable with gonum/plot.
Any plans to include it?
Check out my blog post about oauth and oauth in go: https://jacobmartins.com/2016/02/29/getting-started-with-oauth2-in-go/
&gt; You really have no idea about how the world works. Learn more. * I am asking questions am I not? * the world != USA * the world == ZA WARUDO
Are you getting paid while being sick?
It seems you have copy pasted the code (and the text) from [this page](https://gobyexample.com/errors). The page text (on the left) explains very well what each part of the code (on the right) does. What exactly is it that you do not understand? 
I don't think so. 3D is pretty, but unless you have interactive plots, 3D is pretty useless too :) (ie: it's hard to correctly convey an information with 3D plots, like it is with pie charts.)
&gt; Note that the oauthStateString should be randomly generated on a per user basis. What is a good way to generate the state token on a per user basis?
here is an old gallery: https://github.com/gonum/plot/wiki/Example-plots we are working on an automated way to extract all of our examples and reference plots into a nice "always up-to-date" gallery...
When you originally posted this question, it had zero explanation. Anyways, the language is done. They wouldn't add other models of concurrency at this point. BUT they are discussing Go 2 at the moment. If you are really serious about this then you should create a concrete proposal and describe if you want a language change or if it could be added as a library, what problems it solves etc.
The only joke here is your behavior. A jealous person could never respect the people who succeed, I get it.
I love you. You're my favorite troll on this subreddit.
good bot
The word you were looking for was "sociopath". :P
generate a session for the user, stored in a cookie and in a database (or a map) (just a key being the cookie and the value being arbitrary data you can put there) -&gt; crypto.Read into a byte slice -&gt; urlencode/base32encode/base64encode -&gt; put into a map / database / redis into the session data for the current session -&gt; when the user comes back, get his session and check if the state string matches the one in your database/map/redis
Not sure what you mean here around looking at GitHub. Do you mean all of the persons repos? I throw a lot of personal hacking sessions into GitHub, but I also contribute to some large open source projects. Your criteria would seem to suggest I would be Junior. Wondering on the thought process around the GitHub analysis? Thanks
i do exactly that with this test project. https://github.com/lacion/iothub/blob/master/main.go
Thanks for your reply &gt; when the user comes back, get his session and check if the state string matches the one in your database/map/redis I thought the state token was only useful to do the oauth login and so after the login is successful, it can be safely discarded. Why do I need to keep it in the database along with the session?
As someone who actually wrote parsers back in the days, it's because `0 &lt;= x &lt;= 9` is interpreted as `(0 &lt;= x) &lt;= 9` which means `bool &lt;= int`, which is silly. In order to actually get this to compile to `0 &lt;= x &amp;&amp; x &lt;= 9` you need to make the parser more complex.
Of course. I've never even heard of unpaid sick leave.
Very well then.
Honestly? I 100% prefer go's "write synchronous code and let the runtime handle asynchronicity for you" philosophy. I'd much rather write (fake javascript using go's concurrency model): function getData() { showSpinner(); try { data = get("/data"); otherData = doSomethingElsePossiblyInvolvingTheNetwork(data); return doMoreStuff(data, otherData); } catch (e) { showErrorMessage(e); } finally { hideSpinner(); } } than write (with promises): function getData() { var data; showSpinner() return get("/data").then(function(d) { // Wait, how are you supposed to even do this idiomatically? This can't be it… data = d; return doSomethingElsePossiblyInvolvingTheNetwork(data); }).then(function(otherData) { doMoreStuff(data, otherData); hideSpinner(); }).catch(e) { showErrorMessage(e); hideSpinner(); // Am I understanding correctly, that promises have no finally? } } (as you can tell, not great with javascript…). Go's concurrency model allows you, to write sequential code, without needing to *care* whether something you write will block or not. To make that work with javascript, it would need to a) spawn callbacks in a new user-land thread, b) would need to yield when doing (asynchronous) IO and schedule threads and… that's it, pretty much. You could also add some locking to browser-APIs that mutate state (like DOM-manipulations), but you could also just continue to let js run single-threaded. With that kind of concurrency support in the runtime, probably upwards of 90% of user-code could just be synchronous. The power of go's concurrenly model isn't so much channels and goroutines, it's the fact that all go code and all IO integrates nicely with it. I rarely actually use channels or goroutines and instead rely on things like `errgroup`. I still profit immensely from the go concurrency model, because the runtime will make sure that long-running IO will be interleaved efficiently - and in the end, that's the real goal. PS: Serious question though, how *are* you supposed to pass on some data in the continuation-style? I mean, I have `data` and a promise, returned by `doSomethingElsePossibly…` -- how do I pass both on?
Hm, but you can already have unbounded, asynchronous queues in go: func asyncQ(ch &lt;-chan int) &lt;-chan int { out := make(chan int) go func() { var ( q []int send chan int next int } for send != nil &amp;&amp; ch != nil { select { case v, ok := &lt;-ch if !ok { ch = nil continue } q = append(q, v) next, send = q[0], out case send &lt;- next: q = q[1:] if len(q) == 0 { send = nil } else { next = q[0] } } } close(out) }() return out } So, this seems to be perfectly expressible with the current concurrency primitives (though I'd consider it a bad idea). It might be a bit unwieldy, but can be abstracted once in a library. There doesn't seem to be a particular need for adding this as a language feature.
&gt; However, I do believe that the community currently lacks good guidance on how to properly route requests using net/http.
Thanks for sending this. I took a look at the code, and also updated my approach on the article. I kept the scanning on a file since I want to make sure the code is able to deal with input of arbitrary size, instead of a byte slice which is already in RAM. Current version took the run time from ~482ms to ~308ms on my machine, a great improvement. If you have other suggestions for speed, I'm happy to hear them.
&gt; math/rand To make the supposed API work, one of two things would need to happen: * Either go grows a generic, recursive type-inference algorithms. Which would then need to be described in the spec, unless you want to have the compiler authors define what a correct go program is. AFAIK no other programming language does this ATM, for good reason. Note also, that even the [most likely candidate](https://github.com/golang/proposal/blob/master/design/15292/2013-12-type-params.md) for a generics-proposal intentionally leaves this out * more likely, you would need to specify the type explicitly. So you'd need to use `rand.Number&lt;uint64&gt;()` instead of `rand.Uint64()`. Seems like a clear loss in usability to me. Add to that what /u/0xjnml said. Look at the implementations of [Int63](https://golang.org/src/math/rand/rand.go#L81), [Uint64](https://golang.org/src/math/rand/rand.go#L87) and [Uint32]( https://golang.org/src/math/rand/rand.go#L84) -- there is no way to unify those generically. So, this would neither be a win on the user- nor on the implementer side. It may *seem* like an obvious win, but it is a net-loss (as, IMHO, most use cases for generics…). &gt; And some others applicable cases are AFAIK, all three of those packages would likely go away in go2 either way. `heap` might survive, but would probably get a radically different API. Linked lists and ring buffers are just too trivial to implement yourself, to deserve a package. And are then type-safe. &gt; I believe if there were generics this kind of operations could be improved /optimized at compile time since the compiler knows what the format of the data looks like. This isn't about generics. For this to work, you need meta programming, code that writes code, not generics - the two are sometimes related, but don't have to be. `encoding/json` would need to write code that loops over fields at compile time and outputs the appropriate encoding code. Alternatively, you are trying to argue that the compiler can just automatically optimize existing code, but this kind of global interface-optimization is already possible, in theory. &gt; What I’m trying to say is that the stdlib CAN be reduced and simplified in numerous places with the help of generics Sure, but most, if not all of the places you mention are not that (others have gone through the rest of the list). That would've been obvious, if you've also actually described the semantics of generics. Instead, you asserted pretty broad magic over them. Generics will probably come, but they definitely won't have this amount of magic in them. They are possible in a language like Haskell, where most of the code can just be evaluated at compile-time without any issues anyway. But not in go.
Really good read! Taught me quite a few little things about Go I didn't know like the profiling tool - had no idea you could get a detailed line-by-line report of execution speed. Thanks!
&gt; maxFieldIndex := int(math.Max(float64(keyIndex), float64(valueIndex))) Don't abuse casting like this! `math.Max` only exists because floats have special cases where a simple `max := a; if b &gt; max { max = b }` doesn't work as expected (e.g. `NaN`, but possibly also `-0.0` and `±∞`). 
Discussion is great. But good inputs to the debate look like [this](https://github.com/golang/proposal/blob/master/design/15292-generics.md) -- describing concrete, implementable semantics and how you can usefully trade off simplicity to still achieve powerful results. Seriously, in particular the [Type parameters](https://github.com/golang/proposal/blob/master/design/15292/2013-12-type-params.md) proposal is frickin amazing and did a good deal to convince me that it'd be possible to have understandable, but still powerful generics in the language. There is a lot to be learned from those proposals. Among other things, after reading them, it should be obvious that the mentioned examples either won't be implementable with any realistic implementation of generics for go, or won't benefit from generics at all. It is a bit tiring to repeatedly get inputs that seem to have little conception of the complexity of the topic (not that I claim I have that, FTR) and reduce it to "look, this piece of code is much simpler than what we had before, if we add some \&lt;T\&gt;'s to it".
You can do `finally` by slapping a `.then` at the end (after `.catch`). It seems many share your sentiment though, as the new async/await looks very much like your first example.
&gt; func processFile(filePath string &gt; func processFile(file *os.File) In both cases the argument almost certainly should be an `io.Reader`. In the first case, if you were to export this, you should leave opening the file to the caller. There are many cases where the caller has an `io.Reader` but not a file and if they have a file it's trivial to get an `io.Reader` but very inefficient and annoying to do the opposite. In the later case it is pointless over-specification, the `file` argument is only used with `bufio.NewScanner` which takes an `io.Reader` so requiring an `*os.File` adds nothing.
async/await, AFAIK, still requires you to actually know about concurrency and whether a function blocks or not (and make that part of the API). I don't want to care.
Sorry, can't take a company that supports fraud seriously. Using iris that is. 
You seem to understand that word stronger, than I intended. In particular, I did not intend it to mean "clearly you are uneducated and need to be explained how the world works", but to make the observation "as one of the people who is expressing the sentiment to just use the stdlib, it seems we have failed to properly explain how we meant that". And I'm basing that observation on the links I provided; the tweet in which someone says "people say use the stdlib, but there is no good router in the stdlib" (but that's the point. You don't need a good router) and the article which says "the stdlib makes it so hard to express these routes" (that's because you are still thinking in the same pattern, using the same solution as before). I also talked about these ideas for a while in this subreddit and someone (though I can't find the comment right now) literally asked me to put them in a post, because that'd be helpful. So I did. And I am at least not aware of anyone expressing the same (or similar) ideas previously. So, given all of that; what would be a less arrogant way to express this observation, in your view?
Just to clarify - the other versions (in other languages) have the same optimizations (eg operating on bytes)?
Meanwhile, the Java people in the /r/programming [thread](https://www.reddit.com/r/programming/comments/6qeo18/processing_22_million_lines_per_second_with_go/dkwv440/) are still trying to optimize their version.
My issue with your statement is that you pretend to be an authority providing guidance to a community you think doesn't understand how to "properly" route requests net/http. Here would be a much less arrogant way to express your observation: &gt; Many people believe that the stdlib provides inadequate routing but I strongly disagree. I think they should look at it differently.
Okay, thanks for the pointers. I will consider that in the future.
Thank you for being very civil and understanding.
This is the right answer!
The joke is that you are creating one account per post on Reddit. - iris-go - gmgolang (gm for Gerasimos Maropoulos, right?) - rdmin -&gt; redditor for 13 hours
Thank you. I definitely understand the responses to op better. I guess the recent mentions of adding generics to go by leadership has made people who miss them hopeful again. It sounds like generics don't really fit in with go and that we should stop trying to make go something it isn't.
You should create the session even before the user authenticates. You create the session for the current visitor -&gt; add the state to the session -&gt; redirect him to login -&gt; when he comes back check if the session matches -&gt; you can delete the state from the session now.
&gt; You create the session for the current visitor -&gt; add the state to the session Why add the state to the session? What problem does it solve?
What you want to do is check the HTTP request status code. If it is not in between the limits of 200 and 299 then you have an error so you Decode to the error struct.
Thank you!
How would you otherwise check if the state you received back from the user when he came back after logging in is the same that you gave to him?
I am currently storing the state I generate on the login handler in a cookie and check that cookie again on the callback handler.
But how do you know if the state in the cookie is actually given by you. The user could fake it and set the cookie himself.
I would like to know how to accomplish this when you can't know what the JSON schema is prior to reading the JSON.
http://eagain.net/articles/go-dynamic-json/ might help.
I am currently using Secure and HttpOnly cookie so I think it's not possible but... if it is... good question! I hadn't thought of that. In this case I need to sign the cookie value with HMAC.
Oh by the way, I forgot to mention, I am currently storing the state tokens I am creating on the login handler on an in memory map to prevent replay attacks. So if the user tried to supply a token themselves then it would fail. Still your idea is very good, I think I should still sign the cookie value for additional protection. Using this method, there's no need to store the state token in the session right?
If you put the state in a signed secure cookie, and later check if it's correct then it should be secure.
There's so much wrong in this blog post, I don't even know where to start. The text is littered with misspellings, copy-paste errors, bad grammar, and the font nerd in me had a stroke. The code examples are terrible: the code isn't even formatted well, let alone organized or even following any principle of design. Nearly all of OP's sumbissions to this sub have zero points. And there's quite a few. How about taking a break from posting, and spend some time reading and learning why we all think your submissions are crap?
Step 0: don't. There is no next step. Just write go like you're writing go and you won't have all the headaches people have when they treat it like other languages.
&gt; It's advocating against generics in one example, and then immediately jumps on advocating typescript generics in the very next sentence. Which sentences are you talking about?
 It's not always practical to hand write a parser like this. For more complex situations, I would recommend Ragel.
I totally understand evaluation of GitHub profiles in some context, but it being a make or break seems wrong, sure I have a few things on GitHub to support community discussion but most of the code I've written has been as a professional in closed projects. 
Sounds interesting - in what languages? Meaning is it english only?
In the time you spent registering a domain, you could have taken five seconds to discover the behavior you saw. Anyone familiar with the language, which clearly excludes you.. would immediately notice it is something to do with the way Split is implemented. The behavior is a little surprising but saves allocations for a majority of use cases, which is reading. It's never a good idea in Go to just take ownership of a slice you didn't create and begin appending to it without understanding the state of the slice backing. Here is how you could have seen this for yourself to prevent looking like a fool. https://play.golang.org/p/eb6_4BB_jB I mean- you didn't stop to think, oh hey this is surprising, I wonder if it's just this function? Lol. Face palm.
This isn't a useful comment. Things like this are why this subreddit has such a bad reputation among people who aren't jerks. Please stop being a jerk.
Yes, essentially. The `PragmaticSegmenter` (a sentence splitter) currently supports English, Spanish, and French -- but everything else is English-only for now.
&gt; I kept the scanning on a file since I want to make sure the code is able to deal with input of arbitrary size, instead of a byte slice which is already in RAM. mmap would give you the best of both worlds.
I've written parsers that can do it, but they are too small of changes to the overall language to make me care to follow through with it.
To be fair, he's replying to someone who bought a domain called fucking-go-slices.com so there might be some implicit permission to reply to this however you want.
It doesn't matter what the linked site is called, or where it's hosted, or really anything about it. Homeboy made a jerk post right here in our subreddit. Thumbs down.
Just spitballing: what if there were something like `type Reader interface { Read([]byte)(int, error); optional WriteTo(w Writer) error`. Then maybe the optional interfaces would be documented and embedded interfaces would know to pass them along when applicable. 
I explained the issue, gave an example how he could have made the discovery on his own. In response to a ignorant post meant only to troll the worst thing I said was they looked like a fool. Of all the conversations here filled with trolling and insults I find it amusing you chose one under this context. I would further argue that my post added more value than yours because it was relevant to the discussion. Your social justice post arguably was written in a harsher tone while having zero relevancy to the topic. You called out someone who regularly contributes meaningful discussion as a "jerk" because they called someone who posted a troll domain containing explicitives a fool. But you're entitled to your opinion.
&gt; you can't know what the JSON schema is prior to reading the JSON. Do you know the JSON will be one of several formats and you just need to read a field to find out which format, or what? If the former, check out this article: https://blog.gopheracademy.com/advent-2016/advanced-encoding-decoding/#encoding-and-decoding-generics:ed675bd476e2bd7c07a2d82583157710 It isn't generics in the sense that has been debated a lot in Go lately, but refers to generics as in multiple different JSON formats that vary based on the object's type. Something like this could possibly be adapted for your needs.
https://github.com/golang/go/issues/21149
Yes the behaviour is logical based on how Go works. The criticism is instead that it works this way in the first place. The reason it's like this is that slices were attempting to address two separate use cases—growable arrays and subarrays—and the original design didn't fully reconcile them. Slices don't retain leading capacity since neither use case needs it. They do retain trailing capacity because that's needed for growable arrays. But for subarrays, it doesn't make any sense to lose leading capacity but retain trailing capacity, and the latter can be detrimental, as seen here. This mismatch between the two use cases of slices was partially addressed by the addition of capacity slicing. However, existing APIs, like bytes.Split, haven't/can't change to take advantage of this, and a lot of code has and is still being written which unnecessarily uses subarrays with overlapping capacities. Certainly, understanding ownership is important when working with slices—in part because they have implicit capacity sharing, but also because they can overlap arbitrarily by design. Unfortunately, Go has zero tools for evaluating ownership and sharing, and it's commonly up to the user of a library to reason about when and how it might be appropriate to modify/append to a subarray slice returned by a library, often without any help from documentation. Swift uses pervasive reference counting and copy-on-write to address this. Functional languages use immutability. Rust uses statically checked ownership and sharing semantics. Each of these have problems as far as being suitable for Go, but the point is that there are techniques that exist to partially or fully address this. Even just using capacity slicing more widely would go a long way to mitigating these kinds of problems. Dismissing rather clearcut usability challenges as "working as intended" doesn't help anything, though.
Homeboy made a jerk post- and.. what was yours? It's extremely hypocritical to criticize me for how I speak to another person on the subreddit while being guilty of the same thing. The only difference is you felt righteous and just in your cause- improving the sub Reddit at face value. But if that was your intent you would have worded it in a way that didn't specifically call me a jerk, you would have demonstrated by example the type of community you were striving for. You could have stated you believed it didn't help build the reputation you would like the community to strive for and pointed out the sentences I could have phrased differently to better align with this goal. Furthermore if you wanted to only improve my behavior you would have given me this feedback in private and wrote your own reply worded in the way you felt was most just to the communities image. But you didn't, you took a social justice warrior approach whom aren't fighting for change. They don't want to make a difference as effectively as possible. They feed off the euphoria of having an audience of similar minded individuals reinforce the superiority of their views. Leading to escalating and more militant methods that ultimately build resentment towards ideologies that their (forced into a position of) opposition already supported. I'm not stating you are a sjw, I'm saying your methods are ineffective and hypocritical. I won't comment further. 
&gt; Please stop being a jerk. You can make the same point without the tone, both of you, /u/epiris and /u/peterbourgon 
Dunno if OP owns the domain, but the "link to GitHub" takes me to a 404 page. Maybe it isn't open to the public?
Wat. I didn't know that's how defer worked.
?? That's like the only way to use them, what do you mean ?
Okay, I just wasn't sure what I had to do myself and what the package handles for me. So the data I get in the callback function is all goth does for me and I use that however I want. Thanks!
I updated the post with a clarification.
I don't disagree it's surprising the first time you come across it as mentioned in my post, but am firm on my stance of slice ownership. I think patches to all std library functions that set capacities would make Go easier to pick up, but ultimately just defers the lesson that slices you didn't create need to be well understood before you assume ownership of them. It's a tough lesson but you learn it once, with only occasional gentle reminders.. which I'm sure I'll be granted sometime soon myself :-)
Yes. The comment just describes the difference between the semantics of defer.
We evaluate all aspects, but at the end of the day the code is what matters. It also saves time for the applicants, the last thing we want is for someone to go through an interview and have it be a waste of their time. I understand what you're saying tho, and for those special circumstances the quick test we do in the interview establishes their level of knowledge, we just prefer to know before getting to that point. Thanks! John
No, why? It's just demonstrating how defer works.
So what would the method set of `struct{ Reader }` be, in that case? Does it include `WriteTo`? If yes, then a type-assertion on `WriterTo` would sometimes succeed, even though the wrapped Reader doesn't implement it. If no, I couldn't actually get at the Method. If "depending on what the value are", how does the compiler handle, e.g. passing that as a `Reader` (or a `WriterTo`), if it doesn't know the runtime method set? And what would that imply for a construct like `struct{ Reader ; WriterTo }`, when you call the `WriteTo` method on it? Depending on what you put in there at runtime, there would either be a conflict, or not. It also would bind the declaration of optional interfaces to the interface type, which seems unfortunate. It would preclude me from adding my own optional interfaces to `http.ResponseWriter`, for example. It seems that this goes against the design principles behind implicit interface satisfaction. Lastly, the issue goes beyond knowing what the optional interfaces are, towards it being impossible to wrap them efficiently. The number of possible combinations of interfaces grows literally exponentially and you need a separate type for each of them, the way go is currently implemented. I'm not trying to shut you down, just trying to show that the design space is pretty complicated. At least for now, I think the best way forward would be to fix those reflect feature requests; they would allow us to experiment with the implications of these kinds of extensions without a language change and hopefully help inform any language choices if they are deemed necessary.