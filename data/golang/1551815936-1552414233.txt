basically, every file in the same directory (excluding test files) belongs to the same package/command. a single package/command can only have at most one `main` function. when it doesn't have `main` function it's considered a "package", otherwise it's considered a "command". For commands we usually just say `package main` but it doesn't have to be "main".
So then is the standard just to use a POST request containing username/password to authenticate the users? That seems rather insecure. I get how oauth and openID help once someone is already logged in, but the actual login itself is the part I'm concerned with now.
If you don't care for animation, [fogleman/gg](http://github.com/fogleman/gg) is a great and simple drawing library. Furthermore, AFAIK, you can draw primitive graphics in Ebiten [with this method](https://godoc.org/github.com/hajimehoshi/ebiten#Image.DrawTriangles). Or, you can also use Pixel (which I'm the author of :P) that has [IMDraw](https://godoc.org/github.com/faiface/pixel/imdraw) for drawing shapes.
Use TLS? You have to get your credentials to the server side somehow.
If you just want to persist structs, you can use [bow](https://github.com/zippoxer/bow). The API is not too far from shelve's: `db.Bucket("pages").Put(page1)` Disclaimer: I wrote it.
I tried gg, trying to use hsb was wack and I never got it to fully work, and I never got pixel to display anything although Ill try it again sometime.
I think I may be duplicating the question asked here: [https://www.reddit.com/r/golang/comments/5yy903/user\_authentication\_in\_go/](https://www.reddit.com/r/golang/comments/5yy903/user_authentication_in_go/) 
Go has DumpRequest built in (not color coded, but it is complete - and part of the standard library): [https://golang.org/pkg/net/http/httputil/#DumpRequest](https://golang.org/pkg/net/http/httputil/#DumpRequest)
we have something similar though we mostly want a set at the end not something iterable you have to have an array or map to hold them all and then make each instance with a function which adds them to that so: type item struct {stuff} var allItems []item func newItem(stuff) item { a := item {stuff} ; allItems = append(allItems, a); return a} and then just make the ones you want so each one has its own identity and can be referred to if you need it or you can walk the set via a function that shares allItems or just expose it we tried the additionalInfo sort of route and it just separates the stuff from the enumerated type and is a huge pain
Interesting tool!!
Looks nice. Props. 
This üëç
This is commonly referred to as IdM or IAM (Identity (and Access) Management: [https://en.wikipedia.org/wiki/Identity\_management](https://en.wikipedia.org/wiki/Identity_management) There are a slew of open source (Anvil, Keycload), SaaS (okta, Auth0), closed source providers (AD, Ping, Siteminder) of various levels of each component. The topic is insanely deep and varied, but honestly if you just need a simple means for a user to login (Bearer Token) then you can use a simple login page that returns a JWT with [https://github.com/dgrijalva/jwt-go](https://github.com/dgrijalva/jwt-go) as /u/expatMT mentioned. Then use a middleware to check the token as valid (using the same jwt key). The jwt lib has an example implementation of all these steps here: [https://github.com/dgrijalva/jwt-go/blob/master/http\_example\_test.go#L164](https://github.com/dgrijalva/jwt-go/blob/master/http_example_test.go#L164) I have worked with plenty "modern" APIs that still use Basic Auth without issue as well. JWT is great when you have separate services for auth and the consumption of that trusted auth (your business services), or if you require stateless services for performance/scale. It is also common to use pre-shared keys (aka API Tokens, Bearer Tokens, or just Tokens) that have a long life. Those can be JWTs or just a unique value stored in a local DB. If the ability to revoke access is important make sure you maintain a list of invalid jti based on exp in the jwt. Without more understanding of your concerns/needs for the API it is hard to provide more guidance. If you do leverage JWT, there are some best practices around ensuring security that caught some early users off guard. The short list is at the end of this article: [https://stormpath.com/blog/jwt-the-right-way](https://stormpath.com/blog/jwt-the-right-way) &amp;#x200B;
Yes this is the standard. It's effectively no different from putting in your username/password on a website to log into any other website. Use TLS 1.2 to protect the site and the data is encrypted between client and server.
&gt;new fancy features, other than CSP &amp;#x200B; Not exactly new, but definitely fancy...
You have to do it in the shell: `$ PATH=\`cleanpath $PATH\``
&gt;the fact the language is simpler is a \_huge\_ advantage üíØ
\[There are only two hard things in computer science...\]([https://www.martinfowler.com/bliki/TwoHardThings.html](https://www.martinfowler.com/bliki/TwoHardThings.html))
Maybe something like this: https://play.golang.org/p/xJdjvhUurCz Not really pretty.
&gt;I've never heard of somebody using Redis to cache DB queries &amp;#x200B; You must not get out much! üòé
&gt;because that‚Äôs what redis is made for No, that's not what Redis was made for. Redis was made to be a super fast in-memory data structure server. Which is to say it was made generically to handle many data storage tasks.
One more reason to throw on a gigantic heap of reasons to use Postgres.
&gt;locked tables All modern DBs use row level locking such as MVCC. Honestly, I don't believe anything except MySQL MyISAM tables have had table locking for decades.
If I'm understanding it correctly, I don't think the notary would prevent a library from pushing evil code and then tagging it with a minor version bump (which you may update to). The dependencies wouldn't be able to be modified at an already released version, at least.
Why do we have so many KV database for Go?
I second this question!
Yes, I'm just saying that protection against auto-updates is already provided by `go mod`. So my only concern is looking at the lib changes before updating versions... and missing something. Especially since people could be screaming about the hack somewhere online and I miss it. At least github projects have issues, but [even those can be disabled](https://help.github.com/en/articles/disabling-issues) by a malicious entity. I guess reddit, IRC, gitter, hackernews, etc... are still our best bets against outbreaks from bad actors. 
In Go, you don't think too much in terms of files, but instead in terms of packages. Running `go build` will always treat all files in a directory as a part of the same package, same namespace. For example, if your directory has two files: `main.go` and `help.go`, and `help.go` defines a function called `help`, all code from `main.go` can call this function without any imports. In other words: all files in the same directory "see each other". All `.go` files in a directory together make a package. There are two kinds of packages. The first kind is libraries. These are meant to be imported by other packages. Their package name should, by convention, be the same as their directory name. Their package name is what the importer will use to access the package. For example, all files in the `"fmt"` package begin with `package fmt`. That's why when you do `import "fmt"`, you use `fmt.Println` to access the `Println` function. The second kind of packages is runnable programs. Their package name is always `main`, so all the files in this package start with `package main`. These packages cannot be imported and they must contain a `main` function. That means that exactly one file in the directory must contain it. Doesn't matter which one. Hope this clarifies it. If not, please ask more questions.
My bad. That was a typo. I meant go-pg https://github.com/go-pg/pg
You're right, if you don't do something yourself, then your build will never change. Good or bad, I habitually update my deps all the time, probably a bit more often than I check the news or read the changes myself...
*Hi human!* It's your **9th Cakeday** oldgreggsplace! ^(hug)
Ah didn't know that. Thank you for clarification!
Not too complex = no sessions? What about http basic?
Nope. You need to implement login and consent endpoints for oauth2 authentication flow. Take a look at tutorials on Hydra. You can surely find some oauth2+openID solution already bound to users, but usually they force you to adopt their use system, while we use Hydra because you can freely use your users system, just implementing login and consent flows. Note the user never calls those endpoints directly, but just redirected there by oauth2 flow.
You should definitely consider other options before JWT: http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/ http://cryto.net/%7Ejoepie91/blog/2016/06/19/stop-using-jwt-for-sessions-part-2-why-your-solution-doesnt-work/ https://kev.inburke.com/kevin/things-to-use-instead-of-jwt/
To be clear: you ask oauth2 server for a code with an already created oauth2 client. Then you are redirect to login endpoint (and there you can manage whatever you want the user auth). You accept the login to oauth2. The oauth2 server redirects you again to consent endpoint where you accept the requested scopes. From there the scopes are accepted to oauth2 which redirects you to original app providing a code, which can be used to retrieve access and refresh tokens. With those you can APIs.
You can go for oauth2 but with password credentials grant type, I was looking for the same thing as you do now and it was my way to go, there is oauth2 server implementation already, you just need to set it up and eventually implement your client side code
I currently use [https://github.com/golang-migrate/migrate](https://github.com/golang-migrate/migrate). I include the library into my binary and expose my own functions for migrating up and down by wrapping the core library functions. This library has go-bindata integration which allows me to compile the actual sql migration files into my final binary, then on app startup I automatically apply all pending up migrations provided I've been careful about how I write them. This has the nice property that there is no need to figure out any separate workflows for shipping migration files to production servers, or bundling them separately into a Docker image with your binary.
I have an endpoint that accepts a username and password, and returns a session uuid in a cookie. Requests to other endpoints must come with a valid session cookie or they get rejected. The session id is used to track user activity on the site and maintain an audit trail. There's an in-memory cache for current sessions. The session terminates when the user logs out or 15 minutes after the last activity on the site (I have a goroutine in the background checking once a minute for expired sessions and moving them to the database from the cache). It's pretty old-skool and vanilla, but it works. I don't use JWT not because I think it's bad or anything, I just don't need it - it doesn't do anything that the session ID doesn't do anyway. If I was using a proxy and could delegate the authentication to that then I'd consider JWT. It's vulnerable to session hijacking - if an attacker can get access to the cookie and copy the session ID then they can impersonate the user. But the cookie is http-only and marked secure, and I use https so to get to the cookie an attacker would need to break https encryption, or have physical access to the user's browser. If either of those things are true then the attacker can do anything they like to the user's data anyway. I would say it's pretty simple to set up, but this is the fifth time I've written a version of it, and it took me four days to get it working this time (using an event stream architecture made it more fun). I think it'd be about a couple of hours to set up if I wasn't learning new architecture choices as well ;)
The answer you are looking for is cookies
MySQL has a \`show open tables\` command that shows locked tables... oracle has \`V$Locked\_Object\`, mssql has \`sp\_lock\` and \`dm\_tran\_locks\`.... there are still tons of possibilities for locks. Mass updates can be locked for shared sessions, and reads requiring explicit resources being changed become locked. If the cache key hasn't been invalidated in redis, you completely bypass that.
What‚Äôs the different from this and badger from GraphD
Type alias an int. Declare your enum values, add additional info using a map of your type alias to a struct type.
I didn't suggest databases have no locks, I said most databases don't have table locks. As long as we're on the subject of locks, Redis has a single global lock last I looked which was, admittedly, a while ago. But it was one of the original tenets of Redis: be super fast by never managing locks by serializing execution.
You want something like this: https://www.sohamkamani.com/blog/2018/02/25/golang-password-authentication-and-storage/
Your approach is actually what [tptacek recommends](https://news.ycombinator.com/item?id=16157002#16159301), and he knows a thing or two about cryptography.
for passwords, use bcrypt. for session tokens, just keep in mind that cookies should have the secure flag and httponly flag, and your site should force https. another method popular among single-page sites that utilize things like Angular heavily is to store session data in localStorage. cookies are weaker to CSRF, and localStorage is weaker to XSS (ie. rogue browser extensions, the ultimate XSS)
\&gt; you could just have `apple_test.go` with package `lib_apple_test` Pretty sure Go only allows 2 packages for testing: `mypackage` and `mypackage_test`. The compiler won't allow you to have `mypackage_myfile_test` because it will treat at `mypackage_myfile` as its own package, which is a code violation. I just tried your example and it indeed did not work. Thanks for suggesting, though!
Oh good to know :) Thanks for trying that.
Aaargh! Came too late! :(
faiface/pixel was the first git repo ive ever made a contribution to! I added the custom fragment shader support with great support from the rest of the community. It was a very fun experience and glad to have been apart of it as only a hobbyist programmer :)
Damn, I've missed it. Some hero that can share it with me? I would prefer to stay away from the dark side üôÑ
Thanks for the info, I figured something like this half life would be the solution. I‚Äôd guess the period of time that constitutes a half life would be tuned based on use case? If your accesses are largely bursty (say reddit front page) you‚Äôd want a short half life to keep recently hot stuff but purge aggressively. On the other hand if your accesses were more equally leveled across your data set or swung over longer periods (maybe something like a stock photo website?) you‚Äôd want a longer half life. 
Unlike Charles Carmichael, who always comes quickly. 
This is fantastically helpful. Thank you!
Not new, and I believe currently unmaintained.
how many? IMHO, much fewer than other languages, such as C++/JAVA/JS. We need more!
Gob is a stream encoding and is not well suited for this. Custom types are described with a new identifier when first seen in the stream and all future uses refer to the previously seen type description. Creating a new gob stream for every individual element written or read is very inefficient.
Exactly. An approach with a similar effect should be to modify how much you increment by on each access over a fixed aging period. That should be cheaper than halving scans. We tried that and while it helped, our another approach was more effective so we didn't try the scan variant. The reasons why increments weren't as effective seemed to apply to aging scans, so too a potential distraction. Our case was a little different because we use a frequency admission filter, which is cheaper and more effective than a frequency eviction order. That lets us retain counts for items outside of the working set which LFU forgets, helping to promote them. For example a small cache with a loopy workload may not work as well with an aging LFU if it halves too frequently to keep useful items. The best approach was two LRU spaces, promoting by the filter so that the latter had frequent items. We adapt the size of the spaces by sampling the hit rate and hill climbing. It worked amazing well! Here's a short [write up](http://highscalability.com/blog/2019/2/25/design-of-a-modern-cachepart-deux.html) on it and a longer [paper](https://dl.acm.org/citation.cfm?id=3274816). I really like the how quickly it tunes itself when the workload changes in article's chart.
In general, you've got to close the body to release the underlying connection for future reuse. Nothing is "downloaded in the background", it is up to the caller to consume the Body. It is entirely possible that it isn't technically necessary for HEAD requests, I can't remember the details off the top of my head. But, you should just do it anyway because the documentation says so. It means your code will remain safe even if the implantation details of net/http changes in the future.
If you're just looking for browser sessions, you can use this package for session based authentication: https://github.com/abraithwaite/jeff Disclaimer: I wrote it. ;-) 
Can you share a use case?
Thanks for posting! Seems useful. [This is the Github repository](https://github.com/autom8ter/goproxy), right? 
Thanks mate! I almost have a client that auto configures itself with sub commands based on the same proxyconfig structure. Pretty nice if you have a bunch of endpoints you call regularly. I‚Äôll also add an example of pulling authentication at runtime from a secure remote config source like git/etcd/consul. Does anyone have an opinion on whether adding methods to chain middleware like sessions/oauth/user-database/logging/opentracing/metrics would be overkill? Scope-creep is my weakness. 
Yes it is! Thanks
argon2 is also a good option :)
How is this battle tested?
100% agree. There is an [open issue](https://github.com/golang/go/issues/19814) about enum support, in which [I voiced my opinion](https://github.com/golang/go/issues/19814#issuecomment-298751831). I really don‚Äôt get why such a fundamental primitive is missing from Go. I can obviously get work done without them (I have until now), but it really sacrifices code safety. Some things are just best represented by an enum. Swift really got enums right. I just wish Go had them _at all_. 
test &amp;#x200B; test
HEAD is just a method name. RFC says that there should not be a body, but a non conforming server might send one. Go library is flexible and orthogonal: Head does not have any built-in logic in addition to Get or Post; it just issues the request with the specified method name. The socket is returned as Body after parsing the headers so that IF there is a Body after all and you want to read it, you can do. Otherwise, just close the Body (the socket) and that‚Äôs it.
This is your main competitor https://www.gonum.org/ That being said, I don't think Go is a good fit for data-science. 
Thanks. What makes you say that re. Go not being a good fit for data science?
A REPL is pretty important IMO.
If Kek is a slice, how do I access top kek? ``` Foo.Bar.Baz.Kek[0] ``` ?
You may also want to look at https://github.com/tobgu/qframe/ 
With that I don't mean literally cache MySQL output. I mean storing data in memory and fast retrieval. Of which caching can be an implementation. I'm surprised how many people here say that MySQL needs to do the job of caching data while it can do a lot more useful things with the resources it has. MySQL also doesn't understand your data, so it's a hard task to cache something if you don't know the frequency of usage and invalidation. Writing that yourself on top of redis or memcache or whatever kv-store or other caching solution will help MySQL drastically to free it's hands to do other stuff. Like mentioned in another comment: it's often better to turn off query cache for better performance. I believe they even dropped it in MySQL 8.
Really nice library! My immediate thought would be other forms of api authentication. Another common one is http header. Custom logging may be nice, if I were using this in production I'd be most concerned about performance.
Be cautious with JWT. I‚Äôm not necessarily advocating against it, however I want people to be more aware of what they are getting into https://news.ycombinator.com/item?id=13866883
Maybe the confusion stems from unjustified assumptions on how Go works (which is different from lots of "common" languages). Stop thinking about individual files. The main concept in Go ist that of a package which basically _is_ every file in one directory. How you split your code into files _does_ _not_ _matter_. (There are fine points but that is not your problem.) Each file in one directory (=one package) must have the same package declaration (obvious). Which package name to choose? There is one convention and one rule. The rule first: - If you want to compile a program, an executable the package name _must_ be "main". (For all files; all files have the same package name always; nothing special with main.) - If your package is a library, something to be imported, something which is not by itself an executable (because it has no `func main()`): Name it after the directory. This is convention, but one you should follow! (Again all files have the same package declaration as files by themself play no role.) So there is no contradiction in the cited statement. You must use `package main` for each and every executable and you really should name any non-executable package like the folder. (You see again: Files exist but play no role here.) The `go` tool allows to work with files but I think you should not use that feature: Always let the go tool work on whole packages/directories. 
Your repo is interesting but maybe you should learn go directory structures. It seems like other language so I confused. I want support you so please write README and Issues.
It was only available in the packtpub reader format, not something distributable unfortunately. 
Given that it's a HEAD request, the body might be nil. In that case, the call to close might return as soon as it detects the receiver is nil, resulting in a no-op.
Did you just thank yourself ü§î forget to change accounts?
I haven't taken a wide look over the repository, but out of curiosity maybe you can explain to me how you accomplish bi-directional communication? Is it websockets or streams?
I believe that's the case for all new "free" content?
I agree 100%, hence the other options I mentioned, and the reference to best practices. Have used JWTs for about 5 years now without issue, but I work on large scale distributed systems with independent Authentication and Authorization services. If I was building my own monolith without scaling concerns (which in todays cheap compute world takes a lot to hit), probably just use secure session token. No reason to introduce complexity for no gain. JWT has its purposes, but does not solve any problem for a simple monolithic application. As long as you keep the implementation details independent of your business logic (jwt, basic, session, digest, whatever is handled via middleware and your service just deals with a trusted User object) then you can swap it out as needed. In fact one of my clients just migrated a (groovy... yech) service from monolithic local session manager to JWT to support distributed services (written in Go) without having to touch any of the business logic in the old monolith.
Oh this is nuts! Nice work.
Using the suite package setup and teardown is really easy: https://godoc.org/github.com/stretchr/testify/suite
I use this same pattern except for the extra done channel. Why is this necessary? Doesn't the listen in the main goroutine unblock when the graceful shutdown finishes? Or have you found that the shutdown is still completing even after the listener returns? 
Embedded kv stores are the Go equivalent. Since they compile into the static binary, it's not as big of a deal to take on the dependency. 
In this blogpost I show you how to gracefully shutdown a http webserver utilizing Context, routines and channels. Those concepts I have addressed in an earlier blogpost. [https://marcofranssen.nl/concurrency-in-go/](https://marcofranssen.nl/concurrency-in-go/) 
It is to signal the main routine that the sub routine finished successfully.
My first impression reading this post‚Äôs title was... Why isn‚Äôt all the letters of API capitalized?! I know it‚Äôs petty and ultimately trivial, but it really grinds my gears. 
Yes it looks that way. They used to provide alternative formats :/
The world is full of em, kid. The CamelCasers... the lowercasers, and the CAPSLOCKERS. Least he didn't use apI ... that's just chaos.
OK That makes sense. Thanks!
I added pebble benchmark in [go k/v databases benchmark](https://github.com/smallnest/kvbench), it looks better than rocksdb in sdd case (fsync=true)
I've update readme, and also moved the repository to a non-personal account. Link is: [https://github.com/hyperia-go/goframe](https://github.com/hyperia-go/goframe) Do you have any good resources for learning Go directory structures? There are not many issues yet because well... there are not many features :) As I said, I'm quite new to github and open source, so guidance is very welcome / wanted
Those are two completely different classes of problems.
I don't have a macos system, so I won't be able to make it work on iOS.
The nutsdb does't not work on windows :(
I checked out your `go-11-modules` branch, and the tests ran in a couple of seconds using `go test ./...` Do you know which step in the CI that takes so much time? Maybe you can add a verbose flag to the tests to get a better understanding of what's taking time if it is indeed the actual tests themselves `go test -v ./...` &amp;#x200B;
It is explained on this post: https://blog.golang.org/modules2019 
Id suggest also caching the results of go get if possible. In docker you can make that a separate build step by adding the go mod and sum file and then running go get. 
`reflect`
Maybe you can use `go list` to iterate over the local packages? Something like this: for mod in $(go list github.com/alde/ale/...); do go test -v $mod done 
Locally it takes just a few seconds, so I'm wondering if maybe it's got something to do with how azure-pipelines check out the repo and downloads the dependencies...
So yes, this seems to have been the issue, it sets the GOPATH to be inside the project workspace where the code is checked out.
If you aren't vendoring (which seems to be the general concensus of the community), on a "clean" build server, `go build` has to download all the dependencies. That's probably what's taking the time. However, if you weren't vendoring before, this shouldn't be much of a difference. 
I wasn't. The problem was (as I discovered above) that the GOPATH was set to a subdir of the source checkout (by the suggested azure pipeline setup). I changed that to be outside of the workspace, and then it went down to 8 seconds. :)
no flushes to disk (potential data loss likely) and no Windows support might be good warnings to put in the README. It's easy to be the fastest if you don't stop to make sure you save things. ;)
Interesting. Do you know why that made it take so long?
yes, It was running tests for all the downloaded dependencies as well, such as https://dev.azure.com/alde08/ale/_build/results?buildId=51&amp;view=ms.vss-test-web.build-test-results-tab 
Yes, I didn't mean to downplay the Notary. I just thought this was a good place to mention my need. Then again, I assume the Go authors know what _the bigger concern is_.
Last commit 1y ago? Thanks, but no thanks 
Or A. P. I.
Not specific to programming language, it depends entirely on use case. &amp;#x200B; Will you be storing relational data? MariaDB/MySQL/Postgresql Will you be performing a lot of searches? Elasticsearch (not strictly a db) Will you be storing non-relational, schemaless documents? MongoDB &amp;#x200B; With that considered I usually always pick MariaDB (or any other RDBM). This current wave of NoSQL is usually the wrong choice, I'd say the majority of data is relational in some way, as soon as you introduce the concept of users, it becomes relational. In most RDBMs you can store (and query!) JSON blobs, so the benefit of Mongo collapses. The big one for me is the concept of schemaless, it doesn't exist, you are simply moving the schema to code and I'd much rather let Maria tell me when I insert crap data then have to deal with every edge case in code. &amp;#x200B; If you do start looking at Elasticsearch, remember this should never be used as your primary datastore. ES + Maria works very well if you need a lot of searching. &amp;#x200B; TL;DR: Use a relational database until you find something it can't do - which I doubt you will
Very cool! As a beginner, I was interested in a clean way to do just this. The boilerplate link isn‚Äôt working (resource not available). Also, I was unable to compile the code from the TLDR section successfully (Golang 1.11.5 on Windows). Any help or guidance you can provide would be appreciated. 
PostgreSQL until you find something it can't handle. Since it works as a NoSQL database as well as a relational database, that's unlikely to happen until your projects get really huge or special purpose.
https://www.dropbox.com/s/lvie4c4gtyibdiu/mastering-go%20%281%29.rar?dl=0
https://www.dropbox.com/s/lvie4c4gtyibdiu/mastering-go%20%281%29.rar?dl=0
Saved to my Dropbox! Tnx dude!! 
If this is for programs to communicate with, I'd say use HTTP Basic auth over an HTTPS connection. There's probably no need to add the complexity of session management. If you need to support AJAX or other browser-based access, or you really want session tokens, look at [PASETO](https://paseto.io/) for your session token management.
No probs. Let me know if you need more resources! happy learning.
Go 1.8.5.. Glide.. Thanks but no thanks
[removed]
I've been using [https://github.com/myitcv/gobin](https://github.com/myitcv/gobin) as well, since it seems a little more in line with what might actually make it into the go tool itself possibly. 
different queues as they're supporting different resources. 
Thank you so much buddy! I'll read it right away, thanks again!
If an indirect dependency also does this with the same package but a different version then aren't you going to end up only one of the two versions in $GOBIN?
An experimental accompanying helper tool called gobin can ease some of the boilerplate: [https://github.com/go-modules-by-example/index/tree/master/017\_using\_gobin](https://github.com/go-modules-by-example/index/tree/master/017_using_gobin) &amp;#x200B;
Postgres with pgroonga will give you all you need. You can have fulltext search even on jsonb columns. No ElasticSearch necessary.
Not 100%, but iirc you can only have one bin in the same name of GOBIN. The tool gobin was designed to work around potential issues like that. &amp;#x200B; See: [https://github.com/myitcv/gobin/wiki/FAQ](https://github.com/myitcv/gobin/wiki/FAQ) and: [https://github.com/go-modules-by-example/index/tree/master/017\_using\_gobin](https://github.com/go-modules-by-example/index/tree/master/017_using_gobin) &amp;#x200B; All in all, it's a decent solution to projects with a go-generate step, or for projects with specific code analysis tool requirements. Otherwise its back to unversioned system-wide peer dependencies during development, or bespoke project scripts.
*Hey just noticed..* It's your **1st Cakeday** B1-663R! ^(hug)
My first Go project that displays "Go 100%" on GitHub because of the awesome [Magefile](https://magefile.org) project.
That's a strange hardline to have. The repo has zero open issues, zero pending PRs, and does what is promised. A lack of recent commits does not mean non-functional software.
I believe [https://echo.labstack.com/cookbook/subdomains](https://echo.labstack.com/cookbook/subdomains) is what you're looking for.
Thanks. I will give this a go üòÑ 
Wow, speak of the devil. I just did this exact same thing after migrating a project to Go modules. One interesting thing is that this method is advocated by rsc so it can almost be thought of as an official Go team hack: https://github.com/golang/go/issues/25922#issuecomment-402918061
I haven't been following along much but it seems like installing binaries in the package structure and providing tooling Ruby Bundler style `bundle exec` or `pkg-config` style to locate the correct version of the binary would solve this if we added a `go mod run ...`
You could split up your project into multiple modules. Each repo can have as many modules as you want (as long as they aren't nested). You could have a module at \`/tools/go.mod\` just for tool dependency versions and then put your other code in a different module.
Will check this asap and let you know. Thanks for bringing this to my attention. Currently not able to access my laptop.
No I get that it provides synchronisation with the other goroutine. What I am asking is if you found that it is required. I had thought that the listener in the main goroutine would unblock once the shutdown that is called in the goroutine completes. Without the extra done channel, does the listener unblock while the graceful shutdown is in the middle of cleaning up? 
I wrote a small boilerplate to have a graceful shutdown so requests can finish. https://marcofranssen.nl/go-webserver-with-gracefull-shutdown/
Found the answer to my question in the docs &gt;When Shutdown is called, Serve, ListenAndServe, and ListenAndServeTLS immediately return ErrServerClosed. Make sure the program doesn't exit and waits instead for Shutdown to return. I didn't realise that the listeners return immediately. I thought they waited for the connections to close. Good to know. 
For actual applications, the biggest change for me (in any language) was to learn to design the system based on the ideas - not the implementation. You should have working business logic before you ever write a HTTP handler or database call. Domain driven design / Clean Architecture https://www.youtube.com/watch?v=twcDf_Y2gXY
Thanks for explaining. I was still trying to remember why I have added that üòÇ. 
Here is something interesting. The example they give for shutdown, which shows the similar done channel approach, seems to have a bug: https://godoc.org/net/http#Server.Shutdown In the error handler after the listener returns, they use log.Print instead of Fatal. If the server failed to start for any other error then it would reach the done channel and block until you sigint the process. 
So back in the day, there was a Java based API gateway like product called Repose. Basically a glorified Java servlet filter with custom/dynamic filtering options. It had the option, I believe of reverse proxy, as well as logging, filtering on authentication, black/white lists, rate limits, DDOS, etc. Could this potentially blossom in to such an API Gateway offering? Or is this about as far as you will take it? I am learning Go slowly.. and wanting to figure out how to build a microservices offering with Go, but not sure about the API gateway bit. I was assuming, especially if deploying with Kubernetes, that K8 would handle a bit of that, using something like Istio. So in a potential deployment like that, is a library like this still needed? Or does K8 potentially handle all the API gateway stuff? 
I really like the versioned devDeps pattern from other language ecosystems, the go variant of the pattern really seems to have flown under the radar, thats why I'm trying to promote it some more.
Heres a service I started somewhat following a DDD design pattern. It can run either gRPC or GraphQL [https://github.com/longfellowone/field-services](https://github.com/longfellowone/field-services) &amp;#x200B; Heres a simple example project I made up for someone showing how everything fits together [https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c](https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c) [https://play.golang.org/p/EvpszGg1Bmh](https://play.golang.org/p/EvpszGg1Bmh) &amp;#x200B; Using the example above your http/grpc/graphql server might look something like type Server struct { bsvc blogServiceInterface usvc userServiceInterface } func NewServer(bsvc blogServiceInterface, usvc userServiceInterface) *Server{ return &amp;Server{ bsvc: bsvc, usvc: usvc , } } func (s *Server) CreatePost(request) response { response := s.bsvc.CreatePost(request) return response } Then inside your http/grpc/graphql server you would call a single method per function. (Take a look at my other project for an example) &amp;#x200B; Folder structure something like |-- /cmd | |-- /usersvc | | `-- main.go | `-- /bloggingsvc | `-- main.go `-- /blog |-- /http | `-- server.go |-- /postgres | |-- authors.go | `-- blogposts.go |-- /user | `-- service.go |-- /blogging | `-- service.go |-- blogposts.go `-- authors.go So with interfaces between the layers your dependencies would look something like Domain &lt;- Services &lt;- HTTP
Thanks for spreading the gospel! I don't like seeing people call \`go get -u\` from scripts since it's always a moving target.
[removed]
Having all of the modules with `tools.go` fight for who was the latest to write to `$GOBIN/stringer` is not the right way to do that...
Works like a charm! ‚ù§Ô∏è 
Since there are no examples, then I can only make assumptions. But as long as your handler isn't using state, yes you could use the same handler for the callback of different rabbitmq queues. It's just a function that would get called. If the function is a method that saves state then you probably want different instances of the struct which contains the method handler. 
Maybe to prevent the server from shutting down when a http handler for a given request panics? Not sure, thinking out loud...
It will be interesting to see what kind of response this gets. I'm without. I've seen others espouse clean architecture in Go before too. For many it seems to cut against the grain. 
This book uses an up to date and idiomatic structure for a web app (you essentially recreate github gists): [https://lets-go.alexedwards.net/](https://lets-go.alexedwards.net/)
Have you tried profiling it? 500 concurrent requests isn't that high. [https://jvns.ca/blog/2017/09/24/profiling-go-with-pprof/](https://jvns.ca/blog/2017/09/24/profiling-go-with-pprof/) is a great intro to pprof [https://rakyll.org/pprof-ui/](https://rakyll.org/pprof-ui/) is also useful &amp;#x200B; &amp;#x200B;
`ab` isn't a good load testing tool. Consider an alternative like [https://github.com/tsenart/vegeta](https://github.com/tsenart/vegeta) or [https://github.com/rakyll/hey](https://github.com/rakyll/hey). Testing a lot of load from a single machine to itself can be fraught with peril related to the underlying operating system. One thing to try is to make sure your file descriptor limit is high enough. In the terminal session running the Go program, run `ulimit -n` to check it, and e.g. `ulimit -n 128000` to set it. But for realistic tests, you'll probably want to deploy the thing to a VM, and hit it from at least a couple of other machines.
With the lack of class inheritance, and the emphasis on composition and embedding - Go actually seems like one of the best languages for applying Clean Architecture. Almost everyone understands the pain of making an website/app, then having to move to a react/vue/angular SPA that needs API calls (or mobile client that needs to make API calls). Moving from a REST API to GraphQL, or from MySQL to MongoDB. It's implementation pivots like this that make domain design look like a great choice to smoothly transition. 
Naw. That would be caught by recovery handlers. Also panics can't be caught by a return error. I submitted it as a doc bug: [https://github.com/golang/go/issues/30641](https://github.com/golang/go/issues/30641)
Build a package, not files: $(PROG): $(wildcard *.go) go build -ldflags "-s -w" . Note the switch from listing out all the files to just telling `go` to build the package in the current directory.
I can recommend Vegeta as well. Nice tool. And this case is most likely file descriptors. I ran a performance test on my machine locally yesterday with 3000 concurrent requests with no problems, even with all services and database running on the same machine. Do a simple echo service should be no problem at all üòÅ
Many years ago, I took a course in parallel algorithms. Can't say I remember much of it, but the professor who taught the course, who was an expert in the field, just said "you just had to solve the algorithmic problems he was assigning" with the assumption that given enough thinking, you'd figure it out. The only problem was, what if you couldn't figure it out? It's probably something that the professor didn't really contemplate, outside of "just think some more". So I think it's appropriate to say "I", because that covers a certain skill level. You say that you rarely run into problems learning a new skill (presumably because you have a strategy to learn, but also because you probably know a fair bit already). I had a coworker say they don't really know linked lists, but for what needs to be done, it turns out not to be important. The code doesn't require a deep (or any) understanding of more sophisticated features in a language. The less experience you have in languages overall, the less likely you are to ask the right questions about what to learn, and the more likely you are to get stuck, whether it be not understanding what you're reading in technical resources, or having the wrong computational model for how a language works, or even basic skills in how to debug code. Even so, there's probably an audience for this, once you reach a certain level of proficiency. I was told by a CS prof. that as one gains experience, you develop "taste" or the ability to decide what's important to learn, and what's not, and that can help avoid unnecessary learning.
&gt; MySQL also doesn't understand your data This statement is fantastically naive. &gt; so it's a hard task to cache something if you don't know the frequency of usage and invalidation Which is the sort of information SQL DB contributors have spent optimizing the shit out of. üëçüèª
"Initial commit"
Looks abandoned‚Äîlast commit 2 years ago, no issues (neither open nor closed).
It is at least an indicator. This, and the fact that the repo has not only no zero open issues, but also zero closed ones, would make me wary as well. Not saying that the repo IS abandoned, but it could well be.
Thanks for your reply. Your `Makefile` works well for me. It also gave me an idea for fixing my `.goreleaser.yml`. Changing this made `goreleaser release` work: from: `main: fstat.go` to: `main: .` I will also consider just not having Makefiles in the future. 
Yeah, I could do that. I just added the option to modify the request, response, and http.RoundTripper of each reverse proxy. I will add implementations of these middleware functions for logging, metrics(prometheus), tracing(opentracing/opencensus), rate limiting, CORS, etc to remove some common boilerplate. I work on Kubernetes quite a bit but Im not an Istio expert. In a Kube cluster, Id probably use this as a gateway to all of my external API's that internal services could connect to. You could scale it behind a load balancer and use Istio/Kube to control access like any other service. You could then deploy a tiny image in an authorized namespace with curl as its entrypoint and do something like `kubectl exec POD_NAME PROXY_ENDPOINT -d PARAM1 -d PARAM2`. This could also be used as an init container to ping an api every time a pod is run. Example Docker Entrypoint for Init Container: `curl PROXY_ENDPOINT/TWILIO_HANDLER -d "To=PHONE_NUMBER" -d "From=TWILIO_NUMBER" -d "Body=A pod has been deployed to your Kubernetes cluster"`. Or you could just use any http client within your own applications and programmatically call endpoints. Just thinking out loud.
&gt; I just bought effective Go and have yet to have a good look through it So I'll write a reply and you won't bother to read it. Great use of everyone's time here. http://www.catb.org/esr/faqs/smart-questions.html
That's a fair point and why I think working in a healthy engineering environment (with good mentorship and that actively invites knowledge sharing) can have such a deep impact in our careers. The main idea I had with this article was to suggest people to be more self-aware of how they choose to learn new subjects and try to build, over time, a framework of their own. Thanks for the feedback.
Interfaces. For your functions that consume your ‚Äúmodels‚Äù, have it consume an interface instead. If you need a basic attribute from the struct, in the interface, define a function that just returns the value. Eg, Name() string instead of accessing attributes directly. Every value you need from the struct just define that way. You also want to define it as basic as possible, with the bare minimum functions, so more objects can adhere to that interface. In a ‚Äúproper‚Äù OOP, you just inherit functions from the parent that do work, then your subclass alters the behavior. In Go, you use external functions and pass your struct into them to be manipulated. The sort package is a great example of this, where it just works on some unknown data, dutifully calling 3 functions on any struct, which are painfully simple to implement (length, less than, and swap). For more info on interfaces, I suggest Francesc‚Äôs talk on the upcoming generics. The first 2/3rds go into some great detail about interface best practices. 
This library was doing json logging before it was useful.
This is the right answer. It all depends on what you‚Äôre doing. For typical scale a RDBMS is great. For massive scale you need NoSQL. If you anticipate needing to scale up quickly, swapping out RDBMS to NoSQL is non-trivial. I did it a few years ago to solve some scaling issues and it was a lot of work. As a side note, I typically go Cassandra for NoSQL, as it‚Äôs very easily scalable (probably the most scalable database), and you use a schema with SQL like syntax now that they‚Äôve dropped Thrift. A lot of gotchas but overall it‚Äôs my go-to now, especially with its huge collections per partition key that can be pre-sorted. Denormalization becomes the norm with it, and it does a great job of it. 
I posted the first release of this package about a year ago and have since improved on it in a few different ways. There's still some work to be done (we always feel that way, don't we?), but this release is stable enough to be put into use now. If anyone has any questions or would like to point to something I can improve, please leave me a message or an issue on GitHub. Thanks for your attention :)
It should be `go get -u github.com/penguingovernor/length`
i use gorilla pretty extensively for all things web related. specifically their securecookies and mux; they make it really easy for authentication and routing. Also I've taken a generalized services type of layout. Each major function of the program is broken up into servies, ie: web, api, email, business logic, etc. Now that dynamic loading of plugins is working I update specific parts of the app without disturbing other parts. The servicemanager handles running/loading/unloading the services, ipc, logging, and database access. Services are loaded and advertise their web routes through ipc which is captured by the web service and merged into the routing tree. Great for rapid web development.
Every tool has its purpose and I pick whatever is most suited when I've the chance. That includes picking Redis or memcache as a cache. You should try it when you get the chance üòâ O and fix your SSL certificate on your app subdomain and company's website. It expired 13 days ago and the other one is for *.wpengine.com. Also your newsletter sign ups are insecure. Doesn't look good if you're in the accounting business. So stop pretending that you know it all. Spend more time on positive comments on Reddit and just fix your s***... stuff Cheers üçª
Should be ParseMetric and ParseImperial instead of a global flag.
Can you explain ?
I don't quite follow. ParseLength does accept metric and imperial units. Perhaps I'm missing something? (:
Oh shoot! Thanks for that! 
Ah, didn‚Äôt realize that. Either way, having a global flag that changes behaviour is not a good idea.
Same it didn't seem right to me but I couldn't really figure out a better way to have String (which can take no arguments) conditionally return units in metric or imperial. Do you have any suggestions?
How about define `type ImperialDistance Distance` which implements `String` to output in imperil. 
Hi, please consider the following two links: [https://groups.google.com/forum/#!msg/golang-nuts/GE7a\_5C5kbA/fdSnH41pOPYJ](https://groups.google.com/forum/#!msg/golang-nuts/GE7a_5C5kbA/fdSnH41pOPYJ) [https://stackoverflow.com/questions/25218903/how-are-people-managing-authentication-in-go](https://stackoverflow.com/questions/25218903/how-are-people-managing-authentication-in-go) &amp;#x200B; To be honest I will consider the scope of this project. If it's a quick phone app project, I would probably go with either JWT or [https://aws.amazon.com/cognito/](https://aws.amazon.com/cognito/) If it's a series project I would build a auth-server just to handle login/logout and session.
Thanks for sharing!
I a number of logging systems, like that which docker and kubernetes use, logs are expressed as json objects. It makes logs easier to parse for facts, instead of relying on "standard" log format like Apache. Bonus: the log parser can drop the json conventions and store elements in a more compact form.
Hey, at least you know the code *really* works.
Yeah, but Jenkins doesn't play nice with non-vanilla Go test suites. :(
Asking here, because I'm curious if anyone else has looked at this - I'm interested in logging at varying levels depending on fairly arbitrary criteria on a per-request basis (say, for example, IP address, or for certain users). Logrus stores the logging level at the "Logger", so the most obvious way of doing this is to make a new logger for each request, or to implement a wrapper on Logrus logger that forwards or denies each log based on its own level filter. Option 1 might not even be possible (?), because it would be impossible to know when each log line write was complete on an io.Writer. Option 2 allows me to reuse the Logger and it's associated mutex, but creates a load of extra complexity on things like Entry. Has anyone done something like this? It doesn't seem so out that that you might want to mark a particular context as worthy of extra logging. It seems like it might be possible in zap by using WithOptions on a logger and a WrapCore.
I would recommend the method you're using. The extra code of selecting a balancer from a list of 1 is very minimal. If however you must have no balancer, you could write your own, the interface is very straight forward https://github.com/labstack/echo/blob/775b2eefec49e0a4d224b3f38f2c5640b509c3cf/middleware/proxy.go#L59 type NoBalancer *proxy.Target func (n NoBalancer) AddTarget(*proxy.ProxyTarget) bool { return false } func (n NoBalancer) RemoveTarget(string) bool { return false } func (n NoBalancer) Next(echo.Context) *proxy.ProxyTarget {return n } // ... e.Group("", middleware.Proxy(NoBalancer(url1))) // ... I haven't run the code, nor have I read the documents so a few things for you to check: * What happens when you return true/false from AddTarget/RemoveTarget * Namespaces
An interesting and forgotten issue with clean architecture is transactions. They are assumed. Try moving from an acid system to a base system without explicitly modeling transactions at least in the controller + repo imply layer. 
License says 2016-2019, which means it's been around for a while. I used the code in ~6 projects and it has been patched to cover missing cases. Also, one of the latest changes was to add map, which made it more useful, for YAML and JSON documents. And I was lazy to document it, to publish that earlier. 
Dynamically suggest template variables for a given Context. E.g. you have a Context with fields `.User.Name` and `.User.ID`, you can tell to the frontend that this template supports two tags ‚Äî `{{.User.Name}}` and `{{.User.ID}}`. Another case is to programmatically access struct fields, for example for validation. This can be attached using tags, but what if those must come from external source or frontend.
Slices are not supported, it targets object's field names. Also, when decoding YAML/JSON many "objects" are represented as maps in Go, so it makes sense for maps.
Of course! :)
And how would one do this? Store results in redis until a new insert update or delete is done? And when querying check if data exists in redis, if not, query database, put to redis, deliver to client, goto 10?
that repo changed case and broke the internet for several days
I'm writing a forum based on Go, you can check it out. here is also some shortcoming (I'm looking for best practice too ), e.g.: 1. I put db instance in context 2. Ignore instance error 3. database/sql is not code clean but i don't use any framework, orm, it's simple and clean
From the title I was trying to deduce what is the length of an opensource library: 1 LOC, 100 LOC, ...
The database is not request-scoped, and therefore doesn't belong in the context. In my applications it's a field on the API "object" struct.
I prefer this one: https://github.com/uber-go/zap
you can create a new parser type, that internally holds the flag. For instance: ``` const ( ModeMetric = iota ModeImperial = iota ) type Parser struct { Mode int } func (p *Parser) Parse(v string) (Duration, error) { /* code */ } ``` I would recommend making `Mode` an unexported value that isn't changed once you create the parser. This will make your library reentrant and thread-safe also, expose an interface for the parser so that people who use your library can mock it in their tests.
&gt; Store results in redis until a new insert update or delete is done, then repopulate? You would only invalidate your key on those operations, you would not repopulate. You would let whatever was getting your data check if the value exists in cache and repopulate if not. &amp;#x200B; &gt; You write "Redis in front of a production database" anything I missed that makes that whole thing simple? One doesn't simply put redis in front of something and it magically works. I mean, I never said it was magic, but it's literally just adding \`cache.Get("MyKey")\` and \`cache.Invalidate("MyKey")\` to their respective calls, and then yes, it just "magically" works. &gt; And there's even more to consider, how do you limit the cache size? How do you decide what remains in the cache and what gets discarded? Redis automatically does this for you. If it gets to much in memory, it will start using disk, both of which has limits that it will start dumping the latest data. &gt; And that also means you have to maintain 1 additional service and your app depends on a database and redis or redis compatible server. I don't know what you mean by this. Redis can be ran anywhere, and is a single command to up an entire docker instance. There are bindings for every language, so I don't know what you mean by "redis compatible server". &gt; There's also added development time because of this Takes 5 seconds to set up (literally, it's one docker line) , and the same amount of time to implement caching logic. This isn't an excuse. &gt;and additional RAM requirements. You will use less RAM than the amount of RAM your database will take up. Have you ever seen a production database? It holds its shared buffers / execution plans / some db's query results. The fact you can limit your cache size without affecting your performance in redis and allow your database to span what it needs is a massive plus. &gt; And when you have many inserts, updates and deletes, performance might even drop because the cache always needs to be refreshed every time something changes, if you want up to date data and you do. I did not say every table under every scenario needs to be cached, especially not the exact same. The whole reason there are different caching strategies is because of that. If it doesn't make sense to cache a table, don't cache it. But there are very few things that are changed SO OFTEN and that ACTUALLY needs to be live data. Take anything you get from google, it is all massively cached data and is NEVER live. Redis saving cache even has an automatic way of dumping data after x period of time. &gt; if you want up to date data and you do. Then be smart about what and how you cache it? There is nothing with cache that doesn't allow this.
Thanks, it's true request-scoped is bad practice 
Basically there no bidi-streaming as gRPC-Web doesn't support it (especially client-streams). If you want to understand implementation - I recommend to take a look at gRPChat [schema](https://github.com/enfipy/grpchat/blob/master/schema/src/chat.proto). So workaround is that I just subscribe for new messages and deal new message as unary request. Honestly I did it via bidi-streams first but noticed incompatibility too late (in this [commit](https://github.com/enfipy/grpchat/commit/4704022f65319c06b2802906fca55b6749782062)) Also good links about [gRPC state and future goals](https://grpc.io/blog/state-of-grpc-web), [good post about goperjs and their bidi-streams through sockets](https://jbrandhorst.com/post/client-streaming/)
Neat idea. But, but the code isn't very idiomatic, and can be greatly simplified. getRandValue and friends all take a []string, but it's always supposed to be of length 2. Why not just accept 2 strings as arguments? And each has a helper "Check" function, which does all the work of digging through the maps in your data package without returning any values. The first value in the slice is just used as the key in data.Data lookups. Why bother? Each value in that map is exposed as its own map of strings. And, you can also lean on the fact that maps in Go won't panic or anything if you try to look up a key that doesn't exist in them. What you really want are utility functions which simply return a random entry from a []int or a []string. Consider, func rndString(s []string) string { if len(s) == 0 { return "" } return s[rand.Intn(len(s))] } func CreditCardType() string { return rndString(data.Payment["card_type"]) } That's just one map lookup, instead of many, for the same result.
Valid points. Wasn't too worried about performance but these changes sound simple enough. I'll see if I can make some updates.
A logger that depends on 7 other packages, is it a joke? 
You cannot run shell expressions unless you run the whole command through a shell interpreter. Wrap your whole shell string like: []string{"bash", "-c", "echo hi &amp;&amp; echo bye"} 
I like the structure and form of this one more: https://github.com/yields/phony/tree/master/pkg/phony
You don't use inheritance in idiomatic OOP. 
What
Composition is the go to way of doing opp. What you think DI IoC are for?
Underneath the suite simply uses go subtests, so I don't know what Jenkins doesn't play nice with then. 
Or https://github.com/rs/zerolog In any case, if I'm using structured logging, I love the libraries with type safe functions instead of just `interface{}`.
That's the primary function of my application here: [https://github.com/alittlebrighter/coach](https://github.com/alittlebrighter/coach) &amp;#x200B; There's more focus on being a searchable script library, but it builds and is capable of running scripts cross-platform (can run arbitrary windows batch commands and powershell). You can even run scripts and see the output remotely with cmd/coach-grpc-server and cmd/coach-grpc-web where server only provides a gRPC API and web runs a small web application that interacts with the gRPC API.
Use a waitgroup, and then go func(id int) { ... read code .... waitgroup.Done()} Then have it stitch the outputs. 
Hey, I fixed the issues you reported. I noticed I had a unsaved change and missing server config to serve go files. Please have a look again and let me know all is working out fine for you now.
Thanks Pickle. Actually I didn't think about rewriting the interface for now (didn't do that before). I'm glad everything works as anticipated, even with additional balancer one liners (running several subdomains [mentioned in this topic](https://www.reddit.com/r/golang/comments/ay10bm/echo_golang_virtual_hosts/)) :) &amp;#x200B; I'll definitely dive into this later on (bookmarked) and check back when the current solution doesn't fit my needs anymore or needs to be adapted. Then I can provide you with some answer on how to implement `AddTarget`/`RemoveTarget` func to proxy content without required balancer. ;I
No link, whoops.
Link?
Homework?
Sorry, added it
Sorry, added it
Not sure it's a good idea to use the Discourse name...
Not sure too, but it's ok, i have learn a lot from some kind man, and code is more important than the name, right?
Is it worth a buy? $35 isn‚Äôt cheap for a web book 
It definitively is possible; what's going on is that he is basically \_still\_ using \`gomobile\` to deploy a Go package to the Android app but instead of routing the data through the generated Java/JNI-C/Shared-C/CGo APIs he creates a http server in the Go package that will handle calls from React Native components and so forth. &amp;#x200B; \`gomobile\` also works for iOS/macOS and you can take the same approach, however publishing apps to apple stores now requires the \`BITCODE\` enabled when you compile which \`gomobile\` does not support nor has plans to support. \* [https://github.com/golang/go/issues/22395](https://github.com/golang/go/issues/22395)
well, 2 of them are golang.org/x so semi-official standard lib and another 2 are packages in the same repo. So really only 4 dependencies. Digging deeper, 3 of those packages are involved in Testify - a testing tool. The other is 37 lines of actual code, and of that maybe a dozen lines in one function actual effective code (this is the sort of stuff I would copy/paste into my codebase rather than my dependency list). So not that bad, in the end. But point well made... it's just a logging tool...
hi ,i have update the README ,thanks your advises.
thanks
My mac is not allowing me to modify the ulimit -n. (The already set value is 7168.) &amp;#x200B; Could I modify it from my app?
So no problem to change name, then. The name is misleading in 2 ways. One, it implies affiliation with Discourse, which is not the case. Second, it implies feature parity, which is also not the case. 
note - I know half of the things are literally covered in the tour. Since I never went through the tour and learned golang by experimenting on an existing codebase, I missed that :)
without actually doing this for you, I'd suggest something along the lines of: 1. open all the files as streams 2. create a struct like: type counter struct { lock sync.Mutex wordcount map[string]int } 3. create a function like: func (c *counter)CheckWord(word string){ c.lock.Lock() defer c.lock.Unlock() wc, ok := c.wordcount[word] if !ok { c.wordcount[word] = 1 } else { c.wordcount[word] = wc+1 } } 4. Use the method in the documentation for the bufio package, Scanner struct (the example for ScanWords is nearly complete) to grab each word from each stream and pass it to `CheckWord`, stopping at EOF. Run these as goroutines, passing them all the same `counter` instance. 5. As /r/DeusOtiosus suggests, use a WaitGroup to determine when all the streams have completed. 6. Your answer is in the wordcount map of the `counter` struct
What's your question beyond what is made clear in the readme? Boltdb author froze the project in a stable condition. BBolt forked and continued developing it. 
Given that you are new to Go and this sounds like a homework challenge, I would recommend taking a more simple approach. First create a solution for reading one file and counting the word occurrences. You can do this with a map of string to int, and use a Scanner to scan words from a given file. So at the end of this function you end up with a map of unique word counts for a file. Next make your program iterate over N files to sequentially add each individual map to a final result map. Once you have a working sequential program you can make it concurrent by starting each function to process a file in a goroutine. If you create one channel of maps then you can pass it to each goroutine and push the output into the channel. At this point all the files are off in different goroutines. Now loop over the channel N times to collect the maps and merge them. Now that you have a working concurrent solution, you can investigate optimizations to the logic. 
So, that's a good thing ?
Haha, it did happen to me, like 1y ago I believe
Rad. This turned up yesterday as I was searching for insight on Go's randomness generators. I'm a lowly noob so I didn't grok much. Dig the comprehensive array of cases... keep at it!
This just seems to be a much wordier version of the Go Tour chapter on channels, with many more grammatic issues. What's the point of this article?
[https://github.com/motemen/gore](https://github.com/motemen/gore)
Thanks, I appreciate it. &gt;For more info on interfaces, I suggest Francesc‚Äôs talk on the upcoming generics. The first 2/3rds go into some great detail about interface best practices. Do you have a link? Googling or searching youtube for "Francesc upcoming generics" does not really get me any talks by Francsesc, only one by Jon Bodner ([https://www.youtube.com/watch?v=5IKcPMJXkKs](https://www.youtube.com/watch?v=5IKcPMJXkKs))
Strange it seems my post isn't being displayed on the sub ü§î
You write: "NutsDB offers a high read/write performance and supports ACID transactions." The "D" in ACID stands for "Durability", which means you guaranty that no data loss happens after a successful transaction, even in case of system failures like power outage or similar. And than you write: "Current version no flush call (potential data loss likely)." Well, either ACID or potential data loss, you can't have both.
Nice and flexible. thnx 
How would you deal with db transactions in your example?
Had a quick look. Some of the things I found to be distasteful: - the strict adherence to the MVC pattern - non modular approach (MVC monolith looming) - `categoryImpl`: Java naming convention... Yuck. That said, quick look on my phone, so I could be wrong, but that was my first honest impression
 yes i see. it's my mistakeÔºånustdb current version supports transactions,but not ACID transactions. i have update the README . Welcome [contributions to NutsD](https://github.com/xujiajun/nutsdb#contributing) to improve it
im so sorry. Welcome [contributions to NutsD](https://github.com/xujiajun/nutsdb#contributing) to improve it.
If i remember correctly to get all records you have to use nil and not bson.D{} in the function Find() call: `err := db.C(formsCollection).Find(nil).All(&amp;responses)`
if you use models, you could easily switch to another fork of your library. ``` require ( YourLib v0.0.0 ) replace YourLib =&gt; ../YourLibFork1 ```
&gt;My personal recommendation is **to never use struct values as receivers, always pointers**. You ran into "Variable shadowing". But sometimes this phenomenon can be useful ;-) &amp;#x200B;
My advice fro writing something concurrent, is to write it first as not concurrent but just so that it can work on its own. In that case, you have it all in place and then later refactor it to concurrent usage. let's assume, your function is called scanFileForUniqueWords. it will return a map or slice with all words that are unique to this file. Those results go into the mainUniqueWords map/slice if they not exist in there then you go to the next file and do all of this. if you print the content of the mainUniqueWords, it will contain the unique words of all the files. at this step, you can make it concurrent. &amp;#x200B; &amp;#x200B;
I tried that but it didn't work
Hmm ok that works for packages outsite the main project. For forking that should be something like this: module example.com/notme/hello require ( YourLib v0.0.0 ) replace example.com/notme/hello =&gt; example.com/me/hello Is that even possible? The only other, somewhat useable, solution i found was; adding the forked repo to the available remotes. Which unfortuneatley breaks the `go get` command. (We recently changed from selfhosted gitlab to gitlab EE and its a pain to go through all the .go files, but doable. So if i have to do a do-over i wanted to do it "right"/future-compatible. Thats what led me to the forking / relative imports issue.) 
Dop you really need a database, is my first question. if the answer is, yes, because I need to store and retrieve stuff, I say: not a valid answer ;-) I can do it all in XML as an example. Just focus on your application first and what kind of datastorage solution you choose later on, will not matter in the end :-)
Thanks I really appreciate it
Did you check if document was created after the Insert() call? And also, did you check if the err is nil after both calls?
String in Go are just immutable bytes slice. https://blog.golang.org/strings
yes I saw that document from the mongo shell right after I called the handler for creating the doc. Yes the error was nil.
 exec.Command(".", "./script", "&amp;&amp;", "A") when you run the script and it ends the A command disappears, to prevent that, we use . ./script &amp;&amp; A try it
It looks to me like you're inserting `models.Responses` but decoding query results (via `All`) into `[]*models.FormData` rather than `[]*models.Responses`.
&gt;React &gt;No framework Pick one.
To be fair, React itself is a "rendering library" or "UI library" rather than a framework (it doesn't do routing, state management, HTTP requests, etc).
Ah, completely missed it: the document you insert is type of Responses however when you try to retrieve all documents you use array of FormData. It won't throw error it will return the array of objects whereas the number of documents will match the number of documents in the collection but the documents will be empty. &amp;#x200B; To fix it change the type of the variable responses. It should look something like this (might screw pointers but I have no means to syntax check it. func (d *CollectDAO) FindAll() (*[]models.Responses, error) { var responses []Responses err := db.C(formsCollection).Find(bson.D{}).All(&amp;responses) for _, response := range responses { log.Printf("all docs %v\n", response) } return &amp;responses, err } &amp;#x200B; &amp;#x200B;
The secret is just random bytes, but random bytes are not necessarily valid UTF-8. To get around this, encode the secret with encoding/base64 before saving it. 
React is actually considered a framework instead of a lines a programmatic sense because it isn't a set of functions that you call and then control is returned to your program. When you create your React components, you define lifecycle callbacks and the framework runs your app in the background on the page.
Running Bash scripts over the Internet? Seems like a possible security problem. 
Isn't that something else though? err := doSomething() for i := range yada { res, err := doSomethingElse(i); // creates a new err } // err still has the result of doSomething I don't mind this as much, as gometalinter warns against it and I notice that quickly :D
There can be potentially a lot of SQL injection issues. Instead of formatting query by hand \`fmt.Sprintf("SELECT %s ...", something)\` it's way safer to pass query and args separately: \`"SELECT ? ...", something\`.
Not that is probably matter now that this post is forgotten, but Clean Architecture assumes time. Here's a post that goes into it more. [https://deusdatsolutions.com/index.html#tricky\_transactions](https://deusdatsolutions.com/index.html#tricky_transactions)
Sorry, I meant that Jenkins doesn't seem to like it when you use test-specific third party libraries like \`testify\` in your Go tests. It encounters dependency issues from what I recall.
Yeah...kind of...n I've already reached the deadline :( ...so am asking for help
Love it, you rock!
Ah alright, that makes more sense. Sounds like a \`go get -t -u [github.com/your/repo](https://github.com/your/repo) \` should fix that 
A good name is often more important than good code. If users reject then name then they'll never use the code. 
Badger. 
Write a readme and include a license. 
So, who exactly will be able to consume the API? Only you? If yes and you only wanna do server-side rendered templates i don't exactly see the need for a REST API anyways. You'd output the data straight away without calling your own REST API. &amp;#x200B; Adding NodeJS+Express to consume the API and output SSR templates is just the same as having a Go webserver that consumes your own API and renders a SSR template. Introducing a different stack seems kinda pointless to me here. Or do you wanna have a publicly available API AND provide SSR output?
That's definitely an interesting way of looking at it, and I can see where you're coming from there - but then a _lot_ of libraries, including Go ones (in fact, including the standard _library_) would be considered frameworks. Any router for example could be called a framework, after all you bind your services to handlers, and your handlers get attached to a router, and the router then controls when and how those handlers are called. That's just like how you bind your services to components, and then React controls when and how those components are called to be rendered. A router's routes are similar to a components lifecycle functions (i.e. when this event occurs, perform this action). It's tough really to define what a framework is. One other way I've seen people look at it in the past is that a framework dictates how you do things like structure your files. I guess that's more about enforcing conventions. That along with providing boilerplate functionality. Not sure I really have much of a formal definition of "framework" at the moment, but I'd personally not class React as one.
Indeed - prepared statements should be used!
Yes, i created a publicly available API, so everyone can use it. For iOS Apps, Apps for Mac or Windows. AND i want to provide a SSR output for the Website that communicate to the same API. `DB -&gt; API (go) -&gt; Website/ iOS/ Mac/ Windows or other Appications`
God is course - the way I read it. But something like chatter, gossip, or confab would be better indeed. 
i tend to decouple front and back as much as possible nowadays since there is always a good chance of another frontend join the game (i.e. native mobile) and also the second backend as well, see all the microservices hype. &amp;#x200B; get them together either with a mono-repo or super-repo with submodules.
Go doesn‚Äôt really support relative imports. It sometimes half works but never reliably and the Go developers are on record as being against it. 
&gt; including Go ones (in fact, including the standard *library*) would be considered frameworks No it wouldn't, you're calling the code. The standard library runs your code, then returns control to you. It is a library if you're the one that calls it, which is true of the entire standard library. &gt; Any router for example could be called a framework, after all you bind your services to handlers, and your handlers get attached to a router, and the router then controls when and how those handlers are called. Yes, they could, and they do name themselves as such: [Gin is a HTTP web framework...](https://github.com/gin-gonic/gin) it's not really that tough to define what a framework is. I do agree, there are some that fall in the line between both, those that both call and get called, but in general, if you're telling it to do something then getting control back, or you telling something to run then it's calling you are two completely separate practices. &amp;#x200B;
&gt;The name is misleading in 2 ways. Thanks, i'm not disagree with you, do you have any suggestion for the name?
&gt;God is course - the way I read it. But something like chatter, gossip, or confab would be better indeed. Haha, never think about it, i think it should be Go Discourse :)
I know I could go write one -- but I'm looking for one that is complete and is known to be bug free...:) 
Thank you, I'm thinking about it too!!
Do you mean by mono-repo to keep the frontend code in a subdirectory like `/website` with a seperated `/website/cmd/main.go` file ?
Sorry, i don't think so, the %s is usually field name and hard code, for where condition, i use $1, $2. But i'll check my sql too, should care about SQL injection, thanks guy
You are right! React is a framework! I mean i didn't choose backend framework like gin etc. For the name, I will seriously consider it. Thanks!!
Agree with you, I didn‚Äôt think about it. Thanks
thanks :)
Thank you for your opinion
did try that but still doesn't work, I get the same error and an empty slice of responses.
Thanks
I mean in development time, your git structure. &amp;#x200B; Here's a good article about the problem: [http://www.gigamonkeys.com/mono-vs-multi/](http://www.gigamonkeys.com/mono-vs-multi/) &amp;#x200B; There is some examples, not go-related but the architecture for a go project regarding a modern web application would be the same.
&gt;That said, quick look on my phone, so I could be wrong, but that was my first honest impression Thank you! For MVC, i have put models, views, controllers under api. I didn't write much Java code, just learn from others. haha
 `grep 'go' /usr/share/dict/words | sort -u | less` I like `agora`, `argol`, `dagon`, `spigot` It's still up to you.
Fair points. Technically according to that definition routers are frameworks. xD And to be honest, I have no problem calling them that. Once you've committed to serving your program via HTTP, you're stuck in that routing framework. You'll always have handlers reacting to streams of bytes. I would concede that React is a much more flexible framework than things like Angular. You can mount a small React app to just one part of the DOM and the rest of the DOM is kept safe for vanilla JS, jQuery, etc. Angular takes over.
[removed]
[removed]
Not sure what you're doing wrong. Here is the test sample derived from you code (without DAO interface but idea is the same) which works perfectly fine: package main import ( "github.com/globalsign/mgo" "log" "time" ) const formsCollection = "test" type FormData struct { Name string `csv:"name" json:"name" bson:"name"` Gender string `csv:"gender" json:"gender" bson:"gender"` Age string `csv:"age" json:"age" bson:"age"` Hobby string `csv:"hobby" json:"hobby" bson:"hobby"` MobileNo string `csv:"mobile" json:"mobile" bson:"mobile"` } type Responses struct { Data []*FormData `json:"response"` } func main() { var err error DialInfo := &amp;mgo.DialInfo{ Addrs: []string{"localhost"}, Timeout: 60 * time.Second, Database: "test", Username: "test", Password: "test", } session, err := mgo.DialWithInfo(DialInfo) if err != nil { panic(err) } defer session.Close() //resp := []*FormData{ // { // Name: "by", // Gender: "synced", // Age: "response", // Hobby: "submitted", // MobileNo: "revision", // }, // { // Name: "byoooooo", // Gender: "sytewed", // Age: "se", // Hobby: "subed", // MobileNo: "revissaaon", // }, //} db := session.DB("job-manager") //err = Insert(db, resp) //if err != nil { // panic(err) //} responses, err := FindAll(db) for _, response := range responses { log.Printf("all docs %v\n", response) } } func Insert(db *mgo.Database, responses []*FormData) error { resp := Responses{ Data: responses, } err := db.C(formsCollection).Insert(resp) return err } func FindAll(db *mgo.Database) ([]Responses, error) { var responses []Responses err := db.C(formsCollection).Find(nil).All(&amp;responses) if err != nil { panic(err) } return responses, nil } &amp;#x200B;
[removed]
Thanks!! These are all good, i need some time to think about it.
I didn't find any SQL injection at the first look, just saying that this style of coding doesn't look secure. When I see `WHERE category_id='%s'` I need to jump to other function to check what can be in this string.
Sorry, what is that?
Go binding for tenserflow lite
Thank you, I'll check it too 
Could you provide an example?
You can use the three index slice for your first problem. Append will find that the slice is full and allocate new memory slice := []string{"a", "b", "c"} subslice := slice[0:1:1] // subslice is "a", slice is "a" "b" "c", and has a capacity of 1 subslice = append(subslice, "e") // subslice is "a" "e", since the "e" was appended to subslice, // but since the slice was already at the capacity, it had to allocate // new memory and copy the "a" there before adding the "e" fmt.Println(subslice) // yep "a" "e" fmt.Println(slice) // still "a" "b" "c" You'll still modify the original slice if you modify the subslice without appending to it first, but the behaviour of "append" is where it usually surprises people..
Personally, i'm fine with the domain having dependencies on the STDLIB.
Good one. Cheers.
You don't include enough information on what your project is doing to warrant a thorough answer. You also state that PostgreSQL is an 'even worse of an idea'. Why is that? PostgreSQL is a fairly straight-forward and easy-to-use (my opinion) database. If you're having issues with that, I'm curious to know what it is you're trying to accomplish and what you're running into.
I didn't know this! Thanks
Thanks for the clearup. Well, then you can have a seperate package that acts as your SSR application, but that would mean the following IF you call the API: Client Request &gt; Webserver &gt; Request to API &gt; Webserver &gt; Client Response. &amp;#x200B; If you have re-usable services, f.e. for the database calls you'd have: &amp;#x200B; Client Request &gt; Webserver &gt; Client Response. &amp;#x200B; This would ofc require more work than simply calling the API and rendering the data.
I'll look it over and drop an issue on github :)
Thank you so much!
Just saw that you already dropped the issues. Awesome feedback! I'll dig through them an adapt Gophers style.
https://youtu.be/E75b9kuyRKw Here ya go. :)
As they say, that escalated quickly. You can chose to do what you like. Using Redis or memcached, both of which I have significant experience with, is a TERRIBLE IDEA until you truly need them. Of course, experimentation is always encouraged, never harm in that. I do hope you recognize the difference between technical facts and a difficult business that has fallen into disrepair. This discussion turned into attack when you chose to make an ad hominem attack. I never continue discussions past ad hominem, as it‚Äôs clearly not worth my time past this final comment. I appreciate your pointing out that we have some work to do. Seriously. Thanks for that.
Thanks!
You would put the web files in un-prefixed directories, and then scope your api to /api or a subdomain. Eg: / goes to the web root. /users would get users info. /api/users would get the users API. Using a sub domain does work, but introduces complexity if you are needing to consume the API from the same site, as you need a CORS policy. Alternatively, you can use a more rails centric approach and check what the user is requesting and respond appropriately. Eg. /users from a browser would get an HTML page generated. /users from AJAX or requesting content-type application/json would give you the API content. 
Tell that to all the system libraries that use inheritance for everything. 
Ah, thanks that explains it! 
Sorry, missed this one. Yes you can increase up to the hard limit I think but never tried. Since I needed to increase that one as well. I needed to fix something in my Mac config and restart to reach higher counts. I did a quick google:. https://gist.github.com/carlos8f/3557993 
I actually use locks almost exclusively. I tend to rarely use channels at least in production code.
To be clear I only did a speed read of linked article, but I believe it provides a nice opinion on topic
I find it hard to believe that the best available package just happens to be the one you wrote, 3 times. What's wrong with httprouter? Why would you use JWT? Isn't it kind of pointless to start using dep at this point?
Yes a lot of libraries which were written back in the day before world wide web took over and people have the time to reflect upon the way they do programming. Inheritrance is still used sometimes in very predefined ways like extending API in frameworks. But it's going away even from there as there are DI IoC options or hook implementations etc. However, that kind of implementation of OO is not used anymore in any serious software development. Composition is pretty much everywhere. And we were doing this for past 2 decades. 1) Because it couples code too much 2) It exposes too much API and sort of violates OO principles in that regard. OO is about bundling data (state) with behavior in software units which communicate with each other through rather strictly defined ways. Go also lends a lot from Object Oriented paradigm. Although can be used as purely procedural too. However if you use your services together with data in form of structs via predefined interfaces .. you're doing OO in Go. However I'm quite surprised to see how shallow the understanding for programming paradigms and styles some programmers have. 
Why not use the snap? It's kept up-to-date and it's easy to select the exact version you want (or follow the latest).
I have never heard of the first 3 libraries and using dep us suboptimal. Hard pass from me.
Very bad choice of name given a CookieJar is a very specific thing in [Go](https://golang.org/pkg/net/http/cookiejar/) and [many](https://docs.python.org/3/library/http.cookiejar.html), [other](https://github.com/square/okhttp/blob/master/okhttp/src/main/java/okhttp3/CookieJar.java), [languages](https://github.com/guzzle/guzzle/blob/master/src/Cookie/CookieJar.php).
you gotta use CGO instead of just go. heres the doc https://golang.org/cmd/cgo/ pretty sure you could find some medium posts about it too.
[yes](https://blog.golang.org/c-go-cgo)
It's not clear to me exactly what you want, however encoding support is provided on structs by implementing the relevant Marshal/Unmarshal methods for the encoder/decoder you want to support (eg - `MarshalJSON`/`UnmarshalJSON`). If you need to encode external types that don't have native encoding support, you can create a local type alias, add missing encoding/decoding methods, then use the local type instead.
[https://fosdem.org/2019/schedule/event/gco/](https://fosdem.org/2019/schedule/event/gco/) gives a good overview and links to other resources + sample code.
Oh shit, nice. I needed something like this for Django years ago and all of the solutions were stupidly over complicated to set up and use for just simple filling of a database with dummy data. I'll definitely make use of this soon.
I'm aware of that, but thought it would still be a fun name that fits the project's narrative. Thanks for the feedback though.
Awesome. Ya i use it to seed databases all the time.
ok? Going to need a bit more info than that....
I generated them. then injected my services [https://github.com/longfellowone/field-services/blob/master/supply/graphql/resolver.go](https://github.com/longfellowone/field-services/blob/master/supply/graphql/resolver.go) [https://github.com/longfellowone/field-services/blob/master/supply/graphql/schema.graphql](https://github.com/longfellowone/field-services/blob/master/supply/graphql/schema.graphql)
Best practice is always to separate the two. It makes sense, they're not coupled, your business users are probably going to want interface redesigns or edits far more frequently than logical changes. Personally I think angular when done right is a good fit with a go api, but when angular isn't a thing anymore you can reuse your api without needing to update it.
Analytics 
Web scale big blockchain as a service with an on-prem edition
Thanks for sharing. I think there is room for a better article on this subject.
I believe channels are nearly universally ‚Äúbetter‚Äù except in a few very narrow performance-ultra-critical situations ‚Äî and in such situations, you‚Äôre probably better off going directly to C/C++ instead. And it‚Äôs worth noting that channels are not analogous to locks. Between goroutines and channels, entirely new architectures arise.
As others already pointed out, you need to use cgo. The ["C? Go? Cgo!"](https://blog.golang.org/c-go-cgo) blog post is a good introduction too. Also, as a minor nit, the name of Go is just "Go", not "GO". See also https://golang.org/doc/faq#go_or_golang Cheers!
Yeet I saved this 
Decent Sized Data.
Forgot KubernetesLess.
[removed]
Well-hung Stats
https://godoc.org/github.com/google/btree
Can you please explain what this is/does, specifically? What is a worker/worker pool?
You can link C libraries in go , if you are writing a C wrapper on top of the library make sure to handle gc 
In case anyone wonders, it is indeed possible using zap by implementing a Core that overrides Enabled, and Check.
t2.nano-sized data.
Sure thing. So basically a worker pool is a design pattern that allows for controlling the execution of multiple tasks concurrently. For example, imagine you have a bunch of text files and want to find the number of occurrences for a certain word. Sure you could process them one by one, but it would be much more efficient to process multiple at a time and then aggregating the results at the end. For this, you could create a new worker pool with 5 workers that listen to a common channel. The main routine would then scan the directory and get the list of filenames and start sending them to the common channel. A worker picks the filename and starts executing the task, then the next worker does the same and so on until all 5 are busy. Once a worker becomes available again it goes to the channel and fetches the next filename, and so on until all filenames are processed. This project, specifically, aims to be a generic worker pool (meaning it's not aware of the type of work it processes) and to ease the use of this pattern by abstracting this logic of spawning workers and distributing work.
To me, \[\]rune instead of rune\[\] is because to align with arrays. \[3\]rune instead of rune\[3\] is because it will be confusing with index.
You need to pass `#cgo LDFLAGS=-lcrypto` because the flag is `-lcrypto`, not `crypto`.
http://catb.org/esr/faqs/smart-questions.html
if you have multiple implementations of the interface scatted in different packages and none of them are the logical "owner" of the interface, then put it in its own package makes sense. but say if besides mocks you only have one implementation of the interface, then clearly the packaged implemented it should also own it. you issue might be resolved differently. remember that go is duck typing. package B doesn't need to import package A to use that interface, it could be defining the interface again with a different (and probably unexported) name, or maybe just the subset of the interface it really needs. 
Don't know why your posting that, it's a very clear question. To anyone who searches this in the future, the difference is you use gomock.AssignableToType() when your method accepts an interface and you want your mock to act on a certain implementer of that interface
In general, there's a truism that applies: Be general in what you accept and specific in what you return. With Go, that means you should accept interfaces and return structs (whenever it makes sense, obviously, but avoid the opposite, especially returning interfaces). There's a second point of advice in programming, which is that Things should be defined as close as possible to where they're used. When you combine these two together: Because Go has implicit implementation of interfaces, if your function accepts an Interface as an argument (as it should, per #1), the place its actually _used_ is that function, not the implementing type. So it should be defined next to the function which needs it, or in the same package (per #2). In the AWS example, we should be clear that Amazon's usage of that interface is a little different than we're used to. Its almost like a utility; its mostly there for package users to build mock types around, and for application developers to accept versus the struct (remember #1) to enable dependency injection of those mocked types. So, their packaging decisions are a little uninteresting. Whether its in the main sqs package or a subpackage, doesn't really impact anything. And that's an important point I don't want to gloss over. Let's call it #3: Don't make things more complex than they need to be. Actually, let's make that #0, because its the most important tenant of programming you'll ever learn in your entire career. Where you put the interfaces doesn't really matter. Per #3: Don't create subpackages if you don't have to. That's creating complexity when you don't need it. Unless it DOES matter: Circular imports. That's where #1 and #2 come into play, and strictly following those rules legitimately does help reduce the number of circular imports you'll have (example: if a.F() accepts an interface as its argument, and that interface is defined in pkg b, then b will never be able to use a nor a.F()). 
I would be curious if this API actually gets used much, and at what sort of volume? If it does, how is it deployed, scale to handle load, etc?
Are snaps available by default, or do they require the snap service to be installed first, like with ppa‚Äôs?
Go 12 is out now, may want to revise for Go 12. I like this.. clean. I have found a few like this now on the net. Very nice that you can build, then bundle the binary into a tiny image. Scratch makes it so tiny. Great way to bundle up microservices, though usually you will need to add certs and some other stuff to lock things down I believe.
SQL is something I've always disliked , it's more of a person opinion , I need fast read and write throughput 
Sometimes it's cumbersome to do the whole channel / goroutine / WaitGroup song and dance when you just want to process a list of things over n workers. This little package makes it relatively painless, and takes care of finicky details like early cancellation. I wrote this a while back, but got inspired to post it from the thread about gnu parallel on r/programming. Let me know what you think!
There's no reason to use an interface in another package (other than convenience/laziness). That's kind of the point of interfaces; you define them in the same package that uses them, and other packages don't have to do anything to satisfy the interface. Take from example io.Reader. Every single package could define their own Reader interface and there would be no problems whatsoever; you can store a foo.Reader in a bar.Reader variable. It's there for convenience since so many packages use it.
Seem that swig is the best solution now
Backend ‚Äúrails structure‚Äù - suboptimal to say the least, better use something more go-native
&gt; suboptimal to say the least, better use something more go-native Thanks, I'll try to keep go-native too.
Well, not going through the tour is a best approach to get surprised and write an article about it :) So, surprise!!! It's like that doctor joke : "Doctor, it hurts when I push here!" and the doctor says : "Then don't push it!" 
Haha. The vendor in this case is completely open source. Technically, you always have a vendor lock in. The first vendor you lock into is the language you are using. The definition of a vendor is what matters here. We want to be viewed as a completely open platform always. Not sure if we qualify as a vendor in that case. Security will be a super huge problem. I'm still working on covering it in the documentation. We have some neat features which are pretty cool. Can we do this? Tell me all the places it will fail (would appreciate if you do this as a GitHub issue)? Let's try to overcome that. There are a few solutions which already do it (google firebase) so it shouldn't be impossible.
Wrong protocol. You want IMAP or POP3. Search godoc.org ...
grpc/grpc-web with envoy with envoy works pretty much ok for me.
looks awesome, must try.
Agora is particularly apposite
Just want to add why you would use this instead of just spawing a lot of goroutines: Your program works most efficiently if there are approximatly as many concurrent threads as there are cores on the chip. (Rule of thumb, depends on the actual work sometimes a few more are better). So you use a worker pool with a fixed amount of workers that 'max out' your cpu without having to worry about the amount of goroutines you have already started.
Cool. You might want to put `ExampleRun` and `ExampleRunWithContext` in a file in package `spara_test` ‚Äî that way, the examples displayed in godoc will have `spara.` before Spara's identifiers, just as clients would write everything. The `ExampleRun`-derived example in your README does it like this, but the `ExampleRunWithContext` one below it doesn't. I wasn't quite sure if `RunWithContext` was in the spara package or not.
The grpc-gateway works pretty well, besides some unavoidable quirks when it comes to gRPC/REST conversions (like time).
For what I understand, you put the statement for creating a table like in this example: ``` -- +goose Up CREATE TABLE post ( id int NOT NULL, title text, body text, PRIMARY KEY(id) ); -- +goose Down DROP TABLE post; ``` Those are commands that you can try in a database-client, without go. If they succeed, you're good to go ;-)
If your program is the only user of the API then get rid of that and make an application that works directly with the data. But what if you are ALSO the user of the API, but give others access too? Then, I would advice you to separate the read data parts from the API into stuff like repositories and call that from within the API (for the others) and your program can access those repositories directly. &amp;#x200B; With both solutions, your program doesn't need the API and gain speed and loose some of the translations to "n between objects", making it easier. 
I struggled with this when I started using Go. I was used to how interfaces worked in other languages, and I wanted the interface to act as an API contract. In Go, it's okay, may be recommended to redefine interfaces in different packages. At first, I thought this would be a maintenance nightmare, but so far it's not. When I do redefine the interface locally, I've only redefined the parts of the interface I needed to use in that package which can often mean a radially smaller surface area than the original. 
This seems pretty dated now. 
Where do I invest...?
My advice would be to simply solve the problem and not worry about the language being used to describe what you've done - leave that for sales and marketing. If you don't have sales/marketing, then just be honest - explain what the problem was, what you did to solve it, and what the result/improvement was. "Big data" applies to a very, very, very small set of problems, but that doesn't stop every man and his dog claiming it's what they are, and everyone believing they need a Hadoop cluster to solve all their problems (nobody should have that inflicted upon them).
What's bad with using a project-wide find &amp; replace? It will work the same way, it's not that you're changing any logic in your code to cope with go modules...
if name/foo/bar are packages that belong to your internal library, you can leave that as they are! Just address the right way in the go.mod file and you are ready :-) As an example, this is my go.mod from an demo application: ``` module MyDemo require ( MyLib v0.0.0 github.com/antchfx/xmlquery v1.0.0 github.com/flosch/pongo2 v0.0.0-20181225140029-79872a7b2769 github.com/gorilla/mux v1.7.0 ) replace MyLib =&gt; ../MyLib ``` So in your source inside this module (anywhere), you can use: import "MyLib/foo/bar" and it will automatically point to the correct local version of the MyLib Now, if you want to play with a experimental version of the same library, just change the last line into its correct location: replace MyLib =&gt; ../MyExperimental/v2 (just an example) your sources will now load functionality from that new location without changing anything else. :-)
I would say that it has to do with the way they are stored in memory. Maps are scattered, slices are stored more block-wise inside the memory
\&gt; Maps are scattered, slices are stored more block-wise inside the memory More details are preferred. :)
[removed]
Thats seems the only suitable solution so far but it's keep look to me a little bit cheaty TBH. This concept of module is still new to me but I don't get it how a subfolder of a project should be see as module. Also the fact it does not detect it by it's self if feel to me I'm doing something wrong. Btw thanks for the advice :)
Well, a slice just refers to one contiguous piece of memory. Iterating through that just involves a counter, incremented on each loop and compared to the upper bound. Modern CPUs can do that in pretty much zero time. Maps, on the other hand, [are an actual datastructure](https://www.youtube.com/watch?v=Tl7mi9QmLns) and walking that requires hashing (which takes time proportional to the length of the key), pointer-chasing (which is less cache-efficient - computers are a lot better at walking through memory sequentially than jumping around in it), more checks, more interactions with the race-detector‚Ä¶ They are simply more complicated. Watch the video for actual details of how the implementation works :)
I don't get what are you saying. Can you elaborate a little bit more? :D
If you just did a find and replace from your current import paths to the fully qualified import paths, would that affect anything? They're asking you if that will break anything.
The project will be a high traffic website, think AirBnb/Booking.com but not offering places to stay. And I want the auth side of things to be very solid. Thanks for the links, very helpful 
Just find &amp; replace your import paths from `"/name/foo/bar"` to a fully qualified import path like `"github.com/example/name/foo/bar"`
oh now I get it. So if our code is versioned you suggest to switch to a full path. We will try this path but this mean if we have the following situation: src foo go.mod bar shared foo2 go.mod bar2 Where shared is used by 2 modules, when we compile the modules it will download 2 times the shared library or the whole repository?
I think the mod should have auto detect, we want auto detection, not manual write replace for every internal package ( manual write replace as last resort ) say if if no domain name prefix and no replace directive the go mod should just using local directory(the same with import package name) ( the same effect with replace pkg to the current directory )
Sorry, but TBQH, I think posting this once was enough. This is *at least* the third time you submitted it here.
Can anyone who has experience with this, and Jenkins, share their thoughts on how these two compare?
You need to reorganize your code base, I think it would be better to extract `shared` to a separate module and import it using `go get` You should watch /u/campoy videos on Go modules: 1. https://www.youtube.com/watch?v=aeF3l-zmPsY 2. https://www.youtube.com/watch?v=H_4eRD8aegk
A subfolder of a project should be a package, not a module. Put your modules as a sibling to your main project and the \`replace MyLib =&gt; ../MyLib\` will work.
The name has always bugged me because searching sites for articles about Go ethier bring up no articles at all because the search term is too short or you get a load of unrelated results. Although Golang is not the official name using the search term golang gives you far higher quality results.
The usual purpose is code-deduplication. That is, you have two functions that are *mostly* the same, but not quite, and then factor the common logic into an unexported new one. In this specific case, it doesn't really make sense. This split was introduced [in this patchset](https://go-review.googlesource.com/c/go/+/125575/2). I would assume it just was a mistake - maybe Brad thought he'd need it, but then didn't end up doing so. Can't find any indication of why, though. There is one *potential* other reason to do something like this, which is to create a well-defined stack-depth. e.g. the logging-package uses [runtime.CallersFrames](https://godoc.org/runtime#CallersFrames) to get the source-location a log-line is coming from. For that, it needs to know how many frames are "internal" to the log-package and must be skipped and that could sometimes mean introducing superfluous call-frames (that would be optimized out, hopefully). TBH, I'd consider that brittle and bad code. But it may be a reason to do this.
Besides the points I already exposed in my article, there are some things that I believe you haven't considered. For example, if your company does publish some source code you wrote online with a GPL license, and you later republish it on another license, you should know that there the former will likely be identified as the copyright holder by programs specialized in detecting plagiarism. &amp;#x200B; Copied 10 lines of code from StackOverflow and some company published the code somewhere on the Internet (i.e., GitHub, GitLab) using GPL? You're likely to be flagged as an infringer right away by these software (they do use web crawling). Imagine how worse would it be if you did something on your private time and made the "mistake" of reusing at work later before releasing it. In this sense, closed source is 100 times better as it doesn't open roads to the attorneys who make a living as copyright trolls "hey, we can try to convince company X to litigate against company Y because they copied 500 lines of code in this 1.000.000 lines codebase". &amp;#x200B; Besides, this might cause complications if someone wants to leave a company to work on another way doing similar stuff and suddenly can't even reuse memories without fearing lawyers getting on the way, but I believe I already told this before.
We use a combination of "all things": our API is all protobuf and gRPC, we use pure gRPC for our mobile and desktop apps, the official grpc-web for the browser (we already using envoy for our pure gRPC anyway so this was easy) and grpc-gateway for legacy REST systems that can't use the generated clients that we produce for our public API (this is part of the main gRPC server that proxies to itself in the same process, rather than a seperate service as the docs suggest) We took a lot of inspiration from the googleapis
I'm curious what people think constitutes as "big data"? 15 TB? 50 TB? 1 PB? 50 PB?
interesting! do you start with any boilerplate / framework? &amp;#x200B; I'm not sure how to get started with protobuf definition, and integrated with gRPC-web and gRPC-gateway. &amp;#x200B;
CoreOS have a great blog post on the basics, as well as example source code on GitHub: https://coreos.com/blog/grpc-protobufs-swagger.html
It used to be the case that there were two similar but subtly different C+Go combos: CGo and GoC. If you search the git history, you'll find \`.goc\` files -- those used to be compiled by \`gc\` (the Go compiler) as opposed to to CGo which uses an external C compiler.
Your C library is underlinked if it requires clients to link to libcrypto. Fix your C library. https://wiki.mageia.org/en/Underlinking_issues_in_packaging
Fuck Jenkins. It‚Äôs garbage. Use Gitlab.
HoverFly would work. I've used it in production and it's easy + stable. 
Since no one else has pointed this out, the mention of linking to the GNU libc is moot as GNU's libc is licensed under the LGPL, not GPL. While it is a copyleft license, it allows for linking without requiring linking code to be GPL licensed. Additionally combining non-GPL code with GPL code if not distributed is also not a problem. The GPL specifically limits distribution and grants freedoms to use. This however with the rise of the web has led to the situation where much code that would be released for use in web services now using the AGPL, which would require code that links to it and is available through a web service to be AGPL compatibly licensed.
[removed]
&gt; Is it just spending copious amount of time doing data structures and algorithms? Yes. As with anything else, practice makes perfect.
I have implemented this pattern when there's a mutex involved: func(t Thing) DoX() { t.mutex.Lock() defer t.mutex.Unlock() t.doX() } func(t Thing) DoY() { t.mutex.Lock() defer t.mutex.Unlock() t.doY() } func(t Thing) DoXAndY() { t.mutex.Lock() defer t.mutex.Unlock() t.doX() t.doY() } In this scenario, `DoXAndY` can acquire the mutex once, do two operations and unlock. If the implementation was inline, I'd have to acquire the mutex twice in a row. Acquiring a mutex twice in a row is at best sub-optimal and at worst a bug. 
Yes adding certs etc.. would be great. I mostly just created this for reference but thought I might as well share the code. 
Yep, super helpful if you label your logs properly.
I download sqlite3 browser and open the created database after excuting the program and add my tables.ÿåis this way will resovle my problem?? becuase i figure out that some queries that aleardy exist on program did not work, i do not know if my way cause this issue or not... 
The same happened to me. the project (your library) is the package you use. Within that package you can have sub-packages. You normally address them in your import, like some other external package. So it's the same. github.com/mi/lib/sub/package makes that you can use package.somefunc() back to your library the "replace MyLib =&gt; ../MyLib" takes care of all of what's inside of it. so if MyLib/some/handy/set/of/funcs has a func you need, you just import that and now you can use funcs.hammerTime() ;-) It's exactly the same as external packages (a package is what is says: a box with go functionality, scattered in various directories , and therefore subpackagaes) 
Can confirm that Jenkins is garbage. Everything requires a plugin and 90% of plugins are orphaned. Apparently no one wants to maintain Java plugins, at least for Jenkins' haphazard "architecture".
I am happy with current website. And I am cautiously hopeful that they do not take cue from Rust website redesign which was giant clusterfuck. Instead of taking sensible advice from critics and fix it Rust folks decided to aggressively shutdown discussion and kept their crappy design intact.
Every massive enterprise shop uses Jenkins and it's a pain. We're no different. Upper mgmt picked Jenkins and Bitbucket so that's what every dev team must use regardless of the tech. Granted 90% of apps are Java apps but I always hear rumblings from the Rails, DotNet and Go teams about having to use things obviously tailored for Java.
Can't tell for Jenkins, but I've been working at OVH and used CDS and it's a real pain =/ You've to configure everything using mouse-click, meaning you can't commit your CI/CD like all modern tools. That means you can review changes in here. the UI change every two weeks and is a PITA. And it happens very often that your build won't start, but I think this is an OVH specific problem. &amp;#x200B; Anyway, you'd better invest some money on a real CI/CD rather than having to pay someone to take car of this one =/
Interesting reads : * [https://www.ovh.com/fr/blog/how-does-ovh-manage-the-ci-cd-at-scale/](https://www.ovh.com/fr/blog/how-does-ovh-manage-the-ci-cd-at-scale/) * [https://www.ovh.com/fr/blog/continuous-delivery-and-deployment-workflows-with-cds/](https://www.ovh.com/fr/blog/continuous-delivery-and-deployment-workflows-with-cds/) &amp;#x200B; &amp;#x200B;
Hopefully never
Early revisions iterated quickly, but you've moved like nearly a year, and there's been a ton of work since then. Moreover, workflows are templated and can be managed as code. I invite you to read : [https://www.ovh.com/fr/blog/continuous-delivery-and-deployment-workflows-with-cds/](https://www.ovh.com/fr/blog/continuous-delivery-and-deployment-workflows-with-cds/) So far, we have a real success inside OVH (and from feedbacks, other companies too) and CDS provides CI/CD as a service for the whole company with many different requirements (goland, packaging, FPGA, etc.)
That's good to have the workflow templating :) But sorry I wouldn't come back around anything developed at OVH.
It said it was Enterprise Grade right in the title. So it already covers the fact that it is great for showing off to management while still being bloated and hard to use.
Hi, [https://www.postgresql.org/docs/current/sql-prepare.html](https://www.postgresql.org/docs/current/sql-prepare.html) I read this again, the problem is the query is simple, and don't have similar statement in a single session, do you still think it worth to use it? Thanks
I made the program to run for a particular file but i am not able to run it for N files... can you help me out?... I have attached my code below: "**package** main **import** ( **"bufio"** **"fmt"** **"log"** **"os"** ) **func** main(){ file, err := os.Open(**"file1.txt"**) **if** err != nil { log.Fatal(err) } words := make(**map**\[string\]int) */\*asking scanner to split into words\*/* scanner := bufio.NewScanner(file) scanner.Split(bufio.ScanWords) count := 0 *//scan the input* **for** scanner.Scan() { *//get input token - in our case a word and update it's frequency* words\[scanner.Text()\]++ count++ } **if** err := scanner.Err(); err != nil { fmt.Fprintln(os.Stderr, **"reading input:"**, err) } **for** k, v := **range** words { fmt.Printf(**"%s:%d\\n"**, k, v) } }"
Indeed, for security the key part is this: &gt; Prepared statements can take parameters: values that are substituted into the statement when it is executed. By using a prepared statement, the database server has an extremely clear understanding of what the _query_ is, and what the _parameters_ are. If you think about it from the perspective of what the database server has to interpret, then if you send up a whole query each time as a string with the parameters in place, how can it know the difference between parameters and the query itself? Well... it can't, and that's how you end up with SQL injection attacks.
https://dave.cheney.net/2018/05/29/how-the-go-runtime-implements-maps-efficiently-without-generics
I feel like we're being asked to do someone's CS homework. lol
I really like the "hand-drawing" style of that blog
I like the current website. It's "old" looking, but it's very easy to get around. As far as branding goes, I really don't like the new stuff but it doesn't affect me in any way other than having to look at it.
I used to work for a company where I was in charge of creating the hackerrank tests and doing a big part of the interview. I really did not like it but at that company it was implemented because higher management wanted "proof" that people hired could code. Before I left I made the tests short with maybe 3 problems and users had something like 4 hours per problem. I also took these tests and yes, the only good way to get good at them is to study and practice. Today when interviewing candidates I don't do any projects, exercises or coding at all and I have found some of the best candidates for my team. What I do instead is ask them real problems that our team has encountered and listen to how they explain that they might solve these problems. We talk about different topics and you can then get a pretty good idea of how good the person is at programming.
[removed]
GopherCon 2016: Keith Randall - Inside the Map Implementation https://www.youtube.com/watch?v=Tl7mi9QmLns
&gt;Its hard for a person who is married w/kids and extra circular activities/volunteering, etc... It's not THAT hard. I'm not saying that you shouldn't put your family first. Obviously do that. But as long as you're using your family as an excuse for not growing, you're not going to grow. Make the time. Buy a book. Read and exercise. Don't try to take shortcuts.
[removed]
You sir, are a minority! HR won't let you talk to anyone without taking a HackerRank test. Wierd how much the industry changed in the past 5 years. When I interview candidates, I too ask whats on their resume and get detailed as the interview goes on. If you know the topic; you can sense the B.S quickly. Good to know people like you exist. lol &amp;#x200B;
[removed]
This is a Golang sub and I'll get murdered but I work and worked at large companies in Silicon Valley and wanted to give you some advice. 1) Do many many problems on HackerRank until you become FAST at them. You'll have about 45-60 mins per interview to produce a working solution. The capacity of quickly thinking on your feet, being able to start coding and seeing your choices of algo is what we need to see. Interns get 3 months to produce useful stuff. In 45 minutes, I need to know you can take a problem, parse it in your head, break it up, and code it. If you get something working on the board, you're ahead. Then we discuss your choice of algo and data structure. Did you use a list when you needed a set? Could you memoize O(n2) functions in a hashmap? etc... 2) I'd recommend Python if that's what you're more experienced with. Most large companies will hire a generalist Software Engineer (SWE) and want to evaluate algo/data structures more than syntax and language. Now if you're applying for a Go role, that's different... The reason for Python is because it's quicker on a whiteboard and more forgiving. That's like passing your driving test with an automatic vs manual transmission... 3) Now if you get a "Spider 10M pages" type of question, ask your interviewer if they are familiar with Go and channel/goroutine away! So in summary, if they let you choose the language for the interview, go with that you're most experienced with and lean towards Python. We want to know if you can do problem -&gt; code in 45 minutes and Python is usually the fastest way to code small algorithmic problems on a whiteboard. 
Totally agree re: Python. I do almost all HR/Leetcode type things in Python simply because it's the closest you can get to pseudocode.
I hope it gets redesigned sooner.
I feel your pain my friend. Been trying to find a job again, and it is really hard out there. On the one hand, it seems like there are a LOT of jobs, yet everything I have interviewed for are SUPER picky. So far, the feedback I have gotten is everything is great until I do whiteboard test. Because I dont do well on that part, I dont get hired. Despite the numerous posts/articles/etc that talk about how that is one of the worse ways you could determine someones value for a position, it is used by just about everyone as the ONLY factor in hiring. You could be an asshole, have a negative attitude, and if you do well on whiteboard, they hire you. Ever work in a place with asshole developers who dont have any bedside manners and wonder how they got hired? It is because they did well on whiteboard. Nothing else matters at most places. I am sure some people will reply to this (or you will read elsewhere) that they dont use whiteboard or if they do it is not the only factor, but you will also read a LOT more people of varying ages/experience tell the same story I am. It is all that matters. If you are lucky to find that 1 in about 1mil job opportunity that actually considers everything, e.g. experience, the way you communicate, etc and either doesnt do white board tests, OR they dont use it only... you may have a chance.. but then you will find you are competing against 100s of other applications in most cases too. Yah, I am a little sour right now because like you, I have family, mortgage, lots of bills, etc.. and I am running on fumes. Having 10+ years experience, being able to communicate, everything else, and to be turned away time and time again because of a stupid academic whiteboard shit that I havent done in any of my jobs since I started writing code, honestly, I am thinking of selling everything and finding a shack somewhere in the mid west and working at a local minimum wage job. It is really depressing this industry right now. When I started, we didnt have white board stuff, and you didnt need a degree. Now, if you dont have a masters and can answer the hardest leetcode question, you apparently arent worthy of applying. Very frustrated. Also scared.. after so long in the industry, at the end of my rope and about to have to uproot my family and live like the lowest paid 
Thank you both gents for your feedback. Appreciated.
If you'd bother to read the link, it would tell you why.
Bought many books. Read them cover to cover. Reading something and putting it on paper/code is another thing. lol. Not using family or situation as an excuse. 
Spend the first 30 minutes of your day practicing a concept. "I'm gonna write a bubble sort today." Then do it. If it takes you longer than half an hour, work on it the next day. You'll get some free spaced-repitition out of it. Keep doing that until you finish it. Then move on to another concept and do the same. Every once I'll n a while, work on something you have already completed, and try to finish it in your 30 minute window. I believe in you. 
Yes, they should just work. I believe 18.04 ships with some snap by default. 16.04 can be a bit finicky the very first time you install a snap, but generally it just works. 
Thanks, it makes sense, stmt for security. I'll do as you said.
It should be noted that the AWS SDK has a terrible UI. It basically has to be bad because it‚Äôs just a thin wrapper around some API calls. Still, you should never use it as an example of what to do. 
Just create a test that iterates over each DB request, then assert that the given response matches the expected response. If it's JSON data and you're using the testify framework, you can use \`assert.JSONEq\` to test JSON string equivalence.
I did read the link. I inspected the code myself and mentioned I didn't understand how the code was different. I've searched stack overflow and not found the answer to my question. Therefore I went to the golang Reddit where people can ask golang questions to ask a question about gomock which is go's version of mocking.
yes. I hate hate hate hate hate hate hackerrank tests. They only test how well youve memorised your notes in your ALG101 class. Ive succesfully removed those hackkerrank tests for take-home exams (that are either 3hours long or 1 weekend long, we check commit times) at my current company and the quality in the type of candidates that approach us has increase by 10 fold.
Can you by chance recommend a resource that i can practice these hacker rank tests? My professional career has been IT and and engineering this far but my true passion is programming and I think i'm finally ready to make the leap. And any other advice to best prepare for potential interviews?
That's an oversimplification. net/http actually says: ``` func (c *Client) Do(req *Request) (*Response, error) { return c.do(req) } ... func (c *Client) do(req *Request) (retres *Response, reterr error) { if testHookClientDoResult != nil { defer func() { testHookClientDoResult(retres, reterr) }() } ... } ``` This lets the body of `do` refer to the named return values inside the deferred function _without_ the awkwardness of exposing those names in the public signature. (Sometimes it helps to have names to refer to in a doc comment, but if not, it's usually better to avoid the names in the exported function.) 
You can sign up for a hackerrank account for free and do their challenges. When companies make their tests they will search and select from existing problems most likely. There are also pre built tests for companies based on the tests and challenges you can do as a free user. Companies can also create their own questions or modify existing questions if they want to. Personally I don‚Äôt really apply to companies who require such a test so I never practiced much on my own.
Gitlab is great, but the CI feature is still relatively new. I just recently ran into [https://gitlab.com/gitlab-org/gitlab-ce/issues/29447](https://gitlab.com/gitlab-org/gitlab-ce/issues/29447), and suspect I will run into more issues that take time to fix.
All that clicking in the gui reminds me of jenkins 1.x, and that part of it sucked horribly.
&gt;The capacity of quickly thinking on your feet, being able to start coding and seeing your choices of algo is what we need to see You will not see that at all from the usual hackerrank test. the only think you will see in the best case is how recently someone has resolved a similar problem or in the more frequent case you will get one "memorise some exercises" lottery winner. The typical 45 minute hackerrank test I have seen has between 6-9 questions/code exercises, that is 5 minute for question under ticking pressure. So you want me in 5 minutes to come up with a solution, making the right algorithm/data structure choice and code it right. As I said those 2 cases i mentioned earlier is what you get. 
First note is try not to share code of this size in a reply. It's hard to read. Use either play.golang.org, or a gist, or some code sharing link. So in your current attempt, you need to learn about using functions.before you can make anything concurrent. Notice how you have duplicated your logic to process two files. What if you had 100 files? Would you have to copy and paste this to cater to every situation? Refactor the logic into a function like `func CountWords(path string) map[string]int`. Then put your 2 file path strings into a slice, loop over them and call the function to get the count. Your main function should become much smaller. After that, learn how to create a channel, start each function in the loop in a goroutine and pass it the channel. Then loop over the channel in your main and collect the results into a final map. 
What do you find crappy about the rust redesign? Personally, their javascript loads data that takes some serious time on certain pages. I was wondering if the clusterfuck you refer to is that or if there‚Äôs something else.
I like the simpleness, easy navigation and clear presentation of the current site. I do not like the somewhat hobbyist theme, it does not reflect the maturity of the language.
Has any one compared it with stackstorm? 
I always code in `go`. The code part is suppose to be the easy part. `go` is a great language to demonstrate your understanding of CS fundamentals. `go` doesn't' have alot of built-in functions like python. Most of them you have to write it your own. Writing those python-built-in function day in day out in `go` by itself is already a good practice for up coming coding interview. I used to do bash -&gt; python. Now it's bash -&gt; `go`. 
Okay this is great, the only thing I kinda wish there was a way to judge my solutions against potentially, you know, more elegant solutions? For example I came up with https://www.hackerrank.com/challenges/compare-the-triplets/submissions/code/101342552 and wonder if there's more elegant solution
Exactly. People who think these Hackerrank things are useful are the same type of people who think grades are an indication of intelligence 
Generally you don't use the prepare statement directly. In this case what it means is using placeholders \`?\` and filling in the parameters in the query call. As to when to use it, the answer is always. Never interpolate values into an SQL query. Even if you know what you're doing, it's not worth the risk.
There is https://goreplay.org/
How nice of you to give candidates 4 hours per problem... I once was rejected by a company for struggling in a HackerRank test where I had 40 minutes to solve 4 problems.
It's not clear to me how the Dial() method of the client is meant to work across multiple addresses. There are a few abstractions in the source and I didn't follow it past the OpenChannel interface method call to find out. I also couldn't find an example of someone using it that way as a reference. But why not just ssh.Dial once per address and keep a map? 
I don't have an issue with the current site, but I really wish they'd put the download link in the header navbar.
*YOOOOOOOOOO!!!!* It's your **8th Cakeday** aeikenberry! ^(hug)
Sure, I have no objection to using "golang" as a search term, or recommending it for that. I use it all the time myself. Similarly, I think it's fine when people tag their blog posts about Go with "golang" as a keyword, since keywords are all about helping with searchability. It just mildly irks me when I read English prose about "the Golang programming language" or a new program/library "written in Golang," so I try to take the opportunity to help new Go programmers avoid learning from those bad examples.
There's no context in your post. No example code. No links to the things you've read. Absolutely nothing to go on. Seems my link is lost on you. Sorry for wasting your time.
First time hearing about rr... That is so dope
maybe try /r/rabbitmq
Honestly, I think you have also been a little lucky. I interview many candidates and I generally stick to the basics to cover algos and data structures. No trick questions. No dynamic questions. Just typical real world problems that one might encounter. I ask them to start by writing something simple on the white board and the peel it like an onion. Adding more constraints and making the problem harder as we talk. I too look to see how they solve the problem. But I also pay a lot of attention to see how they write code. If they say they know Java on their resume but don't know the difference between Set or List then they are probably lying. That to me does matter and I want to make sure they can regardless how good they sound like. 
Coding questions/interviews are one of those things that you need to prep yourself. Some times you get lucky and have heard a similar question and can code it up. Often, I have found that the best questions are the ones that are not tricky. The interviewer is just making sure you can write code, debug it, and understand the performance bottlenecks. &amp;#x200B; Some companies do ask tricky questions like dynamic programming, recursion or bit manipulation. The good thing about these questions is that once you have seen one or two you can pretty much have a good idea where to start. &amp;#x200B; I also highly recommend Cracking the coding interview. I have used that and have gotten offers at the big companies and start ups. Being mentally prepared is really the most important thing you can do in an interview. 
That's called a *method* in Go, which are functions that receive a type behind the scenes. So that snippet indicates that the type `Time` is defining a new method called `MarshalJSON`, that returns `([]byte, error)`. [More information](https://tour.golang.org/methods/1)
Hey thanks a lot for your feedback! I didn't even know that you could do that so learned something new today :)
&gt; Since no one else has pointed this out, the mention of linking to the GNU libc is moot as GNU's libc is licensed under the LGPL, not GPL. I didn't say "the GNU libc", I said "a GPL'ed libc". The argument would actually go, that I could technically just implemend a wrapper around `malloc`, release that under the GPL and then use `LD_PRELOAD` to load it into proprietary software to infect it. Clearly, that's absurd. But from a legal perspective, I don't see how that's significantly different from taking *any* GPL'ed library and dynamically loading it into software. Clearly, the author of the proprietary software has no control over what library you decide to load into it and what that's licensed under - some would say, that's the very point of dynamic linking :) And so, I don't see how (except, as I said, if both are *distributed together*) the process of dynamically loading a shared library has any implications for the GPL. And FWIW, the sources I found about this claim seem consistent with that view - both static and dynamic linking are equivalent, in that both imply obligations if you distribute compiled versions of the code and neither implies obligations if you don't. &gt; Additionally combining non-GPL code with GPL code if not distributed is also not a problem. The GPL specifically limits distribution and grants freedoms to use. I don't understand this sentence. It seems self-contradicting to me. How does the fact that the GPL limit distribution constitute a problem, if you don't distribute?
Any company that uses an artificial metric for hiring is going to be a shitshow to work for. It's a great sign that the company is either outside their competency or doesn't trust their own principals. Or they're just hiring monkeys.
&gt; Sure, I can start adding v2 to everything, which I think would work even if the git histories are completely different AFAIK there is no technical check of any of the "laws of modules" - that is, you don't actually have to go to `v2`, you can just increment the minor/bugfix number, even if the API is completely different. Yes, whenever someone would run `go get`, their build would break - but when we're talking about re-using one import path for a completely different project, we're way past that anyway :) So, worst case scenario, AIUI, is a) you push a new tag `v1.2.3` to your new repo, b) you notice that this broke because of the notary, c) you create a new tag `v1.2.4` from the same commit and push that, d) breakage is gone. And c/d) can happen without urgency, because things only break when people explicitly upgrade. Yes, Go modules assume a certain model of what versions mean and what breakages are and are not allowed - but if those assumptions are broken, the consequence won't be the end of the world. It just means‚Ä¶ some stuff will break, that's what usually happens when you make mistakes :) I don't really think Go modules or the notary are any more prohibitive of making mistakes than any other package manager TBH.
Super neat! It seems that's the way llgo was implemented too, although I'm not sure where it's at now.
From my personal experience, I've never have taken nor know anyone who was forced to do a hackerrank test. But I don't do startups. 
[removed]
Thanks for sharing your first impressions of Go. This kind of post is unique in the sense that an experienced Go dev can't write an article about first impressions since those are long gone. It's important to improve the language.
I am sometimes sad that we already live in the time in which people don't know how C strings work and someone feels like there is a need to write an article about it.
Are there golang projects where I can redirect based on things I run at home in Docker? I know I can do this in nginx, but Go would be so light weight... e.g. [owncloud.example.com](https://owncloud.example.com) \-&gt; [unraid.example.com:8011](https://unraid.example.com:8011), [splunk.example.com](https://splunk.example.com) \-&gt; unraid.example.com:8022, etc?
&gt; people don't know how C strings pepperidge farm remembers when that was innate knowledge
This post makes me really happy - one of our junior engs who had been doing some work on our Golang project went to GopherCon and came back really excited to learn more about the different tools we use on our project, and it ended up as this blog post! I am hoping for more Go in her future :gopher:
&gt; [...] you should add the ~/go/bin to your $PATH environment variable. Isn't that the old way? I've nothing Go-related in my $PATH and everything works fine.
I feel you dude. I've got 3 kids and 2 do competitive sports so I'm always on the go during the week and weekends (and the other one is 2 so that one keeps everyone on their toes). That being said I try to take an hour a week to work on something. Sometimes it's algorithms, but most of the time it's side projects. It's not a ton of time, but it's what I can allocate given the rest of my commitments (without killing myself). I don't do leisure anything - go out, play games, etc. - unless it's with my family. I just don't have time for it. I've had this post on my phone since this morning while I was dropping a deuce and am responding during my evening deuce. You're welcome for the visual. Moving on. I personally won't interview somewhere that requires me to do a pre-test. You either accept that when you ask for X amount of experience (we're not talking entry level) that you screen me out through other means. Again, that's a personal thing. My time is worth something. If I'm taking time out of my job and/or family time to get a new job, it's not gonna be to write a sorting algorithm when 99% of the time, for the actual job, using the internal sort method would work. I'll show open source work, personal projects, etc, but I'm not taking my personal time to write code for a job I don't have. Now the caveat there is if someone was rather enterprising and asked you what language you'd be most comfortable in and asked you to fix a bug that had some decent requirements in some OSS repo that fit your language, I might actually be game for that. But that'd basically be the hour a week I get. Unless I'm unemployed... then I'm basically the crack head from Friday; "Man, I got these cheeseburgers, man."
UI has become the new holy cow you can‚Äôt criticize :( 
Regarding the iteration order of maps, I think go 1.12 now orders the key values so that iteration is predictable/consistent.
Depending on what you‚Äôre after you can use a UNION or UNION ALL to bring back two result sets.
If you're after consistency, just make two separate queries inside the same transaction. If you're after performance, some drivers have a Batch method for bundling requests together to reduce the number of round trips to the server, but that's not part of the sql package.
I think the article is a bit confused about causality and motivations of Go's string design. The convention of {pointer, length} is to allow efficient subslicing. If this wasn't a concern, you could save memory by using a length-prefix encoding. The problems about security are fixed by having a dedicated string type that enforces invariants, and the problem of arbitrary length limits is fixed by using indirect allocations. Just see SQL as an example where fixed-length strings are common, but there aren't memory safety issues due to forgetting about NUL terminator bytes.
Thanks, i'm using placeholders as parameters in the query call, maybe i should try stmt first. :)
I‚Äôm not sure what you mean.. like a gateway that sits in front of the docker daemon and directs requests based on what services are running?
&gt; If you're after performance, some drivers have a Batch method for bundling queries together to reduce the number of round trips to the server, but that's not part of the sql package. Actually, it is. You can send multiple queries, separated by a `;` (probably ‚Äì implementations may differ) and then you can call `[NextResultSet](https://golang.org/pkg/database/sql/#Rows.NextResultSet)` to access each result set.
&gt; that's not part of the sql package. To help clarify, [`NextResultSet`]( https://golang.org/pkg/database/sql/#Rows.NextResultSet) is part of the sql package, but not all drivers implement it (properly).
&gt; that's not part of the sql package. To help clarify for u/bibat003, [`NextResultSet`]( https://golang.org/pkg/database/sql/#Rows.NextResultSet) is part of the `database/sql` package to allow batch queries, but not all drivers implement it properly. Refer to the documentation for your specific database driver. That, or just try it and find out. What do you have to lose?
Solid breakdown of Golang's basic tool chain. I also enjoyed the org-specific approach to the narrative. I don't think we'll ever have a language + ecosystem that fully addresses an org's needs without a touch of devops code. I look forward to seeing the progression of Secretless, and maybe I'll drop in with a contribution or two ;-) -Myrtle 
Nobody is born knowing how C strings work. Everyone who knows it, learned it at some point.
I honestly have never heard of hackerrank but I can honestly say that most of the candidates I've interviewed and hired over the years that we're particularly adept at these tests turned out to be some of the worst developers who were particularly awful at working with other people. There are certain concepts I always ask for, and definitely have been known to show a segment of code and ask for a description of what it does. But I would never bother giving an actual test to an applicant.
At least you don't have to work with all the assholes who are good at whiteboarding.
[removed]
Looks good, I use similar structure of my web projects. 
It can run anywhere but reverse proxy whatever I define in a config file. I was thinking of running it in a VM or a Pi where it would listen to 80 or 443 and then reverse proxy so I don‚Äôt have to remember the port numbers in my many docker containers. 
Can I see sources?
[removed]
There‚Äôs giant text in the middle of the page saying ‚ÄúTime Series Language (TSL)‚Äù
This structure uses a lot of frameworks, this is MVC. Look for example this project https://github.com/beego/samples/tree/master/todo
Yeah, what's that, who made it, what uses it, where do I get more info?
Oh yeah, you could do that. I‚Äôll try to get more examples up soon. 
[removed]
That'd be super. I'd love to test the heck out of it. Maybe even contribute. =)
The website has been moved to its own repository, likely in preparation for this change.
That why I put the remark that this is only a rule of thumb and depending on the work more can be better
I use debian almost exclusively and on all my systems, I just download Go and extract it into a subfolder of ~/.go I have my .zshrc file setup to set my path to include it, and set GOROOT/GOPATH accordingly. Works great, and it's super easy to install/update. 
If this is her first blog post ever, then i am really impressed. It is very well written
Also excited for the public release :)
maybe try LeetCode, same sort of deal but gives you a time and memory ranking against other users. The solutions are quite detailed and compare more optimized approaches to the naive solution. 
1. Don't keep vendor in repo, use go modules. 2. Don't use `SELECT *` in any application queries. 3. You have left some of fmt.Println in code. 4. Viper configuration looks like serious overkill for your app, consider using something simpler, like toml. 
It is in-progress. Possibly we will hear an announcement soon. No idea when though.
didn't notice that :) And didn't think of that :)
Amazing work!
code runner
glot
Hi @SeerUD, I have change to stmt you can find it here, let me know if you have any suggestion, thanks [https://github.com/godiscourse/godiscourse/blob/master/api/durable/database.go](https://github.com/godiscourse/godiscourse/blob/master/api/durable/database.go) 
Hi, i have updated, thanks [https://github.com/godiscourse/godiscourse/blob/master/api/durable/database.go](https://github.com/godiscourse/godiscourse/blob/master/api/durable/database.go) 
Yeah, I just wasn't sure that iOS will allow to create a http server for localhost.. It's possible to create anything for android, but iOS way is bindings only. &gt; however publishing apps to apple stores now requires the `BITCODE` enabled As for now, it looks required only for Tv/watchOS
When I worked for Google I did 150+ tech interviews (the whiteboard interviews that a lot of people hates). The languages I "accept" (Google have an internal interview system that you can say which languages you are able to conduct interview with and the recruiters arranging interviews will match the candidate's preferred language(s) with interviewers) was Python, Java, and C/C++ (I only started working on Go after I left Google). For the 150+ interviews there was probably about 50-50 split between Java and Python, with a few C/C++ candidates. Comparing Java vs. Python, with similar algorithm questions, Python usually generates much less code, which is quite helpful when you need to handwrite your code on a whiteboard with a time limit (I don't rate Python candidates higher than Java candidates just because they wrote less code faster, of course, but finishing the code faster will help us advance to the follow up questions and some in depth discussions, or give the candidate extra buffer when they made a mistake on their initial approach, etc.). As long as you are comfortable with Python, it's one of the best "interview language". But language doesn't really matter that match. I used C when I interviewed with Google (as interviewee), and after I worked on Go I mainly use Go for my interviews.
Is the \_test.go the most common/standard way golang developers write unit tests? 
Standard. The default tooling (`go test` etc.) identifies tests via file and function names. https://golang.org/pkg/testing/
imho the documentation is messy, for example: https://golang.org/pkg/net/http/ - Docs should be versioned, no comments with "this was added on go 1.6" - Why start with examples? That is a doc page, would be better have a link to the examples (and better ones) - As a general rule, just one reference to a function, when I enter a doc page I just want to "Control f" a function name. If the function name is in many places, is harder to find the actual definition. - Maybe some hints "func Error(w ResponseWriter, error string, code int)", What does suppose to mean? Where should use I it?
Jenkins works fine for Go. It's Java and a bloated mess but it gets the job done. 
You need infrastructure elasticity. You also need to treat server instances as cattle, not pets. Stop nursing servers back to a healthy state. Stop creating special snowflake servers. Use docker/kubernetes/istio on AWS, GCP, or Azure. Kubernetes will provide load balancing. When an instance reaches 70% memory allocation, it will spawn a new instance. When CPU is 80%, it will stop sending traffic to that instance. When instance is not healthy, it will take it out of circulation and spawn a new one. The point is, let the infrastructure grow and shrink according to the traffic demand.
I can't see that you call Close in request.Body or response.Body, although that's needed.
I very much prefer https://github.com/urfave/cli It is more intuitive to use for my taste.
Yeah, forget understanding the operational characteristics of your application and turn it into an infrastructure problem. Christ, what stupid advice.
I tried hard to come up with at least a far-fetched example of what such a tool could be useful for, but failed.
Looks good, I‚Äôll try to use it.
I'm pretty sure the server closes those automatically 
While this is true it doesn't answer the poster's question as to why the Java and NodeJS applications were capable of handling this load while the Golang application was not. It should be able to compete or out-perform the other applications, so there is likely a problem here.
Yes but at some point C was the first language that everyone learned and I think it was a good idea to do so: it teaches you some important concepts that you would otherwise never know about learning other languages.
Hi I understand your point but my concern is that my go app never gets no memory nor cpu issues. Thats why I am worried, it works fine and using just a few of the resources consumed by a similar Java or NodeJS resources so I am wondering if it will actually scale when reaching file descriptor limits or open socket limits... Also, the fact that same applications made with Java or NodeJS work fine in the same server where my go app fail should and could have an explanation. IMHO 
Oh, yes, you are right... it was a mistake during copy &amp; paste of the code.
There is a line in the second code that say: &amp;#x200B; req.Header.Set("Connection", "close") Also, there is this line in the second code: `respData, errResp := ioutil.ReadAll(resp.Body) defer resp.Body.Close() if errResp != nil { log.Fatal("Error en RespData", errResp) fmt.Fprintf(w, "Error en respData: %s", err) return }` &amp;#x200B; &amp;#x200B; &amp;#x200B;
No, and it was the reason that my test failed for a couple of the days. &amp;#x200B;
I think the problem is with the http.Transport: https://golang.org/src/net/http/transport.go &gt; By default, Transport caches connections for future re-use. This may leave many open connections when accessing many hosts. This behavior can be managed using Transport's CloseIdleConnections method and the MaxIdleConnsPerHost and DisableKeepAlives fields. &gt; Transports should be reused instead of created as needed. Transports are safe for concurrent use by multiple goroutines. Instead of making a new transport for each request, you should just make one and use it for all requests. You could pass it as an argument to the echoHandler.
Why are you creating an http.Transport on every request? Transports should be reused instead of created as needed. If you are going to attempt to create as needed, then cleanup resources by calling defer tr.CloseIdleConnections() after creating tr.
Nice post. Does secretless.io solves the problem of allowing repo `X` access to secret `S` but denying that to repo `Y`?
thanks for share. &amp;#x200B; where are the tests? How do you manage the dependencies? I'm not sure if use relative paths is a good idea (`"apistructure/store"`) Maybe a readme could be useful.
Very good blog post for a junior engineer! Look forward to seeing more from her and the rest of your crew here in the future. I‚Äôm also very interested in Secretless after reading about it. 
Some things to consider: `type Distance float64` Having a float value as your base type opens up a big can of worms. Consider this: ``` package main import ( "github.com/penguingovernor/length" ) func main() { l := length.Lightyear for i := 0; i &lt; 100000; i++ { l += length.Centimeter } if l == length.Lightyear { panic("wtf?") } } ``` I know for practical applications this is rarely an issue, but having an integer type as int64 gives predictable results, even if the smallest representable unit is 1nm. Compare to `time.Duration`. To help users, you could add `const Max Distance = math.MaxInt64`, similar with `Min` (if you want unsingned values - see below). Having negative "lengths" can be weird. The distance between two points are usually considered positive, unless you want to signify an implicit direction. Methods like `func (d Distance) Abs() Distance` and `func (d Distance) AbsDiff(d2 Distance) Distance` could of course help with this, or your type could be unsigned. Global state in a package is a big no-no. You could add an `Imperial` type and create back&amp;forth conversions. Since you are defining "Light Year" as a constant, use the full precision: 9460730472580800 metres (exactly)
Viper and Cobra are amazing projects.theyre my preferred configuration and cli libraries. 
It's not her first, but she worked really hard on it!! I'll definitely pass the feedback on, I'm sure it'll be appreciated :)
Ok (mostly - why defer after a ReadAll?), but you should call r.Body.Close() in the server handler, too! You may argue that the server closes it automatically - yes, maybe, sometimes. But it's waaay easier and robust to close it yourself ASAP!
Secretless handles the authentication handshake for you so that your app doesn't need to retrieve secrets from a vault or secure them once it has retrieved them. The RBAC would still be managed at the vault level - ideally you use a secret storage system that can identify individual applications and grant access to secrets at a granular level based on those identities. I'm happy to talk about that more too - I work on the CyberArk Conjur team, which is exactly that kind of vault. But the focus of the Secretless project is just making it easier for devs to use a secret store in the first place, which we hope will enable better security practices for us all.
Please let us know if you have any questions or if there's anything you'd like to see from the project! We're pretty excited about it, and want to make sure we deliver something that's useful and pleasant to use.
That would be awesome! I'll keep an eye out for you, and I'm happy to chat if you're looking for ideas on how to get started!
Even big established companies make you take HackerRank. 
Not in my experience. 
&gt;Any company that uses an artificial metric for hiring is going to be a shitshow to work for. It's a great sign that the company is either outside their competency or doesn't trust their own principals. Sad to say, I think the later. Devs are becoming a commodity
&gt;Totally agree re: Python. I do almost all HR/Leetcode type things in Python simply because it's the closest you can get to pseudocode. LOL thanks. I started with binary search. Moving to DFS now :-) &amp;#x200B;
what is your background/location? Honestly, I am shocked. &amp;#x200B;
The most direct and simple answer is that \`go get\` is not a dependency manager ‚Äî and never was intended to be one. &amp;#x200B; \`go get\` is only able to fetch code, and compile/install it (unless you tell it not to). This tool neither does have any real concept of a version nor is it able to manage versions of the so-called "transitive dependencies" for you‚Äîit can only download their latest versions available, plain and simple. &amp;#x200B; This thing about versions is not to be underestimated, and that is really the source of the constant bashing of Go for not having "core" dependency management, and also the reason for the tools like \`dep\` or \`govendor\` or \`glide\` or whatnot to exist. The problem is that when you make your program or a package depend on other packages, you really want to record which \_versions\_ of those external packages you depend on. &amp;#x200B; Having said that, and taking into account you're a Go newbie, I'd look at the \[Go modules\]([https://blog.golang.org/modules2019](https://blog.golang.org/modules2019)) instead: this is a recent addition to Go (first appeared in Go 1.11) which brings dependency management into the core toolset. Sadly, there was a pack of issues between the core Go team and the team behind \`dep\` about which approach is more correct (and more), and the dust is not completely settled, but a core solution IMO has greater chances of acquiring the widest adoption, so if you're starting fresh, I see a clear point in adopting a core solution. When you gain more prominence in Go, you'll be able to reconsider/correct your approach to dependency management in Go and adopt another tool or tools. &amp;#x200B;
&gt; at some point C was the first language that everyone learned At which point?
A great, comprehensive reply. Thank you. I will read into what you have highlighted. Thanks again
Read the README, perhaps? The one that explains the query language and links to the spec?
&gt;context btw, I use Context struct in model to remove \*sql.DB from context, the struct is like \`\`\` type Context struct { context context.Context database \*durable.Database } \`\`\` and here is the submit ([https://github.com/godiscourse/godiscourse/commit/0ff4d4ba2e56c17b562dd9946ada6df36ed4dcdf](https://github.com/godiscourse/godiscourse/commit/0ff4d4ba2e56c17b562dd9946ada6df36ed4dcdf)). Thanks again, learned a lot from your.
see example [https://tour.golang.org/concurrency/5](https://tour.golang.org/concurrency/5) 
This is a fantastic project, I love it! So you have a go service that is scheduled to run each morning that will: * scrape yesterday's video's YouTube page * tally the votes * agree on a direction to travel on this day * use gg to produce a series of image files following the daily direction * use ffmpeg to turn the series of images into a video * post and upload that video * record the name/link/url of today's video so we know where to scrape for votes tomorrow Is that the jist of the project? Are there any major points that I'm missing about this? It certainly gets me thinking about the possibilities. It also reminds me of going on a "murder mystery train" dinner theater type of experience. It's a theatrical production that happens during a train ride dinner. During intermission, all the passengers fill out a survey attempting to guess whodunnit, and eat dinner. While the passengers are eating, the actors are reading the comment cards, and they choose to end the evening's performance using the ending that they like the best. That said, I can imagine an interactive movie, or "news" cast (https://www.cnbc.com/2018/11/09/the-worlds-first-ai-news-anchor-has-gone-live-in-china.html) adjusting to popular opinion.... Anyways, thank you for sharing this project, I think it's really cool!
the phrase you're looking for is console UI, or terminal GUI, or anything along those lines. I've not looked into them so can't make a specific lib recommendation, but google for "golang console gui" gave me a page full of links to github libraries of that nature for you to evaluate!
Great comments, I think he can replace fmt.Println with log.Println if the debug messages are kept. 
Thanks friend! That‚Äôs exactly what I‚Äôm looking for!
Why not slam some URLs on your server with a tool like [wrk](https://github.com/wg/wrk), [httpload](https://github.com/perusio/httpload), [JMeter](https://jmeter.apache.org/), [siege](https://github.com/JoeDog/siege), [ApacheBench (if you can extract it from Apache server and create the missing folders and symlinks)](https://httpd.apache.org/docs/2.4/programs/ab.html), etc, etc. ?
Why not slam a few URLs on your server with a tool like [wrk](https://github.com/wg/wrk), [httpload](https://github.com/perusio/httpload), [JMeter](https://jmeter.apache.org/), [siege](https://github.com/JoeDog/siege), [ApacheBench (if you can extract it from Apache server and create the missing folders and symlinks)](https://httpd.apache.org/docs/2.4/programs/ab.html), etc, etc. ?
Goroutines are not always run on another thread and the runtime tries to keep goroutines on the same thread and tried to keep them running for as reasonable amount of time. With such a simple example it is quite likely that the runtime is only using a single thread and thus makes simple things seem more deterministic - though small changes can alter this order, such as putting in a time.Sleep(1) before the select. For example, [putting in a print](https://play.golang.org/p/aKGaFZJq0z6) and running it enough times you can get: ## two one ch2 got a 2 ## two one ch2 got a 2 ## two ch2 got a 2 ## See that last one did not run the first goroutine at all before exiting. Note that this might not work on the playground is it does [some special things](https://blog.golang.org/playground) for security and performance so is not the standard go runtime and its behavior can differ.
&gt; Don't keep vendor in repo, use go modules. Why not? What is the better alternative?
[Text-Based User Interfaces](https://appliedgo.net/tui/)
Try: package main import "fmt" func main() { for { ch1, ch2 := make(chan int), make(chan int) a, b := 2, 10 go func() { &lt;-ch1 }() go func() { ch2 &lt;- a }() select { case ch1 &lt;- b: fmt.Println("ch1 got a", b) panic(111) case v :=&lt;-ch2: fmt.Println("ch2 got a", v) //panic(222) } } }
Has anyone bought goland as an individual license? If so is it worth it? I'm doing more go in general so I'm wondering if it's something that provides value for how much it's worth
It was the first language I learned and that was only 3 years ago, granted it was through an engineering school 
Imo, the roi in terms of time saving features compared to any free alternatives, will be met within the first 90 of using Goland, and that‚Äôs without getting to know all of it‚Äôs killer features, just the code completion alone. I write mostly Go so there really isn‚Äôt anything that can beat it for me. Now, if you do a lot of front end stuff, ymmv.
Twirp works well. It works over HTTP/1.1, whereas gRPC only works over HTTP/2 (although if both your client and server are written in Go than it wouldn't matter to you). I chose Twirp over gRPC for a pretty big project because I had issues with the latter and the former simply worked. By now I don't even remember what the issues were, I didn't have enough time to tackle them (deadlines...). That said, I am working on an even bigger project now with gRPC, but we've only just started so can't really elaborate further.
/u/snwfdhmp we already know about this project for 3+ years ü§î Is there anything there that you want to highlight?
I've recently worked at a few smaller but **very** well funded shops, and this absolutely seems like the new trend coming down from the money guys. In both cases the CIO was basically working himself to death since he refused to delegate. Engineers wouldn't be invited to meetings that turned out to be critical. Information would be doled out "as needed" by people who weren't aware of the necessities of the job. The sad thing is that everyone involved with these projects had a fairly decent reputation in a competitive industry, and they're in the middle of burning that reputation by listening to their investors.
Load balancing should be handled by whatever you are using for your service mesh, which could be kubernetes. Concurrency depends on what you mean. Load balancing does offer application concurrent stateless requests and the built in go http libraries have concurrent requests built in to them. However, if you're talking about some other kind of concurrent processing, you would write that yourself.
[removed]
Viper is really nice but it is overkill for many applications and adds significantly to the size of your app. 
Microservices come with a lot of infrastructure overhead. Unless you have a huge team, build a monolith :)
Heres a service I started somewhat following a DDD design pattern. It can run either gRPC or GraphQL [https://github.com/longfellowone/field-services](https://github.com/longfellowone/field-services) &amp;#x200B; Heres a simple working example project I made up for someone showing how everything fits together [https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c](https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c) [https://play.golang.org/p/5p28UL4thc\_r](https://play.golang.org/p/5p28UL4thc_r) &amp;#x200B; Folder structure something like |-- /cmd | |-- /svc | | `-- main.go `-- /blog |-- /http | `-- server.go |-- /postgres | |-- authors.go | `-- blogposts.go |-- /users | `-- service.go |-- /blogging | `-- service.go |-- blogposts.go `-- authors.go So with interfaces between the layers your dependencies would look something like Domain &lt;- Services &lt;- HTTP
[removed]
Survey is a great library if you're looking for form type of the input in CLI. https://github.com/AlecAivazis/survey
No need to close request bodies on the server-side; net/http knows when your handler exits, and can clean up at that time. On the client side, there's no such lifetime hint, and *that's* why you need to close Response.Body.
I know one: I think it works great as an extra attack surface üëå
Why the down voting?
So many different packages, for what purpose?
The programming world needs to separate technology-adjectives from moral/value/importance connotations, and furthermore separate those connotations from the value of a human being in life, the world, etc. Go concepts are OLD! VERY VERY old. Go brings nothing new to the table. So what? Was the criticism that "Go introduces bad coding?" or "Go encourages bugs?" or "Go projects tend to fail"? Secondly, why should ANYONE care even if the above were true? Remember these lessons when you think "picking a supposedly bad language" somehow reflects badly on you: 1. The world saw Smalltalk and took completely the wrong ideas out of it in the name of OOP (to the point where Alan Kay had to directly state that!) 2. The same world decided CORBA, UML, SOAP, WSDL, WS-\* were wonderful. 3. The same world wrote Wikipedia and Wordpress - written in PHP. Seriously go ask a developer what kind of moral value PHP has? So yes, Go has old concepts. Go's object oritentation is broken, and Go has no functional approach. It's okay to be okay with all those things. :-) It's okay to choose said language and still be a kind and wonderful human being who upholds human rights, helps the needy, is a good friend, etc.
go concurrency primitives will help you distribute workload across threads &amp; CPUs on one server. &amp;#x200B; Load-balancing will help distribute workload across multiple servers.
this test is not representative of any real world scenario you will encounter, so it's not a useful test to begin with. The playground is basically always deterministic, since time and randomness are both unchanging on the playground. I haven't had a chance to run your program locally and see if it exhibits the same behavior. 
It is actually called TUI, just saying.
no tests :(
It says ‚Äústop sending me messages‚Äù. Messages already sent may still arrive, so you are expected to drain the channel still. But no more will be sent to you from that queue. Canceling a long-running operation would need to be coordinated between you and whatever consumer is performing the operation. Probably you‚Äôd send a message. Maybe with priority.
I think the playground may have a hand in this. It has many constrains that do not apply on a real system. Try running it locally
`It's not clear to me how the Dial() method of the client is meant to work across multiple addresses.` We already have a connected client. Why just a single dial to a host from the client should close the client itself?
pretty cool. What would be really cool is if a go-jdbc binding could work with the Athena JDBC driver, as that supports streaming results back to the client, rather than having to write all the boilerplate code to poll the query execution status and download the file etc. I've seen this https://github.com/japettyjohn/go-jdbc but I'm not sure what the status of it is/whether it works. 
I guess what I would have to do is create two types ``` type MetricDistance uint64 // Since - distances don't make sense type ImperialDistance uint64 // Define constant Metric Lengths using a nanometer as the base unit // Define constany Imperial Lengths using a thou as a the base unit func (md MetricDistance) Value() uint64 { return uint64(md) } func (id ImperialDistance) Value() uint64 { return uint64(id) } // Instead of distance being a concrete type make it an interface type Distance interface { Value() uint64 } ``` I guess that would solve that problem and also solve the problem of the global since I could extend the interface to also include the String() function. And in a function like parse Duration, I guess the user would have to type assert the return value ? Or maybe have to Parse functions one for imperial and for metric? My initial reasoning for making the underlying type of distance a float64 because I wanted Metric and Imperial units to be used interchangeably and that would have required floating point math. But perhaps there's a better way. Thoughts? 
It's a matter of preference, on my projects, I use dep (old ones) / vgo (new ones) and keep the vendor at the repository. That way, the build/test is always reproducible, the CI runs faster, and you don't have external dependencies. Once the code is on your machine, is there, forever, always gonna work.
I was saying that based on not finding any examples of Client.Dial(addr,...) I don't understand what it is meant to do across multiple calls with multiple returned channels. I assumed that you were dialing more than one address with that call, so my question was why not Dial each unique host and store the host:conn in a map? Is this meant to be a listener or a client dialing servers? Yes I noticed it was meant to multiplex multiple communications to an address, but it wasn't clear if you were trying to multiplex across multiple servers. 
https://tip.golang.org/doc/go1.12#fmt Maps are only *printed* in sort order. Iteration is still non-deterministic. 
And I tend to use gvm to manage multiple concurrent installations. But we can do more to make it easy for newbies to access Go.
Awesome, thank you for that explanation. I'm new to Go, and network programming, in general. I am however working on a project that's a bit above my existing understanding (encrypted peer to peer chat system) and have been thinking that it might be a good idea to have the ability to spin off processes (threads/workers?) for the server functionality. The idea being that it can evaluate incoming traffic and determine which are real messages and which are riff-raff without bogging down the machine (reduce effectiveness of DoS attacks, and handle higher traffic gracefully). Do you think a worker pool would be an appropriate for my use case? 
This all depends on the type of system you are building. If you are creating a HTTP server, your app already handles concurrency: multiple request can be made by various clients at the same time. In this example it is common for you to have a seperate Load Balancer to distribute the load to multiple nodes/pods/containers in your system. However, there is another form of load balancing: client load balancing. In this setup each node/pod knows about the other nodes/pods (usually via service discovery) and can self-distributed the load if needed; this would be handled in your Go app. A good example here is using gRPC client load balancing. A service mesh (like Istio) would be help here.
Neverending goroutines, callbacks, _callbacks in other goroutines_, missing error checks, println in a goroutine while main time.Sleeps and hopes for the best. No thanks.
Good read, I just looked for a caffeine port to go a few days ago. It led me to https://github.com/dgryski/go-tinylfu 
None of my cache eviction algorithms have special handling concurrent access, which is one of their requirements. They did use my testing framework though.
I believe we can use twirp and gRPC in a monolithic way. My goal is to define the protobuf so I can get server and client codegen benefits.
the libraries list may be helpful if you are looking for console UI. [avelino/awesome-go - Github](https://github.com/avelino/awesome-go#advanced-console-uis) &amp;#x200B; Other sections of the page also could help to find some great go libraries. 
Cool. Do you have a lot of clients to implement?
You're getting into signal processing. That's very difficult stuff with a ton of mathematics behind it no matter which language you're using. Start off simple with something like this [knock detection article](https://medium.com/@almeidneto/sound-pattern-recognition-with-python-9aff69edce5d). Try rewriting it in Go with any audio library (mp3 conversion is really a separate problem) and see if you get any decent results.
You might trying looking into SoX: http://sox.sourceforge.net/Docs/Features If this is something that looks like it could work, then here is a Go interface: https://github.com/krig/go-sox Also check out: https://github.com/avelino/awesome-go#audio-and-music 
Well, to be fair, Debian does have packages for Go. I'm not sure why I'm being downvoted for providing the way that I install Go either, but /shrug. https://packages.debian.org/search?keywords=golang You can get all the way up to go 1.12. The biggest issue for most users is that by default the release version of Debian or any OS isn't going to have the most recent version of Go. Go updates pretty frequently and these distributions lock the packages for a given release. So you need to be running Debian Testing (which is what I use) or Debian Unstable to get bleeding edge packages. 
Ah damn, I should‚Äôve read more carefully. Thanks for letting me know. 
I was taught C++ in high school, and they never explained C strings to us. I had to learn about null termination on the streets. 
JS or http for web, and Ruby clients. Go for the server side. But twirp ruby doesn‚Äôt seem to be actively maintained
Hey kid. You want some of that buffer overflow? I‚Äôve got exploits that will take you places you‚Äôve only dreamed about.
Use FFT to split the signal into frequencies. 
Thank you I'll check it out. I figured it would be difficult. Was hoping for something off the shelf my b Google Fu missed.
Do you have a link you could share?
That sounds promising. I'll check it out! Thank you
This all depends. At ingress, you can use many things to distribute the load, from external balancers to internal kubernetes. I personally prefer using a NodePort with an external access policy of the node. Basically, the Node only exports the port if the pod is on the Node so it‚Äôs not redistributing it around the cluster in kubernetes. Inside kubernetes, I use gRPC with a simple round robin policy, then I use a dns:// url for the gRPC server. (Eg, dns://mygrpcserver:1234) and ensure dns returns all of the hosts. I don‚Äôt recall the setting. If you are running a HTTP/REST api, simply using the standard DNS name will reconnect for each request and it works nicely. 
*forehead smack* the one time i look it up as ‚Äúgo‚Äù instead of ‚Äúgolang‚Äù, that‚Äôs why i missed em. thank you for posting
dope
Glad I could help :)
This looks promising https://github.com/mjibson/go-dsp
Great article as usual from the Dgraph team!
To avoid mutex locks I usually have map in a single goroutine that I interact with one single channel input. It reads read or write command from channel and performs operation returning channel with response. That might be slower than mutex but it works almost exactly like redis and should provide less blockage. It doesn‚Äôt do a write on read. But to be fair I didn‚Äôt do super tight performance benchmark so I could be in total wrong on this one.
Accepting interfaces as arguments is all the dependency injection I need. 
I'm not so sure it should be better. A channel still uses a mutex internally, so it might not provide any benefits in terms of contention.
You are right, I‚Äôm pondering just performance difference. For me the isolation is better this way. Maybe cpu utilization with multi core cpu. But this is all conditional as epic DI is also not always fun.
It‚Äôs for tunneling TCP over an SSH connection. You can dial any host that the SSH server has connectivity to but you might not, and the connection is tunneled via the SSH server. 
I don't use much SQL so I'm not versed in the specifics for your application, but is it possible to make a common interface that Animal would fall under? It's too difficult for me to say without another example or two. Using interfaces is there closest way of handling generics in Go. Also as a general comment, having a package called AnimalDAO seems very specific. Just by the looks of it, my impression is that the package should be "dao" with AnimalDAO as some kind of struct or function
Thanks for clarifying! 
&gt; I personally prefer using a NodePort with an external access policy of the node. Basically, the Node only exports the port if the pod is on the Node so it‚Äôs not redistributing it around the cluster in kubernetes. Can you tell what the proxy part is in https://www.asykim.com/blog/deep-dive-into-kubernetes-external-traffic-policies ? Is this a certain container running on on every node? Or us Kubernetes managing the proxy and routing traffic to said port only to the nodes exposing the NodePort by looking at the ports specified in the deployment? Do you use dns for externally connecting clients too, if so how do you set that up? Networking in Kubernetes still eludes me.
Thanks!
Go playground has its random generator fixed. You cannot use playground to observe "random-ness".
I thought go was a way to spawn a thread. In other languages it is not the same thing. You use go-to to jump to a section of code sometimes breaking out of loops. Doesn't seem the same to me. 
&gt;more generic Haha, nice one. &amp;#x200B; Anyway, create struct with pointer to pool db connections to eliminate this GetDatabase call everytime and set methods like yours "FindAll" to it. I don't use gorm myself (and advising not to until you know that you really need to), but expected some utility methods. Create another struct on repository level with those funcs and embed it when you need it. &amp;#x200B; Also use dependency injection for dependencies and never use global state. Global state is evil and destroys your soul eventually.
Previously: https://www.reddit.com/r/golang/comments/8eu2av/notes_on_structured_concurrency_or_go_statement/
The issue is not what it does, but how it does.
Lol :D thanks sorry for necro. Gonna close
In which sense are you referring to isolation? AFAIK your cache type would expose a Get/Set(/Del) method. For the outside world there's no real difference concerning channels or mutexes used internally. In my opinion a mutex makes the flow of actions more direct, so those are preferable. You see a function call and you see exactly what it does: lock, store, unlock. If you use a channel, you need to forward to the go-routine that handles messages on that channel. Makes your code harder to understand. The Go wiki feels the same way: https://github.com/golang/go/wiki/MutexOrChannel
the querystring is not a route, you can access the values from the request using r.FormValue("from") and r.FormValue("to").
Hi Thanks a lot, seems I missed that point even when I have been reading a lot. I am trying to follow your recommendation but stopped with it... I have defined this in my main method: // Define just one transport for all calls tr := &amp;http.Transport{ //MaxIdleConns: 500, //MaxIdleConnsPerHost: 500, } And then use it in the handler call router.HandleFunc("/echo/{message}", echoHandler(calledServiceURL, tr)).Methods("GET") But when I try to define the handler as this: func echoHandler(calledServiceURL string, tr *Transport) func(w http.ResponseWriter, r *http.Request) { return func(w http.ResponseWriter, r *http.Request) { I can¬¥t compile because an error saying that Transport is an unrecognized type. As far as I understand tr is receiving a pointer to a Transport type. Isn¬¥t it? I am totally new with golang and sometimes get confused with pointers and sintaxis. Thanks in advance J
Wth is D.I? Wikipedia article made 0 sense. Sounded like something I don't need to worry about, like putting handles/names on things that don't matter
Actually I'm working on a HTTP proxy which takes the request, hijacks the writer side of the connection, rewrite the request in wire format to the conn returned by Client.Dial() and pipe it to hijacked writer. A map I guess wouldn't help in my case because requests are ephemeral.
Not sure how that addresses the problems DI is intended to solve. On the side note: [https://blog.golang.org/wire](https://blog.golang.org/wire)
I, a professional Minecraft Linguist, have found some errors in your comment and have recrafted it. &gt;not sure how that addresses the problems di is intended to solve. &gt; &gt;on the side note: [https://blog.golang.org/redstone](https://blog.golang.org/redstone)
This makes for better code readability in some cases, but there‚Äôs no performance benefit. 
For mp3, there is a native decoder here https://github.com/hajimehoshi/go-mp3 . To identify beep is difficult, you can check how shazam works to get a picture http://coding-geek.com/how-shazam-works/ .
How does it differ to existing solutions like: https://github.com/Knetic/govaluate
Well, I have solved this by myself by passing the client instead of transport as an http.Client pointer. &amp;#x200B; J
Little simpler, with focus on learning rather than using.
Why are you posting an archived, unmaintained project?
Well, I have applied the changes but the application now stopped working after 3000 requests with an i/o error. I have defined the transport and the client in the main func. `// Define just one transport for all calls` `tr := &amp;http.Transport{` `//MaxIdleConns: 500,` `MaxIdleConnsPerHost: 100,` `DisableKeepAlives: true,` `}` `netClient := &amp;http.Client{Transport: tr}` And passing the parameters for the handler: `router.HandleFunc("/echo/{message}", echoHandler(calledServiceURL, netClient)).Methods("GET")` &amp;#x200B; And the handler definition. &amp;#x200B; `func echoHandler(calledServiceURL string, netClient *http.Client) func(w http.ResponseWriter, r *http.Request) {` `return func(w http.ResponseWriter, r *http.Request) {` &amp;#x200B; I am wondering how to properly set the client or transport parameters to prevent the app to get stopped due to i/o errors. &amp;#x200B;
&gt; However, for a language built around concurrency, it still lacks an ecosystem of performant, concurrent libraries which can scale well to the number of cores. A concurrent list or map[1](https://blog.dgraph.io/post/caching-in-go/#fn:1) is largely left as an exercise to the end-user‚Äîwhich would be just fine if this was a serially-executing language‚Äîbut feels like a glaring omission when everything is built around concurrency. And that, in a nutshell, is why I'm strongly pro-generics. The Go data structure landscape is one of the worst things about the language. Slices and maps are not always enough.
Use code generation. https://github.com/spacemonkeygo/dbx/ is an ORM which generates code based on a definition of the database.
As others have said, audio processing can be challenging. If you are able to provide more detail we might be able to give more specific advice. What's in the audio file (speech, music, environmental noise; generated or natural)? Is it "controlled" audio in that you can expect the content to always be at the same average amplitude and that the content is clearly distinct from the beep? Is the beep consistent - same frequency, duration, and amplitude? If you are very lucky, it may be that the beep amplitude is significantly greater than the content amplitude. In that (unusual) case you could pick out the beep just be looking at amplitude. In the more general (and typically more likely) case distinguishing the beep can be much more complex. An FFT is likely the best tool for the job, but there are many more details to consider. You can't simply dump the entire audio file into an FFT and "find" a beep. You will need to slice the audio file up into "short windows" and analyze each window separately. How short is short? It depends. What is the frequency of the beep you are looking for, what else is happening in the audio? Very short windows may introduce a lot of false positives. Very long windows make it difficult to pinpoint the exact location of the beep (darn that Heisenberg!). You will likely need a large sample of typical audio files to use during development. Then you can play with different options and "tune" the system. If you are lucky, the process will be quick, easy, and accurate. If you are not lucky, there may not be a 100% reliable solution. Post as much detail as possible and we will see if we can guess where on that spectrum your problem lies. Audio processing can be frustrating but can also be a lot of fun. Good luck!
For clarification, FFT's aren't the only way to solve the problem, but they frequently represent a good trade-off between functionality, implementation effort, and efficiency. One counter example would be to apply a notch filter tuned to pass only the beep frequency, then the problem again becomes one of thresholding on amplitude. It works well in some cases, not at all in others. And the trade-off in terms of implementation effort and run-time efficiency are not at all clear.
I have a few sad pieces of information for you, it's actually way easier than you're making it. 1. In general, you can just use `string()` to encode a bytes into a string. ``` db.Query("INSERT INTO authentication (token\_id) VALUES(?)", string(jwtId)) ``` 2. In this case though, `ksuid` has a `String` function that generates a string for you directly, you don't even need to go through bytes: ``` PersistInDatabase(jwtId.String()) ```
Thanks ! I don't know how I didn't see the String() method in the docs....
That's fascinating thank you!
I'm downloading outgoing messages from voicemail systems. I want to truncate the audio at the beep which should be in an ANSI defined range per an RFC I need to look up. 
In general, channel has locking, just like mutexes do. But, the benefit might be in "when and where" are these locks acquired. There could be benefit in having a channel which can avoid converting LRU/LRU reads into writes when they're a cache hit. So, a read which can be serviced by the cache can just write to channel and move on. Then, something in the background can pick up the channel, and update the elements in the algo for positioning in the LRU/LFU cache. &amp;#x200B; Caffeine's underlying design uses a similar technique. It is based on a paper called BP-Wrapper, which can make any algorithm contention free by batching up multiple access, which would typically be individual writes into LRU algo, into a few writes. See [paper](https://drive.google.com/file/d/0B8oWjCpZGTn3YVhCc2dZSU5DNFBJRlBZa0s1STdaUWR5emxj/view?usp=sharing).
If anyone wants more resources, I just did this same thing and went around and collected a bunch of caching libraries and benchmarked them so I could pick one that worked for my load: [https://github.com/Xeoncross/go-cache-benchmark](https://github.com/Xeoncross/go-cache-benchmark) * [https://golang.org/pkg/sync/#Map](https://golang.org/pkg/sync/#Map) * [https://github.com/coocood/freecache](https://github.com/coocood/freecache) * [https://github.com/allegro/bigcache](https://github.com/allegro/bigcache) * [https://github.com/patrickmn/go-cache](https://github.com/patrickmn/go-cache) * [https://github.com/muesli/cache2go](https://github.com/muesli/cache2go) * [https://github.com/bluele/gcache](https://github.com/bluele/gcache) (\_I did not benchmark groupcache due to the single-instance use-case I had\_)
Look at every one of the OP's posts; they're all "&lt;repo name&gt;: &lt;repo description&gt;", pulled straight from GitHub.
I got the impression you were looking for a way to handle multiple CLI inputs like --a somevalue --b anothervalue and so on, so that you could have a single CLI that takes in a variety of parameters? The TUI stuff looks a lot more advanced.. e.g. multiple options, screens, etc. 
Thanks for the feedback! Yep that's pretty much it. I setup a Cron job using the cron GO package to schedule the execution at 5:30 am. Using GO to render all the images and then using FFMPEG by calling a cmd from GO. There's 2 text files saved to disk (didn't feel like using a database just yet) to handle the history. One for the video ID's and one for all the past moves. This was a super fun project and I'm already starting work on the next version!
&gt;https://github.com/Xeoncross/go-cache-benchmark \`GCache\` seems to be impressive 
I like to think of it as _schedule the work, not the thread_. If you can reduce the scheduling overhead and build in the right overflow semantics, then you get better performance with a simpler mental model.
The readme file can explain more about what's going on. On the other had, https://github.com/golang/go/wiki/Modules is a thin book. Is there something between the zero readme of that repo and the thin book of that wiki that explains modules?
You can do everything via UI, CLI OR via files in yaml inside your repository (or not) https://ovh.github.io/cds/workflows/files/
From an educational perspective, you don't understand encodings at all. The hex package does hexadecimal encoding not UTF8. UTF8 is used to encode Unicode code points (text) to binary data. What you're doing (trying to do) is encoding binary data as ASCII printable characters. I suggest reading http://kunststube.net/encoding/ to learn about encoding.
Someone needs a ban. 
https://vyskocilm.github.io/blog/implement-sql-database-driver-in-100-lines-of-go/
I already saw that one, that doesn't connect to a DB...
Did you know that Protobuf comes with JSON marshal/unmarshal ability right out of the box using the same .proto file generated code? https://godoc.org/github.com/golang/protobuf/jsonpb
Is it a bot, or just an attention whore that isn't very bright.
There are a only a few methods you need for the interface. The rest of the driver will be the network protocol you need to implement to talk to the remote server.
I wanted to find something to help me with exactly that
Then I'd look into implementing network protocols. Something like https://youtu.be/pUaFW98V1Sc or other networking tutorials.
Do you have a specific DB in mind? For SQLite you do C-FFI for most other sql-dbs you have a client-server protocol to implement. This is language agnostic so you are better of asking the question in the relevant db specific forums or even better just read the documentation and faq. For MariaDB you find the protocol documentation here https://mariadb.com/kb/en/library/clientserver-protocol/ (MySQL should be more or less the same).
PostgreSQL, it should have documentation like this too, I am going to look for it, thanks! Seeing your response and /u/dgryski I start understanding that what I am looking is a network protocol and I need to create one, thanks for the help
Not sure that it matters either way. It‚Äôs spam. :p
Ok, I've created a simple example: [https://github.com/rwarford/tone-detect](https://github.com/rwarford/tone-detect). It's far from perfect and care needs to be taken when changing the FFT size. The example sets the FFT size based on the audio sample rate which may not be ideal. Changing the FFT size changes the width of each FFT bin (a.k.a., spectral line). I chose a completely arbitrary tone-detection threshold. It works on the few examples I created but I haven't put any thought into making that a reasonable value. Nor have I attempted to filter out false positives. At a minimum you should check the duration of the tone and ignore very short tones as they are likely false positives. You may also find that you have to smooth over small gaps in tones that might be caused by noise in the recordings. It's easy to fool yourself when working with audio - everything may work perfectly when testing and then fall apart in production due to some unexpected variance in the audio. Use as many actual production audio samples as possible for testing. Kudos to hajimehoshi and mjibson for their libraries that I used. I have no affiliation nor I have vetted the libraries in any way. If you really care about performance look into FFTW - it is the Fastest FFT in the West (and just about anywhere else). It's written in C but you can find a cgo wrapper if you look. Good luck and have fun.
You probably need the package name before the interface: net.Conn
That did it thanks!
At compile or runtime? You need to prefix it with the package name, for one. 
I really like [tview](https://github.com/rivo/tview). It's higher level than termbox with widgets/components.
Check https://github.com/avelino/awesome-go Usual driver for postgres is lib/pq You can use arrays and postgres specific things with it, and connect / query with parameters ofc
What is wrong with the existing PostgreSQL drivers?
Dude can I send you can instead of gold for helping me? I fucking love you. 
&gt;Don't create a bug hole that took time with no added value, use a well tested driver Unless it's educational/experimental I am doing a project on my own with the main objective of learning, and don't wanna use third party libraries 
Good luck with learning! I always enjoyed implementing protocols.
Your love is sufficient. :-)
Nothing at all, I wanted to make a project without external libraries or see where I can go without them This makes me learn new things, like a network protocol, never did this and always wanted to give a try building a network package, this is will be perfect for me to learn
How to write a compiler: 1. Download a compiler 2. Draw the rest of the fucking owl
I'd be interested to have a look at the code (obviously) :) I thought about doing something like this, but ultimately I already have a Wacom tablet, so wouldn't get much mileage out of this. I do kinda sorta maybe intend to at some point replace xochitl though, which would pretty much require solving the same problems. :)
Yes sure, will make public, yeah I'm already thinking about replacing xochitl myself, I've done some work with qml and go before and am looking into using it to build an app to replace it. Should be pretty straight forward
I found that specific sentence a bit‚Ä¶ strange. The only way in which "everything is built around concurrency" is that Go inherits from CSP. And the S stands for "sequential". i.e. Go is specifically *not* built for this kind of shared-memory stuff (though TBQH it's not particularly amazing as a CSP implementation either). Now, mind you, I'm not saying sharing memory is bad - I do it all the time. Just that making this specific point seems weird to me. If you want a language that's actually built around concurrency *like this*, I'd point at Rust. For example, races are impossible there, but they aren't in Go.
Well I give you a lot of credit. You definitely went down the hard road many people looked down and thought many negative things. It's too new, it's too slow, it's hard to redo what jQuery did, ect Good to see someone didn't care and just went straight for it.
In addition to what u/ericzhill has mentioned, you might also want to take a look at Twirp. https://github.com/twitchtv/twirp/blob/master/README.md
I don't enjoy reading critiques that don't provide examples. It just states the pro/con opinions without anything backing it up either way. It reads more like a list of assumptions. I stopped reading shortly after the contradiction where in a pro it touted Go having a dependency manager, and then in a con dinged Go for not being able to express versions of imported dependencies. I didn't read past the strange "automation" section that claimed the GC would cause unexpected errors in the middle of a server request. 
IMO Github should just intelligently pull from godoc.org (or use go doc) if a repo doesn't have a README.
I would personally accept function to do the search in my `Findall method, So (s *Store) FindAll(finder func() SomeResultInterface) []SomeResultInterface` but another possible solution to your problem could be a big switch statement, something along the lines of, &amp;#x200B; *\`\`\`type* Entity *interface* { ID() string } *type* EntityDao *struct* { db \*SomeDB } *func* (e \*EntityDao) FindAll(kind *interface*{}) \[\]Entity { *switch* c := kind.(*type*) { *case* Animal: *var* results \[\]Animal e.db.find(&amp;results) } }\`\`\` 
If you don't mind... why did you decide the reMarkable wasn't for you? It's not inexpensive, so reviews and personal annecdotes are appreciated.
I was going to link to that. It sounds rude, but if you‚Äôre asking the questions OP is asking, it sounds like you don‚Äôt know what UTF-8 is yet, so you should read the link. It‚Äôs a classic of programming. 
I use [https://goswagger.io/](https://goswagger.io/) to generate a swagger.json document from code comments. I then use swagger-codegen to generate html documentation. The comments it requires are pretty verbose to add, but it gets easier over time. swagger-codegen is a giant pile of crap for static html documentation. If you don't like it you can just use the swagger.json thats outputted from go-swagger to feed into the swagger UI ([https://swagger.io/tools/swagger-ui/](https://swagger.io/tools/swagger-ui/))
I want this to succeed so bad. Godspeed.
yes! I use my reMarkable quite a bit. Would love to see how you play with it
Go is still lacking per-processor storage, making it hard to shard caches by processors.
Doesn‚Äôt this mean you‚Äôre giving a 3rd party write access to your repository? That sounds like a terrible idea!
Others stated how to convert to string. But as others said, your post demonstrates a lack of understanding about what string encoding is. Please read this: https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/ Then please pass it around to literally every software developer (current or aspiring) you know. The more people read this the better!
What am I looking at here? I'm trying to understand, but I think I'm not getting what the readme is trying to tell me
I haven‚Äôt looked at the required permissions, but the description indicates you will get PRs with updated readme files. That wouldn‚Äôt require write access. 
I fell into this trap and had to claw my way out. Things I learned: - move as much data manipulation into the database as I can. The client never wants a list of all the Animals. Getting all the animals from the database into the code (and all the related data held in other tables), and then doing something with them to return the actual data that the client needs, is a waste of resources. Create a sql function that does all the data manipulation and returns the exact data that the client wants, and then stream that through the code base (though handling arrays of custom types through database/sql and pq is ... fun). - the client has a different view on the data than the server. Adding objects to the database demands different data structures than pushing data to the client. e.g. the database just needs a user_id uuid value for all interactions, but your client doesn't care about the user's ID, it needs to show the name. Creating a single set of generic DAO objects will create way more work than creating specific retrieval and upsert functions, both for you to write the code, and for the database to shovel back all that un-needed data to the server. - think of the server api as providing a set of commands, rather than a generic interface to the data. So to add a new user, the client makes a call to the "create new user" command, passing the parameters it needs, and receives a result of the new user's data model. Then you can choose in the server whether to write insert queries in your Go code, or pass the same parameters to a sql function to create the data entries (I opted for the sql function, it seems to be working well so far). This is kinda similar to "event streaming" - the server receives a stream of events from the client and responds with data. Hope this helps. 
It seems to be a web UI framework like React or Vue in Go WASM.
Oooh. I get it now. That'd be so huge to have.
Here's an interesting read that may help you: http://marcio.io/2015/07/handling-1-million-requests-per-minute-with-golang/ Basically, you could just range over a chan chan &lt;struct&gt;.
You might not have your GOPATH set up. Make you you get-install golang aside from downloading go initially
What you think about this one &amp;#x200B; `package main` `import (` `"fmt"` `"time"` `)` `var subs = make(map[string] []chan string)` `func publish(topic string, data string) {` `go func() {` `if chans, found := subs[topic]; found {` `for _, ch := range chans {` `ch &lt;- data` `}` `}` `}()` `}` `func main() {` `ch := make(chan string)` `ch2 := make(chan string)` `subs["simple"] = append(subs["simple"], ch)` `subs["simple"] = append(subs["simple"], ch2)` `go func() {` `time.Sleep(1 * time.Second)` `publish("simple", "its so simple")` `}()` `fmt.Println(&lt;-ch)` `fmt.Println(&lt;-ch2)` `}` 
Out of topic question! If you write your go program with manuel garbage collection, does it needs runtime when compiled to wasm?
Without any code at all it's a wee bit hard to tell where your problem is. In the code below I used *"*[*gopkg.in/gomail.v2*](https://gopkg.in/gomail.v2)" and a mail address from gmail. m := gomail.NewMessage() m.SetHeader("From", sender) m.SetHeader("To", *receiver...) if len(*cc) &gt; 0 { ccs := []string{} for _, c := range *cc { ccs = append(ccs, m.FormatAddress(c, "")) } m.SetHeader("Cc", ccs...) } m.SetHeader("Subject", *subject) m.SetBody("text/html", *message) if len(*attachments) &gt; 0 { for _, a := range *attachments { m.Attach(a) } } d := gomail.NewDialer(config.SMTPServer, config.Port, config.Sender, config.Password) if err := d.DialAndSend(m); err != nil { log.Panic(err) } else { log.Info("Mail sent!") } &amp;#x200B;
I think webassembly can‚Äôt beat react. Maybe something that will compile to react with all bindings open for react libs can be useful. I like react and I don‚Äôt know if anything can make me move from it. But it took me some time to learn react.
What you describe is not a feature of go but a weakness, and this is why many people strive to contribute and improve the language
Have a look at the NATS bus. It‚Äôs written in Go and pretty much ticks all your boxes. Did a project with it recently (including the streaming add on) and was pleasantly surprised. 
Again, let me be clear, I'm not trying to say that I necessarily *like* CSP or that Go's concurrency model is thus very good. I'm just saying that a) "Go is built for concurrency" and b) "Go not having good shared-memory datastructures is a glaring omission" don't belong in the same sentence. *If* Go is built for concurrency, that model of concurrency doesn't include sharing memory. If you don't like CSP, then Go isn't actually built for concurrency in your book.
Depends on what you need, but you can grab it as easy as this: ``` args := os.Args\[1:\] mainArg := args\[0\] fmt.Println("mainArg:", mainArg) ```
Check deferrable constraints, they might be what you need.
I like the general idea of that implementation. Just a few pointers (that you probably know as this is just for showing the concept) I would wrap this into a struct, so you could have multiple busses amd avoid global state. Also i would add a (un)subscribe function instead of directly altering the map. Then there should probably be locking in all the methods to prevent race conditions. 
Nats is really nice, but i think he does not need a network message bus, just one internal to his program.
&gt;deferrable constraints That looks pretty good. This also gave me the idea to just do an ugly for loop in my Go code to try each command until all complete, and check for the number of failures. As this is just in an \`init\` block, it shouldn't cause any problem. Thanks!
yeah it was actually a quick prototype. I developed it further into this &amp;#x200B; package main import ( "fmt" "math/rand" "sync" "time" ) type Data struct { data interface{} topic string } type ChannelSlice []chan Data type EventBus struct { subscribers map[string] ChannelSlice rm sync.RWMutex } func (eb *EventBus)publish(topic string, data interface{}) { eb.rm.RLock() if ch, found := eb.subscribers[topic]; found { go _boradcastEvent(Data{data: data, topic:topic}, ch) } eb.rm.RUnlock() } func _boradcastEvent(data Data, sl ChannelSlice) { for _, ch := range sl { ch &lt;- data } } func (eb *EventBus)subscribe(topic string, ch chan Data) { eb.rm.Lock() if prev, found := eb.subscribers[topic]; found { eb.subscribers[topic] = append(prev, ch) } else { eb.subscribers[topic] = append([] chan Data{}, ch) } eb.rm.Unlock() } var eb = &amp;EventBus{ subscribers: map[string]ChannelSlice{}, } func printData(ch string, data Data) { fmt.Printf("Channel: %s; Topic: %s; Data: %v\n", ch, data.topic, data.data) } func publisTo(topic string, data string) { for { eb.publish(topic, data) time.Sleep(time.Duration(rand.Intn(1000)) * time.Millisecond) } } func main() { ch1 := make(chan Data) ch2 := make(chan Data) ch3 := make(chan Data) eb.subscribe("topic1", ch1) eb.subscribe("topic2", ch2) eb.subscribe("topic2", ch3) go publisTo("topic1", "Hi topic 1") go publisTo("topic2", "Welcome to topic 2") for { select { case d := &lt;-ch1: go printData("ch1", d) case d := &lt;-ch2: go printData("ch2", d) case d := &lt;-ch3: go printData("ch3", d) } } } &amp;#x200B;
Yes, i actually intend to use an internal message bus for my system
dup' of https://www.reddit.com/r/golang/comments/aypvwi/pure_go_to_llvm_toy_compiler/ :)
Ok I'm traveling a lot for work this week, so let me tidy up a bit and I'll share code
Good question. It really is designed as a paper replacement, but for me, paper is so ephemeral, that's almost the beauty. When I need to get a thought down, pen and paper is just the best. I just found myself turning to open and paper first. It's purely subjective. However the ability to share what I was drawing/scribbling, does have some amazing use cases and the tablet itself doesn't come with this as a primary feature. The syncing feature wasn't doing it for me really. I still like the device, I much prefer to scribble on it that an iPad, is so light which is amazing and not having to charge the pen is fantastic. I just would see different use cases for it
&gt; is build in Assembly and C++ Go compiler and runtime are implemented in Go since 1.5
Oh, I didn't know it, thanks for letting me know.
You mention that := is syntactic sugar, when := is to assign/declare within a function scope. In essence it isn‚Äôt sugar but a whole different operator. 
[https://tour.golang.org/welcome/1](https://tour.golang.org/welcome/1)
Are you sure you properly installed Go as per the windows instructions? https://golang.org/doc/install#windows It seems like you missed something. 
I will specify that I have covered all the basics from ghe tour, a book and a video course. Just need to get experience by applying the basics and hence my question, thanks
...Did you write a 6000 word article without researching the topics of the article?
I've researched a lot but maybe some of my search results were outdated
You can set a goal and start writing code. Or use services like [https://www.hackerrank.com](https://www.hackerrank.com). There you will be assigned tasks that you will need to perform in the programming language you need.
Considering most of it seems to be wordier versions of the [Go tour](tour.golang.org) with some historical preamble lifted from Wikipedia, I'm confused as to how you managed that...
Good read 
Looks like you have to suck it up if you end up being interviewed by someone that wants you to do hackerrank exam. It's just an arbitrary bar someone raised to weed out people like you. it's nothing personal, it's just an arbitrary metric someone chose to judge you. 
Thanks for that!
What frameworks do you know? Make a list. Post it here. So, we will tell you what is THE BEST.
That's a real good project. But I would reckon be more focused on accuracy and security instead of just providing a cheaper alternative. As a matter of fact there are lots of free alternative as well. &amp;#x200B; While verifying their email database through third party vendors, email marketers and organisations looks of a secured alternative instead of the cheapest one. &amp;#x200B; ZeroBounce cost $40/5000 email verification (not the cheapest one) still have 23500+ active accounts with its military grade encryption and 24\*7\*365 customer support via live chat.
Gin, Iris, beeGo
Since it's open source, I'd let people judge the quality of the project
The article recommends Iris which i wouldn't recommend to anyone. It has such a bad, shady history from stolen commits, not upholding licenses, star botting, rewriting history etc etc
My framework of choice is go-chi. It follows the stdlib API for the most part which is always very nice and it has very easy middleware support
If you develop on Ubuntu. You can try with my config: &amp;#x200B; export GOROOT=/usr/local/go export GOPATH=\~/go export GOBIN=${GOPATH}/bin export PATH=${PATH}:/usr/local/bin:${GOROOT}/bin:${GOBIN}
Go was never written in C++. There used to be C though.
Wow! I didn't know about this. Can you give me a link? And I would advise the author of the GIN... In this case.
https://github.com/avelino/awesome-go/pull/1137 http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html?m=1 Heres two for a start. Theres also a quora questions that the author of go iris replied to. The way he talks and goes around with the sense of ego really says a lot. "Fastest web framework on THIS planet" is quite a bold statement when the most popular benchmark list wont accept him
there are some in this link: [https://github.com/avelino/awesome-go#server-applications](https://github.com/avelino/awesome-go#server-applications)
Seems Reasonable. Thanks.
That's a nice post 
The package management section is outdated: &gt; Dep isn‚Äôt in the core yet, but it‚Äôs widely used and I think the recommended method to do dependency management in go today. It‚Äôs from the Go authors and is called an ‚Äúofficial experiment‚Äù. 
go get -d ./... go build -o main \*.go ./main
hi, now the master branch of nutsdb has supports persistence , i have use sync function in [my code](https://github.com/xujiajun/nutsdb/blob/master/tx.go#L164) to ensure durability and update the benchmark, i choose some kvstore for comparisonÔºå visit [https://github.com/xujiajun/nutsdb#benchmarks](https://github.com/xujiajun/nutsdb#benchmarks) for detail. 
Your start was pretty good. root is now the value of a config struct. Now you have to get to the Recources filed you can do this by name or by index. You access it with Field(idx) or FieldByName(name). You can check if you had success by comparing the result to the zero value of Value or skip this but it may panic executing the next step. Now you iterate over the slice values (you get the slice length by the Len method and index it using the Index method). The result will be a Recourse struct so you now access the SourceFile filed (again FieldByName or Field and potentially a check). Lastly you can now set the Value with Set or SetString and you are done.
[removed]
You can definitely write your own test suite package that generates api documentation from executable tests. I‚Äôve done this twice before (sorry, no public Go packages at this point). The big win here is that if your documentation is wrong, a test will fail. Also, documenting the response is simple, you just capture the output. 
Looks really interesting! I would love to see this mature
Standard Library has everything you need.
It took me a long time to learn so there can't be anything better üòÖ That's adorable.
Don't you need CGO to free memory manually?
That's not how that works. You're comparing apples and... cherry pie. This comment makes no sense. React is framework made in javascript. WASM is not a UI framework. It is a compilation architecture target for various languages so compiled binaries can be run in the browser. You could convert the entirety of React to typescript and compile it to WASM. This is simply an attempt at a React-like front-end framework in Go compiled to WASM.
It is a competitive coding platform, it is totally free to practise
Very cool, I look forward to seeing your next version also! And now I know there's a cron package for Go, I'll check that out!
IMO: Accepting the `plugin` package was a mistake in the first place - especially in the state it was in. It was predictable, that it would end up in a Linux-only state with even that working poorly. And FTR: If the Go developers give you a reason it's not that simple, then you should assume that it "makes sense" :) They wouldn't lie and I think you've discovered by now that the problem isn't as straight forward as it seems. I don't know enough about Windows to tell you anything meaningful about if `plugin` will be available on Windows or why not. But I *can* make the recommendation that no matter what, you should just implement plugins as sub-processes if you need them. It's simply superior. You can still share memory (any operating system I know of offers a way for processes to share memory) - but meanwhile, because it's a separate process, the plugin can't take down your main process and it can be safely unloaded (e.g. for upgrades) by killing the child process.
I'm rooting for Coco and [Vecty](https://github.com/gopherjs/vecty) to gain more traction.
Yes, it has more allocs on set, but the overall speed seems to be the best for the load I used.
My experience is: It's not worth the price. A collection of issues I'm having in no particular order: * Using a third-party pen with a button will horribly confuse the UI if pressed - to the point where the pen tip and where the line appears are off by 2cm or so. * Given that the UI doesn't support buttons (the default stylus doesn't have any), accessing more than one tool becomes super inconvenient. This is super frustrating for me when I need to erase things - you have to expand the menu (1 tap), select the eraser tool (2 taps), erase things, select the pen tool again (1 tap), minimize the menu so it doesn't get in the way (1 tap). That's 5 separate taps that would be obsolete if I could just assign the button of my stylus to be the eraser tool. * The boot time is‚Ä¶ long. Like, several minutes. Which wouldn't be that bad (my phone's boot time is bad too), if not for: * The battery time is too small - you either have to charge it at least once a day *or* disable the auto-poweroff, so it only goes to sleep. i.e. you get to choose between a) bad battery life, or b) having to wait several minutes whenever you want to take notes. * The eBook app doesn't save progress regularly, so if your device runs out of battery (see above), the progress gets reset to *somewhere*. * If you change font-settings, that's not persisted well either and positions in the book are not relative to where in the text you are, but what rendered page you're on. That means, if you change font-settings, read half the book, then the device dies, you end in a situation where the font-settings are back at default - and if you change them, you end up on some random page. * Speaking of font-settings: Your preferences aren't saved, so you have to input them for every eBook afresh. It's a minor inconvenience, yes, but one that I wouldn't expect from a ~$800 device. * The notes-app lacks several features that I find baffling. E.g. there's no copy/paste and you can't insert new pages into the middle of an existing notebook. These, to me, are pretty much the main features that set it apart from paper notebooks (except the functionally infinite storage of course) and yet they are just not there. * A bunch of functions of the device are slooooooow. I have quite a large eBook right now (several thousand rendered pages). It takes ~5m to open and another ~5m to load the table of contents (to be fair: Once I start reading, flipping through it works okay). * The cloud integration lacks any Linux support. I don't understand why I can't access cloud functions via the web. Instead, I have to connect it over USB and use their on-device web interface. Which is super slow - downloading a 10 page PDF from it took‚Ä¶ I really don't know. 5-10m. The web interface is single-threaded, so when you want to do multiple things, you can basically have a coffee between each (there are open source tools you can use to upload files, but they literally just proxy to the on-device web interface, because xochitl uses a non-plain storage format, with prerendered images and things). * The PDF reader pre-renders all pages, AFAIK. This has the advantage that they only need to render once - it has the disadvantage that it takes a lot of storage and that it takes *looooooooooong* to upload a file to it. I think that's all I can think of xD Now, this reads like a long hateful rant of reMarkable - but to clarify, I actually *love* the device. I carry it around with me at all times and for me, it has completely fulfilled the promises of replacing paper notebooks and my kindle (the latter with some frustration). But two huge reasons for that are a) I had loads of disposable income, so the price-tag didn't matter and b) I love the fact that you get a root-shell and I can thus tinker with the device and fix at least some of the things that annoy me (though if they would open-source xochitl I could try and fix all of them, probably). But if the money matters and if you just want a device that makes you productive‚Ä¶ Honestly, the reMarkable is just not worth it.
this. Learn the standard library and it will be there for every project. Go frameworks tend to be used by devs coming from other languages (because they don't understand how much better Go's standard library is) and then discarded once people get up to speed on Go. 
build the database, then dump it out to a schema-only .sql file My makefile task: database: pg_dump -U version3 -d $(DEVDBNAME) -O -x -s &gt; deployment/sql/schema.sql you can then play that sql file against a blank database. 
You can look through many of them here: https://awesome-go.com/#web-frameworks Some are basic Express.js/Flask/Codeigniter systems. Others are trying to be more full Meteor/Rails/Laravel replacements. - https://gobuffalo.io/ is pretty full featured. - https://github.com/mustafaakin/gongular is a nice, unique take on a pure API-based system. - https://github.com/labstack/echo is the minimalist Go web framework my friends like. Regular popular recommendations are https://github.com/gin-gonic/gin and https://github.com/go-chi/chi Make sure to look at the libraries you want to use for things like auth to make sure you have what you need. - https://github.com/markbates/goth - https://github.com/volatiletech/authboss - https://github.com/firebase/firebase-admin-go - etc... Keep in mind, there is no batteries-included framework in Go. There is no Django yet. 
Yes, the runtime is more than just the GC
&gt; I don't know if this is the right place to rant about this It's not, nor is ranting a way to get anything done. That's why you're being told to "stop complaining and do something yourself." Here's a link that might help. http://www.catb.org/esr/faqs/smart-questions.html
&gt; security and stuff If you can't articulate what you need, how do you expect to get a helpful recommendation? http://catb.org/esr/faqs/smart-questions.html
Vue (sometimes) and bootstrap. My UI always looks like hot garbage for our internal tools, but it works!
Thanks for the update :)
Sounds like a good fit for Github Actions
[https://cli.vuejs.org/](https://cli.vuejs.org/) makes things ez mode
[removed]
The API is the UI for a backend. Are you asking about a GUI? A Web UI? A CLI utility? What is the workflow / use case(s) you want to support? Devil is in the details.
Bootstrap still looks better than 99% of the internal tools where I work. It's nice getting compliments for the lowest effort imaginable.
I chose grpc because I needed the streaming.
Thanks, someone already mentioned go modules to me, I will have a look and probably update that section
I'm using this, and it's nice and easy to get something reasonable together. It won't win awards, but it won't cause bleeding eyeballs either. And Vuex, though probably overkill for most projects, is actually really useful for handling all the API interactions. It also solves a ton of "am I really passing this data down through 3 layers of props?" problems - all components can access the $store and get their own data directly, and trigger their own API calls via the $store.
+100 on bootstrap vue and vuex. Yeah, it's overkill but so long as it's not customer-facing, I don't sweat too much about that added load time
this is a code smell to me. Anytime you end up using the reflection package to do something weird with the type system, it's a code smell. Always ends in disaster. What's the actual requirement behind changing all the sourcefile values? Is there a better way of doing that, instead of doing this?
Bootstrap and the like are tools, no shame in using them mate. I totally get why one might not to base their business on bootstrap (it looks kinda samey after awhile), but for administration or internal interfaces it just saves time so why not.
As much shit as people talk, having a good grasp of modern JavaScript fundamentals is a great asset. Even if it‚Äôs being able to whip up a quick working concept in ReactJS, I‚Äôd recommend setting some time aside to learn how a typical browser based application works with your API, etc
Thank you so much for the detailed reply! Many of those items are deal-breakers for me, so it's good to know. The lack of Linux support, for example, would kill it because I don't own any non-Linux devices (I have a work Mac, but this would be my personal device, so no). I hope they do make improvements and release a v2.0; if so, I'll re-evaluate then. Thanks again!
This is my code m := gomail.NewMessage() m.SetHeader("From", "from@example.com") m.SetHeader("To", "to@example.com") m.SetHeader("Subject", "Hello!") m.Embed("passlist.rxt") m.SetBody("text/html", ``) d := gomail.NewPlainDialer("smtp.gmail.com", 587, "ss@gmail.com", "ss") d.TLSConfig = &amp;tls.Config{InsecureSkipVerify: true} if err := d.DialAndSend(m); err != nil { panic(err) }
I'm a "full stack" developer, so I'm fairly comfortable with front-end development. I usually throw something together with React and avoid most of the best practices (e.g. don't bother with styling, redux, etc) if it's just for an internal project. If you're not familiar with front-end development and you don't really care to, perhaps using jQuery is a good option? There's a ton of examples and there's no build process (just include jQuery and your JS code) and you're off to the races. But honestly, I would learn whatever your frontend devs use enough that you can make simple prototypes with it. 
if it's an internal app, there are quite a few options, but I personally would just stick to template rendering with something like turbolinks or intercooler instead of creating an api. Will make life much easier and inn the best case you wont have to write any javascript.
React + MaterialUI.
Wow, thanks for putting together the [demo page](https://nykakin.github.io/QuantizationTournament/). It looks like github.com/marekm4/color-extractor is great combination of fast and accurate. I wonder what the author didn't like about it? 
goreadme-server uses the [update-a-file](https://developer.github.com/v3/repos/contents/#update-a-file) github API, which requires also content write permissions.
goreadme does require read/write content permissions. But only the app can use these credentials. You can browse the [server code](https://github.com/posener/goreadme) but you'll have to trust that this is what actually runs. You can always choose to run [goreadme manually](https://github.com/posener/goreadme).
I learned some react/html/css, I think it's pretty valuable for a backend dev to have a decent grasp of that. Not just because of the handicap you mentioned but also because you will get a better sense of how to structure your apis.
You can use [goreadme command line](https://github.com/posener/goreadme) for that. If you are creating such github action, please share :-)
I've seen [`grpc-gateway`](https://github.com/grpc-ecosystem/grpc-gateway) used successfully at a prior employer -- see [this blog post](https://medium.com/yik-yak-eng/migration-to-google-cloud-platform-grpc-grpc-gateway-1d6e626b71a9). It just magically wraps protobufs as REST APIs if you correctly decorate your proto files.
Elm is pretty fun and straightforward (especially if you've ever written in a purely functional language like Haskell before.)
I absolutely agree. Any time I've used reflection, it's been a code smell, but a necessary one. I'm not sure of any design pattern that's going to help me here. The issue is I must pass the root object to the library to populate. The catch is, that is on a per file basis, and I have many files and would like to capture which resources were from which file. 
Qt for portable GUIs. APIs in GraphQL so they use tools like insomnia so I don‚Äôt need to wrap them in anything more friendly. For web - any of the common Javascript libraries work. Choose what works best for you. 
Thanks heaps. I'll give that a crack today.
+1 for Gin
Vue.js + bootstrap. usually doesn't even need user management, http basic auth in nginx is enough. use nginx to proxy `/api` to the backend, `/` to load the html/css/js.
Yeah there is no easy front end way of doing things. I was hoping for the go team to work on gowasm but I don't think that's happening soon. It's hard because oop was made for UI. But ui and the Dom is just plain hard. So.... Idk you can try a framework but it's gonna change. You can do jQuery but it's time consuming. Idk. The UI design doesn't have a great paradigm yet. 
I really loved the https://github.com/chrislusf/seaweedfs code for when I was learning Go
Bootstrap 4+ and Angular 7 currently. I can throw those together in a few hours and they look better than 95% of sites out there. I'll even go grab a free bootstrap template if I'm feeling fancy.
I'd take the time to evaluate why you're doing work outside your expertise, job, or interest, in addition to the other advice here. I'm not saying that these aren't good skills for a backend developer to have in their toolbox, but they're irrelevant for that career arc once you're past entry level. Make sure you have a good reason to do this. 
What you're talking about -- data structures, methods, packages -- are very basic features of the language. Something you should be able to glean from a walkthrough of https://tour.golang.org/ If you wanna learn, you should figure this one out yourself... for future reference see: http://catb.org/esr/faqs/smart-questions.html
Agreed. If you're a backend developer then why do you have any pressure to work on frontend stuff? There should be someone else ready to do that part of the work, and you shouldn't feel bad about it at all. A plumber doesn't feel bad about relying on an electrician or carpenter.
i actually dropped a handful of pet projects as soon as i reached the UI stage. Just can't stand it... it's so uncomfortable... plus I have no visual taste at all
I think he simply didn't advertise his work anywhere. At the very least I can't find any mention besides the repository itself.
You might be able to get away without having to build a GUI. If internal users of your backed are of a technical background building a command line utility might be enought (or even preferred). If something like Slack is widely used in your company you can build a chat bot that exposes your backend. Go is a good language choice for both of these options. Depending on the featureset of your backend, you might get away using stuff like google docs (forms + sheets) to collect users' input into a table and performing some sort of processing on it. You could also use a task runner / scheduler like Rundeck as a UI that lets your users trigger some backend actions.
That covers the resolver side of it, but what about the XDS and Grpclb balancer options instead of round robin? 
I actually meant you @Nykakin, why did you find his implementation lacking enough to make your eigenvalue decomposition algorithm? Looking at the demo page, his results seem to perform better while being an order of magnitude faster. That said, I am wondering about the memory usage since his demo seems to store every color/bucket found.
I just grab an existing template that I think looks good, and slap that on it. There are lots of templates out there that look good and come ready to be generalized. In the ruby world, many of them came as gems. Be prepared to pay a few bucks for them. But it‚Äôs totally worth it. Ensures you have a great UX. A few years ago, I pulled down an old customer portal and replaced it with a new one, just using a template I grabbed online. Got so many compliments. It‚Äôs important that things look good so people understand it‚Äôs value. It may be vastly better, but if it doesn‚Äôt look good, people will often malign it. 
There is no xDS involved with a client side load balancer (since there are no envoy proxies) the client deal with the connections on its own. For the balancer here is a consistent hash example implementation (not tested though) [https://github.com/kcollasarundell/balancing-on-k8s/tree/master/clientSideBalancer/base/consistentHashBalancer](https://github.com/kcollasarundell/balancing-on-k8s/tree/master/clientSideBalancer/base/consistentHashBalancer)
Bootstrap-Vue is pretty modular. I use a handful of the components from that library in my projects, without importing everything.
Well in a recent version of gRPC they added EDS balancing. I haven‚Äôt played with it yet but I‚Äôm tempted. The idea is that it will replace grpclb, which currently doesn‚Äôt have a server side implementation available freely. That means you can run the envoy head end without envoy proxies, and have the actual gRPC client handle a more in depth load balancing. Eg, round robin just fires off to the next host in the list. But what if one of those hosts is overloaded? What if half of your servers are running on last gen hardware and can only handle 80% of the load of the current gen stuff? Round robin is too stupid to know about that so it just balances across them. With a balancer protocol, it can know and understand that and put more traffic on the faster machines than the slower ones. Traditionally, one would build that into the client and have it make all those decisions. But grpclb and eds allow you to make all those decisions on a central server and just hand down basic weights to the gRPC client. That makes it a lot easier, especially since gRPC runs on so many different languages, as you don‚Äôt need to rewrite the same load balance algorithm a thousand times. 
People love to hate on Bootstrap, but it looks good, and saves a ton of time when building GUI's (forms especially). I usually leave out the Javascript side of it, but the CSS is hard to beat.
&gt; As much shit as people talk, having a good grasp of modern JavaScript fundamentals is a great asset. Depends. Are you making a user facing web app like Reddit? Then do not use god damn React, Vue and similar for make a god damn SPA for an app which is MPA by nature. You will need a server side html renderer with some js sprinkled. Arguably, some people claim that Go is the wrong language for rendering html, even though it comes with an official template renderer. For an internal/admin dashboard like app, SPA is the right choice. 
Yeah I've seen the package but not tested yet, the only implementation I'm aware of is Envoy. Agree it's step in the right direction to give the client more information about the topology.
I went with Vue + Vuetify. I use the Material Design spec to build my GUI since I don't have to come up with anything myself. The style guide is already there. Just stick to that and it's pretty easy to make things look pretty good. It's a plus that my customers also enjoy the look/feel of MD. I'm actually liking it so much that I'm moving to more front end type work and finding others to help me with back end.
I didn't intend to write the full story, but oh well, here we go. Actually me and marekm4 used to work in the same company. We needed image color detection for the project we were working on and the lib we used (if I remember correctly it was github.com/RobCherry/vibrant) gave rather bad results for some cases. marekm4 was studying machine learning at the moment so he decided to implement his own algorithm in his free time. This sounded like fun so I decided to tag along and write a rival package, so we could choose the better one. As you can see from the results he eleary owned me and we ended up using his project. Should have used k-means clustering from the start too instead of some overly clever mathematic ways... Also, math programming in Go turned out to be pretty painful. At the very least I somewhat forced him to tune the code to max the results. If you take a look at the comment history you'll notice that both repositories started at the very same day - 10th February 2018.
I did some work with reflect on my [merger package](https://github.com/gabstv/merger) (merge data between structs/maps using json or other tags). First I map all fields by the specified tag (default = 'json'): https://github.com/gabstv/merger/blob/master/merger.go#L107 Then I populate them: https://github.com/gabstv/merger/blob/master/merger.go#L130
Take a look at [intercooler.js](https://intercoolerjs.org). This allows you to tackle 90% of all possible use cases and moves them to the backend. It might not be cool and fancy but the users won't notice, because your app can be as responsive and web2.0ish as most of the SPAs. And that without significant investment on the frontend side.
Why not document your api with swagger and use the swagger-ui as a first step. There are many client libraries which even allow you to generate your client UI.
As a backend developer, what is a UI?
Vue.js + Bulma.io
Yes, I feel that way :) in my experience there is a lot to gain if you take that extra step and provide UI for the API even if it only is for demo/debug/testing Vue+typescript is nice. Bulma or bootstrap for layout. I also like to use mojolicius(lite) for quick and dirty tooling/UI If you can choose toolstack, find something that seems fun, then you might actually like doing that UI part as well. Good luck :) 
I just tried your code and it works for me. Have you used the same mail address for *from* and in the plaindialer?
That's a great back story, thanks for sharing!
The only thing I can share is this brief overview of TUI/CUI packages: https://appliedgo.net/tui/ 
Just curious, what was used to generate the graphs in this article? they look quite nice!
For more thoughts about this, you might want to check out this: [http://wiki.c2.com/?StringWithoutLength](http://wiki.c2.com/?StringWithoutLength)
I'd argue almost the opposite really. For an internal app, a bog-standard web application, maybe rendered by Go, or w/e is just fine. Using something like React has a _lot_ of benefits for a customer-facing application. &gt; You will need a server side html renderer with some js sprinkled. This is what server-side rendering is for. If you take the "SPA" approach correctly, it'll still have things like routing that you can use via the address bar, and that lets you go straight to a page, and it should load instantly thanks to SSR. None of these things require that much effort these days, and you do get a lot benefits for taking this approach - I'd argue _especially_ for user-facing products. One huge benefit you can from it is perceived performance. If you're not doing a full page-load each time a user moves to another page after the initial page load, things will feel a lot faster to the user. They won't get a flash between pages, and they'll only be waiting for new content to be loaded (yes, assets are cached by browsers, so would load quickly, but there is a real performance difference still from doing things like parsing CSS and JS again and rendering the page again which your browser won't do if you've stayed on the same page). Plus, you still gain the benefit of decoupling your backend and frontend, allowing your backend to be re-used for either other "front-end" applications like mobile apps, or even for consumption by other services, or things like advertising partners, and affiliate networks.
Going hardcore here with backbone (also underscore and require). I have made tons of SmartTV dev with it and I like how everything can fit in place after making ‚Äúplugin/widget‚Äù system.
He is asking for frontend UI so I guess its Web UI 
Postman
Ever done authentication in a Windows env? I‚Äôm also full stack, also React, but now need to figure out how to auth against AD. Is it just as simple as put a login screen, verify creds against AD, cache some JWT token in localstorage with an expiry, expire, rinse and repeat?
It gives me an Auth Error
No, I really try to avoid Windows as a general rule. I _have_ done authentication with LDAP (which I think is the same as AD auth, but I'm not sure), and I found [this Go library helpful](https://github.com/go-ldap/ldap), and yeah, that's basically what I did.
panic: 535 5.7.8 Username and Password not accepted. Learn more at 5.7.8 [https://support.google.com/mail/?p=BadCredentials](https://support.google.com/mail/?p=BadCredentials) l19sm886298pff.185 - gsmtp
Cool. Thanks!
I don't agree with the sentence in this paragraph [http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/index.html#nil\_slices\_maps](http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/index.html#nil_slices_maps) it is only OK to add items to a 'nil' slice using append function. Following assignment would cause in panic: `s[0] = 1`
Bootstrap + vuejs is an easy approach. I try not to use npm because I hate to have hundreds of volatile libraries and a large codebase. But if it's for internal use only, maybe it can be a desktop app as well, such as a WPF C# .NET app. It feels more like backend programming, is less work compared to SPA and you can't beat the responsiveness of a real application.
&gt; I guess This isn't a guessing game. Consumers, both internal and external, have concrete use cases for everything under the sun. A bare REST API can be integrated into existing automation. A CLI utility can be put into a script, such as what lives in some CI/CD pipelines. A web UI or GUI is great when there is data to visualize, but if it's just A Big Button, there's no value-add. OP isn't throwing us a bone...
Swagger ;)
React with material UI will give you a very well executed generic googly aesthetic. Clients love it, the components look fantastic, and it's easy.
It's what allows potatoes to interact with your application
You mean a terminal?
This seems to load the file in memory and then call the Unmarshal method for the encoder/decoder. It would be more efficient if instead it used the Decoder.Decode method on a reader. Also, you are using the afero package, I guess to support different type of filesystems/repository but there is nothing in the documentation that says I can pass something that is not a local file. 
Yes, it is. Make your own Ajax wrapper lib that handles the JWT headers
Vue and Bulma with Buefy. Websockets when I want real-time updates
hmm, I get your point but in this case I would consider that to be an "assignment" not an addition to a \`nil\` slice. And the author does not recommend assignment to an element of a \`nil\` slice
Thank you for sharing! This is helpful to me, as I am learning Go and navigating many of these gotchas.
As a backend developer, I use curl as a UI once I write an API. "A man's got to know his limitations." -- "Dirty Harry" Callahan &amp;#x200B;
&gt; Is there a way to send my terminal output to a file? Yes /u/zomBitch89 you can redirect `/dev/stdout` like this: command 1&gt; file.txt You can also redirect `/dev/stderr` like this: command 2&gt; file.txt You can also append to a file, like this: command 1&gt;&gt; file.txt Ref: https://askubuntu.com/a/420983 More info: https://thoughtbot.com/blog/input-output-redirection-in-the-shell
What‚Äôs the main difference with LXD? 
‚ÄúMy desires are unconventional.‚Äù ‚ÄúShow me.‚Äù Opens repo full of ungofmt‚Äôd code. 
I feel like this is very outdated. It used to be true, but with CSS Grid, UIs are much easier. I use Angular for front end work and Bootstrap isn‚Äôt as good with those components. If you‚Äôre doing an internal tool, it‚Äôs fine. I‚Äôm using it for an internal tool I‚Äôm building with Jquery right now. But everything looks so bootstrapping and that‚Äôs just untenable in any real app. 
I think Google sheets.
&gt; It used to be true, but with CSS Grid, UIs are much easier I'm not referencing the layout mechanism, but the aesthetics. CSS Grid doesn't style forms, lists, or provide a cohesive visual system like Bootstrap. Plus, I don't think it's any easier than using flexbox. While I personally agree that there are too many "bootstrap" looking sites, I think the only people that give it a second thought are designers and developers. And, achieving a polished look like Bootstrap from scratch can take a lot of resources.
It‚Äôs definitely still good if you don‚Äôt know design and want to get your app out there. Or like in my case you are building an internal tool and just want to finish it in a day. My current important app methodology involves CSS Grid, looking at other designs for inspiration, and copying existing color schemes that work. The color scheme is the hardest part for me to do on my own. The layout is a part that bootstrap both does well and is limited by. Without a real design, things never look in place and I don‚Äôt believe that had to do with whether or not someone is using bootstrap or rolling their own. I feel like I‚Äôm also weak in that area so I always hope for a designer above everything. 
Have just started using React + MaterialUI, and so far it is fantastic, highly recommend it.
&gt; For an internal app, a bog-standard web application, maybe rendered by Go, or w/e is just fine - you won't gain all that much from using React or something similar here For internal 'admin dashboard' app, as I mentioned originally, which is basically data entry, content moderation and other CRUD actions, SPA is a lot faster to develop than SSR. &gt; One huge benefit you can from it is perceived performance. The only thing you mentioned about performance was switching from page to page, and that problem has been solved by methods that Github uses. There is FULL page reload anyway. Assets must always be cached. Indeed, you will LOSE performance by moving html rendering from server side to client side, specially on those poor low end mobile cpus. That's exactly why people are increasingly using Node or headless Chrome to prerender their SPA content. In fact, a good way of finding out if SPA was a poor choice for an app is when they end up using a fucking browser, a piece of software designed for the client side, on the server side to prerender. &gt; This is what server-side rendering is for. If you take the "SPA" approach correctly, it'll still have things like routing that you can use via the address bar, and that lets you go straight to a page, and it should load instantly thanks to SSR. This does not make sense. &gt; I'd argue especially for user-facing products. I think you have a different definition for user facing web apps. My definition, like I mentioned, is an app like Reddit where a small percentage of users create content and millions read it. You might be talking about a SaaS product, like Spotify where every thing is behind a login page and the content is created for a single or a small group of users. &gt; Plus, you still gain the benefit of decoupling your backend and frontend They can be absolutely decoupled by proper Go packaging. Your server rendering package just consumes your API functions, but without the serialization overhead. The fact that my parent comment gets heavily downvoted, shows the sad state of the web development as a result of uninformed, uneducated yet arrogant developers making poor design choices for the rest of the users.
Thanks! Although compile time mistakes could be really omitted
Garbage Juice is great
a) style: prefer // comments over /**/ comments. The benefit is that then you can use /* */ comments to temporarily comment out any or all of a file. b) efficiency: Reading from disk is slow. Don't read the whole file a second time. You already know how many lines you have, because you can use then len() function on any slice. c) style: give your functions better names. 'pathway' doesn't describe what the function is doing. 'readPlayerStatsFromFile' would be better. Similarly for variables, 'user_entered' does tell us the meaning of the variable. Here 'userEnteredStatsFilename', or simply 'statsFilename' would be better. d) floating point math: when you are a beginner, almost always prefer float64 based math and not float32 based math. float32 can be not very accurate, and is typically only used in very special circumstances to optimize some special calculations that need to be fast, like game graphics. e) you compute the batting average in calc, but then you don't save with the player or return it from calc. You'll need to do one or the other if you want to work with it again.
YES!! I knew I needed some refactoring on this thing. Thank you for the advise
The subslices use the same memory as the original slice. If you modify the subslice, you'll modify the original. Additionally, append also doesn't create a new slice (unless the original doesn't have enough capacity). If you append to a subslice, you'll overwrite the elements that come after it in the original slice.
But I'm never assigning the result of append() to anything. Does append modify in place? 
Oh shit. Thanks for pointing that out. Is there a way to make a new slice from two subslices?
Elm dawg, its the best
Yes, use the three value slice operator: `append(arr[0:i:i], arr[(i+1):]...)`. 
And this ensures that the original array is not modified?
Thanks so much, I wasn't aware of the three value syntax.
gofmt, go vet, go lint (I believe)
I would change the title to *"(...) Common Mistakes for New Golang Devs who don't study the language before starting to code"*
I would change the title to *"(...) Common Mistakes for New Golang Devs who don't study the language before starting to code"*
The only unfortunate thing is that it doesn't support per expiration per key.
Looks like I missed this... **Go Code Review Comments** [https://github.com/golang/go/wiki/CodeReviewComments](https://github.com/golang/go/wiki/CodeReviewComments) &amp;#x200B; This is what I'm looking for!
No, no. Terminal is for intellectual potatoes. UI is for the less fortunate potatoes
Awesome! Please keep maintaining it. 
Effective Go is a very good style guide
I collected some resources. [https://github.com/smallnest/go\_best\_practices](https://github.com/smallnest/go_best_practices)
True.
I would imagine I'm in the minority here, but I prefer to simply use html/template and sprinkle in some vanilla JS when necessary. I don't like dealing with the whole JS ecosystem (NPM/Webpack) and you can get surprisingly far without it, although it is a very old school way of developing. You don't have to worry about server-side rendering your JS etc. I think the vast majority of websites do not need to be SPAs... For personal projects this works great, but if I'm working with some front-end devs I just make a JSON API and let them do their thing.
Cool.
This is a great read. While most of it might be common knowledge for most there are some in it that are often overlooked. For example doing `defer resp.Body.Close()` without checking resp for nil after doing `http.Get`.
Thank you!
I had almost zero front end experience, never did anything more I JS than an alert(), and work mostly with Go on the backend and it always annoyed me that for side projects I was mostly stuck as soon as it involved dringend. Started doing a project with Vue and Bulma.io then a few months ago and it worked well. I actually started twice, the first time I gave up because I couldn‚Äôt get it to work with webpack and all these things I had no clue about. Gave it another shot with their hello world project and got it to work. For my current side project I have a way more complicated Vue Code base already and I finally have the feeling that my technical front end capabilities are not holding me back any more. I‚Äôm not super fast but can get everything done I want. I can only suggest to go with Vue and just work with it until you ‚Äúget‚Äù it. It‚Äôs fun.
I've a question to this: ``` data := "eÃÅ" fmt.Println(len(data)) //prints: 3 fmt.Println(utf8.RuneCountInString(data)) //prints: 2 ``` Which function do I need to get `1` as result like an average human would expect?
&gt; For internal 'admin dashboard' app, as I mentioned originally, which is basically data entry, content moderation and other CRUD actions, SPA is a lot faster to develop than SSR. If that's what works for you team, then that's great (actually, it also does for my team currently - our front-end developers are mainly React developers; so we use it for internal apps, as well as the customer-facing website). Other teams differ, and really internal apps are about what you can make functional quickly enough to satisfy business needs. If your team knows PHP and Bootstrap the best right now then that's fine too. What I said here was that you don't _gain_ all that much from using React or something similar here, i.e. to your internal users, they probably won't notice a difference even, especially if you're not making either of them painfully slow. Perceived performance doesn't matter the same way here because your internal users will have a different mindset about systems they have to use for work. &gt; The only thing you mentioned about performance was switching from page to page, and that problem has been solved by methods that Github uses. There is FULL page reload anyway. Assets must always be cached. I'm not sure what you mean specifically here. I know GitHub _do_ send you though full page refreshes, but they also dynamically load in content in other places (e.g. when browsing a repository) at which point they do update your client-side history so that you can still refresh the page or share the URL to the part of the repository that you're currently browsing. Indeed, assets will always be cached, as I mentioned originally. &gt; Indeed, you will LOSE performance by moving html rendering from server side to client side, specially on those poor low end mobile cpus. That's exactly why people are increasingly using Node or headless Chrome to prerender their SPA content. In fact, a good way of finding out if SPA was a poor choice for an app is when they end up using a fucking browser, a piece of software designed for the client side, on the server side to prerender. This is the point I have been making, but it is the next part that maybe I didn't word well or maybe there's a terminology confusion or something. But yes, I completely agree here, this is the point I was making about using SSR. I am _absolutely not_ suggesting people use a client-side rendered SPA for a regular user-facing website. They load slower, put more strain on any device, require dramatically more network time to load client-side because of added latency, and have other impacts on the business for things like SEO (though, most modern search engines do run JS now to get around it, if your site is "slow" to them then that will also affect SEO). &gt; This is what server-side rendering is for. If you take the "SPA" approach correctly, it'll still have things like routing that you can use via the address bar, and that lets you go straight to a page, and it should load instantly thanks to SSR. 
so you read the whole docs before you start to write a single line of code, huh?
French fries?
https://koekeishiya.github.io/chunkwm/ "chunkwm does not handle any keyboard input. A third party program (e.g: skhd) is needed to map keyboard events to chunkwm actions." https://github.com/koekeishiya/skhd 
I had seen that Goleveldb supports transactions when I was asking about transaction support in ledisdb: https://godoc.org/github.com/syndtr/goleveldb/leveldb#DB.OpenTransaction https://github.com/siddontang/ledisdb/issues/305
What is flak? I don't wanna read through a huge article just to guess.
mac and Linux handling keyboards differently hence you can't write 100% portable application for that,you will have to use os specific code. as of where to start with - always start from architecture. you'd have to know how each os handles keyboard input and decide on what you want to achieve. make an MVP for your main use case. See what could be improved in your architecture. Adapt. Extend. 
thanks [justinisrael](https://www.reddit.com/user/justinisrael), i only read see the readme of Goleveldb, it never introduce about transactions. i will read doc and try it. about motivation see [https://github.com/xujiajun/nutsdb#motivation](https://github.com/xujiajun/nutsdb#motivation) for detail
I think you'd run that through unicode/norm.
&gt; dns://mygrpcserver:1234 Is the port necssary here, incase you use gRPC? I read somewhere it's querying SRV entries automatically but I'm not sure. Maybe `dns://mygrpcservice:namedPort` can work too? 
Can you point to an example using eds? I'd love to understand what server is needed and what in Grpc to make it work.
Well, the go compiler itself is written in Go, so you probably technically could look into the code behind the `go` command. However, you'd have to include the entire Go compiler package with all dependencies as well. It's probably easier to just go the os.Exec way.
Seems like someone who at some point in time thought LUA was a good bet as a future proof web tech now retraced their decision and chose to go with Golang instead. Nothing in the article indicates as to why they ever chose LUA to begin with.
When you put it that way, it's clear that my request is unreasonable. Of course I'd have to include the entire compiler in my binary, and why would I do that? os.exec it is! Thanks for setting me straight.
To be fair that's much more feasible for Go than most other languages
Could you add [fastcache](https://github.com/VictoriaMetrics/fastcache) to the benchmark?
From the godoc for DeepEqual: &gt;Specifically, it is possible for a value to be unequal to itself, either because it is of func type (uncomparable in general) or because it is a floating-point NaN value (not equal to itself in floating-point comparison), or because it is an array, struct, or interface containing such a value. The error type is an interface containing a function - String().
well, following map example is doing assignment as well, am I right?
This is because `DeepEqual` compares types before comparing underlying data. `Atoi` returns an `*strconv.NumError` where `errors.New` returns an `*errors.errorString` Look [here](https://play.golang.org/p/eMJK6bCl-ru) to see in practice.
If that is the case, then you are claiming DeepEqual cannot compare any non-empty interfaces, which, by definition, contains a function. I don't think that is true.
&gt;The error type is an interface containing a function - Error(). You are confusing method signatures with func types. The variable of the func type is a closure.
if I try to do this ` if !reflect.DeepEqual(err.Error(), tt.err.Error())` I get a nil pointer dereference.
I'm not saying it. The godoc is saying it.
You don't need `DeepEqual` to compare strings. The simple `!=` will do. Second - you don't need to wrap errors strings inside error variables to check them. As for nil pointer dereference, just create a helper [like this](https://play.golang.org/p/7njIVPktVy-) that will not panic on nil pointers.
Oh, I see.
Cool. But I wonder what the comparison is, if Goleveldb has transactions, and Ledisdb has all the same data structures with swappable backends. So my question is if you intend to replace Ledisdb which does same feature set? Seems like that project could have benefited from your time and gained transaction support in its front-end. 
[removed]
[https://play.golang.org/p/0RxuezTjB5L](https://play.golang.org/p/0RxuezTjB5L)
"Flak" is just the name of Ted Unangst's blog. (Ted Unangst is a high-profile OpenBSD developer.)
You can't easily, because Unicode is complicated. That string is the Unicode equivalent of `&lt;acuteaccent&gt;e&lt;/acuteaccent&gt;`. You need a unicode-aware parser to figure out the horizontal width or count of graphemes.
Whats the difference?
Would also recommend a look at [50 Shades of Go](http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/) as it nicely highlights what is the bad thing to do. Also, not directly related but shining a light on commonly accepted good practices is [https://github.com/golang-standards/project-layout](https://github.com/golang-standards/project-layout) as it demos a known good for projects, and as a side effect also highlights projects the community considers decent.
Don't use DeepEquals in tests, it will give you false positives way more than it's worth saving some typing. I just type out the struct field comparisons.
&gt; I am absolutely not suggesting people use a client-side rendered SPA for a regular user-facing website. This was my whole point here. Sadly, as you can see in this post and generally in Go community, people keep suggesting to use SPA for their Go web apps regardless of the application type. This has broken the web. As the web founder Tim Berners-Lee issued a warning about the future of the internet recently, in my view some part of this warning should include the technicals of web dev too. Frameworks like React are not the right tool to be used for every and any apps. But due to their hype machine success and the community attitude of having no roadmap, React has became the cancer of the web dev. 
Yes, I already have a ticket for it: https://github.com/Xeoncross/go-cache-benchmark/issues/1
The sentence is right: it's always ok to have nil in a slice variable, because it behaves exactly like a zero-length slice. In your example the panic is not because the slice is nil, but because you're accessing a slice out of bounds. The following would also panic: s := []int{} s[0] = 1 The map example is not an assignment, but an insertion (which for maps uses the same syntax as assignment in go). What is important to remember is that maps are one of the few cases where the zero value (i.e. nil) is not directly usable.
Good question! One is the character e with an accent on it, as a two-byte UTF-8 encoded value. The other is the character e, with a combining mark on it, which is a single byte for the `e`, and two bytes for the combining mark. [See this playground entry to see them both side-by-side.](https://play.golang.org/p/4Jy0Ev20p2a) Unicode can be wild.
You might be interested in Up (I wrote it), but utilizes AWS Lambda for serverless deployments to your own AWS account, which at 1,000,000 free requests/mo is typically free: [https://github.com/apex/up](https://github.com/apex/up) &amp;#x200B; Just create your main.go file and run \`$ up\` 
If you want to make it a little more clear that you are using a new slice, you can get the same effect as Matthold's method like this: `fmt.Println(append(append([]int32{},arr[0:i]...), arr[(i+1):]...))` This just makes it explicit by declaring a new empty int32 slice, then appending the two segments of the original slice in turn. Same result in a little more wordy way, but you might have better luck coming back to the code a few years down the line in figuring out why it was done that way. &amp;#x200B; Or not. Just a matter of taste. &amp;#x200B;
Stuff like this drives me crazy: &gt; For subscribing we are *gonna* use a channel. 
&gt; Which function do I need to get 1 as a result like an average human would expect? Most of the time when you are asking a question like "how many characters does a human see" you probably want runewidth.StringWidth: https://play.jsgo.io/d5b07c70b293db72131bdeb82a35582831585027
&gt; but as part of the golang.org/x/ packages I can't show you on the playground Don't forget: https://play.jsgo.io
Did I say "the whole docs"? Can you read English text? I was generally talking about "studying". When I approach a new language I always study what I need to start coding in that language. Many "developers" don't do that and I suppose some of them did never open a technical book in their life, they think it's simpler to ask questions on StackOverflow.
While I agree in principle, grammar isn't set in stone and is constantly changing, e.g.: [https://www.nytimes.com/2018/11/29/nyregion/photography-books-nyc-gift-guide.html](https://www.nytimes.com/2018/11/29/nyregion/photography-books-nyc-gift-guide.html) [https://www.cnn.com/2019/01/04/politics/rashida-tlaib-trump-impeachment-comments/index.html](https://www.cnn.com/2019/01/04/politics/rashida-tlaib-trump-impeachment-comments/index.html) \#lulz [https://insider.foxnews.com/2019/03/11/michael-caputo-responds-jerrold-nadlers-trump-documents-request-no](https://insider.foxnews.com/2019/03/11/michael-caputo-responds-jerrold-nadlers-trump-documents-request-no) Perhaps we're not all ready to the level of BBC's strictness [http://www.bbc.co.uk/worldservice/learningenglish/grammar/learnit/learnitv165.shtml](http://www.bbc.co.uk/worldservice/learningenglish/grammar/learnit/learnitv165.shtml)
Sorry, fixed the issue :)
That is what gobin and gex are solving for. Also you only generate on the active module, so it isn't a problem in practice. 
Here's how I do it for my projects: curl -s https://api.github.com/repos/vipnode/vipnode/releases | \ grep -om1 "https://.*/vipnode-linux_amd64.tgz" | \ xargs curl -sL | tar vxz Basically Github has an endpoint that returns the releases, latest first. Grab the first that matches your architecture, download it, extract it. Feel free to change the final line to `xargs wget` to save it without extracting. Could be generalized to your project.
Would be great to add some discussion/benchmarks to how it compares with other solutions (leveldb, boltdb, badger). What scenarios is bitcask a good choice for?
That would be condescending 
Ideally your code isn't too highly dependent on how you transfer data from one point to another. You should be able to start out with JSON over REST between your internal services, and gradually change them to gRPC and Protobuf for example. You're right that you have to convert back and forth between your Go object and the protobuf object, no way around that. So there's definitely a cost for your devs there. If the benefits outweigh that though, go for it. There's a big gain in terms of how fast you (de)serialise data. The payload can also be quite a bit smaller if you're dealing with a lot of numbers. It's also convenient for your devs that if you change/update the available gRPC methods of your server, the client code is also auto-generated. Slightly less dev time required here. gRPC also offers stream processing, which may or may not be critical for your requirements in terms of processing time and latency. If low latency is key, go for gRPC over JSON+REST. Otherwise, it pretty much comes down to operational costs. Check out how much processing time you're potentially wasting on JSON (un)marshalling, and how much a different protocol can reduce those costs. If gRPC per se is too big of a change, you can also use JSON and websockets of course for lower latency processing. There's plenty of options. List up the pro's, con's, risks etc. to see what fits your requirements the best. A side-note for gRPC: as far as I'm aware a gRPC server always needs to be made available on the "root" URL: e.g. my-url.com and not my-url.com/v1/grpc. This is less critical for your internal processes though.
Great article :) &amp;#x200B; I just had a question about the Publish method. If a subscriber subscribed with an unbuffered channel, could that block the Publish method? Why not write something like this? `for _, ch := range dataChannelSlices {` `go func() {` `ch &lt;- data` `}` `}`
&gt; The new flak makes no effort at caching, except that which can be added by a front end proxy. Smart! üëçüèª
Both Google and Amazon provide free tiers for many of their products, including virtual machines. Go is very lightweight, and you'll generally be able to stay within the limits of that free tier for simple stuff, with the flexibility to grow and become more robust as you need to. Failing that, there are fantastic providers like DigitalOcean too that offer high performance VPSs for relatively low costs too (e.g. $5 a month). Unlike PHP, you probably won't find something like traditional shared hosting for Go. Applications just don't work the same way.
So he's rewriting his blog in Go?
Anyway, the article was great
Oh god the comic sans tho
I would have liked to see [https://github.com/valyala/ybc](https://github.com/valyala/ybc) in the comparison. In the past I have found it outperforms most Go memory-based impls and it can mmap SSD based storage.
Basically channels used here are unbuffered. As you can see subscribers get the result and process it. Blocking could happen if you did not consume and blocked it. It can be avoided using a goroutine :) Hope it helps 
Yep, he's re-written the blog engine powering it. (I think the rewrite is completed and rolled out.)
I thought about doing something like that a while back when trying to design plugins. Then I figure `go` want everything to be webbase. You can architect your code to use microservices as plugins instead. 
It's one of those "damned if you do, damned if you don't" kind of scenarios. In the case of a subscriber with an unbuffered (or fully buffered) channel, you'll block. In the case of spawning a goroutine for each channel send you could be blocked forever -- never know it -- and spawn enough goroutines to exhaust working memory. Typically adding a buffer is a good idea if the channel is unbuffered, and for more complex scenarios you might want to do something similar to what you've put there. &amp;#x200B; One note is that in your implementation you'll most likely end up only sending to the last channel in the slice. You'd need to pass the channel into the goroutine: &amp;#x200B; for _, ch := range dataChannelSlices { go func(ch DataChannel) { ch &lt;- data }(ch) } &amp;#x200B; You may have known that, but it's bit me many times!
...or with systemd-nspawn?
Nice, yeah that makes sense and is similar to what I do in the server, which just calls the GitHub API under the hood. At its core, my server really isn't anything fancy, just a convenience for what you have up there (with a little extra under the hood like auto-detection of os, server-side uncompression, and maybe some other stuff in the future). Right now [https://bin.suyash.io](https://bin.suyash.io) does try to automatically detect the correct OS from the `User-Agent` (which curl doesn't really supply, but wget does) so at least that's there. Arch might be a bit harder (right now assuming x86/amd64)... My main goal with this project was to have an easy semantic way of fetching releases, with semantic args! `wget --content-disposition` [`https://bin.suyash.io/suyashkumar/ssl-proxy`](https://bin.suyash.io/suyashkumar/ssl-proxy) will get you the latest version of `suyashkumar/ssl-proxy` for your OS (since wget provides that info in the User-Agent). You can also have it untar for you on the server side: `wget --content-disposition` [`https://bin.suyash.io/suyashkumar/ssl-proxy`](https://bin.suyash.io/suyashkumar/ssl-proxy)`?uncompress=true` and also explicitly ask for a specific os `wget --content-disposition` [`https://bin.suyash.io/suyashkumar/ssl-proxy`](https://bin.suyash.io/suyashkumar/ssl-proxy)`?os=darwin` In the future hoping to add options for arch, and asking for specific tagged releases. &amp;#x200B; Contributions are welcome!