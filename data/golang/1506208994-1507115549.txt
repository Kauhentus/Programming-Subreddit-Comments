Sure, I made an assumption that the print would just print bogus data if the command had yet to start.
Yes I would, so very much. Also, a generational garbage collector, so I could have used pointers :) Disclaimer: I'm not an expert on the different types of GC implementations. It could be that Go's is tuned for things a generational GC wouldn't handle as well. 
Yeah, but I'm fairly sure a generational GC would have handled this better -- no?
Oh, and right. I'm using the wrong terminology here. I'll clean up that README, thanks
The DBs provide you an option -- because there are many use cases which would trade sync writes for performance. For e.g., if you're using a write ahead log, via a file which gets synced to disk for every request, then you might want to turn off the sync writes for better write throughput. Assumptions that all users must use sync writes, or must not use them, both would be wrong. There's no right answer here. Everyone's use case is different. Here's a wiki about RocksDB's async writes, where they mention that async writes are 1000x faster than sync, and when async writes would be better (loading large amount in DB, which is what we're doing in the benchmarks): https://github.com/facebook/rocksdb/wiki/basic-operations#asynchronous-writes 
Well, I used code generation for all the different types. Look in the Makefile
Yes and no. Generational GC and "pauseless" GC can greatly improve the typical performance of your program. However, the worst case behavior with every GC algorithm I've ever heard of is always the same: full stop-the-world collection.
It's ok. Everyone does it because the term "garbage collector" is also wrong terminology. Modern garbage collectors collect things that we want. Reference counting algorithms collect garbage.
ok, so I am moving mage's main function into a library, so this will totally work. You will be able to do // +build mage package main import ( "fmt" "github.com/magefile/mage/mage" ) func main() { mage.Main() } func Build() { fmt.Println("hi!") } and then `go run mage.go build` will do the same thing `mage build` does (except it'll have to compile mage, then mage will compile the targets (if not cached) then run it). I like that idea for people that don't want to have another binary dependency.
Hmm crap, it'll have to be in a separate, non- `// +build mage` otherwise there will be two `func main()`s. so you'll need // +build ignore package main import "github.com/magefile/mage/mage" func main() { mage.Main() } And then regular mage files like otherwise described.
Done! There's now a zero-install option :) https://github.com/magefile/mage#zero-install-option-with-go-run
What does this have to do with autocert, go, or SSL? You obviously have a DNS issue. Maybe just stale DNS entries, we don't know.
Stuck in what way? Build output may give me a hint at a quick glance. What Linux distro you run? I wouldn't compile llvm in a docker container myself, a lot of the defaults are gonna leave you resource starved. I've never looked at or used llgo, but the link shows it as a top lvl prj for llvm so maybe the most recent Jenkins builds will be in the llvm lab. Will give you some hints maybe on any flags / dep version combinations that are known to work harmoniously. Best of luck, though crypto might not be the safest area to play with lol.
The same reason you can write an os in js
can't run docker on it, no thanks.
Did you forget the `A` record from your domain to your IP?
This is maybe a little bit out of scope, but I recently learned about hardware-implemented garbage collection for Java that completely avoids stop-the-world (and has been implemented in software with some kernel extensions). [It's an interesting read](https://www.azul.com/files/c4_paper_acm2.pdf). They had hardware that'd interface with the JVM directly, and manage updating references lazily. Of course, when you get to the end, they state that while the algorithm is fully concurrent and without pause, the implementation they ship actually does do some short stop-the-world pauses in the sub-millisecond range, which just so happens to be the pause time in Go. :)
What's so complicated about the pricing?
Golang team has a feedback form where they ask developers what they wish language supported. They said on a conference that they didn't get enough generics feature requests to implement this, so they don't see if that's a needed thing. Could you write to them please?
Classic NIH syndrome.
Excellent work and great thinking out of the box. I replaced gotask + yaml and 5 bash scripts in a sub directory with a ‘mage.go‘ file in the project root (with some helpers shamelessly copied from your samples). No more panicking when having to update the build system! I suggest you keep it simple and magical as the name suggests.
Do you mean a tutorial? https://golang.org/doc/articles/wiki/
There's an important piece missing. Why do you want to do all of this in the first place?
Considering the start of the README that states llgo is not feature complete yet I doubt anyone has picked it up and packaged it. &gt; llgo is under active development. It compiles and passes most of the standard library test suite and a substantial portion of the gc test suite, but there are some corner cases that are known not to be handled correctly yet. Nevertheless it can compile modestly substantial programs (including itself; it is self hosting on x86-64 Linux). If you're looking to get Go code to run in WebAssembly though, [wagon](https://github.com/go-interpreter/wagon) or [wag](https://github.com/tsavola/wag) might interest you.
Not intro work but helpful projects awesome-go.com
If there were a similar option that was as clean to use and run, I'd be all for it. I've seen some options here, but they aren't as good as I'd like.
There overall goal is to port the Java library to Go in such a way that using it feels almost identical to the Java library. Implementation on the back end will be different to play more to Go's strengths. For this particular problem I wasn't sure in Go how to get the same feel for using that particular class as you would in Java. I've resolved to starting to break down the Java convention and just do what feels right for Go.
Regular expressions are fine. Sure, you can do it wrong. But you can also do it wrong when you're *not* using regular expressions. It's all about the right tool for the job...
Sorry, but why do you keep posting this? You posted this [five days ago too](https://www.reddit.com/r/golang/comments/711qdw/validate_input_in_golang_easily/), and I'm fairly positive I've seen it a few days before that as well.
Thanks for explanation. The end result is really neat.
I'll admit I didn't read the whole paper, but if they've truly managed to improve the worst case runtime complexity, I would think that would be remarkable enough to be clearly stated at the beginning of the paper. They wouldn't be quibbling about generations or pause times or whether it was even practical for real world use at that point.
As the author of Task, I'm interested to know what was "panicking" about updating it. By what I understood if your use case (need of external bash scripts), maybe Mage is better than Task for your case. They have different ideas in mind.
One more week, one more Make alternative written in Go. ;-) I'm the author of Task. Great tool and approach! I'll add it the the "Alternatives" section the Task README. I actually see Mage more as an alternative to Ruby's Rake than Make. Both have different use cases and target users. While Make is more declarative, Rake is more programmatic. Cheers and good luck!
I'd like the source graph color theme for IntelliJ but it looks like they just have it for sublime so some conversion is needed...
Did you make this or can you buy them somewhere?
You can wrap sql.DB in another struct, then implement needed interfaces such as Query, Exec that will pass all the arguments to an actual sql.DB, in the mean time you can measure and log. For more advanced method look at this https://github.com/marcusolsson/goddd
I made it. I got 10 for like 7$ using a stickermule.com promo here's the png https://imgur.com/gallery/x3GY2 and here's $10 credit at the place I got them made https://www.stickermule.com/unlock?ref_id=5433090701
+1 to this. For s while now, when people ask a question "Should I learn A or B?", Go community answers "Learn standard library". The issue is that you want to learn the language, not the library. When you know the language well, you can learn and understand any third party library. You don't want to be in a situation where the only way you know how to interact with database is trough gorp, when gorp isn't option to be used.
That's a good direction, thanks! Although I was looking for something that can be done "behind the scenes" (i.e. just by adding a reference to my package). 
Take a look at this (many of those books are free) https://github.com/dariubs/GoBooks/blob/master/README.md
I hadn't heard of pyinvoke. I'll take a look, thanks. 
I have declarative dependencies coded, just need some testing and some reviews on approach and error handling. But you can declare a function depends on x,y,z and x y and z can depend on other things and they'll all get run from leaf dependencies on up exactly once, in their own goroutines.
I should dive into rake more than I have and steal some more ideas from it. I'm not a Ruby guy so I haven't looked it more than to follow some install instructions. What's the difference between make and rake? The biggest thing I know that make does that I'm not sure I'll care to implement is the auto detection of when source files change in order to regenerate a target file. That doesn't seem terribly useful in this day and age. In my opinion, the tooling should do that, like go install does, not the build script. 
https://github.com/ExpansiveWorlds/instrumentedsql is quite good for wrapping and then logging!
This is all very nice, but I was amazed to see it used 9pfs/virtfs as a storage layer. Last time I tried it was simply unusable in Ubuntu 16.04, and RHEL refused to package it due to the bugs. Has this changed?
&gt; port the Java library to Go in such a way that using it feels almost identical to the Java library. That's a bad idea. And replace Java and Go with any two programming languages and it's still a bad idea.
These are the slides from https://www.reddit.com/r/golang/comments/71j5go/can_you_write_an_os_kernel_in_go/
Nice! I wasn't even aware that both the mysql and postgres drivers expose the Driver struct so I can reference it directly. Thanks!
A lot of people have suggested that to other people, but that looks like an interpreter written in go for running llvm byte code. Did I miss something when checking that out? 
I wouldn't say that's always true, take the AWS sdk for example. Between the different languages that are supported, there's a very recognizable feel (I haven't tried all of them of course). There are deviations in each where the language favors a different implementation than another. That familiarity is what I'm trying to achieve rather than a one for one mapping. I may have misrepresented that in the quote you referenced.
Rake is just Ruby, so you can import libraries, run complex code, etc. while Make is more about calling other executables. Up-to-date detection is very useful for apps that use a lot of code generation, either Go code or bundling of assets with Minify/Gulp/Webpack/etc.
gollvm might be a better horse to bet on than llgo (no disrespect to the llgo devs) gollvm has a few go googlers working on it...
Case in point: the Go AWS client API is generally considered miserable to work with.
edit: i had supplied some profiling tips, but it was getting down voted. /r/golang is getting to be as good as the rest of reddit it seems. :(
This type of comment is an elitist attitude. You clearly don't get it. Bash is a fully qualified and good language. It also does work in Windows if you install it. Where is bash good? For systems automation. To this very day I find bash scripts require less work for custom fleet deployment than amsible, fabric, and Travis. Having full control over things means that you have to literally write your own checks for everything and that is where people tend to fall short. Most people don't have the knowledge to really do sanity checking in bash. It's not an easy language, but it is rewarding. 
sadly :(
You can do this either the docker plugin, a configured host machine or the kubernetes plugin. But in general, it's very difficult and every so often, you will have to clean up a lot of bad state (containers left running, full hard drives etc) For this reason I recommend either Google Container Builder, CircleCI or indeed TravisCI as they can run all of the above and clean up after themselves. I had some success with Wercker but it's very limiting when you want to build a special image (say, with libvips or c libs)
Extra easy if you're using postgres - throw in a quick db.Exec(`LOAD 'auto_explain';`) db.Exec(`SET auto_explain.log_min_duration = 0;`) then check the logs of your postgres instance (running in the foreground, in docker makes this super easy for development)
I like the idea and your implementation so far. However, looking at your deptree branch, I think you're missing two key pieces of what makes `make` a great tool. 1. Targets can be generic, specified by pattern. Every file that needs to have a process run on it is it's own target that can be a dependency, and I don't need to write a target for each one. (e.g., rules on how to turn `.c` files into `.o` files, with only the `.o` files explicitly named as targets that are depended on. 2. Dependencies aren't just an ordering issue, `make` checks whether those files are newer than their dependents, and only runs targets that need updating. Obviously these grow out of `make`'s "targets are files" philosophy, which I'm not sure is what you're going for with mage. (And leads to the `PHONY` targets which so many people dislike.) Off the top of my head, I'm not even sure the concepts map well if targets aren't files, without having some other concept of freshness. But without similar features, I wouldn't call any system a `make` competitor so much as a just a way of running scripts. EDIT: "just a way of running scripts" sounds more dismissive than I meant it. Having a consistent way of easily running scripts, and being able to write them in Go is pretty great in its own right.
You're welcome. . . if you are from or live in the Boston area, there's a good chance that I know you. 
These two sites are great to getting started with Go: - https://tour.golang.org/ - https://gobyexample.com/
I'd suggest adding an agent (f.k.a. slave) to Jenkins instead of installing any tools on the master or using on-master executors. This approach is better for several reasons including performance, security, and scalability. Install Docker, Docker Compose, and other required tools (Git, etc.) on the agent and then invoke your build process using [power]shell scripts. You don't need any Docker plugins to do this. Keep the agent clean by running Docker cleanup scripts on a CRON schedule, or as a post-build action like [this](https://github.com/schottsfired/sample-rest-server/blob/master/Jenkinsfile#L85-L90). If the agent itself is a container, then you'll need to install Docker and Docker Compose inside the container and bind mount /var/run/docker.sock (Docker on Docker), similar to what I've done in [this example](https://github.com/schottsfired/cjt-demo-environment) right [here](https://github.com/schottsfired/cjt-demo-environment/blob/master/docker-compose.yml#L17) and [here](https://github.com/schottsfired/cjt-demo-environment/blob/master/Makefile#L13).
1. String replacement and concatenation as the primary mechanism for metaprogramming. 2. Declaring that the following rules and dependencies are necessary for building a target but failing to check that the target was built as a result of the make rules. 3. Debugging output that would actually be useful if there was just some way of telling it "Seriously, stop looking for the filename with 30 different automatic extensions when I'm not even using C ffs." Don't underestimate the importance of debug output. 4. Actually quite hard to correctly declare dependencies if it's not just a list of files in the current directory. Declaring a self-contained build module, then trying to depend on that is actually surprisingly annoying.
I'm from the Boston area, but I stopped going into Boston just before I started getting active in the programming community. Now it's a hike, so I don't get in there very often (I'm just outside 495).
Do you have a Github profile?
Almost: it is to run interpreted wasm code, not llvm byte code.
hmm... it's certainly doable. I'm just surprised minify/gulp/etc don't have that functionality built-in.
Dude, holy hell, I love your work. I was just getting a bit tired of the NodeJS drama lately looking around at other options and dang dude, your project is, while I understand of course small, really inspiring to me. Love it!
I'm a CS masters student and only have a vague idea what I'm looking at. 😅 Is this statically evaluating a Fibonacci function? Whatever it's doing, does this generalize? What is the value of it, speed? How's the memory performance compared to a recursive call stack?
Might be worth adding an imagine of the output to your readme..
It is something like an interpreter based on the golang parser and ast. It parses the Definition of functions and memorizes them. For the Evaluation it walks the ast and Evaluates the expressions given with the parameter. Pretty cool tho. If i understand correctly what hes doing there, it should not be restricted to fibonacci but any recursivly defined function should work. 
Lol not really
I am working on some trading programs. Which I don't want in a public repo.
Why use the discord app instead of the already existing golang slack ? Edit : gophers.slack.com
What's the great thing about beego vs Buffalo or Revel? Which one has the best documentation? Which ones have a mailing list where one can ask questions and expect to get answers in a reasonable amount of time.
There's also: https://www.reddit.com/r/golang/comments/4h10gn/discord_gophers_discord_chat_server_dedicated_to/
added it https://github.com/deltaskelta/readme
Wow thanks so much for your kind words. I also came from NodeJS recently, found Go and never looked back! Please don't hesitate to ask if you have any questions, and be sure to join the Gopher slack. Lots of people there (including me) can help you get set up and write your first Go program.
 Never understood the appeal in slack. How are you supposed to join the group?
Thanks friend. I just started work last night and managed to get a lovely Hello World setup in about 30 minutes. Really a fan of writing with a standard library actually, reminds me a lot of my old Python days...Only much faster actually and with less decision paralysis.
Why are you creating things that already exist?
Very cool! Keep up the good work!
While I do love Makefiles, here at my $dayjob we have an interesting "problem" where all the development and deployment of our $product happens on Linux-based systems, but most of QA folks want to *build* and run it on Windows. Now you can have `make` on Windows (either as a part of GfW or MinGW or whatnot) but the thing is, `make` in itself is just a dependency resolver (which, in our case, has nothing particularly complicated to solve, I'd say), and all the heavy lifting is done by running external programs in the Makefile targets, and that is precisely what causes problems for our poor Windows souls. So we're pondering rewriting our Makefile in pure Go to have those folks leverage the `go run` to carry out the builds.
You can join the lovely 20k members community using this link https://invite.slack.golangbridge.org/
All of the above are also available in Slack, minus the ads that discord has :) 
I also wrote this little fellah, to send messages in game to users. Turned out pretty cool. https://github.com/nokka/d2client
I've been using discord(desktop) for almost 6 months at this point, and not once have I run into an ad, perhaps ads are a thing on the web client?
Perhaps
The important bit is in the `eval` function under the `CallExpr` case. It's just caching the result of that specific function call with those specific arguments: func eval(mem map[key]int, vars map[string]int, expr ast.Expr) (y int) { switch x := expr.(type) { /* ... */ case *ast.CallExpr: name := x.Fun.(*ast.Ident).Name arg := eval(mem, vars, x.Args[0]) k key{name, arg} /* create a key containing the function * name and its arguments */ if v, ok := mem[k]; ok { /* check if we've cached this * function call with the same * exact arguments before */ return v /* instead of re-calculating everything, just * return what we cached before */ } defer func() { mem[k] = y }() /* there was no hit. y is the named return variable. * Whenever any code path in this scope does a `return` * then the result of that return for that function call * will be cached */ /* ... */ } panic("internal error") } This wouldn't work too well if it had static scope variables or mutable types being returned. In this case with a simple int return value it works really well.
&gt; i had supplied some profiling tips, but it was getting down voted And you've removed your potentially useful advice, because a couple of imaginary internet points were taken from you?
Thanks!
The selfie image is not really my taste ;). This is how it looks the cameleon. https://imgur.com/a/XjrB9. Of course this can be "tuned" even more.
I am calm, and you didn't answered to my question. 
As mentioned there already is one. Dont be like JS devs and reinvent the wheel Inb4 "Calm down :)". Really soured the first impression with that
I wrote this a couple weeks ago to scratch an itch. Might be useful to other gophers.
cant find any ads on the web client.
Community said it wasn't valuable. And it's probably my last act of protest on reddit.
For Go projects there's also https://github.com/christophberger/goman
/u/Acidic92 it doesn't look like anyone mentioned it yet but you can limit concurrency with a channel and use that in combination with sync.WaitGroup to both limit concurrency and wait for all work to complete. https://play.golang.org/p/dVK4KOvjUW Or you could avoid sync.WaitGroup and just use channels: https://play.golang.org/p/YsC03XJlwn
This is really neat. I have automatic memoization in [the little scripting language](https://deedlefake.github.io/wdte) I've been working on, but using the Go parser to do it with Go-like code is a neat idea.
I like it
that's because by the time the go routine is run, the horses loop has reached the last horse. If you have goroutines running in a loop, any variables that change should be passed into the goroutine, like: go func(horse *Horse) { horse.Feed(food) }(horse) Try that, and you will see each horse is fed (in a pretty random order). edit: playground link: https://play.golang.org/p/XgIpD5aFgH
I just added dependency trees to Mage, btw. So you can say f depends on b and c, and d depends on c and e, and it'll run them all in the right order and exactly once. And it runs on Windows just fine :)
I guess what I mean is that the way to call Go is *through* C. Like they do here -&gt; https://blog.heroku.com/see_python_see_python_go_go_python_go The problem with calling Go DIRECT from PHP is incompatibility associated with Go's garbage collector. Because the memory manager is different than it is from C, any language using internal reference counting (python, PHP, ruby) is going to have a hard time calling go directly for the same reason it is nearly impossible to call Java directly from PHP. As with the link, people *have* done by going through a C layer, but it's hard. If it was me, I'd probably either go gRPC or shell out :(
I see. So it's definitely not a solution for the end goal. I really like gopherjs. I just wish things didn't get slower when using encryption algorithms. 
Any findings/updates to this problem. I am seeing this same problem as well - $ go build # github.com/test In file included from C:/Users/Raksac/src/github.com/test/shared/minwindef.h:182:0, from C:/Users/Raksac/src/github.com/test/shared/windef.h:24, from C:/Users/Raksac/src/github.com/test/um/windows.h:168, from .\test.go:71: C:/Users/Rakesh/src/github.com/test/um/winnt.h:154:2: error: #error "No Target Architecture" #error "No Target Architecture" ^~~~~ 
The thing that gets frustrating with Makefiles is when you want to automate more complex project tasks. You're right that doing basic builds is pretty simple, but if you start adding operational code in the mix things can get more complicated. For example, if you start adding ansible plays that you drive with Makefiles to perform releases on actual nodes. While you could argue it is better to do that outside of your code repository, a Makefile is a great way to communicate how to do things with your project, including releasing and operating the code. In many projects I've worked on, we use a Makefile to help communicate how to get started in development in addition to how to automate common tasks. We then started using our repo + Makefile as the entry point for other tools like chatops and CI. Basically, if you wanted to perform some task, you'd write a target in the Makefile that could be called from a parameterized build in Jenkins and triggered via ChatOps or the Jenkins UI. This became so engrained that our managers started using it as UI for updating customer feature flags. The point being is that if we had something like this, it could have been helpful. This might also be a helpful tool alongside a Makefile in that a make target might run `mage` to run more complicated "scripts". In any case, I don't think there is anything wrong Makefiles, but if you start to get more complex, a better system can be helpful. Mage especially makes sense if you have a monorepo where you can capitalize on the rest of the organization's code and help standardize on build patterns such as how to create docker containers or perform releases. 
The first potential use case for patricia that came to my mind was for black/white-listing IPs (perhaps integrating this into proxy layer somehow). Then I noticed the repo is Kentik’s, which totally makes sense, guessing DDOS mitigation could be ideal use for this... Would be curious to hear if u/blakecaldwell is able to share more on if/how patricia is being used in production yet over at Kentik? Had no idea y’all were using Go—very cool. Also awesome that you’re open-sourcing stuff :)
+1000 to the **chroma** project!
https://gist.github.com/cstockton/4ae03a95a1592b43f496c727ca6589da
Wow, that was fast.
Resty first version released on Sep 15, 2015 then it grew gradually as a very handy and helpful library. Its been a two years; v1.0 released today. I'm very thankful to Resty users and its contributors.
Take a look at BoltDB and Badger. Its 100% in Go.
I was going to suggest memsql, http://www.memsql.com/ but I am not sure it's embedable. Feel free to join their slack channel, which devs frequent and ask there.
Is Cassandra columnar? You can try [Clickhouse](http://clickhouse.yandex): it is a lot easier to setup on a single machine (cluster setup is not that easy though). I wrote a couple of packages to deal with data insertion in a type safe manner (and they are no slouch when it comes to the insertion speed) at my last job where we used Clickhouse: 1. [ch-encode](https://github.com/sirkon/ch-encode) to generate serializing objects for given tables 2. [ch-insert](https://github.com/sirkon/ch-insert) provides data insertion via HTTP and buffering And there's a [database/sql driver working via HTTP interface](https://github.com/mailru/go-clickhouse)
I'm not sure if Cassandra is columnar, I might have used the wrong word in the post, what I need is just dynamic columns.
Install Docker compose and docker in a slave. Add a docker and docker compose tag to this node. And then in your job use a bash script with docker-compose up -d and an exit trap on the bash script with ```bash function stopDocker { docker-compose stop } trap stopDocker EXIT ``` 
For 2, something like: if mg.Deps(a, b, c) { // I need to rebuild myself } But at which point this starts to become too verbose ? 
FWIW, wiki already lists a discord channel: https://github.com/golang/go/wiki#the-go-community
Got it. Clickhouse may not work for you indeed, I make a transition of column-store into columnar (column store is frequently used a synonym for columnar). You rather need document based DB. This may work: https://github.com/HouzuoGuo/tiedot But there's a chance CH still suits your needs: how "dynamic" are your dynamic columns? There might be the case you have a wide (thousands of them) pre-known set of columns, not really dynamic columns. Columnar DB will work for you in this case.
So is Hugo now. I have a bunch of code snippets on my site. The new version renders my site about a hundred times faster.
https://github.com/golang/groupcache maybe? It isn't strictly a column store but an embedable cache
I'm currently using Postgres with jsonb storage, where my data format is: { "some-key": [ { "Jan": 10, "Feb": 20, "etc": 5, "attr_1": "some-value", "attr_x+": "other-value" } ] } The problem is that the amount of attributes can be changed at any time. I tried spreading the dimensions with the amazing json tools psql has, but it ends up taking around 4 seconds, and expands 30.000 json rows into 200.000+ rows before filtering. I'm currently just building the queries in Go, and it takes between 700ms to 2s in the worst case, but that won't do for bigger use cases in the future. Looking for options now.
There is also [grequests](https://github.com/levigross/grequests) and [gorequest](https://github.com/parnurzeal/gorequest), which seem to be more popular options looking at the stars, how does go-resty compare to the two?
I couldn't tell you. Only that at the time I started using Go, Beego was the closest thing to what I was used to (Django). After learning Go I started using React for the front-end so I didn't end up using any of the frameworks.
[tiedot](https://github.com/HouzuoGuo/tiedot) then. It is essentially document structure. But there's an issue: you need an index to look for values in certain column. May be a total no-go for you.
&gt; Is Cassandra columnar? [No](https://www.quora.com/How-is-Cassandra-a-columnar-database). And to be clear, this is in the spirit of helpfulness for all concerned, not criticism, since a short post with just "No" comes off harsh.
How big is your data? Are you distributed? Because if the answers are "fits comfortably in RAM I can afford" and "no", my first thought would be to just write some code that does the thing you want. And if the answers are anything else, details will be very helpful in answering the question. A bit more characterization around what data you already have and the kinds of summaries you want would be helpful, too.
Not distributed, and currently not that big. The 35k rows stored in jsonb is around 8MB, very little and I shouldn't need more than 1GB at a time (already considering the future). The data should fit in ram, and at worse, just throwing more ram at it is a feasible solution. I can't see it needing more than 32GB, ever. It's basically analitics data that needs to be transformed (f =&gt; x +y * 10, if x == 'certain_key'), but I need to allow on-the-fly filtering on the frontend. So my basic needs are to store everything in memory for fast response times over websocket, but I also need some performant transformation abilities, like count(), sum(), group by, etc. This could all be done in BI software like Tableau and the likes, but it's integrated to something else and can't be separated. I could just keep a cache, but I'm not sure I'd get the same performance when doing grouping and transformations that a heavy-duty DB already has.
So once you started using react you didn't need any configuration management, environment management, an ORM, a test suite and a way to run them, restarting your app as you develop, authentication and authorization, route management, dependency injection, etc? Somehow all those needs magically disappeared?
I think you may be reading too much into my post. I said I started using React and that I did not end up using a backend framework, not that React somehow magically replaced everything that is needed on the backend. If you've been reading my comments looking for recommendations, I have not offered any and I don't think you've yet asked for any.
oh thats cool, I didn't come across that when I was searching for similar tools. Thanks
You are going to know far more of your own use-case than I possibly could, so I can only generalize. But consider that the reason AWS sdk "feels" the same may be due to it being ported 1-for-1 with the mindset of the SDK being the total environment. While it may be nice on the face of it, consider some other scenarios. Now, if you spend 90% of your time in only the AWS SDK (e.g. developing it, porting it, or a big project that uses it for everything) then a familiarity with the SDK may be beneficial when changing languages. But it doesn't stop you (or the end-user) from needing to learn the Go-way (or any language) for everything else. Eventually, in many cases, said library/SDK gets in the way as it no longer fits with language idioms. A GraphQL library I've been using as of late is guilty of this (why must you throw away my errors, why?). This makes things like testing, composition, or error flows much harder: as a simple API decision made to try to keep things 1-to-1, may have consequences when it clashes with other expectations/best-practices of the new language. Singletons in Go, for example, can be convenient and work well as defaults (e.g. net/http DefaultClient) but can also be a huge headache when it comes to testing, if you rely on it everywhere, in a complex app. If a piece of code uses http.Get directly, then modifying the global default is your only option to add a custom TLS cert, or change timeouts, for example -- but that can affect other tests. An API written for one language, may have decisions made that have specific solutions for testing in the origin language. Designing an API for Go, which may have the same capabilities as the original API, will most likely look very different after you consider: testing, documentation, compatibility, extending, and all the other lifecycle differences between 2 languages. And all of that is not considering when multiple consumers of a library get built into the same app. Go can still accomplish the same things, but the solutions look different for a given problem in language A than in language B. In the case of Go: testing makes use of interfaces in many cases, documentation has requirements on code structure and naming, the practices of forward-compatibility and no overloading, no dependency cycles are allowed, etc... While some things may or could be the same, a lot won't or shouldn't be. Just as well, a consumer of the library (e.g. say, someone who spends 90% of their time in Go, but a small amount of time using the SDK) would benefit far more if the SDK followed the language conventions. They don't necessarily have the domain knowledge of the SDK, as it is simply one of many tools, so the "familiarity" is lost on them. OTOH "familiarity" with various Go libraries can speed things up considerably since everything in your toolbelt "feels" the same, rather than each tool having it's own learning curve (beyond what is unavoidable). The more specific/different it "feels" the more nuances are going to be not-obvious and cost more (context switching, digging through docs, etc..). --- All that being said, a 1-to-1 port, to get something working initially isn't necessarily a bad start. But keep in mind, not only the API but even the implementation will have a whole different set of tools available in Go that can leave the port feeling like tech debt, if care isn't taken. In any case; if you have the freedom/resources to do so, I suggest you to use this as an opportunity to learn/hone your skills in writing idiomatic Go. API building and design can be a lot of fun (for myself at least), even if just porting, and it's a huge boon when you already have all of the "hidden" requirements worked out (a-la working implementation). My Go-to (sorry, had to) is to look through the core packages for examples when I'm looking for ideas, or wondering if something is "idiomatic Go". Though, without knowing more of what said struct's job is, I couldn't point you to anything specific. --- **TL;DR** The expectations and tooling of different languages can all but dictate separate API designs in many cases. Anyway, hope there was something useful amongst all this text!
I've a similar use case coming up in a week. Would love to hear about your solution and the reasons behind it.
I suggest getting some commits in to some public repos, it's fine if they aren't yours.
Is there any specific reason you need it embeddable? Why can't you run something like Postgres on the same machine as the app using localhost or a unix domain socket. Postgres is supported on all major platforms.
Druid
/u/ZetaHunter Thank you for your interest. [resty](https://github.com/go-resty/resty) design is unique and its [capabilities](https://github.com/go-resty/resty#features). Please have a look.
Looks interesting! Looks like you guys ported sentry to go? Ican't promise sponsorship or anything, but I would love to kick the tires / contribute...
If you can't be a sponsor, don't worry, just sign up to the maillist and you'll be up to date with development. Sponsorship is mainly for being involved with the product and delivering value specifically for the sponsors. As soon as we feel the open source offering is ready (feature/functionality wise - actually usable), hopefully that will attract some new sponsors &amp; customers for a paid tier. Until then, feel free to follow along and we hope to get the first version in your hands as soon as possible :)
Neither of those is in-memory *or* a column store.
Confusing beginners is not really helpful: Passing a pointer to a function or as a method receiver is not pass/call by reference. That sounds nice and clever but is not producing a helpful mental model of what's happening. If you are a beginner to Go but an experienced C programmer than pointers don't need much explanation. If you are a C++ veteran then "reference" has a different meaning to you than "a pointer to". If your background is Java then calling a pointer a "reference" makes a halfway sound explanation; just halfway because in Go you can have pointers to basic types and pointers to pointers which are not "reference of reference" in Java. If your are a hard core Python programmer you won't benefit much from talking about "call by reference" because it's not exactly how Pythons name binding work. If you are a total novice in programming (not just a beginner in Go) then there is no need to introduce a technical term which is a) not well defined, b) not helpful and c) not part of the language spec. A lot of people seem to have problems with pointers, especially when coming from high level languages which totally abstract away that computers have RAM and use that to store your variables. To master pointers it is necessary to have a proper mental model of what is going on (this is true for almost everything). A proper mental model for Go could be: Values have a certain layout in memory and variables are symbolic names for a certain area in memory filled with a certain layout/of certain size. Pointers are values. They are one word wide/long and their values are addresses into the long block of RAM. We may store the memory address a variable `v` of type `T` inside a pointer variable `p` of type `*T` like this: `p := &amp;v`. No `p`'s value will be the house-number of the first byte of `v` in your RAM. Such a mental model would be much more helpful than talking about the crude "pass by reference". Some things are not addressable (e.g. map entries) and this can be explained much easier if you mental model of what variables and addresses and pointers are is a consistent and proper one. Try explaining in depth why calling a method on a map index expression might not be possible when your mental model of `func (t *T) method()` is that of "method is called by reference". Try explaining `func f(p **int)` with "pass by reference". "Call/pass by reference" is a pseudo-explanation: It blurs your non-understanding of the internals so much that you are misled into thinking you understand it; just because you have a clever sounding technical term for it. Slices and (buffered) channels have reference semantics. Calling these type "reference types" might be okay, but this type of reference is different from the "pass by reference" so why use the same term here? Could we stop calling a pointer a "reference" and passing a pointer value as "call/pass by reference"? It's not helpful: Not for experienced programmers, not for absolute beginners. 
Thanks, Nate! I've already posted a link to this thread to our internal messaging system for discussion ;-)
Great stuff yet again /u/campoy, so part 2 is ..... [2 weeks away](https://i.imgur.com/M42FZwz.gif)? :)
You should reach out to the folks at codesponsor.io. They're great guys trying to help open source maintainers. It's not a huge amount, but we're getting a couple hundred bucks a month for some open source React projects we've written. I don't have any relation to them other than having met them as they were getting started.
&gt; qod stands for Quick and Dirty bahaha I just realized I got the acronym wrong. It's fine. It's on brand. Quick AND Dirty. That was great, definitely on-brand. Is this something you're going to keep adding to over time? I mean, there'll be a lot of things that'll still be more concise in Python, no?
Great features. Also came across this in the process: https://goreleaser.com/
I already use postgres and jsonb, but queries still take a bit too long. I need sub-500ms queries.
Sigh. A 'script' describes more than just a 'program', the same way a square is more than just a 'rectangle'. A 'script', colloquially speaking, is typically characterised by: 1. Accessed via cli 2. Relatively short LoC 3. Typically using a terse language (bash, python, javascript) 4. Often relying on having runtime dependencies (ie interpreter) 5. Likely isn't performing highly CPU intensive calculations 6. Likely interfaces with a 'low level' language 7. Shebang 8. Often written by one person and a bunch more assumptions not listed. There is a significant distinction between a 'program' which is a highly general term and a 'script' which is a type of program. Yes a script is a program, however a program is not a script. Your comment "A script is a program", is seemingly implying the distinction between a script and a program is not significant relative to the article and I disagree. A script is an application of programming with a particular set of added assumptions around it: what it might do, how to interact with it, potential dependencies, etc, etc. The assumptions (out of my list) the article is attempting to dispel are 3, 4 and possibly 5. 
disclaimer: this is not my game, and as far as I can tell it is not open source. I just wanted to share this to show what can be built with our language of choice.
Goreleaser is indeed a handy tool for releases. Especially for Bjørn Erik (@bep on GitHub, the current main developer behind Hugo) it's a real time-saver: https://twitter.com/bepsays/status/910977202371440640
Very nice - Another interesting direction is to detect faces and do some "content aware" resizing and cropping. 
Thanks, I'll definitely keep that in mind when we go public with the OSS offering. :)
Agreed, focusing in on "important" parts of images such as faces is really useful. I built a movie DB site and dynamically making movie posters etc look good was a nightmare. I ended up using some Python/OpenCV heavily inspired by the following :- https://stackoverflow.com/questions/13211745/detect-face-then-autocrop-pictures the entire thread and all the good/bade sample code is really worth a read.
Another great episode. About the responseHandler returning the data instead of calling write methods: I had arrived at that same pattern myself then noticed most people here think doing the writes (instead of returning data to a handler) is cleaner. Any idea why?
/u/emergencevector
Is this supposed to be an article?
What do you mean?
Maybe it's just mobile weirdness, but I am only seeing a link to a picture of a gopher with a package.
Hmm, you're right, I'll fix it and then post it again. Thanks!
Uses cgo.
You could use AppEngine's image manipulation tools for a similar system. 
I thought i was too dumb to understand this, glad that i have company. 
I took a stab at his recommendation to look through the repo before watching the video. First thing I did was get rid of the packages, it's easier if everything is just in package main for such a small codebase imho. I'm not sure why base62 is a thing or needed here, the encoding/base64 package has an option for URL safe encodings if that was the goal. Overall I think there is too much complexity and code in here for what this program should do, nobody ever died from trimming fat(I hope). 
Maybe we must do a Kickstarter for part 2?
What's the use case for using this over [gift](https://github.com/disintegration/gift)?
How do you mean? gift seems to be an image processing library (not a gopher here). imgproxy is a plug and play server to process images that can be used with any web application with both remote files (such as eBay images, our use case) and the files you've uploaded to your own storage or cloud storage. Something like imgproxy could use something like gift under the hood, but they solve different problems.
They both do image processing-- if you want it to be fast, why would you roll up a server on your own machine? Isn't that going to add overhead time? Is the only use case for this for use in programs written in languages that don't have access to that sort of library?
Not that much of an overhead if you're running a webapp: in any case, you would have a request to a "resized" image under some kind of a proxy and maybe a CDN before that. imgproxy is exactly that kind of a proxy. Regarding the use case, imgproxy goes for speed, security, and convenience. For speed, it uses `libvips` which usually wipes the floor with other libraries when it comes to pure resizing speed, which is what webapps usually do. For security, imgproxy adds image bomb protection; for convenience, it only takes a single request to process an image without the need of doing it in the background, for instance. imgproxy has some pros and cons against other solutions, but the closest one would be the one called imaginary. The use case is as wide as "most web applications", I believe. If you do all image processing inside a console utility or have a bigger Go app, you probably won't need it—just take a libvips wrapper instead :)
Search godoc.org 
I'm sorry, you're just restating the taglines-- what is image bomb protection other than checking to make sure you aren't asking to resize to something really big? Isn't that just a couple lines of code? 
You also can't say that using libvips here is faster than gift, because the app doesn't have benchmarks, and c calls in go have an additional overhead.
You basically asked what's the diffirence between a drop-in solution with a HTTP interface and a Go library to do image processing. I believe I've provided enough info for an answer :)
You aren't answering the question, and apparently don't want to have to justify this app's advertising as having new or useful mechanics. That doesn't reflect well on you or the app. You also continue to use marketing terms in your justification: all libraries are " drop-in solutions".
I'm not advertising anything. This is a reddit post that links to a blog. Look for the "Sounds great! Any alternatives?" header in the original post to get comparisons with similar applications; they all have their pros and cons, as does imgproxy. I understand you would rush to comments before reading the actual post, that is not uncommon. Thanks!
: /
Good call about DDOS! There's tons of different IP-based lists like BGP, GEO, and reputation (bots, spam, etc). We receive netflow from our customers, and fuse it with all of this data. Customers can also define tags based on IP/CIDR ranges. As you can imagine, this leads to TONS of lookups per second - this is a real hot spot for us, so I'm thrilled to have been able to figure out how to keep the GC happy. Our web tier is NodeJS, but just about all of our infrastructure (which is a lot!) is Go. We have some C, but would gladly convert that to Go if it seemed feasible. This project replaces an open source C Patricia tree. The goal was to simplify our stack, because a full-Go service is easier to work with and profile. We expected a performance hit, but as long as it wasn't too bad, it'd be worth it. What's crazy is, after I was able to get rid of all the pointers and kinda fly under the GC radar, this thing actually *saved* a ton of CPU over out C/CGO implementation. It's likely this was the overhead of calling into C from Go. Just like everyone else here, we rely on open source, so it's a real pleasure to share when we can. Please let me know if you find this package useful!
I use github.com/artyom/smartcrop More or less the same but without needing OpenVC 
Or just google: github.com/rwcarlsen/goexif/exif 
You are advertising this tool that you (wrote? Supervised?). You need to be open about the fact that you took part in building this thing you are advertising, otherwise no one can trust you. Your example use case with ebay is the same as the one described in the blog post. How can you claim you aren't affiliated with this product?
&gt; github.com/artyom/smartcrop Thanks, very nice recommendation and clicking through to the JS library it's based on leads to a nice summary of how it works - https://github.com/jwagner/smartcrop.js#algorithm-overview
It's just not something you see every day...
There's an implementation of it in pure Go, too: https://github.com/muesli/smartcrop
Can someone do benchmarks for the library's processing? I don't have access to a computer but Curious how this would be faster than even just downloading the image and pipelining the image data to a C based image processors that uses vector instructions for processing. Not to mention the threat about png bombs is literally non existent if you just set a dimension limit on each image and check the headers. I'm skeptical of the claims of greatness though I can imagine it is easy to use this drop in solution. Edit: I hate typing apostrophes on non US keyboard mappings.
This is some good stuff. Do you know if this can be deployed on Apex or another similar FaaS?
This is a common standard when converting a monolithic application to micro service. If your load is in thousands then it would be cheaper to just do it on the app server. But imagine you had millions of requests with each application being written in different languages or frameworks. Creating a service is much better as you can scale up independently and upgrade without cashing downtime. 
`go help packages` and `go help importpath` are also good reading. Personally I prefer to more direct/concise writing style of that, but to each their own I suppose :-)
Right, but this is basically just a microservice that checks your image dimensions and then calls a library to resize it. There's hardly any code here, and you could probably write a service like this yourself in an hour. Not only that, the use case doesn't justify a microservice, they only served a million images in three months. They also make speed claims without benchmarks, and refuse to answer questions about the product, and refuse to associate themselves with the product. Why use this if you can't get an answer from the dev when you have an issue?
Yeah, I agree. After reading those, you can read this article as well. It's more like a curation from all other places like `go help packages`, web, and my own experiences.
In addition to what others said: The best projects to contribute to are the ones you actively use and want to improve. :)
I've had to import phone images that had no exif data for orientation, and they tended to be rotated 90 degrees, so I decided I needed to use OpenCV to determine face orientation... which was enough to cancel the feature request for uploading profile photos. If it doesn't seem to work, keep in mind that you can't assume all devices will save the data, though that might not be as common anymore with current hardware.
base62 is for nice human-readable URLs, I suppose.
I almost always like to split this type of thing out of a web app because the image manipulation might grow to have C-deps and a weird build process long before the bottleneck is processing, and I don't want that to put non-web processes in a web app (if I can help it) for that reason.
don't give me ideas ... hahaha I *might* release part 2 on Monday, but I'm currently traveling and need to do some planning first
Having each handler do the writes is definitely a good idea, and it generalizes better. In this case, though, since the format of the response is common to two different handlers I'd rather keep all of that in one place. And that place could be either a function called by the handlers, or a function wrapping the handlers. The latter is better imho for the reasons explained in the video :)
I don't want the types of dependencies that could enter an image library in my web app. For example, the last time I had a project needing to resize, I also needed to use OpenCV because exif data stored incorrect rotation data. As image manipulation needs grow for a web app, I think OpenCV and perhaps OCR will be a common need for many users who won't want Cgo in the web application. The existence of benchmarks, how the author refers to the product, or how simple the code might be doesn't bother me here. It is an MIT licensed project and could be used in almost any way, including contributing back or forking. This is the most generous license and asks nothing from the user. It's up to any user to decide if they want to learn from the code and do something similar, use it, or decide to go another route entirely. Personally, I'd probably take a look at the code and write something more specific to my needs since the project is very simple, but it is trivial as well to come to that conclusion without any time wasted, and I still appreciate the example project.
 internal packages Naming your packages like this allows you to hide your package’s internals even more, brings more encapsulation. This is a kind of an advanced package name and you don’t need to know about this when starting with Go. Go provides no sub-packaging mechanism and this is also a solution for that problem. When you split up your packages, anyone can import them. This prevents packages to be imported by the order you define. Could you please elaborate on this? Specifically how this could be used as a solution for sub-packaging. One thing I dislike about using go for web server functionality is that if I want to break my handlers into separate directories for code organization, I need to explicitly inject my dependencies into each handler because the build tool treats it as a separate package. But to me a webserver handler is tied to the main web server and I am not likely to try to get reuse from it on another server, I would just rather share a global database pool implicitly to each handler, rather than inject it into each handler. I created my own build script to support this on my web server. I structure my code in subdirectories but at build time its all resolved as one large main package and compiled in a staging directory. I have heard the criticisms of this approach but to be honest its working great for me and my specific use case. To me what would be more ideal is that the Go build process would allow me to specify these sub-directories as sub-packages, which would implicitly share the main global state with the subpackage while maintaining the remaining package level distinctions. Not sure if that is what you are indicating the internal package allows. 
Thanks, I've updated that part of the post to clarify things. As I've said in the article, there's no sub-packaging in Go. *Internal* convention is more like *an access-forbidder* rather than *an access-granter*. **It prevents some of the other packages to import your packages.** For your case, maybe a generic struct that contains every dependencies that your handlers need can solve the problem. env := &amp;struct { *pool ... } package1.handler.New(env) package2.handler.New(env) 
Aha, that makes sense. Thank you.
I had previously thought of that but then I was fighting cyclical dependancy issues with the build tool. How can you make the main package and the subpackages share the generic env type without re-declaring it in every package? 
Cyclical dependency issues may mean that your design of your program is not simple and/or explicit. Or, maybe it's too abstract. I can't tell you without seeing your code. &gt; How can you make the main package and the subpackages share the generic env type without re-declaring it in every package? Why not just put it into a HandlerEnv package and let main and handlers use it there?
The correct link to this article is [here](https://www.reddit.com/r/golang/comments/72jxd3/definitive_guide_to_go_packages_focus_on_the/).
Previously I was trying to pass the env struct from main into the subpackages, which would then not allow me to import main to get the definition of env. I think it would work though the way you are suggesting. Each handler package would then access the global database pool through a copied version of the global database pool pointer, initialized at server startup. And all modules would import the definition of this struct from the HandlerEnv package, preventing the cyclical dependencies. I wonder if this would have a compile or startup cost penalty or not.
&gt; I wonder if this would have a compile or startup cost penalty or not. Not a bit, trust me :)
Thanks for all your responses. I will definitely give that layout a shot. I assumed the go compiler would be smart enough to make this either a trivial or non-existent performance cost, but I am a bit vague on what happens if a package is imported multiple times by various packages within a project.
Just out of curiosity, would it be possible to get you to do a code review of [one of my projects](https://www.github.com/DeedleFake/wdte)? It's not fully finished and it's lacking some polish, but it's in a mostly usable state right now, and I think a code review would be nice at this point while I work on some polish details and a few features I already have planned in between college stuff.
No problem! There's no multiple-package importing in Go. Packages are imported only once.
The one /u/1Gijs mentioned was forked from that one, to remove a dependency on OpenCV. It looks like they've merged his changes now, though.
I appreciate your explanation, and respectfully disagree.
Sentry isn't the nicest thing to set up, I can agree with that, and there are a lot of parts to maintain and monitor. I've done a docker-compose setup for it previously, and the db initialization is annoying. Something that you can painlessly "docker-compose up" and scale easily, with health-checks would be great. Fixing errors as a bragging stat is (imho) a bad idea. It is biased against people who test well enough that they avoid introducing errors, and potentially encourages Hero syndrome which I've seen a number of times in developers who liked to brag and not make the code they owned less error prone. 
Awesome, finally code I can understand and has a lot to do with the standard way of doing things. Please make more.
Or content aware compression where important parts have increased quality and background stuff looks like shit. I wonder if that's a thing already or even possible with current file formats.
&gt; URL-secure Base64 We call that URL-safe. It has no security properties.
This is a frequently built wheel: https://github.com/pressly/imgry https://github.com/willnorris/imageproxy https://github.com/oysterbooks/halfshell 
True; we've used imaginary as well, seems to be the most popular one, with lots of features. Comparisons are right there in the post.
There's a tradeoff either way. If your functions don't match the http.HandlerFunc signature, they can't be composed with things that expect to receive handler funcs, but they can be tailored for your needs. If they do match handler func, you can compose them, but you can end up with repetitive or error prone code.
I did one today. It focused around writing a really basic restful API, following a spec, and the unit testing to go with it. Took about an hour. Another couple I've done have focused around using maps to store data.
Ah, that's not to bad. I'm assuming it focused on doing your implementation using the standard library, or could you have used the gorilla toolkit or something? I just got this book from Amazon called [Data Structures &amp; Algorithms in Go](https://www.amazon.com/dp/1976503302/ref=cm_sw_r_cp_api_KcSYzbE342VT3) and it seems to be written from the point of view of preparing for more traditional interviews. Go just seems more practical so I would expect more interviews like yours, but I could be wrong.
I chose to use the standard library, but I could have used a different toolkit if I'd wanted to. My API would have been easier if I used labstack echo for handling the http server, but net/http was fine.
It was a fleeting thought. If there's enough interest, maybe some sort of status board could be made, mainly for OSS projects, to pair the stars to error resolution, maybe. Didn't mention this in the intro, but we're aiming to support mysql and pgsql out of the box. As long as you're fine running either of those databases, docker-compose up isn't going to be a problem, and healthchecks also not :). I have [some experience with such things](https://leanpub.com/12fa-docker-golang). p.s. seems everybody and their dog created their own sentry packaging in docker. Just goes to show that it has problems unlike go which would result in a single binary which you run. That's it. p.p.s. currently we're not aiming to support an embeded database (at least not sqlite because of CGO), but we should be able to support cockroach db, if that's somebody's thing. Would love to consider some embedded database client driver with a reasonably compatible SQL layer to mysql/pgsql. With over a decade of experience with those, writing the same query that works on both systems is not a problem... yet :D
I've been using Go professionally for about 4 years now, I have interviewed lots and hired plenty of other Go developers, and I was in several job interviews for Go positions. I've had everything from some basic programming tasks ("build a REST API to store and retrieve whatever in-memory data") to questions about intricate details and semantics of language elements to just general discussions about large-scale architectures without any coding exercises. I have not witnessed any focus on DevOps tasks. Everyone I've had contact with, including in previous and current jobs, used Go for backend development, usually web services or microservices of some sorts. When I interviewed people, I primarily checked that people could demonstrate an understanding of Go and some language-specific features like chans and goroutines, that they had sufficient communication skills to discuss their code in a review, and that they had some general ideas about how to architecture code and make it testable. Of course, every interview is different, but if you can present and demonstrate your Go skills, you should have pretty good chances, especially since Go developers are currently highly sought after.
Thanks for the information. I hope you get that job.
Thanks for sharing, I've just ordered ten myself. I would be glad to mail out the extras to fellow gophers once they arrive, just leave a reply if you are interested.
...so?
I've applied for a few Go roles and I get the impression that employers are looking for willing Go converts, rather than experienced Go developers. Was this true in your case?
So it breaks go cross compatibility. I wouldn't complain in that case since the reason is legitimate and because imgproxy have very convenient to use heroku buildpack and docker image. It's certainly something worth documenting though.
Very interesting. We have taken a slightly different approach with [dnscontrol](https://github.com/StackExchange/dnscontrol), by attempting to be a more complete dns management platform. I kinda like this notion of trying to find a simpler api that everything can implement. The problem I keep running into though is that every single dns management api is completely horrible in completely different ways. It is very hard to find a common api that works uniformly across the quirks of different providers. I may look into this deeper though and try to make providers from your library as a dnscontrol driver.
Just realized your current provider interface is pretty limited at the moment. Do you have plans to implement more record types? 
Shameless plug for [dnscontrol](https://github.com/StackExchange/dnscontrol) if you are looking for a more fully featured system for managing DNS.
Thank you OP for this open source project. I understand that you aren't trying to sell a product or service. I appreciate that you've put effort to document it and followed Twelve-Factor-App. The included buildpack and dockerfile makes it a breeze to spin up an instance, to scale, and to integrate within our current organisation. Some people just don't get the difference between a library and a web service but they are more than welcome to waste all their effort reinventing something already done and attempting to maintain it across different projects. No one was saying it and I felt awful seeing this stupid comment thread with just you two.
I know the difference between a library and a web service. Please stop promoting OP's attempt to tarnish my character.
It was a detail I was looking for and wasn't documented anywhere. If something uses cgo, you suddenly have to mind the dependencies of the library in question which can introduce a whole new world of headaches.
I didn't just answered every questions that was asked just by describing how OP software was built and the advantage of using a similar software. I'm also not saying that you're being rude and dense.
I can't tell if you're being sarcastic. Please let me know, so I know whether I should block you. I don't really enjoy trying to explain myself to people who don't respect me, but if you aren't being sarcastic I'd be happy to attempt to explain or restate my perspective.
I'm not following. If your handlers aren't http.Handlers, then you have to have something to turn them into http.Handlers, at which point you can compose them with things that expect http.Handlers.
At my job we use go for our backend, but asfaik we don't use channels or goroutines. Are we missing out? What kind of use cases are there for your typical backend?
this looks very similar to https://www.nomadproject.io/ what is this attempting to accomplish that nomad, marathon, or k8s can't?
That's pretty cool. I've been toying with the idea of rewriting an API with gRPC + grpc web-proxy but I haven't really found any documentation on how http headers translates and how caching works with grpc. For instance, the API is sending the etag/last-modified header to clients and they can send to the server the if-modified-since header to save traffic. Is it possible with grpc/the web-proxy?
Absolutely. Definite work in progress. Any common Python idioms leap to mind as examples?
I'll take no answer as a no. You didn't actually answer the last question I asked, which was why the feature of image bomb protection was being advertised when it amounts to three lines of code. My issue with this product is very related to that-- its features are very small things (that have already been done before). This would be fine if it offered any of 1) significant documentation, 2) tests or 3) benchmarks, but you and I both know it has none of those things. In Go, a little dependency is worse than a little copying. This project goes against that principle. Not only does it go against that principle, the owner of the project doesn't want to respond to questions about their project. Not only does the owner not want to respond to questions, when asked, they spew out marketing advice, like how it's important that this is a twelve-factor app. The headline reads like marketing: "lightning fast!" -- but there are no benchmarks "secure image resizing!" -- what about image resizing needs to be secure? This is just referring to the communication protocol. "tiny footprint!" -- but there are no benchmarks "protection from image bombs" -- but according to [an issue](https://github.com/DarthSim/imgproxy/issues/8) on the project, this protection is overzealous and makes the project difficult to use for real use cases. Other issues reveal that, due to lack of testing, the product [doesn't even compile on linux,](https://github.com/DarthSim/imgproxy/issues/10) and its dependencies are apparently ill-specified. This project is flawed on a number of levels. Most importantly though, is the way that I was responded to in this thread by OP. They treated me as if I hadn't read the article and openly mocked me. You shouldn't get to openly mock people asking reasonable questions from your project and get away with it. PaluMacil offered a number of reasons to answer my questions that, while I still disagreed with, were answers that OP should have been able to provide just as well. I hope you do read this, I do think we can come to at least respect each other.
very cool, I didn't realize there was a pure Go library for this. I've just added support to [imageproxy](https://github.com/willnorris/imageproxy) (see example at [the end of here](https://github.com/willnorris/imageproxy#examples)).
I work for Dropbox. We have very large Go codebase. Questions are never go specific on our interviews - you will learn it during onboarding anyway.
Heh, this looks awesome, like those old Atari vector arcade games.
Actually they are, both use mmap, so, if you have enough memory, the OS gonna keep everything in memory. About the column, just serialize a array and you have columns. 
Nice, well done!
I know we had more positive interactions in the past so I'm willing to sit down and maybe bring things to a better understanding. You come off as being really rude to OP and dismissing the answers that he took the time to give you. Maybe this is a language barrier, maybe you are assuming the worst out of him, it's not my place to answer the why. You have asked some good questions which OP answered but you always dismissed them as marketing gibberish. You are claiming that both him and me are marketing a product (he's not selling anything, he's sharing his interesting project), you are lying by saying that he refuses to answer you (we can all see that he did answered you), you also sort of shat on his project and the effort he put in it by saying that there's hardly any code, that it could be done in one hour, that it is flawed, etc. You just said that he openly mock you. Either he made a comment which mocked you and he deleted it, or it didn't happen because there's nothing in this thread from OP that is mocking you. You have to realize how rude you were. You have raised some excellent points over the claim made on the footprint and the speed, there's no benchmark to prove it or judge how suitable the tool could be in our organizations. However, those points are entirely lost due to the tone and attitude that you chose to take, this is why you were heavily downvoted. I imagine the root cause is that you had trouble extracting the information from the answers he was providing you, I'm sorry if this is a bad assumption but I really can't see how else you would interpret it as just being marketing tag-lines. I can't exactly go over everything that was said so I will attempt to use a broad-brush to convey the essentials. [Twelve-Factor app](https://12factor.net/). I get it that you could see that as marketing, it's sort of is a buzz word but it mean something, it has a context. If someone goes "We follow Twelve-Factor" I know what it mean, I know what I can expect from their app. It's a bit like saying we got a RESTFul API, we're using git flow...they all mean something tangible. If he says it follow 12f that mean that his dependencies are declared and isolated (vendored +README), that it can easily be used in continuous integration, that it is configurable through environment variables, etc. What it tells me is that this app is ready for the cloud, it can be (or already is) containerize, basically that it isn't a huge pain to get up and running. His project is fairly documented, not the code and this is alright for who this tool is for (more on that below). OP tried to explain why your comparison of a micro service vs a code library is incorrect. Maybe I can give it a different spin. A library is useful to programmers. If I wanted to I could write a CLI that import an image processing library and use it. It would take a while to get it how I want it to but it won't be terribly useful sitting on a server. Maybe I could write something server side but it could break very easily and I will have a non negligible amount of effort to integrate it into my current code base. If I want to take my time to code something like that, I want the library to be well documented. His software isn't a library but a self-contained web service. It doesn't matter that the code is poorly documented because I'm not going to look at the code, I'm not going to modify the code. I want to just run it. I will read up how to use it, then I'll be done. You could run that on the same machine as your current project, on a separate machine, or scale it to multiple machines. The effort to put it into production is extremely small (one click of a button with heroku) and the effort to integrate with your current code base is also small since you only have to do http requests. Hell, you could even use the same web service to power multiple projects.
Hi, this is a pet project of mine I've been working on for a while. When I started it, there weren't any real options for arbitrary-precision decimals other than cgo bindings. My goal for 1.0 was having it pass the FPGen test suite, and I finally got around to it this last week.
This: &gt; I'm sorry, you're just restating the taglines-- what is image bomb protection other than checking to make sure you aren't asking to resize to something really big? Isn't that just a couple lines of code? Is the question that wasn't answered. In retrospect, I could have worded it in a less accusatory manner. OP's response to this didn't refer to my question, and that's where I considered their character mocking: uses of sarcastic ":)" and "Thanks!", and saying "It's okay that you didn't read the article" in a condescending tone, when I felt the question I asked wasn't answered. And perhaps, because OP didn't actually code this (they said they weren't a gopher, so I'm assuming that), they don't know how it was implemented and can't clarify, but if that was the case that's all I wanted to hear. I was rather short in what I wrote because I was writing from my phone, and that can come off as rude, but prior to the response to this comment I wasn't attempting to be. I apologize. I still think this project overly uses marketing keywords, but I think that's something we'll continue to disagree on. I don't associate the twelve-factor app with anything substantive, from my time sitting through talks praising it in software engineering jobs (and then working on projects that followed it in name only). I understand OP isn't selling anything, but that doesn't mean marketing and advertisement aren't things used to promote projects that aren't being sold at the time. In addition I had a question that I didn't ask and failed to implicitly ask, and that was why use a microservice over a library for this small a dependency. That wasn't something that OP addressed, was something other commenters addressed, but I wasn't clear about that being the question.
Cool. Are you aware of: https://github.com/cockroachdb/apd ?
Checking the headers likely isn't enough - there's no guarantee they're accurate. I've seen problems before where the headers seem fine but the attacker put far more data after it. Malicious / malformed data can cause a crash or arbitrary processing time with sloppy programming
Yeah, they originally looked at my library for use in their database, but because mine was fairly immature at that time they decided to write an implementation themselves. (From what I recall, their reasoning was it's better to have a simpler implementation that they own and can prove correct, which is a good idea for a database IMO.) We also have different goals wrt the direction of our libraries, but theirs is a good one!
Well when I said header I was including the first critical IDHR chunk which contains image dimension and compression information. Technically you're right since this isn't part of the header. Technically. At least for PNG this absolutely is enough however in both theory and practice. Edit: Also seriously if you're gonna downvote at least look at the specification and TRY to tell me a scenario where dimension limiting will allow a PNG bomb to pass through vetted image processors with a malformed IHDR chunk. I'd rather be wrong and learn a contradicting case, but if you're downvoting me because I refuted something someone said no one gains anything. We are programmers after all, all of us gain from discussion.
I'm currently using github.com/shopspring/decimal which has been a real life saver with the SQL interfaces and marshaling included in the package. I'll take your package for a spin as well. Very glad to see people contributing to things that to be blunt should be in the core library already!
That library is one of the reasons I decided to make my own. I'm not sure how far it's come, but at the time it still did stuff like converting to a string and back again for division. That said, I'm glad at least _somebody_ had the good sense to create a library at that time, lol. Also, at one point I tried to get it into the /exp, but not too long after they decided to axe new additions :/
So we are done comparing NodeJS to Go now?
Compared to all the other solutions I've seen so far my project is much more simple: you don't need to install anything, just write a config file and mount it into a container. That said, of course this is just a very small pet project I wrote in a weekend and is not comparable with the tools you mentioned which are complete solutions. So if you are not just playing around, I highly suggest you to go with one of the solutions you mentioned!
If your problems are easier to be solved using goroutines and chans, then use them. Don't try to use them for everything, though.
Now write an app that steals Instagram posts and submits them to reddit. Let the sweet cycle of karma begin.
Seems like they could just randomly generate their inputs from some sample space. Then actually implement the algorithm to compute the correct outputs. I like to do something similar for unit tests... I always seed the rng with the same number to make it reproducible across builds when testing. But they neednt do that. 
&gt; Actually they are, both use mmap, so, if you have enough memory, the OS gonna keep everything in memory. That is not the same as an "in-memory database", but fair enough. &gt; About the column, just serialize a array and you have columns. Literally the opposite of what a column store is. (not saying that you can't implement a columnar database on top of a key-value store - but what you are saying is a little bit like saying "boltdb is a perfectly fine SQL database", just because it's possible to put an SQL engine on top of a key-value store)
New here what can I do with this
These are the essential open source packages you seek: https://golang.org/pkg/ Know them well and use them appropriately. Become intimately familiar with the standard library and its design.
I wrote it to help me solve the cryptopals challenges. http://cryptopals.com. I've only made it through the first two sets so there's plenty more to add to the library.
Very cool. How does it compare to https://godoc.org/gopkg.in/inf.v0 ? How do you handle division if there is no exact representation for x / y? inf for example makes a distinction between *QuoExact* and *QuoRound*. Very nice to see someone trying to fill this gap.
&gt; you will learn it during onboarding anyway Wondering how's code quality of a large codebase written by first-timers. Alternatively wondering, whether you guys spend 50% of your time doing code review?
I'm not actually a Python developer, I was just curious. Though I will admit, having seen the Python vs. Go code I'm a little intrigued now!
Cursory glance says mine has more features, but I haven't checked that one out yet. Thanks for pointing me towards it! &gt; How do you handle division if there is no exact representation for x / y? If x / y doesn't have a terminating decimal expansion Quo rounds to the context's set precision, which defaults to 16. You can check to see if your decimal was rounded via the Conditions method.
How long did it take to render the 500 objects image?
[removed]
BTW, it is a published IEEE paper.
But if you're judging based on running time, it's only fair that everyone gets the same input. Otherwise you run the risk of someone getting a worse score than they deserve because they happened to get harder test cases than their competition.
 This was not done as you were allowed 60 seconds per test and simple DoS would be to run tight loops for each run taking N minutes to complete. Better to allow say 100 runs or as many can fit within 60 seconds. Several of my solutions were &lt;40ms and the longest was ~700ms so this would seem reasonable.
Ah, that makes sense. That does sound like it would work. (I ain't downvoting you, don't look at me!)
As an example, you can have an API that returns the expected json response on the main thread, but spawns third party notifications and tracking on separate goroutines.
If you are an experienced programmer its fairly difficult to write 'bad' go code, especially if your code is reviewed by someone more skilled in go. Go is very opinionated, and very simple. I've never been a huge fan of procedural languages until using Go. Greg Wilson cites some studies in [this video](https://vimeo.com/9270320) saying code review is the most effective way to eliminate bugs early, even more effective than unit testing. my $0.02 
We use a popular cloud development platform which has a built in delay method, which I'm guessing does roughly the same thing with some syntactic sugar - or maybe its just a way to limit the number of open chans or goroutines a customer can use.
Combine with https://github.com/carlmjohnson/shitpic for maximum memeage.
Why does everything have to be reduced to the letter acronyms? Am I the only one who has to look up what CAS was? PS this wasn't something negative directed at op, more a frustration with the situation in general and my own lack of knowledge
Computer algebra system ? A software program that facilitates symbolic mathematics ?
This was by far the most interesting part of the Vivint contest. :)
FYI, this is why Go does not have atexit: https://groups.google.com/d/msg/golang-nuts/qBQ0bK2zvQA/vmOu9uhkYH0J -jeff
Hi Jeff, Thanks! This project is an approach to help libraries imported by programs to be able to participate in the shutdown process. 
It took 5 hours and 8 minutes to render on a Intel® Xeon® Processor E5-1650 v2 with all 12 processors. Mean CPU usage was ~90%. Image dimension: 1200x800 with 1000 samples per pixel.
Code quality is ok. Go was designed for not requiring years of experience. Dropbox is hiring nearly hundred engineers per month - there is just not enough gophers out there. And yeah, we're spending some quality time reviewing code. 
True but I figured it would close to average out. Also sometimes life isn't fair.
`requestedPage := path.Join(assetPath, r.URL.Path)` You should clean that URL to prevent people from doing http://example.com/../../../../etc/password or whatever.
It's a commonly used acronym used in mathematics/computing field.
Correct. It does things like integration, expression manipulation, taking derivatives, etc. 
Perhaps too common. I had to look it up as well because there are so many uses for that acronym. As an example, I've been dealing with CAS a central authentication service protocol at work, but there are also specific uses for math, there's something in .NET and I'm sure it's used elsewhere as well.
Too bad it doesn't work. At least I couldn't get it to work on chrome.
I most definitely shouldn't, as it's going to http.FileServer. &gt; FileServer returns a handler that serves HTTP requests with the contents of the file system rooted at root. Here's a test for you: # telnet localhost 8080 Trying ::1... Connected to localhost. Escape character is '^]'. GET /../../sync.sh HTTP/1.0 HTTP/1.0 301 Moved Permanently Location: /sync.sh I verified the file exists beforehand. `http.FileServer` also provides you with a directory listing, so it would be pretty awkward if you could traverse outside the root folder. ~~Your comment would be valid if I used `ServeFile` for this purpose. Which I'm not :)~~
Actually, [ServeFile](https://godoc.org/net/http#ServeFile) will reject any path with a '..' in it as a safety measure, so that's safe as well. My point was more that someone could copypasta your code and adapt it into something unsafe, but I agree that it's fine as long as you use FileServer/ServeFile.
Does it need macOS also for Android only development?
This is really cool and a great example of how artificial sleeps can create timing attacks.
Windows definitely doesn't work atm. Linux is a maybe, I haven't tried it myself.
I didn't know httputil until now
Sure, people should follow secure coding practices (which aren't really the subject of this article). Edit: ServeMux sanitizes URL paths, so at least in this case, even with `io.Stat` usage, the example is safe due to the implementation details of the net/http package. Care would obviously need to be put into that if the path would come from a query parameter, POST variables or some other source. There's a detailed post next to yours regarding implications of theoretical attack vector, which at least in this case isn't there, but worth considering in other cases.
No worries, it took me a long time as well! No shame in that, the stdlib is quite large and there's still a lot we don't know :)
So would you say the interview questions are more on the algorithm and data structures side? In order to see if the candidate has the basics down?
I got this impression too, especially because Go is fairly young.
It helps that go is quite a small language and relatively easy to learn. Experienced programmers should pick it up quite easily. There was a stack overflow survey about languages and I noticed that Go was significantly more popular in the US than most other places. That must be a factor in finding a role and in how many candidates a company will find that already have Go experience.
It's 50/50 algorithms and system things(like how files API works and such stuff). Also, there are concurrency questions for experienced candidates. I believe it's pure algorithms only for new grads. 
The idea is to make the running process inspectable. The stdlib package debug/pprof for example can be used to set up an http server that gives GC and go routine stats. You can do the same to allow a 3rd party to inspect your process by making your "server" type implement the relevant methods so you can effortlessly see what it's doing from outside.
Update to clarify "3rd party" in my initial description means something like collectd or telegraf with the JSON input source plugins.
I can only see a reason to do embedded for very light setups, where an attached volume might be sufficient. It could be worth thinking through what it means to run it yourself - that doesn't need to mean on-prem these days, and an AWS Cloudformation stack with aurora and auto-scaling of some sort could result in a very hands-free deployment if done well.
Looks good I was looking for something like this
Noted, the argument for embedded is mostly something that will get you up and running quickly (as a test which you can then throw away). I think it's going to be better to do an online demo and just make it clear you need mysql or pgsql to run it yourself.
ELI5?
So if RPC is bad, is gRPC also bad?
Thank you :) hope it helps you!
looks as a good start. Btw for those interested there is flutter that works quite fine for most apps
If you have more than ~~256~~ 1024 logical processors from Go 1.10 onwards you can use them all. EDIT: As others pointed out - the current limit is 1024, not 256. It was changed in [1.9](https://go-review.googlesource.com/c/go/+/45673). It also interesting that before [1.6.2](https://go-review.googlesource.com/c/go/+/22206) you couldn't even launch Go apps with GOMAXPROCS bigger than 256 and not get an error.
Add `$GOPATH/bin` to your path
The build executables should be saved in `$GOPATH/bin`, which you could add to your path. How, depends on your os; on Linux, something like `export PATH=$PATH:$GOPATH/bin` in your `~/.bashrc` should work.
Nice stuff, but why did you put the logic into the "pkg" package?
For all of us concerned :D
For a concrete example, at work we have a batch process that can take several hours. We use expvars to tell us where in the whole process we are at any given time, originally they were string vars but because we use datadog for monitoring, and they only support numeric values, we keep a list of numeric constants. We also have other variables to tell us the rate at which we are processing the data that comes in. It is really handy and easy to setup.
The Go-specific questions I've been asked at Go shops are mainly bozo filters with obvious solutions: recognizing when you should be using channels, goroutines, etc (e.g. how would you download hundreds of URLs in parallel and save to disk). Everything else I was asked were standard data structures and algorithms questions, API design, etc. which is easier to whiteboard with Python. I've gotten an offer at all three Go shops I've interviewed at over the last couple of years, so that's saying something.
now kith
I should have specified I am working on Mac OS, of which I am not the biggest export on. I believe I have added the path properly; when echo $PATH I get "/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/go/bin:/bin" which indicates that /usr/local/go/bin is added. However, I am still getting the same behavior as mentioned before :-( edit here is my terminal output just now: Calebs-MacBook-Pro:~ calebhamilton$ go get golang.org/x/tools/cmd/goimports Calebs-MacBook-Pro:~ calebhamilton$ goimports -bash: goimports: command not found
What does `echo $GOPATH` report? I suspect it is unset and your binaries are in $HOME/go/bin. 
You are right. It is set to nothing.
Okay. It’s like PATH; you can set it in your bash file. If you set GOBIN, you can specify a separate location for just binaries to be saved to, apart from source files. The default on Mac OS is ~/go/bin. 
OK I think I am closer, but still getting command not found. I'm beginning to realize how little I actually know about unix based systems :-(. Here is my terminal output: Calebs-MacBook-Pro:~ calebhamilton$ echo $GOPATH /Users/calebhamilton/go Calebs-MacBook-Pro:~ calebhamilton$ echo $PATH /usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/go/bin Calebs-MacBook-Pro:~ calebhamilton$ go get golang.org/x/tools/cmd/goimports Calebs-MacBook-Pro:~ calebhamilton$ goimports -bash: goimports: command not found Calebs-MacBook-Pro:~ calebhamilton$ I attempted to set GOPATH to my go installation, but that throws an error about not setting GOPATH to GOROOT. edit: I'm stupid, it isnt in my $PATH echo. One minute...
OK got it. Thanks for the help!!
 openssl x509 -in cert.crt -text -noout
sure, but it only shows the root cert, and there is: openssl crl2pkcs7 -nocrl -certfile certs.pem | openssl pkcs7 -print_certs -text from http://comments.gmane.org/gmane.comp.encryption.openssl.user/43587 or pbr certs.pem I made the later so it would be much simpler than the alternative.
&gt; there is flutter that works quite fine for most apps Flutter is a Dart thing, right? How's that relevant in /r/golang
&gt; ErrorHub is currently in early access, supporters get access to private builds before the Open Source version will be ready. No, thank you.
Dynamic columns is very much not what "column-store" means.
Plot twist: OP is not looking for a column store: &gt; I might have used the wrong word in the post, what I need is just dynamic columns https://www.reddit.com/r/golang/comments/72et0y/inmemory_columnstore_database/dni45nv/ 
512 ought to be enough for everyone, right?
- _MaxGomaxprocs = 1 &lt;&lt; 10 1024? :)
Nice idea. The `__snapshots__` directory is truly ugly (use `testdata`), and it does nasty things with flags. For something similar implemented very differently, see the approval tests in my utterly unfinished X statusbar project: https://github.com/tv42/quobar/blob/139f6533afd766dc8b8f4ea013952bb393171922/draw/sparkline/sparkline_test.go#L37 https://github.com/tv42/quobar/blob/139f6533afd766dc8b8f4ea013952bb393171922/draw/truetype/truetype_test.go#L35
Firstly, nothing to criticism this project. It is a cool and great project! Secondly, I am wondering for a very long time that why most mobile app development tools need a Mac machine to develop and package apps. React Native, Flutter, SDL, Go Mobile, none is an exception. Up to now, I only have found Adobe AIR SDK doesn't need a Mac machine to develop and package iOS apps. And the development experience is quite smooth. Is it really so hard to develop iOS apps without a Mac machine totally? But why Adobe did it? and did it very well?
This is insanely cool! I had always believed that building cross-platform mobile UI apps [almost] completely in Go will always remain an unachievable dream. After seeing Matcha, my belief has shattered and I can't sleep :) How about launching crowdfunding campaign to make this project a real production-ready thing?
Its mainly because Xcode does a lot of stuff that would be pretty challenging to reimplement yourself. I don't know how Adobe AIR does it.
Everything old is new again. Up through JDK 1.1 Java only had green threads.
I like this. I feel there's an opportunity to build much simpler certificate tooling, and Go is as good a language as any other to build it in. square's certstrap is a perfect example of a tool that makes a no-brainer out of a previously very convoluted process.
Thank you! I really appreciate that. Yeah, I'm still trying to figure out how to fund development on this. I'm not really sure where to start.
You most definitely should clean the path if you make a fs system calls on it. I also disagree with the sentiment in a later reply that while you believe people should follow secure coding practices, it's not the topic of the article. But even if you punt the responsibility of security to the reader, I think it's a very poor example of serving files and **it DOES have a security vulnerability**- though it is not severe it offers adversaries intelligence that could be used for more advanced attacks. Your example: var serve = http.FileServer(http.Dir(assetPath)) // I assume serve is this func serveIndex(assetPath string, serve http.Handler) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { indexPage := path.Join(assetPath, "index.html") requestedPage := path.Join(assetPath, r.URL.Path) _, err := os.Stat(requestedPage) if err != nil { // serve index if page doesn't exist http.ServeFile(w, r, indexPage) return } serve.ServeHTTP(w, r) } } The entire purpose of using the FileServer handler is for a simple and easy way to serve a list of static files, leaving all interactions with the file system to the standard library. If you wanted more granular control you should have required a FileSystem instead of the asset path. You could create a FileSystem in the handler, but it's much better to have the T of FileSystem in your handler to enforce awareness to the caller that you require a safe interface for fs access. Here is what I think may be a better example: func serveIndex(fs FileSystem) http.HandlerFunc { serve := http.FileServer(fs) return func(w http.ResponseWriter, r *http.Request) { // Do not perform any file path manipulation here. If path // is not rooted to the FileSystem, you should use http.StripPrefix to // modify the request path before this handler is called. httpFile, err := fs.Open(r.URL.Path) if err == nil { // if the file is not found you should NOT just serve another file at // the same URL with a 200 status, but I won't digress into that. If // the file is not found to keep your behavior before you can: // note: Better practice would be to create a serve*Func that // accepts a fs, name and uses ServeContent(). r.URL.Path = "/index.html" serve.ServeHTTP(w, r) return } // there is no reason to stat this file, fs.Open took care of that. But if // we did want file access we can use the httpFile interface to do basic // things like Stat, safely without making a possibly invalid stat call. httpFile.Stat( .. ) // Serve file once you are satisfied by using serve, or you could // call a serveContent helper func that takes a http.File (Would be reused // by the serve*Func that accepts FileSystem and Named file as well). serve.ServeHTTP(w, r) } } I am willing to explain in detail why what you're doing is still a security issue if you want. But want to avoid combative back and forth so the summary is I could use the handler to determine what files exist on your system that may be read by the process running Go. As an attacker: - Make a valid request to your index.html *observe a valid 200 of index* - Make a invalid request to your ../i-dont-exist.html *observe a valid 200 of index* - Determine orientation by making requests at various depths: - ../${sentinel-file} ... ../../../../../../${sentinel-file} - When the known sentinel file is reached I will not get a 200 index, because the stat will pass but the http.Dir will return a failure. - So I know that if I get a 404 (or a redirect request in the case of the FileServer for paths that contain .. like in your example) I have found a file which the call to os.Stat succeeded but does not exist within your asset path. - I can use this to ask you if files exist on the system, to gain intelligence about the services it runs and so on. - ../../../../${orientation_to_known_root}/systemservice-file - Now I can build a index of files that exist and use the signatures of them to find possible attack vectors, or invade your privacy. I may wake nfs servers, cause general annoyance in SELinux logs, the list goes on. Arbitrary stat calls aren't good. 
Some combination of https://npf.io/2016/10/reusable-commands/ and the kubernetes "kubectl" CLI. Felt a bit strange to me as well, but "desprite/desprite" didn't make that much sense either.
it's easy to understand
The limit was 1024 actually.
Great... New crappy framework to build more shitty apps for iOS. I do like Go. Using everyday for backend development. But UI apps for iOS/macOS? Only native framework!
Have you done macOS UI development? It can be pretty terrible. If you try Matcha I think you will find it much nicer and more modern. It uses native UI components and doesn't involve any weird jsx stuff like ReactNative.
[removed]
&gt; there is just not enough gophers out there. Not in the few cities you are hiring in. If you want more/better people you should start setting up remote teams.
&gt; Unfortunately only macOS is supported at this time. Gross and disappointing.
We use in service to monitor how many requests have been succesfully processed and how many failed. I while ago I write a blog post about it: [expvar in action](https://orangetux.nl/post/expvar_in_action/).
No problem, there's also the mailing list if you just want to know when the OSS version will be functional enough to be released. ;)
Are you sure? I definitely hit 256 as a limit for `go test`
Air is a runtime, already designed to work on iOS (aka is basically a precompiled sandbox runtime you can run things in). React Native and similar tooling allow great UI development without packaging an entire runtime (unless using CRNA which uses Expo). You need MacOS because XCode will only run on MacOS. XCode is the only tool to compile your project to Native Code to run within iOS. None of these things are out in the open for people to even have a chance to write an alternative. React Native was created because Facebook didn't like packaging an entire Browser runtime with their app (and losing some Native specific functionality). People shy away from packaging a whole runtime because it is overhead that can decrease performance and increase app size. Apple is BS but there's no real way around it. You even need a Mac to simply publish to the App Store.
Xcode at the very least is required to sign iOS apps for publishing in the App Store ? The whole Store certification process is not for the faint of heart. Are you sure its possible to create an iOS app for the App Store, entirely compiled on Linux / Windows ? I can imagine you actually are using a cloud service for that, like https://build.phonegap.com/
It used to be 256 before [1.9](https://go-review.googlesource.com/c/go/+/45673/2/src/runtime/runtime2.go) 😃
Thanks, fixed!
The limit has just increased to `^uint(0) &gt;&gt; 1` :)
By offering a cloud service like build.phonegap.com For people that do not have a Mac and/or want a more controlled and deterministic environment for building (like enterprises). 
Looks really interesting, comprehensive (at least in eyes of a layman) and quite well documented! Some initial questions I have: - is this usable for handling money? if yes, then assuming I'd want to add a currency, should I use a pointer: `struct { amount *decimal.Big; currency string }` or a value: `struct { amount decimal.Big; ... }` ? - I assume I should use `decimal.New` to create new values; what Context is used by default in such case? and/or how does a "zero" Context behave, what is it equivalent to? - I see you plan to add examples; I miss them indeed; a top-level introductory one would be especially useful, showing most basic usage and behavior. I'd imagine e.g. creating two simple numbers, then doing a simple operation (add?) then more tricky one (div by 3?); show what would happen on two Bigs with different count of decimal places (all ok? or some panic/trap — how to handle it?); finally print a Big, which would be a nice way to demonstrate how to convert it to a string (and optionally maybe float64? or something else). One of the initial Bigs could be potentially deserialized from string or JSON instead of being created by hand. - Division seems an especially important case; as such I find `Quo` (IIUC what it does) severely underdocumented, as a layman. Similarly, I'd be interested to know what happens if I try to `Add` two Bigs with different number of decimal places.
Check this one, the sister project: https://github.com/markphelps/go-trace. I made a quick test with this implementation and the rendering time for 600 x 500 pixel scene with 485 objects took 6.33m on Intel® Core™ i3-3220 CPU @ 3.30GHz × 4. 
You realize the frameworks aren't the problem, it's the developers, anyone can submit an app, so just like how there's a lot of bad steam games, there's a lot of bad apps. And if you looked into this, it seems quite clean and modern
This is interesting and speed is good. I'm wondering what things have been optimized. Code wise it looks similar. Was that done with gccgo? 
Yes. A lot. I have no issues to use technology provided by Apple. In latest Swift 4 and framework included in 10.13. I do no think that somebody outside can do this better than Apple engineers. And using native elements doesn’t mean that apps will respect Apple Human Interface Guidelines. When your building “cross-platform” apps you almost always using one platform interface and behaviour. Take a look at MS Office. Windows crap. Completely alien software on macOS. Take a look at Google apps at iOS. Completely unusable crap. Same story will be always when somebody trying to develop “cross-platform” software with “cross-platform” developers.
Again. You cannot develop native apps with full respect Apple Human Interface Guidelines with “cross-platform” frameworks and “cross-platform” (!) developers. This lease rise the hands who really read this book? Yes. This is not only website articles.
Just looking on first example. TODO app. Is this elements native? No. This same crap UI generated just some "compenent library similar to ReactNative". They even not using native libraries, bindings to Swift. Just more trash for App and Mac App Store.
Exactly. You can use this with Consul to put active resource stats within a health check, and alert on that. Or you could dump the stats to Prometheus to set up time-series data. 
My previous team, in Chattanooga, TN, was about 25% Go, 50% C#, and 25% Python with most of each backend having an Angular front if it wasn't simply an API or data-crunching away somewhere. Interviews would tend to lead candidates to talk about hobbies, favorite things in software development, and other topics that could allow us to gauge if someone enjoyed programming. Specific skills are nice for frontend, statistics, but a love of coding is all people need to learn Go. Our job postings and interviews didn't mention Go as a requirement.
I used the standard go compiler.
cloud9
I did this to some degree with some of their previous years' contests. It could be fairly easily defeated by adding some random amount of sleep time to failing submissions if they were really worried about it. That would not completely stop it, but would reduce the resolution you could extract in each iteration. I found even with automation on the time extraction, some of the tests with larger inputs were impractical to extract. You could also defeat this by having automated random problems from a generator used for verification purposes, and then a final standardized problem set for determining times for the leaderboard.
Random tests for verification, followed by a standardized set of static problems for the leaderboard?
Seems the author of a Java coroutine/fiber framework has joined Oracle and proposing his previous project as part of JDK.
fantastic!
I really wish you to integrate `golint` or something similar. I used to [this](https://i.imgur.com/KflKZHO.png) kind of warning messages (public objects should have proper comment) in my Emacs setup.
if it can accurately differentiate between C headers and C++ headers, then I'll be impressed. :P
Sweet!! Does enry consider shebangs? Can enry detect bashisms, kshisms, zshisms?
Support for moovweb/gvm yet?
Gogland should support gvm as out of the box it can manage multiple Go versions without the need to install gvm or similar. Point the IDE to the directory where a Go version is installed and Gogland will track that directory. If you upgrade in place the that will be reflected by the IDE. If you have multiple directories then you can change the Go version on the fly for the current project. I'll file a request to automatically detect the Go versions installed by gvm to further ease out the usage.
Gogland has been my Go IDE pretty much since its release, and I like it quite a bit, but the only pain points I really have with it are related to refactoring. Specifically, moving things between packages doesn't seem to update existing usages and it also doesn't seem to able to propagate refactoring of interface methods to their implementing types. Interface refactoring propagation probably should be optional given the nature of Go interfaces, but it still seems strange to me that a company built upon their prowess at creating refactoring tools wouldn't be putting more effort into the feature (an [issue](https://youtrack.jetbrains.com/issue/GO-2977) has been open on their tracker about this for almost a year...).
Hmm, file programming in a server scripting language? O_O
Really only Google uses it hence the name.
Considering that it's a free preview and they have a ton to do, I'm sure it isn't being ignored.
I think Alexander's comment is the perfect explanation why this hasn't been yet addressed: &gt; This particular feature is quite easy to implement but we still don't know how to do it handy to use. E.g. renaming method spec of single-method interface might lead to renaming 100500 methods of types that have nothing to do with that interface and implemented him just by an accident. &gt; &gt; So the issue is mostly about user experience. If you have any suggestions on how to deal with it, please share them. Go's interfaces and the GOPATH / vendoring concepts make this a very hard UX problem to solve.
I understand that it's a non-trivial UX issue, it's just that excellent refactoring tools are kind of what JetBrains is known for. As a result, it feels weird for the only specific complaints I have to be refactoring-related. It's like getting in a Rolls-Royce and finding that the only thing that bothers you is a harsh ride. 
&gt; Are you sure its possible to create an iOS app for the App Store, entirely compiled on Linux / Windows ? Yes, you can use Adobe AIR SDK to create an iOS app for the app store entirely compiled on Windows 
&gt; ... away from packaging a whole runtime because it is overhead that can decrease performance &gt; and increase app size. Please show evidences to prove them. In my opinion the two are both not true. This is just a cross-platform compiling problem. 
This is just a cross-platform compiling problem. It has nothing related to IDE.
&gt; is this usable for handling money? Yep! That's (one of) the goals. In general, I'd follow idiomatic Go and use `*decimal.Big` if you're putting it in a struct, unless you have reason otherwise. &gt; I assume I should use decimal.New to create new values; Yep. Or `&amp;decimal.Big{}` or `var x = decimal.Big`, same way you can do `&amp;bytes.Buffer{}` and `var x bytes.Buffer`. &gt; what Context is used by default in such case? and/or how does a "zero" Context behave, what is it equivalent to? The zero value for `Context` has a precision of 16, rounding mode of half even, operating mode of Go, and traps set to everything but inexact, rounded, and subnormal. &gt; I see you plan to add examples; I miss them indeed; a top-level introductory one would be especially useful, showing most basic usage and behavior. Should be in by v1.1 or v1.2, so soon-ish. &gt; I'd be interested to know what happens if I try to Add two Bigs with different number of decimal places. Same as the normal rules of addition, e.g. `1.2 + 3.55 = 4.75`. Thanks for your feedback! 
Turns out that there's already an issue for it but not many have voted for it https://youtrack.jetbrains.com/issue/GO-3031
Thinking about it, app size doesn't really have much to do with it, missing native components and utilizing native code does. But everything I said above basically boils down to compiling and how people achieve it. In Facebooks React Native announcement they go so far as to say packaging a whole web browser runtime wasn't as performant or scalable as they needed and missed out on Native code, which was sort of what I was trying to get at. I don't know why I added that app size dinger at the end. One of those "echo chamber" things, my bad.
Go has some good stuff for handling systems stuff. It's not just "server scripting language." 
Go is general purpose.
It is surprising if this hasn't been a focus for them as, for me, refactoring is the killer feature of IDEs. 
All of these are considered "Shell". We comply with linguist's taxonomy everywhere. However, I don't see how adding the detection of different shells can hurt, so PRs are welcome! I think the best would be to join our Slack community and discuss this with the actual maintainers. 
Well, we accurately tell the difference between py2 and py3 in https://github.com/bblfsh/python-pydetector so does not seem too hard after that :D
Felt I needed more firepower, up the goroutines.
@mcandre You can join the source{d} slack community at www.sourced.tech
s/High Performance // The article does not contain even a single instance of the word "performance" that isn't just repeating it's title for emphasis.
I'm surprised too, using Go for projects like Docker and Kubernetes is one thing.. but peforming basic lexical analysis is another. Sure, the Go toolchain, tokenizer, scanner, parser and more is written in Go but it's just a simple scripting language. How could it possibly be used to split ANY programming languages grammar (there are so many!!!) into a stream of tokens and run them through heuristics in a fsm. P.s. What on earth is "file programming" 
I mean sure I could write a C++ library to write an operating system in LUA but... you hopefully get the point?
I would want it to run gometalinter on save, I have asked this of them before but I can't remember what the response was. Currently The only "on save" options are: * Do nothing * Go imports * gofmt But this is seriously missing gometalinter in this list, it's the one feature I am missing since switching from Atom + Go Plus. edit: I was thinking maybe they don't want such an option because they prefer to do their own linting instead? It sounds like a bit of a double up of effort, but the amount of things it can check for is increasing with each EAP release at least.
You can write an operating system in Go without a library.
I don't. What is the point? Also please explain what is a server scripting language?
Good to know thanks! 
If Go even had generics I could see this. As it matures more things will be possible as more than mere "look what I can do" side projects. But for now I am sorry but open minded as I may be I find this pretty funny if it is serious.
Please don't use `println`, especially in examples.
What's the threshold in lines of code for a feature being worth mentioning? Useful features are worth mentioning in the documentation. Lots of useful features are just a few lines of code, it doesn't mean they aren't useful features. This particular feature for this particular software seems more than just useful, too. You might think it's "essential baseline functionality". Though in evaluating the software you'd want to make sure they did this work (even if it's just a few lines), so them saying upfront they did is nice. What's the problem?
This sounds like it could be cool to play around with, but I personally don’t know enough about SAT to really know where to start. Would be great if there were a few simple examples in the repo—I looked at the test files and that didn’t really help give me any ideas either, heh
The problem has to do with how the product is advertised. OP repeats this feature as a tagline when asked to justify the existence of the product, instead of offering novel features. It's also deceitful-- the impression you get from "protection from image bombs" doesn't convey the reality of a single hardcoded constant to check inputs against. The OP never clarifies what the tagline means and the article doesn't either, because they want you to see "cool feature!" instead of "two integer comparisons".
That's pretty hilarious, I never imagined that source code could be exposed like that. Does it change anything if your binary is stripped? 
Can you still limit the use to only one processor then? I had a helper program that needed to be sensitive to the CPU usage so I would use the `GOMAXPROCS=1` to ensure it left resources available for the primary program on the machine. 
Ok, your point was well received. I still think that not every example should have a caveat emptor about possible security implications when the point is elsewhere. As you took your time to explain the implications, I will also take my time to amend the article, to resolve and note the possible security issue. Thank you. Edit: In the end, it seems that everything is handled even before a possible call to any `io.Stat` function in our handler. This is from the official code docs (http package, server.go, line 2098 approximately): // ServeMux also takes care of sanitizing the URL request path, // redirecting any request containing . or .. elements or repeated slashes // to an equivalent, cleaner URL. So, it seems that all this drama about security in this particular case is completely redundant. I know the importance of cleaning paths and possible directory traversal attacks, but in this case, Go http package is handling the request URL to prevent you having to deal with it. Obviously this doesn't eliminate directory traversal attacks that come in from the query parameters or POST body or somewhere, but it seems that I'll again have to resort to my previous stance. I wasn't trying to teach users about security and if anything, it seems it would have to be a subject of a different post because all three of us didn't know the full details about the http implementation that handles this particular case, it might be worthy of a write up.
Yes you absolutely can. Although GOMAXPROCS only handles how many number of threads will execute Go user code. So, for example, if you are calling C API, IIRC runtime is free to execute something else until your code returns from the C function. 
Not having coroutines up until now is one of the main reasons why Java is dead, so I see this mainly as gripping at the edges of the endless pit of lack of use. For most projects my company would have used Java for 20 years ago we now use Haskell.
Are you sure the .vscode folder should be checked in, it looks like editor specific settings. Look at adding an .editorconfig file instead which is universal, and git ignore .vscode
why not?
Yeah there's no way you could write a compiler in Go. It's clearly never been done before, after all it's just a server scripting language. 
Exactly what I was looking for today!
Rule of thumb for me has been to never serve application logic on the default mux. Usually have one server exclusively serving expvar and pprof (the default mux), and a separate server with its own custom mux for my api.
Agreed! This is mentioned in the "Prevention" section of the article. Also covered by a Farsight Security blog post a while back: https://www.farsightsecurity.com/2016/10/28/cmikk-go-remote-profiling/ I think there's an argument they should never have added a global mux in the http package. Too late now. 
Discussion on github issue: https://github.com/golang/go/issues/22085
Do you call Docker and Kubernetes side projects?
It's not really that new at this point. 1.0 was 5.5 years ago. Most of us enjoy the explicitness of deciding exactly what to do with each error. Sure, at first ,and in trivial programs, you may just return every error as-is, but in bigger and more serious projects, you start to think about whether you log the error, add information to it, etc. I use it 40 hours a week at work and do all my side projects in it. What some people consider drawbacks, I find to be refreshingly simple and obvious. 
This is a great analysis. Thanks for the writeup! I think this is something most people don't have on their radar, but definitely should. Not sure if you are a crypto fan, but here's a small tip. /u/tippr $2
u/mmcloughlin, you've received `0.00448723 BCC ($2 USD)`! *** [^^How to use](https://np.reddit.com/r/tippr/wiki/index) ^^| [^^What is Bitcoin Cash?](https://rocketr.net/blog/2017/09/24/bitcoin-cash-a-simplified-explanation/) ^^| [^^Who accepts it?](https://acceptbitcoin.cash) ^^| ^^Powered ^^by ^^[Rocketr](https://rocketr.net) ^^| ^^r/tippr ^(Bitcoin Cash is what Bitcoin should be. Ask about it on r/btc)
Yep, the global instance is one of my least liked Go patterns. I feel like implicit stuff is more confusing than just calling a real constructor or the like. I might even go as far as saying adding package `init()` functions was a bad idea.
I don't know, what are they? From that I haven't even heard of them, yes.
Because it's intended for debugging parts of the compiler before `fmt` works, isn't as friendly as `fmt.Println`, and might be removed tomorrow. https://golang.org/ref/spec#Bootstrapping
I find Bart Simpson's code much more readable (the one with `if err != nil`). I think it's counter-productive, to use a language with simple syntax and try to make it look more complex, yet concise. You lose a lot of properties that way. E.g. if I want to quickly see where errors are returned in a package, being sshed to a remote server, I'd just `grep -r "return err" .` and I'm done. With your inventions, Go code is no longer context-free.
the link is broken
Could see what? Your post confuses me.
Thanks for noticing. It has been fixed now.
It certainly does work!
Am I the only person who doesn't mind the if err returns? Yea, it's a little tedious at times. But it makes it SUPER easy to trace my code when hunting down issues. 
+1
Faster compared to what? I currently use tokei (which is not, to my knowledge, the fastest) and I quite like it. I'd certainly switch if a similarly fast/pretty option came around.
https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html
Very nice explanation. By the way what is `&lt;A&gt;` operator i don't think I've seen this before. I know it represents a type A but is this possible in go (fairly new to the language) ? 
"Get used to it." is the best advice I can give. So: get used to it.
Go is just a bad language then?
oh. I thought you meant fmt.Println, because it's used in the article.
&gt; being sshed to a remote server I would undestand if you will do this for python script. But Go?
&gt; the solution seems to be to create a shared library (Linux only). &gt; I know this can be done with cgo This is not correct: the Go compiler supports a special "build mode" called "c-shared" which produces a shared library with C-style API. The `cgo` subsystem is not involved in this process (in the sense you don't use `import "C"` and stuff); you just supply the `-buildmode=c-shared` command-line option to the compiler — see [this](https://golang.org/doc/go1.5#link) and [this](https://golang.org/doc/go1.6#compiler). 
Please don't forget to add "for the web". I'd suggest updating the Github's project title to reflect that. Authentication is not something specific to the web (google `SASL+auth` for one example), so there's no point in misleading people by making them think it's some sort of generic authentication protocol or something like this.
No types used throughout all the examples, I wonder why?!?!?!
Usage examples?
I love this IDE! :D
I always thought that particular behaviour of http/pprof to be utterly stupid; I'm all for making debug as easy as possible but requiring to explictly run it in specific endpoint isnt exactly high barrier to entry
https://github.com/niemeyer/godeb wget https://godeb.s3.amazonaws.com/godeb-amd64.tar.gz tar -xvf godeb-amd64.tar.gz chmod +x ./godeb-amd64/godeb ./godeb-amd64/godeb install 1.9 rf -rf godeb-amd64 godeb-amd64.tar.gz
Right, this was just an example. You're correct, for Go one does not usually store sources on production instances, just binaries. I tried to make a case for situation, where you don't have full-blown IDE with code navigation to browse trough Go sources.
So, no technical merit to the idea, it's just corporate metoo-ism?
My eyes hurt
We're going to provide a way how to run any tool `on save` before the final release.
Hopefully once [this](https://github.com/golang/go/issues/18162) lands the custom patches will be redundant. 
No, it's pseudo-syntax
Very important to keep in mind, especially because of the DoS attack possibility: the pprof trace can have a huge memory overhead. This is one of the reasons the agent https://github.com/stackimpact/stackimpact-go is proactively sending the profiles to the dashboard, i.e. they are never fetched (no need to enable pprof server, deal with ports, etc.). And it doesn't use trace.
Topkek
I'm sorry, but I can't think of a worse language to explain monads with than Go. Well, unless you either just hand-wave all the types away, or pepper everything with `interface{}` and `reflect`. Useful tool in other languages, not so much in Go
I think you might be branching too much. If you return in your if block that detects an error, then you don't really have a lot of branching. I've seen good devs get tripped up on that at first since they are writing so much error handling. So instead of an else block on something like an error in a handler, try something like... ts, err := time.Parse("2006-01-02", query.Get("ReportDate")) if err != nil { log.Println("ReportHandler:", err) http.Error(w, "Bad Request: bad start date specified (needs YYYY-MM-DD)", http.StatusBadRequest) return } //use the ReportDate timestamp... In other cases it's better to return the error itself. In APIs I tend to add information to an error and return the error until I get to a handler and then log the error in the handler. This gives me all the information needed to understand the context around the problem. I adapt pretty well to different languages, so I enjoy the paradigm that Go asks me to use. I don't think people who use Go by choice see this as a shortcoming, though people who don't use Go are hesitant about it. I don't know what you mean about speed. I would think it would be faster than any of the other languages you know besides C++, so it's possible you have some design concerns due to misunderstanding something that you'll learn as time goes on.
I'm not sure that I'm clear about what you mean specifically about a "DDD-like architecture" and how that avoids circular imports. A specific example as a link would be really helpful. I suspect that you're talking about the domain and repository packages, and that the repository knows nothing about the domain, but I'd be hesitant to call that DDD-like... I think that's just a layered application.
[removed]
Sometimes your editor just isn't the best tool. I'd argue that grepping your source code (particular egrepping) is a great example of where the IDE is unable to provide a similar function.
This is the main feedback we got :) This is a priority in the short term: a tutorial with a few examples. Next priority (but this will be longer) is a user-friendly input format.
No. It's different. I find it a nice middle ground between the (IMO) overly explicit &amp; strictness of rust and the overly permissiveness of python. It fits in the same niche as java or C# without java's boilerplate, huge memory footprint, and tendency to over-abstract, and C#'s neverending feature-itis.
"Disclaimer": I speak Haskell. I don't think you have to apologize... it really is the worst. If you go less typed, you end up pretty quickly in the dynamic languages, where it works. It blows up at runtime if you use it wrong, but that's the agreement you make to use the dynamic languages. (And usually it's too syntactically noisy and too performance-draining to be worth it.) In the other direction, actually, you have to get a _lot_ more strongly typed before monads are usable or make sense. Few languages can express the monad type correctly and work properly. Some languages can do the equivalent of `a -&gt; m a`, that is, a monadic expression where the type is always the same thing, but that's not the full monad type. But Go really is sitting in just about the worst possible position for this. That's not a "criticism" of Go. It just is what is.
https://www.docker.com/ https://kubernetes.io/ 
if you don't care that it's not covered.... isn't that good enough? Just stop caring. Check your coverage manually for the rest of the files in the package. If possible, you could move the generated file to a different package, and then just declare you don't care about the coverage for that package. But in general... code coverage is a lie. Code coverage tells you what code is definitely not tested *by this package*. It doesn't tell you if it actually *is* tested by anything.
I can explain, but I think it's better to start by going through the tour of go, to get a handle on how go works: https://tour.golang.org/ Honestly, the easiest way to make c into a slice of the ints 5 and 6 is to create the slice on that line: c := []int{ 5, 6 } This creates a slice of two ints, with values 5 and 6, creates the variable c, and assigns that slice to c. However, if you want setNumbers to return multiple values, you need to specify that it returns multiple values. Right now it is specified to return a single int. func setNumbers(a , b int) int { ^^ This says "setNumber returns a single int" If you want it to return two ints, you have to specify that in the function signature like this: func setNumbers(a , b int) (int, int) { Note that if you have more than one return value, they have to be in parentheses. Now, that will make setNumbers return two ints, but you can't use two return value to create a slice. Each return value has to be assigned to a separate variable where the function is called. There's no way to convert them into a slice (without passing them into a different function). I hope that helps.
[removed]
The thing is that the state-machine generated is very/very verbose. It's probably impossible to create documents that would cover everything. (Also, more likely, it's the fact that I'm not yet quite proficient with ragel, and I probably wrote a sub-optimal parser.) Also I think some sort of numbers getting higher every time you push changes is good for the enjoyment of a programming task. Gamification and all that... :D
?
The article has a whole bunch of `println` calls. package main func main() { for i := 0; i &lt; 5; i++ { defer println(i) } } 
&gt; Mature Go hackers say "you shouldn't use a framework. Just use net/http." (Slide 18) I beg to disagree. While this is indeed often cited as a common Go mantra, for me the actual meaning is more like this: "Before using (and therefore having to depend on) a third-party library or framework, try the stdlib first *and see if it is sufficient for your needs.*" 
I like frameworks that play nice with stdlib, like chi. You can have all the features from framework and have all the plugability from everything that uses the stdlib.
Oh yeah? So, what made you a fan? :)
Sounds right. One of the audience said about my "DDD-like" one as a little bit different from a normal DDD. I'll call them "layered" from now. Thanks.
It's not exposed. pprof can only print the source if it has access to the source. The binaries only contain source code coordinates for symbols and PC to line tables. OP ran all his tests on localhost, where pprof has access to the source. 
That wouldn't work. All you'd do is check if the input is one of the hardcoded inputs and otherwise use a normal solver.
Hi /u/vem_ I'd recommend you to have a look into the "enri" post, that tries to answer your doubt (and others). https://blog.sourced.tech/post/enry &gt;*enry is a tool written in Go to perform programming language detection in files. It started as a port of github’s project linguist.* [...] &gt;*enry’s language detection has been compared with linguist. In order to do that, linguist’s project directory linguist/samples was used as the set of files to run benchmarks against.* [...] &gt;*Calculating the mean spent time to process a file with both tools, on average enry is 211% faster than linguist. This is a rather pessimistic estimation; for example, the analysis time on tensorflow/tensorflow is 5x shorter, and goes down to 20x for small-sized projects*
Yeah, exactly. I also use them to prevent the visibility leaks after I split a big package.
Thanks for the explanation.
Examples are high on my TODO list, will be added in v1.1 It's the same as math/big, though.
Totally agree. "Don't just blindly use a library 'cause you think you need to." The overhead of learning a library and the potential maintainability issues it may introduce might be less beneficial and more work than adding a `switch` to your handler Like handling errors, make "adding dependencies" a conscious decision with some thought behind it
I benchmarked it compared to tokei, and I got that `enry` was 40 times slower than `tokei` though also more accurate out of the box. I guess I'll keep it around for that reason, but the speed has yet to impress me.
Beauty is in the eye of the beholder. 
It may be the accuracy, one of the goals of `linguist` and `enry`. If your benchmarks are right, and `tokei` is faster, but less accurate, it is a matter of priorities, I guess. /u/vem_ you said that `tokei` is ~40x faster than `enry`. Did you used the same examples that `enry`? What about the accuracy? Any metrics? Thanks!
Maybe you can put the ragel parser in an `internal/parser` package, and just ignore the coverage of that package?
Good idea, thanx. I was already doing something similar, by not exporting the function generated by ragel.
Hilarious seeing this meme here
FYI, because I finally thought to look into this... it's actually configurable. As soon as github rescans my repo, it should report nearly 100% go... and ignore the vendor directory for LOC changed: https://github.com/github/linguist#overrides
Given you care enough, you can still detect schenanigans. For the benchmark tests, if the runtime is off by an order of magnitude from a similarly scaled random test case, assume they are trying timing attacks and kill it or add random delays. Also isolate test runs and switch up the ordering so it is impossible to know which test correlates to which sleep times. Essentially, for random tests, you can tell them "test 1 passed in 10s" or whatever, and it doesn't matter because it is random each time, or chosen from a set of similarly scaled random tests. But for the benchmark tests just give the final time. Maybe don't even tell them how many cases or break them down. If you don't run the benchmark suite until they pass the random suite, at least you can be more confident they actually solved it. Worst they can do is cheese the fastest score. 
thank you for all the hard work you guys (and girls) have been putting into this. 
This is getting old...
Thank you for pointing out my mistake. I will update the post accordingly.
Proof that we gophers have a good sense of humor! \ʕ◔ϖ◔ʔ/ 
Really? I thought it was hilarious. Oh well ¯\\\_(ツ)_/¯
I never claimed I drew the original and reddit doesn't really have a good way to give credit when you upload an image.
No, unfortunately not :) I will note some disparities: * Enry can distinguish Verilog and Coq out of the box. * Enry picks up ATS out of the box. * Enry distinguishes literate Haskell and Haskell (may be good or not according to taste). * Enry picks up YACC. * Tokei picks up `scons` stuff out of the box, enry does not.
Finally came to home, used typical sample what I usually had at my last job. As expected, generated code is about 1000 times faster than a regex. I didn't even try ragel as it is nearly useless for this task: writing finite state machine for a high number of fields is about as "easy" as parsing manually. go test -v -bench '.*Complex' github.com/sirkon/ldetool/benchmarking BenchmarkLDEComplex-4 1000000 2034 ns/op BenchmarkRegexComplex-4 1000 2132328 ns/op Writing this regex was a challenge itself (https://regex101.com helped a lot). And, I repeat, regular expression (and finite state machines) are poor match for well structured text with delimiters. The tool itself has improved a lot though in these 25 days.
You can comment...
&gt; Worst they can do is cheese the fastest score. In a case like Vivint, that was basically the whole point. I had a working solution to every problem on the first day, so the real contest was in optimizing them. Anyway, it's a tough problem, because the less information you provide, the harder it is to debug, and it's already very frustrating to debug these things. I know I wasn't the only one who resorted to sleep statements to try to debug why code was failing. If you make the black box too impenetrable, then you risk having the contest come down to whoever happened to guess that the test input contained an extra newline and accounted for that (which actually happened in the Vivint contest before they fixed it). I think doing manual review of the winning solutions is the best approach, but you still need to spell out policies about what is and isn't acceptable.
that's true but I didn't bother. It's a well known meme
Chill mate it's just a meme for laughs :)
Yeah, and it means at least two different things in the realm of programming.
_Yeah, and it means at_ _Least two different things in the_ _Real of programming._ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^tv64738 ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haiku.
Feeds as in RSS?
I noticed that this links to a deleted message. Not sure if that means this is cancelled or if they are simply redoing the announcement.
The message was a duplicate (source: I got the emails).
One of the messages was deleted because it was duplicated, the other message is in the same thread there, see: https://groups.google.com/d/msg/golang-announce/Aqam2y8QoLA/7_MiTf3tBAAJ if you prefer a direct link to it
Ignore the detractors, great post!
I wish he had more time to get into the details of enabling the memory allocation. I was on the edge of my seat to find out if this portion of the runtime is hidden behind unexported strict fields, so I was patiently waiting to be disappointed by someone patching the runtime. This didn’t seem to happen so I’m confused. I think it would be interesting to know if there were any language specific limitations that might be a good candidate for fixing in future updates. Maybe there are none. This talk was really awesome!
I still laugh
Is the concept of a meme new to you? Is this your first time on the internet?
Reddit is free, and you get what you pay for.
so, your'e saying this joke is becoming generic?
What about the ambiguous case of a file that contains py2 and py3 compatible syntax? Does it just default to calling it py3?
This should be avoided due to taking up more space needlessly although it might be used as indication of a bad IDE.. :s
Agreed. Even though there should be a reverse proxy in front of the golang thing doing the app work, most people won't bother.
[removed]
Does it make sense to put the generated code into a package?
_Does it make sense to_ _Put the generated code_ _Into a package?_ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^everdev ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haiku.
this thread is... maybe... not panning that out.
This is unfortunately a bad example, as of now you should use multi stage build in your dockerfile ( #1 get the dep / compile, #2 append the result of #1 in an empty image )
Can you explain A) how this is a bad example? B) How you would suggest doing this? This is how I build all of my apps for production so I am interested to learn how I could improve.
Go has a different style to programming and I guess that this is more like converted from other OOP languages. I know that DDD is not language-specific but Go is a different beast to apply DDD principles. I like explicit Go code more than those many abstractions that need dependency injection everywhere. Btw, I also have coded an API recently like in DDD style and I liked it and didn't like it. Couldn't decide.
[removed]
What is the reason for the patch?
Ah okay I see the point. I would say when scaling a production server to a cluster of sorts I would agree. However if dealing with a small static webpage, I don't see any reason a few mb would hurt performance. Not to say this couldn't be improved.
Yeah I dunno man, the people in this thread seem to be lacking one... Rob probably shat on /r/golang for good reason. Edit: this comment is liiiiiies
`few`... `golang:latest - 271 MB` vs `scratch - 0 MB` or `alpine:latest - 2 MB` sorry what?
Since Docker 17 it's possible in the same Dockerfile to have multi stage build, you don't need to get dependencies / compile in the image that's going to be deployed. Have a look there it's well explained and it even uses Go as example: https://docs.docker.com/engine/userguide/eng-image/multistage-build/#use-multi-stage-builds
We'll find out when it's available. The purpose of the pre-announcement is to give people time to schedule an update. On Wednesday the new releases go out, complete with a description of the fix in the release announcement. This hopefully minimizes the window for people to use the release announcement, or the patch itself, to engineer an exploit and use it against installations that haven't updated yet.
These posts are funny, made my day.
&gt; Rob probably shat on /r/golang for good reason. I don't know what you are talking about. /u/robpike comments on this subreddit [every now and then](https://www.reddit.com/user/robpike) and gives very insightful answers.
"Definitely avoid ultra-generic package names" ... yeah. So you don't think it's good idea to have a "models" package containing all entities and database interaction? But rather a "user" package? So..like... a single package for all models? instead of just... having them in one place? I'm confused ... what exactly is the benefit here?
the docker run should be docker run -p 80:8080 mywebserver since you're forwarding the container's :8080
You're absolutely right, it's 271MB vs 0MB, but this is not as bad as it would seem. The point is, all the garbage only wastes *disk* space and maybe some bandwidth when moving the image around. It does not take up more precious RAM when executing the binary than a build from `scratch`, nor does it hurt performance of the target binary inside. But I agree, since multi stage builds are around, why not use them! And only if it is just for the most important avantage of multi-stage Go builds (that no one has mentioned yet): You can show a ridcuously small docker image to your jealous friends or coworkers and proudly say, "I build this server entirely from scratch!" ;)
You should probably also name it, run it daemonized &amp; maybe add a restart policy docker run -d --name mywebserver --restart always -p 80:8080 mywebserver I usu just compile it first and run in debian:jessie 
Maybe /u/TheBallPeenHammerer meant Brad Fitzpatrick's suggestion to shut down /r/golang but this was because some Reddit CEO did something extremely stupid (I believe he faked or deleted comments, can't remember), and Brad did not want to have Go associated with Reddit at all anymore. However, this happened quite some time ago, and I believe no one still cares (or even remembers). 
And substitute generics with "sense of humor" for applicability with its users.
this is starting to look like spam
+1
Thanks
Well, the generated code results in one low level function containing a ton of goto statements. I use it by wrapping it in a higher level function that I then export. So, in my opinion, it doesn't really qualify to be in its own package.
&gt; There is no package versioning in Go. Ahem. There might be no package versioning included in the default tools but we've had tools for a long time that allow you to do this.
Real Gophers(TM) don't break into a sweat about generics (or rather, the lack of).
Well, he references code generation, the poor man's generics.
No, not like that, I've updated the article accordingly. I think that it's a good idea to separate everything into smaller packages, NOT like creating a single package for everything, exactly the opposite.
Yeah, I updated the article and added some example tools :) Thanks!
but "models" is a smaller package then? So whats wrong with naming it "models"?
Since the Go source tree is gofmt'd, you can easily find all of the functions returning multiple values with grep: grep -r 'func .* (.*,.*) {' As of tip from a few weeks ago, there are around 55k functions, of which there are almost 5k functions that return multiple values. - 1 function with 16 return values (test function for compiler) - 4 functions with 7 return values - 5 functions with 6 return values - 35 functions with 5 return values - 69 functions with 4 return values - 433 functions with 3 return values - 4202 functions with 2 return values Only five non-test functions return 5 or more values, and none of those are exported: pkg/bootstrap/src/bootstrap/cmd/compile/internal/ssa/dom.go:func (cache *Cache) scratchBlocksForDom(maxBlockID int) (a, b, c, d, e, f, g []ID) { src/net/rpc/server.go:func (server *Server) readRequest(codec ServerCodec) (service *service, mtype *methodType, req *Request, argv, replyv reflect.Value, keepReading bool, err error) { src/crypto/tls/prf.go:func keysFromMasterSecret(version uint16, suite *cipherSuite, masterSecret, clientRandom, serverRandom []byte, macLen, keyLen, ivLen int) (clientMAC, serverMAC, clientKey, serverKey, clientIV, serverIV []byte) { src/cmd/compile/internal/ssa/gen/rulegen.go:func parseValue(val string, arch arch, loc string) (op opData, oparch string, typ string, auxint string, aux string, args []string) { src/cmd/compile/internal/ssa/dom.go:func (cache *Cache) scratchBlocksForDom(maxBlockID int) (a, b, c, d, e, f, g []ID) { Of the 4202 functions that return two values: - 3260 return an error as the second value - 306 return a bool as the second value - 175 return an int as the second value So using the go compiler and stdlib as an example, you can infer that: - Returning multiple values is much less common than returning a single value - If returning multiple values, it's by far most common to return an error as the second value - The only other semi-common cases are returning a bool or int as the second value (e.g. math/big/Rat.Float64) If you're interested in some outliers from the standard library that don't fit the above: src/image/color/color.go:func (c RGBA) RGBA() (r, g, b, a uint32) src/math/big/floatconv.go:func (z *Float) Parse(s string, base int) (f *Float, b int, err error) src/image/format.go:func Decode(r io.Reader) (Image, string, error) src/mime/mediatype.go:func ParseMediaType(v string) (mediatype string, params map[string]string, err error) src/strconv/quote.go:func UnquoteChar(s string, quote byte) (value rune, multibyte bool, tail string, err error) 
natefinch, baliance, thank you i made this example for clearing package main import "fmt" var ( a, b, x, y int ) func main() { fmt.Println("Enter numbers! ") fmt.Scanf("%d %d", &amp;a, &amp;b) x, y := returnNumbers(a, b) fmt.Println(a, b, x, y)//5 6 25 36 } func returnNumbers(a, b int) (int, int) { a = a * a b = b * b return a, b } 
Can you elaborate? What are you trying to do? What did you tried? *edit*: Ahhh... cmd/present, and me who was thinking you wanted help to let your tools handle https traffic. :P
I am guessing you are using https://godoc.org/golang.org/x/tools/cmd/present ? It doesn't seem to provide a way for that, you would need to setup a reverse proxy or modify the source for the tool.
But she's only a poor young gopher...
So much this, I've never considered explicitness of the error handling to be a drawback.
thanks. i modified the source to do exactly what i want.
Only one "`models`" package can be big depending on the project and limits you to one package, probably will be polluted with your specific project details. Distinct packages can be moved easily for reusability and have their own organic APIs which will force you to design them appropriately.
Another option is to minify the image if you care about the size. DockerSlim is meant to do just that ( http://dockersl.im ) while you get to use any base image you use now. Scratch images are easy when you have a single Go binary, but it gets messy when it's more than that (extra data files like certs, dynamic libraries, etc).
Thanks, will update. I use cockpit for all docker starts and if i need to save the commandline option its generally in a bash file.
Something i need to look into thank you.
We have completed 20 algorithm in the previous section. In this section we have added a few more. It is very important to do the analysis of algorithms in order to find the most efficient algorithm to solve the problem. * [Radix Sort](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-for-implementation-of-radix-sort.html) * [Pancake Sort](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-for-implementation-of-pancake-sort.html) * [Huffman Coding](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-for-implementation-of-huffman-coding-algorithm.html) * [Draw Cuboid](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-for-drawing-a-cuboid.html) * [Random Maze Generator](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-for-implementation-of-random-maze-generator.html) * [ZigZag Matrix](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-for-implementation-of-zigzag-matrix.html) * [Spiral Format](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-to-print-a-matrix-in-spiral-form.html) * [AVL Tree](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-for-implementation-of-avl-trees.html) * [String Permutations](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-to-print-all-permutations-of-a-given-string.html) * [LZW Data Compression and Uncompression](http://www.golangprograms.com/data-structure-and-algorithms/golang-program-for-implementation-lzw-data-compression-and-uncompression.html)
&gt; SUPER easy to trace my code when hunting down issues. Sure, but all other solutions available in other languages also make it super easy to hunt down the issue.
`for {}` equals `for true {}`.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/golang] [Any thoughts on updating the package](https://np.reddit.com/r/golang/comments/73ggd9/any_thoughts_on_updating_the_package/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
ah, so in this case, is it infinitely looping until it receives an EOF, or an err ?
It looks like it _does_ loop. If there is no error it receives (`r.Recv()`) and writes it out. Then it would accept another and write it out until there are no more
Looks neat. Any reason to make a whole new project than to contribute to Checkup which already has (most of) these features? (the email notifications can be implemented as a Notifier). https://github.com/sourcegraph/checkup
Hey, wasn't aware of it but also wanted to make something from scratch myself :)
That's cool, it's a great way to gain experience!
I'm going through a similar transition from the systems end. I've always been a systems administrator, but writing applets in go has made my job easier, and I want to do more go dev in future.
Correct.
awesome thanks for the tip. Read the docs but wasnt familiar with C for(;;){ } structure
It's the Go equivalent of a while loop when there's no condition in the for
Yeah, same here I guess. I am also trying to incorporate Go into my daily stack, though for now, these are pretty little things, mostly CI related stuff
If I were to give you any direction from a systems point of view, I'd suggest looking at all the tools Hashicorp have created.
I disagree, I hate error handling with languages which use the throw/catch concept. 
Thank you! That is very interesting, will have a look
The concrete example is for serializing streaming responses - if you remove the for cycle, onky the first response will be returned. Though if this endpoint is not streaming, you won't notice any difference.
&gt; Instead of a model package, define a package that does user things named as user. Or, define another package for a client order as order. Do not put everything inside a models folder, split them into more smaller packages. We're actually moving the other direction on this one. We've had all our objects in separate packages for a couple years, which is my personal preference, but breaks down when defining relationships between them due to circular imports. We ended up doing some really weird workarounds to enable cross-model communication. We haven't found any good ways to handle this except for putting them all back into a single package.
I got hired at my current job as a Go programmer with no previous Go experience. I got hired at my last job as a Ruby programmer with no prior Ruby experience. Some companies *will* look for buzzwords to "tick off" their list, but many don't and are simply looking for good programmers. Being productive in a new language is relatively easy for most languages (it certainly is for Go), although true mastery usually takes a bit longer. I also left school at 16, worked minimum wage jobs for a few years, and didn't have my first programming job until I was 26. Not a carreer path I would recommend anyone take, but it does demonstrate that background and a "traditional" CV isn't everything.
You can hate such error handling, but the fact remains that such languages allow the developer to quickly find the exact path where the error occurred since they give you an actual stack trace. Go's error output is quite unhelpful out of the box, and I don't really see how it helps you trace a problem
Oh, this is inspiring, man, thank you for sharing your story :) I can partly relate to that, as I do not have any technical degree and worked as a salesperson for a couple of years, landed my first software job when I was 23 or 24. You are right, if you are decent developer picking up a new language is easy(well, at least this is true for languages that share the same paradigm). What concerns me more is the ecosystem of the certain niche, like frameworks, tools, etc. 
even `go install`?
If there're relationships in those packages like that then they should be clustered together of course. But, that still doesn't mean that you should put all of them together inside one `models` folder. How are you organizing now, any examples, I'm curious about your experience?
There is also [goma](https://github.com/cybozu-go/goma).
&gt;The problem is, I have no idea how to execute the switch of the niches. I can learn Go (actually I am already pretty comfortable with it), but backend is so much more than just a language. What things should I look into, what kind of pet projects should I make? That really depends on what kind of backend job you want, but here are some pointers: * HTTP, especially HTTP/2, + WebSocket * modern databases, e.g. PostgreSQL + key-value storages, e.g. Redis * some basic Linux/Unix administration (ulimit, bash scripts, etc) * tools, like profilers, debuggers, especially static analysers As for toy projects, the simplest thing, that can also be challenging and interesting, is a forum/blog platform. Make something basic, and then add as much as you want: authentication, caching, administration tools, JSON API, tags, real-time updates (e.g. new comments), rate limiting. Then also race against yourself with profiling.
What we're doing now is pretty close to what you're recommending. Every api object is in its own package. We solve about 80% of our needs by only allowing hierarchical imports, where the parent object imports its children, but the children don't import the parent. That allows for cascading updates/deletes, and allows most GraphQL style queries that returns a single object with unlimited depth. It's the remaining 20% of operations where it isn't a hierarchical relationship that cause trouble. It leaves us copying data access functions, and in a few worst case scenarios, using an `interface{}` event system to circumvent the import system, which is so easy to screw up.
I'm sorta in the same boat but doing only front end :/ I'm trying to build a site but idk wether to use a 3rd party package or not. Seems like there are more resources on non 3rd party package code then packaged ones. But then you have to fight the http core package way of implementing the 3rd party packages. One thing that took me a while was the whole cors thing with cross origins stuff for restful API. Here's some of my resources I've been updating as I go along. May not be the "right" way but it's learning. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
Nothing is perfect for sure. But, I really wonder about that 20% of code. When there're some problems that need solutions my curiosity increase.
Working example test I did for something I was trying out recently. I did a c-archive instead of a shared library, but the principal is similar. https://gist.github.com/protosam/edcc00cc309b5f4a163ece39c46d9e4a
This is great advice, I would just add that you don't need to know everything about backend development to make the switch. Today there are things I still don't know and next month/week I know them. As long as you are good at learning, I would say you are all set.
seems kinda silly to set data and other rather than just use their direct sources.
This loses all the potential value as soon as the example shows int64 as key type... &gt; make generic | sed -e 's/KEY/int64/g' -e 's/VALUE/int64/g' &gt; example/int.go Also, why would one use this when the key types are not comparable? You mention a slice as being the case but I don't understand where that would be preferred or useful. And of course, the bigger question, why not use the Go 1.9 sync.Map instead of this of this or the built in one? 
I fell into a backend position at a startup and really got into cloud stuff with Kubernetes. It seems like that kind of thing is becoming high-demand and the single-server or machine-specific kind of work only applies to either legacy projects or really small websites (from my experience anyway). Everything else is in AWS/GKE/Azure running possibly hundreds of stateless instances of tiny one-job applications which are all talking to each other, crashing, respawning, being scheduled/managed/scaled by other applications. That clusterfuck of interconnected spaghetti is what really gets my brain going! So, if that sounded kind of interesting, GKE literally give you free servers to learn their product so write a basic app and deploy it to Kubernetes then scale it up, watch it break and figure out how to make it scalable, stateless and future-proof! If you like the sound of Kubernetes itself, you can write plugins for it that control the behaviour of how it makes decisions such as where to schedule apps and how to handle failures etc. If that's not your cup of tea, you could try building a simple API driven webapp based around a side-hobby, for example I made a [game server list](http://samp.southcla.ws) API in Go and then used it to learn ReactJS to write a frontend to visualise the data. Hope that helps brew some ideas :)
How tied are you to go only, and where are you based?
First of all, as a backend engineer at any reputable company, the odds of you programming exclusively in Go for the duration of your employment are extremely slim. Now onto your main question. "server side programming," also called "systems engineer" or "back end development," uses many of the same programming paradigms and concepts as other specializations. A firm understanding of things like parallel processing and "multi-threaded" programming and its various forms is pretty much necessary, as is a solid grasp on things like synchronization primitives and what-not. Another major concept that you'll need to understand is _scalability_. In ages past, scaling _vertically_ was the norm, where you simply threw resources at a host until you had enough. These days, systems are typically designed to be _horizontally_ scalable, where you have multiple instances of each application running in parallel and depending on the use case, these instances might run independently of one another, or they might need to all know about each other and work together towards a common goal. With this paradigm shift came the requirement that engineers at least have a basic understanding of the various concepts and algorithms for things like high availability, data replication, consensus, and intra-cluster communications. Caching strategies are another very important aspect of back end development, as network communications are inherently slow (relatively speaking) and costly. This is all just concepts for back end **development** so far, but the reality is that _most_ back end engineering jobs will require you to take on at least some Ops roles as well (Some companies expect their developers to do double duty and perform development **and** ops at the same time. These roles are typically called "dev ops."), so things like basic linux server administration (VMs, containers, w/e) and knowing your way around the shell and basic linux tools is also important, but I digress. There are loads more concepts that back end engineers will typically utilize in their day-to-day, but there is really no way that you can expect to learn _everything_ before landing your first back end gig. Much of what I have already mentioned will be learned with experience and time on the job. The one thing you will have to accept when switching from one specialization to another is that your title will likely not transition over. For instance, if you are currnetly a "senior" software engineer, then you will probably land the new gig with something like a "mid-level" software engineer title (or w/e that company calls it). Unfortunately, this also often results in a pay cut. In this particular case, you might get lucky, however, as back end engineers **typically** get paid more than mobile or front-end engineers, so it might even out in the end, but I wouldn't bank on it. Source: I am a back end engineer for a popular global engineering company.
try to find a job where they're doing android development but are also looking for backend help. Most apps need servers. Offer your app expertise with the condition that you get to tag along with the server team and come up to speed that way. Honestly, having someone that spans teams is super useful, in my experience, because they can more easily understand how both sides work, and help explain to the backend engineers why they shouldn't just rip out that API, and explain to the app engineers why they shouldn't request the same data 10 times in 2 seconds... (etc)
Also, FWIW, when I am interviewing candidates for a job, I am less interested in what they already _know_ (though don't get me wrong, this is certainly important to some degree as well), and more interested in their aptitude to _learn_. I find that it is much more enjoyable and easier to work with people who are not caught up in their ways based on past experiences, and are instead willing to keep an open mind. Also, cultural fit is a _HUGE_ requirement for any candidates that I interview. I'm in the gaming industry, but since we don't actually write games, but instead work on a major service, we get a lot of the benefits of the game industry, without much of the downsides (i.e crunching). Because of this, we get _a lot_ of candidates that are trying to migrate from a career in gameplay or engine programming, and into back end development. We, of course, don't expect these people to know everything there is to systems engineering, but we expect them to be competent programmers with a high aptitude for learning. As long as they have these two traits, we will usually at least give them a shot to convince us to hire them. In fact, most of my current team has come from some other form of development. I came from full stack, personally, while others were game developers, engine developers, front-end developers, and even a couple Ops people.
Video description: "Go's simplicity and concurrency model make it an appealing choice for backend systems, but how does it fare for latency-sensitive applications? In this talk, we explore the other side of the coin by providing some tips on writing high-performance Go and lessons learned in the process. We do a deep dive on low-level performance optimizations in order to make Go a more compelling option in the world of systems programming, but we also consider the trade-offs involved."
That'll still need the Go runtime active, it won't behave like a C library. I would recommend against trying to embed Go in another language.
&gt; Maps provided by this package can be useful when using a key type that is not comparable at the language level, like for example a slice. If that's a `[]byte`, you should know that `m[string(s)]` is optimized and a fine way to solve that problem.
May I ask why Go? You must have lots of Java experience and there's tons of work to be done server side with Java or another JVM language like Kotlin, Scala, Groovy, or whatever is cool these days. Just asking since I believe the JVM job market is much larger. Some may mix Go in for particular cases if you want both.
[removed]
There's an issue about it. https://github.com/golang/go/issues/21921
You've already got lots of good advice about thoroughly understanding TCP and HTTP, so I'll add this: https://pdos.csail.mit.edu/6.824/labs/lab-raft.html It's an MIT lab that has an exercise where you build a Raft implementation in Golang and it gets tested by their own Golang test harness. Distributed systems is usually the missing piece for a backend engineer, and if you can say (and if you actually have) that you've implemented Raft using Go channels, people will take you seriously when it comes to interviewing etc.
Just GO for it. . . OK, I'm done for the day.
C++ or Ada dont give you a stacktrace by default either.
Author here. Looking forward to your feedback!
https://github.com/avelino/awesome-go
If you can't use tools provided by the language (go fmt), then please refrain from makings public posts, as it just makes you look bad.
That definitely sounds really interesting. Actually right now I am thinking about implementing simple messenger app with Android frontend. This should cover Websocket connection and much more. To be honest, for now, I don't have any experience with K8s, well, I know the purpose of it, just haven't worked with that. This definitely goes on my todo list. Thank you so much!
Well, yeah, you are right. Guess, I just miss that junior feeling :) I do have lots of experience with Java and Kotlin. Actually, since companies with exclusively Go stack are somewhat exotic, I was thinking about companies who have JVM stack and doing some Go microservices in addition.
I am based in Stockholm, Sweden. Not tied at all. I do acknowledge, that "only Go" stack is somewhat exotic, that's why I am asking more about ecosystem I should look into, rather than the language itself. Language can be picked in a week or two(well, maybe not C++ or some hardcore functional stuff).
Thank you, very useful :) 
Good talk, knowledgeable speaker not being religious, sometimes something hard to ask for in the Go community!
are there any benchmarks compared to numpy?
Thank you a lot for such comprehensive answer. Yeah, currently I am digging into microdevice architecture and Docker, I believe today it is a crucial part of being back end engineer. Well, at least, if you are not working in some pure monolith type of a project, but even these projects are trying to break down their monolith today. As for the titles...Well, I do understand the risks here, but software development is just so much more for me than a title or a paycheck. I am just incredibly passionate about it. Therefore, if it brings me the joy of learning/struggling with new stuff, I am more than ready to sacrifice some fancy titles :)
My route was fairly similar, after failing horribly at school I spent a few years cooking in a few different pubs and restaurants then did a 5 year stint selling tools and other junk. I got lucky and got hired as web developer for a company site which then led to a Support role with some dev helping out some of the top FTSE 100 companies with security and file transfer automation. After 4 years there I moved on to supporting one of the leading print management solutions and looking into bugs and now I spend my time dealing with really odd support issues and writing integrations between systems using Go.
Feel free to submit feature proposals or send pull requests. Thanks!
What do you mean?
Not explicitly against numpy, or none that I know of. Numpy uses blas under the hood though so what we would compare is Gonum's BLAS implementation against BLAS. For this we do have some benchmarks. Basically for small matrices we are as fast (if not faster) than BLAS. For bigger ones BLAS wins (but there's work on going to rewrite parts of our loops with SSE/avx support.) /u/howeman knows all the details.
Great write-up. Thanks for sharing this. 
Talk: https://www.youtube.com/watch?v=F2Ls6xZdSrE Slides: https://atmanos.org/talks/go-without-the-os-gophercon-2016 Website: https://atmanos.org/
Yes. If this is _your_ definition of bad, then yes, it is. You might spend some time reflecting on your definition.
People are saying that "oh, picking up a language is easy." I would tend to agree; being able to write compiling applications is easy. The biggest stumbling block that I see among Go programmers is that they fail to understand that Go is the result of conscious efforts to make a language that is concise, simple, and powerful. Rob Pike and Ken Thompson are on the project, and they've experienced nearly all of programing history. They and their team have carefully crafted Go to enable people to write concise, simple, and powerful programs. The part that you need to understand is that people seem to have an overwhelming need to make it complicated. Yes, you can write Java code in Go, with piles of frameworks and lots of unnecessary abstractions. The language was developed explicitly to eliminate those, though. Make it simple. To make it simple, though, you need to understand the history, context, and details of the language. I urge you to watch the tech talks and presentations produced by the Go team. Rob Pike and Andrew Gerrard are two good names to search for on YouTube.
There are a few mistakes in the article: * OnesCount is so fast because it is implemented as a builtin on x86-64, and it uses the POPCNT instruction on any CPU that a supports (anything since Nehalem, 2008), with a runtime check that falls back to the math/bits implementation when it doesn't. * The same applies to TrailingZeros, which is implemented using the BSF instruction, available on all x86 CPUs. * The benchmarks that use builtins are benchmarking a mostly empty loop because the compiler sees that the return value is ignored and does not do the calculation. To avoid eliding code, the return value should be assigned to a sink (eg: a global variable).
It's definitely his first time on the internet LOL
database 1st
If you upgrade x/tools/present to tip, the slides will work on mobile. 
Thanks for the corrections, I ~~will update~~ updated the article with a link to this comment. Looking at the maths/bits package, I didn't see architecture-specific code, and took the code in the package at face value. I'll have to go dig to find the runtime fallback, could you point us to it? As to the last point, assigning the return value in this case makes no difference to the benchmarks. But you raise a good point, and I ~~will update~~ updated the benchmark in the post so that there is no uncertainty here. Thanks!
wow showing YOUR true colors here!
/u/dlsniper &gt; This loses all the potential value as soon as the example shows int64 as key type... Example updated to use `*big.Int`. Note that even though `*big.Int` _is_ a valid Go map key the equality operation would only consider the pointer value, not the _value_ the pointer represents. OTOH, `big.Int` (non pointer) is not a valid Go map key. &gt; Also, why would one use this when the key types are not comparable? You mention a slice as being the case but I don't understand where that would be preferred or useful. There are infinitely many non-comparable types having regardless perfectly defined value equality semantics, so I don't understand why it would _not_ be usefull. &gt; And of course, the bigger question, why not use the Go 1.9 sync.Map instead of this of this or the built in one? Because you cannot put, for example `big.Int` as a key to neither of them. 
/u/tv64738 &gt; If that's a []byte, you should know that m[string(s)] is optimized and a fine way to solve that problem. I'm playing with a number-theoretic term-rewriting system and want to have `big.Int` keyed maps, to start with. Benchmarks using the string value as the key, even when hex encoded, showed the costs are higher than computing the hash from Sign() and Bits(). Also, in the later case any allocations are avoided. The example has been updated to use big ints.
FYI you should really include a `rate` in uses of `histogram_quantile`, as you probably don't want the 90th percentile latency _over all time_: ``` histogram_quantile(0.9, rate(http_request_duration_seconds_bucket[10m])) ``` See https://prometheus.io/docs/querying/functions/#histogram_quantile()
I tend to use irate for network histograms. I haven't seen much difference in practice - have you? I know irates are for faster moving counters - network fluctuations seem like a good place for irates, right?
Recommendations against this are dated. While some of the interesting go features are funky, you can design a black box that works fine. Also things have gotten a hella lot better in the past few go releases. 
[removed]
I tend to use `irate` for almost everything in a dashboards except `histogram_quantiles`! But I guess I don't have a good reason for that, might just be cargo cult.
&gt; Looking at the maths/bits package, I didn't see architecture-specific code The code is replaced by the compiler as the code is generated to avoid the function call overhead. See here: https://github.com/golang/go/blob/master/src/cmd/compile/internal/gc/ssa.go#L2758 Also, your benchmark has a modulus in the benchmark loop. You have 34 entries, so I suspect this could be an integer division which is quite slow. You should reduce your test-set to 32 entries, and the compiler will likely do a "&amp;31" instead (or just rewrite the modulus yourself).
[removed]
Thank you for the article. A note: 79.9 vs 9.07 is not 10 almost 10 times faster, it is almost 9 times faster (9²=81&gt;79.9). That doesn't really matter of course, but number 10 has boundary meaning in most modern cultures, thus you should be more careful with this value.
very cool!
very cool!
have you had a look at gonum and gorgonia?
&gt; The benchmarks that use builtins are benchmarking a mostly empty loop because the compiler sees that the return value is ignored and does not do the calculation. To avoid eliding code, the return value should be assigned to a sink (eg: a global variable). I don't think that is true. Go is smart enough to detect false eliding in the benchmarks. For clarity's sake, I think doing a `_ = fun()` is good enough.
My favorite stack
What I wrote above is not an assumption, it’s result of direct observation of assembly code generated by the code written in the article. Try yourself 
Here is some code. Both of them give the same result. So not sure where I am going wrong - func BenchmarkPrefix(b *testing.B) { str := "-somerandomstring" for n := 0; n &lt; b.N; n++ { strings.HasPrefix(str, "-") } } func BenchmarkPrefix(b *testing.B) { str := "-somerandomstring" checker := false for n := 0; n &lt; b.N; n++ { checker = strings.HasPrefix(str, "-") } b.Log(checker) } 
Thanks, it was closer to 10 in my first run, but then I updated the benchmarks and results after the comments here, and neglected to update the "almost 10" in the body of text. Corrected to "about 9" now :) Edit: Actually, after removing the modulo from the benchmarks, the difference is much larger than 10x. Updated the numbers (and the text this time)
Elision matters for builtins, because the compiler knows that a built in can be elided without side effects. The same would apply for code that gets inlined. If HasPrefix is not inlined, then it doesn’t matter whether you use or not the result value, it will still be called. Try comparing assembly code for your OnesCount example with or without assigning the result value to a sink (global variable). I’m off computer now so I can’t do that myself to show you the difference 
Thanks for the link! I'm going to update the post with this info. And great shout about the modulus, that actually changes the results significantly. When using &amp;31, the benchmark results are: $ go test -bench=. goos: linux goarch: amd64 BenchmarkNaiveOnesCount64-4 20000000 74.3 ns/op BenchmarkBitsOnesCount64-4 2000000000 1.19 ns/op BenchmarkNaiveTrailingZeros64-4 200000000 6.34 ns/op BenchmarkBitsTrailingZeros64-4 2000000000 1.02 ns/op PASS ok _/home/code/bits 8.123s 
Ah its for builtins ! Alright thanks. I was afraid that all those years of benchmarking was incorrect. :(
How do you revoke access?
Chrome debugger protocol has DOM.QuerySelector and DOM.QuerySelectorAll methods. Not sure how they are exposed in chromedp. I tried them out with my implementation: https://github.com/raff/godet/blob/fa9486a9c62f0a3eec7474be590c87e1a407f9a6/cmd/godet/main.go#L413 
Not enough traffic? I do not recall seeing the site before, for one.
I'm interested to hear what Go folks think of generating (stub) code in this way.
Awesome. Would love to see this backported into the official Go binary!
btw. is there any way to overcome int64 limit of FileInfo' size? How about an abstract file system supporting files having size &gt;MaxInt64 bytes?
A WSDL library that really work, not just on simple use cases.
Stringifying is gonna be costly, for sure. The `m[string(aByteSlice)]` trick has none of that cost. I appreciate the realistic example.
You don’t. Access tokens (jwt) are issued with short lifespans, say 10-15 minutes. Alongside the access token, an opaque refresh token is issued with a longer lifespan and stored on your backend, the client can than exchange an expired access token with a new valid one using the refresh token.
This is very cool.
People kept posting about it without clickable links
&gt; The m[string(aByteSlice)] trick has none of that cost. On one side of the assignment only. Anyway, `big.Int` has no zero cost `[]byte` representation available, only a computed one, but `Bits()` are zero cost.
Native crossplatform GUI. True bidirectional RPC. 
A pure-Go implementation of WebRTC.
Awesome! I made a PR to add removing the current track from your library, going to the previous song, and getting current song info if you wanna check that out.
Tried grpc for bidirectional RPC? If so, what kind of limitations have you had with it?
XML Schema validation
👌 [Learn Go Programming Blog](https://blog.learngoprogramming.com) 
As far as I understand in "grpc" it is suggested to implement it through the bidirectional stream. And there is no way to call client methods on the server or at least pass a new session through some tricky method. Here is [issue](https://github.com/grpc/grpc-go/issues/484) about it: "I think you need to refactor your service model somehow to fit into the client-server model of rpc". In the world of "grpc" my desires are wrong by design. So I would like to find a world where my wishes are normal :) ps: I was implement this through the wrapper/manager around net/rpc: the client and the server are init two connections, in which they have implementations of both roles for each other. But at the moment it all looks pretty messy and cumbersome. Soon I will try to implement this through a multiplexer, which would cost a single tcp connection. And all this things needs to be coded. Bui I wish it had been "import 'hogwarts.code/archmage/awesome-rpc'" and pew pew pew.
A native library for mDNS+SD that's compatible with Avahi
A high quality, pluggable task queue library. There are a few out there that only work with a specific queue provider, and there are others that have many non-optional advanced features like task result storage. None of them are particularly robust or efficient, and they also usually don't fit in with Go's ethos of simplicity and composability. I just want something that lets me give it a function that returns messages to process, a function that marks processed messages as done, a function that processes messages, and it should handle the rest.
This makes sense. I don't think there's a way to get around having a client and server at least for the initial connection - something has to listen for a connection provided by a client. Once that's established though then I don't see a reason why they can't pass that connection off to the same handlers to serve the RPC.
I'm not disagreeing with you, just making it very clear that the "string" in `m[string(aByteSlice)]` is very different from your "using the string value as the key".
Take a look at https://www.cilium.io/ it’s who I’ve been using lately for this type of stuff 
"Systems" refers to a type of application that only speaks to other applications. 
The Go runtime will still be there, once for every time you embed Go into non-Go. I stand by "won't behave like a C library".
Great post. A small readability note: using backticks for strings will allow you to skip escaping double quotes. 
Yeah this would be good. Having to work with SOAP is painful from Golang
Could every other language be considered a "systems" language though? I can't imagine an application that wouldn't be able to talk to another application? Speaking from the perspective of the language that was used to code the application
Yes, but usually it's languages with certain capabilities or features that lend themselves to the task. For Go, I'm pretty sure it is it's ability to quickly process huge amounts of requests. 
https://en.wikipedia.org/wiki/System_programming 
**System programming** System programming (or systems programming) is the activity of programming computer system software. The primary distinguishing characteristic of systems programming when compared to application programming is that application programming aims to produce software which provides services to the user directly (e.g. word processor), whereas systems programming aims to produce software and software platforms which provide services to other software, are performance constrained, or both (e.g. operating systems, computational science applications, game engines and AAA video games, industrial automation, and software as a service applications). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
You should x-post this to /r/PrometheusMonitoring
In the same way that any vehicle could be used as a rally car. Sure, you can do it, but you'll probably have better results if you stick with the Subaru.
It serves as a backbone for other part of the app (even the backend). You can say it works like an OS,
Not exactly a library, but GNU Parallel, rewritten from Perl to Go. A modern parallel vcheck, rewritten in Go: http://www.jasonc.com/code/vcheck/
implement the parse method for https://github.com/domainr/whois The fact that each domain registrar has decided to implement whois in a different and incompatible way is what makes it non trivial. 
I have one I made for work but it's not open source (yet)
1. An idiomatic implementation of json5: http://json5.org/ 2. An idiomatic implementation of the JOSE suite which would be these: * JSON Web Signature (JWS) (RFC 7515) * JSON Web Encryption (JWE) (RFC 7516) * JSON Web Key (JWK) (RFC 7517) * JSON Web Algorithms (JWA) (RFC 7518) * JSON Web Token (JWT )(RFC 7519) * JSON Web Key (JWK) Thumbprint (RFC 7638) * JSON Web Signature (JWS) Unencoded Payload Option (RFC 7797) * Examples of Protecting Content Using JSON Object Signing and Encryption (JOSE) (RFC 7520) * Proof-of-Possession Key Semantics for JSON Web Tokens (JWTs) (RFC 7800) * FRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE) (RFC 8037) 
I've used https://github.com/square/go-jose which is actually pretty good.
A good MQTT server library. Existing ones have been abandoned or are incomplete.
A pure Go implementation of https://github.com/google/woff2 would be nice, but it's nowhere near the top of my list of practical needs. It'd be a nice to have.
A pure Go implementation of zeromq would be nice. I use zeromq heavily. EDIT: Yes I know about mangos
So much the cross platform GUI. Would love to be able to create GUI stuff in Go. Nothing comes even close to being production ready currently sadly 
I guess the intention is to demonstrate the logic of an Adaline neuron in pure &amp; simple Go. (I did [the same with a perceptron](https://appliedgo.net/perceptron) a while ago.) Of course, you're right, for any real-life NN project, gonum and gorgonia are preferable over programming from scratch.
I did a tiny PR that lets you repeat strings to fill up the file.
Sweet thanks. I'll take a look!
The author of zeromq and nanomsg lists [a couple of shortcomings of zeromq](http://nanomsg.org/documentation-zeromq.html). To me it seems that porting 0mq to Go would be a significantly complicated endeavor, and that't probably why only bindings but no true ports exist.
Is there any perf benefit in using the `RotateLeft` functions ? In my benchmarks, they perform equally well with just native `&lt;&lt;`.
👍
I have been using "github.com/grandcat/zeroconf" with a lot of success, any particular issue you have with the library of why it doesnt work with Avahi. I have Avahi in raspberry pi's talking to either a windows or OSX server using this lib, and works great for my usage so far.
As others already mentioned: * fully featured wsdl / soap library * more official win32 api lib that goes beyond what should be in the stdlib * "popular" electron + go framework * no cross platform but a strong Windows / MAC GUI framework 
[DNSCrypt](https://dnscrypt.org/) golang library Compatible with https://github.com/miekg/dns
Though I've run into a few bugs, [Eclipse Paho](https://github.com/eclipse/paho.mqtt.golang/) is pretty complete, actively maintained and maintainers are responsive.
Same boat as you. I'm a front-end dev and trying to learn some back end to assist me with my personal projects. That resource link will help alot so thanks!
Good to know I'm not the only one struggling.... 😕
Why exactly are AAA games in the examples if game engine was already there? Isnt anything else in the game that isnt the engine the application part of the game? Sometimes Wikipedia confuses me :D
I'm working on a [project](https://github.com/arsham/expipe) that ships **expvar** metrics to **elasticsearch** (soon to other databases) and I'm pretty much alone on this project. Feel free to join in.
It's a shame that Google Flutter doesn't support Go.
The key point was "systems programming aims to produce software and software platforms which provide services to other software, *are performance constrained*, or both". Game engine would be a subset of AAA video games, but they are together both an example of a performance constrained software. One could subdivide that further into [audio libraries](https://www.fmod.com/), AI, etc. all of which still fall under the same designation of systems programming.
You should take a look at [github.com/knq/jwt](https://github.com/knq/jwt) -- most of what you would actually need in a server/client package is available there.
Bad wants HTTP Digest authentication: https://twitter.com/bradfitz/status/914559647457042432
Wow! This looks great at first glance! I'll look more into it tomorrow. Thanks! Edit: And I just noticed you're the author. Even better!
Something to avoid writing `if (err != nil) ...` after every line, like an Either monad but one that doesn't use `interface{}`
Exactly, as /u/ChristophBerger says the intention is to show the neuron internals as simple and understandable as possible. I used it to learn how it works. I looked over gonum but I believe that it would had added many unnecessary complexity to the program. 
I'm not often in Colorado anymore, but when I am there I'm around Downtown Denver and the Westminster/Thornton areas. Sometimes also out at Boulder.
In fact JSON rpc is a standard that has clients and servers for the connection, but communication doesn't have a concept of clients or servers. And it is a standard, node for example has some libs for it. 
The detect() function returns 2 for Python 2, 3 for Python 3 and 6 for files compatible with both. 
It's worth noting that RotateLeft is not exactly the same as left shift, since `&lt;&lt;` fills with zeros on the right, and RotateLeft wraps around. (https://play.golang.org/p/mufr4QFTRy) But yes, performance-wise, I also found no difference between the math/bits function and a custom implementation.
I would like to see a Sass compiler for Go. There's one in Ruby, C and Dart. It would go well with Hugo. 
simplest one would be to not pretend you're filesystem and just return data in a loop directly in router
The difference I see is that `&lt;&lt;` is a bit shift without rotation and `RotateLeft` also rotates the bits at the end. So there's no reason to compare the two.
[Errors are values](https://blog.golang.org/errors-are-values) might be an interesting read. The `errWriter` approach works great for those repetitive checks.
To be fair, having to work with SOAP is painful with most languages and libraries.
tbh SOAP is always painful, there's just… degrees of suffering.
Pure Go Kernel32 / User32 implementation
Compile Javascript/Node to go.
Oh boy, thanks for pointing it out. Those are 2 ENTIRELY different things.
was this talk recorded somewhere? It looks interesting, but the slides are missing a lot of context.
How many files do you have lying around containing more than MaxInt64 bytes and how often do you need to read them? That's what I thought ;)
https://www.youtube.com/watch?v=DJ4d_PZ6Gns&amp;feature=youtu.be
&gt;[**"So You Wanna Go Fast?" by Tyler Treat [38:22]**](http://youtu.be/DJ4d_PZ6Gns) &gt;&gt;Go's simplicity and concurrency model make it an appealing choice for backend systems, but how does it fare for latency-sensitive applications? In this talk, we explore the other side of the coin by providing some tips on writing high-performance Go and lessons learned in the process. We do a deep dive on low-level performance optimizations in order to make Go a more compelling option in the world of systems programming, but we also consider the trade-offs involved. &gt; [*^Strange ^Loop*](https://www.youtube.com/channel/UC_QIfHvN9auy2CoOdSfMWDw) ^in ^Science ^&amp; ^Technology &gt;*^1,745 ^views ^since ^Sep ^2017* [^bot ^info](/r/youtubefactsbot/wiki/index)
Im trying to make a link building site just to learn. I've been using cloud9 ide so it doesn't matter where I'm at and I figure then for interviews they can see my environment, code, and it running in the same environment I coded it in. I wanted to make a tutorial for people learning. Cause they keep posting giant complex packages on Reddit but... They dont seem to teach you much. So I figure If i want golang to spread, I gotta try to scour the web for resources and try to slap it together and then why not share my steps. Once I got something useful, I'll post the steps with the resources for context. But I never did this stuff before and I only work on it on my time off and it's a new language, so going from one stack overflow to the next is kinda a slow process.
On mobile so I can't provide much context but... I'd love a gpgme ("high" level gpg library that's recommended) implementation that wasnt using the C library (for cross compilation purposes) OR a libassuan implementation which is what you use to talk to a gpg agent. 
On mobile so I can't provide much context but... I'd love a gpgme ("high" level gpg library that's recommended) implementation that wasnt using the C library (for cross compilation purposes) OR a libassuan implementation which is what you use to talk to a gpg agent. 
Actually looks like this guy kinda beat me to the chase but he is using a lot of packages but I think the structuring is good to review. To be honest I'm not a purist but packages are useful but kinda limiting too. https://github.com/dhax/go-base?files=1
Ugh apart from some nil pointer panics, sure. They didn't handle returned errors at some point, and the fact that they got to a nil pointer panic is a completely other issue. https://github.com/eclipse/paho.mqtt.golang/issues/115 tbh, it's still your best bet, just don't expect it to be completely bulletproof. As you say, it's actively maintained, but I can't say it's exactly issue free.
Don't know about compiling it, but you can use a pretty great interpreter, https://github.com/robertkrimen/otto - it might not get you all the way up to running things like babel or something, but you can get pretty far.
There is no production-ready / non-experimental JSON-RPC 2.0 client and server package - and that also implements batched requests (&lt;- saves on roundtrip times). Even [the most mature package](https://github.com/sourcegraph/jsonrpc2) does not implement batch requests and is marked experimental. And stdlib net/rpc/jsonrpc only supports v1.0 :-(
Yeah I use Eclipse Paho on the client end, but missing is any good library for the *server* end.
yes. that would be really great. this would, e.g., allow an easier installation of gophernotes, the Jupyter kernel for Go. there are already these (incomplete) libraries: - https://github.com/zeromq/gomq - https://github.com/sbinet-alice/zmq the second one is my naive attempt at implementing 0MQ on top of mangos' infrastructure.
nice! I have a couple of comments, though. - first, please `gofmt` your code, it presents better afterwards :) - in `initWeights`, wouldn't it be easier to only shoot 1 random number directly between [-1, 1) like so: `w := 2*rand.Float64() - 1` ? - you should check your `errors`. especially when writing/creating files, and also when `Close()`-ing a file that was written to (_e.g._ in `createCSV`) - you should also check the error coming out of `reader.All()` in `readCSV` - you should check all the errors coming out of `strconv.ParseFloat` in `readCSV` 
Probably the most missing package for Go is a namespace-capable xml (de-)serializer, which in turn limits support for legacy interfaces like SOAP.
also, if `-path` is `"."`, then `readCSV` will silently fail, trying to read data off `".training.csv"`
here is my CL: https://github.com/Plorenzo/goAdaline/pull/1
a soap server.
panics, it's as simple as that. You can't have a fully typed either monad in Go because there are no generics or type classes.
This paper seemed to be a nice read. And the reasoning seem valid. I would not judge if it's bad or good. But I'm interested in trade-offs. The paper states that RPC is now trying to solve the problems that are already solved in REST land. And seems sharing a read on reddit is the most stupid thing someone could do. I promise I would not do that again; whatever.
Agreed, I want to use MQTT so much in some IOT projects but the lack of a good golang server implementation makes me just look into HTTP with its large overhead
Some have used NSQ for this, total overkill for simple use cases http://nsq.io/
does it really matter what the mqtt server is implemented in? It's a server - deploy it, connect to it, move on. 
Are there any good, public SOAP APIs with WSDLs that someone could use for testing and development? Ones that are not just "simple use cases", obviously.
here are the slides as well: https://www.reddit.com/r/golang/
If you are in operations or want to simplify operations then how the server is designed matters. https://github.com/mqtt/mqtt.github.io/wiki/servers https://github.com/mqtt/mqtt.github.io/wiki/server-support Nothing jumps out as open source, simple and good. The closest is RabbitMQ but it feels like overkill since it is designed for AMQP
We recently switched from Python to Go. It took a bit more discipline to make things testable. Love the new setup though, works like a charm.
Your 2nd and 3rd snippet looks the same, why bother and use stretchr/testify?
Add a cron/scheduler task to run on scheduled date + on server startup. In the application code write some logic that makes sure that it runs either if the thing failed on last run, or when it's the time of the month.
Hi Dmitri, Have you tried transpiling it using https://github.com/elliotchance/c2go ? I know the project is very nascent. But maybe worth a shot, since the core woff2 code seems pretty contained.
Let electron die pls. If we get fully cross-platform GUI in golang we wouldn't need electron.
The same? You save all that 'expected this but got this...' stuff which you have to write for every test. Personally I just wrote myself a few helpers(https://github.com/gempir/go-twitch-irc/blob/master/helpers_test.go) , but I get why assert is useful. 
&gt; You save all that 'expected this but got this...' What's wrong with them? [edit] Starting 1.9 your helpers should call t.Helper() to record correct failure location in the source file. I wonder why you was not bothered by this so far.
https://github.com/faiface/pixel Obligatory, since I'm the author. The progress has been slow recently, but that should change in some time.
The thought crossed my mind, yes. However, the more I looked at it, the more I thought it would require porting from C++ to C first, since I doubt c2go would support C++. I have not tried it at all though, so it may be harder or easier than I anticipate. It's worth a shot before exploring more costly avenues, that's for sure.
One benefit is that stretchr/testify does value equality so it'll still work for pointer fields in structs (under the hood it uses davecgh/go-spew on the two values and then does a diff on the outputs)
They are fine in small codebases, but get repetitive very quickly otherwise. Especially when either: - You never expect a call to fail in a test (1 line vs 3) - When you want to do more than a simple `!= nil` check (such as `DeepEqual` like stuff) - When you are refactoring tests, because you cannot forget to change the message
Think something similar is the best solution. The application process is split into three parts, the init phase, process phase and the cleanup phase. If I change it so that the init phase is done by schedule only then I can have a checker every X that checks if the if the process is running and if the cleanup is done. If the process is not running and if the cleanup is not done then the process is started again, if the process is not running and the cleanup is done then nothing is done until the next scheduled time and the init phase is done. The only issue left here is how to handle if the scheduled cron time is missed.
+1, this would be huge. Or even a complete-ish API implementation for the C++ bindings (lots left out in https://github.com/keroserene/go-webrtc/).
This is the kind of thing for which I'd be happy to lend a hand, provided someone with good knowledge of the WebRTC spec were there to guide the project. Just in case such a person is lurking ...
I authored https://github.com/oakmound/oak We're planning to release 1.4 this week, and 2.0 later in the month. We just hit 95% unit test coverage on the 2.0 branch. https://github.com/hajimehoshi/ebiten is worth looking into, as well.
&gt; There are some scenarios where [interface-based mocking] would be too complicated and/or steal too much time (or, even worse, obfuscate the underlying code). I challenge this statement quite strongly. I've not seen a situation where this is true, especially if you understand the need for this style of dependency injection from the outset. GoMock is a heavy and unwieldy dependency, and AFAIK abandoned by its original authors.
Gotcha - I figured something like that existed, but hadn't gotten around to looking it up; thanks!
Unfortunaly, I don't think there are good public WSDL/SOAP servers out there. SOAP is usually used by enterprise systems like ERPs, etc. 
do you think it would be possible to expose an API so one could: - point some `go/ast`, `go/types` or `go/ssa` based tool at a Go function - parse it and extract an `expreduce`-compatible string representing that Go function - call `D[..., x]` - and then generate some Go source code out of that. ? 
Thanks, I'm the author of Ebiten :-)
Personally I use Ginkgo coupled with Httpexpect for controllers specs and really enjoying it. Find it even better that Rspec for Rails.
&gt; The only issue left here is how to handle if the scheduled cron time is missed. cron can’t do that for you. Perhaps you could create a file containing the due date of the next run, and if that file exists and the due date has passed, run the task. 
This would certainly be possible as long as we put reasonable restrictions on what types of functions could be translated. I.e: if the function opens up a file or does anything besides use some of the standard math functions and have some variable assignments, all bets would be off. I'm trying to understand the use case, though. Why not do numerical differentiation? Why not just find the derivative manually for a small number of functions? Are there so many functions that doing so would be infeasible?
the idea is to be able to funnel this to a minimization package such as: - https://godoc.org/gonum.org/v1/gonum/optimize - https://godoc.org/gonum.org/v1/gonum/optimize#Problem gonum can do numerical differentiation, but at times, it's handy to get an analytical differentiation to reduce the number of floating point operations. 
Well, honestly if you think this is cool go for mirage, it's actually well supported, is being supported by docker and citrix engineers, and I mean for a lot of what one would use go for (apart from fast brute force logic type programs), ocaml is more suitable to use. 
I'll check it out, Looks promising, I hope you get audio in soon
I'll check them out!
Audio actually does exist in a separate library: https://github.com/faiface/beep/
I love your examples, very varied. The typewriter examples looks great!
Thanks :)
ctrl-q asks if you're sure you want to quit, no matter what you type it just says "okay, then" and continues the game. pressing "s", which is supposed to save and quit just yields "unknown key" or something. the only way to quit was to kill the process... so that sucks. EDIT: apparently you have to use capital letters!? that's... not how this is supposed to work. `[Y/n]` in the Unix world means that yes is the default, you just have to press enter to select it. Typing a lowercase 'y' is also acceptable. That's what capital letters are supposed to mean...
There was an interview with important people in various "systems languages", from D, Rust, Bjarne Stroustrup for C++, and Rob Pike for Go. One of the first questions asked was what a systems language was - after all four of them gave different answers, I think they all agreed to stop saying it. I'm pretty sure Rob Pike admitted that when they wrote that long ago in the early documentation, they didn't have a good boundary on what is or is not systems software. 
There is not any viable cross-platform out there. Everything has so many compromises that thinking there will be one is being just very naive.
I run that site, that was the old domain, which has forwarded to a new domain for some time after Unknwon donated a nicer domain. Didn't realise anyone was still using that older domain or had it bookmarked as I only used it for a few months. It moved over to https://golangnews.com a while ago, so if you enjoyed it, you can find it there. It has an active community of people posting links. There's also a twitter account which posts upvoted links - @golangnews.
Really? Where? Or is this sarcasm? I've never posted it here on the subreddit as it is quite similar, so wasn't sure if it would really appeal to redditors. Anyway, link is below if you're interested. 
Oh, yes, you're right that this is not the usual meaning. The idea behind this was to really avoid to accidentally suicide a character, because most of the time you just save with `S` to quit the game, but I understand this is surprising. Hm, I'm now quite unsure about how I should write this message. Edit: I have [rephrased](https://github.com/anaseto/boohu/commit/decf9dd4f00e65b6f839b5afb5cc87b38d0c553b) the confirmation prompt. Thanks for pointing this out!
You're just the cutest little thing.
Is this a job interview question? It reads like one based on the naming of it all and everything else. If so, I first suggest reaching out to the company that sent you the problem. They would be happy to answer any questions you have I'm sure, and they likely want to evaluate your ability on your own, not the ability of everyone on r/golang. Finally, your question isn't really specific enough for anyone to help. What is troubling you? What specific step are you stuck on? What have you tried? Without a little more context we can't help much.
Why would anyone come to Reddit if there was absolutely nothing of value here? (Hint: there's value in the time and energy people bring here) By your logic, we should be fine with shitposts everywhere. Thankfully not everyone follows your logic.
"Chill mate"? Grow up.
[github.com/lestrrat/go-jwx](https://github.com/lestrrat/go-jwx) implements some of those; enough for signed, encrypted JWT at any rate.
A full namespace-aware [XPath](https://www.w3.org/TR/xpath/) implementation, which would allow you to implement [XML Canonicalization](https://www.w3.org/TR/xml-c14n), which would allow you to implement [XML Signature](https://www.w3.org/TR/xmldsig-core/), which would allow you to implement [XML Encryption](https://www.w3.org/TR/2002/REC-xmlenc-core-20021210/Overview.html), which would allow you to implement [SAML](https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language).
**Security Assertion Markup Language** Security Assertion Markup Language (SAML, pronounced sam-el) is an open standard for exchanging authentication and authorization data between parties, in particular, between an identity provider and a service provider. As its name implies, SAML is an XML-based markup language for security assertions, but SAML is also: A set of XML-based protocol messages A set of protocol message bindings A set of profiles (utilizing all of the above) The single most important use case that SAML addresses is web browser single sign-on (SSO). Single sign-on is relatively easy to accomplish within a security domain (using cookies, for example) but extending SSO across security domains is more difficult and resulted in the proliferation of non-interoperable proprietary technologies. The SAML Web Browser SSO profile was specified and standardized to promote interoperability. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Cross platform GUI that is 100% go. No cgo required. 
gRPC dude. It's awesome. 
Not exactly a Go-only solution, but Amazon's [SWF](https://aws.amazon.com/swf/) would be ideal for this kind of system. At a prior company, we started "daily workflow" at midnight every day performed several tasks throughout the day. Your use case sounds exactly like a long running activity with heartbeats.
Grow a funny bone pal. ;D
Just use the SDL.
Why don't you just go with the well-established norms instead? The standard way to do this to the effect that you're looking for would be to have the prompt say [y/N]. Have the input look for lower case y and n, and in the absence of those default to n. The default is indicated by which letter is capitalized
Ebiten is great, I've tried it with Leap Motion and works well.
Neat!
It can seem funny, but I actually never consciously payed attention to this norm before, so I thought something more explicit would be safer and more accessible to less Unix-versed people. But maybe it's just me, and I have nothing against this norm, so I'll eventually go with what you say :) Edit: [done](https://github.com/anaseto/boohu/commit/6c490be57830503a7d1fd2dd8681bb2fb98d3793).
Would be nice if you could "run" with capital `H`, `J`, etc. Even in the original rogue you could do that :-) It will make the character move until an enemy appears, hits a wall, or encounters a corner.
This is awesome! Thank you for contributing, I'm fairly new to go. Having libraries like this really helps with the learning process. 
ebiten... hmm... the name is pretty interesting when pronounced in russian. Which can be translated as f***ed... oh well.
Yes, I've thought about it more than once, and somehow forgotten to add this. In my defence, the original rogue did not have auto-exploration :) Edit: [running commited](https://github.com/anaseto/boohu/commit/4ea1550239d2fe42cacd656f8bf0edd2f41dae8f).
I just want to learn what do they want from me. Is this a rent a car application? Is this a algortihm? What i have to learn to make this application? I just want to learn this. (Which pkg, datastructers etc.) Thank you...
I know and I'm sorry if my writings suggested I don't.
Great article! I would change in-built to built-in, but then again I'm not sure of the semantic differences. I enjoyed the fact that you linked out to some really great resources. (I.E. Rob Pikes's talks, avelino/awesome-go, etc) One helpful topic would be when you're covering the language weaknesses. It would be great if you could include some "industry best practices," to mitigate these weaknesses. Specifically around dependency management, would be the most helpful for newbies like me. I would also move "target audience," closer to the top. It gives a clear guideline for who this article is for from the start. I think the addition of you adding "how to get started with go," is a really great add. The fact that you included companies currently using go is awesome. It helps to give dev's who are relatively new to go, a good sense of its popularity within the market. Thank you for writing this, it's a great article. edit: a word
Integration test is great to start when you have working code that might not fit into a unit test (yet). But on the long term you should aim for unit test as they are much faster and less flacky. I have very clear separation of responsibilities of my packages, so everything that doesn’t do any IO I write unit tests, eg.: http handlers. The handlers itself depend on a “storage” interface, that always has two implementations: inmemory or postgres. During unit tests I use the in memory storage. Because the postgres storage interact with database, to be sure they work as expected, I write integration test, but that’s very specific to these functions/structs. The last step is my e2e, which uses Selenium to test my application from a user point of view. This is the hardest test to setup and the most likely to fail. I try to avoid them and focus on Unit and Integration, but a few e2e are very helpful!
What do you recommend to use in place of gomock? gomock can be a pain in the ass, but I haven't found anything else that works well. in particular if you have multiple calls to the mocked method implementing the interface from scratch also becomes unwieldy
Gotta fix that site for mobile, homie.
I've got a sense of humor. You're just not funny.
I'm actually glad you pointed that out, you made me go back and think about the optimization. The reason that optimization doesn't exist for assignments is that the key needs to be stored, and for that to be safe it can't just keep using the mutable memory of the slice -- it needs to actually create the string, to store the key in the map.
&gt; Go’s official experiment dep should ideally become the solution to this problem soon. Probably in Go 2 "dep" should be ready long before Go 2. Though you might have just been being facetious.
Can you tell me more about your storage interface? I tried doing something similar for a mysql database but failed miserably. Simple queries aren't too bad but the more complex don't seem to fit the mold of a wrapper style approach well. Any tips?
Httpexpect looks promising, I'm not sure I understand enough about BDD to use Ginkgo.
good overview of Go features
The problem with that is that you need to know how testify works as opposed to just knowing how Go works. Anytime I look at a library's code that uses a testing framework, I have to learn that framework as well. Does Equal() call reflect.DeepEqual() or does it call some other library with a different definition of what equal should mean?
Check out how https://github.com/fortytw2/hydrocarbon/blob/master/db_test.go works - all the db tests are done directly against a live postgres, spun up inside a new docker container every time. However, there are still interfaces in front of each set of handlers so they can be tested with OR without the DB. (see https://github.com/fortytw2/hydrocarbon/blob/master/user_api.go#L22 ) Entire test suite here takes ~8s on my fanless laptop, no worries about speed w/ docker. Project pretty heavily leverages the database, so mocking everything out is a bit stupid for my purposes (doesn't actually provide anything useful besides an increased coverage %)
Awesome thanks! So, rather than mock the database, you're throwing up a containerized database during test. Brilliant.
Has the plus side of making it really easy to ensure all your queries are syntactically valid / return what you expect. I like to think of it as making integration tests so easy / fast to run that you don't even need to bother with testing in isolation of the db
Working on it :)
This is not my project. Keep in mind that several other implementations exist as well: * [gopher-lua (5.1, with channels)](https://github.com/yuin/gopher-lua) * [shopify's go-lua (5.2)](https://github.com/Shopify/go-lua) * [golua (5.1)](https://github.com/afitz/golua) I would consider go-lua to be the most stable implementation in this list, if you dont need the 5.3 features (like 64 bit integers, bitwise operators and utf8 support)
Thank you very much :) 
There's no mention in the readme, but what platforms does beep work on? From a quick glance your interface seems really great! I tried a game jam in Go the other month and lack of cross-platform audio libraries seemed to be an issue. Unfortunately I didn't get far enough to actually add audio, but I had been looking for a library in preparation!
The pronunciation is /ebíteɴ/ in IPA. It's hard or almost impossible to say a word is safe in any languages :-P
Thank you! That's interesting that it worked on VR.
1. thread safety is a misnomer and Go does nothing to help with that. It depends on concurrency fundamentals and knowing your data, which is not Go specific. So, Go does nothing for thread safety as a language. 2. Go is just fine for concurrency for most of the stuff but IMO a systems language cannot be judged without talking about latency responses and integration with C. Fortunately, Go is good at latency responses as long as you understand limits of Channels. C integration is important because most of the systems out there are in C and Go is not the best when it comes to communicating with C world due to its runtime limitations which is unfortunate. I personally have worked around this issue with ease after understanding limitations and working around it. 
Those 3 for loops one inside another gave me a mild heart attack. :) j/k, I understand matrices are awful when it comes to software. 
What kind of performance does your implementation have? I've looked seriously at the other Go Lua implementations for in scenario where performance is fairly important (and code mutates in real time). Unfortunately they were generally on the order of 100-1000x slower than LuaJIT, so I ended up just writing bindings out to LuaJIT. Would love a pure Go implementation that could get within the same order of magnitude of LJ.
I worked through this through the first mutation, and could not get it to work copying the code exactly. But this is exactly the tutorial I need, thank you! 
There's a WAMP client library called Nexus https://github.com/gammazero/nexus
Probably not going to happen 
Too bad the facts do not agree with you. ;D
Interesting. Looks like gonum has a file full of function definitions (in plain Go) along with corresponding gradient definitions also explicitly defined. These implement the Func() and Grad() functions. I suppose the idea here would be to auto-generate the Grad functions. Taking the derivative is easy. The question of if the automatic simplification is actually faster may or may not be true. It probably often is. There is also the option of using automatic differentiation instead of calculating a symbolic derivative, but you've probably considered that already. If we want to get crazy, we could have rules at the end that detect easily optimizable patterns like the inverse square root and replace them with the relevant optimized functions. This depends on how much we trust the Go compiler to make the right decisions. I don't care for writing the code that works with the Go AST, but if you or someone on the gonum team takes care of this code and is able to return something resembling a real equation in memory (no variable assignments, but can still be in some expression tree form), I would be happy to write that code that uses Expreduce to compute the derivative or return a failure.
&gt; Unlike C, you don’t need to remember to free up pointers or worry about dangling pointers in Go. The garbage collector automatically does this job. This also makes sure that there are no memory leaks Yes, but that doesn't mean you can play fast and reckless with your resources. Memory leaks can still happen. You still have to close connections and file handles. There should be a note on that.
Can you commit a pointer to a reference on where to begin again? On startup of the program it can see where it left off then begin from there. 
My storage actions are not complex as well, so I didn’t have any issues. You can check it out here https://github.com/getfider/fider/tree/master/app/storage storage.go has the interface and those packages the implementation. Tests against the postgres storage runs against a Docker instance, each test cleans up the database and seed with well known data so that the tests always start with a predictable state.
Could you give me a link to one of the projects where you use the bindings? 
Assertion libraries and gomock do not improve testing. They are both ways of optimizing for the test author, not for the reader or the person who breaks the test, and both are code smells of change detector testing.
pure zmq implementaion for Go supporting both ZMQ 3.x and newer ZMQ 4.x. All native Go ZMQ implementations suck balls when it comes to matching C/C++ implementations. Sad because now I have to use CGO :( 
man, that what awesome! I'm still learning how to handle errors in Go, is kind of confusing to me Thank you to put the time to fix all that things, I just merged your PR. 
thanks. here is one that fixes the PRNG: instead of drawing twice from the PRNG, draw once and rescale the range to fit `[-1,1)`: https://github.com/Plorenzo/goAdaline/pull/2 and here is one (just as an example) that uses Gonum's pkgs: https://github.com/Plorenzo/goAdaline/pull/3
in which benchmarks would you be interested? I guess it would be rather easy to test a few matrix/vector, matrix/matrix and vector/vector multiplications for a few sizes... just ask :)
I don't fully understand your question. Requirements in [**Questions**](https://gist.github.com/ferhatelmas/a118e823650d9719d5af5a0e530fe5f0#questions) part are pretty clear, you also have prepared testing suites, you only need to create structure with methods which fulfill these tests. You probably doesn't have to use any Go packages.
This is serious triple black diamond territory. New gophers should look, but don't touch. :) I really loved this video!
Could you please share that library?
Have a look at https://concourse.ci
Thanks for reviewing :)
Sure. I will do that. Thanks for taking out the time to review :)
I've seen a lot of lies from @dlsniper but paid github stars is the most crazy one!! You have fantasy
I always visit https://golangnews.com when I wake up and once when I go to sleep, it's a democratic news site not like this reddit.com/r/golang channel who people like @dlsniper delete my comments and my posts are invisible from public neither the gopher slack chat, which I got banned some months ago (when I announced a good deal between Iris and a startup company in my github repository) without any reason while I've to chat there from over a year...
It works on all major platforms (Linux, macOS, Windows, Android, iOS i think). But, the latency is significantly better on Linux currently than any other platform. That can get better of course if we (or someone) takes a stab at improving the latency on other platforms.
Think that is the best way to go in my case.
Was looking for a new framework preferably open source, so I'm steering away from SDL and SFML just because I want something new Edit: even tho I didn't specify new, just my preference here :P
matrix multiplication and (if implemented) solving Ax=b (matrix inversion) is always very interesting
Unfortunately it's closed source!
Unfortunately it's closed source (contains some further sandboxing code, LuaJIT modifications). I started it by looking [this person's](https://github.com/aarzilli/golua) Lua bindings; swapping out LuaJIT for Lua is a drop-in, since LJ's C API is mostly identical to Lua's.
[removed]
&gt; Our typical use case is when dealing with gRPCs In my experience, spinning up an in-process gRPC connection (like httptest) works much better than trying to mock the client stub.
We recently open sourced this project https://github.com/beme/abide. We use it capture "snapshots" of our API responses, which subsequent tests compare against. That way, if we make a change anywhere in our API and it "breaks" the response we expect, we're alerted. It also keeps the snapshots in version control which helps keep track of how our API changes over time.
This is our biggest and largest release ever. Checkout the full changelog: https://github.com/fatih/vim-go/blob/master/CHANGELOG.md#115---october-3-2017 You'll see many under the hood improvements, bug fixes, improvements. Huge thanks to Martin and Billie, our two new collaborators. 
Very hardcore guy. The tip about type-specific code is very useful.
Thanks for the hints!
[Alessandro Arzilli now maintains golua](https://github.com/aarzilli/golua), which support for Lua 5.3 in the dedicated branch (although some features may be missing). Also [luar](https://github.com/stevedonovan/luar/) provides convenience functions that make interfacing between Go and Lua a real bliss, if you can bear the performance cost.
Noice !! 
for #4 you'll need to volume mount the results outputs to folders then aggregate/upload the results to something like s3 (or some generic object storage like minio) after the run completes i don't know of a clean way to isolate #3 at the network level
... using https://github.com/graphql-go/graphql Which, according to my tastes at least, is too much of an `interface{}` hell to be nice. It wants the graph defined as a map of keys to (essentially) functions that return `interface{}`, which may then again return objects. Lots of `interface{}`, including in "params" coming from the client. 
Going through the readme, I'm getting a sort of Lua vibe? Is this intended for a similar embedded-scripting purpose? Can anyone speak more to Skylark's intended use and strengths? Edit: upon further reading, Skylark seems more tuned for dynamic generation of configuration. I've been burned hard by that before (Groovy comes to mind, among others), so initially I'm a little skeptical.
Indispensible tool. Thank you and the contributors!
It actually seems to be more inspired by Python than Lua, and yes its for dynamic configs, although I imagine it could work as embedded scripting engine, although I am not sure how efficient it is for that, wish it had some benchmarks...
Hey I had the same issue when I created my api so this is how my api is structured atm https://github.com/steffen25/golang.zone I’m new to Go so any feedback is highly appreciated as well I would like to hear from other experienced gophers out there what they do. I’m going to run this using docker and I made some changes yesterday I haven’t pushed..
Yes, I also was interested in some benchmarks or some ideas about the speed of the interpreter (for example compared to the standard python interpreter). And yes, the language is a subset of Python: "The extension language, Skylark, is a superset of the Core Build Language and its syntax is a subset of Python." 
language docs: https://docs.bazel.build/versions/master/skylark/language.html
it's really hard to benchmark languages. What would you benchmark? Use it one way, it's fast, use it a different way, it's slow. That's true of any language. 
seems like it's perfectly fine for an embedded scripting language. It was made for configuration, but so was Lua. It has functions and variables and string parsing etc.... so you can do pretty much whatever you want. Having embedded almost-python is probably a lot friendlier to most people than embedded Lua. I don't think it's intended for creating vastly complex behavior, but if you need to add some simple functionality to a go project, it might be a good option.
Does this hint at a Skylark use in go build? Maybe a Bazel clone built in Go?
Yes, Skylark is the evolution of the Bazel build language, which was originally Python. It got stripped down over the years to have less bells and whistles and more represent a config language that can be statically analyzed. Source: I'm a Googler
You all kick some ass. Thanks!
[json.RawMessage](https://golang.org/pkg/encoding/json/#RawMessage) might be of interest.
Benchmarks like these: https://github.com/yuin/gopher-lua/wiki/Benchmarks
Trying not to be negative here, but I can't imagine a situation where I would be happy with no UTF-8 support and limiting myself to plain ASCII data.
Interesting. I think your example uses of RefCtx might actually be anti-patterns. They do save you from needing another channel or WaitGroup though. I won't use this, and I think code using this would be harder to read. But I'm glad it exists to show some of the situations where the context.Context API isn't as obvious as it should be.
&gt; I think your example uses of RefCtx might actually be anti-patterns. I'm guessing you're referring to the second refctx example? The first one is just illustrative. Could you please elaborate on why you consider the second example an anti-pattern? We've found this pattern to be invaluable in managing connections/resources between distributed components. In effect it's a form of probabilistic coupling. 
I started using goland a month ago and I'm not looking back. 
To be very precise, you can't do conditional unmarshalling with your limitation. What you can do is parse the user list into `[]json.RawMessage`, and then loop through that, decode the actual `User` struct, and if Age is larger than 18 append it to a slice of users. The difference of this approach vs. using `[]User` is, that each user struct will be unmarshalled, but you would not allocate each onto a slice, but only the ones that fit your conditions. Why? The main reason is that `Age` is a field directly inside the `User` struct. That means that you have to decode the complete User struct to read the field value. Optionally, you could decode it into: type UserOnlyAge struct { Age int `json:"age"` } And thus check Age before deciding to unmarshal the complete `User` struct. In term of performance, I would expect that the penalty would be similar to parsing the complete struct twice. You could resort to [a third party json unmarshaller](https://github.com/mailru/easyjson) to test what works better for your case.
Here's mine for a project I am working on. It's super duper early though so /u/steffen25's is probably a bit more mature. ├── handlers │ └── handlers.go ├── LICENSE ├── main.go ├── models │ └── models.go ├── README.md └── router ├── router.go └── routes.go Eventually, I'm going to have to separate things further; either by another directory or separated by their URI. eg `routes` -&gt; `domain_routes.go` + `storage_routes.go` + `network_routes`.go In my example.
I suspect this was made available now at least partly because Alan is going to be giving a talk on it in a few days time in NYC at Gotham Go.
[Repository link for the lazy](https://github.com/gomatcha/matcha). I'm not the author of this framework so I cannot answer any detailed questions
I was just going to ask if you were open to pull request, I can 'dockerize' the app, just wanted to part take in the hacktoberfest :)
Sure 👍 Do I have to tag it first? 
I don't think so, I will just fork your project and send you the pull request this afternoon, were you thinking of adding any other features, or perhaps any open issues?
As tempting as that model is, it scales poorly because it basically doesn't have any ability to grow. If you're going to have a handlers/users/\*.go (for example) and a models/users/\*.go and a router/users/\*.go, you might as well have a "users" package that has the relevant routers, models, and handlers. (As for wanting to look in one place for router details, I believe that is better solved by routers having an ability to dump out their final state, not requiring users to declare all their routing in one physical location and forego all code-based mechanisms for building things. I acknowledge that there may not be any such router right now.) Note how there's actually nothing Go-specific in that criticism other than "*.go" being the file extension. I think this pattern is popular because it's really easy for a framework's initialization routine or someone's github-hosted boilerplate project to slap down an impressive number of subdirectories, but the problem is shared by any web site project that gets large. A criticism that _is_ Go-specific is that anytime you end up with packages with the same base name they become very difficult to use in one project, requiring constant qualification at import. You don't want three (or more) different "user" packages in your code. I used this pattern lo these many years ago on my personal blog in a Django project, and even _that_ stretched this model to the breaking point, if not beyond. And that was a tiny project compared to anything useful.
Facts you made up, sure.
Well I have some features in mind etc right now I’m using just one access token it would probably make more sense to add access + refresh token on a successful login Then I want to do something about validation either find a package or make my own that I can inject where needed. Then I was thinking about splitting my stuff into domains like ddd a users packages, posts etc, split routes, logging again either a package or my own, orm (gorm) But this is my first project in go so I wanted to minimize the usage of third party libraries right why reinvent the wheel when it’s already out there I think it is a great learning experience to see how long the std libs will take you. By the way I look forward to your PR 💪
&gt; I believe that is better solved by routers having an ability to dump out their final state, Not sure I understood but chi has doc generation ("Doc generation - docgen auto-generates routing documentation from your source to JSON or Markdown" )
Comparing apples and pears.
I've found VSCode has better Go support than Gogland, if you haven't tried that yet. I like Vim-Go for what it offers but nothing beats vsc for me yet. 
I think pears are faster. Working on benchmarks now...
You’re funny, but my point stands. You’re comparing what is basically a memory allocation with launching a kernel thread. Also, I think the channel communication is the bulk of the measured time, but I might be wrong.
I'm really looking forward to playing around with this
Wow, thank you very much for the insightful post. I think I went with this structure because, like you said, it is super easy to grok. I think this format will scale just fine for this project (for now) because it won't be anything made for production use (hopefully...) but I was wondering why larger projects didn't adopt the same structure. What you're saying though is that each "piece" (in this case domains, storage, networks, hosts) would all be their own package with their models, handlers, and router + routes included? And they'd all just get concatenated together at the end?
Great! I hope you're productive and happy with that.
Thank you! This is the best one I believe so far. Here's a list I've compiled so far of the various JOSE libraries: - https://github.com/lestrrat/go-jwx - https://github.com/knq/jwt - https://github.com/SermoDigital/jose - https://github.com/dgrijalva/jwt-go - https://github.com/square/go-jose (See branch "v2")
There was a chipmunk2d binding set released a couple weeks ago, I assume it isn't out of date but I don't actually know: https://github.com/jakecoffman/cp There was also a box2d binding released around the same time, but I don't know if it satisfies what you're looking for: https://github.com/ByteArena/box2d
thats not a chipmunk2d binding... thats a *port* Even better. Thanks.
Right, so is the box2d, sorry I wasn't thinking about terminology
No need to apologize. a *Port* is always better than a binding (usually)
Of course it is slower, he is spawning tons of threads in the C version. Goroutines are multiplexed on a limited number of threads , avoiding a lot of contex switching overhead. There is no dichotomy, they are different (and both useful) things. Apples vs oranges and very bad usage of C threads.
Yep, agreed, when you know something about how these things work it's not surprising which is faster. Everyone says goroutines are cheap. This begins to put some kind of number on that - they're 50x faster than doing the same thing with a thread (in this rather crazy scenario). Which means you can start a goroutine for a smaller workload than you'd choose to run a thread I didn't know what this number was going to be before I ran the benchmarks, and I didn't know how much of "goroutines are sweets, go at 'em" was hope and hype. And I've been writing threaded, distributed &amp; kernel space C &amp; Go code for 26 years. People told me green threads, m/n threads and plain old threads were cheap in the past too..., and a select loop with async code always beat the pants off them (and I suspect still will if you have the time &amp; the will to write it).
Seems like we need a 3-way apples, oranges &amp; pears experiment. I think oranges will roll better, and the dimpled surface may be more aerodynamic. Apples, oranges and pears solve many of the same problems (if I'm hungry, constipated or dying of scurvy). It doesn't seem unreasonable to compare some of their characteristics if we're trying to learn how they might help us.
Nope, 'cause i won't compare a wheel of an airplane with a wheel for a rail: they serve different purposes. They are both useful for travels, but still uncomparable.
Hi, also just uploaded my first attempt of a structured api using chi and a minimal feature set required in most api backends, like logging, postgresql database, request input validation and email. It supports jwt authentication with refresh token and a passwordless login flow which could easily be changed to password checks. Any feedback is highly appreciated, thanks. You can check it out here: https://github.com/dhax/go-base
My main issue with gogland is that it's not vim.
[removed]
After some small testing, I found out Skylark is not turing complete (can't do recursion for example) so it would not be possible to use it as scripting engine, which is sad, but its still nice as config lang.
The comparison illustrates that it’s generally a bad idea to spawn a lot of threads. Goroutines are multiplexed and have their own scheduler so what would be interesting is a comparison with Grand Central Dispatch or C++’s coroutines.
Well to me both of your examples show why it's actually a bad idea. If someone needs a wait group, then they should just use a wait group directly instead of importing your library and then using context.Context. Your use of it isn't abstracting over anything - you still need to increment and decrement, you still need to wait, etc. All you really added was the use a context.Context instead of making a signalling channel directly. context.Context objects should be used for signalling cancellation, not completion. So yeah, I think your library would make code harder to read by hiding some of what's really going on. But it's still valuable to see your take on it.
There's a plugin to emulate vim in the editing panes. Problem solved.
I use it regularly when in Idea, but I can't get the buffer switching keybindings to work the way I want to.
yeah i have been on the fence because i want to get really good at vim (instead of good enough to do daily config file edits, and basic nav / yank / paste / del commands), but i also love vscode. Im curious Is the vim extension considered good enough? (even with neovim?)
I highly recommend someone take him up on this ticket. dotGo is fantastic. 👍
The problem I've always had with VIM modes in other editors is how incomplete the emulation is. It's no fault of the other editors really, but for me, tends to be a deal breaker. I'd also say that other editors don't make me any more productive or offer very little (if anything) extra that helps my day to day work in Go that VIM doesn't provide. However, I'd wager most will be more productive in other editors and productive sooner. So the solved problem is by using the editor that works for you. I've met some VIM users who are happy with VIM modes. That's what works for them.
Congrats on the new release. I'll be updating sometime in the next day.
looks interesting, my only issue is with this &gt; Most (if not all) of the API functions **may cause a panic**, but only if things go REALLY wrong ideally, it wouldn't panic
to say that that's superficial, it would be an understatement if you wish to run similar(as in apples to apples) benchmarks, then you're supposed to implement a queue where you can add a function(simple_thread) and pass in a callback(or signaling mech); start the thread(at program startup), that checks the queue for "jobs", as soon as there's one available, exec the job, call the callback/signal completion; what you want to benchmark, is the time it takes since you've added the "job" to the queue, until the callback happens(i.e. you got a result), then compare with golang, you should get very similar results depending on the job, and other variables, sometimes you may get a slight advantage in go code, however, more often than not, the c code will score a few points higher than go at minimum
Here is one my team are working on in the open. https://github.com/feedhenry/mcp-standalone. I also wrote a blog post on http://idiomaticgo.com about how I structure server apps and why.
You can have a look at https://github.com/getfider/fider as well. I’m happy with current structure, it’s somehow similar to /u/debee1jp
Just check the upvotes.
"should" is the operative word here, imho I think it's so low on the priority list that it explains all the community efforts (gvt, glide, gb, etc.) and because of those there's no real drive to solve this. If to continue with the definition of the RFC lingo: there's a difference between "should" and "must".
It feels slow compared to vim, and has some weird behaviour that don't match my expectations. There are a bunch of open issues reporting those. Overall works well enough.
If you can please send me a message of why this is not working for you, I'll follow-up with a ticket to get this on the list of things to fix for the vim emulation for devs. I don't want to further comment in here as I respect Fatih's and all the contributors work and I'm excited to see this new release. Please try and do the same. Thank you.
[removed]
Where I come from, our Web development is separated into back end and front end. Our back end is comprised of Java and Go microservices and AWS Lambda functions (Node.js) that expose a REST API. Our front end are React Web apps and Android &amp; iOS mobile apps that consume our REST APIs. We chose to use Go for the following reasons: * It's new. * It's different. * It's gaining popularity. * We were curious about its performance. * We were curious about how it is as a day-to-day language for development. We don't see Go as a Web development language. It's just another programming language that we can write our back-end services in.
Easy deployment, fast start-up, static typing and good scaling properties make go a good match in a few cases. Funny thing is, C++ devs say "OK, go is a reasonable replacement for python/PHP/Ruby in webdev, but why use it in places where C++ is better?" ;)
So, why do you need a framework again? Go has a strong standard library. If you're importing packages, they usually solve a very focused issue which doesn't fit into stdlib (like UUID generation for example), or reasonably upgrade what exists in the stdlib (I think jmoiron/sqlx is a great example of this). One of the things to note as a comparison towards Node is that there's not a package marketplace. Code lives on github, and whatever package which you make might not get adopted due to various reasons from quality of code and so on. Certain package authors are thus more known than others and if you're looking for something as trivial as a configuration flags package, you're left with little but good quality choices. This just isn't possible with Node/NPM. Of course, Node has the focus split between front and back-end, so there's a lot of quirks code in Node that just doesn't exist in Go. Go is a completely server-side language, while Node tends to service a lot of front-end javascript code as well. To skip over what you mean by "can't even come close to 3-years-ago-Rails" (so much for holy war intents ;)): - smaller ecosystem - there are a lot of Go based projects which have terrific adoption, recently [go-chi/chi](https://github.com/go-chi/chi) with 2500 stars on GH and very positive reviews (like sqlx builds on the underlying net/http package), - higher entry level - I find that when it comes to frameworks that this just isn't true. Language specifics differ ([how slices work, for example](https://scene-si.org/2017/08/06/the-thing-about-slices/)), but you'd find those kind of issues when migrating from any language to any other language. Ruby [predicate methods](http://ruby-for-beginners.rubymonstas.org/objects/predicates.html) for a weird example. - good things are improved and tailored to their specific use cases. This is normal everywhere, from the top of my head I can name a few testing frameworks from Node like sencha, karma, ava,... Go is a young programming language, where this will be more common than for example PHP. But even there, you have a lot of choice, and a lot of frameworks there also rise and die, - weak integration - so, what do you expect here? Angular, React, NodeJS and other similar projects build a front-end HTML website, which interfaces with the backend with APIS like REST or websocket or other choices. As such, Go is responsible for one thing, and the front-end for another. You can of course provide your own interface with stdlib `html/template` and that's your choice. These things tend to have two separate responsibilities, and it's good to lay out your projects like that as well. Less integration is a good thing, because it also means that you can replace one thing without throwing the whole thing out of the window. Mainly the selling point for me is that the quality of the stdlib, language and library is very high. It enables scaling outside of 1 CPU core with very understandable goroutines unlike Promises or yields which take some time to wrap your head around them (edit: and they don't really provide concurrency, node is a single process app). Ruby, Node, PHP and other web-development centered languages usually are single threaded and going beyond that is an add-on instead of a first-class citizen of the language, if even possible. Their memory management is poor (albeit, for atleast PHP it improved greatly over the last 15 years), and perhaps most importantly, all of them seem to fall into the scripting languages category. Compiled code will always run faster than whatever you run via an interpreter. I hope this provides a bit more depth to your argument. People always reinvent the wheel, not just because they can, but also because they can improve it in some way. This can be done in small increments, like optimizing a specific function that generates a specific output, or it can be done in larger increments like creating a programming language that has concurrency as a first-order citizen. Other things might not be handled as well (which is why there's so much drama about generics in Go), but there's always space for improvement. I'm not excluding the possibility that somebody would just fork Go and provide generics the best way they see fit. People react to their experiences. If your experience is telling you that concurrency is a problem with some XY language, then you're going to find a way to solve it. Migrating to Go is a good way to do that :)
Because C++ is harder (to the uninitiated ;)). But fun fact, recent C++ versions really are *sick* in comparison to what the language was 15 years ago. I guess the only caveat would be memory management (garbage collection, etc.), which Go and Java both have, and there's not a direct solve in C++ afaik (because more low level).
For me, I only write web services in go because I'm already writing other services in go, and it makes it super simple to integrate them.
Thank you very much for detailed answer. To be honest I'm looking for a healthy alternative to Node.js. I've got a dozen of Node.js apps, written over last 5 years. And it's getting harder and harder to maintain JS-code, even written with ES6+ features like `async`/`await`. And it's still error-prone. So, that's the choice: to get back to Django/Rails (both still rock as hell) or give a chance to something new like Golang. Thank you again)
If you're doing front-end work, esp. with popular front-end frameworks like Angular/React/VueJs, you won't get rid of Node for those, but it's a relatively healthy balance, I think. I'm sending you a copy of [API Foundations in Go](https://leanpub.com/api-foundations) via DM, if you want/need to get started somewhere.
another *medium* article with a *medium* quality.
BTW consider reading [this classic dissection](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/) of this "async/await vs runtime-integrated concurrency" thing.
&gt; any other high-level webdev toolkit &gt; higher entry level That's one way to look at it. Personally, I've always found Rails, Django etc. hard to get my head around because they're so huge and there's so much "magic" going on under the hood. It all works very well until it doesn't. Or you want to do something in a different way to your framework's "blessed" methodology. With Go, any layers of abstraction you've got in there, you put there yourself. I find I have a much better understanding of my Go webapps than ones based on monolithic frameworks like Django. Hell, even with Flask, I'm not entirely clear on how all the "magic" works. Also, Go is *ridiculously* fast compared to any of the usual suspects. 
Because migrating from Java won't give you any performance benefits ( well, maybe save some RAM ), but migrating from Ruby/Node will
I did Rails back in the day. Here are some reasons I think folks migrated over. * Really easy to install on your dev machine. * Much faster. Channels make using your CPU cores a delight. * Really easy to learn and hack on. And, easy to grok other Go code. * Basic HTTP functions are built into language. Most folks just pull in a few helper packages. * Deployments are a breeze. * Static typing means silly mistakes are caught at compile. * Compiling is really fast enough that it is not much different than an interpreted language.
From my perspective, Go’s simplicity and robustness are what makes it stand out. It’s also very performant and the standard library is mature and has almost everything one needs when writing a web service/app. I was initially suspicious of Go having a GC because I had bad experiences with it in other languages but Go’s GC is really amazing and virtually never a problem (since Go 1.5 or so).
Those ram savings aren’t hypothetical! I’m finding Java is consistently 3x or so the memory cost for anything.
&gt; VSCode has better Go support than Gogland Care to expand on that?
Here is a go engineers version of why. He is Brad Fitzpatrick and he used to write a lot of pearl/ruby/Python/JavaScript. He even embedded some into go. https://youtu.be/xxDZuPEgbBU I personally love go because those frameworks were built inspite of those interpreted languages, not because of them. This guy really addresses why to use go https://kanishkdudeja.in/?p=108&amp;shareadraft=baba108_59cbbcb8b061b# 
For those like me who struggled to spot the difference: https://i.imgur.com/BaFPwPO.png 
Let's stretch metaphors some more: If you are building a new mode of transport which requires wheels, you *would* look at the different existing implementations and compare them, to see which best fit your use case (or how best to combine them).
Is the order of the items important? If yes, you'll have to loop through the outer slice of `[]Container` and match individual container paths to merge everything together. If the order isn't important, you can create a `map[string]Container` where you would use container.Path as the key, and append components to it when a key would exist. If you want to do this efficiently, you'll have to avoid reallocations. A way to do this would be to loop once over the containers to produce a map[string]int (key=container.path, value=count(containers with same path)). You can use `make(map[string]int, len(containers))` to produce one allocation, which allocates to your worst case scenario. Everything comes down to what you understand about `best`. If you want the fastest, then the best way to measure that would be to [create some benchmarks](https://scene-si.org/2017/06/06/benchmarking-go-programs/). edit: p.s. write a test in [go playground](https://play.golang.org) as it makes it easier for other people to improve it. I would gladly rewrite a functional example, but I don't want to write the whole thing.
FWIW, another reason that makes goroutines "cheap", is that they don't require allocating significant stack space, as go can grow/move its stack on-the-fly (because GC).