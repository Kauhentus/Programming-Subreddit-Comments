How? Type safety and hard schema is the greatest thing about it imho.
[removed]
It's not so much about calling a function, you're a developer, that's easy for you. It's selecting the right functions, understanding side effects and caveats of their usage and if you should call them at all. Key management is important, but every detail is. How do you know he data decrypted was in fact data the user encrypted? If an operation fails why? Did the user enter a wrong key or was it possible data tampering? Corruption? How do you handle key rotation in the event of a key compromise or security flaw in the app that requires responsible disclosure? How much ciphertext can fn(K) produce until it leaks entropy? Does it even leak entropy? Asymmetric or symmetric? Is the size always fixed or arbitrary. How likely is cipher text to be observed by bad actors? How many rounds do you need to perform in your key derivation function to protect against offline dictionary attacks? You shouldn't just use the same key for each file, so how do you integrate entropy from file details such as name, date or a special guid from a separate table without losing determinism or breaking other invariants you have already settled on? Do you want the user to have plausible deniability in the event of an invasive government investigation? What is legal in the country's your users operate in, does the lowest common denominator from a legal perspective diminish your security posture as a whole? If so what do you do? On and on I ask myself these questions, no one here can tell you the right approach without knowing every minor detail. Just food for thought. Have fun and think through things carefully!
[removed]
[removed]
[removed]
[removed]
Block post version of the talk https://backtrace.io/blog/building-a-go-debugger/
This might be guilding the lily, but i bet adding rpm/deb support would be pretty trivial. You could lift the spec templates from something like [fpm](https://github.com/jordansissel/fpm), or just use fpm directly. I'd be happy to knock something together and send a pr if you like (i've been needing to try out go in a project for a while).
Edit: gilding :-|
Cool project, but it'd be good if it recognised non-US spellings of `LICENSE` like github, and others, do. Especially for publishing back to github.
A colleague at work loves Rust (speed, efficiency, C-Go-ness). Right now I'm in full Scala learning (it's got a lot of things to learn to be most effective) but so far I really like the expressiveness of the language. I started programming with Lisp, so FP is kind of natural, and Scala is very, very well oriented for it without enforcing it (completely). The type system then is a blessing. Give it a try and let me know if you find something fun or weird!
:) Thanks for the kinds words, @kostix. I probably have errorred on the side of light hyperbole here rather than going Amish, but still I do believe this is a case of "revolution by evolution". To explain: To me it is the confluence of a number of "small" features (themselves available in isolation in other formats) that add up to a big deal: 1) the omitempty support (not previously available) means that large/complete schemas are viable without taking any space on the wire when 99% of fields go unused; 2) schema based on Go instead of separate schema language that must be maintained; 3) strong field numbering; 4) field deprecation support; 5) codegen for speed; 6) possibility of any language being able to do reads/writes with a minor ammount of work. Nowhere else can you get all these, for Go and all other languages, today. Moreover, particularly compared to Gobs (which is promoted as a Go centric serialization format but is not cross-language compatible and is quite slow), ZebraPack could and should be the next generation of serialization for Go, the "go to" choice when reaching for a serialization lib.
Go would do better with an arena. But the stdlib doesn't have one and they explicitly disallow custom arenas.
I can't responsibly answer that without a lot of unknowns being defined, but I can give you something to think about. I feel like: &gt; In the implementation i have, the only data i have is the raw bytes to store. This statement insinuates a paradigm similar to block level encryption, i.e. Linux block devices and LUKS. Since you have no meta data, indices, etc. However the next statement seems to be in contention with this: &gt; There will be millions of data entries all without any reproducible metadata to be encrypted with. If you have millions of **data entries**, you have millions of distinct records. If you have distinct records then you do not store raw bytes, you store encrypted but distinct records. They have meaning to you or the user in some way because they derive from a distinct transaction. They must be retrieved later, by filename, by location, or iterating the entire set. I'm sure you don't intend to walk the entire file system each time the user requests a file so you must have a index or some kind of way to look these files up. Even if you decrypt the entire file system and bring it into some data structures in memory, at some point they have to be represented as the distinct values originally given. Point is they must at least have a canonical location relative to some rooted point with an association to the user, how do you know after a user is authenticated that a group of files belongs to them? If they exist on the users local machine and you have a tool that runs there, I really think you will be doing your users more harm then good pursuing this. Lets say you take the time to get a correct implementation, don't forget you have to support it ongoing. You have to become a responsible member of the security community and watch for CVE's for your dependencies, ensure you have a mechanism to quickly notify users of vulnerabilities. You have so much responsibility to take ownership of to be acting in good faith, you need to keep a proper audit trail in case a user every attempts to enter litigation with you because a flaw in your implementation causes them damages. Maybe your product is free, on github, or just encrypts cat pictures, has a license that "Frees" you from liability, none of that matters when you receive a subpoena it must be dealt with through legal channels regardless of merit. If a vulnerability is found or a bug in your implementation in a future migration from old product versions loses all your customers data, that is your company / reputation on the line and the results could be disastrous for your future. I would really think about it carefully! If that is enough to make you reconsider, you can still provide encryption for your users through engagement and being a evangelist of vetted best practices for your end users given platforms. You could write tools or tutorials to help with the setup or configuration of those systems, which is a slipper slope but much less risk then a start-from-scratch. I wrote this a good while back for a buddy, but has some documentation on [LUKS](https://gist.github.com/cstockton/6be455f683e8011904d00b384ea82d90) encryption. If you are targeting Linux you can actually allocate a file and mount it as a block device so it may be used as a regular file system. Then that data can be sync'd to dropbox, or other external storage systems securely. It also supports multiple keys, so the user can have backup keys or share their files with approved individuals. It would be very easy to implement scripts for this, around line 150 I touch on this and have an example script in bash. If you have to support OSX/Windows, I would suggest good write ups on bitlocker and FileVault. Or might be able to support all 3 with the spiritual successor of TrueCrypt, VeraCrypt.. though I do not know the status of the project. I only use Linux, which means Luks and OpenPGP (GnuPG implementation). The TLDR; if it's just bytes of data, I would highly recommend block level encryption from a vetted implementation to relinquish the responsibilities imposed by implementing this yourself. If you choose to move forward in your implementation, there are too many unknowns here to even nudge you in the right direction. Don't let this be discouraging or take offense, it's written with good intent. I am sure if you put enough time and resources into this, you can properly implement it, just be careful and patient! Happy coding. 
Maybe it's because my experience with AWS is limited (having worked mostly with on premises solutions like OpenStack and OpenShift) but I'm having a hard time understanding how this scales non-horizontally. But I imagine on AWS other (commercial rather than technical) considerations are more important.
Start by reading [goquery](https://github.com/PuerkitoBio/goquery)
Just created an issue: https://github.com/goreleaser/releaser/issues/10
I work in web editing and I think it's not really their fault. Check out https://medium.com/content-uneditable/contenteditable-the-good-the-bad-and-the-ugly-261a38555e9c for some background. Tldr browsers provide a feature called contenteditable for making arbitrary HTML pages editable. However, it's the buggiest piece of crap you've ever seen. Web accessibility is hard as is, and contenteditable doesn't help much. Devs are left reimplementing editors from scratch (like Google docs), or heavily mutilating contenteditable to work. Sometimes, adding accessibility back in is very hard, due to browser limitations.
https://github.com/avelino/awesome-go#resources
It would be nice to see this one resolved https://github.com/golang/go/issues/10958 but I guess it's unlikely the fix will reach a non-experimental stage before 1.8.
If you've used Terraform where you have a lot of different providers, for example those could be all shipped as plugins.
It's sort of annoying, but some drivers use different placeholders than ?. I know at least one of the postgres drivers uses $1, $2, $3, etc. Perhaps this is the case here?
You can't use placeholders as column names in prepared statements. Placeholders are for values.
Hopefully not.
I have no clue what this issue is about o.O I guess I don't like low level stuff
&gt; I'm having a hard time understanding how this scales non-horizontally Just to be clear, I'll explain horizontal and non-horizontal scaling. Horizontal scaling is highly preferred, of course. SNS and SQS are built from the ground up by Amazon to scale to gigantic scale, so there's no issue there. You can run as many notification creators -- which I *always* use HTTP endpoints for -- across as many hosts as required. You can run as many queue workers across as many hosts as required as well. The only potential bottleneck is SNS/SQS which Amazon says will never be a bottleneck... Vertical scaling (non-horizontal) scales to as many cores and RAM as you can get on a single host. Go's HTTP server implementation scales across cores, and with channels it's trivial to build receiver processes that do the same. Hope that helps!
That explains a lot. What is the best way to have variable columns? `fmt.Sprintf`? There is no user generated input since it is a quick script of sorts.
Did you try to flush the writes?
I think you can type assert it to a io.Flusher, and call flush, same like you can on a http.ResponseWriter
I love the idea. I think we definitely need more tools for this kind of thing. Some things my current release scripts do that would be nice to consider: - Building in version number / sha / date as link-time string constants. This is really a must have for me. But I have seen like a hundred different schemes people use. Would be great to see a standardization. - Generating "release notes" from merged pr titles since last release (I usually generate a release as draft and then edit the generated notes). 
1.8 looks to be a great release and I am really looking forward to the package management work in 2017 now `go get drunk`! ;)
Build the query string dynamically which is usually not recommended for security reasons but if there is no user input, it is probably okay. Also, you could just SET all the possible columns even though only some will have changed.
&gt; Overall, Go 1.8 continues the work on getting back the compile speed lost in the 1.5 release and it’s now around 15% faster to compile than 1.7 but still slower than 1.4. How much slower than 1.4? I think Go 1.5 was the first release of Go that I used, and I'm looking forward to when it catches up so that I can see what all the people who were complaining about the "slow" compile times at the time were used to..
The garbage collector needs to make sure nobody can access the memory while it checks for memory to collect. To do this, it stops everything. However, to stop everything, there needs to be some kind of hook for the garbage collector to take control (basically the hook asks the runtime if it needs to pause). This used to only happen on method calls, so if you have a loop that doesn't call any functions, it could hold up the garbage collector, which means your whole program waits until that loop is done. This change adds more hooks, which should reduce the time the garbage collector has to wait for all goroutines to pause. Basically, it makes things faster.
Afaik it doubled with 1.5 and then doubled again with the new SSA frontend (or backend?). Would be nice to see a timed graph with version numbers at timestamps on the x-axis and the compile time on the y-axis. Any data out there to plot that?
Will the server gracefull shutdown on ctrl + c or do i have to code this in myself. Eitherway its a nice addition. 
It will be interesting to see if someone makes a nice hot code reload framework with this plugin interface
This is a good first app! Congrats. I'd recommend creating packages and following the MVC pattern directly or in a way you are comfortable. It will help you. I liked the way you have obly one handler, good work!
I don't believe this is true. 1.5 was slow as it was the first 100% Go release, and its improved in 1.6, 1.7, and soon 1.8. SSA lowered the compile time because it better optimized the now 100% Go compilation steps...
As far as I can tell, it's running external programs using `os/exec` (some of which are written in C). Even if that's not actually `cgo`, it doesn't seem all that different in spirit.
Both `io.Writer.Write` and `ioutil.ReadAll`return an error as the second return value. Always check returned error values, they help determining why a call fails.
Last I looked Minio still doesn't replicate, so it's still a toy. I'm rooting for them, but it's a red flag that they're building an object store and starting out with a SPOF architecture with plans to fix it somehow, someday.
Thanks, that helped
http://docs.minio.io/docs/distributed-minio-quickstart-guide
"Go Web Programming" book is awesome.
Sadly the new Plugin mode does not allow for unloading a plugin omve it's loaded. As such the functionality you have in mind will not be possible for now.
Mac OS X have been pulled out last minute due to a bug in that part. Windows plugins would also be nice to have but no word on that yet. 
So 1.8 is 45% slower than 1.4.3.
The value returned by ``StdinPipe()`` is an [``exec.closeOnce``](https://golang.org/src/os/exec/exec.go#L522) struct, which does not support ``Flush()``. I could try to gain access to the embedded ``os.File``, but that would still not give me a flush, only a ``Sync()``.
Thanks! I'll look into that next
Thanks for your input; it kind of confirms my thoughts that I simply cannot just use ``ReadAll()`` in this case, but have to handle reading from the stream myself. I got inspired by jPowerShell, a Java wrapper around PS, to handle the end-of-output by always including an ``...; echo random_marker_string`` to the command and then scanning for that string. [Edit: So I've changed my code to not close stdin and manually read a few bytes from stdout, like so func run(stdin io.WriteCloser, stdout io.ReadCloser, command string) (string, error) { fmt.Printf("&gt; %s\n", command) written, err := stdin.Write([]byte(command + "\r\n")) if err != nil { return "", err } buf := make([]byte, 128) read, err := stdout.Read(buf) fmt.Printf("read %d bytes from stdout.\n", read) if err != nil { return "", err } return string(buf), err } This works better, but it also clearly brings up a bunch of timing issues. Like waiting for 2 seconds after writing to stdin before reading from stdout works much better. There's a lot of work to do, but at least it seems possible after all :-)]
not sure whether powershell works exactly like bash, but here what one should do in that situation: use `pkg/term`. _e.g._: https://github.com/driusan/gosh/blob/master/main.go#L226
Here is how I have been using it: https://play.golang.org/p/_Q3q5-fidF It doesn't compile in the playground, but I've tested it with 1.8 beta. When I hit "ctl+c" it prints "server stopped" and the time.
 invalid operation: Server.Shutdown &lt; 3 (mismatched types func() and int)
tl;dr: Make sure to not fall into the all too common, "I heard AES256 is the best; I just found that lib/function and call it. Hey now I'm super duper secure secure and no one can ever attack this!" fallacy. [epiris mentions many things to consider](https://www.reddit.com/r/golang/comments/5l01jk/encrypting_files_if_you_know_nothing_about/dbsorhq/) but there are even more basic things like which ["mode" to use with a block cipher](https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation) (e.g. ECB, CBC, CFB, OFB, etc). For example ECB should never be used unless you have very specific requirements and fully understand the implications; there is a history of products that naively used ECB opening up many attack vectors (e.g. you mention your data has records; if either the record size or block size is an integer multiple of the other an attacker can trivially and undetectably manipulate your data by reordering the data blocks). Did you make sure to use some kind of authentication with your encryption? If not do you know what that implies? If so did you use an HMAC? Correctly? Or did use a [cipher with built in authentication](https://en.wikipedia.org/wiki/Authenticated_encryption)? You mentioned "*some type of key file on disk*", is this a raw key (e.g. from /dev/random with the correct size), a password, a pass-phrase, a random file such as an image? If it's anything other than a raw key how are you converting it into a key (e.g. [PBKDF](https://en.wikipedia.org/wiki/PBKDF#Alternatives_to_PBKDF2)). Are you aware of the issues of storing such sensitive information "on disk"? Are you aware how your operating system stores such files and that it's unlikely there is any way to securely wipe/delete it?
just for fun, I've created `plugs` to ease the pain of building and loading plugins. this doesn't completely solve the `go get` -ability of plugins, though. https://github.com/sbinet/plugs
If this is your first project, don't waste energy on "optimizing" your package structure. There is no optimum layout. Do whatever allows you to progress to your goal quickly, and when you have something useful, revisit the structure. edit: some things to look at, if you're really curious: - https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#.sfxuencdz - https://github.com/thockin/go-build-template - https://peter.bourgon.org/go-best-practices-2016/#repository-structure
[removed]
right. but right now you can still write pure go code and execute them via os/exec. Later I will try to make this easier so that it can feels like just writing another go function, with the recent plugin package.
What he said + the suggestion of "for now, just put it all in the same package." Try not to use any private fields or functions outside of their general domain. Use interfaces if you have a good grasp on them - but don't feel averse to just use your structs (it took me a bit to realize how powerful and useful interfaces are in go). My approach has been "break it out when breaking it out will prove useful." When I do split packages, I put generic types at the root level. This would put user, thread and post structs+interfaces at /project. Then `{user,thread,post}_handler` in /project/http, and `{user,thread,post}_client` in /project/sql
[removed]
Cool! Thanks everyone :)
Appreciated! Are there any good Go libraries to control selenium from start to finish? Eg, it appears there's some sort of selenium web server *(i'm not too familiar with it)*, does this have a way of starting that server? Stopping it? etcetc.
Any replication is better than no replication. And it's not spof as you claimed. 
I claimed they started out by being SPOF and left clustering for later, which is true.
If all you want is source code: - [Blink](https://github.com/lelandbatey/blink) is the package I wrote to blink the keyboard lights - [Watchserver](https://github.com/lelandbatey/watchserver) contains the client and server, with the server notifying the client whenever a file changes Pull requests for both projects are very welcome, and feel free to ask questions here or on the Github pages.
Yeah not offering separate installers seems strange. http://www.theregister.co.uk/2016/12/16/oracle_targets_java_users_non_compliance/
Does this differ at all from something like Serf?
That is a very cool project, I will take a look at it
This is awesome! I just turned this into a Caddy plugin, but I don't have Linux (or a "regular" keyboard) to test it. Somebody want to help me out? 😊 https://github.com/mholt/caddy-blink The Caddy integration drops the requirement for a plaintext TCP server and log file, as it is just a websocket endpoint built directly into the web server.
I *think* Serf uses the SWIM protocol same as this project (someone please correct me if I am wrong)
You are sending all of the token requests with the default user agent. You need to add a custom transport to a client to set a user agent. Otherwise your users will be rate limited as most services do to default user agents.
Nice job, but could we get a screenshot?
does this give you a way to quickly check why certain actions fail? say u want to click on an element, but it throws an error and you wanna know if the element does not exist, is hidden by another element, etc. i've looked at other selenium implementations and it always seemed like it could be done better. also, do u capture the whole error including stack trace, etc? i guess i haven't really looked at the source code yet, but does it have its own error struct? finally, how does it deal with cases where u need to click on something and wait for content to load before doing something else?
Not really a web back-end project but my first reall program in Go was a UFW (firewall) log reader that reads a ufw.log file and displays the amount of block port scans. Not really complicated but I learned a lot about the language just by building something I thought was interesting. The advice I give you is to just start building something that interest you. You can start really simple like I did an expand it into a complex program. For example I'm looking for a way now to hook my program into the ufw logging system to parse the data more easily and save it in a database.
Two ways to approach the issue. I'd like to point out that the way dgryski suggests( the later is the examples below) incurs overhead through copying while the former uses the value directly. I will probably get banned for constructive criticism of such a naive comment by dgryski, just like I have in the past.... package main import "fmt" func main() { sum(1, 2, 3, 4, 6) } func sum(input ...int) int { sum := 0 for i := range input { sum += input[i] } fmt.Println("sum was ", sum) return sum } package main import "fmt" func main() { sum(1, 2, 3, 4, 6) } func sum(input ...int) int { sum := 0 for _, i := range input { sum += i } fmt.Println("sum was ", sum) return sum }
Not sure if you saw this already but I just made this post yesterday to help with the language, DB, DB drivers, and the server. Also, it's online so when you go for your interview its environment is already setup. Which actually is a login. Let me know if you need help. https://www.reddit.com/r/golang/comments/5lcnhb/found_an_amazingly_beginner_resource_for/
added a pair screenshots
**Desktop** automation. Synthetic mouse/keyboard events, screenshots.
Here is the error handling example I was talking about: https://github.com/bunsenapp/go-selenium/blob/master/examples/error-handling/main.go
Go + GUI is a topic that pops up regularly - with (from what I've seen) the conventional wisdom being that none of the options are yet ready for prime time. I doubt I'd be the only one interested in hearing your take on building a program with the gtk2 bindings.
&gt; Just use []T for slices. When is it more appropriate to return []*T?
will have to take a closer look at this, but at first glance this looks like very good work. i'm using selenium as crawler in one of my current projects so i'll consider swapping this in. great timing! thanks :)
cgo :(
I used it temporarily for an object pool (to avoid excessive GC) but quickly changed to a linked list + free object stack implementation. Edit: another related use I can think of is maintaining small struct size with an array of pointers. Or you might want a list of objects you wish to mutate. Obviously these are all specialized use cases.
No, an array is NOT a collection of pointers. It is a bunch of objects in memory. A slice is a pointer to an array, a length, and a capacity.
I can't find any source that supports your statement. Could it be that you're confusing slices, which contain a pointer to the underlying array?
In the case of MergeSort, since we are not doing any long I/O (like reading from a socket) and we are pretty much just CPU-bound, having n-goroutines &gt; cpu cores won't help at all, will just create unnecessary contention for CPU time between all those goroutines. Instead of using 100 concurrent workers, using the number of CPU cores may work just as well or better.
Isn't sync.Pool for this purpose?
There are different use cases based on the pros/cons, and they're nearly exactly the same as non-slice versions (i.e. `T` vs. `*T`). `[]T`: * Pro: Contiguous in memory with respect to T (the runtime will allocate `sizeof(T) * cap`), which increases cache locality. For example, a loop over `[]int` can be very efficient and potentially even be vectorized. * Con: To access a slice element, it has to be copied, which is more expensive than passing a pointer around. Similarly, modifying an element requires copying the element, modifying it and then copying it back. `[]*T`: * Pro: No copying needed in order to read/write elements. * Con: Requires an indirection to dereference the stored pointer, which can point anywhere in RAM and will be unlikely to take advantage of cache locality. Cache locality also includes [RAM prefetching](http://www.futurechips.org/chip-design-for-all/prefetching.html); modern CPU architectures are complicated, but sequential access is generally faster than random access. --- I would recommend using `[]T` unless you have a specific reason to want to minimize copying. For example, let's say we have this: type Document struct { // Lots of fields here, making Document large } func ClassifyDocuments(docs []Document) map[string][]Document Imagine we want to "classify" the documents based on some heuristic, like divide them into topics like "business", "sports", and so on. There's one input slice, and a map of topics to output slices. Some documents may be in multiple topics, though; and by using `[]Document`, we're potentially duplicating each document multiple times, which is wasteful. So we should probably do this instead: func ClassifyDocuments(docs []*Document) map[string][]*Document This allows the result to simply point to the same documents as the input. Except for the allocating the `map` and slices in the result, it's possible that this function doesn't need to allocate anything at all on the heap. 
Relevant discussion in `go-github` library, started by Russ Cox: https://github.com/google/go-github/issues/180
just read #go-nuts. or some of the issues on github. There is plenty to choose from. *And what is with your tone, dial it down a bit- don't be a bigot (look, I rhyme, some of the time) **And I'd like you to stop banning my accounts when you don't agree with what I'm stating. You have removed over 100 comments of mine, and that is just mine. I am sure the over all number of comments removed from this subreddit is astronomical. *** I will find the video for you where brad fitzpatrick stated his dislike for go get, and a few others on the stage agreed with him.
[removed]
basically it gives you control of your browsers and the JS runtime. not sure what you mean by cancel requests.
[removed]
i think selenium gives you control after page is loaded, so you wouldn't be able to filter what resource you wanna load to your DOM. these types of tests are better suited using phantomJS, although they'r much more specific. i'm sure there's still a way you can hack your way to do that though. where there's a will theres a way ;)
Also note that you can take a pointer to a slice element which avoids the copying and lets you call pointer methods on the type, while still maintaining that lovely chunk of continuous memory. Example: https://play.golang.org/p/pz0JVHj2dQ The small downside is that (at least the last time I checked) in cases where the slice could otherwise be allocated on the stack, taking pointers to elements will cause Go to allocate it on the heap.
Good point, and also in a loop to avoid copying via a `range`: for i := range things { thing := &amp;things[i] } 
This comment was caught by Reddit's spam filter. I've just approved it. 
&gt;*And what is with your tone, dial it down a bit- don't be a bigot (look, I rhyme, some of the time) I politely asked for some examples to back-up a statement you made. &gt;**And I'd like you to stop banning my accounts when you don't agree with what I'm stating. You have removed over 100 comments of mine, and that is just mine. I am sure the over all number of comments removed from this subreddit is astronomical. The new moderation team (starting in December) has certainly not removed 100 of your comments. The accounts we are banning are mostly spam bots. &gt;*** I will find the video for you where brad fitzpatrick stated his dislike for go get, and a few others on the stage agreed with him. That would also be a good example. As would specific issues on GitHub.
[removed]
Wicked!
in your go file, I think line 8 should just be 'continue', a return would stop the function and not continue the loop where your js implementation goes to the next iteration.
Why didn't you use systemd's syntax. You don't have to support all the features, but sticking to the basic syntax seems like a better idea than a non-standard syntax which is very similar.
What do you mean by "you need to be explicit about what type of work can cross the network barrier"? Every actor is distributable, as long as its messages are generated by the protocol buffer compiler. What issues do you see with regards to horizontal scaling?
the overhead for integers alone is nearly double.
[removed]
https://play.golang.org/p/4XnUNAw7G0 share your results.
The answer for the map has been the same as the previous times this has been asked. With multiple writers, or with a writer and readers, you need to synchronise access to the map. That is, mutating the map itself. The elements of that map are a separate story. If you want concurrent access to a particular element of the map, then it would have its own synchronisation. I imagine you would acquire the map lock to get the element, then drop the lock and acquire the element lock to start mutating it. 
It is common problem. If a value has "alway" to be positive or zero, then replace "someInt ==" 0 by "someInt &lt;= 0". You will manage also integer overflow (if you don't use unsigned)
Like it, straightforward and easy, without having to bother with encodings etc.
interesting! but... it doesn't seem to me like you are handling zombies (and more importantly, zombies' reaping). do you? for my little docker-initd daemon (when running systemd wasn't really possible), I had to handle this. see: https://github.com/hepsw/cubie/blob/master/cubied/main.go#L209
you probably have a data race on `startedTypes`: https://github.com/driusan/dainit/blob/master/service.go#L53 which is populated (and read) by many goroutines concurrently.
Thanks. I will probably end up with a RWMutex in the map then and more locks on the elements. That way multiple elements should be able to. Be written to/accessed.
Maybe you can leave the per element lock, but it depends on your implementation. 
Compatibility with systemd init files would be a nice feature and are probably one of the few good things about sysd.
What I don't understand is: Why was there any prolonged impact at all? I would've assumed that the server panics, restarts and then the leap-second is over. Or it panics for every request for one second, the panics are recovered from and then the leap-second is over. Why was the impact longer than one second? (this probably should be a comment on the blog article. But it requires registration…)
My guess is that the panic killed a single goroutine / request, but meanwhile a shared data structure had been updated which proceeded to kill more.
I'm still confused as to why they didn't just use an unsigned integer in the first place. `In our case, some code assumed that the difference between two times would always be, at worst, zero.`
My employer allowed me to open source our PowerShell wrapper, so here you go: https://github.com/gorillalabs/go-powershell -- It's still under active development, but it already demonstrates the basic workflow (similar to jPowerShell and what /u/ChristophBerger explained)
I like the readme - it's well written. Quite possibly the most important part of the project IMHO. I'm curious about your choice of lambdas. Was the only reason you used them to get fresh IP addresses? Could you instead just allocate IP addresses dynamically to the ec2 instance?
ever played with a similar idea: https://play.golang.org/p/e6Pie4vh-l The concurrent version is about 2.2x faster on a 4-core cpu. 
Yes. It even has an FAQ! Too bad connections will drop every 5 minutes.
Run anywhere? You mean compile anywhere, right?
You can run the Javascript asynchronously and abort it and used the built in 'callback' function that Selenium provides to return your argument. Unfortunately, I'm not too sure it can let that occurr multiple times - so you may be better off sticking with PhantomJS for this. 
Do you have an example Gist/Playground at all? I'm just getting into Go and I would really appreciate it. 
I switched from Linux to DragonflyBSD a few months ago because systemd made me hate Linux so much and all I really need is a OS that supports Go and has a decent web browser, since that's most of what I do in my free time. I came back to Linux yesterday because every termios package I could find for Go only supports Linux, Mac, and FreeBSD making it impossible to fix some fairly major bugs in the shell that I'm trying to write. Writing my own init system was a compromise I made with myself to go back to Linux. (After posting this, I tried to replace udevd with a script that just calls modprobe for my specific hardware for about an hour and got my wifi working, only to discover that without udevd Xorg doesn't find my keyboard(!)). That is to say: I don't like systemd. Other people can like it and use it, but I don't. I'm not opposed to accepting patches that improve compatibility, but I'm not going to go out of my way to do it myself. As far as the weird config syntax goes: it's actually a result of my experimenting with literate programming. If you squint hard enough and note that unknown lines are just ignored, you'll notice that it's actually just markdown. (I thought of naming the config files .md to get syntax highlighting in GitHub, but that seemed too cheesy.) I wanted to try "literate configuration" where you can write prose explaining why and what config files are doing inside of the config itself. (It's quite possibly a bad idea, but I thought I'd give it a shot, because why not?)
http://norvig.com/ngrams/enable1.txt
Nevermind, I just realized I'm an idiot. Daemons can die after being forked. You're right, I need to manually handle SIGCHLD.
agreed -- you probably shouldn't swallow panics if you have shared mutable structures. let it crash.
i'm confused -- i thought leap-second smear was meant to prevent exactly this problem, by just making each second slightly longer of some period of hours?
how in the world did I miss Go fonts: https://blog.golang.org/go-fonts
As far as I know, the shiny library is written entirely by the Go "core team members" right now (though I'm sure they'd accept contributions. Nigel Tao is one of the friendliest Go core team developers I've interacted with.) Last I checked, the higher level widgets which is what most people who are trying to do GUI programming want aren't there yet, unfortunately. If you want to do something like `de`, you'd need to familiarize yourself with the Go image, font, and draw packages (as well as some of the x/mobile event packages) to use the lower level drivers directly. (The higher level stuff might have improved since I last checked, but I don't use it because I've already done the work with the lower level drivers and wouldn't get much benefit anyways.)
I've always been using `*T` as the default for my methods, I thought it was the opposite. Use `*T` unless you need to use `T`.
all I initially heard was a *woosh* but double checking, no, I didn't even notice.
Interesting looking project, do you have any intention of adding in (Free|Dragonfly)BSD support or are you only interested in maintaining Linux support?
You also need to take into account NTP where all the servers were not syncing their time at exactly midnight so you get this negative time propagation consistently untill all servers have resynced. 
Beginner here too, it was fun to search for an idiomatic way to generate the combinations : https://play.golang.org/p/EGfxQBDWOe Original code and author : http://stackoverflow.com/questions/19249588/go-programming-generating-combinations
Ah gotchya. So most systems would just repeat the second?
I will point out that we are comparing apples to oranges. I am benchmarking the difference between a copy and direct access of an array while you are benchmarking the difference between copy and direct access of a slice. I believe the use of intermixing slices and arrays has skewed our results. I find the results of this benchmark puzzling: https://play.golang.org/p/B0jjGvLnCN BenchmarkDirect64Array-2 10000000 166 ns/op BenchmarkCopy64Array-2 5000000 273 ns/op BenchmarkDirect64Slice-2 10000000 165 ns/op BenchmarkCopy64Slice-2 10000000 206 ns/op BenchmarkDirect32Slice-2 20000000 88.8 ns/op BenchmarkCopy32Slice-2 20000000 105 ns/op BenchmarkDirect32Array-2 20000000 89.0 ns/op BenchmarkCopy32Array-2 10000000 151 ns/op I will modify your benchmark with large arrays and slice to look for similar anomalies. *I will also add that we might be benchmarking with different releases. these benchmarks are using 1.7.1 
I wrote this gist over nap time [syncmap](https://gist.github.com/lateefj/dfff4399996928c4e18c78f5f7a98f19). I ran the test and race detector (go test -race) however have had time to write a large goroutine test or benchmark. Baby is up so good luck. YMMV
&gt; There are no clocks that are any good for actual benchmarks (process/thread time). Maybe that's the problem then. What happened to the old trick of counting ticks in the CPU and dividing by the clock frequency?
It seems that trie.go uses a null character stored in a constant named nul to indicate the end of a word. just append nul to the end of your rune array to get the desired result
If you're talking about [runtime.Gosched()](https://golang.org/pkg/runtime/#Gosched) for tight loops, then yes, that's what I understand.
Just out of curiosity, why did you decide to write your own generator instead of using an existing one, like [Hugo](https://www.gohugo.io)?
Build once per platform run proper build on each platform... not quite as catchy.
Completely alternatively, consider writing a goroutine that functions as a server, and accepts and handles requests in some domain-specific meaningful API, owning all the data and allowing you to use no locks at all. "Share memory by communicating, don't communicate by sharing memory." It's possible you'll need the structure you're describing, but in idiomatic Go, that's a last resort, not the first thing you reach for. Write too much code like that and you'll be right back into locking hell.
Just go to https://tour.golang.org/welcome/1 and have fun. If I were you I wouldn't be too worried about it then just be able to read code. Just like if someone asks me to build them an app for commercial release, I would tell them to get an designer if they don't have one already; You can't replace a programmer who had years of experience. I am sure you already know, there is too much work (and loneliness) for one person anyway. Anyway, Python is like a language taught to engineers, so I guess that is why they would suggest it. 
&gt; FWIW you can directly request a monotonic time using system calls: Sure. Except that `clock_gettime(CLOCK_MONOTONIC)` varies between operating systems. Not sure who, but at least one system screwed it up and instead of returning frequency adjusted seconds, they return unadjusted seconds which might not even be close to SI seconds. Another system screwed up and theirs could actually go backwards when their NTP daemon (or equivalent) adjusts the frequency of the clock. &gt; So I think it's sufficient to say that getting a cross-platform, consistently behaving monotonic clock won't happen for a long time. Well. If the standard library can't do it, no one can. That's where abstracting away all the operating system stupidity should be done. Go didn't even make an effort. Wall clock time for benchmarks that run for a second or five? Half of the results in the usual "1.x is faster than 1.(x-1)" benchmarks are probably more due to weather or number of open Chrome tabs on the benchmark machine rather than the code improvements. &gt; Out of curiosity, can you point to a time library in some programming language that handles Gregorian time before year zero 'well'? No. Haven't researched it too much. I just ran into those curiosities when I was helping someone on Stackoverflow who wrote bad code and ran into things like that. I've mostly been on the OS clock side of time code. The way I'd handle it is to error out for anything before a safe point in time (arguments can be made for 1972 - start of UTC or 1927 - last country to switch to Gregorian time) and tell the programmer that if you're dealing with specialized dates like that, you'd better know what you're doing and that mean you know better than the standard library programmers.
Jumping straight into Go's standard package library was really helpful when I started learning Go since Go is itself written in Go. Any time you write any Go code, you should check out the source for the functions or methods you are using themselves :)
I'm calling your title misleading.
I've done some migration from node/waterline to go/gorm. Gorm has nice association patterns and is very entity driven. It was a little buggy early on but seems to be steady lately. Been mostly happy with it. It is richer than the alternatives.
I did try "embracing" Go for this but fell back to a Mutex quite quickly I found in my testing!
With docker 1.13 coming out this month you can specify `docker run --init` to use an init system inside the container. By default we're using https://github.com/krallin/tini but you can specify your own via an `--init-path` daemon flag. You can try it out by installing rc4: check out Downloads section in https://github.com/docker/docker/releases/tag/v1.13.0-rc4 
BS. Go is being heavily used outside of google. It's used for some of the most popular open source projects around by non-googlers; look at docker, etcd, and a lot more as well. 
Go checks value equality. For strings, it is safe to use ==.
Yup
yes you will have problems since each request is handled on a different go routine and each routine is using the same struct to store user information. It may show up with https://blog.golang.org/race-detector
There is a gulf between Go and any of the top languages, still. I have seen more jobs posted for Perl, R, and Visual Basic, than Go. I've seen languages *really* take off, but Go has yet to actually do that. If you want to learn something *now* that will help you get a job *soon* then you should be doing something more common.
Sorry for that. I will remove it from README
This is wildly off-base and incorrect. A significant number of technology companies, with needs for scalable, high-performance systems, are using Go. A few major ones, besides Google: Uber (which I can personally vouch for - I work there and we're using Go across the org), Dropbox, Twitter. Here's a more complete list of companies which are using it: https://github.com/golang/go/wiki/GoUsers 
Great idea! Just one minor nitpick: The `New...` method names are quite verbose: govaluate.NewEvaluableExpression govaluate.NewEvaluableExpressionFromToken govaluate.NewEvaluableExpressionWithFunction How about, for example, govaluate.New govaluate.NewFromToken govaluate.NewWithFunction which would be more concise yet including all required information (since all `New...` functions instantiate an `EvaluableExpression` anyway).
Finally some information. I've personally seen lists like that before, and they're often unhelpful and misleading. The first link I clicked on there happened to be dead lol. Thanks for the effort, but I know from looking for jobs that getting a Go job is a lot harder than you think it is.
Go and Python are both important languages (I know them both). In fact, I'm porting a personal project from Python to Go right now. First, Python has been around a lot longer. You're going to find many, many more resources on the web about Python. It is very commonly taught as a first programming language. It also addresses more market segments than Golang. While Python and Go are both used in server-side programming, Python is also used significantly in scientific computing, embedding in other environments, old-fashioned local GUI applications, and generic scripting. With Python, you're going to find a package to do whatever you want. Any question you can think of is going to be answered on Stack Overflow. This is not true of Go. It simply is a newer language. As a developer, you simply have to know Python. Even if you don't use it for the main programming task, it is too useful a tool to wrangle test data or backups, or reports, or anything else you do. There's a lot in development that isn't actually development, but putting together the infrastructure to automate the testing and delivery of the things you develop, and Python is the language of that. That said, I just finished my first professional Go project, and it is literally like a DSL (domain specific language) for the kind of stuff you do as a server-side developer. Go has two things going for it that Python doesn't. First, it is statically typed, which means that a good IDE can tell you as you type mistakes whether you misspelled a variable. Second, Go was designed with concurrency in mind. It has very strong multithreading capability. I'd recommend learning Python, because it is so useful to know in general, then I'd recommend looking around at other language/frameworks. Databases: start with SQLite, since it comes built into Python, then play with PostgreSQL, then play with Redis. Oh, and learn Python 3.
This appears to be a simple file uploader, unlike Hugo, which has a more features along with more complexity
we're hiring at Datadog https://www.datadoghq.com/careers/detail/?gh_jid=87091
Fantastic reply, thank you. And what if it can be argued that the app that we've begun writing in the ad tech space was written in Nojde.js/MongoDB: it already requires a rewrite due to the discoveries we made while figuring out the algorithms. We found out that the process is insanely recursive, and requires a ton of writes/reads to a database. Any additional concurrency advantage we could gain next, will be useful to rewrite the services. Hence it's why the majority of devs say: this ad tech app is really needing some GoLang. Although I understand that Python may be easier for me to learn, I feel like I'll be going backwards for the purpose of this app's rewrite? Or can it be argued that I should be realistic about this, and I won't fully be able to rewrite a complex series of algorithms myself with 0 experience either way, so I should take this opportunity to teach myself the basics in the most flexible environment for learning (Python)?
Thank you! So do you advise GoLang over Python? And can you give me a quick reason why Postgres may be a better option over Mongo? Cheers!
Thank you. Would you argue that it's worth getting the degree for the paper? Or the learnings/practices from it? What if I'm mainly most likely looking to use his new skill for personal projects rather than a full time career? Would you still argue against Go?
Author here; thanks! I know they're long. In the beginning I had thought I might be making other sorts of expressions too, but that never ended up needing to happen - thus the specific use of `EvaluableExpression` in the factory names. And enough people/companies are using it now (and cloning from master when they do) that I'm extremely reluctant to make API breaks, especially for something that doesn't change behavior.
That's actually a bad idea. Some of the projects are far from idiomatic code and will damage your learning experience. Start with the standard library, there's plenty of code there. And if you want more, choose any HashiCorp project and read it. 
Which raises the question: "Why write a file uploader when you can use rsync --delete?" Seems like re-inventing the wheel.
As far as I can see Swift version allocates all the data at once.
I understand what's happening here. First, let's clarify which "copy" we're talking about. When using `for i, v := range a {` the corresponding slice or array element is assigned to `v`. If these are large struct elements, this continued copying can lead to some overhead. This is the "copying" I was referring to that should be virtually 0 for an array or slice of integers: copying the element is a single memory-&gt;register move. However, with arrays there is another tricky copy that happens when using range, and this is the source of the discrepancies in the benchmarks. I've created a sample program here: https://play.golang.org/p/4b181zkB1O If you run it, you'll see that `IndexValueArray` doesn't print out 100 -- it prints out the original value `4`. This is where the extra copy is coming from and why your benchmarks are slower. The relevant line from the specification (under "For Statements") is: `The range expression is evaluated once before beginning the loop`. For arrays, to "evaluate" the expression mean copying it, because arrays are values. ("copying" a slice just means copying the small slice header, similar for "copying" a map.) The way to get around this expensive copy is instead to range over a pointer to the array, which is `IndexValueArrayPtr`, which we can see does print the updated value. (Also, the benchmarks you provided were dealing with arrays, but the original question was talking about slices.) 
The problem I tried to solve wasn't just the file-upload, but setting the correct headers for all files as well as invalidating the correct URLs on Cloudfront afterwards. Otherwise, I would definitely agree, writing a tool which simply uploads files wouldn't have added much value.
Because I had never done it and it seemed like an interesting problem to solve, but I was aware that there are already great alternatives out there (like Hugo). Just like with the tool described in the blog post, the motivation for my site generator wasn't to create something groundbreaking, new or disrupting in any way, but instead to create a simple tool tailored to my needs and to learn how to do that using Go in the process.
Nice article. I am a total newbie when it comes to AWS but it is something that I'd like to try eventually. What turns me off is that their payment system seems awfully complex. I am currently using Digital Ocean which have a very simple system. Could you give some insight on the pricing for what you are using for this project?
Happy to see Rob Pike's idea catching on and used in production.
&gt; This is quickly hard to read, there is too much noise on that test. I believe those tests are very readable especially when compared with the final result in this blog. &gt; We setup a whole Node struct, but the only thing we really intend to test is the Platform.OS part. The rest is just required fields for the function to correctly compile and run. Yeah okay I can see how that makes things more verbose than desirable but then why not just test the part you want to test? In Go, variables declared without an explicit initial value are given their zero value. There should normally be no problem if you initialize just the Platform.OS part that you intend to test. If the rest of the fields are still needed by the function then why not break up your function into smaller chunks and test those instead?
Thanks! Frankly, I'm a total newbie when it comes to AWS as well. I'm currently in the "free tier" for the first 12 months, so I basically don't pay much of anything. I agree, that the pricing is a lot more complex than with DigitalOcean, but at the same time it's a lot more fine-grained. There are also monthly calculators like this https://calculator.s3.amazonaws.com/index.html where you can punch in your expected requests / traffic and see how much it would cost. I didn't put much effort into the pricing models for my blog for now, because it's a static website with a very low footprint, so the costs should be pretty low regardless of where it's hosted.
non at all like most of the go community because the [stdlib](https://golang.org/pkg/net/http/) is all you need
What's wrong with the standard log package or defer/recover?
Have you built a non trivial web app using stdlib only? Can you point us to it?
I'm enjoying http://goji.io/ it's enough help on top of the standard library for me. I do not want to handle routing on my own and I like the API goji provides for middleware. I like gorilla toolkit. It's a pretty minimal approach and that's what I like about it the most. I did not outgrow this solution yet and I feel good about that :)
While stdlib is enough, I think it's wise to use [Gin](https://gin-gonic.github.io/gin/) or [gorilla/mux](https://github.com/gorilla/mux) since they make it easier to define and group routes, have middlewares and handle panic recovery.
I'd rather not have my reddit account be associated with the company I'm working for but yes I have. Some are public facing most are running in our intranet. Strictly speaking most of the apps aren't stdlib only (some actually are tho) but that's not the point I tryed to make. If you're using gorilla/mux you can pretty much go back to the net/http mux without needing to change that much. Go libs tend to extend the stdlib functionallity but they aren't 'game changing' frameworks like django/rails etc. It's more like golangs third party libs are 'tools' that you can tie into your app and still use the stdlib for most of the stuff edit: if you want to look at a non trivial web app using a lot of the stdlib look at [mattermost](https://github.com/mattermost/platform)
&gt; because the stdlib is all you **need** doesn't mean you **have** to only use the stdlib but it's possible. OP isn't a experienced go dev so it's best to start off using 'pure' go to get to know its paradigms etc. It's easy going from plain go to using third party libs but if you're using an elaborate tool chain from day one (not that you'd be able to because you don't even know what tools you'd need and what tools you'd actually benefit from) you might start to wonder why you need to name a function ServeHTTP on struct X in order to get everything working. I really don't know what you're problem is with my statement. What's you're favorite go framework then? 
Yes, mattermost is almost always the answer that I get when I ask this question, but: 1. Have you seen their [sql migration file](https://github.com/mattermost/platform/blob/8406e854aa912f3d7f9179b10356444f07e25223/store/sql_upgrade.go)? 2. Did you know they use [gorp](https://github.com/mattermost/platform/tree/8406e854aa912f3d7f9179b10356444f07e25223/vendor/github.com/go-gorp/gorp)? That is not stdlib only, is it?
having to do thing[i] to mutate []T is significant and annoying syntactic friction. it pushes you toward using []*T even when what you really want, for locality, is []T. i wonder if adding something like this would be a good addition to the language var things []T var i int var x *T for i, x = range things { // since x is *T, it takes on the value &amp;things[i] } not sure how you'd do the inline variable declaration version. maybe like this? for i, *x := range things { // *x means x gets the values &amp;things[i] } or maybe for i, x := range &amp;things { // &amp;things means x gets the values &amp;things[i] } ? (there's no ambiguity because you can't currently iterate over *[]T) 
&gt; The only way would be an official solution from the Go team, and that wouldn't happen until Google has a use case for it. Then what would be a solution to this problem? I don't even think there is a problem. Go doesn't try to provide a solution for this problem because it's not gos business. Go plays nicely along in an microservice environment or when a problem needs to be solved in a scaleable way. Go doesn't try to be ruby/rails or python/django and that's fine. statically typed languages don't provide that much of an advantage when you want to build a big fancy web framework + orm. 
The web is my job and has been for years, and I know accessibility is hard, and often ignored because "it's an internal tool" or "we don't have time" or "it's not high-traffic enough to warrant the cost" or whatever other BS excuses we come up with to justify it. But providing an alternative plain-text editor that supports simple markup (not wysiwyg, obviously) isn't a tough thing to do. If we can make tools for blind users to write code, we can easily make a simple Markdown-enabled text editor as a fallback for those who can't (or don't want to) use a WYSIWYG editor. Generally speaking, if it's too hard to add accessibility back into something custom, use the standard HTML option instead of replacing it in the first place. Not meaning to bite *your* head off per se, I just get tired of the excuses the industry uses to justify making life tougher for the sake of flashiness.
You can start here: [Writing Web Applications](https://golang.org/doc/articles/wiki/)
I think the standard library plus https://github.com/julienschmidt/httprouter is enough.
At this point I'd go for an httprouter fork that uses Context and standard handler signatures.
Depending on what I was trying to do, I'd use either parts of [Gorilla](https://github.com/gorilla), [Negroni](https://github.com/urfave/negroni) (due to the third party middlewares) or [Revel](https://revel.github.io/) in case I needed a more complete web framework
Looks nice! Have you done any kind of bench marks against similar libs, like https://github.com/spf13/cobra?
Terrible choice.
I didn't since I didn't think about the performance as a crucial factor in this library. The basic usage which doesn't even involve parsing options and arguments would have minimal impact on the performance of the program and would occur only once at the program startup (I assume that many people will prefer to parse the options on their own using the standard library anyway and the option parsing implemented by Guinea is only a thin wrapper around the standard library anyway) .
Pretty much the same reasons why I wrote this tutorial, http://github.com/thewhitetulip/web-dev-golang-anti-textbook/, wanted to have a new comer friendly guide to teach how to write webapps in Go without using a framework, spent the better part of the last year writing this app, https://github.com/thewhitetulip/Tasks/.
This doesn't seem to be a go language issue. This is a best practice when using transactional databases. Yes, you should use database transactions at the proper place so that your database does not become inconsistent. It might be at the request level, it might be at another level. 
Yes, you are correct. But I'm hoping to discover how people handle this in Go. After reading [Ben Johnson's Standard Package Layout](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#.rugppc1ml), I wonder how people do database transactions in this or in other common Go server models.
I think /u/bkeroak meant don't put them in the same category. I've only ever used Mux, so I'm not in a position to make a comparison. However, Gin always seemed too restricting, just like any framework. Whereas Mux isn't really a framework at all, just provides a nice wrapper for creating routes.
https://github.com/pressly/chi uses context to pass url paramaters and allows standard handler signatures. I recently switched from httprouter to chi's router just to try it. I had to edit a few routes that used parameters in the urls, but it wasn't too bad. It also wasn't a huge/fancy project.
I haven't used it myself but I've seen lots of hype around [SQLBoiler](https://github.com/vattle/sqlboiler). Also sqlx is a fine choice. Personally I use plain SQL with `database/sql`.
Pressly/chi has context support.
Can you elaborate? I'm just curious why is it a terrible choice?
Transactions do not have much to do with project layout. You just use transactions in your database code: * http://go-database-sql.org/modifying.html * https://github.com/golang/go/wiki/SQLInterface
I've used SQLBoiler on a few different projects and it works well. It uses code generation which after a lot of experimenting and using other DB libs I believe is a good approach. Works well in combination with [goose](https://bitbucket.org/liamstask/goose/) which I use for migrating the database itself. edit: fix link
i was thinking by analogy to variable declarations: var x *T ==&gt; *x Though I guess that's really more a C-ism than Go. I think my favorite so far is for i, x := range &amp;things It's easy to see the &amp; as being projected through each of the elements of the slice, which is why x ends up being a pointer. Yeah, Go is very conservative so I'd be surprised if we ever saw this, too. But I do think it's a real wart in the language. Not even sure myself if it's worth the extra syntax or not.
Did you ever consider using Gin (uses a modified version of httprouter + some useful goodies) ? 
I don't consider Gin to be monolithic. It doesn't come with tooling, orm, and other extras the way revel and Beego do it. I consider gin a lightweight framework that gives you routing, handling, and a very simple middleware concept. Also, I wasn't aware gin was receiving heavy criticism from the community. I see it recommended often, and I personally use it. 
I wouldn't say it's "all encompassing". Beego is more all encompassing than Gin. Gin doesn't include an ORM, for example.
It seems pretty clear from the responses in this thread that there is no one clear winner. I guess the answer is to take a look at several and use what fits your brain the best.
I think the point is that for a new Go user the built in stdlib method is a bit overwhelming (mentally) compared to a nice all-in-one framework that they're likely used to. Plus, just saying use stdlib doesn't show them where all the pieces are nor how to tie them all together. (restating from grandparent.) 3+ years gives you a bit of an edge over a newbie and certainly enough time to have become adept at no framework plus gorilla/mux.
I'd like to say thank you for writing the book and sharing it with the community. You are greatly appreciated.
to be fair, the original question was about the misunderstand of the semantics of the for loop. We both just took a different approach to answering the question, which lead to the discussion about the performance hits of different solutions. I too after reading a bit came to the same answer as you. just another odd quirk of the language that I now better understand. however, modifying the benchmarks still show the same odd behavior just less pronounced.
&gt; I agree that a good functional example that implements templates, logins, CSRF, and demonstrates DB connection handling is sorely needed. I'm actually working on this right now as a way to teach myself. I'll post to github (and /r/golang) when finished and allow the community to peer review it and let me know how bad I failed and what needs to be fixed (kidding about the last part, I hope). Unfortunately, I am new to Go so it's a slow process as I try to learn the safe/secure/correct way to do it.
It's sad that you see war where people just answer what they use and what works for them. You answered the same when i asked what do you use to handle form. But look at the question, we ask "what do you use", not "what should i use". 
Thank you, I will look into it.
So it goes through a python and C shim. Forgive my ignorance, but would using C# be faster (less overhead) then, since its already compiled to a binary? 
https://godoc.org/?q=router -&gt; will show the imports there and gorilla/mux is first https://godoc.org/?q=http -&gt; will show gin but if you look at the number of imports is still lower than gorilla/mux
Also, the title is wildly misleading as there are no changes in 1.8 that would render any previous "frameworks" incompatible and the context stuff is a 1.7 change.
I think both Heroku and CloudFlare are using it. I really like that it uses the new http context. 
Agreed. [database/sql](https://golang.org/pkg/database/sql/) and [sqlx](https://github.com/jmoiron/sqlx) is all you really need.
Can you create a runnable playground version for us to look at? We're missing some context with the code given (Node, the inputs, etc)
That's great to know. Thanks for the tip :) Curious where they get stars from?
I heard about buffalo on the Go Time Podcast a while back, looks promising if you're looking for a more complete solution but still want to use existing and battle proven packages. http://gobuffalo.io/docs/getting-started 
Thanks for the response. I've also been researching ways to fix this and came to the same conclusion that there is no off the shelf solution at the moment. If you do find anything, please let me know!
Those are taken from the Github API but they are not a useful metric imho since people can use stars to bookmark projects or because of the HackerNews effect
Usage question: in practice are significant delays in connecting with an RDS?
What you apparently didn't understand is that it was a question, and a chance for you to tell the world what the differences are.
If the link is too long to read and you're worried about Raspberry Pi 1, don't be worried any longer! They will still support armv6k. If you write Go for early model Kindles, this might affect you.
Do any of the more monolith frameworks depend on gorilla/mux, or can this be inferred to be explicit standalone uses?
Didn't someone on go-dev offer to run a builder to help maintain the support for older ARM chips? (In fact, the end of the thread you linked to even implies the support is staying..)
Main differences: * Native and parallel printing to stdout and stderr with fmt.Print* * Native and parallel logging with log.Print* * Panic recovery with stack trace * Native context functions call (GetRemainingTimeInMillis) * Official like and dynamic handler signature thanks to Go 1.8 plugins (smoother migration to future potential support from AWS) * Official like errors when invoking Lambda
Okay Thanks. Just to be more specific, as i'd like to go use golang for AWS lambdas as well. I didn't mean using C# over using golang for the lambda code. I simply meant using C# over python for the binding middle-man. As you avoid the python startup and runtime overheads.
The indirection is less than ideal; agreed. There is more cognitive overhead in the final result. It may _read_ better, but to understand it, you have to _know_ more.
Thanks for sharing!
You're welcome ;) Don't hesitate to give us feedback, and if you need any help https://gitter.im/eawsy/bavardage 
Shameless plug, but I wrote the code for a start-up all in Go microservices. I had one in Gin, one in Echo, one in Iris, one in standard library. I eventually came to the conclusion that each had their merits, and each had their annoying points. The standard library in Go is so powerful, it took me all of 4 hours to come up with my own mini-framework building on the parts I likes from those frameworks: https://github.com/EwanValentine/stack-api 
storing a username or uid in a cookie for authentication is a bad idea, as it's completely guessable, so anyone can log in under any user, unless the cookie is properly encrypted. using a proper session setup is to be advised here, e.g. with [gorilla/sessions](https://github.com/gorilla/sessions) or [alexedwards/scs](https://github.com/alexedwards/scs). I used the latter before and my authentication middleware looks like this: func RequireAuthenticated(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { uid, err := session.GetInt(r, "UID") if err != nil || uid == 0 { http.Redirect(w, r, "/login", http.StatusFound) return } next.ServeHTTP(w, r.WithContext(newContextWithUser(r.Context(), uid))) }) } func newContextWithUser(ctx context.Context, uid int) context.Context { u := model.UserByID(uid) // this is where user data is loaded from database return context.WithValue(ctx, userKey, &amp;u) } now, in the controllers I can just use the context from the current request: u := r.Context().Value(userKey).(*model.User)
So I wrote TJ Holowaychuk (Express/Koa) an hour ago and asked his opinion on this question. He's a developer who certainly qualifies his remarks. This was his response: &gt; I think if you spend some time with net/http in stdlib you'll find it's actually really similar to Koa already. For example line 1749 in https://golang.org/src/net/http/server.go is a middleware similar to Koa's mount(), and semantically it's really similar to async/await. &gt; As far as routers go I usually use https://github.com/julienschmidt/httprouter or Gorilla, or Pat, lots of decent options out there for routing.
For those interested to see how it looks, I wrote a simple stdin demo synth example: https://github.com/go-audio/generator/blob/master/examples/realtime/main.go And here is an offline example of the same generator + codecs: https://github.com/go-audio/generator/blob/master/examples/offline/main.go The place where the audio buffer interface will live is still TBD but you can follow that conversation there: https://github.com/golang/go/issues/17244
For what it's worth, I appreciate you giving this reply a second shot, and can hardly blame you for how you originally reacted. Pay no mind to the haters. I've played around with *xlab/go-lambda* and I'm actively using *eawsy/aws-lambda-go* on a project I'm building atm. The work you and *lsuss* are doing is far more enjoyable to use. Keep up the great work.
Oh man! That's fucking beautiful! Thanks!!
How many times do you normally parse your command-line arguments, for benchmarks to be interesting?
It wil affect the Atmels AT91 line like the AT91SAM9G25. And of course it will affect product that are build on these microprosessors like the AriaG25.
Someone offers hardware to keep support for ARMv5. But I don't read that this support is accepted.
 {{ if .LoggedIn }} {{ template "sidebar_auth.html" }} {{ else }} {{ template "sidebar.html" }} {{ end }} And send dat `LoggedIn` on template execute?
Before Django we was working without any framework, just the Python Stdlib and now i still use my mini-framework. Thanks to that i could jump in the Go wagon with ease. In fact, with a router inside, Go stdlib is a framework ! Look at Pyramid (in python), i believe it's very near what we have in the stdlib. I mean that even in language where we have big framework there is a demand for mini-framework.
I create one transaction by request that i pass to each handlers. If the handler panic or return an error i rollback if not i commit. When you speak about email, it's good to do the same when you send email in an handler. I mean to just put the mail in a request queue and really send it only if the handler was going to the end without error.
&gt; the ORM (gorp) is a poor choice since it doesn't support migrations, it uses goji1 instead of goji2, needs an example API added, etc. cheers, will check it out! 
It's faster, simpler, has a syntax much closer to C and a bigger ecosystem. Go already has first class functions, so I don't really miss anything from the FP world. As for BEAM, its tradeoffs do not benefit web dev as much as it does its original domain (telecoms).
We tried to build an API with elixir in my job, we had already APIs with go. My team is not expert in Elixir, but we know many things. After two days, we gave up of elixir. Our opinion: Go: * Faster (Performance) * Medium (Productivity) * Safe * Easy to write code Elixir: * Slow (Performance) * Not so Fast (Productivity) - Maybe could be faster, if we know even more... =/ * Safe - Could be more safe than Go * Very hard to write code - there are so many ways to write!!!
Ares you saying that in Go, you can at runtime stuff an entirely new attribute into a struct, because the go structs are implemented as dicts ? That the compiler cannot optimize field access, because go structs have a bajilion of ways to fake it, that might come into play, and are not possible to be known unless the precise point in runtime ? Silly surface similarities aside, the two languages are nothing alike.
So I love Elixir and I think Phoenix will replace Rails and when that happens the world will be better for it. However, I use Go for pretty much everything at this point and if someone were to ask me which they should learn I would say Go every time (and likely I will say Go for pretty much ever). Allow me to elaborate: **Go is simpler and works much like our brains do (imperative programming)** I really enjoyed my foray into functional programming and it made me a lot better developer overall however I find that largely it's impractical in day to day use when I'm trying to "just get the job done" an imperative solution is faster. **Go makes you learn it all** Elixir / Phoenix like to hide complexity, they do so in the most elegant way I've seen (i.e. less magic and you can extend their model very easily) but at the end of the day it can be hard to know exactly what's going on. You might think that's a great thing for a beginner but Phoenix (and Ecto) has lacking documentation and if you want to do anything outside of the lines it becomes extremely difficult, so here if the goal is for a beginner to get something working the easiest Rails still takes the cake and if the goal of the beginner is to learn Go will make you understand everything. (be this good or bad depending on your own views) **Go is more hackable** This spawns more from the previous point but since I'm doing everything anyway it makes it really easy for me to plug in libraries or extra code wherever I want so that I can change the behavior any way I see fit, which matters a lot for non-trivial development. **Go is better at everything other than web development** This may not be particularly useful for your question but it is a point that I use in Go's favor when someone asks me what language to learn. Elixir for writing CLI's is frankly not fun (IMO). Not to mention the fact that you have to have the BEAM installed on the targets machine, I write a lot of small command line utilities and just compiling a binary and dumping it wherever I need it is the bomb and something that I found very frustrating with elixir. There's also a lot of work to get Go working for mobile and desktop applications which is HUGE and is something that Elixir cannot do today and doesn't appear to be on the road map. **You don't need npm** This is a small point because almost all of my Go web projects use Ember or React on the frontend so end up requiring npm anyway but I do think it's weird that a full MVC framework like Phoenix requires npm. I think this point is largely irrelevant but I'm sure some people care.
Downvoted. It's 5 steps to get started. 1. install 2. download dataset 3. run 4. load dataset 5. query There's nothing awesome about it. If you need clickbaits to get people to your product, you've already lost. Edit: downvoting me won't help the product either
"Asynchronous code in Go" is very rarely needed. Look around in https://golang.org/pkg/ and you'll see such a thing is not that common. Instead, let the caller be in control of concurrency, and create simple APIs, that are also easy to test.
the message passing is pretty safe and intuitive. Go has borrowed the concept of channels from Erlang
(teeny bit off topic, but I found the link to 10m only yesterday) Comparison of Go vs Elixir - Definitely not Apples to Apples. Go was pushed to make **10million clients on 32-core / 208GB** source: http://goroutines.com/10m Phoenix was portrayed to **2 million clients on 40core / 128 GB** (but there were significant improvements made within few months of releasing this post) source: http://www.phoenixframework.org/blog/the-road-to-2-million-websocket-connections 
I really enjoyed that, the code is very readable and as the author points out, it takes some of the mystery out of writing interpreters/compilers.
Thanks! Glad to hear that :)
Makes you wonder how much python they must have that it was easier to write a new python runtime in go than just convert the python to go
Nice introduction to interpreters, bytecode, and simple bytecode optimization. One question: why is the instruction set a slice of pointers instead of just locating the fixed-size instructions directly in the underlying array? Wouldn't really matter for anything but very long programs, but still better practice to avoid pointers in this case.
wonder how easy it would be to use grumpy as a library in other go programs
I'd like to know that as well. Perhaps this could be a start? https://godoc.org/github.com/google/grumpy/runtime#Code.Eval
That looks like it should work. I'll try it, thank you.
Good eye, I'll fix it. Thanks [EDIT] Done
Reminds me of facebook and the hhvm/hack
But that's exactly what it does. It converts the Python to Go, and then compiles the Go.
So, the reason was that Python 2 is bad at concurrency. But how does a transpiler help solving this issue? I don't think you can simply "translate" normal Python code to code that runs concurrently automagically ... whatever that means. All that is a way too big question mark for me to get excited about this project just yet.
Too expensive sadly 
&gt; So, the reason was that Python 2 is bad at concurrency. But how does a transpiler help solving this issue? I'm not sure how familiar you are with Python, but any application that has multiple threads will still be bound to a mutex called the Global Interpreter Lock (GIL) for any CPU related tasks. In other words, only one thread can make heavy use of the CPU at any given time despite other potential gains from threading. In general, the default CPython platform is going to be inherently slower at interpreting the code at runtime. I imagine you'd also get a lot of the benefits from a Golang build that you'd get with something like PyPy by performing static analysis and generating a binary ahead of time. 
[removed]
&gt; you'd prefer experience over anything else I agree. This gets more important the more programmers you have involved on the project, regardless of whether it is a web app.
Well since this just transpiles the python code to Go and themp compiles it there is no runtime GC. It's all just Go at that point with the standard go runtime/GC. As for parllelism. They took the existing threading module and adapted to just run each thread in a go routine. Stdlib theading module: https://github.com/google/grumpy/blob/4e1a5b2bcb785464e35f6051a715f0f631b5d857/lib/threading.py StartThread: https://github.com/google/grumpy/blob/4e1a5b2bcb785464e35f6051a715f0f631b5d857/runtime/core.go#L667 So python programs don't know that they are no longer on a kernel thread, but just running in a go routine.
Google...
Yes.
Ugh, why did it have to be legacy Python? (I know why, just venting) I hope they keep this project going and bring it up to date with CPython!
&gt; there is no runtime GC. It's all just Go at that point with the standard go runtime/GC. I wouldn't really expect there to be a gc running on top of the go gc..
I would never store sensitive data (like email, uid and username) in cookies, unless its properly encrypted. JWT by default is not encrypted, only signed. What I also don't like about JWT is that authentication is implicit, as in, how are you going to revoke access from a user? short answer: you cannot, long answer: u'll need to refresh access-tokens often, have working expiration, etc. my advice: don't over-complicate things when there is no need, you're not building a complex enterprise system are you? ;) imho context.Value for small apps is nice for these type of things. just like the author of that blog-post said: "*Obvious request scoped data could be who is making the request (user ID)...*"
The 20% increase in CPU was a relative increase. The absolute increase was only 2%, from 10% to 12%.
I understand that. The other was saying there's no runtime GC because go has it's own GC??? All I was saying from the beginning is that it's using go's GC rather than reference counting so that'll help with parallelism.
I was merely confirming that you suspected correctly.
Sorry i mean no python GC. It's not an python interpreter in Python. It's a transpiler. The runtime features are straight from Go. Sorry for the confusing sentence. 
Except that Chi has 0 external dependencies, Echo has way too many: * github.com/GeertJohan/go.rice * github.com/dgrijalva/jwt-go * github.com/gorilla/websocket * github.com/labstack/gommon * github.com/mattn/go-isatty * github.com/tylerb/graceful * github.com/valyala/fasttemplate * golang.org/x/crypto * golang.org/x/net (chi uses Go 1.7 built in "context" package rather than through x/net) * google.golang.org/appengine * gopkg.in/mgo.v2 Not that there is anything wrong with most of these dependencies, but I prefer to manage my own dependencies rather than a framework pulling in 11 of them... so I use Chi too. For example, I am never going to run on Google app engine, so why should a web framework bring in these dependencies (and I think go-isatty is also needed for app engine), also I can't see myself using go.rice either so why should a framework bring in so much stuff I don't care about.
In what ways does Chi improve your life over using the standard library?
Not sure if it improves much on the stdlib, but I have modularised my app so that different modules or parts of my system "e.g. admin, auth" have a method called NewRouter() which sets up routes for that module and returns a *chi.Router. In my main router I then "mount" these into the main router. I am sure you can do something like this with the stdlib yourself, but Chi gives me this out of the box which is nice. Also I believe Chi's router to be faster than the stdlib one since it's based on a 0-allocation radix-trie algorithm. Other than that, I make use of the middleware stack in Chi only, though I do not use any of their middleware and provide my own instead (which are based on Chi's middleware which were originally based on Goji's middleware). The main reason for this is that I don't like how many frameworks have default middleware which use globals everywhere, e.g. a global logger. In my project I have an Application{} struct which stores the application config and logger instance for example, so I would prefer my middleware to use this too for consistency.
If a program's "primary purpose" is human readable output, isn't that closer to a pretty printer? [coffeescript](http://coffeescript.org/), though less prominent nowadays, produces decent looking javascript.
Isn't that kind of awesome though? Imagine a future where you can write any language and change at any point. Maybe you are running into limitations of one language so you translate to another without any repercussions? Or as you said translating libraries. Write libraries that work for any language. A bit far fetched but cool to think about.
That's not the point of having different programming languages though...
wow thanks a lot, i forgot to read strings.Compare doc and just focus on == operator
The following [code](https://play.golang.org/p/0etXPnCaye) executes, but this is not how I want to implement DES. * The **key** variable throws an error when it is larger than 8 bytes. I would like to be able to specify a **key** in the following format: "0xbc, 0xbc, 0xbc, 0xbc, 0xbc, 0xbc, 0xbc, 0xbc" * The **iv** variable throws an error because **iv** length must equal block size. I would like to be able to specify **iv** in the same format as the key: "0xbc, 0xbc, 0xbc, 0xbc, 0xbc, 0xbc, 0xbc, 0xbc" 
There's two reasons: 1. A byte slice because the .Read and .Write methods I'm passing it to only accept byte slices, not single bytes. 2. A byte slice on *Machine, so I can reuse it and don't have to allocate a new slice every time this function is called. Does that make sense?
I've gotten a significant speedup in the past changing away from a slice of pointers to a slice of struts purely by removing cache misses from the inner loop.
I see. The second is what you want to do for a rewrite such as converting the Go compiler from C to Go. https://talks.golang.org/2014/c2go.slide
For me it's because I don't come from a Ruby background but a Python background. Elixir might be attractive to someone that has just come from Ruby, but not so much for me as a Python developer, it doesn't really do it for me. Then the last thing is Elixir still requires the Erlang runtime, with Go I can just drop a binary on a server and that is it.
I would say check out Chi as well, I switched to Chi from Gin as well, but to be honest I don't think Gin is "lagging behind" so much really, in the last few months Gin has actually been moving ahead a lot again. Gin is just importing from golang.org/x/net/context rather than from context in order to still support older versions of Go before 1.7. However in Go 1.7 this will actually import from context anyway. 
https://en.wikipedia.org/wiki/Data_Encryption_Standard
&gt; If a program's "primary purpose" is human readable output, isn't that closer to a pretty printer? No. Anything I'd call a "pretty printer" has the same input and output language. gofmt is a pretty printer. The C-&gt;go transpiler used when migrating gc and the runtime to go isn't, it's a transpiler.
anyone else remember the leap smear?
nothing special.. just easier way to do that :) maybe someone will found it helpful .. enjoy
There are some coupons and group discounts around, I'm asking for a special Reddit one. Consider the price covers coffee breaks and lunch for two days, ☕ 🍴🍛
Thanks for your reply, that's a good set of features to have. I actually had no time or ideas to implement such things, so your package seems superior. My question was though more about principle of work, i.e. how plugins are helping there, so &gt; smoother migration to future potential support from AWS looks like another cool feature, cudos. Keep it up! 
I love elixir and attempted to use it for a rather large project recently, however I found a few issues that were blockers for me: - The ecosystem still lacks officially supported packages from various online services - The language and core packages are going through quite a bit of flux with a fast release cycle. - Raw performance isn't terrible but it isn't as fast as I would like for a lot of what we do. This might be changing now, however the solution that is ready now is Go. If Elixir had a few more years I might very well be using it instead of Go, because I really do like elixir but for now I just wasn't productive enough. I like functional programming but u don't think I'm at that point yet.
The CPU increase was from 10% to 12%. This is an absolute CPU increase of 2%. But *relative* to the original CPU usage of 10% it was a 20% increase. 10% + 2% = 12%. 10% * 1.20 = 12% Consider the case where the CPU usage doubled from 10% to 20%. It would be an absolute increase of 10%, but a relative increase of 100%.
The first point is fine, I didn't know that Go IO methods don't accept single byte. For the second one though, I doubt that stack-allocating single byte in a function is such an overhead that it deserves it's own special treatment...
Yeah, that's probably over-the-top, but I thought it was cleaner :)
Gerrit and jumping through hoops with providing real information about yourself like address and real name stopped me from contributing and that will not change. Why would Google need to know where I live? I had a nice fix for PGP standard library implementation not letting you specify key bitsize but didn't submit it because of those unnecessary obstacles. Other projects somehow let you contribute without providing private information about yourself and yet Google still does that.
I looked into nearly all frameworks and I had a hard time choosing the right one that would do something that httprouter can't do and that would be useful for me.
I think it is kind of 20MB page with 2KB text awesome or those famous Javascript editors taking 400MB ram to process 2MB text file awesome. People find all this amazing but I am just not so sure.
Thanks for the appreciation :-) I have recorded video tutorials on the same material, about to finish it, would that be of any interest to you? I'm going to post it on YouTube
I am getting closer. I figured out that I was suppose to specify the key and iv in the following format/syntax []byte{0xBC, 0xBC, 0xBC, 0xBC, 0xBC, 0xBC, 0xBC, 0xBC}. Even though the [code](https://play.golang.org/p/g86TgoUf6P) runs, it is not encrypting or decrypting correctly. Any tips/suggestions/clues?
Doesn't using `-o` work to send it to an output file?
Will also be an interesting optimization target. At the moment I don't have much use for this, but in the future it would be interesting to write a tool that consumes the verbose compiler output and verifies assertions about the optimization in your code, such as "did you violate what the ROC optimization needs?" The idea here is that when optimizing you can end up caring about that a lot, but it's ___really___ easy for that sort of work to regress without you realizing it. (Of course, you normally shouldn't care, and should wait for this to be a problem before doing anything. But those times arrive.) You could do something now for heap allocation and inlinedness, but I'm not sure it's worth that for now.
&gt; comment inside of a line wow .. you mean, you can select a portion of a line and comment on that ? Practically, it does not have much advantage over commenting on a line IMO, because in most case, you get the context. Only the flexible automerging policies is a straight winner over github. Other things can be lived with. Thanks for the reply anyways.
So ... it used 20% more CPU. That's how percentages work.
Derp, thanks. For some reason, I thought that only applied to the other commands since it stated that by default it want to STDOUT.
Usage of Go plugins is an evolution in our strategy to provide "official" like support. We began long time ago with a Nodejs C++ addons but it was too cumbersome to call native context functions like GetRemainingTimeInMillis. After what we've created https://github.com/eawsy/aws-lambda-go, in which we've fully supported all native aspects of a full featured shim. But one thing remained. In the past, end users were impacted by the fact that we use a C bridge (compilation, system compatibility, etc). With Go plugins, we have a huge improvement. The shim is now prebuilt and is only injected in the end user Zip package. The Docker usage is also ephemeral as in the near future when [golang/go#17150](https://github.com/golang/go/issues/17150) will be resolved, one won't need to use Docker anymore. So we are touching the absolute "official" likeliness more and more :) We hope as soon as all stars are aligned, AWS Lambda team will support Go officially and in the meantime we are committed to propose shims in a way that enables smooth and seamless migration. This project is a shim, as such it is not here to live after an official support ;) 
I would start with a [simple example](https://play.golang.org/p/2epUZ0oMiB) and [expand](https://play.golang.org/p/z-CLICXkdZ) from there.
A better approach is to make your JWTs expire after however long you want your session timeout to be, and re-issue them transparently with each HTTP page request. Then you don't need a session table or column in the users table.
I think Chi could use better documentation that clearly explains the difference between 'Use', 'With', 'Group', 'Route' and 'Mount' and explains the use cases for each. I read what was there and thought "This is confusing and I don't have time for this"...
I think the Go team uses the ability to review commit messages pretty frequently, in order to ensure a consistent/clean history too.
Ha, my `-m` comment was meant for a different thread :) No wonder it didn't make sense to you!
For me, the biggest problem with GitHub is that a rebase on a branch will do weird things to its pull request. Comments on commits based on the old parent but that are still relevant get lost or outdated or something; it's hard to know what you have already reviewed, and what's pending; and whatnot. This and other issues (e. g. you can easily get the same commit in two different pull requests) come from choosing _branches_ as the thing you review and merge, rather than just _commits_, as Gerrit does. On Gerrit, to handle feedback, you just make a new commit _replacing_ the old one, and link the two of them by a Gerrit-assigned _revision ID_, and then you can see diffs between those commits (and subsequent), comments in their right and immutable context, etc. This is much cleaner than the GitHub approach IMHO.
Only if you are in GC 100% of the time... you are not
You can write a type switch as `if x, ok := v.(Type); ok`. Switches are theoretical more efficient but in practice they break inlining, so you need to do a benchmark to know for sure which is faster. Just do whichever reads better 99% of the time. 
Generally, it is recommended to avoid the use of `else` (https://golang.org/doc/effective_go.html#if). First turn to control statements such as `return`, `break`, `continue`, etc. If "else" still makes more sense, prefer switch/case for readability (https://golang.org/doc/effective_go.html#switch). Also, avoid deep nesting of conditionals (https://because.complexity.example).
Juju recently moved to github reviews (from an external reviewboard instance). I don't mind it at all and find huge benefits to having the code and reviews in the same place. Allowing PRs from github is a good first step.... I hope the Go team will eventually move to using github as a primary source for everything. Certainly the current setup is a vast barrier of entry for me to be an occasional contributor.
My personal preference for switch/case is when I want to be very explicit AND exhaustive about all the cases. In my codebase there are only a handful of incidences where I have a switch without the default case. If for me is mostly for optional stuffs (if some condition is met the state is changed). I try not to use elses.
I struggle with structuring all the time but I'm always improving. I really wish he had an example. Link to the github: https://github.com/benbjohnson/structuring-applications-for-growth
Hmm, that doesn't answer the question. /r/Spirit_of_Stallman showed me what I was looking for in case you're curious.
No, if the JWT expires, you make the user log in again. If they make an HTTP page request with a valid, unexpired JWT, then you issue them a newer one to replace it, with an extended expiration period. So if it's 2:14 and you issue JWTs with an expiration time of 2:34, that validity period is your session timeout -- 20 minutes. If the user hits refresh at 2:20, the JWT will be valid, so they will be issued a new one which expires 20 minutes from *then* -- at 2:40. If they then idle until 3:00 and hit refresh, their JWT will be invalid so they'll have to log in again. To handle session revocation without having to rely on session timeout, you can keep a list of revoked JWTs based on their JTI values -- which you basically want to do anyway, so they can't be sniffed and used twice undetectably. Or if you want to revoke all sessions, you can change the signing key for the JWTs. The nice thing is, a cache of revoked/used JTIs is small enough that you can likely keep it in RAM and not have to hit the database for every authenticated HTTP request.
Another example here https://github.com/benbjohnson/wtf
This statement in its entirety is untrue. CLA are not required. BSD license is more than enough. I've brought this up so many times on the go-nuts list that I really don't feel like getting into this again. Just know what you are declaring is false. This particular CLA attempts to remove rights.
I think I'd be nervous of storing it in plaintext on an object, because you might then be tempted later to pass that object around (e.g. to populate an email to welcome the user, or generating json) and leak the password by mistake. I usually hash it as soon as it comes in from params, and then work with the hash only. PS This video and repo is great as a reference for go crypto: https://golangnews.com/stories/1469
That is a good point. I did intend to block that out from json exporting but I realize now I only blocked the hash. So would you recommend passing it in as a parameter to Authenticate() and Create()?
Yes I would. Create/Update really need to know the hash, so you could call user.HashPassword if you want to keep all the hashing in one place in the user model. 
That's what I assumed was happening, but I didn't see where if-blocks are described as having their own scope. Inside the if-condition, it says the variables are scoped: if local := Func();local != nil { local.prop = 1 } But I figured using := inside the if-block itself wouldn't scope the variable to just that block.
&gt; := wouldn't create a new variable if one with the like name already exists. if one with the like name already exists in the current block. You can "shadow" a variable like this: x := 1 { fmt.Println(x) //x is in scope, so this works x := 2 //no x was declared in the current block, so this works fmt.Println(x) //the "new" x is in scope, so we get 2 } fmt.Println(x) //1 2 1 https://play.golang.org/p/JjR6uMseDC 
You probably also never hammered a nail with a screwdriver. :-)
Yes, variable declared within braces are locally scoped. 
Can you link to the golang-nuts thread? 
Every block is a block.
I, for one, am looking forward to playing with this
Why do all these IDEs think it's great to automate the go tools? It's just hitting up in the terminal.... edit: wow you guys sure have not used golang cli have you. Well I guess life is only tough when people make it that way.
 err := templates.ExecuteTemplate(w, tmpl, data) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } On error, `ExecuteTemplate` probably had already written to `w`, and so `http.Error` is at most useless. Write to a `bytes.Buffer` first or just log the error (`log.Println`).
`import "webapp/ncrypt"` Use absolute imports, dammit. `import "github.com/nickvellios/golang-web-app/ncrypt"`
Hold my beer and watch this
Because some think it's worth wasting time writing code to solve their problems rather than doing the same thing over and over again when it could be automated. You know, that's why we have machines, to solve the boring stuff.
Raft means choosing the C in CAP. "Highly Available" means choosing the A. I mean, yeah, adding consistent replication certainly means that it can be more available than something *without* replication, but advertising this as "highly available" is just misleading. IRC is highly available. Bigtable is. Anything built on raft isn't.
Thanks. I think I borrowed most of that function from an official go tutorial on building web apps. I'll have to check in the morning to be sure. Thanks for the feedback!
You know what, package management has been kind of confusing for me. As has been source control. So before I uploaded to GitHub I didn't have a GitHub source for this import. Would the correct way be to put it in that directory first and predict I would have that GitHub path? I come from an old school C era so sorry if that question is too elementary.
This is something I'm struggling with as a newbie to the language and this was quite informative. Thanks for the link :)
All our pages are built with Hugo, and they are served by the Cloudflare CDN, so who knows why the page is not loading for you ;). We are aware of the missing features and got tracking issues for that, but 1.0.0 have been mostly fixing things, 1.0.0 have been purely fixing bugs and 1.1.0 will include multiple new features. You should not wait too long, who knows how long the upgrade path works, it depends how far the Gogs database schema changes.
This may be relevant as well. Same idea used to set socket options in some of the x/net packages. https://github.com/mikioh/netreflect
i 'll give a try
Isn't this what gophercon uses for its new website?
I like using the CLI as much as possible, but managing breakpoints, step debugging, and looking at local scope while paused is NOT a comfortable time to forgo an IDE. A friend of mine does debug Python 100% in the terminal, so I have seen it done, but that's not the preference for most. :)
This is the Github for lukehoban. I'm not familiar with the history of its naming, but it links from here to https://marketplace.visualstudio.com/items/lukehoban.Go It's possible that it started as a personal project by a Microsoft employee and then Microsoft begin to more formally sponsor it. However, that is only my supposition.
So we could guess they merged it into the repository, but didn't want to break the plugin (given that it has almost 400k installs). Works for me. I'm quite happy with this plugin.
Actually really pleased this exists (together with Neo4j). Not ready to use it/them yet, hopefully soon.
This reminds me of an idea that I had a while ago that I never got around to trying: an automatic semantic versioner for Go. It would parse the AST of a package and then compare it to the AST of the latest git vx.y.z tag. If any exported signatures or types were changed, it would return x+1.y.z, if any new exports were added, it would return x.y+1.z, and otherwise, it would assume you just did bug fixes and return x.y.z+1. I'll probably never get around to it trying it to see if it works, but if you're interested in automatically updating versions, you might want to give it a shot.
wrapping means each method of the structure, calls the same method name of the wrapped structure. Or, it embeds the wrapped structure. See `UserCache` in the [post](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#.wfu15ry2f).
I found https://discuss.dgraph.io/t/differences-between-dgraph-and-cayley/23
Your code, by convention, should reside in `$GOPATH/src/github.com/nickvellios/golang-web-app`. See https://github.com/golang/go/wiki/GOPATH Currently your repository is not go-gettable: $ go get github.com/nickvellios/golang-web-app package webapp/db: unrecognized import path "webapp/db" (import path does not begin with hostname) package webapp/jwt: unrecognized import path "webapp/jwt" (import path does not begin with hostname) package webapp/users: unrecognized import path "webapp/users" (import path does not begin with hostname)
Yes, many large sites are written this way (server side) - probably still the majority of sites. It works very well and keeps all the logic in one place, server side. It also tends to be a lot faster on first page load than js-heavy client-side sites. Frankly I'd rather write in Go than in JS so it's my preferred style too. This framework looks interesting I think if you like that style of development. I've come to very similar solutions myself so it was interesting to see more Go development inspired loosely by Rails (which I think this very much is).
https://golang.org/doc/articles/wiki/final.go Line 63. I just assumed if ExecuteTemplate started writing to w that it will probably finish without errors at that point. Any recommendations on how to test that to be true or false?
Thanks for the advice. I made the changes so it should work now.
https://play.golang.org/p/E_-jtdCLjk Their example is misleading. Open an issue: https://github.com/golang/go/issues
Ok, the post says, &gt; You can add a UserCache that implements UserService which can wrap your PostgreSQL implementation The word "wrap" can be misleading here. `UserCache` does not "wrap" `postgres.UserService`. `UserCache` only implements the `UserService` interface. The wrapping part happens at runtime, when some code calls `NewUserCache()` and passes a `postgres.UserService` instance as an argument. This way, you can avoid that package `myapp` needs to import `postgres`. Rather, the dependency is created at runtime by the code that instantiates `UserCache`. If your validation and authorization entities are also just implementations of the `UserService` interface, then you can implement them exactly like `UserCache` (that is, embed the `UserService` interface and re-implement one or more of its methods). None of these `UserService` implementations would depend on each other. Hence there are no "wraps" relationships at this point. Rather, the desired layering occurs when these entities are constructed. For example, dbsvc := postgres.NewUserService(...) cache := myapp.NewUserCache(dbsvc) validator := myapp.NewValidator(cache) auth := myapp.NewAuthorizer(validator) 
Yes. All you described is actually what my question is. (It just got distracted by the meaning of wrapping) So the question remains: is this a good application design when it comes to fitting validation and authrization into the pattern that the post descibed?
Unrelated, but I see this enough that it bugs me: `fmt.Println(err.Error())` why not `fmt.Println(err)`? I see people calling the interface method for error and stringer all the time in places where the interface is accepted. Is there a reason to do this? https://play.golang.org/p/q0nEfr1vlW
How has your experience with Go and React been? I spent a bunch of time learning React, and have recently been learning Go so I definitely am looking to put the two together for projects in the future. But I was using React within Meteor, so I'm not sure what the setup/environment will look like with Go. 
Seconding a yes please 
 valFn := doWithoutFoo if hasFoo { valFn = doWithFoo } Or some other version depending on circumstance.
[removed]
The go errors package of Dave is awesome ! But the context is not enough. In my handler env (that i pass to my handlers) i use a log to write some info even when everything goes well, and only if i return an error or recover from a panic I record this log and the error. I can also print this log if I start my server with -verbose for example. edit: I wonder if the solution of D&amp;K to add the context at the moment of the error is better because it force you to think of what you will need to know when an error occur here.
The only reason to do it is if you're concating a string to it, for example describing where the error occurred.
TLDR: - Focus on tooling and bug fixing - Better process for PR - Get more people to contribute (rely more on the community)
In such a case I usually do fmt.Printf("oops: %s ", err)
This library looks fine. Keep in mind though, that with Go web applications you don't necessarily need a separate async job queue like you would in the Rails world, for example. With Go, you can just fire off your async job in a new goroutine at the conclusion of the HTTP handler, to use a simple pattern.
I know at least one that does ;-)
Sure, I'll elaborate. Problem #1. When I see a code like this, even if it's used as an example to explain how errors work, it's a pretty ill-advised code: func main() { result, err := divide(1.0, 0.0) if err != nil { switch err.(type) { case *ErrZeroDivision: fmt.Println(err.Error()) default: fmt.Println("What the h* just happened?") } } fmt.Println(result) } First of all, it doesn't return from a function when error happens, it prints both the error and a result. In many cases the result will be undefined. Library authors just give you that interface and never say whether the result is valid or not. The best advice would be: "don't touch the result if err is not nil". Secondly after switching on error type, the example does nothing but throws away type info and in "default" case the error message completely. If you're a big fan of reading "wtf" error messages in logs, then it's a great way to achieve this. So why would you even explain something using pretty bad code like this? Be creative, make a real world use case example. Problem #2. Ill-advised `if err != nil { return err }`. This code is a bad idea, because Go errors are not exceptions like in exception-based languages. Exception along with the info you throw, usually contains the full stack trace of an error. That's why many people like them and no doubts it's useful info to have. But doing `if err != nil { return err }` in Go is a worst idea of all, you throw away info about the origin of an error. If you have two actions which return somewhat meaningless error messages (some real world libraries can be bad at this), you additionally lose the origin information. For example: db, err := openDBConnection(addr1) if err != nil { return err } err := db.Write(data) if err != nil { return err } Now imagine the library you're using is bad and all its errors always say: "DB operation failed". Yes, my example is a little bit contrived here, but cases like that happen in real life a lot. You will meet a lot of libraries which do not include absolutely all info required to track the origin of the error. So, in this example if you do what article suggests, you'll end up with some generic error somewhere up the stack. Never do that, try to include at least some minimal additional info on the origin of the error. How to do it is up to you, the minimalist approach is to use `return fmt.Errorf("db connection failure: %s", err)`, it's far from perfect, but it's better than nothing. And a side note: err := getItem(123) // This would throw errNotFound Go doesn't "throw" errors.
For sure! And your solution looks like a good, simple way to do so. For more complex application setups I would look at emitting events into something like Kafka and then have one or more listeners responding to them. I just wanted to point out to folks coming from other communities (because I made the same mistake myself) that queue systems aren't reflexively necessary in the same way as with something like Rails.
Cheney gave us a nice wrapper for errors now: https://github.com/pkg/errors
Check out the timers module (I'd link but I'm on mobile). Essentially does this exact thing; specify your function, give it a time to run, and it will run in its own goroutine when the timer fires.
Bigtable is a master-slave architecture. By definition, if a master crashes, the entire thing is useless. That's not being highly-available. (That's why you must have passive backup masters ready to replace a master. In fact, the masters probably use chubby (paxos/raft) to determine who would be the main master, and who'd just sit idle waiting to become master.) I'm not a fan of CAP theory. It over-simplifies something inherent complicated and diverse. But without going into that, let me address the point about high availability. This is from Wikipedia: There are three principles of systems design in reliability engineering which can help achieve high availability. 1. Elimination of single points of failure. This means adding redundancy to the system so that failure of a component does not mean failure of the entire system. 2. Reliable crossover. In redundant systems, the crossover point itself tends to become a single point of failure. Reliable systems must provide for reliable crossover. 3. Detection of failures as they occur. If the two principles above are observed, then a user may never see a failure. But the maintenance activity must. Dgraph does each of these 3 things. 1. We don't have a single point of failure. That's why we use RAFT. Each server has the same capabilities as the next. 2. Even if some servers go down, the queries and writes would still succeed. The queries would automatically be re-routed to a healthy server. 3. Unless majority of the cluster goes down, the user wouldn't see the failure. But, the maintainer would know about them. Given these 3, I think I'm right to claim that Dgraph is highly available.
Not to mention that if you want to append to an error, the [errors package](https://github.com/pkg/errors) is really helpful, and you can to things like ``` return errors.Wrap(someFuncThatErrors(), "failed to call someFunc") ``` which will return `nil` if the function returned nil, or wrap the error message accordingly. It's a must-have for me lately. 
TIL, thanks.
Use four-space indent on reddit, not ``` blocks.
Why does it use its own Context object? Why would you start a new project and not utilize Go 1.7 context.Context? &gt; Oh, yeah, everyone wants benchmarks! What would a web framework be without its benchmarks? Well, guess what? I'm not giving you any! That's right. This is Go! I assure you that it is plenty fast enough for you. ... I have no interest in playing the benchmark game, and neither should you. Okay, thanks I guess? It also uses packages that have much better alternatives. Isn't the point of this to curate the best packages, not "good" packages?
Echo isn't great. It was good until better things came along. 
Having a new certificate generated every single time is kind of ridiculous when you have to manually make browser exceptions to add it to your trusted CAs.
A router is not a framework. It's a router.
Yes its true its changing every time and its the purpose of it,not intended to replace standard TLS server with fixed certs (ie browser usage). The use-case as i see it: server&lt;-&gt;client TLS communication for short time with another layer of auth or with some automated way to add the cert to your client CA(maybe i'll add another method to get the generated cert from the TTLS).
We are talking about two users here, right? One user that wants to access EditUser, and another user who is stored in the system (and is about to being edited). The way I see `UserInterface` is that it only manages the second type of user - the one who is stored in the system. Authentication and validation would thus seem more than just a `UserService` type to me, as they also have to access another kind of user data - the access rights of an active user who accesses one of the endpoints of the system. But frankly, as I know very little about your architecture, all of this is only guesswork. I think the decision whether to integrate validation and authentication into the `UserService` service boils down to two questions: 1. Whether it is the duty of `UserService` to validate and authenticate the ones that want to access the storage system it manages, and 2. Whether user validation and authentication are also used by other services of the system and thus should be independent of `UserService`. 
[removed]
You have a point. The language should provide the right way to generate and handle errors. Now we have at least four different design patterns and the opaque error pattern suggested by Dave Cheney is still not optimal. 
Yeah, that's fair.
[removed]
[removed]
[removed]
Or fmt.Println("oops:", err) 
&gt; Bigtable is a master-slave architecture. By definition, if a master crashes, the entire thing is useless. This is not true. I recommend reading the Bigtable white paper about how they deal with failures of the master, it's pretty cool :). In short: The master is only responsible for assigning tablets to tablet servers; it's not in the critical path for either reads or writes. &gt; I'm not a fan of CAP theory. It over-simplifies something inherent complicated and diverse. Definitely true. But it *is* a useful tool to talk about the inherent conflict between availability and consistency. There are nuances and details and you can make tradeoffs differently for different aspects of the operation of a system (e.g. Bigtable makes the tradeoff differently for balancing tablets and read/writes) and as such it's often useless and unhelpful to say "a system (as a whole) is {C,A}P". But at the end of the day, there is an inherent conflict between these two and not being upfront about where the priority is set is being intellectually dishonest and disingenuous. Bigtable and IRC are honest about these tradeoffs. They choose availability at the cost of consistency, which makes it harder to use Bigtable for applications (and makes it completely unsuitable for some) and which makes IRC grow annoying netsplits whenever any kind of network problem occurs. And the same way, choosing consistency means disadvantages; if I run a dgraph deployment and the network splits, if users can't reach any node from the quorum, I'll become unavailable for them. And this is why I believe it to be important to be clear and upfront here. Your customers are going to have to make these tradeoffs and being unclear about them is a disservice to them. &gt; This is from Wikipedia: Yeah and from context it should also be clear that it mostly applies to a specific deployment. And that it's not particularly helpful to talk about "high availability" as a binary concept, in the context of the article. It treats "availability" as a quantified measure and if that quantity is high, you have "high availability". A sentence like "we added raft replication, so now dgrap is highly available" just doesn't even parse in the context of the article in the first place. &gt; Given these 3, I think I'm right to claim that Dgraph is highly available. That's well within your right. I still believe that it's disingenuous. But it's not like I'm a competitor and would have any incentive to actually do anything about it. Agree to disagree, I guess.
You can use the pkgreflect library: https://github.com/ungerik/pkgreflect It generates maps of the types to make it easier to reflect on them: var Types = map[string]reflect.Type{ ... } So: typ := Types["Nate"] You could build another map of all the packages you want: var Packages = map[string]map[string]reflect.Type{ "pkga": pkga.Types, "pkgb": pkgb.Types, }
Did you know there's another package with the same name. http://github.com/alioygur/gores :)
[removed]
Visual Studio Code is the best in my opinion for Golang development. Vim second best. I have a sublime text license and I have used it for years but I definitely would not use it these days for golang development. 
I also bought sublime text but felt (at least a year or two ago) that the experience was far better in atom for Go development. IMO vim tops the chart. I can't imagine something VS code can do that vim doesn't
Aha, I didn't know that ;)
That's true. Having separate queue also helps keeping track of job infos and states!
Agreed, but not all Go apps are web apps!
I've seen a few example programs listed in this forum that start at the `src` directory. Please don't do this as someone cannot `go get` the package. It is better to have your main in the root or to have a cmd package with main in it. I glanced at the code and see data abstraction object factories. Feels like they are trying to write Java in Go. I get the feeling that these are developers new to Go and they may not be in the best position to offer community direction. On the flip side, I would be interested in seeing packages that others feel are great examples of microservices. I think microservices are a bit different from organization to organization depending on their tooling. There is gokit, but that seems heavier than what I feel the goal of this project was.
Ah there it is. Thanks!
You may be able to use what [I talk about here, under the "You Don't Need Permission To Use Class Methods" section](http://www.jerf.org/iri/post/2945). I'm not 100% sure, because it doesn't always work depending on exactly what you start with. But if you want to be able to go from a string name to a full object, you control all the objects, and can implement the methods, this will do. From there you can do a normal non-reflection type assertion, but before that, I'd try to simply write to some interface if possible.
After Atom and vscode are there still people using sublime?
How exactly support of `http.Pusher` is implemented? I.e. what can I do with this using chi router?
from what I can tell, they just extended their http.ResponseWriter wrapper types to support http.Pusher. 
Definitely [the tour](https://tour.golang.org) and [Effective Go](https://golang.org/doc/effective_go.html).
*iirc* Nobody has [contributed a program](http://benchmarksgame.alioth.debian.org/play.html#contribute) that uses `sync.Pool` &gt; That's not in the spirit of the benchmark… True but difficult for some to understand -- *Those benchmarks are garbage. The binary trees put go at something like 39 seconds but [a user in /r/golang on reddit was able to write a program that performed better than C](http://boards.4chan.org/g/thread/58318469/ntp-is-officially-getting-rid-of-c-and-going-to#p58336558).*
yes you're right, I just updated the benchmarks in the README. Quick link: https://gist.github.com/pkieltyka/d0814d5396c996cb3ff8076399583d1f now reading ``` BenchmarkChi_Param 3000000 380 ns/op 304 B/op 2 allocs/op ```
Thanks for the comments. Yes, I am a new to go and ex Java developer. So are you saying these abstractions are not necessary or incorrect in go? I would like to hear more of you would suggest an alternative.
Wouldn't the DoOnce just be the moderator in that case?
what acdenisSk said + https://golang.org/ref/spec Start implementing some small CLI utility straight away and refactor as you learn more.
Thanks for the response! Okay so I understand wrapping they applescript responsible for tapping the key in an os/exec call, but I'm not quite following with the net/http part in terms of having it communicate with the phone component. In this solution, can I write the little iOS app in Go? That's what I'd like to do, even if it's not the most efficient/smart solution, it'd be nice to get my feet wet with mobile stuff in Go. This might sound like a dumb question, but if I were able to write the iOS part in Go, what would be the best way to open up a "channel" of sorts to communicate between that application and my laptop, running the applescript (or the Go code that wraps it)? Thanks again in advance! 
Looks nice! One thing that'd be awesome is if you added support for showing highest inode usage.
That's a pretty gnarly idea. Wouldn't need the ast level necessarily, go/types pkg can do what you'd need. There are other ways to make breaking changes than just changing signatures though, so I'm not sure how to deal with that. 
Gin uses its own function signatures, while Chi uses the regular http.HandlerFunc and the associated middleware format. I personally prefer Chi's composability versus the groups that Gin uses, so I can make one thing that creates a full path (say for an API) and then mount it directly into another router, while the subrouter just assumes it's at root, and Chi does the rest (for instance, a struct called API which is also chi.Router). You can achieve the same thing in Gin by creating a group, and passing that group into another function (which then uses that as its root), which is about the same. (sidenote: I think there was some weirdness in Gin with this method, but I can't recall why so it doesn't matter) I personally stopped using Gin because I didn't like the way it dealt with template inheritance, and I have to do some funky stuff with websockets in my current project. But, Gin's nice too, and would probably be my other choice.
[removed]
Exactly. I tried using vscode, sublime and vim. When I don't care about the resources it eats, I prefer vscode, else vim is just amazing. You can't beat the macro feature of vim, it is 10x powerful than anything either vscode or sublime provide ( that I'm aware of at least), on top of that vi doesn't east much battery and system resource, vi with vim-go is best provided you've taken your time to learn vi.
Atom is considerably slow as compared to sublime, vscode is faster compared to atom, I find vi to be sufficient, although I've yet to learn using tabs and other advanced features of vi
No, OP is just saying to delete the src folder, and move all its contents to where the src folder is, replacing it. This makes your code work with the go package mgmt system. As it is, your code is difficult to re-use. See godocs about the "go get" command.
Yeah - systems that use the filesystem essentially as their database run the risk of running out of free inodes on a typical filesystem (even with plenty of block storage space left). 
yes, it is.
c and quitOnError are the same channel? Yes, It is ok if no values were ever sent to c/quitOnError.
I think anyone who complains about closing a channel is creating their own problem and like that you showed correct solutions. Small thing I noticed is you say you can only know if a receive operation fails on a closed channel with a select statement and a default case, but what about about dyadic receive expressions? select { case v, ok := &lt;-ch:
&gt; I think your logic is swayed because it comes from a BigCo. How would you feel, if I said you just can't be objective, because you are defending your brainchild? Or that you are holding a grudge against your former employer which is why you jumped to attacking Bigtable? Probably not great. That's because it's a [shitty tactic](https://yourlogicalfallacyis.com/ad-hominem). Please don't do it. &gt; You ignored to even address my scenario about 2 server crashes (master and any tabletserver). True. Just as you did not address the majority of my arguments. That's fine. I just assumed they are not contentious and moved on. This happens in unstructured discussions all the time. So, to address it specifically: Yes, you are correct, that when the master and a tabletserver fails at the same time, some of the data will not be available. But that doesn't change the larger points of a) calling the master a SPOF just doesn't hold up; the master can fail and the data stays available just fine. b) In practice this will be even less relevant, as the master will swiftly be back up anyway. And c) on the spectrum of "prioritizing consistency" to "prioritizing availability", Bigtable clearly falls towards the latter end. (and FWIW: One of the *specific* points you didn't address was, how in a typical 3-node raft cluster, *any* two failing nodes will mean complete unavailability of the cluster. Which makes it even less relevant to pile onto this specific failure scenario of Bigtable) &gt; Even with healthy master, any tabletserver crash in Bigtable will take longer to recover from than a node crash in Raft. I think that may very well be true (to explicitly acknowledge your point). It also doesn't really change the larger points, though. &gt; The entire premise of this discussion is also flawed. CAP theorem says nothing about high availability I pretty early on swayed from talking about the CAP theorem specifically, to talking about the general tradeoff between availability and consistency. The CAP theorem just happens to illustrate it pretty well. But if you prefer: In distributed systems there are, in general, two conflicting goals under various failure scenarios, which are a) keeping a system available in a broad sense, meaning that it will remain usable in a timely fashion and b) keeping a system consistent in a broad sense, meaning that it will appear to an external observer as a single system and that changes to its state will be observable later. Using the term "high availability" seems, to me, to advertise that a system tends to prioritize a), whereas usage of raft usually implies that b) is prioritized. &gt; high availability which is defined as "In information technology, high availability refers to a system or component that is continuously operational for a desirably long length of time." And (where we are back at unaddressed points) I pointed out that the specific definition of "high availability" doesn't apply either, as it refers to a) specific availability measures that b) are quantifiable and c) are then higher that considered normal. If you want to default to this, you should give the specific availability measures, what they are for Dgraph (which is ridiculous, to be honest, as they will largely be dominated by how it is deployed, not so much by the software itself) and how they are higher. And yes, I *do* doubt that you could come up with a sensible availability measure which is higher for any Dgraph deployment than for any production Bigtable deployment. And even though it seems unlikely to me; if you do, I will gladly concede that Dgraph is more available than Bigtable in practice. But simply attacking my character and attributing this doubt to my blind belief in Google won't do that. You would at least need good technical arguments why the different choices made would lead any sensible measure to be higher. For any sensible measure I can think of (whether it's latency or percentile of successful read/writes) all the points and arguments you made are correct, but simply not particularly relevant. It doesn't matter that the master might fail, if this doesn't actually lead to any dropped requests. It doesn't matter that a tablet server failure will make it's rows briefly unavailable, if, overall, this still leads to a smaller fraction of failed requests than the occasional complete failure of a raft cluster. And I'd even argue that you could just delay all requests to a failed tablet server, pushing up the percentile of successful requests. Yes, it would make the latency for those requests horrific, but I wouldn't be surprised if the mean or 99%ile or any other realistic measure of latency would *still* come out on top of a system that needs every read or write replicated. FWIW, my view doesn't come from an academic perspective either (which you seem to assume, as you overemphasized being "an engineer running these systems"). My view stems from running a large system and seeing how most of our operational burden is based on the myriad of pains that are associated with strong consistency. And yes, to be abundantly clear again: I'm not saying that prioritizing availability does *not* come with pain, but people should know what they are getting and which pain they are choosing.
I don't have a chance to try out, the walking algorithm is using standard go library and should work. The gdamore/tcell library I'm dependent on should support Windows as well: https://github.com/gdamore/tcell#windows it is quite possible that godu has some bug in it. Please create github issue with stacktrace and I'll have a look.
Maybe the whole problem is that I fail to understand the meaning of "validation and authorization are types that shall satisfy the UserService interface". Validation and authorization are independent services to me. When a user logs in, the system would validate the user and instantiate some "LoggedInUser" object that carries all the permissions that the user has. Then you could create a new UserServiceWithAuthorization object (with a less verbose name perhaps) that satisfies the UserService interface and re-implements the interface methods to check the required permissions before carrying out the actual method. Like e.g., type UserServiceWithAuthorization struct { svc myapp.UserService usr myapp.LoggedInUser } func NewUserServiceWithAuthorization(u myapp.LoggedInUser, s myapp.UserService) *UserServiceWithAuthorization { return &amp;UserServiceWithAuthorization{u, s} } func (u *UserServiceWithAuthorization) User(id int) (*User, error) { if u.usr.permissions("UserService") == false { return nil, error.New(...) } return u.svc.User(id), nil } Are we on the same page here? I think this is indeed a valid way of enhancing the UserService with authorization capabilities. Looks that I just got confused about the wording. This would still be a UserService kind of type to me, not a Validation type nor an Authorization type. (EDITED: A typo and a small clarification.)
my advice would be to look at the test file for examples and ask the package owners before asking here.
The choice they make for 2016 is straightforward. But still this company's data is absolutely unreliable. For example: Dart vs Typescript comparision. According to this company, Typescript is very popular in the commercial industry, but at position 137. The Dart that is unpopuler according to google trends is 17th place in this index. This company says that they get half of the data needed for the index from the google search engine. https://www.google.com/trends/explore?q=%2Fm%2F0n50hxv,%2Fm%2F0h52xr1 A similar situation is clearly present between php and perl.
/u/pkieltyka Very nice. I'm a very vocal advocate of Chi. Could you please elaborate on how Pusher is used and/or can be utilized with Chi now? Can it be configured to auto-push certain files, files with certain file types, and/or files in specified directories? Also, whilst I've got you here, my only complaint of Chi is that in our own project we've had to use our own FileServer opposed to the Chi FileServer for serving our public dir because your implementation does not disable directory listings. It's very unfortunate. It would be nice if this was configurable at the least. Is this something you could look at?
Looks interesting, however `oragono.go` and `oragono-web.go` should be in different directories as they both declare `function main()`. As it is now the project isn't go get-able.
/u/pkieltyka
&gt; Could you elaborate a bit further on why to use filepath.Join? Sure, there's a few reasons * It's cleaner. `filepath.Join(a, b, c)` vs `a + "/" + b + "/" + c` * It's more consistent. In the example above, you `a` could be something like `foo/` in which case `+ "/"` is unnecessary. There are other things it does too, I'd read the docs for more information: https://golang.org/pkg/path/filepath/#Join * It's cross platform &gt; I kinda struggle with interfaces in general... To be honest, I did too until recently. Coming from a Python/C++/Java background interfaces were a bit odd. Here's a minimal example which might help with the understanding: https://play.golang.org/p/sXkiAW9ReY In the example code the `Bob` and `John` structs implement the `Name()` function. The `Person` interface stats that any struct which implements `Name()` is also a person. This is a simplified view of what's actually going on under the hood of course but hopefully it's enough to give you something to test/play around with. &gt; I don't think i can do this with interfaces, can i? I'm sorry, I don't know. It's still a little difficult to tell what you're trying to implement without seeing the code you're thinking off. Interfaces may not be the right solution but there are probably better solutions than parsing syntax trees too. Here's my suggestion, write some tests for your existing code especially around edge cases which could break your existing design. If it's easy to test and your tests don't need to be modified or rewritten for every model you have then maybe the current approach is an ok solution. If you can't write tests then your current design may be incomplete or not be sufficiently testable in which case you might need another solution.
We'll build with -Wall and make C++ pay for it!
Even though atom has a new rendering engine for its editor, it is still ass. Horribly inefficient for large files. Ex https://blog.xinhong.me/post/sublime-text-vs-vscode-vs-atom-performance-dec-2016/ Granted that test is very anecdotal but that is my general experience when it comes to using atom. 
Yes, I tried atom once, a long time ago, it was slow so stopped using it. vi rocks :-) couple with vim-go it is the best editor for writing Go code
PHP and Delphi are neck-and-neck? Python is more popular than JavaScript? Java is **six times** more popular than JavaScript? I wonder how they justify these numbers.
&gt; Well then look no more and try out the god**o**.
It's a simple example, there's basically no advantage in this case. The main point behind the example was to show that you can use an interface to pass around a common type instead of a specific type in a function call. Basically interfaces allow you to provide abstractions: https://play.golang.org/p/GzNmf1M31C. So in your code you could have something like: type Model interface { Set(name string, value interface{}) error Get(name string) (interface{}, error) } So any struct which implements the above interface could figure out how to handle Set/Get internally. `interface{}` allows you to handle 'any type' instead of having to be explicit. So you will have to do the type conversion yourself but I feel like this approach is cleaner than parsing the syntax tree and generating functions. On a side note about code generation, I neglected to mention that `go generate` is pretty standard. So if you do still want to go that route, that's probably how you should be generating the code.
I would put simplicity and maintainability in first now. Everybody know now that Go is good for system, speed and concurrency. But if we don't read to the end we can think that it will be at the cost of difficulty to use for basic app and then compare to other hardcore language. But finally i found Go very well suited to basic apps and it's the question that come more often now isnt'it ? 
Only because there's a function for something doesn't mean you should put type assertions everywhere, maybe resort to javascript if you don't want a type system.
The layering would reduce (or even avoid) dependencies between packages. postgres.UserService is a storage service. In a layered architecture model like the [Clean Architecture (see the opening diagram in that post)](https://8thlight.com/blog/uncle-bob/2012/08/13/the-clean-architecture.html), the postgres packages would be in the outer rings, as it would be an interface adapter or even a driver in this model. A UserService that would also check permissions not just an adapter or driver, so it would perhaps better fit into the Application Business Rules layers as a "use case". So the benefits would be, as you said, better orgainzation, better readability and thus easier maintenance. 
That's still a runtime error instead of compile time error.
It's almost as if a lot of "middleware" was just cargo cult programming...
Yep, the main use I think is when you want to do some tool for yourself or for low-demanding business. The Nuklear itself is in the public domain, all stack is MIT and is very, very portable. So there isn't a situation with Qt and its licenses against static linking and commercial use. Games and game-like applications, some info terminals on cheap 10" Android tablets, this approach is just a quick and easy way to do some UI with layout and have it on multiple platforms out of the box.
The oracle at Delphi in Greek mythology... My pet python ate a rat today. I had a cup of java on the way to work. The programming for the backend is based on google searches (and other things) for "$lang programming". And now since a search for "delphi programming" will turn up this page too... Whee! They don't need to justify the numbers - the just need to get eyeballs. That sells advertising on the page and some of the eyeballs turn into sales of people looking at their products (manager hears about the tiobe index, sees that C# is a more popular language than Objective C and announces a goal for 2017 to port everything to C#... and looks up at the TICS Basics for C# reads the three sentences about it marketing wrote and decides this would be a good tool to help with the process of porting." Its marketing. Have you ever trusted anything marketing said?
&gt; if I were to do it all over again I'd probably write it with gRPC Could you explain, perhaps with a concrete example, how grpc is related to this?
I really, really, doubt this would be a bug in the stdlib. Make a simpler repro; if it were a Go bug it would trigger without xvfb-run or wkhtmltopdf. What sounds more likely is that you are running the commands somehow differently, manual vs in your app.
Strange. `exec.Command` should take care of that for you. What error did you get?
In a shell (e.g. bash) the shell will strip the " and pass everything between as a single argument to the executable. So in order to get the same result from Go you may not quote the argument.
its a trivialized version for a single handler, the pattern is more useful when your have a much larger amount of routes, and different middlewares to handle different logical parts, with the goal of composability across the request path 
Rather, the pdf plugin in your browser doesn't want to display your pdf.
Why the fuck is Perl still moving up on this list? Are people really still adopting that language? Don't get me wrong, it's fun to write some magical stuff in Perl, but I can't imagine any sane companies making the decision to use Perl for their next project.
you might hate Perl, most redditors do....but it is still in wide use. I don't know why Perl actually increased in Tiobe...but is it really important to determine? we all know Tiobe is garbage redditors seem completely incapable of resolving the disconnect between what they advocate and what is in use in the real world
What do you mean by runtime error? The above code will not produce a panic under any circumstance.
right, but it was at one point and many of those codebases are still in use and are maintained to some degree you will probably do something today on the internet that at some point will touch Perl written in the 90s in 2027 someone's Java from 2002 will be accessing your credit card sad truths that upset reddit
No, but it will "somethingelse" in a way that compile-time checks can prevent.
Your follow up response is much less eloquent (and correct) than saying "I didn't realize the above code wouldn't panic.", but to each their own.
hi, I am using gorilla package as websocket therefore you should install gorilla websocket package to local 
You seem to think the only runtime errors are panics. Also, great tone, here's your downvote too.
Starting from a strongly-consistent database, adding Raft improves availability. The fact that even higher levels of high availability are possible (by relaxing requirements on data consistency) is something else, and not denied here. Please stop interpreting the world as a boolean.
Go is useful now, but I think the power of the concurrency model is still in its infancy. We spend entirely too much time optimizing programs that the compiler could (theoretically anyway) be smart enough to optimize. As an example, it's faster to send large payloads a small number of times over a channel, then small payloads a large number of times. When you write Go programs with pipelines you need to consider this and batch data. What if the compiler could recognize such a pattern and do that optimization for you? Is that infeasible? GCC can optimize mathematical operations to take advantage of SIMD instructions - maybe a future Go compiler could do the same thing with channel and goroutine patterns?
You replied to a counter argument about losing type safety. &gt; That's still a runtime error instead of compile time error. You seem to find referring to a demonstration of conditional control flow within legal boundaries of the languages type system appropriate. Runtime error has a distinct meaning, reinforced in this context by being directly after referring to a compiler halting error. This is different than errors that occur during runtime, which in Go are just values, not runtime errors. Feel free to be butt hurt and down vote me but it doesn't change he fact you're wrong, sorry. We can go further and I can make you show me a example of doing the same thing the op posted that doesn't fall with your own unique definition of a runtime error. Equality check of if article does not equal nil after fetching it? Which uses... conditional control flow within legal boundaries of the program? I won't down vote you, have an up vote and a good afternoon, may your butt fully repair. 
My guess is that Perl 6 feels like it is finally stabilizing. In the Perl world, there's been a bit more activity and news about it than in previous years.
You have a silly interpretation for #2. Of course one should use things outside of the stdlib, when the need is there. The stdlib does not contain even a single database driver! Don't use a "web framework" for the sake of using a web framework.
Anytime, glad I could help! Code generation by itself can be a powerful tool and is sometimes necessary too, like when using Protobufs, but it certainly has some drawbacks to it too. Picking the right tool for the job just takes time and experience...especially when learning a new language. Best of luck!
https://blog.golang.org/constants
Pretty much. IIRC, this is why: Imagine you're declaring and assigning from a function instead of a constant. Later on you decide to change the return type (rename, change to interface). Now since you used type inference, your types are updated automatically and you still get static typing and all the edit-time and compile-time benefits that go with it. Someone who explicitly declared the types has to go chase down compile errors and fix them. Even in internal/private code that can be arduous and potentially error prone. There are certain instances where you may want to be explicit on your types, and that's fine and can be useful, but use it sparingly or you'll spend your time chasing around a cascading change with little benefit.
I'm curious how did you get to the conclusion that perl 6 is winning the race against python 3?
Ahh ok now I understand. I was kinda getting that being the premise but then you lost me lol.
I see. Still surprising to me to see it even held such a high spot for so long before Perl 6.
Maybe I am missing something but I don't see how Perl is any better than any other language for string manipulation. I don't see how PHP is any worse off, or even Golang with a small string manipulation library.
https://golang.org/doc/articles/go_command.html
Shiny appears to getting few updates, I'm afraid it's not a contender.
If you can't initialize a variable, you declare with var else use :=. Is it the right thought process?
what kind of pattern(s) have you found work best for the actual database access functions that you are calling from the handlerFunc eg, at this point I'm creating a struct with a db pointer and creating methods with the handlerFunc signature type ArticleStore struct { db *DB } func (a *ArticleStore) GetArticleByID(id string) (*article, err) { // can now references a.db to access the db } func (a *ArticleStore) ModelCtx(next http.Handler) http.Handler { return http.HanderFunc(func(w http.ResponseWriter, r *http.Request) { articleID := chi.URLParam(r, "articleID") article, err := a.GetArticleByID(articleID) if err != nil { http.Error(w, http.StatusText(404), 404) return } ctx := context.WithValue(r.Context(), "article", article) next.ServeHTTP(w, r.WithContext(ctx)) }) } Then in chi r.Use(articleStore.ModelCtx) This 'works' but feels like an ungainly way to be able to work with the database, however there doesn't seem to be a way to pass additional parameters to the handlerFuncs (like a db pointer) to reference inside the function? Would love input from anyone
I have uploaded the videos here, https://www.youtube.com/playlist?list=PL41psiCma00wgiTKkAZwJiwtLTdcyEyc4 Please let me know what you think!
There are some large (really large) companies with huge perl code-base that still evolving.
I'd use the context for 1 or 2 things. Use it to store data that was extracted from a token that was sent in the request and also to timeout functions that could run for a very long time and cannot time themselves out for some reason. But to answer your question directly I do not think that putting the result of a DB query was the intent in the first place of the context object. 
&gt; Starting from a strongly-consistent database, adding Raft improves availability. I don't know what this sentence is supposed to mean. Adding Raft to a database with strongly consistent replication doesn't make sense, as that's literally the only thing that Raft is for. Even in the most forgiving reading, this sentence is at best a repetition of what has already been said thrice now. &gt; The fact that even higher levels of high availability are possible (by relaxing requirements on data consistency) is something else, and not denied here. If I have a garden shack made out of plywood and I add a 5$ padlock to the door, it improves security. Claiming that its "highly secure" is still a completely false claim. Likewise, the claim here was never that adding raft "improves availability" or anything like that, but that dgraph is now "highly available". &gt; Please stop interpreting the world as a boolean. This is not what I did. Go ahead and read my responses here. I mention the continuous nature of this tradeoff all the time. All I'm saying is, that talking about "high availability" suggest leaning towards one end of that spectrum whereas in actuality you are leaning towards the other end. If you have something significant to contribute towards *that* claim, please go ahead and do so. Right now this particular thread is, TBH, pretty ridiculous and random. You seem to - intentionally or not - misunderstand what I'm actually saying and then coming up with weak arguments against this thing that I never said.
For examples it's better to check out the original repo https://github.com/vurtun/nuklear There is `overview.c` file that explains much, e.g. how to do a sample grid https://github.com/vurtun/nuklear/blob/master/demo/overview.c#L216 `nk_layout_row_static(ctx, 50, 50, 4);` would make a grid of 4 columns
Reason to not infer the type: If you don't want it to be an int. If you need, for example, an `int8` or something to pass to a function, you need to declare it as such.
I'm curious what you mean by "micro-services". Contexts aren't passed between separate applications in any implementation that I know of. Even with GRPC, you have to opt in to passing any "arbitrary" data by using the `metadata` wrapper, and even that's limited to strings (or slices of strings). And it's explicitly serialized on one end and deserialized on the other by the GRPC libraries. GRPC's context might be similar to Go's context (and I'm guessing one influenced the design of the other), but they're definitely distinct things and only one is really relevant in the case of this question, which is about an HTTP server.
Seems plausible enough.
Is there a guide on migrating from Gogs to Gitea, or vice versa? I've searched in both projects on GitHub, it doesn't seem to be any that I can find (not easily at least if there is such a guide).
I hope there is nothing heavy about Go kit, nor anything that requires buy-in. It's primarily a set of recommendations about how to structure microservices at the code level, modeled on established practices like DDD, The Clean Architecture, the Hexagonal Architecture, etc. — as well as a few abstractions (endpoints, etc.) that work well if you opt-in to those recommendations. It's certainly nothing like Revel, or Beego, or even Gin, which are much "heavier" frameworks with their own deep opinions about how do things.
Well it's only starting from 1.9, so if you really need it, you can use 1.8. Still sad, but understandable if there's no-one to maintain them, certainly since most changes in Go these days are under the hood (which also means 1.8 would probably be usable for a long time without any compatibility issues)
Cheers seriouslulz, both of those are captured as github isses :) hopefully myself or someone else gets to them soon.
Fixed, cheers :) https://github.com/viktomas/godu/commit/e5cf85325979706a985500cf7173a92f55e334a1
First use on-line available resources mentioned already. as far as books go I'm reading "Go in action" at the moment and it has quite interesting approach, more problem based than tutorial. https://www.amazon.co.uk/Go-Practice-Matt-Butcher/dp/1633430073/ref=sr_1_1?ie=UTF8&amp;qid=1483963854&amp;sr=8-1&amp;keywords=go+in+practice
&gt; &gt; As an example, it's faster to send large payloads a small number of times over a channel, then small payloads a large number of times. That's because of mutexes used for channel blocking afaik.
I don't really think most people are going to need this "multicore/multithreading" massive parallel stuff, so I don't think that's a good reason to learn Go. Most popular projects written in Go are not multi-threading/parallel processing "performance" limited. Horizontal scaleability is the future anyway, multi-cpu and multi-core are very useful for running multiple small things next to each-other. Be it VM's, containers or stuff like AWS lambda's running microservices - doesn't matter. It's also a (dangerous) myth that go-routines are easy and safe. Synchronization is still an issue you have to care about and be aware of, and there are still many pitfalls, which are all the more dangerous because starting a go-routine is so simple. Go however fills a huge gap: script-like productivity, with performance much closer to C/C++ applications, that is easy to deploy as a static binary with zero dependencies. You get best of both worlds with only a few tradeoffs. This allows for more advanced applications that would have required a decent amount of commitment by C/C++ coders to tackle a certain problem. Go takes out the complexity from a lot of the hard stuff like resource management, boiler plate code, build-tools, portability, ... which traditionally are time-sinks when writing native applications. This allows for a new breed of applications, and certainly on the server-side of things this has been picked up. Some of Go's main advantages: * well documented * static typed, but still flexible with autotyping (`:=`, like `auto` in C++11 ) * easy to learn, script-like language with C-like syntax compiled to static native code * supports many "modern" (server/client) technologies out of the box (JSON, HTTP2 server &amp; client, encryption/hashing algorithms, ...) and many that are not in the standard library are available as 3rd party packages, ideal for server-side stuff * deploying is a breeze * cross-compilation is easy * very readable and maintainable * healthy eco-system, many tools available There are some fields where Go would not be suitable. Stuff like SOAP is not very nice in Go, XML is supported but I wouldn't recommend using it too much. I'd still pick Python for stuff like that. If you want GUI's, you better look for something else, unless a web-gui is what you want, or you can do it in a terminal. While high performance stuff is possible in Go, it's hard to get right, and C++ or Rust would probably be the saner path to take. Go is ideal for server-side stuff, and useful for many other things, but as everything, it has it's strengths and weaknesses. For me it's a very useful tool in my box, as it would be for many people.
Gogs has not made any progress in a while, so I'd suggest you should just treat it like an update in a staging environment and see if that goes well.
Just semantics then. _heavier_ than what the OP wrote and the term itself was picked up from @sethammons' comment. Though not the _heaviest_ by your estimate. If I'm free to use it as a reference design then I'm all for it, and admittedly missed that goal in their readme. Another aspect of my rambling point was that I understand OPs example coming from a C#/Java background. You could sit me down and after 30 minutes I'm ready to get to work extending it to meet new use cases. Not saying *I should* do that or that the code I produce will be elegant, simply that I could. I can't really say the same for gokit. Perhaps what I'm asking is -&gt; Is there a shorter wall I can climb to get into this garden? If not, cool. However what I like about OPs example is it seems to ask "Why can't it be this easy?" Super open to anything you have to add. Loving Go so far.
I wonder if we can look into source code example of such a service. 
[Kargo](https://github.com/kelseyhightower/kargo) [hello universe](https://github.com/kelseyhightower/hello-universe)
it's no straw man..."Reddit" is that gestalt tendency that reinforces repeated mistakes with the false confirmation of "upvotes" twitter OTOH has at least accepted that "twitter" is a thing and can be attacked as a tendency
Does it work for windows and darwin? When I try to build for Windows I'm getting an error: &gt; GOOS=windows GOARCH=amd64 go build ui/splash.go:8:2: no buildable Go source files in ...vendor/github.com/go-gl/gl/v3.2-core/gl ui/splash.go:9:2: no buildable Go source files in ...vendor/github.com/go-gl/glfw/v3.2/glfw 
That's largely because it doesn't follow the advice and example given in the [`context` package documentation](https://golang.org/pkg/context#Context): &gt; Packages that define a Context key should provide type-safe accessors &gt; for the values stored using that key: For the lazy, the example given is: // Package user defines a User type that's stored in Contexts. package user import "context" // User is the type of value stored in the Contexts. type User struct {...} // key is an unexported type for keys defined in this package. // This prevents collisions with keys defined in other packages. type key int // userKey is the key for user.User values in Contexts. It is // unexported; clients use user.NewContext and user.FromContext // instead of using this key directly. var userKey key = 0 // NewContext returns a new Context that carries value u. func NewContext(ctx context.Context, u *User) context.Context { return context.WithValue(ctx, userKey, u) } // FromContext returns the User value stored in ctx, if any. func FromContext(ctx context.Context) (*User, bool) { u, ok := ctx.Value(userKey).(*User) return u, ok } This is always type safe (type assertions are type safe). Also, since the key passed to `context.Value` is a non-exported type it can only be set or retrieved via the exported functions which take and return types the compiler can verify for you. Also, note that although the example `FromContext` returns the boolean from a type assertion that will never fail due to a value of the wrong type. It's needed because the context may not have any stored value at all. In this specific example it may be better to just `return ctx.Value(userKey).(*User)` and document that if the value wasn't set the return will be `nil`. 
Hint: the answer is gonna make you want to track me down and punch me in the face.
Seems that your setup is a bit screwed, my repos for nuklear don't have `vendor`. By the way, desktop example is located there: https://github.com/golang-ui/nuklear/tree/master/cmd/nk-example P.S. currently supported desktop platforms: Windows 32-bit, Windows 64-bit, OS X, Linux, FreeBSD
&gt; It's needed because the context may not have any stored value at all. Yes, that's why there's a whole new code branch in that scenario, that isn't present without it.
Thanks! 
&gt; with strongly consistent replication I didn't say our imaginary database in this scenario was replicated, before Raft. That's the point of adding Raft, and the part that makes it more available. What I know about dgraph, that's what happened here. I sure hope you're not trying to claim that the only way to be "highly available" is by eventual consistency?
Noob question, happy user of vim-go, Is the update go gettable? Or should I just reclone the repo?
Can you try again? I tried to open the playlist on Firefox for (Android 5.0) and it worked. Maybe there was some connectivity issue.
Yup!
Redis can do 150k/s increments on that single core.
I'd be interested to hear why more people don't just use Gin. It seems a lot simpler syntax to read query / form params, provide default values, setup route groups, etc.. Yes, you can do all of that yourself with net/http, but whynot use a tool that makes it quicker to type?
Saw it posted on /golang. I'll watch them soon. Thank you very much for providing this work to the world. :)
I noticed that, too. I have a feeling that's a canned answer he hasn't updated in a while. :)
Disclaimer: I have never used Gin so maybe it's great and I just don't know it. That said, the biggest reason for me is that for routing and the other things you mentioned, `net/http` seems to be covering my needs pretty well. Therefore I do not see a reason to introduce an extra dependency in my projects. &gt; whynot use a tool that makes it quicker to type? If I was after that I probably wouldn't even use Go. Besides, I type pretty fast already. :-P
Already punched the guy in https://botbot.me/freenode/go-nuts/2016-11-11/?msg=76303107&amp;page=4
The trick is: every time you're about to do that, don't. It's stupid, it's worse than useless, and it makes you look like a petulant child. If you can't bring technical arguments to a technical discussion, don't get involved in the first place.
Thank You! The current implementation does not handle static images at the moment. I will consider to integrate in a future version. It shouldn't be a big issue.
That's true. I also think that it rubs off a little on others though - One person reacts this way for the reason you give, somewhere down the line someone else does because they've sort of internalized that kind of rhetoric.
Seeing mystery trivia in the title made it exciting but when I saw the code I was disappointed. This again? This is probably the 3rd or even 4th time.
If you optimized everything, and need more performance, then you can try to use unix domain sockets between your processes (nginx &lt;-&gt; Go &lt;-&gt; Redis), as they mean half the overhead as localhost IP.
What are you using to benchmark? Can you connect to your Go service directly instead of through nginx? 
try github.com/chrislusf/glow It has a bit more.
That is a very cool library, but I think it addresses slightly different use cases. Glow seems hyper helpful when trying to use work with go to set up Hadoop or some other parallelized processing tool, especially when going from a local dev environment to the actual deployment. go-pipeline is intentionally simpler, and doesn't actually have any ties to MapReduce like functionality. The idea is to be able to write your own named operators, so that Flows can be very declarative in what they do, like ``` flow := pipeline.NewFlow( verifyUser(), verifyData(), process(), emitStats() ) ```
BUT IT'S SO AMAZING! If I say it in all caps, it becomes true. Internet 101. Sadly, not only was this general situation already shared, my EXACT code snippet had already been shared and I didn't know it. Ah, well. Maybe I can come up with something else someday.
I'm using Loader.io. Technically I can, but I would prefer if I could keep the reverse proxy through Nginx.
see thats why i like perl...none of my coworkers will have any ideas about "improving" my code. perl's minimal obfuscation acts as a gate keeping out the feeble-minded
Still no dice. Trying to load directly from the Reddit mobile app.
Being able to hit the Go service directly can let us know if the bottleneck is in the service or in the nginx&lt;-&gt;service connections. Also, Go rarely gives "connection refused" -- that sounds like the Go service is running out of file descriptors. Either raise the ulimit and (as has been suggested) ensure the nginx is able to use keep-alive connections.
I wonder if the discussions on the recently-approved type aliases language change for Go 1.9 ([link](https://github.com/golang/go/issues/18130)) motivated this post.
First of all make sure you're actually testing go: 1. Remove nginx proxy - you don't need it, even in production 2. Replace redis operation with something not relying on external service - even `&lt;- time.Timer(time.Millisecond)` will do 3. Spin up 2nd droplet (a smaller one) and use siege/ab or something similar to test it 4. Run go app in the background, not in the foreground pushing logs through your ssh connection 5. Run the tests over http
Connections are persistent, there is a connection pool also in the OP's code. Also I'm not mentioned artificial benchmarks, I'm just saying that 3K/s is a joke throughput for a counter in Redis. Even if redis becomes a bottleneck, the CPU cores are nothing to do with it, it's probably because of network and disk use.
Dave Cheney was one of the most vocal anti-alias supporters. I wonder if the new proposal has changed his mind.
Very cool. I would be especially interested in seeing desktop demos.
You might be hitting the *net.ipv4.ip_local_port_range* limit. Check the numbers you are using by running *sysctl -a | grep port_range* and use *netstat* during your test to make sure you are not hitting the socket/file descriptors limit. You might have to tune your *sysctl* configuration.
The feeble-minded shouldn't have access in the first place, I'll play gatekeeper myself.
He didn't do a good job of explaining what you gain from using this. Docker and k8 is great because my understructure does not care if it's a nginx box, node or a golang service. It also makes sure that the build environment is as close to configuration free as I can get it.
I'd try to exclude Loader.io - you can install `wrk` for example and run it locally like this (this will send requests from 10 threads with 10 open connections during 10 seconds and will show latency report in the end): ``` wrk -t10 -c10 -d10s --latency http://localhost:5000/?param=1 ```
What's the runtime overhead? Are the stdlib/other dependencies "deduplicated"? Is it all one big Go runtime, or one per plugin?
Could you also try with not so huge connections number, for example 10 (`-c10`) as I showed in example?
Lol:) At least there are no socket errors now:) Those are very strange numbers. Here is the same bench of you server from my notebook: http://pastebin.com/kLsdZCeU Maybe something wrong with network - are you sure there is no any kind of proxy between? Do you have a possibility to run the same on another machine? I even doubt that profiling will help a lot in this case as the problem looks global...
Good to know, thanks.
What's the output of 'dmesg'? Usually any packet drops on tcp level show up there. I'd also suggest installing firehol/netdata to see if there are any obvious issues (high io, etc) during your benchmarks.
Running on my Linode 1 core machine gives me similar results. 10 connections: Requests/sec: 63.03 | no errors 1k connections: Requests/sec: 3646.15 | 115 timeouts
It's the ports any network service can use for communication (sending in your case). I would suggest some sysctl settings for sure, these work well for me on a high load nginx edge service: ~~~ net.ipv4.ip_local_port_range=1024 65000 net.ipv4.tcp_tw_reuse=1 net.ipv4.tcp_fin_timeout=15 net.core.netdev_max_backlog=4096 net.core.rmem_max=16777216 net.core.somaxconn=4096 net.core.wmem_max=16777216 net.ipv4.tcp_max_syn_backlog=20480 net.ipv4.tcp_max_tw_buckets=400000 net.ipv4.tcp_no_metrics_save=1 net.ipv4.tcp_rmem=4096 87380 16777216 net.ipv4.tcp_syn_retries=2 net.ipv4.tcp_synack_retries=2 net.ipv4.tcp_wmem=4096 65536 16777216 ~~~ The settings are mostly dealing with connection allocation and reuse of sockets in FIN_WAIT states and so on. I'd suggest reading up on them to not just be stabbing in the dark. Usually if you hit these problems the start is ulimit -c unlimited (or a very high number) and after that issues usually start with connection tracking (conntrack) and the speed your server is able to open and close these (keepalive reduces that but is not always an option)
If end up with a lot of interface{}s in my code and the only solution that I can think of are generics, then I rm -rf my code and start all over again.
Right now I'm just testing Go itself and still only getting 4k req/s.
Like I answered to /u/TinyBirdperson above, the lack of type safety is my biggest grudge with this code as well, and the most obvious fix of course would be having generics. In lieu of having them in the language though, sometimes you have to use type assertions (or even reflection!) sometimes in order to have cleaner code. The balance between having cleaner code and losing type safety depends entirely on the body of code you're working on. Sometimes it's worth it, sometimes it's not. I personally always hesitate before using reflection, or losing type safety in some other way, but I can't deny that there have been times when the solutions using those methods were the right approach. 
Use *netstat -nltpa | wc -l* to count how many sockets you are using during your tests. If I am right, you should start to see some slowdown when the count is close to **28232** (61000 - 32768). You can use *grep* to make sure you are counting just redis sockets, nginx sockets, etc. After this test, I would suggest that you change only this value to the one /u/titpetric suggested. &gt; net.ipv4.ip_local_port_range=1024 65000 And run your tests again.
If you *sysctl -a | grep port_range net.ipv4.ip_local_port_range* again, do you see that the configuration has changed?
It goes from 3300 to around 6000 when running the load test with 3k connections. I'm using /u/titpetric config but 6000 65000 instead. Still theoretically well below the limit.
Yes: sysctl -a | grep port_range net.ipv4.ip_local_port_range = 6000 65000
The first thing I did was copy/paste `setValue` over the func definitions since I've seen this evil before. Saw `setValue is undefined` and `setValue redeclared`. "Yep, trick characters at play!"
what about the machine memory, load average and CPU %? how are they during the tests?
40GB free ram. Go app shows up to 175% cpu usage load average: 1.51, 0.95, 0.89
20 cores.
I did not say use of interface{} makes no sense, I said if you end up with interface{}s all over the place because of API you designed, then the API is wrong. How would generics help with Context.Value? You still would need to do some type cast after Get, whether you have generics or you go with type assertions. I would say Context.Value is a legitimate use of interface{}.
You're testing from your own laptop, aren't you ? So it seems to me you're actually benchmarking your mbp, and your internet connection. Please try again from your server (ie. benchmark localhost)... then from another Digital Ocean instance...
Testing from a Linode instance got me 25k req/s without the Redis part. With Redis still just 2.5k req/s. Now it shows some errors though: 2017/01/09 17:57:23 http: panic serving 45.79.179.63:59998: dial tcp :6379: getsockopt: connection timed out Will update op 
I used it to build a quick and ugly Golang REPL example. https://github.com/dragonfax/go_repl_plugin_example Each command you type gets compiled into its own plugin, loaded, and executed. Your sharing memory between main program and the plugins. But you only have access to the things passed back and forth through the Plugin API. I didn't look to see whats visible to reflection though. I'm pretty sure the dependences are duplicated, as the 2 binaries (executable and plugin) are compiled separately, may have different versions of their mutual dependencies compiled in. So they get kind of sandboxed in that respect, and only communicate via the Plugin Interface that your using. Maybe externally linked shared library deps wouldn't be duplicated though.
Oh, then I am not sure, you might want to go to Youtube directly then watching them here on reddit
Same as /u/neoasterisk here, I type pretty fast :) plus do not want a an additional layer of dependency. I come from the Django world hence I avoid frameworks, I do not want to write an app in Gin1.0 and later Go1.9 is released and I've got to update the app to use Gin2.0, luckily for me Go is backward compatible! Also it is a matter of taste, I learned writing an app using net/http because it meets my purposes, I do use routers etc because they make life easier and worth the dependency, but I one think I'll use a framework in Go, because toolkits like Gorilla are enough
This looks exactly like what I was looking for, thanks! My friend had actually mentioned build tags, but he said he didn't think App Engine provided one, so I didn't look into it further, guess I should have!
Hey this looks pretty good, thanks for making such a thorough tutorial.
Thanks very much for the issue! I've mostly treated it as a personal project for now (cding to the dir and running `go run...` directly), but I can definitely see the upsides to doing that. As mentioned in the issue, I'll fix that up in the next few days or so, whenever I can find time. **edit:** And this is now resolved (with likely some better fixes coming down the pipe). Thanks for letting me know about this, given how I install/test it this never came up.
With information, when I know what I'm talking about. With silence, when I don't, because the problem rarely *is* that those people don't go away, it's that some people can't stand not having the last word and keep giving them opportunities to respond. And it's good to remember that when you're on an open forum like reddit, *anyone* can respond, which means *everyone* doesn't have to. If all you can do is leave a response that makes the community look bad, you're not the person to respond right now. Go spend some time doing something else. When you come back, there's every chance that someone else will have left a better reply than the one you were going to write. If not, there's a good chance that with some time passed, you'll have something more considered to say. If not... screw it! Internet is not such serious business after all.
Good point. Maybe there are pure Go scenarios that don't need large deployment/manangement infrastructure. Small teams might shy away from adding another complex toolset to their workflow.
Goroutines are meant to be cheap on top of how the operating system does the concurrency, so you may want to look at the open source implementation for your platform, if "big money" detail makes such detail matter. Otherwise my guess is the operating system code and the networking hardware will be the major choices for performance, not Python vs Go.
Support for macOS/Darwin and Windows has been postponed to (probably) 1.9.
newBitReader is not exported.
You could stop using strings and use some kind of generically typed context-keyclass and use that to get typed values from the context. In pseudo go-code the Get method would look like this: 'func &lt;T&gt; Get(key: Key&lt;T&gt;): T'. As you wouldnt use magic strings as keys and would define constants for your keys anyway, this would be a lot cleaner without much extra code. Just define your key like this: 'const KeyUser = Key&lt;DbUser&gt;(" user")"
I noticed amount is spelled wrong everywhere, amount only has one m.
There is a wrapper which allows to limit number of total requests or number requests per host: https://godoc.org/github.com/kr/http/limit
Again, it's me disagreeing with you and you say that my opinion represents all of reddit. These are individuals that you interact with. Goteem.
Good. Now I'd use a lower MaxActive param for the pool. 10k connections sounds a lot like "no max"... Try using 500 and see if you still have panics. Alternatively, you could check how many are created... I'm not sure it's a good pattern to open thousands of redis connections anyway. Next I'd try using pipelining to limit the number of redis connections, and round trips. Also check if your load generator is not the new bottleneck (it's less beefy than your server). If so, use more than one.
thank you! After getting a few dislikes to the video, I was wondering if the videos are of any use.
FYI, the bitReader is kinda funky. It reads bits out starting with the MSB of a byte, rather than the LSB. Most bit-based streams (nearly all other compression formats) read starting from the LSB.
I cloned the repo and tried to build the example. It works fine in ubuntu but same problem for windows/darwin: ~/nuklear/cmd/nk-example $ GOOS=windows GOARCH=amd64 go build main.go:8:2: no buildable Go source files in ~/.gvm/pkgsets/go1.7.1/global/src/github.com/go-gl/gl/v3.2-core/gl main.go:9:2: no buildable Go source files in ~/.gvm/pkgsets/go1.7.1/global/src/github.com/go-gl/glfw/v3.2/glfw I had to get `go get github.com/golang-ui/nuklear/nk` and `go get github.com/xlab/closer`. Also another question regarding dependencies. As I understand the compiled executable has dependencies to some external libraries (or am I mistaken?). What needs to be installed before executable is installed?
Exactly my thoughts, couldn't have possibly written the way you have!
&gt; I've heard gorilla/mux is slow in comparison to httprouter I find it so strange that people go crazy about which is the fastest router, trying to save a few micro seconds while building web applications which are IO bound.
Can't tell, but this appears to be a layout style grid rather than a table widget for presenting rows of data?
&gt; That is way too much information to be useful when saving one file. I think that is the main problem. Gometalinter is full of false positives and some stuff that just do not matter for many applications. Running gometalinter on save is insane in my opinion. My suggestion is to instead run golint and/or go vet and run gometalinter manually.
&gt; Generics are not something you can just add to a language. Yeah, no. [STL](https://en.wikipedia.org/wiki/Standard_Template_Library#History) was "added" to C++ and so was generics in Java 1.5. In fact, they went to great lengths (and accepted tradeoffs; i.e type erasure) to be backwards compatible with Java 1.4.
There is an option to pick your linters that are used on save, if not my save would take 30s each time. Personally I just use vetshadow and golint on save.
Feel free to contribute! :)
&gt; And you can't show off with boring. I'd argue that latency/throughput/cpu load graphs are the sort of showing off I prefer to do. If I can rewrite a process from [language X] in Go, using much more readable and maintainable code, and improve in every functional metric by a clear and obvious amount, that's what it's all about for me.
You are right, I was thinking you were referring to UI grid/table, not a data table. The toolkit is low-level, I think a data table is expected be done by user.
Go kit has always been the thing you turn to after you've run up against the complexity and headaches that come with a microservice architecture. It's meant to be a tool you can wield to overcome those hurdles. And here I mean hurdles in both a technical and political sense, both "how do I do this" and "how do I convince my engineering lead that Go has answers to these things". It's admittedly and deliberately not a great vehicle for getting microservice newbies up to speed. To some degree that's my fault for not providing good enough documentation and examples, and where that's possible to improve, I'm constantly trying to do so. But there is a natural tension here between catering to new users and power users, and whenever they come into conflict I'm typically favoring the power users. For good and for ill. In short, go ahead and use a different approach/framework/whatever for microservices to get started, if it makes you productive and teaches you things. At some point, you'll start hitting some walls, and get some experience with the pain points. Then, I hope Go kit will make more sense.
Thanks, fixing the misspelling 
Very cool. I'll take a closer look when I'm not on my phone, but I was thinking last night about how to implement something like this for a side project of mine. Looks like beat me to the punch!
Take a look this library - https://godoc.org/golang.org/x/time/rate. I use for scraper throttling.
Thank you! &gt; implement something like this You could send a PR to improve this open library instead ,) 
If you started to learn go a few months ago and you know already how channels work, then I would suggest that you use a buffered channel to limit the concurrent requests that your web scrapper can do. How? https://play.golang.org/p/1a9PKptOO6
So PHP7 is pretty excellent, and as a framework Laravel is very solid and robust. If you have some heavy stuff, write that heavy stuff as an API in go. You don't need to use an all in one. Personally I hate go for templating and routing, especially when Blade and Laravel are so good. Just write a little Go API and call that with your Scheduler. This way you get the gains of Go and the utility of PHP.
A bit offtopic: I thought hyperdex is abandoned? Thus year it had small number of commits.
&gt; I'm pretty sure the dependences are duplicated, as the 2 binaries (executable and plugin) are compiled separately, may have different versions of their mutual dependencies compiled in This is absolutely not true, and you can test it by sharing singletons. You will not be able to import your plugin if the shared dependencies are different versions.
I can't wait till we get some better NLP / ML-NLP tooling in Go. Python is having all the fun, haha.
Is there Go support for HyperDex? For something non-standard like that you will run into these issues. Are you sure you are having a DB bottleneck, or is it possibly poor query structure / table design? These are all things to consider, most importantly Go support for HyperDex. Honestly, Go is not the best templating engine or web framework. Can it work? Yes, and stuff like Gorilla make life much better. Go really shines as an API or server management language. Many places just use Go as a JSON API and use something like Angular or React on the front. Depending on your server and traffic the overhead of the call is negligible.
I recently wrote something very [similar](https://github.com/tinchogob/flowlan), but typed, and a little more flexible to work with existing code.. Also it supports not only series, but a combination of series and concurrent tasks. I'm still working on a better way to hand back the results (like [this](https://play.golang.org/p/ujiPP82HPV), or [this](https://play.golang.org/p/8pFE4WHlWB)) 
Yes, hyperdex supports go officially https://github.com/rescrv/HyperDex/tree/master/bindings/go I don't think that the db design is the actual problem. The db table (the project has just one) has just 51 columns which "holds" a string and the equivalent hash value.. no relations or stuff like that.. just plain simple. To use Go as the backend and AngularJS as the frontend would be possible.. But as I'm not familiar with AngularJS at all it wouldn't my first choice.
&gt; My Python scraper/parser can handle about 10,000 requests per minute. That is really low (it's 167 QPS, I would expect most servers to be able to handle at least an order of magnitude more). Have you looked into what the limiting factor actually is? It might just be network bandwidth or something. If you are scraping, it is definitely a good idea to add limits anyway. For a simple limiting of concurrency, I like [this very simple pattern](https://play.golang.org/p/bp5fyqsgwK) - simply add a Lock/Unlock pair like with a mutex, it will make sure that at most n functions can hold a Lock at any time. But I'm not sure concurrency is what you actually want to limit. It would still mean that you would not be a nice net-citizen, because you don't actually limit traffic. You want to limit actual QPS and you also want to add exponential backoff - the service owner will thank you for it. There are a bunch of go libraries out there that will help you with that. For extra coolness, do this separately per domain or something. Even if you don't care about being nice; there really is no use in limiting concurrency. The runtime, http library, OS networking stack and the available resources will do a much better job utilizing the resources you have. What would you hope to achieve by applying this limit?
Laravel is also _slow AF_.
I don't think you need to go with a non-standard DB for this, what about Redis, MySQL, Mongo and others was slow for 51 columns? I am not explicitly saying to do the Go backend idea, but I work with Go as my job and I personally really dislike its template system for complex pages. It may work well for you if your site is simple but once you need a complex structure it can become a nightmare.
As MySQL doesn't really provide something like Redis (handling the db in memory to improve the speed) it depends a lot on which drives I'm using but upgrading the drives to SSDs is to expensive at the moment. Redis itself is just beautiful but it doesn't provides a way to search for a db entry not by the key and Redis can only work with databases which fit completely into ram. That's why I choose HyperDex. It provides a way to search just be the value (like SQL where=foo), it handles most of the db in memory and offloads the rest on to the hard drives and is still faster than MySQL. As I'm planing to fill the db with up to 1 billion entries MySQL will be just not the right dbms. I know that it can handle such amount of data but as I'm not using any relations or stuff like that the general overhead of MySQL is just to high
Wow, even this comment was downvoted :-D
[removed]
[removed]
Ok thanks! I think that this is the best way to achieve my goals. But sadly it seems like that HyperDex is already dead http://stackoverflow.com/questions/38212505/is-hyperdex-still-being-maintained Now I need to find a new no-sql db with the right features but that is off-topic here. Thanks to everyone for helping me to find the right way for my project. I really appreciate it!
[removed]
You can cache as much of the MySQL to memory as you want and determine at which point it writes it to disk. Also look into something like Digital Ocean to host your site, its all SSD and generally cheaper for what you get. You do need to have more Linux knowledge to use them however, but their guides are fantastic. I would really take a long look at your DB, as under dog utilities like HyperDex can be abandoned or pivot drastically. Building on unstable ground will hinder you in the long run.
Not a bad plan.
If you decide to use go, give boltdb a try.
So for each goroutine you launch, you're occupying a channel slot, then freeing it on completion of the goroutine? . What's the purpose of using a blank struct as opposed to something else? Not challenging it, just don't understand.
If your database insertions are spawned by web requests this might be a good pattern for you. The http package spins up a new go routine for each request it handles. The trick is getting a reference to the channel into your handler. To do that you have to write a function that returns a handler. It took me a little while to learn this pattern, but it's not too bad once you see it. Alternatively you can make your channel global, which is simple and straightforward.
With a bit of work it should be possible to track down discussion regarding the decisions that resulted in (lack of) features that later became common language complaints in gerrit or github, I think?
For what I'm doing (Hosting several VMs with a custom Proxmox VE installation on a dedicated server at OVH) the server fit perfectly my needs. I could move the project to another server/vps with SSD storage yes. I'm not a Linux newbie but not a professional as well but I'm familiar with iptables, fail2ban, monit, exim, postfix, apache and everything else to protect my server and achieve my goals. But I'm totally new into everything that is not the standard MySQL database. I think that is some of my problems here. 
&gt; Well all said and done this scraper will be doing over a billion requests, if I could just spin those off all at once that would be awesome but I can't imagine that's possible so I need to limit it to whatever the computer/go can reasonably handle. AFAIK a goroutine will use ~2K of RAM initially, so yes, a billion would probably be too much, yes. A million likely wouldn't be a problem, though, RAM is the only limitation you need to worry about, AFAIK. So yes, this might be one of the few cases where the number of work items is large enough to justify a worker-pool.
If Laravel is slow for your needs, Elixir's Phoenix is pretty solid. Does golang have any Rails type frameworks?
It looks pretty interesting, but I think you have the same issue with type safety, namely that the compiler can't tell you if one task is passing the next one invalid input. I think in terms of trying to abstract things out in Go like we are comes with an unavoidable price of losing type safety, we just have to know when to use it. 
You're right, the compiler can't. But, at runtime, we can, that's a TODO, validate the "flow". Not only in/out compatibility but the graph (avoid invalid deps, self dep, cyclic deps) Also, I agree, this kind of things should be avoided in go.. I don't recommend to use this in production. I'ts more of a personal experiment, than a prod-ready lib
For what? Put them in an faq?
Interesting, very cool. . One last question, is feeding to a full buffered channel a lock? Like it just pauses the operation until the channel has an open operation? . So I could just have a goroutine running a loop that reads the next url from my CSV zone file and waits to feed it?
I think you're misunderstanding something. Every value in my database ist unique. So their can't really be any relations (except the fact that hashes could collide.. see md5 and similar algorithms) My project just calculates the hash value (md5, gost, sha1, sha3 etc..) of a string and saves that in the database.
Because it would be good to have in one place, for both those familiar with go and those that are not. So gophers understand that some of the language could have gone other ways. So people that reiterate the usual complaints can be pointed to an "it is complicated, here is how we ended up where we are" answer. Those discussions may provide a deeper understanding of the language that can help when talking about future language changes.
&gt; One last question, is feeding to a full buffered channel a lock? Like it just pauses the operation until the channel has an open operation? Exactly. It will block the current goroutine until there's space in the channel. In this case the goroutine is the main one. &gt; So I could just have a goroutine running a loop that reads the next url from my CSV zone file and waits to feed it? You can have, say, the main goroutine reading the file and start one goroutine for each URL, for example. You could even optimize the logic so that, even you ran out of goroutines to handle the URLs, you would still keep reading the file.
Eloquent is not fast, Laravel is not eloquent.
/r/dadjokes/ Awaits you :)
https://github.com/NYTimes/gziphandler 
that is option 1, is it better than the other options though? I don't need a package, I can implement any of them myself. I'm interested in their advantages/disadvantages.
Natural language processing and machine learning 
Can you show us the schema and slow query log. Why do you think the datastore is the bottleneck? Nothing about the problem you describe sounds like it's the language's fault. That said, Eloquent is slow. 
natural language processing and machine learning - natural language processing I assume. Maybe Google will release Tensorflow libs in Go at some point.
Downvote them. 
This to me is the scariest part of the whole setup. It wont be so bad initially, but I bet as soon as 1.9 lands we will see a ton of issues for apps that went down the plugin road and now have chicken/egg update problems.
Are there any links to Golang Tensorflow then?
That's actually not the way Go's designers view it, their position, last time I checked, was that if they find a good way to do it, they will, but they haven't yet. There is nothing impossible about making it backwards compatible. If you've read the proposal, it retains backwards compatibility. 
great comment and good insights....one more thing to add...the best way to optimize delivery of many of the types of relevant files mentioned here is to exploit locality with a CDN
use a CDN
at that number of requests, you stand a decent chance of having your IP blocked, not all hosts are permissive about being crawled. every ops team i have worked with has spent some part of their day banning request flooders. VPS providers will also ban your account as this type of behavior is associated with malware hosters distribute the load across a number of hosts that are not topographically adjacent (in same colo, etc). also respect http expires headers and use content digests to limit the number of times you retrieve the same stuff over and over (a major "script kiddie" mistake) also, get a new user name, seriously
Please please please run this and hammer on it as hard as you can. Go 1.7 was released and the same day a bunch of nasty bugs were filed that all could have been caught during beta testing. The stability of the final releases (for "everybody else") relies on people from the community stepping up and testing out the betas.
[removed]
Per https://golang.org/pkg/time/#Time &gt; `type Time` &gt; A Time represents an instant in time with nanosecond precision. ... &gt; Time instants can be compared using the Before, After, and Equal methods. The Sub method subtracts two instants, producing a Duration. The Add method adds a Time and a Duration, producing a Time. So, the Cloudflare issue sounds like a library bug to me. Either `Time` did not represent an instant in time with nanosecond precision, or `Sub` did not correctly subtract two instants.
I'm not crawling, just scraping the home page. I'm only making one request per website in my zone files. I've already made over 10 million requests with my Python scraper and haven't had any issues with my ISP (fingers crossed)
Nice! I built something like this in Python before, and this will save me for rewriting it in Go :) It would be nice if there was some documentation for the rules, just to have a quick way to see what is supported. Also, would be nice to have something like "past month", "past 2 week", "last week", "last month", "since last xxxx" etc. 
Always serve gzip and ignore the infinitesimal quantity of (perhaps malicious) clients that do not support it.
Or you could help testing out, not in production of course, and not have the bugs...
I see. But unix time can't represent the leap second, so it either goes backwards, or you lie a little bit in the hours leading up to it, and smear the second. Do systems really have an internal time representation that isn't just unix time? Maybe windows? Checking time.Time in go, it appears to be unix time underneath, so it would go backwards. (Which I think was the problem in the original post.)
I understand why it seems that RC testing is mainly the Go team's responsibility, but I'm going to make the case that it is everyone's responsibility. It not simply a matter of testing "other people's software". If you are a Go programmer, then Go *is* part of your software and it is in your own best interest to test the release before it happens. Any sufficiently large repository of Go code will inevitably use Go in a way that nearly no-one else in the world does. It is for these use cases that it is crucial that people test the RC to discover if there were any bugs. The Go team does do a heavy amount of regression testing. They probably have the largest regression test suite in the entire world. However, the reality is that a young language like Go with a fast moving toolchain (relative to other languages) will inevitably have regression bugs regardless of how careful each commit is reviewed. Even when they test with their huge regression suite, it still a small sampling of how Go is used in the broader community. Furthermore, testing a RC early actually *increases* the reputation of Go's stability. Given that bugs will inevitably happen, which is better? * Catch bugs in the Go1.8RCx, and have a Go1.8.0 that builds confidence of its stability for production OR * A useless Go1.8RCx release, and a buggy Go1.8.0 release that degrades everyone's confidence to use it in production. It's okay for a RC to have bugs (the point is to shake them out). It's worse when the release itself has bugs. Yes, it happens in reality and the very fact that people are skeptical about Go1.8.0 is telling. However, we should be encouraging the community to aim for what Go1.8.0 should be rather than what you think it will be. The call to test the RCs is not necessarily asking people to run it in production, but to run it in a production-like staging and provide feedback about anything they discover (either good or bad).
I kinda get the trap. "Holy crap this one does 50k RPS vs that one's 40k!" From my experience (huge retailer), most APIs see their peaks well under 1k RPS. The benchmarks might look sweet but if handling another 10k RPS (that's over half a million hits per minute) is crucial, your bottleneck will probably be something other than your mux library
You're a piece of work
Thank you for your thoughtful response. I am certainly not suggesting that they should not do RC releases, or even that I am not willing to run them. I was mostly reacting to my gut feeling from the top level comment and other interactions throughout the last few release cycles that make the go project feel a little more "shoot from the hip" than it has been historically. Was mostly trying to point out that "wait for it to be released a while and see what issues rise up before I use it" is a perfectly valid conservative position to take, and attacking someone for expressing that seems a bit odd.
Why would I ever test in one version and deploy in another?
&gt; httprouter is incompatible with net/http Huh?
I agree, this is the best baseline. From this, you can choose to queue requests or drop them.
I have switched to Go 1.8RC1! Hopefully it's okay that I am using the same $GOPATH as from 1.7.
Yes; packages will get automatically rebuilt as necessary.
He's wrong. On the github page, julien even tells you that you can use http.Handlers.
If you run multiple instances of an app, you can deploy a canary version. Have 80% (for example) of those instances run your production version and the rest run 1.8rc1. Direct some of your traffic to the 1.8rc1 instances and track the error rates. Another more conservative approach is to apply the above, but only to non-mission-critical services/apps.
We use go for pretty much everything. It works great for us!
&gt; Neither actually. time() will simply return the same value for 2 seconds. Hmm, interesting, what about gettimeofday (whic gets subsecond resolution)? Pausing, by the way, can be viewed as an extreme case of smearing (smear the extra time into a single instant.) I think even that would probably not cause as many problems in software as going backwards. &gt; Any remotely serious unix implementation will have a time representation that is not just unix time these days. It's not the 70's any more, and unix time is no longer based on GMT. That's cool. Watching xdaliclock show the leap second also sounds fun, to me. I'll add it to the bucket list ;). Still, at least at the application level (time.time() in python, time.Now() in Go), unix time still seems to rule the world. (And hence why Google would need to do a leap-second smear...)
I've used it to run the RTB infrastructure for a DSP for the last few years, and it's been working great for that.
&gt; Oh wait! there is still no centralized package manager/registry. Yes, there is a registry. You can find it at http://godoc.org/. How does rust solve the problem of external dependencies?
I meant to say it for those faint-hearted that might not have canaries and so on available
We use it extensively in our Big Data department. It's mostly daemons and cli (automated or not) tools. Some context: Data sources: * Huge amounts of API traffic (This is Go + fluentd pushing to AWS Kinesis) * CDC logs from a few large/huge sized MySQL instances (This is Java, again pushing to AWS Kinesis) These two add up to 2.3B records a day in our AWS Kinesis stream, closing to 2 TB of data every day. Then we dump the kinesis stream into filesystem, and do the processing/categorically squashing and consuming in Go daemons. Everything is HA. So, tools: * Squash logs categorically in some way (it's also a library package, we use it in parts of our consumer as well) * Consume logs into our data warehouse * S3-related (about billions of objects) operations, backups, etc (have a custom-built S3 cli tool, hoping to make it public) * Repeatedly run queries in various databases and expose the results to prometheus (prometheus-sql fork, it's public) * Various other shim-type daemons to expose internal APIs to other services, doing medium amount of work in the process 
Same there.
Because you can deploy it to a staging setup for a few days while you do test it as it would be the real thing in parallel to your real thing. 
&gt; this scraper will be doing over a billion requests Feed the request details into a queue like AWS SQS and write a worker to read the queue and make the request in a goroutine, using a WaitGroup as described above to make sure you don't plow the machine under. This way you can spread the requests over a bunch of small inexpensive servers like AWS t2 instances. 
That almost makes sense, except: Have you ever wondered where x.x.2 (.3, .4, ...) come from? Your code base might be special and trigger bugs that won't get fixed until you find and report them. Releases don't become bug-free over time, they become bug-free because someone is testing their stuff with new releases. 
Will do! As soon as it lands in the official docker repo.
That requires effort 
As someone else well said, if people don't help out then the .1 or .2 builds won't ever come and whenever they'll feel safe to upgrade, if ever because there's no point release right, theb they get the bugs then and blame it on the developers instead of themselves. 
Release notes for the lazy: https://beta.golang.org/doc/go1.8
how well does it work for you on Windows ?
httprouter, as far as I know, is incompatible with the ServeHTTP interface, it requires you to write a custom Handler like `func Index(w http.ResponseWriter, r *http.Request, _ httprouter.Params) {` EDIT: It turns out /u/FIuffyRabbit is right, the last time I checked the library's README, "Why doesn't this work with http.Handler?" this section was not present, (the version I have on my system is ancient, say more than 1yr old), mux suits my needs, so I don't need to go to httprouter. 
Odd that they used a Getty image rather than one of the actual Go gophers which are available under creative commons ¯\\_(ツ)_/¯
It turns out /u/FIuffyRabbit is right, the last time I checked the library's README, "Why doesn't this work with http.Handler?" this section was not present, (the version I have on my system is ancient, say more than 1yr old), mux suits my needs, so I don't need to go to httprouter.
A supplier condition service: Account managers enter permanent and temporary discounts for specific products/brands/product groups for a supplier The system then listens for approved invoices on the purchase side to be able to claim purchase discount. The system listens to webshop orders in order to claim sales allowances. We monitor sales and purchases for a total turnover exceeding one billion euro a year (&gt;9M invoice lines, &gt;40M shop orders a year). We also keep track and update the supplier offers with these discounts (60M product offers) We also do the financial bookings and preparation of invoices for this stuff. Meta data from different sources is need to match conditions: product information, financial unit classification. We save these as raw xml replies in our database and marshal them on the fly when needed. Scaling: since the system has just started we don't have a lot of data yet. For matching 1500 conditions over 3M invoice lines, 10M shoporders it takes my macbook 28 minutes to create full YTD overview over 2016, day by day. This is an unoptimized process atm.
Same reason why I use Go. &gt;I still write some of my one-off scripts in Python b/c some finance and investment packages aren't/weren't available in Go I hope this changes within a few years. It looks promising. 
I have used Go professionally for more than 4 years, and I can say it is a fully general language, meaning you can use it pretty much for everything. You still have some problems in finding libraries - as the ecosystem is not as old as Python's or C's... Still, if you can use a C library, you can import it in Go code (as long as you're willing to lose the nice memory walled garden of Go). There is, however, two particular use cases which Go might not be "the right tool for the job" (tm): those where a GC is a deal breaker (and for those, you can use C and Rust), and targeting your application to those platforms that the compiler does not support... Although you might get yourself these binaries compiling with gccgo. 
I work for an NGO which tries to bring interactivity between farmers and people who want to reach farmers. We have a box( yes literally a black box) that has a rpi3 , usb hub, and a some custom stuff. The rpi runs a arch linux, and asterisk and a nodejs based app that uses dongles to allow radio station to make/receive calls send/receive sms on their browser. I was asked to help ease configuration of the box. I used Go, we had an amazing experience with the guy who do frontend. I exposed a simple API. Which alows people to configure network/channels and other aspects of the rpi on their dashboard. I cross compile, ship the release on github and it work seamlessly. I can't recommend more. Go is awesome for creating tools fast and efficient. I didn't mention I have another tool( which runs in the pi) that streams live events about the state of devices( here concurrency and channels won big tim). The other devs are JS people, but they all agreed Go rocks on this space, they can easily read and understand my code. And It works like a charm.
By writing your own context struct with data you need to share between middlewares and passing it to each middleware.
Ahh thanks. I saw their examples all had that third "params" variable and even used the underscore to discard it. As someone who hasn't used it, they should make that fact more apparent.
That's key. Not "don't use it because it's a library" but "I don't use it because I haven't had the need to." I haven't felt limited by ServeMux but maybe my routing is simpler than most. 
&gt; and Perl, a NASA-created language renowned for its reliability, if not its elegance. &lt;chuckles&gt;
Thats why everybody waits for the 1.8.1 release. Which means the smart people wait for the 1.8.2 release ;-) BTW THIS WAS A JOKE REDDIT
We've used Go as an API Gateway on a couple of projects. Specifically, we used Mailgun's Vulcand Proxy (https://github.com/vulcand/vulcand), writing a couple of middlewares for what we needed. I feel like Go is a great fit for the API Gateway pattern, allow us to have a solid, performant middleman for a services-based deployment. The gateway has never broken a sweat and is very extensible. I am now looking at Go first for most of our projects.
I don't know about the talk, but the technique is well discussed: - http://blog.nella.org/zero-downtime-upgrades-of-tcp-servers-in-go/ - https://github.com/rcrowley/goagain - https://groups.google.com/forum/#!topic/golang-nuts/41TPj4PWBI8 - And checkout Go 1.8's new [Server.Shutdown](https://tip.golang.org/pkg/net/http/#Server.Shutdown) method.
Here's another one: https://grisha.org/blog/2014/06/03/graceful-restart-in-golang/ The methods are probably all same.
Windows is a fully supported platform for the runtime and toolchain, so no major issues. Standard library has some occasional quirks but nothing unexpected if your are use to cross platform development. Haven't done any GUI development yet, but CLI or web dev works great using go on Windows.
This is both exciting and terrifying to me. It's what I want, but it's not how I want it.
I think the difference in performance between Java and Go vs Python and Go is a lot smaller. Java also has a ridiculously large ecosystem and talent pool because of how widely it has been adopted in enterprises that I imagine it will take a long time before Go starts to be the backend replacement for java in enterprises that aren't explicitly producing consumer software. 
I think the difference in performance between Java and Go vs Python and Go is a lot smaller. Java also has a ridiculously large ecosystem and talent pool because of how widely it has been adopted in enterprises that I imagine it will take a long time before Go starts to be the backend replacement for java in enterprises that aren't explicitly producing consumer software. 
&gt; i was wondering what libraries/frameworks are you using for http, routing or database. What I use for the above is [this](https://golang.org/pkg/net/http/) and [that](https://golang.org/pkg/database/sql/) in combination with the appropriate database driver. If you are using jwt you might also want to use [this](https://github.com/dgrijalva/jwt-go) package.
Sounds like you're basically doing a [Blue-Green Deployment](https://www.martinfowler.com/bliki/BlueGreenDeployment.html). Do you go through a "canary" period where you monitor the new binary for problems, or just switch as soon as the connections are stable?
I've been doing the same, but this new project is going to be big, and using plain database/sql is going to result in a huge codebase, i'm considering a ORM or a library.
I'm using the standard library plus mgo for connectivity to Mongo. I was using httprouter but it honestly wasn't hard to write my own routing, and I get better performance and more flexibility rolling my own. It's just a handful of switch statements.
&gt; I've been doing the same, but this new project is going to be big, and using plain database/sql is going to result in a huge codebase, i'm considering a ORM or a library. If you are going down that road, the ones I've heard the most buzz around are https://github.com/vattle/sqlboiler and https://github.com/jmoiron/sqlx.
Wow! Thanks for the update (and so fast too!) I'm unclear on the android-go portion, I assume it's included in nuklear go when you clone that so I'd just have to get the updates via the go tool at a guess? Sorry for newbie question
Yeah, the Go tooling is first-class citizen here. Just `go get -u` the package, then `make &amp;&amp; make install` as usual, the Makefile uses `go build` so it won't update anything implicitly.
Cool, how's Mongo working for you?
wow, good to know, i think i'm going to use sqlx then,
This is awesome. Maybe someone will create an easy to use SDK wrapper. /offtop Pixel XL Black 128 is still out of stock from the end of November. Argh.
gorilla/mux and silvertape to hold it together. api2go was probably the best stack I worked with, Ember makes that an instant REST api without any serious work. The rest (pun not intended), middlewares and such, is basically coded from scratch since it's usually not as bad.
I think you're underselling goroutines. They're not just for parallel data processing, like number crunching. They make it a lot easier to separate the concerns of your application. Instead of branching on what you need to do next, unnecessarily serializing your code, you can model everything as a goroutine, letting your jobs naturally parallelize. Sure, you need to coordinate between goroutines, but you'd need to do that between processes as well. In Juju, we routinely have hundreds of goroutines running at once, each doing their own thing. We're not doing number crunching, there's just a lot of different jobs that all need to get done, and generally don't depend on any other job to be finished first. While Juju doesn't do number crunching per se, we do perform a lot of work, and if it were all serialized, our maximum capacity per machine would be lower in direct proportion to the number of cores we have available. Sure, horizontal scaling across machines is needed for large projects, but at the same time, the less you have to communicate over an incredibly slow network, the faster your service will be. And being able to use in-memory locks is orders of magnitude easier to synchronize than processes running on different machines.
I've tried using Go for some embedded Linux work that used a lot of IO over SPI, but it became too much of a hassle. C/C++ was much more straightforward in that realm. That said, I have another embedded project that I need a web server running. Go worked perfectly in that case.
net/http database/sql 
Go-kit and squirrel for sql. 
holy shit those are a ton of advanced projects. impressive.
Would be nice if go doc supported the usual `.`, `./...` conventions for referring to local directory packages.
What's the difference to go-mobile which supports jni calls, too?
"zero downtime" means different things to different people: Some just mean that you don't reject any HTTP requests. That's as simple as no longer accepting new requests on one server (for example take it out of the pool), and restart it once the existing requests finish. As long as you have at least two servers and no persistent connections, it works great. This is what 'endless' and Go 1.8's Shutdown do, but really a load balancer will do just fine. To me, zero downtime means maintaining the TCP connection, and passing it between processes. That's a lot more fun! It's also essential if you are doing pretty much anything other than HTTP (I needed it for an XMPP server). There are two ways to do that. - One is give the file descriptor of the socket to the child when you start it ('goagain' does this) - The other is to send the socket file descriptor to the new process over a unix domain socket. This is the most powerful way of doing it, but you have to get the details right. I blogged full details on that technique here: http://www.darkcoding.net/software/online-upgrades-in-go/ 
I'll stick with Postgres then, i was thinking on using Mongo at first, and then move to Postgres, but i think ill start with Postgres. Thanks!
Yeah, absolutely for timing things you should be using a monotonic clock. Even today, Go doesn't give you one out of the box. They're working on it... https://github.com/golang/go/issues/12914
`go-mobile` has another goals and priorities. This project appeared to fill the niche and do things differently where go-mobile doesn't help, for example, go-mobile is targeted for mobile developers who want to play with Go. `android-go` on the other side is a project for Go developers who want to do Android development without touching C or Java code. &gt; which supports jni calls, too? No it doesn't, they generate JNI code to do calls from Java to Go, like I said that's a tool for Java developers. To do calls from Go to Android SDK, they write C shims like this: https://github.com/golang/mobile/blob/master/exp/audio/al/al_android.go#L20-L23
For those "in the know" about Go &amp; Android, what is the current "best" method to create 100% Go Android apps? Ideally, i want Native UI components too, not custom drawn OpenGL stuff.
Came here to suggest exactly this.
What I meant was "reverse bindings" (see https://godoc.org/golang.org/x/mobile/cmd/gobind ) which looks like calls from go to java/coca for me. Am I wrong with that?
Looks cool, however that's a DSL (domain-specific language) kind of language constructions here that have no sense without invoking `go-bind` generator that will generate Java code and C shims that will setup a bridge between Java and Go. No JNI calls from Go. My approach allows to access SDK without code generation, in a very direct and explicit way, using Go. I'm not stating that it's better, it's just different and I like it to be that way. 
I've made a usual mistake 'oh seems nice I'll wait for some reviews'. Enjoy your device :) OP, sorry for off-topic conversation.
I am using [mongodm](https://github.com/zebresel-com/mongodm) in production. 
&gt;Hive queries written in Go How? Which drivers did you use?
Been using Go for about 2-3mo now. Since then I've built: * Reverse Proxy to mask our asset server from clients. * HTML -&gt; PDF converter for invoice generation. * URL shrinker like tinyurl.com and goo.gl * SMS messaging service. * Credit Card payment gateway * JSON Web Token package Currently I am building a web app that will manage content on 5,000+ digital displays. (This is the initial reason I adopted the language. We needed scale and performance. All other projects up to this point have been tests to learn my way around). We used to use PHP exclusively for our web apps. It worked OK but I think PHP's downsides are well documented enough where I don't need to get into them here. So far, development has been much slower than PHP. This is mainly because I am still learning the language every day I use it and refining my design patterns. I have found that my code ends up cleaner and generally easier to read and manage. 
This rings true to me. I take the same approach when showing design patterns to junior devs. That is -&gt; Once you can properly articulate the problem, and are certain it can't be solved elegantly with the tools you have _then_ you are free to look for a more sophisticated solution. Admittedly I didn't recognize you as a maintainer of Gokit or a moderator of this sub. I'll ponder internally as to whether it would have impacted my comments or tone. That being said, you certainly deserve a lot of credit and respect for the work you continue to put into the community. Thanks for taking the time to respond.
Quite possibly, I guess alot of Go is those simple rules that just make it easier to not make mistakes. Even gofmt enforces some pretty simple rules but make writing go easier and more enjoyable. In the same breath though tools are just tools, something meant to help you get the job done. If I need routes I'm probably going to use a router because there are smarter people than me out there writing code haha. Fully understand on the web framework as i'm fairly sure it's a less tested area so projects aren't as mature so maybe more frowned upon? Also helps strip away unneeded features/code.
Anyone up to do some benchmarks?
What I have done was, used Mongo to prototype and moved on to MySQL once its stable. This was for an app couple of years ago. 
I really hate them for taking short-cuts and using type erasure. This makes mixing reflection stuff and generic stuff much more difficult. 
Ok, I see what you meant. Thanks for the information.
* [Chi](https://github.com/pressly/chi) for Routing * [jwt-go](https://github.com/dgrijalva/jwt-go) * [satori/go.uuid](https://github.com/satori/go.uuid) * [logrus](https://github.com/sirupsen/logrus) for logs 
thanks
The entire article is relevant today. My only gripe is that the post doesn't have a very good title. This is quite a short introduction to Go- useful to know that before clicking the link.
"At $9.99, the author would need to sell 3x as many copies of the book for it to make financial sense." but at $9.99, 5 to 10 times more people will buy the book. I always buy stuff which is less than $10 even if its not that much interesting as this book, and I buy that stuff even if there are less chances to actually use the stuff.
Hi author here, I would love to get some feedback! Greetz 
Awesome, thank you! I had some issues with Android-go not pulling with nk, but otherwise great! In your Android example opening the keyboard and pressing a key causes the application to close without reporting anything to the listener. I'm struggling to find the workflow to use the soft keyboard, how do you find which key was pressed, moreover how can you attach the keyboard to an editable text field? From looking at the source there's multiple mentions of TextEdit and SoftKeyboard but in my tests I've been unable to find a way to give the keyboard a buffer in which to write
I agree, I would have preferred if they broke BC with 1.4 because the tradeoff is too costly :/ Still, even with type erasure, it's much better than not having generics at all.
I also have been using Gin. I am curious how Gin achieved zero allocations while still using their own context verse Chi which is using the native context with 2 allocations.
&gt; Contexts allow us to pass optional values to handlers down the chain The docs even says you shouldn't. &gt; Use context Values only for request-scoped data that transits processes and APIs, **not for passing optional parameters to functions.** 
Me
[removed]
I'm aware of that, it is because I still have to make it. Thanks for pointing out though
I thought the tutorial was clear and easy to follow. Any reason you went for the functional approach, returning a copy of the identicon, instead of having methods that modify the identicon? 
I'm in Montreal, but I don't think anyone can judge their own experience level.. Without knowing why you're looking for people who are both local and experienced, there's a (sporadic) [GoMTL](https://golangmontreal.org/) meetup. I don't think there's currently any planned, but you can try to email the organizer to poke him. He's very friendly and approachable (but often has trouble finding volunteers to be speakers...) If it's because you're hiring, you might be better off just not being concerned about whether they know Go but whether they have good software design and development experience. Go is designed to be an easy language to learn, so it'll take you farther in the medium-long term (in fact, I think that approach will take you farther no matter what your stack is, but that's just me..) If it's because you're looking for someone to help mentor you, you might be better off with resources that are online like this sub or slack without being concerned about where people are. Otherwise, there's the above meetup..
I mean, it's the least amount of Ruby/Python/Javascript gambling possible. It's like if Python/Javascript required you to check isinstance/instanceof before using a variable. I think they realize the lack of polymorphism hurts container construction, but they've decided fixing the problem isn't worth the tradeoffs. Anyway, given the situation, I guess I'm still defending that it's relatively type safe. It's not the best hill to die on but it's my hill, haha. As for macros, Go has go generate now! It's kind of similar, aside from the expectation that people check in the intermediate artifacts to their code repos.
Oh, and I forgot the postscript I intended to add: In Quebec, "engineer" is a controlled profession. You can't (legally) call someone an engineer or say that they have "engineering experience" unless they're a member in good standing of the Ordre des ingénieurs du Québec, the same way you can't call someone a doctor or lawyer unless they're part of their respective professional orders.
I'm surprised the author missed to mention https://github.com/pressly/chi in his analysis. It's very current and leading for context based http routers in terms of capability and performance. Update: thanks JT for mentioning the project as well!
At *compile* time, it does make sure that you're at least checking isinstance/instanceof. I agree with you that a language with generics could be more type-safe.
&gt; i want Native UI components We all want that. If you know about that stuff, please contribute to [shiny](https://github.com/golang/exp/tree/master/shiny).
Oh, no, I didn't see this. This certainly looks better than almost everything else I've seen. I would caution that using strings as Context.Values keys is a huge footgun and an accident waiting to happen. You should use something like https://godoc.org/gopkg.in/webhelp.v1#GenSym, even if you don't use webhelp at all.
yea, I totally agree. The best pattern I've seen is actually from the stdlib in how it handles context keys: https://github.com/golang/go/blob/master/src/net/http/http.go#L28-L34 and https://github.com/golang/go/blob/master/src/net/http/server.go#L212 it fits in an interface{} without allocation, has no conflicts within the same package definition where the contextKey type is defined, and it offers nice readability of the context tree. btw, chi supports this pattern as well and its something the library uses itself everywhere.
Thank you!! The reason for the functional approach is because I was following some functional courses lately. Got kinda stuck with the paradigm in my head, because I made this identicon generator in elixir I tried to copy it as much to go. (https://github.com/barthr/functional_elixir/blob/master/identicon/lib/identicon.ex)
I have always wanted to try this. Thanks for the tutorial. By the way, RoboHash - https://robohash.org/ generates robot images similar to identicon (written in Python) which I felt was worth sharing
tollbooth for rate limiting and a very simple custom piece of code for connection limiting
Looks like a cool project! Thanks for sharing
Hey inbox me your contact info. Love to speak to you about a project. Thanks Mike
I trust Google but I don't trust them _that_ much. ;)
Interesting, I like the way how go does the development cycle for new versions. BTW your tls certificate is not valid anymore
There are countless stories of an entire Google account being frozen for random reasons like using a reseller in another state to avoid sales tax on a Pixel purchase. Something like this is really nice to keep a local copy in case that happens. You might be out some other data, but at least you don't lose your family photos and videos that are synced automatically by your phone (and often deleted locally afterwards). 
Go has polymorphism via interfaces.
I am in Toronto. Learning to work on GO and the ecosystem. panbhatt attherateof gmail 
You can use the Code | Show Reformat File Dialog and then tick the option to run Optimize Imports when formatting which will make the IDE behave like goimports on save since instead of pressing CTRL+S you'd need to press CTRL+L (or whatever the key is for formatting).
Regarding the format on save, please watch for updates in the https://youtrack.jetbrains.com/issue/GO-31 issue. The internal formatter needs to be on par with gofmt and the developers know this and will be as such before 1.0 is released. There are several reasons the IDE does not use gofmt on save is: - the internal formatter is needed in order to produce the code from refactoring and various other code generation facilities. - there are several points in the IDE that can trigger a save action. If you miss having gofmt on save, you can either bind a key to gofmt/goimports and instead of using CTRL+S then use that or, as you said, setup the File Watchers plugin (but that might give you a not so nice experience). If you do identify any issues in formatting the code with the internal formatter, please do report them as unfortunately the Go team did not want to provide a specification for this (see: https://groups.google.com/forum/#!msg/golang-nuts/JBvEoyPJlL0/-jDNgEWS1McJ ). As for the other issues, for refactoring, press twice the shortcut and you'll get a dialog for this which will allow you to specify for how this should behave. Thank you for the nice words and if you encounter any issues or think of any features you'd like to see, please either open an issue here: https://youtrack.jetbrains.com/issues/Go or ping me and I'll be happy to help you out.
Okay. I've honestly never heard of such a thing happening.
I've been using the original plugin for a long time so when they announced the EAP for the new IDE I jumped right in. It works almost perfectly, and whatever bugs there are, they are *very* quick to respond. I reported 2 bugs in the first EAP, one of them was fixed within *hours* (and got released ~yesterday) which is absolutely amazing. The other is a cosmetic improvement so it's very low priority, but it was still acknowledged and assigned within a day which is impressive.
https://play.golang.org/p/r3JR1lkaag
That's funny, it seems that reddit differentiates between http:// and https:// links, otherwise it would warn /u/dgryski about the already posted link.
I'm sorry that you think this is hilarious but the "most basic text editors" as you call them, do not provide the level of functionality an IDE provides, so the comparison is not fair for the text editors. As for the reasons why this is not done in the IDE, please see the explanation here: https://www.reddit.com/r/golang/comments/5nlybr/is_anyone_here_using_the_new_ide_by_jetbrains/dccltrj/ (tl;dr is: because it's not a simple text editor but yet it's still possible to via a plugin).
Totally rad, Alec! Thanks for all your help!
This seems to be extent of the automated tracing: https://github.com/stackimpact/stackimpact-go/blob/6387624c15555c19a7a1a2bd16c069e87c9f0a5a/internal/block_reporter.go#L221-L258
This looks nice, apart from the silly scenario where photos are uploaded and then downloaded over the same internet connection..
Yes, actually it is. Gofmt doesn't work on source code that doesn't compile as an example. The devs acknowledged this issue btw: https://youtrack.jetbrains.com/issue/GO-31 and there are simple ways to get it working. As for speed, there are a few performance issues / optimizations that need to be done at the moment (it's still a young product and not even in public release) while the screen estate can be minimized to the extent that there's only your code on the screen and that's it :) But to each its own tool. You don't like IDEs, I love good IDEs.
Search for the gomobile project, it lets you run Go code inside your Android app. Networking works.. but I would just rewrite that part in JS. You shouldn't be expecting pure golang mobile apps.
Not yet, but I will in the near future. 
The linter catches this before save though so it's not an issue i've run into, nor did I even realise it was the case because the issues get caught earlier haha. Very true! Keep up the good work for the IDE users of the world! 
&gt;But I cannot think of a way to glue together sth like Cordova and the output produced by Gomobile. You don't have to use Cordova. Cordova is at its core a native app with an embedded browser and a JavaScript API that exposes native APIs. You only need the first part, which you can easily write yourself in any Android-supported JVM language. From there you just hand it off to the Go part of the application (using the Java bindings generated by gomobile) to dictate what's going to be run in that embedded browser. &gt; Also I assume I would have to write both the cli and server into one app right? So a rewrite (sort of) would still be needed. You would need to decouple the CLI from your actual application. I believe one should always avoid coupling the external interface to the core logic for any non-trivial app, since this kind of stuff happens too often.
&gt; 100% Go Android apps &gt; Ideally, i want Native UI components too, not custom drawn OpenGL stuff. I am quite positive he meant Native UI components created by Go.
&gt; I believe one should always avoid coupling the external interface to the core logic for any non-trivial app, since this kind of stuff happens too often. Yes that is what I am doing currently (for desktop) but I want to publish one app only (let's call it Test) and not force the user to first install "Test" and then tell them to go ahead install "Test-CLI" and "Test-Server" in addition just to be able to use "Test". &gt;You don't have to use Cordova. So if I got it right I shall create a native Java Android app that just has a Webbrowser component. That app runs the Golang functions in Java exported by Gomobile meaning I have to take the logic of the CLI and the Webserver and create a single library through gomobile containing both implementing the rest through Java. One thing that bothers me is still left though. The like 5% JavaScript code I have is literally 100% Node code (executing/writing/reading files and changing the current URL). Any idea how I should work around this? Sorry for my extensive questioning but I am new to Mobile devoplement and would really like to get this task done properly without having to waste lots and lots of money (/time) and then in the end failing.
Before: - go binary - docker artifact - multiple YML files After: - go binary
Yep mostly very happy with it. Very excited to see it evolve.
No I use an editor called `vim`.
Your edges field is a pointer to a slice which is not what you want, slices are inherently reference types. Did you mean to have a slice of node pointers?
I second this only if you have a guarantee that all members of T are of the same type. If it's more like a filter operation with an unknown count then append is likely best.
I will have to take a look! The Lua-C bindings are really used when performance is of the essence - Using Javascript is nice, but if it has to be interpreted by the go runtime, it adds a lot of overhead.
I've been using Gogland since I got the email, also used phpstorm up until then. Only reason for me to switch really was what I'm hoping is going to be better native support for various things in this ide 
 gScore := make(map[Node]float64) fScore := make(map[Node]float64) openSet := make(map[Node]Node) closedSet := make(map[Node]bool) basically the hash of a user defined type isn't guaranteed to be deeply comparable. Dumping these maps will probably show a lot of errors in how the nodes are indexed. if your intent is to hash on their location, perhaps make a method for Node called Position() that returns the position as a unique value and map the key to position as a string instead of using the node itself.
Probably you need to manage a queue, could be implemented inside your Go program or with any solution like Nats.io
It's sort of a vague question, but I believe this is a good use case for Go and it might help to read this blog post about concurrency patterns in go: https://blog.golang.org/pipelines I think you are specifically going to look at the fan-in / fan-out patterns.
I lied. Some paths get stuck in a loop.
You're right it's pretty vague. I'm planning on writing a go version of a Java app that is in use(I didn't write it so I'm not sure what's totally involved. I wrote a service that feeds into it). I want to see what the performance difference would be. I'll read that article, thanks!
Looks like that would have been fun to write. Good job :)
The only problem is that I just paid for Sublime. O:-) Isn't there any way of using Delve with Sublime?
I'm not familiar with that book but something that helped me a great deal when I started with Go was joining the Gophers Slack channel. You can get some good recommendations there for learning resources as well as be able to ask questions in real-time. Good luck!
Probably pretty well. The code might get a bit verbose, especially for failure propagation, but goroutines are a pretty good model for this sort of thing. Sending off some requests and then doing stuff when the responses come in doesn't require major contortions code-wise, and the performance should be good. Thousands of concurrent reqs isn't anything to worry about. Use [Contexts](https://golang.org/pkg/context/) to manage cancellation of outstanding requests on failure, timeouts (overall and for various phases), and holding values that are needed several levels apart in the call stack. 
That means you shouldn't do things like func doSomething(ctx context.Context) { foo, ok := ctx.Value("foo").(string) if !ok { foo = defaultFoo } ... } Passing optional values through HTTP handler chains is somewhat different.
Oops. I didn't notice. :( Normally if I see I've posted a dupe that reddit didn't detect I delete it.
Fyi latest versions of Postgres support json data in your tables as well as traditional relational DB table columns (you can even have a combination of traditional columns and json data columns in the same table). Full support for querying and indexing on the json fields as well I believe. Best of both worlds
I am missing a lot of features of VS Code, but in some points Gogland is better. I liked the OOTB debugging of tests!!! I do not like that it has a slow startup and that the memory consumption is enormous (1,2 GB RAM). I miss the hover over a function and see the arguments... I miss go fmt on save... I miss auto remove of unneeded imports... I still use vs code for quick and dirty work!! 
Few things: * Someone who has barely touched the language probably isn't an authority to be writing how-to articles for other beginners who may not recognize some of the really bad practices(not even specific to Go) in this article * The docs on panic() found at https://blog.golang.org/defer-panic-and-recover tell you in a pretty straightforward manner how to use and recover from panics. This code either silently ignores errors or panics without ever recovering from them. * Authenication is determined by setting a global boolean. I'm still new to Go, but I'm pretty sure if one person is logged in then all requests are considered logged in because they check the same variable. Not to mention if they never explicitly log out they will always be considered logged in. Authentication via tokens or cookies or sessions should always be checked on a per request basis. * inconsistent with dealing with wrong HTTP methods. Some redirect, some send back an error code. Specifically allowed HTTP methods should be handled appropriately and all others should be responded with an error code. * http.Error() and http.Redirect() don't end your function or close the stream per Go http documentation at https://golang.org/pkg/net/http/. Thus, several of your handler functions send an error response or redirect response when the improper HTTP method is used, but then continue to execute the rest of the function as though the proper method were used with the request. I appreciate that people are eager to help newbies out with some tutorials and articles, especially for a relatively new language. But for the love of God, if you preface your tutorial with "I have only used this language for a week", reconsider posting a tutorial that may instill horrible practices to beginners. Many mistakes and bad practices you have in this article are things that would be easily avoided by skimming the documentation about the packages you are using, and the rest are just terrible practice regardless of what language you are programming in.
Perhaps the correct solution is detecting the loop and bailing out?
How much would they be?
Aussie marsupial Gopher. Hmm.
Did you intend to ignore everything from uglyFunc that is not *Foo? If so, leave a comment to indicate it is intentional. I don't like that non *Foo items are ignored. Since ulgyFunc returns []interface{}, the code needs to deal with that. Letting the type assertion panic is a valid way of dealing with this, and will even shorten your code.
I'd be interested in. 
Good question. I will certainly make it reasonable. It's not set in stone yet, and I'm not greedy as to I don't mind if I don't make much of a profit by it. It's more fun to get this out to people. I was also thinking to have it low initially as a thanks for my first supporters. What would you pay for it?
&gt; I do not like that it has a slow startup and that the memory consumption is enormous (1,2 GB RAM). All JetBrains IDEs are like that. There are tips and tricks to reduce it, basically it's disable stuff you don't need. But in a world where browsers take up GB of RAM an IDE doing it doesn't seem so bad.
Just a thought, but seeing as how it is often pretty easy for the user to spot this optimization, couldn't the compiler also in trivial cases make this optimization itself? Looking at playground code it seems for this case it probably wouldn't work though.
Me2 !!
I think there will be enough people to want it! BTW, you can also contact conferences organizers, they love to have cool swag.
Tests, prints and *thinking*! 
It has support for this, please see my reply here: https://www.reddit.com/r/golang/comments/5nlybr/is_anyone_here_using_the_new_ide_by_jetbrains/dcdewck/ Thank you.
&gt; Did you intend to ignore everything from uglyFunc that is not *Foo? My original code was returning an error in case the thing was not *Foo. But then I figured, if the thing is really not *Foo then there really nothing I can do so I might just well ignore it but maybe returning an error is better after all. &gt; Letting the type assertion panic is a valid way of dealing with this, and will even shorten your code. Can you show me how? In my original code it was `if !ok { return the error }`. I am not familiar with using panic. 
I use ctrl+click a lot to jump to the definition
&gt; would avoid needing to append constantly. In general, is append considered bad and why? I seem to be using it very often in my code so if it is not good please let me know.
I would for sure grab one.
yeah that too :) middle mouse click does the same thing.
Need more information on DB drivers!
ugh, iris 🤢
Awesome! My own comic strip. Thank you!
1. Fetch data 2. Slice data based on your condition 3. Render template 4. Handling the forms on the backend For more details read my tutorial :-) https://github.com/thewhitetulip/web-dev-golang-anti-textbook
You can read my open source tutorial https://github.com/thewhitetulip/web-dev-golang-anti-textbook I've also created a YouTube series, https://youtube.com/playlist?list=PL41psiCma00wgiTKkAZwJiwtLTdcyEyc4
would be great to see it open source / linked :)
I'd buy a couple.
In that same vein, is there any reason you couldn't just make the whole belly panel into a pocket instead? I know its more work but it could make it more useful as conference swag...
Hi /u/snippet2, Can you please give some more details about this? Gogland currently supports the following database engines: https://www.jetbrains.com/help/idea/2016.3/database-tool-window.html#d1483985e929 and the documentation from here: https://www.jetbrains.com/help/idea/2016.3/database-tool-window.html should apply to Gogland as well. If you have any troubles using it, please let me know or feel free to open an issue. Thank you.
Lol, /u/iris-go accidentally replied to this from his geekypanda_docker throwaway and then deleted the reply.
I saw that. LoL
Re stolen code: https://github.com/julienschmidt/httprouter/issues/148
How do you pronounce this? gog-land? go-gland?
It's super easy to learn, easiest depencency management story, CSP is really solid especially for things like socket pools, it has a lot of libraries, a lot of the innovation in devops comes from the gophers. Now to cover direct use cases. a. You need to scale up your team only knows some dynamicly typed lang with insert mvc framework here, and you have over 9000 resque/celery workers and you need something fast, b you are into making servers c You just want something that performs well, is easy to learn, and just compiles to one executable that you can just deploy. Honestly meh I like CSP just because I like seeing what I can do with it, but I mean it is not the magical beast people think it is. Many who do only find it so amazing because they only encountered the reactor loop in the past. What I hate about go is you do a lot of hand coding, people make a lot of stupid design choices in it including myself, people make bad decisions with concurreny and state.
Lol man this is hilarious! I am gonna make popcorn! P.S. I saw that as well.
I hadn't seen this, but I'm going to look now. Atom &amp; GoPlus have been a bit painful for working on separate projects + vendoring
If you use tha `cap` argument (that third one), and you append three times, then it will be `len(foo) = 3`. You can look at the playground link I posted above for an example of that. Instantiating it with `make([]string, 0, 5)` means that `append` won't trigger a memory allocation until you reach that capacity. Otherwise, you would trigger a memory allocation at the first append, then the second (since the underlying array is doubled each time), and then the fourth. In practice, you probably won't notice these allocations unless you're really trying to push the envelope, or you're doing a lot of appending to smallish slices, since the allocation cost is amortized the larger a slice you're using.
It's failing to load the gist for me unfortunately. I might try again over the weekend. I really recommend that you start with unit tests for your basic data structure manipulations. I think that will help to a certain extent with catching things where you might be passing copies rather than references and other gotchas.
I have already read these and I don't see a reason why not to use iris. It seems that you spamm these links everywhere. I was on the golang chat room and you send these to each one of the logged user, including myself. you should be shame. You might be interested on these too: https://raw.githubusercontent.com/iris-contrib/website/gh-pages/assets/comics/comic1.png and https://www.youtube.com/watch?v=jGx0LkuUs4A . 
&gt; I have already read these and I don't see a reason why not to use iris. It seems that you spamm these links everywhere. I was on the golang chat room and you send these to each one of the logged user, including myself. you should be shame. You might be interested on these too: https://raw.githubusercontent.com/iris-contrib/website/gh-pages/assets/comics/comic1.png and https://www.youtube.com/watch?v=jGx0LkuUs4A . Awesome! My own comic strip. Thank you! (again)
Is this an api gateway service perhaps?
Websockets or long-polling are good options for client notifications, and large file downloads can be broken up via Accept-Range headers, which can be handled automatically on the server-side using http.ServeContent.
What about editing and deleting github issues and faking benchmarks?!?!
make([]string, 0, 5) creates a slice of length zero, backed by an array of size 5. That is, it's essentially the same as: var bar [5]string foo := bar[0:0] with bar hidden in the background. len(foo) is 0 (the second argument to make). len(bar) is the cap of the slice foo (the third argument to make). If you append to foo and len(foo) is already 5, then Go needs to allocate a new bar, and point foo it, instead of the original.
Thanks. I haven't used websockets or long-polling before. Does HTTP/2 change the picture at all? Edit: How does long-polling get around the read/write timeouts?
And now you (/u/geekypanda_docker == /u/kataras) are even impersonating /u/dlsniper at https://www.bountysource.com/people/41977-kataras 🤣
If the author would have behaved in a different manner first time when the issue happened and wouldn't have gone back to the same practices a couple of months later, none of this would happen. But even after being told, explained and otherwise shown these issues, he still tries to put himself in a position where he's the victim of all of this. And the fact that he's using fake accounts, as pointed out by others, really does not help out.
Yeah I totally agree, I am just pointing out the irony. According to google translate, kataras translates to curse. 
&gt; I'm sure holding the request open and using long timeouts is not the right solution. Why?
It is.
It seems to be best practice, based on the reading I've done, that if you're exposing Go to the internet, you want to have server timeouts (and relatively short ones) so that possibly malicious connections can't be held open indefinitely. The examples I'm seeing are having timeouts of under a minute. Most in the realm of 10 seconds or so.
a service that is calling multiple api's, joining the data and returning it.
I will buy 2
Ok, perfect. About what I was thinking selling at too!
Would you be able to elaborate how you mean? Maybe do a quick drawing?
It certainly feels like quality too. Do you think a pink version is something your wife would like, or she is more into blue?
Thank you for replying.
Ok great! It's the ballpark I was thinking too actually. 
:)
Thanks! Great tip regarding conference organizers!
I guess you could mention how the author escapes from prison, disappears, comes back with a different mustache, arrested again, rinse and repeat. 
It's much more expandable and powerful in terms of plugins (i.e. it even has webkit &amp; gtk support). And it's graphical. It's a game changer for me as I want to preview-on-the-fly my LaTeX documents and I don't want to use some special software for it. I may not get used to it and eventually return back to Vim (neovim), but I just want to try it out as my daily driver. Someone names slow startup, etc. I personally don't care if it works as fast as Vim. I'll give it a try anyway :)
Definitely pink! We already have the official blue Gopher plushy, if we get the pink one from you then they will become a pair :D While I got your attention, if this effort is successful and if you feel like making the classic design in the future, I will buy that from you as well. All four different colors.
Indiegogo?
I'd buy a couple! 
That would be something that I cannot verify. And the author does these sort of things where he comments then deletes them way too often.
Mine are currently at 1m. Sometimes the calls my server is making to an external API (hosted by some other provider) can take 10s to 5m in time. Depends on the amount of data and whatnot. So it's really hard to gauge the duration. I suppose that particular endpoint in my server would have to set up to not trigger the action again once it's already processing. Then be able to send off the data once the next request comes in after it's completed. Thanks for the reply.
goʊglænd is how i say it. i'm using this [key](http://public.oed.com/how-to-use-the-oed/key-to-pronunciation/) It should sound like the g could be a soft h and there are no hard stops. It shouldn't sound like a Go.gland or a Gog.land, it's more like a (gh)ogueland.
I do something similar at a small scale using objects that manage requests and caching to each service to ensure that they're updated on schedule, based on events etc. You have to think it through to watch out for sending on closed channels and avoiding deadlocking the messaging of a service based on waiting for another, but it works well. In general, doing thousands of aggregations probably means you benefit from a bit of intelligence avoiding redundant queries that you have to wait for, high levels of concurrency and careful management of connection pools. However, if you have to do that much, it may be that there's a mismatch between the microservice APIs and the way that you want to actually use them, which would be worth trying to fix to reduce this issue.
In this situation, LibA import be: `github.com/foo/log.Logger ` as well, no? I think something is missing here, if this were true, then a lot of packages that imported logging library such as `Logrus` wouldn't work when imported.
It is pronounced Gogland, as the island it takes the name from: https://en.wikipedia.org/wiki/Gogland
It looks like the endpoints have changed but Gfycat lets you upload files to convert. It may take a long time so the server provides you a unique url that the client can request periodically to check on the progress. Once the processing is done the client gets a "processing done" response and can get the data The requests are cheap since it can return a simple string/json telling the client to keep checking back
I think conceptually context values are okay, note the word "values" as in more than one. I disagree with several implementation details of the entire package though that I think affect the usability as a whole including that of values. I won't deep dive here, mostly I just wish the context interface was implemented more in the spirit of package io. In the current implementation it's impossible to extend without caveats due to Stdlib asserting concrete types. I.e. For cancelation / propagation I don't know why they don't check if a context.Canceler{ Cancel() } interface is implemented.
 for _, u := range ugly { foo = append(foo, u.(*Foo)) } return foo Like that. You don't actually have to force it to panic, Go does it automatically if you try to do do a single value type assertion (i.e. you don't provide an error variable to the type assertion). If, for whatever reason, one of the variables in ugly isn't a *Foo, your program will panic and crash. If you don't want that to happen and have a way of dealing with, you can use a recover() in whatever calls SafeFunc. There's a good guide to defer, panic and recover at https://blog.golang.org/defer-panic-and-recover I agree with /u/nathankerr that it's probably bad that you're just going to ignore non *Foo items in that slice. If you think that it should never ever happen that a non *Foo item is in that slice, then use something like the code I put up above. You could also have SafeFunc return an error along with your slice of *Foo, but I don't think that's what you want. Based on the fact that you're only converting to a single type, I think you probably want to crash out the program if you get something like a string or an int in that slice.
For this reason and for the ability to edit XML structures at run time I started writing https://github.com/go-simplexml/simplexml. Not perfect, and still doesn't handle the missed data from unmarshal (yet), but is my go to when I have to deal with SOAP.
&gt; But what does it mean? You pointed to an example (db connections) and there are others like it (eg templates your app uses). Those are pretty obviously not suited for context values. The purpose of this post wasn't to start a thread where we point out the faults of the language, but to instead to discuss the types of issues people using context values this way have run into. Is it harder to understand where values are coming from? Is not having compile-time type checks on values you store in the context values actually causing issues to pop up in production? While I understand you have a strong opinion on this, you aren't really contributing to the discussion I wanted to have :(
You could make a tiny/local Logger interface (one without any custom types in it) and use that in signatures.
Yea it sucks, i don't actually *want* to vendor for my library, but my library also provides a binary. So i have a vendor in the package too, and thus, i introduce this problem.
[removed]
For large files, I'm tempted to delegate to a CCDN, like S3 or BitTorrent
Except that I literally hate using Visual Studio / VSCode (tried it). You won't ever come back to IDEs when you get used to something like Vim or Emacs. It just feels... _supercharged_. And yeah, the tooling is same, just a visual debugger.
This makes even more sense now! This sub is awesome. Putting middleware in context of avoiding logic duplication really helps. 
Delve? And what's wrong with GDB (aside from lack of decent UI in Emacs / Vim / anything)? I've tried LiteIDE, BTW. And it's quite good with debugging support! Though I want to stay in my editor.
I've been using Vim/Vi since the '90s and personally I've found the convenience of VSCode incredible. The ease of installation for plugins, the intellisense stuff, baked in git support etc. I like being able to just hover my mouse over a var and get a synopsis of the type, or over a function and get the function signature etc. Each to their own I guess :)
Perhaps one day I'll give it a second try. My number zero requirement: no mouse requirement. Do you use any vim-like plugins for your installation? EDIT: and yeah, how's the debugging there? I'm OK to use mouse to place a breakpoint :)
I've used [vim-bootstrap](http://www.vim-bootstrap.com/) to set up and manage the plugins for the various languages I develop in and it's great but I have no qualms about mouse usage. All of my servers have vim set up with my vim-bootstrap config and it's great but if I'm coding on my local machine and I just want things convenient I use VSCode. Edit: Honestly, I mostly debug with print statements. I write short test cases in a scratch folder to play with different ways of approaching a problem and then implement what works best :)
Looks like your question was answered below, but feel free to ask further questions if you have them. If you are coming from another background like Rails you can think of middleware as a `before_filter` or `before_action` often declared in a controller concern (see http://elegantbrew.tumblr.com/post/70990048275/controller-concerns-in-rails-4 for an example). There are other forms of Middleware in Rails, but what you expect to be a `before_action` in Rails will often be a MW in Go. 
I meant if you use any plugins for VSCode that makes it like Vim in terms of editing, like [VSCodeVim](https://github.com/VSCodeVim/Vim). And awesome thanks for pointing me to vim-bootstrap!
From the link I read, "regex are slow in Go" Is that true? I recall hearing that early in Go (years ago), but benchmarks compared to PCRE seem to be very very close, and Go is also guaranteed to have linear time, where complexity could increase PCRE time exponentially in some cases. Perhaps that wouldn't happen in a small querystring, but if you can process hundreds of megabytes in a couple seconds using Go, a query string should be almost no time at all, even if it's 20% slower than PCRE.
Ah, no I just use vscode go plugin for go development. I tried vscodevim and felt that modal editing wasn't a very good fit for vscode.
Try out https://github.com/mailgun/godebug It isn't Sublime specific, but will likely cover a majority of your use cases. 
Thanks!
Some past discussions around iris: https://www.reddit.com/r/golang/comments/57w79c/why_you_really_should_stop_using_iris/ and https://www.reddit.com/r/golang/comments/57tmp1/why_you_should_not_use_iris_for_your_go_projects/ More recently, one in which the author of this post is proven to impersonate me by another user: https://www.reddit.com/r/golang/comments/5nqz6v/oauth_20_authorization_server_middleware_for_iris/ Please stay away from this person and projects until he publicly apologizes for all the issues he's been involved in and learns how to work with others in the open-source community and respect their work. Thank you. Edit: I also recommend http://gobuffalo.io/ if you really want a web framework for Go. It is recommended by the community and the author was featured in the episode 29 of GoTimeFM, https://changelog.com/gotime/29
No its still there. But I screen shot it in case it gets edited http://imgur.com/U5NvpuF
Ah, my bad, I took the quotes literally w/o reading all text. Cheers.
I second that, was looking for an alternative to webtranslateit!
Also i like your code, i'm taking out some ideas for my own api project.
Context.Value is great. It has not made my programs any harder to reason about; in fact, it makes it easier to reason about because I don't have to use non-standard way to pipe in request scoped values.
I can definitely envision myself using this as a sex toy.
You're right, I'm aware of that ;-)
Without getting into the "why iris is bad" talk I will point out this - the author of this library violated (aka removed the authors) licenses of other people and their works on several occasions. They were nice to him, politely asking to add license docs back, and he did. Then he removed the licenses again. I'm not going to talk about how it is good or bad. I'll only say this - this is a subject for DMCA strike. So if you choose to built your software using iris - please be aware that original repo can vanish at any time. 
Funny, that was one of [my first go projects](https://github.com/retzkek/cloudflare-ddns)! :)
Took the words right out of my mouth.
I'd buy one 
One of the shitty things about the current state of Go :(
Details?
https://blog.gopheracademy.com/advent-2016/saga-go-dependency-management/ If the package management committee is successful, there will be a tool that will help ease the pains of vendoring. For example, the tool should be able to strip/hoist the vendored dependencies of LibA. In the mean time, do what you have to.
Do tell first.
Please do not re-cycle an old -when iris was just a router- issue which has been solved months ago, in order to advertise other friend's (good or not) frameworks. Go has a small community, Iris won a big part of the people trust and love (https://www.youtube.com/watch?v=jGx0LkuUs4A ) and that's because of code code code and code every day and every night. It brings new ideas and features to the community, it's a win-win for all, you should be happy for the existence of Iris. I have understand that you may don't respect yourself when you spamming such as these links on chat and reddit but I'm asking you: at least respect the people behind this excellent community. Thanks.
Aaaand it was edited :) His specialty.
Haha. Thanks for putting that image in my head. :)
If you can't complete a task in a second or two, you should instead return a new unique URL that can be polled or web socketed to find out when the task has completed. Don't just leave the client hanging on forever while you do some slow DB work or file transformations or whatever. 
Yeah it seems like some sort of task engine is a popular choice. I know libraries exist for Python. I haven't looked to see what Go has to offer. Anything in the std lib? 
&gt; Almost all projects have dependencies Using a dependency (including potentially vendoring it) is one thing. Copying the code into your repo, then removing the license is literally copyright infringement, even if you make modifications afterward. That, and the attitude of deflecting or erasing any criticism, definitely left a bad impression on some people. That's hard to change. Honestly, the whole attitude of either deleting individual issues/pull requests or hiding the issues section entirely just makes it really hard to put any trust in your accountability. Criticism is hard. We all know that. But being thin-skinned is not the answer. Making comics mocking your critics is not the answer. Deleting issues is not the answer. Using obviously fake accounts is not the answer. Open source has evolved to be about more than just the code (if it ever was). It's about discussion and collaboration. Trying to stifle that and getting defensive flies against the spirit of an open community. Open doesn't mean uncritical, it doesn't mean nice, it just means open.
I don't use context for passing argument to handlers. I use this pattern instead: https://golang.org/doc/articles/wiki/#tmp_12 It's type safe and works like a charm. And I don't have any issue with not implementing the http.HandlerFunc in my final handler since it's usually not reusable anyway. Middleware handlers I use before still implement http.HandlerFunc. While I think that context.Context is a good solution for things like cancellation I prefer to have explicit arguments in my handlers.
At the time of my reply only the parts you quoted were edited. Goes to show how he does open source. 
If he apologizes and starts doing the right things I don't see why people can't get a second chance. But this hasn't happened yet and worse it seems to continue down the same path.
The API is still in flux and once stabilized, (most of) the package will likely migrate to 'gonum/fit', but it's already useful as it is. Comments/feedback greatly appreciated.
I think it might be better if libraries would not expose interfaces to anything they have vendor'ed. If this is needed, the library should expose it using an interface that is either in the Stdlib or is defined in the library. (Or alternatively type aliasing) I think instead of removing the /cmd/ folder, I'd rather establish best practise that a library should not expose foreign interfaces outside the stdlib.
No, you shouldn't put a vendor folder anywhere other than the root of a repo.
&gt; the old issue was about the ~90 lines of code (of the total of 24.000 lines of code across all the iris relative packages I did code.) and it has been solved by private e-mail and @dlsniper knows that because the same guy told to him to stop writing his name. It doesn't matter if it's 10 lines of code or 1000, copyright infringement is still a problem if you do not attribute the original code from the place you've taken it. The same issue then happened again a few months later when you "mistakenly" removed all the licenses. And flattening the history of your git repository without at least mentioning those whom sent PRs you've merged back in the past is also taking away their contributions. &gt; So go again, why you don't like Iris? Because the project leadership is broken &gt; do you have any better alternatives to show us? Yes, of course, http://gobuffalo.io/ for example :) Now go, tear that one apart as well. Say how the author and contributors are my friends and other such lies.
lol ... nice one ... How did i miss that :) 
For a lot of us who have to still deal with legacy system ... I just skip go or write a proxy that translate the request to soap 
I would argue that the project itself also benefits. GORM was quite buggy and unstable at the beginning but grew in quality and stability with more people starring and using it. More users -&gt; more feedback, more traction, more PRs and so on.
I second that. I am just getting into Go, and it is nice to see a real project to get some ideas from.
Yeah, definitely. It's just a shame that some of the really good projects out there struggle so much to get a bit of attention.
Hey, you may want to refresh your Let's Encrypt certificate for your homepage, or better use golang.org/x/crypto/acme.
If this is in a book I recommend a new book.
This sounds great, thank you!
If Renee is fine with i, I guess you are ok.
Authentication and user info are the most common. I've also put in runtime mutable application config information that can be inject in each request then each request won't have it change out from under them.
After refactoring the cors code, dropping the custom types, this is better (IOW: nested handlers without dependencies are preferable): cors("*", "SomeHeader, AnotherHeader")(yourHandler) func cors(origs, hdrs string) func(http.Handler) http.Handler { return func(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { if r.Method != http.MethodOptions|| r.Header.Get("Origin") == "" { next.ServeHTTP(w, r) return } rw.Header().Set("Access-Control-Allow-Origin", origs) rw.Header().Set("Access-Control-Allow-Headers", hdrs) next.ServeHTTP(w, r) }) } } It's worth noting that there is a fundamental difference in how the above handles "ACA-Methods". I prefer to have the router handle that since it's already receiving the information. For example, I wrap the router and have a method "OptionsAuto" which filters requests based on which methods have been previously set on the route. Headers can be handled in the above middleware, or in the router method, but it's probably best in the above middleware. *Edit to add - Also, I prefer to check the request origin, then return the requested/validated origin back to the client rather than returning a full list of origins allowed. Showing all allowed origins feels like a leak of info to me, but I'm ~~probably~~ paranoid.
&gt; ./weed master lol wat
yup
It strikes me as strange that it is called a file system when it doesn't have almost any of the features of a file system, it really just seems like a key value store.
This has been asked many times by different people. But what is a file system? GFS or HDFS is for storing large files. SeaweedFS is for storing small files. Anything that can store files and optimize for storing files can be called file system. POSIX is not a criteria for file system. It is a key~file store. It's a different way to manage files. That's my 2 cents. 
makes you more creative. :) not from personal experience.
Ch-Ch-Ch-Chip 'n Dale!
Let's say you had middleware that authenticates a user (and looks them up in the DB during this process). How do you provide that information to other handlers down the chain? Or do you look it up again? Or do you stop using the `http.Handler` and start using a custom function def at that point? There are pros &amp; cons to each of those approaches imo, but I'm curious which one you have found success with (or possibly something I didn't list).
I am the author of Gleam actually. I would like to know what's the cost to invoke LuaJIT via go. Since Gleam is stream processing large amount of data, does it cost too much to switch context between go and Lua for each datum?
Perhaps the hash should be done on "foo.tar", not "foo.tar.gz". Other than wanting to check the hash, why else would you want the .gz file?
The linked page doesn't seem to allow ctrl-click to open the projects in a new windows. Then a browser back always moves to the top of the page. Annoying.