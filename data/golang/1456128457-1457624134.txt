Yeah, I played around with it and got lost configuring it. Was a fan of nginx, but now mainly working with self-contained web servers/microservices. Also needed a common solution for my old TCP modbus devices. And UDP, does anyone know a DTLS implementation in Go?
It looks like you're missing a defer on the unlock within Context.copy. I like that you have CORS on here and an extensible middleware system. That means I could add logging, authentication, and all the other things I'd need in a real app. I don't use mongo, and I'm not sure I could hook this up to a different data store without modifying the framework itself. I also prefer goji's use of net/x/context because it's immutable and is what some other libraries, such as pat and appengine, use for request-scoped values. It looked like you're doing a bunch of unnecessary manual json decoding for the config; I'm not sure why you didn't just use encoding/json.Unmarshal.
&gt; It looks like you're missing a defer on the unlock within Context.copy I should have spent more time looking into the 3rd party libraries I'm using, because the context part is coming from [Stack](https://github.com/alexedwards/stack). Thanks for that. &gt; I don't use mongo, and I'm not sure I could hook this up to a different data store without modifying the framework itself. Unfortunately, I haven't documented any of the APIs or how exactly to use the system itself. My bad, but you *can* use any DB you like, just that you'll have to add all the required functionalities on your own, and you can set it inside the *Globals* struct, *App*, which is a `map of string of interface`. &gt;It looked like you're doing a bunch of unnecessary manual json decoding for the config; I'm not sure why you didn't just use encoding/json.Unmarshal. True, I should have. Again, I'm using a 3rd party library to read JSON ([Simple Json](https://github.com/bitly/go-simplejson)), why I did this is so that you can include any config in your JSON file, not just the framework's. And you wouldn't have to define a struct to read it. And I thought I could let the *unnecessary* json reading stuff slip, since it's only a one time thing, when starting up the server. **Thanks a lot for the feedback!** P.S: I will be updating the [webgo-sample](https://github.com/bnkamalesh/webgo-sample), showing how to use all the APIs of the framework.
Nice! Looking forward to testing it. Thanks for sharing :)
Check out Caddy - not sure that it meets all the features you're looking for, but configuration is a breeze and HTTPS automatic: https://caddyserver.com
The only effort of making Go (or a subset of it) available for Arduino that I know of is this one here: https://twitter.com/rakyll/status/626138782799020032
[**@rakyll**](https://twitter.com/rakyll/) &gt; [2015-07-28 21:14 UTC](https://twitter.com/rakyll/status/626138782799020032) &gt; import "arduino" &gt; &gt; Targeting a small subset of Go, writing a compiler to bring Go to Arduino boards. \#golang &gt;[[Attached pic]](http://pbs.twimg.com/media/CLB954gUkAEex3A.jpg) [[Imgur rehost]](http://i.imgur.com/1sjdgZ2.jpg) &gt;[[Attached pic]](http://pbs.twimg.com/media/CLB95tuVAAAm9Bc.png) [[Imgur rehost]](http://i.imgur.com/HJU3Qhk.png) ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Don't think there is a lot of go usage in Munich. But here is a group to network with. http://www.meetup.com/Munich-Gophers-Go-User-Group/
The performance and stability is way better than hipache in node :) #golang
oh my god, don't you want to handle errors in package that deals with money?
/u/dgryski don't get me wrong, I thank you for all the cool links you've shared so far and I hope you'll continue to do the same. I've learned a lot from them. I'm not saying that negative comments / rants against Go should not be linked here. What I'm saying is that there's no technical merit for them, there's no suggestion on how to overcome them and, the worst of all, it's clear that the author hasn't even bothered to read the manual before criticizing the language. To top all of that, there's no form of commenting available so that any type of positive, constructive exchange can happen. That's why I think those types of links shouldn't be here (what you refer as curating the content).
The spec says: &gt; The method set of the corresponding pointer type `*T` is the set of all methods declared with receiver `*T` or `T` (that is, it also contains the method set of `T`). This rule could be read as applying to arbitrary layers of indirection, or it could be read as applying to a single layer of indirection. Automatic double-dereferencing is now considered a bug and was [fixed in Go 1.4](https://golang.org/doc/go1.4#methodonpointertopointer), indicating that the second interpretation is correct. If this change broke your code, dereference once using `*` (thus converting `**T` into `*T`) and call whatever methods you want.
Hi, do you know fabio from ebay ? (https://github.com/eBay/fabio) Isn't it similar ?
Oh I had no idea that's how it was done with Django as well, I assumed it was structured similar to Rails. TIL! 
Two ways you could communicate with a running Go binary: using some sort of API over http or using RPC. But are fairly straightforward. Take a look at the net/http and rpc packages. 
You can write very small programs in Go and call them repeatedly; they can be initiated and/or terminated without major. Because Go is compiled and lean there isn't a substantial wait for a virtual machine to start up each time. You do not have to be scared of treating them like 'scripts' in that regard. Communication between running programs is a common, common need. It is resolved different ways depending on the situation, and every general-purpose programming language has several possible answers, Go is no exception. One of the simplest, and from your description, possibly most appropriate for your situation is to have shell script(s) calling your program(s) and supplying them with arguments. This method works regardless of if you have written your scripts in Perl, Go, or most any other language. If your server was going to be triggered on simple criteria (once a minute, do X), then [Bash](http://www.tldp.org/LDP/Bash-Beginners-Guide/html/Bash-Beginners-Guide.html#chap_02) and [Cron](https://en.wikipedia.org/wiki/Cron) would be all you need in addition to your collection of simple perl/go programs. Another way to fulfill exactly the architecture you're imagining is [RPC](https://www.cs.cf.ac.uk/Dave/C/node33.html). You would write your "mini" applications to expose a [RPC interface](https://golang.org/pkg/net/rpc/), and then they would stay running all the time. When you wanted them to actually do something your server would call them via RPC to trigger it. Depending on how your home automation things are connected, you can also use wireless protocols like [ZigBee](https://github.com/ninjasphere/go-zigbee) directly in go instead of RCP over TCP/IP. For a much more "heavy weight" connection, you can do what virtually all web applications do: communicate via a database. Your server would put rows into a "tasks" database (for example), and your "mini programs" would query the database periodically and take action based on what they get back.
Could be due to the C -&gt; Go conversion tool.
Ok I can understand valid criticism. But with companies like IBM and SpaceX starting to use/support Go aren't articles like these foolish? I mean seriously "I can't copy and paste, don't know how to download a binary, can't understand objects and pointers, can't tab autocomplete file names... " I mean even if your company isn't using Go do you want hire someone that sounds so limited? Why not just say to yourself I'm not a fan of this style of language and move on to the next?
Write it like Effective Go shows, then go read the blog.golang.org posting on profiling by Russ Cox. Jeff
It could be, or it could be an attempt to make sure the runtime crashes when it gets into a bad state where a pointer is null that shouldn't be (there was a star in the original code that reddit formatting ate..), or it could be for some other reason. I'm not that familiar with the code, there's just some things like that that feels like something that someone who knows the code did intentionally and I don't entirely trust an automated tool to guess at even if it *should* be logically equivalent..
The stars are just dereferencing. It's probably something like: `*(*uint32)(unsafe.Pointer(&amp;something[0]))` Which converts the first 32 bits of `something` into a uint32. The added conversation (AFAIK) does nothing because you've already got a uint32. I haven't had my coffee yet, but the only thing the added conversion would protect against is assignment, since it'd make assignment illegal and assigning to the above expression writes to the memory where `something` resides.
I know that the stars are for dereferencing. I was just pointing out that reddit rendered star bracket star as an emphasized bracket, and not a dereferenced pointer in my original comment and I used the word "star" so that it didn't happen again..
Would you wrap middleware that need access to app wide variables in the same way? That was my major concern using that method.
Sure, suppose your middleware is created through a function or method, e.g. *MyMiddleware(someAppVariable)*. You call that in your server/route initialization.
Go. Not GoLang, not golang, not Golang. Just Go.
I clicked to get useful notes but it was nothing like that! Don't bother opening.
What country is the meeting?
If the app requires a database (or any other external service) it'd probably be nice to get Vagrant (or Docker Compose or whatever alternative you like best) to manage it for you.
The relevant section of the spec is: https://golang.org/ref/spec#Selectors Specifically: &gt; For a value x of type T or \*T **where T is not a pointer or interface type**, x.f denotes the field or method at the shallowest depth in T where there is such an f. The spec should probably specify that the T in &gt; The method set of any other type T consists of all methods declared with receiver type T. should be a *named* type. The fact that it can't be a pointer type would then be implied by: &gt; The receiver is specified via an extra parameter section preceding the method name. That parameter section must declare a single non-variadic parameter, the receiver. Its type must be of the form T or \*T (possibly using parentheses) **where T is a type name**. The type denoted by T is called the receiver base type; **it must not be a pointer or interface type** and it must be declared in the same package as the method. Honestly, the language around methods has always been difficult to get right because of the interactions between selectors, method sets, and method promotion from anonymous fields.
Which idea?
I work at NY Times, we use Go. We hire for Go. Here's our career's page which has at least 2 jobs that reference Go http://www.nytco.com/careers/Technology/#
Best I can think of is either a function variable with the right strong types and `reflect.MakeFunc`, or code generation. Something like this should be achievable: func fooOld(n int, s string) (*T, error) { ... } func fooNew(n int, s string) (*T, error) { ... } foo := fooOld // old value of foo used as control, // varargs for candidates at the end exp := labassistant.Experiment("optimize-foo", &amp;foo, fooNew) exp.SetCompare(cmpFoo) // ... t, err := foo(42, "bar") 
Glide is really good. Already using it for all our projects.
That's not what we usually call configuration, but ok. There's plenty of options for bundling asset files in the binary, e.g. https://github.com/tv42/becky is the simplest thing I could make that provides file contents available as variables, https://github.com/rakyll/statik gives you a `http.FileSystem`, https://godoc.org/github.com/jteeuwen/go-bindata has approximately 3 kitchen sinks in it.
I build go-1.4 in `~/src/go-1.4`, used it to bootstrap `~/src/go-1.5` and `~/src/go-1.6`. Symlinks in `~/bin` make them all callable with no messing with environment: $ find bin/go bin/gofmt bin/go-1.* -printf '%p -&gt; %l\n' bin/go -&gt; go-1.6 bin/gofmt -&gt; /home/tv/src/go-1.6/bin/gofmt bin/go-1.4 -&gt; /home/tv/src/go-1.4/bin/go bin/go-1.5 -&gt; /home/tv/src/go-1.5/bin/go bin/go-1.6 -&gt; /home/tv/src/go-1.6/bin/go 
@lordmatrix Thanks for your kind words. This is more than something Glide can accomplish. For example, packages need to start tagging release versions. If there is something you liked about the post I know others would appreciate knowing the parts you do and don't like.
Hi go-team, thanks for this great tool. I'd really like to see issue 11058 fixed. Be able to build dlls on windows will be great for interoperation with many languages (I think about AutoIt that I really like, particularly for making GUIs). Thanks!
MediaMath also hiring Go engineers in NY, Chicago. https://careers-mediamath.icims.com/jobs/2380/software-engineering%2c-full-stack---media-intelligence/job You can also contact me if you want to know more about it.
This looks nice. Really really nice. Seems to solve all the problems my dirty bash script package manager does, but properly.
This issue is also interesting background reading on this subject: https://github.com/golang/go/issues/13517 It might be worth coming up with a clear and very short call to action for people releasing code which all tools can agree on - * Please tag your releases with semver (v1.0.1 etc) * Check in a manifest file (and possibly lock file) * ~~Don't check in vendored dependencies~~ (edit - controversial) My wishlist for a vendoring tool is quite simple: * versioned packages (we mostly have this) * vendor dir (we now have this) * vendor/manifest.json for humans to edit showing what is required/requested (we don't have this) * vendor/lock.json for a lock file showing what is used (we don't have this) Both file formats probably need to accept commit hashes, even though they really should record semver tags ideally. json as yaml is complex and not in stdlib. That current tools all have their own pet format and file locations etc puts me off using them. So the biggest step forward we can now take is to attempt to define a standard format for lock and manifest which is not tool-dependent or named after a tool and could be used by the standard tools in time. I do think the doom and gloom around this is a little over-egged - the situation is totally fine just now with the latest pkg/vendor dir changes it just takes a little more work to resolve dependencies manually as required, and tools will come in time. While there are lots of complex problems around resolving dependencies automatically, at present humans can do it just fine at the cost of more work, and if the above was right those could be tackled in time. At the moment these tools are too balkanised and there are too many of them, each with their own file format. 
A few things to consider. 1) I've personally spoken with people who've not chosen Go (looking to Rust and Swift), walked away from Go, or are quite frustrated with Go because of package management. Go has hit a growth plateau. For some of us trying to onboard people to Go this is a roadblock. Maybe not for you. But, it's a roadblock. 2) Details matter. Putting files, like a manifest or a lock file, in the vendor/ directory isn't a good idea. If you want to ignore it you have a problem. Ignoring the vendor/ directory is important for most libraries that may still use it for development. There are lots of little details that matter. 3) There are some who don't agree on a need SemVer (or versions at all) or a manifest file. If we could agree on SemVer, manifests, and a lock file we could do so much. Some have expressed that we should not use versions or a manifest. If we implement just one part we won't have a solution. We are on our way to something better.
I think this sums the issue up entirely. 
I'm trying to understand your perspective. I honestly think that pip and npm are much better than Go for package management. Why exactly do you think they are worse than what we have with 1.6? 
I think you're half right here. Rob Pike worked on Plan 9 and kept compile times small by managing headers and includes well. His initial work at Google I think was to fix a mess of build times and systems within Google in C/C++. Go initially used Makefiles to build packages, directly invoking compilers and linkers. Then a few build tools sprang up that didn't require Makefiles at all. One of the more popular ones was called "gb" (this is what Dave's tool was named after). That tool used paths to resolve packages. From here the go maintainers merged that idea into what we now know as the "go" build tool that uses $GOPATH before go1 was released. Google doesn't actually use the "go" command internally, but a system like http://bazel.io/ . GOPATH *is* similar to a monorepo in many respects, but I think that is more happenstance than explicit design. I think it ended up this way because a lot of users really liked not having project files or package descriptors or make files. Perfect? Probably not. What makes go different is that each file has a fully qualified path to the source (spatial, not temporal). Every other language I'm aware of doesn't have this property. I agree we do need a way to pin dependencies in time. I'm not arguing against you, more to the side :). I don't care if the solution for go looks like everyone else; fact is, your car analogy is perfect. I've driven lots of vehicles, sometimes empty, sometimes full with trailers. They handle *very* differently and the controls will widely vary. You need a different skill set to drive a large-ish truck with 5-speed manual with a browning then a 3 speed automatic (yeah, auto's used to only have three gears). But that diversity is good. The truck's control is designed one way, a commuter is designed another way. Let go your desire for conformity and let's design a solution best suited to go. Because more information is available from looking at source file dependency trees, I think we can use a tool heavy approach, rather than a edit file and sync approach that will be a better end user experience for go devs. 
FWIW, as someone who does hiring, this sounds like a terrible idea. You're advertising yourself as someone who makes arguments while *literally* not knowing what you're talking about -- saying Go can replace C while not knowing C. Have you considered just being humble and saying that you know Go and haven't done C but feel confident you could pick it up quickly given your Go experience?
&gt; Don't check in vendored dependencies I agree with most of the post but not this. It is up to the author of an application/package to check in vendored dependencies. The benefits of checked-in dependencies are quite significant to blindly recommend to avoid them: - reproducible builds no matter what happens to the upstream (cases like rewritten history, deleted repository, github is down, etc) - an application can be installed with just "go get" - faster build times
Vendored dependencies should be flattened most of the time. It can be done manually or using some tools. To be honest coming from Java I didn't even consider non-flattened transitive dependencies. Possibly developers who are coming from other languages (JavaScript?) need more time to become comfortable with this idea.
i think you can try to find a job which you can wfh 2-3days a week over the hill. the commute is not that bad :)
Yes, but that's the section on selectors. Method sets don't explicitly depend on selectors in the spec (though conceptually they fall out of the combination of selectors and addressability). In order for the method set spec to be complete, it needs to specify that T is a named type or else tie it to selectors in some way. I think the language around method sets was changed in order to accommodate unnamed struct types with promoted methods, but it went too far in the other direction.
I was using Sublime for a last 2, 3 years. Recently I started using Atom. It was annoying for the first week or so ,for me to get comfortable, but it end up to be really good. As a Sublime user I suggest you to try Atom if you can. Go works better in Atom. Otherwise I was also using GoSublime.
gosublime is nice but not necessary now, you could be using https://github.com/golang/sublime-build . Also notable is the go oracle tool https://github.com/waigani/GoOracle 
Who says everyone agrees on a 'lock file'. Assuming you mean an additional file outside your 'dependency file'
ah you're so right :) You know I guess I'm just dreaming of startups moving over to my side of the city...
"The path for major API version is a Go thing. It's not intuitive. Someone had to tell me. And, many Go developers just don't do it. If they did there would be no reason for gopkg.in." Yes, it's a Go thing. So is no classes, no exceptions, and GOPATH. If there's a repo that doesn't respect the idea of the import path as a major version (i.e. no breaking changes), then don't use that code. I must disagree with your statement that many developers don't do that. In my experience they do, at least anyone with any experience writing go code. Pretty much any Go library I have used that is not specifically stated as "still in flux" has a hard lock on keeping the API backwards compatible. If there's a repo that doesn't do that... don't use their code. And yes, gopkg.in means you don't need to use a separate repo per version, just a separate branch (like normal people). So.. what's the problem? Someone had to tell you about it? Someone probably had to tell you about using ./... with the go tool, too. So what? You mentioned dependency hell with diamond dependencies... except that is actually completely solved in Go. It's not possible for B and C to import different versions of D... there IS only one version of D... HEAD of that repo. If it were a different version, it would be a different import path, and thus a completely different package. I never actually heard a problem that you are trying to solve other than "other languages work this way, so Go should too"... which is kind of a silly argument. The other argument you have is that people are walking away from Go because of it... to the contrary, it seems like a pretty lively community. Tons of companies dealing with networked servers are using it. Sure, there's always going to be grumpy people who don't want to learn a new way of doing things, but so what? They'd probably just leave due to lack of exceptions or some other BS.
`go get` clones the repo so the `.git` is included.
Just for the record, "latest gccgo" compiled app is a bit slower, than go1.6 compiled one, 700 compared to 600 for the same computation (-O3 enabled). There seems to be no magic left. Thanks for all the suggestions.
- why are you panic-ing everywhere? just return - use the inline if err:=....; err !=nil - never ommit the err ex (data, _ := json.Marshal(object)) - json.NewDecoder(r).Decode(x) instead of json.Unmarshal 
[What growth plateau??](https://www.google.com/trends/explore#q=Golang)
That works fine for me in Sublime. Did you have gocode running?
Let me make sure that it's the same thing. Let's say that you have defined a struct myStruct in structs.go In you main.go, you have autcomplete working for myStruct ? 
I'm sure this is already here (somewhere). But I thought it was about time for a reminder given recent posts on the golang-nuts ml. previous discussion: https://www.reddit.com/r/programming/comments/19rtbn/benign_data_races_what_could_possibly_go_wrong/
&gt; In my experience they do, at least anyone with any experience writing go code. Most libraries are careful not to introduce breaking changes (because if they want to be go gettable there is no choice). In the very long term though that is not sustainable and changing paths for breaking changes is an ugly and impractical solution - I think the article was saying hardly anyone does that (which is true), not that no-one is maintaining a non-breaking API. I don't really want to use a central package manager like gopkg.in (which actually feels more contrary to the spirit of Go pkg management to me), or put versions in the urls, I'd rather just use tools to manage dependencies within ./vendor. Dave Cheney seriously tried versioned urls and found it [terrible](https://github.com/golang/go/issues/12302#issuecomment-137301778). It *is* really nice to have non-breaking APIs forced upon us in Go, and that's something which I would be sad to lose completely, but it is necc. sometimes to break an API at some point. For example in the go language itself there are a few warts which it would be nice to clean up in a v2 - I don't think at that point we have all our std lib import paths change, it'd be a mess and cause endless confusion. Better just to communicate clearly, fix any code and move on. The problem they are trying to solve is certainly real, if only suffered by some people (open source authors of larger libraries used by other people, consumers of such libraries). I agree the hyperbole is not accurate or helpful and actively harms the author's case. The solution though is just to build the tools - I think rsc said it best on the same [issue](https://github.com/golang/go/issues/12302#issuecomment-159017534). 
Vendoring is just fine for applications. As for libraries, don't manage anything. Make sure it works with master of your dependencies because that's what the majority of Go developers will use anyway. I use Maven with Java, and Go with godeps, let me tell you I'd much rather have godeps than Maven.
If you manage to get venture capital funding for a smokin' weed, chillin' &amp; surfin' based web platform I would like to be your first employee. Sorry, I only know .NET ¯\_(ツ)_/¯
Sounds like sarcasm to me (well, the whole post does).
What is this 64? https://github.com/narqo/go-badge/blob/1650d0cdc85951e530d6d9d96dfbd9bd735235f7/badge/badge.go#L48
However the cars work, not everyone will want to use them -- a lot of people are fine with manually vendoring/managing git submodules. Also, even if most/all people - including those who don't "drive cars" - decide to provide manifests for their libraries, it won't happen overnight. So the package manager can't operate on the closed world assumption that every library has the metadata it needs.
&gt; Because they is a convention that library developers adhere: you don't break backwards compatibility. This is one of the biggest reasons why there is such clusterfuck with deps. I can dig out 10 years old Perl script, update deps to latest version and at most cases I'll just get some warnings like "you might want to use X instead, this is legacy" from lib. Not a chance with Ruby code, I've seen functionality added, deprecated and removed within few months and without major version bump. Shit goes in, shit goes out, it is impossible to make a decent dep system with that, only approximate and hope it wont explode
Yep, it works. Don't forget to save structs.go to affect autocomplete
Yeah! This looks weird for me as well. This magic has came from my "googling/stackoverflowing" about how to convert `fixed.Int26_6` results of the [Drawer.MeasureString](https://godoc.org/golang.org/x/image/font#Drawer.MeasureString) to float64 pixels.
Package managers are a bad idea. Code should be portable and work wherever, and shouldn't need to be "bundled" or whatever. It should just fit in. The following are a list of package managers that I know of, and have worked with in the last 12 months on at least one project. * pip * easy_install * npm * bower * bundler * composer * cpan * nuget * sbt * maven * lua-rocks None of these have a consistent interface, work differently and with different concepts, are prone to third-party sites breaking/going down, often do not build or "compile" properly, have ghost errors, etc. etc. etc. I could go on forever. You don't need it. Especially when you have a complied language.
Bundler is not part of Ruby, it's a gem that has to be installed separately. The only piece thing that is part of Ruby is `gem`. 
FYI oracle (from golang.org/x/tools) has been renamed to guru.
Have you tried GOGC=off?
Oh, you want to reuse npm for Go? That's an interesting idea...
GOGC does not "give more memory"
So, I work with Dave on Juju, and I would not qualify it as terrible. Yes, the churn when you change the version of a commonly imported package is annoying... however, it is a really easy, mechanical change. The most annoying problem came when we had two different repos importing different versions of the gopkg.in/yaml library, and one of those repos then imported the other one. Because the yaml libraries behaved slightly differently, and because we do a lot of round trips through yaml, it caused problems. For libraries that don't do round trips through plaintext, I don't think it would be much of a problem, because you'd just get compile errors. It was kind of a pain to detangle, mostly because we're doing some things wrong in Juju that makes it harder on ourselves than it should be. However, this kind of problem would happen with externally defined versioning as well (like if you had a config file that would set what version to use for the yaml package).... because then your code could break without any changes being made to it. At least with import paths as versions, there's a very clear reason for breakage, and a very clear idea of what parts of the code you need to be concerned about when the version of a dependent repo changes. Versions as import paths also make it easy to avoid importing two different versions of a library... you can write tests for such a case (and I believe Dave did so for the yaml package). This helps when merging in code from people whose branches are significantly behind master, who may have added references to the old version of yaml. To be clear, I don't think Dave's entirely wrong, but I don't think the answer is to go whole hog and make Go work just like other languages, either, which is what the OP seems to be asking for.
&gt;The GOGC variable sets the initial garbage collection target percentage. A collection is triggered when the ratio of freshly allocated data to live data remaining after the previous collection reaches this percentage. The default is GOGC=100. Setting GOGC=off disables the garbage collector entirely. The runtime/debug package's SetGCPercent function allows changing this percentage at run time. Seehttps://golang.org/pkg/runtime/debug/#SetGCPercent. https://golang.org/pkg/runtime/
You might've just hit shit libs, I'm not saying all of them have good backward compability, but a lot of them works pretty well
It becomes marginally faster. However turning GC off might be ok for a command line utility that quickly does its job and quits (like a compiler). Turning it off for a web application is not desireable. 
Could you please elaborate? From https://golang.org/pkg/runtime/ &gt; The GOGC variable sets the initial garbage collection target percentage. A collection is triggered when the ratio of freshly allocated data to live data remaining after the previous collection reaches this percentage. Effectevely by giving an application more memory you make GC run less frequently thus freeing some CPU time for the application.
I currently use the [faster implementation of Protocol buffers](https://github.com/gogo/protobuf), but you should check if `gob` or even `JSON` isn't fast enough for you. To clarify: I only use protobuf because instead of rendering templates I use [gRPC](http://grpc.io) and had to write the protobuf defintions anyway.
Is this a permanent effect for the built application, or does it just affect the go tool while building?
The advice applies to any application written in Go though. And it is so easy to try and see if a larger GOGC value makes any difference for your application. Compare this with 1000 JVM GC options ;)
About what? About not wasting his time implementing SSLv2?
Yeah I thought of that, except the data I'll be dealing with will be all different structs. And I don't want to reflect over the struct fields to pull them into a new map[string]interface{}, that just seems like doing double duty with `encoding/json` and not really performant.
Thanks for the well explained answer. I'll have a look at what you've suggested and it definetly helped me to get a grasp on it. Thanks!
Honestly, most of the problems with Ruby are Rails-related. I never worry about things breaking when upgrading my regular Ruby utilities, but every time I go to upgrade a Rails app I get nervous.
Embedding won't help. The [encoding rules](https://godoc.org/encoding/json#Marshal) state that embedded interface types are always keyed.
I don't think there is any way to reliably do that, except with reflection. You could try something like `str = "{\"timestamp\": 123456789," + str[1:]` with `str` being the json encoding of the value. But that would break if the encoded value itself contains a field `timestamp`. Or if the encoded value is an array, instead of an object (or even a string, number,boolean…).
Another way would be to encode, decode into map[string]interface{}, adding timestamp, encode.
&gt; With respect I think you should rethink that, and also the use of yaml. Yeah. When I saw YAML was required, I decided to walk swiftly in the opposite direction.
FWIW, I think this is more portable solution that will work with older go compilers - http://play.golang.org/p/UJKpqBHNG2 package main import ( "fmt" "time" ) func main() { now := time.Now() cm := now.Month() // current month cy := now.Year() // current year nm := (time.Month)((int)(cm)%12 + 1) // next month (wrapping if necessary) ny := cy // year of the next month if cm &gt; nm { // Next year if we cross Dec/Jan boundary. ny++ } // Get current time zone. loc := now.Location() // Calculate time differences between first day of the current and first day of the following month. diff := time.Date(ny, nm, 1, 0, 0, 0, 0, loc).Sub(time.Date(cy, cm, 1, 0, 0, 0, 0, loc)) // Calculate number of seconds in current month as int. secs := (int)(diff.Seconds()) // Calculate number of days in current month as int. days := (int)(diff.Hours()) / 24 fmt.Println(secs, days) } 
Atom is too slow for my tastes, is horrible for larger files, and randomly crashes far too often.
It's not semantic although I'd admit pedantic. When stated as-is it indicates the OP doesn't fully understand why result was achieved. Giving you a +1 though as you ran the point to ground.
You should check the encoded result to see if it marshals to a JSON object. Reflection isn't likely to give you the right result because the underlying object could implement JSONMarshaller even if it's a int. Something like this: http://play.golang.org/p/ZT-O2h4zfo
&gt; The profile of these openings have changed a bit too. In 2014, Go was used as a bait to attract talented people into companies where Go was not the main piece of their technology stack. Sounds familiar. I'm hoping to move from PHP to full-time Go and applied for what I thought was a Go development position at the end of 2015. The first thing they asked was how much experience I have in Python.
And this write up ("How To Fix The Go Package Management Problem") doesn't get the facts straight. Apparently your definition of "sharing culture of open source" doesn't include the actual history of open source and free software and is limited to some new millennium toy language subculture. And this is not a "Go thing". This is how we have been developing *open source* libraries for *decades*. What is new is, breaking changes within the same major version, and this weird culture is all thanks to web scripting (javascript/ruby/python/php/etc.) people. If this isn't intuitive or I had to spell it out for you, try to learn more about the history and culture of programming and open source --which didn't start with bootstrap and nodejs.
&gt; Reflection isn't likely to give you the right result because the underlying object could implement JSONMarshaller even if it's a int. The json-package only uses reflection itself. So I disagree with this statement. In fact, the simplest and most robust way to do what OP wants is probably to copy-paste the relevant parts of json and then add the code in there directly.
You're missing the point. Bundler is de facto part of ruby. It would take quite the reclusive rubyist to avoid having to learn bundler, these days. It's been downloaded more than 72 million times according to rubygems.org.
I've also always seen this working. You have to make sure that everything you are working on is in your GOPATH and that your GOPATH is configured in the GoSublime env settings. Once you have that you should see completion across all objects imported from any package 
if you can guarantee they are all structures (and not just raw slices or values), you could do something like this: https://play.golang.org/p/AXoh1fQYyp
Its just another article where someone used Go for a quick moment and then ran off to write a blog post acting as a well informed assessment. 
Great for Solaris users, Linux users would have to wait for gdb :( My point was just an example how a debugger can be a working horse to eliminate production issues, and can't easily be replaced. Not mdb per se. (this is the reason things like Delve aren't a full solution).
You forgot "conda" from your list. 3 python package managers!
does this support switching to forks without rewriting all your import statements? package aliasing is the reason I've started using glide (previously used Godeps) https://github.com/Masterminds/glide
First rule about go package mgmt: don't talk about go pkg mgmt. 
I &lt;3 G1GC.
had a similar problem some time ago. [look here](https://play.golang.org/p/N6kaxQhlMr) 
Try wrk (https://github.com/wg/wrk), it can create a lot of requests to simulate a high traffic situation.
Is the project open source? Edit: Nevermind, I think I found it: [gochan](https://github.com/Eggbertx/gochan)
Yeah, that's it.
I'm sorry, you're right. I *thought* Bundler was officially in the Ruby distribution these days, but I guess not. I like to think of `gem` as existing for only one purpose: to run `gem install bundler`. :)
Nope not senior only, also heres internships http://www.nytco.com/careers/Student-Jobs/#T10
Take a look at the link I posted -- it's very efficient, simple, and generic, and you can explicitly handle a non-struct JSON result however you like.
By the way, an important caveat: If the structure that you are marshaling already has a "ts" field, then you will end up with two "ts" fields in the generated struct. This is valid JSON, but the Go code won't know what to do with it and will probably corrupt your data when you decode it. Most language libraries have inconsistent handling of repeated keys in JSON data.
It doesn't matter whether the community adopts it unanimously. The fact of the matter (and the point you miss) is that it's a third party solution. **Ruby does not provide bundler**. So why does Go have to provide a solution like that? We already have third party solutions that do these things. Eventually the community will unify towards one and we will have our "bundler."
Well it has to exist for more. Bundler uses it behind the scenes I imagine. 
&gt; It's a trade off that works well in your case where you evidently have plenty of memory to play with, but in a more memory constrained environment it's not necessarily such a good idea. There is no such thing as a free lunch. There is always a trade off.
I understand it. I don't think you do. It says in its description that it's the ratio used to determine when the collection of garbage happens. That's it. That's what the value is for. I would hazard there a point where this would actually _decrease_ the amount of memory used by the application because the memory would be tied up waiting on a sweep to start. The wording is very clear. 
I'm aware it is third party. Your lack of response to the substantive portions of munificent's post implied you weren't understanding his point. I apologize, as it seems like you're just looking to snipe.
The garbage collection mechanism primarily used by the JVM
I a Go only solution is sufficient then just use Go. It's the most convenient solution to use: No external description of your datastructure needed, best support for datatypes (afaik no time.Time on Protobuf for example) and the performance is much better than json. It's also quite conventient to add or remove fields.
&gt; I would hazard there a point where this would actually decrease the amount of memory used by the application because the memory would be tied up waiting on a sweep to start. I must admit that I do not understand this statement. Can you please explain? Certainly increasing GOGC will result in an application requesting more memory from OS.
Your example shows the package text/template when you should use html/template for page renders.
I think it has plateaued for people writing tens of lines of code that requires hundreds of libraries. 
Fuck the web sites that don't even display a fucking text without the fucking javascript.
Your point isn't clear
Fucking terrible on mobile with the initial scrolling.
Apologies, I'm not a front-ender, I bought a theme for Ghost and installed it. I'll look into it. 
From your post from source: &gt; The GOGC variable sets the initial garbage collection target percentage. A collection is triggered when the ratio of freshly allocated data to live data remaining after the previous collection reaches this percentage. First things first let's assume our program over the course of its run consumes a total of X bytes. This is the amount of memory used in total, not the amount it uses at any given time. This is just space allocated on the heap and stack as it does its work. If we took a slice before a garbage collection sweep we might see Y bytes in use and immediately after the seep it might be actively using Z bytes (where Z &lt; Y) due to memory being freed. No memory was "created," instead memory that had no more references in love code was released and potentially reordered (I honestly don't know the specifics of the Go GC). Now let's break this documentation down. &gt; The GOGC variable sets the initial garbage collection target percentage. What we can gather is the value of GOGC is a percentage. Usually used in cases where 0-100 is significant. I'm not sure what "initial" is meant here, could mean it's not the permanent value but just the first time they need a value this is where they get it. But right off the bat no mention of memory, I would hazard if this had a direct impact on memory given to the program we would have already been made aware of it. Lets move on anyways. &gt; A collection is triggered when the ratio [...] reaches this percentage. (We'll look at the omission next) So now we see the significance. Whatever this percentage is of its used to trigger a collection. With a name like GOGC and the "collection" I'm going to immediately assume we're talking a GC sweep which _frees_ memory no longer in use by the program. It does more, but for this we don't care about that. This would be that collection that will clear up I used chunks of memory for us (be thankful we don't have to free or delete memory!). So the question now is what is it a ratio of? &gt; ... freshly allocated data to live data remaining after the previous collection ... So when data that has been allocated (memory taken by this program) divided by the amount of live (I assume they mean available) memory that was last after the last collection. So on you case when the amount of data allocated is 20 times the amount of remaining available data to consume then another garbage collection is started. But still no mention of giving memory, just discussing at what threshold the GC of used/available memory the GC starts a sweep. Now. Our program hasn't changed and is not altered. So over its lifetime it _still_ consumes only X bytes. So even if we did give it more memory it would be wasted unless we constantly kept heap and stack space full with active memory, most likely we won't. --- Now. What does that have to do with my statement? &gt; I would hazard there a point where this would actually decrease the amount of memory used by the application because the memory would be tied up waiting on a sweep to start. First let's note that said "I would hazard" so I'm guessing. This could be incorrect but I think its true. Now, since we've previously established thenGOGC value is a ratio of active/free memory the assumption was made that at some point the ratio could be set such that there is a build up of unused, allocated memory that we can't use until the next sweep of the GC and we need to allocate some number of bytes greater than we have available. Now since I've made this comment I've taken on this leading tons crash rather than a "pause." Still an assumption either way. --- So my theory is you mounded stood GOGC and based on that you played with it and it coincidentally seemed to do what you expected it to do. When in reality the speed up is most likely associated to reducing the number of times the GC pauses and runs during the runtime of the program. That's my theory. 
Great! All the developers in the website picture look young.
No. I concluded you were wrong based on the definition you used to defend your stance and my knowledge of how memory is allocated to a process, used by a program and why a GC is beneficial.
I wouldn't take it personal. Javascript just seems to be getting out of hand again. My laptop browser actually choked on the initial scroll.
whats truly frightening is that php *does* actually try to offer some concurrency (well, async) features, despite no language support i never knew anyone to use them, its just too scary to think about
Agreed, it's nice to work with a language that was made in the thick of the web era — basic web functionality is baked in. BTW, a minor fix: in the section on "Syntax," I think you meant to say that "Go's language designers have been *explicit* from the outset." Because they have.
Does anyone knows of any open source non-trivial web application written in Go that people can checkout to learn stuffs? I played around with Go, and one of my first impression with it is that its gonna be quite a pain in the ass to write a server-rendered web application in it given how limited the available templating systems are compared to those available in the Ruby/Python/PHP world. I can see how that issue being much less of a concern if it is being used for an API. Also, another thing I noticed is obviously how goroutines can help with asynchronous operations without having to rely on another task queue systems, but wouldn't you have to offload the tasks to an outside task broker if you want to have the task being processed by multiple machines anyway? 
I know DigitalOcean hires Go developers. Pretty sure they're in Soho. 
Obviously the author doesn't understand Java well enough.
I had a similar impression. I started playing with Go and pointed it at some APIs. It was SUCH a pain in the ass because you needed to decode the JSON into a struct. I was using the forecast.io API which returns a massive, nested JSON object. It gets even worse when your endpoint might not always return JSON in the exact same way every time (depending on your query). This article sums up all the problems I was having with it: https://eager.io/blog/go-and-json/ I feel like Go would be great if you were porting some known code to it. I appreciate why Go is the way it is, and the benefits that come with it. However, due to the static typing and pedantic nature of Go, it's a pain in the ass to prototype stuff with it.
I see you edit your posts without noting they're edited. That's a lot of information to silently edit in. You're confirming my suspicions. &gt; This means memory allocated since the last GC. "Live data" means all the data that is reachable from the root set (stack and global variables) via pointers, i.e. all data that shouldn't be garbage collected. This is exactly what I meant. You still reference memory. The GOGC documentation says nothing about changing the amount of memory. Longer periods between GC pauses (which I would associate to larger values of GOGC) would result in _more memory_ having to be processed by the GC but fewer GC pauses. For smaller values you see more GC pauses but smaller amounts of memory to process. Either way the total amount of memory available to the programs is the same, and the total amount of memory used by the program is the same so changing this value _has no effect on increasing the memory available to your program_. 
Nothing changes the amount of memory potentially available to modern applications. The amount of memory available is the size of virtual memory. The application has no control over it. It's set by the OS and physical hardware. Pedantically speaking, "increase the size of memory" is wrong, but anyone interpreting it should understand the meaning, which is to consume more memory at one time due to less aggressive GC cleanup. 
looks like you're running not just the build but all tests too, which fail at the tests specifically expecting periodic GC to work. instead just use make.bash: $ export GOGC=off $ time ./make.bash 2&gt; /dev/null ##### Building Go bootstrap tool. cmd/dist ##### Building Go toolchain using /Users/.../go1.4. ##### Building go_bootstrap for host, darwin/amd64. ##### Building packages and commands for darwin/amd64. --- Installed Go for darwin/amd64 in /Users/.../go Installed commands in /Users/.../go/bin real 0m48.378s user 2m0.226s sys 0m13.555s $ echo $? 0 
Interesting. In a talk about rewriting the compiler in Go, Rob Pike mentions that one reason the old C-based compiler is/was faster is that it never frees allocated memory, since it knows that it's only going to be alive for a few seconds. This puts the new compiler on even footing. 
&gt;it's a pain in the ass to prototype stuff with it As far as prototyping stuff goes, I wouldn't even consider Go. I wouldn't even consider it for the first several versions of a webapp. I find it really good for optimizing certain parts of the application that can greatly benefit from concurrency though. At this point, I can only see Go as an optimization tool, certainly not something that I would consider to build a web application from scratch. The overhead of its limitation is overweights the *potential* benefit it offers.
Yes - it seems like Go is really, really good at optimizing a known solution to a known problem.
wrk allows you to write custom Lua to generate request bodies, POSTs, etc. 
Also: don't use FastCGI in Go. The FCGI server hasn't been optimized and is substantially lower than the HTTP server. Reverse proxy over HTTP (i.e. nginx to Go). 
Apologies for editing the post without noting. I've added "Updated:" comment now. Don't get me wrong, I am not trying to prove that you are wrong. But from your posts we either completely misunderstand each other or you seem to be mistaken. I could be completely wrong too but so far I haven't seen any convincing arguments ;) The amount of memory available to a program is limited by OS (e.g. by setting appropriate ulimits) and hardware. However the amount of memory that is allocated by a program has direct relationship to the GOGC value. In fact it is very easy to check. If you run the following program http://play.golang.org/p/snRk6E_7qt with GODEBUG=gctrace=1 and different GOGC values you will see that with GOGC=100 the maximum heap size is 4mb, while with GOGC=2000 the maximum heap size is 80Mb. Resident size of the program (from top output) also different with different GOGC values. 
These are all technically JSON dialects due to the constraints of the data environment they are being parsed into, so anything is really fair game. Your "would be expected" may get some applications into trouble. JSON has no notion of duplicate keys, and there are absolutely JSON use cases for a set that can handle duplicates. Go could get away with a custom interface for JSON objects instead of a map, or just live with a slice, to enable that behavior. That's really the problem, there's not a straightforward way to represent this nuance of JSON. Specifically, map[name][]interface{} instead of map[name]interface{}? But then everybody trips up on this and its kinda annoying to always have to deal with iterating over slices of interfaces in translated JSON objects. interface{} type assertions are there already though, I personally wouldn't mind. In my opinion that Decode call should return an error, as the struct does not match the JSON definition.
Done. Here's my rebuttal -- what you're looking at proves my point. I ran your sample with GOGC set to 100 (it's default value). &gt; gc 19705 @11.937s 12%: 0.004+0.16+0.042 ms clock, 0.034+0/0.060/0.044+0.34 ms cpu, 4-&gt;4-&gt;0 MB, 5 MB goal, 8 P So we had 19,705 GC passes, and you can see here `4-&gt;4-&gt;0 MB` the size of the data the GC is looking at before, during (?) and afterwards. I'm pretty confident in the first value and last, not quite so on the middle but it's fine. So yea, with GOGC at it's default the program uses about ~4 MB of heap space per GC run. So then I run with your magic number, 2000, which I've already established should (based on my theory) run the GC fewer times and only when 20 times the amount of space was consumed. &gt; gc 978 @9.600s 1%: 0.004+0.18+0.049 ms clock, 0.032+0/0.058/0.083+0.39 ms cpu, 80-&gt;80-&gt;0 MB, 84 MB goal, 8 P Well, the GC ran 978 times, not too far off the previous run count / 20 but I feel that's a coincidence. The usage line looks to have proven your point! We see `80-&gt;80-&gt;0 MB` which is definitely more than 4, but how much more? Exactly 20 times more. So we have fewer GC sweeps overall and more Heap size going into a GC sweep. Nothing has changed -- in fact you gave the garbage collector _more_ memory to sweep but made it run far less times. About 10k fewer, to be exact (on this program, during that execution, on my laptop). The memory usage by the program hasn't changed, just the amount of time and allocated memory before memory is cleaned up by the garbage collector. Changing GOGC can't change how much memory the program allocates. This sample program _still_ allocates the amount of memory necessary to what you programmed it to. It just gets cleaned either more (for smaller values of GOGC) or less (for larger values) often than it normally would have. A source I recommend (which also taught me a something too): http://dave.cheney.net/tag/godebug **edit** I was partially right, but still wrong. #-&gt;#-&gt;# MB heap size at GC start, at GC end, and live heap # MB goal goal heap size Accidentally pulled the "MB" into the heap print outs. That doesn't change my points made.
The golang talks on YouTube were what hooked me. Project layout takes practice, just put everything in main, then go overboard with packages, then you'll go back to center with a good way to split. Understanding the value of interface types goes along with this, which is maybe a ways down the road. You are going to have a tough time delivering something if your entire team is not very experienced with software projects. Go makes many things better, but there's a lot to know before knowing what better is.
I don't see your point at all. Duplicate keys in JSON are either dropped (in the case of `jsonb` after conversion to the storage format -- again last value applies). Postgres `json` stores JSON as text and will honor duplicate keys but only the last value. The languages I posted that parse JSON, a pretty standard action now-a-days, all handle duplicate keys the exact same way -- the last value applied. JSON is not magical, it's a key value store. You can think of each parsing of a key/value sets the value on the appropriate data structure so a duplicate key just overwrites it. JSON (or JavaScript Object Notation) is based on how objects are defined in JavaScript and was pulled directly from valid JavaScript syntax. I would very much expect the behavior would also be carried over (as it had). I see no danger in duplicate keys or depending on them being gracefully handled. As far as Go returning an error it's because it does not validate the JSON matches the value you give it. Let's see this in action [here](http://play.golang.org/p/JIRaSWEh4S). Everything is hunky dory. This is probably due to the fact that a major use case of JSON may be to omit fields that don't change, or are necessary during certain types of requests. I'm sure that's not why they left validation out but it's a perfect use case for not having validation like you're mentioning. Duplicate keys aren't a problem and shouldn't be. **edit** fix play.golang.org link An online JSON validator says JSON with duplicate keys is valid, however it does not there are duplicate keys with a warning -- no error though. It's not a good idea, but by no means is it an error or malformed JSON.
&gt; The memory usage by the program hasn't changed, just the amount of time and allocated memory before memory is cleaned up by the garbage collector. Changing GOGC can't change how much memory the program allocates. This sample program still allocates the amount of memory necessary to what you programmed it to. It just gets cleaned either more (for smaller values of GOGC) or less (for larger values) often than it normally would have. I believe by "allocates" you mean "the program requests memory from the Go runtime". In my previous posts by "allocates" I meant "the Go runtime requests memory from the OS". Note that after a single GC run the memory is not released to the OS immediately. If the program keeps creating objects with the same rate the heap size will not shrink. Of course the size and number of objects created by Go program do not change with different GOGC values. However the amount of memory requested from the OS (physical memory used by the program) is different. 
Go is also very good at refactoring, that make it a good language for prototyping.
Look into the timeout command 
What?
Your starting to confuse me. Are you trying to say that because it's not mention in either of those locations we should expect behavior wildly different than what should happen (slice values as opposed to single values) rather than more simple method that was already the behavior in the language that inspired JSON? I really don't understand your point. My point: duplicate keys are treated the same way in every implementation of a JSON parser I have used (silently ignored, last value applies) which is the behavior I would expect. Does that mean I approve of duplicate keys? No. That usually means you've hacked something together as most map representations of JSON prior to string conversion function in such way that _they_ don't handle duplicate keys. But they don't fail if you assign the same key two different values. They use the last value. 
I disagree. Go lets you decode unstructured JSON (look at /r/skidooer example in a sibling comment). Go is perfectly okay to develop a prototype. The static factoring helps a lot in refactoring quickly.
The output of go trace does not show amount of memory requested from the OS. It shows heaps pace the garbage collector is concerned with. 
Nice article. Thanks. &gt; Go's not really object oriented Why would you say that? It is object oriented. It just hasn't got inheritance - which is a good thing in my opinion. 
You can use `top` output to confirm. Let me ask a question. If a program doesn't use more resources (such as CPU and RAM) how can it finish sooner? If setting GOGC to a larger value gives you guaranteed performance increase without increased memory usage why the default value is so low? 
For the Go compiler these strings are opaque import paths, they have no meaning and for the Go compiler (and linker) you can use whatever you like. And there is the go tool which is typically used to build, run install and download Go packages (the go tool invokes the compiler, linker, etc.). The go tool subcommand get (go get &lt;packagename&gt;) _knows_ about several public code repositories like github which makes such packages "go getable" which is very nice. So this convention has nothing to do with the language but the typical tooling used to distribute, download and build Go code: the go tool.
I mean that 'go get' is a part of Go (like others go tools). It's in the design of Go to have common tools.
Ah, thanks. Guess that's convenient, I'm used to PHP's [composer](http://getcomposer.org) where we'd [define all](https://getcomposer.org/doc/02-libraries.md) the packages in a file and their versioning and use their namespace when necessary. Is there a way to manage packages from github repos without directly inserting them into the import or import aliases?
What's especially infuriating is that all the content is actually there in the page, but opacity is set to 0, and I'm guessing that some JavaScript is supposed to gradually raise it to make the text "fade in".
Yes, I mostly use VS Code instead. Similar in concept, better performance from what I can tell, but fewer plugins. However, it does support Go with the corresponding plugin.
Woah! I had no idea you could do that!
&gt; Is there a way to manage packages from github repos **without directly inserting them into the import** You seem to be having some kind of issue... maybe it would help to tell us what that is instead of asking about potential solutions? &gt; or import aliases? It's not clear what you mean by this. It doesn't seem to make sense in this context. 
Yeah, I'm not too comfortable with Rails and the magic it comes with either, which is why I am attracted to Go and its promise of simplicity coupled with powerful standard library in the first place. I just didn't expect it to come with this much of an overhead as well. I find frameworks like Django/Flask/Laravel to be just at the right level of abstraction for me. It relieves me of many of the "solved problems" right out of the box and I can still easily dive into the source code if I want to see how certain things work. I find the whole "Javascript fatigue" thing is mostly caused by the overpromise &amp; hype by many of the latest frameworks. Many of these frameworks claim to be a breakthrough in building a web app while leaving out the limitation in came to have for enabling the shiny &amp; exciting part of the frameworks, and in order work around these limitations you have to use another tool that also comes with its own limitations and the cycle repeats itself. I think the key is just not to buy into the hype too much and don't set your expectation too high. 
Please help me to improve it. Thanks.
There shouldn't be a " (double quote) after the last line. That's what's causing the errors.
You should remove the " after } and run the code like this: go run main.go
Was referring to the Unix timeout command. E.g timeout 10m ./program
If you're done with the official docs, start reading the official lib directly. It is very well put together. Copying its style would be a great place to start (or even stay!) and you'll be even more familiar with the standard tools. Don't neglect the tests, either.
Well, it depends on how you define what OO really is. Lacking things Java (eg) has does not disqualify a language to be considered OO. In my opinion, go's approach encourages a better way of using OO than other languages do (in particular: composition over inheritance).
Maybe something like: import "time" import "os" func main() { select { default: myCode() case &lt;-time.After(10 * time.Minute): return } } ?
moddingHills, thanks for the kind words. I do plan to cover more topics on Go at https://medium.com/learning-the-go-porgramming-language 
You've confused categories of variables (primitive vs reference) with types of variables (e.g. "textual, numeric, boolean, pointer, composite, function, and interface values."). 
Would this run everything past the case &lt;-time.After ? So like in my script I have the following block of code: for _, nickname := range nicknames() { if conn, err := kahoot.NewConn(gamePin); err != nil { fmt.Fprintln(os.Stderr, "failed to connect:", err) os.Exit(1) } else { defer conn.GracefulClose() conn.Login(nickname) } } If I added the function you're suggesting to say, the top of my program, would it run the rest of the program diligently until that 10 minute timer was reached? Thank you for the input, nonetheless!
The webserver would need permission to execute the file.
Alright, thanks for the help.
yes
One advice I have is that the package name and the name at the end of the import path should match. It can be confusing to import something under one name but refer to it with a different name. 
I argue for duplicate keys because I see myself using them in a JSON format sometime. I want an unordered collection type in Go too. map[*atype]struct{} is the best there is today. JSON is a really beautiful specification in its simplicity. One of the best things in computing in my opinion, anybody can write a parser and read raw JSON data easy. I've used custom parsers that match this collection spec detail. I like that Go has this struct approach, and that the json APIs will reject anything that doesn't match the struct. Good way to catch bugs, and sending duplicate keys in a map-style collection is likely a bug in many cases.
I agree that duplicate keys are usually the sign of the bug, but in one of my other posts I specifically pointed out that Go 'encoding/json' does not validation on structure matching. Unless you're referring to that it ignores them silently in which case that is indeed what it does.
Oh hey, I saw you play once - yeh if you can do good Go then you should be able to afford the commute, which is great fun when its going smooth. I'm doing Go up in the city for myself, hit me up in a PM if you want code review or free consulting. I can't afford to pay anybody today.
Its not much cheaper than the bay unfortunately. For startups networking is important, hence the focus on places like Mountain View.
Locks are a terrible design pattern for distributed systems. If you must use mutual exclusion, use leases. 
I was pretty sure I clearly answered this. When running with `GOGC=2000` the final gctrace was: &gt; gc 978 @9.600s 1%: 0.004+0.18+0.049 ms clock, 0.032+0/0.058/0.083+0.39 ms cpu, 80-&gt;80-&gt;0 MB, 84 MB goal, 8 P And with `GOGC=100` it was: &gt; gc 19705 @11.937s 12%: 0.004+0.16+0.042 ms clock, 0.034+0/0.060/0.044+0.34 ms cpu, 4-&gt;4-&gt;0 MB, 5 MB goal, 8 P If we break it apart we see that with `GOGC=2000` (which runs the GC less often) the GC ran 18,727 times. That's a lot. We can see form the `GOGC=100` sample that the final gctrace says that 11.937 seconds after the program started this GC sweep began, and overall 12% of programs runtime was spent in the GC. 12% of 11.937 seconds or 1.43244 seconds was spent running the GC alone. Now since we're running gctrace we'd also want to account for printing every line but since we ran gctrace for both executions we're really looking at I/O time for the extra 18,727 times the GC ran. If we look at the `GOGC=2000` we see that the last print occurred 9.6 seconds into the programs runtime with 1% of the time spent in the GC, or 0.096 seconds which is far less time than the previous. We've also touched on the significantly fewer amount of I/O operations that occurred for this execution due to fewer GC sweeps. So how is it possible? Quite easily, actually. Fewer GC pauses, fewer I/O writes (in the case of using gctrace) can easily lead to "faster" runtimes. 
A small but reasonably important nitpick: The article conflates string values with string literals, claiming the former represent UTF-8 encoded text. String literals are guaranteed to be UTF-8 encoded values by virtue of the requirement that all Go source code be UTF-8 encoded. String values are simply immutable consecutive bytes and have no prerequisite of being valid UTF-8: http://play.golang.org/p/GFou-DO0BF Otherwise, it seems to be a good introduction to the basic types available in Go. Good job!
It isn't just about github, the thing about Go is that they didn't want something like Pypi maybe, and that's why it is easier to fetch remote repos if you name your package as the URL of the git repo. you can have your own git server on the internet in place of github and it'll still work. This doesn't mean that user/stringutil won't work, just that you won't be able to distribute the package since it won't understand where the user/stringutil is located (again because there is no pypi kind of thing for go) But for private projects which you do not want to distribute over the internet you can surely use that kind of package name, go doesn't forbid us from doing so.
You may be interested in etcdv3's upcoming distributed lock implementation; the early version can be found at https://github.com/coreos/etcd/blob/master/contrib/recipes/mutex.go
Sure, i will take a look at it, thanks :)
On my mobile device, your theme works flawlessly. I appreciate the post and agree with you on many points. Keep posting!
Is manually specifying the caller id really necessary? If it's a per-instance thing, just generate a guid for it. 
blast from the past... back in the days I was using wily a port of acme for linux.
It could certainly do the http calls without the library. Would keep size down considerably.
So for example, type Circle struct { x, y, r float64 } is a reference type for you? I don't see it that way, because you can pass a Circle to a function and there are absolutely no pointers involved. The entire thing gets shoved on the stack, exactly as if you were passing the three float64s as individual arguments. In fact, the x86 can load the entire struct into float registers as a single instruction. &gt; Structs, classes, strings, arrays, slices, etc. are referenced types since they are stored in memory as blobs and the programming language (or library) interprets its value. x86 has string instructions, and some arrays are natively implementable in raw machine instructions (e.g. byte, word or float arrays), so the meaning isn't Go-dependent. And on the other hand, bytes and words have no inherent type to the CPU -- the detail of whether they are uint8 or int8 is up to Go. And then when you consider Java, the instruction set includes class and array support. So I don't think your distinction matches how people actually talk about primitive vs reference types.
Great read, I like that they explain why Go is a particularly good solution to this specific problem (CPU bound not IO bound) vs. NodeJS. 
They did some things wrong IMO. I had to solve exactly the same problem in exactly the same language. One thing is the city-&gt;geofence index. That's a fantastic data point to index on, however the mistake comes with their concurrency solution. Store/Load Pointer is the correct way. I'm not sure why they said it was brittle. Every reader just copies the pointer to the current map, and then you only need to synchronize the writers (or have just 1 writer). The writer with create a new map, copy all entries from the current map into it, and then StorePointer to it. Right now the RW lock costs them on every single query but it sounds like there's going to be a huge read/write ratio so it definitely makes sense to go immutable.
It would have been interesting if they could show some measured performance impacts on the same workload. Also would be interesting to know the read write ratio. 
The ability to pass by value does not make a non-primitive type a primitive one. I suggest you go read some literature if you need further background. (FYI The x86 does have string instructions but its argument is the starting address of the string) To get back to the assertion incorrectly made by vvivien, Java has all the standard types of Go and is strongly typed. Vvivien apparently read "two kinds of types" in the Java spec and mistakenly interpreted that as Java has only two data types. 
Having the geofences sharded by city in the serving part sounds quite bad. If they used precalculated rectangle lat/long based shards, the first lookup would be free.
So basically Go is becoming PHP of 2010s :)
Definitely more useful than your pointless comment.
Consul has a lock feature out of the box. It's super easy to use. https://godoc.org/github.com/hashicorp/consul/api#Lock 
Yeah, dismissing the whole concept of R-trees seemed like a misstep there. You don't need a full-blown R-tree (which, as they state, is difficult to get right) to get some/most of the benefits of the idea. Pre-classifying the geofences (which seem to change relatively rarely) into a grid of lat-lon rectangles that they intersect gives you that fast initial lookup without doing point-polygon for each city. That also makes things more tunable. Grouping by city only works while each city has a reasonable number of polygons. Grouping by intersections-on-a-grid allows you to tighten the grid each time you find yourself dealing with too many actual polygons.
&gt; It's not really OO If you want to keep arguing in that direction, nothing but Smalltalk is "really" OO (maybe except Lisp), and if you stretch it, you'd really have to go for some hypothetical actor language with receiver matching or something. The reason why that section says "and no" is that interfaces are not the only kind of value in Go.
No a slice is a dynamic array. ~~Arrays and~~ slices are always references not values in Go.
Thanks. It's OK. So, change the project name to 'etcdsync'? 
Thanks. I think that make sense. But the implement of `Watch` interface is a litter bit complicated. Maybe I should have a try latterly.
This. Syntax highlighting comes via vim-go, automatic formatting too. Auto-completion, I'd like to know others' solutions, as I've never used it, but check out YouCompleteMe vim plugin. .vim example (but check out the help for information on each of these, sorry for the lack of comments): let g:go_fmt_autosave = 1 let g:go_fmt_command = "goimports" let g:go_highlight_functions = 1 let g:go_highlight_methods = 1 let g:go_highlight_structs = 1 let g:go_highlight_operators = 1 let g:go_highlight_build_constraints = 1 Essentially, you should consider a dotfiles repo to keep you vim config in sync between machines (if relevant for your use case).
If there's a specific error that you want to be exported and you have a good use case, I doubt the package maintainer would be opposed to the change. I can't think of an instance where a change like that wouldn't be backwards compatible. Exporting every possible error would be overkill and it makes more sense to keep it simple until you know you need to make a distinction between them. Go's interfaces let things like this grow organically.
I don't have an answer, but I'm interested in why you need to use x-forwarding. I don't have experience with x-forwarding, but I imagine that running emacs in an SSH terminal session, transfering a few ANSI characters at a time, would be a whole lot faster than transfering x-window data. Just a guess, but I can't really think of how the vim suggestions would really make a difference in your case for the same reason. Maybe someone can expand on their answer? 
I was trying to use the same environment as when I am on-site. I used Emacs with go-mode. And you are correct, it is much faster when I just do "emacs -nw" on the SSH terminal itself. But I lose all the fancy fonts and stuff.
Strictly speaking you still need synch, but it is much cheaper. You do not need a mutex, just an atomic read will do.
check http://github.com/thewhitetulip/web-dev-golang-anti-textbook and go through http://github.com/thewhitetulip/Tasks to understand the functionality of the application
"I don't know what that means." Fantastic answer. I have tried twice now and still cannot finish this video. The class just ruins it.
A small price to pay in order to get a more responsive editor IMHO. If you have a really bad connection then you might also want to check out MOSH (The mobile shell)
In Go packages typically contain _all_ code for some specific concept. So in a web application you would have maybe a `package user` for everything user-related and a `package blogpost` for everything dealing with a blog post. And `package blogpost` would contain the routing, the handler, the data model and the view model (or whatever MVXYZ-religion you are following). And of course each package has it's own test code in the `*_test.go` files. I hope this answers our "Bonus Question". Go is different in this regards. As you can multiple types and functions etc. in one package it is much more natural to group by concept than the "traditional" (??) grouping by class and functionality used by Java, Ruby et al. 
http://dave.cheney.net/2014/12/24/inspecting-errors is a good read on the subject. In my experience, static ErrXXXX strings are fine for smaller packages, but I tend to lean towards writing an `Error` interface (similar to https://golang.org/pkg/net/#Error) with appropriate methods to inspect the type of error. e.g. // For an imaginary SQL library type Error interface { error Driver() bool Syntax() bool // Wrap the underlying error; e.g. a pg.Error, net.Error, etc Cause() error } This allows the caller to inspect the error in a non-brittle (read: string comp) manner, special case the errors they care about, and extract the root cause from an underlying library if necessary. 
Yes, packages should be split based on them being isolated, maybe even reusable functionality. If you instead split interleaved functionality as an attempt to group things, then you end up with a cyclic dependency mess. I would argue that the name of the file, router.go, gives away the presence of NewRouter. :) Jump to definition is nice, but I also very much enjoy not having it. It means that, if things aren't easy to navigate, people get frustrated and fix it, which is quite contrary to some languages known to be very jump-to and IDE heavy (usually Eclipse being the IDE, to give hints to the language).
the only thing I am vaguely aware and is vaguely official (but related to audio) is: https://godoc.org/golang.org/x/mobile/exp/audio 
It would be nice to know what this actually *does*. Neither the headline nor the repo README mention that.
Thanks your advice and you patient. I will refactor the project.
nice post! but sad to see this internal stuffs isn't really optimized. calling a method of a interface has overhead? why? channels isn't lock free. extra cost to use defer. i really like tons of things in go, but i do really miss the 'zero-cost abstractions' of rust/c++/etc..
Excellent analogy.
&gt; Calling a method of a interface has overhead? Why? * http://research.swtch.com/interfaces &gt; Channels isn't lock free. * https://github.com/golang/go/issues/8896 * https://github.com/golang/go/issues/8899 * https://github.com/golang/go/issues/8903 &gt; extra cost to use defer. * https://github.com/golang/go/issues/6980 Defers are also run when there is a panic, so there will always be some overhead. (probably, not sure though)
I wonder if they considered just dumping the data into a competent GIS database, like PostgreSQL. Given the numbers presented (4250 qps/server) the performance would probably be better, and you get much better tooling and generality.
This makes sense, thank you! It looks like declaring a variable in one file of `packageA` and referencing it in a different file of `packageA` is completely legal, if not slightly hard to follow. Is this commonly practiced?
Thanks for posting this! I like the writing style of the book, I'm going to look over this during lunch. 
May I ask why you decided to use a custom struct type for context instead of using [net/context](http://godoc.org/golang.org/net/context)? That would have made this much more reusable…
Go to http://vim-bootstrap.com and select Go and any other languages you need, then use Vim. It's excellent.
I've never heard of Gogs before, but I've just downloaded the latest version, there is a per repo wiki and issue tracker, milestones can be created in the "issues" section. The "no search functionality" is a BIG issue for real life project though.
Yeah, this is not my area of expertise, but ISTM you could pre-compute a lot of this. The Earth is ~200 million square miles. Divide it up into 1 million chunks of 200sqm by lat/long. Probably most squares will be empty (ocean) or be in a city with a couple of dozen polygons in them. Make an array of one million pointers to slices of polygons. On look up, jump to the pointer by multiplying lat times long, then go through that handful of polygons. On update, figure out how many squares the polygon overlaps then duplicate those slices with the new information and atomically replace the pointer in the lat/long array (only one update process can operate at a time, but that's probably fine).
Nice article and analogy. &gt;People aren’t happy about Go’s approach &gt;Apparently Gophers think it’s equally crazy for libraries You might be writing "People" and "Gophers" but it's essentially a few vocal dudes that just want an easy way to have one hundred dependencies in their projects (some even same library but different versions) and never care about them just because other languages taught them it is okay.
TBH the data size quoted (1000s of polygons) doesn't sound all that hard for PostGIS to handle. At work we do on-the-fly pruning of the OpenStreetMap data to render custom maps. That's polygon/polygon intersections against ~100G of data, if it can manage that in 50-300ms it can manage lookup of their geofences. Hell, there's even [this](http://www.gaia-gis.it/gaia-sins/), which would let you keep simple deployment/operations/scaling and still probably get similar performance "for free".
Vim
true and true. https://www.digitalocean.com/company/careers#software-engineer:-storage https://www.digitalocean.com/company/careers#software-engineer:-metrics
I feel this best sums up Golang devs who approach Erlang devs after watching an hour tutorial on Erlang: https://www.youtube.com/watch?v=Mrx24jofi0w
From the go-lang specification: &gt; A variable declaration or, for function parameters and results, the signature of a function declaration or function literal reserves storage for a named variable. Calling the built-in function new or taking the address of a composite literal allocates storage for a variable at run time. Such an anonymous variable is referred to via a (possibly implicit) pointer indirection. &gt; Structured variables of array, slice, and struct types have elements and fields that may be addressed individually. Each such element acts like a variable. The words "Heap" or "Stack" do not appear in the go-language specification. Perusing the forum messages it appears that even if the struct was optimized and allocated on the stack it would immediately be placed on the heap if an address to the struct or its members was requested. I will add that regardless of the structure being stored on the heap, a stack, or a set of registers it still looks and act like a referenced data type. In general if it is not a primitive type (numeric or boolean), it's a referenced type. 
sshfs.
It seems like the difference between a primitive and reference type for you is "I know it when I see it", which isn't really satisfactory to me. BTW, structs are [definitively primitive value types in .NET](https://msdn.microsoft.com/en-us/library/aa664465(v=vs.71\).aspx). Maybe you're confusing [composite types](https://en.wikipedia.org/wiki/Composite_data_type) with reference types? Some people (languages) would define only non-composite types as primitive.
So i'm working on the player portion of the program and i'm a bit stuck. Maps kind of allude me. package main import( "fmt" ) type User struct{ Name string } type Player struct{ User score int } var Turn int type Players map[Player]turn func setPlayerInfo() map[Player]turn{ newPlayer := Players{ User{Name = "josh"}, 0 :0 } } func main(){ player1 := setPlayerInfo() fmt.Println(player1) } -------- error: # command-line-arguments ./Players.go:19: syntax error: unexpected =, expecting } Error: process exited with code 2. Id someone can explain what i did wrong, thatd be great
indeed. Sorry for that. Hand typed links are hand typed. :)
More importantly (and related to the point of not polluting the global namespace), you can define *several* `Area()`methods for different types: package main import ( "fmt" "math" ) type Rectangle struct{ Width float Height float } func (r *Rectangle) Area() float { return r.Height * r.Width } type Circle struct{ Radius float } func (c *Circle) Area() float { return 2 * math.Pi * c.Radius } func main() { r := Rectangle{10, 5} c := Circle{10} fmt.Println(r.Area(), c.Area()) // prints: 50.0, 62.83185... } This can then be used with interface types containing `Area() float` to create functions that can be passed either a `Circle` or a `Rectangle`. 
Nice info here too. Thanks for posting these!
Last point should be first IMO. Interfaces!!!
They said they have hundreds of city geofences, so perhaps this is a fine-grained resolution right there, and another level of resolution wasn't that necessary - though it would be just a matter of simple arithmetic to rule out someone checking Uber from rural Nevada, the amount of traffic from outside geofences must be small.
Wouldn't this be better suited on /r/PHP?
&gt; Unlike with reference types, you cannot derive a new type from a value type. However, like reference types, structs can implement interfaces. That terminology seems local to C# since, you can make any class "final" in Java and C++ which prevents it from being used to derive a new type. We could easily say that structs are final classes that are passed by value in C# by default. Regardless of the naming scheme Microsoft uses in its text, at least academically behind the scenes it's a reference type (especially if pass-by-reference remains an option). There's nothing wrong with calling them composite data types. You can be composite and referenced (for all practical purposes they are synonymous). Keep in mind, this whole discussion spawned from vvivian's quoting the Java spec which set the conversation in reference v. primitive frame of mind. You have to agree that composite data types are not primitive, and the incorrect assertion originally being made was that Go had more types and Java only had two because apparently in vvivian's mind referenced data types were second class citizens in Java. Anyway, I enjoyed this discussion even though I think we beaten this topic to death. Please pick up a textbook or dust one off the bookshelf and see how referenced vs primitive are specified. At least you get a sense why us older guys are insistent with our terminology. I hope we meet on a more interesting topic.
I would use methods more for core functionality of a type and functions as extensions since they can be defined in / moved to other packages. 
In your first example you are correct that is the way I propose to do it. $GOPATH/src/A/.git $GOPATH/src/A/main.go $GOPATH/src/A/vendor/golang.org/x/net/context $GOPATH/src/B/.git $GOPATH/src/B/main.go $GOPATH/src/B/vendor/golang.org/x/net/context Yes you are correct, you would have to update them individually, but only if both projects A and B shared golang.org/x/net/context objects between themselves and in that case, I may not vendor golang.org/x/net/context like in your second example; But if they don't share objects, then packages A &amp; B are self contained and can have differing versions of golang.org/x/net/context. maybe a larger example is in order; so let's say you have 4 projects: * A * B * DB - shared database logic which you or your company has full control over and projects A and B use * golang.org/x/text I would break it down like so: $GOPATH/src/A/main.go $GOPATH/src/A/vendor/golang.org/x/text $GOPATH/src/B/main.go $GOPATH/src/B/vendor/golang.org/x/text $GOPATH/src/DB/db.go both A and B can use different versions of golang.org/x/text with no problems by vendoring; sure if you wanted to update both you'd have to but they are setup as self contained packages except for the DB package, but because package DB is under your full control ( you can trust it ) it can be put on the main $GOPATH instead of vendored. What I was saying about gb is that you don't have this option to both vendor and use the $GOPATH. You make a great point about putting multiple packages into a single project, but think that you could run into the same scenario where multiple projects may require the same version of a package like DB above, and have to update all projects individually. ( as a complete aside, IMHO I find that putting multiple packages into a single project, although necessary, can also lead to import cycle issues, not saying that it will happen, just that it's easier to get painted into a corner rather than separating common code into it's own package ) I hope the above clarifies it a bit?
I'm really liking the features of Caddy but I wonder how it stacks up against something like nginx for production servers. The LE integration is awesome... really hope to see this simplicity show up in every web server.
Thanks. It's not common to find this kind of middleware pattern in the client side, however the approach is pretty useful in both sides IMHO. Extending behavior and logic should be easy with gentleman, for instance turning it into a resilient HTTP client with backoff support or server discovery using Consul. BTW I already implemented this kind of pattern in other client libraries and works well, such as: https://github.com/h2non/theon
Maybe I'm missing something, but it looks like an invitation to being DDoSed. Anybody can storm your server by opening TLS connections to your server with a different SNI hostname every time, which will quickly exhaust your maximum number of certificates.
Well written.
Straight from the post: &gt; A hard limit is required due to the potential for abuse. On-Demand TLS is also tightly rate limited: after the first 10 successful certificate issuances, Caddy will not issue new certificates within 10 minutes of the last successful challenge. And if a challenge fails, Caddy will not try for that name again for 5 minutes. The limiting is reset when Caddy exits. Even disregarding the rate limits, the hard limit, set conservatively, renders such attacks futile. Assuming certificate issuance remains snappy, future versions of Caddy will allow you to set further restrictions on this feature, like origin IP (if technically feasible) and allowed domain patterns. Caddy doesn't make any guarantees here; we're still in the early days of piloting this new technology in an effort to make HTTPS "just work". Any security engineers with suggestions/feedback are welcome to post to the issues and we'll work on making it more sound.
Methods are useful when you have a bunch of functions that share common data. Eg, you find yourself writing several functions that all have parameters A and B--consider making them methods of a struct that contains A and B. It's a bit of a false dichotomy though--they're all just functions. 
His examples are just stdout printing, so I wouldn't use them for gauging performance. 
AFAIK, it was first put on hold due to C -&gt; Go conversion and then the memory allocator work. But, one of them has been marked for Go1.7Early, so not dead.
Not sure if it's exactly what you want but the closest thing I know of is https://www.kajabinext.com/marketplace/courses/1-essential-go
&gt; I wonder how it stacks up against something like nginx In what way?
That stuck out for me too. 
Thanks. The source code changed to : https://github.com/coreos/etcd/blob/master/contrib/recipes/rwmutex.go
Thanks. It's a new visual angle
&gt; Essential terms, such as timeout handling, health checks, metrics collection [...] are often unfamiliar to a PHP engineer. Well that's frightening.
I keep hearing people say this but building web services in Go feels fantastic to me.
Liteide
there is no competition.
On the Windows platform the [Zeus IDE](http://www.zeusedit.com/go.html) does just that. 
&gt; It was never recommended to decompose a system into microservices while it is not mature enough. While small, a business has to be flexible and react quickly to the opportunities in the market. This is not an ideal environment for building microservices, and more benefits can be achieved by having a monolith instead. PHP with its ecosystem perfectly fits into this strategy. I take big issue with this because I don't think this guy has spent enough time with Go and has not actually put anything into production either. Go is amazing, *AMAZING* at microservices. You CAN and what I have done, is port a huge monolithic application in PHP and move it to a microservice architecture. Which when it has been ported, you have resilience with clustering and a more secure application. With a monolithic application, the application is maybe running on 1 web server, it may be running on 1 db server (mysql usually) and most likely has no message queue either. PHP also sucks badly for processing/threading. Go on the other hand, you can shift all the backend processing into microservices and move into kubernetes territory. I'm doing things with Go which would have caused me lots of pain points with PHP. Here's another thing. You can do anything in Go that you can do in PHP. You can't do in PHP what you want to do with Go. Oh and with Go, it's going to get better every 6 months. 1.7 and 1.8, I cannot wait for. PHP, any one remember how long that was stagnant? I was there, in production! I had to jump ship to HHVM and remember the folks over at zend had to jump into action to make PHP 7 otherwise they may lose out. Ironically, they are losing out to Go. 6 months ago, I was a pure PHP shop. Now I'm a 100% Go shop and not looking back! 
&gt;You have to agree that composite data types are not primitive Well, Wikipedia says opinions vary about that. I could be persuaded either way.
I assume this is Go 1.5?
They all use the same go tools (gocode, godef) so pick any you like.
happens to all of us :)
Also, if you're after byte-by-byte duplicates you should store a hash of Pix along with your Image in your database and look for that hash instead. Otherwise this won't even remotely scale.
&gt; I would use the word "designed", and the answer is Systems Development. Programs which, before Go, would have been developed in C/++. No, that's Rust and D's field. By design, Go can't tackle the two largest (Systems) fields C/C++ reigns in: embedded/bare-metal and osdev. It's too tightly coupled to green (application-scheduled) threads and GC. Go's area to shine is the *bridge*. Those apps that fill in the large segment of tasks people currently use VM/interpreted languages for, for convenience sake, but that can benefit greatly from cutting the VM out. The perfect field so far has been web services and that's where it really shines, but highly concurrent applications are also starting to transition.
Try to not overthink it. At least not before you have a good understanding of how a programming language work. Here is a simplified example: http://play.golang.org/p/lOnhHhwptN As an example, can you explain why you think a type `Turn` is important? I think an `int` is sufficient. I would recommend to go through the go tour: https://tour.golang.org/welcome/1 
The whole idea of the big O notation and using the correct data structures for the correct job is alien to most so basically the basics of software engineering
The thing is, they don't know what license the code being vendored is under, so they can't make assumptions. For a distro repository this gets handled by the package maintainer.
pHash is possibly what you want here. [There was a thread](https://www.reddit.com/r/golang/comments/2wnns5/findimagedupes_use_phash_to_find_visually_similar/) about it some time ago.
Well, like a "sanitation engineer" but with more shit to deal with.
wow, this screencast was very helpful. I was looking to read about Glide from some time now. Keep it up !
If you need a new package that you don't already have you'll need to use a package manager to get it. Glide does try to help a little with this thought. The `glide update` command walks only the import tree referenced in the code path. Just enough to build and run the application. With the `--all-dependencies` flag it works a little differently. Running `glide update --all-dependencies` will fetch all possible dependencies in the tree. It's still based on what you have in the `glide.yaml` file so you need to list the intended dependencies there. This can be useful during development. Especially early development on a project. Other package managers may have similar features. I'll let them speak for themselves as I'm not an expert on all these little details.
@kardianos There's one more thing, you may already know but if not might find useful. Not all open source licenses are compatible with each other, it can matter at the version level, and sometimes it matters if you're doing something like distribution. Checkout the Apache licenses compatibility to the GPL. You can see it [on the Wikipedia page](https://en.wikipedia.org/wiki/Apache_License). The -dev packages on Linux are specific cases with specific licenses that have been reviewed. I'm sometimes surprised at the number of open source licenses in use. The [OSI has a list online](https://opensource.org/licenses/alphabetical) if you've not already seen it.
Any intention of making a docker image? It would be handy if I could just replace [`schickling/mailcatcher`](https://hub.docker.com/r/schickling/mailcatcher/) with `mailslurper/mailslurper` in my project.
I hadn't thought much of it. It's a good idea though! 
Wasn't it unsafe to remove the symbol table from a Go binary due to reflection using it?
Not a huge fan of UPX! Doesn't the kernel have problems sharing objects that have been UPX compressed? &gt; Imagine what it could do to a full fledged program. I am not convinced that binary size is a real problem for end-user applications. What worries me is the size of software tools. Maine Coons notwithstanding, no-one wants a huge `cat`. What would people think about creating a (strictly alternative) Go stdlib that uses as little code as possible?
[Alan Kay answered the question a long time ago.](http://userpage.fu-berlin.de/~ram/pub/pub_jf47ht81Ht/doc_kay_oop_en) ([See also this.](http://lists.squeakfoundation.org/pipermail/squeak-dev/1998-October/017019.html))
Cool! Sounds great.
1. It requires a fully working golang env to run, which makes using it inside docker containers a pain - you have to make the images way larger than they'd otherwise be. Being able to compile migrations to a binary (which it does on run anyway) would be nice. 2. If you write a migration in go it's really hard to use anything but database/sql in it to access db. I really like my sqlx helpers and sometimes I'd even like to use the micro-not-really-orm we use 3. Environments have to be defined in a separate config file - I can't just use command line params, env variables etc. 12-factor app out of the window for migrations ;-) 4. Largely useless error reporting and despite all that it still is the best solution right now, which is unfortunate.
Yeah i ended up realizing some of the problems, one of them being turn was getting returned rather than what type turn was. package main import( "fmt" ) type User struct{ Name string } type Player struct{ User score int } var turn int type Players map[Player]int func setPlayerInfo() (map[Player]int){ var newPlayerName string newPlayer := Player{} fmt.Println("what is your name?") fmt.Scanf("%s", &amp;newPlayerName) fmt.Println("Player1 name: " + newPlayerName + ". " +"Score set to 0") newPlayer.Name= newPlayerName newPlayer.score=0 players := Players{} players[newPlayer]= 0 return players } func main(){ player1 := setPlayerInfo() fmt.Println(player1) } 
Go has a convenience type for doing atomic swaps of COW data: https://godoc.org/sync/atomic#example-Value--ReadMostly
I don't think that quote says what you think it says. However, even if header files don't constitute being a part of the work as far as distribution goes, a sub-selection of files from a greater work will still be published from the original source. All references in the GPL imply that actual modifications to the existing source take place, or extend it. Most Go licenses does not even care about this kind of nuance in any way, in part due to the static linking nature. If you have a lawyer who agrees with you (and this isn't just you) and the licenses you use seem to require it, it is simple to include the whole repo.
Rob Pike answering "What is a systems programming language?": https://youtu.be/BBbv1ej0fFo?t=6m45s Other answers are also good.
Sure, but to give a better example: I use github.com/dlsniper/demo/package1, which pulls all github.com/dlsniper/demo as dependency. Then, at some point I need to use github.com/dlsniper/demo/package2. Now, because the vendoring tool was playing smart, I don't have package2 in my vendors. So what do I do? i have to run &lt;insert pm name here&gt; to get it. But that might imply that now package2 and package1 are not compatible anymore. Or that package1 was updated and my code is not working anymore. Or that the vendor tool is actually smart enough and gets the correct version for package2 but then what happens if the vendor is not there anymore? And finally, all these things happen just because I use a vendoring tool which was "smart" and removed unused packages, no? Oh and if the presumption is that you don't remove subpackages from github.com/dlsniper/demo how do you know then to not remove say from dlsniper.xyz/demo? Plus all the hassle to actually run the vendoring tool again. And there are soo many other things that I could think of to actually get this right. If unused dependencies are a problem, I could just remove the vendor dir and reimport things again (provided I keep the file which tells which revisions I want to use and the tool is smart enough to update it only with used dependencies, and again that "smart enough").
govendor add github.com/user/musteverthing/^ (same as "govendor add -tree github.com/user/musteverthing") The above adds the entire directory tree, regardless of used go packages. 
@kardianos This is why I avoided the original discussion on the details of the Linux kernel. You're discussing the GPLv2 in a specific case. Go itself uses a BSD-style license + patents clause. There are many open source licenses in use (for example [see the opensource.org listing](https://opensource.org/licenses/alphabetical)). It's a question of the safe default for users without knowing the licenses they're dealing with and how they choose to handle each situation. You'll notice I was specific in talking about what Glide does by default. The default is that Glide doesn't make legal decisions for users. We don't assume their intent. As for lawyers and legal issues ... unfortunately I've spent too much time around lawyers and other engineers who've dealt with license legal issues. That's part of the reason I'm so tentative about having anything other than a default that does no harm. Lawyers have taught me more about open source that I thought they would have. Did you know that browser JavaScript going from a server to a users browser is distribution and invokes those clauses in licenses? Minifiers have even built in features so they can preserve copyright and license statements. *Disclaimer: I'm not a lawyer, this is not legal advice, consult with a lawyer on software licenses issues.*
I just want to point out that this conversation would have had a lot more screaming about manual reading in other languages' subreddits. Thanks for keeping it classy, folks. :)
&gt; You'll notice I was specific in talking about what Glide does by default. The default is that Glide doesn't make legal decisions for users. We don't assume their intent. This is a fair statement. The rest seems like you are talking around the issue. I mention the GPL because of it's clauses concerning "modified works" or "derived works". The issue with Iceweasel was that debian applied their own patches to Firefox, modifying existing source code. It seems like a huge stretch to say copying a subset of the work along defined boundaries constitutes modification. You could be correct. I take issue because it sounds like FUD and not a reasoned approach. Yes, code that is distributed requires licenses attached, and every internet view is a distribution, just like any normal local install is. I'm assuming you also don't use minifiers in javascript that removes unused functions or variables? I'm assuming you would state that a minifier that just removes whitespace (also not used) and doesn't constitute a modification? Should I not minify javascript files that use certain licenses? I could be wrong here, but if I am, a great deal of existing practices would need to change.
Not sure if it's updated yet but it used to be full of race conditions. https://github.com/gogits/gogs/issues/613 Seems that it's fixed (at least partially...) now, though.
I don't know if you're arguing with me; but Stroustrup, Alexandrescu and Niko (C++, C++/D and Rust, respectively) all disagreed with Pike's latter definition ("systems" = cloud language).
I agreed that people used it. I also stated that the use is based on a niche and archaic terminology and nigh *never* applies when referring to C/C++ as a "systems language" (which is the context OP used it in). Even Pike admitted that calling it as such was problematic on his part, after Stroustrup and Alexandrescu called him out on it.
This looks cool. I'm excited to give it a try!
How do goroutines and channels work in a functional language?
https://github.com/mattes/migrate
Ken, you should take the opportunity to tell everyone to go out and read Peter Seibel's *Coders at Work*, since it's got this stuff and goes more in depth about other stuff, too. It's also got interviews with Knuth and Guy Steele.
I would second this. I've tried them all, and IntelliJ was by far the best. You just need the free community edition (https://www.jetbrains.com/idea/download/) Follow the instructions here to install the Go plugin (https://github.com/go-lang-plugin-org/go-lang-idea-plugin) I'd also highly recommend installing the "File Watchers" plugin, and getting it to run goimports (https://godoc.org/golang.org/x/tools/cmd/goimports) on every save. This not only gofmt's your code, but it also fixes your imports block. It makes development effortless.
Don't `go get` your fork. Instead `git clone` it under appropriate folder structure (mimicking canonical url) in vendor folder of your test project. 
Wow awesome explanation! 
Whoa Generics! 
Because execution order is not guaranteed in a pure functional language. Since there is no global state, functions can be evaluated in any order (or in parallel for example) since the resulting state of the program is the same. As icholy said, this probably isn't a pure functional language.
That is correct, it's not a pure functional language.
If you are referring to enforcing ordering, I'm guessing monads.
&gt; Exactly what Go needs to keep the generics fanatics and Haskell hipsters distracted. This post sums up everything I hate about the Go community, the disdain, the patronizing, the "my way or the the highway". Then i hear about inclusiveness and diversity in the Go community when no diversity of opinion is allowed or respected.
&gt; genetics My phone also hates the word "generics" 
To be fair, other communities are much, much worse. *Mere mention* of Go on Hacker News, /r/programming, or in just about any language-specific community will be received with hate and vitriol.
Glad to hear it!
Awesome! I think that's a pragmatic approach. I independently came to the same solution for representing sum types, as I've been trying to get started implementing what you've made. I've been digging into the code, hopefully I can help contribute soon! I've made some changes to use stack rather than cabal for easier building that I'll PR later.
Plus a demonstrable example of how much genetics could help in Go code.
The `switch` in go is similar to many other languages' guarded statements or `match` statements. This *departure* from traditional C `switch` semantics what makes them so useful, not some better understanding of what switch statements should have been. The C style `switch` is very useful for a bunch of other reasons your article does not cover. The cases where it's amazing to me tends to be protocols or drivers where you have some set of inputs that all map to some subset of actions, so cases get stacked prodigiously. Using Go's `fallthrough` in these cases is exactly as frustrating as your article describes for `break`. I would love if `C` had a match primitive though..
Whoa can someone explain to me how this compiles? Does Go use some interim bytecode for its compiler?
Exactly, I am tired that most iterations I get from a Gophers are full of zealotry.
&gt; To be fair, other communities are much, much worse Cheap deflection right there. What's your point exactly? Because other people are supposedly giving Go bad press makes your own faults lighter and justifiable? Also, is this a realization of your own zealotry? 
I'm not familiar with the `match` statement but if it does a similar thing then I can understand their motivation to create it. For me the lack of `break` is nice for reducing the amount of code and potential bugs - but the real power, I think, is that the cases don't have to be literals.
Also consider https://github.com/signalfx/golib/tree/master/web for inspiration. I personally think a handler like the following is the easiest to use. The code/abstraction was made some time ago. I think other libraries may do something similar. type ContextHandler interface { ServeHTTPC(ctx context.Context, rw http.ResponseWriter, r *http.Request) } type NextConstructor func(ctx context.Context, rw http.ResponseWriter, r *http.Request, next ContextHandler) They then chain together and use ctx for context information.
Hacker news is pretty well-rounded in their Go opinion. On the other hand, /r/programming hates go.
No need to use `git clone` manually, you can `go get` the upstream, `git remote add` your fork.
It produces Go code like a Javascript transpiler. Although Go has a very simple calling convention so in theory you could write an LLVM based compiler and a linker plugin for Go's object file format and inter operate with an optimizing compiler. The tough part would actually be getting Go's GC and runtime to work with a different compiler. It would be easier with GCCGo's output and runtime, but then you don't get the new fancy GC and copying stacks. I'm planning on attempting his someday though since the payoff could be great.
So I'm not the only one who started calling people I don't like Francis? I feel really sorry for anyone whose name is actually Francis.
Good genetics always help. :D
&gt;let n If there is a single feature that will keep me turned away from a language, it's the let keyword. Otherwise good for you.
It was a joke. I think I forgot to read [vol. 5 of the internet manual](http://cdn.meme.am/instances/66248979.jpg).
Please don't mistake my comments for saying that I don't like it, I do! I'd just rather they called it `match`. I'm curmudgeonly sometimes. And your user name. Do you really like mixed cases WITH an underscore!? :) Great username.
mixedCase was taken, only later did I realize the irony in my workaround.
Thanks for sharing this. It took me some time, and some ungainly code, to come to a similar realisation. I'd like to think the "share memory by communicating" mantra could be amended to bring this problem into focus. I can't think how to express it succinctly, so I'll try some bullet points instead. 1, Avoid sharing state unnecessarily: * We should *prefer* to share-by-communicating, wherever we can. * i.e. where possible, avoid mutating entities after having passed them across goroutine boundaries. Once data has been shared between goroutines (via `&lt;-` or via the `go` keyword), avoid writing to it on either goroutine. Pass-by-value &amp; defensive copies are useful tools here. 2, But, when you need to share state: * Whenever you *need* to manage state across different channels, then ensure that these entities are thread-safe (aka goroutine-safe). * When we need to support thread-safe modifications, Mutexes &amp; RWMutexes are a powerful and straightforward tool. 3, Always: * Always use the race detector to verify that you're doing it right. Does that ring true? Or, do you see it differently?
I couldn't find any mention of Oden on [golang-nuts](https://groups.google.com/forum/#!forum/golang-nuts). How come?
I visit this sub and read the comments.
Sorry if I'm missing the point but isn't there a 3rd option where you keep the pointer receivers and the type of printRepoInfo's argument the same but make githubRepo a pointer? https://play.golang.org/p/030Ed-xQYb Is this a bad idea for some reason I'm not aware of? In this case a pointer to a GithubRepo implements the interface rather than GithubRepo itself.
I'm wondering why did `gvm` set my gopath to be `~/.gvm/pkgsets/go1.6/global`?
Go _ecosystem_? hahahahahahahhahah. Go doesn't even have a proper package management. And it's never a focus of Go.
Not familiar with gvm, but it sounds a lot like Ruby rvm. It seems to want you to make sets of packages in addition to maintaining several versions of Go. Do you really need several versions of Go? The brief history of Go package management is the go tool chain could download dependencies for you, but only to your GOPATH, so projects would share the same version. Dependency hell brought all sorts of community solutions. As of 1.5, Go supports a vendor directory that will be preferred location to resolve imports, falling back to GOPATH. There are several tools that work with the vendor directory: https://github.com/golang/go/wiki/PackageManagementTools
I think this shows a lot of promise. Maybe now I can implement some monadic form of error handling, so I can compose actions instead of sprinkling ifs all over my code
This is great! Regarding the first one, is the mutex stuff really necessary for a mock? I would personally just create a new instance for each test and that should work just fine, no?
I hope there will be a "proper" package management for Oden to satisfy people who think like you.
Anything that can keep that kind of stuff away from Go so that it remains simple is good news.
There are two Gopher styles available: * [Fancy Gopher](https://teespring.com/gopher?s=r) * [Traditional Gopher](https://teespring.com/golang?s=r) Each comes in multiple colors and shirt styles. There's a lacking of good Golang swag so I thought /r/golang would enjoy these!
One solution to the problem is the [busybox](https://en.wikipedia.org/wiki/BusyBox) approach where you have one binary that does N things, and depending on how the binary is called, it chooses which code path to follow. For example, you could have a binary that does `cat` when called via a symlink named `cat`, and does `grep` when called via a symlinked named `grep`. (On OS X, `pbcopy` and `pbpaste` are a single binary that chooses whether to copy or paste depending on what name calls it.) That's a relatively simple way to keep binary size down for toolsets without rearchitecting Go.
C-style switches also have the advantage of being easy to optimize, often into an O(1) lookup. I haven't looked at the Go compiler's behavior for the simple case, though, so it's possible that it detects these and optimizes similarly. [Further reading on C++ switch optimization] (http://www.codeproject.com/Articles/100473/Something-You-May-Not-Know-About-the-Switch-Statem)
One annoyance about Go's switch for types is that [this](http://play.golang.org/p/zHz8QP4okb) won't compile: var o interface{} = 7 switch c := o.(type) { case int, int64: c += 1 fmt.Println(c) } Since `c` could be an `int` or an `int64`, you can't use addition. That makes it harder to write code that does math without caring what the concrete type of the numbers is. In practice, you end up just always using `int64` or `float64` and then truncating when you're done.
I really dislike Haskell's syntax for type annotations, and I don't think they should be copied. From the example, I think this: twice :: (#a -&gt; #a) -&gt; #a -&gt; #a twice f x -&gt; f(f(x)) is much easier to read as this: type T generic func twice(f func(T) T) func(T) T { return func(t T) T { return f(f(t)) } } Among other reasons to dislike the Haskell-style syntax, it implies auto-currying, which is goofy. If you need to curry something (which is not very often in my experience), you can trivially write a wrapper function if your lambda syntax is any good. And it needs to be good because sometimes you want to curry the third parameter of a function instead of the first. As a whole, Haskell's auto-currying syntax makes it difficult to tell what the programmer intent was concerning important things like "how many parameters does this function expect" and "what types does it expect to take". Those are not unimportant things to gloss over on a separate line from the function definition! And they should get all boogered up with `-&gt;` so you can make currying—an infrequent need—slightly easier to see.
Yeah I understand that but I'm not sure it answers my question. In my example all of the methods are declared with a pointer receiver which means the pointer, not the object, implements the interface. I was just trying to understand if the reason this wasn't included in the article as an option was just because OP hadn't considered it or if it is a bad idea in some way I haven't thought of?
In Go, the stacked statements would be comma separated, like the author described in the "Collapsing Cases" section. No need for fallthrough.
Good point, but there's an argument to be made for using the global rand (and not seeding it) - determinism. Unless you really need nondeterministic behavior, using the global rand will mean that whoever's using your package can expect deterministic behavior out of it, and can test it, which is a big advantage, especially when debugging. EDIT: To clarify, I'm saying that you should try to use global rand and /not/ seed it. If you need something seeded, then definitely don't use global rand.
It's not one vs the other it's both. If you need concurrency yet you need all concurrent operations to finish in order to get a result you need to use wait groups. For instance a map reduce operation , you expect processing to be distributed but the result is reduced into a single one.
&gt; Lighten up, Francis. You're the enlightened hey ? you just proved my point about the Go community.
I do not disagree with that either.
The entire go codebase is encumbered by the Google Individual Contributor License Agreement and the Google Software Grant and Corporate Contributor License Agreement. 
The issue, overlapping, is a non-issue. there are many overlapping features within the language. Most of the arguments against most of those proposals are just noise, but that noise always seems enough to derail the conversation about the feature. This is absurd considering builtins have access to generics-like functionality.
How is it possible that a userland program cause the kernel to die?
Relying on deterministic behavior from an RNG just sounds like you're asking for trouble. Edit: It is documented. I still think it's a bad idea to rely on the seed not changing.
I was going to complain about more ethereum spam but then I noticed this wasn't in /r/bitcoin. Carry on.
pseudo-RNGs are always deterministic, it's pretty much part of how you expect them to work. In go, it's even explicitly specified that it is deterministic.
How is error handling performed? In the examples, I see fmt.Println used as unit, but fmt.Println actually does have an error return instead of returning nothing.
You'd also need to produce Go runtime information. E.g., type metadata and identifying what memory addresses on the stack contain live pointer values and when.
you can only Unmarshal to an exported struct key. Try ``` Configuration struct { TestKey string } ```
&gt; it implies auto-currying I think this is a legitimate concern. I imagine the language is targeting users of Haskell, OCaml, etc., who will be fine with Haskell-style type syntax. Once you're used to it, it's a breeze to read and write. I'm not sure I understand your concerns about "how many parameters does this function expect" and "what types does it expect to take" - could you elaborate?
Thanks, adding the `json` part made it work! Also... this is weird but it only works the struct fields are CapitalizedLikeThis, not capitalizedLikeThis... is this some implicit rule of golang structs that I did not know about? Seems so weird. 
Ok, I did not know about this Go characteristic, TIL. Thanks for the help
Don't tell the truth here. Please re-read the r/golang code of conduct.
are you sure its being seeded only once, that's never happened to me before :/
These numbers shouldn't be surprising. Rust's LLVM backend generates very good code. Rust code runs on par with C and C++. The Go compilers are less mature and are 2x-3x slower than the equivalent C code for CPU intensive workloads. This is exactly what we see in these benchmarks. 
"When writing locking code ... if you have M states and N methods, you need to think about all N states in each of the methods, giving you an M × N code explosion. " The combined system has N^M states. It's not code explosion, it's state space explosion. It's unrelated to whether the code uses locks or messages or some other form of interaction.
Sometimes it isn't explicit enough. Also it conflates the intention of the lock, which may only be protecting some fields.
A very good and important point, but there's no way Go's garbage collection is slowing programs down by a factor of 2 or 3.
I believe the GC only runs when you allocate. For many applications, it's reasonable to do your allocations in buffers outside of your inner loops. If you do that and are diligent about making sure nothing escapes to heap from your functions unless you want it to, the GC isn't an issue. But still, even if they weren't trying to minimize GC time, a factor of 2-3 is surprising to me. For a lot of the HPC code I write, I prototype in Go and then rewrite in C, so I spend a decent amount of time comparing cross-language benchmarks. A factor of 3 is pretty big: my rule of thumb is &lt;~ 1.5.
As far as I know this is not currently possible from the compiler. Maybe you can search in the Go issues to see if there's anything there or open a new issue for this. However I think it is useful to have the full path as GOPATH can be a collection of paths and then it wouldn't be clear where the file comes from. I guess a simple tool could also change this in the logs if you really need this
OK that looks like it would be suitable, pretty standard by all accounts :) Thanks
Correct. False negatives, but not false positives.
If you just want to have less information, one way is to define a "recover" in your main function. package main import "fmt" func main() { defer func() { if r := recover(); r != nil { fmt.Println("There was an erorr ", r) } }() b := 0 a := 1 / b fmt.Println(a, b) } https://play.golang.org/p/BHQ6-UWKx- Try to add and remove defer section and see what happens. Another way is to set the GOTRACEBACK=none in your environment. You can find more about it here: https://golang.org/pkg/runtime/#GOTRACEBACK 
Get off your high horses, John .
I thought about that, too. But this method is overkill for my tiny app.
I've read about GOTRACEBACK, but it is evaluated at runtime - not compilation. But recover() is pretty much the perfect solution. Thank you :) I always thought that the defer/recover section has to be in the same scope as the panic. So recover() and panics are somewhat like Java's catch-blocks and exceptions? Panics bubble up more than one scope... edit: manners
I agree for debugging purposes. A full stacktrace incl full path is pretty helpful. But in production-mode a less verbose output is imo preferable (or even better there shouldn't be panics at all :D)
For 75% of functions, the most important thing about them is what kind of input they expect and what kind they produce. So, in a Go context, the http.HandlerFunc type takes a ResponseWriter and a Request. In a more functional context, you could imagine changing that to be a function that takes a request and half-finished response and it returns a fully finished response. Could that be more generic? Well, Request could be an interface, like ResponseWriter is, but beyond that? Not really. The types matter here because the type provides semantic information. If you genericized HandlerFunc, it wouldn't be a HandlerFunc anymore, it would just be a function with two inputs and one output, which is the same as bazillions of other functions. Yes, there are some generic universal functions like map and apply that need to be able to handle any kind of input and any kind of output, but the common case is that something takes in a certain category of input and produces a certain category of output. Describing input and output is very central way of documenting expected behavior for other programmers. In Haskell, instead of optimizing for the common case, optimizes for writing map yet again. Type inference is nice to have in small doses, but the bulk of functions should be working on something simple enough that their parameter expectations can and should be documented. If something is simple, the programmer can handle the burden of listing the types. If it's complicated, type inference is liable to break in unpredictable ways, so the programmer is forced to specify the type expectations. What's left over then? Well, if you wanted to write another version of map, Haskell makes that easy. :-/
I have no idea what you are trying to ask.
Please refer to https://www.reddit.com/r/golang/comments/485e39/ask_rgolang_what_are_the_legitimate_cases_for/
There are two use cases for `panic()`: * `panic()` when an error condition occured that should never occur in a normal use of your module. * `panic()` as an exception mechanism to escape from deeply nested stack frames. Such a `panic()` should not cross module boundaries. Good situations where the first one applies are: * `nil` was passed where a pointer was expected * an internal invariant doesn't hold or a consistency check fails * a case was reached that should be unreachable Situations where the first one does not apply are: * A configuration file is missing or malformed * The function was called with incorrect arguments * A network connection was lost
Wanting to close a channel that might already be closed is _always_ a problem in your program design.
I largely agree with /u/FUZxxl, panics are ~exclusively for programmer errors e.g. invariant failures. You can also use panic/recover for error control flow in certain _very limited_ circumstances, like building a recursive descent parser. encoding/json is one example.
I was wondering the same thing a while back. Right now, I use it in every case where the caller is simply using the function wrongly. With wrong I mean literally, this can never succeeded, this is faulty code. This does not include cases where the method fails because the object is in the wrong state, as state might be manipulated by outside influences and the caller might not know of the state change beforehand (e.g. race in networking protocol). An innocent question that led to quite a elaborate discussion can be found here: https://groups.google.com/forum/#!searchin/golang-nuts/%28master%29/golang-nuts/Qg4CNgC7RPY/KWyWPD3ACVYJ It might be an interesting read as a lot of people share their views on this. In general, I think the go team takes the approach I described above. (However, please correct me if I am wrong on this.)
I strongly disagree. For example if I offer some resource and want to have an idempotent Close() (IMHO, Close() should *always* be idempotent). If your resource needs to shut down other goroutines you need to signal the Close() somehow and the easiest way is closing a done-channel. Above gives you a goroutine-safe idempotent way to do this in just a handful of lines of code. Offering a clean and not unnecessarily hard to use API is a nice thing in my book and I don't see anything wrong with using above code to express this clearly. I see no reason to be a purist here except purity as an end in itself.
[nlp4go](https://github.com/korobool/nlp4go)
It might be the exception, but it is both a valid usecase and a nice thing to offer. Especially when only a single line of code is needed to solve it elegantly and quickly in your abstraction instead of the level above.
Besides their normal use, I use them as a simple way to escape from nested functions in a web applications. For example, to implement HTTP redirection with a simple syntax.
It is as you say kinda similar to exceptions, in a way that it can give us control over a "panic". But please be careful as how you use "recover". I is kinda considered bad in Go style. Your case seems to be actually one of the situations that it might make sense to use "recover". https://golang.org/ref/spec#Handling_panics
mind explain what do you this the graphic bottleneck is? does not sound like a super complicated app. 20 fps is pretty low even on moto g i think.
i think machine learning community is still heavyly python based. much better options there. you can setup a python server and call it from golang.
My main() now defers a function with recover() and handles panics gracefully without a stack trace at all
it it online yet? i can't seem to find any.
I think it's better to have a controller that can return an error and make an error for 404, 301, etc. that the outer controller uses. 
you should read this https://blog.golang.org/pipelines
Then use sync.Once. 
While I agree with you mostly, &gt; Yes, it's a Go thing. It definitely is *not*. Breaking backwards compatibility in a major version on the other hand is a new weird culture that is part of web scripting culture.
&gt; Though that is often not a good idea. For example in games. Or in Monte-Carlo simulations. I'm not saying it always has to be that way, but it's often useful, and as a package author, you don't want to make assumptions about your users' use cases. &gt; Untrue. You can make it an exported variable that is initialized with a deterministic seed and main can then set it to some other rand instance (for example one with a global seed or whatever mixture you can imagine. Just implement rand.Source). Fair point. That seems a bit cumbersome to me, but maybe it wouldn't be that bad. In any case, it would work. &gt; But… you are using goroutines (yes, you are) You might be, you might not be. When I write testing code, I try to make it non-concurrent precisely so that I can have predictable behavior. I try to only have concurrent tests when the concurrency is part of the point of the test. &gt; your program is not deterministic and it should never depend on being deterministic First of all, that's not true - many programs are deterministic, and most algorithms are trivial to write in a deterministic way if you want to. And I'm not suggesting that it's a correctness issue - I'm suggesting that it makes debugging much easier because you can rerun the program over and over and have the differences between program runs be guaranteed to be meaningful.
&gt; Trying to run it on the JVM pretty much destroys most of what is good about Go. What about Android? Isn't running go code on an android essentially just using a variation of the JVM anyway? (dalvik or android run time)
&gt; Sometimes we have to be a little bit inflammatory when being critical of other technologies. No, sometimes we *want* to be, because it's easy and simple. It's easy being dismissive and it's easy to discount something by being inflammatory. But that is the easy way, the much harder way is to actually give criticism. &gt; I don't understand the code of conduct considering that even the founders of go (I won't mention any names) have said, directly or indirectly, that Java is a joke or questioned whether java code snippets online are a joke. In that case, they probably made a mistake (insofar as they might have violated the CoC). Calling them out on it (in the form of a private message either to them or the CoC Working group) is fine. &gt; The code of conduct is a good idealist utopian liberal politically correct way of living our go lives but I doubt any serious real programmer could follow it 100 percent. I am not following the laws of my country 100 percent (and doubt anyone really does). Should they be abolished? You shouldn't fret it. It is not expected that the CoC actually has significant impact on anyone's life in the go community. When discussing go, do so professionally and no one will really care if you follow the CoC to the letter (though you probably will. Because that's pretty much all it says). In any case you should probably wait and see if it *does* affect you, before taking preventative measures. &gt; My favorite thing to do is to gently flame people's hello world apps in other languages which are overly complex, verbose, and ugly. That is a strange hobby, if you don't mind me saying. Making fun of other peoples work, that is. Everyone worked hard on their language and their code and whether or not you like it doesn't change anything about it. &gt; And sorry but I'm not going to participate in go mailing lists and such places as much if gentle flames are not allowed, and critical thinking is not allowed. There is zero limitation on thinking and zero limitation of criticism. You just need to express it constructively and professionally. And ICYMI: The go CoC applies on this reddit too. If you are unable to participate professionally on the go forums, understanding and following the CoC as stated, then it is fine if you don't -- it's sad to see people leave over something that should ultimately not matter, but if it matters to them that much, that is fine too.
Or just write that one line of code (though I acknowledge that I didn't think about sync.Once. But it also needs more code for no benefit here). Seriously, what is the problem with that line of code. I would like to hear an argument that isn't a) "I don't like recover" or b) "I don't like closing channels twice". It is obvious, it is correct and it does what it's supposed to do. All these purisms have a *practical* usefulness, but this doesn't apply here. They make it easier to debug, they make code more readable, they make it easier to write it correct. But none of those apply here. We shouldn't blindly trying to be pure, just for the sake of it.
I have. Multiple times.
Sorry, let me rephrase: using goroutines in a way that affects the semantics of your program. The runtime and GC goroutines will not use the global rand, and will not introduce any nondeterminism into your program if it isn't already there. If, in the magic world of ideal execution in which neither the runtime nor the GC exist, your program is deterministic, then that's true in the real world in which they do exist as well. 
&gt; Go packages are not a DAG, but a graph Is this right? It seems off to me.
I've added this to my main() if !*debug { defer func() { if r := recover(); r != nil { idl.Emerg(r) } }() } If it's in production mode it "catches" all panics and keeps a log of the error via idl (which is a logging package) Do you think this is bad practice? edit: idl.Emerg calls os.Exit(1) after handling all log-events
If you call exit that's a good thing. Keep in mind that panics may occur because the memory allocator ran out of space and other such issues
Sounds like an interesting idea. I'll have to look into that further. Thanks!
Also, C has undefined behaviours, and any language translated to C inherits all of C's undefined behaviours. (Read Regehr on this.) The C compiler is allowed to assume that you never mean what you said if you do something that includes an undefined behaviour and will optimise everything away based on that assumption. This creates some really unintuitive failures. So modern languages like Go and Rust avoid that by not having undefined behaviours and not compiling via C.
Not a Go expert &amp; not sure which one's more idiomatic, but I'd prefer option 2 as it is more readable and could be used without first declaring a project instance.
The actual CPU inside those Arduinos is a small and weak 8bit affair. You could also ask: What about programming Go for the SNES? It's just not going to fit.
You may want to learn vim. The go integration is great (most integrations are great). The downside is that there is a learning curve. The upside is that vi/vim is everywhere. I switched a couple of years ago and never looked back.
This to me reads as a compelling reason for _not_ committing the `vendor` directory. Would it be possible for glide to clean up and fully manage `vendor` when it detects it's not versioned (e.g. no `.git` directory, acknowledging that git isn't the only option)?
&amp; HN discussion: https://news.ycombinator.com/item?id=11196635
Ability to extend. I'm not the author of that piece, but I work with the author of that piece. What we have found is that the easier it is to get a micro-service up and running, the quicker you can go about adding the business logic, and that ultimately is where you are adding value when writing software. It's very rare you'll actually just spin up a microservice with a REST interface providing CRUD to a database table, you'll want to do more stuff in the middle - however those crucial first steps need to be rapid. If you look at what you get out of the box with that setup, you get a ton of things you would have to bolt on down the line and slow you down - here you have an established framework that lets you get straight into the business logic you care about.
Isn't that what [init](https://en.wikipedia.org/wiki/Init) and alike usually do?
This is perfect, thanks. I was able to get a quick bandaid solution with `nohup ./http &amp;`
To support different data formats I now usually do a type switch across the types returned by the Golang sql package and then deal with them accordingly. But this feels error prone - if I forget possible tiles that might be returned. Are there better solutions? switch value := (value).(type) { case []byte: charData = xml.CharData(string(value)) case int64: charData = xml.CharData(fmt.Sprintf("%d", value)) } I had alot of problems parsing arbitrary SQL queries into a map of interface{} until I found the https://github.com/jmoiron/sqlx package which supports *MapScan* to do just that.
screen session or a tmux session. These are really good for quick hacky solutions, just pipe the output to a log file and you're good to go. screen -dmS &lt;screen_name&gt; ./http &gt; out.log 
This. Screens.
Out of curiosity, what's the difference between the attribution requirement for BSD and MIT? I thought MIT did require attribution, is the difference just that you don't need to attribute it in the binary? http://programmers.stackexchange.com/questions/218331/what-are-the-requirements-for-attribution-in-the-mit-license Also on quora: https://www.quora.com/Does-the-MIT-license-require-attribution-in-a-binary-only-distribution
My gut says you should mount an EFS share as a volume inside the DB container - here's a [guide to doing that](https://aws.amazon.com/blogs/compute/using-amazon-efs-to-persist-data-from-amazon-ecs-containers/)
- I find it easier to run postgres containers with persistent volumes for storing the data. You need to take care when upgrading from e.g. postgres 9.4 to 9.5, though - Your application needs to be able to handle the migration, or you need to do it by hand (not preferable). With postgres and its excellent flexibility it's also possible to e.g. create versioned schemas that use e.g. views or functions to offer the same data to different versions of the application
Here you go: https://gist.github.com/montanaflynn/b59c058ce2adc18f31d6
Who cares. Let them be how they want to be. There are plenty of other places to go on the net and this world. 
I'm using GeoJSON as an intermediate format, as long as you can get every points of your shapes, it will work. I'm planning of using OpenStreetMaps data, there is no reason not to. S2 is to my knowledge only used with WGS84 (it's already an approximated projection on a sphere). Here are some details on S2 https://docs.google.com/presentation/d/1Hl4KapfAENAOf4gv-pSngKwvS_jwNVHRPZTTDzXXn6Q/view#slide=id.i0 regionagogo is a response to a specific problem: get the country/states for coordinates, I don't recommend using it for anything else, but the technique described here will work for many situations. I plan to build something more generic. EDIT: S2 and WGS84
Sounds interesting. Can you provide a little more color on what you mean by "precalculated rectangle lat/long based shards"? Maybe a example would suffice.
Why not use nginx?
Wasn't aware nginx supported this. I'll take a look.
I mentioned other projections, because only dabbled a bit with map rendering using mapnik and [ESPG:3857](http://spatialreference.org/ref/sr-org/6864/) aka "google projection" seemed easier to calculate here a tile begins/ends. One of the things that i have found a bit lacking in the OSM stack was a specialized (and distributed) database. Are you planning on building something along those lines ? That would be a cool project.
I've been working on this https://github.com/goburrow/netforward which might meet your need. nf -certFile /to/cert.crt -keyFile /to/cert.key -caFile /to/ca.crt -address :8443 -remote.address :8080
You can even get nginx to do TLS termination, and pass the client certificate as part of the headers.
How would one go about serving multiple users?
I can highly recommend tutm https://www.tutum.co/ to help in managing you environment.. it helps abstract away allot of the management work and when integrated into dockerhub for your images provides a very easily managed environment..even accross providers.
I'm the author. I've been working on this for a long time and I think it's at a pretty good state. I know of a few companies in Japan using this in production. I would love to receive feedback on improving the API, or features you would like to see. In particular I'm looking for suggestions on a nice API to create tables, and perhaps a way to specify hash/range keys as struct tags (indices make this tricky).
Or just use RDS. https://aws.amazon.com/rds/
Try hitting it from a private tab or another browser to see other accounts as options. Since the account in the main instance probably already gave permissions the flow is faster and doesn't require you to select an account again until you've logged out from the service.
SupervisorD is great for this, I also use it with node http://supervisord.org/
Also: https://godoc.org/go4.org/legal
Yea, it uses Google remembering. Actually, setting up Github or Facebook is pretty similair, you just have to get the secret keys and client IDs. In Addison to the Google library use the other proper you want.
only problem is ffmpeg is backed by a religious cult known as GPL GNU
DI is a wonderful pattern, but when I was talking to the author about this practice we discussed how this was not very Go-like, it's almost an anti-pattern. The question is, is that because DI has no place in Go, or is it because the Go community just hasn't tried it out in a comfortable way yet? I'm not sure I know the answer yet.
&gt; Golang is not the language to solve every problem with, and *in the field you're going into, it's rarely ever the right tool because the goal isn't building robust software, it's studying data.* This is why we can't have nice things. 
So you'd say that was a bad approach overall? Do you have any best practice examples?
Standard encoding/json is used for for JSON serialization - see https://github.com/TechEmpower/FrameworkBenchmarks/blob/ae151145d6df37d4d6b494574b69feb9d0b06787/frameworks/Go/fasthttp/src/hello/hello.go#L230 .
Try adding the following features: * [If-Modified-Since](https://varvy.com/ifmodified.html) support. This allows saving network bandwidth when clients request the same file multiple times. * [Byte range](https://en.wikipedia.org/wiki/Byte_serving) support. This is useful for serving large video files. * Add [transparent response compression](https://en.wikipedia.org/wiki/HTTP_compression) for saving network bandwidth when serving files with high compression ratio such as js, css, html. * Optimize it for speed. See [fileserver example](https://github.com/valyala/fasthttp/tree/master/examples/fileserver) built on top of [fasthttp](https://github.com/valyala/fasthttp) for the inspiration.
Yeah ffmpeg is probably the way to go, try the Go bindings for ffmpeg https://github.com/avelino/awesome-go#video
Thank you for the feature list, I will work on them! Fasthttp looks really interesting! I think I can learn a lot from it, I will start with the FAQ and the tests. :)
The [Boost Software License](http://www.boost.org/users/license.html) explicitly does not have this obnoxious requirement.
Or on Dokku running inside a 5$ DigitalOcean droplet. Fully compatible with Heroku build packs.
I just wanted to say that that webpage is so well-done.
Nice! Cross compile for ARM/Linux and throw it on a Raspberry Pi or similar single board computer for a cool headless jukebox for your speaker system.
Good to see! Are there any special flags necessary to activate it for compilation?
Doesn't seem like it. It would surprise me if that was the case. The Go folks have been strongly anti-ifdef in all code they wrote.
I haven't tried but have you looked at https://plugins.jetbrains.com/plugin/?id=5047 ?
Effects on the go1 benchmark suite: [link](https://docs.google.com/viewer?a=v&amp;pid=forums&amp;srcid=MDQ5NTA0MTA1MjI2MzE3Njg4OTIBMTE3NDA3OTc2NDY0NTc0OTIwNzcBZF9laHlmUE9DQUFKATAuMQEBdjI) Also Keith wrote in the ML that * the SSA compiler (with development consistency checks turned off*) is 10% slower than go1.6. * SSA-generated binaries are about 5% smaller than tip-generated binaries. * Work will continue on the SSA compiler - we expect the numbers below to improve \*please note that right now the development consistency checks are on in the main branch (but they plan to turn them off for the 1.7 release)
My main point here was that instead of munging your binaries in exotic ways, you might want to change what actually goes into them. Edit: I don't feel like picking this particular bone.
What problem did you encountered with it? I would recommend opening an issue on the tracker (and please follow the template) and I'll be able to help you get this done. 
Apologies in advance for the ghost theme I'm using, I know it's shit, I'm replacing it soon. 
&gt; the SSA compiler (with development consistency checks turned off*) is 10% slower than go1.6. That's actually great news, since there were a few doomsayers when the SSA compile-time impact was mentioned. 10% is tiny, and I'd suspect that to disappear prior to 1.7.
I thought there were going to be efforts made to recover from the compile speed loss from 1.4-&gt;1.5 before merging in the SSA compiler for 1.7. Will gc ever be at least as fast as 1.4? 
I hope in a year or so someone will compare optimizations in Go compiler(s) vs LLVM. I have heard a lot of times Go compilers are missing many optimizations compare to LLVM.
Good idea! I'll try and get one up tonight. 
My understanding is that the introduction of ssa is a step towards improving compile times. In particular ssa makes certain classes of optimisations much easier to implement: https://en.wikipedia.org/wiki/Static_single_assignment_form#Benefits Now that the ssa branch is merged Id guess that they're going to start putting more effort in to making these optimisations a reality.
This meme about targeting C++ programmers should die already. Here's a detailed explanation of design goals of Go: https://talks.golang.org/2012/splash.article What Pike once said is that he thought that C++ programmers would find Go attractive (based on the fact that Go is much closer to C/C++ than it is to Python or Ruby) but it turned out that Go has seen more migration from Python/Ruby etc. programmers than from C++ programmers. This is not even in the same universe as saying "we designed Go with the goal of attracting C++ programmers". 
I don't think it's a good idea to call `log.New` every time a message is sent. 
Is it possible you can try using the 1.4 compiler also?
If you're on AMD64, you're using the SSA backend unless you explicitly disable it.
SSA is better for the long term. 
Hi, I'd be happy to hear what (concrete) problem does this solves. Imho the biggest issue with (generic) containers is that the compile time checks are lost so you'll need to run tests to get this back. Thanks.
May I be added to the repo so I can submit a pull request? [\[Link\]](https://github.com/itsmontoya)
This one perhaps? https://github.com/mitchellh/mapstructure
A lot of the issues in the article aren't specific to Go, although I think the author touched on that point a bit. If you want a tl;dr: don't do extra work if you don't need to. Need to use the string version of a number multiple times? Don't convert the number to a string each time, do it once and reuse the string. Need to use data from the DB? Buffer it so you're not incurring the overhead for every operation.
You don't need any permissions to send a pull request to a project that you fork on Github.
Stopped reading at Mongo"DB".
I didn't want to fork it. Just wanted to pull a branch, submit pull request, and be done.
Folks have been complaining about some javascript scrolling issues. I thinkt that's just on mobile though!
&gt;unfortunately what i do involves C libraries, so i'm never the beneficiary of fast compile times :( You could vendor the bindings into a separate package and precompile them, this makes compiling code that calls C libraries crazy fast. Of course, this assumes that the bindings don't change all the time.
Awesome PR! I was trying to figure out the best way to add mutex locking. But when I converted the type to a struct, I was breaking the map, this is perfect. Thanks! 
You tell a nice fairy tale, but the facts strongly disagree : https://web.archive.org/web/20091113154831/http://golang.org/doc/go_for_cpp_programmers.html (edit : this is from 2009, the oldest version of golang.org available on archive.org). "Go is a systems programming language intended to be a general-purpose systems language, like C++. These are some notes on Go for experienced C++ programmers." Note there was no "Go for Python programmers", "Go for Ruby programmers", or even "Go for Java programmers". Only "Go for C++ programmers". 
This looks great...Appreciate that you say it's for local dev / testing purposes, but "off the record" have you tried it in the wild, and how well did it perform?
Were you ever able to get this to work? 
What you mean with "agent based models" ?
would be nice than it could support incremental updates similar to restic or syncthing: if a file changes then you need upload the whole file instead of some bytes can it support ftp or just sftp?...thanks
Probably right on that. I created this library back when I was a young gopher and recently decided to start cleaning it up.
I don't know why you were downvoted for asking a question. Have an upvote.
Few things are more annoying when reading blogs than having animation on the page. Just making sure but you do understand that motion distracts? So my first thought when seeing animation on a page is that the author doesn't want us to actually pay attention to what we're reading.
I was thinking the same. I'd need to figure out a good way of doing that. Right now it just supports SFTP but adding FTP probably wouldn't be too difficult. I'll look into it.
depends on your definition of what a programming language is. You can actually do some very interesting stuff with it beyond just a basic stylesheet now days.
I dunno, http://stackoverflow.com/questions/2497146/is-css-turing-complete :)
Alright, alright, gifs frozen
I find it a bit odd that the author didn't mention wait groups. They're sort of the canonical way of solving channel closing synchronization. The fact that this trivial example which is a bad fit for channels in the first place can be solved with a mutex doesn't really illustrate much on its own, but the lack of discussion about the actual solution is odd. That said, quite often with channels, the only solution for bridging a gap between a channel API and a function API *is* to spin up an unnecessary goroutine. For example, with a WaitGroup, somebody has to be waiting on the WaitGroup in order to respond when the channel is ready to close. Since the consumer cannot itself select on both WaitGroup.Wait and the input channel, it has to be a different goroutine, and the most straightforward solution is just to create one specifically for that purpose. The other solution is to introduce yet another synchronization point to ensure only one of the producers calls Wait, so the others can exit. ---- There is a good reason why nil channels behave as they do. It allows you to turn off cases in a select. When a channel closes, if you change it to nil, then the select will never choose that case again, because sending or receiving on a nil channel blocks forever. Of course, you do need to account for the possible case of *all* branches being disabled, but that's relatively straightforward.
This is how you would do it with Gorilla Mux (we do the same thing with EmberJS): router := mux.NewRouter() router.HandleFunc("/{rest:.*}", emberHandler) func emberHandler(w http.ResponseWriter, r *http.Request) { emberView := template.Must(template.ParseFiles("index.html")) if err := emberView.Execute(w, nil); err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } } Does this help?
&gt; But holy smokes, let me tell you about the first time you decide you might need to select on multiple things but you don’t know how many and you have to use reflect.Select. Or chain multiple channels together. If you don't know how many things you need to select over, it should always be possible to do a fan-in into one. Yes, that needs possibly a goroutine per thing.
Enjoyable article. I mostly agree and the things I really disagree on I brought up in other comments. So thanks :) In regards to channel-GC, I might also add, that the GC could not only collect channels when it knows there are no more values coming down, but also that there are no more readers. In that case the channel shouldn't be closed, but the goroutine simply reaped. This would enable channels to be used as concurrent iterators (because currently that's of course impossible due to leaks). I brought that up before and it should be actually possible within the go1 compatibility guarantee. A program that has a goroutine blocking on a send that can never be received (or the other way around) is semantically equivalent when you just kill off that goroutine at that point. The same is not true for your closing behavior, because this introduces a semantic change.
Any idea on how to do it with the default libs, or https://github.com/julienschmidt/httprouter ? 
&gt; I find it a bit odd that the author didn't mention wait groups. They did. They are one of the "other synchronization primitives".
&gt; Spend some time planning and designing a set of structs that describe the document and then using the Un/Marshaler interfaces you can parse virtually ANY JSON document without resorting to such measures. Do your structs have to be complete. Does unmarshaler ignore missing fields?
This is a collection of bad ideas, founded on misunderstandings, wrapped in a rant that borders unreadable. I could nitpick all the little things, but let's just choose this: &gt; Go’s theoretical underpinnings are heavily based in Hoare’s CSP model, [..] &gt; As soon as you [...], bam, you’re no longer in pure CSP land. Let's compare that with what the authors themselves say: https://golang.org/doc/faq#ancestors &gt; Go is mostly in the C family (basic syntax), with significant input from the Pascal/Modula/Oberon family (declarations, packages), plus some ideas from languages inspired by Tony Hoare's CSP, [...] So, "heavily based" and "pure CSP" vs "some ideas [...] inspired by [...] CSP". 
Why do have same handler for both "/" and "/about"? Both needs to have their own separate handlers. When someone goes to localhost/about, "about" handler needs to respond not "/". Additionally your js app can send special headers that you can parse on your middleware or something to distinguish between SPA call and normal call.
I much prefer http://eagain.net/articles/go-dynamic-json/
Well, your structs must represent whatever you expect and need. Fields that are not present in your structs are dropped, yes. When the JSON can have "any" structure, you can always define different structs to represent your document blocks and use interfaces to allow nesting. Then these structs can un/marshal themselves. Operations like GetChildren(), GetParent(), GetSiblings, etc. become very easy. Even checking whether values exist like the example above Find("path/which/does/not/exist/separated/using/slashes/") are not a problem. The difference is that you don't need to use reflection (ignoring of course the fact that the json package is using it under the hood) to get to the values you need + you keep the static typing. This works extremely well.
Many users of context.Context simply call context.Background() for their first context. The context that is returned is a global singleton (check it out: https://github.com/golang/net/blob/master/context/context.go#L187) and Done() never fires. The Context interface never guarantees that the channel Done() returns closes in the general case.
Let's say you have a structure Document Id string UserDefinedData map[string]interface{} // &lt;- user can change this structure property only SystemMetaData SystemMetaData BillingMetaData BillingMetaData User has a validation `schemas` for his documents. So, let's assume that `UserDefinedData` is always correct ( in a way customer sees it ). We do not know what properties are inside of it, because the `schemas` can be changed any moment user decides. The user wants to `PATCH` some document's properties. He sends a `PATCH` to his document's property `/user/accounts[0]/facebook/is_active/` with any body content. So, backend needs to: * get a document from a database * build a graph of property dependents ( using the `schema` of a document ) * change the document's property &lt;- this is where we use a `UpdateProperty(document, "/user/accounts[0]/facebook/is_active/", &lt;payload&gt;, "/")` * validate the document using user's validation `schema` * update a document in a database. The schema of a document is a `jsonschema`, saved as a map in a database :D
If you are going to use construct that was not designed for sharing data globally data to share data globally, you're gonna have bad time. Yes, first example is trivial and clear to do using mutexes (or `sync/atomic` if you wanna be fancy). You should just do that. Channels are great when you have defined data flow and your goroutines do "receive, parse/merge/split, send". Yeah they could use a bit of fixing (especially panic on close...) but if you are not trying to use channels just because they look cool at a glance, you'll be fine. And callbacks are even bigger mess in most languages and really fulfill same purpose as channels
:D Nice to know that someone else is doing similar things :D
Bikeshed
Yep :)
True, thanks, I take it back :)
tied with haskell interestingly enough
I'd assume that future versions could also run parallel sub-tasks for many compilation units.
Yes that's true, though I would presume that currently there are some low hanging fruit available in terms of optimisations, where the execution time improvements outweigh the cost of the optimisation resulting in a net improvement in compilation time.
You can't dispute that this behaviour is pretty odd though: &gt;**Closing or sending on a closed channel panics**! Why? If you want to close a channel, you need to either synchronize its closed state externally (with mutexes and so forth that don’t compose well!) so that other writers don’t write to or close a closed channel, or just charge forward and close or write to closed channels and expect you’ll have to recover any raised panics. &gt;This is such bizarre behavior. Almost every other operation in Go has a way to avoid a panic (type assertions have the , ok = pattern, for example), but with channels you just get to deal with it. &gt;Okay, so when a send will fail, channels panic. I guess that makes some kind of sense. But unlike almost everything else with nil values, **sending to a nil channel** won’t panic. Instead, it **will block forever**! That’s pretty counter-intuitive. 
nil channels behave the way they behave so that you can write for-select loops that behave the right way in all circumstances, setting a channel variable nil where appropriate. Closing or sending on a closed channel is a programmer error; avoiding it is done by programming the right happens-before relationship so that you don't use close or send on closed channels.
Don't get me wrong, Logrus is a great logging library! I just can't stand looking at FATA[0000]
&gt; But unlike almost everything else with nil values, sending to a nil channel won’t &gt; panic. Instead, it will block forever! That’s pretty counter-intuitive. To elaborate a bit on the Tv's reply, that `nil` channel behavior allows to implement `select` clause *guards*. Compare to the (very similar) `select` operator in Ada: https://en.wikibooks.org/wiki/Ada_Programming/Tasking#Guards In Go you'd set a channel type variable to nil when a guard evaluates to false.
Or, to put it another way: If closing a channel twice is a programming error that warrants a panic, then so is closing a closed *os.File. Yet, no one ever suggested panic'ing there and everyone is fine with just returning an error.
That is a *bad* TL;DR. Not only does it drop a lot of stuff from the article on the floor, but it would be far more apt to summarize it as "I *shouldn't* have to worry about any resources I allocate". And I tend to agree (apart from the obvious fact that any resource is finite). There is no inherent reason, why the arguments for a GC don't carry over to goroutines and channels. GC was chosen for go, because it reduces cognitive burden and it makes it possible to create simpler APIs. The very same arguments go for goroutines. If goroutines would be collected instead of leaking, that would reduce the cognitive burden *greatly*. And it would also make some APIs simpler to express (for example iterators, or notifications).
Oh, as a piece of evidence btw: You can't implement [time.Timer](https://godoc.org/time#Timer) yourself for *exactly* the reasons outlined in the article, without significantly changing the semantics. time.Timer needs extensive help by the runtime to provide the semantics it does without resource leaks. It would be *trivial* with the changes outlined in the article.
This game was made entirely in css: http://jsrun.it/GeckoTang/4rXg/
Or you could `go install` instead of `go build`-ing each time you make a change. 
FWIW, if you use select only Go using the visualization we provided at the bottom, here's the trajectory over time: http://sogrady-media.redmonk.com/sogrady/files/2016/03/go-plotted.png
hello. i have installed the plugin.. but how to i build or run?? The "run configuration" has [none] in the module area, and shows this as being the problem. also, setting the SDK location shows the version as "N/A" 
Well Java marketing guys changed versioning scheme so java 1.8 is called java 8. But hopefully Go 1.8 will remain Go 1.8. :)
IMO, having to select over N channels is *usually* just a sign of bad program design in the first place. In all likelihood the N goroutines sending into those N channels should all be sending into just one channel in the first place.
Interesting. Thank you.
Just a quick update, we made the whole screenshot a clickable link so it should work better on mobile. We also improved the way it's displayed to make it clearer it's a quick preview and not intended for actual reading on our site. And we'll keep on looking for ways to make the site better and better on mobile.
Same update here as to the other commenter above, we made the whole screenshot a clickable link so it should work better on mobile. We also improved the way it's displayed to make it clearer it's a quick preview and not intended for actual reading on our site. And we'll keep on looking for ways to make the site better and better on mobile.
Yes, but I meant more specifically. What I'm really taking issue with is the idea that if you can't use channels for everything then they're bad. I get that some people like to express themselves hyperbolically, but it's not particularly constructive here. There's a reason why other synchronization primitives exist in the standard library.
Actually I think you are wrong. I am fairly sure one could implement their own time.Timer in pure go if they wanted to. But it would require (at some level) Somebody worrying and thinking about resources allocated.
&gt; There is no inherent reason, why the arguments for a GC don't carry over to goroutines and channels. If goroutines were garbage collected like memory then a deadlock would mean all your goroutines disappear. Have fun debugging that.
You don't always have full control over your whole program, so arguments like this are weak. For example, [time.After](http://godoc.org/time#After) gives you a `&lt;-chan time.Time`. Imagine needing a variable number of timers (for example for cron-like behavior). fan-in is the only solution here.
&gt; What I'm really taking issue with is the idea that if you can't use channels for everything then they're bad. But they also mentions *why* they think this. Because channels and traditional synchronization primitives mix badly. (I don't really *agree* with that sentiment, but you can't claim they didn't explain themselves).
Buffering doesn't help because you would just fill the buffer over time (with Ticker) and using select with a default for send wouldn't help because you might send before the user receives from the channel and the value would be dropped (and then the user would block indefinitely waiting for a write that never comes. Or at least *much* later than expected). Believe me, I have thought about this. I tried implementing it for a while and I didn't succeed. Unless you come back with a working implementation, I am thoroughly convinced that it is not possible.
Learn how to use ssh, scp, and then rsync. Then make a script to automate your deployment with rsync and ssh. Use Cygwin and/or a Linux VM for this if you're on Windows. You should be using key-based authentication, and password login should be disabled on your server. This lets you do something like: rsync -avz localdirectory user@website.com:/home/user/directory ssh user@website.com 'go build /home/user/directory &amp;&amp; killall appname &amp;&amp; /home/user/directory/appname' I prefer to keep my server applications running in a tmux window, so I close and restart them manually in my interactive ssh terminal. Note that running a single command using ssh (not in an interactive shell) may have a different PATH setup than your average interactive session. That can be configured in your server's .bashrc file.
&gt; I brought that up before and it should be actually possible within the go1 compatibility guarantee. A program that has a goroutine blocking on a send that can never be received (or the other way around) is semantically equivalent when you just kill off that goroutine at that point. The same is not true for your closing behavior, because this introduces a semantic change. While correct, this has the unintended side effect that deferred statements never run. It would be better if this created a panic so the stack is unrolled and all deferred statements execute, but right now, an unhandled panic in a Go routine is, let's say, problematic.
This is why I wrote "usually". :) Fan-in solutions certainly have their place, I just find that they're not commonly needed in practice. (I've *never* had to use reflect.Select.)
At that point, N calls of time.After would be the wrong thing to do, you can easily manage just the earliest-firing timer.
Because `(*os.File).Close` has an error return anyway. Do you really want channel send to return an error?
Most straightforward way would be to break the API guarantee and force the user to release it, with something like t := time.NewTimer(...) defer t.Close() This can be avoided for time.After by buffering the channel on the assumption that it only writes once.
Now you're switching your argument from Timer to Ticker. Ticker can drop ticks if the receiver is slow, it's in the docs.
I really appreciate the info, but this post very much sums up everything that has overwhelmed me so far. What is ssh, what is scp, what is rsync, what is tmux? Are these the first things I should learn before I go any further?
&gt; While correct, this has the unintended side effect that deferred statements never run. No, this is an *intended* side-effect to not change the semantics of current programs and not break the go1 compatibility guarantee. If a goroutine is forever blocking, defer'ed statements aren't run *either*. &gt; It would be better if this created a panic so the stack is unrolled I believe this would be strictly worse, because a) it makes programs crash that currently don't crash and b) it removes power from the proposed semantics (namely to return channels as iterators or event notifiers). It also has hard to argue about consequences for the correctness of some programs using channels (i.e. if the correctness depends on "this will never unblock until someone writes to the other end", this might break programs in unpredictable ways).
I assume FullHD. It looks the same on my FullHD screen (though I don't mind. I also don't mind the GIFs, btw, neither before nor after).
I implemented the buffered version (edit: of time.After, that is). It leaks memory. [edit] Again: Bring me a working implementation to convince me, not ad-hoc explanations.
Reading through the runtime package it looks like it uses a select on send and throws away unrecieved ticks. Maybe there's more magic in there that's not obvious to me. 
Do you really have to play Nancy Drew looking for clues and reading from tea leaves when https://talks.golang.org/2012/splash.article lays out the design goals of Go explicitly. If you're too lazy to read it, here's the bottom line: "When Go launched, some claimed it was missing particular features or methodologies that were regarded as de rigueur for a modern language. How could Go be worthwhile in the absence of these facilities? Our answer to that is that the properties Go does have address the issues that make large-scale software development difficult. These issues include: * slow builds * uncontrolled dependencies * each programmer using a different subset of the language * poor program understanding (code hard to read, poorly documented, and so on) * duplication of effort * cost of updates * version skew * difficulty of writing automatic tools * cross-language builds " Those are the issues the designers tried to address. Notice lack of "we designed a language that C++ programmers will like". C++ is only mention in the context of having problems that Go is trying to solve. You really have to twist yourself into a pretzel to claim that being frustrated by C++ and trying to design a language that is anti-C++ means that you're trying to design to attract C++ programmers.
or just use iptables like any other normal human being, without overhead of running processes.
Neither maps or type assertions are programmer errors. If you're checking the error anyway, you can use the error. Panics are only relevant for when there's no error mechanism.
https://github.com/golang/go/commit/3b860269eeb0b2d6176da5c972139b7c21d5251b
Also, `time.After` is not the only API that returns a channel; it's just an example of an API that expects the caller to use `select`, which is the one case where channels as part of an API make a lot of sense. As an example that's less likely to make you scream about cheating with runtime, `net/rpc` has a `.Go` variant that provides a channel, `/x/net/context` has `Done`, etc. The commonality is that they all expect to be used in a `select` that does different things based on what happens first.
&gt;May be it is not really as popular as its proponent make it out. Probably true for any programming language ;) 
&gt; to contribute to the project you have to sign a license with Google Alarm bells are ringing. I guess the question is is it risky for a company to use Go with regards to specifically googles relationship with go? I mean what can Google actually do to disrupt an open source language?
Well, if you are going to say go minus one package then maybe it can't be done. It for sure could be done with a small help of the runtime package. Mainly the finalizer. The main thing the rest of the runtime stuff is used is to be fast and efficient. But that is not what we are arguing here. A pure go implementation would require use of runtime package and would have a bit more overhead, but it could be done. I am not going to even attempt to show you if you cry foul for me using a finalizer. EDIT: Also, I think adding all these other restraints are stilly, you are programming, if you need to use unsafe or cgo or anything else it is not trickery, its programming. 
I agree with you on this. Just taking a look at the runtime support a bit part of it is so you can have a ton of timers and it would cost you about as much as a single timer as far as processing goes. 
&gt;Alarm bells are ringing. Not really. You just swear that you aren't willfully infringing patents, release your copyright, the standard stuff. It's the same as any project but it's Google-specific. 
I don't work for Google, so this might not be 100% accurate, but... Google requires CLAs for contributions to code that Google 'owns'. Google 'owns' Go for reasons you can [read here](https://www.quora.com/Does-Google-require-that-employees-grant-them-the-copyright-to-all-code-they-write-while-employed-by-Google-or-are-employees-allowed-to-own-their-own-non-commercial-side-projects). Go's creators (Robert, Rob, and Ken) were all Google employees and afaik created Go *at* Google, not outside on their own. (I know somebody will correct me if I'm wrong.) Google can't really disrupt an open-source, BSD-licensed language because anybody can easily fork it and continue the development themselves, [even if Google changes the license.](http://programmers.stackexchange.com/a/173198/130374) Plus, AFAIK Google is pretty hands-off with Go. You don't need to worry about anything. Bigger companies like Cloudflare use Go -- it's safe.
This. You can also checkout various Cloud Foundry based PaaS like Pivotal Web Services and IBM Bluemix, all of these support Golang apps. 
Tested and confirmed that it is memory leak free, though it does use three times more memory than the standard library implementation. 
&gt; Plus, AFAIK Google is pretty hands-off with Go. You don't need to worry about anything. Bigger companies like Cloudflare use Go -- it's safe. Depends what you mean by hands-off. They have a dedicated team working on Go if I read the AMA right.
&gt; Why not use structs to define the expected structure of the document (API response)? Serious question--what if you don't know the structure? Obviously, one can log the response/use curl/postman/etc to figure out what the strucutre of the data will be. But what if you are dealing with a large JSON? Or if you have a JSON where a property either has a nested JSON (or multiple levels of nesting) or an array of JSON (basically really complex JSON structure)? How would you handle these cases? I'm actually working on a project at work where I'm making multiple calls to a REST API and I'm getting complex JSON back. I could technically spend the time to create the structs out but currently, I'm just converting my response to a map[string]interface{} cause I'm on a time crunch. It works but its pretty messy at the moment (lots of type assertions). 
It sort of depends on your time horizons. Learning how to run a Linux box is a useful life skill, but it takes a long time. If you are in school, may as well spend the time learning. If you have a job, may as well do the fastest thing to get a real live result. 
Running your app on a server is exactly the same as running it on your home computer. The only difference is now you're running it on someone else's computer. What operating system have you been using while developing the app? Do you have basic command line knowledge? The direction I would point you in depends on what you already know.
There is something wrong if you don't have control over your whole program... In your example for a cron-like behavior I would not use time.After. I would have a single loop that would wake up every second and check the heap and see if the next timer in the list needed to be triggered. If not go back to sleep. You would be surprised, that is almost exactly how timer.After works with the exception of being able to have a much finer relsution than 1 second clocks. In short some times you have to actually write code to do what you want and not rely on the system packages entirely. 
According to the Go authors, panic on close is a feature. I once suggested that closing a channel should be idempotent, and the response was very definite - panicing reveals latent bugs, and is a feature. That is probably true, but I find that it makes for brittle programs.
Fuck your memes.
I have not finished it yet, but it is close to being done. The only thing left would be to add the futex_wait in and it would be done. But obviously that is trickery.. But I think it can be done with with the syscall package. But you might be able to replace the futex_wait with a syscall.Select. I don't have time to mess with it any further. https://play.golang.org/p/gv1-jFxAry EDIT: this is mostly how the core timer package works btw. 
Your point that an goroutine may never be cancelled is true (if cancel() is never called) but it _can not_ be garbage collected while you have a reference to it...
You could also just do neither.
&gt; Serious question--what if you don't know the structure? &gt; But what if you are dealing with a large JSON? Or if you have a JSON where a property either has a nested JSON Did you read any of my other posts? It's exactly what I am talking about :)
&gt; but if you are not trying to use channels just because they look cool at a glance, you'll be fine. The article reads like this is something the author sees frequently. I think it's a primary point -- a lot of people new to Go think they should use channels for lots of stuff because they are a novel language feature. In the few hundred thousand lines of Go code I've written, channels have been a good solution maybe twice (not counting time.Tick).
since this was a problem to many more languages before go i have create a package that abstracts the implementation of a logger. You can plugin, switch to whatever you like on program startup and don't have to worry about anything. Instead of directly depending on one of the many good implementations out there you just use a abstraction. [adaptlog!](https://github.com/mantzas/adaptlog/)
&gt; There is something wrong if you don't have control over your whole program... No, there *really* isn't. In my world, code reuse is a *good* thing. &gt; In your example for a cron-like behavior I would not use time.After. I hate it when people come up with ad-hoc explanations and ignore what an example or comparison was trying to illustrate and instead nitpick and discount it on the things they see wrong with it. That is not fruitful discussion, that is verbal fighting to see who is the rightest. &gt; In short some times you have to actually write code to do what you want and not rely on the system packages entirely. This is not a convincing counter-argument to "the arbitrarily chosen channel semantics make them far less useful than they need to be".
&gt; That's not the point I'm trying to make. What I'm saying is, that this creates a situation in which deferred statements are never run. Untrue. My informal proposal doesn't change the semantics of *any* program, so the only way for a deferred statement to never run *with* it, is that it also doesn't run *without* it. It doesn't create such situations. &gt; Adding behaviour that makes such a Go routine not a bug in your program causes a legitimate way to have a deferred statement never run, which is a terrible thing. But that's still a bug? We currently expect programmers to know that their goroutines don't block forever. Why can't we expect of them to know that their goroutines either don't block forever, or don't cause a deferred statement to never run? &gt; So all together, much more had to be changed I disagree. You might *want* to change more, but there is no real good reason. My idea doesn't create new bugs, it just makes some current-bugs into non-bugs.
Awesome. Your post just went from shit-my-pants intimidating to you-can-do-it-buddy reassuring. Really appreciate it. 
Cool, thanks. I set up an account yesterday. Didn't have my credit card handy, so I'll try spinning up a droplet later today hopefully and just go step by step and try not to get bogged down.
I didn't say "solvable by static analysis". I suggest you assume the best in the people you are talking too, which includes that they have a basic computer science education. The halting problem has precisely nothing to do with this. This is a dynamic problem. But let me rephrase: I am convinced there is a solution that is not worse than the current deadlock-detection and probably better (because you can detect more cases in which a lockup occurs).
&gt; Well, if you are going to say go minus one package then maybe it can't be done. It for sure could be done with a small help of the runtime package. Mainly the finalizer. Go ahead. I'm *genuinely* interested in the solution, as I couldn't come up with any. &gt; EDIT: Also, I think adding all these other restraints are stilly, you are programming, if you need to use unsafe or cgo or anything else it is not trickery, its programming. If you think they are silly, you didn't understand my point or the point of OP. Because this is about restrictions the language puts on you. If you circumvent those restrictions, *of course* everything is possible. You can just implement your own language with whatever semantics you choose. But I am not trying to be unreasonabl. I'm not trying to find anything wrong with solutions, I'm just trying to make clear why I don't think there is any, within the restrictions set forth by the language.
ARGHX, I shouldn't post to reddit when I'm tired. Sorry for the noise with this.
First you tell me I didn't have to point to an old link since I could try to prove my point with the 2012 link. Then you tell me the 2012 link actually proves nothing. Ahem. (as a meta-side note : that reference to Nancy Drew was fun, btw. Poirot and Sherlock are too much cliché, and Drew is more ridiculous, so that adds spice to the argument, I like that). 
Dates are important. The point I link to is the very first public website for Go. It describes Go as a systems programming language, whose performances are on par with C/C++, and can be used in lieu of C++. Then it contains a link "Go for C++ programmers", and no other link "Go for XX programmers". When they made Go public, they were mainly talking to C++ programmers. The very fact that your link "Go for pythonistas" is from 2013 while "Go for C++ programmers" is from 2009 says a lot about who the supposed target initially was, and who it is now. I don't know why people are in a denial about that. There's nothing wrong about not being used by those you originally expected. Many languages lived like that (Pascal/Delphi, BASIC/VB, Ada, Java, ...). Actually, what made me look at go early on was precisely because I was a frustrated C++ programmer and I read about that "new systems programming language designed at Google". 
So, not use channels?
This looks extremely useful, reminds me of https://github.com/getsentry/responses. Nice work :D
The flaw in your mental model is that it is not the channels that are synchronized, but that the goroutines synchronize over the channel (regardless of whether channels are buffered are not.) When a goroutine comes along and reads from an unbuffered channel (say), it is put to sleep. When the second comes along to write to the channel, an atomic transfer of data happens from the second to the first, and the first one is made runnable again. Now the goroutines are the reading and sending entities, and point to the to the channel. If the reading goroutine quits, it is gc'd. The channel is gc'd only when the sender exits and gets gc'd too. However, if the sending goroutine happens to use the channel, it gets blocked for ever (since no reader is going to show up), so it and the channel will get blocked for ever.
So for example when reading goroutine quits and gets gc'd before actually reading while sending goroutine is still waiting that's where block happens? 
Just because you already have a left shoe does not man you should cram it on your right foot for the sake of reusing it. It may work, but you are going to have a lot of problems. You picked the arbitrary solution and problem. You can't go around blaming the code or the language for not handling it how you wish it to handle it. In your case, spawning a thread or gorutine for the sake of making a cron is just a bad idea and terribly inefficient. That is the entirely why runtime handles time ticks and sleeps using the systems it does. 
https://github.com/MichaelTJones/walk Fast parallel version of golang filepath.Walk() 
Yes, that's correct. Sending goroutine has no idea whether the channel its blocked on will ever be read by another.
If you can saturate the disk with goroutines, do it. You have to test out on your hardware what's the best way to move forward.
Thanks a lot for the breakdown. Definitely feels manageable now. Is setting up a production MySQL/MariaDB database also pretty much the same as setting it up locally? I'm just worried about creating gaping security holes if I do it wrong. 
On HDD it might be slower, because you have to move head for each read. On SSD it should be significantly faster.
it's still a WIP package. - I plan to also provide write access. - I may modify the `Reader.Read()` api like so: `func (r *Reader) Read(valptr interface{}) error` - support for `.npz` files (need some pickling support)
Waiting for the mass of nodejs refugees
Almost 8 months of work: https://github.com/cznic/c/commit/cf0f504e0fc33dd6dec16a0446e64085cc57a2fc
[I found the article I was looking for.](http://commandcenter.blogspot.cz/2012/06/less-is-exponentially-more.html) There's no way Go wasn't intended as a replacement for C++, or, more specifically, as a language to write the replacements of Google's legacy C++ services in, even if it weren't supposed to be some kind of general C++ replacement for everyone.
Installed and trying it out. This looks pretty good so far. * Go to definition works * Peek definition is a nice feature if you don't want to go down the rabbit hole * Autocomplete works well * Type info on hover is a great feature * Lint/fmt on save works as expected The visual debugger looks appealing, I definitely want to get that working.
(Just my opinion.) Saying "mutex is bad" and "channels are good" is like saying "strings are bad" and "structures are good". They can't be good or bad, they can only be good or bad *for a particular task at hand.* If you need a mutex, you shouldn't try and shoehorn a channel-based solution. And vice versa, when a problem requires concurrent messaging, creating your own solution by building pseudo-channels with mutexes, conds, and slices is just silly. As for OP's questions, the Go concurrency patterns slides have nice examples of how and when to use channels: * http://talks.golang.org/2012/concurrency.slide * http://talks.golang.org/2013/advconc.slide
Honestly, if Google would decide (hint: it won't happen) to stop investing resources on Go, another big name in tech would step in and take the lead on project development, which would probably mean to hire most of the creators and maintainers of the language to work full time on it. 
Don't worry about it. Do what you think makes sense and let good patterns diffuse into your brain over time. Participating in projects with presubmit codereviews helps (for example go itself and the golang.org/x repos). Most of the discussion is quibbling on a very high level, i.e. no matter what you do in those cases, you will probably end up with something decent (and I say that as someone who participates in that quibbling *big time*).
D'oh! ... Im in Berlin that weekend before and'll leave on the 14th ... :-(
I don't know who cznic is, but there's a ton of interesting work on his/her github account.
Filenames are usually lowercase. This is not idiomatic (i.e. good Go code is tested): $ ls *_test.go ls: *_test.go: No such file or directory Good use of interface FileFetcher. Each implementation of FileFetcher should have a line that does the compile-time check that the interface is correctly implemented. This is useful documentation for the reader, it says, "look, this is important, this is one kind of FileFetcher". https://splice.com/blog/golang-verify-type-implements-interface-compile-time/ Good job not ignoring errors. Why is it not designed from the get-go for HTTPS? HTTP is old, bad news. A TLS connection might be able to negotiate HTTP/2, depending on the client, which can get you all kinds of goodness. Not to mention, frustrate the NSA, which is a nice side benefit. (Unless you ARE the NSA... hmm.) frontend.go's globals "fetcher" and "webServerConfigs" are code smell. What if you wanted to have two servers in one address space, with two different fetchers? Globals should be very rare. It is rarely a good idea to write the whole thing in package main. From the first moment, write in a package, and make a subdir which is package main with a tiny bit of code to call into your package. Then as you add features decide if they go in the library or in the cmd. When someone wants to add your feature into their project, they won't curse you for putting everything in main. -jeff
I'd say that channels are great when you are using them to handle resources that may have significant latency. Then their overhead is not significant and the ease of use is a huge win.
Another variant would be. func After(d time.Duration) &lt;-chan time.Time { ch := make(chan time.Time) go func() { time.Sleep(d) select { case ch &lt;- time.Now(): default: } close(ch) }() return ch }
I tried this out when it was first released, but not since. Does gocode still remain running in the background even after VS Code has been exited?
So, this seems to be a continuation of the c2go work that helped convert the Go compiler suite from C to Go, extended to support C99 (instead of Plan 9 C). In practice, the `ccgo` part seems to convert C code to Go, but punt on calls to libc functions. For example, https://github.com/cznic/c/blob/b453df5a4033976fc667549dc019726b6126cb37/internal/ccgo0/example1/main.c is converted to https://github.com/cznic/c/blob/b453df5a4033976fc667549dc019726b6126cb37/internal/ccgo0/example1/generated.go by https://github.com/cznic/c/blob/a2fbceaa5809b708c00ba08576e874bda5316470/internal/sqlite3/generate.go and there's a conversion of the whole sqlite3 C file there, too.
You sure know how to ask for help without being offensive.
Benchmark. Repeat.
Yes. `2125 ?? 13:34.66 $GOPATH/bin/gocode -s -sock unix -addr 127.0.0.1:37373`
My 2 cents here... Whenever I read an article about something bad in Go, there's almost always a clear explanation why it is the way it is on the [official language website](https://golang.org/doc/). I say, stick to the core documentation and its close surroundings like [gobyexample.com](https://gobyexample.com) and follow their examples. Don't hesitate to get code reviews on the Go [mailing list](https://groups.google.com/forum/#!forum/golang-nuts). People there are awesome and always willing to help. Use the [playground](https://play.golang.org/) to demonstrate to others what you are trying to do to get code reviews. Go is awesome but also very opinionated. So that's normal that there are some polarized discussions around it. Take the good things, build on it.
I agree with half of those complaints!
At first I thought "Never mind, I just don't get it" but then I got a little curious. Could someone give a simplified explanation to what this means? Usually when I come across a frontend it is a program providing a gui to a console program. Does this case of frontend mean go can somehow access the c99 using the frontend just like a human can use a frontend to access a console program with a gui?
https://en.wikipedia.org/wiki/Compiler#Front_end
Thanks a lot, will address this on the weekend
"There are only two kinds of languages: the ones people complain about and the ones nobody uses." – Bjarne Stroustrup
*shrug* Those aren't mutually exclusive.
Great! Thank you for the explanation! 
You mean jumping to definition for vendored packages? It depends on https://github.com/rogpeppe/godef/issues/13 . meanwhile, just use GOPATH="&lt;project's workspace&gt;:&lt;base workspace&gt;" for example, cd /home/my/go/src/github.com/your/hipstershit/ mkdir /home/my/go/src/github.com/your/hipstershit/deps GOPATH="deps:/home/my/go" | +--------- install global tools here (godef, ... etc) +------------------- install project specific dependencies go get github.com/some-other/hipsterthings # will go to /home/my/go/src/github.com/your/hipstershit/deps/src/github.com/some-other/hipsterthings # or, you can manually git checkout specific version You don't have to manually do stuff. Just use wgo: https://github.com/skelterjohn/wgo . Before launching VSCode (or vim or other editor that uses godef to jump to definitions), set your GOPATH="deps:/home/my/go" 
I wonder how long before people start equating this one (with the same rules and functionality) to the unfairness and horrid environment that StackOverflow supposedly has. Also, thanks for the share that looks really interesting.
First off, any article titled "X is bad" (or "X is good") need to be taken with a grain of salt. You're immediately given the information that you're about to read someone's opinion and the outcome they're complaining (or parading) may be that of an accident or misunderstanding. I've been guilty of barring something from my tool belt because I thought it was highly error prone only later to find out I was using it the wrong way and when used properly there was absolutely nothing _inherently wrong_ with it. What does this mean? Read the article, really put some thought into the complains/praise and do your diligence. Blog posts and articles now-a-days are so easy to create you've got people from beginners (not that there is anything wrong with this) to experts writing posts about X and Y left and write, day after day that you have to be extra diligent about the accuracy of what you're reading. I think it's great that we have such easy access to vast arrays of information because some people have ideas about how to use and/or do things I never would have thought. Other times I've seen reputable individuals who people implicitly openly speak against certain standard design patterns when the real meat of the article equated to "uneducated engineers don't use the pattern right, therefore the pattern is bad" which is so obviously false. A pattern is bad when there are no applications of it that improve performance, workflow, understand or any other common aspect of code and programs. The [Bogosort](https://en.wikipedia.org/wiki/Bogosort) is a terrible algorithm for sorting lists of things. That is a provably bad pattern. And no point would it be useful or wise to use this algorithm to sort a data set. Anyways, I ramble. **tl;dr** people are prone to ranting about things they misunderstand or dislike (or praise things they misunderstand or absolutely found extremely useful) but that, in itself, doesn't make those opinions the stone cold fact. Read and research what you learn, add to your what you need and understand and be careful when someone speaks in absolutes. Absolute truths are an impossibility.
Unfortunately, there's not. Is this something that comes up a lot? One of Go's design goals was to keep language size down, and this sometimes comes at the cost of an extra line or two of code, especially in less common scenarios like the one you're describing.
Not a lot no, but with how concise go lets you be other places, `:=` ,`defer` instead of `using()`-style blocks, channels instead of mutex nightmare, etc, it feels odd to make throwaway variables.
You don't need rsync or tmux to start. 
Bash is different, idk about more powerful though. 
Like everything in programming, there are right and wrong applications of any technology. It takes experience, wisdom, and a hundred thousand times doing it the wrogng way before you are able to identify and understand when something like a channel or goroutines are the right thing for the job. Even the best out there still make mistakes and will often go back and revise. Knowing who to listen to also takes a lot of experience and knowledge in its own right, and is complicated by the fact that a lot of devs out there who are in the 60th percentile think they are in the 99th percentile and often post lame articles expressing outrage or disgust about tech XYZ. For instance the blog article that made the rounds yesterday about how channels and goroutines sucked. I read half way through the long winded post before I came to the conclusion the author knew basically nothing about properly building concurrent apps in Go and **when** to use that design/language feature. Knowing kung fu isn't as important as knowing **when** to use kung fu.
Why not just pass the arguments individually? Maybe you're attacking a peanut-sized problem with a sledgehammer.
Try out https://github.com/codemodus/chain Further, here is a discussion regarding moving net/context into the standard library and adding a context-passing handler func def: https://groups.google.com/forum/m/#!msg/golang-dev/cQs1z9LrJDU/S_9pzcAhCgAJ
Thanks, seems like that chain package implements the same method but still uses the net/context package. Why is that? Is it just to have a place to store the context variables, rather than creating their own struct?
May I ask why? Upstart and systemd seem to cover the common use case (starting on boot, restarting on failure) and it's one less service to run.
I was thinking about doing this, for instance just passing a User struct to the handler that needs it. Consider though using multiple middleware functions that do not have the User struct as a parameter. Each middleware function would have to pass this User struct in order for the end handler to receive it, and handlers of a different signature (different parameters) would be unable to use the same middleware. By using a map[string]interface{} for context and passing it by default to every handler, all handlers will have the same signature and can then be used with any middleware.
If it was going to be something you needed frequently, one approach I tend to use is simply provide a function that takes the same parameter as the multi-return https://play.golang.org/p/igDQw-0dmK
Yes. My goal was to use the most "blessed" (for lack of better term) approach. This great article: https://joeshaw.org/net-context-and-http-handler/ along with this post: https://blog.golang.org/context and a distaste for burying the standard library without great cause brought me to a mindset which pushes away from http frameworks. There is no gain avoiding helpful libraries, but seeking a do-it-all http framework left me feeling somewhat duped and disconnected from the process of learning Go. As for a takeway from this, it would be useful to focus on the context.Context changes that are likely to happen within the standard library. Once a context-based http handler func definition is decided upon, chain and libraries like it will be able to more easily operate interchangeably.
Hi. ELI15: The frontend of a compiler is the part of it that converts plaintext code to a tree-like structure by parsing. The backend converts that structure into machine code.
I started using context because appengine requires it, then I continued because I like goji. The result? I can run my code with goji on appengine. There are other libraries (especially middleware such as github.com/rs/cors) that use context. I can drop these into my code without modification. You can use a map (or whatever you want) to pass data between handlers, but your code may be incompatible with other libraries. I personally benefit from the compatibility, but if you don't, then do whatever works for you.
You are correct. And I doubt he alone represents the CZ TLD authority haha. But yes, he does some very interesting work on his github.
Thank you for the explanation!
Ah, Thanks!
Nice, very useful, I'll in fact be able to use this to test something today...
Isnt the gocode daemon shared between all clients? (like all my emacs instances, across vscode restarts etc...). IIRC gocode also shuts down after a period of inactivity. I could be wrong about this if i mixed gocode up with some other completion daemon...
The daemon is indeed shared in the best case scenario, but some editors and plugins they have do some crazy things. GoSublime as an example, the author uses a fork of gocode integrated into his own daemon called MarGo. And no, I've never implemented inactivity shutdown and it never clears the cache on its own. 
A project which I also wanted to start some day ... but now I don't needed anymore :-) What is the difference to https://github.com/mailhog/MailHog? I've downloaded the release 1.8 from here https://github.com/mailslurper/mailslurper/releases for OSX and unzipped it in my "Download" folder ... baaaammm all files have been unpacked in the current directory. Pretty hard to figured out all unpacked files and delete them after trying MailSlurper out. Also this folder https://github.com/mailslurper/mailslurper/tree/master/test-files should be named "testdata" because the folder name testdata and all folders/files starting with an underscore are getting ignored by the go tools: https://golang.org/src/cmd/go/main.go#L597 I would love to see all non-go-files to be also packed into the binary. You may use a package like that one: https://github.com/jteeuwen/go-bindata With that you can really unleash the "whole" power of Go: one file. 
Looking at the vote stats, you're not the only one. The old Reddit Judge-a-post-by-its-title rule at work.
Thanks for the feedback! I do have a story in Github to look into packing everything into the binary. I did look into one of the available solutions, but ran into issues with how it required me to structure the data. I am still interested in this, however.
would be great if you provide write access. i would like to stay away from python as way as posiible but still doing ml in python.
http://www.gopl.io/ might be the best technical book to come out in a very, very, long time. (Meanwhile, most of tech books published these days are not worth the paper they're printed on.)
That's the fastest I've ever gone from seeing a book mentioned online to buying it. About 60 s. And I totally judged it by its cover too! ;)
`net/context` is actually fairly close to what you are describing when you check the code: https://github.com/golang/net/blob/master/context/context.go#L138 and this is how you implement something very close to your example: https://github.com/pressly/chi#middleware-handlers So why shouldn't you roll your own? It's likely that `context.Context` field will be added to `http.Request` in standard library's `net/http` in go 1.7
Thanks!
I needed some vendor solution quickly. Did 5min tests on a couple of tools and arrived at glide. Apart from the little annoyance to change my `go get ./...` commands to [go get $(glide novendor)](https://github.com/Masterminds/glide#glide-novendor-aliased-to-nv), it seemed to me that glide was really ok and quick to set up.
Actually I think the book tries too hard to be like it.
&gt; man scp &gt; man ssh &gt; man rsync
an excellent book? The book starts with math examples and starts to explain packages in detail. All we wanted is making Rest servers.
Yes, you have to wait until page 19 before it gives you an example of a tiny HTTP server. Terrible.
I didn't come that far I threw it away after mandelbrot.
I just deployed caddy for first time and overall was a great experience
I would agree with djherbis, and also point out there isn't a need for this to be a object. I think just having a Do function is cleaner. http://play.golang.org/p/moNwZu1h_F 
As mentioned in the Caddy gitter chat this is a great feature. Using this it is now possible to create a website that sends mail using a form, without having anything but Caddy in the backend!
[**@davecheney**](https://twitter.com/davecheney): &gt;[2016-03-05 01:53:45 UTC](https://twitter.com/davecheney/status/705934293881597952) &gt;[#golang](https://twitter.com/search?q=%23golang) top tip: if your unit tests import any other package you wrote, including themselves, they're not unit tests. ---- [^[Mistake?]](/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=/491ob0%0A%0APlease leave above link unaltered.) [^[Suggestion]](/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/joealcorn/TweetPoster) [^[Issues]](https://github.com/joealcorn/TweetPoster/issues) 
Important clarification I think: - https://twitter.com/NateTheFinch/status/705966475790704640 - https://twitter.com/davecheney/status/705973210039189504
Is this different to how a normal email server works?
All generalizations are wrong.
Thus this is wrong.
[**@davecheney**](https://twitter.com/davecheney/) &gt; [2016-03-05 05:08 UTC](https://twitter.com/davecheney/status/705983231032602624) &gt; @benbjohnson @NateTheFinch @calebspare that's my point. If your tests cannot run without importing a type from other package,thats the smell ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I've always wondered, what is the performance impact of measuring performance?
When I blog about Go, I tag the article "golang" for SEO purposes, but use "Go" in the article body. I think that's the right approach. 
Congratulations, you just invented monads. 
The site is by Damian Gryski I think, lots of interesting videos on there.
Yup. And videos I haven't yet added are in https://m.youtube.com/playlist?list=PLiAILMXD9huEKtg1Lyx0PO6Ki1WaJSyR5
I agree glide looks pretty nice, but I literally have to try them all to see what works best for our workflow. Sigh
Sorry, that's wrong. You summed it up in the second paragraph. If you're actually afraid of the repo disappearing, saving all the code into a vendor folder isn't the right approach. It's better to fork the repo and vendor your fork, for which submodule is still valid. The point is, submodules provide a consistent mechanism for vendoring.
Sorry, that's wrong. You summed it up in the second paragraph. If you're actually afraid of the repo disappearing, saving all the code into a vendor folder isn't the right approach. It's better to fork the repo and import and vendor your fork, for which submodule is still valid. The point is, submodules provide a consistent mechanism for vendoring without the need for additional tools to learn/support.
That's pretty gross 
I think there's a misunderstanding here with regards to package tests importing "themselves". He's not that he's talking about is not what files the tests live in, but rather what package they are defined as. Consider a package `foo`. You write your tests in separate `*_test.go` files. Those tests can also be package `foo`, in which case they have access to all of `foo`'s private, unexported variables and methods. Alternatively, those tests can be put into package `foo_test`, in which case they will need to import package `foo` and only have access to the public, exported contents of `foo`. The result of the two approaches is not identical, and I believe both are useful (Go can handle both for the same package).
So this is what's going to happen once the Javascript/Node community flocks to Go. I write Go because it's simple. The "Go way" is incredibly blunt and obvious. It's not clever or abstract because it doesn't want to be. Your code is littered with `if err != nil` because it allows for failure points to be present and obvious in your code.
I really like this site, I've been going back to it now and then since finding it. So thanks for that, nice to see resources like this popping up for Go. It would be great to see the newest videos playlist show up by default on the right hand side when you open it, as otherwise the page looks a bit blank and it's not obvious there's loads of videos available. Also might be worth considering having a few videos stacked under one another on the left? Anyway, off to watch another video :)
What is your Go version? Also I would file an Issue on Terraform repo instead of asking for help here, this subreddit is more for questions related Golang itself than its applications.
Dude ought to change his name - I had a reflex reaction of intense disgust to his comment before I managed to process what he was actually saying and the fact that his first name is not Dick.
&gt; should I use GetDB() as a singleton function? Are you using an SQL driver under that GetDB -- if so, it already handles that. https://golang.org/pkg/database/sql/ "DB is a database handle representing a pool of zero or more underlying connections. It's safe for concurrent use by multiple goroutines. The sql package creates and frees connections automatically; it also maintains a free pool of idle connections." (Always read the docs) &gt; But singletons and global variables are said to be bad. Don't worry about "said to be bad" and worry about WHY things are said to be bad. If those reasons don't apply to you then don't worry. Globals often muck up testing and can be confusing, but if that doesn't apply to you -- don't worry about it. &gt; Anyways, should my signleton return error or panic? Umm, panics are for exceptional cases, your DB being unavailable is not that. &gt; Should I recover and send 500 on any error? Umm, panics should be things that "never happen" -- don't use them as control flow. &gt; Some enterprise frameworks like Spring allows you to write services and handles their lifetime. Should I try to find something similar to it? huh? P.S. gofmt 
If you can't satisfy the request, respond with 503 temporarily unavailable. You can suggest a retry-after with a header too, in the case of planned downtime.
Hey all, I recently started playing around with [Prometheus](http://prometheus.io) at home and decided to try my shot at creating a metrics exporter for the Ubiquiti UniFi controllers API. The [client library](https://github.com/mdlayher/unifi) that makes it work is available on GitHub as well. I've been monitoring a couple of sites with this for a couple of weeks and it's been very useful for tracking trends in bandwidth consumption and access point utilization. Hope it's useful for you as well!
That is great advice. 
I pushed back at first, but then I really thought about what I'm doing in Go. I'm not hacking something together for a blog post or github stars, I'm building a critical piece of business logic at work. Being forced to account for every error is refreshing and reassuring, if not verbose. 
Don't panic. panic is for conditions that should *never* happen or prevent the app from functioning (e.g., it can't find the config files on startup—and even then I'd recommend the log package.) If a DB query returns an error first check what it is. If it's an error with your DB, return status 500. If it's an error because the user submitted a bad request, return that to the user. Also, make sure to log *all* errors that aren't due to bad requests from users. 
I think the difference between glide and govend is that glide forces you into the manifest file and has a different syntax than "go get". Also govend is simpler and "go get"-able. 
Nice work! I have a competing Go project ;) http://www.inbucket.org/ Inbucket lacks the neat search stuff MailSlurper has, but offers POP3 and RESTful APIs to access the email. I also have a MIME mail parsing library: https://github.com/jhillyerd/go.enmime if anyone needs one.
Do you have plans to merge this into golang.org/x/tools?
'a collection of shell scripts for searching, browsing, and managing API documentation' and (therefore) only for 'POSIX environments'. I was hoping for a multi-platform Go implementation ;-)
Not really, no. A monadic interface would: 1. Allow one to compose computations in such a way that the result of earlier ones gets passed as an argument to later ones. 2. Allow choosing different computations to perform based on the results of previous ones. Those things could be done with the abstraction presented, but in a comparably more painful way. Mind you, you don't need monads to get short circuiting. They are a far more general abstraction. Not exactly the most suitable thing for Go.
Wince we're posting alternative approaches... https://play.golang.org/p/yD_AZCraUi It doesn't force all computations into a chain of callbacks (which feels wrong in an imperative language like Go).
Thanks! I just poked around in your Inbucket project. I really like the user interface. Looks real nice! 
There's a proposal to merge this upstream, see https://github.com/golang/go/issues/14654
This would be great for web applications as I'm always grabbing a context package to use anyway. It would be nice to have one in the standard library.
Please file an issue at gonum/stat including what features you think would be valuable to include in this kind of type - pandas dataframes have kitchen sink-like qualities.
oh i didnt mean putting dataframes inside of gonum/stat, but it would be nice if gonum made gonum/dataframe 
+1 so much this! Would be nice for it to be in 1.7!
Oh dang! That looks interesting. Does anyone have an opinion on how well it works vs. Atom with go-plus installed?
https://github.com/golang/go/wiki/GoUsers Using Go feels like the Stockholm Syndrome. At first you might not like it then you can let it go.
yw!
It doesn't have to be in stat, but stat is an obvious place for it. Wherever it goes, we need a directed request to make decisions about what to include - the pandas dataframe model does much too much in my view. If you're not convinced stat is the place, please start a thread at gonum-dev.
I use Go for hobby projects and at work. Hobby stuff: miscellaneous utilities Work: web server, custom long-term data storage system, miscellaneous utilities to support management of both of those services, etc. Deployment for work-related stuff is not ideal at the moment, as it's not really automated: * `go build` w/tag + version information * scp build up to target servers _manually_ * update configuration if necessary _manually_ * run a shell script to gracefully stop/restart the service _manually_ * move on with my day
well, "wicked fat" sounds fun :D and I recognize this link now. This is what I was considering at the time to implement. Right now I kick down the gain when mixing multiple samples but I'm a sucker for anything interesting. That said, I'd like to add more methods for mixing but its lower priority at the moment. Right now I'd like to get some FFT action going on so I can setup a vocoder from all the pieces that need FFT.
Me too.. the only thing I can think of is a fancy way of saying "load balancer"? 
You might find ansible interesting for deployment (that's what I use, after the learning curve I'm pretty happy with it) - you can probably get the above down to a one-step process. Would be interesting to hear how others are deploying go apps.
`ls`output in a proportional font... I don't even...
Yeah, I actually started looking at Ansible on Friday, followed by a quick-and-dirty fabric implementation of what I typically do. I'll probably look into doing something less lazy (i.e. Ansible) in the near future.
Dumb question... Why do you guys use a context library? I have a context struct that holds a Storer interface (how I call the db) and a logging object. This gets passed into my handlers. What would using something like gorilla context buy me here? 
I've played with Glow a couple times, and the documentation is pretty bad. You have to already be familiar with a map/reduce framework like Spark if you want to use Glow.
Uber uses go for it's highest query per second service. https://eng.uber.com/go-geofence/
The net/context library is used for passing contextual data across boundaries. It is not for passing dependencies. When used within http handlers (nested or otherwise), context.Context is used for carrying request-scoped data. Again, this is independent from system dependencies. Edit to add - From https://godoc.org/golang.org/x/net/context: "Do not store Contexts inside a struct type; instead, pass a Context explicitly to each function that needs it. The Context should be the first parameter, typically named ctx: func DoSomething(ctx context.Context, arg Arg) error { // ... use ctx ... } ... Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions."
I usually make a data access interface and make a database implementation of it and pass that into a struct that defines my endpoints that require that resource. E.g. https://play.golang.org/p/JyZ2BE41pe Makes for much simpler unit testing since you can easily mock the interface for getting users (or whatever the subject may be). edit: fixed link with db impl
Using Go at work, currently working on a UDP server for high volume metrics ingestion. Using Docker for the build, then deploying to an on-prem cloud based on Apache Mesos.
I think the point was less about test frameworks, and more about importing your own buggy code to test your other buggy code. Also, the implications (which go beyond just testing) of one package requiring the use of types from another package.
Cool idea. Have you checked out [PipelineDB](https://www.pipelinedb.com/)? It's a similar premise though built on top of PostgreSQL. The main benefit over what you have here is the ability to window sketches over time and the ability to aggregate on an arbitrary number of dimensions. So we have a raw event type that has a lot of dimensions, but in most cases we collapse those down for the purposes of reporting. I'm curious to know if you're moving into that domain, or the long term design goal is in a different direction. Again good stuff and thanks in advance for replying.
Not sure this really answers the question, which is "Why use context.Context instead of using my own struct?" You described the type of data found in Context, but not why anyone should use it over their own implementation.
/u/RickAndMorty_forever detailed two dependencies that they are concerned about, so I addressed how dependencies pertain to context.Context and what it's purpose is defined as. As for the related issue of using context.Context versus something like a map[interface{}]interface{}: At the global scope, a map/mutex presents possibly high levels of lock contention which is worth avoiding (for heavy use). As for it's own features, context.Context provides for deadlines, timeouts, and direct cancellation. Lastly, by providing a common approach, interoperability will be improved.
Dave's message was certainly focused on decoupling, but he did also address abstracted testing facilities (https://twitter.com/davecheney/status/705939716881850369). Nevertheless, my thought remains; There is a sort of desire within the community which is not congruent with the "Go way" of reasoning, and Dave's statements indirectly and directly touched on that.
I like glow but I hate the method chaining. It looks so unreadable to me, but other than that the project is awesome.
I use docker for distribution and packaging, and instead of shipping binaries, I ship source code. Once we get better at CI, that might change as the build environments should be able to pump out the binaries, and upload them to prod directly.
Thanks for the insight! 
Could I ask how you managed to pack static assets into the Linux executable? I was looking to do exactly that a few months ago, but couldn't figure it out.
You don't need it. There are a few companies with problem spaces for whom containers make things easier. More often than not, the opposite is true for the rest of us.
There are projects that help you do that, for example https://github.com/jteeuwen/go-bindata but I have a very simple solution of my own based on similar principles. As part of the build process I use a simple Go program I wrote that: * packs all static resources (html templates, js code, images etc.) into a single .zip file (using go's built-in zip package) * I generate resources.go file that has that zip file as a single []byte global variable Then at program startup I decode that data from .zip file into memory, using a hash to map file name to content and then use that data in place of reading from file system. go-bindata and other similar projects work the same way. There are variations on this technique (instead of using a .zip file you could have a global variable per file). If you want to see an example of this technique in practice, you can study https://github.com/sosedoff/pgweb/blob/master/Makefile My program isn't open source but I can share the build-time script that creates .zip file and generates resources.go: https://gist.github.com/kjk/0782a36fa4e62f32c19d 
Used it for a couple small backend things at work (replacing a slow Python cronjob) but mainly for hobby projects: https://podbaby.me is one I'm using myself day-to-day. - Godep for dependencies - Ansible for deployment (tried docker: turned out to be overkill for my modest needs) - Digital Ocean for hosting - Supervisord for keeping the lights on - LetsEncrypt for SSL - Nginx for web server - Echo framework for routing - PostgreSQL for database (using sqlx on the Go end) - Redis for caching - ReactJS for front end - Bootstrap + theme for design (I suck at design, just wanted something simple and mobile-friendly out the box) - Highs: fast, straightforward, easy to refactor. Reminded me a little of Java in the early days of servlet programming before it went down the J2EE enterprise rabbit hole. - Lows: no clear "one way to do it" re webapps. A dozen different routers, lack of proper context and error handling in core http handlers means everyone does it their own special way (I understand that may be fixed soon). Lack of decent examples out there (I mean large, working open source projects, not toy examples and tutorials). I didn't mind the lack of an ORM - it was quite refreshing being forced to use PostgreSQL features properly (amazing how your RDBMS knowledge atrophies after years of ORM usage). Biggest pain was in React development, lots of churn in libraries + steep learning curve.
I've been using it for almost a month and I'm really happy with it. Before VS code I tried sublime which lacks functionality for me to use it all the time. Atom was also nice. I liked it a lot more then sublime, but still it was lacking in some ways. Still it has potential to be a great tool and I hope it will in the future. I also tried PHP Storm with GO plugin and I liked it really much but eventually ended up using VS Code because it feels a lot lighter then Storm and it has everything I need for GO programming. 
Coolio
The recommended way of working with GOPATH is to set it to your HOME directory. This way all of your projects will be under the same GOPATH - no need to switch. Also, on all your machines the .profile paths will remain valid.
Not an experimental feature anymore.
Ah, I missed that whole thread of conversation.... thanks for pointing it out. 
I'm using it to build out geospatial tooling.
Hey :D Thanks for the feedback. You are right PipelineDB is actually very similar to what we are doing. We intend to introduce a 2 new features soon: * histograms: by automatically partitioning sketches and domains, total amount of counts, cardinality and memberships will be done via merging over the histogram. In some cases like the Count-Min-Sketch we will be using Hokusai concept for histograms. * Metrics: Unlike domains which can only deal with "strings" metrics will be similar but dealing with "numbers". We want to introduce t-digest, running means, running medians, etc... One positive thing about PipelineDB is that everything can be dumped to postgres. I am however not sure how it deals with the reading. How much does it keep in memory for reading. It might be worth getting in touch with them and exchanging ideas and fundamentals. Cheers Seif 
We're a small startup currently developing an ERP solution and we're using Go for the backend and Docker for deployment.
I've done some thinking on that, going so far as to implement a relational algebra in go, and I'm not sure how to do it in a way that isn't extremely cumbersome and also slow. The problem is that dataframes can have columns of any types, and so you either need lots of reflection to perform operations on the dataframes or you force the user to basically implement the whole thing for each *type* of dataframe. Typical R and pandas use involves adding and removing columns from dataframes. That being said there might be a nice way to do it, particularly with a subset of relational algebra for predefined types, but it won't be easy.
We're using go (at work) to build our next gen ad-tech system. 
Hey, awesome :) I love seeing projects using Discordgo :) 
Also, as a side note. Support for multiple voice connections on different guilds is coming fairly soon in the main Discordgo library :)
FWiW, I agree that test framework libraries are a bad idea. We use them at work, and I think they make the tests worse, in general (slower tests with less useful failure messages, and harder to understand tests). Slower because test suites encourage horribly complex setup and teardown, rather than just making your code more decoupled. Worse messages because instead of writing a few lines of code to test exactly what you need, you write one line using an assertion that sorta kinda tests the right thing. And harder to understand tests because they're a different DSL, and the setup and teardowns mean that you can't actually tell what a test is really doing without looking through up to 4 extra functions that wrap your test function.
At https://www.sparefoot.com I snuck in a Go project as a background worker that uses an Aws SQS queue as a queue for our MySQL server. It works flawlessly biting off up to 10 queries at a time and running them concurrently. It runs in a docker container that only takes up about 8MB of memory last I checked. We're a shop that typically only uses PHP and Node.JS but I'm hoping other start to notice how useful Go can be for certain tasks.
One of the authors here. We did an extensive write up on the technology behind the product and lessons learned here https://medium.com/@BlockBust. Let us know if you have any questions we would love to answer them.
The company I work at was C# based when I started. After 1.5 years of slowly converting (both the code base and other developers) we are now 100% Golang. We have a huge micro-service based back end that is always crunching large amounts of data from our hardware in the field. Since switching to Golang the faults that would arise in our system have almost dropped to zero (at least on the software side) To answer OPs question: We use it for both our website APIs and back end services. Our services are mostly built around Go-Kit (https://github.com/go-kit/kit) and discovered/configured by Consul (https://www.consul.io/). These services are mostly backed by MongoDB and communicate either directly via their APIs or indirectly via RabbitMQ. Other services make use of BoltDB or Reddis as required. Everything is built to scale horizontally and vertically. Our infrastructure resides on Amazon EC2 and is managed/deployed by Packer (https://www.packer.io/) and Terraform (https://www.terraform.io/). Thus far our server deployment time has shrunk from easily 5+ hours to about 15 minutes. 
We use go extensively as the back end for our digital forensics analysis tool. We've seen massive improvements over the legacy code that we're replacing. 
You want to use Websockets in the case where you want data flow without having to terminate and re-establish a connection for each frame of data. Think of it as a phone conversation between two people, instead of going to the other persons house to speak a sentence. You can speak freely over the phone, without having to walk back and forth. Here are two use cases: -------------------- **Use Case 1**: A Data Ingestion Layer As an application developer, I want to ingest some volume of data into a system. In this case, you might open a websocket on the server that is constantly reading for messages, and when a message is read you would process it. -------------------------------- **Use Case 2**: A Notification (push) Layer As an application developer, I want to know when an event happens in the system in real time. In this case, you might open a websocket connection between client and server, and when the server receives an event (from an external source), it is pushed to the subscribed client. --------------- 
I use Go in my side project https://bestfoodnearme.com I host my app and related microservices on a private git repo. On my production host, I build the binaries then I stop the services via systemd, copy over the new binary and start them back up. I am starting to use Go at my day job at an electronic brokerage but it takes time to build up all the supporting libraries I need. I did benchmark some of the tasks and Go was 5x faster than the current program I was using.
In the repo, @akavel asked me if we should join ytdl (Thanks for the question). The point is that this cli is liked the example for the core library https://github.com/dwarvesf/glod. If you are building your music streaming website, the command line tool to download media files or even a crawler ... you do not have to build it from scratch, glod is here to help. And further, we do not want to be just a clone of youtube-dl. The brand name is not so good in general.
The blog is only about the choices for technology used. Ok, in an 'extensive' way, maybe.
There were brief mentions of possibly open sourcing parts of the application. We would love for that to happen, but ultimately our company owns it and its up to them to decide if they want that to happen. I thought others would be interested in Go being used in production regardless of it being an OSS project or not.
Dunno, something about the implementation (the trial and error before finding the suitable solution) that drove those choices. And then how you went into implementing the current solution. Leave out the part that are too specific about your business, though. ;)
I will follow up next weekend with a proper benchmarks post (hopefully)
&gt; So this is what's going to happen once the Javascript/Node community flocks to Go. That and we'll be told that [channels are bad and we should use callbacks instead](http://www.jtolds.com/writing/2016/03/go-channels-are-bad-and-you-should-feel-bad/).
We use Go to build most of the back end at Bitly. This includes the next version of our API (currently written in Python), our entire queuing system (using [NSQ](http://nsq.io/) which we built in house and open-sourced), and much more. I also use it for personal projects here and there.
Neat
Wow! Me likey. It's a little jarring that the vertical movement is faster than horizontal movement, but this is still super cool.
[Drone](https://github.com/drone/drone) is distributed via Docker image, and configuration/initial setup is much simpler than it was before.
https://github.com/golangchallenge/golang-challenge/tree/gh-pages/_posts
Thanks! I'm going to explore docker ecosystem more. 
the GNU GPL is an offensive text, as it insults my intelligence, but apparently not some people's. There's a reason GoLang was released on bsd terms. Search "gpl written by a monkey" on Google for more information on why, if you're interested.
ffmpeg is a cool and powerful tool, albeit GPL'd.
extract audio stream, could be into Wav, but prefer mp3 or ogg
What system are you on? Windows/Linux/Mac, etc.? One of the recommended ones is [Lite IDE](https://github.com/visualfc/liteide), which runs on many systems. Personally, I'm happy with Vim plus the vim-go plugin.
+1
Atom for sure, with the go plugins
I use Visual Studio Code with Go plugin (https://marketplace.visualstudio.com/items?itemName=lukehoban.Go). Before that I used Atom with go-plus plugin and that worked too. Before that I used Sublime Text with Go plugin and that worked too. 
I am on OSX/Linux.
Wow, really cool!
god, I hope not.
Yes it is
vim with vim-go is a great option
I'm on OSX/Linux as well. Using Lite IDE, considering it is free I am so far happy with it. Been using Vim with the vim-go plugin too a times. If you are enjoying IDEs perhaps Jetbrains CLion (https://www.jetbrains.com/clion/) with the GO-plugin (https://plugins.jetbrains.com/plugin/5047?pr=idea) could be something. I'm still to try it out, any day soon...
I use Sublime Text with GoSublime. It's sublime.
Let's see. With Go we've got a couple options: it's VSC (VS Code), Atom, Sublime, Vim or Acme. Since you didn't bother searching through the sub, apparently ou are a real newbie to programming. Vim doesn't fit — it's some old-fashioned rubbish for either old farters or posers. Unless you are Plan9 nut, Acme is not your choice. Sublime is dying legacy, run away from. Oh, btw, don't touch LiteIDE, it's a bloody joke. VSC and Atom left. Both open sourced, both look good. I ain't got no chance to take a close look at VSC, yet I'm aware it has debugger support.
emacs+evil is what I count as both... Roll your own set of packages ;)
For some Fun prototyping I use Atom with go-plus. For more serious projects Intelij idea + Go plugin
Your brain. Nothing else. Any editor is okay.
So True! But I'm too lazy to learn Emacs from scratch (but I'll do it one day). Anyway spacemacs' modules are quite nice to work with. 
https://www.jetbrains.com/phpstorm/ + https://plugins.jetbrains.com/plugin/?idea&amp;id=5047 Intellij make a great product which you must pay for. It pays my rent. I tried Atom when it was new and it was too buggy/crap. Maybe more mature now and it's free.
https://github.com/go-lang-plugin-org/go-lang-idea-plugin
I wrote this today as we use sockjs in the client and it was quite educational learning the code and added a dumb pub/sub to it. https://github.com/17twenty/sockjs-go-demo Really simple, open it up in two windows and you can chat between them. I've used longpolling (check my repos) to do similar before but this is very cool.
I use Eclipse + the Go plugin under Ubuntu. You'll need to download the latest Eclipse directly because Ubuntu lags a lot there.
Sadly i've been unable to see this properly on windows. Putty, babun and cmd with ssh neither refresh properly.
&gt;They're very against having lots of knobs Yeah, that's pretty much what I based my guess upon. &gt;I guess having no or very limited switches is a good thing ... I think there are both negative and positive aspects, you touched on the positive, on the negative side there could be some nice optimizations which are a bit too compile time expensive if there are no options to only enable them when you want (like for release builds). Anyway, the go compiler generates well performing code already and when the new SSA backend has matured we'll likely see further performance improvements as a result.
don't you see it through?
I use go-vim, it's fantastic. Atom's also great for Go. 
This is really cool. I have tried it. However, I think there are some potential features you can upgrade, for example: stop or pause downloading... Anyway, good job. One reason I like it because it's written in Go. 
I have tried Atom with the [go-plus plugin](https://atom.io/packages/go-plus) and now VS code with the [VS go plugin](https://github.com/Microsoft/vscode-go) The latter has a partially implemented debugger which looks promising.
It's essentially a fancy Atom, btw, so yes EDIT: [Visual Studio Code is not built on Atom, but on Electron, which used to be called Atom Shell.][el] [el]: https://en.m.wikipedia.org/wiki/Electron_(software_framework)
Oh, sorry. Didn't get that.
Only problem I have with this one is https://github.com/go-lang-plugin-org/go-lang-idea-plugin/issues/1820, but else it works great. And it feels good to have all the comfort of an IntelliJ IDE
IDEs I am using are blazingly fast, can you make a single point of using GNU vim in 2016?
Your favorite. A simple text editor goes a long way, you'll just want syntax coloration and auto formatting for your code. There are excellent plugins for Vim and Sublime, but also for Atom, Visual Studio Code, and even IntelliJ IDEA. My point is, you don't need to switch editors for Go, just use the ones you are familiar with, which most likely have decent support for Go with plugins.
oh wow. I didn't know that ! I thought its a Windows only thing and left it. Definitely gonna check it out.
In 2026 you wont use your IDE but vim will be around. 
I'm afraid you'll die of Vim-caused cancer much earlier than 2026
Are you asking for a FULL IDE? If yes then JetBrains has a Go plugin for IntelliiJ. I don't know of any other full IDEs that support Go, but there are plugins for major editors like Visual Studio Code and Atom.
Can you provide some more details about your requirement? For example, * Define "popular". How do you measure popularity of a comment? * What does "pick a comment" mean when the articles only contain title, content, and source but no comments? (Or do they?) * What does "a good way" mean? Good for which purpose? What are the criteria for finding the best way of doing this? * When you say "scraping", do you mean screen-scraping a Web page? How is scraping related to the problem? * You say, "some additional scraping that I should do" - In addition to what? * How is this related to Go? Can you point us to some code that you are currently struggling with? A code snippet shared via play.golang.org perhaps? (Shortened down to show the problem as concisely as possible.) This would help a lot.
when you use external imports, how do you access methods implementations ?
IDEA community is free fyi
There is no recommended IDE. Use the one that suits you best.
It may also be worth looking at neovim + vim-go at this point. neovim can run tasks asynchronously so things like go build or go test don't block the entire UI.
yeah could we stop please looking for political correctness everywhere? fuck this is annoying. if it is a group of exclusively women who program go, it is not sexist, it is just a group of exclusively women who program go. stop it.
&gt;if it is a group of exclusively women who program go, it is not sexist, it is just a group of exclusively women who program go. 👆
&gt; Imagine a grocery store "for women only" There are gyms like this, which is perfectly fine.
If it is not related to Go, you might want to try a more suitable subreddit for your issue. (Something related to online marketing perhaps, as the things you ask seem typical marketing questions.) You seem to be in a very early phase of your project where you still need to identify the concepts to use. Decide about the appropriate programming language later.
vim with vim-go is my "go-to" choice, but Visual Studio Code is really nice if you want something with a proper GUI.
The majority of the Go ecosystem is "Men who Go".
And code coverage on save!
In what world would a non-newbie programmer say that vim is rubbish? Vim is incredible if you take the time to learn it. 
Vim and emacs can for golang. There are syntax checkers available. Never used atom. 
That's definitely the difference between US and Europe man. no a "black girl scout" group would be seen as totally racist down here, as much as a "white girl scout" group. In fact If I were to see some crap like in my city that I'd definitely sue the organisation.
My god, victim complex much? Did you ever think the group was created because there's so few women in tech? Or why women might want a space just for them? As a white dude, I don't need a "white dudes who go" because I can pretty much go to any tech conference, and by and large, that will be what I get (such a club sounds awful anyway). Maybe there's a reason women feel uncomfortable in the wider Go community. Maybe they just wanted a break from all the *brogrammers*. If you wanna make your "men only" golang club, then go ahead, but it sounds just like going to a meeting at the office. And yeah, it's gunna look pretty silly given how male-centric the tech industry is. I think you need to relax.
You are american right?
Yeah that is a good idea.
It's not discriminatory because men are already severely over-represented in software development to the detriment of our industry. All this does is, I gather, create a safe space where women can get together and practice their craft without fear of any sexism or harrassment. The fact that it is necessary is a sad indictment of our industry. I have worked with several female coders throughout my career and they were generally very skilled and I hope felt part of the team even though the teams were inevitably always male dominated. Having also worked with many men who are crude, aggressive, unskilled and complete and utter morons I find it very easy to believe that many women's experience in IT (and in the workforce in general) is less good than it should be so anything that helps reverse this is to be welcomed IMO. To try and make an issue out of proactive initiatives like this just seems petty and pathetic IMO. They problem isn't that this exists, but that there is a need for it to exist - if you are mad about something then direct your effort and energy toward changing the underlying inherent problem, not one of the symptoms.
It's been proven that diverse teams from various backgrounds outperform homogenous teams. Also, due to the social nature of people, we tend to associate mostly with people like ourselves. In an already male dominated field, which tends towards cliques based on race within larger groups, it's important for programming to remain approachable to everybody.
Then why do these people cloister themselves into their own group if diversity is better?
Why do alcoholics go to AA meetings with other alcoholics? It's a support group - not an exclusivity club.
but girlscouts are ok? or do they accept boys? /edit i don't want anyone to sue the girlscouts ok? just to be clear. 
awesome work /u/Jinzhu congrats to everybody that worked on GORM
Alcoholics are a group with a problem they are trying to solve and, yes, it is an exclusivity club. I submit that groups who only allow one race or gender to join are limiting themselves by closing themselves off and labeling themselves as different. This only serves to create further distancing they created themselves. 
There's no "sexist against men". Sexism (and racism) is prejudice plus power. It requires an institutionalized power gap. Men are (currently and historically) the privileged gender. It may be discriminatory to exclude men, but it is not sexist. There's a difference. Discrimination on a small scale can be for many reasons. Maybe it's People Who Like Chocolate Ice Cream Who Go. That's discriminatory against people who prefer Vanilla. But it's not an -ism. And certainly not something to get upset about. Does the existence of "Women Who Go" impact your life at all? No? Then why do you care?
Working programmers are not writers, we are readers, which is why gofmt is good.
Are you equally taking such a stand about the detrimental lack of representation of men in the nursing field? (Less than 10%)
That is some beautiful documentation. Well done.
I have tried sublime text, vim, liteide, idea, spacemacs. And I think visual studio code with go plugin has best go support. 
&gt; It requires an institutionalized power gap Bullshit. [Sexism](https://en.wiktionary.org/wiki/sexism) (and similarly [racism](https://en.wiktionary.org/wiki/racism)) is just treating people of different sex (or race) differently, usually without valid reason. It has nothing to do with "institutionalized power"; that's a dumb ass SJW invention. 
Happy International Women's Day.
love gofmt. since we're usually not appreciating programs at the level of visual artifact, it's great to have a tool to just handle the styling. another benefit: it makes it easier to use like grep to search your code (since there are fewer possible stylistic variations you have to worry about). 
I really liked this article, and I don't think it's just because it's written for Go. Most of the other articles I see trying to introduce property-based are so intertwined with Haskell (or sometimes Erlang) that it's hard to grasp the concepts behind it if you're not already in those worlds. 
I don't think these are very realistic benchmarks. It seems that the compiler is getting rid of some of the instructions completely. Try without inlining, `go test -gcflags="-l" -bench . .`: BenchmarkGetXInderectStruct-8 100000000 15.3 ns/op BenchmarkGetXManually-8 100000000 20.6 ns/op BenchmarkGetXerectStruct-8 100000000 15.2 ns/op BenchmarkGetXInderectInterface-8 30000000 48.3 ns/op BenchmarkGetXerectInterface-8 100000000 16.5 ns/op BenchmarkSetXInterface-8 100000000 20.4 ns/op BenchmarkSetXStruct-8 100000000 18.4 ns/op BenchmarkSetXManually-8 500000000 3.25 ns/op BenchmarkSetXReflection-8 30000000 51.0 ns/op I'm not sure whether in your real-world situation the inlining can be done. Either way, if you want to get rid of the overhead, don't do the method calls (either on struct or interface).
Anything you want.
Great!
I use vim. It has a bit of a learning curve, but I can use it for all languages on all platforms. It makes for a really consistent programming experience and lets me focus on the work rather than the environment. Showing my age a bit here, but I also like to use GNU Screen to manage multiple editor windows.
I was not quoting Anita Sarkeesian, but found that wording in multiple places on the web (none of which attributed to her), and found it to be compelling. If she said it, I was unaware of that, and frankly don't care.
This is exceptionally helpful. Thanks! Without diminishing the value of the article... "assertion" seems, to me, to be a misnomer. "assertionFunc" would be more correct, but still not quite right. Following the quick package's api naming/purpose, checkFunc", "cFn", etc., seems more suitable.
I would tell you why I think you're incorrect... but anyone who uses SJW in serious conversation is obviously not open to persuasion in this particular topic.
Thank you, this sounds like a great learning lesson.
https://twitter.com/probirdrights/status/368542088897372161
Hi, author here. I think you may be onto something. When I first looked at this it wasn't immediately obvious what was going on from the example in the godoc. So I tried to come up with something a bit more descriptive. I may well update it to "checker" (func is already implied, imo) later tonight. Thanks for the feedback.
LiteIDE is first one I tried for Go and never wanted to look for alternative. Compared to IDE-s for other languages it is top notch: blazing fast, simple enough and has all features I need.
Or as someone on twitter called it "Happy international why don't we have an international men's day day"
&gt; func is already implied Yes, certainly. "checker" does seem to be quite apt. I tend to try too hard to come up with short variable names, and "cFn" was the shortest I came up with that wasn't just "c". Though, until I get over my habit, it's likely I'll still aim for something compact (even maybe just "c", if the context permits). 
One great thing about Go is the wonderful tooling. Godef, godoc, gocode, goimports, etc... Any IDE or text editor with Go support uses these tools. So pick whichever you like.
in Atom? if yes, i need to know as well!
For things like this where the identifier is defined within a function and only used very close to it, I'll often use whatever the godoc documentation names the arguments. E.g. in this case `f := func …` (and `g := func …`) for `quick.Check(f, nil)` and [`quick.CheckEqual(f, g, nil)`](https://golang.org/pkg/testing/quick/#CheckEqual). In this case, as with `i`, `j`, `k`, etc in a loop, `f` and `g` are just notation.
No, and its in poor taste to post this on international women's day. The section on where the code applies states: &gt; Explicit enforcement of the Code of Conduct applies to the official forums operated by the Go project (“Go spaces”): &gt; &gt; - The official GitHub projects and code reviews. &gt; - The golang-nuts and golang-dev mailing lists. &gt; - The #go-nuts IRC channel on Freenode. &gt; - The /r/golang subreddit. So unless they're going around harassing people on one of those venues (or somewhere else that explicitly adopted the Go CoC), their mere existence doesn't violate anything. On the other hand, your post could be seen by some people as a violation (since this is an official forum, and given the context) and the top rated comment is almost certainly a violation. [edit] formatting..
Then why don't you found one?
You're right! Electron used to be called Atom Shell, must've mixed that up, sorry. I was just talons about that a few days ago with someone and he confirmed that when I asked, so I was pretty sure about it. https://en.m.wikipedia.org/wiki/Electron_(software_framework)
Oh, that makes sense, then. I didn't realize that. I'm looking at them side by side(ish) now, and the Rails Girls one looks more strict than the Go one. I still can't find the reference, but from memory RG doesn't consider sex. I don't remember if it said why, but presumably so that transsexuals feel welcome, and because it would be hypocritical given their code to explicitly judge based on sex and give ammo to trolling like the OP.
&gt; You are attempting (as most redditors do) to make the topic about me and not the subject. Incorrect. I was pointing out that *your experiences* (which is what you asked about) could well be explained by your privilege. Don't ask for an explanation for your experiences, if you don't want an explanation that is specific to you. &gt; So females can do that in nursing but males can't do that in programming? Can do what? Suppress? No, as I mentioned elsewhere, it is wrong to keep men out of the nursing profession or discriminate against them. And the thing that I quoted wasn't about females in nursing, but females in plumbing (and other things you mentioned), i.e. underrepresented groups in other professions that might not feel a need to form a protest movement (which is their right). &gt; Your last paragraph totally misses my point and I said no such thing. Now you're making stuff up. I quote again: &gt; If one wants to label themselves as different in some way, they are only adding to the differentiation and will be treated differently. I pointed out to you, that no one has a problem with being treated differently. So saying that labeling yourself as different will only lead to you being different (as you did) misses the point: This is not about being treated differently, this is about being treated *less* and changing that. You can't do anything about discrimination without first defining and measuring it. You can't define it, without differentiate. Differentiating yourself is, by definition, a *necessary* part of fighting the discrimination against you, not a contradictory.
No, it depends on the reason for the difference. If the variance is through people's own choices then that's no problem but we know in IT that there are a lot of problems with misogynistic attitudes that force women out or at least make it unattractive as a choice. I don't know much about the nursing profession (not 'industry' surely?) but I could see it being less of a draw to men for any number of reasons. The notion that women are forcing men out is low on the list. But ultimately it's irrelevant - people wanting to fight that battle can fight it and it has no bearing on the right or wrong of supporting women who want to work in IT being given equal opportunity to do so and not have to be subjected to unacceptable and unprofessional standards of behavior to the point that they feel the need to setup groups for women only. Attack the cause, not the symptom. Be part of the solution not part of the problem.
what specifically about gorm do you consider to be non-idiomatic?
http://www.forbes.com/sites/ruchikatulshyan/2015/01/30/racially-diverse-companies-outperform-industry-norms-by-30/#684374625742 Saying "black people are poorer than white people" isn't racist, it's a fact. Yes it's a generalization, but that doesn't mean it isn't true. http://www.theguardian.com/world/2010/may/17/white-people-95000-richer-black Flinging "that's racist" around never helps an argument unless something is actually racist.
That's a good point! I suppose you could just pass in gcflags to drop all optimizations for normal builds. Also (tangentially related) there's a great thread on the mailing list about how some (rather large) builds have 10x build times and they think it's because of parts of SSA. (Although, it was a pretty active thread so there could be more comments that have decided otherwise.)
How do you get that compile error if package c doesn't import package b. The compiler only knows what happens in c.go and a.go.
I used Sublime + GoSublime + GoImports for the last few years. Yesterday I switched to Visual Studio Code. So far, it is fantastic. My favorite features: hover shows definitions and types, you can preview definitions or jump to them, and, unlike GoSublime, it analyzes source code for autocompletion (none of this read into the pkg directory and have to clean it out all the time). 
There's a package with some basic applescript commands: https://github.com/everdev/mack. Looks like it's using [os/exec](https://golang.org/pkg/os/exec) with [osascript](https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/osascript.1.html).
You have to be kidding me. What is *that*? A bunch of little websites. Facebook already uses Haskell. Golang is great for beginners and kids who want to build cute games, but for **industry** you want something that has **compostability and modularity** that is **highly readable**. Its not just that, it may take a little longer to write Haskell, but the compiler can do thing in that golang's definitely can't! All those types add safety, as well as strategies the compiler can use to build a **more efficient** program for **highly reliable, mission critical environments**. So sure, for you little hobby projects, go have fun. But if we're going to Mars - we'll be writing that flight computer in Haskell 2014, we don't want to risk it on a toy language with a gopher.
Fixed it, thank you ;)
Stuff like this: db.AutoMigrate(&amp;User{}, &amp;Product{}, &amp;Order{}) Overuse of reflection in Go is very bad design/practice and should be avoided. Code like this is basically trying to shoehorn Go into a scripted language paradigm like PHP/Ruby/Python/etc. The reason this is bad is that you are throwing away all the reasons (type safety, speed) for using Go in the first place over a dynamic language. If you prefer coding in this style, then use a dynamic language. Also, it should be noted that directly authoring SQL is not difficult and you end up with surprisingly similar syntax to what gorm (or any other ORM for that matter) causes you to end up writing. It should be noted that you could implement this properly **without** reflection by having User, Product, and Order all implement a 'Model' interface or some such, but under the hood, that's not how gorm works, nor is it from what I've seen how any other Go based ORM works for that matter. This [article](http://www.hydrogen18.com/blog/golang-orms-and-why-im-still-not-using-one.html) does a fairly good job of covering why you don't "need" a ORM in Go.
So, still can't show a single program in Haskell that YOU wrote? Not even a tiny, teeny, hobby one? One program, however insignificant, it's really all I'm asking for. Should I aim lower? Can you show me a single line of Haskell that you wrote?
If you are coming from Python then go with PyCharm. It will help you with Python as well as Go. Or try any other IDE from JetBrains, they are all cross-platform and all support Go (even Android Studio does so) 
In addition to the compilation problems brought up, it effectively would make new methods defined in the imported package a breaking change because they could potentially conflict with a method that the library consumer defined. For example, if package "a" defines method "Foo" on type "Bar", and package "b" defines a method "Baz" on "a.Bar", if package "a" goes back and makes a method "Baz", the compiler will throw a duplicate method error. This would make keeping backwards compatibility while adding new functionality more difficult.
You know that you talking with troll, right? When they use both &gt; highly readable &gt; Haskell you already know that person has no idea about what he\she is talking about. Or they throw too much sarcasm at it. Haskell mostly proves that your program is race free \ leak free \ bound's checked. From logical and architecture view it still pretty much the same cycle of writing and testing. 
You should tell SpaceX to stop using Go. And I'd be really happy to hear more about these mission critical systems built in Haskell. Oh and btw, Facebook uses PHP (or Hack) and probably there's a bit of every language out there. Does that mean that every language out there is production ready then?
I'm totally aware of the difference. reflect is a package that pulls in the unsafe package and then does voodoo to pull metadata from an object whereas typecasting is setting a pointer on an interface to a specific type to specify which implementation of an interface a specific object is. What I don't understand though is your stance that encapsulation is non-idiomatic.
Please use the standard [go directory structure](https://golang.org/doc/code.html) for your project or at the very least [godep](https://github.com/tools/godep). Also I don't run other people's go code in my projects unless it has unit tests.
So, let's see: &gt; Facebook already uses Haskell Good - it also uses [D](http://www.drdobbs.com/mobile/facebook-adopts-d-language/240162694), [PHP/Hack](https://code.facebook.com/posts/264544830379293/hack-a-new-programming-language-for-hhvm/) and I'm sure many others like Perl, C, C++. Oh, and they also use [Go](https://github.com/facebookgo). &gt; but for industry you want something that has compostability and modularity that is highly readable Google is larger than Facebook and they not only use Go but they created it in the first place to deal with those issues. &gt; But if we're going to Mars - we'll be writing that flight computer in Haskell 2014, we don't want to risk it on a toy language with a gopher. No, it will be written in [plain ANSI C](http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf), not even C++, let alone Haskell. Also, as others mentioned, SpaceX is [using Go for their telemetry system](https://www.reddit.com/r/golang/comments/3pu3nl/spacex_is_using_go_for_its_telemetry_system/). Even one of their [open positions](http://www.spacex.com/careers/position/8711) lists Go as a preferred skill. Apparently they haven't migrated things to Haskell yet... but anytime soon, cross your fingers!
I created this in response to [this thread](https://www.reddit.com/r/golang/comments/4939ht/freeze_your_git_vendors_with_submodules_and_a/), or, more specifically [this comment](https://www.reddit.com/r/golang/comments/492w0u/do_you_like_go_get_want_to_vendor_your_code/d0ovhiq).
In large web projects, we have used a different language to rapidly build dynamic interfaces to a common API or have chosen to not use Go -- at all -- for this reason. Go is still relatively new and while it may one day have great and amazing tools/packages/whatever to build complex dynamic UIs, it's a poor choice for it as of March 8th, 2016. I even said in the post you replied to that PHP/Ruby/Javascript/etc would be better for things like a CMS frontend. Go is a great option for building things like backends for single page apps, mobile apps, or synchronizing large fleets of servers. I would also comment that building SPAs and Mobile apps seems to concern about 90% of all new development that goes on in the wider tech world today, which means Go is a great use case for about 90% of all "modern" dev work. It also has a million amazing uses elsewhere, which is *mostly* on the backend.
It's not that the code is specifically bad, but that its the entirely wrong approach. It's not like I could send you a ten line pull request to 'fix' it. The model you and the other authors have on qor/gorm is just the wrong model, because its attempting to shoehorn a RoR/PHP/whatever design into Go, which doesn't work. While you can certainly write that pattern in Go, you end up giving up all the benefits of using Go (type-safety, static compilation, easy deployment), and end up with all of Go's drawbacks. For example, to build Qor, you need to use bower, gulp, and npm. Why not just build the whole thing in Node.js if you're going to introduce all of those dependencies to begin with? You could then use the dynamic features of Javascript to better implement certain types of abstractions in the code that do not work (namely the ones that make experienced Go developers scratch their head and question "wtf?"). Another example, you have a 'sorting' package. It's like qor's developers don't even know about the existence of sort.Interface. There's just a hundred different issues in qor like this that spread all throughout gorm/qor. If you want to develop web apps using the RoR paradigm or the ExpressJS or whatever, why not just code using those frameworks?
You would connect the SPA via an API. Go would serve that API. The API could be REST, or something like GRPC or Thrift or whatever. Also, you don't necessarily connect to a 'database' -- you connect to a *datastore*. A database practically refers to a relational SQL database (PostgreSQL, MySQL, etc). Go is a great choice for implementing business rules on top of a database and then serializing input/output via the API to frontend clients. With a single page app (SPA), you would likely use something like AngularJS, React, Express, etc. and then communicate with Go via the API. The Go API implementation ends up looking something like this (please note that I'm not trying to write a real example, but writing something very quickly for purposes of demonstration): func HandleObjectPut(w http.ResponseWriter, r http.Request) { const s := "SELECT * FROM table WHERE = ?" z, err := db.QueryRows(s, params) if err { ... } // do some kind of processing / applied logic to result set for _, r := range z { } // maybe do something else to the database const y := "UPDATE othertable SET x = ? WHERE j = ?" err = db.Exec(y, params) if err { writeErr(w) } } There is all kind of middleware that can help with this, such as encoding/decoding json, etc. This kind of data processing is what Go was designed/built/optimized for (optimized in terms of being able to rapidly build apps like this). It isn't trying to be a Ruby+RoR replacement or a PHP+Symphony replacement, or a Java+Spring, etc. etc. replacement.
First using qor doesn't rely `bower`, `gulp`, `npm`, it is only needs when develop qor. (sure, we need to pick up the right tools to write HTML, CSS, JS, but can't use Go to do all the job) Second question, just confirmed you don't knows what `sorting` do. --- We should stop here, too long list already.
I am very aware of what sorting does within the package. What you should have done is implemented types that correctly interface with sort.Interface, which then get exposed correctly to the underlying meta layer within qor. The issue is that the developers who are building qor/gorm don't really understand 1) advanced database concepts 2) don't really understand Go. For instance, look at this line from sorting/publish.go: fmt.Sprintf("UPDATE %v SET position = (select position FROM %v WHERE %v);" ...) If you don't see what is completely wrong with that code, then there is nothing I can do to help you, as you don't have enough real world experience yet. I wouldn't expect you to understand why this is THE WRONG WAY TO DO SOMETHING, because the git blame lists you as the author for it.
I appreciate the example, but how does this answer the question? In your example, instead of rendering json, render html and it can be a multi page web app.
Has nothing to do with SQL injection: You don't know about `SELECT INTO` do you? Nor do you realize that you are using %v in a string when you should be using %s.
LOL bro https://golang.org/doc/faq#Is_Go_an_object-oriented_language
The thing you linked there says specifically 'yes' and 'no' which is an accurate answer. Classical object orientation refers to hierarchies and inheritance. It's why you have the fairly standard introductory example of `class Car` and `class Toyota implements Car`. You can do things *like* object orientation in Go, but I'll let the developers state it in their own words, from the very FAQ you linked: &gt; There are also ways to embed types in other types to provide something analogous—but not identical—to subclassing
I completely disagree. And your tone about it, even if you don't like it, shows that you're ignorant about what it can do. Don't knock it until you learn it. 
&gt;Also (tangentially related) there's a great thread on the mailing list about how some (rather large) builds have 10x build times and they think it's because of parts of SSA. Well I think with the advent of a SSA backend, we'll be seeing more optimizations added to the gc which will make compile times a bit longer. However the slower compilation we are seeing right now with SSA is probably mainly that of the SSA backend code being very unoptimised as it's just been introduced and still in in heavy development, also the compiler in overall got a lot slower when it was converted from C to Go using poorly optimised automation which likely still hasn't been fully rewritten. Overall I think we'll see the gc speed up a lot as the new codebase matures, hopefully we'll see it happen already by 1.7. Also another aspect of SSA enabling better optimizations is that while more optimizations means the compiler has to do more work, the compiler itself also gets faster from these optimizations (as the compiler is also in Go) which helps making them less costly.
Yes, VS Code + Go plugin is the best Go IDE combination out there IMHO..and its free !
&gt; Overuse of reflection in Go is very bad design/practice and should be avoided. FWIW, https://github.com/jmoiron/sqlx - which I am a very big fan of - uses reflect extensively. (Un)marshalling arbitrary results into arbitrary structs/maps/slices requires `reflect` (also see most encoding libs that don't use code generation). It's also worth noting that although reflect is performance hit, it is often unnoticeable compared to network RTT, database query execution time, etc. A Go program that heavily uses reflect is still likely to be an order of magnitude faster than a similar Ruby/Python application. 
I have never once stated that using reflect is bad. Using it to shoehorn Go into a programming concept that it doesn't natively support is what's bad. Like anything, reflect should be used judiciously and in the right place. I do not believe reflect is being used correctly in gorm, nor do I feel that ORMs in general are the right approach for Go. sqlx and other packages do a much better job for general SQL utility. If one really wanted to use a ORM, why bother using Go at all? There are much more stable/well developed platforms (RoR, Symfony+Doctrine, etc) with much better implementations that are out there. Using Go in this manner significantly deviates from the where Go excels best, and more-or-less eliminates the gains you would have received from using Go.
It's not really necessary to unmarshal into arbitrary structs, since you know what your models contain. This is probably safer, and there is an argument for avoiding reflection (for speed, for type safety) and being explicit about what types you expect to see from the db. It's quite possible to do it this way without using reflect at all and still have most of the convenience of an ORM (specifically the query builder part). petulant_snowflake may be being a little argumentative about this, but there are good reasons for avoiding using the reflect package habitually.
Sorry, I have no answers here. I never dealt with these things. I just thougt that your issue might boil down to a specific Go question... 
I agree that ORMs have their uses, however rarely do the use-cases for ORMs intersect with the use cases for Go. Actually, I have never seen the use-cases for an ORM and Go intersect. If a project is small enough that an ORM would be prudent, then you don't need Go as there are much better frameworks that already do a spectacular job (as you said, Django/Rails/etc). Alternatively, if you have a big enough project where you need the speed and efficiency one can gain with Go, you shouldn't be building that project with an ORM. I have never seen a project that 'floats' between those two extremes. Either a project is small enough that one can use an ORM, or it isn't.
Yeah. As the complier keeps getting more SSA merged in (meaning both git merges and being complied in) we'll begin to see some of the benefits of SSA. I didn't mean to come across as negative about SSA, because the benefits are (obviously) fantastic. It just popped into my head because I had just read that mailing list thread prior to responding to your comment! 😊
&gt;I didn't mean to come across as negative about SSA, because the benefits are (obviously) fantastic. You didn't, it was a valid question.
&gt; SELECT INTO Oh, have you ever looked which databases supported `SELECT INTO`? Anyway, **YOU WIN**, as no one could stop people don't want to listen.
Yes, I know what databases support it. But that just furthers my point -- as what you're doing is trying to create a general purpose SQL implementation. If you see my previous comment, about the primary use case of ORMs is for SQL portability, you will note that I specifically mentioned that in real world, you don't really need SQL portability, as changing databases is extremely rare. So instead of taking advantage of the underlying facility for a database (such as `SELECT INTO`) you avoid using it to create this slow and error prone "portable" SQL. What's the point? Look at all the extra code you've had to write, you've traded off using an optimized/performant variant available to the underlying database, all in order to save writing one or two lines of code?
How about http://www.meetup.com/Bangalore-Christian-Coders/ ? :P 
Uhm?!
Uhm what? Are you not a native English speaker?
I told you the precise reason in the last comment: I'm not into wanking in terminal all day and I don't think it's yhe way to go in 2016. As I said, unless you wanna look classy.
Gvim, macvim, etc. You don't have to be in a terminal if you don't want to...
Lmao. What's the point of Vim then? (Are we still talking about GNU vim?) It's comfy for only and the only reason: it works outta terminal. You make an SSH session, lay out your workspace with tmux and start hacking. We don't do this much recently, so Vim becomes pointless.
FWIW I have written quite a lot of Go (~18 months part-time) but a lot more Scala (~5 years) and I can honestly say I enjoy both and as many have said it's all about trade-offs. In languages like Scala you can push a lot more errors to the compiler and can model domains far more expressively than you can in Go. If you get the modelling right you get very easy to understand code that almost writes itself. But it's not a free lunch. Scala has a lot of accidental complexity because it's a *really* big language so two developers can solve a problem in completely different ways. If you dont have a disciplined engineering team that communicates really well you can quickly run into a mess. Go on the other hand is pretty opinionated, easy to pick up and the standard library can get you really far. It has plenty of tooling to ensure consistency in a code-base. That's not to say its not possible to make a mess. But the stability and simplicity of the language mitigates that risk hugely. You will run into situations however where the type system will let you down and you end up either duplicating code or having functions with `interface` which can be pretty bad.
I cannot see how this reaction is specific to the Go community. Adding extension methods to the language is not an easy task (you were presented with many hard questions to answer) and the benefits are not clear. Try suggesting to add extension methods to Java or Python. I doubt the reaction will be different.
I was just waiting on an explanation of *compostability*... I'm sure this year's veggie garden would love it some functional goodness, nom nom nom
There we go! You must be violating CoC now, kiddo!
I just downloaded visual studio code + that go extension on your mention. It's not exactly sublimetext... but it isn't missing much. It's like I'm back in my old C# days. To have intellisense and go to definition back..... mouse over definition peeking.... VISUAL DEBUGGING. We've finally made it...
&gt; I don't know much about the nursing profession (not 'industry' surely?) but I could see it being less of a draw to men for any number of reasons Main reason is the bad payment and that women chose more jobs in the social field (which are mostly not very well paid), teachers, kindergarten people, mostly women. That's the reason women earn less than men in general, lower paid jobs and part time because of family.
&gt; This is changing What changes are you referring to? Non-idiomatic Go is very foreign, and idiomatic Go is vey restricted to the language authors, who happen to be very opinionated. This makes changes rare. I'm interested to know about these web related changes.
Yeah, the Go community isn't inclined to do things just because other languages do them. A lot of us like Go because it's such a simple language, and it's a simple language precisely because it *didn't* follow the bandwagon. In particular, you'll have a bad time writing Go if you're constantly trying to shoehorn other languages' idioms into it--Go is not a very expressive language, as such there is often only one good way to do a particular thing. Depending on your priorities, this might be a good thing or a bad thing. Personally, I think having a uniform way to do things is a very good thing, even if it that way is not my preferred way to do a particular thing. &gt; As().This().Is() I'm confused about what this has to do with extension methods. This is doable today in Go without extension methods; however, it's rarely used because Go methods frequently return multiple values.
As someone who programs in Python/Vim in my day job, I think you'll really come to appreciate any text editor with gocode integration. I recommend vim + vim-go; the &lt;C-x&gt;&lt;C-o&gt; autocomplete is fantastic compared to what you get in any Python IDE.
The thing is, when you use a strongly typed system from the beginning you don't have to have reflection at all. This sort of amateur and ad hoc behavior is why golang isn't used at facebook. But, Facebook creates SQL systems on Haskell such as Haxl. The key is **abstraction**. Which leads to **consistency** and **readability**. Haskell does so elegantly. If you solve a problem in Haskell, you solve it forever to a level of mathematical and logical certainty. It makes no sense to do anything else... I advise the golang community coming to terms why reflection is the hack that proves its simply not ready for industry. Haskell also has Yesod, a web framework. We're among the smartest 5% of the programmers so if you go full haskell, you elegantly separate the wheat from the chaff. Anyway, good luck fumbling over whether you're going to use an ORM or SQLx. ;)
So, I'm trying to follow the logic that because people are talking about it, it must be trolling. Look at the history of posts to the Go reddit. VSC was mentioned a few days back. That is when I first even knew it existed. Until then I had tried Sublime but had settled on Atom. VSC with the debugger support is very nice and in the past week I have switched. Like many others, because of the recent mention of it. In the future, someone will post another editor/IDE that is "new" and I may switch again. Trolling? 
Genuine question: are people building real production *web* apps in Go, and if so why? It seems that inside and without the Go community there is an aversion to building Go webapps (whether following some variation on "MVC" or not) beyond very simple, stripped down microservices for a specific need. Whether that's due to Go's verbosity, lack of an ORM (or more accurately, lack of the language features you need to build a proper ORM), missing features in the core net/http libraries such as context handling, or whatever, there is a definite feeling that building a webapp in Go is a fool's errand and you're better off using e.g. Ruby or Python and keep Go for whatever heavy crunching you need to do in a backend service. Does this reflect people's actual experience, or just prejudices?
I think he means it generically as a tool used for editing source code, in which case any text editor would be encompassed. I'm interpreting him this way based on the fact that he specifically mentioned that he came from a "Python/vim" background, which seems to imply that vim satisfies his definition of IDE.
Then why didn't he say editor in the first place? The term IDE has a specific meaning and “editor” isn't the meaning of IDE.
Personally, my reason for freezing is partly to retain the independence of the repos. I'm freezing third-party repos that I don't want squashed into my repo. Effectively, I want to lock my repo to a library `github.com/package at version` but i don't want that third-party repo integrated with my history in any way more than a simple link. I see it being very much like parts of an npm package.json or python requirements.txt file, but maintained by git. Regarding all the complaints with submodules, I can counter all of them. Effectively, in my opinion, they're all moot, and are mostly due to either a misunderstanding of how to work with submodules or not wanting to learn a slightly different workflow. Neither is a good reason not to use submodules. I've used them to fantastic effect for years for this very specific purpose, locking one or more repos' commit to another.
Nice. `godm` is more full-featured. One of the reasons i chose my approach is to provide the command through `git` itself with the least possible effort. Given all the pushback I've experienced when recommending submodules, I was hoping that making it a simple `git` command makes it feel more comfortable to use and remember.
I can see times when using a link is adequate, but I also see times when subtrees would helpful. I'll be making a similar executable that is capable of both.
niet. u must move to ukraine. 
&gt; That stance, that go doesn't follow the bandwagon is also not necessarily true. There is a range keyword, there are plenty of other niceties from other languages. You can end up with similarities to bandwagon-followers without following the bandwagon yourself. Specifically, you're conflating "Go has `range`" with "Go has `range` because all the hip langs have it". &gt; Is not really doable today on types you don't declare. You have to alias them first. Ok, that makes more sense to me. Thanks for explaining.
(shamelessly piggy backing on the first voted answer) I happened to find this blog post (fyi : I am not Julie Evans, and I am a male ... ) : http://jvns.ca/blog/2016/03/06/women-only-spaces-are-a-hack/
You don't need to run an AppleScript to call a phone number, you can just launch [a URL](https://developer.apple.com/library/ios/featuredarticles/iPhoneURLScheme_Reference/FacetimeLinks/FacetimeLinks.html) using [open](https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/open.1.html).
in ukraine, is the grass green and the girls pretty?
grass is yellow and the girls might be missing a few teeth, but otherwise maybe.
If you use Dvorak, its equivalent to WASD is also supported.
I don't really like git submodules vendoring approaches, because they assume all of your dependencies are going to be version controlled via git. It seems like a bad thing to couple a build toolchain to a particular vcs.
Why does the Generate method return a reflect.Value instead of interface{}?
So if I'm reading this code and the article correctly, what allows 10 million connections is basically system tuning using `sysctl` and opening a thousand ports on the server? (Or is the thousand ports thing merely for the benefit of testing from the same client machine?) Edit: Not to discount the article. I actually have been looking for the magic tricks that allow such throughput. The Go programs are trivial enough, so I just wanted to see if my understanding is correct.
So what you're saying is, perl is the death star?
And you're entirely free not to use this tool. ;-) I'm just curious, what vcs do you use and that Go supports that git can't submodule? hg and bzr can be submoduled by git. Personally, and obviously :) I have no problem with git submodules. I use git exclusively and if i need to vendor something _that git can't submodule_, i will mirror it in a git repo. I would agree with your concern if there was significant reasons for using many other version control systems. There aren't, and this coming from someone who prefers hg over git. But git won. It does everything you need from such a tool. Accept it and let's move on. I've not encountered a scenario where it makes more sense to use a different vcs. Depending on git is like depending on a file system. Sure, in certain cases you'll need something specialized but it's such an insignificant minority of cases, it doesn't warrant the time spent providing enhanced tooling.
I agree. I doubt i'll use it but i can add a `-subtree` flag to add flexibility. BTW, my prior comment was not intending to imply that subtrees aren't sometimes a useful solution. Only that i think all the arguments against submodules don't have much merit in my opinion.
We don't need that in Go.
The thousands of ports trick, and widening `net.ipv4.ip_local_port_range`, is purely to help create the load from a small number of clients. Otherwise the sockets in `TIME_WAIT` fill up the available space. http://www.serverframework.com/asynchronousevents/2011/01/time-wait-and-its-design-implications-for-protocols-and-scalable-servers.html http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html
Okay, that makes sense; otherwise it's just system tuning then? Specifically, this part: sysctl -w fs.file-max=11000000 sysctl -w fs.nr_open=11000000 ulimit -n 11000000 sysctl -w net.ipv4.tcp_mem="100000000 100000000 100000000" sysctl -w net.core.somaxconn=10000 sysctl -w net.ipv4.tcp_max_syn_backlog=10000 
GAE is overall fantastic. Super fast deployments, integrated logging, metrics, etc. It's not great for CPU intensive / long running tasks, but those are pretty easy to move over to Managed VMs. We went through a decent chunk of the sad times, but I'd recommend it to anyone now.
Yeah that's just opening the throttle for the TCP stack.
You can use the go-imports tool and go-plus plugin. 
The point is more that there are no magic tricks required for 10M connections or large heap sizes in Go. The throughput is actually quite low for this server, which I guess is a trick in a way.
GAE is really nice for most applications and has a well-made Go library. The datastore works pretty well with Go, and having everything integrated and ready to go is very helpful. The downsides that people are likely to encounter are: 1) No native socket access. This means you have to use the socket API (which is particularly annoying in Go) and/or urlfetch (an okay service, but mildly annoying). This is fixed by Managed VMs, but those are still kinda beta and the deploy times are on the long side. 2) Goroutines, one of the coolest feature of Go, are a bit less useful because a goroutine cannot outlive the request that spawned it. For doing stuff in parallel, you can use goroutines. For doing stuff totally asynchronously, you'll have to use the taskqueue. Once Managed VMs are out of Beta, I expect it will be even better. The plus side is that porting from regular Appengine to Managed VMs is basically no effort at all.
Great write up. Thanks. So it sounds like, for hosting websites that may end up requiring a small db, GAE sounds alright for it.. For now at least.
Nice. Thanks!!
I agree heroku was easy and faster to configure
Two things: this has a [deadlock problem](https://github.com/gorilla/websocket/issues/97), and it [doesn't work on Docker](https://github.com/docker/docker/issues/4717)
It works out of the box in vim. Other editors might need to update their plugins.
I use openshift... and I love it. It's free, it's fast, and works great.
1. Since we just stream-through all commands/data to MySQL, on database level it all works fine. In terms of PUB-SUB part, things are not as stable yet. Transaction rollbacks are not yet implemented and update race is not properly handled (unpredicted end-outcome). 2. 3. - It's Apache2, thanks for both findings! 4. True... This goes into the bucket "lots of things we need fix". I'll file an issue so it doesn't get forgotten 5. Thanks again! 6. Yeah, arithmetic operations are not supported. Honestly, since we inherited/resumed the project, we believe this whole parser and its constraints should be rewritten/improved. It is too inflexible and doesn't support full spectrum of MySQL syntax. Thanks for all the thoughts! Feel free to file issues on github if you plan on keeping a closer eye on the project or even contribute :)
I appreciate a stickler for consistency. It's generally a good idea. Especially in the case of code.
Well, we're not a 50 people company or a 100 contributors open source project, there's 3 of us working on this currently in our spare time, not counting original devs. Different people worked on this, some without Go background, of course code is not perfect - would you prefer we lied about it? :) We'd love to continue working on this and get it to the next level, starting with refactoring the code to be more "goish" and improve the syntax handling and data handling.
I use Digital Ocean with docker-compose to manage my app, database, redis and nginx.
Hi! I've started to use ovh vps and dokku – a mini-heroku on your servers. Have launched two apps in it, and it really awesome and useful combination.
So what you're saying is not that Go is not suitable for webapps, but that Go is not suitable for complex HTML generation? Whether I'm using Django, Rails or Go for a webapp the HTML generation is only a fraction of what the web app has to do (and as you point out, one that is increasingly being pushed to SPA/mobile clients, though I doubt the 90% figure at this point). That still leaves everything else: - Authentication/security (including CORS, CSRF, JWT, oAuth etc) - Database (SQL/noSQL) - Caching - Input validation/serialization - JSON/XML/GraphQL/....? output - SMTP - Web sockets - Connecting to any number of 3rd party APIs - "Business logic" specific to the project HTML generation is probably the least of these concerns. Given the debate in this thread concerns ORM/databases and not templates, the question is whether Go is best suited to all of the above requirements? Or is it just for the odd corner case such as a backend cron job or high-performance chatbot? 
maybe https://cloud.google.com/compute/
the go-imports tool of go-plus? or another one?
If you guys want a faster, liter and better system what you need is Haskell. It won't long until all **systems programming** and **websites** are in Haskell. Face it. The gigs up gophers. Haskell is fast as C, while everything golang done is always decided slower since you have to statically link a 20mB GC to every binary - what is this Unity3d for console apps? I mean seriously, you have no **generics or templates**. How can you even program anything? Have fun with the McLanguage. I'm going to go count my millions - writing **bug free** programs in haskell gives me a lot of spare time!
Couple brief comments: 1. That flame is old news. 2. You're a troll. We don't feed trolls. Thanks for dropping by. -jeff
How so? Reading up on it and I haven't spotted either of those quirks yet. Heroku sounds intriguing. I like Postgres and may also have node.js sites. 
&gt; Posted on December 29, 2014 at 19:06 by wesolows This is more of a complaint against cgo, less about golang itself.
The thing I love most about GAE is the integrated security. One Yaml setting and only people from my google apps domain can log into the app.
Can you please tag versions of the library? it would be really helpful
One of the thousand reasons to not use docker
Criticism is quick, solutions are critical. Not a docker user, but I find a lot of unnecessary "this is shit" comments and would rather see "this is shit, why not try this" at the very least.
Type system is still an unsolved problem in programming language design. It is like the state of structured programming in the 1950s. Today we all agree that a decent programming language should have functions and control structures like "if" and "while", but there wasn't a consent back then. More elaborate type systems catch more bugs at compile time, but they also tend to be harder to reason about. They can also be too restricted at times and you have to work around it. (I omitted verbosity, because that is mostly solved by type inference.) The very reason we have dynamically typed languages is that people got fed up wrestling with static type systems and would rather throw it away along with all its benefits. It is good that there seems to be a renaissance of static typing systems in the recent years, but you don't have to feel bad because go's static type system is not expressive enough. Type systems are as good as how programmers can use them. The experience of ordinary programmers is the ultimate judge of which type systems are better.
hey, what you're doing I appreciate. I'm not the only one. I had a friend call me up and my friend he said "dasacc22, this haskell_oxford's words are great, he has the best words", and I agree, they're the best. But look, we have people coming to this community that are looking to do tremendous harm. I mean, look at r/golang, look at what's happening in r/golang, these people did not come from r/haskell, okay? Look at what happened with docker, look at what happened last week in stdlib with, with you know, SSA merged with CLs. Other people are going to merge CLs. We have a real problem. There's a tremendous hatred out there, and what I want to do is find out, is -- you know you can't solve a problem until you find out what's the root cause, and I want to find out what is the problem, what's going on. And, it's temporary, I've had so many people mail me to praise you. I don't know why they're mailing me but they are. Just wait a week, just a week, people will be more vocal saying "haskell_oxford, you have done us a tremendous service, because, we do have a problem and we have to find out what is the problem".
I love lodash/underscore. I'll be taking a look at this for sure.
I have been using VSCode + Go plugin (on Mac) for a while as well and I have been very happy with it. I switched from Sublime though, it was working. But VSCode is much nicer.
Eh, I don't think it butchers anything. The only thing they require is Godeps, but latest godeps with go 1.5/1.6 uses the `vendor` folder (instead of it's weird `_workspace`). Heroku config with variables is pretty nifty, and deploy using git branches is veeery smart. Also they are pretty quick on supporting new versions.
It would be nice if the Is functions worked with Readers; I find myself using Readers a lot more in Go where strings made sense in JavaScript. And there's no Unicode support, which is something Go is really good at. Perhaps if the state machines were written by hand instead of regexps, they could be made to work with readers and Unicode, and maybe faster. I really don't like the `Each` function. It's a range loop but adds the overhead of indirection. I don't think there is a use for it.
But a lot more than expensive !