Ends up being a great learning codebase for me so thank you!
Congrats on this. I starred it for when I move to vuejs and go, from a jquery and php backend. I know, I'm years behind. But porting over a monolith is not something one simply does lol.
Downvote for XML, upvote for funny = no vote.
Given that the Go world doesn't have a standard for this, look at the tools you are using alongside this new thing and make the config file the same. Thus if your ops guys already are doing YAML for their Docker Compose definitions, use YAML. (Which is gross, BTW.) -jeff
Given "we need all the help we can get", curl(1)'s `-sS` should be the default behaviour.
I think it's highly unlikely for `dep` to be rolled into the standard toolset as is - `dep` is an experiment, as far as I'm aware. relevant ML bits - https://groups.google.com/d/msg/golang-nuts/PaGu2s9knao/Bq4vmFh7AgAJ
I love using Go because it makes maintenance and deployment really simple. (Seriously, once you deploy a Go binary, everything else will look hilariously overcomplicated.) It's also nice to use the standard library for almost everything, although I imagine this approach can be slower than finding a good library or two. In any case, Go is absolutely a reasonable choice. However, the abstractions that Go encourages you to make are different than other languages. Where Java encourages OOP, Go encourages composition and interfaces. Where Node encourages callbacks/promises, Go encourages channels. It's a different way of thinking, but I find it enjoyable. &gt; which framework should I use (if any)? The community seems to think that you don't need a framework to make web apps, and I'd have to agree. It's pretty easy (or at least straightforward) to wire up your app using the standard library, maybe with a routing or a template library thrown in for good measure. Oh, and check out [Caddy](https://caddyserver.com/). It'll change your life.
I would recommend learning Go and using it to make the app _only_ if you are sure it's going to be worth learning a whole new language, and while Go isn't too hard to learn (especially if you aren't doing any fancy stuff with channels or too much with concurrency outside of using the net/http package), I would think you'd make a better app in a language you've actually done than one you have to learn, no matter whether Go is better or not. Then again, even if you don't make *this* app in Go, no reason you still can't learn it! Use it in the future possibly too! my 2c
&gt; thank you for your time and dedication to it. &lt;3 &gt; Do you think that a successful dep tool will spark other official tooling projects I do hope so, and I see them as natural outgrowths of the work we're doing now. Hopefully, many such things will fall out pretty naturally, now that we've established a path - there won't be such a need for such drawn-out consensus processes. For each: &gt; centralised package repository I do hope we get this, for a lot of reasons. I've tried to design carefully for that possible future, in fact. Much discussion in https://github.com/golang/dep/issues/175 and https://github.com/golang/dep/issues/174 - I expect that, at minimum, private/enterprise needs will demand we do it. &gt; Go version manager like https://github.com/moovweb/gvm ? I don't currently use one of these, so I don't know where the rough edges are, nor am I fully clear on exactly what the connection would be with dep mgmt - I guess indirectly through https://github.com/golang/dep/issues/223 ? &gt; $GOPATH-ectomy This is very much a part of the long term plan; many things will become possible once the metadata dep provides becomes a first-class part of the toolchain. My sketchy thoughts on what that all might look like are here: https://gist.github.com/sdboyer/def9b138af448f39300cb078b0e94cc3
&gt; What I check so far that Go can be used both for system programming and Web Application No. Google meant something different with "system programming", more in the way of the "server system". Stuff you can do with C/C++/D/Rust you can't do in Go. Use it for the backend, server, web stuff and you will be fine.
Do you care how your program behaves when there is a fault somewhere else in the system? E.g. Do you care about what the program does if the database exists but doesn't have the correct/any schema; if the network connect to the database server suddenly goes away while the program is doing something; etc. The answer is probably yes since you are checking for and returning errors. That is the behaviour your linked `Store` function appears to claim to have. Therefore you should test that the `Store` function does what you think it does in such situations. E.g. by using a stub test database that returns errors at various points of interest. Is this the most important and first part of your program you should make sure you test first? Probably not. P.S.: Don't call `sql.Open` inside functions like `Store`. Database connections are meant to be long lived and opened once, not opened per-fuction call. From [`sql.Open`](https://golang.org/pkg/database/sql/#Open): &gt; The returned DB is safe for concurrent use by multiple goroutines and maintains its own pool of idle connections. Thus, the Open function should be called just once. It is rarely necessary to close a DB.
I've checked out Iris, Revel and Gin frameworks - are they worth giving a try? My back-end will be mainly rendering dynamic HTML, some REST endpoints and database access. My concern with using a framework is in having to build things from scratch like routing, POST api calls parsing and html rendering like you'd need to do using pure Node (without express/koa plugins)
Very interesting, thanks for the links I'll check out the discussions. 
No. If you know javascript and node already, this sort of project would be better done in typescript I imagine; the node ecosystem of 3rd party packages is more mature and robust than the go one. Many go libraries exist for the same sorts of tasks, but: - It lacks a package manager. - Different packages use a variety of different package management hacks / 3rd party tools. - There's no good high performance orm and auto migration story. - The ecosystem of middleware is smaller and poorer because there is 'standard framework' that people have centralized around. What go *does* give you is an *excellent* parallelism and deployment story; I would totally recommend learning go and picking it up for a small project to see how you feel about it and if you're happy to work around the limitations it has. ...but not this project. I don't see anything in your task is node is particularly poorly suited to; I can almost guarantee doing it in a language that you already know will be more successful than trying to learn go *and* build a large project in it at the same time. Try making a user authenticated 'todo list' app in go and see how you like it. You'll stumble straight and immediately in the problems with go web development and you can see if you're happy with the comprises or not. Personally? If you need something more serious and reliable, I would use java or C# to build the platform you're talking about if you're serious about it. 
What about private dependencies? How does the docker image pull them into the build? Do you have to manually ADD them all?
Ethereum blockchain has been built in Go.
Isn't that just a server application too? A more complex one, yes but still a CLI server application.
it's not *just* a sever application :) Anyway check this out as well: https://gobot.io/
&gt; framework for robots, drones, and the Internet of Things (IoT) Those are all things that * have low specs (memory, cpu), especially IoT devices ... running Go binaries there seems weird if not impossible * probably need deterministic calculations so no Go GC (drones, robots) The Arduino site says "SRAM 2k bytes" (ATmega328) and "SRAM 8k bytes" (ATmega2560). The Go GC alone is several megabytes. I'm not conviced :p.
[removed]
It's not free
Yes, github.com/eawsy/aws-lambda-go-shim uses in-process proxying via FFIs, which I specifically called out as something I wanted to avoid in the request path. They claim that in-process proxying is faster than inter-process proxying (which I fully believe), but no proxying should be even faster still.
What language are you talking about that has support out of the box for unknown soap endpoints and custom MQs????
the 4 projects: - https://summerofcode.withgoogle.com/projects/#5387946543808512 - https://summerofcode.withgoogle.com/projects/#4687989750890496 - https://summerofcode.withgoogle.com/projects/#4532728897732608 - https://summerofcode.withgoogle.com/projects/#5254287362883584
It is so long as you don't mind giving out an email address.
Yep. And they are actually good on their word about not spamming. I used a + address on Gmail so I can tell who sells my data. These guys sent me one email that I used to unsubscribe and that was it. They never sold it and they haven't sent me anything since.
I'd recommend you pull back a bit and learn something even more fundamental. The concept of a "web app" is somewhat nebulous. Many people that use that term think in terms of an application running on a server that renders HTML pages for the browser. The development style is, IMHO, completely outdated at this point, as it typically does not provide the right interface for mobile app development -- though some frameworks allow for a "web app" and API all in one. Rails is a good example of a framework that allows for this. Modern development, in my opinion, begins with a static HTML/CSS/JS web site that makes HTTP API calls to an entirely *separate* backend API. This extends nicely to mobile app development, as you can have a native mobile application that uses the same APIs. Go is a *terrific* language for backend APIs. Javascript is, short of transpilation, the *only* language that runs in browsers, so it's the simple choice for the front-end UI browser application.
Very good advice. There is also a rule of thumb I would like to mention. In a serious project, you can afford one experiment. A new configuration tool, a new library, a new testing framework. Keep it to one experiment, or your project becomes an experiment. Using a new language, producing quality features and decent tests does not happen all at once.
The ability to pay off your programming sins.
Looks very clean! Code and UI-wise.
https://www.reddit.com/r/golang/comments/69hcsj/updategolang_05_script_to_easily_fetch_and/
Download the archive (https://storage.googleapis.com/golang/go1.8.1.linux-amd64.tar.gz) and extract it into /usr/local, creating a Go tree in /usr/local/go. For example: tar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz From: https://golang.org/doc/install#tarball
I agree with you. I'm a frontend developer and I work with modern webapps - pretty much 100% dependent on javascript in the browser and only consuming api calls in the back-end. Can you elaborate why Go is terrific for backend APIs? Would I ran into trouble to create endpoints that talk with the database (maybe a no-sql one) and return JSON?
terrific = very good terrible = very bad
Is your data non-relational? Almost no application benefits from "NoSQL" databases. Even the big players often use relational databases with a non-relational schema (Uber is an example). Also, no, these frameworks are not worth a try. The standard library is already a framework. If you want more performance, which is usually the shiny selling point of these frameworks, get a better *router* (I like [Chi](https://github.com/pressly/chi)) rather than a whole unidiomatic ecosystem. If you need middleware, the [Gorilla toolkit](http://www.gorillatoolkit.org/) is able to cover most needs.
From what Rob Pike has said, the language hasn't changed a lot, but I'm not sure if that's applicable here.
A fine of example of using a better tool. While I prefer Java, if someone comes from a JS background, golang is a great, better language and environment. You can get all of the web scale features of Node, without the glaring issues like those listed here. 
No, go is good at that. The reason it's good at API level stuff is that it is compiled so you get good errors before you deploy, you have tool in to do API stuff built into the library, and you get a simple binary to deploy. Go has decent drivers for all the big SQL DBs as well as Mongo and ArangoDB for document storage. 
Missed it :( Not exactly a lot of notice. You guys know that we're not all in the same timezone, right?
Nice work! I have a couple questions: * With S3 used for the images. Is it stateless and thus horizontally scalable? * Would it be possible to store the config in environment variables rather than a local file? This would make it much easier to host in AWS Elastic Beanstalk.
This is great advice. :)
I would highly recommend reading this article that talked about someone using node, having problems and how they were solved extremely well in go. https://medium.com/@chrisgregori/i-wrote-some-golang-and-it-felt-great-3c3367a67db5 Dont let learning a new language stop you from building a new app in it. I learned that the hard way. Iv'e used both PHP and Node and as soon as they go to any decent size they start showing there limitations in a big way. Go doesn't do that to you!
Pheonix (http://www.phoenixframework.org/) is also an excellent choice for doing high quality work in elixir and I totally recommend it, but once again: all I can say is that using a new language/framework/platform for a project is super risky. There are plenty of mature platforms you *could* use; Spring, .Net core MVC, pheonix, django, rails... but really, I guess my only practical advice is break it down into a couple of choices that you like and try them out. Build a few small things in them before you try to build a big project. If you're really set on doing it in something different, elixir is pretty reasonable choice.
I was actually also wanting to give no-sql a try and see why people usually say it's bad. My data will be very variable in a sense that a store can post any kind of product, and be able to add steps to the purchase (like adding/remove stuff etc), but I think a relational database would be just as good...
I suspect it would be easier to learn than Ruby or Python, because it's a much simpler language, with an easier-to-explain execution model. I also think static types will probably make it easier for a beginner to follow what's going on. Have you tried reading any of the official Go docs? I think they do a good job of explaining structs, methods, and interfaces. If you have concrete questions, I'm happy to answer them.
&gt; give no-sql a try and see why people usually say it's bad It's not that it's bad (except for Mongo, whose implementation has been riddled with issues, many of them fixed, but still doesn't inspire confidence), it does one thing great: Help scaling ***non-relational data*** access and storage in a trivial way. The thing is: The overwhelming majority of applications out there manage ***relational*** data. And for dealing with that we have a solid mathematical foundation (relational algebra), which is the basis for SQL and relational databases. You mentioned products, purchase and purchase items in your comment. That's relational data. It's not that a relational database would be just as good, it would blow these NoSQL databases out of the water for dealing with that data because it's designed to handle all that efficiently with man-centuries of work put into it; while non-relational databases are much simpler. At the end of the day these technologies all have tradeoffs to suit different purposes, but with databases you can follow a simple rule to get it right: If your data is relational, use a relational database. If your data is non-relational, *consider* non-relational ones, but if the data set is important still go with a relational one and only think of switching once you hit growing pains.
If your payload is json, you can setup omitempty fields 
I would love to see some of the Node code vs the Go code. I can't help but feel like there must have been something fundamentally wrong with the Node implementation to get this level of boost out of Go.
Based on your description, it is very likely you can use composition: type PostContents struct { UserID UserID `json:"user_id"` Title string `json:"title"` Text string `json:"text"` } type Post struct { PostID int `json:"id"` PostContents } The reason I say this is that it is likely that if you exercise type discipline consistently you will find that at any given point in the program, you will _definitively_ have either a `PostContents` or a `Post`. If you are careful with your types, you are likely to find there is never a point where you have "maybe a post with an ID, maybe a post without an id". Though it does sometimes take a bit of practice to get good enough with typed programming to be correct enough in your handling to get this correct. The next tier of flexibility is interfaces. If you _do_ have a place where you may be manipulating "a post that may or may not have an ID", you can declare an interface: type PostContentsI interface { GetUserID() UserID GetTitle() string GetText() string } and implement it on `PostContents`. By the way composition works, that will automatically implement it on the `Post` I show above, so `Post` will automatically conform to `PostContentsI`. This is a bit smellier than the above, but is still statically-typed and has compile-time guarantees that anything using `PostContentsI` will still not manipulate the ID that may or may not exist. This is especially true if the value being passed by interface doesn't really "go" anywhere else after that; for instance, one thing I would accept without too much thought in this context would be a `Render(p PostContentsI, w io.Writer)` method since it is completely plausible to me that you may want to render a post prior to it being given an ID. (For instance, a live preview function in the post creation UI.) (I don't love the name PostContentsI, but without more context I don't know what you might want to call this. RenderablePost would be plausible if that's your primary use for the interface, for instance. Which you'll probably find evolving into a `Renderable` on you....) Only as a last resort would I consider using a pointer to the ID that may or may not be nil, in a `Post` struct that tries to encompass both cases. That puts all the onus on you to ensure that every time you go to use an ID, you must first check that it exists. Better to let the compiler do that with the types above. There isn't _that_ much daylight between an expert Go programmer and a beginner in my opinion, at least not compared to most languages, but fluidity with the compositional style rather than the inheritance style is definitely one of the distinctions between beginner and expert.
Yeah, super easy, but I would guess that it's not that well known. Besides, I believe that only works with Gmail addresses and mine is hosted on Gmail, but it's my own domain, so they would have to perform more checks to even know that it would work for my address.
Yeah. It seems to work well for the most part anyway. Their spam filters are really second-to-none, so it's really for those rare times something might slip through.
The code looks alright, but... Why not use inotify? instead of ticking every X seconds, you can actually get near real time update.
Article was kinda weird for me. Concurrent http requests would be IO bound, not CPU bound. Thus if it were taking 500ms in Node it would almost certainly be in the same order of magnitude in Go. If anything Node is actually better suited for simplistic things like issuing a bunch of http requests to be handled concurrently. I've also never heard anyone say or argue that Node is multi threaded. I do get the issue of npm install everything, but not when it comes to comparing std libs. They're largely the same in functionality. I'd be curious to see the actual code that had a 6000% speed up just because of a switch to Go.
Okay! Thanks for the tip, I'm checking it out now +1 edit: seems it's now [fsnotify](https://fsnotify.org/) in case anyone else is looking followup: Hey! I was actually looking forward to having something similar like this brought to my attention. I wasn't so much concerned about the originality, I really just wanted to get my hands dirty. And in the end it's nice to have something I can directly reference for ideas/guidance (like using select and defer, which I totally overlooked). Thanks again :)
Thank you very much for this in-depth response! It's exactly what I was looking for.
 package post type ID int64 type Post struct { ID ID `json:"id,omitempty"` Owner user.ID `json:"owner"` Title string `json:"title"` Text string `json:"text"` } func (p *Post) IsStored() bool { return p.ID == 0 }
I may have been misreading, but I believe the speedup is from Node memory limitations. Article mentions the data file can't fit in memory in Node. I believe this hints that the solution was to stream from disk for each request, whereas Go can easily load all the data on init and do all processing in memory. It's been a while since I last did data processing with Node but I can't remember running into memory limits like that. Still feel there's something weird with the Node implementation.
Thanks, I've been looking for something like this recently!
Ah, a Bash script. Thanks, I'll check it out. This may actually set up more for me than I actually need.
It does install LiteIDE as well.
What was Node's memory limit in your experience? I found conflicting information about the 1.7GB limit. Some people say it's much higher now (8GB+)
Please post a Benchmark compared to a simple map with sync.RWLock. The difference will surprise you ;-)
&gt; you still have to deal with nullable ints, dates, strings and wrapper types, even more so. so? it's not that much of a big deal to deal with these issues. 
Not sure if "forgiving syntax" is a feature i want in a config file.
I have always been told that JSON is for data and TOML/YAML/INI for config. I believe Crockford said so too. Why insist on using JSON for config if your target language is not JS?
I hate to be the bearer of bad news but a channel uses a mutex under the hood. At the level a map operates at your biggest slowdown is the use of the channel. You'd get 2-3x speed up rewriting with a mutex and no go routine. And better read focused characteristics if you used an RWMutex. I'm a huge fan of hacking about the builtin data structures though and it's always good to see others doing the same!
Request(url, function(data) { do something; }) That's an asynchronous http request in Node. You can repeat that line as many times as you need and all requests are async and concurrent and executed at an OS level. The equivalent in Go would require quite a bit more code, channels, etc.
None of the modern editors as far as I remember supports such syntax, which would make working with this format annoying. I would much rather use something actually designed for configs.
Have you seen [this](https://github.com/hashicorp/hcl)? Not saying you shouldn't do your own thing but you might be interested in a similar project.
Perfect! That is super helpful. Thank you!
You could probably put watcher in a different package. You exported NewWatcher but then only use it from main, so it doesn't need to be exported. Same for Watcher struct and exported variables in Watcher. You can also invert some of your if statements to avoid indenting the whole function. The function at the end of the watcher file is a good candidate. Use an early return instead.
Look at the builtins. crypto/rsa uses math/big. 
I will be doing that as well, but at the moment I am stuck how to make go-routine for each column (this print statement will be replaced with go-routines), because if I have to iterate over everything, that will make go-routine for each square, not column or row
Thank you so much, will try that. Thank you all &lt;3
I'm not the original author, but my best guess is they wanted to support diverging code paths that all stem from the same request. Let's start by looking at a simple example: https://play.golang.org/p/jaEX4gSOvt (shown below) package main import ( "context" "fmt" ) type Test struct { ctx context.Context } func copy(t *Test, key, value string) { t2 := new(Test) *t2 = *t t2.ctx = context.WithValue(t.ctx, key, value) } func noCopy(t *Test, key, value string) { t.ctx = context.WithValue(t.ctx, key, value) } func main() { t := &amp;Test{context.Background()} copy(t, "name", "jon") fmt.Println(t.ctx.Value("name")) noCopy(t, "name", "hank") // because we didn't do a shallow copy, all future uses of t's ctx // will have this value set fmt.Println(t.ctx.Value("name")) } In the second function call (`noCopy`), because we don't do a shallow copy we end up with the original `t` object having a new context value. That is why when we call `fmt.Println(...)` the second time the context has a value for the `"name"` key. This might not seem so bad, but what if the `noCopy` function had instead set a deadline intended for functions it calls instead of setting a value? Now *all* future users of the `t` variable's context have a context with a deadline that was set by `noCopy` even if it wasn't relevant to them. By copying you avoid this and allow each code path to set its own values and deadlines as it sees fit, and if you want one shared across them you simply set it on the `http.Request` before passing it along to both of the code paths.
Make sure to pass those arrays by reference too or you will be copying 9x9 every iteration. If you don't end up using a struct matrix as suggested already.
Usually you end up with a lot of different IDs, which can be easily mixed up. So just some typesafety at the cost of having to deal with explicit casts some times.
SetConsoleTitle https://msdn.microsoft.com/en-us/library/windows/desktop/ms686050(v=vs.85).aspx
This is so very true my friend. Come to think of it, I don't think I've ever managed to code something that (upon further searching) doesn't already exist :D 
I'm a little confused, from what I understand of GraphQL, queries always follow a predefined schema, so I'm not sure how they could be 'very dynamic'. I have used a graphql server lib for Golang and it was a good experience. If you're having to use reflect and unsafe, or lots of interface{}, chances are you need to reconsider your architecture, not your programming language.
Unbuffered channels will not yield concurrent code: the producer waits for the consumer.
Yes, I agree having dependencies is not nice but { I : [/* would */ like //to "see" that \n sed] } spitting out { "I" : ["like","sed"] }.
I think so too, thanks! I wish I could answer whether the above dockerfile is compatible with hub automated builds, but I don't use that feature. Nonetheless, my guess is that any valid dockerfile will work.
That's only true of http requests running in different goroutines , which like I said you have to code up. Try running a bunch of http.Gets in a row in a single goroutine. Each one waits to be done before moving to the next.
There's no difference in search engine issues. Just think about it as using an API to store your data rather than a database...
And it easy to deploy. And it's "[fast as fuck](https://medium.com/@chrisgregori/i-wrote-some-golang-and-it-felt-great-3c3367a67db5)"
You're far better off if you never use nullable columns... There's really no need. The solution is simple, elegant, highly performant and storage efficient. And it completely eliminates what appears to be your main reason for not using Go.
yea if ur just doing string parsing use another lang like php or javascript, i think go is a little annoying to write for something that simple, because of all the terseness of string.foo() and rune.bar(), and interfaces{} like you said. (perl is best: `matches =~ /regex/`) for proxying though go is a perfect language for these high-speed apps like middleware and servers.
I prefer godeb: `https://github.com/niemeyer/godeb` to install or update golang on Ubuntu. It transforms tar.gz into deb and installs it. e.g. $ sudo ./godeb install 1.8.1
My idea is to build a proxy. The server receive a request to add a graphql endpoint, after this, the server do a introspection on the endpoint to get the schema (this is the hard part) and after this, the server is ready to receive requests. When a graphql user query get in, the server know how to cache, validate the query, generate metrics, etc... All at run time, the schema isn't pre defined like a standart graphql server.
What about a stop method for the Watcher?
Whoda thunk... It's like having a bunch of nested callbacks, just without the callbacks. 
/u/SEND_ME_RARE_PEPES you can get values from environment variables in go. https://gobyexample.com/environment-variables You should definitely request new ones and remove your secret and key from your git repo. When you run the program you can just pass them in via the ENV
&gt; If the requirements will change constantly I'd use python or JS. This is what I was referring to. I find that if requirements are constantly in flux, it means I'm doing lots of code reorganization, and if I'm doing lots of code reorganization, static typing speeds things up significantly in my experience. I would say that if you are looking to generate lots of UI out of the box (e.g. admin panels, etc) then GO is not the best. But honestly, I never used generated UIs out of the box.
I originally started doing config files in Json until I ran into the brick wall of wanting comments for each setting to give context on them. At which point I switched to yaml and had a much better experience for what I needed and probably would recommend yaml for config related stuff if you want to make it easy for a end user to edit and if it's something you semi expect or require them too. If you don't expect or desire such behaviour Json is fine too so use whatever floats your boat and gets the job done. 
If those are the actual ones being used for a deployed version of your application, then it should definitely not be committed​ into a code base, ever. As an example, a malicious person could use the ones that you publicly committed, create some malicious service using your client id and secret, and now that service could behave like yours, but in fact be doing something malicious, without the user knowing. Like a phishing attack but against APIs, so to speak. Or, someone could use those API creds to send a bunch of API requests and now your account is gonna be rate limited. Those are just some examples, there are other things that could happen, malicious or otherwise. Secret (API keys, DB passwords, other passwords,you etc) management the scope of this sub, but it's a common aspect of any software product. As mentioned above, environment variables are a good first step.
Yeah, for me it's very simple to create a new (reddit) app and just change those in my code or use an environment variable, so no problem, I left them there as an example
That still sounds like something that belongs in the GraphQL server...
Go can do dynamic things like any other language, only your concepts need to be concrete. A struggle here makes me think your design is not flushed out, have you written anything up? If not you should start with 2-3 high level user requests and map them to a bullet list of features they should be able to do. Then find what is common between them and begin flushing out your design in concrete types. Point is a static type system does not have a unsolvable problem, so if you want to use Go, you should :)
Don't worry, you didn't miss out on anything in there that there aren't a hundred examples of online. 
Some general rules of thumb when it comes to application security and secrets: * If you are provided with something that's unique and is required in order to access something else that's a secret. Other things could be secrets too but this is the most common case. * Do not publish real secrets to your repo even if they are no longer valid. Why? Because you don't know how the secret is being generated and it's possible that publishing a formal secret might allow an attacker to either figure out other secrets, learn more about you/your app/etc or do other kinds of damage. * Once you commit a secret simply removing it from your repository is not enough. First, be 100% sure you revoke or invalidate the secret. Second, you either need to recreate your repo or force push modified history to completely remove it. * Always treat secrets like they identify you personally (date of birth, address, name, etc). You never know what an attacker will come up with in terms of abusing your secret. For example, there could be an API that could be queried to find out more about you.
I categorically challenge any 100x speed up benchmark for node vs go until I see the code from both, and the actual raw data. I just cannot believe it. People spouting this kind of stuff are either doing very specific things that most people aren't doing, or doing it wrong in node if they're getting that kind of speed up (and if you're referring to that recent article, it *is* because they were doing something most people aren't doing, highly concurrently). Node is a highly *highly* optimized runtime, that is, despite javascript being a pile of steaming goo, really very fast and good at what it does. I think we can safely say that go is great, but if you're expecting 2 order of magnitude speedup from using it for a generic web app, you are just plain dreaming. It won't happen. What *will* happen is you'll struggle with the tooling (like migrations), the package management (because GOPATH is a stupid idea, and luckily `dep` will help us solve that eventually) and a lack of 3rd party ecosystem for middle ware. You've just got to be pragmatic about it; yes, you can build excellent little services in go which are quick and easy to deploy. ...but no, it's not a drop in replacement as an application platform for node. Not. Even. Close. ...and you **will not** get a 100x speed up from using it. 
https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=go&amp;lang2=node Based on this article I would estimate a more accurate speed comparison maybe that golang is typically 2x-20x faster. And those benchmarks probably miss the "real world" qualifications. Also the memory footprint is probably generally 10% of node's. If you have a better way to describe how much faster golang is than nodejs, I would love to hear about it. Also that's a good point about golang's lack of a "Rails". Node's ecosystem is certainly ahead of golang in terms of Rails alternatives, but I don't know if golang has anything "Rails enough". It's pretty common for somebody to says "Yeah, who needs Rails, X has everything and is way better than Rails" then when you take their word for it, it's only 5% of what Rails is and what is available is experimental.
Great explanation, thank you. The example of setting the deadline for child function calls really concreted it for me.
&gt; That's not his problem though That may not be his responsibility or fault, but it's most definitely his problem. The decision: You use real, if invalidated, secrets publicly. Pros: - You don't have to change a few characters. Cons: - You are now relying even more strongly on those services to be perfect. - Even if it is perfectly implemented, you still have to be pretty sure that you know exactly how their security protocol is working, because you've just gone off-script. Does not seem like a good tradeoff. Obscurity isn't reliable, but that's no reason to go around willfully dispelling it. It's at *best* equally secure, but only if you can put the odds of stuff being wrong at zero... which is pretty much the worst bet you can make in security. 
The questions of whether they are currently compromisable (they aren't) and whether they should have committed secrets (they shouldn't) are different. If I make a bet with you where I win if you roll a 1 and you win if you roll 2-6, and I win, I still made a bad bet. Similarly (--ish--), it doesn't matter whether Reddit is not actually susceptible, because OP wouldn't have known that for sure, and certainly not in the general case. In some sense, the actual effect is a moot point here, because it is the cause which is more seriously questionable. 
Read [package](https://blog.golang.org/package-names) and then write [tests](https://golang.org/pkg/testing/) including a [testable example](https://blog.golang.org/examples) or two. The Go tooling will guide you towards the side of correctness as long as you use it. Specifically be diligent with golint and goimports to make life a little easier. I say this because early on while writing simple programs like this you will get more out of tooling and practice than line items from experienced engineers. The interesting questions will start popping up as you get farther along. Glad to see your giving Go a try, happy coding.
&gt; You can then start to learn front-end js frameworks and connect them to your API Well that specifically is not what I was looking for: I asked about compiling Go to JS/WebAssembly. Is it possible to create a DSL in Go similar to [UrWeb](http://www.impredicative.com/ur/) and have it do all the JS for you? &gt; If you really want to learn a front-end js framework I would recommend focusing on front-end or backend first with just enough of the other to get by, The thing I dislike about using different languages server-side and client-side is that any sufficiently complicated UI needs to replicate the data model of the app to adequately render it. So I hate having to recode all of my data structures and a good amount of the business logic on both sides. A good framework like Meteor bends over backward to replicate the server-side data model client-side.
That sounds much better than putting golang in `/usr/local/` manually (or with a bash script). I don't like the idea of circumventing `apt`. I think I'm going to use a backport from a PPA like this [one](https://launchpad.net/~longsleep/+archive/ubuntu/golang-backports) so I can have automatic updates though.
I was in the same situation, having lots of Json config stuff and at some point comments would have been very helpful. But rather than using yaml which uses line breaks and whitespaces as part of the syntax, with no standard formatter used - :( - we tried to use regexes for preprocessing which was difficult to maintain. check comment above. So a standard defining a simple json extension allowing comments with agreed formatting would be a very nice thing to solve the problem with some style.
 No +----------+ Yes +----+ You need +-----+ | | comments | | | +----------+ | v v JSON +--------+-----+ No | You care for | Yes +-----+ dependencies +-----+ | +--------------+ | v v TOML YAML (Uses gopkg.in) 
I always use this method and it works well. It's also far more portable, working on a Manjaro and Ubuntu for me. When upgrading I needed to remove the existing version too. Running the following before the tar command usually does the trick. rm -rf /usr/local/go EDIT: just realised it does say to remove the existing version in the guide that's linked above.
For what it's worth, it's Gustavo Niemeyer who is a very senior engineer at Canonical. He's been a Go advocate since very early on, and if you've done anything non trivial in either Go or Python there's a good chance you've relied on him before, even if you didn't know it ;-)
Great, this will help. Thank you!
My bad, I was thinking of a single type of requirement change. If the requirements change slightly like freelancer job etc. static typed would increase the speed and quality whereas if there are no concrete requirements and the project can pivot to something else I'd recommend dynamic languages​. I thought of the second case initially. I agree with you on static type for the first case. Hope I was clear :) 
I will give this a go (no pun intended) as I am also a hobbyist and this only just clicked... So [sorting](https://www.youtube.com/watch?v=XE4VP_8Y0BU) data seems to be actually quite a big deal in computing (it's used a lot in software for lots of different reasons) and there are lots of ways to perform it - some are faster than others, but some require quite a bit of programming to achieve (see heap sort). So I was trying to solve a maths/programming [puzzle](https://projecteuler.net/) recently, and to help me solve it, I wanted to sort some interim results so I could see more clearly what was going on. Problem was that I'd create a structure that described the sides of a hexagon (i.e. how long they were), as well as holding the perimeter. I wanted to sort by perimeter. So the sort package has a sort interface. To implement the sort interface your type (i.e. my hexagon) needs to be able to return to it - how many items need sorting, how to swap two items around and how to measure which is larger. So I made sure that I satisfied those methods, and voila! it was very easy to use Go's optimised sorting method on my data. To summarise: If you have some code that takes a substantial amount of time to write which does a specific job that can be generalised, then interfaces allow you to use that code and apply it to different situations. Without an interface, you would need to have your data stored in a way that the sort package could understand. And then if you wanted to use another package, you might have to rearrange the data to use it. Failing that, you'd simply have to write your own functions/package for your own data.
OP didn't provide arguments for being a great solution. So maybe you can start there. Why is OPs solution great? 
It really is though. 
I've avoided using it partially because I'm waiting for the dust to settle on the whole Go dependency management situation, and partially because I simply haven't needed it. But I did recently start documenting its usage for one of my projects which is going to introduce a lot of breaking changes with v2.0. Using gopkg.in seems the best solution for freezing v1.x so developers may continue using it without any problems.
interfaces are Go's way of achieving polymorphism. As a hobbyist, are you familiar with OOP programming? If so, imagine a case where you would extend a class and override a method from the parent class. interfaces are how you would accomplish the same thing in Go, where there is no class hierarchy.
For me it's simply because it requires and only works with GitHub repositories. There are many other repository hosting sites, plus private ones, and there are DVCS other than Git. `go get` has a redirect mechanism that works with any supported VCS at any URL whatsoever so this restriction, to me, makes gopkg.in a complete non-starter (even if I bought into the claimed utility of semver).
No matter who is running it, it's a potential point of failure. So far as I've ever been able to figure, there is no guaranteed SLA for it, the blog hasn't been updated in a while, there is no status report, and their uptime report linked to on the blog isn't visible to the public. If I'm going to hang my software on your service, I need confidence in its reliability and future. Edit: wow autocorrect 
Both solutions are meant to allow you to pin a specific version of a library. gopkg.in makes you reliant on that service being available and correctly functioning. Vendoring does the same thing without the reliance on an external service. Just look at how the Javascript world falls apart when NPM is down.
I prefer gopherpit, which can pin to certain branches and has proper vanity naming. Plus no forcing me to use github as a source of truth for my code.
WxGo is apparently pretty good. I haven't used it myself, but there was a thread a couple weeks ago about it. Don't have the link on hand (on my phone) but you can find it via Google pretty easily.
Anecdotally, it doesn't seem very reliable. When `go get` has failed with some kind of network/protocol level error, I've often seen gopkg.in in the error message.
&gt; I'm looking to start building go project and decided to go with some gui application I am going to approach this differently. Is this an arbitrary decision? Does the project have any specific requirement that forces it to use a GUI? If it doesn't, I think you'll be better off using HTML/CSS stuffs. As soon as you introduce C in your project, you can kiss many of Go's advantages goodbye, including the easy cross compiling and delivering a single binary. Of course if you do not care about that stuff and you really dislike Javascript, sure you can go for a GUI. That said, no matter what you choose for the frontend, I still think the best you can do is to separate the backend stuff and have it be pure Go. Then the frontend can be Go+C madness or Javascript madness. That way, you keep the madness in one place and then you can pick your poison.
no multiple choice? Edit: I personally dislike import's where you have to enter the whole github path. I'd rather configure a dependencies file pointing to said packages and import w/ the `user/repo` and the dependency file knows which repo it's grabbing from. I can't think of an instance where `user/repo` would ever be the same either especially in the same project where that conflicts anywhere. If there is a rare case that there's an import w/ the same name, being able to have aliases in the dependencies file would be better than a full path to the repo imho. (eg.: `g:user/repo` | `b:user/repo` vs `github.com/user/repo` | `bitbucket.org/user/repo`)
The images used in the README aren't in the same length, so after one pass through they aren't in sync. It should be pretty easy to use a docker image to test that it works in Linux, if you want to. For more features/functionality/etc ... Have you looked at syncthing? Have you looked at go-sync or other similar software? Neither are identical, but should be good for inspiration (use folders, rate limiting, etc) ... also if you want to add patches to either that'll probably help you more than working on your own (and get more people to use your code).
I knew it was Gustavo's project. But like others say there's no guarantee or SLA. It's like using a link shortener. Maybe he'll fed up once and close it and you'll have to go back and change it. I use several of Niemeyer's tools including godeb and mgo. 👍 Edit: I've also used your xlsx tool for a real estate company before, thanks! 
This seems like a bad idea ... generics are winning atm. but I doubt that's going to change people's opinion much. The generics answer is also the easiest to "understand" without thinking too much about it, and esp. without having to think about any downsides.
The place for tutorials is for showing how to do very basic things in a new language or platform. Tutorials aren't for building large, amazing, complex systems.
How does it handle previously compiled packages ? Will it recompile them ? Compiler update should trigger a recompilation of all packages. 
Generics, sum types and or predeclared interfaces. Really just anything to mitigate the use of efaces. We have this fantastic language with a powerful type system .. that is constantly subverted. I feel like a vast majority of places which take a eface really only want to accept a few different kinds usually. Sum types would mitigate this a ton, I.e: // the kinds accepted by sql.Scanner interface, allowing // interfaces here could be nice to. type basic ( string, int, float, ...) // used like package sql func Scan(b ...basic) { switch b.(type) { // standard type asserts } } // Now if Scan doesn't unbox "basic" the compiler can throw // an error. No default cases permitted? So now I can get a // compiler warning if I call Scan without a type that is one // of strong, int, etc. This helps a lot of eface usage, the builtins package could include a sum type roll up for whatever groups make sense, perhaps a signed and unsigned type that contains various bit width integers with a numeric type that joins them. A basic type could group all basic types. They would be a bit cumbersome to implement with the type switches, so it will hopefully naturally discourage over use but allow many valid use cases to have a strongly typed API. Sort package is an example of a places that would greatly with sort.BasicSlice(b []basic) or something similar. The builtin interfaces just is something that surprises me doesn't exist given how central interfaces are to Go. In short a way to allow interfaces at compile time to define behavior to avoid some tedious patterns we have today. First thing that comes to mind is a set of interfaces for each predeclared type to be checked at compile time for seemeless conversions to those types. It would make it less obnoxious when you want to declare a type MyString string. I.e: type Path string func (p Path) Clean() Path { ... } os.Open(p) // compiler error today, crisis subverted? Probably not. Just // a tedious nuisance in the general case that discourages // creating simpler helper types, despite the benefits of doing so. func (p Path) string() string { return string(p) } // Compiler knows the built in method string is implementing // the predeclared stringer interface, so now we can: os.Open(p) // works, calls p.string() The same could possibly be applied for operators, like a equaler interface to define struct comparisons, but it's much more nuanced when you involve parameters. What T may the Param be? Only same T? Could be useful but Go probably wants to stay away from operator overloading and I could care less if they do, I don't need it. I really just want harmless, tedious patterns to be minimized. Type conversions save bugs at compile time, under/over flow across ints for example, I get it. But on user defined types it sure does get painful when you can't just pass your type State int64 to atomic.AddInt, its likely exactly what you wanted to do and very little side effects are possible here. A way to avoid this would make writing Go code more enjoyable for me, but I may be the minority. 
I used to think of commenting as something to be done later if there was time, but I can honestly say that my own comments have saved my ass a number of times. Especially when I come back to code that I've written one or two years previously. I now try to write my comments first (as pseudocode), and then once the logic and intent is worked out, fill in the real code. It's way faster to solve any logical issue in pseudocode than in real code, as well as often revealing better solutions. For your next project try to start with comments and see for yourself.
* [glide](https://glide.sh) becoming an official tool. * Built in visualization of goroutines (output a video with 3d graphics). * Debugger that comes wih the go command with a way to view registers, debug coroutines in one new little window per goroutine, in parallel + view of registers and assembly output, all in ncurses. * Two identical lines after each other is now an error. * Four new built-in types (or a way to define them with operator overloading and multiple dispatch): Quaternion, Vector, Matrix and a type for numbers stored internally as fractions for potentially better optimizations for large expressions.
Back in that DNS outage in October, my team couldn't build because this site was inaccessible I've always told them we should be able to do a full build from an airgapprd machine if we had to, don't put these dumb dependencies in
Well it's also only sensible option. 1) Remove GOPATH - there's nothing particulary wrong with GOPATH but yes making it possible to have relative import paths would be benefitial but you can do that without having to release Go2 2) Option types - If you have proper generics you also have option types (you'll waste a bit of space because of no sum types in Go but that's not a problem if you are developing in go. 3) Generics - without a doubt one of the biggest feature go is missing. And by missing I mean missing. Closes you get to generics now is code generation but thats not optimal and a lot of the times just not enough. 4) Tidy STD - What? Go STD lib is probably best std lib I've ever seen. So no problem here. EDIT: Also I think you could improve Go err handling easily with just two steps. 1) Add some syntax to the language that if last returned value from function call isn't null return it. So you dont have to write if err != nil { return err } everywhere. Something like. i := Function()? 2) Make go vet warn you when you don't consume value of type error. Easy. Wanna know if your code and all dependant libraries handle errors properly? Just run go vet.
I'd only suggest you create your own http.Client and set a readtimeout, otherwise you might see some very long wait times while connections just dangle. The default client will literally wait forever.
`Rust` has `Cargo`, `Node.js` has `npm` (and alternatives: `yarn` &amp; `pnpm`) The fact that Go doesn't have anything has really hindered the uptake of the language. Programmers coming from languages that have brilliant dep managers are shocked with the status of Go.
Cool. One thing that jumps out is: You are currently waiting on your slowest URL to finish scanning before you start downloading, why not dispatch the downloaders as soon as img uris are scanned?
I'm not saying that this is the sole/only reason why uptake "could be better", but it's a huge contributing factor.
Well it's better than writing something from scratch. You can use that time to improve onwards. Still, thanks! :)
&gt; I now try to write my comments first (as pseudocode) Does it count that I [wrote it in Python](https://gist.github.com/Duroktar/b1385aa0951e13d3f041e49745f53993) first? I'm only kidding and I totally agree with you. (I didn't write any tests either which is also pretty important) But I appreciate the insight greatly and will add comments tonight, also, on my next project I will try to build the comments _with_ the code. Thanks John! Cheers
Even if recompiling whole library took 10 seconds (it takes me to compile whole Go compiler 8 seconds on my PC) its basically no issue. How often do you introduce new types? Just imagine generics in go being as bit of code generation that compiler does instead of external tools. You have to generate that code either way if you wanna have type safe code.
I like that approach you mentioned. Do you have an example? (I haven't wrapped my mind around it yet, lol)
 ch := make(chan int) ch &lt;- 1 ch &lt;- 2 fmt.Println(&lt;-ch) fmt.Println(&lt;-ch) That's a bit of a contrived example, but a real-world example could do something similar. There are probably some libraries out there that also allow you to call the same method twice in a row to do something too. There are plenty of impure functions out there in Go. Another contrived example: var counter = 0 func incrementCounter() { counter++ } // ... incrementCounter() incrementCounter() People also do things like: fmt.Println() fmt.Println() fmt.Println("This is now further down") It's difficult to think of too many concrete examples because it doesn't really happen often, but I think it will happen, and there will be legitimate use-cases for it. Even if it were something to do with assigning something to the same variable twice in a row like this: foo = doSomething() foo = doSomething() It would _still_ be possible for that to be doing something crazy if `foo` was a package-level variable, or an upvalue of a closure. Provided `doSomething` is an impure function, again.
Meta-programming tools (more than just building a tool that can be called from go:generate). Compile-time generation of boilerplate like sort.Interface implementations and `if err != nil { return err }` wrappers would go a long way to making the language more ergonomic. Also, while we are wishing for things: List and map comprehensions.
airgapped
Don't confuse code and service.
I find no utility in gopkg. It's extra fluff that gets in my way of getting stuff done. Packages like mgo that use it seem to suffer from it. I much prefer development cycles like https://github.com/google/keytransparency. No need for gopkg.in.
I have mixed feelings about GOPATH. It makes things within a go-only project much simpler in many ways, makes it clear where go source is stored, and makes it easy to fetch and find dependencies. But it has some downsides too, and is particularly problematic for those new to go - it forces you to structure your projects under GOPATH/src, and makes it hard to build code elsewhere and is just more ceremony to get someone set up. It's one of the most commonly cited stumbling blocks for those new to go. Clearly people have trouble with it or you wouldn't have projects like hellogopher. It also contains cruft that does not need to be there. GOPATH/pkg is just a cache that doesn't need to be exposed. GOPATH/bin is not really required as there are already lots of places to put installed binaries on every system, and that leaves GOPATH/src which could be replaced by vendoring. Much better IMO would be to ditch GOPATH, and install your dependencies per project directly under the project in PROJ/vendor. Then you'd get reproducible builds (either with a vendor spec file or the vendored pkgs checked in), you could keep import paths exactly as they are, at the cost of not sharing dependencies. For an open source ecosystem it's not really viable to have all dependencies shared between projects and kept at head at all times. They do have an open [issue](https://github.com/golang/go/issues/17271) for ditching it at some point.
Disclaimer - I wrote these terrible questions :) I'm afraid they were truncated by the procrustean bed of twitter polls. &gt; 4) Tidy STD - What? Go STD lib is probably best std lib I've ever seen. So no problem here. This isn't to say the stdlib isn't very good, I agree it is one of the better ones out there. There are quite a few things that need renamed or could have minor fixes to behaviour but are breaking changes and so can't be done in Go 1. I think they have a list of Go2 type issues most of which are things of this nature. Also for example if they introduced generics they might want to change a few interfaces, change containers etc. Minor fixes like http client timeouts could be introduced. Breaking changes could probably be done without much disruption in a Go 2 if a tool was provided to fix or warn on possible breakage, and the transition was managed well (i.e. not like python 3). I'm actually really pleased at how stable they kept Go 1 and the amount of work that has gone into improving Go 1 and keeping it stable at the same time. On the other hand there are some improvements that could be made which can't be made because of the Go 1 promise. So I think in fact tidying the std lib up in lots of small ways could be one of the best 'features' allowed by a Go 2 if it were backed by a gofix type tool that fixed up existing code bases.
Bingo, if you apply similar logic to most proposals, you'll realize why Go2 will never happen
When it actually comes time to make concrete moves, they will realize that they risk destroying the Go brand entirely and will call it off Go2 is just there as a lightning rod for complainers Surely the Go team has no desire to enter a swamp like Python3 Think about it...once you announce Go2, no one will want to work on Go1...but the world will need Go1 support forever...but Go2 will also take years. No one has said Go2 would be a superset of Go1. Go2 would mean the end of Go
Thanks for the downvote, stranger. I'm glad that going to the community for advice is downvote-worthy. 
&gt; No one has said Go2 would be a superset of Go1. Actually, this is the exact point that Brad Fitzpatrick made when interviewed during the Go Time podcast.
I mean, I was disappointed and slightly annoyed but not shocked.
&gt; Are there any books or pages online that describe good C/Go/non-OO program design and architecture? Or perhaps some good repos to check out? Look to the right, click the thing that says "[Resources for new Go programmers](http://dave.cheney.net/resources-for-new-go-programmers)"
Doesn't Go have a centralized registry called github?
Not connected to the internet, has a "gap" in the cable.
Sounds like it's no different than npm then, except Go has worse tooling. My work for example, has its own npm registry and mirroring proxy. 
Lots of people install bcrypt every day, including myself. Perhaps the problem is the end user.
The only people who complain are the people who haven't figured out environment variables (e.g. fake programmers). 
Glad I'm not the only one who runs into this all the time, Usually happens when I'm parsing text and need to perform multiple actions on a string.
Anything but generics.
int should merely be an alias for int32 or int64. Having a third non-compatible int type that doesn't work with the math lib is only rarely a convenience. stlib to do math.* functions with other normal data types.
Immutability?
It seems like interfaces generally satisfy most use cases that require them except for some of the more egregious boilerplates such as sort, and associated higher level set operations. When we talk about generics are we really only talking about enhancements to the sort and container package? ( that may require language changes to achieve )
&gt; Are there any books or pages online that describe good C/Go/non-OO program design and architecture? For resources around this topic, please check out my [answer](https://www.reddit.com/r/golang/comments/56wk4v/structuring_go_api/d8n4axl/) to a similar question. &gt; Or perhaps some good repos to check out? Good repos to check out: * https://github.com/upspin/upspin * https://github.com/golang/perf Also try to read the standard library and [Effective Go](https://golang.org/doc/effective_go.html) as much as possible. 
&gt; I'm trying to pick a method of handling properties testing Properties testing? Please give an example and show why you cannot do your testing the standard way.
I do apologize, I've been unduly harsh. My bad day is not your fault. I'm on mobile, so I actually can't immediately see the sidebar. That being said, I have found that, in the resources that are linked to, the examples usually only serve to describe a specific syntactical topic, rather than the language's idiomatic design philosophy. I will absolutely check out the link you have provided, and I do deeply appreciate your help (and for being understanding in spite of me being an asshole)
And literally every time I try to go-get something that depends on that stupid gpgme library which has a different header location depending on which distro you're on it fails to compile the cgo. Difference is one of those tools is built in a fixable flexible way and the other is a "fuck you" to compiling on anything but ubuntu/fedora. Linking against c libraries is a problem go has too, and it's worse for not providing a real make-like tool, but rather those horrific cgo comments.
Thank you very much! I've been through Effective Go and Kernighan's "The Go Programming Language", and while the examples they provide are good for describing some of the syntactical idioms, I felt I needed more direction in the area of the design philosophy. I have a hunch that it's similar to how C programs are designed, but having developed almost exclusively in an OO paradigm, this is a totally new area and way of thinking about things for me. 
That's runtime. Meaning that you can have a race condition in a rarely taken branch which won't be detected.
First class debugger support from golang developers. Delve is cool, but I'm afraid to suggest to use golang in at work and then they start to complain because they can't do simple* things like: 1 - set breakpoint while the program is not stopped at a breakpoint 2 - set the value of a string variable (https://github.com/derekparker/delve/issues/826) 3 - evaluate function during debugging (https://github.com/derekparker/delve/issues/119) I really love golang, but a good debugger would make things so much easier for us and would certainly increase the language adoption. \* simple from the POV of the users of the debugger, not the developers
&gt; it forces you to structure your projects under GOPATH/src Or have your project contain `GOPATH` and have a separate `GOPATH` per project. This isn't as nice, but this eliminates contention between projects that need different versions of the same repository. So you can already vendor them without making any changes to Go. However, I honestly don't like vendoring dependencies. With a proper package manager, the package repository can do the vendoring for you, which means you don't need a huge repository that contains a copy of everything. I gave up trying to submit a patch to a Google project because their repository was so big and building it was arcane due to having to download and compile all of the vendored dependencies (and the build process for each had dependencies, etc). I also feel like vendoring makes it too easy to make local changes to dependencies without pushing them upstream, whereas using a package manager gently nudges you to contribute upstream, so there's that aspect as well.
&gt; I don't have a twitter account Here are the results as of now (478 total votes): - 44% - Generics/Cust. Containers - 26% - Remove GOPATH - 16% - Option types for errors - 14% - Tidy up std library This is also my same order of preference, which is awesome. In fact, the first three are all features of Rust, which I've been using recently, and I really feel annoyed when I go back to Go.
Hello, blunder on. If you're an experienced developer your probably fearing what a lot of people do early on. You can be punished pretty harshly in Go for approaching some problems like you would in a OO language. Go prototypes and refractors fast, interfaces let you have zero coupling early while figuring out your problem space and abstract when patterns emerge. So write code and when something feels cumbersome, lacks eloquence, or simply just won't work paste it into a play and post here or on the gophers slack channel. I always reply to people who ask questions with a example of their problem and I notice a lot others do as well. It doesn't have to run or compile, or even be valid syntax, just illustrate your problem. Even posting a snippet of another language for reference of what you want to do is fine too. Point is don't stress about design early on. Have fun.
Thank you for your response. I'm having a blast learning and playing with Go. I've just gotten so used to an enterprise environment and Spring configuration that it almost feels foreign looking at 'main' and figuring out how to start and to organize everything. I'm absolutely loving channels and goroutines. Syntactically, the language makes sense to me, it's just been organizing and fitting the pieces together in a sane way that has provided somewhat of a challenge. I'll definitely poke my head into the slack channel if blundering doesn't prove to be fruitful!
"Everyone is an asshole here and there. It's the Internet. Welcome!", the man farted.
[msgp](https://github.com/tinylib/msgp) from tinylib is more efficient as it generates code, using go generate, during compile time. 
I would be happy with just a SUM-type
Stop thinking about types. About "nouns". Java is a kingdom of nouns and types. In Java, you start by describing a "thing". Go starts with functions. Functions are verbs. They do. They *act* on things. Programs are valuable because they *do* things not because they *describe* abstract things. So Go lets you get to the *value* part quicker. Start by writing functions that take parameters and return values. Let your types *slowly* evolve as needed. Look at how Go does polymorphism. Look at fmt.Fprintf and really *look* at it. It's a function. Not a method. And it takes a polymorphic type - an interface - as a parameter and *uses* it. Really think about that and how it differs from the typical Java approach. And then realize how much more light weight and flexible this approach is without losing any functionality. For me, fmt.Fprintf and http.ResponseWriter.Write were key for grokking Go. Hope this was helpful. I don't know when exactly Go "clicked" for me - I think it was by just using the std. lib. on toy projects and seeing the patterns come thru. Stay simple. Be obvious. Don't be cute, don't over-design and over-engineer - those are signs you're doing it wrong. 
Thank you, I really think this was a fantastic way of framing it. The noun/verb metaphor is excellent!
net/http uses channels, but doesn't force the user to worry about them. Another example of a place in the stdlib that does expose channels (in a cool way) is time.Ticker.
Rust does it through static checks in mutability. If you only allow one mutable reference at a time, you can't have data races. Is that nice? IDK, but there's definitely a trade-off here.
High Order Interfaces too.
Now now, shush with your wild ideas. Using language that have, or even, god forbid... encourage immutability is just impossible because &lt;reason&gt;. Besides, what advantages do you get other than code being easier to read and thread-safe by default ? 
Apologies if you missed this particular title. We try and post on Reddit as early as we can in the GMT timezone giving users ~15 hours to claim. If you're interested in Go titles then you can always try a 30 day trial of Mapt, our online reader. Every Packt book and video is in there: [https://mapt.io/](https://mapt.io/)
Excerpt from russ cox's blog, &gt;The race detector is one of Go’s most loved features. But not having races would be even better. I would love it &gt;if there were some reasonable way to integrate reference immutability into Go, so that programmers can make &gt;clear, checked assertions about what can and cannot be written and thereby eliminate certain races at compile &gt;time. Go already has one immutable type, string; it would be nice to retroactively define that string is a named &gt;type (or type alias) for immutable []byte. I don’t think that will happen this year, but I’d like to understand the &gt;solution space better. Javari, Midori, Pony, and Rust have all staked out interesting points in the solution space, &gt;and there are plenty of research papers beyond those. &gt;In the long-term, if we could statically eliminate the possibility of races, that would eliminate the need for most &gt;of the memory model. That may well be an impossible dream, but again I’d like to understand the solution space &gt;better. FYI,https://research.swtch.com/go2017
Well I know Go is Go and not C++ or Java and any comparison to them is slightly out of place, but I'm slightly surprised that nobody in 87 comments ever mentioned constructors, inheritance, overloading, or functional operators for casting between object types or to other types. Some of it might fall towards generics. I realize that some of Go decisions have been to actively avoid those things, and this is well documented. I'm just not sure that there are no people migrating from other languages that would be better serviced by some layer of comparable and not completely evil patterns. So, +1 for generics, I guess?
Yep, it was my only intention. I respect you for having taken time to do a good example and trying to highlight possible ways of achieving what OP conceived. Just wanted to highlight that the `panic` part should be taken with a grain of salt, everything else is on spot :) 
I think I'd be happy with just an option to bubble it up like try, if you're *really* handling it, you don't need to return it, if you're deferring error handling to the caller, it'd be nice to lose 3 lines of boilerplate for every possible error. It would be instructive to see how many times this if err!= nil return pattern is used in existing code bases. I tend to use it a lot in lower level packages so that the caller can decide to log or present to the user. Just had a look at kubernetes, there are over [1100 uses]( https://github.com/kubernetes/kubernetes/search?utf8=%E2%9C%93&amp;q=%22if+err+%21%3D+nil+%7B+return+nil%2C+err+%7D%22&amp;type=) of the if err != nil { return nil, err } pattern. That's 3000 lines of redundant code that could be removed and simplified. 
It's not a "great solution", it's a hack that fills a gap left by bad tooling, which is equal parts admirable and terrible. But now that the tooling is improving, only the "terrible" part still applies. It's an additional moving part to break, it's an additional thing that somebody needs to learn about, it's not a general-purpose solution at all, and all in all, it's just kind of unnecessary.
This is something that doesn't really bother me, but always found very strange. Seems to go against the language philosophy.
Fully agree :)
To be fair it was dependency of the dependency of the dependency 🙂
Although I sort of like how GOPATH works, I think it was a mistake for developer on-boarding. It is very confusing because it is so different from all other popular languages/eco-systems. It is clearly something google badly wanted to make their mono-repo life easier.
I would like operators, append and len, overloading for structs and interfaces. Using postfix/prefix notation for complex numbers, vectors, matrices, really makes any math heavy code very hard to read.
I know what dep is, but what is alias? Google doesn't seem to turn up anything useful.
wxwidgets https://github.com/dontpanic92/wxGo
 func (s *simple) Reset() { *s = simple{} }
very good point, simple solution. But what does it implies in term of allocations ? (simple question, the idea was to learn gotypes, ast, ... by doing a use-full example). This aims to reset, not to recreate. 
&gt; Compile-time generation of boilerplate So, Rust's macros and/or compiler plugins? These seems extremely powerful, but I feel it kind of goes against Go's goal of being simple to read and understand. It also brakes Intellisense and other static code analysis tools, doesn't it? (real question: I don't know if other languages have succeeded in making tools which play nice with meta-programming). So I'm a bit on the fence on this. It's a trade-off (boiler-plate reduction vs language simplicity) which may not be worth it, though the stated goals are very appealing. 
https://github.com/therecipe/qt is excellent
Wait, so you want exceptions? I definitely don't because: * not worth the performance hit * makes errors less obvious * the default of crashing isn't good for most error types However, I'm all for making the current system require less boilerplate through additional syntax.
Blaming the end user. That's really original. The same could be said for any of Go's problems "Lots of people work without package managers every day. Maybe the problem is the end user."
And http://gopherpit.com can be installed onpremises, it's very useful for inner company private packages and if relying on public site is a problem. Arbitrary branch/tag pinning is much better then semver compliance.
So… why reuse structs instead of creating a new one? I can kinda understand it for some cases where you have no dynamic allocations during the resets, but string members etc. are going trigger allocation anyway, aren't they?
It's not that hard to read off from Go's philosophy that Go2 would be a superset of Go1. A Go2 module would be able to read a Go1 module. There might be cases where you couldn't use a Go2 type-system feature in a closure passed to a Go1 method, but that would be a side-effect of the Go1 code's inability to understand it and nothing more. (Even so, that might never come up; a lot of the things I can think of where that might happen would still be compile-time resolved before going down to the Go1 module into code the Go1 module will understand just fine. reflect might break, but that's a rare enough use case to not be the end of the world. And a reflect module in a Go1 harmony release that could work with whatever the Go2 vaues are could probably be written, too.) You could also do something like fix up the standard library to distinguish between the two modes and be reverse-compatible for Go1 while allowing Go2 to make otherwise breaking changes without too much hassle. Python 3's problem ultimately stemmed from the fact that it couldn't simply import a Python 2 module without changes; all code used in a Python3 program has to be upgraded in one big bang to work at all. If Go2 has instant access to all Go1 code with no conversion process, the issues with Python 3 won't apply to Go.
&gt; That's quite a big downside for anything potentially facing user input. Perhaps in some cases where the hydrated struct is not validated following unmarshalling, but this could be an issue with or without a well-formed check of the json. And one may find it as a positive feature that it guarantees no panics on decoding. 
you get one of those no matter what, which is why Go2 will never happen
The difference is that Rust was highly unstable until the 1.0 release in 2015. Sure people were working on Rust before that, but people were working on Go before 2009 as well.
This feels like a potential language enhancement rather then something requiring go2. I'd love to have it for db code or deep code blocks where id want to retry on err.
The lack of minor versions in URLs is very much by design: https://blog.labix.org/2015/01/14/no-minor-versions-in-go-import-paths
I guess this isn't exactly the same as at least the non-nil feature of OPs project. But it's awesome anyway! :)
For the record, the status report is broken because pingdom itself broke it. I think they've brought it back recently, so I need to check back and re-enable. And yeah, although it's uptime is really good over the last years and it has an HA deployment, I won't ever offer any SLAs on it.
And it will probably be hacked two months from now again, until I get rid of Wordpress.
I don't see why you need constructors, and constructors seem to be going out of fashion anyways (see Rust). Really, I like the Go/Rust attitude that there are structs and functions on structs (which is what classes really are). 
Abdicating some of the performance issues you can write something like this as a library https://play.golang.org/p/GxtCo9p89d where the library provides types and interfaces that should be embedded into a user's code and then leverages the interface definitions for the container. It would be highly desirable not to require type casting and type assertion going into and out of the eSlice by allowing a container accepting type Element to accept any type with type Element embedded for performance and usability, but it's not a requirement. If we're only concerned with generics for the purpose of writing containers it may also be possible to make a particular Element type which should be embedded in types used by Containers and has the above property. 
I wrote a JSON library which is also 3-4x faster than stdlib and does NOT have "unexpected results" for malformed JSON. In a world where safety is key, it doesn't seem smart to add the potential for unexpected behavior. How often is stdlib JSON encoding/decoding your bottleneck?
I believe I see three ignored error returns.
You say it's "developer responsibility" to validate, but the library fails to return the information a developer needs to do that validation, so this is basically the same thing as saying that developers can not validate incoming data on that dimension. This is not something you will be able to talk around. It is objectively true that there exists valid and invalid input that will result in the same representation in the end, and this will result in errors. For instance, imagine I'm sending in a request to add something to a database, but the request gets truncated. If you simply return "something" to the parser user, it will not be able to tell it was truncated and may insert a record into the database that nothing ever meant to insert. And those are real "fun" bugs to work out. You _have_ to tell the user if the JSON was invalid in the general case.
&gt; I wrote a JSON library which is also 3-4x faster than stdlib and does NOT have "unexpected results" for malformed JSON. Sweet, perhaps you can share the link to the library? I love exploring various options. &gt; In a world where safety is key, it doesn't seem smart to add the potential for unexpected behavior. There are no unexpected behaviors with GJSON. If so please file an issue. &gt; How often is stdlib JSON encoding/decoding your bottleneck? Often. When you are dealing with reading directly from disk, using in-memory blobs of well-defined json, feeding in data from key-value stores. Plenty of use-cases. 
You posted your reply as a top-level comment. I can see you take inversion of control really seriously 😜 Edit, might as well give an answer: Go's motto is 'get sh*t done'. Program whatever you have in mind out, as straightfowardly as you can think. Refactoring is a breeze. This, over time, results in very direct, outspoken code. You read it, you know what it does. Elegance emerges therefrom.
He wants try like in Swift.
I'm just speculating, but it's entirely possible that in the future the compiler could optimize something like: func (t *T) F() { *t = T{} } into a `memclear(t)` which would be even faster. They already use `memclr` when the compiler finds: for i := range t { t[i] = 0 } instead of looping. I'd suggest generating some code for that instead of `t.field = [N]T{}`. It'll still be fast and save an alloc.
Which, from what I understand, is basically exceptions without the overhead as it's basically sugar for what Rust does and is possible to implement in Go (though a little annoying as there are no enums).
I'm generally fairly skeptical of libraries that claim to be faster than stdlib but less safe (eg, see fasthttp). One of the great things about the Go standard library (unlike some other languages) is that it is usually safe and sane by default. These libraries, if not done just for personal projects, just seem to be playing microbenchmark games.
So, looking at benchmarks: did you used easyjson's lexer to bring the same json path functionality? Or it is the whole struct unmarshalling?
I'd suggest type World struct { sync.RWMutex Players map[PlayerID]*Player } Along with other possilbe maps as needed. However, for each Player I'd make it a server goroutine that is communicated with along a channel, as I describe towards [the end of this blog post](http://www.jerf.org/iri/post/2917). You shouldn't let things just send down arbitrary sockets. It may feel like extra boilerplate to write but you'll be happier in the end. In fact I would do the same sort of thing with C nowadays, because directly accessing sockets some portion of the code doesn't really "own" is dangerous; the thing just stuffing bytes down the socket is making it so that nothing quite knows the state of the protocol running on the socket. For a text-MUD that's probably recoverable since it's all text anyhow, but in general that's not a scalable design methodology.
Damn! Foiled again by my own inattention to detail. It's taking some getting used to, but leaving my java mindset at the door has really helped. I was making things difficult by trying to solve problems the Java way.
I accidentally replied to this as a top level comment, but I might as well reiterate it here: I think the noun/verb metaphor is fantastic. That really made things click into place for me, so thank you very much!
Glad it helped :)
No struct unmarshalling, I used the `jlexer.Lexer` type based on the docs, and parsed using [shortest path possible](https://github.com/tidwall/gjson/blob/master/gjson_test.go#L1272- L1285). If you see a way I can optimize, please let me know. 
Oh, you missed the comparison. We're not comparing *one* of NPM's problems with all of Go's package management problems, we were discussing one of NPM's problems as a proxy for the whole category of build failures we experience under its regime: cryptic error messages, build state corruption, and the host of failures introduced by node-gyp which itself depends not only on the compiler installed on the host system but also on various system libraries the state of $PATH.
&gt; Another difference is that gjson.Unmarshal will automatically attempt to convert JSON values to any Go type. For example, the JSON string "100" or the JSON number 100 can be equally assigned to Go string, int, byte, uint64, etc. This rule applies to all types. Thank you for this! Will be checking this out today, for the life of me I never understood with the std-lib does not do this. My other brain-scratcher with the std-lib json is why bigint is not marshaled to a string when javascript/json can not support the values https://play.golang.org/p/TI5YvyDtKT
I just hope that it's not actually language-design-by-democracy. That's going to be a disaster.
It always bothers me that there are two different ways of doing the *exact* same thing. `var x = 1` is no different *at all* from `x := 1`
&gt; Only idiots thinks Go should be approach in a special way. Oh, the irony!
Got any comparisons to protobuf?
Agreed. All of my applications handle invalid json differently than syntactically correct json with invalid values. The strange thing is returning a parse error shouldn't cause any performance hit. The parser already needs to know if the next token is valid or not. If it isn't valid it just needs to bubble up that error to the caller.
To run it locally, if I recall correctly you just call godoc -http=":6060" or something along those lines. Where the port number is where it's bound on localhost. You can also simply use the go doc subcommand, it gives nice output for a search query.
I'm sorry but I don't. 
Move the state to where it belongs: "the world" in this case. Make it a process and let clients communicate with it using a channel. No globals, no explicit locks. Just give clients a reference to the world process.
You claim that your library is 3-4x times faster than the stdlib. Some real world example that demonstrates this improvement would really help, otherwise this is yet another microbenchmark that proves only the very specific case.
Honestly, I can only hope you are right. It would be nice to improve / fix some warts in the language, but I'm not interested in a version split that will divide the community.
I agree with what you are saying for the most part. Fuzzing is not a replacement for any of the things you mentioned and shouldn't be used as such, but as systems get more complex, using more and more external libraries, formal proofs become hard or impossible. I am just testing out the concept in a personal project to see if it has any value in testing complex user inputs when there is no large collection of production inputs to fall back on. 
I don't tend to do a lot of planning when I write go so I tend to start with everything in the main package. From there it usually becomes apparent what can and should be split out from main. The major exceptions are things that are almost always self contained like a database struct or a parser.
What's the point of this? Not doing validation of input as part of a library that provides Unmarshalling is like having a car without breaks: Oh look, I can drive a car that's 3-4x faster than yours. Breaks? Lol, yolo, amirite? Why not add some caching for input as well, I'm sure that will make it even faster in benchmarks. Seriously, effort or not put behind it, learning exercise or not, as long as you have that clickbait title to it I can't assume good intentions, and by reading the replies here I can't help to say that everyone should stay away as far as possible from this. How can you ask users to the work the library is supposed to do and say that it's the user job to validate the input? It's the lovely library job to do it!
Currently I'm just making my usual intro to a programming language program of a scientific calculator. There isn't really any huge reason why I would need to use this technique, but I saw it in a bunch of the golang testing articles I saw ([example](http://www.quii.co.uk/Property-based%20testing%20in%20Go)). It seemed to be an interesting way of doing testing(especially user input testing) so I wanted to try it out, but I wanted to learn the community accepted library as to save myself trouble later on. 
Sigh... well OK then. Just trying to share code with the community that I've served fulltime for 2 years in the FOSS space. I was asked about using GJSON for unmarshalling tasks so I added the feature. I generally mention major changes to my libraries on these types of forums. I choose a title that includes A) the library/feature and B) what makes it special. I included a clear representation of the caveat in the README, commit message, and godocs. I figured that people can choose to use the feature or not, but I guess there's nuances that I missed with this crowd. I promise that I'll leave your forum alone moving forward.
I would love to see real Enums (not just `const`s, but actual statically defined enumerations). I think Swift really got enums right, and I'd love to use them in Go. Generics would be nice, but haven't been a deal breaker so far for me. This wouldn't have to wait for Go2, but I'd also like to see an official "release" build option (go build -release). It doesn't need to do much, mainly just strip stuff, but I don't like that my builds have identifiable information in there, like my GOPATH (which contains my username), or the repository path. Currently I use ldflags, gcflags, and asmflags to simulate this, but it would be nice to have something built in and automatic. `GOROOT_FINAL=golang.org go build -ldflags="-s -w" -gcflags="-trimpath=$GOPATH/src" -asmflags="-trimpath=$GOPATH/src`
&gt; I wanted to learn the community accepted library From my perspective, the community does testing using the standard library testing package. That is usually enough. So in your case, you are looking to do something interesting just for the shake of doing it while you could do your job just fine with the standard (and boring?) way. There is nothing wrong with that but at the same time it is a niche and I doubt there is a community accepted way of doing it. My opinion is that you should stick with the `testing/quick` package since it belongs in the standard library and assuming it has all the features you need. That will save you from having to manage one dependency just for testing. And because of the Go 1 compatibility guarantee, unless we get Go 2, your tests will continue to be working with `testing/quick`. That said, you know better the requirements of your projects and what you value most. Personally I tend to favor ease of maintenance above everything else so I would avoid depending my tests on a 3rd party package unless I had no choice.
So why was this not proposed as a replacement to the standard library `encoding/json`?
They only support C++ and Python officially. The Go wrapper takes a long time to compile and loses some of the idiomatic Go features. There are also concerns on Windows like Go unable to use MSVC which the Qt webview needs. There is some work on others but they are not best-of-breed. I think Qt should never be an answer to the original question unless the language/runtime is not a factor.
Some of you guys are a little bit too religious about the standard library for my taste. Of course there are cases when you can expect data to adhere to certain rules in order to optimize in some sense. We make those assumptions on a daily basis, and I don't see how this is any different. Clearly not a replacement but rather a complement to json.Unmarshal!
Yes, I run two godoc instances while developing. One for stdlib with **GOPATH= godoc -http=:&lt;port&gt;** to prevent all my GOPATH polluting stdlib docs. I also run a second depending on current gopath which I include -timestamps and omit gopath override. Small tip is for your code instance use **m=all** query param to show internal packages too.
I would add this regarding generic; the question isn't "Do you want generics", the question is "Do you want to read other people's code with generics". Go can be more difficult to write than many other languages, but I've never seen another language I'd rather read. A lot of these suggestions would damage that.
GOPATH is pretty close to virtualenv if you think about it. Coming from python, it was easy to understand.
You know there's [JMESPath](http://jmespath.org/) And here it is for [Go](https://github.com/jmespath/go-jmespath)
Yeah :\ I'd very rarely, if ever, want to introduce undefined behaviour in the face of badly formed data.
You should probably mention this should never be ran on the internet.. safe when used in a network server context usually implies security.
Silly summary. This seems to be a library for wrapping Go errors into HTTP errors, with some stack recording functionality mashed in, topped with weird names (error vs fail, cause vs because).
Yes, it's completely insecure.. the comment above was me letting you know. I'm on mobile but I can tell that this is susceptible to basic directory traversal attacks. You can see with something like **touch ../../private.md; curl --path-as-is localhost:8080/../../private.md** and I'm sure private will be exposed. I've covered this topic before so see my post history if you're so inclined. Depending on how those libraries handle various file extensions and formats you could replace private.md with /etc/lsb-release and concat ../, ../../, ... until you hit the root to understand your WD. Then you can acquire system context until you find a possible attack vector for more privilege escalation beyond any possible sensitive / private information exposed already on disk. Basically it's game over in this scenario in some form, it's why dealing with the file system is so important.
If Go wants to implement constructors, it can reuse the `init` function semantic at struct level, and if necessary the `Closer` interface for destructors. Inheritance I think is better done with the interface composition Go has right now. *shrugs*
I think this is just poor codemanship. I agree it's stupid, but no need to enforce it down to language level.
Yes, there is an official Go API: https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go
symlinks and paths with '../' are disabled for that very reason edit: but thank you for your words and keep them coming
Hmm. I'll have to try this. I don't want to set a GOPATH at all since gb doesn't need it. I don't even have one at all so idk if `export GOPATH=$GOPATH:$GOPATH/vendor` even makes sense. Might be neat to try some version of this with `$PWD` though, so, thanks for the tip regardless. :)
https://github.com/aerth/markdownd/commit/3cd20a10ef77d563010fd8a41ccc3fd03547e34b Committed 9 minutes ago. So pretend there was no issue to a experienced security professional and then fix it .. with a public audit trail. To .. make it appear as if the security issue wasn't there? Why? No one cares, I don't care. Bugs, including security bugs are a natural part of software engineering and you are only hurting yourself and potential users of your library.
It can be anywhere, until you need to import sub-packages from your own project, at which point it must live in GOPATH.
Great work! 
Hey, I just want to say thank you for your contribution and friendly license. You handled the more constructive comments super effectively with that patch; ignore the inane ones. 
What you're speaking of sounds like a simple API. What are you trying to communicate exactly?
[removed]
node.js is the worst fuckin thing that has ever happened to computing. pls stop.
So far simply the Google site search. Not the best, but it works. 
I haven't used anything personally but the [docdock theme](http://themes.gohugo.io/theme/docdock) in the Hugo showcase uses [lunr.js](https://github.com/olivernn/lunr.js) and [horsey](https://github.com/bevacqua/horsey), which give a nice experience for the small theme site. Doesn't look like lunr would be suitable for anything over a few dozen pages, though: https://github.com/mkdocs/mkdocs/issues/859.
Yes, I'm working with go + tensorflow. The Go APIs are just bindings for the C++ API: you have to manually define the graph, deal with the scopes (that without the context managers of python it's a pain) and differently from the C++ API the type system is a complete mess. Since every method accepts a tf.Output type as input and the tf.Output has it's Tensorflow type, you have to correctly define the tf.Output structure with the right (and thus implemented) type. You have no compile time check and thus if you, for instance, pass a int64 instead of an int32 when you create a parameter and the function you're using has no a registered kernel for the int64, your program will compile but when you execute the graph within a session you'll get a segfault and debugging is extremely hard. Moreover you don't have the Variable (that's a Python class) and thus you can't train model (no tensorboard support, ecc...). The Go API (and the C++ API too) it's extremely good to load a model defined and trained using python and use it in a production env. If you want to define and train models: use python. If you want to use trained models or use the Go bindings to execute simple operations within the tensorflow environment (for instance execute a RGB to HSV conversion) you can use Go (but keep in mind that's hard to define and debug because of lack of the compile time support)
I would take a look at "Go Programming Blueprints", I quiet like it and it starts with simple program and build it up the Go way.
When you do new value affectation if the variable already exists, it will only replace the value, not triggering any new allocation.
You're not necessarily always doing as much reading from disk as much as you are doing parsing. I'm currently working on a project where in a specific area JSON parsing specifically became a (minor but notable) bottleneck. We switched to an in-house JSON parser and from that alone saw a noticeable performance increase. It can happen. 
Yes that's pretty much what I mean, though I think keyword not function and I wouldn't personally be quite so compact as I think that's too far the other way, and usually there would be steps in between calling other functions, for clarity I'd use try on its own line: func f() (string, error) { try v := g() try w := h() return fmt.Sprintf("%s: %s", v, w), nil } I think a lot of people would like that. NB for the parent **this is not an exception** or anything like an exception, just a shortcut to return to the immediate caller if an error is encountered.
So you think that they don't do it already on simple structs ?
&gt; Moving forward I'll likely not engage with the Golang community through Reddit. I prefer positive feels and constructive criticism... I guess I can't say I wasn't warned by friends. So sorry for this community. It is a place of intense negativity and sometimes, as in this case, ignorance. I suspect anyone who's worked on Go projects at scale knows that Go's JSON library can be quite slow, so thank you for taking the time to try and improve that. I will say that we ran into major problems with a 3rd party library like this, where it used unsafe improperly and led to data leakage... the cardinal sin of any decoding library. That's left us a bit cautious ever since. But the problem you're trying to solve is very real, and I'm sorry for the way this community has treated you.
You can't do it in a function for the same reason Rust doesn't: it needs to alter the control flow of the scope it's used, to get the early return. This is fundamentally impossible for a function.
I do agree generics are tricky and think this is a fair point - they add complexity and make the language more adaptable, which means more abstraction. Not necessarily a good thing and they'd have to do it very carefully, it also has implications for compilation times. I think it's unfair though to say the majority of these suggestions: Removing GOPATH removes incidental complexity, Generics would add to it, simpler error handling I think would help reduce verbosity without being much more complex. Tidy up std lib again I think could reduce complexity, by making things more consistent, less surprising, correcting any small errors, using the paradigms that work. So on the whole I think these suggestions are in the spirit of the language. 
Non-nilable reference types
I genuinely feel bad that you think npm is "good tooling". It's like someone who has only ever been in abusive relationships saying "Jimmy is great, he almost never hits me"
No danger of that, and I agree it'd be awful :) I do think it's informative though for people at Google to hear what problems users of the language have (or think they have). Even if many solutions proposed are wrong-headed or ill thought out, it might be useful in delineating the pain points to focus on.
Just to let you know, I've read some of the more negative comments in this thread and I hope you won't feel attacked by it, ignorance exists everywhere on the internet. You have done some great work, truly, and I use your KVStore and GJSON in some of my projects with good success and I'm certain that most people would agree this is post and the library are great ideas.
Thanks! Wise words. I find it sometimes difficult to filter out the inane ones. But practice makes perfect. 
Thank you :)
Chances are that a website would craft JSON for the request to the server and then Node would send the same JSON to Go (it's a great format for any language to send or receive data), so I think we're all missing what you want Node in the middle to do. You mention universal JavaScript, which I assume means you have a specific bit of work you'd like to accomplish in the server, but if you can explain what this needed functionality is, we can probably point to a Go solution so that you won't need to have multiple server apps for a simple application.
Thanks, is that Google CSE?
Totally agree on comprehensions; that is a very minor syntaxic change, but they are really cool and readable. As for the meta-programming, I really feel this is nailing it. I understand the reasonning behind not having generics, yet at the same time, the lack of extensibility in Go is sometimes almost suffocating. Go has always tried to be a better C, so it would only make sense that the way to add extensibility without complexity to the language would be to have a better macros system/preprocessor. How they could make it idiomatic and ergonomic, and prevent it from delving into an undecipherable macro-soup though ? I'm not sure... But it really feels like if Go wants to keep its place as a fast and pragmatic language sitting between the strongly typed/CS-backed systems like Rust (Types everywhere ! Solving generics by having a more complex theoretical framework underlying the language) and more dynamic, 'scripty' languages like Python (No types anywhere ! Solve the problem by essentially handling nothing but `interfaces`), it will need a way of letting the programmer handle specific types generically, if it wants to avoid generic types specifically...
Bookmarked this ages ago but haven't yet used: http://www.blevesearch.com/news/Site-Search/
yes i think it is a good way to manage repos locally. but it is not good that i am forced to do it that way. when i create a new project, i usually just start it in ~/dev/newProject. with go i am forced to first decide where the code has to live ($GOPATH/src/github.com/&lt;user&gt;/newProject). not just the import-path, i am forced to put the package locally into a specific folder. yes you can work arround this, but the "go-way" just doesn't want you to. by the way, most of the time i just run a docker-container and mount the code as volume into the container - that way it works on every system no matter what your $GOPATH is, you dont even have to have go installed. so when someone asks me what i do not like about go, this is the very first thing that pops up in my head.
&gt; simpler error handling I think would help reduce verbosity without being much more complex What kind of error handling style do you have in mind here? (I'm being curious.) 
Something like [this](https://www.reddit.com/r/golang/comments/69smja/what_would_you_most_like_to_see_in_go_20/dhaarze/) or something like option types where you return an option which contains either an error or a value, and the language lets you unpack that. Rust has some interesting ideas here. 
&gt; On top of that it also lacks lock-free and atomic operations which can save your computer from blowing up if you’re not familiar with those primitives (seriously). Huh?
You probably want to look at the bottom part of: https://blog.golang.org/pipelines
Yea, this was the wrong audience to present your first Go program to as a lesson on low latency. He's only *a := make(Fool, len(article))'ing* of himself with all that casting. He should have just used a Wait Group for his dynamic goroutine despite them not playing well together, to fully leverage the flux capacitor.
How would a `try` keyword handle multiple return values?
GOPATH doesn't work well with large multilanguage monorepositories. So many hacks to get Tools like bazel and buck to work with them. I know that is probably more rate, but I wish there was GOPATH_SRC to just look at the source side in tools.
Sure. It was just my personal experience, specific to C++. What exactly is the limitation of constructors? Glorified, static factory function applies :)
There's lots of possibilities, I have no idea of the tradeoffs or implementation, sorry, I was imagining something like: myFunc() (t1,t2,err){ try v1, v2, v3, err := myFuncThatMightError() ... } * on err returns all zero values for t1,t2 + err * on no err assigns the values and continue I'd be fine with showing the err at the end of assignment with try as above, or a different syntax, though think the rust ? is horrible and easy to miss. This would require a language change anyway and go2 for the keyword addition alone - not much point to it if it doesn't gracefully handle things like multi-value returns. I'm hopeful they'll come up with some solution to this having read Russ's note above, it is obviously on their radar. However it seems from the issue linked above that the go team and others are not keen on this sort of idea (which of course isn't new) because they think you should always annotate errors - I'm not sure how that helps if you have a call stack something like this made up one (obviously in real programs you might have several levels in the middle here): myHandler() -&gt; dictionary.Open() -&gt; os.Open() I see no reason for the middle pkg(s) to annotate the os open err when the handler knows what it was doing when the error was returned and can simply say 'error opening dictionary' to the user - in many cases it's enough to just return an error and let the caller deal with it without annotating all the way up the chain. Sure if you have 10 different ways a function may go wrong and those are all important you need to wrap, annotate or use custom error types, so obviously sometimes you need to wrap errors in a chain, but oftentimes it doesn't add anything except at the lowest level IMO and the built in tools for doing so in go are not great anyway.
unsure if it's a thing. I haven't checked.
You can generalize the `safeClose` function by making the signature `func safeClose(c func() error, e *error)` and using it like `defer safeClose(f.Close, &amp;err)`. It might be a good addition to pkg/errors, actually.
Hey, I remember recommending this as a sample project! Good job, cool to see it finished. 
Quick comments: a) use `flag.Args()`, not `os.Args[2:]` b) it would be easier to reuse the output if it were in a JSON file mapping input to output c) this is purely subjective but I have grown to dislike `check` functions and prefer having a 3 line main function that runs the real core function and if that returns an error, print the error and exit with an error code. That makes it easier to see where an error might pop up. 
You may find [this](https://www.reddit.com/r/golang/comments/65rv74/reqlimit_ratelimit_any_httphandler_on_a_perip/dgd5k5q/) or [this](https://www.reddit.com/r/golang/comments/64e7zl/ratelimit_methods_in_golang/dg1tyoq/) useful around this topic. In short cooperative rate limiting isn't without nuances, your implementation is okay for simple use cases and a learning experience. But for real rate limiting, which is intended to protect resources (value) to your infrastructure it's better for people to use a vetted solution backed by known algorithms like [golang.org/x/time/rate](https://godoc.org/golang.org/x/time/rate). To give you a concrete reason why your implementation is flawed, you back it with the "onecache" library you wrote. I already mentioned reasons why you don't want cooperate rate limiting to be incremented per-request in prior threads, instead I'll look at the default which is a memory store. This memory cache is surely useful for general library usage to store some stuff. But for cooperate rate limiting you run into issues, for example [memory.go:109](https://github.com/adelowo/onecache/blob/master/memory/memory.go#L109) here you clear the cache by iterating the map and hold a lock the entire time. I suppose your solution to avoiding mutating the map during iteration was to launch a goroutine, but this means each expired entry creates a goroutine to simply delete the item. Deleting the item requires holding the mutex, which is held during the entire iteration of the map. So by the time the GC func exits so the lock is no longer held you will have started N goroutines that are all waiting for a single lock, then have a period of very high contention while deletion occurs. During this period you also have items being inserted under the same mutex. Instead you could reserve a slice of your keys type to the memory store struct, perhaps with a initial len of 0 and capacity of 32 or so. Then when you iterate your map instead of starting goroutines append the keys you want to delete to your 0 len slice. Once the map iteration is done iterate over the slice and delete each key directly from the map since you're already holding your mutex. Then simply reset the slice for the next run, this will avoid needless allocations. As a bonus you could append to a copy of the slice header and only assign the new backing to your struct if it doesn't exceed some upper bounds, so your not holding onto a very large slice backing for a single unusual burst of entries but it grows slowly for the common case. Anyways, details like this can cause serious bottle necks and potential attack vectors (dos) when rate limiting is being used for (the common case) of alleviating resource strain from nefarious / abusive users. Regardless I am sure the experience was useful and the API for it is fairly nice and well thought out, so good job on that. Happy coding.
Practically never by table. I usually split data access code into modules that access relatively independent set of tables. That way I can search on a column name in a single file and make changes consistently if situation requires it. There may be some queries that span these sets/groups. Those go into one of the sets or into a separate file. Nothing is perfect. The worst case scenario is to check two files for potentially needed modifications. In SQL I always use column name delimiters (square brackets in MS SQL, double quotes in Postgres, backticks in MySQL) so that I can lookup column and not variable or other identifier by the same name. This is just basic hygiene when working with SQL queries embedded in the code. As usual, YMMV.
I made an issue asking. Looks like they won't get it till the feature hits stable (likely june) https://github.com/docker/hub-feedback/issues/1039
And it did dynamic graphs out of the box too (in the coming weeks it'll be CUDA accelerated too!)
Thanks! ping --user=/u/Oliviaruth
Try to kill the same process with kill command and see how it behaves
Well done, I'm curious though why the cmds struct has a slice of WriteCloser. Wouldn't there just be one, the head of the pipe? Or are you suppose to provide each commands Stdlin separately? Edit: Oh I see after reading it, its just an oversight during setup. Maybe that Cmds struct should be private since it would be difficult to use, OR move all the external setup in New and Commands directly into the cmds struct. It's not clear what purpose New serves, other than giving you a slightly more setup CMDS struct, but slightly less than Commands returns?
While /u/chewxy makes a very good point about checking for behaviors rather than types, I do think that the answer depends on your specific use case. There was a previous discussion about custom error types [here](https://www.reddit.com/r/golang/comments/680s4j/using_custom_error_types_for_testing/), where I presented a scenario in which you are processing a lot of input, and cared about distinguishing between different error messages. Recently after working on that parser, I realized that comparing strings isn't that bad when it's just done in internal tests. Here is an example from the [net/http](https://github.com/golang/go/blob/master/src/net/http/requestwrite_test.go) package which compares an error message to the wanted error message. Regarding your package, besides preserving stack traces, I don't see what additional functionality it provides that someone couldn't do by embedding an error: type FormatErr struct { error } // return FormatErr{errors.New(...)} // switch err.(type) { // case FormatErr: // fmt.Println("Format error: ", err) // }
Can't comment too much on the video yet, but I can say that Ponzu is pretty awesome from what I have seen. Nice work on it :)
Hey, thanks! There have been some fantastic contributions from the community too so credit is due to them as well. 
Constructive criticisms: -no described attempts to use SelectCase anywhere instead of the plain "select". -CLI assumes the user knows how many cores are in his hardware all the time. Use a % of cores available instead as a cli parm to avoid such assumptions. -no described steps made to examine currently running processes to see if it's a good idea to run at max core count. -no steps described about profiling your code before/after your commits for improved low-latency. 
That makes sense, when those details are hidden the package will be clear and concise, thanks for taking the time to explain.
I don't like commands in comments either, but don't you think we have enough make-like tools by now?
&gt; So... how would you validate for this well-formed json {"log_message": "the database is on fire"}? As I understand, the stdlib unmarshaller will pass it without an error and happily return the zero value too. I think you still miss the point. If the JSON payload gets truncated, then it's not valid JSON anymore and service will error out, which will be visible in the logs. By the nature of JSON it is not possible, that truncated JSON is still a valid JSON, due to the closing characters. If you implemented a YAML parser, then you could argue. With encoding/json false boolean field means: - JSON contained `"key": false` pair - JSON did not contain my "key" at all With your library false boolean field means: - JSON contained `"key": false` pair - JSON did not contain my "key" at all - Someone streamed /dev/urandom in the payload
Good idea. I'd be very surprised if this was an issue with Go as it should send the signal immediately.
You shouldn't need to do anything special on the go side. For node, you'll probably want to use something like express (https://expressjs.com/) for the http server, and then a library like request (https://github.com/request/request) to make an http request to the go server from within the express handler (using the port of the go server).
Few things in my company: 1) We've got a great project for trying out Go: the budget was ok for a few extra days to learning new stuff, the project lies down on websockets and concurrency patterns where Go shines. 2) I've got talk with a few engineers in our company about how we got enough of programming web pages in php. 3) The company's managers are willing to trying a new stuff, so they get competitive advantage.
I said that Docker was written in Go. This put a final stop to suggestion that Go would just be another academic and exotic programming language. It was fit for production application. This was a very strong point. The remaining concerns were about long term support of the language. I explained that Google is leading and supporting development of Go. I added that the compiler and all std packages are open sourced on github. Even if Goggle would stop supporting Go, it would not be a problem. Another concern was about it's young age. I explained that because the language is simple and complete, many people are publishing packages on github. The tools we need (manipulating FITS files, Swagger, DB, web) are all already available in Go. Last concerns were about programming language fragmentation in our project. Usually programming languages are restricted to C++, C, Java and Python. In our distributed application there wouldn't be interoperability problems. The problem is about developer competence. I explained that I learned it in a week-end because it is very simple. A colleague who never saw the language but know C, C++ and Python had a quick look and confirmed. He decided to also adopt that language for his parts of the development. Everybody currently agree on my usage of Go, but I still have to go through a formal review by a third party. So it's not 100% sure yet that Go will be used in our project.
build something useful in go, tell them how fast it is and how it took you the same time as it would take in python or nodejs, and them tell them this is way better for long term maintainability because it has static type checking. Tell them segment.io moved from nodejs to go for reasons like this https://medium.com/@tjholowaychuk/farewell-node-js-4ba9e7f3e52b
I'm not suggesting that Go is not a good choice for you but there are more than just technical considerations here. One example is the pool of available developers to hire from. Similarly, the need to do front-end JS work as well as back end might make these developers more flexible.
&gt; The remaining concerns were about long term support of the language. I explained that Google is leading and supporting development of Go. Why would you bring that up if they're concerned about long term support of the language? That's the one thing that puts long term support in doubt.
I built a very simple web app in both Go and Java EE, compared the number of lines of code involved, and showed the CPU and RAM requirements and how they would affect our hosting costs. Comparing with NodeJS, I mostly made a technical argument based on the lack of stability and reliability in the JavaScript ecosystem, and pointed out a few examples of companies that had switched from NodeJS because of the long term maintenance problems.
I found this medium post quite useful, particularly in the node vs go argument: https://medium.com/javascript-non-grata/the-fall-of-the-house-of-node-43697fd56a6
1. I was not handling short writes in my code: the example from the standard library was doing that. I was wondering why they were handling short writes for exactly the reason you mentioned. 2. Thanks, I didn't know that!
We started using it after I learned it and built something for work one weekend. I walked my manager through how it worked and basically just got him as excited about it as I was. The combination of "Hey look at this cool language" and "I actually used it to build that thing we talked about last week" was enough to get it into production. Any new stuff we build now will probably be in Go.
I'm aware of that. SIGKILL can't be trapped and handled by the application. It should be immediate but I suppose it's still down to the scheduler ultimately. Using kill -9 should be equivalent to sending a SIGKILL from Go.
Sure, I just wanted to mention that SIGKILL is a special case, but *normally* signals are queued and delivered "as soon as the application can receive one" which is subject to the rules laid out in the man page I linked. Sorry if my post wasn't helpful, a RTFM rarely is, but in this case, it's just unexpected that delivering signals can take a while. I think also we've all seen that ourselves, frantically hitting a ctrl-c to try and stop a terminal program spooling out the contents of the entire internet (or a binary file :-(!) to the terminal, but it refuses to react. The reasons are similar (although can also have to do with a poorly implemented terminal emulator in that case!)
Lack of stability and reliability?
Yeah, direnv can accomplish this
In my team I am the manager, so maybe my story isn't too helpful. I built a few small services in Go to see how it worked out. I was happy so I sent out some "suggested reading material" to the team for anybody interested in learning it and told them they have my blessing to take a few hours a day learning it and writing new endpoints in Go. Nobody took my offer. PHP dev continued as normal. *sad* But I know how interrupting a required language change would be, so unless something was fundamentally broken with our existing language or process, I wasn't going to demand a change. Flash forward 6mo. One of the services I wrote had a fatal error. I forgot to remove an os.Exit() call and the service was dying in very rare cases instead of elegantly handling the error. I was unavailable so my other lead developer who has never used Go in his life dug into the code, understood it, found the bug and reported it to me but didn't know how to rebuild it. I told him to SSH in and run "go install servicename" and "service servicename restart". He seemed impressed with how easy it was. Try to get someone to debug a Node crash who has never used Javascript (or even someone who has only used JS on the frontend) and watch their head explode. Nothing about Javascript is intuitive or makes sense to someone with experience with programming languages with a consistent pattern and structure. If you are a proficient JS developer you can build in Node much faster. However, I'd rather take a bullet to the head than take over a large poorly documented Node project.
I did buy the Go Gopher Toy from kickstarter, and showed it my manager. "This is Go" I said, "we need to write our new code in Go". He looked at me silently and nodded. 
OK, so this is about interfaces. In an OO language, you can define "class Animal" which has a set of behaviours (methods). You can then inherit from that class and create child classes with slightly different behaviours ("class Dog" and "class Cat"). Code that requires an Animal can be safely given a Dog or a Cat because they're all Animals. This is what inheritance is useful for in OO programs. In Go, you do this by defining an interface. So you'd define an Animal interface, with a defined set of methods on it. You can then implement these methods in a struct called Dog or a function called Cat. As long as they support all the methods of the Animal interface, they can be passed to any code that expects an Animal interface. The beauty of this is that it removes cruft. The code that wants to call Animal.makeSound() may not care about Animal.climbTree(). So it can specify an interface for its needs (call it SoundMaker) that only has the methods it will call (makeSound in this case). Then anything in your code base can be passed to this code by adding the appropriate methods to make it support this interface. Easiest practical example: http.Handler is anything that has a ServeHTTP method. Anything. You can do this: type StaticHandler string func (sh StaticHandler) ServeHTTP (rw http.ResponseWriter, r *http.Request){ rw.Write([]byte(sh)) } and then use that as a handler in a route: rs := StaticHandler("this example rocks") http.Handle("/", rs) s := http.Server{} _ = s.ListenAndServe() which is pretty neat, huh? In an OO system, the standard library would define "class Handler". You'd add a ton of methods and stuff to that (see any Rails class ever for details) because it needs to be useful, right? And then you'd create a child class of that to handle the static string example. But that inheritance also inherits everything included in the Handler class, which is probably going to break because you've only got a string to work with. You'd probably need to overwrite a bunch of the default behaviours of Handler, and there'd be a lot of complication and pain. All sorts of edge cases that would get tedious to test for and cater to. If your standard library rocks, then its Handler class would contain one method (ServeHTTP) that you could then inherit from and implement with the static string example. But you'd still have a class, which means instantiating it and all the rest of it. You still can't just hang a function off your simple string type and boom! automatic Handler object like you can in Go. So... to get back to your question. This is encapsulation, broadly speaking. You ask for the things you need by defining an interface. All that you need is encapsulated in that interface, and your code can work with anything that supports that interface (whether it works *well* is another question). It solves a lot of problems with OO inheritance because inheritance takes the kitchen sink with it in each generation. It's not just multiple inheritance. Every child has to deal with *all* the methods of *all* its parents, and allow for the fact that great-great-great-grandparent methods might get called on its instance. It does take a bit of time to get used to not thinking in objects. But the power is amazing :)
SQL is code. It lives in your code base. You wouldn't look at all those If statements crowding around your code base and think "this is confusing, I should work out a way of consolidating all these If statements". Don't worry about the Select statements either, for the same reason. Become more comfortable with SQL. It's survived this long for very good reasons.
Remember the [left-pad](https://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/) incident? Look at the dependencies of a typical open source NodeJS project. Look at how fast entire frameworks appear and disappear from the popular projects list.
I'm talking about [churn](https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f). You may not feel it's an issue, but many disagree.
Should I list all of the Go web frameworks as a counter example? 
Counter-example to what? And there's a reason why people on /r/golang say not to use Go frameworks.
I'm less concerned about the pool of golang devs. Our experience has been that python/c/c++ devs are productive in golang within 1-2 weeks (as in shipping production code) if supported (code review etc) by existing golang devs. I'm happy to hire good devs and cross-train to golang. We get a benefit from running golang in the cloud and on-device (for IoT). It allows us to move processing between the device and the cloud in different releases relatively easily. I can see that a similar benefit could acrue to nodejs on the backend with js in the browser. 
Shhh, it sounds cool to people who don't know google's track record of projects.
I said I'd take a job elsewhere if they didn't let me use it. :-)
I'm not sure pointing out that docker was written in go holds much weight considering how buggy docker is.
Engineering manager here. We use Go, heavily among other languages, and the discussions around choice of language have been: * Does it fit the problem space? (Mostly, in our case) * Does it have library support for... ? (Usually and while cgo can be a pain it frequently just works. Debugging cgo sucks, valgrind/helgrind support is weak/absent) * Are there good tools and an ecosystem around it? (Sometimes, dependency management still sucks, debugger support is poor) * Will it interoperate with _baz_ thing or vendor _quxx_ service? (Almost always, depends on what you're doing) * Can... * I hire people who know it? (Yes, but if they don't they'll pick it up in a few days or weeks on the job) * my worst developer learn it? (Yes, but they're still my worst developer) * we debug it and support it? (Yes) * Who will perform code reviews and has time to shepherd? (This is a big one, we insist on having at least one person on each team who can lead with the language and one on cross-team who is able to pitch in) FWIW, I personally don't like Go. It has the wrong level of abstraction for me and its trade-offs and design decisions are not ones I prefer. 
Usually if you want to use Docker/kubernetes or Gauge(testing) since they are open source tools, the company should have some go developers in case they need a patch or to fix a bug. The alternative to this is to buy support. I'm sure by now in most companies use some software which is open source and whiten in go. Argue that the company should have some go knowledge if they are serious about using any of these tools. For me it was easy since I'm the manager and pushed go on my team. Initially it was mostly due to using docker in the company, but now people really like it and we're trying to get a Meetup started.
This looks too good to be true. I'll need to test this out later and see how it performs... You even already have a Docker image ready to go. I've taken a look through some of the docs and FAQ and it seems very impressive. Who's using it at the moment? (With it being so new and only just being announced as production-ready I imagine not many people?) Edit: Just a heads up too, trying to actually click something on the drop-downs in the menu was very difficult! The menu kept disappearing.
[cockroachdb engineer] we've just turned the corner on production readiness. we have a couple of customers which cover the range from startup to enterprise who are already in production. there's a larger group which is currently evaluating CockroachDB through proof of concepts and beta testbeds but if you're looking for specific names, two we publicly announced (in the blog post) are Baidu and Heroic Labs.
Reading through this confirms my suspicions that nix will work nicely with go, solving common pain points :) can't wait to get some time to try it!
You can try to use [os.FindProcess](https://godoc.org/os#FindProcess). I remember using it for this exact purpose, so I'm pretty sure this should work. The caveat of this method is &gt; On Unix systems, FindProcess always succeeds and returns a Process for the given pid, regardless of whether the process exists. But since you're on Windows this shouldn't concern you too much.
Man, thanks a lot for this post.. I really appreciate this. I would try a fix according to your instructions.
Call with exec.Command: tasklist /FI " PID eq 1234" and parse output.
The [talk](https://talks.golang.org/2013/oscon-dl.slide#1) by /u/bradfitz regarding dl.google.com being now powered by Go instead of C++ is quite a good comparison of the 2 languages regarding web services and interoperability. I don't know about your company and your products but you mentioned C++ so... I thought it might interest you.
For unique constraint violations, I believe Postgres reports the constraint name, not the field name (since multiple fields could be involved). I'd recommend testing it out and checking all of the fields in [`pq.Error`](https://godoc.org/github.com/lib/pq#Error) to see what data Postgres provides.
You mean inserting a foreign key value that doesn't exist? That should be a different error code. List of errors can be found in pq/error.go: https://github.com/lib/pq/blob/master/error.go#L177 If you have two unique columns on the table, you could follow up the error with a select to the table to find out which value was a duplicate. Something like this: select coalesce(select 1 from table where slug = $1,0) as slug_is_dupe ,coalesce(select 1 from table where id = $2,0) as id_is_dupe
Yes, I just tried it out. I think I can work with this. `pgerr.Constraint` will give the name of the constraint (e.g: `users_email_index`). I can use that to write out a friendly message. Thanks!
Google has been using Spanner in production for years now -- we use Cloud Spanner at work now too, it really is just absolutely amazing. I can't recommend it enough.
Ideally, it'd be nice if we can "watch" a variable. var err error watch err { a, b, err := foo() e, err := bar() f, err := stuff() } if err != nil { fmt.Println(err) } Execution inside the watch block stops as soon as err values satisfies one of the if condition.
Unless you're reading them from independent drives you'll be IO bound and concurrency won't help you.
Being easy to read and understand without much training is itself a big boon, particularly if you're dealing with a large codebase. As someone looking for a Go job, it's refreshing to hear that Go experience is not a prerequisite.
Why use just one? Why not pick the best tool for the job? We use MySQL for account data, totalling no more than a few MB. In Mongo we have a collection of 15M documents of structured, indexed data. Pulling out the documents for any given user or account is simple. There are use cases where Mongo is clearly better, and cases where MySQL is clearly better. What I hope we see in CockroachDB is a relational database that improves on areas where SQL performs notoriously badly.
&gt; It's ACID compliant, but only for SELECT queries. Isn't ACID compliance really only useful for writes? What's the big deal if my reads are ACID?
Now we just need AWS to make an RDS version of this
What if the files are on S3 :-)
Not sure what the [deleted] comment is about. I think you are confusing inheritance with polymorphism. Encapsulation is just composing behaviors together in a class, or a struct with functions. Encapsulation is independent of inheritance or polymorphism. It's simply just a class. Inheritance inherits previous encapsulation. It is a form of code reuse. If you have defined a concrete class `Person`, with all its behaviors, you can inherit another class `Child`, and add additional behaviors that only applies to a child. But an instance of `Child` still carries all `Person` methods and behaviors. Inheritance not only inherits methods but also properties of its parents. Interface composition in Go, or polymorphism, allows you to mix in multiple behaviors together, but the actual behavior is defined by the struct that implements the interface. The `Closer` interface, for example, defines a `Close` method, but what the `Close` method does is defined up to the struct that implements that interface. Unlike inheritance, the struct that implements the interface is also not limited to implementing the `Closer`, it can implement other interfaces. This is **very** different from multiple inheritance, which is terrible anyway due to the diamond problem.
The C and I of ACID are super important for reads. You probably want to get a consistent committed view of the data when you're reading. https://en.wikipedia.org/wiki/Isolation_(database_systems)#Read_phenomena
The spanner paper has what you need: https://static.googleusercontent.com/media/research.google.com/en//archive/spanner-osdi2012.pdf One tradeoff is that since it's based off raft, it's a CP system, which means that if your network is flaky your availability will suffer. Google manages to run their implementation of spanner at several nines of availability by tightly controlling the network. https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45855.pdf
etcd and cockroachdb as well
 func example() (err error) { defer func() { if r := recover(); r != nil { if v, ok := r.(error); ok { // https://github.com/pkg/errors err = errors.Wrap(v, "example failed") } else { err = fmt.Errorf(fmt.Sprint(r)) } } }() // At least one of these calls can panic. a, b := foo() e := bar() f := stuff() } ... err := example() Then again, that looks like exceptions, but that's as close as you can get probably. I imagine the ability to watch a specific variable while executing a block of code would start to elicit some desire for watching multiple variables, not to mention the chains of if statements that handle specific error interfaces (e.g. the various types supporting `Timeout() bool` and `Temporary() bool` methods in the standard `net` package).
Am I the only one who think GOPATH is great just the way it is now? The dependency manager(https://github.com/golang/dep) seems to solve the issues so why bother with "workspaces" and other concepts? 
Isn't this just an instance of https://blog.golang.org/pipelines ?
I really really hope that the sameshit() method actually works and does the, well, same shit that you did to another array/slice earlier 😁 Might be challenging with concurrency but I am sure there's a way
All of these approaches in this thread hide, or at least obfuscate, the error handling flow. I know, this is exactly your point. :-) But I am not a big fan of this. First, tracking down errors to their source becomes more difficult. Second, your code will be less readable to others who are not faimilar with these non-standard error handling idioms. (Non-standard in Go, that is.) I totally agree that Go's error handling can appear overly verbose at times; however, being able to see which function call might fail and what the caller is doing *in that particular case* can be a plus.
Always put basic info and usage of the library in the README. The extra repo for the example is not needed yet, it could've been a directory in the repo. Since this is a library, documentation matters even more. Add https://godoc.org/github.com/thegtproject/jobqueue link to the readme and ensure you document all public types, functions and methods. I can see you are spawning additional goroutine. You should probably add test and run your tests with the `-race` flag to ensure there are no data races. I hope that isn't too much. Those are the things I noticed from my quick glance.
Some thoughts here: What youve got there isnt really a queue. A queue would release the items after they are finished (yours would grow indefinitly). I would do it like this: have two seperate slices, one for waiting workers and one for running workers. If a worker gets scheduled put it into the running slice. After the worker is finished remove it entirly. Another thing would be, that your queue is doing something called busy-waiting (ok not really because of the sleep but still) you could try to use channels there, to be notified, when a worker is finished or a new worker has been added to the queue. One last thing: why do you pass the workerinfo to the Start() method? Maybe im missing something here but i'd think thats not good (malicious workers could change the values and break your queue) Overall a good project though, i hope you have some fun learning :) 
Not too much at all. I appreciate it. I was under the impression that each project should be a repository but now realize this was a bit silly. As a stupid little example it could very well sit in a subdir. I will fix that as well!
&gt; Ha, you may also want to share that almost all the criticism Go faces from the programming community fit into the category of "Go isn't academic and exotic enough". I'm not sure there's been a language as brutally practical since C or Awk or something. LOL right, because languages like Python, Java, C# or JavaScript are academic, exotic or impractical... /s Seems like Go programmers keep telling each other how Go is simple &amp; practical and how other languages are academic/complex/whatever, but really what is this meme actually based on? How is Go simpler and more practical than, say, Python or Java? The answer is it's not, it's about the same in all respects. To be absolutely honest, I don't see a very big difference between Java and Go. If I had to choose between Java and Go for a backend platform, the only difference that would actually matter to me is that Go has a less resource-hungry runtime and Java has a better type system, but that's about it. Yeah, sure, there are differences in the language details (such as no inheritance in Go etc.), but in the grand scheme of things those differences are IMHO rather minuscule. 
madness
I'll take that as a compliment. Any aspect in particular that you find especially mad?
&gt; Ha, you may also want to share that almost all the criticism Go faces from the programming community fit into the category of "Go isn't academic and exotic enough" Nope, Go is just the most badly designed language I've seen. I thought that it is impossible to design a more ugly language than C++ or php, but here it is. It is definitely not awk or C. awk and C were beautiful and simple, and Go is not simple, it is complex as hell. Do you know what makes languages simple? **Rules**. Do you know what makes languages complex, ugly and hard to use? **Exceptions** from the rules. And Go is full of exceptions. For example: 1) No generics, but generic slices, maps and channels in stdlib. You cant define your generic map or rb-tree, but there are some generic entities in the language which are exceptional. 2) There are no tuples, but functions can return multiple values, which is also an exception, not the rule. In language with tuples you can get multiple values as a tuple from a function and pass it to another function. But in Go you can't pass a pair of values to a function, there is no such type as pair, you can only return it. 3) interface{} which make Go type system unsound, just as python's one, but static (handicapped) typing is still there, not preserving you from errors but disturbing. 4) nul Go feels like its creators didn't even try to design a decent language. It feels like they wanted C with plan9 libthreads, so they took libthreads and hastily made a language around it. Go is not simple, it's poorly designed, and I think more design issues would show up as they would add new features such as generics.
This is the stuff I was hoping I'd get from some bored programmers! Perfect, thank you! I completely understand your reasoning here and it makes sense. I am not quite seeing what starting StartNextJob as a goroutine would solve in terms of the back-notify without exposing inner implementation. But that could be because its almost 2am. I will sleep on this and take a fresh look in the morning
Oh it can fly alright
Could somebody please explain whats the benefit in first creating a command and then consuming it?
True. It is like a comparison of rose vs potato. http://www.bash.org/?151227
There's plenty of Go jobs out there, you wouldn't be learning it for just one company. There's also tons of Docker jobs out there, and understanding containers is a pretty important thing nowadays for a lot of shops. This will only grow in the future also. 
Thanks. I just realized that terraform, Kubernetes and grafana are largely written in Go so that's cool too. 
I get learning Ruby because it's your new job, but you're not really going to actually /learn/ anything new about programming if you've already done Python and Perl...
'Downloading packages from china is just terrible' -- I'm sorry, what?
Yes. most of my Ruby hatred stems from Rails. Earlier in my life I met so many Rails "developers" whose code was not secure in the least bit. My buddy and I often pointed out how insecure their sites were. Rails made coding too easy. Not that I believe that coding should be in the realm of only the super smart, but come on, adding that heavy of an abstraction layer to where the code practically writes itself create a ton of people writing terrible underlying code
I like this! https://github.com/kare/gends
I am working in China so most of google related websites are blocked. I didn't say that to you but i do hope someone reading my answer would create a mirror here to make golang dev smooth. It was just to share one of my concern.
This is a bad practice. PITA to debug and I'm not sure how does it affect current transaction. Just check if the slug is already in the database before inserting new one.
sorry I dont understand what you mean by coordination, i just want a way to read files in paralel/concurrent mode and to be able to store the processed data somewhere, the files are independent from each other
As /u/tv64738 mentioned, this is a case for https://blog.golang.org/pipelines You'd collect all the results in the `main()` function, and then do whatever you need to do with them.
You'd be surprised how many CPU cycles you can sink into parsing (needlessly) complex XML documents. And then you have shit like remote XSLT references that need to be downloaded, which is I/O bound, but can be parallelized in most cases (latency, not bandwidth bound).
I think he meant that documents are only in Mongo while account data is only in MySQL. Presumably each document in Mongo will have a user_id field which matches the never changing user_id in MySQL. 2 different databases that are better suited to each type of data.
I think you'll learn something different. Types and open interfaces are heavily used. Also not many generics. https://medium.com/golangspec/interfaces-in-go-part-iii-61f5e7c52fb5 https://www.goinggo.net/2014/05/methods-interfaces-and-embedded-types.html https://peter.bourgon.org/go-best-practices-2016/#top-tip-9 https://docs.google.com/document/d/1vrAy9gMpMoS3uaVphB32uVXX4pi-HnNjkMEgyAHX4N4/mobilebasic A good editor https://github.com/visualfc/liteide 
You don't really need to know golang for docker right?
To use Docker know but I want to extend it and figure it would be nice to use it's native language
I'm surprised C# team would be interested in Go. If you are already happy in the MS ecosystem, then C# seems superior. Can you talk more about why Go is appealing?
Would that not mean two SQL queries in place of one. Also what happens in the scenario when 2 simultaneous web processes are making requests with the same slug? I think the SELECT query will succeed for both, and a duplicate record will be created.
some sort of list like a slice or a map
some sort of list like a slice or a map
DevOps person here.. You won't find many jobs where you are working just in Go. You probably want to target a company like Docker and try to work there and I'm sure you can do Dev and probably some ops if you want. To be honest most companies that hire devops is just another title for sys admin but does cloud automation stuff. 
Fair enough. DevOps does seem to be a buzzword title that came around with the Cloud movement. I guess a better question is, would having Go in my toolbox be worthwhile? 
As you already have some previous experience, I would actually suggest you my API Foundations in Go &amp; 12 Factor Apps with Docker and Go - it seems both very much fit exactly into your use case. There's a bundle available where you save about $8 if you get both and if you don't leave me a tip which is used for buying books, usually :) https://leanpub.com/b/golang-app-bundle * Go is very much a general purpose language, but it's geared more towards back-end development, * Go shines very much with high concurrency and things like websockets - learning this is never bad, * I use Go a lot, I tend to pick it over Node/PHP pretty much all the time, but I don't always have a choice Anyway, bunches of jobs are available for Go, interesting stuff and most of it is dealing with some kind of scaling, but not exclusively. It's a very good language to learn in my opinion, because it gives you a different outlook on other programming languages, and perhaps you'll notice some bad patterns in terms of how people write code in other languages today. The question is not so much what Go can do, but what you can do with Go - providing APIs feels very natural for Go, but writing front-end code with html/template not so much - you can, it's fine, only you'll be better off with Vue/React/Whatever and use whatever in Go as a back-end service, where it shines. Unlike node, the libraries available for Go are usually of a higher calibre, and nobody thinks of using things that could result in that fucking `left-pad` fiasco. Vendoring your dependencies into your codebase solves that problem completely, while just the way how people write Go code and use packages already take care of this. Go has a very strong stdlib, and external packages are used when they solve very specific needs, and not something like generic type checks or whatever. I'm rambling at this point. TL;DR Go is great and you can build cool stuff with it, Node hurts my sensibilities
&gt; LOL right, because languages like Python, Java, C# or JavaScript are academic, exotic or impractical... /s I said that the criticisms Go faces are of that nature. Are you aware of a great bulk of criticisms against those languages for "not being academic and exotic enough"? C#, maybe, though usually it meets those criticisms by adopting more academic features over time (non-nullable types, LINQ, etc., all added after 1.0). What you're "lol"ing at is not what I said, it is what you _expected_ me to say. If you just want to talk to people saying what you expect them to say, then you don't really need to go out on the Internet for that; you can conduct a monologue without me just fine. I could easily criticize Python for being not very academic. Despite occasionally wearing the superficial trappings of academically-interesting features, like list comprehensions, it is basically disqualified nowadays because all academia is based on ever-stronger type systems, and dynamic typing is right out. But it is not the common criticism leveled against it. I assume it is because people don't expect languages released in the 1990s to track all the latest 2010s programming language theory developments and fads. Let me pre-emptively point out how I wrote about the _developments_ and _fads_ separately quite on purpose, because they are different things. I'm actually also critical of Go not using the experience of the various _developments_ of programming language theory; for instance I'd like all the nillable things to also have non-nillable types to go with them, because things like C# show that you can even _retrofit_ that sort of thing on to an existing language. (Being able to retrofit things like that is actually fairly rare.) I thikn Go would have also been helped by some sort of memory isolation model between goroutines, both for programmer correctness and for easier GC, in the style of Erlang. However, it is also absolutely the case that a lot of the criticism of Go is because it rejects all the latest _fads_ as well. There is a non-trivial amount of the criticism of Go that arises because it directly challenges some people's self image of themselves as being members of the community that is in sole possession of the rights to determine who's the cutting edge new language and who's last year's trash, and Go's success challenges that authority. Those criticisms should be discarded by serious engineers. I do not have a lot of respect for the fad-driven community, because they have lost that respect with me by failing to use sober judgment. Scala was one of the more recent fads, for instance, and I've seen a lot of criticism about how complex it is and how that complexity doesn't seem to pay off anywhere near as much as it should, and a lot of those criticisms should have been evident from the beginning. It checked a _looooot_ of boxes off the fad-of-the-year list, but in practice, it's probably going to end up a failed language. This is not uncommon.
&gt; Fair enough. DevOps does seem to be a buzzword title that came around with the Cloud movement. I guess a better question is, would having Go in my toolbox be worthwhile? IMO yes, as soon as you have multiple operating systems it's nice to be able to deploy a single binary instead of messing with gems and python packages on windows vs linux servers. 
&gt; I'm also not a fan of how callback/promises work in JS- just seems dirty to me. async/await makes code very easy to read and understand. it's available _now_. I'm not advocating for JS over Go, I just wish people would revise their criticisms with the current state of things.
Not sure I follow. Documents are stored solely in Mongo, not in MySQL at all.
https://nathanleclaire.com/blog/2014/02/21/how-to-wait-for-all-goroutines-to-finish-executing-before-continuing-part-two-fixing-my-ooops/
* Install protoc * Create a .proto file. * Generate a golang struct using [golang/protobuf](https://github.com/golang/protobuf) * Fill the struct using sql.DB * Call proto.Marshal(struct) 
I work devops for my company and primarily program in GO. It's the best tool we've found for cloud operations (like a client side loadbalancer or monitoring tool) as well as being the most flexible tool we have for designing a CLI for our integrations (cross compiling is awesome. Python and Ruby environments always get messed up on dev's laptops). Most of the Devops tools coming out (Docker, Hashicorp's library, Container Schedulers, etc) are being written in Golang. This means that over time companies will likely pick this up as the go-to for devops work (in my opinion, at least). TL;DR I think you'll be okay and in fact increase your hirability if you become a good Golang developer.
Try using the [golint](https://github.com/golang/lint) tool. It will both help with the code as well as find the parts of the code that should be documented. You should follow the godoc standard for documenting your code. The best part of doing so (imo) is that [your project](https://godoc.org/github.com/thegtproject/jobqueue) will be documented on godoc.org. I would also add some tests. I'll add that I really like the [assert](https://github.com/stretchr/testify/tree/master/assert) package to help with testing, but that's a matter of personal taste. If the package is intended as a library, you shouldn't print to stdOut. I would log the messages that you're printing, but that's only one option.
Cockroach errs on the side of being really slow (250ms delays, ouch) when it can't get a good clock source. So not really too good to be true, assuming you have a good enough infrastructure for it.
It's a neat idea. Maybe some members of the language body are looking at things like this. Generally, in my opinion, you don't want to do stuff like this. Don't break the customs of the people. A language, and some artifacts (like PEP 8 for Python), are the customs of Golang World. Moving outside of these customs makes life harder for both you and the people that come after you. Here's an example from Android: Accessing the database with ORM like features. In Android, people want to use ORMs or DTOs for rows. They think this breaks the database connection. What many don't understand is that all of the Android tooling is based around row-centric data access. This is true if the data come from the DB or a WS. Android's default view is rows or tuples. I kicked against the pricks for a while on this (used domain objects rather than tuples). All I ended up doing was creating more work. Rather than using the default binding abilities, I had to write a multiple adapters and such to get my object onto the screen (or into a list). Finally, I just looked at Android and said, "Android, I may not like how you do things, but I'm going to use you. I will focus my Android data into tuples." Since then, life in native Android is better. The result is any native Android developer can look at the code and see what it's doing. They can tell really quickly too. There aren't 4 layers of data converters required. You get data from a provider and use the binding features to quickly slap it into the page. Is it the most abstract, future proof thing ever? Nope. Does it need to be? Nope. Is it good Android? Probably, and that's what counts.
Return errors, don't panic.
It's also worth mentioning that having multiple read requests queued up and waiting allows the disk to keep working, rather than stop while you do something with each file.
My guess would be that the kafka queue serializes the commands, allowing you to recreate the current state snapshot by replaying the event stream on any number of instances, allowing stateless scaling of micro-service instances. The problem is, the article doesn't go into any of the "why?" here, and doesn't address any of the questions that follow, like - is the expectation that Kakfa will keep the event stream forever, and is it good for that? So why Kafka, and not something like Cassandra with an accountID as the primary key and a UUID timestamp as a range key? There's potentially more explanation in https://www.confluent.io/blog/using-logs-to-build-a-solid-data-infrastructure-or-why-dual-writes-are-a-bad-idea/
&gt; The dependency manager(https://github.com/golang/dep) seems to solve the issues I already mentioned this in another post, but no, vendoring and dependency management do *not* solve the main issue of having to organise your whole Go code under a single root. Vendoring and project based workflow are two separate things. &gt; why bother with "workspaces" and other concepts Because I organise my code the way I want, not the way Rob Fucking Pike decided was the best for me.
I do a lot of deep work in terraform creating patches or new resources. So ya go will help a lot. Its always nice as others have said about shipping a single binary around and it works. I create a lot of really simple REST api services around things in go also. 
Use net/http status constants, rather than hardcoding 400/500/etc.
Could use WMI, github.com/StackExchange/wmi 
If in Europe try Schibsted Product and Technology. They contribute to many projects written in Go, ig. Spinnaker
So this would let one write Javascript and compile it to an executable binary? Very cool. Interested in what the perf is like.
Yup, that's the gist of it. The project is still pretty early though so prob. it will take quite some time to benchmark anything.
Anonymity is not the goal at this point. Because email is asynchronous and everywhere. What alternatives did you have in mind?
This is exactly the kind of comment I was hoping for posting this. I find this the fastest way to learn when others can steer me into the right answers. So let me preface this with- i've been learning go for about 2 weeks now. So im still taking everything in and am not very knowledgeable on channels yet. What I think I know... Channels are simply a guaranteed space. I think the word is atomic. Meaning that if a process wants to read or write to it, it will be guaranteed that the operation completes without something else changing it at the same time. Knowing that, I'd say that safety is exactly why channels would be useful in my queue here cause there is nothing providing that safety from my rather ugly state variables in the struct. So something can happen when im trying to change the state from one thing to another and cause issues. That said, i've kind of been intimidated by channels and havnt quite jumped into learning them yet, hence my implementation without :) But I will very probably switch to a channel based system in the near future. Im just using this project to learn go, and im having a blast.
Thanks for feedback. Do you have any thoughts about project structure? I know, it's pretty simple API but I would like to know if there is any convention how to organize this kind of projects.
One pretty simple benchmark: https://github.com/jingweno/godzilla#performance
Yes.
Thanks Mark :)!
Pretty neat idea. Do you save the code? Might be a nice way to convert node projects to go.
Go can use [Example](https://golang.org/pkg/testing/#hdr-Examples) tag you can add to your tests (also you are missing tests). Godoc will create a special collapsible note like [this](https://godoc.org/github.com/go-redis/redis#ex-package--CustomCommand).
This "bugs are my fault" AES implementation hosted on your personal .me domain DOES NOT serve as a drop in replacement for stdlib crypto/aes. How are you comfortable even suggesting that? I don't think your intent here is malice, my guess is your excited about the work you did here and just want to share? But it should probably be presented as such, with a clear indication it should not be used...
&gt; This "bugs are my fault" AES implementation hosted on your personal .me domain DOES NOT serve as a drop in replacement for stdlib crypto/aes. That's there because I don't want people complaining to the upstream for stuff that's likely porting errors. &gt; How are you comfortable even suggesting that? * I'm fairly comfortable with writing this sort of code in general. * Unless it produces wrong output (and it doesn't as far as I can tell), it's not going to be worse than `rijndael-alg-fst.c` converted to Go. * Other people seem to like the upstream code (http://cvsweb.openbsd.org/cgi-bin/cvsweb/src/sys/crypto/aes.c?rev=1.1&amp;content-type=text/x-cvsweb-markup). &gt; But it should probably be presented as such, with a clear indication it should not be used... Anyone that wants a "secure" AES shouldn't be using `crypto/aes` either.
Would love to see you create a example attack that operates within a main pkg operating on solely function calls. I doubt you will have much luck but would honestly be intrigued and impressed if you did. That said taking this beyond a theoretical best case scenario poc to a tangible attack vector towards any Go program isn't happening.
The comment is about not being constant time, you are again avoiding my primary concerns of peer review and everything else accompanying a cryptographic software by focusing on the implementation. You may be a great engineer, cryptologist, etc. Again that is not the point I wanted to raise, from the beginning. The original concern stands: how are you comfortable suggesting using of a implementation of aes that has not undergone peer review? This is nothing personal, remember I don't know you. Your name is all hex characters with a .me sub domain and you post a lib as a drop in replacement for the standard library.. is my position really unreasonable? :-) Torproject is great, are you affiliated with them? If you are is it typical for cryptography algorithms to be implemented by maintainers and contributors of TOR without peer review? Ones with the same sort of dependency graphs of stdlib. I'm genuinely curious, perhaps my ways of thinking are dated and I'm not rugged enough. Regardless have a good evening.
It is. It's a C version of Käsper/Schwabe's SSSE3 bitsliced code. https://github.com/jedisct1/libsodium/tree/master/src/libsodium/crypto_stream/aes128ctr/nacl `cgo` and concurrency don't mix so calling external libraries isn't really an option for me, and the BearSSL code was easier to do in Go.
why not GOPATH for libs and any directory for working? (like python) /u/sdboyer
a) It's not yet possible to compile a node express server from a .js file, is it? b) How far is this project from compiling a universal react app incl. graphql?
a) not yet b) far from it
Yup,I do want this to happen eventually
&gt; a resource where I can post code (github URL) There is [StackExchange's CodeReview](https://codereview.stackexchange.com/) but questions there are usually for smaller pieces of code that fit within the question itself and not links to entire repositories (see their [How do I ask a good question Help Center entry](https://codereview.stackexchange.com/help/how-to-ask) for details). For Go code, make sure to read [the common code review comments](https://github.com/golang/go/wiki/CodeReviewComments) made when submitting code to the Go project *before* you ask anywhere for anyone to review your Go code. Not all those comments need apply to all code bases but if/where you differ from them you should have a reason.
For everyone else that might need encryption that Is also in constant time, you should check out https://godoc.org/golang.org/x/crypto/chacha20poly1305
Go has gc pauses, runtime scheduler that blocks, so many factors that would make a remote timing attack on real Go programs more difficult than the c equivalent. I really think this is academic / theoretical territory, but if you provide a example of a remote timing attack on amd64 implementation for example then I think you would have this fixed fairly quickly. Point was if you don't provide any examples it's a bit difficult to accept all the measurable risk of your library when the core premise you wrote it on has no proven risk.
You could join the go slack group. I know there is a channel for code reviews there but I'm not sure how active it is. 
My question on TOR was to hint at revealing your role, if you are a phd'd cryptologist it changes the context yea? If you sysadmin yum repos probably not. Neither changes the importance of peer review for a core crypto primitive. Did members of the TOR project review this implementation, if so which ones?
Post it here, if you find a better place, post it here too :) I'm in the slack reviews chan but like async nature if a forum setting more.
Thanks for the detailed commentary; What I have is a series of files (i.e. XML, kinda big), and the program needs to read them and put the mapped structs in a list or map. There is no interaction between them at this point. After having all the XML parsed, the structs will be passed to other functions that will show the user the results or apply some other logic on them. What I have now: My test data consist of 24 XML files, I have a loop that goes one by one, reads them, gets them "unmarshalled" (sorry not sure if this expression exists), and appends the result into a list, this takes about 15min to happen (some of the fields need to be transformed, but this is already part of the function that works on the XML file). My ultimate goal is just to spead up the process by having them processed simultaneously.
exactly my thoughts: misleading title
The only part was downloading the Youtube video using a Go app.
I've often wondered why everyone has rallied to go and left SML/CML off to the side. It's not really an academic language (academics dropped it for haskell decades ago). It's not lazy, it's not pure, and it's not completely immutable. It is fast, concurrent (with CML), has a great type system with good inference and support for generics all while being a more simple language than go too. SML (the language) beats go in every single area I can think of. The only downsides are tooling and libraries (both are far more solvable than most problems).
I'm agree with most of what you've said except I wouldn't call haskell academic. SML, OCaml, haskell and even scala are great general purpose languages and are also used for academic purposes. And I think it's a quite strange trend to call academic anything more advanced, than a hammer.
I was asking about improvement (not current GOPATH). ‎https://docs.python.org/3/using/cmdline.html#envvar-PYTHONPATH if you follow PYTHONPATH like design (extended design actually for version, I haven't check Pipefile yet) then item 2 will be solved and we will be able to work on any directory, also non go programmers will be able to 'git clone' and run a go program.
Who says they need to download it from golang.org? A lot of Linux distros host it on their own repos.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [Golang is not for Iranian](https://np.reddit.com/r/programming/comments/6asaiy/golang_is_not_for_iranian/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
So I actually did not look at your example first before trying to reason with your advice myself. Like I said I was super tired when I responded last but I woke up the next morning and just had a total "duh" moment. Im embarassed I didn't think to do it this way first. No funky call backs-stuff required, just pass the method as a go function and do my clean up in there after it .Work()... duhhh! Already changed this in the code. Now im going to work on using channels to communicate progress and such. I freaking LOVE golang. This is the most fun Ive had since i was 9 and just found Visual Basic, haha. Feel like a kid again
&gt; no polymorphic operators It's a feature. Polymorphic operators should be done with something like type classes or modular implicits, not just overloading. &gt;My thoughts on what makes an academic language are based on my (admittedly opinionated) view of what is pragmatic. Oh, I'm not sure that academic is an opposite to pragmatic. I think academic is just something being used in researches within academia. Of course sometimes people uses workarounds without proper research to make some tool suitable and pragmatic, but it's not often the case. SML is definitely a language with a strong academic background (especially type theory), but it's pragmatic.
Would you then suggest to use sth like pkg from zeit.co? https://github.com/zeit/pkg
It's very active.
I like pkg as a packaging tool, but that packages node in the bin so it's the same as running `node xxx`. Godzilla is a js to go compiler (transpiler to be exact) and from there the code can be compiled to natives. So your js program is as effective as one written in Go.
Asking "why not GOPATH for libs and any directory for working" *is* regressing the second problem described in the exposition, even if that wasn't your goal. &gt; if you follow PYTHONPATH like design (extended design actually for version, I haven't check Pipefile yet) then item 2 will be solved and PYTHONPATH does not look substantially different from GOPATH as it exists today (except that it has the python version prefix, because python 3). At least, that's my impression from a cursory look at those docs - I don't know its semantics well. &gt; we will be able to work on any directory, also non go programmers will be able to 'git clone' and run a go program. Yes, that would be possible. But you're ignoring the multi-project workflow, which is half of the problem to balance. Ignoring half of the requirements takes away 95% of the difficulty. Such a workflow is among the most common requests against glide and dep today. It's also something that other language package managers support, although often quite poorly. In the multi project workflow, we're working on e.g. project A, which has deps B, C, and D - but we're simultaneously working on B, as well. The issue is that, when B, C, and D are all just sitting under GOPATH, a tool can't know if the code is an inert dependency like C or D (subject to change as needed by the version solving algorithm - an *output*), or if we're hacking on it, like B, in which case it's an *input*. The design in the document cleanly separates the source cache, where inert dependencies will live and WOULD need versioned paths, from GOPATH, where - _if_ you want to use the multi-project workflow - code that you're hacking on lives. Simply by virtue of which section the dep is in on the filesystem, the tool can tell whether to treat it as an input or output. If you conflate them back together under GOPATH, then you reintroduce the ambiguity, and undermine the multi-project use case.
Just thinking my node API servers dish out http requests at much less than 70ms .. how come hello world would take that long.
I guess the majority of the time taken in the hello world example is node's startup time. For a long running process like web one, there are other costs of node that are larger than a Go equivalent, e.g. memory &amp; GC etc.
It's just start-up time, I assume.
All in all, the biggest gain I see so far is for you to read the 24 files concurrently. 
What needs to be done to get code like graphql express server transpiled via Godzilla? What are the steps exactly? Are there possibilities to help? I see great potential because most server side graphql code ships in node.js and therefore lacks performance and is aweful to deploy, compared to binaries. On the other hand, is it possible to output some format that could be included into native apps? .so? go bind? Thinking out loud. React Native transpiled into go code?
What???
have you tried using a VPN?
Indeed. That would also be faster than something like this, and harder for implementors to get wrong (by virtue of the primitives being easier to implement, correctly).
Well, Go does lack lock-free and atomic operations. Channels are slow and use locks and there are atomic counters etc. not atomic operations per se. Everybody uses Channels or RW.Lock()/Unlock() but that's not lock-free (and slow).
&gt; In Fedora, we only ship certain reviewed curves. Holy shit.
Not yet!
I don't have the details what's involved to transpile graphql express server. And I like all your suggestions of outputting .so etc. As you prob. could tell, i'm juts getting started with the project. I'm looking for help from the community to get the project into a useable state.
I could switch from PhantomJS / Headless Chrome to your lib if I can do that and filter and cancel the JS requests. Like a web crawler that also gets the JS content of a site, would be perfect for my needs if you plan to go this way.
Looking through the source code, I either missed something or the only Javascript it can understand right now is Console.log. Is that correct?Am I missing an entire library of functionality? As far as structure goes, it looks well structured (cobra, package arrangement, good readme), but it looks like it's almost a stretch to call it "started". I hope it goes well though. It's a fun idea if you can manage to wrap the complexities of a loose, dynamic language into the simple elegance of Go. :)
You'd prefer using the pre-broken ones that the NSA pushed on the world?
That's right! It's literally just started! And only console.log is working :p. More contribution is welcome!
Wow, this is awesome. I am just studying your code architecture, which pattern is this?
Great work jetbrains, I love it! 
I will be messaging you on [**2017-05-13 09:00:00 UTC**](http://www.wolframalpha.com/input/?i=2017-05-13 09:00:00 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/golang/comments/6atfzt/go_api_skeleton_built_in_load_balancer_jwt_gen/dhhampn) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/golang/comments/6atfzt/go_api_skeleton_built_in_load_balancer_jwt_gen/dhhampn]%0A%0ARemindMe! Tomorrow read this ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! dhhanne) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
That's true, no mirrors elsewhere?
Thank you for the heads up !
If I wouldn't halve my battery life by 50% on my notebook with Linux vs. Windows .............
eval will work?
Interesting but why not use goa? 
If you're open to paid solutions, I've used Sentry (https://sentry.io/welcome/) at a few of my workplaces and only have good things to say about it.
[removed]
Goa?
Yea, should of made it with crypt.Random() I think it is. Just needed something to generate a secure key quick and dirty. Thanks for checking it out though!
You can host sentry on your own.
Looks quite nice, however I would make sure that you check if the git operations went well by parsing the exec output. 
[removed]
gogland is a shill editor
https://tour.golang.org/list
I am pretty happy with Emacs and the various Go packages. What would be a good reason to switch to Gogland?
[removed]
[removed]
We use Go heavily at my job. Almost all of our backend processes are written in Go. Our DevOps guys aren't using Go at the moment but that's because we're still in basically a startup phase of the project and still trying to figure out what we need. We're a trying to repair a badly broken system that was implemented before my time. Overall Go has been gaining a lot of popularity so I wouldn't consider learning it a lost cause by any means.
Why are your services panicking so much? It's a legitimate question, I've been writing Go since it's release and I can't remember the last time I had a panic outside of a test or some really prototype code I was developing on my laptop. Rather than figuring out a way to effectively manage these things, it seems like your energy is better spent stopping them from occurring in the first place. It's possible! 
I honestly just dove right in. Wanted to rewrite my entire Backed in golang. I was coming from *cough* PHP. gobyexample.com is a very useful site when I wanted a specific of the language to be explained to me
Welcome your response any time :)
My understanding is that this is a *nix limitation, not a language limitation. *nix has no good "async" story for non-socket I/O, unlike Windows. 
Whatever OS, to do anything useful there has to be some sort of system call involved. If you want to be responsive and not waste CPU (eg by doing non-blocking io in a loop 1000x/s) you have to block (eg in poll or select or something). You can either have an OS thread dedicated to the system calls, which you then have to broker with or you have to build the exact same event-driven code you would in C, the timing of which is ultimately driven by system calls rather than by go timers. I so far prefer the system-call dedicated thread approach (because I get to do all the go-y things in the main loop, then), but it's not always obvious how to do it and god help you if you don't understand the concurrency model.
I'm sharing this just because I think the Go code in this project is very snazzy. One of my favorite parts is the [`playerMove`](https://github.com/shurcooL/tictactoe/blob/1bb9d2b39738cc527aaf332e77768b6cb93693c1/cmd/tictactoe/game.go#L74-L105) function. It's written defensively to deal with any kind of [bad player](https://github.com/shurcooL/tictactoe/blob/1bb9d2b39738cc527aaf332e77768b6cb93693c1/player/bad/bad.go). But there are many other parts of it I like. I'm curious to hear what other people think of it.
May I plug a [library](https://github.com/itsmontoya/async)? :)
Nice tool :-) Its a good idea to monitor such things from a client perspective. We are currently monitoring this from a server perspective with a shellscript that logs to Splunk. Next time it comes up at work Ill look into this, because why not monitor from both client and server perspective.
Check tls.DialWithDialer which takes a normal Dialer as the first parameter. You can use a timeout here and save using another goroutine and Channels in check()
You're missing the point. Security is about layering and secure defaults. Just because the Go GC has pauses and there are other blockers, does not mean you should abandon well-known and well-tested principles. If it turns out those are predictable or open to manipulation they're no longer saving you. You're correct that you shouldn't trust some random and untested package, but that doesn't mean the existing package has satisfactory security for all applications.
I normally use a middleware that wraps the actual endpoint and catches any panics if they happen. But the first line of defense is to write code that can't panic wherever possible. Is this for cryptowatch? Good luck.
What ever happened to your ELIF blogs on gorgonia? I have a need to implement a classifier type thing but I'm completely lost. Are you still doing those?
Cool, good learning experience then. :)
I tried Gogland just the other day because I needed to get some Go done on Windows. I thought, I'm on Windows, I should do things the Windows way. After hours of swearing, I installed emacs and I'm done trying to be like the cool kids. I had a simple package. It was on git. The first option after installing Gogland was to clone something from git. Great. So I did. It didn't build. There was just no way to build it. I couldn't run it, because they only support one file to their `go run` and when I chose to build it like a package (normal humans would type "go build foo") the build configuration kept saying something like "Can't find module ''." They name things wrong. Packages might be called modules (unless modules are something else because they also ask for a package path in the build configuration). Functions they call "methods". This was completely undebuggable. So I kept trying, retrying and randomly changing things until after 7-8 attempts I managed to just randomly walk into a functioning clone of my repo which could be built. Don't ask me how, I have no idea. There was no diagnostics, nothing that indicated what was wrong with the attempts before and what went right this time. It might just be the repo I cloned manually in git bash. I was too frustrated and just wanted to get things running at that time to remember how I did it. But there's a problem. There is a generated file in this repo. That sometimes needs to be generated with `go generate`. Their build configuration has support for running go commands. So naively I just added generate in there. go generate did run successfully. There was a generated file in the filesystem at the right place. Everything was a success. Except that Gogland never saw the file. I kind of wanted to look into the file to check some details. Nope. Had to restart the whole IDE for it to detect that there was a new file there. Ok, fine. Restarting is the Windows way of dealing with problems. I'm integrating well into this culture. Let's get to work. I'm here to test my program on Windows. Let's run it. Of course it crashes. Let's run it under a debugger. The debugger doesn't work. I mean, you can click on the backtrace to get to the right place in the code, but that's it. I presume that there's supposed to be more in there because the backtrace only has a small amount of real estate in the window, while the big part of the window is reserved for some message saying it's fetching something from somewhere and some kind of progress widget (IIRC it was a spinning thing). It never did anything, so I went back to printf debugging. I actually just tried a minute ago. Now it works. I'm pretty sure I didn't change anything. Additional paper cuts. The editor is just too noisy. Every other function (which they call method) has some random spam in it telling you what the arguments are after you've written it. When typing, massive fucking tooltips show up trying to be helpful but for me they were just obscuring the code around me so I lost context. Whatever indentation rules they use are not compatible with the official indentation (I tried to be clever here and added "go fmt" to stuff to run before building, just like "go generate", but it didn't pick up that the files have changed). At random points in time, often while typing suddenly a window would pop up asking me to add some crap to my repository. The imports list is hidden for no particular reason even though they got the automatic imports wrong sometimes. I really tried to like it. It's a lightning fast compared to other similar things I've tried in the past. It looks good (other than the noisy editor which I'm pretty sure I could configure away). Surprising amount of things just worked fine. But for a long time user of the command line where I know what's happening and how to deal with problems this amount of inconvenience was just too much of a culture shock. Edit: to add some more poisitive words: their emacs keybindings are brilliant.
mirror won't fix it (go get won't work). only vpn or proxy can fix it.
[removed]
Why not wapper the goroutine to defer and recover your goroutines? I found (but not tested) this code snippet as an example: https://gist.github.com/glyn/9527053
&gt; Go is made for the command line. This however does not imply that editor or IDEs cannot be built specifically for Go.
As usual, it depends on what you are looking for. I'm personally not familiar with Emacs or the capabilities it has but I know the IDE features rather well. So speaking solely from personal experience, Gogland (or any other JetBrains IDEs) have a few nice things such as: - they are able to show you errors as you type, without having to access the disk or run external programs - their SQL database integration is top notch, and you can get autocompletion for SQL queries right in the string literals, and run them against your server. If you are using SQL for your projects, this is a very useful feature - a lot of other language integrations that can be added via plugins. For example you can add Javascript, Bash, Lua, R, Haskell, Elixir or even Rust - speaking of the plugin support, you can also have plugins for more than just other programming languages. For example there are plugins for for AWS CloudFormation, Terraform, Puppet, Vagrant, Docker and many other developer tools There might be a learning curve to becoming productive with this, of course, but I think you'll have the same for any other editor you'll choose. Hope this helps.
As others have basically sad, you're reaaaallly going to want to get familiar with channels in this kind of solution, they will give you a lot of power and safety. One major issue I see after a quick glance is that you are using a slice in a concurrent world. You will definitely need to consider a sync.Mutex if you want to continue with the slice... think about the race that happens when you add your deletion code and one job is being deleted from the slice at the same time as another job is being started with a slice index that may or may not have now changed. Also check out the context package, it's a great way to manage how and when your workers exit (assuming that they are long-living workers), but it will require an initial understanding of channels. Francesc Campoy has a great YouTube channel called JustForFunc - I highly recommend watching all of the videos as your understanding of the language allows you to. But specifically check out [Episode 9](https://www.youtube.com/watch?v=LSzR0VEraWw) and [10](https://www.youtube.com/watch?v=8M90t0KvEDY) for coverage on context.
But I get what he or she is saying in that in order to give an IDE a real crack you have to commit to it to sometime to get used to the new key bindings and environment
Yeah we do that with HTTP handlers too. I'm having trouble with a different service that has a ton of goroutines and isn't structured in such an easy way to wrap. And yeah it is. Thanks.
I tried it but scrolling files alone in vscode definitely feels smoother and faster. I don't know goglang feels slow.
In my opinion: As cheap as the `go` keyword may superficially be to use at first, it isn't _quite_ as cheap as the tutorials may indicate if you're going to be writing production code. I believe I've seen Dave Cheney make the point that you should always know how a goroutine will end, and _technically_ this is a special case of that consideration, but I'd add that you should always explicitly know what will happen if a goroutine panics, because, indeed, every time you type `go` and start a goroutine that may panic with no shielding, you are writing something that could take down your entire program. Which could be doing tens of thousands of things at a time, or more. Quite inconvenient. Just as `if err != nil { return err }` is sort of a default you can slap down and subject to modification as you discover what else you need, I often in a very similar way slap down defer func() { if r := recover(); r != nil { WhateverYouAreLoggingWith("some message for context: %v", r) } }() on _every_ goroutine, one way or another. Where possible I prefer to use a library to do it; [suture](https://github.com/thejerf/suture) for my own stuff, the HTTP library automatically handles panics in its own handlers, etc., but if I manually `go` something I need to handle it myself, too. Just as the "default error" handler is not always appropriate, neither is that snippet, and I often find myself modifying it. One of my more common use of `var` statements is to pull the scope of a variable up above that handler, so that handler has access to it to examine where the crash occurred to some extent, usually just packing it into the log statement somehow. (Doing _logic_ on what may be data in any arbitrary in-between state is one of those things that turns out to be _way_ trickier than it looks and I strongly recommend against it, but simply _logging_ the intermediate state's values can be valuable.) Another very common thing that shows up in my final handlers is channel closing, or some other mechanism for indicating that a request has failed. Otherwise it's easy to end up with crashed processes causing other processes to deadlock themselves, and before you know it you've got a cascading problem. So, basically, my proposed solution to you would be to go through every `go` statement in your code, including any libraries that may be crashing on you, and auditing that `go` statement for how the goroutine terminates, and what it does when there's a panic. The downside is that this will suck and take some time if you've built a large backlog of such things. The upside is, well... you pretty much haven't got a choice and if you want to write reliable Go code you kinda have to do it anyhow.
Good post on *_test*. I almost exclusively use the *_test* package when testing. One thing to note is that you can mix a test package and non-test package in the same folder so if you need to test some implementation details you can simply have an *internal_test.go* that doesn't use *_test*. (That doesn't work if you have circular dependencies but I don't usually find that to be a big issue in tests personally)
If you use LetsEncrypt it just emails you when the frets are about to expire. 
They removed 1 out of 4 NIST curves for use with ECDSA. NIST is the agency you're not sure if you can trust. They readded the curve later post-review. Unfortunately, x509 does not support the Ed25519 curve, so you can't avoid NIST curves there.
1 out of 4 NIST curves. It's really weird, but not that big a deal. It was latter added back. x509 doesn't support Ed25519, so you're stuck with NIST curves regardless.
My notebook has only ~50% battery time with Linux. Windows gives me double the runtime.
 Loop: for { select { case &lt;-t.C: fmt.Printf(" transferred %v / %v bytes (%.2f%%)\n", resp.BytesCompleted(), resp.Size, 100*resp.Progress()) case &lt;-resp.Done: // download is complete break Loop } } What is the "Loop:" doing there in the example code?
I used to be a fan of deferpanic for this, but they've since shut down. https://stackimpact.com/ offers monitoring for panics and I believe https://newrelic.com/golang also offers panic monitoring. For http services it's also useful to have a recovery middleware which catches panics and renders a 5xx page/api response.
https://tour.golang.org/concurrency/5
I'd like to be able to use panicwrap with sentry (https://github.com/getsentry/raven-go/issues/95), but that would probably give me most of what I'd want or expect compared to say, the global exception handler in Python.
Will test it when I am home, thanks. 
&gt; Also, while we are wishing for things: List and map comprehensions. I personally prefer something like linq fluid/java streams api than a custom syntax for iterables. It seems more readable (to me) and more flexible.
There's quite a big issue that tracks sum types. I really hope it doesn't get overlooked for 2.0 https://github.com/golang/go/issues/19412
It will gofmt or goimports on a manual save. I wish it would do so on *any* save. One of my favorite features is how Intellij will save files whenever they lose focus. I'm currently using the FileWatcher plugin to get that functionality, but having it built in would be nice so I don't have to set it up for every new project.
Fair enough, it was more in direct response to the post above me. The async library is perfect for exactly what he was describing. Essentially, it allows all thread-blocking tasks to be done on dedicated threads. So you avoid the slowdown of context switching. You know, I almost always write up full documentation in my readme's. I guess I forgot for this library. It was something we needed internally, so once it was ready - we began using it in production. I forgot to do all the ancillary tasks required to make it a complete public library, so I apologize for that. I'll get the proper documentation up sometime this upcoming work week. The go test benchmarks don't really tell the story of the performance improvements. If you test in real-world scenarios, you will find vast speed deltas. 
You are correct, I've opened up this issue here: https://youtrack.jetbrains.com/issue/GO-3865 to see if it's intended behavior or not. Thank you for bringing it up.
Thank you very much. FWIW, I've been using intellij with go since early in your original plugin's lifetime. I very much appreciate all the work you did on it.
Part 1 : http://gopherdata.io/post/deeplearning_in_go_part_1/ next part is part 4 due this friday - a simple essay on linear regressions. Parts 2, 3 are part of my Gophercon Singapore talk, so I'm delaying the publishing If you email me (my username at gmail.com) I would be able to help you personally (for free) - describe the task you want to do, there may already be a Gorgonia module for that
Thank you! I dont use any specific pattern. I just split the code to self-contained packages if it feels like the right thing to do. E.g. separate data access layer from http handlers, etc.
Centralized is better it's one point of failure controllable by your language team. Plus you can add public mirrors and rollover.
I used `select` deliberately to act on whichever channel is ready to communicate. See the link from /u/1107d7.
I know, but you don't need to break out of a select. That label is pointless.
Precisely my reasoning. Thanks for your reply!
Thanks, I'm familiar with the language.
It needs to break out of the outer loop, but a call to `break` will only break the inner `select` structure, unless a label is given. If the label is not used, the loop continues forever. See https://golang.org/ref/spec#Break_statements You might best argue your position with an example?
&gt; Yep... It's slower than Python and Perl and that's not changing any time soon. According to the information I've run into lately, CRuby performs very similarly to (or faster than) CPython. What use cases are you considering? What benchmarks are you basing your claims on?
I have some fundamental questions: you look in your database for id(s) for some username. I mean sure there can be more then one user with the same name, but then you save the message that was sent for every one of these users? Maybe Im not seeing something, but I think that isnt right? So i'd suggest instead of passing the username, pass the id to your method, then you dont need to query for the id and you dont need the for loop. (you will need to give the users unique ids anyways so you can simply use the dbID) Correct me please if that is wrong in some way :) 
You could try **go get -v &lt;package&gt;**. This would at least give you some more details and help you find your problem. 
It seems unlikely that "go get" would not clone anything to your GOPATH while also saying nothing about errors. Is there really no output? 
What was it set to? 
Bikeshed suggestion: `f, return := os.Open(filename)`.
Thank you for your kind words.
I wonder why they call it “INSERT ... SELECT,” it's just a normal `INSERT` statements with a `SELECT` subclause instead of a `VALUES` subclause.
Probably because "`INSERT` ... `SELECT`" is shorter than "A normal `INSERT` statement with a `SELECT` subclause instead of a `VALUES` subclause".
Very cool!
Thanks for pointing that out. I agree it needs to be fixed. Would you like to raise an issue or PR on GitHub? If not I'll make sure it gets addressed anyway.
Hi newbgopher, Redis is a single-threaded database, so although concurrency may help a little here, in the end you're limited by the database itself. To improve performance you need run multiple Redis processes and partition your data. Some other suggestions: 1. If you are truly inserting a range of integers, using a Lua script will likely perform far better (all the computation happens on the server it self so there's no network load) 2. You should limit the size of the pipeline and periodically execute it. Doing all 3 million in one execute is probably asking too much. 3. For the goroutines, make sure you are using a separate redis connection for each one.
Ya wot maaate?!
You might want to use an erlang-lilke supervisor: cirello.io/supervisor or https://github.com/thejerf/suture and wrap the part that calls your code with the instrumentation information.
Try this: cd $GOPATH rm -rf pkg 
No problem - this has happened to me several times so glad I could save someone else the trouble!
The package and configuration in use in the code sample is using a connection pool of 10 (default) so at least your 3rd point is covered somewhat :) 
Thanks for asking, I'll let you manage the issue. Feel free to ask if you get stuck but I'm sure you will be fine. 
&gt; Just use a parameterless for loop (for { ... }) wait wait wait, i misunderstood something here in my previous reply. I can't use break because that just breaks from the case, not the loop. Using that exiting variable is how I got around this. Is there another way? for !exiting { select { case work, ok := &lt;-workqueue: if ok { q.eventHandler(EVENT_JOB_START) callbackHandler(EVENT_JOB_START) workerDoJob(work, q) } else { done &lt;- true exiting = true } } }
Yup. I wish they fixed that. On the plus side, it lets you add to the dictionary with alt enter.
Actually they aren't separate, the salt in the struct is old code before I looked at go's hashing func. Everything is squeaky clean don't worry :) 
Thank you this looks prefect :) 
First for me. Strange, as I've been kicking around from 1.2 on...
In addition to the single-threaded nature of redis producing a bottleneck ( even with proper batching redis will only push 60-400k ops per second ). It's important to consider the number of bytes on the network - 3 million ints has a minimum overhead of 12 MB prior to serialization and connection overhead. A stock linux host will also consume a minimum of 4KB ram per connection. Depending on your needs for this data you may want to consider serializing the 3 million ints into a single record. This would avoid most of the per op overhead of redis, and with some cleverness will still allow per record access using the get range command. 
I'm looking forward to trying this out. Thanks for sharing!
I love watching the development of DGraph. I've tested it a lot with various datasets and I had to take a break working with the datastore. I might have to take another look. I highly recommend it and the team is very good. If you have issues, they're willing to help you at every turn.
This actually made me wonder why is there no bash/zsh completion on the go tool itself. (I installed it through Homebrew.)
*Serious question:* How do you know you are not getting panics in production? 
&gt; I installed 1.8.1 via &gt; &gt; tar -C /usr/local -xzf go1.8.1.linux-amd64.tar.gz Did you also do `rm -rf /usr/local/go` before untarring Go 1.8.1? It's important to do that first, otherwise files from older versions that have been removed in newer versions will stick around and have a chance of causing issues. To have a clean Go setup, you can't rely on overwriting files only.
Note that command extracted directly on top of your old install, you probably want to mv or rm -rf the old goroot in the future because it could break if files are moved around.
Long, long ago, I ventured out from the dynamic types of Visual Basic 6 to the world of strictly statically typed languages. Figuring out how to print a simple string from different data sources was a nightmare. Trying to convert all the little bits and pieces to strings manually made perfect sense before I knew there was a better way. &gt; Here if Len args != 2 you could log.fatal with no else block, added benefit is log.Fatal includes a non zero exit status. See, that's the kind of thing I had no idea about! It makes perfect sense now that you mentioned it, but I wouldn't have even known to look for a simpler way. This is very good advice.
Because it's platform specific? 
Could you give an example?
The links that others have given here are really good, one of my favorites is Go By Example. In terms of video resources if you are willing to spend a few $'s, then I highly recommend:Introduction to Go Programming From Hello World to Writing Highly Concurrent Programs By John Graham-Cumming It's really well done, I find the way the material is presented is very much to my taste. In addition to that it's also worth checking out videos on Youtube from guys like: Rob Pike, Brad Fitzpatrick, and the afore mentioned John Graham-Cumming. If you already know how to program in other languages don't skip ahead in Go, go through each exercise and learn the Go way of doing things. The core things to wrap your head around I think would be: Interfaces and how powerful they can be. Channels, when to use and when not to. (easy to turn every problem into a nail with this hammer) Remember too that Go is super awesome but it's not the be all end all, there are other languages that are suited for particular tasks. Overall Go is very flexible though. All the best and enjoy! 
Okay! I did a lot of improvement, cleanup, etc. It is officially working well and no obvious bugs. https://github.com/thegtproject/jobqueue What you think?
The source? https://github.com/posener/complete/blob/master/cmd/install/zsh.go
Haven't deeply read the code yet. Do migrations happen in isolated transactions? Also apart from env value look up, are there any other differences to https://github.com/rubenv/sql-migrate? Does it use gorm under it?
If my program panics it typically crashes. When my program crashes it's picked up by my supervisor (typically runit) and my monitoring. If it's a contained panic e.g. an HTTP handler it's picked up in the logs which I see. edit: And the class of things that can induce panics is not particularly large. Nil pointers and slice out-of-bounds errors account for the majority, and once you train your eyes a little bit it's easy to spot the conditions where those things might occur on a skim-through.
Every Go data structure is subject to race conditions in its scope. I say let the caller control the scope and do their own locking outside of your functions. Your map will be no more susceptible than any other Go data structure. Its not like slices, maps or records have concurrency control built in. Typically callers will have some set of data structures they will want to have exclusive access to while they manipulate your map...easier for them to take one big lock for all of these instead of having N different packages creating M different locks over and over There are very few cases I want libraries having an opinion on concurrency...mostly those where an external resource is being accessed (a db, webserver etc)
Oh I should have specified this is my design for the control structure (a means to an end) and `doSomeWork()` does involve I/O. 
&gt; no obvious bugs time to write some tests :) I don't think Queue.Items should be published, it should never be directly accessed outside of the package. Also, you currently expect the package consumer to understand that they have to create a Queue struct with a specified value of NumWorkers (or set it after creation like in your example). It is better to offer a reasonable default value, and a New() function at the package level that will create the struct and return it.
I don't think anyone thinks that errors don't matter. People may be lazy at times but that doesn't mean they intrinsically think error handling is unimportant. Human behaviour tends to be that when you provide people with a shortcut to handle "all cases" they tend to take the easy route. The problem with being able to say "catch {/*show exception in modal*/}", whether it's right or not, gives some people a false sense of security in believing that they are actually error handling rather than thinking about what a more appropriate course of action should be. As it's little more than a value in Go, I've found that it forces a person into a habit of thinking a little more about whether they should suppress, panic(), or deal with it in another way.
Cheers. I've added some sanitisation, borrowing a lot from http.Dir. https://github.com/cavaliercoder/grab/commit/52e6cfcdbbd62a06ed46b237ef47c1767c78e7cb The tests confirm that it's more difficult (I won't say impossible) to break out of the desired target directory. Please let me know if you spot any further improvements.
Thanks all for the replies. Before I ask others to review my code I think I had better review the common code review comments first. I'm sure I'll get more out of it if I fix up any obvious issues first.
i think the other posters answered clearer, but to answer your specific question i would think you need 3 clients (or 3 insert-interfaces), so even though may not be able to with single-threaded redis, you would try something like: func makeandinsert(array* []int, index int) { client := redis.newClient(...) for i,v := range array[index] { client.insert(v) //or whatever } } func main() { elements := ... go makeandinsert(&amp;elements, 0) go makeandinsert(&amp;elements, 1) go makeandinsert(&amp;elements, 2) } its just a different way of doing it multi-threaded (aka refactoring) 
I can understand your preference for Erlang, but simply stating golang to be less real world useful will not move me towards your point of view. Unfortunately, the code I have written may not be shared due to contractual agreements, but suffice to say I can state golang is a great deal more maintainable than c/c++ or java ever was. It doesn't mean I don't find those languages useless, but I do prefer using golang over the mentioned c c++ and java because it is more fun and has not let me down for real world problems put on my plate i.e. calling campaign, web server, database storage, storage firmware construction, parallelizing exports/imports of data. There are certain apis I wish would exist such as orangefs and hsa for golang, but none of my clients past and present are demanding them, but I foresee greater popularity for such bindings.
It really doesn't matter how many different connections you add. Redis literally only does one thing at a time. Your total time will be the sum of all three, the best you can do is eliminate a couple round trips by concurrently sending the data. If your long pole is Redis inserting those huge lists, you'll be waiting regardless.
Good first pass, you did make it more difficult for a operating system which uses 0x2f as a path separator- but left it vulnerable to 0x5c (windows primarily) because you are checking for 0x2f slashes during your sanitize step instead of the filepath.Separator and using path.Clean() instead of filepath.Clean which will ignore 0x5c. Since you are not ultimately calling a sub-directory and filepath.Base is guaranteed to return a element name with no path separator you could simply call that and omit all other steps, failing if any of the following is true: * filename is empty or . or .. * filename[0] == filepath.Separator Filepath.Base allows a filename consisting of only dots, which is a valid path element (parent) as well as consisting of only dots. I wouldn't allow either case but you want to prevent "..". Also I just noticed also you should probably replace test.com everywhere in unit tests with example.com (rfc2606), icann permits the registration and transfer of ownership for test.com.
&gt; I don't think anyone thinks that errors don't matter. People may be lazy at times but that doesn't mean they intrinsically think error handling is unimportant. We clearly have had pretty different experiences in this regard. &gt; Human behaviour tends to be that when you provide people with a shortcut to handle "all cases" they tend to take the easy route. Agreed! This is why Go's approach is not so great. It's very easy to just *not* do the error checking, or just ignore it and accidentally/incorrectly try to use a garbage return value because you didn't copy-paste `if (err != nil)` or whatever again. &gt; As it's little more than a value in Go, I've found that it forces a person into a habit of thinking a little more about whether they should suppress, panic(), or deal with it in another way. Agreed as well! Which is why they should have just gone with an `Maybe`/`Option` type instead... except that they can't because that would require parametric polymorphism... which Go also can't do. Anyway, my point was that it's better than the usual "ignore everything all the time" approach, but given that Go seems to want to care about errors, it's frustrating that it did so little to accomodate handling them. Also, how is `panic()` not exactly like using the same generic `throw Exception("Oh balls!")` everywhere? At least with Exceptions you can have more than one type, no?
Whatever object you pass to panic() will be passed back when you call recover() so you can have any type you like. It doesn't even need to implement the Error interface.
Fair enough. 
No. The whole point of the vendor directory is "what happens if the dependency I depend on disappears". Though I did read that the rules are different for libraries vs projects.
I can't tell if this is brilliant for insane. :) Seriously, I don't see any obvious problems here, other than the fact that this is subtle code which is not obviously correct (see: http://wiki.c2.com/?TwoWaysToDesign) Before this was production-ready, it would need some heavy duty test code, which actually triggers races, and then which passes with "go test -race". It would also need better documentation explaining what problem you are trying to solve, and why this non-standard setup is the solution. Your future self and or colleagues will thank you. It has happened for me that while trying to explain and measure and justify why I'm doing something tricky that I prove to myself it would be better to just junk the entire thing. Going through that process is valuable no matter what the outcome, if you keep the tricky code or if you chuck it. Good luck! -jeff
There is no right answer. Decide for yourself. https://github.com/golang/dep/blob/master/FAQ.md#should-i-commit-my-vendor-directory
&gt; It means that everybody who wants to build your repo needs to also have glide installed. I don't think that's a good assumption. It's not an abnormal assumption across the package management ecosystem. Whether it's one you want to make/enforce depends on your project and audience.
I'll echo something another person has said. It depends on what you're building. I have a couple of projects where they are committed, and another where they are not. The ones were they are committed are projects where I want the user to still be able to _just_ run `$ go get ...` to install it. If that weren't the case, I'd have to start distributing pre-compiled binaries. In libraries however, I may not choose to commit them... again, it depends. You have to judge it a bit on a case-by-case basis.
Very nice. Self-completing feature using `CLI.AddFlags()` is the cherry on top.
The github repo has a very interesting logo and also comparison table against BoltDB which I find a much better comparison than to RocksDB https://github.com/dgraph-io/badger
You should always have a backup. 
Generally they don't. `go get` walks and pulls dependencies as well, just not into vendor subfiolder but onto GOPATH. `godep` used to rewrite imports, which would break `go get`. Not anymore.
God vendoring is a mess
Hello, whenever I see some impressive benchmarks first thing I do is search for fsync because it's really the single most impactful design consideration. What is your fsync policy? At a glance it appears you have no fsync policy [at all](https://github.com/dgraph-io/badger/blob/0c0bc0853b9b8a0598dd940fdabab61474c96cbb/badger/kv_test.go#L41) by default. The reason tests there are flakey without sync calls is because data is not reliable written to the system. I'm not familiar with rocksdb design, but being it's been heavily engineered by Facebook they call fsync or fdatasync or a application space buffer and direct i/o. They likely have some algorithm that offsets as much of the cost as possible based on some heuristics of the system, or maybe it's as simple as a interval. But you really don't want to go forever without calling fsync, or data loss will occur for users. That is okay in some cases, but probably should heavily be documented. All and all it's an impressive amount of research and surely a solid implementation. My apologizes in advance if I missed your sync policy.
The oh-my-zsh plugin is great.
If you are programming professionally, I suggest having a copy of all imports in at least one place in house. Having them checked in is a good way to meet that criterion. This prevents against a lot of scenarios that may individually be low probability, but together add up to something that probably will eventually happen if you continue to grow. Note that I'm not advocating directly for "always checking in vendor"... I'm specifically referring to having a copy internally. For instance, if you have an internal library that lives on your local source control system, there's obviously not much benefit to having more copies of that just hanging out elsewhere in your system. As a rule I also try to strive for "I ought to be able to build all projects from scratch without hitting the internet". Again, all sorts of low-probability events (internet is down and you need to rebuild something anyhow, someone takes a project down, someone force-pushes and whacks the commit you used to be able to get, you don't have proper authentication on some internet download and you download malicious code, or someone accidentally set something to "Take latest" version and you get malicious code, etc etc) that are just easier to avoid and deal with if you've got the resources internally.
Sync policy is there to not lose data that has been successfully stored in a correctly closed db? That would be the most idiotic setting in the history of bad storage systems if true.
Thanks for pointing that out. I updated the readme. Also, can you elaborate on why you wouldn't recommend anyone instantiating a cipher directly in a project? I assume you mean that it is easy for a novice in the field to make a mistake that could have far reaching consequences. 
(totally off-topic) Another Go developer that likes Stardew Valley. Time to start a club :D
Yes - exactly that. It's also about what your goal is - to build cryptographic protocols, or to build an application that use them? If you instantiate an encryption cipher, you're suddenly responsible for a million decisions about the protocol. What mode will the cipher run in? Where does the key come from? If dynamic, how is the handshake performed? Are they stored? Do the keys ratchet? What mechanism will you use for authentication? Where do *those* keys come from? In your specific code, you're implementing a KMAC by prepending a key to payload you want to authenticate, and hash it with SHA-3/Keccak. Had SHA2 incorrectly been used, then it would no longer be safe, and such a defective construct is unfortunately not uncommon. You also mention the blowfish cipher, an encryption cipher not considered secure anymore, with its author not recommending its use. If you just need two parties to talk, TLS is a much safer bet, despite its defects. If you need to encrypt something with symmetric encryption, NaCl's secretbox is great solution.
Soothing game, soothing language :)
Have you understood the post? Combine multiple types of databases and reduce them to the lowest common denominator.
Since Google is a US company they literally have no choice in the matter. Sad for people in the E/T 5 countries, but that's the way it is. Violating US embargoes can result in massive fines and up to 10 years in prison.
Looks nice, is this strictly intended to manage Vault secrets? I ask this because we're currently looking at products (sadly I fail to find any decent opensource solutions for this) to manage passwords for humans in a team context. I've thought about writing a frontend with Vault as backend, without exposing the technical Vault details, but I'm no frontend dev at all...
 ...yet.
Yes, this strictly works with vault. A lot of the backend is built like a wrapper around vault's golang api. This simplifies things for me, since I can rely on vault for both credential verification and storage. Team context operational secrets are vault's specialty. I would recommend taking vault for a spin (with or without goldfish as UI) and see how you like it. If you aren't comfortable with the base vault API administration, it's a moot point anyway :)
I've used Vue a little bit, but the way that you're doing it is a lot different from how I understood it to work. I'm much more of a back-end developer though. Would you mind explaining, or pointing me to some docs, on using the .vue files / templates? It also looks like you're exporting the Vues in these type of blocks export default { data () { return { csrf: '', type: 'Token' which seems pretty neat, but also different from how the docs for Vue.js read. What's the reason for this structure?
I'm right now going through a Vue tutorial and then planning to use it with my Go project. This will probably be a huge help for me to reference, thanks!!
Strangely, the side panel doesn't show for me on Safari (10.0.3). It shows up fine on Chrome.
Yes. A complete nitpick over http status codes is on my to-do list. It's not as trivial as it seems, since vault api returns error for both permission denied and internal errors, so I'll have to comb through each error detail.
The reason is pretty straight forward, it allows you to have all your business, view, and styling, logic in one self-contained place. It reduces the number of directories and files in your project. It also provides a single "build story" for your project meaning you just add vue-loader to webpack and everything gets taken care of*. In practice many editors have problems properly highlighting the polyglot syntax of Vue files. Furthermore things like adding support for Pug templating instead of HTML can be a headache. The community for Vue is small enough to the point where nobody may have tried your particular setup and you'll have to do it yourself which is a huge misnomer for some. It also leads to the problem of incompatibility when you may choose not to use vue-templating but want to pull in third party projects which do, or vice versa. All in all I think the Vue templating is ok but should not have been made into a psuedo standard for Vue projects like it has been...
Centralized is more vulnerable.
This is then called "Enterprise Software" ;-(
For my purpose Enterprise software like Spring provides endless supply of lovely class/method/variable names. 
&gt; Have you understood the post? No, it's very confusing actually because of the way it is written and because of the lack of formatting. Judging by the lack of responses I think the rest think the same. Have you understood my comment? 
Why not add tooling to SML instead? Basically all of the issues people have with go are already solved in SML and have been for 30+ years. The reason that generics are problematic in go is precisely because all the advances in type systems were ignored. I like a lot of what go has become, but that doesn't absolve it of its issues. I disagree with the claims made against functional languages being hard. Sure, if you want to use very complex functional ideas everywhere, you can (in fact, you can technically use a lot of those same ideas in go). That doesn't mean the are the definition of what functional should be. Remove functional purity and two thirds or more of the complexity simply vanishes. Remove laziness and a bunch more drops away. Allow a couple primitive constructs in addition to things like tail recursion and we're now basically procedural with an upside. While it's true that you can still abuse some of these things, it's also true that you can write "enterprise" software in any language. When you mend the two paradigms together, you keep the easy and fast parts of procedural code, but you gain access to superior means of abstraction that functional languages offer. To directly address the idea of varying skill and ability. One of the big reasons that SML hasn't added features seems to be because so many schools want a simpler language for teaching (one reason ocaml is a thing). If a programmer is so unskilled that they cannot learn SML in a couple of weeks, I'm not sure that they meet the minimum bar that most companies (including Google) set when hiring. 
Plugin loading/unloading, and generics! Nobody seems to be talking about plugins. In C world we'd use `dlopen()` and `dlclose()` for an extensible system, in Java we can simply load the class... Go recently has made a plugin build mode, but it can't be unloaded once there. :( Though I understand this is _by design_, it greatly complicates the lives of us who are trying to build a software with loadable functionalities.
yes! The simplest thing to do is add your windows specific code to a file called mystuff_windows.go see this great article: https://dave.cheney.net/2013/10/12/how-to-use-conditional-compilation-with-the-go-build-tool
As you pointed out, the Go APIs are currently more geared towards inference or constructing small graphs for pre-processing (like in the label image example). However, they are intended to not segfault :). If you do have a case where it segfaults instead of providing a graceful error, I'd encourage you to file an issue at https://github.com/tensorflow/tensorflow/issues/new
Only DefaultOptions are exposed: https://godoc.org/github.com/dgraph-io/badger/badger Note that when SyncWrites = false, that doesn't mean data is in memory. It just means we've left it to the filesystem to decide when to flush to disk.
Sign me up
Your locked Boolean is a race condition
https://media2.giphy.com/media/gOkawaguYNiSI/giphy.gif
Aye, the clear text search through their golang API errors was my biggest annoyance about their client tbh. I ended up ripping out their API and calling it myself to get the correct status codes. 
 fmt.Printf("%x\n", md5.Sum([]byte("ab")))
This is one my first forrays into contributing to open source. I definitely could use your help. Things that need work are better security (DDOS protection &amp; encryption come to mind), UI improvements, and plenty more P.S. check out https://onetimesecret.com/
(Badger author) Our fsync policy is simple. If you set SyncWrites, then the writes to write-ahead log (value log) would be synced to disk before being applied to LSM tree; and the call returned back to user. If SyncWrites is set to false, then we would only write value to value log, if it exceeds a certain threshold (set to 20 bytes). Otherwise, it would be applied directly to LSM tree. As you can imagine, doing async writes is faster, but comes at the cost that you might lose your changes in case of crash. However, if there's no crash, and you do a clean exit by calling Close(), you won't lose your data. All of this is as it should be. Let us know if you'd like to see something different and why.
I don't want to print it. I want to do something with it, and I don't think (I could be wrong) that fmt.Sptrintf is as fast as EncodeToString
Opened: https://github.com/tensorflow/tensorflow/issues/9931
It is not a stupid question, especially since the existing answers to it are out of date. One year ago I mixed Go and Java by having them talk via protobufs between them. It was yucky. I am also interested in knowing the current answer to this today. -jeff
I don't recall who talked about this but someone on the Go team did muse about this--something for very small machines indeed--but it would be far in the future since much fewer people would use it, the technical complexity of maintaining such a different edition, and all the language features that would need to be added for things such as manual memory management. Some of the ease of Go is from the carefully selected default decisions that fill most needs. Go and Rust are good for different things, but both overlap enough that a GC-less version of Go would only add a few more cases (Arduinos, true RTOS, manufacturing controls, etc). Another issue is that tutorials and documentation would need more caveats and clarification. That might beg us wait for a much larger Go marketshare before adding and noise via Go-slim.
I really like the focus on simplicity! You clearly have spent some time thinking about developer experience as whole, like loading environment variables, creating databases, using it without installing Go, switching between dev / test databases... While not very revolutionary as single features, in combination it makes a rather compelling, simple to use project. Recently I have went through the pain of picking a schema migration tool in Go, and I was missing exactly this: simple, single binary, with DB creation and easy switching between environments. Thank you for implementing it and making it available as open source, I am looking forward to use it in my current project! 
It seems to me, the real problem is the log.Fatal calls in GetCommand. I think the whole thing reads better as [this code](https://play.golang.org/p/AJF32BxLg5). 
Ahh, that's a lot nicer, thanks! What does the log.fatal have to do with it though? I did mean to remove that though, forgot I left it in.
Does the app have the option to be distributed as a single binary?
log.Fatal will quit the program.
Right, but why does that mean the type switch in main fails? It'll only quit on invalid input, right?
tried my request is already with the same headers as in the browser, but just in case I tried this too.. same redirect. The issue is with server check if my service have JS which it defiantly dont have... Im trying to use JS interpreter and create a request with XMLHttpRequest(), maybe get the response from the target this way...
&gt; what if all the good qualities like no GC, automatic memory management, minimal runtime and all other goodies that rust has, will be ported to go? Then you'd have rust. Seems a lot of work compared to just use rust from the start. The complexity of rust isn't accidental, it is problem-inherent and due to all the "goodies" you mentioned. You can't just take the good things of both sides of a tradeoff; it wouldn't be a tradeoff then. You have to weigh both sides and accept the downsides of your choice to get the upsides. There is no such thing as a free lunch.
It's always possible to do something in a single line. Whether it's possible to do it in a single statement, or expression is a different question. But it also seems a misguided goal to me. "why not" is not a valid reason when asking how to do something. If you think your two lines aren't readable enough, make a function `hexMD5Sum` or whatever and use that. Purely minimizing the number of lines is not a contest that go is designed to win at.
From Wikipedia: &gt; Weakness and successors &gt; &gt; Blowfish's use of a 64-bit block size (as opposed to e.g. AES's 128-bit block size) makes it vulnerable to birthday attacks, particularly in &gt; contexts like HTTPS. In 2016, the SWEET32 attack demonstrated how to leverage birthday attacks to perform plaintext recovery (i.e. &gt; decrypting ciphertext) against ciphers with a 64-bit block size such as Blowfish.[9] &gt; &gt; A reduced-round variant of Blowfish is known to be susceptible to known-plaintext attacks on reflectively weak keys. Blowfish &gt; implementations use 16 rounds of encryption, and are not susceptible to this attack.[10][11] Blowfish users are encouraged by Bruce &gt; Schneier, Blowfish's creator, to use the more modern and computationally efficient alternative Twofish. He is quoted in 2007 as saying: &gt; &gt;&gt;At this point, though, I'm amazed it's still being used. If people ask, I recommend Twofish instead.[12] &gt;&gt; &gt;&gt;— Bruce Schneier, Blowfish's creator, in 2007 &gt; &gt; The FAQ for GnuPG (which features Blowfish as one of its algorithms) recommends that Blowfish should not be used to encrypt files that &gt; are larger than 4 Gb because of its small 64-bit block size.[13] The block-size is the primary weak spot here. We don't usually wait until a fast and practical attack has been mounted before we label a primitive as unwise to use, but do it when it no longer seems sensible to use. Blowfish is ancient, and when the author points you in a different direction, stating 10 years ago that he was "amazed it's still being used", then it's definitely time. SHA-2 doesn't have any practical attacks either, and yet you chose SHA-3 in a KMAC configuration over SHA-2 in a HMAC configuration. If you use a crypto primitive, you are designing the crypto protocol that describes how they are used. In your specific case, assuming you manage the key responsibly, then your authentication mechanism using KMAC should hold just fine.
Can you keep a dirty bit in the LSM tree indicating if the entry is synced to the log? You write to the log without syncing, you write to the LSM, setting the dirty flag, you later sync the log then remove the dirty flag for the entries concerned. That way you could have best of both worlds and when recreating the DB in case of a crash you would discard the dirty ones. You would still loose data in case of a crash but at least the LSM won't be corrupt, which is good for a cache system. EDIT: I don't know how fsync works and if you can know when the file is actually synced so I may be talking shit right now, but it's just an idea
I love their blog post about GRPC! https://spatialos.improbable.io/games/grpc-web-moving-past-restjson-towards-type-safe-web-apis Have you had any problems with this yet? Any limitations you encountered? Are you using this in production? I love strongly typed languages, so the combination of backend (go) frontend (typescript) and a strongly typed api (grpc) sounds pretty amazing.. Thanks for the starter kit! I'll definitely check this out. 
&gt; correct requests what do you mean "correct requests"? as far as headers, url, method, body (in this case its a GET request so no body), query parms? thats what i had in mind and all of those are exactly like the request from the browser... do you thinks there are other request properties I should think of?
They're called [build constraints](https://golang.org/pkg/go/build/#hdr-Build_Constraints).
Solid article. I heartily second the condemnation of the third way (which is just to make your signature ...interface{} -- don't do that! :). 
Feels like a bit of an over-reaction to me. You could use `*CoffeeOptions` instead of `interface{}` there, and maybe not run around like a headless chicken. allCoffees := Brew( ALargeCoffee(), ALargeCoffee(), ForTheOffice(6), AnEspresso(3), ) Also, this is great way for people to not take you seriously: &gt; feel like arguing your point in the comments below, don’t bother as I have no intention of responding-to or approving your idiotic view. Classy. Edit: This might be more useful (and not condescending) reading for many: https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis
How curious that I read that yesterday… Functional options: one of Go's own "design patterns". 😉
That's probably a slight misunderstanding there. When I said `opts ...interface{}` I'm referring to the fact that in the method body they then have type assertions like this - ``` if shots, ok := opts[0].(int); ok { // Use shots } ``` Hence why I refer it to as the "JavaScript" way because it's a pattern that's commonly used there.
I'm sleep deprived right now, but what's your point? I don't get it...?
It's called [Covarience](https://en.m.wikipedia.org/wiki/Covariance_and_contravariance_(computer_science\)), and yes go doesn't have it. 
https://golang.org/pkg/math/big/
What are you intending to do with this number?
&gt; If CRC32 would be as easy, I'd use it instead What's hard about using [CRC](https://golang.org/pkg/hash/crc32/)?
The way code has to handle and call for example func() [20]int is different than how it has to handle and call func() interface{} The amount and type of data being returned is different. Code that is expecting an interface{} cannot just be straight-up handed a [20]int, it needs some wrapping to happen. You could imagine a language that does something fancy and automatically creates a small adapter function for you when you assign the former to the latter, but Go doesn't try to be fancy, it tries to be simple. Of course, you can always do it yourself easily: func() interface{} { return someConcreteFunc() } 
It may be simpler but it is not clearer. The two lines perform two different tasks: The first one does an md5 calculation, the second one turns the result into textual output. Clear separation of concerns. The combined line mingles these two logically separate steps together. Simpler maybe, as it saves an intermediate value, but less clear IMO. And I don't see a problem with having an intermediate value. 
https://github.com/sajattack/go-euler/blob/master/08/main.go
I think you have a typo which might confuse some people: // FillTemplate will accept a template and a slice of name-values and // replace the named tokens with the given values and return the result. func ParseTemplate(template string, tokens map[string]interface{}) string { }
Where can I find more information about GC improvements in Go 1.9? Especially about handling large heaps.
The use is a dependency, you don't get away from that in either method. What you don't get is the potential of two embedded types conflicting with each other (diamond inheritance etc) or changing the way the embedded object behaves because of virtual functions being overriden etc.
Not doubting you're correct, but could you explain or provide a link to why dep is better than godep?
Citation needed. How 'buggy' is docker? Compared to what?
Based on the WiscKey paper, However, WiscKey provides the same crash guarantees by using an interesting property of modern file systems (such as ext4, btrfs, and xfs). Consider a file that contains the sequence of bytes�b1b2b3...bn�, and the user appends the sequence �bn+1bn+2bn+3...bn+m� to it. If a crash happens, after file-system recovery in modern file systems, the file will be observed to contain the sequence of bytes �b1b2b3...bnbn+1bn+2bn+3...bn+x� ∃ x&lt;m, i.e., only some prefix of the appended bytes will be added to the end of the file during file-system recovery [45]. It is not possible for random bytes or a non-prefix subset of the appended bytes to be added to the file. Since values are appended sequentially to the end of the vLog file in WiscKey, the aforementioned property conveniently translates as follows: if a value X in the vLog is lost in a crash, all future values (inserted after X) are lost too. --- If you have ideas about how to improve upon this, feel free to email me, or raise a Github issue. We can discuss what's the best thing to do here would be.
The dirty bit wouldn't work. LSM trees can't modify what's already written. They just have to pile-on new writes on top, which would eventually overwrite the older values, during compactions. Also, Badger is designed to deal with crashes. In a crash, it won't become corrupt, it would only lose recent data, if user is doing async writes. OTOH, if a user is doing sync writes, nothing would be lost, that is guaranteed by design. As a general rule of thumb, if a user is worried about crashes, they should be doing SyncWrites (we do them in Dgraph), and just use a large enough batch, so as to amortize the cost of a sync.
My mom didn't refuse to get me vaccinated just for me to go and ruin it now.
thank you &lt;3! we know how crucial this project is to the community. emphasizing inclusion and clear communication throughout the process is one way we keep that front and center. if it sets an example for other parts of the community...well, all the better for all of us :D
Rust could have been better if it was not designed by a committee: great ideas, so-so execution. With a Go team's more systematic approach, some of these features could be done better. Still, Go's concurrency does not seem to jive with Rust's borrow system. That's why Rust is unlikely to ever get nice concurrency as part of the language and will have to live with macro and wrappers in crates. 
Very interesting read! Just two nitpicks (it's early in the morning, and I had only five hours of sleep, so I am in nitpick mode :): 1. Third code block - possible typo: should the struct named `CoffeeOptions` be rather named `CoffeeOrder`? 2. The very last sentence says: &gt; NEVER USE VARIADIC FUNCTIONS FOR OVERLOADING I think the problem of the "JavaScript" way is not that the function is variadic, but rather that it uses an empty interface{}. UPDATE: Apparently I missed the point you are making about variadic functions. Further up the text, you explain the problem: &gt; Misuse of variadic functions – in Go they are intended to be used for an arbitrary number of arguments, not an arbitrary number of signatures! Absolutely right. Variadic functions without `interface{}` are not the problem.
I'm not an expert in Go, but I create a temp variable when: 1. You use it in two places. 2. You have no choice (your first function returns two variables, so you can't nest. So Atoi can't be nested directly). 3. You have deep nesting. So a(b(c(d),f(g),h(i,j))) (did I match the parentheses? ) is much less clear than temp1 := c(d) temp2 := f(g) temp3 := h(i,j) temp4 := b(temp1,temp2,temp3) a (temp4) but a := XtoA(CtoX(c)) is much clearer than temp := CtoX(c) a := XtoA(temp) It could be that I'll have no choice here because of language semantics, but such a short function chain doesn't seem to merit a temp variable. Maybe I'll ask it as an independent question on the Reddit.
Yeah you're exactly right. I'm not against variadic functions at all. I'm against using them as a means to method overload by using interface{} parameters. The issue I've observed in a few posts and GitHub projects is using it in this way which is moving compile-time type checking (one of the big selling points of Go) into run-time. If the only reason to do this is to make up for a lack of method overloading (the focus of my post), then I don't believe this is a sufficient reason to potentially introduce run-time errors.
Cool, thanks for posting!
Oh, if you've thought about it and decided that you require certain file systems to have this work reliably, fair enough. It is a massive pain in the ass to get this right in the general case and probably even impossible. I have never actually tried to get it right without checksums (and an ability to replicate the data from multiple sources if the checksums fail). The latest interesting paper about it is: https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-pillai.pdf and it shares a big portion of the authors with the WiscKey paper, so I guess just doing what they say should be done will be good enough. But it would be nice to see those assumptions documented somewhere. This will not hold on OSX, nor FFS without soft updates (with soft updates it probably will).
I think rust is pretty great. I just don't think other languages need to become rust. &gt; That's why Rust is unlikely to ever get nice concurrency as part of the language and will have to live with macro and wrappers in crates. Rust *had* a nice concurrency system, but it was removed to keep the runtime down and stay with zero-cost abstractions, AIUI. Y'know, those "goodies" of rust, that OP is referring to.
I understand your reasoning. But the one-liner you came up with *does* have 4 levels of parentheses, so your point 3 seems to apply here. But anyway, try to avoid micro-optimization, you just lose time and gain almost nothing. Two lines vs one line; a temp var vs no temp var - this is far less important than finally shipping code that works (and is maintainable, of course).
Looks cool to me though 2 of the gophers look the same. Either all of them should look the same or there should be 3 different ones. I am also glad you used Renee's artwork. I've seen some horribly drawn gophers and not because of bad drawn quality but because some people just don't get it. Also I'd like to ask, what is the deal with those spinners? I see them everywhere on the net lately.
This is pretty good stuff. We're doing a very similar setup where I work and it works wonders! Thank you
Wow thanks ! Will try it for sure :)
For inspiration have a look at [cfbypass](https://github.com/laplaceon/cfbypass) it bypasses cloudflare's JS check.
1) Peaks on our system have been in the 200k requests / 5 minutes. Due to smoothing req/s may exceed 1k req/s. Current rate is about 1/5th that, but it's off-season for online media, people are going on end of spring/summer vacations already :). This setup is on a pretty-much idle state even at high peaks, benchmarks put us somewhere up to 20k req/s peak from HTTP edge to SQL, if we wanted to go beyond that we'd have to shard some data or replace MySQL. Redis can go faster, doesn't even saturate a single CPU core. 2) We actually log much more than 20k r/s over the system, as we're using it also for internal instrumentation, but this doesn't hit the HTTP layer but goes directly to Redis, multiple times from a single pageload (ie, sql query log with timings and such). So, we use the system for more than just click tracking. We have about 6 distinct schemas that log more/different data (ie, we log video tracking data which has things like number of seconds played, pauses, etc., per session, api, front-end, ...). At some point it's basically just a JSON mapped to an SQL table. Adding/removing fields can be done online (redis queues up if mysql is unavailable, much like scratchd does for you as I understand). We're also using this to split similar requests between different sub-groups, to avoid bias like the latency increase which you experienced and mentioned. We actually can split it up into about 50 parts due to the way the app is structured, but mostly we don't drill down unless there's a technical reason to do so (ie, support ticket that XY part of app is experiencing performance issues). Too big of a code base to manage it all efectively :) 3) We're not using pub/sub, but we did apply several tricks to get the high insert volume from MySQL and still rely on auto_increments to process database data further (map/reduce jobs). Keep in mind this is also with a few years of previous experience with MySQL, so we avoided a lot of pitfalls that have to do with concurrent r/w access and such. Perconas MySQL blog is mandatory reading - https://www.percona.com/blog/ (and of course, we use the Percona build of MySQL as well). I hope I didn't go into too much details, I guess I'm just enjoying the comparison and how different decisions don't necessarily mean one of them is wrong. Ingenuity is solving complex problems with simple approaches, and it seems we both managed to do that :) Edit: fixed 200k to 20k in point 2. 200k requests/s would be great, alas, false.
Uh? Why not BrewALargeCoffee() and BrewForTheOffice()? See [os.Open](https://golang.org/pkg/os/#Open) vs. [os.OpenFile](https://golang.org/pkg/os/#OpenFile) vs. [os.NewFile](https://golang.org/pkg/os/#Open) in the stdlib. Or did I miss something in the article?
I think its mostly about the fact that dep will be the 'blessed' dependency management solution going forward, and as long as they don't screw it up (which they seem to be doing a great job so far of keeping things transparent and making sane choices), people will continue to rally around and support it going forward.
One clarification - escape analysis is done at compile time. Otherwise, you nailed it.
what would be your reason for choosing glide over godep? 
im hoping there will be swag on location, since I wasn't able to convince my work to cover the cost of a sweatshirt in addition to travel/ticket/workshop costs
Still don't get it. AFAIU, the "generic overloading pattern" in Go is "rename your method/function", done. Again - see the example from stdlib I linked to. Those 3 would most probably be overloads of a single method in C#, in Go stdlib they just are given a different name. 
With respect, the original post is concise and accessible enough that a TLDR isn't really necessary. People should just read the post.
Nice. Some useful stuff in there!
Can you elaborate on what you mean by "set the problem content type for the form"? Sorry, I'm quite the noob. 
I usually do the opposite, eg: s,err := foo() str = s Is one more idiomatic than the other? Pardon for formatting, on phone
"Safely" here is underspecified, because that depends on a lot of things about the file. I have no idea what Go may guarantee here. In general I suggest that rather than parsing through code for behavior that may change anyhow that you correctly implement exactly what you want. The most sensible Go answer is to spawn a goroutine that is responsible for writing the file and offers a `chan []byte` that other goroutines can push to when they have something to write. The next most sensible answer is to decorate the file with a wrapper that implements locking, as in: type LockedWriter struct { m sync.Mutex Writer io.Writer } func (lw *LockedWriter) Write (b []byte) (n int, err error) { lw.m.Lock() defer lw.m.Unlock() return lw.Writer.Write(b) } However, in this case I would consider this somewhat dangerous. `io.Writer` and the other io interfaces are a bit weird, in that there is their literal Go interface specification, and then there is the sort of things that people expect those things to do that aren't written down, and are subject to opinion. I would suggest one of those opinions is that the average bit of code receiving an `io.Writer` expects that w.Write([]byte("a")) w.Write([]byte("b")) will result in the two writes being contiguous. This usage of the io.Writer value violates that, even with the locking in `LockedWriter`. (By contrast, and to give another example of the unwritten io.Writer semi-contract, an io.Writer user should _not_ expect that those writes will be "merged"; if writing to a file that may result in two disk transactions, if writing to a socket that may result in two packets with one byte of payload each. If you want that you need an intermediate buffer yourself.) By making it a channel communication that is not defined by a standard interface, you have the chance to write your own semantics and your own documentation about what users can expect, whereas you really shouldn't expect to do that with io.Writer. Having something implement io.Writer but trying to "document" the deviations from expected behavior is a bad idea precisely because the entire point of having interfaces is passing values in to code that only knows about those interfaces and doesn't know about your prose documentation.
Is this the discussion you are referring to? https://groups.google.com/d/msg/golang-dev/F3l9Iz1JX4g/szAb07lgFAAJ
IMO, this is a desperately missing facet of the stdlib. For lack of it, everyone has invented their own, meaning no two libraries can share any sort of logging without adapters or hard dependencies. Puke. https://github.com/go-logr/logr
You can also use url.Values to create the values, which gives you access to a safe key/value way of constructing them. [Multipart form support is in the multipart package](https://golang.org/pkg/mime/multipart/) but is intrinsically more complicated to deal with.
TCMalloc, the allocator that serves as the basis for Go's, still can suffer from fragmentation. Go's can suffer from noticeable fragmentation as well once allocations reach a size class and the allocations have multimodal lifetimes. The reason: such allocations are stored in 'spans', which act as containers for your program's allocation, whose contents are never consolidated, meaning spans for larger size classes can come to appear as Swiss cheese (RSS that is up to markedly larger than live heap, which is confusing if you don't know that's what's happening). Inactive spams are freed back to the operating system when not in use, but that is beside the point of no compaction. Just imagine partially occupied moving boxes whose contents cannot be consolidated into fewer. More content can be added to them, but any data that is still live post-collection stays in the box in which it was born until it dies. Nevertheless these boxes take up the same amount of space in your house.
The official tour on the golang page will help you learn the syntax, then look at the package list (expecially net/http), and read the examples.
I also organise my code the way I want. Manipulating the GOPATH makes that possible trivially.
You can. Because interface implementation in Go is implicit, interfaces are better defined where they're used, not where concrete implementations are defined. Since nothing in the standard library takes a logger, there's no need for a logger interface there.
You can't.
Not sure i agree about flag, it seems to have a well defined api thats implemented by namsral/flag, pflag and other flag packages that add config files, environments and so on. As a basic implementation I don't see flag being a pain point. Sure, viper (or something better) add additional configuration mgmt functionality, but it's an apples/oranges comparison at that point. It would be interesting to check what the PHP-fig came up in the PSR for logging and how it compares to golang log package.
Storm seems fantastic. I'm just getting into to both in my personal time as well as at work. To quote @epiris on cznic/sqlite, "Before you use this please view the dependency graph. It's implemented.. in a virtual machine that is loaded at runtime from a giant blob of "custom" for lack of better words IR." The above makes me wonder about whether the sqlite project is ever meant to be used in production. The ql looks interesting, but I haven't looked into it.
I don't get it :(
Yeah, cznic/sqlite is weird. I don't know if it will ever reach production readiness or if it's just an experiment. I initially wanted to use sqlite3 for this project, but got annoyed by cross platform build issues. ql is cool. I actually started this project with it before switching to bolt/storm, but can't remember why I switched away from it. I think maybe I got a corrupted database file at one point when frequently restarting during dev and got annoyed, but not sure.
Generally looks OK to me at first glance, but I'll call out a couple things. I'd put your quiet setting in a global so you don't have to pass it to your log function every time, since you always pass the same variable in. Unless this is a throwaway app you'll use twice and never look at again, you should handle errors better than just panicking. Lastly in all the places where you're instantiating a struct and comment all the fields, dump the comments and use the field labels instead of the short hand format. Hope it helps, good luck with your gophering! Hope you're enjoying it!
You can loop over the characters using "range", eg. s := "Computer" for _, c := range s { fmt.Printf("c = %d (%c)\n", c, c) } Output: c = 67 (C) c = 111 (o) c = 109 (m) c = 112 (p) c = 117 (u) c = 116 (t) c = 101 (e) c = 113 (r) Take a look at https://blog.golang.org/strings
sweet
This is a narrower use case of course, but if you're doing anything with natural language (though numeric and other types can be indexed too) bleve is a great project that had really powerful querying and indexing functionality. There are several back-end implementations but bolt is one of them. It's worth checking out, and if performance in pure go becomes an issue it's trivial to swap it out for leveldb or any of the other back-ends.
Libraries shouldn't be logging though. If there's an error, they should return an error. If there isn't, you should be able to inspect any other data and log it yourself if you choose to do so. A library doing its own logging is just annoying.
Theirs recently been a [project](https://github.com/improbable-eng/grpc-web) released that proxies gRPC over http in a fairly functional way.
If I print &amp;s inside the loop, I get: &amp;{a} &amp;{b} &amp;{c} so how come even though I'm checking if s.a == "a" before setting f, f is always set to &amp;{c}?
As your title suggests, you want to use `io.MultiWriter` to collect your outputs together, then use `io.Copy` to copy from you input (the request body) into the multi writer.
Thanks for the workaround. So the address of the local variable always points to the last element of the slice?
Another way to do it is to convert to `[]byte` (a slice of bytes): func printBytes(s string) { sbytes := []byte(s) // You can also replace this with something like fmt.Printf("% x\n", sbytes) // if you want different output. fmt.Println(sbytes) } If you want to print each byte individually along with the character it corresponds to, you might do something like this: func printBytes(s string) { for i := 0; i &lt; len(s); i++ { fmt.Printf("Byte %3d: %3d %c\n", i, s[i], s[i]) } } This differs from `for ... range s` subtly since a `range` over a string results in the runes of the string being looped over. For ASCII, it doesn't matter, but for all other characters (e.g. characters like `á`), [it matters](https://play.golang.org/p/BGiufc52Jj). Of course, if you have bytes in the string that don't form a valid UTF-8 sequence, the rune received for each "bad" byte would be the value of [`unicode.ReplacementChar`](https://golang.org/pkg/unicode/#pkg-constants). You can find out more by reading [Strings, bytes, runes and characters in Go](https://blog.golang.org/strings) as suggested in another comment.
I disagree. A logger with features like control of a logging namespace as well as control over logging levels within that namespace, ie "debug" or "error" would make it so you control what actually gets logged. There are scenarios during development where it's useful to see the logical flow without having to bust open the source code every time you have a question.
Both code blocks compile to the same code (IIRC) so it's definitely worth going for readability.
On line 228: tables[i].Columns[j].Primary = v Can be replaced with column.Primary = v And the i and j variables (defined on 221 and 223) can be thrown away because this is the only instance of their use.
Sounds complicated dude.
These are great. Really enjoying them. I hope they keep coming.
To begin with, it's not threads, it's goroutines. And the way I would do it, spawn another goroutine which reads from a channel and writes to a file. The worker goroutines write to the channel. c := make(chan []byte) go func(c chan []byte) { // open file for writing, defer Close() for b := range c { // write b to file } }(c) for i := 0; i &lt; n; i++ { go worker(c) } To make the above more correct, you might want to add a close/quit channel. Or use wait groups to keep track of your goroutines, so they don't exit too early.
I'm taking todd mcleods Udemy course. Amazing. $15 for 169 videos. He has a ton of free stuff on youtube but the udemy courses are better produced and (I think) easier to follow.
I agreed with you until I worked on the largest, most complex project of my career and it turned out the easiest way to handle logging was to remove it from all of the libraries we wrote. It's one thing to just import a logging package and use a package-level logger while you're in development, but coordinating different handlers/formatters/levels in library loggers that are often used in multiple files/packages within a single project...it's bad. It's messy. You end up re-implementing so much in every library that is already included in every logging library already. You do you, but I'd keep it simple for sanity's sake. Productivity, too. 
I had to actually click "load 2 more images" to see what this has to do with Go. Now I get it. For those who don't get it, it's from [this scene](https://www.youtube.com/watch?v=05dT34hGRdg). The gist is: Gophers = Jedi, Javascript-ers = Sith. I approve.
public/open-source libraries....sure....in-house libs...why not? logs collect useful data. users of libraries do not know what it useful, in scope or volume...authors do. if both the user and author are committed to a logging platform (because they work together), its perfectly fine for libraries to log, particularly if the library already produces side-effects (logging is just one more) 
Yes, so the artwork was originally repurposed from this asset which I believe is exactly how Renee's original illustration was done: http://60plusadventures.com/static/img/blog/gopher/header.jpg Thanks for the complement...even those this is novelty it does spark conversation and gives me an excuse to talk about Go. On the subject of spinners, I'm not entirely sure why or how they blew up. But kids love them and apparently they provide an outlet for people of all ages to help ease their mind and body when sitting down. At least that's how I understand them.
Very interesting and well explained as always, thanks /u/campoy :)
An interesting read on white-box vs black-box testing in Go. I had a quick look at the official docs and into a Go textbook, and all seem to only consider white-box testing. Fellow gophers, what is your preferred testing approach - black or white? Or are you using a mix of both?
I don't know if a standard library interface would be a good idea or not but if it could stop this logging package madness and fragmentation we have in the ecosystem I'd sure love it if it existed.
Good try but experts in the field [claim otherwise](https://www.quora.com/Does-the-vashikaran-love-mantra-work). &gt; Satyabhama Ashley-Farrand, Have studied mantras and pujas since 1980. I am a Vedic priest and teacher. &gt; Does the vashikaran mantra for love really work? &gt; Answered Jan 26 &gt; Vashikaran mantras do not work.
Thank you, what a steal for the amount of content!
 &gt; Removing Vashikaran is from boyfriend,husband syntax error: unexpected is, expected English too many errors
Ralph, you've got to understand that this is a Go reddit. the way you are implementing this is not idiomatic in Go. I took a stab at implementing this in Go to show you what you should have posted: https://play.golang.org/p/ul9EcVSXs- Peace, -jeff
I've created something similar, but with code generation and leveldb https://github.com/microo8/mimir
Instead of instantiating your structs like this: table := ddTables{ row[1], // Tablename row[2], // Tablespace row[4], // Comments []ddColumns{}, // Empty Columns []ddIndexes{}} // Empty Indexes Do it like this: table := ddTables{ Name: row[1], TableSpace: row[2], Comments: row[4], Columns: []ddColumns{}, Indexes: []ddIndexes{}, } The second one is more typesafe: consider someone refactors the `ddTables` struct and switches the order of `Name` and `TableSpace` for consistency with other structs. This will introduce a silent bug in the first code variant, but not in the second (see also [Effective Go](https://golang.org/doc/effective_go.html#composite_literals)). You can still add comments in the second one, but normally the code should speak for itself. Also note that the final `}` got it’s own line, and the additional `,` at the end of the previous line: That’s for clearer diffs.
All of the variables on the left side of the range statement (i, j, table, column) are references. My understanding was that 'column.Primary' would serve as shorthand for 'column-&gt;Primary' though. After poking through the spec a bit, it seems that 'column' is only preserved within the scope of the for loop because you used short variable declaration (:=). https://golang.org/ref/spec#For_statements
Man I needed this like a week ago. I've already made my layers of interfaces now though!
Black box testing as much as possible. Sometimes, however, there is benefit to allowing you to peak at the internals a little bit. Not a whole lot, but a little bit.
IMO it's a good thing; but you can still get around it at least by wrapping a function. This also lets you create your own interfaces to wrap third-party libraries and then create mocks.
Inspired by your video I created a bindings for flite https://github.com/gen2brain/flite-go . It only has a couple of basic public functions, but voice can be chosen. 
This is exactly how I feel, it would be really nice to not enter a holy war about logging every-time my team start to talk about logging.
io.Writer doesn't capture context, for one. A line of text in your log is less useful than a line of text with a bunch of metadata describing what and where the line of text is talking about. Then there are different logging levels. You could, of course, typify these things like you're saying by creating a specific Logger for each service (so it includes context for itself when calling Write) and a specific Logger for each log level. But I'm not sure that is a good way to go, either. It would make application-wide changes to logging pretty unpalatable.
I don't think it would have that effect. I think different projects have legitimately different logging needs. Some need speed, some want convenience, some want levels, some want structure, and on and on. I don't think one logging package or interface will satisfy all needs, which means there will always be several alternatives that are popular for different reasons. But that's OK, because logging is an application concern and as long as widely shared libraries don't couple themselves to a logging solution teams will be free to choose what they need for the application at hand.
one more subscriber, #win!
This is a great step forward operationally over zookeeper. Do you have thoughts on when this project will reach a 1.0 status? 
Sorry about the self promotion, but I'm about to make Gopher plush available shortly. Will this be something of interest maybe? I wrote about it here: https://www.reddit.com/r/golang/comments/5npdzx/practical_golang_gopher_plush/ And it will be the one with that thin extra piece: http://imgur.com/pjr8S9v and http://imgur.com/nGEPnRw Why the hole you might ask? Well, I wanted something more than just a plush, so I made a hole for a phone. That way it can look like the gopher is "using" the phone.
Both of these are still true, you also can't add nodes to the cluster without restarting the world. 3.5 is supposed to fix these things but the apache ecosystem moves at a glacial pace.
I imagine this depends on the community. Who uses zetcd, how hard, and when.
what terminal script are you using in your videos? (showing git, etc)
It's really difficult to operate and configure, especially in containers
things could be better: 1. google chose kotlin for android 2. google chose dart for fuschia 3. google even co-opted the brand "Go" for its stripped-down version of android kind of unfortunate that `sync.Map` has a completely different interface than regular maps, but I guess that can't be helped `alias`....don't care, will never use it runtime improvements look decent enough 
dart is for frontend, and kotlin was already a drop-in replacement for java. go seems more like a backend language meant to replace java on the servers, and it's gained a lot of popularity for people looking for better solutions to replace node. 
[removed]
It's one of those things that would be great if people were actually using it and if it would be integrated into say $randomSocialNetwork. However as of yet I haven't found use for it
pow() is returning one value, but it's being called it twice.
Fair enough (and welcome back). Personally I think I'd try to setup an environment for the devs where the code *can* live on a "normal" port, like running a gitlab instance somewhere. I can't say anything about your network though, so that might not be feasible. 
I gave it a quick, not-so-serious try but I got stuck/gave up after some step/error while trying to set up the whole thing. Admittedly it's a little complex to set up and since the project is new, googling for the error didn't help. I had to go post in google groups for help and I was just not in the mood. But that was months ago when the project was just released. It might be in a much better state today.
Your thought was wrong.
1. Android already has a huge JVM system, so the language that directly supports it will always be a better choice. That and because kotlin supports different versions of Android runtime (thus different versions of Android Java) it means that Android devs are no longer stuck with Java 1.6. This is quite big. The performance critical code was and is done in C/C++. Actually I saw some apps which are using Go for same thing, but currently generated binaries are quite big so it's not a universal solution. 2. Fuschia is definitely interesting. And Dart was designed for UI (they even had standard library of web components). But currently, I'm not holding any hopes. Fuschia targets the embedded devices - by which I think they are trying to create a new Google Glass. And we all know what happened with the last one. The augmented reality is a really nice thing, but currently even desktop CPU struggles with them. IMHO I think we are at least 10 years away from it. Go has already established foothold in backend, including Google's. It was designed in a way that constant flow of Google engineers could understand and write code for their internal and external services. And as far as I can tell - it is a success. As for other companies - you all know about Dropbox, Twitch, etc. Banking (yes - it's there). HFT (in places where we can have 10ms latency that is). So at this moment I think Go is quite safe. Time will tell how long it will last. 
It's worth mentioning that if you have occasional I/O utilization spikes and otherwise mostly CPU-bound workers, using a buffered channel may be a better approach not to have short term I/O congestion keep the threads waiting at the mutex. Going from unbuffered channels to buffered channels had a huge positive impact on a networked application I worked on that fit this profile.
Stateful sets in K8s 1.6+ make this easier 
Solved it a couple days ago I stored each character's ASCII - 48 in an array (gets you digits) then constructed array of the 988 products. Compared the products
It's neat. But how about per-project list instead of per-active-file?
&gt; always use the database/sql package to construct SQL statements and insert values into them Unless you need database-specific functionality. I had to use the driver directly to get access to the functionality I needed (I think it was for using a WAL file with SQLite). The advice should be, "Don't use string concatenation/formatting for SQL". Most (all?) SQL drivers give you an option to use something like `database/sql`'s API and do something like this: driver.Query("select * from users where email = ?", email) Use `database/sql` until you can't, and then still make sure you still use safe practices.
Yeah, Go's type system is a big pain, even doing just normal REST. It's unfortunate, because Go is just a great fit for us, and being able to compile and deploy a single binary is very attractive.
&gt;The advice should be, "Don't use string concatenation/formatting for SQL". This. More precisely: Do not pass unchecked input from your users to your database statement of you can not use parameterized queries. Applies to any language, not just go.
AFAIK we're still missing a code highlighting library like python's pygments. That's kind of a tall order, but you asked ;) 
Man that site is horrible on mobile
A DB2 database driver.
For those who don't know, https://github.com/neelance is the main creator of GopherJS (https://github.com/gopherjs/gopherjs/graphs/contributors). He's actively working on graphql-go, so it's no surprise it's a great library.
I would hope Go gets big enough that it doesn't *need* google. Knowing Google's tendencies to drop projects, I would rather have go community supported than Google supported.
&gt; vendor directories are ignored by the go tool #19090: Hooray! No more Makefile spaghetti like this (well a bit less anyway!) GO_FILES := $(shell go list ./... | grep -v /vendor/ ) go test $(GO_FILES) go tool vet . 2&gt;&amp;1 | grep -E -v vendor/ ; test $$? -eq 1 errcheck $(GO_FILES) find . -name \*.go | grep -v /vendor/ | xargs goimports -d | grep . ; test $$? -eq 1 go list ./... | grep -v /vendor/ | xargs -i golint {} | grep . ; test $$? -eq 1 should become go test ./... go tool vet ./... errcheck ./... goimports -d . golint ./... I assume the `./...` changes will just work in `errcheck` and `golint` but I suspect `goimports` might need a bit of work.
What's holding off performance
A simple webserver would be an easy example, try and only use the standard library. Show how to serve pages, how to change content on those pages, set up a simple API, etc
I guess it is to get a feedback on popularity. 
Here, have 1/2 of your expectations, since I'm not providing any jokes you know what it was :)
Where can I find more information about planned GC improvements for large heaps? I can't find it on github issues.
Make an SVG Decoder that rasterizes it into an image.Image.
Haha this is a weird mashup of things I like.
fullly tested/production ready ORC file reader/writer
I mean, yeah, all the tools to make an SVG rasterizer are there. But it doesn't look like anyone *really* wants to be the guy to put them all together. I was looking at /x/image/vector (which was designed for iconvg, a simplified binary SVG spec) and thought it'd be neat, before I realized how much work it would be to **actually** implement it in its entirety.
Just a few things I noticed: 1. No need to keep track of `userCount` separately, you could just use `len(users)` instead. 2. Once four users connect to the server, no more users will ever be accepted, even if users later leave, as the for loop on line 45 would exit. 3. Maps are not safe to be shared between goroutines if at least one of them is writing to the map while another goroutine is using it, and could cause a runtime panic. Try running your program with `go run -race main.go`. It would be wise to either protect the map with a mutex lock or only access the `users` map from one goroutine.
You look like an asshole on Reddit. If you're looking to appear smart or clever, you'd be in a classroom teaching 3rd graders.
/u/misternugget finally able to follow through on this! Super excited to finally get to read through this. Also, grabbed the Kindle Match version. Thanks for offering it. I plan to use it to write a lexer/parser so I can actually write a linter for a niche language that we use at work.
No, my opinion isn't unfounded. OP is looking for something to implement that is _needed_ and _wanted_ Looking among things that have already been implemented is stupid, people are going to trust the most mature project, with the most activity, from a more popular source. You can't find things that aren't implemented in things that have been implemented. The only way to find out what is needed and wanted, is to ask the community, like this thread.
If you're making queries at that level then you shouldn't be asking this question.
I also posted this question on Quora https://www.quora.com/What-libraries-would-you-like-to-see-implemented-in-Go but have received only one answer and a lot more follows on the question ... i wonder if there are some other places where i can receive better feedback and opinions ? And to be honest I also thought of the idea of porting an existing useful library from another language ..
&gt; query = fmt.Sprintf("SELECT id, email, subscription_id FROM application_user WHERE email = $1") &gt; query = "SELECT id, email, subscription_id FROM application_user WHERE email = $1" 
Your static.go has a directory traversal vulnerability.
Could you change it to a Triathlon or Other club, so that runners can join too? It's cycling-only at the moment.
I'd like a good number-theory library. Especially generating prime numbers, testing and proving primality, factoring large composites, calculating divisors, there are many related functions.
remember saw this on a youtube talk somewhere, you can replace conn.Write([]byte(message)) with io.WriteString(conn, message) which has better performance.
&gt;[**7 common mistakes in Go and when to avoid them by Steve Francia (Docker) [27:58]**](http://youtu.be/29LLRKIL_TI) &gt;&gt;Steve Francia talks about most common mistakes in Go #golang and how to avoid them. &gt; [*^Hakka ^Labs*](https://www.youtube.com/channel/UCAezwIIm1SfsqdmbQI-65pA) ^in ^Science ^&amp; ^Technology &gt;*^59,722 ^views ^since ^Jun ^2015* [^bot ^info](/r/youtubefactsbot/wiki/index)
Interesting idea, something like NTL in C++ ? I will keep that in mind. Thanks!
This article was pulled from a larger piece I was writing that did discuss argument placeholders and I thought argument placeholders were mentioned here but they weren't. When I realized they weren't I updated the post because I agree it isn't as valuable without mentioning them.
True. I should have phrased this a little better, but I was hesitant to say "don't use X" only to see people go use Y which is equally bad. Saying use the SQL package only seemed safer at the time of writing.
&gt; Keep in mind though that it is not intented to 'port' a complete C/C++ project in a single action but rather do it on a case-by-case basis per function/source file 9 (and created higher level Go code accordingly). So, not as thrilling as it could have been ;)
I think go assembly will become the IL for a bunch of higher level languages, be neat to have something like clojure that generated go asm 
&gt; Assumes of course that in your query the dreaded apostrophe is never used. I think if you are filtering on characters in common fields you are going to have a bad time. Emails, Names, Addresses and other strings will quite often have apostrophes. This is one of those super common terrible practices that pervade software dev :| (Speaking as someone with a hyphen in his name that gets filtered way too fucking many times)
S/mime signing is missing from the crypto libraries. Afiak. Major hassle for backs wanting to use go.
this
@epiris could you please provide an insight and create an issue here https://github.com/go-aah/aah/issues. I will address it. Thanks for your review. I appreciate it. 
 @tv64738 I didn't mean to offend anyone from my fellow Go community.
thanks
or you know, maybe... just use a language with generics built-in
Oh i would love it :) 
You'll be the best if you do what you like yourself !
Sorry I forgot to mention one thing. `http.FileSystem` does not prevent directory listing. so I created `ahttp.FileOnlyFilesystem` in compliance with `http.FileSystem` interface and added option to disable directory listing i.e. `ahttp/fs.go`. 
&gt; just use a language with generics built-in Every language has its flaws. If having to generate a bit of code is Go's biggest, I'd call that a win. 
Native GUI libs
You shouldn't have to pull a TypeScript and run your code through a preprocessor to get something as useful as generics in a high-level language. C doesn't have them because it's C and there's an unacceptable performance hit at the native level. Nice work, though.
This is not true, *net.TCPConn does not implement io.stringWriter interface, so io.WriteString behaves exactly like conn.Write([]byte(message)).
I think there's more to this than just 'connect the dots'. SVG rendering is actually very difficult to do right, as evidenced by the many many partial implementations lying around in many different languages. The [skia bugtracker](https://bugs.chromium.org/p/skia/issues/list) is ample proof that even really big teams have trouble getting it right yet. (skia is the svg rendering engine used in chrome).
A binary compatible pure-go implementation of sqlite.
I will fix it.
So if you want to make a change to all these files you have to regenerate something new? You need external tools to replace something other languages does natively? I like Go but this attitude is bull-headed, naive and very bad for the future of the language. You should strive to make a language easy to use and at least as powerful as other languages it strives to replace
Dtls implementation. More complete quick Webrtc datachannel
This looks neat. I'd like to try it out. 
I think you need to set the number of cores to use. ``` import "runtime" runtime.GOMAXPROCS(runtime.NumCPU())``` This allows GO to use all cpu threads
I truly wonder what would be the next thing to complain about if Go went out with generics. Haters gonna hate really shines here.
It's pretty common for a concurrent implementation to slow things down. I wrote about just such an experience and then detailed how I used the tools provided by Go to speed it up: https://pocketgophers.com/concurrency-slower/ My first impression of your concurrent version is the channel operations you use are not needed. You would also probably get better performance if you used one fewer instance of isPrimeConc because primeConcurrent is also in a goroutine that has processing (sending and receiving) for every step. I will be back in a bit with my own version.
Read and apply this https://blog.golang.org/profiling-go-programs and https://making.pusher.com/go-tool-trace/
Thanks, I wasn't aware it searched the `vendor/` folder. I assumed since there is no official package management yet that `go build` would just ignore `vendor/`. 
Your problem is that you are feeding 4 values to 4 goroutines and then waiting for the reply to send other 4 values, starving the goroutines. I've changed your code to reuse isPrime in both versions, creating a goroutine that feeds the prime goroutines and also using time.Time to compute durations. https://pastebin.com/2h4M2ViG In my PC I can see a clear improvement for big values, however for small values the overhead of channels doesn't worth the effort of parallelizing. Regards. 
That's a bummer. I, personally, veer strongly towards data-structured log files. Way, way easier to consume in aggregate and (more importantly) modify over time (extra fields, order changes, etc) without going into regex hell.
[And 4 days ago. And 10 days ago. And 14 days ago. And 29 days ago.](https://www.reddit.com/r/golang/search?q=rbac&amp;sort=new&amp;restrict_sr=on&amp;t=all)
https://github.com/taylorchu/generic
It's run through a preprocessor but that's part of the compiler and wasn't designed for generics.
Oh right I didn't know that
Thanks - that worked very nicely. Uploaded the new version to the repo with credit going to you where it is due :) I got to remember that pattern of using go-routines. Very nice. Thanks again!
That already exists. Look for gometalinter and they have a pretty comprehensive list of compile time checkers.
&gt;You're acting like nobody complain about any language but Go. You made that assumption &gt;You're also conflating "hatred" with fair criticism. This isn't fair criticism, there are official channels to do so constructively on the go language repo, blog posts and Google docs. There is even an open discussion on how to implement it. &gt; An easy cop-out for people that have no argument whatsoever. My point, exactly thank you :) &gt; Just call it hate and dismiss criticism as so. See above 
AFAIK there isn't anything as integrated and complete as NLTK, but there are bits and pieces here and there. I had this need too, but I've ended just pre-processing the text in python first.
The correct syntax to do this is func doSomething() [][]int { } For further informations, read [Effective Go: Two-dimensional slices](https://golang.org/doc/effective_go.html#two_dimensional_slices). Also note that this a slice of [slices](https://golang.org/doc/effective_go.html#slices), not an array of [arrays](https://golang.org/doc/effective_go.html#arrays).
Search github for calls to zap or log that prove 1-4 is not the more common case, it's just a guess but I think it's pretty reasonable. Then search for hundreds, would be surprised if anything exists. Maybe some advertising companies store hundred+ fields of data points in because data points are their product.. but they certainly don't send it through their logging pipeline. Emitting over AMQP in batches through a message queue ingest and through event correlation before being stored in reliable storage systems sounds much more reasonable then trying to use your logging library.. which is and should be built for general purpose logging. Which is why I wanted to see general purpose benchmarks.
I've left a comment elsewhere, but batching (split range in 4, instead of looping over it) and only sending primes back (with a "done" message at the end) would give a very drastic boost as well.
[This](https://github.com/cznic/sqlite) looks like a good candidate. 
historically is the key point, AMQP had a lot of trouble scaling to high volume and kafka is relatively new. Never the less logging user/transaction data for debugging purposes isn't all that uncommon
that this tripe got four upvotes is truly indicative of where the Go community is headed
Oh and one thing I forgot, why does godeps use the "Godeps" dir rather than the standardised "vendor" dir, is this because Godep is older and supports right down to Go 1.4? Maybe, but anything less than Go 1.7 or 1.8 is no longer relevant to me anyway.
I simply said that "most everyone will use that as well", maybe half is more reasonable? I wouldn't know without measuring it, the fact is you included it. By including it you increased the number of ways to commit a Event based on what I see in the GoDoc from.. one to two. Since the Msgf method is half of the API that commits messages, I thought it should be included as well. As for why would you include a formatted string for the message, for the same reason you include a message at all. More context for a human to read later, if there was no value in reading a message later why not just emit key value pairs only all together?
What is meant by "time is space" in this language?
I haven't gotten to actually play with the program, but looking through the code I was curious if [lexer.go 46](https://gitlab.com/fharding/gobrainf/blob/master/lexer/lexer.go#L46) should be checking for '0' or 0. Also, would it be better here to just go ahead and use the constants defined in token.go instead of the character literals?
lol no generics
Anybody know how similar or different TISP would be to something like [ANI](https://code.google.com/archive/p/anic/)?
I haven't coded this, but I suspect you could take something like this - &lt;https://golang.org/pkg/container/heap/#example__priorityQueue&gt; - and then make the `Item` type used there the generic. You would likely need to rename the `PriorityQueue` type as well to be something unique per generation. So you would likely end up with something like... type Something generic.Type type SomethingItem struct { value Something priority int index int } type SomethingPQueue []*SomethingItem A vast majority of the rest of the impl would be the same, save for replacing all occurrences of `Item` with `SomethingItem` and maybe replacing a few `string` variables with `Something` types. The final output might look like this - https://play.golang.org/p/haxC4iu5dk You might be able to clean it up even further by writing a wrapper type around the `SomethingPQ` type, or by writing an implementation of the original PriorityQueue that uses `interface{}` as the value type, and then had your generated code just a type-casting layer wrapped around that. 
Sorry, i should have clarified: my point is, there are times you need it, and those are tge times to use some other language. 
A type is an superset for structs. A type can mean a struct, or an interface or some primitive type like int or float
I thought Go compiled to native assembly already.
Atom with the go-plus package, which is actually a collection of packages that turn Atom into a powerful Go IDE.
What was the problem?
What you said was the problem I had accidentally miss spelled something while trying to use your solution.
[go-on-rails](https://github.com/goonr/go-on-rails) is a generator used to manage Go app with Rails tools like migrations etc, or convert some APIs in existed Rails to Go codes for performance consideration. And the link above is a simple example shows how to use GoOnRails generator. yes, it's more familiar and easier get handy to Rails developers. But I found more and more Rails developers in Go communities nowadays :) 
1.unwrap has nothing to do with memory management. 2.rust has futures too
That's unreadable. Format code here or add a link to a gist.
Not sure I get what you try are trying to do exactly, but did you try to use live code debugging, maybe with some kind of IDE and golang to get a real clue whats going on?
Better formatted version: package kata import "fmt" import "math" type arrayStore []int //ChooseBestSum : Go away func ChooseBestSum(t, k int, ls []int) int { subset := make([]int, 0) solution := make([]arrayStore, 0, 100) getSubset(ls, subset, 0, k, &amp;solution) res := findMaxDist(solution, t) if res == 0 { res = -1 } return res } func findMaxDist(p []arrayStore, t int) int { maxVal := 0 for _, path := range p { sum := 0 for _, val := range path { sum += val } if sum &lt;= t { maxVal = int(math.Max(float64(sum), float64(maxVal))) } } return maxVal } func getSubset(lst, subset []int, curPos, maxL int, solution *[]arrayStore) { //Happy happy joy joy we have a subset if len(subset) == maxL { //fmt.Println("Found subset ", subset) fmt.Println("Array state: ", *solution) fmt.Println("subset to be added ", subset) *solution = append(*solution, subset) fmt.Println("Array state after: ", solution) //return solution } //Sad day, let's keep trying, if we can if curPos+1 &lt; len(lst) &amp;&amp; len(subset) &lt; 5 { //Don't have the next number be a winner getSubset(lst, subset, curPos+1, maxL, solution) //Choose the next number to be a part of the joyous occasion subset = append(subset, lst[curPos]) getSubset(lst, subset, curPos+1, maxL, solution) } } 
I've seen the issue and that it has been sorted out and notified the developers as well about this. Thanks for the ping /u/PacNinja.
&gt; "Because other languages do it natively" is not very solid logic. That's not the argument though. Basically the argument is that creating a langauge that is statically typed but has no generics makes very little sense. Either go for dynamic typing, or pick static typing, but then sooner or later you're gonna need generics. &gt; Go trades generics for compiler/runtime simplicity. Other languages do not make this trade. Generics don't affect runtime complexity, in fact, _not having_ generics affects runtime complexity, because you need to workaround the lack of generics via runtime hacks - type assertions. They do affect compiler complexity because type systems in general affect compiler complexity. If Go isn't willing to pay that, maybe they should've gone with dynamic typing. I don't think it's surprising Go gets so much flak given how half-arsed the type system is. 
&gt; Arguably (to my knowledge) the times where generics is necessary are few. Every time you use a dynamic-array-like (vector-like) type or a hash map, tree, linked list, stack, queue, heap, etc. etc. (basically anything that is supposed to contain something), you have a very good candidate for generics (and you'll probably do poorly without them). Edit: Also, 'algorithm functions' like min/max, sorting functions, etc. Go kind of solves this by actually providing generics _sometimes_ with a handful of compiler-blessed generic types (slice, built-in hashmap, etc.), but that doesn't scale well - you can't just keep adding exceptions for blessed types in the compiler. And so that situations leads to things like [List](https://golang.org/pkg/container/list/) or [sync.Map](https://talks.golang.org/2017/state-of-go-may.slide#16) that are supposed to be generic but aren't. 
&gt; especially when we were trying to create a class that supported generics A generic data type is harder to create but much easier to use if designed properly. 
`(let (factorial n) (if (= n 0) 1 (* n (factorial (- n 1)))))` Is it just me or is this kind of syntax not very readable? - Too much on one line. This doesn't really come from the language, I guess it's just a personal choice from the author. Here is an attempt at adding a few new lines: ( let (factorial n) ( if (= n 0) 1 ( * n (factorial (- n 1)) ) ) ) - Only spaces used to separate everything. `let`, `if`, functions, args, etc. I guess it goes with the functional paradigm : functions are just args like the others. `if` and `let` are actually functions. So everything is equal. I have this problem with most pure functional languages: I get that there is something elegant in their design, but I miss my curly braces.
Have you looked at ParaSail? It's got a lot of similar goals to TISP. Perhaps there's scope for collaboration. The big shame of ParaSail is that it's not developed in the open enough with a community on GitHub or some other code contribution platform.
I am not a big fan of lua as such, also this has some interesting features.
Second this. VS Code is great with Go. Integrates very well with the go toolset as well. All one need do is install the Go extension by lukehoban - and the rest you'll get promted to install afterwards. Up and running in less than ten hassle free minutes :)
Agreed. Some other general issues: - Each package must have a file with the same name as the package. This is commonly good advice, but should not be a rule. It may make sense to have different files. Constants and variables should go wherever best suited, and separating them from code by moving them to another file lowers readability. Additionally, for long package documentation, it should go in a separate doc.go file. - Order files by godoc order. Good guideline, but again not perfect. Organizing by semantics is often more readable. For instance, non-method functions that manipulate a type may be better placed with that type's methods. Constants or type's only applicable to a single function (often unexported) are better placed by that function. If you really want to navigate via godoc, hyperlinks are provided into the source code. - Commenting The advice about comments contradicts Go style. Go comments, including doc comments, should be full, English sentences. I generally would not try to impose other constraints on, say, function comments, but the advice about variables is to start with "Variable define..." which is grammatically incorrect.
Why not create the solution slice in getSubset() and return it? Apart from that, I believe you need to expand your subset slice in the append call as a variadic, like: *solution = append(*solution, subset...) 
Slice headers need returned if you are going to append them. Read golang blog post about slices. Also after looking at your code .. it doesn't really look like it's finding subsets at all. It's just ugh, checking lengths not values. To find if a set A is a subset of B is simple: sort.Sort(sort.Ints(a)) sort.Sort(sort.Ints(b)) let aN and bN be zero while aN is in bounds of a, bN in bounds of b, inc bN++ if a[aN] == a[bN] We can advance the aN++ When the loop breaks if aN advanced to the bounds Of a we know we found all elements of a in b return len(a)-1 == aN 
Interesting. That's sort of just another variant of "pass the information you need off to the side". I guess it works, but it seems a little clumsy. E.g. imagine a sorted set data structure, which we want to use with the type type MyIdType int64 I guess we'd end up with something like type Elt generic.Type type EltSetNode { // ... } type EltSet struct { Less func(Elt,Elt) bool // ... implementation details ... } Which would work. But we already have a way to associate a specific set of functions with something in Go -- interfaces. I wonder if there'd be some way to verify that in the generic definition and then have it disappear when the specific implementation was generated? Something like type EltInterface interface { Less(Elt) bool } type Elt struct { generic.Type EltInterface } Then the code before specialization could call Elt.Less(), but once specialized would just be calling that method on the concrete type, without the overhead of interfaces.
I did, it looks like there is somethign screwy going on around the append. It appends, but then the next recursive call seems to change the value, even though I'm trying to keep the same solution slice for each recursive call. 
It's not supposed to see if it is a subset, I know that it is a subset by the nature of how it's created. It's generating a binary tree of sorts then when we build a subset that's long enough it adds the answer to the solution set. Slice headers need to be returned if you don't do special handling. By using the same slice by passing it's pointer, I shouldn't have to return it, each recursive call should have access to the same slice (in theory).
I had tried that, but ran into weird behavior there as well. Then I thought it'd be a good reason to play with passing pointers. I thought i'd have to expand my subset slice too, but because solution is of type arrayStore it's not actually appending an array to an array.
I want to, just haven't found the time. Not sure if it's worth it, considering the big data space is still in its nascent stages in Go, but from a technical challenge I'm sure it would be quite interesting. 
Hmm it looks like the use of the slice subset variable to maintain the subset I'm currently building may be causing a problem. I add a subset to the solution, but then sometimes when I return from a recursive loop and it updates a "separate" slice it affects the solution set by updating a value that's already in the solution. 
I am really sorry about the "sound" of the title of the article that I am submitting. By the article, I am not trying to impose something or anything. I just want to add a discussion about Go informal coding style that scattered on internet and which I use and still remember. I should have add a discussion tag or prefix.
My initial example was going to be a network service, but go takes advantage of epoll under the hood to make it work much smoother (so you actually can multiplex network connections in few threads) My latest experiment is that of a service manager. Spawning commands using exec.Start() and Wait()ing on them. Because wait blocks and cannot be selected on, you need to spawn a go-routine per Wait(), which I believe spawns a thread per Wait(). Go could do a similar thing with wait() that it does with epoll(), but I suspect it does not. At any rate, go does not always make it clear what's really happening under the hood. It's ultimately a limitation of how system calls work, though, which it seems like go is trying to hide. It would be neat if someone would build a completely async syscall layer so that all system calls could be multiplexed in a non-blocking way to userland. Go could behave much more beautifully using that in the run-time. 
One issue may be that ORC already has decent support in golang compared to parquet. Although it looks like Tune has tried to get a contractor to complete a parquet reader/writer and had active work at least up until mid last year https://github.com/TuneLab/parquet-go Out of curiosity what requirement are you looking at that ORC can't handle?
It also leads to people using bare slices or maps everywhere, even when a different data structure would be more appropriate.
If you only need small part of that API it is not that hard to write wrapper only for bits you need. I wrote one for festival-lite https://github.com/gen2brain/flite-go, so TTS but maybe you can use it as an example. edit: also, I see that bindings for cmusphinx are generated with cgogen, maybe check that project too
Definitely subjective 
Meh. Sure it does until it doesn't because the "upstream" change URL or otherwise disappear. 
I know this may be legal, but it still feels like a mess/more difficult to understand at first glance: type Employee struct { firstName, lastName string age, salary int } Compared to: type Employee struct { firstName string lastName string age int salary int } The tutorial also mixes the two which from a beginner's perspective may be confusing. I would also say that this kind of initialization is more concise too: employee := Employee{ firstName: "first", lastName: "last", age: 40, salary: 80000, } Versus: var employee Employee employee.firstName = "first" employee.lastName = "last" employee.age = 42 employee.salary = 80000 Maybe that's just my personal preference but I do think that for a beginner's level tutorial the most clear/concise ways of doing something should be used and that whatever you choose it should be used consistently. Other than that the tutorial is pretty nice otherwise, thanks for sharing. One last note, age and salary should probably be unsigned integers unless it's legal to have an employee that has not been born yet paying the company in order to work there ;) 
Wow, definite deal breaker. Surprising that multiple people had to reply why returning errors is important and log.Fatal from a package is bad.
I agree. It's much easier to read and change later if every field gets its own line. And if you're using struct tags this seems like a requirement.
Was there any need in the ecosystem for this project to be created or was it just practice?
Complete? No discussion of struct tags which is essential for xml/json marhal and unmarshal work.
&gt; Structs are value types and are comparable. Two struct variables are considered equal if they have the same values for each of their fields. There are two inaccuracies in this paragraph. * not all struct types are comparable. * two struct values may be not comparable even if they have the same field set. 
I know of two: https://github.com/scritchley/orc https://github.com/graphaelli/gorc Both seem to be readers only. Is there a writer you know about?
A good resource are CMS systems written in Go - they should contain the features you are looking for/want to look at. [A search on GitHub](https://github.com/search?o=desc&amp;q=language%3Ago+cms&amp;s=stars&amp;type=Repositories&amp;utf8=%E2%9C%93) (with filter `language:go` and sorted by stars (yes, I know, stars are also bookmarks and hence do not accurately reflect popularity nor quality)) might be a good start.
Thanks for the detailed feedback. I wanted to cover all possible ways by which structs can be declared. Hence I wrote about everything. And nice catch regarding the age and salary. Since I was more concerned more about conveying the point, I missed this :).
Tags require knowledge of reflection which I have not discussed in any of my blog posts. So I thought of writing about struct tags in a separate post.
I believe Julien Schmidt's router is trie, is there a performance benefit?
/u/mixedCase_ I believe yes. This project is needed, it enables further reach of Go lang provided capabilities to everyone along with ecosystem. My goal is to bring required modules, industry best practices, abstraction, OSWAP top 10 measures and further, etc. for web and api applications. So users have to spend some-time to go through framework configuration to enable or disable the features they need then start focusing on application logic and following convention for rapid development, time-to-market, maintainable. Of-course advanced, experiences developer can put together aah framework structure from their knowledge. If you have some-time to spare for this project. I would like to request you to have a look and provide your inputs. So I can improve it. Thank you.
thanks. I guess I'll really have to bite the bullet and see if I can work out how cgogen works :) EDIT: ...or just use C#. I'd have prefered to use GO as it's my go-to language whenever I start a new project, but in this case it goes down to "use whatever works" 
then do not put in hot path but push to separate goroutine(s) ?
Maybe [go-swagger](https://github.com/go-swagger/go-swagger) can help you with that.
What exactly did you find lacking from the standard library + 3rd party router + Gorilla framework, which seems to be the community standard recommendation, to satisfy those needs? And more importantly, at what level of insatisfaction did you decide that it was worth breaking compatibility with the ridiculously huge ecosystem around net/http?
@alasijia thanks for pointing this out. I missed this. I have edited the tutorial and credited you.
Ah, I guess I just looked at reddit headline "A complete guide to structs in Go" . The original article has reasonable headline.
https://github.com/rif/lov3lyme this one uses only tool-kits no particular web framework. 
In my experience, go is fantastic for network-based development. The standard library is more complete for networking than any other language I've used. It might be best left to professionals, but go is very easy to pick up and read, in my opinion. Recently, we had a huge C# project in production, but due to poor development, a service that pinged an endpoint every two minutes went down. I was able to write a 10 line go program that replaced the external network service and have the service working as expected in 20 minutes, and it didn't require anything other than the standard library
None of that makes any sense, but especially the "attack vector", excepting inasmuch as any third party library you have ever used is an "attack vector", which is true but not generally something you can afford to worry about.
No, solution is nothing like a binary algorithm tree traversal. You never compare a single value in the tree. Second yes it's only discarded if the capacity changes.. which it was always going to in your case, you provided a zero length value and no cap, when no cap is given len == cap. In your case it was just exactly as I said, yes, you passed the slice header by value. So all appends that called into a new function where discarded, leaving only the length and capacity that grew in the top level scope of your slice. Anyways glad your problems fixed take it easy.
42wim made a great list, add https://github.com/osrg/gobgp to it. It's a fairly sophisticated BGP daemon with a CLI. 
If this helps, there's a new book from Apress called "Network Programming with Go". I was just going to pick it up - hopefully it has good stuff in it. Apress usually comes out with decent books. http://www.apress.com/us/book/9781484226919 
Former ops engineer turned developer here. Time to offer unpopular dissenting opinion. Bracing for downboats. It's typically faster to build a stable solution providing high throughput, concurrent operations in Python than it is to build the same thing in golang. One of the only reasons for this is golang is still in its infancy, and it's very likely there's already a python module that does what you're trying to do. Not saying go isn't great. I love it, or I wouldn't be subbed here. I'm just saying that depending on your deadlines, python might still be the better choice. 
Sorry about that, it was a bad joke. 
It's too early to tell if the book is any good - no one's posted a blog or review yet. Overall, I've had good luck with Apress books, especially those dealing with SQL Server. And I only order digital versions, so don't know about the softcover.
Thanks, dad.
I was surprised to see Jetbrains just release a dedicated Go IDE, but the numbers they had for their original Go plugin justified it to them. It has over 600,000 downloads, and to JB that equated to pent-up demand.
I can't quite see what gomplate is good at from that wall of text ramble, but I've used https://github.com/jimmyfrasche/txt a bunch and like it.
&gt; Web Push Meaning the Google Cloud service, not HTTP/2 server push. That `generateVAPIDKeys` function looks pretty trivial: https://github.com/web-push-libs/web-push/blob/99fe255f850eb156224cc5e488c656fe630f1fd9/src/vapid-helper.js#L30-L38
I should have noticed this before, thanks. I found just the [right](https://github.com/enceve/crypto) package to generate the keys.
I'm not sure about the exact footprint in Python, but I have a very similar application I can compare it with. The project goal was to analyze 75,000 endpoints for behavioral indicating a high probability of imminent failure of a particular system component on that endpoint. 4 threads total running 2 separate event loops concurrently processing 1,000 endpoint "blocks" using asyncio coroutines. Memory usage was extremely stable around 250MB, but it would pretty quickly max out the processor without the artificial 1,000 endpoint block size. It really sounds like a difference in design patterns, though, specifically focused around a time/space tradeoff. In my case, I was fine waiting an hour for the results to come back if I was able to do other things in the meantime. In your case, I'm sure it didn't take an hour to work, but the 1.1GB ram usage would have been a bit much for me to explain to management. 
It can be installed locally, i'm sure it can but what are the steps?
For enterprisey needs: * A full [XPath](https://www.w3.org/TR/xpath/) implementation. * A [Canonical XML](https://www.w3.org/TR/xml-c14n) implementation. * An [XML Signature](https://www.w3.org/TR/xmldsig-core/) implementation. * An [XML Encryption](https://www.w3.org/TR/xmlenc-core/) implementation. * A [SAML](http://saml.xml.org/) implementation. Listed in the order you'll need to tackle them...
The pro developer doesn't have to be in-team. He/she can simply advise development from afar. I've done it in companies large and small, and the payoffs well outweigh the additional cost.
&gt;If you want to know why you're wrong about binary trees A binary tree is pretty simple. You start with a node and go left or right down the tree. That is exactly what my code is doing. It takes an initial node, then goes left (don't add to subset) or right (add to subset). That effectively builds a left branch and right branch. It then treats that new node as the root node and does the same thing over and over. The data can be represented via a binary tree. &gt;The fact you state discarding the slice header is not a problem.. Correct, I don't see how it is a problem. Maintaining the slice header IS the problem in this case. &gt;only to go in depth explaining you mutate two separate slice headers with the same backing array as your issue. The reason I say that doesn't matter is A slice header contains a length and a pointer to the start of the array along with a cap. Append only creates a new header (creating a new backing array) if the cap is insufficient. When I pass that slice into my recursive function it creates a new slice by value, but that doesn't matter in itself. The problem is it maintains that pointer by reference. In my original implementation I don't have problems until len(subset) = maxL -1. Because it's passing that a slice referencing the same array off in many directions, that will be modified multiple times, even after being added to my solution set. You aren't wrong about me creating and discarding slices, it just wasn't the problem in itself. The underlying cause was that while I was creating new slice headers, they weren't against new backing arrays. So yes, I mutated the slices, but in doing so I also mutated the underlying solution set. I could have maintained the same slice, but then it would have been mutated in ways I wouldn't want it to be with recursion. &gt;suggests your not looking to learn but win an "argument". I'm not trying to "win," I'm all about learning. But you have failed to explain why you think I'm wrong. I'm saying why I disagree, and you haven't really said anything that is of relevance to the problem I had. &gt;I've been writing in this language for years and was just trying to help. Great, I've been in software development for 15+ years. Pointers, passing by value, and data structures aren't new to me either. I just brain farted with how go handles passing of slices. Here is a GIST of why I'm trying to say it didn't matter if I maintained the slice header or not. As long as the backing array is the same, I will have problems. https://gist.github.com/anonymous/3277d54e1d55b7791b02f2a78353c50a 
Ah, good thing there's a compatibility layer. I don't like the extra layer of indirection (specially since net/http requests can get their own context as of Go 1.7) but as long as it's there that's good. I get your idea of making choices for the developer. However, I believe that it's better to just write a text file that recommends a library for a purpose rather than bring an opinionated way of doing things that tries to accomodate for all possible scenarios (but inevitably, bringing more than what's necessary or not being a good fit). The community and the language authors mostly agree on the "small, composable libraries over frameworks" approach; and it makes a lot of sense to do it this way thanks to the way Go interfaces work. I for one would rather see more stuff like the Gorilla toolkit than "frameworks". I don't want to have to learn or deal with features I do not need. If I need something, I'll search for a library that fits the bill (or write my own) and for this, I reach out for resources like [awesome-go](https://github.com/avelino/awesome-go) that list me some good options rather than a complex suite of functionality like a framework that can fail in unexpected ways and abstract things to the point it can make debugging unnecessarily difficult.
Can you give an example of what you want to do? I'm not sure what your concern is specifically.
https://github.com/seiflotfy/mcs I wrote that a while ago might need some fixes. But it used to work :D I can help you set it up again
I thought the same thing, but the Flatbuffers specification actually allows the serializer to control the ordering of fields to allow for {back,for}wards compatibility. So, technically, you can't rely on doing a byte-for-byte diff to compare a flatbuffer payload on-the-wire, since the ordering of member fields is not defined. My lack of better ideas is why I didn't post earlier.
Okay, thanks for the refresher course on append. I concede to your 15 years of experience anon. Happy coding.
Yeah, I was thinking about this. I almost wonder if you could have a goimports-style tool that would notice special import paths and do the specialization of the package for you.
Okay, I guess that is a better approach. I'll check it out, thanks!
I might have missed something but why did you opt for more memory/CPU instead of more space? Space is the cheapest. Of course that would mean that you would need to swap from BoltDB to something else that is optimized for random writes. But this is something you need to do at some point one way or another because as it seems, you are currently using the wrong tool for the job. The unsafe calls are a cool experimental gimmick and certainly interesting to read about but personally I wouldn't want them in my production system.
Hi all, I figured out my issue finally. I was pushing the offsets to a slice declared as var treeOffsets, nodeOffsets []flatbuffers.UOffsetT And for some reason appending to these didn't take, and I had to change to treeOffsets := make([]flatbuffers.UOffsetT, 0) nodeOffsets := make([]flatbuffers.UOffsetT, 0) And this fixed it. I thought append will allocate a new slice if there's no room, but I may have misunderstood how it works. The final output is still not exactly the same for the 2 languages, but as /u/therealfakemoot said, the two may not be byte-to-byte the same anyway. 
This is super cool.