http://play.golang.org/p/UqVOPKo5D9
I only want to develop on Windows. It'll be running on raspbian
When you do `os.Args[1:]` you're re-slicing os.Args into a new slice and then `range`ing over that new slice. The new slice has indices starting at 0.
I think that the value of index o is the name of the program that is executed.
Gonna have to try that as well. I run Opengl 3.1 mesa on linux and am able to run and program opengl code in languages like java and c++ which makes this odd to me.
Good question. Op, what's the difference?
Please check to see if a link has [already been posted here](https://www.reddit.com/r/golang/comments/3zjr80/improving_performance_with_byte_slice_and_int_map/) before posting.
Quite a luxury that they are working on it so hard! Awesome I notice that performance isn't their top priority (I presume because it is pretty fast as it is and features are more important), I would be willing to contribute in this regard (compiler optimization phase). Anything I must know before contributing? Any tips on where to start looking?
Yes, just put it next to the Go sources. The go tool will simply ignore it.
I might be misunderstanding the question, but doesn't the ReturnChanges option do exactly what's desired in this case?
That becomes nearly impossible.
A *monorepo* is a monolithic code repository which contains many different projects and libraries.
No worries. I just rage about little UI issues like that. Anyway, mocks are easy in Go. I find GoMock to be too complicated; any time saved on boilerplate keystrokes seems to be more than made up when it comes to reasoning about how to use it (this is my opinion). Anyway, mocks don't need to be as complex as yours. his is how I write my mocks (specifically note that the mock's job isn't to validate itself, just to record information about it's calls--invoking methods on `*testing.T` will only mess up your line numbers when tests fail): package temp import ( "bitbucket.org/weberc2/testutil/tu" "testing" ) // This is the interface we want to mock type EmailSender interface { Send(subject, body string) } // This is the "production" function we want to test func CallsSend(sender EmailSender) { sender.Send("Hello", "World") } // This is the start of the mock code; this is just a handy struct to represent // a call in the call list type call struct{ subject, body string } type SenderMock struct { // I like call lists because they let me assert about the call count // and the values passed each time. This is mostly useful when a method // could be called multiple times in a test case. Calls []call } // The mock Send() just stores its arguments in a call frame which is pushed // onto the `Calls` list. func (m *SenderMock) Send(subject, body string) { m.Calls = append(m.Calls, call{subject, body}) } func TestCallsSend(t *testing.T) { var mock SenderMock CallsSend(&amp;mock) // calling t.Fatal() here won't mess up the line numbers in the failure // output, unlike if they were to be delegated to some helper method if err := tu.ExpectEq([]call{{"Hello", "World"}}, mock.Calls); err != nil { t.Fatal(err) } }
As a suggestion, consider expanding a little on your README.md. A feature list is very important, and since it's a GUI application, screenshots are *very* important to get users and potential contributors. Alternatively, instead of the README.md file, you can use GitHub Pages if you want a bit more control over the presentation.
&gt; because a traditional Java Application might take someone half a day to setup just to run a hello world on a server Not sure from where these kind of claims came from. With tools and that Java has, it only takes as much time as it would in any modern language or may be lesser. Java's main problem in today's world is verbosity and it is a bit bulkier. But productivity wise I don't think today Java with its toolset is any less productive than Go or any other language. 
Thanks for the feedback, but I'm too lazy. I host info on my blog with screenshots at http://just.ninja/hostcontrol The only future modifications I'm making to the repo are as listed on my blog unfortunately. I have other things I want to get on to. 
This is only semi-sarcastic, and I might get the downvotes, but you should read everything here: https://dancres.github.io/Pages/
I created a similar package for JSON: https://github.com/nicksardo/jsonpath My design choices: * Constant memory usage * Don't load the entire document into memory -&gt; stream-in &amp; throw away * Don't even load the entire structure into memory -&gt; follow the path while parsing * Early termination * Package will terminate parsing when value at end of path is found * Client can cancel parsing at any time (graceful termination for those large XML documents) * Support expressions * Ability to select elements based off expressions of child elements. 
* Support for Windows environment (mainly IO operations) afaik, totaly, no problem to do simple things. * Support for MS Excel interop See https://github.com/go-ole/go-ole/blob/master/example/excel/excel.go * Script linking / calling classes and functions from separate scripts if you will do "go run", it mean that. * GUI support or existing GUI libraries See https://github.com/avelino/awesome-go/#gui * Decent debugging tools gdb 
https://github.com/mattn/go-jsonpointer or https://github.com/mattn/go-scan
Go is my favorite language, but when it comes to automation Python pops in my mind, not Go. Automation tasks are the kind of thing that can break often and need frequent hacking. Go is built more for making robust software. Python is more suited to the "move fast and break things" style development IMO. I'm sure someone is doing a gorgeous job at automating everything they do with Go, as there are people doing it in C or Javascript, but Python has a good ecosystem for automation, is forgiving without going too far... just dropping my 2 cents here.
You totally want Powershell for this. Integrates with .NET easily, natively works and so on. I would use Go for things that must work cross platform, and cross compile it. Best of luck. 
Your example is running well on my laptop here, an Intel iGPU on Linux too. I also tried the OpenGL 4 cube using the discrete Nvidia GPU via Bumblebee (since the Intel Mesa drivers don't have support for the extensions it needs) and it also works well.
I appreciate the advice, it sounds like you have some experience to speak from. I will create some demo scripts in powershell and have QA try to break them. That's the true test, how much hair do you pull out when fixing an issue lol.
That's the main pattern. One other is to create methods like: func MustMakeThing() which will panic or log.Fatal if they fail. The Must prefix indicates it has to succeed or it will panic (used in the regex package for example). Note that if you use: if thing, err := MakeThing(); err != nil { // handle error } the thing variable is only available within the braces, so it's mainly useful when the method only returns and error and nothing else.
This is true. Python's exceptions are a little too ephemeral, and Go's method of making errors actually part of the code makes things clearer.
Nice video, subscribed your channel, waiting for more like how to set up MRUnit , how to use counter in mapreduce.... 
As a fellow Pythonista it's common at first to think "I'll just panic and recover!" but the Go order of events is to unwind first and look for recovers later, so it's actually nowhere near Python's raise/except system. I pretty much only use panic to kill an application with a stack trace. The defer/recover thing is just not how I reason about code if I can help it.
https://blog.golang.org/errors-are-values
Your shot isn't so long :-) This could be a good compromise. Thanks!
I need to receive and send midi events, for musical purposes. I can't afford to go down to USB level. Thank you, anyway. P.S.: very interesting project! Kudos!
I use defer/recover only at top level of each goroutine to collect and report errors before terminating (or restarting routine). Makes program more robust. Compared to Python, D and other exception languages, I find Go's error approach more simpler and reliable. More than once I forgot try/catch block that caused me a lot of grief. In Go that is impossible, even with error default returning value (zero usually) can cover most cases.
&gt; I'm sure that despite saying I've been primarily a linux user for over 8 years won't keep Gophers from downvoting me for this: Saying rational things in /r/golang or /r/programming won't get people downvoted. This isn't /r/politics. :P
I've used godep for quite a long time but I'm not really happy with it (especially with GO15VENDOREXPERIMENT it has had many bugs). Has anyone tried any of the other tools on the list and had a pleasant experience?
Personally I hate negatives. I would much prefer 'if err' - handle error. 
You're right, the temptation to just panic and let the error bubble up to a more recoverable place is very strong. (As is the temptation to write my variables in `snake_case`, but alas.)
Yeah, `if err != nil` is quite readable and it states exactly what you're doing. Besides, it's literally everywhere in existing Go code. Not saying `if err != nil` in Go is like not calling the self argument`self` in Python.
When you do this kind of error checking: if thing, err := Makething(); err != nil { ... } **thing** is created in a new scope, so it is not usable outside of the if/else, even if it was declared before.
No, These are not official instructions.
the {} introduces a new scope, and the name in the main function shadows the outside name. What you should do here instead is consciously avoid using the same name. Also, you could create a top level struct called e.g. "global" that has a field "name". You can really do that however you want, but keep in mind that avoiding globals can spare you a lot of problems ;).
Executing before panics makes sense actually, because then you could use them as a mandatory cleanup action (`.Close()`, etc) that happens regardless of any panics. Thanks.
I am using gvt for now. Glide currently downloads the whole internet and Godep hasn't worked so well for me.
It is, when you have multiple exit points (returns or even panic) or complex work flow it would be much harder and error prone other way. And it is much more readable to group defer code at function start or grouped with relevant code (open file, deferr close file etc.).
Hmm, I guess it does make sense to bundle all your open/close statements into one chunk at the beginning of a function, before entering an actual workflow.
Gvt is working fine, the way I'm working right now is that go get is fine for pre-1.0 and then wipe out $GOPATH and use gvt to fetch only the minimum packages needed to build and test then do a dep freeze on 1.0. So far so good. Edit: as more software gets built this may change to reduce version drift between the various services and tools we have. but for now it's ok. It would be great to specify version numbers but that would require go developers to stop simply shoving code into master and actually tag releases. We will see
&gt; Go ... forces you to handle them or pass them along. You're not forced to handle errors: func foo(i int) error { if i == 0 { return errors.New("I like errors") } fmt.Printf("Hello %d\n", i) return nil } func main() { foo(1) foo(0) // Oh no, I forgot foo can return an error! foo(2) } When you need to perform foo3, for which you need data from foo2, for which you need data from foo1, every step of which may return a value or an error, and in the case of an error with each step, you need to do bar and then exit, don't you sometimes wish you had a try .. catch .. finally type construct? Yes, I know the go way is perfectly workable, but is it always the most elegant? Apple decided to move to a try .. catch syntax with swift 2.0 after starting with a go-like approach. 
I would echo statements on Python as the go to for this or even .Net. Right tool for the right job and all that.
You are right, when you *can* handle the error (And when you can, you also should). In some cases the only thing you can do is log and panic (or return error 500 if it is a web app, etc.).
True, but I do wish that Go's `error` type contained a bit more metadata or logging capability. When working with Go instead of Java or C#, one thing that I miss dearly is having detailed stacktrace information available. If I call a Java method, and it throws an `Exception` from somewhere within... the caller can inspect it, apply different handling based on its type, write it to the log file and automatically have a detailed stacktrace with code line numbers, etc. None of that power exists in Go. There are no sub-categories of errors, there's only the single `error` type. And `error` has no idea what line it occurred on, or reflection-inserted stacktrace knowledge of any kind. It's just a dumb wrapper for a `string`. Yeah, you CAN work around this by conventions. Always `log.Printf(err)` an error with detailed context info at the spot of occurrance, before returning it to the caller, etc. However, that's REALLY clunky, leads to a lot of double-logging, and even in the best-case scenario is still just lame compared to most over modern languages. Inexplicably, Go's `log` package doesn't support levels (e.g. debug, info, error) like every other logging framework out there today. It's nothing but `fmt` with a timestamp prefix. I like the fact that Go encourages you to deal with errors when the occur, rather than "swallowing exceptions" or "always throwing exceptions" like other languages. However, let's not delude ourselves... Go's overall error-handling model is extremely primitive, and not in a good way.
You can use annotated errors. * [spacemonkeygo/errors](https://github.com/spacemonkeygo/errors) * [juju/errors](https://github.com/juju/errors) They allow attach position and/or message. 
can you try how e.g. 0AD runs on your system?
I do wish that every return value had to be handled, even with just `_` to make it explicit that it was being ignored.
Passing the error to the caller:: func myfunc() (err error) { val, err := errorprone() if err != nil { return } // do something with val } 
As of go1.6beta2 8029 lines of `err != nil` 1792 of those lines are of `if err := [x]; err != nil {` 5745 of those lines are of `if err != nil {` The remainder are either of form `if x.err != nil ...` or `if [string] != "[foo]" || err != nil {` or one of the above with a different name for err. Basically you either start thinking about the implication of errors or you suffer the turmoil of typing out something you refuse to think about over and over. I don't recommend the latter. 
&gt; generics massively increase compilation and execution time Generics come in a couple of different flavors, popularly referred to as "templates" and "type erasure". Templates let you write one version of your algorithm on a set of "type variables", and then when you use that template in your code on real types, the compiler will generate the code for that type. Basically, templates can be thought of as having the computer write the code for you. Templates do increase compilation time because the compiler needs to generate code, but this is sort of an illusion because it's still only a tiny fraction of the time you would have spent writing the code manually. Templates do not increase the runtime at all (remember, templates are just having the computer write code for you). Even in this case, I see no reason why Go's compile times will need to approach those of C++. Type erasure is a bit different in that it operates on pointers instead of value types. Because all pointers are the same size, one generic algorithm can be reused for all implementing types (cutting the compile time); however, there is a performance penalty because the compiler will need to generate the code to reference/dereference your value types. I don't think the performance penalty here would be worse than if you were to implement your own algorithm using `interface{}` (which is effectively the same reference/dereference problem), but generics would at least guarantee your type safety. With that context in mind, if you write your template to operate on pointers rather than values, I would expect all types could share an implementation, which would cut the compile time for templates the same way compile times are reduced for type erasure. This means templates could allow the programmer to make the compile-time vs run-time tradeoff rather than the language always opting for fast compilation and a small runtime hit. I really want to emphasize again that the compilation penalty is just an illusion--it's the time the computer takes writing the code that you would otherwise be writing by hand. So while it might take a few more milliseconds to compile, it's still better than the minutes you would spend writing it (and updating each version every time you want to change the algorithm, etc).
 package main import "fmt" var name = "Josh" func main() { globalname, name := name, "Ben" fmt.Println("Hello ",name,"and",globalname) } The point here is that you recognize you are explicitly changing the `name` variable to a different scope yet still intend to use the global `name` too.
You can also do a HEAD request in most cases to just get the headers.
Have you tried killing your compositor?
That whole "no sub-categories of errors" thing simply isn't true. Since errors are interfaces, you can have errors that include that information. Now it may not be built-in, but there's libraries out there which do just that.
Yeah, if I were designing Go 2.0, I'd change `error` to be an interface of `Error() string` _and_ `Source() error` so that you can chain errors (the last error in the chain would just return `nil`).
Per request, this has been done. :)
Thanks for clearing that up!
so far the issue with glide its not bad that will stop me from using, for far the experience with it has been amazing and super smooth.
Would be better in this case to return a (bool,error) since you are interested in the side effect. In some cases, a wrapper that panics on error could be appropriate.
[A-J]1?[0-9] I *think* that's what you're looking. 
test := "D1 A67 J12 K9" r := regexp.MustCompile(`([A-J]\d\d?)*`) fmt.Println(r.FindAllString(test, -1)) gives me: [D1 A67 J12 ] https://play.golang.org/p/nVt-Xq7AES [edit] If you really want to be strict about it: test := "D1 A67 J12 K9 AA8 u769 uu876" r := regexp.MustCompile(`(\b[A-J]\d\d?\b)*`)
Yes, instead we just get generic `error` strings with no identification as to what kind of errors a function might throw. ``` public User getUser(String id) throws UserNotFoundException, ConnectionExcetion { } ``` Versus ``` func GetUser(id string) (User, error) { } ``` As a reader of code, I find it a delight that I don't have to worry about what exceptions might get thrown in function calls. Except when the function's signature literally defines what exceptions will be thrown and the IDE takes care of the rest. As a writer of code, I find it a delight that I have to read the actual source code of a Go function to determine the types of errors it is capable of returning so I know how to handle them. No, wait, that's not a delight; that's abhorrent. I'm actually amazed at your opinion: its completely wrong in the case of any exception throwing language which requires (or at least allows) throwable exception types to be declared in the method signature, yet simultaneously ironically points out a glaring deficiency in Go. 
And still you can't get rid of code structure. The nice thing about organizing code in packages and structs (and therefore not doing what's been called "polluting" here) is that it's always clear on what every line of code depends, which is an enormous help in understanding and refactoring code. Large packages full of top-level code never provide this clarity, even when nearly everything is "package private".
I got really excited about /u/peterhellberg's post and I may have 'overcommitted' myself. This week I rewrote a word-tree parser (at least the part that was taking over 60 seconds in ruby for a large project) in go and attached a few methods to the original ruby class. Things work amazingly, except sometimes I receive back from go a string with extra characters (...\"friends\",\"and\",\"family\"]]}]@e&amp; \xC8") - subsequential calls to the same method would randomly return the correct string, and differently formatted incorrect strings. Granted, I can 'trim' the string, but that does not solve the problem. I've only been experimenting with go for a week now and this is my first experiment with FFi. I've been changing the :pointer / :string as argument of the attached method with different ratio of fail / success ... https://gist.github.com/etozzato/5cc4c566d5c54e366d18
Your benchmark and discussion of `math/rand` and `crypto/rand` seems to completely miss the point that these serve completely different needs and **should not arbitrarily be interchanged**. I.e. it's an apples vs oranges comparison. If you're doing cryptography (e.g. you need a nonce, an IV, an AES key, whatever) then you damn well better be using `crypto/rand` (or some other cryptographically secure (pseudo)random number source) and you shouldn't care that it's slower than `math/rand`; if you use `math/rand` for crypto stuff you're implementation will not be secure! On the other hand, if you don't need cryptographic quality random numbers then you'd have no business using `crypto/rand` (except for limited quantities, e.g. it's an great idea to use `crypto/rand` once to seed a PRNG rather than using time). One reason is that some system's cryptographic random sources have a limited pool of entropy and consuming that can either slow down the source or turn it into something more like a PRNG. (Although modern good OSes doen't really suffer much from this, it's still a concern). 
More importantly, you can actually type assert or reflect to get that information.
This does break down when you have jackasses like me who use fmt.Errorf() for everything because creating my own error class is too verbose.
Although in Go you still don't know if you're handling all errors correctly, since you don't know the set of all things that could implement the error interface. Sometimes I wonder if the idiom should have been `func() (OSError, IOError, ParseError)` instead of `func() error`.
That is a mistake but not a full blown bug. Thanks. There's another spot where I set the accept headers using `gzip` in the straightforward "if gzip is true then accept gzip" manner. Compression, however, should always be turned off, since turning on compression transparently hides gzipping from the downstream consumer. So, I should replace `DisableCompression: gzip,` with `DisableCompression: true,`. Edit to add the docs for `DisableCompression`: // DisableCompression, if true, prevents the Transport from // requesting compression with an "Accept-Encoding: gzip" // request header when the Request contains no existing // Accept-Encoding value. If the Transport requests gzip on // its own and gets a gzipped response, it's transparently // decoded in the Response.Body. However, if the user // explicitly requested gzip it is not automatically // uncompressed. DisableCompression bool 
The problem is DRY though 
Without looking at the code, on mobile. Compilation makes the 'default' int to either int64 or int 32 depending on arch. I'm still lying in bed and may come back to it later on today if nobody else does. But I hope that bit of info helps. 
Both the best and the worst. The language maintainers sticking to their guns as if err != nil being somehow elegant is hogwash. The standard argument is "I don't have to worry about what exceptions might get thrown" or some such. Go look at any major Go lib(Docker, InfluxDB, Go itself, whatever) you'll see hundreds or thousands of: if err != nil return err All you're doing it passing the error back up the stack, just like an exception. And at some point you write an error handler that logs it and shows a message to the user, just like an exception. The only difference is that you have to do it manually, and without error types. Joy.
&gt; Basically you either start thinking about the implication of errors or you suffer the turmoil of typing out something you refuse to think about over and over. I don't recommend the latter. When prototyping code, I used to do val, _ := func() Eventually an error would occur and I would have to do fmt.Println() to find the problem only to discover I was ignoring the error and forgot. Kinda of annoying that I have to think about all the errors that could ever happen, but it definitely does make for more well defined code. 
I don't plan on testing on Windows, that's purely for development. It'll be tested on the Raspberry Pi on Raspbian. Fixed the issue by setting GOOS=linux while I'm developing. Of course I'll be cross-compiling properly once I'm ready to put the binary on the pi
I'll code where I want? I'm not gonna use my Pi as a dev machine, are you mad?
you can use a json.Decoder and call the function Decoder.UseNumber() that will unmarshal to a json.Number instead of float64 https://golang.org/pkg/encoding/json/#NewDecoder https://golang.org/pkg/encoding/json/#Decoder.UseNumber https://golang.org/pkg/encoding/json/#Number
Ah, that's it. Thanks!
maybe you should be calling the error handler httpErrorHandler ?
You might break up the array into NGoRoutine contiguous sections so they aren't all writing to the same memory pages. See if that helps. Also look into sync.WaitGroup, it could simplify your final wait.
Also, older versions of go have GOMAXPROCS=1 by default.
I think the problem is the four go-routines are doing a lot of redundant work. I think you want to break the array up into NGoRoutine chunks and have each go-routine write to that section in parallel, not have them overlap. Here is a quick and dirty version that on my machine is about twice as fast as the original version: package main import ( "runtime" ) const ( NGoRoutines = 4 ) var array [100000000]int func main() { c := make(chan int, NGoRoutines) runtime.GOMAXPROCS(NGoRoutines) chunk := len(array) / NGoRoutines for i := 0; i &lt; NGoRoutines; i++ { go func(start int) { end := start + chunk if end &gt; len(array) { end = len(array) } for j := start; j &lt; end; j = j + 1 { array[j] = j } c &lt;- 1 }(i * chunk) } // wait for goroutines to finish for i := 0; i &lt; NGoRoutines; i++ { &lt;-c } } running this code gives me: $ time ./parallel-fill real 0m0.234s user 0m0.156s sys 0m0.266s vs the original: $ time ./parallel-fill-orig real 0m0.431s user 0m0.377s sys 0m0.235s Hope that helps.
Now that you have identified the problem, step two is fixing it. :) 
I don't know of any less-verbose solutions, but I'm open to suggestions.
Have you seen Rob Pike's "errors are values" talk? There are ways of structuring your code so that every alternate line is not "if err ...". 
There aren't any less-verbose solutions, but come on, it's 4 lines of code, and that's counting the closing brace. type MyError struct{} func (MyError e) Error() string { return "This is my error." } Then you can just `return MyError{}` Is it a big deal if you aren't writing a library? No. But it's very little effort for a nice boost in code cleanliness. That's what Go is all about: doing more with less. Edit: mistakes
~~Further, there's no reason the func needs to return just `error`. You can have a signature like `func Foo() FooError` and effortlessly assign the return value to an `error` variable as long as it satisfies the interface.~~ That requires no more effort than knowing what the return value of the func is in the first place. This is Go's whole approach to error handling: Errors are just data, and error handling is just code. It's not special. Edit: Never mind. Returning `error` is better.
Every time you recommend somebody use reflect, a baby kitten dies.
AFAIK, in the case of Negroni, idiomatic means the absence of Reflection "magic" that its predecessor Martini uses a lot.
Use gometalinter to be sure, it emits warnings on ignored errors. 
Yea I was thinking that too, at first. It seemed like everything was good when that library first came out. No more magic. But then I've read conflicting articles about its custom types that aren't compatible with native go net/http, which made the case for it to still not be idiomatic. I guess we may never reach a consensus
I love the way how Go handles errors for its simplicity. BTW, another related cool feature are the [Defer, Panic, and Recover functions](http://blog.golang.org/defer-panic-and-recover). I use them extensively, not only for errors, but as a way to exit quickly of a series of nested functions. The below web application example, I use them to print errors and to redirect to other url. package main import "net/http" func CheckError(err error) { if err != nil { panic(err) } } func Redirect(url string) { panic(url) } func handler(w http.ResponseWriter, r *http.Request) { defer func() { if rec := recover(); rec != nil { switch rec.(type) { case string: url := rec.(string) w.Header().Set("Location", url) w.WriteHeader(http.StatusFound) case error: err := rec.(error) http.Error(w, err.Error(), http.StatusInternalServerError) } } }() if user_not_logged() { Redirect("http://site.com/login") } err := do_something() CheckError(err) do_more_stuff() } func main() { http.HandleFunc("/", handler) http.ListenAndServe(":8080", nil) }
Point being that it could be: &gt; RecoverOnError(err,functiontorevocerwith()) Or whatever you please, all the same no conditional statement need to be written out in the middle of one's code if it's not wanted.
Thanks so much for the helpful reply. What would be some good Go code to study on github? Ideally not something *too* big.
I'm not necessarily saying "don't study it", just "don't assume everything they do is good". Just read code by different people and keep an open mind and feel free to question peoples approach (as you did here, IMO correctly) :)
Thanks for the correction. I haven't had the luxury of writing Go much lately. Stuck in Java Land. But why should it return `error` over `MyError` in this case, assuming it never returns a nested error that may be of different type? That seems like deferring information to runtime for no reason.
The race detector works by tracking the various reads and writes. Storing a stack for each of these consumes a lot of memory, so there's a limit, called the "history_size" (Defined by https://golang.org/doc/articles/race_detector.html as "history_size (default 1): The per-goroutine memory access history is 32K * 2**history_size elements."). "Failed to restore stack" is not an erroneous report, but rather a race report where the stack is not available because it hit the limit. In other words, you need to increase the history_size. Ignoring the error means that you're ignoring a race. Alternatively, you could simplify your code or test so that it won't hit the limit.
You just have all the error handling hidden away, easily forgotten about when you add new potential errors, and if you do it wrong panics that you *don't* intend will be suppressed. Panics are not exceptions, and shouldn't be used as such. There are too many leaks in the abstraction.
Don't do this. There are reasons (I wish I had the links handy) of why this is a bad idea. It's for those unlinked reasons that in `os` there are many functions documented as returning either `nil` or a `*os.PathError` but the signature is purposefully `error` and **not** `*os.PathError`. Edit: from the [FAQ](https://golang.org/doc/faq#nil_error): &gt; It's a good idea for functions that return errors always to use the `error` type in their signature (as we did above) rather than a concrete type such as `*MyError`, to help guarantee the error is created correctly. As an example, [`os.Open`](https://golang.org/pkg/os/#Open) returns an `error` even though, if not `nil`, it's always of concrete type [`*os.PathError`](https://golang.org/pkg/os/#PathError). 
&gt; copy and paste FYI, you can add `.go` to the end of a play.golang.org link to get a download-able/save-able version of the source: https://play.golang.org/p/JogUNCX19d.go
Alpine adds only 4.79 MB overhead to the final image but gives you really friendly environment if you need attach into that image in order to troubleshoot some issue. IMO, Debian-based images is too bloated for most cases, scratch/busybox is too extreme while Alpine-based images is a sweet spot.
True, but there's not much reason to use an int64 for the size. You won't be able to allocate a slice larger than int32 on a platform where int is 32 bits anyway.
Definitely for errors you should just be doing type assertions. I don't think many kittens have died over the use of reflect in e.g. the standard json module, tho. :)
Nifty!
[Adding another error case _should_ break API compatibility.](https://www.youtube.com/watch?v=ilcRS5eUpwk) By adding another error case you are saying "something about the purpose of this function has changed so fundamentally that its capable of failing in a whole new way." By changing the function signature you can guarantee that every caller is now capable of handling the new failure case. This is powerful and a huge upside to this method, not a downside. 
well, had to turn back to this point again. Some of my fields aren't strings, is there a way to make it work? besides converting the strings?
No. Edit: Yes, change your field to string.
&gt; With tools and that Java has I guess it's because one needs a serlvet container ... ... whereas with go it's just 3 lines of code and the default compiler. If java had an http server in its core library without requiring glassfish or X, Y ... things would be simpler. Anyway, any java pro dev needs to know at least JEE + Spring , or one can't call himself a java web dev. With go one only needs to know the core lib.
It is an interpreter, not a interpreted application. There are interpreters for Javascript, Python and probably many more languages in the iOS app store. The point is that this is an (compiled !) application that is mainly written in Go. 
That's correct. The interpreter code was completely written in Go, compiled as a static library, and then accessed in iOS with Objective-C bindings, using the gomobile tool.
I don't know of another way to reliably get type information from an `error`. Do you?
A type switch (to be safe against panics) or, if you're sure what concrete error type is returned, a bare type assertion.
Oh wow. Thanks for the tip. I'll have to think on this a little more to totally understand it though.
I've been using Go for OpenGL stuff and it runs great. Make sure you're using a recent version of Go and glfw and that your graphics drivers are setup properly. If you're having trouble running OpenGL stuff unrelated to the Go example, then it sounds like your system is misconfigured somehow.
Well, you're right. It would be better if I added something along those lines since it's something I certainly did skip. It's an important distinction. For more context: the post was in response to people asking "why not use crypto/rand" after I posted about locking in math/rand. In the real-world app I am making, I did use crypto/rand to seed math/rand instances to ensure some real randomness gets in to the process, but from then on I didn't touch crypto/rand at all. EDIT: I've updated the article making this point. Thanks for calling me out on that. It should have been in there in the first place.
I'd like to pitch in here, just because I don't feel like people have been explaining your problem and their solutions quite well enough. First off, the _only_ problem in your original attempt was the `{2}` tacked onto the end of the regular expression. The reason is that `{...}` is a notation for regular expressions that say "match the previous value some specific amount of times." These declarations are powerful, you can say things like "match 1 or 2 times" (what you probably wanted) `{1,2}`, or even "match 1 or more" `{1,}` (FYI, "one or more" has a special character `+`). So your original expression (with a simple modification) `[A-J]{1}[0-9]{1,2}$` gives you exactly what you want. One other thing to note though, while not an error, the `{1}` declaration is redundant. Simply specifying a character, character class or group is automatically only matched once. So just saying `[A-J]` means "match a single letter between capital a and capital j." All in all your shorter regular expression is: `[A-J][0-9]{1,2}`. We can make one more "optimization" if you will. I quoted that because it's not really an optimization in the form of a speed and potentially a minor readability optimization if your reader is familiar with standard regular expression classes. The character class `[0-9]` is predefined as `\d`. It's negation, essentially `[^0-9]` is `\D`. The negation doesn't matter but we can use the class itself. So the final version of your original expression turns out to be: `[A-J]\d{1,2}`. We still get the same results as another comments example: `[D1 A67 J12 ]` (http://play.golang.org/p/BV2iQ8fLYh). Hope you have fun with more regular expressions! **Note** I never really addressed it, but I dropped the the `$` from the end. You probably don't want that for reasons mentioned in another comment (due to `\n` not matching it unless in multiline mode).
While I can't speak to Android development specifically (and I don't really know what you plan to make), I can say that Go is a solid language that's obviously been designed to do these things. If you're an existing programmer, it'll only take you a weekend or two to learn it. The structure is solid, the concepts are universally applicable, and the development pipeline is silky smooth. You'll be up and running in a modest amount of time. So, if you need a Google language for a Google device in a Google class, then yes, Go is worth it.
&gt; There are already some projects that enable you to program in Go for Android, but they are far from ready. &gt; Ok thanks, I am just beginning to learn Java in Udacity. My goal is to finish the four month course in under a month and then continue to learn Android programming. I was just not sure if Android would replace Java right after I finish learning which would be less than ideal so thanks for the answer :D
Ahhh ok thanks! I am just beginning to learn Java, then going on to learn Android development on Udacity (they have a job Guarantee for their nanodegree graduates). I guess once I'm done I'll most likely learn Go so that I will be up to date!
Give this man some gold finally!
Show us some code :)
Then prepare to be shocked. It is same as expecting C standard 20xx to include OO and mandatory garbage collector. It is simply against language design and philosophy. They already included panic/defer for edge case. They might add generics in future. But try/catch addition will probably* never come. (* unless http://e.lvme.me/5o4mnkx.jpg)
Hey, thanks! This is exactly the kind of feedback I was looking for. I really appreciate you taking the time to write this out. [+1](https://media.giphy.com/media/MpiWetOCN5Sx2/giphy.gif)
Having gone down this route before; I don't think you can get away with just one language if you want to automate everything you run into. I will confirm what others have already stated. PowerShell should be your primary choice. I would put forward Perl 5 (don't laugh) for anything else that is suitable. PowerShell hooks into just about everything Microsoft related (PowerShell modules for Exchange, Lync, Active Directory, SQL Server, server management, .Net API, COM, WMI, CIM etc.). You can use it to build GUI's to if you are so inclined. Not sure on the debugging, ISE does not provide that but you may have better luck using Visual Studio with the PowerShell Tools extension. So why Perl 5 and not Python/Ruby/Lua/hot new hip language. I tried them and the core language is nicer than Perl but the problem comes down to the libraries and documentation. Perl just makes it so easy for you with CPAN. I always found great libraries with good documentation, I did not really find this with Python and Ruby. So, Perl is seen as a bit of a punching bag language but in terms of getting work done ASAP; I could find none better. If you have the time; have a read about Service Management Automation. You may find it of interest for the long term. https://technet.microsoft.com/en-us/library/dn469260.aspx https://channel9.msdn.com/Shows/Edge/Edge-Show-95-Service-Management-Automation-SMA-with-the-Windows-Azure-Pack 
Well Go is lower level code than Python and Ruby. I have found Go to be verbose in some regards and my approach to coding Python obviously doesn't translate to idiomatic Go code, but then that is to be expected and as soon as I do some the Go, I am not overly offended by the Go I create. It is certainly more straight forward and less verbose than Java, a language not famed for its brevity. It sounds like you have the right attitude and I wish the best of luck with your endeavour into programming! 
 If you want to learn something else than Java for Android learn C++ . There is next to 0 support for Go on Android ,and good luck for GUI apps. Don't learn Go just for Android if you do .
thanks.. I updated with a gist of the code sample
Especially the map trick is one you should know and which is actually pretty efficient :).
I think you should be able to get the source code of those dependencies and cross compile them first, if even necessary to precompile them. The source code for different platforms is usually exactly the same :).
If keeping the order is important, you can create an index slice and define a sort that swaps both data and index values. import ( "fmt" "sort" ) var data, index []int func main() { data = []int{5, 3, 3, 8, 6, 5, 7, 9, 1, 3, 6, 6, 8} index = make([]int, len(data)) for i := range data { index[i] = i } sort.Sort(IntDup(data)) for i, tmp := 1, data[0]; i &lt; len(data); i++ { if data[i] == tmp { data = append(data[:i], data[i+1:]...) index = append(index[:i], index[i+1:]...) i-- } else { tmp = data[i] } } sort.Sort(IntDup(index)) fmt.Println(data) } type IntDup []int func (d IntDup) Len() int { return len(d) } func (d IntDup) Less(i, j int) bool { return d[i] &lt; d[j] } func (d IntDup) Swap(i, j int) { data[i], data[j] = data[j], data[i] index[i], index[j] = index[j], index[i] } 
Your `io.ReaderAt` implementation is broken. From the [documentation](https://golang.org/pkg/io/#ReaderAt): &gt; If ReadAt is reading from an input source with a seek offset, ReadAt should not affect nor be affected by the underlying seek offset. &gt; &gt; Clients of ReadAt can execute parallel ReadAt calls on the same input source. Your version can't safely be called concurrently. --- The easiest way to do it right would probably be to implement *only* `io.ReaderAt` (so you don't need to keep track of seek offsets), then wrap it in `io.SectionReader` to get `Read` and `Seek` methods. You'd probably want to perform an initial HEAD request to get the size (Content-Length) so there'd be a bit more construction overhead, but other than that it should work better than what you have now. (It would also allow you to verify the Accept-Ranges header is present and includes "bytes", so you could error out immediately if either is not available)
Please don't make singletons: https://stackoverflow.com/questions/137975/what-is-so-bad-about-singletons
They can be used without being abused. To mention an example in something I've been doing lately, I've been implementing Material Design widgets in a Python UI framework, and all widgets by default bind their colors to a singleton whose properties are colors that depend on a palette which may change at runtime. And if it does change, all those widgets should change instantaneously (simple Observer pattern). For this to work you need to have all widgets pointing to the same object, thus, a Singleton pattern makes sense.
It doesn't make any sense to do this in go. Instead, you should declare a variable in the package scope.
the 90ies called, they want their GoF back!
As I can understand, gccgo shares stanfard library, so it provides compatibility for user code. But it doesn't share (or share a little of) runtime: it has no exact stack traversing, no copying stack increase and no cocurrent GC; instead it uses conservative STW GC and native stack, that is why calling C functions is cheap.
Reposting because the previous title contained a currently false statement (being 10 times slower than the bindings). After unwrapping the round function, it's significantly faster - 40ms to 14ms per hash!
Ehh... lots of people write games in Java (Minecraft for example), C# (XNA, Monogame), Javascript, etc, against which Go performs very well.
Go was made for concurrency, games are best written in a lock step single threaded pattern, as it can be very hard to synchronize everything 60 times a second. So write you client in C++/Java/C#, enjoy the native C calling convention support, and write your network server in Go. It's what it was made for.
You should also give https://github.com/raphael/goa a try. When combined with https://github.com/bketelsen/gorma, you get a fully functional API that maps to your DB. I've been checking it out recently and it looks like it's really going places.
Nice work. It may be worth looking at http://dave.cheney.net/2014/12/24/inspecting-errors to help simplify your exported errors: most errors would fall into two categories - bad input (user-facing) and bad params (dev facing). It may also pay to copy the [bcrypt package's API](http://godoc.org/code.google.com/p/go.crypto/bcrypt) with functions that handle the correct salt generation and constant-time comparison for the end-user. Using the same function names as that package simplifies use, too.
In general you can expect CPU-bound Go code to be about 2x-3x slower than the equivalent C code. This is due mostly to the maturity of the optimisers in the Go compiler vs gcc/clang.
Per Tv` on #go-nuts the next step in optimization is writing asm SSE round code. Note that the comparsion in time is non-SSE Go vs SSE C, so it's honestly not that bad.
Why not just use filepath.Walk instead of recursing into directories manually?

Exactly, and even more importantly math operations with matrices and vectors are as fast as C, which is very important for 3d games as it is often CPU bottleneck too.
Thank you, yes that was it. Much appreciated.
Rewrite the code in pure go, its open source. Give as much as you take.
One of the best things about open source world is it's myriad of C libraries that cover **a lot** of ground and are our 20+ year old tribal heritage. Claiming they are a bad thing just because they push you out of your language-of-choice comfort zone just makes you look immature. If your language of choice pretends it's a system language of any kind it's doubly so. Every system language should interoperate with C libraries, and support dynamic linking, and Go is expectedly making moves in both directions. That said, this article is good for pointing out some, arguably not so obvious aspects of cgo or interoping from Go. It's crappy because it's comming on from a very argumentative and emotionally loaded standpoint.
AFAIK, [gccgo](https://github.com/golang/gofrontend) uses its own version of Go runtime (see libgo/runtime) as well as its own modified stdlib (libgo/go). I don't know about what kind of GC they use at the moment (golang-nuts/golang-dev might be good places to ask) but it also lacks escape analysis (which means more heap allocations, although this is being worked on ATM) and true goroutines (last time I've checked, gccgo would map goroutines to threads 1:1 instead of N:1). Oh, and I don't think gccgo is going to be abandoned any time soon. There is also [llgo](http://reviews.llvm.org/diffusion/L/browse/llgo/trunk/) for LLVM, but it's still not quite "production ready" if I recall correctly.
&gt;singleton Here^we^gooooooo
Ok thanks!
I suppose this is all true. I'm generally of the philosophy that you should make good things easy and bad things hard, but that's based on some experience working with people who will happily back themselves into corners as long as it saves them a few keystrokes today.
http://play.golang.org/p/wRFOXy6zzd
there's some things dave didn't mention that you just can't do without cgo; one that bugs me is calling `setuid` and related functions to drop privileges. You can't call it from go in linux (`syscall.Setuid` returns `EOPNOTSUPP`), and if you try calling it by hand using `syscall.Syscall` etc., it doesn't do what you want (you need to `runtime.LockOSThread` and etc.), and the language doesn't expose anything to let you implement libc's wrapper to `setuid` that locks os threads and does `setuid` on each of them.
&gt; drop privileges IMO, this is usually the wrong approach regardless of language, it's just too easy to get it wrong for little to no real benefit. I feel the same way about daemons, especially now that we have systemd, supervisor, etc. that do a better job at it.
Expanding on this, here are examples where unsupported types fail: http://play.golang.org/p/7k9vDTcLgC
csgo is not cgo
In your example gist, you're overwritting the template for index.html with a new template (which happends to be bar.html) on line 34. You should make a new, but empty template, to which you add the templates for index and bar. See [this issue](https://github.com/GeertJohan/go.rice/issues/71) for an example. Notice the difference between "template" (the library) and "templates" (empty template which holds the other templates). In your example gist, you're overwritting the template for index.html with a new template (which happends to be bar.html) on line 34. You should make a new, but empty template, to which you add the templates for index and bar. See [this issue](https://github.com/GeertJohan/go.rice/issues/71) for an example. Notice the difference between "template" (the library) and "templates" (empty template which holds the other templates). Edit: You should also know that most of the bindata like libraries seems to the unstable and not suitable for production. I read up on the libraries from [this list](https://github.com/avelino/awesome-go#resource-embedding) and discovered that there was at least a major bug (major bug as in: infinite loop when acessing a dir, can only access one dir of many or not handling errors in a proper way are some examples) for each. Unfortunately I didn't take notes so I can't really give you examples.. My advice is to avoid trying to embed resources like this and let the libraries sort out their bugs first.
Heresy.
Don't do that.
My question is how to do it not should i or not :)
Thanks, do you happen to know if that's a default behavior if num of goroutines = num of worker threads?
Thanks!
It depends on what you're doing. e.g. if you're running a web-server you can use `capabilities` to listen on a privileged port or better yet, if you use systemd or another supervisor that supports it, use socket activation. If you don't use systemd, you can also proxy requests to your app. If you're worried about the overhead of copying via proxy, you can implement the socket activation yourself. It's not hard: * proxy listens on port 80 * when a user connects, it starts your app and pass the connection's fd to your app * your app processes the connection itself so no copy over-head and no privileges are ever acquired 
I'm not sure I understand: the [gtk windows page](http://www.gtk.org/download/windows.php) references either binary installers or MS Visual Studio, neither of which I have. How could I compile the windows version under debian, and make it available to the go cross-compiler?
try to explicitely add nul-termination byte to a string.
I'm installing software in the system; the security sandbox and different odds and ends needs to be set up as root, and then the decompressing of the tarball needs to be done as nobody.
&gt; Claiming they are a bad thing just because they push you out of your language-of-choice comfort zone just makes you look immature. Was this his rationale? I personally avoid C transitive dependencies because of the additional complexity cost. If there's a Go version with decent performance and support, I'll be more inclined to use it than take on a C dependency. I think it's a reasonable position.
I am really hoping that, with this suggestion, we'll be able to land that f*ing rocket back on the barge!!! :P
"Until the calling goroutine exits or calls UnlockOSThread, it will always execute in that thread, and no other goroutine can". LockOSThread essentially takes the M out of the scheduler's pool of available os threads that it uses when it needs to run a G. "The GOMAXPROCS variable limits the number of operating system threads that can execute user-level Go code simultaneously. There is no limit to the number of threads that can be blocked in system calls on behalf of Go code; those do not count against the GOMAXPROCS limit. This package's GOMAXPROCS function queries and changes the limit. " That is not clear if locked goroutines count against this number, but it seems logical that they would not. If you have GOMAXPROCS=2 and 5 goroutines with locked os threads, you would have deadlock. New threads need to be spawned. I'm gonna test now to confirm.
This implies a best practice for utilizing C libraries. You implement your bindings as a separate package that does nothing else except wrap up the C API with a Go API. Then use that package and the Go API it provides. This would isolate the C build step into the separate package which should simplify things in the application package. It also abstracts the cgo out into something that is replaceable, that could eventually be replaced with a Go implementation if desired.
This also makes sense! thanks. 
Sweet, I'll definitely be using this (multiline stuff can be a massive pain)! Thanks for making/sharing it :)
Hey man, thanks for the input. It might come out a lot cleaner that way. The reason i chose to put it in closures is because my code would have to be worked on with a team afterwards(i hope). It's just the basic setup. I'm trying to make it hard to use the package wrongly by designing the code in a way that the "global" variables can't be accessed on the global scope. and don't have to be re-allocated. Also every stateFn holds a slightly different map, since certain keywords need different state functions in different contexts. And the ability to be able to pass the wrong map to a stateFn seems dangerous. Although i've never used this approach before, it might lead to messy code down the road. But my hope is less messy code than straight-up globals.
I can't imagine ever using something like this.
Awesome link in this article about musl http://dominik.honnef.co/posts/2015/06/statically_compiled_go_programs__always__even_with_cgo__using_musl/ Helpful for those getting things done with C code!
OpenGL does not work properly if called from different threads, it is mandatory to reserve one goroutine for opengl and lock it to a thread.
Doesn't glide already do this though, but using git tags (which seems a bit nicer to me than a .go file in a pin directory)
That's why Vulkan is happening.
So I've gotten the index and other static files to render/load (as seen in the SO answer) however I'm still struggling getting direct paths to load properly i.e. localhost:8080/whatever 404s even if a react route is properly set up and works when clicking a link takes you there.
If your day to day requires something similar to what is mentioned in the read me, then I'm sure you can see the value. The same could be said about `sed` or `grep`, that they have their specific use cases as well that most people don't need until they need it.
I actually kinda like this idea. I have a few libraries where I don't export the underlying type and pass everything around via an exposed interface type. I could use a secondary interface to expose different features of the unexposed implementations of the main interface. I would probably expose the the secondary interface though, I don't want it to be truly "secret", not really sure what benefit there would be in that.
Go 1.5+ GC latency is well within tolerable levels (less than 10% of a single frame at 90fps) and FFI overhead is negligible (way less than 1%), between reusing buffers and moving data to the stack, it's easy enough. There are lots of games being written in Java, or even JavaScript! Hell, even Unity has crazy overhead and it's an uphill battle to optimize every game. Anyways, thanks for your concern. :)
&gt; You waited for it for a long time. And here you have it: Neovim support! Woohoo!
Woooohoooo who does use vim anymore ;)
There are literally *dozens* of us!
was trying to parse stderr from go compile errors and get the fileline and the error msg output is like `\s+ filename:line:char &lt;random bullshit&gt; error: &lt;error message&gt;` tool like this can save me one step, i needed to return a bash array ["file:line:char", "errormsg"] or something splittable '$1,$2' ... afaik not possible with grep without keeping either the random bullshit or the preceeding tabs. either way it was uncomfortable to write, and now clear how-to with grep and i ended up not getting the errormsg b/c it was not clear how to extract and reformat the two in one command
Is neovim stable or does it break from time to time? ~~Do I need to change stuff in my vimrc to switch or is it backwards compatible?~~ EDIT: I'm an idiot, ignore my second question :) https://neovim.io/doc/user/nvim_from_vim.html
Actually, your YAML example pretty much describes one of my usecases to a tee! Out of curiosity, what multiline-accepting regex-matching sed-like tools do you use for search/replace functionality that you explicitly *don't* see **xo** as a substitute for? Personally, the only CLI approach I've been able to make work for those kinds of situations involve Perl scripts.. and Perl isn't exactly fun for me...
Changing the runtime from Dalvik to ART took almost 2 years so switching to new language is almost impossible.
you probably need either the git-version or one of the sources here http://www.gtk.org/download/linux.php The source version there contains compilation instructions for windows compilation. No guarantee that it works with cross compilation though... It's exception rather than the rule that Windows installation pages point to the source code...
I think the Hacker News thread is relevant because this library is very much not-threadsafe: https://news.ycombinator.com/item?id=10917584
I use vim since 25 years and just signed for an other 25 years. I can accept to change language each 10 years, but not editor, no more time to play !
I have been tinkering with go only few days... in prompt.go you just write each character as it is pressed? 
TIL, you can pass `binary.Write` a struct!
Exactly what `xo` was made for. I've given up exactly like you have simply because I didn't want to write a 10 line Ruby script just to parse some text. With `xo`, you could have used something like, ``` echo 'filename:line:char &lt;random bullshit&gt; error: &lt;error message&gt;' | xo '/\s*(\w+:\w+:\w+).*?error:\s*(.*)/["$1", "$2"]/i' ```
 package main import ( "log" "net/http" "os" ) func main() { dir, _ := os.Getwd() fs := http.FileServer(http.Dir(dir)) http.Handle("/", fs) http.HandleFunc("/filter/", func(w http.ResponseWriter, r *http.Request){ http.ServeFile(w, r, "index.html"); }); log.Println("Serving " + dir) http.ListenAndServe(":8080", nil) } Here I am serving a SPA using react on the client. You will see here I have a /filter/ route that is client side only so i just serve the index.html.
[removed]
Ok, so I'm not missing some multiline-capable CLI regex tool that everyone but me knows about I guess... always good to sanity check :)
Might help, if you add a few examples to the readme. Right now its not clear what you are trying to achieve. Unified interface for boltdb, mongo and postgresql? How will that work?
Are you doing something with your server that a simple: http.Get("https://myurl") will not work? If you have a valid ssl setup on your server, it works out of the box. Edit: I misunderstood the thread, I thought that this bug was fixed in go1.5.
The current setup requires a client to provide a valid ssl certificate in order access the server, the example i showed should work with most cases, but it does not for our servers. And i was unable to figure what are the valid server side ssl configurations in order to work with go.
Yeah, from the looks of it, this bugfix has been pushed back to go1.7 :( Most of the threads I saw recommended either disabling security(I absolutely do not like this), or using go-curl. Best of luck! 
Although this works https://gist.github.com/ncw/9253562 if i could figure out what settings are required in apache/nginx to duplicate this i could keep net/http but it does seam i have to revert to go-curl and work out the cross compile issues later. Thanks
A coworker and I have submitted a pull request to your project. https://github.com/wrapp/dockfix/pull/1 We'd love to get some feedback.
I've been using nvim in place of vim for months and I actually forgot I had switched. No noticeable difference (besides maybe a little speed).
They forked SyncThing to become the basis of some sort of social network thing that they tried to crowdfund. I don't see the problem?
He didn't say anything about OpenGL.
Exactly. Syncthing did nothing wrong afaik.
In this case they did. 
ok thanks!!!
And on other apps I've used a trick of client side routes all being to a /app/ route and then all REST API calls being under a /api/ route. It really helps me to organize it that way to reduce friction. 
i would make sure that someID can never come directly from user input.
First I save it to p.buffer and then draw it. Drawing consists of clearing the prompt (writing ' ' in the entire line), then for k, v := range p.buffer { // simplified termbox.SetCell(k, y, v, termbox.ColorDefault, termbox.ColorDefault) } and then calling termbox.Flush. My code is more complicated because of double-width characters and the maximum prompt size (512 runes in my case) might be larger than the terminal's width, hence I want to just draw the slice with the cursor in it.
I've started using it recently and I agree 100%. Some of the setup is clunky and the UI could use some work, but it has more features than any other distributed solution I've seen. The two-way syncing on android phones is killer IMO.
See the comments on the change made at https://gist.github.com/dchapes/8bd2138376f1f571383d/305b45af0820fbf7a1c8333dd75d1d301eebb7eb (sadly, GitHub doesn't appear to have a way to view gist change log messages via the web interface). In particular, please don't abuse `panic` and do check all errors. Also see the "final" version at https://gist.github.com/dchapes/8bd2138376f1f571383d.
In goland there's so much security even the name of the language is obfuscated. On a more serious note, why create a different subreddit when this one is accessed by more people? And governed by a CoC (afaik).
As long as `someID` is an int type, you should be okay AFAICT.
Cool but can you drop the -go from the name? It's obvious it's in Go. Thank God the language ain't called: prismatic-9001.
It's not clear from the title, but HUSL is implemented in 9 languages! http://www.husl-colors.org/
oh lol. typo! deleting. and recreating.
because some of us dont want to check every single post if is not 100% related with my line of work. I'm not interested in general web dev, or general golang development, only in dev of infsec tools and applications etc.
well seems like this subreddit does not allow for editing.. :/
good idea thank you.
No worries, the link goes to the right place.
Package-level documentation would be good. Documentation of what your types are *for* and the differences between them seems like a good candidate for inclusion. You've got some nice examples of how to use the library on the github project page, why not include some of that as well? Without really ripping into using it, I like your approach to method chaining error handling.
It's a system I built for a project of mine, decided to work on the code a bit more to get it into a more presentable state. Working on a CSharp backend, and one of the guys on #go-nuts has expressed interest in developing a JS backend. The current Go backend generates extremely fast code, beating any reflection based system by an order of magnitude, and managing to best msgp generated code. To be honest, most of that is cause I designed my own format and so I put a bit of thought into making it simple to process.
No need for yet another layer of abstraction.
I began using Vim for about a year ago. Wasn't even aware of all the fantastic things I was missing out on. Before I used Emacs, Atom, and a bunch of other editors. Nothing resembled to the coolness of Vim once you learn the "magic"! Besides, a HUGE part of the Gopher community uses Vim.
In fact golang "database/sql" package is also unified interface to SQL data sources. There is no such interface for NoSQL data sources. Such layer is useful to easily change NoSQL database and for testing purposes. Also consider implementation that decorate data store with event sourcing / auditing functions.
The answer is in the comments: http://stackoverflow.com/questions/30352725/why-is-my-hello-world-go-server-getting-crushed-by-apachebench/30357879
Just to point out that I've not come straight here to ask. I did do some digging and found Goose - https://bitbucket.org/liamstask/goose. However I don't know if it's mature enough or if there are better tools out there.
Thank you for helping me out.
Had not seen glide yet, I'll check it out. At a cursory glance, it seems a lot more heavy-weight that what I'm proposing here. w/r/t git tags being nicer, I disagree. I don't want to pin my dependencies on a commit - I want to pin my dependencies on a version number. A version number is an alias for a commit (in the world of git / tags), but it's a valuable abstraction. To put it another way, I could refer to my address using Latitude and Longitude, but my street name / number are a lot easier to reason about. Thanks for the feedback!
How does the speed compare to [github.com/bmatcuk/doublestar](https://github.com/bmatcuk/doublestar)?
I've been using this tool for awhile now, and I really love it too. 
How does it compare to https://golang.org/pkg/path/filepath/#Match?
Did this work out for you?
It is not comparable with filepath.Match, cause, looking at domain of Match func – it is adapted for usage with filenames, not any strings. For example, filepath.Match fails 11 of 59 tests of glob pkg.
obligatory "use gometalinter"
Please look at my answer to filepath.Match. I guess the answer the same? )
This looks extremely useful for us. You should actually post this in /r/programming.
&gt; gometalinter Ah, thanks. I hadn't known about that tool and I'll check it out :) 
Sounds like Java people are migrating.
Awesome - cheers
Thanks for feedback! I've already posted in /r/programming before, so a bit hesitate to spam with links:) Time to write an article I think to create a motive.
I had the same reaction.
Globs are not a subset of regexps - they're wholly incompatible. 
Hey guys, I wrote this because we use a bunch of serialized formats at work over various APIs, and I was getting sick and tired of adding struct tags for json, yaml, msgpack, etc. I hope other people out there find this useful. Contributions and constructive criticism are always welcome as well. Thanks!
I don't think `http.DefaultClient` is really a singleton, and I don't really know go "has an opinion" about the use of singletons. I do know, however, that another googler, Misko Hervey has made a pretty compelling case against singletons here: http://misko.hevery.com/code-reviewers-guide/flaw-brittle-global-state-singletons/
Where did you find that it uses the same source code?
Nice one. Looks like a time saver when working with a lot of structs. I would suggest defaulting to `gofmt`'ing the code.
I use this library in one of my projects for sending realtime logs to the browser. Been rock solid reliable. Thanks for your great work!
I'm just assuming it does, since it looks exactly the same as Slack. So at least the front end is the same.
Nope, Discord has an entirely different backend. 
&gt; advertised there but I've seen it display as electron for a second when you first open Yup, I can confirm that. The desktop client is built on Electron. However the backend is something entirely different.
Ah, so that's the underlying framework that's causing all these things to look the same. I never made the connection from Atom to Slack before, but I can see the similarities now.
In my experience, Go tends to ignore the singleton pattern and (for better or worse) trust developers to understand and abide by simple conventions. For example, as pointed out by /u/philosophicalhacker, `http.DefaultClient` is not really a singleton; it's simply an instance variable. In my program, I can at any point set `http.DefaultClient` to a client of my choosing. I would never do this, because it would be stupid. But I could. In my applications, I will frequently instantiate global objects for things like data access objects, loggers, etc., and I am trusting downstream developers to respect those objects and not reinstantiate/reconfigure them. I have mixed feelings about this, but in general I consider this more the *Go Way* than the singleton pattern described in the article. If you do use the singleton pattern, I would recommend adding an interface so that you can mock and unit test easier. 
agreed. I also just don't like the idea of having large block of code even if it is broken up into further blocks.
As in graphics frame flipping. Not much article there, just a code snippet.
how about default distributed thing , like in erlang ?
This seems like just another SaaS play, not really interesting for /r/golang as far as I'm concerned.
I'm pretty sure that's a race condition, too.
Weird title, nice debugging story. s/with/in/?
Hey gophers! This little gameserver always pairs two connected player togheter so they can play tic-tac-toe. This is my first small go project and also the first time I am using websockets. Feel free to criticize my code, I am trying to learn :) I am for eg. simply sending integers over the websocket connections. This is one thing I would like to change. JSON would probably fit better, like it is discribed here: https://www.new-bamboo.co.uk/blog/2010/02/10/json-event-based-convention-websockets/
Their backend is almost exclusively elixir/erlang
The only reason I use anonymous functions is when it is really useful to have the parent's locals scoped into the closure. Without that you may as well make a separate named function.
I've put it up here if someone wants to try it: http://tic-tac-toe.langhard.com If you dont get paired and are really bored, open a second browser window.
It's a variation on the classic Guess the number game, with the catch that it's multiplayer and in every game it's decided if the number every turn goes up the same amount, goes down the same amount or stays the same.
You're doing much more than globbing there. `man 7 glob`. There are no curly braces in glob patterns.
Syntax was taken from wildcards section of http://tldp.org/LDP/GNU-Linux-Tools-Summary/html/x11655.htm. **man 7 glob** shows glob for pathnames, isnt it? And what about first three errors of matching?
I expect GNU tools offer an extended syntax. The first three look like bugs, maybe you should report them.
You could easily make 'getKey' and 'setKey' functions for bolt that encrypt the key and value for storage. It would not be hard at all.
Not even a little mad. It was just a suggestion. Sorry that you got mad. lol
Yeah, I'd seen sift. The code is kind of a giant hairball, though. Mostly I wanted to prove that a simple solution could be coded in Go in a very short period of time. Plus, it was fun. I'll mention sift to him, though it looks like sift only supports gzip right now... not sure what compression mechanism he was working with.
Yes, after visiting the Discord site it became clear to me! :)
Oh, and a key thing I learned: when you call bufio.Scanner.Bytes(), you're given a slice of bytes that does no allocation, and if you try to use that slice asynchronously, it will get overwritten the next time you call Bytes(). Took me a while to figure out why I was getting odd output. Always read the docs, folks!
You need to serialize the output, otherwise output of lines at the same time will become interleaved. 
No, since the standard library logger protects the output with a mutex.
Ah, i see now that you are using `log.`.
&gt; Kinda of annoying that I have to think about all the errors that could ever happen, but it definitely does make for more well defined code. Ignoring errors works great until it doesn't. :)
Much better from the immediate standpoint of: why/how should I use this library. For more of course I'd probably have to, uh, use it!
Did you go get the tour
No offense towards your code, but I would be surprised if this is any faster than just using grep (or zgrep). In my experience with Go its regular expressions have extremely poor performance at least in Go 1.5.
yeah, I know, the stdlib uses RE2 which is not as fast in simple cases as PCRE. There are alternate regex libraries that could make it faster for simple searches. And yes, you could certainly use zgrep and gnu parallel to do this on the CLI without writing a program. This was not really intended to be a first class tool that would be better than much of anything. :)
I think this is pretty good! It's clean and well-structured. The documentation is sufficient, but not overdone. It works too, which is of course the most important thing! haha A few things: 1. Stylistically, I would make find24 a pure function. That is, I would have it take in a slice of numbers and return a slice of solutions. 2. I would also make find24 take in a slice of primitives (either ints or floats). Then convert them into Num types yourself. That way the caller doesn't have to deal with Num structs. 3. A comment indicating that 'solutions' is being used as a set would be nice. I mean it's pretty apparent from reading the code, but it's always a good idea to explain why you're doing something abnormal. Idk, maybe this is more of an accepted idiom than I realize. 4. If you're concerned with printing the answer in a pleasing format, perhaps print "no solutions found" rather than nothing. 5. It doesn't work with irreducible fractions containing primes. A trivial example is [5, (24/5)]. Perhaps you should just limit the function to taking in integers. Or find a way to make it work for any set of floats. 6. I haven't actually spent time evaluating this, but if you're using recursion and not memoizing, you're probably doing extra work. This isn't actually a big deal as your function is fast enough for its use case. However, just be aware that recursive functions like this can blow up without memoization (even then, it needs to be thought out). [Here's an example with a function which calculates fibonacci(n)](http://rayhightower.com/blog/2014/04/12/recursion-and-memoization/). In the non-memoized version, the number of computations blows up exponentially. The memoized version is O(n). Pretty big difference! So yeah, overall, this looks really good! All the points I brought up are pretty minor.
bufio.Scanner has a limit of 64k per token, so the code as it is won't work for larger sizes, you might want to use ReadBytes('\n') instead.
Here, I cleaned that up and put in in a GitHub Gist: https://gist.github.com/anonymous/279bd5c068206480970a
I've got 'gotour' command in path when installed the tour.
Semi educated guess that: Nginx is chosen: * to serve static directories and assets * assumed to be faster than go's built in server * has cache for these one config line away (or admin already knows how) * assumed to be more secure and battle-proven than go's webserver * doesnt expose hypothetical vulnerabilities of go's webserver past /index and /websocket * assumed to have better ddos protection than go's webserver (by me i guess?) ex: the common ddos of last year was opening a bunch of unfinished HTTP req's "GET /longurl___no new line", &gt;i think its all hypothetical, go has had no sever vuln's posted yet
How can it be slow? Surely it utilizes hardware acceleration? 
Your whole setup might include different applications, some in Go, and some in other languages.
I use haproxy in front of everything as it means my ssl certs are only in one place, not many.
I used a Go server as reverse proxy in front of several services that are reachable on different subdomains and was totally happy with it. But then i had the need to serve an app with fcgi and that's when i switched to nginx.
I'm surprised that gob is slower and requires more allocations than the others. I thought binary formats are generally faster and leaner.
https://blog.cloudflare.com/go-crypto-bridging-the-performance-gap/
IF you happen to have a couple of microservices running on different ports, using NGINX gets rid of the CORS for you. Since everything would be proxied through a single port, the domain would match.
This is pretty awesome gonna look more into it 
I think that Go alone should work out fine. I too have deployed my first go service in production a few months ago. In our case we already had Apache running because of our landing page and Wordpress blog, so port 80 was already reserved. I already had defined dozens of virtual hosts, so I simply created another one with Go using the mod_proxy module. I think using another http software that can act as a proxy makes sense if you got other instances running in your environment like other services, blogs... and want to wrap them.
The reality is that most TLS/SSL termination will be done on a load balancer and not on the app servers themselves unless you have a special need. Ideally all connections would happen over TLS no matter the destination. 
&gt; Arguments such as using Nginx as a load balancer seems more theoretical that actual practical implementation, ie. people are saying this, but not actually doing it. I think this could be handled much better at the DNS request level instead. Ok. So you suddenly exhausted the resources of your server. Think optimization issue or reddit hug of death. You need more resources STAT. Great, set up another server on a new IP and enter this IP into DNS. Then you wait for TTL seconds before clients can possibly hit your new server. And what about maintenance? Do you remove a record from DNS and wait for traffic to slowly migrate to a different IP before you take one of your machines down? Or would you rather just spin up a new VM (or provision some new iron), dump your binary and config on there and (if you happen to run NGINX Plus) just have the binary register itself with the load balancer and watch everything work as if by magic? Replace nginx plus with community version and your config management of choice. Personally I use saltstack for my small-ish setup. Sure, you get a certain amount of load balancing with DNS RR, but it is far from optimal and you're lacking proper HA.
Don't use DNS (only) for load balancing. It won't work the way you expect.
Ahh, good call. Though if you're working with files that have lines longer than 64k, my program probably isn't what you want anyway (since it prints matching lines out to the terminal).
if you have a Go package that does that, I'd be happy to use it ;)
Heard loud and clear. I'll create issues for these on github and get to work on this over the weekend. I'll update this when I've made some progress. Thanks!
This is an interesting idea. I can definitely abstract the os and flag calls out to enable something like this. /u/natefinch has some good ideas that I think would make this really viable. I'm going to work on this over the weekend and see what I can come up with.
https://github.com/alecthomas/go_serialization_benchmarks/issues/36
It is part of 1.6 release. but you can test it currently. https://github.com/golang/net/tree/master/http2
Your approach is valid. SIGUSR2 is the only 'entrypoint' here. https://github.com/facebookgo/grace/blob/053ab5d25436faedf3fe76fbf3da797c8c27c659/gracehttp/http.go#L99
Ah, good to know. Thank you!
The main reason I started using Glide, is that it was meant to become the "official tool" for vendoring using Go 1.5 vendor experiment, I read that somewhere, though it was a wile back now. Glide seems to also be under very active development.
&gt; What's that? Your source is served over SSL? Great! Any disgruntled employees have access to that server? Any trolls? Hey cool, you still have no idea what you're downloading! The same could be said for any software on which you haven't done a source code audit — including 'go get github.com/ellotheth/pipethis' I'm not crazy about piping install scripts for many reasons, but I think the security risks are somewhat overblown.
Thank you very much, was having second thoughts since worked from first try, and per Murphy's law this is wrong :)
- Are the slides available somewhere? I don't have time to watch 1 hour of video, but I would love to check out the slides. - How do you get the live coding in the slides? Is there a framework for this?
The go present tool allows you to play code in the presentation. It works like to examples in the docs. Check out the present go tool
A link to the talk slides would be good
Yes, there are slides available. I was running them from this link: http://go-talks.appspot.com/github.com/GolangBelgrade/go101/go101.slide#1 And yes, there is a Go tool which enables runnable code in the slides. It is called `present`, https://godoc.org/golang.org/x/tools/present.
And using crypto primitives directly can be very error prone. An article about using the nacl bindings would Go would be great.
For sure. To be honest I just wanted to get the first version out as fast as I possibly could, but I'm thrilled with the response it's getting so far. That being said, I tend to work on daemon/server processes at work and that enforces that separation a little bit more by default.
Looking further at your code, you might have a [different problem](https://github.com/ellotheth/pipethis/#people-writing-the-installers)?: &gt; If you don't want to store your signature at &lt;scriptname&gt;.sig, add another line to tell pipethis where you're storing it: If the point of this exercise is to prevent a hijacked or MITM'd script from being installed via cryptographic authentication, then you can't trust the file you're trying to validate. Otherwise, an attacker can simply replace those two pieces of information with their own. #!/bin/bash # PIPETHIS_AUTHOR 1337_h4xer # PIPETHIS_SIG https://someotherdomain.com/whatever.sig ...the rest of the hacked code... Then they can just sign the hijacked code with their own key and they're off to the races. If your intent is to ensure cryptographic validity, you need to ensure that either the author, or the signature are derived exogenously. You start out as opinionated about path-relative signatures. I would stick with that, and allow for CLI overrides; do not allow it to be configured inside un-validated code. Also, [document yo' exported types](https://godoc.org/github.com/ellotheth/pipethis/lookup)
What is your Caddyfile like? I've been trying to run a go web app through Caddy and have been running into some problems, and haven't been able to find much on serving a web app and not just a static website.
I'm not really sure why they decided to do that.
Here's a Caddyfile that I'm using for some stuff I was messing around with. The first one is the basic serve from a directory, the second is the recommeding settings for Gogs (git web host written in go) and the last is a proxy that serves as an easier to remember url with a password on the front of it. All the tls parts have my email so it uses that to auto renew. You could also pass it in at the arguments to start it, but I just haven't added it to my init script. mysite.com { tls email@example.com root /www/mysite.com } git.example.com { tls email@example.com proxy / http://localhost:3000 { except /css /fonts /js /img } root /home/git/gogs/public log git.access.log } sub.example.co { tls email@example.com proxy / http://otherwebsite.com basicauth / me password } Essentially, you just start your application on a different port and do a local proxy to it. You can exclude certain directories like in the git example so the webserver can handle the static content, as it in theory is better at caching and serving it. 
Little hard to install. Created a pull request to make it simpler: https://github.com/ellotheth/pipethis/pull/2 
So much win.
Stop using MongoDB. It's a shit database.
Glad you like it! Haven't a clue what the Keybase invite situation is, but I can shoot you one if you PM me your email address.
As for why: Google will show you answers far better than I can explain. As for alternatives, PostgreSQL. 
Yes, that is correct.
Yes - load balancing is so much more than just making sure more than one node can receive requests. I'm also using 2 haproxy nodes but with a virtual IP on each and another piece of software (the name is escaping me) to migrate IPs when necessary. The idea being that DNS round robin is between the VIPs and those are always available, even if a node is down.
I'm late to the party, but I also run my go app servers behind a nginx reverse proxy. It doesn't take much to setup nginx, SSL setup was fairly easy and I can respond to multiple hosts via virtual host setups by redirecting traffic to each web app's hidden port. Yes, I could have done it all with Go. But nginx is battle tested, can load ballance if I need it, and fairly painless to maintain for a small setup. Besides, sometimes adding another layer of complexity isn't all that bad for security.
I'm on my way to meetup in Amsterdam for it...
As Nginx keeps on pushing their Plus version, it is increasingly necessary to keep the capability in our hands. 
Does anyone know what `label` is for? I found this: https://golang.org/pkg/crypto/rsa/#OAEPOptions but it didn't help me understand what `label` is used for.
Well written post But I cant say I am a huge fan of using a map of strings to define how my dependencies are wired up. Granted you have written code to handle this, but this is sort of my point! You're having to check for the presence of implementations in maps just to gain yourself some flexibility of what I would consider negligible benefit. For me, generally I have 3 needs for DI 1) Production wiring (e.g a real database) 2) Some kind of in memory fake thing for running locally 3) Mocks for tests For 1 and 2 that can be accomplished through configuration if config.isLocal { db = inMem ... else ... For 3, I am probably unit testing a layer, in which case i just call the constructor with my mock. 
This is exactly why I wrote this post - to see how other people approach it. I'm not sure how I feel about using a map of strings either but it seems to work well. I feel like it will get interesting when I start layering the stores. (i.e. have a cache DataStore that attempts to read from RedisDataStore and falls back to PostgreSQLDataStore on misses). 
I used github.com/natefinch/pie for a small project recently and it went well enough, my plugin is written in Java. This looks cool too though and will have to check it out in more detail when I have some more time :).
When you get into "prominent language features" the slide with the code on it is not visible as you talk about it. Please fix!
What about function calls? Do naked strings get copied if the parameter isn't modified by the function? I.e. which one is faster: func x(s string) { fmt.Printf("%s\n", s) } or func y(s *string) { fmt.Printf("%s\n", s) } 
worrying about this is a massive over optimization. the compiler is smarter than you; let it do its job and just write readable, bug-free code. don't use a pointer just because you think it will make things faster. in fact, the security of having values that can't be null means that your code will crash less and have less bugs.. which is probably faster than the tiny speedup that a pointer copy would have given you. tl;dr - don't optimize for the compiler; it is smarter than you
I come from progamming in C. Pointers are not scary. I totally agree that you shouldn't worry about this for 95% of functions, but there will be the 5% that need to be fast. So that leads to my question. How smart is the compiler in preventing unnecessary copies? 
&gt;I come from progamming in C. Same here. It was my first language about seven years ago. &gt;Pointers are not scary. YES THEY ARE. That's the whole point of the article... so that you will use them sparingly. This is also why most of the bugs that you'll find in C programs involve pointers. In fact, the man who invented the concept of *null* calls it his [billion dollar mistake](https://en.wikipedia.org/wiki/Tony_Hoare#Apologies_and_retractions). But to actually answer you question, here are instructions from [the official Golang FAQ](https://golang.org/doc/faq#methods_on_values_or_pointers): &gt;First, and most important, does the method need to modify the receiver? If it does, the receiver must be a pointer. (Slices and maps act as references, so their story is a little more subtle, but for instance to change the length of a slice in a method the receiver must still be a pointer.) In the examples above, if pointerMethod modifies the fields of s, the caller will see those changes, but valueMethod is called with a copy of the caller's argument (that's the definition of passing a value), so changes it makes will be invisible to the caller. &gt;[...] &gt;Second is the consideration of efficiency. If the receiver is large, a big struct for instance, it will be much cheaper to use a pointer receiver. &gt;Next is consistency. If some of the methods of the type must have pointer receivers, the rest should too, so the method set is consistent regardless of how the type is used. See the section on method sets for details. &gt;For types such as basic types, slices, and small structs, a value receiver is very cheap so unless the semantics of the method requires a pointer, a value receiver is efficient and clear.
So that brings up one "gotcha", which is that saving a slice from a larger string prevents that larger string from being garbage collected. Are there other ways to screw up royally? Pass a map by value, for instance?
Here's a playground benchmark: http://play.golang.org/p/kPEVj-x4uM You'll have to actually paste that into a file locally to run it though, because the playground times out. My results: string 200000000 8.43 ns/op *string 100000000 11.4 ns/op copy 100000000 13.8 ns/op 
I don't think it matters and that string pointers aren't meant to be used like this. I use it via flagging to init my configs with nil, and populating them after server starts because my program's config have sources from different places, such as Env and files that gets checked and populated at different timeframe during runtime.
In the particular case of strings, the value itself just contains a pointer, so this doesn't apply. You almost never want to pass a string pointer.
I would recommend not using any framework. Everything you are mentioned can be taken care of by the std libs. Is there some reason you are migrating? If the goal is learning go, then learn the std libs, not some framework.
Thanks for the visual representation of string layouts in memory (also interfaces); I'm bookmarking it in case I get the opportunity to convince my coworkers to adopt Go.
Which of the compilers? 6g isn't doing much optimizations at all. I was amazed it didn't even move the bounds check out of a simple loop like func a(bs, cs []string) int { for i, b := range bs { if cs[i] == b { return i } } return -1 } It was (with standard options) checking the cs access on every iteration. I think it did jump elimination, but wouldn't say 6g is "smart". Premature optimization may be bad, but in this case the reasoning doesn't hold up (for 6g).
You can look to https://github.com/astaxie/beego it's the most biggest framework...but consider write with microframeworks with other packages.
The problem is your definition of `MyErrorType`. It should be something like: type MyErrorType struct{} func (MyErrorType) Error() string { return "my error" } Pointers to interface types don't have any methods because using them is almost always wrong.
&gt; don't optimize for the compiler; it is smarter than you Or more importantly: measure first, *then* optimize if you really need it. Otherwise, you're just guessing.
Ooops, must've been a mixup with the editing. You can see the slides [here](http://go-talks.appspot.com/github.com/GolangBelgrade/go101/go101.slide#1). During that slide I didn't say anything special except that Go has a familiar syntax and that an average developer will understand the simple Go program.
As mentioned by the other posts, frameworks aren't a great fit for Go. For http libraries, I've been quite pleased with [go-restful](https://github.com/emicklei/go-restful) on my servers. It might sacrifice some performance, but it adds a ton of useful extensions over net/http.
It's useful when reading config files that are naturally strings, especially for customers that don't have access to the source code. Or you are a library writer that needs types registered because you are creating database backends by parsing URLs. Or an encoding where `reflect` is not enough: https://golang.org/pkg/encoding/gob/#RegisterName. But, yes, coding with strings instead of symbols generally, when you have access to the source code, isn't nice.
Boom - code review internet style. Thanks - I'll make the edit.
&gt; For 1 and 2 that can be accomplished through configuration 1 can only be accomplished using "DI by configuration" if you assume that you're the only one that will run that code, or that everyone that will run that code has similar infrastructure -- otherwise you'd have to basically import every single database/sql driver out there... (in my mind, the real power of DI doesn't just come from configuration, but mostly from being able to provide an implementation)
What orm does? Postgres has a lot of wacky data types. I'd be shocked if any orm supported them all. What specifically is missing that you need?
Check out http://goa.design | https://github.com/goadesign/goa Unlike other frameworks, you start by designing your API interface. It then uses that to generate idiomatic Go code that you can build off of. Then for free, you get a Swagger definition, cli client, js client and other goodies. If you are also interested in using an ORM, https://github.com/goadesign/gorma is a plugin that integrates with gorm. You can go soup to nuts with a JWT enabled REST API in about 10 minutes.
I need inet, array and json. 
Quite a decent article, I've been using Go for embedded development since later 2014 and it's been awesome. We're using gumstix running Linux and have a lot of tools etc written using Go as well as a significant part of the core system. Any questions let me know, I post a lot of gists up on using Go on embedded at https://gist.github.com/17twenty
&gt; Do not use frameworks, they are not conventional. Use bloated full of magic package that relies on `reflect` instead. We call it "toolkit". &gt; Do not use frameworks, use `gorilla`. It will turn your [thousand lines of code in a single file](https://github.com/mattermost/platform/blob/a9860a0ce8f1ce08dab9aaff0ec0c996de4f0e4c/web/web.go#L9) into a masterpiece automagically. &gt; Frameworks are bad, toolkits are good. Are Go adepts that religious? How about defining exact things you do not like about some frameworks instead of turning "framework" into a four-letter word?
Thanks, this is super helpful. What do you use templates for at your company? I built a dashboard with templates as a pre-alpha demo, but never again. I only use them for dynamic content in email notifications I generate now. 
Interesting read, thanks. I wonder why you don't show the use of build tags. With one of those in place in a dedicated integration_test.go it will only run when requested. This way there is no need to change any automatic invocation and no need for custom flags. Just a thought base on my experience.
Sorry, I dont quite follow. I was just saying that I can control what dependency I inject with just "normal" code and call the constructor. I dont really want/need some kind of magic around this where I pass a map of strings, I just want to say, like in the example... `if config.env==PROD` newMyService(prodDBInstance) else myNewService(inmemoryInstance)`
Look on saturn_vk code - you can define the empty sections **in** the base template to avoid this problem
there is rtmp module https://github.com/arut/nginx-rtmp-module that can stream HLS(chunks over http)
Has everybody that attended this meetup knew English well enough?
When I build websites, I use templates for each of the pages. You can see how I use templates in my project on Github: https://github.com/josephspurrier/gowebapp/tree/master/template
Also looks like the GC folk haven't replied. Maybe it's a bug.
Let's hope so!
No they are treated the same for json unmarshall. As long as spelling is same it will be unmarshalled.
http://www.infoq.com/presentations/go-gc-performance see the slide around the 27 minute mark.
Thanks, I'll look up ways to handle errors properly and modify the code. Thank you for the link also
So I should return the error from the function and check if there is any error in main and log it right. Please correct me if I have understood wrong.
Not clear how the benchmark is being performed here, especially with many layers of filesystem caching in effect here. How many times was it performed? Was there a throw-away warmup period? In which order did the two tests run? I suspect the author ran the Go benchmark first, which cold-loaded the log file, then ran the Perl benchmark which might have been cached by the hard drive/kernel/filesystem. Ideally, we'd run the tests from data in-memory a few hundred times. 
A good place to start is using ffmpeg to serve a sliced version of the file.
Actually, it's fairly well known that Go's regex engine is unoptimized, while perl's is a very complex beast. Additionally, Go's regex engine is implemented in Go while Perl's is implemented in C. Go code runs on average 2x-3x slower for CPU bound code, due simply to the immaturity of the compiler as compared with gcc and clang. However in this case, we can use ragel to drastically improve the performance of the regex match. edit: code https://github.com/dgryski/trifles/tree/master/sshdregex using ragel optimization flag: (none) BenchmarkRagel-4 2000000 615 ns/op BenchmarkRegex-4 3000000 497 ns/op ok github.com/dgryski/trifles/sshdregex 3.881s using ragel optimization flag: -G0 BenchmarkRagel-4 10000000 156 ns/op BenchmarkRegex-4 3000000 487 ns/op ok github.com/dgryski/trifles/sshdregex 3.691s using ragel optimization flag: -G1 BenchmarkRagel-4 10000000 160 ns/op BenchmarkRegex-4 3000000 491 ns/op ok github.com/dgryski/trifles/sshdregex 3.743s using ragel optimization flag: -G2 BenchmarkRagel-4 20000000 75.4 ns/op BenchmarkRegex-4 3000000 487 ns/op ok github.com/dgryski/trifles/sshdregex 3.644s
Not any time soon. See, the regex engine Perl uses is highly optimized C code, in development for literally decades. This is one of the most optimized pieces of code in existence. The regex system for Go is written in Go. It uses Go types and Go functions. It's garbage collected, type safe, portable without #ifdefs or similar. There's no magic happening to make it fast, and as such it's pretty incredible to be performing that closely to the highly optimized code used by Perl.
Go's regexes are notoriously slow, sadly. You can try out an alternative module to try to get better performance. Or use goroutines, although it probably won't help much once you take synchronization time into account.
Any time i see a file named 'helpers' i get scared. Rightfully so, you have methods that would better be represented in a decorator type (which might even make the encrypt/decrypt code unit testable), and a method you don't even use in there (Abs). You also have a bunch of magic numbers in your code. Typically you'd declare these as constants with names that make sense for what they represent.
That's a fair point. The one thing I like about a separate integration package is I can have test file in there that runs the app using only the exported api. This can be done elsewhere for sure but this sort of enforces it. Thanks again
Congrats you just reinvented a tiny part of gin: https://github.com/gin-gonic/gin 
G e n e r i c s ?
First, I can not express enough that everyone should stop using CSV and instead use TSV. TSV is a far more simplistic format, as easy to creat and far easier to read (as long as your data doesn't contain tabs). Naw, with that out of the way, please see https://github.com/sqlrest/sql.rest as an example of how to export from PostGreSQL.
I'm not in the loop completely about how the compiler is functioning lately, are we still trying to recover the speed performance that went down when the go compiler code was autoconverted from C? 
That conversion happened in 1.5 so yes 1.6 is supposed to fix that.
I know this is most like gonna be down voted, but I see this framework tendency as a sickness of bad habits. In PHP - as an example - nobody knows how to program themselves anymore, everyone is using frameworks for every little thing. Some people "carry the sickness" with them and as soon as they begin using Go, they try to develop some kind of "framework" that they think the rest of the world cannot be without. Or they start looking for frameworks to use themselves. But in Go this sickness has been cured and there is no need for frameworks at all. You actually need to program yourself, but since the standard library has everything you need to develop very clean and very simple and easy to understand code, it's quite easy and joyful. I am sorry, but I hate frameworks. So naturally I really love the Go way!
IMHO the HandleError() is really annoying. Go has such a clean way of handling errors and there is no need for the added layer of abstraction here. I agree 100% with neoasterisk as the first thing I did was also to locate the HandleError() in helpers.go and then see a panic being called every time. I suggest you just use the Go way and handle the errors normally.
&gt;Go's standard library is awesome but why wouldn't you use a dependency like httprouter when it seems to perform better than HttpServeMux? It is always a trade-off. You need to ask yourself what that dependency buys you. I haven't used httprouter but according to your words it offers better performance than the stdlib. Now the question is, does that increase in performance really worth pulling one thousand lines of code into your project? To me it sounds like premature optimization but of course, you know better what your project needs. &gt;I also have a hard time letting go of the DRY principle and that makes some level of abstraction necessary doesn't it? I want to get to a point where my application has as little abstraction and overhead as possible while still balancing other things that I place value on: performance, readability, simplicity/LOC, etc. As always, going to the extremes can be problematic. You can hear about the problems that "DRY obsession" can cause by [Rob Pike](https://youtu.be/PAAkCSZUG1c?t=9m27s). "You can actually make your programs compile faster, be easier to maintain and simpler if you keep the dependency tree really, really small" and I couldn't agree more. I would also recommend watching the full talk if you are interested in the philosophy of Go. Nobody is saying that dependencies are bad. The problem is that developers get into a mindset of easily including dozens of dependencies in their projects without seeing the trade-off. When the project is young/small, everything is fine and dandy but as time goes by, having unnecessary dependencies can make a project harder and harder to maintain. Always consider the trade-off. 
For the impatient: https://github.com/gdm85/wolfengo Still some work to be done, but I hope you will enjoy it already :)
This is so incredibly elegant it hurts. Well done sir.
Thanks everyone. The conclusion I have drawn from this thread is to use the packages that best suits my requirements and not a full stack framework. I will post the packages I am planning to use after doing some research.
And what I might about the defer is don't do this: // Open input file to be encrypted fin, err := os.Open(file) HandleError(err, "open input file") defer fin.Close() because fin.Close() won't be called if there's an error, since HandleError panics before it gets there. Do this: // Open input file to be encrypted fin, err := os.Open(file) defer fin.Close() HandleError(err, "open input file") 
Guess what, I've just committed Steam Master and A2S (Source) protocol support along with other goodies.
I'll see if I can help out with it, that would be really awesome.
It's because it needs to avoid conflicts with method interfaces. An ugly all-caps name is an easy way to make that very likely.
Cool! I'd welcome the help.
Pretty nice expansion on my [go-flagged library](https://github.com/Spatially/go-flagged) :P but, seriously, I haven't tried to use it but it looks nice. I've been meaning to get around to implementing declarative subcommands for months.
Awesome work, i loved Wolfenstein and doom as a kid. 
Crypto code review is not my strong suit, so I'll just stick to formatting things. * Documentation comments for functions should start with the name of the function. For encryptFile, instead of "Function to encrypt a file", you'd want to write something like "encryptFile encrypts the named file using the key". Also, it's typical to use `file` as a name for os.File variables; you might want to call the input parameter `path` or `name` instead. * In general, Go code doesn't have multi-line breaks inside functions or structs. `gofmt` will automatically format your code to the standard style. * You don't need so many comments for obvious operations. For instance, it is obvious to anyone reading your code that `fout, err := os.OpenFile(...)` opens an output file, so you don't need a comment that just says "Open output file". Rob Pike, the co-creator of Go, [says](https://www.lysator.liu.se/c/pikestyle.html): &gt;I tend to err on the side of eliminating comments, for several reasons. First, if the code is clear, and uses good type names and variable names, it should explain itself. Second, comments aren't checked by the compiler, so there is no guarantee they're right, especially after the code is modified. A misleading comment can be very confusing. Third, the issue of typography: comments clutter code. I tend to agree with him; I only comment hackish or tricky code and top-level variables and types. * Don't put helper functions in a separate file; put them near to where they are used. Putting them in a separate file just means anyone reading your code must spend time digging around to find a certain definition. Separate files by functionality instead. * Panicking is *not* an acceptable way to handle errors. If a function returns an error, it is meant to be interpreted (otherwise the function itself would just call `panic()`). Usually, this will just mean returning an error from the function you're writing; if an error ever reaches `main()`, the program can then `panic` (or better, print the error and exit gracefully). * You use `fmt.Println` many times to print the current status of the encryption. There is a package called `log` which is similar to `fmt` but is specifically designed for this sort of logging (for instance, it outputs a timestamp next to messages).
Author here -- thanks for the share! If anyone has any questions about the project or how to tackle a particular use case, feel free to ask. I'll do my best to give you guidance. I've tried really hard to keep it simple but flexible. 
This wins the Internet.
Awesomeness Incarnate!!!
Yep, that's due to debug being enabled. [debugGL = true](https://github.com/gdm85/wolfengo/blob/master/src/main.go#L34)
I understand where you're coming from (we also make heavy use of regexp where I work), but why not a simpler API like this: x := struct{ FieldA string FieldB bool }{} if restruct.Match(`(?i)^(?p&lt;FieldA&gt;[a-z]+)(?p&lt;FieldB&gt;(true|false))$`, str, &amp;x) { fmt.Printf("matches: %s, %t\n", x.FieldA, x.FieldB) } The idea is that the 'restruct' package would use reflect to get the type of the fields, and use strconv to parse the different types, it would parse the []byte of the matching data from the standard regexp fields, ignoring any named parts of the regexp that don't have corresponding fields. Additionally, the API could be more general case, matching things like being able to write map[string]interface{}. This has the benefit of not having your fields split up strangely with tags, and could then be used to load data into struct's that aren't defined in code/packages that you control. The only reason I haven't written something like this, myself, is that everything seems to be encoded in json or xml, so the standard encoding stuff seems to work fine. Regexp's are great/amazing, but, personally, with Golang's type safety and great marshaling/unmarshaling, I find that I personally am making use of them less and less. I only state this is that looking through the roughly ~500,000 lines of code we maintain, of which roughly ~120,000 lines are Go, we are serializing regexp's as strings into various config files. That is to say, we are using named sub-expressions in the regexp's at points to extract data from various client apps (don't think too hard about this, I wouldn't be able to explain it, just know that it's something like multi-tenant system that tries to load compatible configurations from many varied different sources).
This is really nice, but you should use the usual go field tag conventions so that multiple field tags can be used on the struct.
I hope it does! :)
Well, any kind of performance. So compiler performance definitely as well as it degraded quite much in 1.5.
I looked at the code of golang/database/sql and their approach is absolut the same. You can automate the register process (they do it with init() functions in the driver-packages -&gt; example from sqlite3 https://github.com/mattn/go-sqlite3/blob/master/sqlite3.go#L130) And the Open() function takes a string as drivername (see here -&gt; https://github.com/golang/go/blob/master/src/database/sql/sql.go#L481) to get the desired driver for the rest of the sql package. So i think its okay to wire up factory methods with strings.
If you're asking why people use variable names like x, y, and i, it's because we decided that local variable names with short lifespans didn't deserve long and meaningful names. Check the Linux Kernel coding style guide, chapter 4. https://www.kernel.org/doc/Documentation/CodingStyle 
&gt; There is no practical limit to the number of goroutines that are running since **only one goroutine will be running at any one time**. Really? I thought this depends on GOMAXPROCS, which (when &gt;1) could lead to situations where to goroutines are scheduled in parallel threads? Otherwise, how come some of my programs had race conditions and crashed?
I understand, but to me there is a difference between short and a single character for everything, looking at my JS a variable name longer than 5 characters is extraordinary. I know Java likes to takeItToTheExtremeWithTheirNaming but there must be a sane middle ground. 
I think it should be possible to add a "regexp" or "restructure" prefix to the tag as json and xml do (for example ``json:"myName"``). Instead of: User string `\w+` It could be something like: User string `regexp:"\w+"` This would allow it to be compatible with other struct tags. EDIT: There's an open issue regarding this @ https://github.com/alexflint/go-restructure/issues/2
I've had a professor that taught me to never use `i` for indices in `for` loops, I get his point though that clarity is more important than brevity. But I think in this case the two are aligned. Using conventional variable names makes it more understandable, at least so for me. Just like `i` is an index in almost all code, so is `n` a size and `err` an error. Furthermore in Go you often see `r` as a reader, `w` a writer, `b` a buffer and `s` a string, etc. I don't know why you're so distracted by the short variable names, but perhaps take the time to get acquainted with the notation will ease things. Anyways, I'd say `b.wr.Write` should've been `b.w.Write` ;-)
this is probably not a good example. so b.n is likely just an int counter (position) or size of buffer `b`. so thats why it was givin a short name the real reason this is all short names is: this is a method func / receiver method. if he used a long name he would just have to type the instance name a lot more: func (ByteWriter *Writer) flush() error { if ByteWriter.err { return ByteWriter.err } if ByteWriter.position == 0 { return nil } newpos, err := ByteWriter.wr.Write(ByteWriter.buf[0:ByteWriter.position]) if newpos &lt; ByteWriter.position &amp;&amp; err == newposil { err = io.ErrShortWrite } if err != nil { if newpos &gt; 0 &amp;&amp; newpos &lt; ByteWriter.position { copy(ByteWriter.buf[0:ByteWriter.position-newpos], ByteWriter.buf[newpos:ByteWriter.position]) } ByteWriter.position -= newpos ByteWriter.err = err return err } ByteWriter.position = 0 return nil } thats a lot of `ByteWriter`. 16 of em! nextpos, err := ByteWriter.wr.Write(ByteWriter.buf[0:ByteWriter.position]) this is hard to read to some devs. because the font's [] are not great, imo. ---- now IMHO go should include @ syntax like coffee script for receiver classes instead of typing `ByteWriter.buf` we could just use `@buf` (or :buf like ruby)
I think that is plenty readable. Those are also unexported fields; it is really up to the author's discretion at that point. If you want to have longer names in your unexported code go ahead. The alternative there would be what? `b.bytesToWrite` instead of `b.n`? `bytesWritten` instead of `n`? Does that really help that much? `b.writer` instead of `b.wr`? I don't see why you'r so up in arms about this or why you think this is a Go specific thing. Have you ever seen C code? I see this plenty in Python code too.
but that make it more ugly
I got online it's about reading speed, after the first occurrence I interpret a long variable name as a single character an skip it just as fast. As for typing, after two characters I press tab and its auto-completed.
b.count? I am from a php &gt; JS background, this is my first toe in the strong compiled hemisphere.
I personally am waiting for perl6 regexes to become available in other languages (p6cre?): my token sign { &lt;[+-]&gt; } my token decimal { \d+ } my token exponent { 'e' &lt;sign&gt;? &lt;decimal&gt; } my regex float { &lt;sign&gt;? &lt;decimal&gt;? # whitespace isn't significant '.' &lt;decimal&gt; # and comments are allowed &lt;exponent&gt;? }
It all depends on your comfort and knowledge of what goes into a framework. Go is very modular which allows you to kind of piece together tour own framework. Some of my favorite packages to help this task along are [Negroni](https://github.com/codegangsta/negroni) and various packages from the [Gorilla Toolkit](http://www.gorillatoolkit.org), primarily the mux and session packages edit: updated broken gorilla toolkit link
I hear Gin mentioned regularly by devs much more seasoned then me. I used Echo in my current project but plan to use Gin next.
Came here to see this. :)
This convention should be followed as other gophers will expect it, but it's probably my least favorite thing about Go. In fact, there is some research that supports the idea that there is a "just right" for identifiers and its somewhere between 'x' and 'anIdentifierInJava'. http://www.cs.loyola.edu/~binkley/papers/isse07-id-recall.pdf
Is the idea to make it distributed or regular client server? 
I wrote a utility in go to basically do this. It's a binary, not a library, but feel free to crib any code that might be helpful. https://github.com/StabbyCutyou/sqltocsv/blob/master/sqltocsv.go Please do not use cursors for this - the go database library was written with large datasets in mind, and will not load the entire result set into memory. Cursors are designed as a bit of a crutch (imo) and database performance suffers because of them. The example code uses TSV (despite what the library name is :) ) but you can easily adapt the approach for CSV. The library is in a bit of a half-finished state, but I currently use this to handle extremely large (several gigabyte) backups, so it should be a fine approach for things that top out near 30k results.
What's rhe performance comparison between gin and echo?
Point is there is plenty of REST frameworks in Go already. I am always amazed at the number of people who keep re-inventing the wheel instead of trying to focus their open source energy on some area that is not addressed well yet....
No magic type conversions!
It's right there on their github page. ;) With big letters saying: **Performance**. They are even underneath each other. BenchmarkEcho_GithubAll 30000 38662 ns/op 0 B/op 0 allocs/op BenchmarkGin_GithubAll 30000 43467 ns/op 0 B/op 0 allocs/op
Auto-complete isn't a ubiquitous feature in every single text editor ever and it often doesn't understand the language your using, so it's better not to rely on it.
`4&lt;&lt;20` is not `32000` (it's `4194304`). If you need a constant, it's clearer just to write 32000 rather than trying to do bit shifting. // If file size is greater than 32KB, make a byte buffer of 32KB // Otherwise, create a buffer of file size var buf []byte if size &gt; (4 &lt;&lt; 20) { buf = make([]byte, 32768) } else { buf = make([]byte, size) }
Here is a small cross platform MySQL query to csv command line tool I created for use at my company. MySQL outfiles are normally generated on the database server file system which requires sudo access or an nfs mount for users to properly retrieve their csv file. This program gives internal users the ability to securely generate outfiles directly from their laptops or automate csv query reports via cron, etc. https://github.com/joshuaprunier/mycsv It's definitely MySQL specific. I had to customize the std lib csv package to produce output identical to what MySQL does. The channel communication/sync'ing is probably overkill but the reading/writing sql.RawBytes is pretty much what you have to do when you don't know what results your query will return. Hopefully this helps a little even if you aren't using MySQL. Best of luck!
Yup point taken. One of the goals of go-restructure was to be a better way to compose regexps -- e.g. the second example on the github page where I define a URL struct with a field of type Hostname, which itself contains the regexps for matching hostnames. My motivation is that I see a lot of copying and pasting of smaller regexps into bigger regexps at work, then when we want to update what it means to match Foo we have to also go and manually update what it means to match everything that contains a Foo. One could imagine building regexps programmatically, but that is a recipe for a whole different kind of disaster. It's true that struct tags can't be deserialized. I didn't think about that while designing this library.
I've made some of the suggestions you pointed out. I see that you mentioned decoupling by using a io.Reader which I will try to include. Thank you for all your comments
I have modified the code taking in your comments. Thank you for the help
Whoops, thanks for noticing. I've updated this
&gt; I am from a php &gt; JS background PHP is much worse than Go: `strncmp()`, `strpbrk()`, `lcfirst()`, `nl2br()`, `strchr()`, `strcoll()`, `strcspn()` and `strpos()` to name a few string-related functions from the standard library.
I tried with the StreamReader and StreamWriter but when I time it, the for loop seems faster. Well, it was faster or encryption but the times for decryption were fairly similar
Sure, I thought you were implying that Go is confusing you because "it's not as clear/verbose as PHP". The idea made me laugh. :)
I see a lot of people recommend Gin. Gin's router is finicky and often have to resort to unintuitive paths. We moved to echo because of it.
I do happen to love JS, but I'm not sure if I want to create full blown apps with it. I'm basically looking to make a REST API with Go, and I'll probably write the web layer in node (write a template once...). For now it's learning though, and concurrency is always a good thing.
Most go devs will use a single gopath on their system. You could potentially "isolate" projects with multiple gopaths, but that can get tricky, and people generally don't. My gopath is ~/gopath. I add ~/gopath/bin to my path. All my code goes in ~/gopath/src/github.com/myname/projectname. Any library code also gets put in ~/gopath/src when you download it with `go get`. Pretty much every person new to go wants to fight this setup. They almost all end up accepting it because it is just easier than fighting it. 
The domain elliot.land is just a redirect the to the real domain: https://elliot.silvrback.com/goroutines-and-channels-a-real-server-in-go I thought I could save myself $100 by not to getting the extra SSL cert for primary domain, but your not the first person to mention this, so I guess I'll have to now...
While I have one $GOPATH for my whole system, it's perfectly valid to keep one $GOPATH per project, giving you something similar to your virtualenv solution. If you do this AND you care about versions, it's idiomatic to put that stuff into a /vendor directory (read up on golang vendoring best-practices; I don't do this and can't give advice) and commit that directory to version control (but make sure your .hgignore or .gitignore is ignoring .svn, .hg, and .git directories so you're not checking in the entire history of all of your dependencies). You will probably also want to keep track of your versions of each package, either in a central dependencies file or drop a VERSION file in each vendored dependency. There are tools like `godep` to assist you with vendoring, but again, you'll want to look up best-practices because they've evolved considerably since I last investigated. Alternatively, if you don't care about versions, then you can set up your version control system's ignore rules to ignore other dependencies altogether (you'll just be building against the latest version of your dependencies all the time). Also, an alternate project-focused build tool is gaining traction, and might be worth looking into: http://dave.cheney.net/2015/05/12/introducing-gb
[**@jmoiron**](https://twitter.com/jmoiron/) &gt; [2015-07-31 02:57 UTC](https://twitter.com/jmoiron/status/626949692090384384) &gt; I really don't like of the use of \#golang struct tags as a backdoor for introducing un-checked declarative mini-languages. ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
No worries! Sorry if I seemed little harsh in my comment; I definitely understand the desire to keep things simple in an intro. :) Here's some extra reading on the rationale for the change: https://docs.google.com/document/d/1At2Ls5_fhJQ59kDK2DFVhFu3g5mATSXqqV5QrxinasI/edit - the short form is that, with older versions of the scheduler, increasing GOMAXPROCS past 1 could actually make some programs run a lot slower. Improvements to the scheduler largely obsoleted that concern.
Yes reflection would be good. Or you could use a schemaless database like mongo. Or if you don't need to do selections of the data you could use gob and store that.
Perhaps use PostgreSQL and the [jsonb](http://www.postgresql.org/docs/9.4/static/datatype-json.html) type? This would let you fetch results as a single column with rich structure, but still have indexed searching over json structures.
Doing it your way, would you store just a PKEY id and JSON column? Right now I have something similar but I pulled out extra data as a SQL habit in order to index it for searches. For example a name column in order to filter a select by author. In your experience how good is the engine at filtering query results with clauses that use the json column?
So like what Caddy does with the git add-on? https://caddyserver.com/docs/git - with it I just `git push` to deploy my site. Is that what you meant? But you need git installed on the server...
You were right, I didn't need to worry about it at all. Thank you for the response.
This is great! Does ragel support all the regex features provided by perl regex engine such as positive/negative look ahead?
My solo entry this year is a cross-platform way to send encrypted files easily: https://github.com/gophergala2016/sendto https://sendto.click Would love to see a few people try it out.
Positive look ahead maybe. As has been mentioned elsewhere, Perl's regular expressions provide a number of features that allow them to match more complicated structures that are not "regular" in the computer science sense of the term. Ragel is a finite state machine compiler and as such is more limited in its features. However this also means it can use faster matching algorithms without backtracking. If you need to match a context free language, try a real parser like a hand written recursive descent parser or generating one with yacc.
Does golang support all the complex regex features supported by perl? I don't think so.
&gt; run it on EC2? It's a game oops..I get it! Thanks.
I'm surprised they didn't mention [gin](https://gin-gonic.github.io/gin/). I've built a few production services with it and can't be happier. 
I would first ask yourself, "Is my data relational in nature? If so, does it need to be? "If not, it sounds like you'd be better off forgoing the db package and using a document store (i.e MongoDB). If your data must be relational then, as mentioned, PSQL and JSONB are your best bet. RDBMS are traditionally structured by design, and PSQL is the only one that I am aware of that offers the ability to store unstructured data and query it intelligently. 
Then just go with Gin. It's so dead simple, it's ridiculous. 
Pretty much exactly what I was looking for - but without the git requirement. Now I have to decide if I want to just install git, or write something myself :\ Still, this is almost exactly what I was hoping for - ty
Too bad it doesn't I use golang.org/x/net/context. 
where is GIN?
Very happy with Goji, new version with net/context is great.
Was just thinking about this the other day. Thanks.
This. Very simple to use, ships with httprouter making it faster than most others and gin-gonic/contrib has useful things if you need functionality like sessions.
Please vote for "todo" https://obscure-savannah-52814.herokuapp.com/
Just to add to that: recent versions of MySQL also support a JSON type: https://dev.mysql.com/doc/refman/5.7/en/json.html I haven't tested it yet though.
It's not just down. It has been shut down :)
Is this google killing off golang?
http://imgur.com/OYJJinj
what? no. code.google.com is going down, as has been announced a long time. Most projects moved to github.
I hope gvm (go version manager) updates the protobuf build bits to reflect this.
Coming from python, i use one GOPATH by project, like i did with virtualenv. I often mix python and go in the same project, then i have myproject/py myproject/go (=GOPATH when i work on myproject) With every projects in the same GOPATH i don't know how you deal with different versions of the same lib, how you know which project use which lib. If you remove a project you have to check which lib you can remove... If you use the new /vendor option, finally you reinvent GOPATH, i don't understand... But i must be wrong if nobody do like that !
That was actually intended as a stylistic reference, but it came off as proscriptive, due to space constraints. This thing is far from done :) Edit: Thanks for calling that out, I've removed the dubious wording.
y not use letsencrypt? 
At this time, the ref sheet's not done. It's only just now started to come together after fighting with LaTeX, which is obviously being pushed to do things it doesn't normally want to do. Space is at a premium, and it's been an interesting challenge to try and cram as much in as possible in, while trying to reference as few concepts as possible that haven't first been defined. This isn't a hard and fast rule, of course, as it's intended to be a programmer's reference, but there are plenty of people (myself included) who like to just dive in with a new language and learn that way, so I wanted some kind of logical progression. Since it's hit Reddit, I would love to hear from golang programmers as to what they would like to see here, and, more importantly how (and where) they're like to see it. All notable contributions will go on the contributors list (which I've just created), and will receive a professionally-printed copy. I would also like to solicit feedback on the theme. I love Solarized as much as the next guy, but I'm starting to think it might be suboptimal for print legibility.
now someone just has to submit a pull request to add that to go as `go build android [files]`! *Please :)*
Fortunately open source doesn't work that way.
now that's "community management" /s
I know this is not what the author is talking about, but you can run Go executables pretty easily on android from a terminal emulator. Just install [termux](https://termux.com/) apt install golang git go get ...
Serious question: what could the Go Team (or anybody else wanting to help) do differently?
And this is why relying on a version control system as a package manager is a bad idea. 
After looking at organisers I am actually impressed by not finding a single mention of CoC.
I used https://github.com/mattes/migrate . I like its non-intrusiveness.
I'm curious, why should I use this instead of [go-bindata](https://github.com/jteeuwen/go-bindata)?
I wrote a small webserver that listens for a webhook, authenticates, and then executes some commands: https://github.com/LiterallyElvis/captain-hook
I appreciate the separation of match and replacement patterns from the really oddball `s/match/replace/g` shenanigans of `sed`. And that's coming from someone that has used `sed` a great deal. Having distinct arguments for the very distinct jobs of match and replace just seems to fit with the overall unix philosophy better.
Also true, but lets deal with reality here rather than the current party line. A dedicated centralised package manager has a notion of longevity about it that the current flavour of repository hosting platform shouldn't be expected to. An actual package manager where it is explicitly in the interests of the maintainers and interested parties to ensure that packages remain available as a whole, not where the onus is on the individual to ensure that his or her external dependencies do not disappear when some corporation shuts something down. Take CPAN as an example, according to Wikipedia it has been around since 1997 and has over 260 mirrors. I can more than likely spin up some 10-15 year old Perl project, pull in the dependencies and away I go. Google code lasted about 10 years. Why is that a bad thing worthy of down votes? This isn't a direct criticism of Golang, there are other tools like Bower content on pushing the primary source of truth for packages into Github.
I'm using https://github.com/dwb/dogfish which isn't go specific, but does require bash, so it's not fully cross platform. Since it's external to the go code, it doesn't require building or running a binary in order to set up the database.
love this, Sed drives me freaking crazy when I'm just trying to extract some data from some output. cut doesn't cut it &gt;:\
Good thing you're not a woman, or you'd have twitter [calling you out](https://harthur.wordpress.com/2013/01/24/771/).
And awk doesn't do capture groups 
Im open to suggestions if you have ideas on further improving the interface.
Using a dead package is as bad as it sound. A centralized package manager won't solve that. Not being able to update your package in 1 year is not a good sight of a healthy ecosystem 
You could, I just prefer Go. 
&gt; A dedicated centralised package manager has a notion of longevity about it that the current flavour of repository hosting platform shouldn't be expected to. I don't buy this. I don't expect Github to be more or less transient than any centralized package repository. More importantly though, this is a problem with a 2 minute fix that comes around once every ten years, and you're given a year's notice to plan for it. You're still winning when you consider all the time saved *not* configuring your project for centralized hosting, but even if you weren't this is the least of all problems.
I'm curious about the decision to include non-matching lines in the output. I would expect `ls |rip '.*\.go$' '$line'` to print only files ending in .go, but instead it prints all files. `ls |rip '.*\.go$' '$0'` almost works, but it still prints a blank line for each non-matching input line.
I whipped this up today after transforming sample curl commands in API docs one too many times. It's far from perfect, but I hope you'll find it useful anyway. (As always, feel free to contribute to make it better!)
Nice! I also once wrote [a Go tool](https://github.com/cespare/sub) because I can never quite remember how to do the task with sed. (In my case it's for find/replacing in files.)
This is so rad! Thanks!
awesome stuff!
This is pointless, a party for what? Nothing THAT major in 1.6 and a date that's randomly picked. At least if they would have gotten the date right... I guess Go becomes the commercial, marketing platform we all secretly want it to be (for people, not the product itself).
nice, awesome idea. how you have the guts to publish your stuff. I never publish things because its not finish, shiny, etc.
The idea is that you should always be compatible with the latest version of the code, you shouldn't easily break compatibility and if you rely on older versions, you should maintain that yourself (hence the vendor directory for that case).
Ah! If I only knew that before I bought the certificate... I'll definitely remember that in the future, cheers.
That's cool! My first try however failed: curl -I http://example.com This should make a HEAD request.
I was similarly inhibited for a long time. When I first published my little open-source project I felt like I had walked into public naked: all my code and thoughts were, for the first time, there for anybody to look at, to critique, to deride. The reality is nobody much cares...or, worse, even knows you're there. You may well be naked in public, but you're naked in public in a very large and sparsely populated wilderness (where everyone else is naked too). The few people who discover your bits^† may try them...regularly use them even...but the most you'll likely get are bug reports and feature suggestions. So my advice is: swallow your pride and just do it. There really isn't anything much to lose and a lot to gain from the experience. ^(† I'm done with the analogy: I'm not talking about body parts.)
Wow, really interesting that you missed that. 
I went back and forth on this a few times (still not sure). But the idea is that it should be easy to incrementally build up a regex, and having the output disappear when you miss type would go against that. edit: this is up for debate edit: I've changed it to skip over non matching lines.
THIS ^^ I release my terrible code all the time, and frequently learn from people's bug reports, suggestions and comments. It didn't take long to lose the inhibition and now I wouldn't have it any other way.
Building something with Alice and gorilla now. I'll have to try gin in the future for comparison
damn this is smort
https://tip.golang.org/doc/go1.6 seems to be so, yes
It was a survey, surveys require that you ask other people questions. I am sorry that this is so difficult for you to understand.
You're right, I didn't add support for the -I flag yet. But I can do that soon. Edit: Done.
amazing and thorough work, thanks!
why sqlFilterMap -- why not just put the correct strings in there in the first place? Also, I noticed that you are manually assembling SQL queries by passing user-provided strings in there unescaped. That might blow up when used unwisely, it would probably be better to prevent that by Design (e.g. have fieldnames always be struct field names, which can't create broken stuff). Lastly, Filter seems like a weird type, because it's identical to fmt.Stringer.
awesome
This is well done. I did a near opposite some time back: take your request object and turn it to a curl statement! https://github.com/sethgrid/gencurl
epic!
Thank you. I took a quick look and see that their and/or is similar to how I'm attempting it, at least in presentation, haven't looked into the actual code just yet.
This is amazing! Great work.
Thank you Jordan! That made my day. By the way, I just saw GoPhish and am really impressed - what a neat, niche project.
Several of the examples include: client := http.Client{} resp, err := client.Do(req) `http.Client`s are meant to be long lived and re-used, not created on the fly like this. I think instead this should be: resp, err := http.DefaultClient.Do(req) as suggested in the [documentation](https://golang.org/pkg/net/http/#Get).
Thanks for your encouragement.
Thanks for your encouragement.
That's really cool - I love the idea of logging the curl command after an error or failed test, so you can try it manually.
If you don't mind writing assembly, sure. You can also use a library in which someone else has already done so. One example is https://github.com/gonum - I know some of the routines use SIMD instructions when the processor supports it.
This is bloody amazing! Kudos.
https://en.wikipedia.org/wiki/Type_system#Static_type-checking
I expected http://i.imgur.com/iDVTstR.jpg (parallelism theory vs practice)
[**@\_rsc**](https://twitter.com/_rsc/) &gt; [2016-01-28 01:46 UTC](https://twitter.com/_rsc/status/692524016012300290) &gt; Confirmed: Our release process has no hidden dependencies on @github. (Filing bugs does though, sorry.) https://twitter.com/golang/status/692521385508356096 ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Not sure if this gives you any inspiration, logstalgia is a neat tool for visualising Apache logs https://youtu.be/HeWfkPeDQbY
This is bloody brilliant!
:) Thanks for caddy, I'm starting to use it more now - using it on golangnews.com too. Yes should have had deeper integration with keybase.io really and maybe linking usernames properly, but didn't have time.
He does mention that there are timing issues in the thing. That's why he isn't open sourcing yet. Maybe it's because of that? It does look cool though. :-)
Thanks!
I don't understand the problem. I don't understand this solution. Sounds interesting though.
Awesome work!
I added more comments in the readme.md. If we need to update some resources of a network service, the simplest way is to stop the process and then start the process again. But during the continuous running period of a network server, this method will mistake some requests. It is harm to the client users. So we use the double-buffering technology provided by this library. What we need to do is only to send a administration request to have it enabled.
This is fantastic 
Will the talk be recorded? 
I'm a curator on Outlearn.
I am sorry but I can't read anything on that Website. It's plain horrible to use.
&gt; I've read a number of blog posts about RESTful APIs in Go If I'm asking this on Reddit and I've read blog posts, you can safely assume that I've used Google... Looking for production server code, so that I can make comparisons especially around testing.
So it doesn't actually work yet? Who guarantees us that you actually remove the file from your server? Why should I trust you?
Agreed. I see op is asking for suggestions, but the usability is bad enough it doesn't need explaining. How about a screenshot of how unusable this content frame is. http://m.imgur.com/5TfTnJY
Thanks for the feedback. The plain text is required as there is no other way for you to enter a password via an input field. Anything entered client side is going to be "plain" That being said if you take a look in the code the password is salted, and iv's are created. The encryption key is a Pbkdf2 based on the password and salt. Open up your networks tab and take a look at the data transaction between the webservices and your machine. The only thing transferred is the iv, salt, and encrypted data. You don't have to trust I'm running said client side code. You can see it (app.mini.js)! All the hashing and encryption happens client side in javascript... yes you do have to trust that the server side is running what i say it is, but ultimately after you have verified the only data I'm getting is encrypted or the iv and salt there isn't much to argue about. Yes the iv and salt are helpful for rainbow table, however, they have to be stored somewhere. Where would you like it? Amazon S3 appended to the file or in a DB? Does it matter? Seriously thanks for the feedback. I appreciate your concerns. Please continue to help by providing suggested answers to your criticisms so this can be improved instead of just critisized. Finally everything is done over https so there is no sniffing unless your talking Man in the middle. Ultimately lets be honest nothing is every perfect. The titanic did sync. But I think it's worth making secure file sharing available to the masses. This is my first attempt... lets improve it together!
Very good point. I'm hoping (need to look into it) that if you are only transferring encrypted data to me and I have no idea what it is that there isn't much that can be done. I mean... they could take the drives but it's all 100% encrypted before I get it or serve it. How can anyone tell other than the sender and receiver? Not to mention there is no records of it seeings as it's deleted upon download or after 24h. Its probably more likely that they force me to shut down due to "National Security". Hopefully with it being opensourced it's not worth shutting me down as there are 1M other people who could spin it right back up. Thoughts?
&gt; C.CString It's working. \@/ I am going to have to poke around with large projects, but I am not seeing any error at the moment! 
&gt;This thread is for people working *on* Go. For feature requests and &gt;proposals please go through the usual channels, not on this thread. &gt;Thank you. what are these? i have a small feature request
/sign for not another compile slowdown of x2.
Yikes, another 2x compile slowdown and hoping to gain "most of it back," when 1.5 itself introduced a 2x or so slowdown is a little scary to hear.
my request to make the compiler more faster
I third-ing the request for the talk to be recorded. Sounds like a talk I definitely would be interested in. Would also be up for seeing a live-stream over Hangouts as well.
You'll want to convert from base64 representation to real bytes before passing it to zlib. Between your first two lines; some sort of `b64 := base64.NewDecoder(base64.StdEncoding, b)` (and then using `b64` as input to a zlib reader).
Especially because the SSA backend doesn't introduce any speed improvements.
Fast compilation is one of Go's best features. Please stop throwing it away, especially for features almost no one cares about!
1) `ch = ch1` - this is just updating the `ch` variable so that the next time through the loop, the new goroutine gets that channel to read from. If the channels were named a, b, c... we spin up a Generator that writes to channel A. The first time through the loop, we make a channel B, and set a goroutine to read from A and write to B. We store "B" in `ch`, and next time we set a new goroutine to read from B and write to C, and so on and so forth. 2) Clarity &amp; protection against programmer error. Code works the same if you don't specify them as read-only or write-only. 3) We've already read from the input channel (line 16). If it's divisible by `prime`, we simply don't send `i` to the output channel and discard its value (because we know it's not prime).
Thanks for the response. What's throwing me, though, is when we reassign ch=ch1, why does that not lose reference to the channel being updated in Generate? i.e. Generate is updating some channel ("ch"), but when we reassign what "ch" points to, how does Generate know to follow along? Why doesn't it continue to update that original channel that is no longer referenced by "ch"?
Was thinking that as well.
I see your point about being a bit harsh. I'm sure SSA is a great feature, but my point was that most users wouldn't notice it. I mean even the translation from C-to-Go which caused a 2x hit in compilation speed didn't provide any benefit to users. Sure it improved the code quality but so what if it makes users' lives worse?
Sorry to answer so late. I didn't see your comment until now. From first read I like it. Your example adds abstraction and it is clear. If you are ok I will see to add it to gofragments (with your name of course, :) OK? Thanks for your feed-back.
The point we're at with compilers is that what works very well in theory doesn't always translate into speed gain in practice, especially on x86 architecture which is a monstrous microcode beast where the "machine code" is just another language being translated and optimized. Halving compile time by introducing new optimization steps that should in theory optimize the compiler and make it faster is wishful thinking, especially in a couple of dev cycles. I found it very hard to believe that 1.5 could ever get back to 1.4 speed in a cycle or two, and we're now discussing about another 2x hit. In my experience, the only way to keep a very complex software fast is not accepting commits that slow it down. Anything else fails, or takes years and years to be counterbalanced. 
There is github.com/gonum/stat for those who don't know. We'd love a pr for the stuff we don't (I.e. Poisson)!
is this really a big deal? yeah, sure, faster is better....but i haven't felt my time slipping away with slightly worse compile times
I haven't seen anybody state that this will *reduce* compiler time, eventually or otherwise. Where did you read that?
&gt; . It's now considerably slower than even a slow-to-compile language like C++ No way. You are doing something wrong. 
Hi, i would recommend you to check https://github.com/sourcegraph/thesrc . You will see structure of Web App + you will find basic implementation of API. As for me combination of standard net/http + gorilla + sqlx seems good enough for development.
I think you're overthinking it a little bit, or perhaps applying lessons from other languages. When you pass something to a function, the receiving function gets a copy of whatever you're sending it. If you send an `int` it gets an `int`, if you send a pointer to an int, you get a copy of a pointer to that int. Even though channels internally are implemented as a reference to the important information, when you do `ch=ch1`, you're not updating what `ch` points to - you're updating what `ch` is. So if you have `ch = { realChannel &amp;memLocationA }`, `ch1 = { realChannel &amp;memLocationB }`, after assignment you have `ch = { realChannel &amp;memLocationB}`. So the realChannel at locationA has no idea and doesn't care that you've changed `ch`, and the function's `in` chan still holds `{realChannel &amp;memLocationA}`. Think of it the same as: count := 0 for { go fmt.Println(count) count ++ } Even though `count` is getting updated each loop invocation, the receiving function doesn't know and doesn't care.
Hmm... so I checked it out, and none of the distributions have a PMF. For my implementation, I defined the CDF of the Poission using the sum of the PMFs. It can also be definied using the Incomplete gamma function, so I could go that route. However, I'm confused as to why there are no PMFs/PDFs. Is it named something else? Otherwise the package does appear to have all of the features I would think to request, and more. So that's nice.
What is the actual benefit here? On the thread it looks primarily geared towards correctness more than performance.
thanks
As a novice developer eyeing Go as my next language to learn, the discussion here has me concerned for the future of Go. What should I make of all this? Should I be concerned? Edit: Thank you for the comforting remarks. Viva la Go! 
I think it's important to remember that software is first and foremost meant for people to use. Anything that detracts from that purpose is a step in the wrong direction. I'll repeat my earlier point: so what if the backend is cleaner if as a result thousands of people lose additional hours out of their lives waiting for the compiler? Is code cleanliness really more important than life?
You shouldn't be concerned. Even after 2x compiler speed slowdown in Go 1.5 it is still very fast. E.g. compiling the standard Go library (250k lines of code) takes about 14 seconds on my PC. Note that due to incremental compilation you rarely need to compile more than a few thousands lines of code during development. I have setup my Emacs to run Go compiler every time I save a file to highlight compilation errors and I cannot notice any lags when saving a file.
I realized I phrased that incorrectly. I had actually upvoted you. Guess my english skills betrayed me this time.
doesn't bash have this built-in?
Note that the issue described there (as any performance issue) is fairly specific and happens only for a particular program that is load tested in a particular way on a particular hardware. You have to benchmark your own application to decide if Go 1.6 makes it faster or not. And please post your findings here if possible!
To add to this, a lot of the slow downs people are experiencing are with specific packages that are notoriously slow anyway. 
Try running `go install` once. This will build and cache (to $GOPATH/pkg) all your dependencies so next time you run `go run` it will be significantly faster.
OK that makes perfect sense. Thank you!
&gt; You don't have to trust I'm running said client side code. You can see it (app.mini.js)! How can I be sure that no one tampered with app.mini.js on your server?
It's a given. The Go compiler is written in Go. As Go becomes faster, so should the compiler. If an SSA backend will eventually result in speed improvements, then compile times should eventually be reduced. If they manage to reduce compile times more than the increase they impose by implementing the SSA backend is another question however...
&gt; github.com/mattn/go-sqlite3 in my experience, if you execute "go install" in github.com/mattn/go-sqlite3 once (a day or so), it compiles it once and then you don't have that long compile time every time you recompile your code. &gt;That's considerably slower than the worst C++ program that's ironic, because the sqlite3 binding is written in C++ (or C) and most of your delay is due to sqlite3 bindings being recompiled I guess..
Visit http://divan.github.io/posts/go_concurrency_visualize/, read about the basics of the visualizations demonstrated there, and then scroll down until you see the prime sieve example. You might find the 3d visualization of the goroutines and channel messages as useful as I did.
function invocation are pass by value, so when passing the channels to the function that gets started as a goroutine, you make a copy of the reference there to that channel. then by putting ch inside ch1 and getting a new value for ch you shift them one up for the next goroutine invocation.
Thanks for updating me.
No need to get trollish!
As you yourself state, if the improvements gained by switching from a C to a Go compiler, combined with a switch to an SSA backend, don't outweigh the net reduction in compile times introduced by those two changes, then it's not a given at all. I think most people would interpret "reducing compiler time" to mean "reducing it from the current status quo" not "slowing it down, then speeding it up some unknown amount possibly in the future". Edit: words. 
Sure, but in that context, no one has said that this change will permanently increase compilation time either.
Valid point :) However i have a repo named countries containing the raw data for the repo (https://github.com/pariz/countries). So it felt natural to name the go implementation gountries.
so glad to see these investments in Go's future. Compile times are so low the slowdown doesn't even register on my radar. Thanks for playing the long game with Go!
see the README
until curl $url; do sleep 1; date; done
Or many people forget to use go install so depending libs are compiled on each call (often I make same mistake when doing cross compilation).
Slow compile times don't bother me either, I was looking forward to some speed improvements though. Hopefully moving to SSA helps enables those optimizations in the future.
It is still much slower than 1.4. I'd like to see the 1.5 regression with respect to speed fixed.
They annoy me to no end. It should be fixed.
Thanks, we can improve the opening of links. Our hypothesis is that there's a lot of value in curation and adding some commentary about why the curator chose a collection of articles. We're trying to balance showing that commentary vs getting users fast to the articles. We'll keep on looking for ways to make that better.
I think we need to make it clearer that the screenshots are links and not really meant to be read on the site. Our thinking was that a screenshot gives a better idea of the content than just a text link. But what I'm hearing from a few pieces of feedback is that the experience is just confusing. Our bad, we'll work on it! Thanks for taking some time to give feedback.
Well, a 46-line CLI tool isn't even an app tbh, it's a helloworld. If I were you, I wouldn't share it. Turns out, the thing won't work on Windows (there is no notify-send, you should stick to custom notifying libs written in Go, like [notificator](https://github.com/0xAX/notificator)). The idea seems good, yet needs development tho.
cool, yes it is a helloworld, but a helloworld which *does* something I was totally unaware of notificator! Thanks :-) I'll add it over the weekend when I get time. Also tbh all apps start small, so this is one small step for a human and a big step for gopher :D jokes apart thank you for your comment! If it is not too much to ask, what else do you think will make a good feature for this helloworld?
You could try interfacing directly with the dbus notification service instead of executing notify-send. Probably doesn't make a lot of difference, but is a bit more low-level. And you could extend it to lock/shutdown your computer via dbus and calling all other kinds of services! [Example](https://github.com/godbus/dbus/blob/master/_examples/notification.go) - [Notification Spec](https://developer.gnome.org/notification-spec/)
If you're using http handlers, you could wrap the parent one and log stats there. Am on mobile so can't add code easily.
Very nice. Testing it now in ubuntu... I don't care how many lines it has. What I like is that it's something useful. The fewer lines the better. Thank you!
Thank you for the advice. The next postings will have a name describing the content respectively. We hope you’ve enjoyed the article. There will be more to come in the next weeks.
thank you! I built it in elementary OS so it should work fine in ubuntu 
This is indeed a very interessting topic. We will take a closer look using Go for other projects. Currently we are building up a distributed system with a neat architecture. Hopefully, we are able to give you some insides asap.
You want something like this: https://github.com/signalfx/golib/blob/master/web/bucketreqcounter.go Notice the Wrap function on that page. It wraps one handler with another. You can then call Datapoints() to get a lot of points about all the requests, including sum of time spent, count of requests, active request count, sum of squares of time spent (for std-dev), min, max, p99, median, and much more.
Perhaps I can help you understand this a bit more. What is happening in this example is essentially a large daisy-chain of filters. First, the Generate function simply passes a continually incrementing number into the channel it was passed. When go is called to spawn a goroutine, the variable at the state it was called is passed. This means that the line in the main function: go Generate(ch) will always reference the original channel created. This channel will keep getting and ever incrementing number of ints passed into it, from 2 until whenever the program stops. Next, the Filter function: func Filter(in &lt;-chan int, out chan&lt;- int, prime int) { for { i := &lt;-in // Receive value from 'in'. if i%prime != 0 { out &lt;- i // Send 'i' to 'out'. } } } Will, until the program stops, read a number from the in channel, and if it is **not** a multiple of prime, it will send it through to the output. Now the key thing to remember here, is that the go routine spawns and will forever reference what was passed into it when it spawned. That means that the line go Filter(ch, ch1, prime) Within the main function, will always reference what channels ch, ch1, and prime were at the time of this goroutine spawn. To illustrate what's happening in the program, we just need to think about the order of what is happening. Now, it is important to know that channels that are created with no length specified will block on send and receive. This is the only point where a function's execution will pause, and wait for other things to begin. With that in mind, let's consider the execution of the program. * *main* - First, we have a channel, **ch**, that is created and passed into a newly spawned goroutine, *Generate*. This is the first goroutine spawned, so I will refer to it as *goRoutine1*. * *main* - At this point, the execution continues into the for loop, where we encounter the variable **prime**. * *main* - **prime** is created and is assigned to whatever **ch** has received. * *main* - At the moment, **ch** hasn't received anything. * *main* - So the *main* function pauses as the receive action on **ch** blocks, and now another goroutine is able to be run. * *goRoutine1*(*Generate*) - Since only the goroutine referencing *Generate* exists, the program switches to that. * *goRoutine1*(*Generate*) - starts it's execution, and iterates through the forloop. It sends the first value it encounters from **i**, in this case 2, through it's local channel **ch**, and continues. * *goRoutine1*(*Generate*) - tries to send another value **i**, in this case, 3, through the channel, but the channel only has the capacity for one number, so the send action blocks, and the goroutine is paused, allowing for something else to execute. * *main* - is now able to resume execution, and resolves the assignment to **prime** since it now has a value within the channel. * *main* - now prints out the **prime** which is 2, which is the first number we are given from *Generate*. * *main* - The program now creates a new channel **ch1**, which will act as the new channel we will receive future primes from. * *main* - The program spawns a new goroutine with the function *Filter*, passing it **ch**, **ch1**, and **prime**, as they currently exist. This is the second goroutine spawned, so I will refer to it as *goRoutine2*. * *main* - Continues, and assigns **ch** to **ch1**. The only thing this will affect is the next iteration of the forloop within *main*. All of this has been fairly straight forward at this point, and the execution after this is still straight forward, it's just a lot of context switching that occurs. * *main* - **prime** recieves from **ch**. **ch** in this case is the **out** channel from the *Filter* function of *goRoutine2*. * *main* - **ch** hasn't received anything so it blocks, and allows another goroutine to execute. * *goRoutine1*(*Generate*) - awakens, it's local **ch** is no longer blocking, and so it sends 3 to it. * *goRoutine1*(*Generate*) - tries to send 4 to **ch**, but **ch** is full and so it blocks, and allows another goroutine to execute. * *goRoutine2*(*Filter*) - begins it's execution. * *goRoutine2*(*Filter*) - assigns **i** from it's **in** channel argument. (This is the same channel that *goRoutine1*(*Generate*) is sending on. * *goRoutine2*(*Filter*) - **i** is assigned to 3, no blocking at this point, since 3 was already sent into the channel. * *goRoutine2*(*Filter*) - **i** is not divisible by **prime** (2) * *goRoutine2*(*Filter*) - **i** (3) is sent to **out** * *goRoutine2*(*Filter*) - begins another iteration. * *goRoutine2*(*Filter*) - attempts to receive from **in** and store it in **i**. * *goRoutine2*(*Filter*) - **in** blocks, allowing another goroutine to execute. * *main* - **prime** receives from **ch**, in this case the value 3. * *main* - prints 3. * *main* - creates a new channel, **ch1** and spawns a new goroutine, *goRoutine3*. Passing the currently referenced variables, **ch**, **ch1**, and **prime**. * *main* - assigns **ch** to **ch1**, and loops. * *main* - receives into **prime** from **ch**. * *main* - **ch** hasn't received anything and it blocks, allowing other things to execute. I could keep going, but that will become very difficult to follow, if it hasn't already. The gist of what's happening is something like this: When we find a prime, we create a filter to help us consider only other things as primes. The filters are created whenever a new prime is found, and helps us to only consider numbers that pass the previous filters as potential primes. As each new filter is created, it receives number to test from each filter before it. That means that the filter for the prime 2 receives every number, and only returns every other one. filter(in,out,2) // sends to out 3,5,7,9,11,13,... only odd numbers Once a number gets through all currently existing filters, it is considered a new prime number, so we create a new filter with it, and hook it up to the previous filter. For a filter with the prime, 2, the next prime is 3. So the next prime we receive will have to get through both filters to be considered a prime. filter(in,out,3) // receives from filter(in,out,2), sends to out 5,7,11,13,... only odd numbers not divisible by 3. 5 is the next prime, and the process repeats. filter2 -&gt; filter3 -&gt; filter5 -&gt;filter7 -&gt; filter11 -&gt; filter13 -&gt; filter17 -&gt; filter19 -&gt; filter23 -&gt; filter29, so on an so forth. The program only outputs the first 10 primes, and so execution stops here, but it doesn't need to. Essentially the main function is just reading **prime** from anything that has passed through all previous filters. As an aside, to try and be as clear as possible, when others are referring to pass by value they are referring to the function signatures not specifying a pointer value (denoted by *). Since these are not pointers, they are pass by value. This means that when the call enters the new function scope, they get a copy of the arguments. Even though the channels are copies of the original, they still refer to the same send and receive portions of the original channels created in the main function. I apologize for the length of the post, but I figured I'd try to provide a couple of explanations to provide more detail in hopes that either, or both, help.
I feel like I'm testing their plaything lately.
That's true. I didn't think about that.
Thanks for writing it! I think the only trouble I had was figuring out how to disable the automatic mechanisms to obtain the cert with like a web server. And how if I serialized the CertificateResource to JSON it didn't save the certs in there. Also this is probably an ACME issue, but it wasn't clear to me why you'd want to renew instead of just issue a new cert every time.
Why do people prefer DNS? If I use DNS, I have to somehow (in)securely give the application my DNS provider credentials/oauth token. If I use the web responder, then... I just need to have my webserver return a challenge on a URL. No credentials to worry about. Especially when you're embedding lego in your Go app, I really struggle to understand how DNS is the better option. Not trying to point fingers... I assume I'm missing some details or something?
&gt; If I use DNS, I have to somehow (in)securely give the application my DNS provider credentials/oauth token. No, only do it securely. &gt; If I use the web responder, then... I just need to have my webserver return a challenge on a URL. No credentials to worry about. True, but then you have to worry about binding to low port that may already be in use, getting privileges to bind to said port, etc... &gt; Especially when you're embedding lego in your Go app, I really struggle to understand how DNS is the better option. If you're behind any kind of load balancer or TLS terminator, you need to use DNS. Right now if your app is on IPv6-only hardware, you have no choice but the DNS challenge.
&gt; ... is slightly more complicated than saying "my container will be able to bind port 80 at runtime" Unless you're already using port 80 for something other than serving static files. If you can't accept downtime, you need another way. Period. &gt; They're very, very, very different problems. Which is why there are very different challenge types. DNS solves very real problems, you probably just haven't run into them. Most people will probably use env variables to set DNS auth. &gt; It just an HTTP request that will be reverse proxied like any other request. Why wouldn't it? If the load balancer sends the challenge request to a machine other than the one initiating the challenge, it will fail. And TLS termination breaks the tls-sni challenge.
It's OK though. Currying is a way to embed multicategories into closed monoidal categories. When currying isn't convenient, stay in multicategory-land and use operad composition: compose a n-ary function with n other functions. They form a tree. Then, no need for exponentials, it's closer to the true nature of these languages (is what i do in Python).
&gt; Like... ipv6 isn't magical in some way that breaks request/responses. That's what I don't understand. I assume you haven't much experience with networking infrastructure. The short of it is that their DC can't connect to IPv6-only networks yet, but it will soon. But DNS challenge works in that case because their system doesn't need to connect to your machine directly for the DNS challenge.
Right now renew can mean two things (according to the spec): Each certificate gets a "stable url" at which you can GET the latest certificate. A CA may renew a certificate by simply responding to a GET request to that url and that request will yield the new certificate. If the CA does not allow for this, we need to create a new one. As there is logic involved on the client side in order to figure out if the returned certificate is indeed a renewed one and this logic is not needed within the normal ObtainCertificate path I created the renew function. As said before tho, this part of the spec may get removed.
I am reading through this answer now, but I just wanted to tell you that I appreciate you taking the time to help me out with such a detailed post. I'm reading through it now, thanks again for your help
This looks very useful, thanks for sharing!
You may want something like 'dhash'. I don't know if there is a golang implementation yet. Some links about it from https://github.com/maccman/dhash http://hackerlabs.org/blog/2012/07/30/organizing-photos-with-duplicate-and-similarity-checking/ http://www.hackerfactor.com/blog/?/archives/529-Kind-of-Like-That.html http://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html http://blog.iconfinder.com/detecting-duplicate-images-using-python/ I've used it in Python and it's quite good at finding similar images even if they have been resized or altered slightly. Edited to add: found this - https://godoc.org/github.com/jteeuwen/imghash
I tried a bunch of the pre- and post-vendor experiment tools, and so far Glide and [gvt](https://github.com/FiloSottile/gvt) are the only reasonable ones. gvt is a bit simpler than Glide - it just manages and locks the vendor folder for you.
Measuring latency in a wrapped handler is not accurate. You completely ignore interval from the time a connection is established to the time a handler is called. This can be significant source of latency in a loaded system. You can read about coordinated omission for more details.
A monad is just a monoid in the category of endofunctors, what's the problem?
I come from python background :D, have not used switch since three four years! Thank you :) Have made the change
Under high load many things can happen while a server is running the code you pointed to. E.g. a context switch, or stop the world GC pause. Now 0.1ms can suddenly become 10ms or more. But even to get to this point the server executes a lot of code from Go runtime and OS kernel. All this should be part of latency numbers if you want to get accurate picture of the latency distribution. Ideally you should measure latency outside of the running Go process. E.g. if it is behind proxy like ngnix you can measure latency inside this proxy.
Well, golang GC is stop the world, so don't expect to be able to measure anything from within when it's happening. GC aside there is nothing you can stick higher up the chain than the handler - `(c *conn) serve()` is not exported - you'd have to add your measurement code by modifying that function: right before https://github.com/golang/go/blob/master/src/net/http/server.go#L1424 start := time.Now().UTC().UnixNano() defer func() { respTime := time.Now().UTC().UnixNano() - start go doSomething(respTime) } 
There are bindings for phash as well. Note that you probably want something like https://github.com/dgryski/go-simstore instead of a bloom filter to store and search through the image hashes.
The problem is that latency measured by timing a handler doesn't accurately reflect the latency experienced by clients of the application. This is like measuring time that takes a barista to make a capuchino ignoring a long queue that you need to wait to be served.
Why 1 hour though? Is it backed by a research? Links to these would be nice if so.
hmm the reason they had given once is that inside Google they take everything inside their codebase so they aren't bothered with changes on dependent libraries since they have the code which they need right inside their tree, thus their reluctance to build a package manager. In a quora conversation someone who seemed to know a lot about how people at google work told me that very few devs use Mac and out of those very few use homebrew because for work they don't need to use a package manager
I posted this in hopes that people will avoid making it a trend (it's already starting) to derail conversions on other posts about Go's performance with useless comments about compiler speed. The devs already know about, many of us know about it; there's no need to bring it up over and over again on threads that are about something else.
I like your attitude.
Wasn't the same thing said about the compile time increase of Go 1.5?
IIRC they didn't plan any compilation speed polishing for 1.6. But they are talking about it now for 1.7.
so that mean Go gc not much a problem when developing game?
I think Jonathan Blow said in one of his JAI language vids that he needs &lt; 10ms pauses to be viable, which ruled out Go at the time, but I could be wrong
Ah thanks!
Great library. It would be great if the ACME specs would allow ports other than 80 and 443 so we can run it side-by-side with a webserver for example. I like the CLI, it's better than the letsencrypt-auto which is slow, complex and verbose. I think the readme can improve with more documentation and examples though.
Very nice - good work
Ffs
OK. I got it. But I think 'Graceful reload' is more apropos for this.
`tip` is the Mercurial equivalent of `master`.
Thanks, makes sense.
In just one round of optimization those numbers you quote have been smashed: https://www.reddit.com/r/golang/comments/43cpy6/gc_pause_times_from_300ms_go_14_to_40ms_go_15_to/ And I have no doubt they will come down further. **Edit:** The correct *smash linking* is given below, but my earlier link is massively impressive as well: https://groups.google.com/d/msg/golang-dev/TerfinvPffw/wvrEefWvBwAJ
Ok, it might be worth a try to use ioutil.ReadAll to get everything the reader has in a []byte and then do a fmt.Println(string(b)) and see if that makes a difference. Edit: I don't typically recommend the use of ReadAll, but for debugging it's very useful
Has anybody used this yet?
Thank you :-) any improvements I can do?
I'm the author of acmetool. You can actually use my tool to distribute certificates to other servers. After new certificates are acquired, a directory of hooks is executed. These can be shell scripts to rsync new certificates to other servers, or well, anything. I recently added support for doing the same for HTTP challenges. If getting HTTP challenges provisioned is complex, you can write a script which acmetool will call with the data when it needs to install or uninstall a challenge. Eventually the same will be possible for DNS. So if you're willing to write a little shell (or any other type of script or binary) you can integrate it quite nicely without putting the binary on a production server.
Sorry, didn't mean to insult anybody I will delete it in that case. Of course they can but that would be sad because I fear Golang would lose userbase in that case.
Cool stuff! Keep more of it coming!
I don't have anything against SSA. What I said is related to the fact that, whatever you do in a compiler, benefits are always measured in very very low percentage points, and in fact most things end up being very hard to measure for how little they contribute against a CPU that optimizes the code itself. On top of this, most optimization theory focus on code generation performance, and compile time speed is not always strongly analyzed (if not for avoiding higher order complexities). So in this scenario, saying that we get a 100% compile time hit and then optimize it is wishful thinking. Remember that the SSA branch itself is not even bringing concrete improvements on generated code, so merging it in this status would be a mistake. Then, of course, if they know the code contains monstrosities that can be hand optimized in a couple weeks, well, let's do that BEFORE merging then. 
This just means they're not supporting it. However, http://google-opensource.blogspot.nl/2016/01/seesaw-scalable-and-robust-load.html
I also avoid results from groups.google.com. The page renders very slow and finding what you were looking for is very difficult because the discussion is collapsed when the page finally loads.
[removed]
Google uses it. I doubt it was used by anyone else since it was just announced.
Aaaah c'mon. I just got into the habit of only doing this stuff in an incognito window. Now I have to clear my history again. 
What's worse is I subscribe to many subs on IFTTT and getting this in my email is NOT what I want..
IMO, it's easiest to learn programming when you have a project or use in mind. It may become clearer which language is appropriate based on that. Another thing to consider is picking a project (or three) and implementing them in both languages. Neither is hard to get started on.
gc is not (even Go 1.5 is good enough) but C function call overhead might be.
... or [micro](https://github.com/micro/micro)?
No it's not. The language spec is concise and should always remain that way, which is definitely one reason why it might be good. The downside, however, are: - You /need/ to understand OO well. The tradeoffs between coding to an interface rather than an implementation - You can't really demonstrate or learn functional programming to anyone with go. To do that, they'd have to learn an entirely different language. - Inheritance in go is quite different that most other common languages. IMO, a first language learned will be at least relatively familiar to other popular languages in order to help lower the barrier of entry. Go doesn't really give you that. - It's far too easy to get into parallelism with go without really understanding what you're doing, which can lead to many a headache. - Testing with mocks and such is easier in python instead of having to worry about DI - Python (again IMO) is quite a bit easier to just hack on than go Then there's gdb. When teaching someone python (although I've never taught someone from the ground up), one of the things I harp on is how tremendously useful a debugger is when wrapping your head around how systems work. gdb is not exactly the most simple or straightforward to debug with. True, pdb has a similar interface, but IMO is simpler and easier to grok.
Micro over kit any day. Micro is much more in line with idiomatic go, whereas I consider go kit to be the over engineered Revel of service libraries.
Also note that it was only used for internal corporate services at Google, not serving external user traffic (source: http://google-opensource.blogspot.nl/2016/01/seesaw-scalable-and-robust-load.html, but also my personal experience hearing about the project).
Meh, it is what it is. Create a reply on a thread specific to go talking about anything negative and I can be pretty damn sure I'll be downvoted ;) Choosing a language to teach someone with definitely /is/ a tough thing. GL :)
Like *aboukirev* said. They complement each other. There is a new alternate Sublime Golang plugin, if you're interested: [GoFeather](https://github.com/frou/GoFeather?utm_source=golangweekly&amp;utm_medium=email) Also, why did this thread become a "What's your preferred editor for go?" :D
&gt;I downvoted you because some wrong statements like the below quotes. And you have a couple valid points :) &gt;There is no class inheritance in Go, and object composition is not a "quite different type of inheritance" as you states. Right. I chose poor wording to get my thoughts across. Many languages offer both inheritance as well as composition. Go only offering composition is quite different. I'm not saying I don't understand the reasoning behind it, I'm just stating that it's quite different. &gt;No, you don't. Go allows to create any program without create any object. And how many projects of any consequence are you aware of that do not use any objects at all (I'm genuinely interested in seeing some)? IMO having a sound understanding of at least interface abstractions of concrete implementations is vital (as well as understanding the oddity of interface{}. &gt;That happens with any language with multiprocessing features, including Python. I might be missing something about some languages, but it's /much/ less obvious in go than in other languages. For example, with python I'd have to import the multiprocessing package and then explicitly kick off a child process. In other words, I'd need to actually think about what I'm doing and do it on purpose. Not so much with go. 
Well, it depends. In most cases i would favor Python: - The dynamic typing makes it much easier to get started - The REPL makes it awesome to write line by line, to inspect and explore - The tooling for learning and application in many science areas is awesome. You can easily use it Math, Physics, Text Processing, for exploring public data sources. - Go IS a systems language. It's designed to be that. You have to be aware of memory, how pointers work. I found it hard to get for beginners to get how slices work. So in general no. But if the person for example has in mind to develop REST APIs, to learn networking/HTTP then Go might be a great fit.
The latest pproposal I've seen for the Garbage Collector is here: https://github.com/golang/proposal/blob/master/design/12800-sweep-free-alloc.md
I can't agree with many of the things you said. A beginner doesn't need to understand interfaces, and Go doesn't force you to use them. OP's friend doesn't need to learn parallelism or inheritance. Testing with Go is as simple as it gets (to the point of being overly simplistic), and it's easy to understand what the tests are doing. Why would a beginner even think about mocks or DI? Your points are only relevant to an intermediate programmer, and by the time OP's friend will be ready to learn the more advanced topics when they reach that level. You're probably being downvoted because your answer isn't particularly relevant to OP's question.
Go is good language to teach a beginner but Python is much more suitable to teach a beginner.
I'm no go expert, but you has no tests??! O.o ;)
Check out http://goa.design/, it's awesome. You get performant idiomatic code generated off of your design docs.
&gt; It's far too easy to get into parallelism with go without really understanding what you're doing, which can lead to many a headache. That happens with any language with multiprocessing features, including Python. Yes, but Go makes it easy to get yourself setup to do parallelism. It's like not having to cut thru thick forest to get to the point where you have to then navigate a field of land mines. Most languages will stop you in the forest before you get to blow yourself up.
Thanks a lot!! I learnt front end dev by myself :-) Json decoder? I have no idea what it is. returning errors, yes, I am going to do that soon, two things are left in the application as of now, sessions &amp; categories About HandleErrors, I have read at many posts that rather than an abstracted function the `if err != nil` is more Goish. About rollback, yes I don't know how I missed it! Also a lot of placed I don't do anything on error because errors shouldn't happen there :-) like the database query things, the reason being the program won't compile if there is an error at that stage. Also it isn't intentional, the thing is when I started writing the application it was from scratch, so I put the print statements to log errors, I am yet to formulate a mechanism to notify about the error to the actual users via template rendering. Thank you for your comment :)
micro looks very promise, but now a lot of choices, which one should I use?
Ahh gotcha. :-) Error popups to the rescue. The json stuff is not that important since you are not posting anything with a json body. You are only using json in the configuration. The decoder handles closing reader bodies, that's why it's convenient. Like this: decoder :=json.NewDecoder(req.Body) var t test_struct err := decoder.Decode(&amp;t) if err != nil { panic() } log.Println(t.Test) This way you don't have to deal with io. ReadAll or something similar. The app *does* look very neat. :-) 
There is now a tracking bug https://github.com/golang/go/issues/14161
thank you!!
If you're having issues with the audio try this stream with VLC: http://stream-a.fosdem.org:8080/fosdem+h1302cam.flv … Thanks Dave Cheney for the tip!
You can't start a project until you know which language you're going to use. Starting a project in more than one language will only cause confusion. 
untilitworks migrateawayfromslack
Including young children with no interest in programming?
&gt; A beginner doesn't need to understand interfaces, and Go doesn't force you to use them. Maybe if you don't intend to use the standard library. That said, I don't think it's exactly a hard concept to grasp, especially compared inheritance based OO. In general I don't think you have to be as tall to ride Go as you would Java.
&gt; * You /need/ to understand OO well. The tradeoffs between coding to an interface rather than an implementation You only need to understand OO to the extent that it is actually used in Go, and methods as functions belonging to structs and interfaces aren't exactly rocket science compared to popular teaching languages like Java. &gt; * You can't really demonstrate or learn functional programming to anyone with go. To do that, they'd have to learn an entirely different language. You can't really learn declarative programming with Python. Obviously every language will have some shortcomings with their scopes in this regard &gt; * Inheritance in go is quite different that most other common languages. IMO, a first language learned will be at least relatively familiar to other popular languages in order to help lower the barrier of entry. Go doesn't really give you that. I guess it depends on what your goals are. If someone learns Go I'd guess that they would probably have less of a hard time unlearning its simple data structure concepts and get into Java than having to unlearn the Java OO model and going to Go. &gt; * It's far too easy to get into parallelism with go without really understanding what you're doing, which can lead to many a headache. I think that it is good for a teaching language to lower the barrier to that which you don't understand. &gt; * Testing with mocks and such is easier in python instead of having to worry about DI And then your mocks fall out of phase with your actual code because you haven't formalized their interfaces and all the tests pass while the program breaks, or someone decides to pass your functions a type that isn't covered by the tests... I seriously think that there are many benefits to using Python over Go as a teaching language, but in my experience testing Python isn't easier than testing Go. You have a whole class of problems you need to take into account when testing that don't even exist in statically typed languages.
First of all, the front-end work is great. I'm used to programming in Python for back-end. I've just started to learn Go and I want to build web applications with it. Did you find it hard build it? I'm reading your code(first web app I've seem) and seem's pretty clean, more than I would have expected before.
If you are interested, I am writing a book on writing webapps with Go. https://github.com/thewhitetulip/web-dev-golang-anti-textbook/ Thank you! I had worked on the front end for a long time, github.com/thewhitetulip/omninotesweb. I love UX/UI equally along with backend :)
Such a great work. Starred. I'll take a look in the details later. Thanks!
Your choices are. - https://github.com/grpc/grpc-go - https://github.com/go-kit/kit - https://github.com/uber/tchannel-go - https://github.com/hailocab/h2 - https://github.com/mondough/mercury - https://github.com/goadesign/goa - https://github.com/nytimes/gizmo - https://github.com/micro/micro
&gt; You can't start a project until you know which language you're going to use. Truly, but that's not what I was suggesting. I was suggesting that OP's friend should focus first on what they're interesting in making, not which language is "best to learn." &gt; Starting a project in more than one language will only cause confusion. I clearly am not suggesting they develop two programs in different languages in parallel to start. I'm talking about implementing a program in Python and *then* in Golang, which is a very useful exercise.
I'm currently in university and the first language we were taught was c if you're an engineer, otherwise you learn Java.
All great points (especially re mocks, in hindsight probably not a strength for a teaching platform), cheers! &gt;You can't really learn declarative programming with Python. Obviously every language will have some shortcomings with their scopes in this regard Indeed. But go has an intentionally narrow focus, whereas a multi-paradigm language at least lets you play with more than one. &gt;I think that it is good for a teaching language to lower the barrier to that which you don't understand. I'm not entirely sold on that (but I also understand that this entire question is wonderfully subjective ;)). I could just see someone using it because they've seen it elsewhere in example code without understanding what it's doing. Goroutine prefixes aren't exactly the most obvious things. But then maybe you're right. Not being a teacher, I haven't exactly taken a look at any metrics to help me understand how people learn most effectively. My response is entirely gut reaction from someone who's spent a number of years in the trenches, so maybe I'm looking at certain aspects with cracked glasses ;) 
The else statement at [Lines 27-33](https://github.com/bettinson/grep-webpage/blob/master/grep-webpage.go#L27-L33) seems unnecessary and if it isn't then `defer` looks weird in there. You can improve your test cases by using [Table driven tests](https://github.com/golang/go/wiki/TableDrivenTests).
Groupcache is definitely interesting, but it is closer to memcache than hazelcast. While it is embeddable, It isn't interfaced with native types and you have restrictions like this: &gt;does not support versioned values. If key "foo" is value "bar", key "foo" must always be "bar". There are neither cache expiration times, nor explicit cache evictions. Thus there is also no CAS, nor Increment/Decrement. This also means that groupcache.... Also, peer communication is over HTTP, which is obviously slower than raw tcp.
Dunno if this is helpful, but I came to programming relatively late in my career (or at least to programming in a structured, deliberate manner). I was a sysadmin and perl/bash/tcl was where most of my work was done, all very forgiving things to work in. Anyhow, the various traps and gotchas are still somewhat fresh in my mind. For me, python was a godsend. I appreciated (and still appreciate) how opinionated it is. Perl's forgiving nature is fantastic when you have to get something done *right now* but it's a disaster over the long haul, because it doesn't instill discipline. Python, I think, brings that to the table. As to Go, it's great and has become my language of choice, but I agree with /u/dbrecht that with Go the wrong things are easy (parallelism) and the wrong things are hard (testing, types, package management). Finally and, IMHO, most importantly: Go lacks a real REPL and, sorry, none of the existing options count. The ability to just type an expression and watch it evaluate in realtime is absolutely indispensable when you're trying to feel your way around unfamiliar concepts. 
It's just as easy as starting with Python, ruby, Java, or c. Which is what most university students have or do start with.
He is speaking about the GO15VENDOREXPERIMENT variable: https://docs.google.com/document/d/1Bz5-UB7g2uPBdOx-rw5t9MxJwkfpx90cqG9AFL0JAYo/edit
Also, in Go, always handle negative cases first. If it's negative return, otherwise continue, and you won't need else in that case. Because by default you just go without breaking. The cases of if's are not needed. Have the for terminate on EOF. That way it will surely not be an endless loop and will be more readable. Your regexPredicate is a bit over engineered. And this just a general git tipp... Have a README.md. :-) Welcome to the community. :-)
not in the league of httprouter yet, but you can see the benchmarks or even run them yourself. Thanks, the reaaon behind it is to stick to what really matters. The golang standard library is fantaatic. 
but which should I choose please help me. Which one is good to start?
Some implementation specific hints: * `regexPredicate` could just return `regexp.MustCompile(pattern).MatchString`. It could also be inlined completely on #29 but then the line would end up being kind of long. * The string slicing you do before checking for other errors after `ReadString` and checking for `io.EOF` could potentially cause a runtime error if some other error condition leaves `line` an empty string. You should probably break in any error case and check if it's `io.EOF` afterwards. * One of the advantages of grep is that it doesn't need to buffer all the output lines. You should probably just immediately write matching lines to `os.Stdout` or deliver them to the main function via a channel so it can range over the output and print it. As for the purpose of the tool itself, I don't see what exactly it offers over curl piped into grep, but the implementation looks good, points above aside.
You could write a layer on top that maps to your typed values. If you want CAS/Increment/Decrement and things like that, it looks to me like you want a database more than a cache. I'm not familiar with Hazelcast so maybe I'm missing something.
now do it with randomized exponential backoffs
It is pretty small in what functionality, keywords, etc. there are and very easy to read. Both of them enable people to learn quickly by reading existing code. The go tools make it extremely easy to not having to care too much about the surrounding topics. Also Go comes with a great stdlib which means someone new to programming doesn't need to first learn about various libraries out there to do something real. I think all those properties make Go an incredibly good first language. The only "downside" - depending on whom you ask - is that there is static typing. But compared to other static languages it is really an excellent first language.
Do you even Prometheus bro?
goose because it is basically the only lib that allows you to write migrations with both .sql and .go. People saying that they don't need to write migrations in .go never managed an app in prod.
Teaching someone who doesn't want to be taught is a difficult challenge, and the language you choose to teach them will only have a small influence over that. Regardless, the OP asked about teaching a friend of his who wanted to learn programming, so the question's entirely irrelevant.
Well I'm biased since I wrote micro but I quite honestly believe that if you're struggling to choose a "framework" then you should just use net/http or net/rpc and construct the bare minimum for what you're trying to do. It comes down to.. why do you want to use a microservice architecture? Why do you think that would be beneficial to you? If you cannot answer that question then you do not need microservices. What features do you need for microservices? What do you need out of a development framework? What do you need out of a runtime or platform? You have to be able to answer these questions to make the choices. If you cannot then I truly believe sticking to the basics is key. When I build side projects I still begin with net/http or net/rpc and build monolithic software.
You're closing the file at the end of the `Logger()` function, and you can't write to a closed file. Edit: Whoops; I'm slow.
Keep the file permanently open and only close it when you close your app 😉 
I think static types very likely clarify things for a beginner. Pointers are tricky for some, but not all, and I think the Go version is probably a bit easier than the C version, just because the syntax is more consistent.
I want to write microservices based application because of scability. In my opinion, it would be better to maintain and testing using microservice architecture. But first of all, I want only configure out, if microservice architecture is suitable for my requirements. Just make a prototype and discover, what microservice really means. Which framework is good for starting, maybe micro?
If your answer to microservices is so simply scalability, you don't need microservices. This model comes only when running a monolith or a few larger applications becomes untenable due usually to organizational scale issues. Trying to solve the scalability issue of infrastructure before you have problems here will typically only lead you down a path of sadness.
I prefer dns because I deploy certs to multiple load balancers. Configuring the entire path from LE to whatever server is obtaining certs can be a real pain, and even after that I still have to copy it around. There are other complications with cloudflare type providers too. Once you enable strict https, it is hard to proxy the validation requests through CF because you don't have a cert to be proxied to. It can be a bit of a chicken and egg problem. With dns challenge I can configure one box to issue all certs on a schedule and deploy them to the load balancers when they are ready. One at a time, without disrupting live traffic.
If you are not using interfaces or parallelism, then for a beginner, the Python syntax is much more easy to understand while learning to code for the first time. And also with a lot of higher order functions and simple data structures, its easy to get ramped up on Python. I think Go should come at a later stage when a person wants to learn the finer points in coding.
Curl is treating it as a HTTP proxy. In order to verify try this. nc -l localhost 8001 Then run the curl command and look at the output. plain http. This is intended, take a look at the following. http://stackoverflow.com/questions/516323/https-connections-over-proxy-servers
Looks nice
interesting. thanks!
&gt; Next stop was documentation That should've been your **first stop**. Go isn't PHP, Python, whatever... if you insist on pretending it is, you're going to have a bad time. This applies to any two languages where you're trying to write code in the one you're learning as-if it's the one you already know. &gt; Next I skim That's the second problem. Because you chose to skim, instead actually *reading* and *understanding* what you read, you missed all the information you needed (IMO). It's literally right there; you even quoted *part* of it. There's even an example right below it that goes into a little more detail... &gt; So long story short. From Time package constants you can figure out how date and time are formatted but I still would prefer a detailed explanation for each placeholder and because of this reason generated a table with list of available placeholders for date and time formatting. And after all of that, I still get the feeling that you've missed the point... To quote the documentation on the `constants` section which you presumably skimmed as well: &gt; the reference time can be thought of as &gt; `01/02 03:04:05PM '06 -0700` &gt; To define your own format, write down what the reference time would look like formatted your way; see the values of constants like ANSIC, StampMicro or Kitchen for examples. *The model is to demonstrate what the* **reference time** *looks like so that the Format and Parse methods can apply the same transformation to a general time value*. 
Such a library does not exist, I know because I've looked for it (Cache that is distributed, embeddable and supports cache eviction) Most libraries you'll find will be of the form `map[string]interface{}`. Groupcache is the closest we have. I'm sure there will be a lot of interest for such a library/server. I'll be happy to contribute.
I don't pretend that go is anything else then go. It's just that in every new thing you come with some expectations. I don't expect and want go to work as any other language, but I still have some expectations, that such common thing as date formatting will work as it does in other languages. PHP, Python, C# all of them use similar placeholders for date formatting so when I search for how to format dates in go, I search for something with similar pattern as in other known languages. Also how hard it is to include table with all the available placeholder in the body of **format** or **parse** documentation like in [PHP](http://php.net/manual/en/function.date.php), [Python](https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior) or [C#](https://msdn.microsoft.com/en-us/library/8kb3ddd4(v=vs.110).aspx?cs-save-lang=1&amp;cs-lang=csharp#code-snippet-2) I think I just got used to PHP and especially Laravel documentation because it is so much more well written than Go documentation. On one hand go approach to generate documentation from comments is great because it forces developers do some explanation in the code. On the other hand I think it is a half assed approach to write it.
There has only been minor work on binary sizes each release. The Go team knows that. The issue tracking it is https://github.com/golang/go/issues/6853
I've been looking for something like this for so long! Awesome.
&gt; Also how hard it is to include table with all the available placeholder in the body of format or parse documentation like in PHP, Python or C# A "detail" that makes Go awesome is that you can write [examples](https://golang.org/pkg/testing/#hdr-Examples) that (like tests) are part of your code base. The "table" you are looking for is this [time format example](https://golang.org/pkg/time/#example_Time_Format) which you can run in your browser. You can even modify the code and see the results for the case you are interested in. &gt; On the other hand I think it is a half assed approach to write it. I couldn't disagree more. The beauty of the Go documentation is that each doc comment, is just a good comment. A good comment that you can read through the console, your editor, your browser or even picked up easily by an automatic tool and it looks good in any form without using any fancy syntax or tags or anything. Add to that the examples I mentioned earlier (which are part of the code base) and you have something very powerful.
Can you please share your particular use case? I personally can't think of one.
My use case is for having fun.
I really like it, but I'm not sure how to generate appropriate images. Did you really draw that by hand, or did you generate it with something else?
Uhm... alright then.
Reminds me of the ca prime computer http://www.quinapalus.com/wi-index.html
Having a REPL is nice, and certainly a huge edge that languages like Python and Ruby have over Go, C, Java, etc., but very few mainstream programming languages have a strong functional aspect, so I think it's a little unfair to call out Go for it. I also did find a Go REPL called [gore](https://github.com/motemen/gore) after a quick search, but don't have enough experience with it to say how well it works. I think Go would be a great first programming language, but to me the biggest issue would be its strictness regarding imports and unused variables. If first-year students think compilers are picky about semicolons, then they'll get really annoyed with Go's compiler.
A great alternative is migrate: https://github.com/mattes/migrate
individuals' fitness should not be recomputed every time. It's better if one can specify a "delta" fitness function.
I second this. Migrate is awesome. 
This is very cool. A useful addition might be to add value conversion with strconv based on field types. For example, if the field is an integer type, try making the appropriate ParseInt call and return an error if it fails. It would be useful if used responsibly, for example if I am matching a sequence of digits that I am confident will fit into the type I have assigned to it. If you approve of the idea but don't feel like implementing it, I might give it a try and send a PR during the weekend. Seems like a good reason to dive into the reflection package.
It's not in pkg, this is in src. I haven't even installed it - still just writing.
* Constructing the URLs via `url.URL` would be nicer. * Some variable names are fairly long (`statusCode`) that could be shorter, and sometimes removed. Go is about "reducing cognitive load for the reader" (whether you buy into it or not). * For `getProjectsBy` the if-statement over method could use a switch statement instead. * For `request`, note that client.Do returns an open body reader that you should close to avoid hogging connections: https://golang.org/pkg/net/http/#Client.Do * For `EditIssue`, splitting the two cases into two functions will make the `string` special case clearer. * For the `Project.AvatarUrls`, idiomatic Go would call it `AvatarURLs`. * In many places you return maps. Go APIs often return slices (I assume it is because they are the simplest collection type in Go), and let the callers create indices they need. Or they would return a type that provides properly named accessors, so you would only have one `GetProjects` and it would return something that can look up either by key or ID. That's all I can think of. The rest looks Go:ey.
Sounds like more of a job for bash or make.
This would be awesome if it did it fro GoConvey. Then wrap it up in a sublime text plugin and do that jump to test/create test shortcut.
There is a callback function `GetCertificate` in tls.Config
Hello. These are the best candidate solutions at each generation. For example the last item on the list has a fitness of 1.4172721198692076e-06 because it's genes are worth [0.0011522833127471895 0.00029919105440098017]. I'm going to code a function to make this more explicit when representing an individual.
&gt; https://github.com/tomcraven/goga Thanks! I'm happy you answered, I would indeed like to compare our two libraries. Both on the theoretical level and the implementation. &gt; Have you had any interesting results with the demes? e.g. multiple solutions to the same problem. Actually I'm going to commit later this week that will put to full use this "deme" concept. &gt; That's true, but is it correct that your code only parallelises (is that even a word?) at a deme level? Have you thought about parallelising at a genome level as well? To be honest, you probably won't see any speed up for the complexity of the examples (you'll actually probably see it get worse), but you may if the evaluation stage takes a long time. Yes, it would be possible to parallelize at an individual level but I feel that the overhead would be too high. &gt; Hope you dont mind me looking at the code - in crossover, should the switch statement use pMother/pFather instead of 0.33 and 0.66? Actually there was a little typo there, I'll commit a fix tonight. Don't hesitate to pick up on the errors :)
Indeed! I already thought about this but for some reason I forgot everything about it. Thanks for the reminder :)
I've had great results with [Goose](https://bitbucket.org/liamstask/goose/). I have no reason to choose another tool on a Go project. Migrations, solved.
I solved this problem by serving my app behind nginx. The problem of managing certs is made less painful and you're given access to nginx's excellent feature set for caching and load balancing.
Interesting, thanks. At least **strconv.Itoa** does as expected; which I will always use now. 
First off, thanks for writing this down! Second -&gt; * Yeah, I know it's that, thought I missed writing that down then properly. Thanks, I'll try to re-formulate the Post! * Actually, if I don't send the headers, it will still complain that the call is not allowed. Either I'm missing something there, or you mean something different, I'm not sure I know about. If I get those headers out of that ajax call, it will decline the request and complain that those headers aren't set. *EDIT*: Actually I'm reading in several posts that you do need to set the header in the request... So. Am I misunderstanding you? * You are right in that I should not use *! I completely agree and will fix that. * I don't trust the backend because the server does not know about the backend! :) The server is a REST API, it can be called by, whatever. Now, I'm not saying that currently, it's a super duper uber secured something, no Mr. I still have a lot to learn about that. But I do wish to fine grain the access to these end-points. Now, if you know a better way to do that, please, point me into the right direction. And again, thanks for taking the time to write this. I truly appreciate it!
I always asking myself for what concrete security threat I'm implementing a security feature. Limiting the access for your frontend to only a rather small selection of API endpoints via CORS is kinda weird and would only make very special XSS attacks harder.
Additionally, the type of the fitness function appears to be limited (slice of float that returns a float). At this point, you can't deal with problems whose solutions are combinatorial objects (e.g. sets, permutations). It might be better to introduce an interface that requires fitness functions (e.g. Fitness, DeltaFitness, etc.) and no other assumption on the type of solutions that the GA evolves. 
Yeah, I believe https://github.com/xenolf/lego has an example for using their library this way.
Or use caddy as a proxy in front of your go app. That's what I do.
So, if I leave out the headers... This is what I get... Request header field Access-Control-Allow-Origin is not allowed by Access-Control-Allow-Headers in preflight response. It complains that the header does not have allow origin enabled in the response... Note, I did read this -&gt; "Developers using cross-site XMLHttpRequest capability do not have to set any cross-origing sharing request headers programmatically." **EDIT**: I got it now... So because you are setting Access-Control-Allow-Origin you also need to set it into the OPTIONS response. And since you Set it as a header, the response needs to contain an allow for that header. Hence, you need to set Access-Control-Allow-Headers. BUT!! Since you set Access-Control-Allow-Headers, you now need to set Access-Control-Allow-Headers as an allowed header in Access-Control-Allow-Headers.... It's headerception. So you end up with this -&gt; headers: {"Access-Control-Allow-Origin": "*", "Access-Control-Allow-Headers": "access-control-allow-origin, access-control-allow-headers"}, And in the Code: c.Header("Access-Control-Allow-Headers", "access-control-allow-origin, access-control-allow-headers") *Magic.*
can someone post an ELI5? I'm not sure what just happened
I think you were supposed to expect ```8f944843cf91205596a82304479a49db20```. Unless you've messed around with go enough to know that if you want to get the characters "2" and "0" you don't ```string(20)``` you ```strconv.Itoa(20)```. 
I totally agree with you about the vulnerability but my application escapes these parameters before it reaches the datastore layer. 
That is awesome, but isn't that sort of unnecessary? It's like, I'm giving my enemy a gun to shoot me with, BUT I'm wearing a high-tech bulletproof kevlar. 
Hex output of the two strings (pre and post string concatenation): 3866393434383433636639313230353539366138323330343437396134396462 386639343438343363663931323035353936613832333034343739613439646214 20 != "20" if you were expecting "20" to simply be appended to the original hash.
So cool. fogleman is my programming hero/role model.
The point of putting REST in front of SQL is to abstract away implementation details. If you want query items forwarded to your data store then you should just use something like CouchDB.
aha...love the metaphor 
Wow, I must have missed the news that delve supports Windows now. Neat
Thanks! I decided wrap my API around PostgREST since this is for my own in house use data project. https://github.com/begriffs/postgrest
Nice! I didn't know that existed. A while back I was looking at CouchDB because I wanted REST straight to the database, but PostgREST looks way better.
When run with a number that maps to a printable ascii/unicode-rune character what happens is what you'd expect. https://play.golang.org/p/xJ__WzE8AW
I guess the surprising thing for me is that ints can be cast to strings (I would think rune(20) would be okay, but not string(20)). I would have expected a compiler error.
Nice. Looking forward to adapt it for my Graphtec plotter.
I made package that will handle updated lets encrypt cents go get -u github.com/CossackPyra/pyrahttp pyrahttp.ListenAndServeLetsEncrypt(":7544", "/home/user/cert/game01.example.com/fullchain.pem", "/home/user/cert/game01.example.com/privkey.pem, nil) Post in Russian language https://habrahabr.ru/post/274749/ I will try to make English post tomorrow. I plan to release more code we use to handle lets encrypt in production with our game servers 
https://golang.org/doc/effective_go.html#package-names says: &gt; By convention, packages are given lower case, single-word names; there should be no need for underscores or mixedCaps. Err on the side of brevity, since everyone using your package will be typing that name. In project.go, I see a call to json.Unmarshal that ignores errors. You probably ought to deal with that error.
Go does not have immutable strings ala Java. Everything (except for consts) is a regular var.
If there is ever a "Go 2", they would like to remove this: https://github.com/golang/go/issues/3939
That's not true. Go's strings are immutable. But he doesn't have a string in `MyStruct`, he has a **pointer** to a string. (Java doesn't have pointers, so there's no analog to a string pointer in Java.) In any event, use of string pointers is almost always a mistaken design. The only time they are acceptable is when you're Marshalling/Unmarshalling and you need to be able to represent `nil`/`null` as distinct from `""`. Even there, `NullString` is probably a better choice.
Possibly your templates are failing to parse: t, _ := template.ParseFiles(tmpl + ".html") t.Execute(w, p) If `ParseFiles()` encounters an error, `t` will be `nil`. Don't ignore errors.
I fixed it just after I posted it. Thanks for the help though; I fixed the error handling as well.
never. NEVER would I expect that. I'd be surprised to get that. yes, PHP and JS are both surprising with their craziness like this.
I was surprised that appending to a slice changed an element in the underlying array. I would have expected that to have caused the slice to reallocate a new block of memory and move. Good to know!
I'd argue that setting up a real timeseries-database (e.g. Prometheus) with a tiny program exporting bytes throughput would get you better results simpler, but good on you :)
Nothing curious, read the docs: https://golang.org/pkg/builtin/#append I really like this "feature"!
The article is aimed at Golang beginners, I'm sure they'll find it useful.
I suggest tweeting @francesc, he reacted really quick to my questions and corrections and will be thankful for the hint.
What's a stable sort vs a (presumably?) unstable sort? 
[Unlikely](https://github.com/golang/go/issues/11726).
IIRC, there are no plans for it because the format for the manifest file is not yet agreed upon. [godep](https://github.com/tools/godep) supports the vendor experiment. I've tried it in my toy projects and it seems to work nice.
Just to be sure, concurrent **read** access to a write-once map is still valid? Also, in [this](https://talks.golang.org/2016/state-of-go.slide#30) example, the output has two lines: fatal error: concurrent map read and map write fatal error: concurrent map writes `m[i]++` triggers the first line (since it's both a read *and* a write), but where does the second one come from?
Ahh, I see. Thanks!
It's not clear whether that's called for every request (which would be horrible in terms of performance), or only once when first calling ListenAndServe(). The latter case is not useful because you still have to restart the server when the certificate changes.
http://www.hydrogen18.com/blog/stop-listening-http-server-go.html That is a great blog post. Exactly what I was looking for when trying to figure out how to change certificates dynamically without restarting the application.
hello! yeah, I'm releasing a podcast now but I'll fix it right after :-) In case you're curious: https://gcppodcast.appspot.com/post/episode-11-internet-of-things-with-jen-tong/
Author of MitM-VM and Trudy here. MitM-VM is a Vagrant VM (so it is a bit unrelated to Go) but Trudy was has been my first large-ish Golang project. I would love any feedback on my code! I can also answer questions if people have them.
If you're not writing at all, it's fine to read from multiple goroutines.
I read the early release on SafariTB, it's great starter material for someone who has a programming background but not experienced Go yet.
You're right. I should have written "could be horrible if you aren't careful". 
Nice solution. There once have been posted here a "similar" solution: https://play.golang.org/p/gf7TZmX6AV This uses json.RawMessage
&gt; SafariTB ?
I actually listened to that on my way home from work :)
I understand the concept of capacity; I'm surprised that the capacity is automatically set to the size of the backing array as opposed to the size of the slice. In other words, I previously thought of slices as a sort of copy-on-write window into a segment of an array.
Can you quickly try out the example? The two dot zip files are all empty after download. 
Thanks for the cross check. I had to use 7Zip to unpack the two zip files, after the download. The default win7 right click extract all action failed. I can compile now. &gt;[rapi@x200lf01 add]$ ls -lrt &gt;-rw-rw-r--. 1 rapi rapi 106 Feb 3 17:15 add.go &gt;-rw-rw-r--. 1 rapi rapi 103 Feb 3 17:16 add_amd64.s &gt;-rw-rw-r--. 1 rapi rapi 6258 Feb 3 17:23 add.o &gt;[rapi@x200lf01 add]$ go tool compile -S add.go 
Woo! I'm honestly more excited for this release than I was for 1.5.
 type WeightedWord struct { Text string `json:"text"` Weight int `json:"weight"` } This will get you what you were looking for originally.
Brilliant Reddit... It changed an `&amp;` to `&amp;amp;` in the URL, resulting in a search results page instead of the article...
I'm having a hard time imagining a scenario where I would need to do something like this. Does the API *randomly* return an integer or an object? If there was an endpoint that returned "expanded" user data I would have a struct for that data, and another for the endpoint that returned an integer user ID. 
Why?
Guys so i rewrote the code and im having issues. It compiles initially asking you the name but panics with the following message: Hello. Welcome to blackjack. What is your name? j panic: assignment to entry in nil map goroutine 1 [running]: main.main() /home/nicholas/go/blackjack2.go:38 +0xa4 exit status 2 Error: process exited with code 1. ------------- Actual code: // blackjack2 package main import ( "fmt" ) type Player struct{ name string overallScore int turnScore int } type Cards struct{ deck map[string]int } func setDeck () map[string]int{ var c Cards c.deck["Eight Spade"] = 8 return c.deck } func nameSetup () string{ var myname string fmt.Println("Hello. Welcome to blackjack. What is your name?") fmt.Scanf("%s", &amp;myname) return myname } func main() { //myname := nameSetup() var p1 Player // fmt.Println("Hello. Welcome to blackjack. What is your name?") // fmt.Scanf("%s", &amp;myname) p1.name = nameSetup() var newdeck Cards newdeck.deck=setDeck() fmt.Println(newdeck) } Also, im now realizing instead of a setdeck method i might as well create my deck in the struct. Thoughts?
Nice solution but it requires the type field.
You could use text/template - probably overkill for the example you have here, but if you're formatting some longer multi-line document and just want to put in a few variables here and there, that's the way to do it.
If you *just* want to put things on multiple lines, you can use `strings.Join([]string{x,y,z}, "\n")` - note that this only puts newlines in between the strings, and not one at the end.
yeah I think that's probably overkill. I will keep that in mind in future though it may come in handy. Thanks!
Nice and simple, I'll definitely use this for *something* but for my current purpose being able to represent the separate lines by literally writing the code on separate lines will really help me with formatting and readability. Thanks for your help :)
Of the things listed at http://tip.golang.org/doc/go1.6 in no particular order: - Native android/386 builds. Expands Go's reach to millions of low-medium-end phones. - Vendor support - Big wins on crypto performance, less significant but still notable wins on compression and sorting - HTTP/2!! It's still a young implementation (they all are) but Brad and the team have done a great job making it pretty solid. And it's on by default for HTTPS connections. Which is now free thanks to Let's Encrypt. No excuse for slow speed and no privacy anymore! - Cleaner panic output (although the more I write Go code the less I see these, which is a good sign I guess) - Template whitespace trimming and blocks - More cipher suite support in crypto/tls, and I've seen better error messages filtering in too. Also improvements to the use of GetCertificate which is suddenly very relevant with free, automated certificate possibilities. - net/http gets "StatusPreconditionRequired (428), StatusTooManyRequests (429), StatusRequestHeaderFieldsTooLarge (431), and StatusNetworkAuthenticationRequired (511) from RFC 6585, as well as the recently-approved StatusUnavailableForLegalReasons (451)" - AFAIK they're just constants, but still, nice to have them added to the package. - Really efficient GC on the order of hundreds of GB - time.Parse got a little smarter I've also seen some benchmarks that look more promising than anticipated, although I'm not holding my breath that it holds true for the general case. Also it's nice to know that the runtime has been worked on internally for improvements to readability and performance. Go 1.6 shows the Go team's commitment to building a solid foundation before running forward with new features and functionality. The reassurance of stability in Go 1.6 is rather calming.
RTFM, there are few more useful options like `omitempty`
This is pretty frigging cool.
I have a use case for this as well, but planned to look into Caddy because I thought that can solve the same situation ? 
[Image](http://imgs.xkcd.com/comics/ten_thousand.png) [Mobile](http://m.xkcd.com/1053/) **Title:** Ten Thousand **Title-text:** Saying 'what kind of an idiot doesn't know about the Yellowstone supervolcano' is so much more boring than telling someone about the Yellowstone supervolcano for the first time. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1053#Explanation) **Stats:** This comic has been referenced 6140 times, representing 6.2372% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cznisgk)
Thanks, this is also quite similar to what I'm looking for; I'll have to see which runs faster in my use-case. Thanks!
Let's Encrypt isn't built into Go, but there are Go client libs that make it [pretty easy to use](https://blog.gopheracademy.com/advent-2015/generate-free-tls-certs-with-lego/).
That's right. You can also have a look at nginx. Both are good options.
my company will surely get it ! \0/
sweet how is the precomputation even calculated since the input could be any 2 chars?
*"[The following keywords are reserved and may not be used as identifiers.](https://golang.org/ref/spec#Keywords)"*
Is this book released already in ebook format? I see that it says it's an early release ebook, but it doesn't say exactly when it's releasing in ebook format. Also, that price is a little steep, but that buy 2, get the 3rd free offer looks a little tempting.
OH NO MORE THINGS TO LEARN ®
Sure, I'm almost done implementing it into Caddy, so when that is done I can get around to it.
Latest thing with Caddy is auto updated https certificates.. pretty damn cool!
A lot of mholt's work is very impressive
It never ends
&gt; that price is a little steep, but that buy 2, get the 3rd free offer looks a little tempting O'Reilly almost always have ongoing 50% off coupons that are easy to find.
Have a look at https://github.com/unprofession-al/yumr... Hacked together in a hurry, quite ugly. But runs fine and does its job. It provides some HTTP endpoints where you can POST packages (via Jenkins for example) and get them in your repo.
I...think....I.... want...my...money...back
http://tip.golang.org/doc/go1.6#minor_library_changes and here it is
Ah yes indeed. It doesn't inline the function that's right. It had a case where function overhead was the biggest impact and you can't improve that with ASM. I would suppose that many ASM functions are small functions, so function overhead becomes a big factor. I'm not sure what the rationale is for not inlining ASM functions. Besides, it's quite a hurdle to implement the function for all architectures, so while it has it's advantages I can see the trade-offs too.
Wouldn't say it's ugly at all - simple and easy to read. Cool stuff. I'd like to add REST endpoints eventually to this for full CRUD access to repos + RPMs.
How to keep wall street chatting using Go - GopherConIndia 2015 https://www.youtube.com/watch?v=mDTg1dLUqBE
Could Algernon be what you are looking for? It can render JSX to JS and is easy to get started with. https://github.com/xyproto/algernon
Totally. Writing in assembly is mostly a bad idea from a practical perspective in Go. If you really need an inner loop to be the fastest it can be though, and you've already tried everything else, coding the entire loop in ASM (not just the inner function call) may be worth it. The example I give is that sort of thing. You have a large array of vectors you need to transform, so you code the whole loop inside the function and you can use SIMD instructions to make it faster than it would be even with an inlined Go implementation.
I believe that almost everything related to Go is open source. So, a quick scan to their github repo, [I found this](https://github.com/golang/talks), which refers to [this tool](https://godoc.org/golang.org/x/tools/cmd/present).
[YouCompleteMe](https://github.com/valloric/YouCompleteMe) is an autocompletion engine that works for a host of languages and editors. By default it works for vim, but [ycmd](https://github.com/Valloric/ycmd) (its core) can be set up with a bunch of other editors including Atom and Sublime. I've been using it for a while in Rust (ever since it got Rust support), and I found it very awesome and smooth. More recently I've had to spend time with Go and I realized that whilst YCM had autocompletion support for Go, it didn't support jump-to-definition. So I added support for that using godef, and it's been working pretty smoothly for me for the past week (I use a mix of Sublime and Vim, works great in both -- feels like an IDE). Quite fun to use; and speeds things up considerably. Note that if you want to set it up for vim, the regular vim plugin will need a submodule update in `YouCompleteMe/third_party/ycmd`. Other editors can work with an independent clone of ycmd so that's fine. There's extensive documentation for installing, be sure to check it out. You will need to pass the `--gocode-completer` flag to `build.py` to get it to work for Go. Let me know if you have any issues!
'type' always gets me. Always am trying to do things like Member.Type, Session.Type. But nope, have to settle with 'Typ' or Member.MemberType. 
&gt; net/http gets "StatusPreconditionRequired (428), StatusTooManyRequests (429), StatusRequestHeaderFieldsTooLarge (431), and StatusNetworkAuthenticationRequired (511) They were there before, not exported tho.
It should be relatively easy to set something up using the utility inotifywait. It's a command line tool which can monitor your file system and react to changes. My team (which writes 100% for server side) uses a (very short) Bash script that recursively monitors our Go source directory for changes, runs our unit tests upon a change, and shows a warning message if tests are broken.
Im not sure about the Hostsplitter-Secret idea, in my world one should not be able to reach the backend directly. But if you insist make it X-Hostspllitter-Secret. Also what happens if the original request is proxied too? 
For whatever reason url didn't work from my phone. Here it is until I can get to a pc and edit. https://github.com/kris-runzer/synapse
I actually dabbled with this on an old pet project of mine. Works great!
Realistically, no, not as part of the Golang environment. An attacker could do "kill -9" or the equivalent, circumventing any program termination actions. What threat model are you considering? I.e. who do you want to defend against - local unprivileged user, local root, someone who has physical access but no login, or something else?
AIUI that's handling the original gocode integration, not jump to definition (which uses godef, and can't conflict with anything since nothing is registered by default for GoToDefinition)
Thanks, you're absolutely correct about the header name, I've made the change [here](https://github.com/ammario/hostsplitter/commit/e2bc287a0f3a255c309a7f6a58259e83f7488d36). &gt; in my world one should not be able to reach the backend directly. I made the feature addressing weird edge cases/those who might have their software bounce on and off the proxy and do not want to make changes to their code when they get off. I figured the performance affect and time it takes to write is negligible. &gt; Also what happens if the original request is proxied too? The `X-Forwarded-For` header will comma separate each value in order of first IP to last. 
Huh, thanks. Hey, as soon as I find some time I'll have a look at your project. If it turns out we're after the same goals it might make sense if we merge the two repos... How about that? 
protip: for simple things use gist. gist works as a pastebin, supports several files and can be checked out with git.
and this is the 'real life repo' https://github.com/etozzato/word-parser-go
Sounds like something cool to look into. Put an issue on GH on my repo when you get around to it. Thanks.
In the past I've used a modification of https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm to create evenly split subslices. A Go implementation is in https://github.com/dgryski/go-ddmin/blob/master/ddmin.go#L86
maybe an expert can answer you i would suggest trying `"foo" + C.GoString(bar) + "baz"` from: https://utcc.utoronto.ca/~cks/space/blog/programming/GoCGoStringFunctions 
This is what I could come up off the top of my head :) http://play.golang.org/p/Hk33xxaFLP [edit] or, if you want it *really* concise: http://play.golang.org/p/MjAFRBH-Jj [edit2] As /u/RalphCorderoy pointed out, the concise version takes a hit on readability and speed. I spent a couple of minutes making it better and I think this is as good as it gets for this algorithm: http://play.golang.org/p/JbiJLB4_YH. In particular, preallocating the ret slice gives a very significant speedup. 
Nicer than my solution! I might have to my ddmin implementation..
extend Go language to accept macros. Call barStuff() macro inside handler1 and handler2
I also wrote about when you might want to use this: https://cugablog.wordpress.com/2016/02/05/lets-talk-about-longpolling/ 
Yeah, I looked at this and apparently duktape is a bit behind in terms of performance. While I don't need a 1:1, it's apparently a 1:5 on a good day :&lt;
I actually fan across this as well; I'll definitely look into it. Thanks for the validation!
probably by writing your own Cookies() method or by looking at the header resp.Header, replacing the invalid char by something like "DUMMY" and replacing it back in your cookie array after you called Cookies(). 
Thank you my friend. That was the problem.
Github or equivalent? 
You are using `Run`, don't. Don't use `Run` - you have to read from the pipe as you're running the command. Use `Start()` then read instead, and maybe `defer cmd.Wait()`? [Here's the example](https://golang.org/pkg/os/exec/#Cmd.StdoutPipe). Basically, if you call `Run` or `Wait` on `exec.Command`, execution of that thread will pause until the `io.ReadCloser` closes. You have to set up the command, and the pipes, then call Start, then read your output, *then* call `Wait` when you're done reading. For anything more complex than a simple example, tbh, it might be better to just wrap the stuff and have a function that you call to use it, and return a `[]byte` of the `stdout` and `[]byte` of `stderr`. At least, that's what all of this reads like to me when reading the package.
https://play.golang.org/p/qoGePCv9xm
Thanks! Unfortunately that only works if both arrays are the same size, which won't always be the case. I updated your example to better describe my needs. https://play.golang.org/p/GNJ2tIRgnL
Can you take the length of the longest one and iterate over both of them that way?
Actually, I just figured it out! https://play.golang.org/p/1Arw3M_KIn
You just need to use two normal loops, one inside the other. https://play.golang.org/p/HY4aHJbjWl
Agreed. An OData implementation would also be useful. There is this guy: https://github.com/amsokol/go-odata. Still very young. A good SOAP and OData package will help me write a cross platform NuGet package server in Go (https://github.com/cavaliercoder/nugo) which, despite the apparent decline of SOAP, will have a prospective future given the uptake of Chocolatey and OneGet.
This looks incredible! Way to go!
go for jupyter? nice!! https://github.com/gophergala2016/gophernotes
&gt; Two Compilers: gc &amp; gccgo two main compilers? there is at least llgo (one based on LLVM) (which also provides an interpreter: llgoi) https://github.com/llvm-mirror/llgo
oh well. Interestingly pulling that out *does* actually make the code noticably faster (With the range of values I tested I got values between 5% up to an astonishingly 20% of speedup). It's still a micro-optimization, though. In practice it probably won't matter. But yeah, if you want to optimize readability you definitely want to make that function a bit more verbose and add some comments to explain how it works. Though I believe spotting the `len(s)/n` part is negligible compared to understanding how that code actually works and why (I mean… I don't even *really* know why it works. It's mainly based on intuition that just happened to create a correct solution \^\^ ).
Shirley there must be eighty to ninety frameworks and libraries out there by now to do this for him.
Damn, you're right. I was used only to conditions as comment.
Thank you for your response! I assume if I have an AJAX call to delete a task then I'd have to delete that particular task form the timeline as well? Which brings me to the question &gt;$("button").click(function(){ &gt; $.get("/delete/12", function(data, status){ &gt; alert("Data: " + data + "\nStatus: " + status); &gt; }); &gt;}); i presume data is an object returned by the ajax call and status is the status returned?
thank you!
I'm sorry who's shirley?
That is pretty awesome, I didn't think of "return ftm" :) if you look at the 'real life example' I got pretty close to the C.CString/C.GoString handling! https://github.com/etozzato/word-parser-go Thanks!
Yes, i drew it by hand using GIMP (http://www.gimp.org). You need to figure out how to draw NOT-, NOR- &amp; NAND-Gates first. The simplest thing is the clock generator (a chain of NOT-Gates). For the 7-segment driver I used Logic Friday (http://www.sontrak.com) to generate the gate diagram.
I'm not 100% sure of what you are asking...but here goes: If you are trying to get the 'Most Band for Your Buck' I'd suggest going CoreOS and using Docker to get greater density on a single server with multiple processes running. 
I wonder if restructuring the code so that it doesn't need to re-run the regexp.MustCompile() statement each time in the matchSentences() function has any effect on performance, which is called in a loop from what I can see. It could also be that Go maintains a compiled regex cache in which case it might be an unnecessary optimisation, I don't know really.
Yes, learn to write 40 lines of cover you don't understand instead of 4 you do. Listen to this guy.
This is so cool!
I usually start out with something like this: if got, want := somefunc(), "expected value"; !reflect.DeepEqual(got, want) { t.Errorf("got %q; want %q", got, want) } // ... mutate state if got, want := anotherfunc(), "another value"; !reflect.DeepEqual(got, want) { t.Errorf("got %q; want %q", got, want) } Then sometimes it expands into more complicated assignments and checks, so I pull them out into separate assignments and maybe reuse the got/want variables. got = ... expect = ... if !reflect.DeepEqual(got, want) { t.Errorf("got %q; want %q", got, want) } Then if I'm doing exceptionally weird checking, maybe it requires reading in from a channel and sync'ing outputs, _then_ I'll make a separate specialized assert helper.
Just a word of caution reflect.DeepEqual will work in the majority of cases, but has a little more difficulty when you start getting into some more complex scenarios such as passing an interface of a pointer, into the assert function, I wish I could dig up a good example but on my cell right now. I use reflect.DeepEqual as well in a very small assertion library and had to do it like this to handle all the strange scenarios https://github.com/go-playground/assert/blob/v1/assert.go#L13 It's not pretty but gets the job done.
You'll also lose out on line numbers. Every failure will point to the `t.Fatalf()` line in your `assert()` function. I do something like this: func assertEq(exp, got interface{}) error { if reflect.DeepEqual(exp, got) { return fmt.Errorf("Wanted %v; Got %v", exp, got) } } And then in tests... if err := assertEq(exp, got); err != nil { t.Fatal(err) } It's a little more boilerplate, but it preserves line numbers. There may be a better way as well.
A single golang process behind a proxy like caddy (for transparent tls) and a db will easily run on a 512 instance and serve at least 100 concurrent connections without problems. Several instances should be fine behind a proxy too on a 512 if your sites are not high traffic ones. Which flavour of Linux doesn't matter so much, coreos looks nice but requires docker which you probably don't need. Try it and you will be pleasantly surprised.
I second this, you can run a lot on one of these little servers--I have 5 websites on one plus a largeish go app on an Ubuntu image. If you use MySQL make sure to tune it though, it likes to hog memory even when it doesn't need it.
That's really cool! Technically, you could put lines [181-188](https://gist.github.com/FZambia/ca83c61beac90a15b4d6#file-himawari-go-L181-L188) in a goroutine (like [I did for the grid images](https://gist.github.com/FZambia/ca83c61beac90a15b4d6#file-himawari-go-L126-L129)) to really speed up the downloads, but that volume of requests in that short time might be a bit suspicious :P
sqlite is also a good choice for small sites, and it has a good go driver. Unfortunately not every off the shelf software supports it.
A couple of problems using sqlite with go: * It requires cgo, which makes cross-compilation difficult, I prefer to deploy binaries. * It requires a global lock on the db for writes, fine for small sites with very low usage I guess, but it wasn't really designed with concurrency in mind. 
I like the way the [testify/assert](https://github.com/stretchr/testify/blob/master/assert/assertions.go) package does it. `assert.Equal(..)` and `assert.NotEqual(...)` are much more clear than having a single function with a boolean. So if I really had to avoid the external library, I'd probably just re-implement at least those 2 functions for clarity.
what you *can* do is make sure process memory is not swapped out or virtualized to persistent storage. `vault` does this. 
ok so found a few simple examples that IMHO reflect.DeepEqual does not report properly regarding pointers passed as interface (or however you want to describe it) https://play.golang.org/p/jhKDWbYTVs myMap, i and s should report back as true, but don't and that's why I use my small assertion library https://github.com/go-playground/assert
These slices are read only. Just breaking up the slice so it can be processed in parallel.
speaking strictly about vendoring, IMHO I will be keeping my distance and using http://labix.org/gopkg.in like @robertmeta stated until an agreed upon/standardized vendoring file format is used by/agreed upon the mass majority of tools support it. Until that happens I think that vendoring may be a little bit of chaos, for example: Project A vendors Project B using tool X using format 1 Project B vendors project C using tool Y using format 2 Project C vendors project D using tool Z using format 3 so now I need tool X, Y and Z because of the different file formats supported, just to load all my projects dependencies? unless I'm missing some key concept of vendoring
I'm seeing the same behavior. Looking at [benchmark.go](https://golang.org/src/testing/benchmark.go?s=2163:2186#L61), I suspect that runtime.ReadMemStats() is the culprit (called from both {Stop,Start}Timer). FWIW removing the Perm call from the bench timing results in a larger N (5000000), but it takes the same # of iterations to get to that N (100, 10000, 1000000, 2/5000000). However, this obviously doesn't account for a 2s-&gt;200s change. Edit: Bumping the array size up from 10 to 100 or 1000 seems to help (likely from the smaller N).
I am not sure if this what you are looking for but there is [Cayley](https://github.com/google/cayley) *"an open-source graph inspired by the graph database behind Freebase and Google's Knowledge Graph"*.
Calling the runtime.Caller function and telling it to skip is a way to get around this with less boilerplate see here for a simple example https://github.com/go-playground/assert/blob/v1/assert.go#L147
Just use one GOPATH for everything, once it's set you don't have to worry about it. I added it to my .bashrc file. http://mwholt.blogspot.com/2014/02/why-i-use-just-one-gopath.html
Have you tried doing all the setup in a separate loop then resetting the timers? e.g. http://play.golang.org/p/4hhsXDBBHB With this approach the benchmark goes from: benchmarkInsertionSort 1000000 1198 ns/op to benchmarkInsertionSort 10000000 182 ns/op on my machine.
Ditto, but using gvt (https://github.com/FiloSottile/gvt) over gb. I really want to be able to provide different library versions outside of gopkg.in, but that's not an option sadly. 
Thank you. TIL about inotifywait, and I've been using Linux for quite a while. Seems like LiteIDE doesn't have a trigger mechanism. How about a customizable button to click on to run shell commands?
That would be great! Just wanted to point out I started doing a bit of refactoring to add dscovr support neatly. I started moving the `himawari` and `dscovr` packages to a single `download` package. The code is very much in flux, so it'd probably be better if you started working on it after a few hours :)
Seems like it'll be at least a week before I have time to work on it, so that won't be an issue. I figured it'd be best to extend and improve someone else's implementation rather than make my own.
Also thought about this, but it seems that entire world now downloads images from their servers to play with:)
+1 for gvt (which is gb + GO15VENDOREXPERIMENT)
&gt;Don't think of your endpoints (URLs) as method calls. This is epic, had never thought from this point of view. Also thank you for a detailed example!!
That seems to work. Even for larger slice sizes, as well. Thanks!
how is this related to go?
&gt; https://github.com/go-playground/assert/blob/v1/assert.go#L147 I've looked at things like this before, but it seems more "conventional" in some sense to make the caller handle an error instead of passing in a 'skip' value, even if the error handling is more keystrokes.
Depends -- if the vendored code is committed with the project you need nothing other that GO15VENDOREXPERIMENT set (assuming gb was not used), although there are hazards to including vendored code with a package.
Initialize first, then b.ResetTimer.
damn those dependencies
I suppose but a library handling the error greatly reduces repetitive code, besides all you really need in tests is simple assertion of line number and what went wrong, handling your own errors seems like allot of extra work. P.S. In my assertion library the Caller doesn't pass the skip value, the IsEqulSkip function my link referenced was just to show how getting the real line number can be accomplished, you can see in the README https://github.com/go-playground/assert/blob/v1/README.md all the user has to do is call Equal(t, val1,val2) IsEqualSkip is just exposed to allow your own assertion functions to use the back end of the assertion library like I do here https://github.com/go-playground/validator/blob/v8/validator_test.go#L116
what dependencies ?
I just use aliases, for example: alias d="docker" alias dm="docker-machine" alias lsa="ls -la" alias g="git" etc...
Seriously impressed with meshbird, will follow that project for sure 
try this one https://github.com/boltdb/bolt ? edit: also you could try sqlite as you already have experience with databases... 
Think about where you want to host the app and what data services the host offers. It's so much easier just using a database service than have to setup and manage a database instance yourself. If you host on Google AppEngine for instance you could use their cloud datastore or Cloud SQL. On Amazon they have DynamoDB and RDBMS services. A hosted Mongo instance is also an option.
Wow -- I had never even heard of gvt -- it is good stuff! Man, I might have to switch to it! NOOOOOOOOOOOOOO, I just made work for myself. 
Hey, thanks a lot, man! I have "forked" your highlight config to [dark theme (Obsidian)](https://git.io/vg4Zt).
That's just the comprehensive version of initialize first ;)
I guess I'll just provide binaries. Wanna be sure people will find it useful first.
Timely post. I've been flip-flopping, refactoring the same code for a few days now trying to decide if I should make a function to generalize a couple lines or just leave the function longer and more specific and verbose. I think I'm liking the latter better.
The solution to your problem should sit at kernel level.
[simpleredis](https://github.com/xyproto/simpleredis), [simplemaria](https://github.com/xyproto/simplemaria) and [simplebolt](https://github.com/xyproto/simplebolt) are three easy ways to store data. They all conform to one of the interfaces in the [pinterface](https://github.com/xyproto/pinterface) package, so that they can be used interchangeably.
Oh -- quick note -- this is **not** an ORM or ORM-like. This generates static code, and thus is similar in vein to ```stringer``` or other code generation tools.
We had written an internal tool about a year ago that did this. I spent the last couple days rewriting the tool and making it open source. It's available at [github.com/knq/xo](https://github.com/knq/xo). Please see the relevant post, here: https://www.reddit.com/r/golang/comments/44q2oi/generate_go_types_and_funcs_from_a_database_schema/
&gt; It requires cgo, which makes cross-compilation difficult, I prefer to deploy binaries. cgo still produces binaries. &gt; It requires a global lock on the db for writes, fine for small sites with very low usage I guess, but it wasn't really designed with concurrency in mind. This is not true since sqlite 3.0 anymore.
pure evil intention of the developers
Like that idea. We're using something similar at work (onewebsql.com it's is for Java). It's something between raw SQL call and fatty OR/M. This approach is not very popular. Not sure why. But is verrry pragmatic . Especially when you generate code from database designer (PowerDesigner, Erwin or Vertabelo). I work for Vertabelo and I'm a Go fan. 
How would this work? Here is some test code I have http://play.golang.org/p/jYXpgNwlXn
I'm not quite sure what you're trying to do, but you'd call it passing your walkfunc to `filepath.Walk` filepath.Walk("/", walkFnWithExtraParams("/", "extra"))
Closures are your friend here
I've updated the benchmarks to include some more complex examples with template inheritance. I've also created a "ego"-fork to generate zero allocs templates (depending on the data needed). Feedback welcome!
Check out 'go build' command, you'll like it.
Your solution eats over 2GBs of memory on my PC and will eat even more on faster machines
I do like it. I just figured the instructions would be a little simpler for folks coming from Python or other interpreted languages. The important thing is that the compile time isn't included in the benchmarks; however, I will update for clarity since you're the second person who's mentioned this to me. :)
Great suggestion. I'll update the post tonight.
&gt; But using go run adds overhead and makes it slower. What overhead is added? &gt; It would be more interesting to see the difference between Go and Pypy - which does JIT'ing. I agree that this would be interesting. Maybe I'll give it a try. Thanks for the suggestion!
&gt; What overhead is added? `go run` compiles all modules your application uses, your application itself, then links them together and and then executes the result, which are quite a few additional steps. It is possible and likely that it only compiles your application and it's used modules the first time and caches the results, and only checks if it has changed in consecutive runs - but the check is still there, and the linking + extra `exec` adds overhead too, since it only caches library objects, not fully linked applications afaik. Edit: quick test to demonstrate this: vagrant@vagrant-ubuntu-trusty-64:~/goproj/src/test$ cat test.go package main import "fmt" func main() { fmt.Printf("Hello %s\n", "world") } vagrant@vagrant-ubuntu-trusty-64:~/goproj/src/test$ time go run test.go Hello world real 0m0.459s user 0m0.384s sys 0m0.066s vagrant@vagrant-ubuntu-trusty-64:~/goproj/src/test$ go build test.go vagrant@vagrant-ubuntu-trusty-64:~/goproj/src/test$ ls test test.go vagrant@vagrant-ubuntu-trusty-64:~/goproj/src/test$ time ./test Hello world real 0m0.002s user 0m0.000s sys 0m0.001s vagrant@vagrant-ubuntu-trusty-64:~/goproj/src/test$ (this is with Go 1.5.1)
Like to give it a try. But head from master has some issues with the postgres templates. I'll have a look later from home and send a bug report or fix. 
I wrote this and used it in many places. However I always felt the implementation was overly complicated, so if someone knows a cleaner/simpler/better way, please tell me!
~~The need to call rand.Perm isn't necessarily about random data, but about the fact that the sorting algorithm is in-place. So I can't use the same slice more than once, or else I'd be sorting an already sorted slice. For example, after 10,000 iterations of your code, I'd be sorting already sorted slices, which would skew the benchmarks towards the lower bound run times of the algorithm.~~ Also, another problem with your code is now the copy function is being measured by the benchmark. I'm sure copy is faster than rand.Perm, but it's still undesirable. I agree though that the memory usage in these benchmarks kind of sucks. I think this whole situation could be fixed if I just didn't use an in-place sorting algorithm, because then I could just use a single slice over and over again, but I'm just following along with what the book I have, for now. Edit: Sorry, I just realized that first paragraph is completely wrong. I forgot about the copy.
&gt; extract it to a temp folder and search (using filepath.walk) its contents If you only need to report matching contents (e.g. `some/path/foo.zip` -&gt; `path/in/zip/bar.txt` matches) or something similar, then it would be **much** better to not muck with the file system and a temporary folder (with all the IO, time, and cleanup issues that would entail) but to use the [`archive/zip`](https://golang.org/pkg/archive/zip) package to [scan through the zip file's contents](https://golang.org/pkg/archive/zip/#example_Reader) in memory without using the file system.
Could you copy/paste the errors here? I have only tried compiling against go1.6rc2 and using PostgreSQL 9.5. 
http://pastebin.com/12UMaPv9 with go1.5.3
&gt;Go(lang) This might be even more annoying than 'golang'.
Particularly if someone puts a [zip bomb](https://en.wikipedia.org/wiki/Zip_bomb) on your hard drive.
&gt; Also, another problem with your code is now the copy function is being measured by the benchmark. I'm sure copy is faster than rand.Perm, but it's still undesirable. copy isnt so bad, it will be roughly same time no matter the algorithm you use (but ofc depending on data size) so for comparing between algorithms it is fine. Altho it might be sligthly faster (if you have cores to spare), especially for bigger datasets, to run few goroutines that just feed pointers to newly created data via channel. &gt; I think this whole situation could be fixed if I just didn't use an in-place sorting algorithm you would just move copy somewhere else. 
&gt; copy isn't so bad That's not really the point though. If I were settling with having initialization in my benchmarks, then I'd stick with what I wrote in my original post where I called rand.Perm on the fly, inside the call to insertionSort. Then I'd have about the same overhead as the copy, but with minimal memory usage.
Oh -- that's from the introduction of the hyphen syntax in templates for trimming whitespace. I would just suggest upgrading to 1.6. The code that gets generated should work with go 1.3+. So I would suggest building/installing with 1.6rc2 temporarily, and then you can use that binary to build the older code. I'll make a point to also release binaries for Windows/OSX/Linux, but just haven't had time yet to roll it up as a package.
"There are lies, dirty lies, and benchmarks"
in case of copy it is about 10% to 40% of benchmark time for such short in case of generating it each time it is 1000% overhead or more (try running it with 1000 elements instead of 10) So I'd say it's an improvement. But benchmarking short functions always will be tricky
This is my first project written in Go on which I work in my spare time to build some experience with the language. The current implementation of Gru's interfaces uses [etcd](https://github.com/coreos/etcd) for discovery and communication between the remote systems (called "minions") and the clients. Along the way I have also created [go-vcr](https://github.com/dnaeon/go-vcr) (another Go project), which is being used by Gru as part of the testing process. I'd love to get some feedback about what was done well and what not, so that I can improve further my skills and understanding of Go. 
What made an impression to me at the questions section was how many people from other languages were anxious about stuff like: Inheritance, design patterns, testing frameworks, RSpec clones etc. and how the speaker was unsure about specific answers because he obviously does not have to deal with those anymore. All the baggage you leave behind (and you do not have to think about) once you enter the Go world is fascinating.