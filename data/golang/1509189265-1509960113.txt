All good things must come to an end. And I am sure more good things are to come. Best of luck to Campoy in his new job! :)
But you can't define methods on pointer pointers. What a shame. ;)
Why not ? Really interested to hear the pros and cons of gob vs protobuf.
It’s just that gobs is already a part of the standard library and that you could reuse the existing struct instead of writing a new message descriptor. Protobufs are great for language interop, but I don’t see the need for that here.
Swift uses grapheme clusters which are the closest approximation to "characters" in Unicode 
&gt; Fact #27: go, in its infinite simplicity, kindly provides you with an isNaN() function, since ‘== NaN’ is too clear to be considered valid. Hope she's not actually using *== NaN* in her codes.
I’ve never heard of lock free arrays, but I read a book on concurrent algorithms a while back that creates log(n) locks to lock the array operations, but still free other parts of the array. I thought it was a cool trick. What are you trying to accomplish? Maybe there is a way of using atomic operations differently. 
Cool. Need this for VSCode...
[Prior post](https://www.reddit.com/r/golang/comments/780fcn/a_programming_rosetta_stone_basic_algos_in_go/?utm_term=aa907eed-abb3-4bdf-8e53-8e2e847574cd&amp;utm_medium=search&amp;utm_source=reddit&amp;utm_name=golang&amp;utm_content=2) 
Try setting `go.gopath` explicitly in user settings. It's nearly always a problem of VS Code not seeing the same environment you have at the command line. https://github.com/Microsoft/vscode-go/wiki/GOPATH-in-the-VS-Code-Go-extension
Have you tried Gogland? 
Thanks guys!!! Can’t wait. 🤗
I'm a bit out of date with windows, but I fixed this on mac by launching from the command line. It managed to get the gopaths properly then. I had issues with manually setting it (as lucky suggestioned) when I went into debug mode with delve.
[removed]
Good luck on your new journey Francesc. Will you also step down from the gcp podcast?
Constant self-promotion is against reddit's policies and will result in your reddit account being banned: https://www.reddit.com/wiki/selfpromotion
[removed]
That sounds interesting. What I'm currently doing is keeping an order book for a cryptotrading exchange in memory. This order book receives updates and also reads for the trading algorithms to run. It has up to 30 entries for both bid and ask. Which are 2 seperate arrays. Currently I'm copying the array and sending it through on every update with a call back function. The callback is implemented in the main function and will send the copy to other parts of the program. I was wondering if I could speed up this
&gt; Python's ... loose typing leads to runtime issues which you just don't have with statically/strongly typed languages Python is dynamically and strongly typed.
That didn't do the trick, have tried a couple of different iterations with the gopath variables in vscode and gotten nowhere
[removed]
seems reasonable...I have to assume being on the Go team is kinda boring at this point unless you are one of the inner circle...it's not like Go really needs much in the way of promotion or outreach at this point
You should have learned a lot more about SSL before you buy a certificate, but alas it's too late. Never mind. crt and pem files are the same thing really, so you can cat them together. Be sure to keep the original files though.
As per https://stackoverflow.com/questions/991758/how-to-get-pem-file-from-key-and-crt-files &gt;Your keys may already be in PEM format, but just named with .crt or .key. &gt;If they begin with -----BEGIN and you can read them in a text editor (they use base64, which is readable in ASCII, not binary format), they are in PEM format. There's a fair bit more information in that discussion, but you may need to use OpenSSL to transform the files into the format you need. (We have to do it every few years for our Windows servers. What a joy THAT is..)
Try asking in the gopher slack vscode channel.
I'm not 100% positive on this but when my team last made the comparison between the two we opted for protobuf as it handled adding fields to the struct without having to recompile and deploy both sides of the communication.
Maybe my lock-free hashmap has some inspiration for you: https://github.com/cornelk/hashmap
Just don't go to team Java now :P
your could try [`sync.Map`](https://golang.org/pkg/sync/#Map) which looks like it fits your use case (stable keys, updates limited to single goroutine)
Can you run the "go" command from the command line? (meaning your PATH envvar has been updated properly) Have you set GOROOT just in case (this shouldn't be needed anymore but who knows): https://golang.org/doc/install
Thanks for the advice. I've saved the error and stack trace I'm getting in Atom here: https://codepad.co/snippet/oRURSkhE
In this day and age, it's a surprise that anyone still believe that they have to pay for a SSL certificate, especially for non corporate users. https://letsencrypt.org/
Goland?
[removed]
Yes I can run go from command, have done some runs and builds already. Goroot is set.
Have not had the need to use slack yet, so I´m not familiar with it, guess this time is as good as any other to give it a try :D
[removed]
Similar problem. I was helping a student set up VS Code on windows. She can run Go programs from her command line, but VS Code will not see the GOPATH. Setting it explicitly with `go.gopath` does not work either. Launching VS Code from the command line does nothing. Sublime has trouble too. I'm not a Windows person so I don't know what else to do. I feel that we exhausted Google search. Her next bet is intellij or gogland or she can learn vim and try getting it set up that way. Kinda sucks. For the time being, I told her that she can run things like go fmt from the command line. She will be stuck without goimports, linting, autocompletion, and all the nice things. 
[removed]
Good suggestion I will take a look at that! 
Interesting project, some very cool code to play with thanks for sharing!
I did something vaguely in this direction using RCU (Read-Copy-Update). The short overview would be; you have a pointer to an array and whenever you write to the array, you copy it entirely, make the modification and update the pointer. You can guard the pointer in various ways but the main useful part is that you can have several readers on old versions of the array while a single writer can update and new readers see the fresh version. If you need full ACID semantics (which I guess you do judging from other comments), you'll have to use a RWLock and fully serialize access with a single-writer-many-reader approach. I would not recommend using sync/atomic as a lock is probably what you want.
Hey! Trying to use this in my personal go project. But I can't quite get it to work. I use Win 10, Gogland, and Go 1.9.1. I have installed gnuplot, and it works when opening the exe file stand-alone. I think I have set the necessary environment variables. Then I just copy/paste your example code, just to try it out. The code compiles without errors, and a png-file is created in the map of my project. But! The png-file is 0kb in size, and it can't be opened. Seems like it's just an empty file. It's been hard to find any clues to what might have gone wrong. Just this mention: https://stackoverflow.com/questions/24682238/gnuplot-showing-plot-but-the-file-is-always-0kb Any ideas?
good point
This is the response I get when I turn on debugging: cmd&gt; set title "Example Plot" res&gt; 26 cmd&gt; set xlabel 'X-Axis' res&gt; 20 cmd&gt; set ylabel 'Y-Axis' res&gt; 20 cmd&gt; set xrange [-2:18] res&gt; 19 cmd&gt; set yrange [-2:18] res&gt; 19 cmd&gt; set terminal png res&gt; 17 cmd&gt; set output'2.png' res&gt; 18 cmd&gt; replot res&gt; 9
A word of caution: Be sure to benchmark expected/realistic use cases of a RWLock to ensure that it's accounting mechanisms aren't slower than using a more simple Lock. https://youtu.be/KJS3ikoiLso
In that test you are bypassing the part of your main function where you initialize the db. So your global DB is a nil pointer. I didn't look at it too closely but the way you have it set up makes it difficult to test. You want a way to mock that DB connection so that you don't need a database to run your unit tests. 
Hi, I am really sorry for the issue. I literally just ran the the example again It worked perfectly fine and here is the debug response ``` cmd&gt; plot "/tmp/go-gnuplot-096465396" title "Simple Circles" with circle res&gt; 68 cmd&gt; replot "/tmp/go-gnuplot-724820163" title "Simple Lines" with lines res&gt; 67 cmd&gt; set title "Example Plot" res&gt; 26 cmd&gt; set xlabel 'X-Axis' res&gt; 20 cmd&gt; set ylabel 'Y-Axis' res&gt; 20 cmd&gt; set xrange [-2:18] res&gt; 19 cmd&gt; set yrange [-2:18] res&gt; 19 cmd&gt; set terminal png res&gt; 17 cmd&gt; set output'2.png' res&gt; 18 cmd&gt; replot res&gt; 9 ```
I am going through the code now to figure out the potential issue for you. 
If anyone still reads, I found this wiki link: https://github.com/golang/go/wiki/Learn
What do you mean by modularity?
Does Gopath or goroot include any nonascii or space characters?
Thanks! I've looked and looked, but I'm at a loss. One thought: when I enter commands into the command prompt for gnuplot I receive feedback on what I am doing. Like: gnuplot&gt; set terminal png Terminal are now in 'png'. Options are 'nocrop enhanced size 648,480 font 'arial,12.0' Is there any way to get these responses back into Go and print them during debug mode. I have looked at your code, but I have trouble identifying exactly where the commands are sent to gnuplot. (I'm new at Go)
Is the src directory where the files are, on the same drive as Go. That bugged me initially.
Good luck with the startup. You're a great source of knowledge and inspiration in the gopher community and deserve good things to come from the work you do.
There’s no reason to separate it into two services either but that doesn’t mean it’s not a useful demonstration. 
What's wrong with [httputil.ReverseProxy]? https://golang.org/pkg/net/http/httputil/#ReverseProxy
What are your thoughts on Crystal, Clojure, Cython and Grumpy for solving similar problems? And do you prefer Reason and Elixir over OCaml and Erlang?
cool i've been trying to write a test for our clients that use https proxy option. i can probably make a decent mock proxy with this even if its not prod ready :D
Nope, I always try to keep stuff like this nice and simple so as to not run into character coding snafus
If you're using the tarball under Linux, you need to make sure to use the code executable in the "bin" sub directory. The root one doesn't copy the environment properly. At least that was my experience.
[removed]
Go's async tends to make more sense because goroutines behave almost exactly like threads - at least, from the programmer's perspective they do. It's probably best to see Python's support for async as more of a performance optimization for people who need to use Python but also care about concurrency. (You could say the same about node.js). I think Go's way is strictly better, but that was not clear until very recently, which is why there were so many projects out there making different attempts to do the same thing. Fortunately, Go's way of doing things does not actually require the use of a specialized language. Python could add a layer implementing Goroutines (I guess they would call them Proutines or something) once they finally get rid of the GIL. It would definitely be a lot of work, but it is possible. You could also argue that the only reason Go's way makes any sense at all is due to some inherent limitations in the design of current operating systems, since it's basically just reimplementing things the OS does inefficiently in order to improve performance.
&gt;once they finally get rid of the GIL Are they actually going to do this?
No, the GIL handles far too many things, that would require a python 4.x release and we see how hard it has been moving to 3.x. There are plenty of great discussions around why they cant or why it's extremely difficult to get rid off it. I don't think they have to either, python is an excellent wrapper language, maybe the best. I think Go is better suited to do the things python is not great at and fill the C level language gaps easily.
Until their wildcard support is out sometime next year, we still use other cas for some things. We were also holding off because LE would have made public key pinning riskier, but luckily the internet has decided to shun that particular technology. 
Yeah... No dice, still won't work
Anywhere near the Denver, CO area by chance?
Any reason you didn't use the ready to use reverse proxy ? https://golang.org/pkg/net/http/httputil/#ReverseProxy
I've used Python Twisted and Go (usually stdlib). Twisted is aptly named. I'd never program the backend of an API in Twisted again. We have a couple of teams who maintain a system that are in Flask. I've put in a few PRs to it. I find it way harder to read and navigate Flask code than Go. Maybe a fancy IDE would help. /me shrugs. Go has first class concurrency and that is the major selling point for the services that we write. Go's static typing lets me skip a whole class of tests I would have to write in python. "This thing param should be a list; did we get a list or a string here?" Python is much better with things that deal with numbers. Math in Go can be a pain. Also, dealing with JSON is much more pleasant for a developer in Python, though it is good in Go as soon as you write all the "convert the payload to JSON code" because you then have static typing again. I found Go to be a pain with "incoming API request, fetch JSON data from multiple dependencies, merge it together with some formatting, and return JSON. Lots of intermediate structs. 
Here are some code comparisons that may be worth looking over: https://github.com/MagicStack/vmbench/tree/master/servers
We Love Go Lang: https://www.welovegolang.com/ Go Forum's Jobs section: https://forum.golangbridge.org/ Stack Overflow Jobs: https://stackoverflow.com/jobs and actually LinkedIn is not that bad.
PyPy is playing around with a GILless implementation, and that's probably the interpreter you should be using if you care about performance anyway.
Thanks for that. Working on the issue
Well, encryption is one side of the coin but isn't it all about establishing a chain of trust and to ensure that the data isn't manipulated by a malicious node in the network? Anyways, I don't quite see how this is related about thinking that you have to pay $70 for a single domain certificate [1]. [1]price from GoDaddy
Amen, that wildcard support next year will be of good help.
Thank you very much for your reply. This helped alot. I tend to use a lot of closures for flexibility but maybe this is something I need to change (either interface method or smntng). About the copying part it only sends a few items from the array as a copy the rest of the program not the whole array itself 
Splice (www.splice.com) uses Go - and our engineering team is largely distributed. I don’t think we have a backend role listed on the website right now but I’d say just apply anyway :D
A similar feature is available as a Caddy plugin, which has some more interesting properties: https://github.com/caddyserver/forwardproxy
True but that is handled by the CPU. Go could make a completely new architecture to fix this but... again simplicity.
Went through the tutorial today, coming in with only a basic understanding of kube. It is very easy to follow, and the code is well done. There are also plenty of explanations for why things are done that way, and plenty of links to other resources. A few questions though. * For the calling the RPC, why do you use the Gin context, instead of context.Background()? * Why do you not compile the application and copy it to the docker image, wouldn't that drastically reduce the container size? Also I had to modify the dockerfiles to use the GOROOT. * What is the benefit of splitting the service and deployment files?
Regarding math, there’s gonum project, which is already nice and getting better over time.
Hacker News: Who is hiring? (September) https://news.ycombinator.com/item?id=15148885 Hacker News: Who is hiring? as a map: https://whoishiring.io/ Especially for jobs in Germany: https://www.xing.com ... all not Go specific though
I've done a lot of stuff using Python asyncio in a professional setting, and only used Go on personal toy projects, so keep that in mind. I will ignore any differences in performance in my assessment. Concurrency in Go is native and pretty easy to get started, but you need to master using channels and waitgroups to get anything useful done, but that's about it complexity wise, really. Goroutines are natively multi-threaded so you may need to sprinkle locks all over your code if you use any shared state, or just communicate with channels. I like Go because of the low barrier to entry and the static typing. Python Asyncio is a mess of futures, tasks, event-loops and a lot of boiler plate before you even getting to the point of executing stuff. The asyncio documentation is absolutely horrendous, and you need a completely new vocabulary to reason about it. But once you get past this initial barrier, things become easier, especially reasoning about your program logic. Asyncio runs in one thread, so any shared state is natively immune to race conditions. A very important downside to asyncio is, that *any* library you use *must* have non-blocking IO (i.e. specifically written for asyncio), otherwise you don't gain anything other than added complexity. You can't just write your main programming logic in asyncio and then use the `requests` library to download things, as your program will then block on IO. Well, you can, but you shouldn't.
Here's an alternative in go, with automatic Let's Encrypt support https://github.com/chrisDeFouRire/tlsproxy
1) Generally, the same context should be used everywhere within the same request. In this case, the call to a REST endpoint. 2) Because that's just a development setup. I'm working on a guide for [multi-stage builds](https://docs.docker.com/engine/userguide/eng-image/multistage-build/) with k8s that does exactly that. Minikube's Docker daemon is too outdated though, so images have to be pushed to a registry. That's why is sort of only relevant for production builds. 3) k8s is very "configuration heavy" and those files can become very large, so they're split up for readability. If you combine them, you only have to perform one *kubectl* command.
&gt; Python Asyncio is a mess of futures, tasks, event-loops and a lot of boiler plate before even getting to the point of executing stuff. This is true for all language impls without M:N threads. I wonder how long it'll take for the majority of language implementors to realize that M:N is the way to go (heh). There was an announcement that Java is getting this feature in the future so there's some hope at least.
Cool. Keep in mind that HTTP client in Golang doesn't support HTTPS proxies yet - https://github.com/golang/go/issues/11332. It'll be there most likely in Go 1.10.
It doesn't allow to have secure connection between client and destination server. ReverseProxy as it's now takes response from the client, modifies it, sends it to the destination and passes response back to the client. In other words it doesn't support HTTP CONNECT tunneling.
I'm writing articles with visual and runnable code examples [here](https://blog.learngoprogramming.com), for now for beginners, with each upcoming post the level of the articles goes from beginner to advanced.
[Golang Projects](https://www.golangprojects.com/) has a lot of go jobs Golang News has lots in the [jobs section](https://golangnews.com/stories?q=Hiring:) [The Go Forum](https://forum.golangbridge.org/c/jobs) has new jobs posted regularly Also see [Stack Overflow Jobs](https://stackoverflow.com/jobs?sort=i&amp;q=%5Bgo%5D)
[Golang Projects](https://www.golangprojects.com/) has a lot of go jobs Golang News has lots in the [jobs section](https://golangnews.com/stories?q=Hiring:) [The Go Forum](https://forum.golangbridge.org/c/jobs) has new jobs posted regularly Also see [Stack Overflow Jobs](https://stackoverflow.com/jobs?sort=i&amp;q=%5Bgo%5D)
Should be fixed with latest [release](https://github.com/vedhavyas/cuckoo-filter/releases/tag/v1.2). The Expected lookup will be 1 because we assume failure if we reach max kicks[500] and once we reach, the current kicked out fingerprint will be discarded.
What? Again? And it still surprises me when people don't mention static typing as one of the benefits.
Python 3.6 has type hints which greatly reduce typing-related mistakes while simultaneously incurring zero runtime overhead and not restricting the advantages of duck typing. It certainly made my life much easier.
And inevitably cause circular dependency issues...
That's with imports, not type hints
Types need to be imported for type hints (except for the forward declaration notation, but that's the exception, not the rule), which means you tend to end up importing things you wouldn't otherwise import. This problem is a little worse than in Go because in Go, the unit of import is a package, while in Python, it's a module. Still, Python's typing story has much bigger problems than this, like lack of support for recursive types, general usability issues, and bugs. But it's coming along.
Show me or describe to me some example code importing typing modules from the standard library that will cause a circular dependency
Let me, as usually, recommend [this classic essay](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/) which deals micely with the distinction between any callback-based (Python + any async I/O library) vs provided-by-the-runtime solution to concurrency.
Training and using trained models are different tasks. As far as I know, it's easier to train models in Python than in other languages. But when it comes to serving them in production, any language will do. Models like decision trees or neural nets would be very easy to implement in Go. For example, TensorFlow has Go bindings which can load pre-trained models.
Came here to drop this link
I'm one state over.
The thing is: 1. Current time is easily guessable 2. md5 is fast. A common attack would be something like: 1. Click "forgot password" and enter your target's email address. 2. Try a bunch of hashed timestamps close to when I submitted the request. If I can narrow down the server's internal clock based on latency and so forth, I can get down to just a few thousand tries needed. You are essentially taking the full range of possible tokens and eliminating a whole lot of them from the search space. That is a huge advantage to the attacker that purely random tokens wouldn't have. Just read 16 bytes from crypt/rand, hex or base64 encode it, and be done. It is probably faster than the time+md5 solution and definitely harder to guess.
What exactly is *secret*? If you just generate an md5 from a timestamp, that's not random. I can compute like 1.000.000 md5 hashes in 3 minutes on my laptop. If someone knows the time, would it be possible for the attacker to try out thousands of codes? I.E. do you have rate limiting on your API?
If I'm not mistaken, it's possible to just set the `user_id` in the cookie. Please correct me if I'm wrong, but it doesn't seem like your server checks the validity of the `user_id` in the cookie. Do you sign the cookie by any means?
Thanks for the thorough explanation, is it possible to manually poke the scheduler from the runtime package? I think I will have to measure it first with a lock! Thanks 
I'm starting to see a trend.
Thanks for the answers!
Hashicorp has a number of open positions, and engineering is all remote: https://www.hashicorp.com/jobs
Infrastructure at Wish is looking. We have a growing number of Go projects under the ContextLogic namespace on github. Please send me (pm?) your info :)
The lack of indentation on those code snippets is really bugging me
Since non-one has mentioned this yet I will also include [angellist](https://angel.co/) to the list. It's a more startup focused website and for me finding it was a breath of fresh air. It's not ideal but it's much easier to find a job without having to ever interact with a recruiter and usually the people looking for employees there actually need something, their not just looking to meet a recruitment quota for the department. I stopped using linkedin, stack, indeed and other such in favor or it and I couldn't be happier, the amount of times I hear "fits our [corporate] culture", "can work in an agile team", "a team player", and other such phrases no human being should be forced to endure without being able to punch the interlocutor, has gone to 0 a month, which I find quite pleasing. Note, a lot of companies may be using other language stacks but the advantage of a startup environment is that you can use any language as long as it solves a problem and, in the case of having a large team, the rest of the teammates can get on board with it easily... which are both criteria go can easily fulfill in a vast amount of projects.
Especially after they mention gofmt at the end
Larry Hastings (and other core py devs) have been working on the “gilectomy” for 2+ years. It works and doesn’t break as much as one might think. But, as of his 2nd gilectomy talk at pycon (2017), it is still slower than the GIL in many cases. 
[removed]
[removed]
lol no generics 
It seems like Go would be faster at training models than Python. Is it just a lack of a quality ML training package for Go that people choose Python?
[removed]
Most of the heavy machine learning frameworks are written in C and have python bindings which are what we commonly use, so no, not much of a performance gain to be had
Python is the primary choice for data analysis/machine learning beside it is easy and it can be used in a scripting manner which works really well in an interactive session (think jupyter/ipython notebooks) for exploratory work
IMO, Python and Go complement each other well and fit well into a solid (and modern) backend stack. My comment to this effect from the other day: https://www.reddit.com/r/golang/comments/792xvf/golangnews_comparing_python_and_go/doyy2ev/
What does that have to do with the price of tea in China? We were talking about importing symbols and how that can cause circular dependencies; not "importing typing modules from the standard library". I can't help you with your imagined scenario, but *my claim* is easily demonstrated: a.py: from b import B # Needed for `takes_b()` class A: pass def takes_b(b: B) -&gt; None: pass b.py: from a import A # Needed for `takes_a()` class B: pass def takes_a(a: A) -&gt; None: pass main.py: from a import takes_b from b import B takes_b(B()) This code will fail with an import error b/c of the circular dependency; however, if you strip the type annotations, the imports in a.py and b.py become unnecessary, and the code will run. There are ways to mitigate this (notably better file organization), but nevertheless your claim that type hints don't create circular dependency issues is incorrect. Don't mistake my correction to mean "type hints are bad" or "static typing is bad" or "circular dependency issues are a valid reason not to use type hints".
3.4 (or earlier) introduced syntax support for type hints--3.6 just added typing modules to the standard libraries; however, there is a backport in pip (also called "typing") in case (like me) you're stuck on 3.4 or 3.5. And yes, type hints make typing in Python much easier.
You're right! Thank you for the correction.
That's not what I asked
I know. Your question is irrelevant; you're leading us into a non-sequitur. Whether or not a circular import error is possible by importing a std lib typing module has no bearing on the original question--whether or not using type annotations can cause us to deal with more circular import errors. The answer to your question is of course no, but the answer to the original question is yes, as I proved.
I work in a small town in North Carolina, we have some pretty cool projects in the government space if you would be willing to relo. Send me a private message and we can exchange emails.
&gt; But the fact that I need 4 imports just to read and write a string seems to be a huge overkill to me. 4 imports to do it the way you want to do it. Really, you just need `fmt`, and `strings` if you want to use `strings.TrimSpace`. ``` package main import ( "fmt" "strings" ) func main() { var name string fmt.Print(fmt.Sprintf("%s\n", "What is your name?")) fmt.Scanln(&amp;name) fmt.Printf("Hi, %s!\n", strings.TrimSpace(name)) } ```
Go isn't optimized for one-liners. Writing a single line of code doesn't amount to a single unit of work. Go has good readability. Let me read your program back you you: 1. Create a buffered reader from stdin. 2. Print to std out a question. 3. Read text from the buffer, stop reading at the newline (enter key). 4. Remove leading and trailing spaces from the answer. 5. Print the answer out to you. I'm not sure what you're expecting. If you'd like to use the fmt package, you could do the following: ``` package main import ( "fmt" "log" "strings" ) func main() { fmt.Println("my question?") var ans string _, err := fmt.Scanln(&amp;ans) if err != nil { log.Fatal("scan err", err) } fmt.Printf("my ans: %q\n", strings.TrimSpace(ans)) } ``` Make sure you read the docs; don't assume something is intended to work how you think it should work, verify your assumptions with the docs. 
Scanln stops scanning at the first space.
Whit this I get 2017/10/29 20:58:08 scan errexpected newline exit status 1 
Okay, that makes sense. Not sure about the logic of using pointers here, though. With your old scheme, after correction of one small mistake, you'd be using 8 bytes per bucket, regardless. With my suggestion, that becomes 9 bytes per bucket. Your new code, assuming a 64-bit system, uses 32 bytes per bucket if it's empty and 40 if it's full.
Nothing to it: `new(big.Int).SetBytes( net.ParseIP(...).To16() )`
Go is simple but repetitive. Go has taught me how the Single Responsability Principle &amp; dependency injection is used well. I was in the same boat and thought it's a very overkill but after some time you realize that the components are well split and make sense.
Thanks for offering. I'm in a small town in Kansas and my wife is active duty military, so I'm unable to move.
[removed]
&gt; you're leading a non-sequitur &gt; as I proved I don't have time for this kind of lazy pseudo-intellectualism. I'm concluding this discussion. Have a nice day.
This is what the [docs](https://golang.org/pkg/fmt/#Scan) say about `fmt.Scan` and `fmt.Scanln`: &gt;Scan scans text read from standard input, storing successive space-separated values into successive arguments. Newlines count as space. It returns the number of items successfully scanned. If that is less than the number of arguments, err will report why. --- &gt;Scanln is similar to Scan, but stops scanning at a newline and after the final item there must be a newline or EOF. --- So as documented, `fmt.Scanln` is reading from stdin, separating the input by spaces, and storing the results in the arguments provided. Since you only provided one argument, only the first word was returned. I think `fmt.Scanln` is not the most suitable for reading a single line from stdin, if you don't need it tokenized. You're looking for a single string of arbitrary length that ends with a newline, and you want to trim the spaces on the ends of that string. I'd say your original implementation is ideal. Yes, Go is a verbose language. I wouldn't say that makes it *difficult*; so your question "Does it get easier?" is, I don't know. I come from the Ruby world and find the explicitness of Go refreshing, but many don't, and Go has other similar shortcomings that will turn those developers away. Best of luck to you!
There's nothing "pseudo-intellectual" about it; you were wrong and got called out, and rather than admitting your error, you tried to cover it up with a non-sequitur and got called out again. If time is of the essence, you could have just admitted your mistake in the first place. You'll have to peddle your bullshit elsewhere; no one's buying it here.
Even though Go doesn't officialy support a REPL, there's the awesome Gore https://github.com/motemen/gore
shush, you can't be reasonable and use the right tool for the job... you have to take side and defend solution X or Y like it's a question of honor /s
You can access elements of a preallocated slice concurrently if you sync on the element. For example you can allocate a slice for the results, start as many goroutines as the length of the slice, having each goroutine write its result into the ith element of the slice. Later you can walk the slice and reduce on it. (This implicitly has two synchronization points: slice allocation, and signaling completion of the goroutines).
[The original post. ](https://getstream.io/blog/switched-python-go/) Does DZone copy all of their posts from other sites?
Oh, so it also creates multiple results. That wording was a bit confusing, I read the documentation again and again but kept assuming Scanln can read multiple lines like Scan reads multiple "words".
We do work on Fort Bragg, if you are ever PCSed here, or when your wife hits her ETS. nkennedy@novetta.com. If you can write go and be able to solve problems my guess would be north of $100k -- with a super low cost of living. I don't make salary decisions though...
If you want a language where you don't have to care much about implementation details then check out Ruby.
Agreed. I expected something along the lines of, "And there are tools to make your code clean and consistent". NOPE. Just a blog that never got checked by the author after being posted....
The type hints didn't make a circular dependency here - it already existed - at least if it were intended to be used as the added type hints indicated. Type hints just allowed it to be surfaced as an error. Further, type hints don't inherently cause circular imports. Writing code that utilizes circular imports does -- which is not an inevitability. As stated, better module organization resolves this issue. You get the same thing in Go, it's just always been a compiler error, so no valid go code exists with a circular import. Lacking type information, it's been allowed in python, so will likely take time to make codebases employing circular imports to sort themselves out, if they choose to adopt type hints. 
I'd recommend reading these articles at a minimum. - https://blog.cloudflare.com/exposing-go-on-the-internet/ - https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/
The original article, including part two can be found here: https://getstream.io/blog/switched-python-go/
Thanks for the heads-up. I am former Army and did my training at Bragg. If y'all will ever consider remote, I'm interested and still have a clearance.
You're absolutely right, I meant to use the term "circular import error"; not "circular dependency". &gt; You get the same thing in Go, it's just always been a compiler error, so no valid go code exists with a circular import. In Go it's only an error if a.go and b.go are in different packages, which makes this issue less obstructive. If Go's imports worked like Python's, most prominent Go packages including the std lib wouldn't pass muster--in my view, this is useless pedantry on the part of Python's module loader, which was never designed for this use case (in other words, while I think it's great that Python is adding optional typing, there were consequences to adding it post-facto).
&gt; Go is syntactically a big language. Neugram’s front end has to match it, and that’s a lot of work, much of which is still to do. I'm writing a functional language that compiles to Go. I was going to start by writing a parser that implements Go's syntax and then extend it, but I quickly realized that Go's syntax is actually quite large and nuanced and getting even the most frequently used 50% implemented would not be easy, so I just chose a functional syntax (which tends to be easier to build parsers for) and I'll build in familiarity later if necessary. Someone will invariably ask why I didn't just fork Go's parser, so I'll add that Go's parser and ast system are prohibitively complex for the sort of prototyping I wanted to do.
You really need to move to NodeJS. Put a few dozen plugin and code will write itself.
Generally, do companies hire entry level Go devs? My research have shown when a company chooses the Go route, they'd prefer to hire a Gopher who can come in and hit the ground sprinting. 
Gophercon is held on Denver and the impression i had when i was there was that is a go hotspot. 
Seems like silly reasons. Syntax? really? Community? Really? gRpc? Really? Ability to build a team? Really? Python is as good if not better on all of those things. Just say performance, that's the only valid reason on the list. 
So first off I am not a full stack web dev, I write a lot of servers and middle ware, and implement a lot of distributed algorithms, I also do some OS programming from time to time. I love Elixir as a language, but I despise it's community though it's getting better, like you see more people leaving their MVC framework bubble these days if you look at the packages on Hex, I don't really write my BEAM code in elixir much due to the fact that most of the projects I'm interested in contributing to, or the code I'm reading, or the community I will need advice from resides in Erlang land. I hope Reason does not turn out like Elixir, where the people using it engage in pseudo intellectual circle jerks because they know how to pattern match. But I mean as a language unlike Elixir v Erlang I find Ocaml syntacticly superior to Reason, functional programming was never really difficult for me to pick up because I learned it when I started programming. Ocaml is actually my favorite PL from a language design point of view. Clojure is great, it's concurrency primitives are excellent, you have access to the JVMs libs, and a lot of erlangs syntactic advantages for writing servers come from it's blend of Lisp and Prolog, but Lisps tend to become unwieldy in larger projects in my experience. Don't bother with Cython or Grumpy that's just a lazy quick fix mentality. 
So basically, Go is set up in a way where all you have to do is Go get shit, and you can create different subprojects in different dirs, and all that nice stuff, so you end up under the impression that oh my code is self contained and what not, the fact that the code you write can easily wind up coupled to the initial use case you developed it for, and how easily Go code can break proves to the contrary. 
Ah, unfortunately we're only considering on-site in Boulder. 
[removed]
You're starting 90,000 goroutines simultaneously. Does it really need further explanation?
The original article had nicely formatted code snippet: https://getstream.io/blog/switched-python-go/ apparently dzone.com did not copy that part correctly when they re-posted Disclaimer: I work for Stream
The quickest solution would be to set a maximum number of connections on dB. db.SetMaxOpenConns(10) would help. You would still be left with a ton of open go routines, but those are a lot cheaper than having an open database connection for each go routine. 
Its not about the majority vs minority, its about intelligent vs stupid. If you don't want generics, you are stupid, and therefore your opinion irrelevant.
Doesn't help.
I even tried to set `runtime.GOMAXPROCS(1)` and it still doesn't help. 
That doesn't change how much memory is allocated by spawning a goroutine, it just reduces how parallel those routines will run.
It doesn't matter, that only affects how goroutines are scheduled onto your CPUs. You need to create less goroutines. Check the goroutine examples on gobyexample or other docs.
That's the case in every language until you get some experience for how to use it. The model for how you "break things up" is different in Go than in many other languages, but you can do it just fine.
Did you try the same with Java or C? spawn 90,000 threads at the same time which each threat inserting a row in your DB? 
&gt; Does Go get any easier later or does everything need so much work? I don't think it gets "easier" in any sense except that you get used to it. Go is verbose. It's probably less verbose than C or Java, but it's still verbose if you're coming from a python background. Python is optimized for short scripts. Go is not optimized for that. Go discourages creating many layers of abstraction. 
You can only compare things that are different.
I can try that. Will post here after
I'm not entry-level so I can't answer that...
As others have pointed out you need to limit the number of goroutines you are creating. Checkout the blog post [Go Concurrency Patterns: Pipelines and cancellation](https://blog.golang.org/pipelines) Specifically the *Bounded parallelism* section.
This was posted a while ago under a different url. I find this segment rather amusing &gt; When I first started programming I always loved using Python's more advanced features. Python allows you to get pretty creative with the code you're writing. For instance, you can: &gt; &gt; &gt; &gt; Use MetaClasses to self-register classes upon code initialization. &gt; &gt; Swap out True and False. &gt; &gt; Add functions to the list of built-in functions. &gt; &gt; Overload operators via magic methods. &gt; &gt; Use functions as properties via the @property decorator. &gt; Really? Swapping True and False? When was the last time this was ever a serious issue?
http://blog.aurynn.com/contempt-culture-2 Highly relevant.
&gt; and whenever you ask why~~,~~ *your hot-path code is running slow as dirt,* you're always given a strange look FTFY. But seriously, some of those tight compact functions that look really cool sometimes end up having horrible time efficiency, space efficiency, or both. Here's a classic example, &gt; tasks = Task.find(:all, :include =&gt; :tags) This has horrible space efficiency, as it creates an object for each Tag In ruby, it is really easy for a bad programmer to write complicated code and hide many flaws or bugs. In Go, it is really easy for a bad programmer to write simple code and their errors will be glaringly obvious, which can be easily spotted and fixed. Anyways, still recovering from the horrors of my Rails days. Magic sucks. Screw magic. 
Would be better to create 9 go routines that insert 10000 rows each. Creating that amount of go routines (even though cheap compared with threads) is a huge overhead. 
I'm aware of that, but it's model is only modular at the package level, which isn't fine grained enough, if it's module system / way of breaking things up was sufficient, how come regardless of experience, go requires a lot of boiler plate (yes I'm aware for some cases having a good level of boiler plate is a good thing optimization wise), how come it would take forever just to separate a child package of say go ethereum (took me 12 hours), to work with since you don't need the rest. Go's model is bottom tier, but it gives you the illusion of it being good. I didn't say that Go made it impossible but it doesn't make it easy, and typically for it to work out 100% you need to set up a good architecture, in the early stages of your project. 
[removed]
It wouldn't, it would only make things worse.
In your loop comparison, do you mean to check for 1 &lt; 90000 (which is always true), or does was that an error in writing this post? Your 1 should likely be replaced with i - otherwise the loop never terminates. 
Oops. Just noticed that. Wasn't in the original code.
You're right. I was a fool.
Yay, who doesn't love more empty interface data structures. I'm so glad the go developers wise enough to ban generics. 
You should try to bundle all these statements into one (or few) transactions. Also, you should not have multiple go-routines (or threads, or whatever) write to the same connection. This can cause data corruption.
Send me your resume, github, etc to nkennedy@novetta.com. I might be able to hook you up with one of our subcontractors if we are not hiring remote devs right now.
Attention folks, it's geneTic not geneRic in the title! :) That being said, the article does have something to say about generics in Go: &gt; It’s the adoption and stance on composition as well as the resistance to generics in Go that has ignited online wars and has put the direction of the language into question. While the first part is certainly true, at least as far as /r/golang is concerned, I think the conclusion sounds more dramatic than reality is. Go's direction is not in question. I believe many of the Go community are aware that on the one hand, Go does very well in many areas without generics, and on the other hand there are areas that would greatly benefit from generics *or a concept suitable to solve the problems that appear to require generics in Go*. The part of the community who are actively interested in getting the generics challenge solved are already working on solutions, and the Go team [has established a process](https://blog.golang.org/toward-go2) to gradually evolve Go based on concrete use cases from the community that show where Go needs improvement. I thus don't see the direction of Go put into question. But that's just an aside. The article is really worth reading as it not only provides a look at genetic programming (a fascinating topic) but also describes the way that someone new to Go experiences the very Go-specific concept of interfaces - this really reminds me of the difficulties I had with grokking this concept when I was new to Go. 
warning: pickyness about words: This isn't about genetic programming (GP), it's about genetic algorithms (GAs). The two have explicit meanings, and GPs, while implemented with similar evolutionary techniques, are significantly more complex. 
Is that thing live on GH somewhere? Show and tell? :)
Don't try to be fancy. Readable code is usually better than elegant code. Your colleagues and your future self will thank you.
https://www.reddit.com/r/golang/comments/79f1xd/_/dp2erv4
nice. i will look into the above to see how it plays out. definitely going to keep an eye out for the final version in order to try it out. Thanks 
About error handling, I've been doing similar things in my job. Difference is that I created a group of declarative syntax, instead of using go's existing ones. The error handling is like bash, but enhanced with machanisms like python's decorations. So developers could just write correct logic using new syntax, and then complete go code is generated.
The point of the EAP program is so that everyone tries it and provides feedback so that it can be improved before it's released, not after. So if you want to try it, now it's the best time to do so as you can directly impact the 1.0 release. So please don't wait for the 1.0 release to try it, do it today and please report whenever this are slow for you (as you mentioned already a couple of times) or not working as expected. Otherwise, chances to fix those things are very small. Thank you.
it doesn't use an empty interface type Entry interface { Hash() uint32 Equal(Entry) bool }
you maybe mistaken thinking that Go is a scripting language similar to python or ruby. Go doesn't feature a REPL, although you might consider a third party REPL such as [Gore](https://github.com/motemen/gore). I would suggest you start at the [Official Golang Tour](https://tour.golang.org/welcome/1) It's a great way to be introduced to the language. Good luck.
Join Gophers Slack, https://invite.slack.golangbridge.org/ , and you will have a lot of material shared with you automatically, ranging from links to tutorials, blogs, videos, to books. That should help you get started with Go.
What operating system are you using?
Windows 10 64 bit
Thanks
You can check this out https://github.com/campoy/justforfunc/tree/master/22-perf. There has an example about creating 4 millions goroutines, and it does run very slow because the runtime must do a lot of work.
Why do you think that is in any way more useful? You still don't know anything about the types that are in the container, except that they implement those two methods. Also the values are still empty interfaces. 
Thank you! I'm looking into OCaml, but unsure if I should jump over to Reason or not. I already like Standard ML, but OCaml seems to be more used in the industry. Python covers a lot of ground, but I think it lacks a way to achieve the speed of C or safety of ML/Ada, without having to bridge between Python and "that other world".
It is structure, that shares some properties with HAMT, but it is not HAMT.
Take a look at the FAQ at https://golang.org/doc/faq, perhaps the information there will be helpful to you. There are additional places for seeking help listed at https://golang.org/help/. It would help if you described more about what you're trying to accomplish. Your question is fairly open ended, so it's hard to give more specific advice.
For the shebang (not a solution, but an interesting reading): https://gist.github.com/posener/73ffd326d88483df6b1cb66e8ed1e0bd
Go does have some ways to be used from Jupyter: https://github.com/gopherdata/gophernotes
You too have programming delusions ? &gt; I actually have no idea how to open a terminal or run a script. Stay cool, in 2 years you will be senior dev anyway.. just learn a bit of Javascript.. 
I would say that Python async is often performant enough to be a good choice depending on what you are trying to do. It is very easy to throw some task to be run in a thread or process and not block the response cycle. The async thinking takes a bit of getting used to, but I have really enjoyed working with asyncio and aiohttp. Though the service was in fact to performant for our core service to keep up with. 
Note that `gore` doesn't work very well in my experience. It works by writing a temporary file and executing that with `go run`, but it's quite easy to end up with an invalid Go file in my experience.
&gt; Please help. You're going to need to provide more information than that if you need help. What OS are you using? Were you hoping to use some IDE?
First you need to set two Environment variables. GOROOT and GOPATH. GOROOT is where your go installation is located, this is usually set automatically so don't worry about it. GOPATH is where your go source files are, all the libraries you install etc. will be searched first in GOPATH then in GOROOT. Next important step is to create a file called main.go and type some code in it: For example: package main import "fmt" func main(){ fmt.Println("Hello Fellow Gopher Candidate") } save it as hello.go. Open your terminal cd into the directory where hello.go is locates and run "go run hello.go" Congratulations!
In the case of Ocaml, for computationally intensive programs, you should use C, honestly it's not a problem Ocaml's ctypes lib is really nice, like it's FFI is the best I've used. StandardML / Ocaml are really similar syntactically, and I mean the main barrier is knowing the module system well, the only difference is Ocaml has classes and objects too, which aren't used often. Really for you it's just a matter of learning Lwt and a build tool (Oasis, Jbuilder, or just make files + ocamlbuild), and then the rest of the ecosystem becomes open to you with relative ease, like if you try writing one ml file a day, within 2 or 3 days tops you would be comfortable with it, it's simply a matter of forcing yourself to do it. I'm actually curious about using ATS, but I mean the ecosystem is non existent, but I mean I guess you can write a serious program using C libs. 
You should also look at https://mariadb.com/kb/en/library/how-to-quickly-insert-data-into-mariadb/ for speeding up multiple inserts.
&gt; GOROOT and GOPATH Neither are required nowadays for a standard install. 
That's true, but it doesn't hurt to know what they are :). The both environmental variables were frustrating to me on my first couple of attempts. On a side note, cluttering your GOROOT by using is as the default GOPATH is IMHO probably a bad idea. YMMV of course. 
It's ok, I've abandoned the idea of it anyway.
The author is pretty positive about Go and the writing of Genetic Algos in Go is very timely for me as I'm going to use it soon for stock market analysis. So thank you OP!
The goalpost has shifted. 
Better yet, stop writing the same article over and over again.
Also it would be interesting to write something similar/simpler than Go and run a converter every time I saved the file - like I do with Javascript and Pretty.
Make sure to check out [gago](https://github.com/MaxHalford/gago), a genetic algorithm library I wrote
もっとほめて!!! ٩(⁎❛ᴗ❛⁎)۶ English translation: I'm so glad as you. Go programming language lacks generics. That makes strict implementation of efficient algorithms impossible and forces us to use a kind of dynamic typing, interfaces. I want generic pointers in this case.
Could this be done with `go generate` to get rid of 
Did you find any wrong implementation? I will appreciate it if you could post them as issues. I'm aware that nodes lacks existence bitmaps of leaves and sub trees in my implementation. I decided not to use them because interfaces and type assertions can provide the same function on behalf of them while use of bitmaps may faster some operations.
Thank you so much for writing and documenting it. Looks amazing. I'll let you know when I start using it.
Good correction, though "or earlier" is right -- the annotation syntax was actually introduced in the very first Python 3.0: see [What's New in Python 3.0](https://docs.python.org/3.0/whatsnew/3.0.html#new-syntax) and [PEP 3107](https://www.python.org/dev/peps/pep-3107/). It wasn't until much later (3.5?) that it was decided these annotations should definitely represent types, and in Python 3.6 [variable annotations were added](https://docs.python.org/3/whatsnew/3.6.html#whatsnew36-pep526).
I develop Go on Windows, and honestly haven't had much of a need for bash (it was handy for doing some quick file system interaction checks). You can cross compile anyway, but I've found that using Docker for Windows has had very little pain involved.
To open the terminal on Windows OS, press the win key, then type `cmd` and press enter. You should then type `go` and press enter to confirm that Go is installed. After that you can download an easy to use editor like [Visual studio code](https://code.visualstudio.com/Download) which will install all the necessary tools if you try to use the Go extension. Feel free to ask for any other questions you might have.
This is the kind of thing I'd love to see submitted to /r/golang, rather than yet-another-why-we-picked-golang-over-X post.
I am developing in Go on Windows and using MSYS2 for `bash` et al. Works pretty well. There is an issue with `git` from MSYS2 not working well with Windows paths as parameters when run from some applications (Visual Studio Code in particular). Solved by using `cygpath` wrapper. I am cross-compiling for Linux too and then deploying to actual Debian machine. WSL could be useful for CI but is too much hassle for development at this time.
A function's (or method's) type includes it's specific parameter types. `func (params ...interface {})` is different than a function with explicit parameters. What you can do, however, is create a function that accepts an error value and does something with it if non-nil. You could then call it like `doSomethingOnError (json.Unmarshal (data, &amp;target))`
[removed]
Sound advice.
One solution would be to have your editor in WSL too and run it using an X-Server in Windows. It's not ideal (some editors like VSCode don't work with X-server) but it works if you really want to be inside WSL most of the time. I tried that with Sublime Text 3 with success, but returned back to my Linux system after a week!
There is a pretty active `golang-jobs` channel in the [Gopher Slack](https://bitbucket.org/getsocial/thrift/commits/afeb19e3825c6d16b4dbb2c676746280436a33f5).
&gt; Also, you should not have multiple go-routines (or threads, or whatever) write to the same connection. Most or all Go database libraries handle multiple goroutines writing to the DB connection. Do _not_ structure your Go programs to route all DB interaction to one goroutine by default. Worry about that only if it's a problem.
I edit on windows and run stuff via wsl My go path is ~/go which is a symlink to /mnt/c/Users/..... Only issue I have is that I can't run tests and such via a GUI in Visual Studio Code. I also have go installed on windows with go path set to that /mnt/c/Users/..... That's how Visual knows what code I have in my gopath.
It lives on GitHub, but I don't have a working prototype working yet; mostly I've just been churning on ideas and learning how compilers work. Once it runs and I have something that resembles the final product, I will share. If this sort of thing floats your boat and you want to riff about ideas or learn more, PM me.
Oh, very cool. Thanks for history!
It's not as though I always have a choice. Sometimes your boss says write an openstack plugin, I gotta write the plugin. The royal mess of imports is already there.
I posted a description of my idea in the past, but responses ranged from "Why would you want to make another language when Go is perfect?" to "No one will use your language because adding functional features to Go isn't enough of a departure". For me, it's a scratch-your-own-itch/learn-about-compilers/yak-shaving exercise, so I kept going, particularly because I think Go's runtime and tooling are best-in-class even though I've been persuaded that functional programming and robust type systems have a lot to offer.
How much memory does a goroutine require?
OK, I see the problem with my approach now: An attacker could guess the timestamp and my secret string and generate a code from it. The attacker could then use the code to create a user account and is also signed in. I've no idea how easy it is to guess both and thus I'm going to generate the code with something like this now: n := 16 b := make([]byte, n) _, err := rand.Read(b) if err != nil { // handle error } return hex.EncodeToString(b) 
[removed]
`secret` was a dynamically generated string of some sort. So, an attacker had to guess more than just the creation time of an invitation. But I'm going to use crypt/rand now. Rate limiting is a good point. I'm thinking of https://caddyserver.com/docs/http.ratelimit for the job.
There's *always* a complainer. Obviously, it's incredibly unlikely that someone is going to use your language as anything other than a toy. It's still really damn interesting! Soooooo... got a link? 
I just develop Go directly on windows the the helping hand of cmder. Haven't come across any issue yet. No need to fudge around with WSL. 
&gt; Is there a neat solution here that I'm not thinking about for the general case? For the general case, no. There are specific cases where you can do some things. [For specific types, you can provide an error-handling function](https://golang.org/pkg/text/template/#Must). Note how a function that returns two parameters can be directly fed into a function that expects two parameters. Go does not have first-class tuples, but it has some traces of it in the syntax. You can create an object like an io.Writer that, once it errors, is guaranteed to continue erroring with the same error on every call. Users can then write code that blindly powers through a series of operations and just check the last error. However you'll need to document this, because in general I would not assume a given object necessarily works that way. Reflection could do the job, but most segments of the Go community will look at you funny, and say bad things about your github repo if you try to post something that "solves" the error problem via reflection. You will certainly take a non-trivial performance hit, if nothing else.
Nope, that's pretty much what you get. Go function types are *exact*, they don't have any ability to move in covariant or contravariant directions. If you declare something as a `func(...interface{})`, then you'd better give it something that can take an arbitrary number of arbitrary things; a `func([]byte, interface{})`, which takes two things, of specific types, doesn't do the job. You can always produce a wrapper function that takes `...interface{}`, asserts that the args it *actually* got are what `json.Unmarshal` wants, unpacks them, and passes them on, but it will inevitably be ugly.
Stop fighting the idiom. You'll be much happier if you write Go as it was designed to be written, instead of trying to force brevity or generic abstractions over everything.
&gt; Though the service was in fact to performant for our core service to keep up with. Sorry, could you clarify what do you mean here?
Why?
[removed]
[removed]
We were posting back so many items back to our Django app it forced it offline. We are going to move over to mainly Golang micro services instead of our django monolith. 
Here's the project: https://github.com/weberc2/gallium You can run `go run main.go foo.ga` to generate some valid Go, and you can run `go run repl.go` to play with the type inference engine. There is no support for conditionals and recursion is probably broken as well. Everything is very likely to change.
Wait, what were the deciding factors for you guys moving over to Golang since you said Python async is performant enough?
Essentially, it's down to the personal preferences of our tech leadership. 
My auth middleware checks if there is a user_id in the session and if there's a user with this ID in the database. For now, the ID is just an integer. In future I want to use some kind of non-sequential random hash ID instead which should be harder to guess. http://www.gorillatoolkit.org/pkg/sessions says "... use it as an easy way to set signed (and optionally encrypted) cookies...". If I understand this correctly then my cookies are already signed but not encrypted. I guess I should add an encryption key like this: var store = sessions.NewCookieStore([]byte("authentication-key"), []byte("encryption-key")) What do you think?
If you can get away with just running a scheduled job that makes whatever assertions you are interested in, that's the easiest thing by far. If you need instant feedback, there is an [fsnotify](https://github.com/fsnotify/fsnotify) for cross-platform notification. However, be aware that the lowest common denominator for file watching is really, _really_ low, and in particular, does not include "watch a directory recursively", because Linux does not support that. You should also be aware that when that gives you instant feedback, that gives you _really_ instant feedback; if a large file is being written, you'll be notified about it potentially when just the first block has been written, and will get a lot of notifications as the file is written. You'll need to debounce that yourself, and AFAIK, you'll need to figure out for yourself when the file is "done" being written. (This is a characteristic of watching the file system, not fsnotify in particular.) If you don't need _instant_ feedback, you should probably just poll every so often.
No it doesn't need to be instant, within 30 minutes should be fine for example. So what do you suggest? I poll the directory using ftp or something else? 
I see no reason why need to embed sql.Null* types in struct. Can scan into local sql.Null* variables, and modify your struct instance depending on whether have Valid variable. for rows.Next() { var a Article var body sql.NullString var user sql.NullInt64 err = rows.Scan(&amp;a.Id, &amp;a.Title, &amp;a.PubDate, &amp;body, &amp;user) checkErr(err) if body.Valid { ... } if user.Valid { ... }
Using the `database/sql.Null&lt;Type&gt;` types is performant and clean.
A few weeks ago I installed WSL and `go1.9.1 linux/amd64` on a basic Windows 10 Home computer just out of interest. When I did `go run` on a simple program I got: go build command-line-arguments: /usr/local/go/pkg/tool/linux_amd64/compile: fork/exec /usr/local/go/pkg/tool/linux_amd64/compile: invalid argument I didn't bother looking at it any further -- just assumed WSL can't do Linux forking. 
This. Doing the same here - GOPATH points to a symlinked folder under WSL that in turn points to /mnt/c/Users/....
The strings you give as arguments to NewCookieStore are your secret keys and they should not be guessable. You're right, your cookies are signed already, but unless you changed the key from the example it's really easy to guess.
It is hardly the best task to be solved in golang. I dare to say bash + [inotify tools](https://www.opennet.ru/man.shtml?topic=inotifywait&amp;category=1) + cron 
A few KB, I can't find a source on what it is exactly for 1.9, but I want to say it's 2KB right now. It's been as high as 8KB before. This grows if the goroutine itself grows to need more memory, it just starts with a few KB.
Sounds like you can get away with simply traversing the list of files from the interesting directory. What’s up in the air it sounds like is how to obtain that list, you would need to describe more details about the remote constraint. Does it have a running service you could interface with? Ssh? Etc.
I'll follow the documentation &gt; It is recommended to use an authentication key with 32 or 64 bytes. The encryption key, if set, must be either 16, 24, or 32 bytes to select AES-128, AES-192, or AES-256 modes. Use the convenience function securecookie.GenerateRandomKey() to create strong keys. 
One crazy way would be to use xming and your prefered text Editor from linux inside the wsl. Another would be to set your gopath to some location that is accessible to Windows (/mnt/c/whatever) 
Or Perl! But yeah, the hardest part of learning Go is unlearning what you've learned from other languages. Once you do, Go becomes a rewarding experience. As for imports, you rarely have to manage those. Editors with Go support do that automatically. It's no different than Java, C# ...
If you only need to check it at specified times, I'd just use https://golang.org/pkg/net/http/#FileServer on the remote machine and just write a simple http query and drop it in a cron job on the client machine
Unfortunately heroku is the closest thing to your requirements. Take note go community there is a market for a go only webhost 😀
Yeah... it may feel klunky, but it's got the best bang for the buck by far.
Don't pretend that there aren't large portions of the problem space where "Go as it was designed to be written" *simply doesn't exist*.
Just write closures around the other functions to convert them into func() error.
Get a digital ocean 5$ droplet, install your DB on it, and deploy binaries. I do this for a number of projects (multiple projects per droplet) with no issues.
thumbsup
The only services I know that have a permanent free tier for minimal usage are Heroku and [Google Compute Engine](https://cloud.google.com/compute/pricing#freeusage). Heroku is slightly easier to set up, so I would use that. Google App Engine is cheap if you have low usage, but it isn't free. 
I develop entirely within WSL using plan9port's Acme and Xming. It works great for my needs.
Are you using Unix specific things? If not, just do the development with the w10 binaries. 
Get a vps (I like vultr) and install dokku on it. It's basically self hosted heroku. [https://github.com/dokku/dokku](https://github.com/dokku/dokku)
Why not host it from our own house? you can run it on a raspberry pi or similar. Just open the ports you need on your router and you are good to go! 
Thanks for everything Francesc, wish you the best in your future endeavors!
And update DNS every time your lease expires at the ISP...
I think you will find that happens less than once a year... So for the price of free I think its a good solution.
True, but neither Java or C has green threads (goroutines)
https://github.com/fsnotify/fsnotify Works well.
heroku free plan?
Unless the modem resets for literally any reason. Or you get a new modem. Or the TTL is much shorter... it's a seriously jank solution if you want it to be anything other than brittle. DigitalOcean is probs the best bet.
Its an app that only he is going to use. It takes five minutes to change the ip address a domain points too or a change an ip address in a config file. It's not jank its the best solution for his scenario. 
Thanks!
It is fine. It meets all the requirements. Deploying to a remote server on the real internet would be about a million times more instructive, but yes, this is fine. They will be limited to a gig of ram and four cores, which is totally okay for a small app. It's just such a temporary thing you're almost better off jumping into a real machine to learn.
I would recommend rsync, either push or pull. You can use SSH keys for authentication. If you use the flags -avz it will handle compression (in transit) and recursion for you.
leave it in the native representation (`[]byte`)...once you understand how ipv6 works it should be straightforward to determine how to mask/shift the parts you need to compare to find CIDRs etc converting to ints tells me you are trying to do something like php's integer representation for ipv4 addresses, which is clumsy and not necessary...Go's big Int type is not that useful and has limited functionality
https://www.arubacloud.com/ - you get a VPS with 1GB of RAM for €1/month. Plenty of Linux distros to choose.
As soon as you open a port your machine becomes the real internet. And of course the machine is real. Hosting on your own machine is almost exactly like hosting on amazon aws for example. The added benefit of using your own machine is you can then use it for other stuff like an sftp server. But agree, its good to learn other services. And if he doesn't have an extra pc or PI lying around it may make more sense to use DigitalOcean. 
Thanks for the suggestion. I didn't really develop this with load testing in mind, but over the weekend I added some features that might be really useful - you can now set repeat=true and we repeat sending when the CSV data source finishes. I've added the 95th percentile as you recommended, and split the metrics by rate segment (e.g. a new segment each time you change sending rate) and by response status (e.g. success / different errors). Check out the example output in the readme and let me know if it makes sense to you.
Use a free dynamic dns provider like http://duckdns.org and make a timer unit that starts every x minutes. Completely automatic and you don't need to change a thing when your ip changes
Hi /u/hobbified, Absolutely correct. I'm working on a a follow-up post based on my conversation with ILT at https://github.com/golang/go/issues/22425.
[removed]
so they were shitting on people for using PHP then they learned that progression into PHP from wordpress or whatever was a common path for women so they realised the error of their ways? Didn't care much about what this femcunt had to say after that
Every one of these articles &gt;Similar dev time Better performce Comparatively easy concurrency We know.
umm the reason that env vars are annoying is not because they are hard to set. The single bash built in of `source` will import a env file. The problem is getting that file onto the machine in the first place in an easy to deploy way. 
+1 For Digitalocean I run my Project Golang.zone on a $5 droplet without any issues. DO will just give you a server so you have to be comfortable with the terminal to setup whatever you need :) If you would like to try DO I got some discount codes... it is $50 so that will give you plenty of time to get started just msg me. Project: https://github.com/steffen25/golang.zone/ 
And when you need to do math on your iPad addresses, are you going to reimplement what big.Int already gives you? 
[removed]
[Here's my (long-ish) writeup on using WSL for Go development:] (https://brianketelsen.com/my-cross-platform-dev-setup-on-surface-laptop/)
Honestly I use `.env` files for local development only.
Did anyone find the link to the full source code for the article?
Nevermind, https://github.com/lawrencemq/geneticAlgo_golang
Digital Ocean is good, but I second GCP. Their logging system is too good to pass up and I believe its free up to a certain amount of usage.
AWS Lambda ([one lambda function can an entire API](https://github.com/yunspace/serverless-golang/tree/master/examples/aws-golang-net))+ DynamoDB. Set billing limits, zero operational work. 
It's not that hard with systemd, where you just add them to your service file. You have to write one anyway if it's a daemon, so I really don't see what's so hard about it. Also, if you're developing, you can just have a simple shell script that has all those variables: export VAR=value go get run_program ... That's what I do and it works quite well IMO, so why complicate it?
Every article always contains something new in a way or another. And while it might not be useful to you it could be to someone else. That kind of articles is also about different perspectives. In other words: sharing is caring. Right?
That's what Openshift is for, isn't it?
There are plenty of tools. All the cloud platforms have some templating resource. Kubernetes has secrets and envs in the templates. You name it.
You nailed it. Whenever I have to use env vars, systemd does the trick quite well. I usually try to utilize toml configs when possible though
Feel free to look at watcher (https://github.com/radovskyb/watcher) if you need recursive directory polling (been a little while since I've made any updates)
[removed]
True-ish, but casefold is still a good neutral option in situations where it doesn't make sense to impose a particular collation, and where you aren't looking for sorting at all, just equality and canonicalization (what collate calls "Key"). And it's a zillion times faster.
 YourErrorMajig(func () error { return json.Unmarshal(someBytes, &amp;someValue) })
That is just bad advice. Go is *designed to be written* like errors are just any value, because it recognizes that there is no one-size-fits-all solution to handling errors. From the linked article, by one of the designers of Go: &gt; Regardless of whether this explanation fits, it is clear that these Go programmers miss a fundamental point about errors: Errors are values. &gt; Values can be programmed, and since errors are values, errors can be programmed. &gt; Of course a common statement involving an error value is to test whether it is nil, but there are countless other things one can do with an error value, and application of some of those other things can make your program better, eliminating much of the boilerplate that arises if every error is checked with a rote if statement. Idiomatically, it is very common with for example functions that repeatedly call an error producer until it doesn't produce an error.
Maybe try posting your Go code instead? Also, explain why it doesn't work (as you expected) and any errors you receive.
Same here, autoenv does the job well. Edit: also has an oh-my-zsh plugin :)
 func main() { user := &amp;User{Username: "dummy",Password: "dummy"} jsondata, err := json.Marshal(user) if err != nil { fmt.Println(err) return } fmt.Println(string(jsondata)) if len(os.Args) != 2 { fmt.Fprintf(os.Stderr, "Usage: %s host:port ", os.Args[0]) os.Exit(1) } service := os.Args[1] tcpAddr, err := net.ResolveTCPAddr("tcp", service) checkError(err) conn, err := net.DialTCP("tcp", nil, tcpAddr) checkError(err) _, err = conn.Write([]byte(jsondata)) checkError(err) result, err := ioutil.ReadAll(conn) checkError(err) fmt.Println(string(result)) os.Exit(0) } I have to send username and password in json format, after that server will send me auth response. Currently I just receive "connection reset by peer" error. 
Is there a reason to use it? For develepment purposes I'd recommend https://direnv.net/, it loads/offloads environment vars automatically once you change working directory, its files are pure bash (you can do `$ source .envrc`) and the most importang thing: there's no need to import vendor packages in your code. And I don't see why anyone should use it in production, this approach brings the same problems as you'd have with configuration files (delivering them along with binaries). Systemd, docker and other process/container supervisers can manage env vars on their own.
Oh, this is very nice ^^ I wrote a similar API (albite more limited and in C++, not go) for the company I previously worked for and now I'm thinking of using clickhouse again and would have to go through the process of writing it again... but this may just fit what I need. My only concern with this would be added latency, but I will definetly give it a test run. Do you need any help with development ? Would you be open to try integrating with the native client ? (Though I'm not quite sure how easy it is to bind C++ library to a Go interface, and it would add certain dependencies, since currently to have the client you basically need to run the whole of libclickhouse)
I guess that seems fine. Since you're getting "reset by peer", have you verified that you're sending the correct message? Tried writing the json data to stdout?
&gt; Every article always contains something new in a way or another No, they really don't. They rehash the exact same points with zero additional insight. This has been covered time and time again: is it better/faster/more-reliable because of the language, or because you understand your problem better having written it once before in language X? Go is a great little language, but articles like these are just noise that drown out the signal. &gt;In other words: sharing is caring. Right? Platitudes. Platitudes, everywhere.
It's pointless, if you are including code to load app's config from file don't half ass it with env, just use some other "real" configuration format
Jesus, use another language already.
IIRC Go's image/* types store image data in [row-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order), so it should be faster to do rows at a time instead of columns at a time (to minimize [false sharing](https://en.wikipedia.org/wiki/False_sharing)).
**Row- and column-major order** In computing, row-major order and column-major order are methods for storing multidimensional arrays in linear storage such as random access memory. The difference between the orders lies in which elements of an array are contiguous in memory. In a row-major order, the consecutive elements of a row reside next to each other, whereas the same holds true for consecutive elements of a column in a column-major order. While the terms allude to the rows and columns of a two-dimensional array, i.e. *** **False sharing** In computer science, false sharing is a performance-degrading usage pattern that can arise in systems with distributed, coherent caches at the size of the smallest resource block managed by the caching mechanism. When a system participant attempts to periodically access data that will never be altered by another party, but that data shares a cache block with data that is altered, the caching protocol may force the first participant to reload the whole unit despite a lack of logical necessity. The caching system is unaware of activity within this block and forces the first participant to bear the caching system overhead required by true shared access of a resource. By far the most common usage of this term is in modern multiprocessor CPU caches, where memory is cached in lines of some small power of two word size (e.g., 64 aligned, contiguous bytes). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Scientists were always asked whether or not they *could*, but no one stopped to think whether or not they *should*. In all seriousness, with GccGo, I imagine all you have to do is either nix the runtime, or severely mangle it to the point that you can fit “Hello World” on a 32kb IAR Workbench free license. It seems like a pretty cool project imo. But I’ll still use C in my day job :P
if I read the specs right (I just did a quick google) that board has like 2 GB of RAM. It's a beefy quad-core SoC.
No matter what you do really, if your React site is completely static, if your React app can access your API, so can anyone else. If your React app was loaded into a page that was generated dynamically however, you could make it slightly more difficult to use. You could inject some kind of short-lived token into the page that would serve as "authentication" or something. The thing is, not only will this complicate your app, it still won't really stop people from using your API. That token would still have to be sent somehow, and someone could still easily make something that picked that out of page to start making requests. Like I said, it would only make it more difficult for them to. What is your API doing, out of curiosity? If it's something like a blog, then why does it concern you? If it's something that has a user system, then making users log in would be enough.
 if requestIsToOtherEndpoint() { send 404 response }
&gt; Scientists were always asked whether or not they could, but no one stopped to think whether or not they should. And the engineer said "don't explore; I won't use it". "Useless" science feeds engineering, as you surely know. 
This really is impressive 
Maybe I'm misunderstanding your problem, but you could generate per-user OAuth credentials and then revoke those that are being abused.
If it's a website, CORS? Otherwise probably a token.
You need a authentication mechanism, you could use jwt https://github.com/dgrijalva/jwt-go
You can call your "main" or "entry" function from init() function as they run without main also 
Loading from env is good for 12-factor apps to be as stateless as possible.
So, I assume by your hesitation that you're not looking to write formal tests just yet, but that you simply want your code to run so you can ensure that it does what you expect. Go test can be used for that, too. I often use a test as an entrypoint to my code to exercise it and figure out what it's doing. Just slap a `func TestStuff(t *testing.T) { }` in a foo_test.go file, and put the "main" code inside the test to run your code. Then running `go test` in the library directory will run that test function (if you have other tests in the same file, you can tell it to only run that one function with `go test -test.run=TestStuff`). That's probably the simplest way, and then you have a test file all set up for when you write actual tests :)
yeah, but you still need some kind of main function to run to get the init code to run.
For testing ideas and basic functionality you can use https://play.golang.org Outside of this Go makes a distinction between executables (main) and libraries. You’d typically start with main, and if you have a clear need to separate parts of the code move it to a package. Then call that package from main. Make sure to use Upper case for exportable items. Usually when prototyping you’d just ‘go run main.go’ , this temporarily builds an executable and runs it. Most users have linting, fmt, etc built into their editors so it updates every time code is saved.
A coupe of ideas for you to look into: 1 - Make use of [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) to restrict which domains can access your API. 2 - Make use of [JSON Web Tokens \(JWT\)](https://jwt.io/introduction/) to authenticate your calls if necessary. 3 - Make use of [OAuth](https://oauth.net/) 4 - Make use of API Tokens
Never said it was useless; my joke wasn’t well received I guess. Embedded systems are difficult to understand to a beginner. Go is an insanely easy language to learn beginner concepts from. The two merging would be great! I was just assuming this would be geared towards Go on an Arduino for this booming IoT phase of commercial electronics, which isn’t really possible.
That’s not my idea of an “embedded system”. It’s a cool board and a cool project though. I was hoping it was a rewritten runtime sort of like Rusts #[no_std], compiled with gccgo that enables most of the features of Go to be run on a micro controller.
I’ve found this pkg quite useful. Just throwing this into the mix. https://github.com/pkg/errors E,g., errors.Wrapf(err, “could not get file: [%v]”, file) Further reading: Blog: https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully Video: https://youtu.be/lsBF58Q-DnY 
&gt; every change I need to rebuild package, rebuild project, and run First, I agree with natefinch's post. This is not a Go suggestion, but a general shell expertise suggestion. Rebuilding and then running should not be something you find yourself reluctant to do. You should find some way to make that easy for you, because the time spent doing that will pay off in a lot of ways. I don't know your environment, but one of the simplest ways to do it in Linux (and I _think_ even the simplest command shell in Windows) is to type out the build commands once, and then just use "up arrow, enter" to re-run again. If you use incremental building, I find it's almost always as fast as a scripting language (and as the project grows, actually faster). Exactly what you need depends on what you have, but something as simple as go build -i -v &amp;&amp; ./my_program is a good start. `-i` means incremental build, so unchanged packages are not recompiled. -v is just because I like to see the compile go by; YMMV. (When I do make a change deep in the dependency hierarchy, seeing all the other packages go by keeps me from wondering what's taking 2 seconds.) You can start elaborating on this easily; you may want to feed a specific package path to go build if you're not in the directory where the executable is (I often work from the top level directory of my project, which may not even be a "go" directory), you can put a `go test &amp;&amp;` to validate test code before even running the core exe, you can feed the test command itself other things.... you can tune it as you go. You can also create a little script to do whatever, but I find that the command line history is generally enough. (Usually anything _really_ fancy I want to do, I do on the commit prehook. For instance, when I'm just running some code to see if I did something I actively _don't_ want the lint checks running yet.)
At 2GB of RAM and quad-core SoC that looks more like a real computer than embedded environment. The truth about Go and embedded environment is that a GC language can never be a good fit except if your embedded requirements are not real "embedded"(i.e. deterministic, constrained resources etc) at all. Who would run sensors driven by a GC language ? Something exciting is the upcoming Swift 5 with the release of a (opt-in) Cyclone/Rust-inspired memory ownership model. Let's hope that goes well and Go 2 would provide something similar for the poor embedded developers.
&gt; I have to send username and password in json format, after that server will send me auth response. Currently I just receive "connection reset by peer" error. Mmmm, that's tricky to get right. Are you responsible for the server on the other end or speaking to somebody else's server? JSON doesn't have an end-of-JSON delimiter. A streaming parser can notice when the stream has ended, but it is very easy to imagine that the server is not using a streaming parser and is instead looking for some delimiter to indicate that the JSON is done, like a newline or something. The difference could be something as simple as your C# happens to incidentally terminate the JSON with a CRLF, which the server was looking for as the sign to send the block of text to the parser, and the Go code isn't emitting it. If you do control both sides of the connection, I recommend delimiting the connection with something, for better reliability and debugging. Something as simple as "4 bytes in network order indicating the length of the JSON to come" is enough to solve that problem. If that is not the problem, you may want to wrap the conn with something that prints all the bytes going in and out, so you can see exactly what's going on.
Just use `go test`. See https://golang.org/pkg/testing/ 
Your best bet is a small vps (i.e. digital ocean ). Stay away from appengine and other closed platforms with proprietary databases, services etc. 
You can try comparing packet captures of the working C# and the non-working Go clients in wireshark or similar tools that can follow a TCP connection (that makes it easier than reassembling the stream from raw packets, though it does hide where the Push flags happened)
Unfortunately, I'm not responsible for the server on the other end. I'll try printing all the bytes though. Thanks
This may not help you but I had to implement a client for a wacky 1980's binary protocol that was built for serial lines and ported by the manufacturer to TCP/IP. Maybe you can use this as a guide: https://github.com/chrissnell/gopherwx/blob/master/station.go
I have made a struct for user: type User struct { Username string `json:"username"` Password string `json:"password"` } and then I initialize it using username and password: user := &amp;User{Username: "dummy",Password: "dummy"} after that I convert it to json: jsondata, err := json.Marshal(user) if err != nil { fmt.Println(err) return } fmt.Println(string(jsondata)) once Println executes I get: {"username": "dummy", "password": "dummy"} However the I'm required it to send in this format: { "username": "dummy", "password": "password" } I thought skipping newlines might not be the issue. But I'll try this way too. 
But have you compared it to what the C# code sends? White-space sensitivity isn't unheard of, unfortunately...
I wouldn't recommend file transfer via UDP if dataintegrity is an issue (which for up-/downloaded files it likely is). You'd have to implement all the handshaking for preventing dataloss caused by lost packets, making sure you got the data fragments in the right order, etc. all by yourself - a job the TCP protocol already does rather well for you, and it's doubfull (yet not impossible) that your code will do it faster than the TCP networkstack.
Then load from env, not have some half config half env monstrosity. OR, use some cli-parsing lib that can do both, for example `urfave/cli` supports that: cli.StringFlag{ Name: "device", Usage: "specify device to check for listening IPs. Defaults to empty string which means all devices", EnvVar: "HA2BGP_DEVICE", } it makes argument env-settable but allows for override from commandline that way i can just set anything I need from CLI OR override env/defaults when needed. Obviously problem is when config itself is big but env vars have exactly same problem. It allows to easily have various test/prod scenarios (either just pass it in commandline or just override parameters you need) and is still compatible with inept platforms that can't figure out how to handle config files Because that's what is really the source of the 12factor's config requirement, if you can't deploy a config from template then your system architecture is just inept. On top of other problems with env, like not being exactly great at structured data, or **leaking any and all passwords/api keys to every single part of the app and whatever binary app internally runs**. You can make it more secure but you have to always remember than any part of your code can access everything so for example any `os/exec` and friends should have by explictly passing the `Env[]` with sanitized vars every time you call external command (which sure, it is rare, but you won't be seeing equivalent of say ffmpeg under go anytime soon) 
Makefile might be good for this. I am by far not a Makefile expert, but it is an excellent way to make sure that repeated tasks are scripted. 
It's scanning multiple values from a line, rather than scanning lines. Similarly with sql.Scan, it's scanning multiple values from a row rather than scanning rows. So at least there's some consistency.
It's from this book: https://interpreterbook.com which is very good at getting you started writing an interpreter. &gt; In this book we will create a programming language together. We'll start with 0 lines of code and end up with a fully working interpreter for the Monkey* programming language.
I doubt these articles now and then "drown out" any signal. And IMHO they are not really about Python vs Go. For someone like me and like many others that switched or are about to switch from Python to Golang it is important to know the trade-offs and how others solved their issues. So you can be as cynical as you want. Fact is that for some ppl those articles are helpful. Deal with it. ;)
This is sadly the flipside of "fat clients". If it's REALLY critical from a security standpoint, I would dump react and render it server side. That way you are always in full control. 
They are all shitty, although https://github.com/golang-commonmark/markdown does look like relatively easily expandable. The most popular is https://github.com/russross/blackfriday but looking at [this](https://sourcegraph.com/github.com/russross/blackfriday@6d1ef893fcb01b4f50cb6e57ed7df3e2e627b6b2/-/blob/markdown.go#L32:2$references) I doubt if it is easily expandable And don't waste your time on this piece of crap: https://github.com/a8m/mark
Visual studio code + powershell terminal on Windows Visual studio code + bash on Ubuntu No need to chase terminals, can use whatever terminal that is available 
Thank you. Blackfriday sounds somewhat familiar so maybe I toyed with it a while back. :)
Hey man I was in the same situation as you described when I began with my first Go project an api I couldnt find any good way to structure my app so I did what I’m used to in php (kind of). My structure could probably be done in a smarter way but hey you gotta start somewhere :) You are welcome to check it out at https://github.com/steffen25/golang.zone/ You can also try out the live demo if you would like at https://golang.zone a Vuejs front end that is also open source 
&gt; Who would run sensors driven by a GC language ? Hardware n00b question: wouldn’t this matter only if one cared about actual real-time measurements (therefore ruling out any language with undeterministic GC pauses)? For example, you wouldn’t want to use Go for sensors on SpaceX rockets, but if your sensors don’t need sub-millisecond accuracy/sampling—say, if you’re measuring temp/humidity/etc for weather readings—then Go would be okay I assume? Or am I missing something?
open telnet, connect your server and type your json message, does it work like that?
I think you missed the point with respect to where the difficult part of parameters deploy is. How do you get the value into the environment in the first place. The hard part when deploying software is getting the database details into the node you are deploying the code on in the first place. How do you get it into the systemd file in the first place, or into the start script or where ever. I say this because those details should NEVER, EVER be in the source control. This is handled by stuff like cloud formation, or similar but my point is that this is the more difficult step. Generating a systemd file that depends on the actual deployed services is the hard part. Actually pulling a value from a file into the environment is easy. 
CORS assumes that the client is willing (i.e. it's a browser that wants to protect the user from unwanted cross-domain communication). It's not a reliable way to protect the *server* from anything.
Embedded system definition is fairly wide and when size &amp; power draw constraints are not an issue it's fairly common to use general purpose hardware - most ATMs are Windows PCs
I love my file transfer protocols to be unstable!
There is a userland implementation of TCP in Go from Google https://github.com/google/netstack It's complex and a very good learning material.
If you really want a library to have its own main for other purposes then testing you can always do a ```libname/internal/cmd/libname``` folder that has a ```main``` that string things together. We tend to do this extensively where I work as we have microservices built around a library of their own functionality with the actual service ```main``` buried. This lends us a good amount of code reuse across communicating services, without reimplementing.
Yeah it'd be fine, it won't be perfect, but often you don't need perfect. I have built a few projects that have used sensors and I was using Python. Was it perfect? No. Did it get the job done and no one was harmed? Absolutely.
That's true. I think that depending on your infrastructure you could do something to get away with it but if you let the clients communicate directly to the backend, CORS isn't the answer. Like you said, CORS is more of a minor deterrent than anything.
Make sure you are handling that gzip data on the go end. Given the code you've shown this is not the case.
[removed]
I tried out gore about a year ago and it had 1 second responses on a:=1 perhaps because it must compile some code in a cache using os/exec.Command for every command entered. A Repl for Go would need to give Python-like response times for programmers to actually use it. Being able to compile and run Go source in its own address space from within another Go program would help with the speed issue, but I don't think Go will be offering that anytime soon. 
&gt; Syntax? really? The syntax falls flat if you want to be creative, but from an engineering perspective, I do like that it forces you to not concern yourself about those matters. Interestingly, Python set out to try to achieve the same, but Go does it better.
One of the best README I’ve seen in a long time.
Ahh! That sounds great. Thanks for the link!
[This book is oft-cited on Hacker News](https://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670) and is largely devoted to code structure and organization. Structure and organization generally isn't a language-specific thing. There are practices from the Single Responsibility Principle and rules of thumb like "don't write a function that can't fit on one screen" that one should follow when coding in any language...
Here's a good selection of resources to help you with organizing a Go project: * [How to Write Go Code](https://golang.org/doc/code.html) * [Organizing Go code](https://blog.golang.org/organizing-go-code) ([Talk](https://talks.golang.org/2014/organizeio.slide#1)) * [Five suggestions for setting up a Go project](http://dave.cheney.net/2014/12/01/five-suggestions-for-setting-up-a-go-project) * [Structuring Applications in Go](https://medium.com/@benbjohnson/structuring-applications-in-go-3b04be4ff091) * [Standard Package Layout](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1) * [Go best practices, six years in](https://peter.bourgon.org/go-best-practices-2016/#repository-structure) + the older version [Go: Best Practices for Production Environments](https://peter.bourgon.org/go-in-production/) * [Practical Persistence in Go: Organising Database Access](http://www.alexedwards.net/blog/organising-database-access)
I don't see the difference between a `.env` file and a systemd service file. Instead of adding it to a `.env` file, add it to the service file. There's not much difference in deployment especially since you'll need the systemd startup script anyway. If you're going to use a file, then why not just have it be a traditional config file and forego the environment variable thing altogether? In my projects, I have a config package that stores global, read-only values for the program that gets populated at startup according to the following precedence (omitting from one area will fallback to the other): 1. CLI arguments 1. Environment variable 1. Config file 1. Hard coded defaults In development, I use CLI arguments. In production, I use environment variables. The default config file is committed to the repository and doesn't contain sensitive information like passwords, same with the hard coded defaults. This way the user can change config values without breaking stuff and production deployments can configure stuff in the startup script.
&gt; I don't see the difference between a .env file and a systemd service file. I don't either that's why the hardest thing to do is correctly generating those files during deployment, not the actual reading of the file. &gt; If you're going to use a file, then why not just have it be a traditional config file and forego the environment variable thing altogether? In my projects, I have a config package that stores global, read-only values for the program that gets populated at startup according to the following precedence (omitting from one area will fallback to the other): &gt; CLI arguments &gt; Environment variable &gt; Config file &gt; Hard coded defaults My environment is substantially similar except I will usually choose CLI/ENV or config but not both. I do try to keep away from hard coded values as they can cause some issues. About the only thing I'll hardcode is localhost for and IP and a default port. 
When I started working on my project, I was greatly influenced by gogs (https://github.com/gogits/gogs). As the time goes by, I kinda changed the structure a bit. If you want to have a look, the project is https://github.com/getfider/fider and I organize it like: - app/actions: The input struct that is mapped from POST requests. Each action knows how to validate itself and check whenever current user can perform that action. - app/handlers: One handler per route. They receive a request and return a response. - app/middlewares: They wrap common functionality like authorization, open/commit/rollback transaction, logging, fill the context with userfull information for the handlers - app/models: Just dummy models that are either used for Input, Output or Internal - app/storage: Interfaces and structs to access the storage the models. I currently support only inmemory and postgres. InMemory is used only for unit testing, while postgres package is used when the application is running. In the future I plan to add mysql and mongo by just creating a new package and implement the interfaces. - app/pkg/*: common packages that are not used by the storage, handlers, middlewares, actions, etc. I also like to wrap most packages into my own packages (example: web, jwt, oauth, dbx) so that I can expose a simpler API to the handlers and easily exchange an internal package with another one. Hope it can help you somehow!
While it definitely works, it is better to make it a habit to avoid generic package names. Please read [SOLID Go Design](https://dave.cheney.net/2016/08/20/solid-go-design).
recently stumbled upon [ways to do things](https://www.youtube.com/watch?v=LHe1Cb_Ud_M) by /u/peterbourgon which has a refreshing way of viewing all this also depending on your scope [go-ddd](https://github.com/marcusolsson/goddd) or [gobuffalo](https://gobuffalo.io) for rapid web dev which might be a good place to start
Scanning from the standard input, while it sounds trivial, it can be surprisingly tricky because it has a lot of corner cases. It's not much better in other languages either. Don't let it discourage you.
Using your definition I'm sure that you can plug-in a fully fledged server and connect it through USB to a bunch of i/o peripherals and call it embedded development.
If you don't have real time requirements you can use anything you want but most of the time embedded development has soft/hard real-time requirements along with very constrained memory/cpu cycles. You wouldn't use Go for your sensors on SpaceX b/c Go has a GC which is not deterministic and requires more memory/CPU than a non-GC language. If you don't have realtime requirements and weight is not a constrain you may just run Go on your PC connect it via USB to SpaceX's i/o peripherals and send it in the space. Something tells me that SpaceX uses non-GC language(s) and most likely the most important parts have some kind of formal verification as well.
I took a look at some of your code and you've got a lot of issues. &gt; copy(passwd[:], *plainPasswd) passwd is byte array of length 32. If plainPasswd is longer than that, it's going to get truncated and you don't provide any indication of that. If it's really important to you that that key is 32 bytes, you probably want to validate that. Right now keys that are too short are going to have undefined behavior at the end (unless Go zeros out array elements on initialization, not sure about that), and keys that are too long get truncated. GetOpenPort also seems broken, since you're using the listening port without checking for an error. I'm guessing that if it fails, the listening port will be nil and you'll segfault there if it can't acquire a port. &gt; fileInfo, err := f.Stat() This line is also broken because you don't check the error. fileInfo could be nil, and if it is then you'll segfault. You can trigger that by trying to download a file that doesn't exist. While interesting, UDP is a terrible protocol for this. You probably want TCP. For example, UDP doesn't guarantee that packets arrive in the order they were sent. If one of the packets arrives before the one that was sent before it, your file is now broken. Unless you implement some ordering on top of UDP. And UDP doesn't guarantee that the packets arrive at all, so you'll want some checking on that. Before you know it, you've rewritten TCP, you're just sending it over TCP. The only real advantage to UDP in this scenario is that you *might* get a better QoS rule from UDP because the protocol itself is so unreliable you have to prioritize UDP.
It is known that their telemetry collection sys is written in Go. Airborne software is always formally verified, and GC doesn't play well with its non-deterministic pauses. The same goes with every non-deterministic aspect of a language, exceptions for example (http://www.stroustrup.com/JSF-AV-rules.pdf). 
Well, I'm sure they use all kind of languages for different needs though I doubt they are using Go for embedded tasks. I don't think the docking system is using a GC language.
I see a lot of new Gophers breaking their apps into folders like you do with Node, Rails, etc. In Go, all files necessary for the app/package to function should be in the same folder. Only create packages for standalone, re-usable code.
Yeah. If writing it in pure UDP protocol is a problem. Now I am still working on the TCP transfer part. And I plan to use KCP to do the UDP transfer, which I haven't really tried.
number 2 and number 4 are the same thing
&gt; upcoming Swift 5 with the release of a (opt-in) Cyclone/Rust-inspired memory ownership So why not just use Rust now?
well, you could wrap everything in a function and use this signature func readLineStdin() (string, error) then, it becomes a one-liner 
I am working on the TCP transfer part. UDP is difficult to write so I think supporting both TCP and UDP transfer is better. And thanks for the suggestion of the password, getopenport and file open part!
Not so, JWT is a very specific kind of token and protocol, a classic api token or key as I meant it can simply be something like `/endpoint?apiKey=123xyz`. Calling it an API Key would have been clearer, though!
And then every API key is in your access logs.
It all depends on what it is you are trying to achieve. Everything has a convenience-to-risk factor you have to take into account. Some people do it via headers, some people do it via url parameters, but like it or not, it is still a valuable and common way to handle keys. Example, [Twillio](https://www.twilio.com/docs/api/rest/keys) does it for some of their API calls.
Can't you also check if a JWT is valid in the same way? Or if you are that insistent on API keys why not put that in the JWT?
Oh, I think you misunderstand, I don't mean to say that you have to use this, I'm just saying it's part of the options (though admittedly a pretty crappy one for authenticating a front-end). You can indeed use JWT's for this, you are absolutely correct!
I think it's a bad idea to suggest putting anything in a Universal Resource Locator (URL) that has nothing to do with the actual location of the resource (exception for interop with old services that still use HTTP basic auth for some reason, my point is don't write new things that do this). This includes things like API keys, which are secrets. Secrets go in the parts of the request designed for secret things, also known as headers.
[@property's latest tweet](https://i.imgur.com/Rl0oYXz.jpg) [@property on Twitter](https://twitter.com/property) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Headers are not safe either, and all keys do not have to be secret, they just have to be able to be cancelled and changed easily. This is one of those examples. If you setup any sort of api key, headers or otherwise, the advantage is that it's incredibly easy for you to change the key on the server side and automatically invalidate any and all calls still using the previous key. Again, it's a risk vs convenience situation, this setup is extremely simple and easy to manage, but not the best, nor the safest. It's just food for thought edit: Headers are safe**ER** over https, of course
Swift will probably allow both memory models, Rust only has 1
what the fuck?
But that is not good! You transfer something to somewhere and it becomes something else.
You don't need to rebuild package and project manually every time. If you just build the project (or even `go run` it) it will rebuild everything automatically.
I actually wrote one in Typescript based off Khan academy's "simple-markdown" in Javascript: [https://gitlab.com/whatwhathuhhuh/bear-markdown](https://gitlab.com/whatwhathuhhuh/bear-markdown) I bet it would be pretty easy to rewrite it in Go since it's mostly just a few regular expressions. Of course it would take more time than using one of the others mentioned here, but if you want to learn more about parsing/markdown/go/typescript it could be an interesting project.
It definitely could!
Yeah, nothing against this article specifically, its just low hanging fruit for website content. If people are going to keep posting all these articles highlighting the same exact points, I would like to see more comparison between other languages. We know python can be slow and we know Go can be fast, but what about Java, .net, or even JIT compiled python (Pypy). What about python combined with cython? How do I even know what you were using for python? Were you using asyncio, threading, or greenlets? You could have deployed on the flask development server for all I know. Did you use cython to speed up the slow parts? Were you using a JIT compiler? There are so many variables that you don't even talk about, that people can't learn anything from these articles. Obviously I can make Go code faster than python code. I could easily get python code fast enough to handle fairly large applications too, but I have no idea how you wrote your python code. For example, the pinterest api takes 12 billion+ requests per day using flask, and their tech stack seems fine. I'm actually 100% certain DZone could use python, and be just as capable as they are now with Go. Not to mention, the article doesn't even say if the website uses python 2.7 or python 3.3+, django, flask, bottle, pyramid, or maybe you were brave enough to roll your own framework from scratch. This article just rehashes the same pros and cons from every other go v. python article in attempt to draw attention from the python crowd. It brings nothing to /r/golang.
UDP IS TOUGH. But it is promising.（Probably)
&gt; tcp is built on top of udp Nope. It's built on top of IP. UDP and TCP are separate protocols with no interdependencies of any kind either way. 
One struct per file is a decent place to start for basic project structure. Put application source in cmd/&lt;name&gt;/main.go. Add unit tests alongside library definitions, as &lt;thing&gt;_test.go.
What problem ars you running into with having your api endpoints exposed? Maybe the solution is in factoring that in with designing the API
Use [build](https://golang.org/pkg/go/build/) [tags](https://dave.cheney.net/2013/10/12/how-to-use-conditional-compilation-with-the-go-build-tool) on top of your main files like: // +build appengine and // +build !appengine Check [golang/perf] (https://github.com/golang/perf/blob/cab923dd6b1a9c8bc6bef50023f8efc9d9508b42/storage/appengine/app.go) out.
Cool lib and great experience report! Be sure to add it to the fo wiki page: https://github.com/golang/go/wiki/ExperienceReports
[removed]
The definition of an Embedded system doesn't place any constraints on specs, size, operating system or real time responsiveness. It is just a computer that is embedded into a larger system and dedicated to perform certain functions efficiently. An Aeroplane or Space vehicle could have multiple embedded systems of varying sizes and power. So yes, a full fledged computer could be an embedded system when its part of a larger system. Just because we had practical limitations on CPU, memory or size 10~15 years back does not mean that embedded systems have to be all small single board computers with 512k RAM and operating at 100MHz. The average smart phone these days is several times more powerful than super computers from yester years.
You can use a main package. package main import ( "net/http" "google.golang.org/appengine" ) func main() { http.HandleFunc(...) appengine.Main() }
This is brilliant. Thanks. I never knew that appengine can live without a Main package. This is not covered even in the official go-appengine docs. I posted this query in the golang nuts list also. https://groups.google.com/forum/#!topic/golang-nuts/Vce6234vk8E I believe that it will be nice if you could reply there also, so that it will be beneficial to many. If you want, I could just refer to this thread and send the mail myself too. Thanks.
Thanks. But, I think I will go with the appengine.Main function recommended in the other comment.
where do you put code that does calculations on data, assuming you're following "Standard Package Layout"? like, I'll have a DataService interface implemented by the mssql package which retrieves and stores data, but if I then want to perform calculations on that data, what would I do? make a calculations package, which implements a DataCalculations interface? because in this case I'm not sure what the interface would look like. EDIT: typo
Unfortunately I couln't get it to work on my machine. I understand that it is almost impossible for you to give an account for why. I just thought I'd let you know anyway, in case you have more potential users that experience problems it might be of interest to look into possible causes down the road. Cheers!
This is great!! For some reason I couln't get gnuplot to work properly on my machine. But matplotlib came to the rescue. Thanks for posting! 
I stand corrected, you're right, they only share the first 4 bytes for src and dst port, every other field is different after ports
&gt; My only concern with this would be added latency, but I will definetly give it a test run. The added latency shouldn't be visible on most queries, since these queries usually need to scan millions of rows, which takes at least a few milliseconds. &gt; Do you need any help with development ? No at the moment. We build and extend `chproxy` for our needs. Currently we are busy with adding configurable response caching into `chproxy`. &gt; Would you be open to try integrating with the native client ? Sure, but this isn't urgent, since wee feel quite comfortable with http protocol :) 
Thanks :)
Holy fuck, no please no. One struct per file is fucking insane.
Standard tcp is very inefficient at utilizing high bandwidth links, since it treats packet loss as congestion. TCP-BBR addresses this, but it's easy to implement UDP file transfer with a set bandwidth and retransfers. You split the file into packet size chunks, transmit each chunk with authenticated encryption, and retransmit anything that you don't get an acknowledgement for after a period of time. 
There's no right way to structure code. Everyone had their opinion, and any suggestion you read here is merely somebody's opinion (including this very comment). You should structure your code in a way that makes it easy (effective, efficient) for you to develop the project and navigate it. For example, if putting all the code in one single file makes that easier, then so be it. From my personal experience, the more you break up the code into files and folders, the harder it becomes to navigate and develop it. So my preference is to have a few big files, around 3k lines or so each. Grouped by how often functions call each other.
Thank you, but I'm already working on implementing a parser of my own, though I'm using a different approach. :) I was looking for a usable solution until I manage to get mine up to CommonMark compliance.
Zzzzzzz
very cool! I have tried your `gago` package and really liked it, the api was very elegant. don't have an answer to your question – but maybe try in #cgo or #data-science on the gophers slack?
...and where the reference to available template variables?
[removed]
Thanks! Glad you like it. I didn't think about Slack, good call.
BBR congestion algorithm is good, but not every server have it.(What about Windows?) So using UDP seems much more universal to achieve high speed.
Hi, I tried to replicate this and check it out but I couldn't, I am really sorry for this. How about this, you try this software on an online virtual machine? For example, make an account at codeanywhere.com make a ubuntu virtual machine and then do the installation. I assure you the whole installation wouldn't take much time and it would be like using a new computer. It tried it myself and it works fine. My other users didn't face this issue either. Hope this helps. 
The manual. `go list --h` The -f flag specifies an alternate format for the list, using the syntax of package template. The default output is equivalent to -f '{{.ImportPath}}'. The struct being passed to the template is: type Package struct { Dir string // directory containing package sources ImportPath string // import path of package in dir ImportComment string // path in import comment on package statement Name string // package name Doc string // package documentation string Target string // install path Shlib string // the shared library that contains this package (only set when -lin kshared) Goroot bool // is this package in the Go root? Standard bool // is this package part of the standard Go library? Stale bool // would 'go install' do anything for this package? StaleReason string // explanation for Stale==true Root string // Go root or Go path dir containing this package ConflictDir string // this directory shadows Dir in $GOPATH BinaryOnly bool // binary-only package: cannot be recompiled from sources // Source files GoFiles []string // .go source files (excluding CgoFiles, TestGoFiles, XTestGoFile s) CgoFiles []string // .go sources files that import "C" IgnoredGoFiles []string // .go sources ignored due to build constraints CFiles []string // .c source files CXXFiles []string // .cc, .cxx and .cpp source files MFiles []string // .m source files HFiles []string // .h, .hh, .hpp and .hxx source files FFiles []string // .f, .F, .for and .f90 Fortran source files SFiles []string // .s source files SwigFiles []string // .swig files SwigCXXFiles []string // .swigcxx files SysoFiles []string // .syso object files to add to archive TestGoFiles []string // _test.go files in package XTestGoFiles []string // _test.go files outside package // Cgo directives CgoCFLAGS []string // cgo: flags for C compiler CgoCPPFLAGS []string // cgo: flags for C preprocessor CgoCXXFLAGS []string // cgo: flags for C++ compiler CgoFFLAGS []string // cgo: flags for Fortran compiler CgoLDFLAGS []string // cgo: flags for linker CgoPkgConfig []string // cgo: pkg-config names // Dependency information Imports []string // import paths used by this package Deps []string // all (recursively) imported dependencies TestImports []string // imports from TestGoFiles XTestImports []string // imports from XTestGoFiles // Error information Incomplete bool // this package or a dependency has an error Error *PackageError // error loading package DepsErrors []*PackageError // errors loading dependencies } 
FTA: &gt; The godoc for cmd/go lists the [structures available](https://golang.org/cmd/go/#hdr-List_packages) to -f, so I won’t repeat them verbatim. 
I am glad I could be of some help. But I tend to prefer 'gonum.org/v1/plot': it's pure Go :)
I’m very sorry but I have little time available, trying to finish a master degree, and it consumes a lot of my time, and perhaps most of all, my motivation. Besides, (as mentioned) I’m using a windows 10 machine. So getting it to run on ubuntu won’t really solve the problem.
/u/jhadi: This is a good suggestion, and what I'm about to say is not disagreement with paul2048, but elaboration. Telnet doesn't work like a lot of people expect. By default it buffers entire lines before sending them over, which means you can telnet to a port, and type in the whole line of JSON, and backspace and such, and the server won't get the backspaces (which it won't know what to do with), it just gets the line. But when it gets that line, it will also have the \n in it from when you pushed enter, so bear that in mind; it may still be a difference between what you do and what your code does, even if you copy and paste the exact same JSON line into the telnet client. (Many people don't realize this is Telnet's default behavior because when you telnet to a shell, the shell immediately puts the Telnet connection in "raw" mode, which sends all keystrokes instantly. The Telnet protocol, which exists and is a thing, has a command for that. This is also why telnet is such a good default client for line-based connections like HTTP; you still can edit a line before sending it along, since there aren't very many, if any, protocols that will accept embedded backspace characters and process them. Which is a good thing; they all would have broken in the Unicode era.)
https://github.com/go-mangos/mangos Some combination of PUB/SUB (and possibly BUS) over websocket should achieve what you want.
Here's a cute trick I've been using for a while: Does my package have a dependency on external dependencies out of my control? #!/bin/bash PACKAGE="$1" MY_LOCAL_HOST=bitbucket_or_whatever.local go list -f '{{ join .Deps "\n" }}' "$PACKAGE" | \ grep -v "$MY_LOCAL_HOST" | \ grep -P '^[\w]*(\.[\w]*)+/' This is written assuming you're working in a corporate environment where you have some sort of internal Git server. Once you change the first line to your source code host, it lists all the dependencies of the given package, greps out any that match the local code repo, which also strip out things included in vendored directories under your host name, then searches for any remaining packages that have a dot before the first slash, which seems to correctly identify remote packages as all the built-in Go packages do not use dots in their names, and all remote packages must start with a domain name which is going to have a dot in it. It's easy to slip this into a git pre-commit hook or a jenkins job to ensure that you haven't accidentally added a dependency on code that you don't have an internal source for. (I'm not using dep quite yet, so I don't quite know how this interacts with that, but if dep uses vendor dirs it'll be fine.) If you _do_ post straight to github or something, you'll need to modify the `grep -v` to filter out the set of directories you control specifically rather than hitting the entire host. (And as a matter of sanity, I always name my Bash arguments, which is what that PACKAGE= line is. Note that the go tool accepts an empty string as a package name and resolves it as the local package just fine, probably because it's a "string" internally and not a "*string" so it gets resolved to empty string whether you pass in an empty string or leave the argument off entirely.)
Ah, that clarifies a lot. Are you looking to do a one-off extension of the syntax, or are you looking to offer a library that allows users to extend the syntax? Either way, I suspect you'll find that the blackfriday library is basically the bare minimum you're going to get to support CommonMark. The standard betrays its origins and it's more complicated than an implementation of Markdown written to be clear from the get go (rather than try to harmonize multiple existing code bases) would have been. If you're trying to offer the latter, you're going to find that, yeah, it's actually going to be quite the challenge. What seems to a user to be "look, I just want to add a |\_ \_| pair that means to wrap this bit of text in a span that puts a box around it" interacts with all the rest of the grammar; what does `hello |_ world *how _| are* you` mean? Either you hard-code answers to that question into the new extension, or you are going to eventually find yourself backed into an interface where the grammar-extending function they have to implement is basically type Extender interface { Extend(p MarkdownParseTree) MarkdownParseTree } , and you just wash your hands of the consequences after that. (And I hope your Markdown nodes are themselves an interface that can be externally implemented. I'm not looking at blackfriday for this; too much work for a reddit post :) )
https://github.com/go-kit/kit Disclosure: I'm a contributor to the project, but rather than imply the quality is due to my involvement I want to emphasize that I recommend it because of how much I have learned by being involved with the project. I think reading through the closed issues and pull requests (both accepted and rejected) can provide many real world examples of lively (and respectful) design debates that have led to some nice Go packages.
Thanx for the input, you make some good points. To be completely honest my effort is not too tied into golang, but I need it as a golang library to extend an existing product. The actual parsing I'm trying to do is using ragel - the go part is just manipulating the resulting AST, but like you said, markdown is quite complicated - and "not regular enough" - for it to work with the naive approach I'm using. I have parts of the standard working independently, but as soon as I combine them, the results are unpredictable. :) Because the actual parser logic is using ragel instead of go, the library wouldn't be extendable per se, but the state machines a ragel document is composed of, can be extended easily enough, as long as they play nice as part of the whole, which is not yet the case. I suspect I need to break the parsing down into stages, but this would mostly invalidate the advantage of using ragel - which would be a "one pass" parsing.
Ahem, the project page itself says the author no longer has the time to maintain the project and suggests switching to bbolt instead.
I think everybody here already knows about the report card and `gometalinter`, nevertheless it's a good reminder; improved my code again ;-)
Are there any more sources to learn how to read traces? I like this tool and in the YouTube video I can see the immediate value but decoding the output is very hard. Any help?
Well, I can encourage you in the sense that, as far as I know, this problem just really stinks. You're not missing out on anything or something; it just really stinks. Definitely steal as much of the test suite from one of the existing parsers as you can. I recognize that is easier said than done, but it might still be worth it even so, because it's just impossible to work with building a parser without a solid test suite.
&gt; &gt; I don't see the difference between a .env file and a systemd service file. &gt; &gt; I don't either that's why the hardest thing to do is correctly generating those files during deployment, not the actual reading of the file. Which is essentially the same thing. My concerns are: * you already need a systemd service file (or other init system), so why have two places where it's done? * sysadmins understand systemd service files, so why force them to understand where you're .env file is? * it needs to live somewhere, so where is that? Systemd is already well defined * building on location, you need to make sure your `.env` file has the right permissions as well as your systemd service file, so why increase the chances that you'll miss one? I see no benefit of `.env` in production especially since it essentially becomes a config file, so either use a config file or stick environment files into your init script, there's no need to get yet another file involved.
And? It's still an interesting and relevant project. Moreover, you're not really doing justice to what was said: &gt;The original goal of Bolt was to provide a simple pure Go key/value store and to not bloat the code with extraneous features. To that end, the project has been a success. However, this limited scope also means that the project is complete. &gt;Maintaining an open source database requires an immense amount of time and energy. Changes to the code can have unintended and sometimes catastrophic effects so even simple changes require hours and hours of careful testing and validation. &gt;Unfortunately I no longer have the time or energy to continue this work. Bolt is in a stable state and has years of successful production use. As such, I feel that leaving it in its current state is the most prudent course of action. &gt;If you are interested in using a more featureful version of Bolt, I suggest that you look at the CoreOS fork called bbolt. tl;dr: it's more a case of "project complete" than "project unmaintained".
&gt; Definitely steal as much of the test suite from one of the existing parsers as you can. Yes, I will do that, I was thinking about the same thing. I have a couple of tests, but the more the better. :)
Thanks! I'll be browsing it this evening.
One big reason is your arent using and dont want to use the lennartware that is systemd. For example you may be deploying via containers.
Someone is just discovering the Go ecosystem. I suppose it's still good for the newer people.
Then configure them in your container configuration. For example, docker compose let's you set up connections between containers, such as your app container and the database. A `.env` file doesn't work here. If you're using a different init, then set it however the init system does it, such as with FreeBSD, have overridable defaults in your init script and set them in `rc.local`. Setting environment variables isn't new and this doesn't need yet another nonstandard way (e.g. `.env`) of doing it. Use the tools provided by whatever system you're deploying to, which should make it easier for the next person to figure out.
NASA [used Common Lisp](http://www.flownet.com/gat/jpl-lisp.html) for the software on [Deep Space One](https://www.jpl.nasa.gov/nmp/ds1/index.php). People are using [NodeJS on Arduino](http://embeddednodejs.com/). Real time software is a small subset of embedded. Plenty of embedded software uses languages with automatic memory management.
[removed]
Read my original comments, .env is standard if you use the bash built in source. its designed specifically for importing a file of environment variabkes.
[removed]
I use boltdb in my project and it is feature complete, fairly easy to use, and very fast. bbolt just adds features I don't need, so I am very satisfied with boltdb, I don't think you need to avoid this for now at least.
Does active server means https://en.wikipedia.org/wiki/Active_Server_Pages ? I'm lost.
**Active Server Pages** Active Server Pages (ASP), later known as Classic ASP or ASP Classic, is Microsoft's first server-side script engine for dynamically generated web pages. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Good as a reminder, too!
FTA stands for what?
There is a similar answer here: https://stackoverflow.com/questions/41492071/how-do-i-convert-a-go-array-of-strings-to-a-c-array-of-strings It's for array of strings, but it's the same for array of floats. Your Go code needs to allocate (with C.malloc) the return array and copy the Go values into.
The encoding/xml library in Go is, in my opinion, an undersung hero. Let me explain. There are two basic types of XML parser, the DOM type parser and the SAX type parser. The DOM type parser takes a chunk of XML, basically as a string, and converts it into some objects all in one shot. You then navigate the set of objects it represents. I call it "DOM type" because the "correct" default type to present are DOM objects that conform to the DOM object standard, but you can consider marshaling those into another more local format as just another change. There are also SAX-like parsers. These are named after the first (big successful) library that implemented this style. In this style, an XML document is presented to a callback as a series of events; "here's a start tag with these attributes", "here's some text", "here's some more text", "here's another start tag", "here's some whitespace", etc. This allows streaming of the XML with a very small memory footprint (provided that you're not being actively attacked by someone who sends you a 3GB tag or something), but at the cost of being a much more painful way to navigate the document. Go's default XML library is a rather nice hybrid. You're using it in the DOM mode, where you ask the library to parse the entire document in one shot into a single object. The "SAX"-style functionality is available via the [Token method](https://golang.org/pkg/encoding/xml/#Decoder.Token). If you feed an XML document to the parser and use nothing but the Token method to read it, you get a SAX-style parser. But the hidden secret is that you can do both, and the parser does the sensible things. You can use .Token() to read the first opening tag. Maybe you just skip it because it doesn't do anything useful on its own. Then, you've got three basic cases: 1. If you _know_ what the next chunk of text is going to be, and you want to unmarshal it, call .Decode with your target struct type. The XML decoder will decode that element into your struct, and then await your next command after the matching end tag, having only consumed the matching portion of the document. 2. If you don't know what the next chunk is, call .Token() until you get a start tag. At that point, if you want to marshal that start tag, call .DecodeElement but pass it that element. It will then work like in case \#1. 3. If you don't know what the next chunk is, and you call .Token() and get something you "don't want", you call .Skip() on the decoder and it will correctly skip over the rest of the contents of that tag, regardless of what they are. You can mix and match a bit too; for instance, if you encounter a "list" of something you can .Token your way past that, the keep .DecodeElement'ing until you encounter the close tag for the list. (You will need to use DecodeElement in this case, unless your XML format rigidly specifies the number of elements in this list somehow.) You end up with pretty much the best of both worlds; you may have to use SAX-style parsing for the top level of the document, but you retain the convenience of DOM-style parsing for any smaller chunk of the document you can find. While JSON is still easier when it works, I find Go to be one of the better environments to work with XML, and it's not really Go _qua_ Go, it's the API offered by this nice library. You can tell that somebody who has clocked a lot of time with XML has written it. (In much the same way that it is obvious to me that neither the original SAX API nor the original DOM API was written by anyone with lots of experience in XML. After all, how would they have gotten that lots of experience before writing the first APIs? DOM got better, especially with XPath in DOM3; I still think the API is klunky but the worst omissions of the first standard were rectified. DOM1 had some really big holes, IMHO.) You can also flip things around; in the middle of a DOM-style parse, if you have a struct that implements [Unmarshaler](https://golang.org/pkg/encoding/xml/#Unmarshaler), that struct gets direct access to the decoder and can use .Token() itself.
I like to break my "web APIs" into three steps: Marshaling a request into a struct, calling some appropriate method on that struct, and marshaling the result back out to the user. I do not always break these into separate functions in my smaller handlers, but I mentally at least keep track of the line between those things. This does not address everything you mention here on its own, but it helps, because generally the marshaling and unmarshaling code gets to a place where you don't really need to test it much anymore. That reduces the problem to testing the functionality of a particular object, which looks more like conventional testing. However, when testing needs to hit databases to work, well, that's a general problem, isn't it? When I really care, I tend to wrap the database behind an interface and swap out a test implementation of that database, which allows me to test whatever it is I'm trying to do. This is generally useful to me because rather a lot of my code involves making a DB call, then doing a lot of non-trivial logic to it before I present it to the user. If you're basically taking stuff out of the DB and shoveling it to the user, then there really isn't much to test here on an API-by-API basis. So if your unmarshaling into a struct is trivial, and your code is just querying a DB and spitting out the results to the user, which trivially unmarshal back out to the user (`json.NewEncoder(rw).Encode(result)`), there isn't much there there to actually test, no. However, when that is not the case, unit tests can still be valuable. And if you clearly delineate between "marshaling this into an object that represents the request", "performing the request", and "unmarshaling the answer", you might find it arranges your code in a way that either makes it obvious some things can't really be tested, but other things are now both in need of testing, and _can_ be tested. This isn't actually a Go answer; it's something I've developed over the 20 years of web I've been doing. HTTP is big and icky and anything that tries to incorporate it into a test suite is asking for trouble because it's just so darned _big_. The first thing you want to do with a request is clearly and sanely boil it down to what truly matters, and hand it off via some clearly delineated interface to the "real processing" code, so that it is clear how to test that code, and it is clear exactly what that "real" code is taking as input and generating as output. I like the `http.Handler` interface for how well net/http works, but I think it encourages an antipattern of jamming too many isolated concerns into one big lump in the ServeHTTP function.
From The Article
Agreed! [UFTP](http://uftp-multicast.sourceforge.net/) is the most easily available example, made by the New York Times to send files to their remote printers over satellite links. I've used it for transfers from Seattle to Europe at high bandwidths (&gt;80Mbps).
(-2910.579503363819) ^ .02 = 1.17063569 + 0.0736501551 i according to Google You're essentially taking the (50th) root of a negative number, so you get an imaginary answer...... math.Pow returns a float64 so it's NaN
Thanks for your thoughts. I especially like your idea of breaking handlers down mentally into smaller subsections, and focusing testing on the aspects likely to break or be complex and ignoring the aspects that "Just Work" for the sake of unit testing. The fewer tests you have, the less there is to maintain, the faster the test cases finish running, and the less likely you are to have false positives / negatives hidden in the test code.
It appears to be a special case. https://golang.org/pkg/math/#Pow
you are doing this: -(2910.579503363819^0.2) = -4.92942080055 on your calculator
For what sort of project do you use it? 
Apparently the result should be a complex number and should be handled with the mapth/cmplx package. fmt.Println(cmplx.Pow(-2910.579503363819, 0.2)) result was: (3.987985200072245+2.897440848908454i) The result was the same as in wolfram alpha: https://www.wolframalpha.com/input/?i=(-2910.579503363819)%5E0.2 
Here is the actual go file I use it in: https://github.com/deranjer/goTorrent/blob/master/storage.go (This is still a work of progress not functional yet) Essentially I am building a torrent server with WebUI using go and javascript (currently looking at gopherjs as a "replacement" for writing pure JS and increasing compatability between the frontend and the backend). Boltdb is used for "local storage". Essentially when you add a torrent to the engine it only sits in there until the server stops, then is flushed (I am using https://github.com/anacrolix/torrent for the backend and they do not implement persistent storage so need to write my own). Essentially I store the torrent hash, name, date added, and storage path (most likely will add more later) in the database to readd the torrent when the server is powered back up.
I'm doing something like this: (-2910.579503363819)^0.2 And the result is: −4,929420801 And google shows: -4.9294208 [Link](https://www.google.pl/search?q=\(-2910.579503363819\)%5E0.2&amp;oq=\(-2910.579503363819\)%5E0.2&amp;aqs=chrome..69i57.2563j0j9&amp;client=ubuntu&amp;sourceid=chrome&amp;ie=UTF-8) 
Funny project, good luck!
sorry, my bad! I copied wrong.... technically both -4.9294.... and (3.987...+2.8974...i) are 5th roots of -2910.579... guessing that special case (that /u/davedev pointed out) exists because floating point math with fractional exponents isn't very precise, but not positive.
...and where can I read the godoc?
This is correct. To quote the last special case - &gt; Pow(x, y) = NaN for finite x &lt; 0 and finite non-integer y OP's x is less than zero, and his y is a non-integer.
FWIW this is a runnable link: https://play.golang.org/p/gtrf-aP11j
This is incorrect, please stop spreading misinformation about Bolt. bbolt is a fork that coreos created to add a couple of extra features that were outside the scope of bolt. Using bolt as is is perfectly fine. If you want the features coreos added, you can use bbolt.
Just as github.com/go-ki/kit separates its Endpoints...
definitely helped me!
...why ...are ...you ...doing ...this?
Don't read the whole file into memory. f, _ := os.Open(fname) defer f.Close() var head XmlHeadStruct decoder := xml.NewDecoder(f) decoder.CharsetReader = charset.NewReader _ = decoder.Decode(&amp;head)
&gt; 3. No testing frameworks / setups I have ever encountered test the server under actual production conditions. With help of containerization, you can construct your testing environment as same as production, like master-slave setup or memcache as cache layer. 
Im a bit of a scrub when it comes to testing, but I set up a simple - though far from through set of tests via Postman. By running your api against a test db and using Postman to make requests you can verify that most of your routes work as expected. Takes about 5-10 mins a route once you get the hang of it. No its not ideal, and no you arent getting full code coverage. But if youre looking for just good enough coverage, you can set up basic integration across an api in a few hours.
https://github.com/google/go-github Disclosure: I'm a contributor to and maintainer of the project. It's a fairly simple API wrapper, so most of the PR reviews are about making sure things are consistent and correct. But perhaps it can be insightful as an example of the kinds of things one can pay attention to. There are many more merged PRs than open.
Cool- this is essentially what I'm looking for. Shame about the tests etc. in VSCode but from what I've read the VSCode team is looking to improve WSL support in the coming releases.
Fun fact: I think I use/rely on the `go list` command (sometimes indirectly) at least 50 times every day that I work with Go. How about you? How often do you use it?
This is incredibly cool! Nice work! I've wanted to create a similar playground with an HTML5 canvas to work with for GopherJS. One can also imagine a Go playground with a drawing canvas, to make it possible to play with the drawing APIs...
[removed]
You could do something like this: package main import ( "fmt" "time" ) func logsleep(tick time.Time) { fmt.Println("Tick at", tick) time.Sleep(5 * time.Second) } func main() { for t := range time.Tick(1 * time.Second) { go logsleep(t) } } But I don't understand what you try to achieve. If the loogsleep function takes longer than one second all the time, the app will run ut of resources at some point.
I'm wondering why there's a disconnected between the types of tests you write and the "real world" testing you're doing. It's common to uncover edge cases in production, but then ideally you can integrate those edge cases back into your tests to make your suite more robust. For me, writing tests (unit &amp; integration) is a way of automating my task of testing the application. Passing tests doesn't mean your application is perfect, but it does mean that your app works perfectly perfect for the tests you've written, which is often better than nothing. There is a cost/benefit to it though and you don't need to test everything, just the mission critical stuff or things that are too time consuming to check manually.
&gt; Integration tests are fragile and take a long time to set up properly The integration tests I'm running right now cover everything from API to a local mysql instance with a mock DB... including setup and teardown... in about 5 sec. About 250 lines written for setup / teardown / mocking, and now you can ensure every line of SQL in your code actually does what you expect. Somewhere in Code Complete they cite a study that found bugs take something of an exponentially increasing amount of time to fix, the longer in the design / code / test / release process it lingers. If you think you're spending too much time testing, you're in for a bigger surprise when it's time to chase down bugs in production. &gt; No testing frameworks... test the server under actual production conditions I don't test under actual production conditions, I test 10x production levels. Plenty of tools available to do this, it's a problem that's been around for well over a decade. Want to hand-roll something quick and dirty, Ansible + a small python script, and you can test with as many TCP stacks as you can launch instances. &gt; you are actually testing something different than your production environment If your environment is defined in code (SaltStack, Chef, etc), you wouldn't be able to tell the difference between test and production. There are plenty of tricks one can play besides this, as well... &gt; Just because a test passes on the test server doesn't mean your production code is sound. From here to the end of your post, roughly half of it, all I can read are the frustrations of someone who isn't skilled at testing, and has no confidence in his existing tests. Now that I think of it, most of your post reads like this. Signal to noise ratio is kinda low... I can't really speak to that any more than to encourage you to see how other folks are testing their codeand learn a bit about testing methodologies. [The Art of Software Testing](http://artoftesting.com/software-testing-tutorial.html) may be a bit outdated, but it gives a good foundation of methods to consider that will make your testing more effective. If you wanna skip the academics, check out [Google's testing blog](https://testing.googleblog.com/), or Netflix, or Spotify, or Pinterest, [or Facebook](https://code.facebook.com/posts/testing/)... they're all solid resources for technical insights gained while running at scale. 
Actually Wolfram alpha lists all five 5th roots of -2910.579503363819: . One is "-4.9294208005523940 + 0.×10^-16 i".
As a small add-on to the previous two great answers by /u/jerf and /u/icholy , and without knowing how your real code looks like, note that those memory numbers you quoted do make sense, in a perverse way, if you store the entire file + the corresponding Go structs in memory. That would be due to the manner Go allocates necessary memory in default mode. For example, 900 MB = the ioutil.ReadAll + (can't tell exactly but let's just say a similar amount for the deserialized Go structs) = 1.8 GB to 2GB You can have a read here: https://blog.golang.org/go15gc To quote: *The default value of 100 means that total heap size is now 100% bigger than (i.e., twice) the size of the reachable objects after the last collection. 200 means total heap size is 200% bigger than (i.e., three times) the size of the reachable objects. If you want to lower the total time spent in GC, increase GOGC. If you want to trade more GC time for less memory, lower GOGC.* So this sort of explains why you get that 4 GB of RAM usage. I cannot comment on your need to keep all those structs in memory, as opposed to reusing just a pool of objects, because I don't know the requirements. Still, on a dev box, you can definitely play with adjusting the GOGC and see if you can squeeze any memory gains from there as well, in addition to the previously mentioned buffered read instead of ReadAll Cheers
[removed]
Guys, thanks for all the great answers!!!
Thanks a lot for that, this is a honest reply from someone truly committed and dedicated to a programming language like Go. kudos Sir !
Thanks, I'll take a read on those links you sent me
That's another good tip, I'll try that, Thanks !!
I've done this, and it's still slow and nasty. Typically, you want some sort of versioning scheme for database updates, and running that to provision a database and do all the updates from scratch can add minutes to your DB initialization. I won't say you shouldn't make it possible, but maybe it's something more for running more occasionally, perhaps with something like http://dredd.readthedocs.io/en/latest/
Ebiten's amazing! Hope more people start to use it
&gt; If the logsleep function takes longer than one second all the time, the app will run out of resources at some point As long as it's constant, you are fine. If it's slow because it's max'ing out IO then it'll get worse, which will be bad.
That's really useful to know. And a really good idea!
You can use a base64 Decoder (https://golang.org/pkg/encoding/base64/#NewDecoder) and feed it with the json "video" bytes. 
A library I've kept at arms length is https://github.com/cloudfoundry/lager It's a logger library. Instead of printing your stderr/stdout in a human readable format (which you get with the standard library log package), lager prints the output in JSON. I have never seen the benefit of my system printing log files that way. In fact it often makes troubleshooting slower. Not the best example, but a cf library all the same.
Yeah but I don't know how to use that. Need a working example. 
https://github.com/cloudfoundry/clock Helps inject time.
[removed]
Well, it's not that hard really. Not going into a lot of details, but assuming you have a string that contains the base64 encoded video, you can create a strings.Reader from it, then create a base64 decoder from that, something like this: b64data := "whatever" reader := strings.NewReader(b64data) decoder := base64.NewDecoder(base64.StdEncoding, reader) decodedData := ioutil.ReadAll(decoder) decodedData will be a byte[] containing all your data.
Done. Yes, sorry, updating docs is on the list. Thank you!
Loved it when i got my A+ report card! https://goreportcard.com/report/github.com/brianvoe/gofakeit
What I really hate about it is that it doesn't really support multiple verification well because inside of the It function any failing verification kicks out to the caller. The other option is to run multiple Its but then it actually runs the test again (before each) instead of just using the existing results!
.2 isn't representable with a base 2 floating point. The only way you can define exponentiation of a negative number to a non-integer is to convert the exponent to a rational number. If the exponent's denominator is positive, you get an imaginary number. But in base 2, denominators are *always* positive. Something like this can only be done via symbolic math.
Just as github.com/go-ki/kit separates its Endpoints...
uh, yes? you are aware of the fact that every networking lib, device, router does this?
I had a much longer post written up but decided to scrap it because I wasn't quite sure how much value it would have added. A lot of the posts I'm reading it seems -- and this might be a wild assumption on my part -- are from the perspective of developers that need to test their own code. As a dedicated QA tester, writing test automation and designing tests is all I do so this stood out to me (emphasis mine) : &gt; My personal experience is that on the projects **with no formal code testing** This is because each of the points (except 1) you present are engineering problems in and of themselves. Once you've solved the problem once, the time invested could potentially pay off. Of course whether it truly is worth it is probably something you'd have to decide. I could probably finish that full write up with my own experiences if it does apply to you in some way, sleep be damned.
Yesterday I downloaded a Go program. It had a makefile which as soon as I did make started listing all the dependencies it was downloading. It was relatively fast till it reached to the cobra dependency which paused the procedure for 5-7 seconds. Knowing that cobra is a completely unnecessary dependency, that slowdown made me feel sad for the ecosystem.
Before subtests were added go test made it hard to run suites. I can't imagine anyone post go 1.7 starting a new codebase with ginkgo or or one of the junit style runners. 
I still can't understand why tests can't be kept simple, sugarfree and especially: free of any frameworks.
[A little copying is better than a little dependency.](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s)
[removed]
&gt; because in this case I'm not sure what the interface would look like. The interface should only contain the methods that are going perform the data calculations and are needed by other services. Essentially the CalculationsService should take the DataService as a dependency on initialization.
We use it a lot in Kubernetes, and I wish would would kill it with fire.
Thanks! I think Go/GopherJS Playground + HTML5 Canvas API would be another great thing.
I hope so too :-) Thank you for compliments!
Some features that I like: * It is easy to run only subset of tests or skip subset of tests * it is easy to run tests in parallel * it is easy to multiple runs to find a flaky test * GinkgoWriter is a nice integrated IOWriter that hides all output for successful test, but shows for failed. * Test suits is a good way to organize tests. For most cases my setup is almost the same - BeforeSuite, BeforeEach, JustBeforeEach are really helpful. I could implement such features in my projects for bare Go tests, but Ginkgo provides unification.
&gt; Bonus points for a Makefile or some other build tool input. High quality Go packages don't need a Makefile, it's non-standard (doesn't run the same on all 3 OSes), unnecessary (you can do everything you need with the `go` tool), and adds complexity and mental overhead. Here's an example: https://github.com/robpike/ivy
I'm sure you meant this as a rhetorical question.... but you of course know they can be. This project just chose to use a framework, others do not.
I think a lot of coders come to Go, don't buy the "you shouldn't use a test framework" argument and go looking for one. At this point, Ginkgo is popular, and it looks a bit like what they're used to so they go for it. It also has features like - focusing tests - running each test spec in a clean copy of the state to avoid leakage between tests (this isn't a bug; each It is supposed to run separately) I've fallen out of love with Ginkgo at this point; it's got a heavy functional programming learning curve with all the closures and deferred evaluation that it does. I _still_ don't get the vague "assertions are bad" argument in the Go docs. There's enormous value to me in an assertion library like Gomega (which is the library used to do assertions in Ginkgo). It takes care of 99% of my pretty-printing needs after a failure; I don't want to have to write this 10,000 times: if a != b { // fail the test, remembering to log out a and b // return } and I do't want to wrap it up in a utility function; I want a library that has it already!
Thanks!
See `https://golang.org/pkg/time/#AfterFunc`
ohh alright, so I'd have like a server pkg, which listens on a /sum endpoint, and takes a CalculationService as a dependency. The CalculationService has a Sum method and a DataService as dependency and its Sum method uses the DataService to retrieve the data it needs. Does this make sense? 
Sometimes when users comes to golang from other languages, they try to find the tool/approach they are familiar and comfortable with in their language. I like to write the BDD-like tests using the combination of mocha + chai in javascript, so I would like to find something similar in golang, despite the fact it is not the "ideomatic" way.
I agree, maybe sticking to the runtime provided sync mechanism is the best way to keep your program running well.
All sounds good except the server pkg. Please read [SOLID Go Design](https://dave.cheney.net/2016/08/20/solid-go-design)
Yeah, it's not actually named `server` but `http` Thanks for the article, it was an interesting read. By the way, should I implement the server in the http package (and have like a http.StartServer method) or just implement the handlers (so like http.SumHandler) and have the cmd package start the server, using the handlers? 
Structured logging is much easier to index and analyse using ELK stack
I like subtests, I don't think that something like Ginko is necessary at all. But I would argue that assertion libraries make testing much simpler (i.e. easier to both read and write). Sure, you have to take the minute to learn the methods you have available, but with something like Testify the method names are so easy to understand and even guess when you're first starting out. I found that introducing an assertion library, even a super simple one with just 6 helper functions made a big difference to how easy it was to write tests, and then read them again later. This is subjective though, I understand that people don't like to pull in libraries for everything, but in my opinion, the time and mental energy saved has made using at least an assertion library well worthwhile.
100% agree. Assertion libraries are well worth it. I'd just commented elsewhere about this. My experience has been they make tests easier to both read and write.
I get the appeal here. I came from Scala and used Scalatest in a similar way to Mocha + Chai, and it is very nice. Nice reporting on the end, etc. Maybe people would like a more idiomatic implementation of a testing framework like Ginko? Something that lets you run tests in parallel still?
What makes you think that Cobra was a completely unnecessary dependency? Was the program literally only parsing flags, or did it have sub-commands?
Cool! I've only recently started using go list, in a small bash script which runs tests and produces a coverage report. I use it to list all my packages and run any tests inside them. I'll have to play around with the other things I can do with go list tonight. echo "Running tests" cd ../../server/lib set -e echo "mode: set" &gt; allcoverage.out for d in $(go list ./... | grep -v vendor); do parentdir=`dirname "$d"` subdir=`basename "$d"` if [[ $subdir == "tests" ]]; then parentdir="$parentdir/..." go test -cover -coverpkg=$parentdir -coverprofile=profile.out $d else go test -cover -coverprofile=profile.out $d fi if [ -f profile.out ]; then tail -n+2 profile.out &gt;&gt; allcoverage.out rm profile.out fi done 
I don't oppose assertion helpers — they can indeed be handy to reduce some boilerplate. However, what I have found myself doing a lot is to write table-driven tests. Then the time spent on writing the cases will dominate the "test fail"-logic by an order of magnitude.
Compared to the rest of the program, Cobra was a huge dependency and it could easily be avoided. And no it didn't use sub commands.
That totally depends. If you are using the standard library it's usually good to have a mux (that contains all the routes) be created by a package and then use the standard library http.ListenAndServeTLS to serve the mux at the main package. But you could also easily have your own https package that serves HTTPS and use that to start your server in the main package.
https://github.com/kubernetes/kubernetes As for makefiles, it’s true that pure GO projects don’t require them, but when you start adding in JS or docker and integration testing - GO’s built in tooling lacks 
Look at my project - https://github.com/nem-toolchain/nem-toolchain
Maybe I don't understand, what problem are you solving? For external code, we just clone external git repos onto our git server then use submodules which point to our git server. Our build system runs just go build and nothing else.
Plesk is an "high-level" panel that lets you manage services like FTP, mail, DNS without having to use the terminal directly. It works well with PHP because PHP applications are deployed copying the source code files on the server, and then the web server uses those files to run your application. Go is a bit different. You need to compile the source code into an executable file and then run that file in the background, so that it's always up. One way to achieve that is to use a systemd service (on Linux), or to use Docker containers. Plesk is... old, and usually used for "simple" website hosting. It's often provided by the hosting provider so that you can manage your web space easily without messing with the system directly. When you want to manage Go/.NET/Java/Node.js/... applications, Plesk doesn't really play nice. I don't think anyone uses Plesk for applications other than PHP, honestly. I see it as an "obsolete" way of doing things, actually.
It doesn't seem that slow looking at the screencast in the readme. Actually, it seems instant.
Problem with using go for an install script is that it's very long winded. For instance, if you wanted to do a cp or mv, you have to write a lot of code to check the files exist, and that there's nothing at the destination already. With a bash script, at least most of that checking is done for you, and you're bringing tools together, rather than reinventing all of the tools.
Have you checked out https://github.com/apoydence/onpar It lets you do BDD style tests, all in parallel.
That's logstash's job though. Why turn the logs into a human readable catastrophe when there are tools that can read normal logs?
Assertion libraries help convert intent. I prefer https://github.com/apoydence/onpar/tree/master/matchers over Gomega. It's more lightweight.
I hate when you run `ginkgo -r` it doesn't run each package in parallel like go test ./... does. No ones got time for that!
Right, that does make sense then. No sub-commands means you can just use flags for sure. Fair enough.
This looks really nice!
Last time I tried this it didn't work on my gitlab repo. Now it does! I got a D and am now really excited about spending my long weekend fixing this.
I think so. Checkout https://magefile.org - a makefile replacement using Go. Bash is ugly and the error handling is particularly atrocious. Error handling is Go's strength... you always know what commands can fail, and so it's easy to see where your script might fail and so you are forced to think about what to do in that situation. An install script in go will definitely be a larger number of lines than it would be in bash... but it'll be a lot easier to read, and probably a lot less prone to bugs, since there's a lot less magic.
This is neat. Looks similar enough to move Ginkgo projects to this.
[removed]
Go one step further, make it a unit test... I just wrote this yesterday when I found yet another instance of our web API importing a database driver to check DB errors. This one checks just direct imports, because there will always be a transitive dependency... but I want to make sure the API package doesn't directly use the DB driver. func TestNoLibPQ(t *testing.T) { buf := &amp;bytes.Buffer{} cmd := exec.Command("go", "list", "-f", "{{.Imports}}") cmd.Stdout = buf if err := cmd.Run(); err != nil { t.Fatal(err) } if strings.Contains(buf.String(), "github.com/lib/pq") { t.Fatal("The API should never import lib/pq!") } }
Test what's worth testing. If you find a bug, add a test that identifies it to make sure it doesn't happen again, whether that be unit, or functional.
You'd usually send that data to a log aggregator, which would then let you do more advanced things like visualisations of your logs, or presenting the log information in a more readable / searchable format.
So, an important note... that list is of "most imported"... it's counting the number of packages that import a specific library. The problem is that the methodology is flawed (or at least, rewards a specific type of library). Note that in the top 10 there are 4 testing packages and two logging packages. Why is that? Because when a project decides to use a third party test framework or logging library, they usually use it for every single package in the project. That alone makes one project with, say, 20 packages, import that library 20 times. Note that the juju/errors library is listed there. If you look on godoc at who imports it... it's not actually used very much outside juju... it's just that juju is a huge project with a ton of packages that all import it *and* every dev's fork of juju also imports it, which godoc (and likely this tool) count as a separate projects. So now you have juju's 500 packages importing it times 30 devs, makes it look like 15000 imports... when really it's just a single logical project. So, I'd take this with a huge grain of salt.
The loggregator project (logs for cloud foundry) has been breaking a few projects out: https://code.cloudfoundry.org/go-diodes - High throughput ring buffer https://code.cloudfoundry.org/go-pubsub - Tree based pubsub for advanced routing https://code.cloudfoundry.org/go-batching - To create batches of objects before emitting them https://code.cloudfoundry.org/go-envstruct - Unmarshal environment variables into a struct.
If you're looking for a build tool, https://magefile.org is a makefile-like tool that uses Go instead of bash. While it's true that simple projects don't need a makefile (usually this includes almost all libraries), it's fairly common for compiled binaries to need more than go install. Many people like to embed the commit hash and tagged version and build timestamp in the binary, and that involves a command line that is very tedious and error prone to type out each time, so a lot of people reach for a script to remember that for them. There's no one true layout, it often depends on the specifics of your project. The key is to use packages to your advantage to manage separation of concerns. Small packages are ok... big packages (i.e. those with a large API surface) can sometimes get unwieldy.
That has tended to be my approach. I would argue the usefulness of the test is highest when you don't know there is a bug in the first place, but regression testing is definitely nice to have when refactoring. Cheers.
I agree, that is why I am trying to see how people have approached these issues in a general sense. When my manager is using the above points to argue that we don't have time to write tests or maintain them in a resource constrained project, I want to have some good suggestions to counter his points and find a happy medium where I can get a few extra hours per sprint to account for some testing.
That sounds interesting. Do you use input files to Postman to setup the testing?
I usually use testify/assert (https://godoc.org/github.com/stretchr/testify/assert) and it's simple and gets out of your way. It just saves me time/lines in writing tests.
I do actually have a mirrored testing and production database and server. I still think this results in several issues from a consistency standpoint. Until I know of a better way it is the way I personally test APIs. You will always have to maintain a specific set of data in the testing database so you can generate expected results and errors, however the production database is constantly filling up with unique combinations of data that could result in specific edge cases in the larger system. 
Yeah you are right, production bugs can be converted into tests, however in my personal opinion, it would be nice to have tests that would help catch these types of bugs before release. You can't discount the value of regression testing but essentially the real value here would be to identify the types of areas of the software that lead to bugs and then try to prevent this class of error proactively.
I definitely would not consider myself a testing expert, so you could very well be right that my displeasure of testing come from inexperience. That being said, I also know that when tests are well done they do lend value and that's why I am trying to find helpful solutions to some of the discomforts I have dealt with previously. I am looking for some good points to help discount my manager's requests that I cut testing hours from my project estimates. Normally I would argue more fervently against it if we were writing more testable code but often my API's are simply querying a database and converting the response set to JSON, or accepting JSON and writing the values back to the DB. What I would argue would be more helpful would be some level of data validation so that the JSON object coming into the server must live up to a specific specification. Maybe someone has experience with something like this and I will figure out a better way to test these APIs. 
You can check out [awesome-go](https://github.com/avelino/awesome-go) for small to big projects in various kinds of domains.
Also, some examples of "Tester" testing versus "Real World" testing would be something like the following: 1. In "Tester" testing, a programmer tries to submit something like a 3000 character string to your API and determines that the API doesn't handle the string gracefully. You could argue this is valuable information because the application should be able to gracefully handle any input. But if in the real world your users never submit more than 10 characters for that field, is there value in bulletproofing your API to unrealistic data? I would say pragmatically, you probably do want to make your API as intelligent as possible but in the real world where resources are constrained would it be better to focus on the data your users will realistically provide and then worry about 3000 character strings if the users ever need to submit them? 2. In "Tester" testing, your testers will likely use the specification to determine what values are valid / invalid to submit to the system. If the specification happens to be inaccurate / incomplete which happens quite frequently on my current project, then you won't become aware of this until the end users get the functionality and start submitting the values and complain about unexpected behavior. Now you have to update the specification, documentation, and tests to reflect the newly redefined scope. In "Real World" testing, the end users will try to submit the data as intended and identify these specification issues immediately, even if you do eventually write code tests after this phase, this ensures you write them the intended way the first time. 
I don't like it at all. There's nothing idiomatic go about this. It's like trying to cram mocha and chai into go's simplicity, it's just not right.
what's your use case? Just so I can get an idea what you are using it for.
*Learn everything about Golang variadic funcs with common usage patterns.* **What is inside?** * ✪ What is a variadic func? * ✪ When to use a variadic func? * ✪ Slices and the Variadic Funcs * Using without params * How to pass an existing slice? * Passed slice’s spooky action at a distance * Passing multiple slices on-the-fly * Returning the passed slice * Expanding operator anti-pattern * Using the length of a variadic param * ✪ Signature of a variadic func * ✪ Mixing variadic and non-variadics params * Accepting variables types of arguments * Why does not Printf only accept just one variadic param? * Beware the empty interface type * Passing a slice to variadic param with an empty-interface * ✪ Functional programming aspects * Using a func’s result slice as a variadic param * Variadic options pattern example
&gt; For external code, we clone external git repos into our git server then use submodules which point to our git server. That's a good solution. But it's nice to find out that you missed pulling an import in before it goes to the build server, just like I run my linters locally because I'd rather hear about my problems before they hit the build server. It's not like this is some sort of expensive check or something.
The use the SAX side of the API to skip over more tags, and the tune GOGC are very good suggestions. Once you've done those, if you want more, look at a runtime heap profile of the in-use objects and in-use space and you might find some low hanging fruit.
Agreed. This package isn't for everyone.
Learn everything about Golang variadic funcs with common usage patterns. --- **What is inside?** * ✪ What is a variadic func? * ✪ When to use a variadic func? * ✪ Slices and the Variadic Funcs * Using without params * How to pass an existing slice? * Passed slice’s spooky action at a distance * Passing multiple slices on-the-fly * Returning the passed slice * Expanding operator anti-pattern * Using the length of a variadic param * ✪ Signature of a variadic func * ✪ Mixing variadic and non-variadics params * Accepting variables types of arguments * Why does not Printf only accept just one variadic param? * Beware the empty interface type * Passing a slice to variadic param with an empty-interface * ✪ Functional programming aspects * Using a func’s result slice as a variadic param * Variadic options pattern example
You may want buffered IO rather than raw filesystem IO here. xml.NewDecoder(bufio.NewReader(f)) I'm not familiar with the xml decoder, but the json decoder does lots of tiny reads and benefits from an IO buffer. A benchmark will show whether or not it's a performance gain. The memory size of the buffer is trivial.
Use case is as follows: * service A talks to service B (which wraps an underlying datastore), sends a BEGIN request * service B uses txmap, responds to service A with a GUID to identify the transaction that it started (or an error) * service A performs a few operations on service B referencing this GUID * service A performs additional operations on service C, which may or may not support transactions (service A may have to implement UNDO for this service, if the commit fails) * service A commits on service B by referencing the original GUID service C is obviously a question mark in the description, but this is a general use case. service A can issue multiple requests to service B referencing the original transaction that service B began.
Thanks, that's what I was looking for! 
There's far more than 3 OSes that Go supports.
GOOS=darwin, I believe.
awesome, I'll give it a shot. Thanks!
Why? 
&gt; $ go tool dist list will show you every combination of GOOS/GOARCH available, and you probably want: &gt; $ GOOS=darwin GOARCH=amd64 go build
Pretty good write up. Thanks again! :)
Thank you very much! I'm glad that you enjoyed it :) I hope you learned something from it.
[removed]
Thanks!
Your welcome! I hope you liked it.
Yeah, and math.Big is a nice library for handling [that](https://github.com/digitalrebar/provision/blob/master/backend/subnet.go#L407) [binary](https://github.com/digitalrebar/provision/blob/master/backend/subnet.go#L80) [math](https://github.com/digitalrebar/provision/blob/master/backend/subnet.go#L534) so that I don't have to do it by hand by faffing around with byte arrays directly.
BTW if you're using Google cloud this may help for your project https://cloud.google.com/endpoints/
If you prefer the BDD flavor of TDD and are doing go development, that's why it exists. So it's popularity is probably speaking more to the popularity of BDD in the go community than anything else.
You completely underestimate what a Makefile is and can be. Like with good code a well written Makefile does not only contain instructions for the computer but it can also be an entry point for humans who want to explore the project. Check out [the Makefile in my project](https://github.com/dAnjou/goup/blob/master/Makefile). I use it to create builds and packages that I can then release, in fact everyone who has Docker installed can use this Makefile - either by running it or simply by reading it - to build the tool the way it's supposed to be built without even installing Go on their system.
Don't know if it isn't a little bigger than you expect, but I like to see how hashicorp's go projects are structured. Specifically, Consul (https://github.com/hashicorp/consul)
I imagine this is popular with developers having done a lot of JavaScript because it pretty much seems to copy the style of tests from Jasmine. First time I saw it I thought it was inspired by Jasmine.
Tis the nature lifecycle of a programming language. It starts simple and sugarfree and then people start working on layers of abstraction. Eventually those abstractions become so layered that nobody understands it anymore. Then, everyone moves to a new language that has a simple and sugarfree environment. The cycle continues.
Both Ginkgo and Jasmine were written by a people who work at Pivotal. 
I think a lot of these come to people's personality. I prefer my tests to be simple assertions too. Some others prefer a stylized BDD like this with verbose documentation. And check out [Gomega](http://onsi.github.io/gomega/), Ginkgo's matcher library. What da fuk is this: `Ω(ACTUAL).Should(Equal(EXPECTED))`. An actual omega symbol as a function name? Nein danke.
https://blog.golang.org/organizing-go-code See "What to put into a package"
Thanks for the feedback :) I liked your suggestion of removing "Should" and went ahead and implemented that.
And the tweet: https://twitter.com/GoLandIDE/status/926157642158034945
this feels highly unscalable to me, correct me if I'm wrong. Keeping a tx open over an extended period of time (starting the tx on a request and committing on a subsequent request an unkown amount of time later) will block that sql connection from being reused for other requests. The sql connection will only be released back to the connection pool upon tx.Commit. This means the max number of concurrent transactions you can have equals the size of your connection pool. sql connections are normally pretty heavy wait and most servers don't keep a very large connection pool, so this will really limit your tx rate/s drastically. You obviously also don't care about losing transactions in your use case because you're keeping it in memory until committing, so if service B goes down after service A does stuff on service C, ie. just before service A COMMITs, then you lose that entire transaction in service B and everything has to be restarted. This is obviously use case dependent and your solution may be fine in your case, but I would think a better solution would be to have a status column in your database that says what state the transaction is in, e.g. Status.Started, Status.Finalised. That would be a rudimentary 2 phase commit using only a sql db. 
Postgres kind of offers this out of the box. Don't know about other databases, though. I've never actually used the feature myself, just read about it the other day. https://www.postgresql.org/docs/9.6/static/sql-prepare-transaction.html
Please watch the video. You seem to have missed the meaning behind the proverb.
Cool thanks. 
That's it? I had hopes for a cooler name. Oh well, anything is better than Gogland I guess. :)
[removed]
you replied to the wrong person, but I have to agree. I've got a similar use case and I'd never try and keep a transaction around like this. especially not with http requests where I can never be sure when the follow ups will come. It's a state machine in disguise.
Interesting! Didn't know of this. Thanks :)
THIS! ^^ The bigtable query linked from the OP shows how "most imported" is measured, and it isn't even per package, it is per file. I could create a package with 3,000,000 files in it, each of which declares a variable of some type, and imports any package I want that includes that type. SELECT line, count(*) as n FROM ( SELECT SPLIT(content, ‘\n’) as line FROM go_files.contents HAVING LEFT(line, 7) = ‘import ‘ ) GROUP BY line ORDER BY n DESC LIMIT 10 This is not useful data.
Seriously, I couldn't believe the old name lasted as long as it did.
Yep, it seems like AppEngine will import all packages beneath the `app.yaml`, and then it will try importing again with all the explicit import statements in your code, which is why it complains of duplicate imports.
Thank you for your attention. So what would you suggest anything similar to use? If I have more than 100 websites and I need to manage them in an easy way. I know how Go works. I have written some apps on it which engossip.com , turalasgar.pro are one of them. I need some kind of management tool to manage lots of Golang apps the way plesk manages php apps.
I'm not sure if something like that actually exists... there are some process managers like [apm](https://github.com/topfreegames/apm) and [pmgo](https://github.com/struCoder/pmgo), though. Take a look at them. You could also dig into [this big list](https://github.com/avelino/awesome-go) and see if there's something useful there.
I couldn't figure out if it was Go-Gland, which just sounded rude, or Gog-land. which didn't roll off the tongue, and made me thing of gog.com.
If using DNS for potentially internal applications is important to the application, then don't cross-compile the darwin binaries. (shakes fist at the default distribution of kubectl). When you compile "natively" it will use the system DNS resolver which has more features, in particular for "split DNS" on VPN connections.
Yes, I am aware of how evil this could be perceived as. Distributed transactions are not meant to be used in an ideal world. That world is not something that we always exist in, however.
"Keeping a tx open over an extended period of time" -&gt; Not necessarily a big deal. We aren't talking long-running transactions here, just the wait time to talk to multiple services. Depending on if you open a transaction against multiple databases, or only in some situations (and combine it with an UNDO), then there may or may not be tight coupling present (so hanging transactions on 1 db do not tie up another)... This isn't the problem you mentioned, but one that I've run into previously at large scale. (start transactions on DB 1, db 2 hangs, DB 1 then has lots of half-open transactions hanging...) "Losing transactions" -&gt; The service talking to the transaction broker decides what to do if the transaction broker goes away. It can retry against a different transaction broker (high-availability) if desired, or just error out and return an error to the original caller. I've seen no such literature regarding implementing 2PC using status flags in SQL. You would still have to do your own Rollbacks or Undos. I fail to see how that maintains ACID or makes it easier to do this in any way. If you have any such literature that implement things in this way, please send it along.
I said it doesn't run _the same_, that means it has different behavior. There are many different flavors of `make` that all use the same Makefile name.
Using Makefiles for things that the `go` tool doesn't support is completely okay and helpful. I've just seen far too many Go packages that have Makefiles that wrap around the `go` tool to build, install, test. I'd rather be able to do `go test import/path` than figure out what the author invented.
Do you consider kubernetes to be a small to medium sized code base?
&gt;Using Makefiles for things that the `go` tool doesn't support is completely okay and helpful. Then you should phrase things like this differently: &gt;High-quality Go packages don't need a Makefile, it's [...] unnecessary (you can do everything you need with the `go` tool) 
As someone who's been the ELK guy for cloud foundry, it's a pretty awesome feature. Very easy to parse, do aggregations and statistics. A while later I did the same with openshift and docker, it took literally over 30 times more lines to do the same and it wasn't equally reliable
gvm support yet?
I mean 2 application servers running in parallel. The difficulty is to share a room between both servers. 
You can use Postman to set up collections and environments suitable for different projects, then export those files and use Newman (command line Postman) to run your tests dynamically. So I built all the tests by hand first, exported to JSON and now I'm working on getting the input from my go app. From there I can run tests or a build script that verifies tests pass automatically before build.
Ah ok, makes sense, thanks
https://en.wikipedia.org/wiki/Gogland -&gt; name of an island near Kotlin, their programming language, and where the IDE devs are based. One word. Now it's GoLand so two words :) But more important is: do you like it? Does it need anything else to be improved if not? Do you have any issues with it?
If by that you mean if it supports https://github.com/moovweb/gvm then the answer is that: no, it still doesn't. Unfortunately this doesn't seem to be a popular request, as you can see from the tracker issue https://youtrack.jetbrains.com/issue/GO-3031 It would help if you could add your use-case / need for it to the ticket so that the developers understand / prioritize it better. Also, as an fyi, you do not need to install gvm in order to manage multiple Go versions, GoLand supports this out of the box, as long as you point the IDE to where the Go version is, it will add it to the list and you can switch it on a per-project basis. Hope this helps.
I guess nobody had a better suggestion :(
If I'm running IntelliJ with the Go plugin, am I missing much that's in Goland? I'm routinely also developing in Python and Java (sometimes Ruby) and for me, it's nice to have one IDE to rule them all.
You could have a user poll/contest on your site. Would be fun for your community to pick the name. That is, you could keep Goland or try that ^^^.
That's exactly what they did.
If you are running IntelliJ Ultimate 2017.3 EAP then no, you are not. If you are on 2017.2 or older then yes, you are. Look at the link and you'll see the features and you can compare them with your current version. The Go support follows the same model as the Python, Ruby, PHP, etc model where IntelliJ Ultimate gets the same functionality as the dedicated IDEs at the price of being a bit heavier and less focused on a particular language. GoLand on the other hand has a cleaner UI, and some indexing speedup due to better control over the process.
&gt; I am looking for some good points to help discount my manager's requests that I cut testing hours from my project estimates. That's a whole different ball game than what you asked in your original post. Good luck with that...
[removed]
I love to run specific table driven test with the green bullet (like classic test). 
Thank you for the suggestion. I've filled in https://youtrack.jetbrains.com/issue/GO-4811 to track it. Meanwhile, you can edit the run configuration via Run | Edit Configurations ... | select the Go Test configuration you want | pass the subtest name to the go tool via Go tool arguments parameter.
Thanks, edited my post. Hope the new phrasing is better.
You're getting downvoted but 1/ shell scripts are transparent 2/ shell scripts are simpler because that's what they were made for.
I would not call the kubernetes codebase good, the project is, the application itself is but the codebase quite clearly has loads of different coding styles, python style, java, c. It's a bit of a mishmash.
The same reason logrus took off. Go was newish at the time these libs came out, and a lot of people were bringing their heavy expectations for heavy frameworks from other languages, primarily the rspec crowd from ruby/rails (I admittedly was one of them)
Excellent, thanks.
Aww I liked "Gode"
Except they would have insulted the French speaking users again with that name.
that graph that shows up every few slides in this presentation seems totally made up
It follows the pattern now: Py+Charm, PHP+Storm, Ruby+Mine, C+Lion. Currently Rider (C# IDE) stands out.
It is. It's an approximation on how much perceived effort goes into things
A quick fix for the name! I was expecting something cool, like the C# IDE name.
any idea when the stable release will roll out?
We all choose tools that help us achieve results. No two developers or teams or projects are alike. All use cases are different. Any extreme mantra (ie. "Never use a test framework!!!" or "Always use an assertions library!!!") cannot possibly be correct in every situation.
Interesting read. Shame on anyone running any kind of gambling game off of math/rand though. Just asking for people like OP to be evil with it. I once had a pretty cool proof of concept making an adapter to use crypto/rand as a math/rand.Source, so that I could use the convenient IntN type functions with a truly random source. Worked pretty well, although I didn't really evaluate it thoroughly.
I've set up something like that using a redis instance as the backing store for data. Each webserver can subscribe to events and relay them to websocket listeners. 
The formatting is nice, but the real gold is in the rewrite rules. They're simplistic and probably slightly buggy right now, but they still let you do things like replacing a function name in the template without accidentally replacing a string or part of the text that is not a function. 
Well, that's marginally better :)
The author of the article looks like Bill Gates.
I use it solely to run tests on change (with normal go tests). `ginkgo watch -r` is the best test runner.
Any examples of doing indented templates (loops, ifs, etc)? And subtemplates?
I briefly looked at it but I did not go with it as it seemed to be tied to the google platform. I prefer to not get vendor locked. Thanks though :)
Goku?
that's more application level 2PC if you want to keep track of all transactions and their states, also probably a naive approach but can be suitable for lots of use cases. As ligustah mentioned below Postgres has prepared transactions to do it at the db level and I just checked mysql supports XA (https://en.wikipedia.org/wiki/X/Open_XA), https://dev.mysql.com/doc/refman/5.7/en/xa.html
**X/Open XA** In computing, the XA standard is a specification by The Open Group for distributed transaction processing (DTP). It describes the interface between the global transaction manager and the local resource manager. The goal of XA is to allow multiple resources (such as databases, application servers, message queues, transactional caches, etc.) to be accessed within the same transaction, thereby preserving the ACID properties across applications. XA uses a two-phase commit to ensure that all resources either commit or roll back any particular transaction consistently (all do the same). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
&gt; Error handling is Go's strength... you always know what commands can fail First time I've heard go's error handling summarised like this, I like it.
Simply put Go is kinda special purpose (which is what I think modern programming languages should be anyways). This truth hit me when I searched for a dominate Go web development framework a la Ruby’s Rails and found none. Turns out Rails is needed because Ruby doesn’t have web development primitives or sufficient ones and so Rails augments the language significantly. Go, on the other hand, spots production-ready implementations of most functionalities you’ll need, which means people reach for the language all the time. When I learnt this I was both excited and frightened 
As stated in the article, hopefully early December this year. 
My preference was Ghost so that I can install Ghost and Rider IDEs... 
Great work! One question tho - why share doesn't generate link next to button but in URL? Similar to play.golang.org. Right now feels pretty odd.
I doubt it.
Google it :) 
I already did. =))
So pricing will be 89€ / yr? 
In the first year, yes. Then it drops to 59/yr in the third year and you can also see if you can qualify for the other discounts available https://www.jetbrains.com/store/?fromMenu#edition=discounts
hate the name, hate the price.
Ah, this is just a UI problem, and I can fix the similar way to play.golang.org. Thank you for the feedback! 
There's some use to "Expanding operator anti-pattern", especially as your application can be dealing with distributed systems messages and user inputs and passing along data which isn't known at compile time. If you'd type it out like that specifically, then yes, out of those two examples, only the second one should be used. Nicely done article :) I appreciated the section about "Passing a slice to variadic param with an empty-interface" the most, as it really underlines a less understood language feature (and the updates for Go2 ;))
Answer to the 1st paragraph: You’re right about the anti-pattern, however, I want to prevent the gophers abuse it. If you have a simple example, I can add it to the article. 5k views so far, so anyone can benefit from it. And the 2nd: Thanks! :)
Sub templates are almost never going to be able to be replaced into reliably, because you can pass them anything as the data. The code will still work, but you'll have to craft your replacement specifically to take into account the sub template. Range and with statements will not work correctly right now (i.e. {{with .Foo}}{{.Bar}}{{end}} won't get picked up by a replace of .Foo.Bar) however this is fixable and that's next on my list. There's unfortunately always going to be edge cases that don't work correctly if you get too fancy with your template, because it at least partially depends on the data you pass into the template. Templates are basically like an interpreted programming language... You just can't perfectly analyze them statically.
Done.
/u/dlsniper thank you so much for all you do for this community, and your work with Goglang now become GoLand!
&gt;Go-Gland In French, that means "Go Dickhead". I wholeheartedly support changing the name to (just about) anything other than gogland :'D
Not the same spelling. You're thinking of "god".
Actually just found a major bug in subtemplates... they don't format correctly, due to how they're parsed. Looks like they're not kept in the normal parse tree.. feh. This is gonna be a PITA to fix.
[removed]
Looks nice! Could you maybe add an issue for a "stable 1.0 release" or something? Then I can subscribe to that and integrate it in vim-go when it's ready.
will do! Great idea :)
https://github.com/gotpl/gtfmt/issues/2
Its actually not if you read my full post. Note the last sentence, probably missed it.
I made a change so that it'll bail on templates that use subtemplates, so it won't mess them up, but it won't format them either :/
I really enjoyed that read, I always wondered how to use the 3-dot syntax ;) (I'm too lazy to read the full language specs). Thanks for the article.
Sure, it would be better with pure Go, but it is an issue of what can be done with different packages, and matplitlib is one of the big and capable ones. And then there is this issue: https://imgur.com/BMUakZB A very ugly "feature", in my opinion(!).
I'm happy that you've liked it! That's the main reason behind my articles: Find the concise and easy-to-understand information in a single place. I think that I'm reaching that goal :)
From a quick look of it, it seems that gtfmt uses a copy of the lexer/parser from go template (https://github.com/golang/go/tree/master/src/text/template/parse), with some modifications. I think I would have used a submodule, but maybe it is a bad idea. Do you plan to keep the parser separate (not saying this is bad, just curious)?
How long have you been using this kind of setup? Are their aspects of it that you don't like or find cumbersome? I have been using Postman directly to inspect and test my APIs as I build them but this seems like a pretty cool solution to get some automated testing in place.
I wrote an article about this last month: https://blog.learngoprogramming.com/about-go-language-an-overview-f0bee143597c
I've actually never used git submodules, though I understand basically how they work. Yes, ideally, I'd keep up with changes to the stdlib. If someone wants to help out with that, that would be awesome. Otherwise, I'll find some time at some point to give it a try myself.
I think I was close to having this epiphany myself, you just saved me the time of putting it together. &gt; When I learnt this I was both excited and frightened I feel very similar. Also I guess that means being proficient in multiple languages will be even more necessary? You'll just pick the language you need for the job you're doing, instead of trying to stuff all functionality into one language like Javascript or C++.
Projects like this should consider moving pictures in their READMEs lower down as I, for one, tend to immediately close the browser's page rendering that README and forget about the project as soon as I notice such a picture.
Yeah, I'm not even sure I'm all that crazy about the functionality either. I've tried the EAP a couple times and it really doesn't add a huge amount over what I can already do with Vim. In fact, debugging actual worked better in VSCode. It's weird, I usually love JetBrains products, but first CLion and now this have disappointed.
[removed]
/u/natefinch is it intentional you're not [watching](https://github.com/gotpl/gtfmt/watchers) your own repo?
The commenter has a point. I'm on mobile and the only thing GitHub showed me was the photo. I have to click on the Readme to continue reading. 
I think one thing that would be very helpful is to provide some information and/or compare this against other existing solutions in the ecosystem to illustrate why to check this out over. For example comparing to https://github.com/h2non/gentleman 
At least he's not using any emoji ¯\\\_(ツ)_/¯
Agreed. Especially if the languages cut across paradigms. It helps you avoid language wars. And your mind expands from shifting between completely different ways of thinking and solving problems
[Very unfortunate naming.](https://www.h5l.org/)
Nope :) Thanks for reminding me. It's silly that github doesn't auto-watch repos you make yourself (presumably because it's in a separate org).
"I don't test under actual production conditions, I test 10x production levels. Plenty of tools available to do this, it's a problem that's been around for well over a decade. Want to hand-roll something quick and dirty, Ansible + a small python script, and you can test with as many TCP stacks as you can launch instances." I agree you can script this to blast the hell out of your test database well beyond the levels of production. My point centered on the fact that its difficult to manage this when you end up with 3 or more development environments with different schema because by very nature production, testing, and development will never all be in the same state at the same time on large scale projects. For any record you have in your testing database, your expected test results will have to reflect the results of that record being included. This often means you are either using dummy test data which is not reflective at all of real data, or you are testing a subset of data conditions that could exist in your application but likely not that 14 million record legacy production table you are forced to support and sometimes goes down because of 'network issues'. This doesn't even remotely include issues that could be the result of tests failing simply because they are on the test server and the test server has a hardware issue that is not present on the production server. Also you mentioned you use mocking which by its very nature means you are not testing your production code. You are testing your mocking implementation. What happens if a developer on the team writes a mock that doesn't properly represent the feature it is mocking? What happens if using the mock in your test is actually hiding a bug you would have found by using the production implementation directly? In both cases you are being impeded in your flow, and the end result is the code compiled in your production binary is not tested. What if you overlooked one thing or somebody set an environment flag differently between your production and testing environment and the binary is compiled slightly differently on one setup. Yes that is a pessimistic view, but the reality is if you don't consider things like this you can get bit by them as I have on previous projects where the lead didn't consider these types of eventualities. Hope you don't mind my challenges, as I would like to learn from you if you genuinely think these are solved problems. 
I think you have been very example-complete, but I just wanted to put a distinction between convenience and practice on this "antipattern" thing. Generally it boils down to this - if inputs are created by the programmer, you should be using `...string`, and if they are created outside of the code (ie, by parsing json, [Event.Arguments from go-ircevent](https://github.com/thoj/go-ircevent/blob/ef65ae61a32a5100a9f50f3eb74fc4266b716239/irc_struct.go#L65) or something along these lines), then you should be using `[]slice`. If you want to unify these requirements onto a common API, most likely you'll expand some slices to variadic, because programmers tend to write code for themselves first. As a programmer, writing code with variadic functions like `fmt.Printf` is easier than providing a `[]string` for a non-variadic one. And then it's all about what's easier for you to write. Using `strings.Split` is not an uncommon crutch to preserve some readability of inputs. Consider `exec.Command` which inevitably ends up as some form of `exec.Command(cmdName, cmdArgs[1:]...)` versus what people would be used to from the shell. If you wanted to make a distinction between creating a variable with the slice and then expanding it into the variadic form vs. inlining that slice, then it really shouldn't make any difference between the two, so the statement of it being an anti pattern is false, as it's a valid design choice. In an unrelated sidenote: while grepping for `...` in my code and vendored code i came across [this thing](https://github.com/golang/sys/blob/master/unix/zerrors_linux_mips.go#L2222). Did you know you can do this: var x = [...]string{ 1: "hello", 3: "world" } What's the result? It's an array with the max length of the highest index. In the example here, it produces a `[4]string`. Maybe I drifted off topic a bit, but I learned something new, so that's a win.
Take a look at Buffalo, it might suit your needs. I have never used it but it aims to be similar to Rails. https://github.com/gobuffalo/buffalo
Too late. I settled into using the language as much as possible and only installing libraries for certain functions I need. 
[Extremely so](https://glassechidna.com.au/heimdall/).
Thanks! &gt; If inputs are created by the programmer, you should be using ...string, and if they are created outside of the code (...), then you should be using []string. Yes, that would be a good addition to the article. Do you have a medium account so I can refer you in the article if you're ok with this too? &gt; Using strings.Split is not an uncommon crutch to preserve some readability of inputs. I didn't get this part. How is it related? &gt; Consider exec.Command which inevitably ends up as some form of exec.Command(cmdName, cmdArgs[1:]...) versus what people would be used to from the shell. There are cases where you can't know how your API (*as in here with Command*) will be used. So, how would you make that distinction between variadics and slices? It seems like Stdlib leans on variadic much more to implement `Command` as this. &gt; If you wanted to make a distinction between creating a variable with the slice and then expanding it into the variadic form vs. inlining that slice, then it really shouldn't make any difference between the two, so the statement of it being an anti pattern is false, as it's a valid design choice. All of the anti-patterns can unleash from being an anti-pattern. It's an anti-pattern in the example from my article. But, couldn't be an anti-pattern for other situations. I disagree that it's a false argument, we need to ask: In which context it's false and we're asking that question here very properly and also answering it. Very good. --- &gt; Did you know you can do this: `var x = [...]string{ 1: "hello", 3: "world" }` Yeah, I knew that from here the spec: ``` // vowels[ch] is true if ch is a vowel vowels := [128]bool{'a': true, 'e': true, 'i': true, 'o': true, 'u': true, 'y': true} // the array [10]float32{-1, 0, 0, 0, -0.1, -0.1, 0, 0, 0, -1} filter := [10]float32{-1, 4: -0.1, -0.1, 9: -1} ```
[removed]
Kinda pissed about the product plug at the bottom, given who wrote the article. It was entirely out of place, and feels like it cheapens the whole article.
The debugger is the same as in VSCode, both use Delve. The problem is that Go itself is problematic and that's what's affecting your debugging experience regardless of editor you are using. &gt; Yeah, I'm not even sure I'm all that crazy about the functionality either. Can you please detail what problems you've encountered with the IDE or where it could do better? Thank you.
`go run` is useful for running things quickly, but it isn't the best method for deploying an application. You will want to run `go build` to create an executable file that you will run. This way, you won't have to recompile everytime you run your program. You will have to run `go build` every time there is a code change. As for keeping a process running, for a real production app you will want to look in to using an init system. Assuming you are using CentOS 7, that would be systemd by default. If you don't want to go that far, look in to using screen or tmux to keep it running in shell when you log out. Sorry for the brevity of my reply and my lack of links, I'm ok mobile now. All of this should be easily searchable on Google. Happy coding!
Run this: nohup go run hello.go &amp; https://en.wikipedia.org/wiki/Nohup
Thank you! But I'm doing very little. The developers of the project and the community are doing the work on this. I just share the news ;)
Unfortunately that was an unfortunate naming, the developers did not intended to have that outcome.
My advice would be to switch to nvim-completion-manager from YouCompleteMe. Then, tap into the power of https://github.com/sourcegraph/go-langserver. You can use it by installing: https://github.com/autozimu/LanguageClient-neovim. You're tooling will then be on par, if not better than VS Code. There are other Language servers for Python, JS, etc...I recently made the switch and it makes a big difference. I'd also suggest switching to ALE if you currently use syntastic. However, if you're happy with VS Code, then ignore my comment and keep on rocking.
Still, you've been an important figure from the plugin to the EAP's, and you've been helping a lot of people in the golang-newbies channel as well. Kudos!
It seems like go-langserver is feature complete. How stable is it? 
same here, I've been a phpStorm/WebStorm convert since forever, and usually a huge fan of jetbrains in general. This one just doesnt do it for me, compared to VSCode.
&gt; This one just doesnt do it for me Can you please explain why? That way actions can be taken to improve it. Otherwise it's not really helpful
sure, would be happy to. being short here since im on phone commuting. i wrote up a list of gripes that i shared with our dev team that i can post 
Problem with training models in Go isn't training models... It's trying out a million things until you find what works best. Python is an ideal environment for exploring machine learning models, and once you know what you are going to do, implementing the training and deploying in Go is much better.
Being a heavy vim and vscode editor, I decided to supplement all vscode functionality into vim to just stick with one. Have you got a git repo of your dots that I could have a look over, all of these plugins are new to me so it would good to see what else I'm missing out on aside from the popular stuff.
My version of the same idea: https://github.com/carlmjohnson/pomodoro I recommend using it with https://github.com/variadico/noti to give a pop up alert when it finishes.
https://github.com/beigebrucewayne/init.vim/blob/master/init.vim
&gt; i wrote up a list of gripes that i shared with our dev team that i can post Yes, that would be nice to be shared also with the IDE dev team since they can take action on that ;) Feel free to either send it to me, https://youtrack.jetbrains.com/issues/Go or share it here whenever you can. Thank you for your help in making GoLand better.
[removed]
Can it do completion yet? Last time I checked that wasn't supported and sourcegraph seem to show no interest in implementing it.
You can also put Linux processes on a background thread by ending the command with '&amp;'. The caveat is that the process is still part of you putty shell, so when you close the shell it will close. And the useful command is 'nohup' (no-hang-up) So if you're looking to boot it up one-time (/u/partkyle mentioned adding it to init.d, which is the permanent solution), you can either `nohup git run &amp;` or build the exe and `nohup ./server &amp;`
I also made [one of these](https://github.com/SeerUK/assert), because I wanted something pretty tiny and lightweight. At the moment I'm using Testify at work though. People will bash on you for making this package probably, but oh well. I'm personally not a big fan of the function names you've chosen, but each to their own. You should add some tests though.
lightweight is vim with go plugin. best and free is vscode. 
Hey folks, developer of CertStream here. You can read more about the motivations and implementation behind this project by visiting the announcement page (https://medium.com/cali-dog-security/introducing-certstream-3fc13bb98067) on my company's blog. I'm also happy to field any questions anyone may have! 
No problem. I think they do it only if you have this checkbox checked in https://github.com/settings/notifications: http://instantshare.win/e2e53wdkupn6.png
Second that. Vscode is amazing for Go.
Sweet, thanks, I just turned that on. Definitely the default I would expect. 
So I'm pretty new at using go, but what's the advantage of using this instead of using the included default client? I know about the timeout issue with it, but besides that, What is the default client lacking?
GoLand - https://www.jetbrains.com/go/
That won't be free by December... That was what I was using but now need to swap.
Yep, these are the ones I use (vim + vim-go for quick stuff, and vscode for any more serious stuff, refactorations, etc ... going more and more towards using vscode more). The only third alternative I could imagine using is LiteIDE (https://github.com/visualfc/liteide), which works really well, and might be an option for someone not used to vim, and still wanting something faster than vscode.
I've been using Liteide for a long time now. It gets the job done. I can't say how it compares to other options though, as I have not tried any, apart from vscode. The Go integration in vscode was very rough around the edges at the time. I can't say how it holds up now.
Forget all about barriers and volatile. B can observe what was done by A if there is a happens-before relationship from A to B.
emacs
I always made my day with sublime text (open on a folder) + gosublime + an opened console. Go is so simple that i don't need too much hints.
I haven't done a whole lot with VSCode lately. What is vim-go missing from what Code has? (I want to know what I'm missing out on)
I don't really have an answer that isn't already posted, but just to note a thing, there are many ways to get free or discounts for Goland. JetBrains is offering free license for students and open source projects, as well as discounts in some cases.
It's not lightweight at least.
Could try looking into Apache Che, there might be a workspace for go setup.
After more than 2 years with Go as our primary language - VSCode is amazing by a large margin compared to Atom, Goglang (now GoLand) and Sublime. More techie devs in our team use Vim too.
Vscode is pretty amazing. Dropped Atom like a bad habit. I use IntelliJ for Java and I dig the simplistic interface the most.
I really like this idea of go scripts without the boilerplate required by larger programs. The only bit I'm not keen on is the rather magical error handling in the original examples, which seems to me to violate the 'Go statements should be equivalent Neugram statements' and Minimize novelty rules here. I'd prefer something simpler and explicit like a new built in function check which panics if an error is encountered, so that the script can either do: f,err := os.Create("hello.txt") check(err) or f,err := os.Create("hello.txt") if err != nil { fmt.Printf("oops, file didn't open") } eliding the errors and panicing on error makes it impossible to ignore errors, just warn the user or respond differently, and hides them for beginners. 
I'm trying to think of a use case where I would need this. The example in the readme didn't convey to me how this would benefit projects not utilizing this feature
So it's basically a list where multiple indices have the same value. How is it better than just doing that?
ACME.
&gt; VSCode is amazing by a large margin compared to Atom, Goglang (now GoLand) and Sublime. Can you please explain what makes this difference for you?
liteide
+1 vim do not be lazy. Linux+VIM=WIN
In situations where the underlying database supports you, I'd recommend you make use of it. Only one of the data stores that I'm dealing with supports transactions, but for one record processed in my system, I may write to several different database products (not all of which would be SQL) So, XA is right out. A short description of what I might choose to apply txmap for (the 'Last Resource Gambit') is here: https://access.redhat.com/documentation/en-US/JBoss_Enterprise_Application_Platform_Common_Criteria_Certification/5/html/Administration_And_Configuration_Guide/lrco-overview.html
not OP but I also moved from Atom to VSCode, main reason was that when I upgrade Go versions, Atom was a mess to get the new plugins I needed, half the setup worked, when I moved to VSCode, it detects the new Go version and offers to download all needed plugins, without me doing anything to trigger it. I also like the way you override user settings, you have a dedicated file that overrides, instead of having to go all over diff screens (maybe Atom also has it, but it was not the default and I really don't want to spend days/eeks learning an editor, I have work to focus on and vs gets that)
Thanks man, looks like vscode will be what I use. My program is a web site so I use some HTML and CSS (and gopherJS) for the frontend and vscode has a lot of functionality for that built in, which a more lightweight IDE might not have.
Similar case for me, vscode for Go (and markojs) and intellij for Scala
I'm not the thread starter but thought I would pitch in: Thanks for all the work you do on GoLand, it is a good product, I like the look of the interface (so far at least, but I was used to it) more than vscode, although I think it might be easier to find things and set up tasks especially in vscode, it was a little bit of a pain (for me personally) to get tasks setup correctly in GoLand. I'm not an experience enough programmer in Go especially to give you more feedback than that, sorry.
Just started using it (vscode), but so far the Go Integration seems on par with GoLand, think I'm taking that over LiteIDE, thanks for the input though.
Where did the white beard image come from?
Yeah, it got me for a second...
Please no. How is your pinky not not tired.
Yeah vscode works good for me. My only complaint is you have to save the file before it detects errors or shows errors fixed. But for the price of free... 
I am so terrified of leaving Atom for VSCode. Can you tell me it'll be OK?
About 2 months, so it's pretty new for me but I am building all the testing for a few repos from the ground up, so there was a lot of experimentation *cough* failing *cough* in my first iterations. Newman can directly integrate with a few automated testing platforms as well which is what I'm trying to steer my workplace towards. I don't remember the exact references I used, but this looks like a good starting point: [http://blog.getpostman.com/2015/09/03/how-to-write-powerful-automated-api-tests-with-postman-newman-and-jenkins/](http://blog.getpostman.com/2015/09/03/how-to-write-powerful-automated-api-tests-with-postman-newman-and-jenkins/)
It's free for open source projects/student. Would you not qualify?
Back when I was still using PHP (gag) I applied for a PHPStorm license since I was just writing in Notepad++ at the time. They denied my request since my commit activity wasn't high enough. Since I have a full time job and life I sometimes go a long time in between commits to github so don't want to go through that again. In my project's current state they will reject my application again for this project.. here are some of the requirements: -Your OS project's community is active. This means that you have recent activity in your newsgroups or forums. -Your OS project is in active development for a minimum of 3 months. (and they MEAN active, that was why I was rejected before) -Your OS project has a website including either a regularly updated News section or links to social network account(s) where project updates are posted. -You release updated builds on a regular basis. 
or perhaps just IntelliJ IDEA that have a community license and supports Go via a plugin?
VSCode is pretty great, once you set up the lukeban (spelling?) go plugin, everything works, including debugging.
Maybe I'll give that a shot, trying out vscode and so far it seems to work well for me.
Yes, a Buffer is just what you said: a struct that contains a byte slice (probably) and metadata. It also gives useful functions for buffer operations, like you said. It's nothing super special; just a nice abstraction built without any fancy tools like you'd find in less elegant languages for less civilized ages ;)
Use spacemacs. Seriously. 
Use the source, Luke: https://golang.org/src/bytes/buffer.go#L17
I just gave this talk at VimConf in Tokyo, Japan. Let me know if you have any questions, happy to answer them :) 
Because it's now the size of a tree trunk.
The Go plugin for IntelliJ is amazing.
That's the beauty of Go. It *prevents* this type of soul-destroying behavior. The Rubyists/Pythonistas (and, to a lesser degree, the JS people) will bang their heads trying to create their DSL's and sugared layers and 12 different mock/assertion libs, and eventually - get bored, frustrated, and give up. And they won't be missed. 
Hey, The link is in my bio. :)
Because Buffer has Read, Write, ReadFrom, and WriteTo, it implements several of the useful [io](https://golang.org/pkg/io/) interfaces (Reader, Writer, ReadWriter, ReaderFrom, WriterTo), which means that you can use it with all kinds of core and non-core functions that deal with those interfaces. If you wrap it with ioutil.NopCloser it can also do Closer, ReadCloser, WriteCloser, and ReadWriteCloser. It's "just" a type to adapt a `[]byte` to all of those interfaces. Although if you look at the source as /u/earthboundkid suggests you'll see that it's not exactly trivial.
I have been using LiteIDE for years.. hard to beat IMO. It's super fast, it does not require fiddling, it has great options for building different configurations of your program, it just works.
None of the linked projects is a Go library, so there is only little chance of confusing any of the three projects. 
Looking into the trace output always gives me a CSI like feeling. Its just amazing.
Buffer is a high level idea. One way to implement one is to use a byte array/slice as the data container. Your question is similar to asking “what separates a vehicle from a motorcycle?”
"How do I use this? Ah... the usage section. Reading... wtf is a backoff? WTF is a EXPONENTIAL backoff?" Where is the simple usage code examples?
You can actually enable live errors. IDK how the setting is called though, just look in the "Go" section of the settings 😉
did you ever consider moving to a language server architecture, ie. combine efforts with vscode-go? Neovim has full support for language servers, and it seems at this point vim has partial support for language servers (https://langserver.org/#implementations-client). IMHO language servers solves a big problem in reducing massive duplication of effort for every code editor/IDE to support a language
Seconded. Takes some getting used to, but it all integrates wonderfully, makes tooling really simple, and makes you write better code IMO.
The setting is `go.liveErrors`. Example usage: "go.liveErrors": { "enabled": true, "delay": 500 } 
I used LiteIDE and switched to Visual Source Code. LiteIDE is good. It's just that VSCode has a few convenients functionalities missing in LiteIDE. It can also be used for all other types of files. 
Fancy arrays, just like integers are just fancy bits (etc). :-)
yeah... at first I didn't like that either. but it grew on me: - this way you still see the important data points that are close to the origin of you plot. - this way, you still see the base of your histogram, without any overlap with the axis line. - https://raw.githubusercontent.com/go-hep/hep/master/hplot/testdata/h1d_plot_golden.png - https://raw.githubusercontent.com/go-hep/hep/master/hplot/testdata/s2d_golden.png perhaps I have had a bad case of Stockholm syndrome...
Enjoyed the article! Cool that you mentioned trace too.
Awesome article 👍 
[removed]
It's also not maintained since 2015.
How would a Buffer with Seek work? In a normal Buffer, reads are one time only, so it would be pretty different if you could seek too. 
I haven't had time to read through your slides yet but I just wanted to say thanks so much for your work on vim-go, it's awesome! Oh and Digital Ocean isn't too shabby either :)
Good choice. I just use VSCode for everything everywhere*. An amazing IDE if one can get over it being essentially a glorified web-browser :D But it do look and behave entirely the same on all platforms - and provide a great workflow for just about anything through extensions. speaking of, the Go support is just the best of the current crop of IDEs. On more starved for resources systems, like say single-core Raspberry Pi models or headless servers, have a look at micro. A terminal/CLI editor not only written in Go and providing very good Go support, but more important, provide a modern user-interface as in familiar keyboard shortcuts and ability to use the mouse to select text. *) Well, nearly true - for larger C# codebases I still boot into Win10 and fire up VS2017...
Like a file rather than like a pipe. Reading moves the pointer but doesn't drop the data. Which, yeah, is another reason you wouldn't want to use it most of the time.
&gt; Neovim has full support for language servers No it doesn't :) but you can use the vim-lsp plugin which supports vim and neovim and then use the sourcegraph langserver (https://github.com/sourcegraph/go-langserver) which btw is the one used by vscode-go
From the docs: {{block "name" pipeline}} T1 {{end}} A block is shorthand for defining a template {{define "name"}} T1 {{end}} and then executing it in place {{template "name" .}} The typical use is to define a set of root templates that are then customized by redefining the block templates within. 
Ok well that's what I meant, you can use langservers in vim, kinda irrelevant that you use a plugin to do that. I just want to know the OPs thoughts on it
I was mostly trolling but this correct I wish every pl has his pkg system and every pl interacted in a way to work smooth in acme. Sort of a good heuristic for compilers. 
That would be a nice type to have. Bytes.Buffer returns the backing slice, so if you give that to bytes.Reader, it won’t allocate. That will let you seek but not write. A new type for seek writing might be nice too. 
Footpedals are the solution to that.
Woohoo. Looking forward to the day when I don't have to remember to "go install" to make my syntax checker stop chugging, just because an app uses sqlite or something :)
You can embed blocks in templates, but not the other way around.
Typo in link. Meant *for multiple keys. 
That was our original implementation, but this saves a ton of memory over using multiple indices and copies or pointers to the value. In particular for a store with a few thousand ranges over total value of ~400000 it's much faster and more memory efficient.
It's a very narrow use case for sure. We use it to efficiently select from weighted sets and to map from autonomous systems to upstreams. If you have a problem like this, however, it's just the right solution.
If you have bought any other jetbrains IDE you could try the go pluggin for it
Very cool. I don't have a "real" use case, but I've been curious about the data and as you described in the post got discouraged by how much hassle it is to get it.
You have a separate go file for every tea variety that is used with your timer. With regard to the Don't Repeat Yourself principle, would it possible to have a "general" tea go file that can serve as a template for whichever kind of tea imaginable?
So why not use Visual Studio Community instead of VSCode? Does the former not support syntax highlighting &amp; Intellisense for Go?
I'm not the developer of this library, [It is](https://www.reddit.com/user/tidwall) . I've seen it shared it shared on Hacker News and not here. I'm not sure if tidwall is hanging out in this forum after this [fiasco](https://www.reddit.com/r/golang/comments/69yae4/gjson_added_a_new_dropin_replacement_for/dhawsqo/)
Thanks for the links, checking them out right now. Thanks also for the honest reply.
My lib [djherbis/buffer](https://godoc.org/github.com/djherbis/buffer) has a type called [BufferAt](https://godoc.org/github.com/djherbis/buffer#BufferAt) which implements io.ReaderAt/io.WriterAt so you can read/write from/to different places in the buffer. You can get a BufferAt using [buffer.New](https://godoc.org/github.com/djherbis/buffer#New) which is backed by bytes.Buffer. 
So Go helpfully has the nice, simple interfaces io.Reader and io.Writer, for anything that can be read from or written to. bytes.Buffer is simply the answer to the question, "how would I implement these interfaces writing and writing to and from a byte-slice?"
A readme and proper grammar would be really helpful. &gt; Introduction &gt; These patterns can you use to solve common problems when designing an application or system. This sentence might be restructured as: This repository holds a collection of patterns you can use to solve common problems when designing an application or system. The difference: *You can* - this means it is possible for you, or you have permission to, as in "You can use git to manage project version control across many computers", or "You can have a cookie" *Can you* - this is asking a question, as in "Can you get me a cup of water?" A well defined readme tells me what your repo does, some basic use cases, installation instructions (if neccesary), and some getting started examples.
At https://github.com/donutloop/toolkit/blob/master/retry/retry.go#L48 I think it breaks the expectation of the user that when the number of retries is zero, it means that the code should use the default number of retries. This is like a loop the actual runtime values mean you don't ever enter the loop. If "r.Tries" happens to be zero because it was computed from elsewhere, it would be bad to execute 10 times. More generally, Retry has multiple responsibilities here: it could check the values are well-defined (this is the caller's responsibility), but not populate them with default values, especially when it is hard to distinguish set from unset values (like zero have a special meaning). 
Second this, Go plugin for Intellij community edition is a solid free option. 
FYI you don't need to use `grep -v vendor` with go1.9. The expression `./...` does not by default include anything in `vendor`.
Good to know, thanks! I'll remove it.
Caching test results definitely be seems like a double-edged sword. For a lot of software, integration tests are the best (or only) way to ensure proper operation. I'd want to be sure that I'm actually interacting with my critical, external systems when I run go test. I would have advocated for opt-in behavior, but as long as there's an opt-out it's fine.
Yeah could point. The test itself should be able to disable caching. 
I use it to have a shared base HTML template with an empty "content" block, coupled with one that uses define to overwrite it, which makes it easy to share common elements between pages.
[removed]
Thanks for asking this. Imho LSP is big and I'm aware of it's capabilities. But I think LSP should be embedded into the editor instead of providing a plugin. Right now in VIM, you need to install a plugin, which kinda defeats the idea. So to provide LSP functionality, I either have to embed the plugin or have to create it from scratch and embed into Vim. Right now there are 4-5 implementations of LSP in Vim as plugin and seems like there is no end for it. It's too much work to be integrated into vim-go right, but once it's integrated into Vim, vim-go will definitely start using it.
Thanks! It's always great to hear things like this, makes me very happy :) 
Well, yes, but, dependency injection means that you're not actually testing real communication with the other service. For integration tests, this is critical. For example, what error message do you really get from your database when you query for a column that doesn't exist on that table? Will it be the same when you upgrade to the newest release? Hell, even things like environment variables and differences in your filesystem can impact tests. We try to insulate ourselves from everything, but at some point, there's diminishing returns.
Because they’re very poorly written benchmarks. 
&gt; If you run into a problem that you think is being caused by the cache, you can retry the command you're running with GOCACHE=off to avoid looking at or updating the cache. Even better, you can leave GOCACHE as is and instead set GODEBUG=gocacheverify=1, which will not refuse to read from the cache but then will double-check that any writes back to the cache of data already present match bit-for-bit. If you ever see a failure with GODEBUG=gocacheverify=1 set, please file a bug. On my laptop right now, GODEBUG=gocacheverify=1 ./all.bash passes. We have the option to turn it off. Also, it Russ also stated that caching only works with specific packages, which means `go test` (which tests everything) doesn't use the cache: &gt; So if you're working in a directory and just keep running "go test", none of those are cached. But if you test an explicit list of packages ("go test all", "go test mydir/...", "go test math", "go test ."), then caching kicks in.
No, no, no. This is a bad thing. There is a reason that you want to check the error from each write. If you find yourself in need of this kind of package, you’re doing something wrong. 
What reason would that be?
Even so, your tests should be deterministic enough that no two runs of the same test code yield different results outside of run time variance
[removed]
An error is an error. Don’t defer handling. You’ll end up not knowing what caused it. 
I totally agree. However, like someone else said, test fixtures are something that can easily cause variances... if you're parsing canonical data that you update occasionally, for example. Or if you're using go test to run integration tests when you update a server or something. Yes, you can know to opt out (I assume there will be a way to force a rerun of cached tests... I didn't look for it specifically in the announcement though)... but it could be surprising and potentially hide bugs if you're intentionally using go test for something other than purely local unit tests.
I agree with you, but not in the case of successive binary read/write calls. It's never mattered to me in the code I've used which specific such call caused the error. 
&gt; Go is not always fast. That is a good assessment. As for why is it slow, you can read this https://blog.golang.org/profiling-go-programs and watch this https://youtu.be/ySy3sR1LFCQ and then you'll have the knowledge on how to investigate this and let us know why Go is so slow. And you'll also be able to improve them if possible so that the results are better. Looking forward for your analysis. Good luck.
How did you arrived to this conclusion? And how can they be improved in that case? 
The whole thing can be reduced to https://play.golang.org/p/gtqcuN3U7X, feel free to use it in your apps, without the need to have an external dependency or obscure/hinder what the code is doing. Don't be clever, be clear and explicit with what you code and you'll thank yourself on the long run.
There are solutions out there which do not rely on packages being installed for them to work and even work on broken Go code.
I rarely find myself disagreeing with explicit error handling. I created this package specifically for types which binary encode/decode themselves. Take the following code: func (t *Thing) ReadFrom(rd io.Reader) (nn int64, err error) { n, err := binary.Read(rd, binary.LittleEndian, &amp;t.Field1) nn += int64(n) if err != nil { return nn, err } n, err := binary.Read(rd, binary.LittleEndian, &amp;t.Field2) nn += int64(n) if err != nil { return nn, err } n, err := binary.Read(rd, binary.LittleEndian, &amp;t.Field3) nn += int64(n) return nn, err } That code isn't fun to write. In my opinion, the slight performance advantage of returning early is not worth it. [This blog post](https://mijailovic.net/2017/05/09/error-handling-patterns-in-go/) shows a more extreme example. 
Fyi, that plugin hasn't been actively maintained since mid-2016.
[removed]
I made this for writing encoders/decoders for structs.
[removed]
TIL the golang subreddit can be... a little rough...
I really like VSCode, but has anybody noticed that it’s gotten REALLY slow with go 1.9? Like it seems to be constantly recompiling everything ... it used to be fast. :-(
That's not feasible with some systems. Networks fail, and some systems can't guarantee strong consistency. They're still worth testing.
Here's another resource for you ("Go Project Layout"): https://medium.com/golang-learn/go-project-layout-e5213cdcfaa2 It's not as opinionated as others in terms of what you put in your packages, but it describes a set of common patterns you can follow (pick the ones you like)... 
The regexredux test uses "github.com/tuxychandru/golang-pkg-pcre/src/pkg/pcre" which is just a wrapper of libpcre. It's nonsense to benchmark Go program that calling C library functions through Cgo. Cgo is not go.
For a unit test, DI or mocking sounds great - but for integration tests I wouldn't find that very useful. We need to verify the health of the whole system, not just our component. In our particular case, our integration test suite is fast enough that the effort of mocking everything out wouldn't be worth it. So for us we'll probably always have test result caching disabled.
Agreed, `t.NoCache()` or something would be nice.
Yes, but you are missing the point, you can take my code and specialize it as much as you want. Make it a template in the editor you use it and and it's as fast t use as well. Your code is simply not needed.
One of the first things which comes to my mind when thinking about simplicity and Go is the amount of keywords of the language: https://golang.org/ref/spec#Keywords
That seems like a good indicator of the language's size. As does the small spec itself. Anything else? What's not so simple?
Thank you again for vim-go. 💯💚
I will just leave [this](https://www.youtube.com/watch?v=rFejpH_tAHM) here.
Binary trees, first line on main: runtime.GOMAXPROCS(runtime.NumCPU() * 2) Your title: Why is Go so slow? Your first line: Go is not always fast.
@kerakk19 I have moved removed global database handler. Though, for now I have retained the global configuration object. I have separated models &amp; controllers into separate directories. Web stuff is already in a separate directory. I want to embed the entire front-end stuff in the application binary. Thanks again for the feedback!
Anyone know if they're planning on releasing all of the videos?
Pull request?
This one is only stdlib and seems to be even slower: https://benchmarksgame.alioth.debian.org/u64q/program.php?test=regexredux&amp;lang=go&amp;id=1
Sure thanks for this suggestion. Will do
If you’re an experienced programmer, the spec is pretty short and approachable and easy to read. I frequently use it directly to answer language questions (instead of, say, StackOverflow et al).
Lots to that, but would have been nice to see the video too :) Re Monorepo: 824 branches: what's the branching model you're using? Or put another way, other than master, how many of the 823 other branches are not one person (or one pair) are not very short-lived (one to two days life)?
I am still in process of refining and updating README. Thanks for the feedback. Will update the README with more information and also example_test files for showing usage. Thanks once again
[removed]
You may be interested to know that Haskell has less keywords than Go so I don't know if that is a great indicator of "simplicity".
Figured as much ;) It's funnier than it is offensive, rest assured.
Seems useful to run grep on it for your own domain. 
This is a very common technique showcased by Rob Pike [here](https://blog.golang.org/errors-are-values). Every gopher should know it and it should be used wherever it makes sense. I don't think we need a package for it. Also remember that "[A little copying is better than a little dependency](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s)".
The standard library regex is different than the classic C regex that most other languages use. So: * In this case, Go is not competing against Ruby, Python etc. It is competing against C. * Most importantly, the algorithm Go uses guarantees to complete in time that is linear in the length of the input. Meanwhile the classic C algorithm that is used by Python, Ruby etc. can take time exponential to the length of the input, which in practice means that you are vulnerable to [ReDoS](https://en.wikipedia.org/wiki/ReDoS) attacks.
**ReDoS** The regular expression denial of service (ReDoS) is an algorithmic complexity attack that produces a denial-of-service by providing a regular expression that takes a very long time to evaluate. The attack exploits the fact that most regular expression implementations have exponential time worst case complexity: the time taken can grow exponentially in relation to input size. An attacker can thus cause a program to spend an unbounded amount of time processing by providing such a regular expression, either slowing down or becoming unresponsive. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
what is the purpose of this tool considering the existence of the dep project?
structs may have been one of the first packages I picked up when I started go, good to see that the author has a nice CI/CD environment under their finger ;)
Both: - "classic C regex" [Go #2 program](https://benchmarksgame.alioth.debian.org/u64q/program.php?test=regexredux&amp;lang=go&amp;id=2) - "standard library regex" [Go program](https://benchmarksgame.alioth.debian.org/u64q/program.php?test=regexredux&amp;lang=go&amp;id=1) Maybe it's the way the programs are written.
The other 5 Go binary-trees programs don't have that "first line on main" [and are slower](http://benchmarksgame.alioth.debian.org/u64q/measurements.php?lang=go).
How well documented every package of the stdlib is, as well as community libraries. GO just has an excellent community in general and this can prove helpful for anyone new to the language. 
If you don't need the speaker with the slides, you have bad slides. If you do need the speaker with the slides, don't post just the slides.
I have been driving back into ng the last couple of days and I must say that even if there's still a lot to do, I can see it becoming a rather good Go interpreter, a trampoline for data exploration and a good tool for program extension/scripting. And it was also rather easy to hack on :)
Thanks for the heads up.
You can use GoLand or you can use IntelliJ Ultimate and use the Go plugin for that. And you can write to sales to see what license they can help you with. Hope it helps.
A former co-worker I knew worked at a place that used the ball clock problem (http://www.chilton.com/~jimw/ballclk.html) to convert their existing programmers to Go, then used it as the hiring exercise for new applicants to submit, if they were hired they spent the next month optimizing the code which requires learning Go inside and out. Her observations were: 1) The best people didn't look up examples on GitHub and embraced the learning exercise. 2) The first working version shows what language someone knows. Ex: "Java in Go" 3) Introduce test and benchmarking tools using 123rd ball, it is the longest computation. How much does a variable declaration cost? 4) Learn how to identify bottlenecks in code and start with the worst one first. Loops cause more issues that lines that execute once kind of thing, do you need to complete a loop or can you break out? Apparently the VP would make people read "The Goal" too. 5) Naturally adopt Go koans and learn how to write idiomatic code, which proves out to be the fastest. Departure from "Java in Go" 6) Fastest examples were around a tenth of a second when executing the 123rd ball without using a math cheat to skip a ball operation.
That is a good idea! If you like you could create a pull request.
Feel free to do a pull request ;) Thanks for your help!
What's your point?
Exactly what I was thinking. While having a registry might be helpful - I do not see why one would choose this tool over `dep`, and possibly use gopm.io to just find packages (even though I don't know it it even makes sense).
I always think it's nice to do something that's useful, even if it's a smaller project - doing something that does operation(s) that take a while, but can print out some sort of progress is ideal. I feel like you should start by trying to use errgroup, just since it helps putting in good patterns for cancellation and error handling. I love using Go to give QA various CLI tools for testing, but I've also used it to build bots for slack that report status of servers etc. and respond to chat commands as mini-projects.
A small amount of keywords does not necessarily indicate a simple language, but a large amount of keywords certainly indicates a complex language. So a small number of keywords is required but not sufficient for designing a language that is simple to use.
+1. It was my understanding the community was standardizing around dep. Let’s not get fragmented. 
If goimports on the large repo is slowing things down, you could index the code base at regular intervals and make your fork use that instead of scanning live code. It looks like you might even be able to use your gta logic to live index only the changed paths and use the rest from the index.
&gt; This is a very common technique Quite an understatement actually. This is Haskell's (and Idris' and others) way of error handling with Monads. In /u/ammarbandukwala's package `Write` and `Read` are just specialized forms of `bind` and the final return (the `N` and `Err` methods) are equivalent to an `Either` except of course, non-generic. This does seem like a good example to showcase as an [Experience Report](https://github.com/golang/go/wiki/ExperienceReports), although there seems to be a few articles about error handling linked already.
* Concurrency is a first-class language feature. * Duck-typing - one doesn't need to explicitly define class hierarchies, as interfaces are implicitly satisfied. * Reduced language keyword set, and eg there's only one loop construct (for). * Garbage collection. * First-class built-in tooling: race detection, profiling, tracing, etc. * Symbols are accessible outside of a package simply by the type / value having a name with a capitalised first letter. * No project files! * Cross-compiling available on all platforms on which the language is supported. ie on Linux I can easily compile for Arm, Windows, etc. * Built-in documentation generation. * Compilation generates single target files, reducing dependencies. * The language is bordering on being sealed, meaning code which compiled today will still compile years from now. * The language favours composition over inheritance, reducing complexity. 
There already is a pretty universally adopted registry: godoc.org.
Comment to save for later 
Thanks, that talk pretty much inspired my presentation. Rob suggests that Go's success is due to simplicity. He says simplicity is multi-faceted, and that although Go has complexity, it should _feel_ simple to use. So I'm wondering how people feel about that. Does it feel simple, in what way, and which parts don't feel simple?
[removed]
[removed]
I enjoyed the post. Technically it was great! Definitely a good read for learning and thinking more about routers and muxers in Golang. 
I started learning Go after primarily coding in Python. For me, I was never going to really learn Go if I tried to just do arbitrary exercises, trying to just use all the goodies of the language. The way I really learned it was to solve a real problem I had a work. A piece of software written in Python needed a rewrite, so I did it in Go it didn't require any concurrency or net logic. But it was a great way to solve a real production need as opposed to a contrived project. Pick something you actually need to solve or rewrite, regardless of whether it exercises all of the Go stdlib. 
There's a save button for every reply, please use that instead.
I'm sorry all--we totally goofed the video feed of this livestream. If you're curious about what it ordinarily looks like then check out some of our previous sessions: http://www.youtube.com/playlist?list=PLjvJiJ23Dh0QuPcYWg9MQP6v3OG5_E9M2 We're about a quarter of the way through the course so far
The bintree bench measures the cost of performing hundreds of millions of allocations, and go is a garbage collected language so do the math.
I appreciate The Goal is a valuable book but I could not finish it
You can't tell me what to do
Wow, Ok. 
I am not even him lol
The faster [Go #2 program](https://benchmarksgame.alioth.debian.org/u64q/program.php?test=regexredux&amp;lang=go&amp;id=2) is not -- *"different than the classic C regex that most other languages use".*
Hah, you are right. Not sure why I never thought of godoc.org as a registry as such. But yes, it deffo is and has a benefit of actually showing the godoc straight of. So even less reasons for the `gopm` project as far as I can see
When it concerns a program which is to be deployed on another system, I don't use `go install`. `go build` to a deploy directory, which also contains any assets the thing needs. The whole directory is then gzip'd up and transferred to where it needs to be. Alternatively, if the assets are not likely to be changed very often, I embed them in the source code itself as byte arrays. THat way they are baked into the binary. Nice and tidy.
Looks really interesting. I'm not entirely sold on the approach to errors (feels too magical), but it is well thought out and looks like a long term project with a really good niche to fill which a lot of people want to see progress on - I'd use go for scripting but it is a bit fiddly at the moment to do so. 
I'd second this approach. Just keep your webapp in src/host/you/project and make directories like bin, templates etc in there as required. 
Seconded. I generally just make a `views` folder, with a `template` and `assets` subfolders to store relevant files in.
fascinating.
If you're building a "modern" app, considering keeping the Javascript, CSS (front end) separate from the Go project (which is an API). 
The correct order seems to be: 1. Package that abstracts error handling 2. ORM 3. Router 4. Integrate 1-3 into a web framework
&gt; deffered Deferred.
Yes, though I have to say Pike's implementation is a lot cleaner than this, this library is just jumbled logic. `check` is never called with `w.err != nil`, yet it does that same work again, etc.
C#, Erlang, Java, Haskell, Racket, Lisp, Smalltalk, … also are GC implementations.
"The Goal" is just a fictional story illustrating the Theory of Constraints.
Yeah I got the gist of it. It's just the story is terribly written.
I personally don't like this implementation of GraphQL. I prefer Neelance's GraphQL library, which ships with a nice handler for Relay. Check it out [here](https://github.com/neelance/graphql-go). They are using it in production over at [Sourcegraph](https://about.sourcegraph.com/) as well. It's been a pretty good implementation to use. Also seen it used with gRPC, at least in this [simple example](https://github.com/iheanyi/go-grpc-graphql-simple-example).
[removed]
it is worth noting that go has additional "keywords" that are not reserved, such as len i can't think of any others right now
What problems did you have?
You are completely correct in saying that, but I am also referring to how the community helps out
You included no useful information in your post. If you found using Go on Windows so painful, it might help to share with us **why** it was so painful. Perhaps you're just doing something wrong.
The language is made for cross-compatibility. The only thing that comes to my mind about problems on Windows is that the plugin system won't work (it is a WIP after all) and the installer won't set GOPATH or GOBIN for you (and it won't give you the option). Windows users are used to have installers that handle everything for them and it's very annoying having to search for resources on what to set those two system var, the installation instructions on golang.org are incomplete on that subject. Once this is configured, you don't have to touch it ever again but it can make first contact with the language needlessly complex/annoying. Beside that...maybe the support of Windows components aren't that good if you want to integrate into the ecosystem (ie: registry/eventlog) but then this is mostly because Windows is awfully built in the first place. ¯\\\_(ツ)_/¯ What are your concerns? If you list them perhaps we can address them and give you peace of mind.
I started picking at my beard while watching this.
I use windows predominantly at home because of games etc.. I also work on a lot of side projects in Go.. I haven't had any real issues. Can you expound on what issues you've been dealing with?
He's calling it a *forum*, he asked for it! /s I remember reading that thread when it was posted. On the internet it's easy to immediately assume the worst out of people, so it was assumed that he was playing the "benchmark game" that we often see posted here due to the title he picked. In the comment thread that you linked it was needlessly hostile and I believe the amount of negative points that we see show that the community didn't think it was an acceptable comment either. As for the other comments in the thread, I think they raised good technical discussion in general. If he's going to sulk the subreddit just because of that one comment...well.....
The user's name is random garbage, and it's his first post. Seems to just be a troll, please ignore unless he comes back with any reasonable information.
I agree, this package is far too simple to be worth the dependency.
For a list of all Go GraphQL server and client libraries, see http://graphql.org/code/#go and http://graphql.org/code/#go-1.
`len`is a built-in function, not a language keyword in the strict meaning of the word. But I agree that `len`, `new`, `delete`, `append`, and other built-in functions should be treated similar to the reserved keywords and at least be mentioned alongside of those.
An interesting article about concurrently traversing a directory tree. (Found via HN.)
&gt; No project files! I absolutely love this about go
https://github.com/mitch000001/go-hbci
Yeah, looks tollish to me. I write in Go every day on Windows. Libraries are maturing and you can even build DLL's in Go now. I would recommend avoiding cgo if at all possible. I also wished there was a native Go lib for SQLite but that is just about it.
So... Have you profiled it? Do you want to let us know why this is happening then? 
i would if i had time. unfortunately there are projects running and time with them. Please forward my list to jetbrains if it is actionable. I promise that I will, from time to time, try any new releases.
But what if we use templates? 
I'm not sure if this was recorded, I'll definitely share it on Twitter if that is the case.
Don't agree. I've put the bullet lists more detailed sometimes just so people can read it after I publish it. However in my talk, I try to share a story and quickly go over them. It's a style I prefer.
Most of them are one week old (at most). It's rare that it's takes weeks. Everyone opens a PR against master and it's get merged. Master means it's deployable. We don't use any of the other Git workflows. But monorepo doesn't restrict how to use the branches, it's up to the individual teams which workflow to adapt. 
Yeap, it's not written in the slides, but I've exactly talked about this :) That Google uses a forked goimports that uses an index, instead of the current public one. 
I recommend doing something with websockets. Maybe a chat client.
&gt; The faster regex-redux Go #2 program is not -- "different than the classic C regex that most other languages use". Well of course not. That's what the very first comment said: &gt; The regexredux test uses "github.com/tuxychandru/golang-pkg-pcre/src/pkg/pcre" which is just a wrapper of libpcre. It's nonsense to benchmark Go program that calling C library functions through Cgo. Cgo is not go. Then the person after that replied: &gt; This one is only stdlib and seems to be even slower So my whole point was that Go's regex (stdlib) will usually be slower but that's only because it offers other more practical advantages.