&gt;https://os.phil-opp.com/ You care to share some links ???
I see no reason not to. Altough for non-SPAs, I tend to use npm with basic cat/uglifyjs/uglifycss to keep things simple.
The UK dev market is pretty shit. Lots of jobs, but the pay in London, for example, is way less than I get here in Copenhagen, Denmark - and the cost of living is higher.
&gt; If the type the vector has is not a type that has the + operator supported, then it would produce panic() where I describe why it failed. I agree, unless Go gets generics, the way you implement methods like FnReduce is the best way to handle multiple parameter types. I was more looking at using a nil *receiver*. https://play.golang.org/p/JgzQP_QzpAG A method with a pointer receiver should take care of the special situation where the pointer is nil. &gt; The way I structured the code makes it impossible to use a the FP functions in a vector with ints and strings. True, that was an oversight of mine.
Nice clear video, straight to the point and no bullshit. Great job, keep it up!
Ok thank you for your reply. I found an example doing something similar with angular and a go backend on auth0.
Maybe ls and dir are PS builtins and not executable files?
I should have mentioned that I also tired it in the command prompt with dir and it still has the same problem.
Supports my point
https://www.itprotoday.com/powershell/emulating-dir-command-powershell
So far for me the main problem is that literally everyone I've found can get the Go part up and running, but the Node parts always seem to fail in new and special ways on each person's machine.
Thanks!
Yeah that's a valid criticism of npm. I've been through that hell before.
They rejected my contribution which was "KISS" :)
This. Sorting and scanning is probably the most efficient if you can afford to sort the original slice. If you'd need to copy the slice I'd use the map approach as it is probably way more readable
The function will be just a few arithmetic operations, it will get inlined, so no function call overhead.
The function will get inlined.
As your original query has been answered, I'd also suggest that reading \`ls\` or \`dir\` output (unless this is just an exercise) is significantly worse in every way than just using the \`os\` package to work with the filesystem.
I was looking at it, and thought of a different way (just to show you, the puzzle can be solved in many ways) &amp;#x200B; [https://play.golang.org/p/RsZMjNOKVTw](https://play.golang.org/p/RsZMjNOKVTw)
`exec.Command()` is not the same as running commands in Windows Powershell, or Cmd.exe, or bash shell for that matter. It specifically executes a program in your PATH in a child process. If you want to run Powershell commands then you have to actually execute Powershell absolute path, and the extra args needed to pass your commands for it to interpret. I'm not a windows user so I can speak to the details of using Powershell but there are plenty of examples of calling it with arguments.
yes - but digging into this a bit more I think it's clear with [https://tools.ietf.org/html/rfc8441](https://tools.ietf.org/html/rfc8441) that websocket libs will just be updated so that a Websocket implementation can just consume a single stream in an HTTP2 connection. That leads me to think I'll just reach for websockets again in future if I need it.
Consider reading fully [this classic tutorual on `database/sql`](http://go-database-sql.org/), or — even better — grab [their e-book](https://www.vividcortex.com/resources/the-ultimate-guide-to-building-database-driven-apps-with-go) on the same matters. They deal nicely with what may caught by surprise a programmer coming from different backgrounds.
I know you want to do it from scratch but maybe look at the code behind some of the projects on github to get some ideas of how to deal with the data structures. I've not used it but ones like this seem pretty much what you're ultimately trying to achieve and looks very well written. [https://github.com/disintegration/gift](https://github.com/disintegration/gift) On my course (many years ago) we used Matlab. From memory most things were achieved by writing different convolution functions. So if you could get that part going in GO then you would be able to achieve quite a lot of functionality. Generally I would try and write a lower level helper api that is reused by your high level api. E.g. helpers for writing to byte arrays, or common functions.
I am noob to viper WatchConfig() and OnConfigChange() interfaces, I could comprehend and experiment with configuration file changes but unable to comprehend that how the updated configuration changes are observed by already running goroutine. Does it require some additional orchestration (may be using channel or context) between the App goroutine and by some goroutine created in OnConfigChange() or its some other mechanism. &amp;#x200B; @[IEatsThePasta](https://www.reddit.com/user/IEatsThePasta/), you are already using this feature in your Go App. Can you give some pointer.
Interesting, I’m reading about that now. I didn’t realize go even did this. I’m having trouble finding info on what the compiler uses to decide what gets inlined vs not, happen to have any good links?
FYI: this is the latest commit with Python code - [https://github.com/psychopenguin/noderecycler/tree/62f2b0045f2d33d68fcac411185836b82b3bd94c](https://github.com/psychopenguin/noderecycler/tree/62f2b0045f2d33d68fcac411185836b82b3bd94c)
It's an option, but you have to be willing to put up with the core Go developer team showing up in long flowing robes about twice a month to gather around you and shriek "*IMPURE! IMPURE! CAST OUT THE HEATHEN WHO DARES MIX GO WITH OTHER TOOLS!*" and similar things for about ten minutes. It's annoying, but sometimes it's still worth it to use best-of-breed tools from other communities. A bit embarrassing when they happen to show up during a stand-up meeting, though.
Not unless you containerize your app using layered Dockerfile (separate layers for building and running app). For example the resultant size for my containerized app is 59 MB which is using viper. Reference: \- [https://docs.docker.com/develop/develop-images/dockerfile\_best-practices/](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/) \- [https://container-solutions.com/faster-builds-in-docker-with-go-1-11/](https://container-solutions.com/faster-builds-in-docker-with-go-1-11/)
I'm just learning Go myself so I can't offer much code feedback at this time, but I do have a question about the tool itself since we're trying to use preemptibles at work: do you have a rough idea of how much this cuts down on automatic preemption? Google states that the _maximum_ is 24 hours, so presumably you can kill a node bring it back up, and then Google will kill it right away. What's your experience in practice with this tool?
I reads okay, if I was handed this by one of the team I'd not be concerned about others supporting it. Personally I prefer to only have func main(...) in main.go and would put Recycler in a file named: recycler.go but thats just nit picking. If its going to sit in a loop what happens when CtrlC or KILL is issued? Shouldn't you want to close down any handlers that you have running? signal.Notify may be of interest: [https://gobyexample.com/signals](https://gobyexample.com/signals)
When noderecycler kill a node, it also delete the instance, so a brand new one with another comes up as replacement - with another 24 hours grace period. &amp;#x200B; Usually - on my former and actual jobs - I configure it to kill a node after 18 hours (with 15 minutes for cool down). Sometimes Google can come first and kill another node before the 18 hours, but this is not very common to happen, so we just take it as a small risk.
Thanks for you feedback /u/MrPhatBob :) &amp;#x200B; When you sugest to put the the Recycler content in another file, should it also be inside package main or should I create a new package for it? &amp;#x200B; Probably won't use for this project right now, but the signal handling package will be useful in the future. &amp;#x200B; Thanks!
Don't know why you get downvoted. I write programs in Python and Go (with Go being my favourite language), but for image processing I stick to Python. It's just easier to work with.
Probably not needed in its own package, but certainly worthy of its own file. Having logically grouped functions (objects?) in their own file then leads you to writing tests for that file. I couldn't see a usable test scenario for the functions you've written because they completely depend on the external interfaces. But if you're in the habit of writing code that way you'll be in the habit of writing tests.
Oh, ok. That's what you meant by that. Thanks for the feedback, you gave me some stuff I could use for the next update.
You only need one sql.DB connection pool. You should pass it to code that needs it via [dependency injection](https://blog.drewolson.org/dependency-injection-in-go).
i don't have much to offer in the way of feedback. i think it looks good -- nothing stands out which is a good thing. one very minor nit i have is that i tend to like to declare and assign variables once. the following block kind of triggered that feeling: ``` func initKubernetes() (*kubernetes.Clientset, error) { var cfg *rest.Config var err error if os.Getenv("KUBERNETES_SERVICE_HOST") == "" { log.Println("Running Outside a Kubernetes Cluster") configfile := filepath.Join(os.Getenv("HOME"), ".kube", "config") cfg, err = clientcmd.BuildConfigFromFlags("", configfile) if err != nil { return nil, err } } else { log.Println("Running Inside a Kubernetes Cluster") cfg, err = rest.InClusterConfig() if err != nil { return nil, err } } clientset, err := kubernetes.NewForConfig(cfg) if err != nil { return nil, err } return clientset, nil } ``` so -- what bothers me is that we declare two variables (`cfg` and `err`) at the top of the function and now, as i read the code, i have to track their value through the condition. what i find is that if you *try* to get rid of the `else` part of a condition, you typically end up with more concise and readable code. to use a $10 term for this, you reduce cyclomatic-complexity. i might do something like the following instead: ``` func initKubernetes() (*kubernetes.Clientset, error) { getcfg := func() (*rest.Config, error) { if os.Getenv("KUBERNETES_SERVICE_HOST") == "" { log.Println("Running Outside a Kubernetes Cluster") configfile := filepath.Join(os.Getenv("HOME"), ".kube", "config") return clientcmd.BuildConfigFromFlags("", configfile) } log.Println("Running Inside a Kubernetes Cluster") return rest.InClusterConfig() } cfg, err := getcfg() if err != nil { return nil, err } clientset, err := kubernetes.NewForConfig(cfg) if err != nil { return nil, err } return clientset, nil } ``` so notice now that we've gotten rid of the `else` and simply return the results of either `clientcmd.BuildConfigFromFlags()` or `rest.inClusterConfig()`, we can HANDLE the error in one place (after calling `getcfg()` whereas we were trying to handle it in two places. also, this free us of having to declare `err` which i prefer to re-use in quick declarations.
Sure :) I've searched a bit and found this: https://github.com/golang/go/wiki/CompilerOptimizations#function-inlining
Do they pelt you with toy gophers?
Then why don't you go use one of those "true programming languages" and stop complaining about go.
&gt; can most programs really recover correctly from accidental bugs that weren't even considered when the code was written? Well, that depends on the type of error, right? And yeah, C++ isn't a particularly good example for how RAII _could_ look in Go. I think Rust's model is a _far_ better example because: - both languages claim to be "memory safe" - Rust doesn't have exceptions, and its panics are less "exception-like" than Go's Some things in Rust are unchecked in release mode (e.g. arithmetic overflow), but unless the program immediately ends (very unlikely), your destructors _will_ get called. That's also the case with Go's `defer`, so I just want some deterministic way to ensure a struct gets cleaned up, and RAII is a _lot_ less error prone than `defer` (though `defer` certainly has its uses). When I `panic`, I usually care a _lot_ more that cleanup happens than the program continues running (e.g. try writing to log files, close active connections as gracefully as possible, etc). Also, accidentally _not_ cleaning up is often _way_ worse than continuing to run, and that can cause all sorts of subtle bugs if someone forgets to run a destructor or something in an edge-case. I am absolutely a fan of RAII, though I'm not a fan of execeptions (I prefer Rust's error model, Go's is acceptable, if a bit verbose). I just want destructors to automatically run when a variable goes out of scope (i.e. would be collected by the GC).
&gt; And thinking your program understands every .bashrc enough to automatically edit them is downright scary. Particularly to those of us who don't even use bash.
Youtube! There are tons of tutorials. Just search around and pick one you like.
Struct tags are definitely useful, they feel reminiscent of less-powerful, stringified versions of Java annotations. Are you aware of uses within the Go standard library other than (un)marshaling? I can't help but feel it's both clever, and kind of kludgey, to define JSON schema as tag in this way.
Justforfunc got it to click for me
Wow, I've heard this before but not sure I fully understand. What are the D maintainers lacking?
We've used tags for custom validation of (json) fields. The validator doesn't have to be aware of what it is validating. Just pass all inputs through it. It will search for the tag and select appropriate validator.
If this is complete, then just that https://github.com/golang/go/wiki/Well-known-struct-tags
Not that I am aware of... There is a go wiki that holds a collection of uses out there. From what I have seen tags are used for serialization and validation. If others have seen other uses please share, I would be curious.
Thanks for the reply. I must have missed this yesterday. [https://stackoverflow.com/questions/13008255/how-to-execute-a-simple-windows-command-in-golang](https://stackoverflow.com/questions/13008255/how-to-execute-a-simple-windows-command-in-golang)
Because searches should be handled by a dedicated search engine, I’d vote for elasticsearch. We’re using it so heavily on a few websites and it’s rock solid.
The [Ultimate Go Programming](https://learning.oreilly.com/videos/ultimate-go-programming/) video series by William Kennedy (who is also the co-author of Go-In-Action book) is the best in-depth Go learning tutorial I have come across (not only for goroutine, concurrency or channels but for other Go basics as well) provided you have access to safari online (can also create 1 week free subscription).
[removed]
SQLite has a pretty good optional built-in full-text search engine built-in, FTS5, and since it's written in C, not Java or some other bloated language, it's fast. I incorporated it into the search engine for my Hugo-based static blog: https://github.com/fazalmajid/fts5index This includes a translator from Google search syntax into FTS5's slightly idiosyncratic one: https://github.com/fazalmajid/fts5index/blob/master/fts5query.go It's subject to the multi-user limitations of SQLite, but try the search function on blog.majid.info and you'll find it's very fast.
Elasticsearch is the way to go regarding search engines. For the "raw data storage" it comes to personal preference. If you have data that fits/requires a schema, go for either MariaDB or PostgreSQL (Maria being the easier, but Postgre the more powerful one). If you want to go schemaless, MongoDB it is.
If you want something a bit more lightweight than Elasticsearch, then take a look at [Bleve](https://blevesearch.com/).
*QED*
Hey hey, [here](https://iheanyi.com/journal/2017/11/22/deploying-an-spa-as-a-go-binary-using-webpack-and-statik/) is a blog post that can be helpful. It also used Vue, webpack, and Go :)
I've had very good results with Bleve
/r/iamverysmart is calling your name
Ah great, thanks. This is pretty useful and fairly close to what I am doing. Yeah the title of that post spells out my requirement, I wanted a single binary which served the files as well as the API as this is to be used as a developer tool rather than a high volume site (a little bit like how goconvey works) Thanks again!
You should do yourself a favor and strip this down to a simple ES query. There is too much custom crap in here to read this properly. Having a simplified ES client query would likely help you first, and then help anyone on this thread actually see what's wrong.
Have you seen the Gopher discord server?
``` code blocks don't work on reddit. You have to indent code by 4 spaces.
[removed]
they work if you use the new reddit interface.
Didn't know that. I'd kind of forgotten that mess exists, tbh.
Whats your Feedback about Performance between this two?
I would agree with this with an asterisk. I've tried using Bleve in the past and it was *extremely* convenient and easy to work with compared to alternatives, and works very well with small to medium datasets (using the new scorch index). I starting seeing extreme performance problems (both with indexing and querying) begin after indexing around ~30M documents, I opened an issue about it and the developers said I wasn't doing anything wrong, so I believe it's just a side effect of how their new index is implemented. That's not to say it couldn't be fixed in the future though. I personally switched to Solr (Lucene) and I'm very happy with it, I saw a fairly large performance increase when handling a large amount of documents, and the index size is multiple orders of magnitude smaller than the index Bleve generated. Only complaint I have is that the config format is a contrived XML document, but once you get through that everything works well.
They're basically magic strings as key-value pairs. They're not imported or defined anywhere as such, you just write them in the correct format, and you can read them with reflection. For example: https://play.golang.org/p/ALW-iw2yeef Them just being magic strings is one of the reasons why I tend to try avoid using them if I'm writing my own code. It's useful for very simple things, but people try put some crazy stuff in them sometimes.
The [`reflect`](https://golang.org/pkg/reflect/) package is just part of the standard library in general - nothing specific to the `database/sql` package. It has many uses - but bear in mind it comes with a performance cost, a code readability cost generally, and a risk of runtime failures too.
And here I am, waiting for the Go port to Android Q.
And here I am, waiting for the Go port to Android Q.
L E G I T
This comes very timely for me! I've discovered this unknown feature for me just short before the publication of your article: https://redd.it/btn4ks Thanks, it's very well done and defensively boosted me a bit on the topic.
You mean [gomobile](https://github.com/golang/go/wiki/Mobile)?
What size is it without Viper?
No, I mean [Go](https://github.com/golang/go/issues/29674)!
[removed]
1's Complement: [Unisys ClearPath Dorado Series](https://www.unisys.com/offerings/clearpath-forward/clearpath-forward-products/clearpath-forward-dorado-systems) As for sign-magnitude representations, I don't think any more machines are being produced today. But that doesn't preclude one from being made in the future. In particular, they are more efficient for some DSP applications.
The what now?
Thanks, glad you found it useful!
The [this](https://www.reddit.com/r/golang/comments/bu4ao9/_/ep804ur?context=10)!
[removed]
For signal handling , you can run each switch task as a go-routine and have a separate case for exit signal. This was you can incorporate graceful exits without using any other custom packages in your repo. add exit possibilities like SIGINT,SIGTERM etc. Read more on channels and the "signal packages" &amp;#x200B; [https://medium.com/@matryer/golang-advent-calendar-day-two-starting-and-stopping-things-with-a-signal-channel-f5048161018](https://medium.com/@matryer/golang-advent-calendar-day-two-starting-and-stopping-things-with-a-signal-channel-f5048161018)
Great talk by Rob Pike on YouTube about Go concurrency patterns, here: https://youtu.be/f6kdp27TYZs He demonstrates using goroutines in some interesting yet powerful ways. It’s a pretty good intro imho.
It looks like google cloud compiles it and executes it expecting it to be a stand-alone, static binary. When you set CGO_ENABLED=1, you’re expecting the application to link to libc. If the container doesn’t have libc, it won’t find all the symbols it requires to start up. To fix it, If you have control over the container image - then change it to library/ubuntu:19.04 to get libc in your environment. On a side note: Unless you’re managing OS level resources that don’t have go-bindings and also unless the effort of writing a go-binding on your own is much larger than the rewards - don’t use CGO.
\&gt; due to not being serializable isolation in the db itself ? Well you can just use the SERIALIZEABLE transaction isolation level of your DB (like MySQL). The standard syntax for this is `SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;` If you issue this command after starting your transaction, you'll be fine (for this transaction). Most database access layers offer a dedicated API call to set the transaction isolation level. I'm not into Go, but a quick google search gave me this: &amp;#x200B; [https://github.com/go-sql-driver/mysql](https://github.com/go-sql-driver/mysql) &amp;#x200B; There you can even set it in the connect string, so you don't need to mind it anymore. Apperently, like this: &amp;#x200B; id:password@tcp(your-amazonaws-uri.com:3306)/dbname?tx\_isolation=%27SERIALIZABLE%27
Consider using yarn. It locks the dependencies better and will compile 6 months from now.
I feel like a fake Go programmer because I have not yet written my own routing library :-(
I feel typical for writing one. To be honest though, I haven't liked the APIs of pretty much every single request multiplexer I've tried, which is mainly why I wrote this.
Thanks! I totally overlooked the ability to set the isolation level like that. I am using that driver :)
Would appreciate feedback on API (it's [not yet considered stable](https://semver.org/#spec-item-4)) and the library as a whole.
If you're starting with their helloworld example, it uses the Debian-based `golang:1.12` container as the base for the build step, but Alpine for the runtime container. Those have different libcs (glibc for Debian, musl-libc for Alpine) which causes trouble. There are lots of ways to deal with that, but a simple one suitable for hello-worlding is to just build on `golang:1.12-alpine` which will have the same libc as your runtime and will probably work fine.
I built one for my bachelor thesis, and I went for ElasticSearch only. It works like a charm and is productive for ~300 employees at an IT company. ES with no Database definitely works. I wouldn’t even know what data to store externally.
So whats happening ? Will golang 1.13 backward compatible ?
The difference is insignificant. To be exact: Without Viper: 57.3 MB With Viper: 58.9 MB
hmmm... that's a really good advice. thanks a lot for it. :)
Well, I wasn't able to spot any performance diference between them - also I haven't compared resource usage, so I have no metrics to share. But if the is one huge improvement: the docker image is much smaller. It went from 400MB in python version (using python:3.7-alpine as base image) to just 10MB in go (compiled without debug info, and compressed with upx).
Thee is a project based on bleve called Blast that makes it much more scalable and HA. It also has GRPC and REST API. I used to use bleve but switched to blast and it's much better.
This link results in a 404
Just wondering why single worker by design? The case would make your system having a very limited audience. Would be more practical that you can configure number of workers available.
My advice would be to start with the [tour](https://tour.golang.org/welcome/1), particularly if you have any prior programming experience, and find an interest in something that's not blockchain-related.
Why, is blockchain programming in go impossible?
Sure it's possible, it's just that the blockchain hype-train got way out of control.
What do you mean by out of control?
This video explains [how channels work](https://www.youtube.com/watch?v=KBZlN0izeiY). This made it all of this "click" for me.
Hum... the issue seems fixed
A complied and curated list of the [best Golang tutorials for beginners](https://reactdom.com/go). Hopefully it helps!
Below link should work: [https://learning.oreilly.com/videos/ultimate-go-programming/9780135261651/](https://learning.oreilly.com/videos/ultimate-go-programming/9780135261651/)
It is a known error regarding go modules, a workaround would be running `go mod vendor` locally, which is what I currently do while this is being worked on
that is mean use \`go mod vendor\` not \`go mod init \` right?
Idk from my experience gopls is far from stable at this point, I've had it crash several times a day or just randomly stop performing certain tasks. I'm curious which tools and settings people use with vscode since modules were introduced.
`go mod init` is fine just run `go mod vendor` afterwards (or when importing new packages) this will create a vendor directory in your project
What is it you actually want to use Blockchain for?
 Yes, gopls is unstable, I can't get the completion of go with vim.
thanks for your reply, \`go mod vendor\` will make a vendor dir,but what time should i use this command, when i import a new package ? can you give a easy example?
Blockchain solves exactly one problem and it is a problem very few people other than banks have. Even then like with pretty much every other problem there are about a hundred ways to solve it. Saying you wish to become a blockchain programmer without any experience is like saying you want to become a lymph node surgeon. Not only is this ultra specific but you haven't even been to medical school. Once you are a doctor figure out what you enjoy because right now you have no actual clue.
Before I continue, did you `go get` the web sockets package?
The biggest Ethereum client, geth, is written in go, so if you don't mind digging the source code, you'll find tons and code samples
[removed]
Looks cool, going to check it out soon. Thanks.
As a vscode user I must say since go modules go tools became very unstable. Autocompletion server (forgot the name) crashes *all* the time. Gofmt flashes the files on format and sets the cursor to [0,0]
[removed]
yes, i go get ,and the websocket package in my \`$Gopath/pkg/mod/github.com/\`
Im just gonna keep it real with you, i found an online article looking for go developers that can make blockchains, and since i have the basic knowledge of go, i thought it was gonna be easy to jumping into learning blockchain in go, but its been a bit difficult
Ohh thanks, im a little disappointed, but i appreciate the enlightenment
It is a problem for all editor users. goland works well ,but you know i am a vimer。
thanks . Any idea about the container boot time for cloud run ?
You say fake, but I am pretty sure I've had Caming Unizans knocking on the door with some pamphlet or other.
Only in appearance, it's still not shipped. And until it's shipped, I'm still forced to wait.
This generated "Loginess" which accurately describes my codebase at work.
The generation is totally random, so it can also generate real words. It's "English-like word" rather than "fake word" maybe.
basic economics? lower supply than there is demand?
Source?
It depend on the company isn't it ?
Because there are lots (and lots (and lots)) of legacy things written in Java. Things that are complex (because there's a lot of in-house code from before various open source libraries existed), important (because your entire business workflow depends on them), and integrated (because microservices are only recently cool). Compare to Golang, which concentrates on having a good, consistent standard library of things that are useful in the modern world, is too new for many entire businesses to be built on it, and comes from an age which is "API-first" and anything can communicate with any other thing in a well structured way no matter what its backend language is.
its abit the critical part by design that this project that its single worker, i need to user it as a 'spooler' - one for executing a process that can only be run once instance of at a time and the other use will be a as a printer spooler where there is also only one printer attached. &amp;#x200B; But dont think its so difficult to launch many workers - its more the intercom between where you push it to the queue and then the reply back part that gives me headache how to do
I'm skeptical that this is the case. I would believe there are far more openings for Java programmers compared to Go, simply because Go is newer, and like [u/g-a-c](https://www.reddit.com/user/g-a-c/) said there's a lot of legacy Java code out there that needs to be tended to.
Thanks for providing this. I was actually looking for something like this or was going to build my own. When you say that this is Dev focused, could that include Ops? If not, would anyone have suggestions for anything better (specifically CLI dashboard) suited for this?
Personally, i don't think the most important use case for generics is a generic "keys" function or the ability to use map and filter. Those are mostly parlor tricks to save lines of code, but don't really add anything to the language. The thing that I really want is new generic datatypes, like trees and graphs and parameterized numeric arrays. Can you show me a binary tree with a user-specifiable key (that is, i give some sort of code to specify the key based on the value) in your proposal?
According to the Stackoverflow Dev Survey it‘s the other way around: https://insights.stackoverflow.com/survey/2019#technology-_-what-languages-are-associated-with-the-highest-salaries-worldwide
Yep, that would be really easy. By 'key' I assume you mean a comparator, right? ```go type Tree(T) struct { node *node(T) less func(T, T) bool } type node(T) struct { value T left *node(T) right *node(T) } func EmptyTree(gen T, less func(T, T) bool) *Tree(T) { return &amp;Tree(T){nil, less} } ``` Then you would instantiate an empty tree like this: ```go empty := EmptyTree(int, func(x, y int) { return x &lt; y }) ``` I guess you can imagine how the rest would work.
Where in the world are you looking? There are definitely some markets where finding any good dev is pretty hard so highly desirable skills like Java (primarily for supporting legacy apps) are paying a decent chunk of change.
I have an even better proposal .. Lets use #T instead of gen T but I don't think the syntax was ever the problem.
Read the proposal. It's not about syntax (only partially).
How is this different than the 4 rejected proposals that Ian Lance Taylor did? https://github.com/golang/proposal/blob/master/design/15292-generics.md#proposal Ian specifically has 2 proposals there that use the "gen" keyword. * https://github.com/golang/proposal/blob/master/design/15292/2011-03-gen.md * https://github.com/golang/proposal/blob/master/design/15292/2013-10-gen.md
I don't want to sound arrogant, but the best way to see the differences is to read (or start reading) the proposal. It's not long and the differences will become very obvious :)
Your timestamps are missing the time zone, so they're not actually [ES standard format](https://www.ecma-international.org/ecma-262/9.0/index.html#sec-date-time-string-format). I'd say that's the first thing to fix. It's also what the error is complaining about.
Also, in general you probably won't get much help if your example code requires knowledge of non-standard APIs you've omitted, like `utils.IndexAndType`.
Don't be too disappointed, there are TONS of cool things you can do and software engineers are in high demand right now. Plenty of people are building with blockchain and they have to support and maintain their code just like everybody else. I used a medical example but realistically it won't take you very long at all. Get the basics down and you will very quickly find yourself able build your own blockchain. Good luck!
Im in Brazil
Intersting, but its not the reality in Brazil
I use vim-go + gopls + go modules everywhere (without /vendor). Without so much problem (i don't use a lot of dependencies) . The code must be valid (with of course import). I use `fresh` to build at each file written, then i'm sure the code is buildable and all modules are here.
I am also using vim-go, but gopls is not related to vim-go. I have found many known problems. I am very curious about how you solved it.
And that's from ... to ...
Do you have a source for this claim or it's just anecdote?
I think GP's point is that much of the Go team's focus in the generics discussion is around being able to efficiently compile, especially in large complex codebases. I scanned the proposal and it seems to be focused exclusively on the consumer side of things (sorry if I missed something). Have you considered building some of the implementation for your idea into the compiler to see how it fares there?
I don't see the need for an additional `gen` keyword with rules like "Mark the first (leftmost) and only the first occurrence". Just use a generic parameter list for both functions and types: func Identity(T)(x T) T func Map(T, U)(a []T, f func(T) U) []U func Zero(T)() T type List(T) struct {}
It looks as if you need to change the format of your input times. You're using 2019-05-20T12:54:29.871000 but it's expecting a time in the format 2006-01-02T15:04:05Z07:00. When working with ES, I tend to just format with RFC3339 and that works fine.
https://blog.golang.org/survey2018-results
The reasoning for the proposed syntax, as opposed to the syntax you proposed is this: 1. Extra parentheses make things less readable. 2. Marking the first occurrence makes it clear where the generic type gets inferred. 3. Only being able to use the `gen` keyword in the argument list makes it clear when to accept an unnamed generic argument to explicitly specify a generic type. Under your proposal, it isn't clear when the user needs to specify types manually and when they can be inferred. In my proposal, this is always specified by the function signature.
Hi! The contracts proposal also doesn't discuss implementation, because implementation actually isn't such a big of a problem. The main thing is that if the generics system satisfies the dual-implementation property (i.e. that every generic call can be implemented either by static specialization or by dynamic runtime implementation similar to `interface{}`), then the whole problem becomes choosing between static specialization and dynamic implementation.
Cool. I can use it for my fake news venture.
I was confused by the words you have used: "novel design". What you propose is actually a slightly different syntax with some important drawbacks (lack of constraints).
The source is the job sites, like indeed, catho, etc
&gt;The source is the job sites, like indeed, catho, etc
Well, perhaps calling it novel wasn't accurate. It is just a nice set of old ideas packed in a nice syntax. Nonetheless, I haven't seen this combination yet, and I believe it's a very good combination for Go.
Questions : &gt;Is the approach correct in regards to using channels and how its seperated from the api handler ? &amp;#x200B; It is close. First, your code to retrieve work could be improved: for { value, ok := &lt;-data if !ok { fmt.Println("Channel is closed!") break } status = "2" message = "processing" update(db, value, status, message) time.Sleep(time.Duration(rand.Intn(8000)) * time.Millisecond) status = "3" message = "done" update(db, value, status, message) fmt.Println("worker - ID done:", value) } `range` loops will terminate when a channel is closed. this could be simplified in several ways: for value := range data { status = "2" message = "processing" update(db, value, status, message) time.Sleep(time.Duration(rand.Intn(8000)) * time.Millisecond) status = "3" message = "done" update(db, value, status, message) fmt.Println("workder - ID done:", value) } i don't know why there's a \`time.Sleep()\` in there. &amp;#x200B; &gt;am using sqlite - that is probably not the smartest way and almost certain not the fastest either, any ideas to what could be better in case of speed ? &amp;#x200B; * i have a problem i dont know how to solve : &gt;in the startJob() - the handler of the api call - when we push the new item to the queue, i respond back to the client immediately - what i somehow would like to do here is to allow the client to wait up to 5 seconds to get a reply if the job managed to be finished within the 5 seconds ( ex the first api call where theres no queue ). &gt; &gt;Since the handling of the job is happening in a workerchannel, i dont have the handle to the httprequest so i am not able to write back to the client from the worker. i was about to answer your questions point by point but let me just say this: what you've done was admirable for a first Go program. i think this was a very small project and i think it would be very approachable to rewrite it from scratch with the lessons you've learned. so i would encourage you to rewrite it while keeping the following in mind: * get rid of all of your global variables and state. * try to encapsulate the data you'd like to communicate to your http handlers within a type. * consider implenting http.Handler by associating a `ServeHTTP()` method to this new type. * consider using error values to communicate errors -- not sentinal values for int or stirng. particularly consider returning `error` from `read()`, `write()`, `update()`, and `readActiveJob()`. * generalize your worker pool. what if your requirements changed so that you could allow more than one worker? i think one of the best talks on this was by Brian Mills of Google: https://www.youtube.com/watch?v=5zXAHh5tJqQ * i'd like to reiterate my earlier bullet point: try to imagine a type that you can create that would encapsulate the data associated with the logic you're trying to implement, then associate functions with it that implement that logic. good job. now throw away this prototype completely and go back to the drawing board.
I like the idea of a limited subset of generics.
[removed]
[removed]
&gt; the best way to see the differences is to read (or start reading) the proposal To be able to tell what’s different, it requires being familiar with previous generics proposals. There have been many previous proposals, and chances are, most people haven’t read and fully internalized them, so it’s hard for them to know what’s different by reading your alone. Hopefully you have, and you’re very familiar with your own proposal, so your insights on what’s different about and the ways it’s stronger and weaker are valuable to share and highlight.
I think that's still possible with this proposal. Just pass it a function that maps the type to the key no?
The standard Mux is also good enough for most APIs.
As somebody that tries to use the standard library as much as possible: when I've tried to use the stdlib muxer for a large API I've almost always ended up regretting it. You end up with lots of logic for switching methods, shifting parameters from the path, etc, that makes it hard to get a clear idea of the API from looking in one place. That's not to say the standard library isn't good enough for some APIs (if it is you should use it!), I just don't think it's good enough for most.
I've found that Saibing's (author of Bingo) fork of gopls works much better than the current impl of gopls. https://github.com/saibing/tools
I just hope they restrict the types. I don't want a file with 50 generic arrays and no way to see what's going on.
Could you expand on what you mean? Particularly, I'm not sure your meaning of the word 'restrict' is the same as mine and I'm not sure what you mean by '50 generic arrays'.
Sick UI! Can't wait for new features!
Why do you need such a thing? Maybe there's another approach to deal with sensitive information which suits you
This may be a stupid answer, but .. Why wouldn't you just read the contents of the template directly (as a file, assuming it is a file)?
thanks alot for your feedback. &amp;#x200B; Note : the **SLEEP** inside that routine that is just 'simulating' work that takes time - should have noted that with a comment or extracted the work into another function - its because the work process can take time. &amp;#x200B; i get almost all your feedback here and i agree i hope i can get to a rewrite of this that looks nice and compact it is abit bloated already even though its performing simple tasks. &amp;#x200B; Would you care to elaborate on these 2 i am not sure i understand it, you by any chance have a code example i could look at that illustrate the possibilities with these two : &amp;#x200B; * **try to encapsulate the data you'd like to communicate to your http handlers within a type.** * **consider implenting http.Handler by associating a** **ServeHTTP()** **method to this new type.** &amp;#x200B; And thanks again so i am not totally off the world here that is nice to know :)
Looking at the Benchmarks section of [this page](https://victoriametrics.com) and I have no idea wtf is going on in that graph. Are graph labels for lesser mortals or something?
Yes, short term i am using upx.exe to compress it but along with compression it makes it very difficult to find any string.
and forgot here - i actually dont want the worker to stop at any point it should always be running and ready for a job.
The graph is just pretty image without much sense. Benchmark results with interesting graphs can be found [in these articles](https://github.com/VictoriaMetrics/VictoriaMetrics/wiki/Articles).
Will check it and provide feedback!
Is this an InfluxDB competitor? Or is it meant to be used as a lib?
&gt; try to encapsulate the data you'd like to communicate to your http handlers within a type. here is the type definition of an `http.Handler`: ``` type Handler interface { ServeHTTP(ResponseWriter, *Request) } ``` that means that any type that implements `ServeHTTP(http.ResponseWriter, *http.Request)` is an `http.Handler` and therefore can serve requests. your program declares global variables that are aware of the things you'd like to do -- particularly an `*sql.DB`, `sync.WaitGroup`, and a `chan string`. imagine if you had a type that you can put those in like the following: ``` type JobManager struct { db *sql.DB wg sync.WaitGroup work chan string } ``` now imagine if we could associate a method with it -- in this case we'd like to serve HTTP data in a way that has access to those values: ``` func (jm *JobManager) ServeHTTP(w http.ResponseWriter, r *http.Request) { // do stuff with jm.db, jm.wg, and jm.work here fmt.Fprintf(w, "hello, world") } ``` finally, in main we can populate an instance of `JobManaager` and start a web server that uses it: ``` func main() { // create an sql.DB instance with our connection parameters. db, err := sql.Open("sqlite3", "jobdatabase.sqlite") if err != nil { log.Fatal(err) } // initiate and test connection. if err := db.Ping(); err != nil { log.Fatal(err) } // create a JobManager instance jm := JobManager{ db: db, work: make(chan string), } // create an http.Server instance and specify our job manager as // the handler for requests. server := http.Server{ Handler: &amp;jm, } // start server and accept connections. log.Fatal(server.ListenAndServe()) } ``` so -- that's a bit much to take in and it isn't ideal but i was trying to get accross how we can place the data that you originally made global into a type and use an instance of that type as a way to serve HTTP data in a way that the HTTP server has access to the members of the struct that we created. for example, the body of `ServeHTTP()` up there can use the `db`, `wg`, and `work` members. to extend this even more -- we can now make the package level functions you declared methods associated with `JobManager`: ``` func (jm *JobManager) update(jobnumber string, status string, message string) (int, error) { result, err := jm.db.Exec(`UPDATE jobs set Status = (?) where jobs.JobNumber = (?);`, status, jobnumber) if err != nil { return 0, err } if _, err = result.LastInsertId(); err != nil { return 0, err } return 1, nil } ``` i did several things here but the big thing to notice is that now we've hoisted the details about what we're doing out of the parameter list and moved those details into the receiver value (which, ya, ya -- is just another parameter but at the moment, lets consider it only in an abstract way). the `update()` method only has the job number, status, and message in its parameter list. now, if you ever wanted to provide an alternative implementation of your update method -- lets say you want to test using a map as backing store instead of an external database -- you can create an alternative type and use an interface as a proxy for your different implementations. &gt; consider implenting http.Handler by associating a ServeHTTP() method to this new type. see above. i kind of rambled on for a bit. i guess i don't have a clear conclusion other than to reiterate: great first try. now try it again having learned from the few mistakes you made.
Oh what i forgot to mention. Groups and domains are fixed. Everything else is dynamic.
ugh. i don't think there's a strong case for generics in go at all. any proposal that complicates the language (adds keywords etc.) i think is a step backwards from go's simplicity/elegance.
I think in order for the proposal to be compelling, you need to do more than simply say "constraints aren't useful", but demonstrate that they're not useful. Look at examples that motivated various constraints systems (specifically Rust traits) and show how your proposal addresses those scenarios (or articulate why those scenarios are invalid). For example, how would your scenario solve sorting if we can't constrain the element to "orderable" or similar? Do you have to box each element in an orderable interface? Do you have to do a dynamic dispatch for each comparison?
&gt; $ CGO_ENABLED=1 go install github.com/wasmerio/go-ext-wasm/wasmer &gt; The CGO_ENABLED part is very likely to be optional Indeed. Unless you are cross-compiling, it is enabled by default.
Those benchmark results are... impressive. Are they cherry picked microbenchmarks or is this really how we can expect real world results will compare?
Exactly twelve of us. There are twelve in the entire world. &amp;#x200B; In seriousness, the Engineering org at my work is about 75 people, about 15 developers have touched our Go services at some point and about 7 developers use it full time.
Contraints definitely can be useful. But I thought the proposal showed many functions that are the usual use-cases for constraints, but are doable under this proposal. For example, `Sort` (requires comparing), `Find`, and `Unique` (both require ==) are all demonstrated in the proposal. The use-cases that aren't possible to do that I was able to find in Go Team's documents are mentioned at the end (generic math functions, string/[]bytes compatibility, graphs, although those can be done in other ways).
thankyou so much i will start digging in ! might ask a question from time to time !
VictoriaMetrics is InfluxDB competitor - see [this benchmark](https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae). VictoriaMetrics is a single-binary application with easy operation. It is possible though not recommended to use it as a lib - see, for example, [this issue](https://github.com/VictoriaMetrics/VictoriaMetrics/issues/33)
Ugh, my bad; missed the Sort example. Anyway, I don't particularly like resorting to dynamic dispatch. I'm also concerned that there may be more complex examples that aren't feasible (specifically generic functions that call other generic functions, especially when the generic types aren't the same).
Well, the type inference is quite simple. When calling a generic function, just replace the generic type with the specific type of the argument (arguments always have a known type). The specific type, of course, can also be another generic type if the call was made from another generic function. From what I imagine, this type inference should always just work. Do you have a particular example that could be problematic? EDIT: Btw, regarding the dynamic dispatch. I agree, it's not perfect. But it's also very flexible. If the sort function required a specific operator to be implemented, then there'd be just one way to sort a single type. However, by passing an arbitrary comparison function, you can sort based on whatever you like, whenever you like.
Looks a lot like the stuff in Odin, (they use `$T` instead of `gen T`). https://odin.handmade.network/wiki/3329-odin_tutorial#parametric_polymorphism
open policy agent
A little different, but definitely similar, yeah. EDIT: Odin actually look pretty cool!
Couple of us at my agency do. Love it.
I noticed I forgot to reply to one of your points: &gt; function that needs to accept arguments of N bytes in size, where N is dynamic and known only at runtime. This doesn't happen, because as you can read in the proposal, generic functions can't be passed around in their generic form (i.e. you can't accept a generic function and then feed it values of different types having it specialize each time). Only a specialization of a generic function can be passed around and the N is always known in advance in such a case. And just to make it clear, functional languages like Haskell also allow passing only specialized versions of generic types unless you enable the `RankNTypes` compiler extension.
You can expect such results in real world applications :-).
Wadler's Law in effect
http://gobyexample.com
Would love some feedback on the API and the project in general! [Here's](https://github.com/Pigmice2733/peregrine-backend/tree/gemux) a link to what using this might look like with a medium-sized API.
I'd recommend to try some CLI apps. I did one for convert temperatures, such as Kelvin to celsius. It helped me at lot! Yesterday I saw a simple app which you can find GitHub users with the github API through a GO CLI. It really inspired me to try using APIs with CLI. For CLI I started with the Cobra library, but I'm searching a way to do with raw Golang. Hope I could help you!
I've long said that this: func Identity(x gen T) T { return x } Should be written like this: type T generic func Identity(x T) T { return x } It's simple and clear.
And what do you do about this one? ``` func Zero(gen T) T { var x T return x } ``` If you did this: ``` type T generic func Zero() T { var x T return x } ``` Then you'd need to do type inference based on the return type. Which, as I described in the proposal, has some problems.
Maybe you mean this? ``` var buf bytes.Buffer if err := tmpl.Execute(&amp;buf, nil); err != nil { return } content := buf.String() ```
First I’ve heard of this! I’m still digging through all your posts. Initiatives like this really excite and impress me. Thanks!
 pathParameters[0] I'd much prefer named parameters. Lack of named parameters couples handlers to the router since each handler must have special knowledge of the exact structure of its path. Named parameters offer greater separation of responsibility between these two components.
[removed]
https://gophercises.com I just started using this website and have been enjoying the tutorials.
I think there could be quite a few reasons. If you are in financial services industry where most of the code is Java, they are complex business apps which require good tech and domain knowledge. So they generally pay above market rates. Infact so much that not even well known tech companies match what they offer. But if you are in other industries then I think java salaries are on average same as good.
You still have coupling between your router and your handlers in this case because you need to use the library mechanism for retrieving URL parameters (`gemux.PathParameter` in this case). While I don't disagree that it provides _greater_ separation of responsibility (since you can reuse the same path parameter parsers/couplers without relying on position), if you really want your handlers to be totally decoupled from the handlers you should provide your own library-agnostic mechanism for passing path parameters to the handler (define your own context keys), or modify the function signature (also has the advantage of path parameter types being known to your handler at compile time). You can easily create a wrapper to do this with the way the library currently is. Again, not totally opposed, I just don't think it solves the problem well enough to add complexity. How exactly would you propose doing named parameters? Appreciate the feedback!
My company has maybe 25 developers working with Go fulltime.
I write a lot of serverless go functions at work. Our platform team uses go heavily for bigger services and our CDNs origin servers
I’m on the Go team and I use Go while working on Go. :)
I'm currently introducing it at work as we speak.
Formatted correctly for those not using the new version of reddit: type Tree(T) struct { node *node(T) less func(T, T) bool } type node(T) struct { value T left *node(T) right *node(T) } func EmptyTree(less func(gen T, T) bool) *Tree(T) { return &amp;Tree(T){nil, less} } Then you would instantiate an empty tree like this: tree := EmptyTree(func(x, y int) { return x &lt; y })
Well basically not how in PHP everyone just throws everything into an array or the same with js [] and all of a sudden you get issues with checking data and you don't know where to look in amongst those 50 arrays of $a = $b; $c = $a['crap']; $d = $c['1']['morecrap']; $e = $d['checkedcrap']['index']; $f = $e['somebigarrayofobjects']['index'] And so on. I don't want that. I don't want that for a second. I don't want to read other people's crap that they are just slamming things into. They better restrict it. Cause that's never been the go way and I hate it. https://golangtutorials.blogspot.com/2012/07/my-favorite-ideas-in-go-ecosystem.html?m=1
I completely disagree that those are “parlour tricks”. I despise the notion that people should reimplement every algorithm every time they need it. Every basic algorithm you reimplement 50 times, chances are good someone did a more optimized and better tested version of. Why would we force ourselves to rewrite code that already exists, worse? A large performance boost .NET Core gained recently was from replacing implementations of some of these methods like IndexOf with more optimized versions that take advantage of SIMD operations. It makes a huge difference, and is something that you’ll never do when you write your own array search loop for the 50th time.
Looks like you killed medium... [https://i.imgur.com/UeeKNSt.png](https://i.imgur.com/UeeKNSt.png) &amp;#x200B; Whats the repo? Love to have a look see..
that's funny, I thought "there can only be one..."
it works for me, however the repo as requested https://github.com/wasmerio/go-ext-wasm
i used ，but some problem also has
Medium link seems broken
Parlor trick doesn't mean it's entirely useless. But next to the value of being able to use data structures other than arrays+slices and maps, it's not terribly significant. Saving three lines on a keys call is not something that will make or break your decision to use Go for some task, it's whether or not you have the data structures you need for your task. Or more complicated and interesting algorithms, like various sorts or numeric algorithms that are much larger than a three-line for loop.
~10/160
You go bro.
https://github.com/Anondo/crontalk Hello, it appears you tried to put a link in a title, since most users cant click these I have placed it here for you ^I ^am ^a ^bot ^if ^you ^have ^any ^suggestions ^dm ^me
Introducing go at my workplace via specialized simple CLI tools.
Cool will check
Great! thanks, I just forked it :D
Java’s been around longer
I like the name, very Go-like :) (I assume it's named in the convention of Go interfaces: https://golang.org/doc/effective_go.html#interface-names)
Since 2014, backbone of our product.
Currently building a trading algorithm in Go using Alpaca’s APIs.
My company has about 150 developers and I’m the only one I know lol
&gt; When i run this as a exec.Cmd in go, and call the cmd.Wait() funtion, it never returns. This is the problem you need to fix. &gt; Some of what the script is doing is starting or restarting services in /etc/init.d, if one of those launches a process in the background, since the parent process is the postinstall script could that cause the process to not fully complete in the eye of the go program? No, they should always for or similar, otherwise they wouldn't return control to your shell when they finish. &gt; Or any other types of commands that could cause this type of behavior? Something holding stdin open or some such maybe? It's nearly impossible to tell what's happening without seeing both your actual Go and shell code. `&gt;2&amp; echo "stdErr"` doesn't look like valid syntax to me.
What could hold stdin open in go and not when run from the shell
I meant blocking for input inside the script. Again, not really possible to give useful advice without code.
Well I could post some code tomorrow, but many of the init.d scripts are custom so it wouldn't be feasible to post every bit of code that this touches. The go side of things works as expected for my test case and other scripts and command calls(I do a preinstall, then untar a package, then the post install where it hangs) so I know it doesnt always fail. I am just trying to figure out what type of command could hang in one, not the other so I can track it down
Do a binary chop on the code (cut it in half, then half again, etc), that should narrow down where your problem is pretty fast.
so the data that is there in my ES Is actually synced from MongoDB by running both mongo (that originally has data in it) and ES with no data and then running mongo-connector to sync data between the two
If you foresee the need to dynamically configure some parameter for the application when it is running, configuration file will be required anyway and frameworks like spf13/viper and lalamove/konfig enable application to see changes in the configuration without need to restart application.
Employed as a full time Go programmer since 2010.
[removed]
I work in a company in India with almost 30-40 people, where all specifically work with go as main backend language, combining it with different DBs and frontend technologies, Me working my first professional job, go is very easy to learn and has many awesome things as we all know, i feel pretty nice working with go!
Our new project back-ends are completely golang. But marketing and e-commerce are still django.i think so %30.
Try removing parts of the script until you can narrow down on the piece that causes the problem. Then paste that piece here
Ya, that is my next step, have to write some test code to do it, the main process for building/deploying the script would get old doing it everytime. Was hoping someone might have an idea what it was before I spent the time looking but I'm sure I'll track it down
I used to.
 &gt;2&amp; echo ... Is the problem, having the &amp; there runs the preceding command in the background, and you only have a redirect there which looks like will not exit if you so not run it interactively. &gt;&amp;2 is the pipe. https://stackoverflow.com/questions/2990414/echo-that-outputs-to-stderr#23550347
Not the problem, just a typo. I was showing what my test script did (it works as expected) it's the long script that locks up on the last line and wont exit properly
I know, you're right. Nevertheless, I'd be much more interested in discussing whether this proposal is good or not.
InfluxDB and TimescaleDB benchmarks are quite interesting. Would be great to have some benchmarks with m3db, pinot and druid as well.
Posting stuff on Reddit (and the internet in general) is very much hit or miss these days. People in general have the attention span of gold fish and are mostly looking for someone/thing to project their fear and suffering on. One negative comment early on will often kill the entire post. I wish more people would take their time to think through the problem instead of blindly trusting Google to do the right thing.
I want to believe people still can have meaningful discussions online. I'm sure many people can. Thanks for summarizing the problem so well, though, I appreciate!
Way to Go!
Make a CLI that runs some text through Google's translation api x times. E.g., English -&gt; French -&gt; Catalan -&gt; Japanese -&gt; ... -&gt; English The result comes out garbled and hilarious.
Gonna have to generate 171,476 words and see how many are actual ones in a dictionary Also why not .MakeFakeWord? 😛
very small thing, you can shorten the err checking: [https://goplay.space/#NYg5RgEiqd\_I](https://goplay.space/#NYg5RgEiqd_I)
I agree on this point too. Plus it's all about the medium you choose to discuss it on. I would like to believe that GitHub would gauge with a better audience since that is where the proposals are currently sitting. But this kind of response on Reddit is unfair towards you and the morals of being a contributor of the larger Go community. I'm sure you have your own merits and achievements to back your insight for this proposal. Overall, I think it's just a bad response by the community here on Reddit. It's a hit or miss. Just try not to take it personally. And consider that all of the world's greatest achievements weren't immediately well received without some degree of criticism and slander.
Firstly, you may have chosen the wrong audience, I don't think I'm alone in that I come here in my coffee drinking and food eating time. I'm here to see what latest projects people have, see if I can answer a question, or read a blog article. Secondly, consider the way that you are proposing your points; we write reports and presentations in a certain way in order to frame the discussion. An executive summary right at the front should bang your points out - if someone is interested then they will wade into the detail. You listed the main points of the proposal in an edit. Thirdly, its a contentious subject, you're not going to get a positive response with this because everyone dislikes everyone else's point of view.
Dude don’t worry. I’m a maintainer of a good sized open source library. As the audience for your ideas gets bigger, so does the volume of the criticism. It’s your job to ignore that and keep on fighting for your beliefs. I like to think of it like this. If your ideas are upsetting people who want to maintain the status quo.... then you’re doing something right.
Firstly, you may have chosen the wrong audience, I don't think I'm alone in that I come here in my coffee drinking and food eating time. I'm here to see what latest projects people have, see if I can answer a question, or read a blog article. Secondly, consider the way that you are proposing your points; we write reports and presentations in a certain way in order to frame the discussion. An executive summary right at the front should bang your points out - if someone is interested then they will wade into the detail. You listed the main points of the proposal in an edit. Thirdly, its a contentious subject, you're not going to get a positive response with this because everyone dislikes everyone else's point of view.
Thanks! The thing kinda is that I haven't gotten criticism. I've only gotten misinformed and misleading comments that led people to ignore the proposal and not give criticism. That's what's bugging me the most.
I still consider that a form of criticism though. You’re thinking of constructive criticism, pushing back on ideas with zero reason is non-constructive criticism. At least in my book. It’s purpose is to make people not want to accept your idea.... without merit.... so in that sense it is a form of criticism
This is an excellent proposal. Where else can I signal boost this?
I truly agree with you, simply giving downvote is not a solution if someone is not okay with what we said he/she must comment with disagreement and not the direct judgment. A few days back even I went through this all I posted some things for that my company i.e [Scalent Infotech](https://www.scalent.io) works on and tired to write down some points and it was not promotional but still some people did gave downvotes and said very annoying things. I really appreciated your post and your intentions behind clearing those doubts out
Thanks a lot! So far it's just this one Gist + I posted it [here](https://github.com/golang/go/wiki/Go2GenericsFeedback). But feel free to share wherever.
I agree, one mistake I made was that I didn't initially list a summary or a table of contents. Thanks for the comment!
No one ever learned anything from a success. Leave mistakes in the past, but take their lessons with you.
It depends on how invocation works. For the existing proposal, you could do `Zero(int)()` IIUC.
Sure! But that has two disadvantages: 1. More parentheses, less readability. 2. Partially up to the user when to specialize explicitly and when to rely on inference. In my proposal, the choice between explicit/implicit is never up to the user. It's always directly visible from the signature.
This is just a general effect of all tech discussions. We discuss the color of the bike shed because that's what we're comfortable discussing. Dan Abramov had [a good post about this](https://overreacted.io/name-it-and-they-will-come/).
I very much like it, but (jumped me right away) I don’t like to pass a main (and I think mandatory) argument (—cron) as flag. I’d expect ``` crontalk translate —bangla “* * * * * *” ``` Otherwise, very nice, will def use it!
Yeah, constructive is the word. Thanks for the nice comments :)
Every single proposal for changes to Go or its standard library has been incredibly contentious, even non-breaking changes to errors. Why would yours be any different? Mountain out of a molehill. Most of your comments in your first thread were just you throwing away your influence over the subject. You antagonized many people who had legitimate questions and concerns. This second thread is the same, a personal rant instead of trying to improve the communication of your ideas. People are turned off by this and you are only helping people lose interest in the technical merits of your proposal in favor of amplifying their dislike of the author. Contributing effectively to a community with diverse technical backgrounds like the Go community requires skill at sustained positive communication to build consensus. Right now you aren't doing that. You are turning off the vast majority of readers by making it all about you.
I like this proposal, contracts just seem like a big wart that's added just for generics with no clear benefit. People will eventually start complaining about Min/Max etc. though, perhaps someone has a good, simple proposal for operator overloading on user-defined types that would work here.
Hi! I completely understand this point of view and I admit, initially, I didn't react very well to some of the comments. Later I edited multiple responses to include actual answers to the concerns. If I have missed some or responded inadequately, please point me to such a response and I'll do my best to improve it.
Sorry for the rough reception, just wanted to say I learned a lot messing around with pixel so thanks for that library
Did you post it on the official go 2 generics proposals and feedback page yet? That is probably the most effective way to promote your proposal and have its merits reviewed. Here is the link: https://github.com/golang/go/wiki/Go2GenericsFeedback
Yep, I posted it under 'Counterproposals'.
The problem is you don't have my undivided attention. You're competing against cat pictures and political drama. I wouldn't be on this sub if I didn't want to hear or talk about Go, but I can't assume that every post is worth my time. So I make summary judgment based on (sometimes ill-informed) comments. Don't take it personally, that's just the medium you're using. I recommend thick skin and overly cheery constructive responses.
Excellent! Thanks for your hard work in thinking through the potential proposal!
you could also just simply ignore reddit and deal with go on the official channels (github, mailing list, etc) sounds like your mental health would be better off
Can I limit the memory / execution time with wasmer? I.e. to provide a sandbox.
I posted here because I'm kinda used to it. I posted here about every one of my Go projects (Pixel, Beep, etc.) and the reactions were great, so you know. I've been talking with a friend of mine and he also suggested posting on the mailing list and yeah, that's a good idea. So I did that, just waiting for the moderator's approval. Regarding GitHub, AFAIK, generics proposals aren't posted on GitHub.
The underlying runtime does have such a feature but it is not exposed yet in the Go library. Please fill an issue and we will work on it :-)!
Thanks! Also, forgot to ask: do we have a possibility to pause, save and restore the VM state?
&gt; I posted here because I'm kinda used to it. Making a drama thread about your bad experience tells otherwise, but I applaud the idea that you can change the reddit community and sincerely hope you succeed. I lost hope long ago
Yep, completely correct. I'm learning.
Personally I feel like generics would decrease runtime, because the compiler would need to interpret a lot more types rather than just assume them. We don’t want Go to become as fast as Python.
Generics are a compile-time thing. The compiler can choose to specialize each generic call which results in no overhead, no decrease in performance. Of course, specializing each generic call could result in a very big binary. So what we need is a good heurestic for the compiler to choose between compile-time specialization and runtime implementation. The runtime implementation wouldn't be slow either, though. It could be made at least as fast as dealing with `inteface{}` and maybe faster.
True
The thought had occurred. But initially i thought i was going to use the same command (translate) for both generation and translation and separate the two operations by two different flags. But then the design changed i think i kinda forgot about the flag. Thanks for pointing it out.
I read your proposal and thought it was a good idea, and then looked at the mentioned thread and noticed that no-one was saying anything particularly bad at all
[removed]
&gt; In my head: "I know. I picked those as examples to demonstrate the syntax and semantics because the Go Team picked them in their proposals as well." The reason I mentioned that is that the proposals need more meat to them to evaluate them fairly. Solving easy problems is easy. The Go Team eventually picked up some very meaty examples by the end. A proposal that stands a chance needs to eventually include a worst-case pathologically complex example in it, too, such as a generic type that incorporates another generic type in it. I was trying to subtly prod you in the direction of a more complex example without outright saying that I wasn't sure you've quite taken the whole problem on, at least based on the text I read. &gt; Me in my head: "If you scroll just a little bit down, I write about how to make your own generic types (with linked list as an example) and, get this, arrays with generic length too. Just scroll a little bit down." I read that. It was not clear to me how to use types that use parametrization in the types themselves, rather than auxiliary functions. It may have been clear to you, but it wasn't clear to me. Clarification requests are normal. &gt; So, 10 minutes after the comment appeared, I politely responded, saying that generic types are indeed covered and described in the proposal and showed them one possible way of implementing a generic binary search tree as they requested. I actually appreciated that, and would have eventually said so, except this is the first time I've had to say so. I'd actually have enjoyed continuing to engage with you, but if you're going to try to read my mind (incorrectly!) and then spray that misinterpretation all over the conversation publicly, I can't say I'm particularly motivated to engage any further.
Perhaps I am overreacting. However, I was never complaining about people saying bad stuff. All I'm complaining about is that yesterday, the proposal received almost no attention thanks to some misleading comments. Also, right now the thread is a lot more positive than it was yesterday (thanks, people!). The post itself had around 5 upvotes and many of my comments (even the ones that constructively answered the questions) had zero, or negative upvotes.
Imagine if Trump got a cat. The internet would be ovar!
Hi! Thanks for your response. First of all, I've never attribute any bad intentions to you. It was just the unfortunate framing of your comment that made it have the effect it had. Writing "The thing that I really want is new generic datatypes" sounds like I didn't include that. I'm sure you didn't mean it like that, but considering that at some points of time your comment had 20 upvotes, while the post and my response were severely lacking behind tells me that that's exactly what people took from it. Your question about parametrized types was entirely legitimate and I hope I answered it in my response. And you're right about complicated examples and edge-cases. I should've included some. I thought it wasn't necessary because the rules of type inference that I (perhaps not clearly enough) described seemed simple enough to me that I really could not imagine edge-cases that would be somehow problematic or hard to understand. But I'll continue thinking.
You should use process like strace and lsof to understand what files your bash script is opening and also what it s doing, adding set -e on top of your script will help a lot too.
Okay, that could be relevant.
Interesting. On a 5MB Go app, though, an additional 1-2MB is pretty significant.
yo dog
I apologize to anyone I'm repeating here. I'm working so I didn't read all the current comments. I know you're very involved in the community--both in Reddit and Github--but I think we all need to remind ourselves sometimes how rough this sort of medium is for communicating. A downvote might mean 12 different things, and an upvote might mean 12 different things. Those things can be meant to signify thoughts that are personal, technical, agreement, etc, which makes it frustrating to interpret when a topic is important and a reply gets buried. That said, it's one of the better systems we have as an open community since only several people in the world make their full time living on thinking about what to do next with Go. It's hard to coordinate as a result. I think you're doing it the right way and might have more success with things you're already doing such as adding the table of contents to your previous post and making this post to try and reboot the discussion. The only way to not get frustrated is by enormous force of will. If you've ever been part of a committee for your city or other local government body, it's a good comparison. I've been very frustrated with lack of productivity and not understanding how 100 people can work together for a year and accomplish a mere tiny list of decisions without my feeling like the "best" decisions were necessarily heard very well. A dictator with perfect decision-making abilities would be much better at these things, but the community wouldn't feel like they were part of it, and the dictator might have less overall success. We're looking at a similar challenge--many people with less than 45 minutes / month allocated to thinking about this sort of thing, so they use instinct and skip some of the decision material. I don't think we can ever solve this problem entirely, but patience will eventually show you how to find the right people to talk to, and you might be able to build a consensus over time and with enough patience. Perhaps you'll find that your proposal in the wiki will generate higher quality thoughts than the responses here. I don't know how helpful it is to pay you a compliment, but I think it might be nice for you to know that when you make a post, I pay extra attention. You are one of the names on this sub that catches my eye quickly, and I have a great respect for your work and productivity. Thank you for all you've done for the Go community. I know I'm not the only one to recognize you in this way, but we might not always share our opinions with the same frequency as critics because criticism is sometimes the easiest thing to share. I think /u/mholt is a good example of someone else who has contributed heavily towards the Go community and found a way to stay sane and keep adapting to communicate effectively despite sharp criticism at times that sometimes misses details of what's actually happening. :) All this said, I will try to read through your proposal in the next several days. I can't promise I will have feedback because I lack a deep understanding of Go internals and suspect the biggest complexities are on impacts to backwards compatibility.
reddit is a place for bikeshedding, not discussing legitimate technical details. If you want to appeal to this audience you should spend more time making a logo for your proposal and publishing a medium post called "generics considered harmful." I'm personally not aware of any good forum for discussing these types of things, maybe there exists an irc channel somewhere. Unfortunately it seems like hackernews, twitter, and reddit have consolidated most of the discussion that happens on the web so we're stuck with the tragedy of the commons.
Thank you, this helped a ton. &amp;#x200B; I will need to marshal to JSON before I send it along to kafka. When you say binary, do you mean byte data? Assuming I'll be unmarshaling into my structs and (re)marshaling.
How often you must per application to need this lib?
Thanks, this is very thoughtful comment and I really appreciate it! I realized that Reddiit probably really isn't the right medium for this kind of thing, so I also submitted the proposal to the golang-nuts mailing list. We'll see how it goes there. Regarding feedback, one of the parts of feedback I'm really interested in is "how happy would you be using the design described in the proposal?" Answering this question doesn't require knowledge about Go internals, so anyone can answer it. Cheers :)
im a junior and use it everyday! lucky enough to have what i think is a super great stack: react --&gt; golang --&gt; mongo/psql
I think you linked a wrong user. The one you linked has no activity.
I currently work on a fork of a large Go codebase for my job. I only started a month ago but I absolutely adore the language and I already made my first lib for it as well.
Ah yeah, turns out https://github.com/mholt/ is /u/mwholt (best known for Caddy server and several other valuable tools and libraries)
Yes. Bare alpine image itself takes \~5 MB so totally depends on the use case/off-the-shelf dynamic configuration handling features used by the application. Provided the feature sets from Viper library, this size overhead can be managed by most applications.
I like the proposal, seems much more Go-like than most implementations. I feel most proposals want to add full-blown generics into the mix, but this is not at all required. It seems a large share of Go programmers are doing absolutely fine without generics, the smaller share would benefit from generics. It seems to me indeed we can solve 80% of the problems by 20% fo generics. This is what I like about this proposal. I will go one further, what is the purpose of generics at runtime? I feel like most problems would be solved by generics at compile time, which will make them more convenient to use (ie. much like \`go generate\` but embedded in the language). This way, any type used in a generic function will invoke compilation of the function with the new type. This also means you can call methods on those type and use +, -, &lt;, etc. as the validity of those operators on the type will be checked at compile time. This is very much like how interfaces already operate, you don't define a type to implement an interface, you simply use the type in a function that accepts an interface and the compiler will spew if the type doesn't implement the interface. For example: func Add(a gen T, b T) T { return a + b } This function will only compile if T is a number type (int, float64, ...) or incidentally also works if T is a string. But in the case that T is an (empty) interface, it will spew `invalid operation: a + b (operator + not defined on interface)`. Ie. dynamic types at runtime are not considered. If you pass an `interface{}` as T, this function will not compile. Pretty much your proposal but changing &gt;**What will happen if a function requires comparing generic values with** **==** **but we use it with a type that doesn't support** **==****, such as a slice?** The compiler should be always able to figure out if a function requires its type to be comparable with == without any sort of annotations. This would, therefore, result in a compile-time error. In a situation that the compiler wouldn't be able to figure it out (I'm not sure it's possible), a runtime panic would occur, just like with interface{}. into complete type checks at compile time, not just ==. It would be dropping the **dual implementation principle**, could you explain why this is an important principle? This would solve the problem for most major projects that need generics, namely: * mathematical libraries * algorithms and data structures * functional constructions However it won't help with type safe heterogeneous containers, value type boxes or type hierarchies, which I would argue add little value in the spirit of Go. I am not too advanced in my knowledge of the problem area though, so forgive my ignorance if this proposal is silly.
There are many proposals though, the list is quite full. Do you think yours is the *one true proposal*?
Hi! What you're proposing is very similar to how C++ does templates. You can just write your functions and use whatever operators and methods in them and the compiler will just figure it all out. This is very convenient, but comes with some problems. First of all, error messages can get very complicated to the point where it's hard to find the actual source of the error. Look at C++ for reference. The other disadvantage is that this makes it kinda hard for a user of a generic function to know what the function requires. It's not mentioned in the signature or anywhere else, all they have to do is to rely on documentation, source code of the function, or simply trying to shove their code through the compiler. So, what you're proposing definitely isn't silly, but I personally wouldn't prefer it because of the mentioned disadvantages. EDIT: Oh, forgot about the dual-implementation principle. It's importance is just that it enables compiler to do decisions. Specializing every generic call can result in an overblown binary. Implementing every generic call at runtime can result in degraded performance. Therefore it's good if the compiler can do the right heurestic to decide each case.
I agree with GP too. There have been isolated pockets of the internet that have been good for thoughtful discussion (last one I saw for tech stud was HackerNews before about 2009, though I’m sure there have been others), but most people don’t read and don’t know what they’re talking about. The best strategy I know of is to seek out specific people whose opinion you trust and ask for their feedback, ignore what strangers on the internet think. (FWIW, I read your proposal and thought it was well thought out and very go-like, but I don’t do enough Go programming these days that would benefit from generics to have an informed opinion — so I didn’t comment.)
Haha, that's a funny question :). But, to be frank, I do think it's a pretty good proposal. Wouldn't call it _one true proposal_, because guess there are some possible improvements that I don't see, but I'd say it's better than all the other proposals.
Welcome to reddit ...
There is no difference between the two that I’m aware of. The second example is most commonly used, in my experience. One thing helped me understand pointer/value passing: go ALWAYS passes copies of values passed into functions. Should that value be a pointer, then a copy of the pointer (it’s value) is copied and passed — which allows functions to reference the original because a copy of a pointer still points to the original object. Hope this helps!
Maybe use window.location as host url instead of localhost IMO cmd should only have a main.go, anything else should be in internal or pkg directory Maybe try a little parser tool, but that’s highly optional I think Otherwise the code is better than you said imo (haven’t read quite half of the codebase, but still) EDIT: oh and maybe put the bind script as a go:generate statement in some go file
Unfortunately /r/golang is not really the shiningest example of the Go community. If you want help polishing up the proposal, I'd ask for some volunteers on the gophers slack with the goal of cleaning it up and filling in gaps and then making the proposal through the standard proposal process. You'll get detractors there too, of course, but you should also get substantive comments, and that's where you need to be anyway to get the proposal tuned to what the Go team wants. They get a fair amount of flack for go modules, but they do take community suggestions and proposals seriously and adapt and adopt them when they are good.
Right. What really is the standard proposal process and where can I find information about it?
Not yet :-).
I am no experienced programmer at all so I really can't formulate a proper opinion on your proposals, however, I would encourage you to take a look at [Kialo](https://www.kialo.com/) and its discussion system (a kind of tree-structured system) which proved to be well built and definitively a better platform for constructive criticism numerous time in my personal experience. &amp;#x200B; Might be a better platform to argue your points.
I'm fairly new to Reddit but so far I think the downvoting system is too negative. I think not upvoting something is nicer. Or if you downvote you should have to comment why. If something is inappropriate then it should be reported and removed by mods. Chin up.
Out of curiosity, how does it compare to Life's AOT "polymerase" option? They have similar graphs to yours (towering spikes for everything else, miniscule slivers for the best time) on their website for the AOT version of Life.
Often times on reddit I find myself correcting people in comment section about something they said because they clearly didn't read the linked article. It really is a big problem. Many people just skim stuff and comment without really being informed. Also if a threaded discussion becomes elaborate, the nature of reddit commenting system makes it so you have to constantly address the same questions because the person may not have read the part of the discussion where you already answered something. It's a real problem.
&gt; `&gt;2&amp; echo "stdErr"` doesn't look like valid syntax to me. It's valid syntax but doesn't have the intended effect, `&gt;&amp;2 echo "stdErr"` would work though.
Sorry, I should've linked it but something something mobile :) [Go Proposal Process](https://github.com/golang/proposal/blob/master/README.md)
Thanks! However, none of the other generics proposals is on the issue tracker, so I don't know if I should post this one there.
Thanks, I have clear this difference. I am more interested in understanding if there is a difference in the stack frame of the caller. I suppose the first one allocate the entire struct in the stack frame, but the second one should allocate just a pointer? If yes, where is actually allocated the struct? How does the GC works for both of them? I updated the post with these questions, I think I was too concise!
Look at handle types in the doc website: https://jmoiron.github.io/sqlx/ &gt; Handle types all embed their database/sql equivalents, meaning that when you call sqlx.DB.Query, you are calling the same code as sql.DB.Query. This makes it easy to introduce into an existing codebase. You can likely start with an existing project and convert to use sqlx without any initial changes, and that's what you're seeing here. ``` type DB struct { *sql.DB Mapper *reflectx.Mapper // contains filtered or unexported fields } ``` See also: https://golang.org/doc/effective_go.html#embedding
It's so common on Reddit it's ridiculous. They'll read the headline which is rarely ever accurate and assume knowledge on its contents. Even worse is when they rant for like 3 paragraphs about an article they never read. Instead of taking excessive time to rant about it they could have used half that time to read the article. It's frustrating.
&gt;https://odin.handmade.network/wiki/3329-odin\_tutorial#parametric\_polymorphism `$T` wins in my opinion
Is there a free plan for Google translator API ?
been reading alot along the feedback you sent me and think i understand now how i can pass globals through to api's either directly or by the struct, but havent got the grip around the server struct and how i would be able to add api routes here and create the functions to it - hope you can help. &amp;#x200B; One thing i cant get my head around in your example though is - how would you in that code refer to different api's ? &amp;#x200B; ex if you want to create the route for 'update' - and create another route for 'getitems' - am unsure how i can do that as the serverstruct only have one jobmanager struct i can pass on - and if i use http.handle - jm.update() - then it will compile but complain at runtime (as it needs 3 params ) &amp;#x200B; Do i need to create the routes in serveHTTP or how can i do that ?
All I can say is don't take things personally. You would be more happy with this approach.
Right -- you can simply handle them in ServeHTTP(). You're not doing any fancy matching so something as simple as: ``` switch r.URL.Path { case "/StartJob": u.StartJob(w,r) case "/GetJobStatus": u.GetJobStatus(w,r) default: // send an error to the client here } ```
There are actually a number of generics proposals on the issue tracker: many small proposals in [\#15292](https://github.com/golang/go/issues/15292), [\#27605](https://github.com/golang/go/issues/27605) proposes using interfaces, [19412](https://github.com/golang/go/issues/19412) proposes discrimiated unions (which could be used for some generic math functions), etc. It's true that there aren't many serious contenders for generics, and I think a lot of the discussion about the Go team's proposals were done on the mailing list following the Gophercon presentation, but there are definitely (counter)proposals to some of the "big three" (e.g. `must` instead of the error handling changes: [\#32219](https://github.com/golang/go/issues/32219)) that have been posed through the proposal process. I would expect that, when the Go team actually has something they think is worth seriously discussing implementation in the language, it will be proposed via the same mechanism.
Nice research! However, most of the proposals listed [here](https://github.com/golang/go/wiki/Go2GenericsFeedback) aren't on the issue tracker. However, I will definitely consider posting it to the issue tracker once I get some more feedback, either here, or on the go-nuts mailing list.
You could post it there certainly, yeah. I view that page as an attempt to sway the Go team and their proposal. The issue tracker version is for starting a proposal yourself. I'm not sure which is right here.
&gt;Some of what the script is doing is starting or restarting services in /etc/init.d, if one of those launches a process in the background, since the parent process is the postinstall script could that cause the process to not fully complete in the eye of the go program? Are there any "trap"s set in the shell script that may run "wait"? Is the script trying to read from stdin and not getting any data? **E** (It sounds like you're reading stdout/stderr already, so I'm guessing that classic deadlock isn't the problem.)
There are people on this sub who can answer this for the current implementation, but even this last release made changes to escape analysis, so more and more things can be stored on the stack instead of the head. I would think the chances are that both those examples would be allocated in the same way, but I don't know personally.
I've worked on quite a few APIs of different sizes and I never had problems. Care to share your API or at least the routes that gave you trouble?
cool, thanks :)
Chunking and sent via a gRPC stream
I'd just like to say that I like your proposal. It makes sense and fits with the general spirit of Go. It's also probably the first proposal I've read that just seems to fit - yes, even better than contracts. So thank you for writing this rant, because otherwise I would have totally missed it. I check in on this subreddit about once a day and completely missed it the first time. That's probably because of the trolls. I agree that sometimes the down voting gets a bit much, especially from those who don't really understand the point. Keep fighting the good fight. That's also the Go way :-)
You could use something like https://github.com/23/resumable.js on the client side for chunked uploads and then reassemble them on the server. The readme has a pretty good explanation on how to implement it.
I appreciate you bringing your experience up here and it looks like it's sparked a lot of great discussion! I just want to mention that I've noticed even on the Go mailing lists that generics proposals are receiving less and less individual attention. I believe this is because the broader community is suffering from proposal fatigue. For all the counterproposals on the Go2GenericsFeedback page, there are 2 or 3 times as many that proposals have been posted here or on the mailing list and I think for that reason people who have the expertise to properly critique generics proposals are wary to invest their time into reviewing new ones. I'm not saying this to discourage you from posting your own, I'm just letting you know that it might be an uphill battle to get the right eyes on your proposal even if it is very well thought out. I wish you the best of luck!
The first rule of Reddit is that noone ever discusses being hit by downvotes.
Yep, the byte data. If you stick the byte data on the Kafka topic, then the consumer has to have the library too, but it sounds like you’re on top of that!
I like this proposal, as it's simple to use and covers all my use cases I can imagine.
&gt; The main thing is that if the generics system satisfies the dual-implementation property (i.e. that every generic call can be implemented either by static specialization or by dynamic runtime implementation similar to interface{}) Is there a good way to restrict acceptance to only static specialization? (I'm thinking in terms of optimization.)
This issue in Github repo have some more info regarding comparison with Life's AOT Polymerase: [https://github.com/wasmerio/go-ext-wasm/issues/16#issuecomment-497139714](https://github.com/wasmerio/go-ext-wasm/issues/16#issuecomment-497139714) &amp;#x200B; In summary: we have similar numbers, but their approach is not ideal as it's not trivial to set-up and have other dependencies in the environment such as clang
I'd be interested to see how much this adds to compliation time.
https://tus.io/ is a pretty solid choice for solving this if you want to introduce a dependency and also care about being able to resume uploads. https://godoc.org/github.com/tus/tusd is a Go implementation of the server side portion of the protocol.
The difference is that the type of a in the first snippet is struct and in the second is pointer to struct. There is no "preferred" way. If the code that follows needs that a is pointer you use the second variant and if it needs a struct you use the first. If there is no other code using the value of a then you'd be better off using editA(&amp;A{3}) and be done with it. The value A{3} will be allocated on stack if it does not escape (see go escape analysis) or on heap otherwise. &amp;#x200B; [http://www.agardner.me/golang/garbage/collection/gc/escape/analysis/2015/10/18/go-escape-analysis.html](http://www.agardner.me/golang/garbage/collection/gc/escape/analysis/2015/10/18/go-escape-analysis.html)
Love it! Great work :)
I'm not entirely sure what you mean by 'restrict acceptance to only static specialization'. With the dual-implementation property satisfied, the compiler could be made to always statically specialize. But, that could result in very big binaries.
Exactly what data structures have caused you to wish for generics? For me, it has been ConcurrentMap. That need could also be satisfied by the ability to implement or override map functions. That, and better ways to implement math libraries.
Thanks a lot!
I've finally started reading the blog post and it's gold :D Thanks
The thing I think I see the most is a page of 100 items loading and then the ui sends 100 requests to the backend for details on each item. There might be different decisions based upon your needs, but often I see a page make 800+ requests and that is probably a pretty inefficient way to build a page (especially if not using http2). Between the server and a database, you can get the same problem--hundreds of queries instead of writing a better single query. In terms of Go specifically, I haven't really seen a particular pitfall related to performance. The slow parts of a web app are going to be related to logic mistakes that duplicate or fragment disk or network IO.
True. I'll try and push it further so that it gets a chance. If it doesn't work out, well, I at least hope the Go Team will come up with something that's better than contracts.
I read the thread yesterday and I wanted to suggest to you to submit the proposal to [https://github.com/golang/go](https://github.com/golang/go). That would get you actual constructive criticism unlike a social network like Reddit. May be you already did but I didn't find it.
I don't think so. WhatsApp's Click to Chat feature does not works with "+". Take a look: [https://api.whatsapp.com/send?text=text+with+spaces](https://api.whatsapp.com/send?text=text+with+spaces). Using "%20" it works properly: [https://api.whatsapp.com/send?text=text%20with%20spaces](https://api.whatsapp.com/send?text=text%20with%20spaces)
lol thanks, merged it. And i was planning on improving the serve command, thanks for the heads up
i am glad :)
copy of [this article](http://phpmagazine.net/2019/05/roadrunner-the-php-application-server-written-in-golang.html) about [https://roadrunner.dev/](https://roadrunner.dev/)
Sometimes I’m tempted to post unoptimized code and say it’s the most optimized just to see if someone will optimize it for me and save me the time, or write a book report about a subject that’s entirely wrong and refer to myself as an expert on the subject. Someone will pick it apart piece by piece and rebut it, if enough people do it you’ve essentially wiki effected your issue by claiming expertise in ignorance. The great thing about the internet is it’s powered by the voices of just how wrong you are..
We’ve gone from ‘the medium is the message’ to the title is the message. Titles and headline are designed to elicit emotion and get people interested in reading the article, titles on social media just send people right into the comments. They should make it so you click the link, you get a comment token from the end of the article and then you can proceed into the comments once you’ve gotten a token.
It's both invalid, _and_ not the intended usage - you can't background a non-existent command, which makes it invalid syntax (though it's possible some shells might let you get away with it I guess), but also doesn't redirect to stderr as was probably the author's intent (I was trying to prompt OP to look at the code and work it out themselves).
Ur welcome BTW, afaik cron can have up to 7 fields
This is great but [proxy.golang.org/privacy](http://proxy.golang.org/privacy) seems to link to [https://policies.google.com/privacy](https://policies.google.com/privacy). Are we really subjected to Google's privacy policy as a whole when using the Go module proxy? I've not attempted to read it so I don't know how bad it really is but this certainly doesn't look like a good thing to me given what Google's core business is and how the a common company wide privacy policy would be shaped to support that business. &amp;#x200B; For example the policy says it tracks information about us when we use Google's services including: * Terms you search for * Videos you watch * [Views and interactions with content and ads](https://policies.google.com/privacy#footnote-content-views) * Voice and audio information when you use audio features * Purchase activity * People with whom you communicate or share content * Activity on third-party sites and apps that use our services * Chrome browsing history you’ve [synced with your Google Account](https://policies.google.com/privacy#footnote-chrome-sync) Does this mean the Go proxy could legally identify a Go user and track all packages they ever attempted to install? I'm not saying the Go proxy authors intent to do this but using his privacy policy does not exactly instill confidence.
There's a free plan and a secret API used by the translator extension for chrome that you can use .. secretly
downvotes are the root of all evil
https://git-scm.com/book/en/v2/Git-Basics-Git-Aliases
This is absolutely terrible. Privacy policy links right to google. This is turned on by default? I absolutely hate this. Now Google needs to know what packages we are installing? I really hope they reconsider this because I really don't like where golang is going anymore. I couldn't agree more with you.
Even the best proposals might not have enough of an interested audience. &amp;#x200B; FWIW, I don't really want generics in golang, even if they are done elegantly, although I can't quite articulate why, at least not without questionable references to pandora's boxes and such... It might be interesting if you could get attention of Rob Pike or Russ Cox or others who have thought about this concept in go from the beginning (and so far rejected it) and are out there speaking about go, and get their perspective on this particular proposal.
I'm sure there is no malicious intent here. Just that it was probably easier to link to this to cover the team legally until they can get hold of legal to draft up a specific one for Go proxy. At least I hope that is the case. A general purpose proxy like this for a general purpose language that is considered an open source project instead of a product shouldn't need Google's all encompassing privacy policy.
Even better. Generate a token that can be seen when they post after they click the article. No reason to stop people from posting if they didn't read but make it so that they are shamed if they don't read it and still comment
While I don't think there is malicious intent, I do not think something like this should be enabled by default. Google is hosting this and the traffic will be going through their infrastructure. To be clear I don't hate that Google is working on this. I actually like that. I am largely against this being enabled by default but do appreciate it can be turned off. This can be disabled by setting `GOPROXY=direct`
Yea I agree.
BTW Github issue: [https://github.com/golang/go/issues/32343](https://github.com/golang/go/issues/32343) Hope we get an answer soon.
i luv to content
Yes, tokenshaming.. I like it
Go's specification doesn't say anything about a "stack" or a "heap". Obviously, the implementation uses them, but it will use whichever it thinks is better. Generally, if you (statically) take the address of any local, Go will allocate that local on the heap instead of the stack, *unless* it can prove that it doesn't "escape", in which case it will put it on the stack instead. The same is true of temporaries like `A{3}` in your example. So if `editA` does something that makes its pointer argument escape (or anything too complicated to verify that it doesn't), both forms will cause a heap allocation. On the other hand, if it clearly doesn't let the argument escape, then neither will cause a heap allocation. So it really has more to do with `editA` than how you write the argument!
I'll throw my hat in the ring here as a general purpose software developer consultant who started his professional career with Java. Today I still use Java on a day to day basis but it's only about what the client requires, so that can be Go, Python, etc. With that said, Java is for "enterprise" software. These are your big, \_generally\_ slow moving organizations who don't want to put up with a lot of risk. Contrary to what you hear, Java is not a terrible language. It's not a slow language either. Oracle is ruining it, but that's neither here or there. It's biggest strength for enterprise software is its integration capabilities. For example, a lot of your big organizations will still have some type of mainframe, or at least a "midrange" server. These machines don't communicate well with applications running on newer platforms unless you're communicating with the mainframe/midrange machine via web service or message broker. Most of the applications written for these systems are not web service enabled. For example, on an IBM AS/400, you can invoke RPG programs on it remotely using JT400, a Java library, because IBM still supports Java. In a lot of cases, you're stuck using those old interfaces to interact with these systems. Java's messaging and middleware libraries also make it stand out communicating with these systems, message translation, brokering, etc -- for example, Apache Camel. Java jobs pay more simply because there is more demand for them. My point is that a company that still uses these types of systems will pay more for someone to maintain them. What's the alternative? Porting them to a new system with a huge financial hit, with no \_perceived\_ value in doing so? Java is replacing COBOL, which STILL exists to this day.
[removed]
Here's my rule of thumb. For every 30 people who look at a post 20 will skim or just look at the comments only to decide they don't feel like reading, 6 will read it and probably leave no comment, 3 will only comment on comments and 1 will be a shithead For example, I saw this the other week. OP first sentence is literally he has no data on his laptop. There was a couple of comments saying his data can be stolen which he address in the first sentence and other people who have no concept of a memory leak and thinks that means code execution exploit. I laughed my ass off and think maybe my ratio is a little low [https://www.reddit.com/r/linuxquestions/comments/bqn8we/can\_i\_disable\_the\_intel\_spectre\_fixes/](https://www.reddit.com/r/linuxquestions/comments/bqn8we/can_i_disable_the_intel_spectre_fixes/) But anyway I think your expectations was too high. Might be better in githubs issue section
Actually you said chunked file upload and streaming via socket are two different alternatives. There are other alternatives including one that uses both i.e. sending file chunks on a stream. Here is gupload written by cirocosta. I was a concept demonstrating golang grpc clientstream, but the details of the actual saving of the file on the server side were left out. I added in a simple file create and write chunks part to this ensuring file uniqueness using timestamps. It will need more work for your purposes, but it's something to refer to at least. https://github.com/cirocosta/gupload/issues/7#issue-448997678 grpc is good because it does support the latest tls. I hope it helps. BTW I wouldn't recommend http nor http2 because they are inefficient for sending file attachments of any size. Just use plain grpc with tls to transfer your files. example server/client with gupload. Please note I didn't use the http2 switch in order to use just grpc: Server side ``` gupload serve --port 1313 --key ./certs/localhost.key --certificate ./certs/localhost.cert ``` Client side ``` gupload upload --address localhost:1313 --root-certificate ./certs/localhost.cert --file ./SOMEFILETOSEND.bin ```
Thanks, that is a lot cleaner
I didn’t see you original post and skimmed the proposal. Regarding your first point with identity why would it be resolved like the following? func Identity&lt;T&gt;(x T) T { return x }
Not necessarily specific routes just: * You have to implement logic for switching methods * You have to implement logic for popping stuff from the path * You lose out on having a SSOT for your entire API, instead of looking at one function that registers your handlers you have to `&lt;gd&gt;` to your handler while following along with whatever logic happening to do the above two things Again, I think those issues are probably worth it for small APIs, but I would rather import a muxer that solves these problems than implement it in one of my projects' code base. The dependency is worth it to me for large projects. Is there a way you've gotten around those issues with the stdlib muxer that I'm unaware of?
Cisco is having a hiring event in the Bay Area, it's free AND there will be baby goats. If you're in the area: [https://www.eventbrite.com/e/goat-the-greatest-of-all-thursdays-with-the-greatest-of-all-teams-tickets-62258921109](https://www.eventbrite.com/e/goat-the-greatest-of-all-thursdays-with-the-greatest-of-all-teams-tickets-62258921109) Cisco Webex presents The Greatest of All Thursdays! \- Have drinks and appetizers with the Cisco Webex Team and Executives \- Learn why we think we're the GOAT (Greatest of All Teams) on the GOAT (Greatest of All Thursdays) \- See our work come to life! \- Oh and come hug REAL baby goats (no, we're not "kidding").
&gt; I'm sure there is no malicious intent here. Just a happy accident… In the announcement, she links the privacy policy before the service itself. They know this is dodgy, but I'm not sure Googlers can help themselves doing things like this. Putting everything on Google's world-class infrastructure, which is right at their fingertips, is the path of least resistance, and hoovering up All The Datas! is as natural as breathing to them.
Care to add [go.starlark.net](https://go.starlark.net) to your set of benchmarks? I'm curious how it compares to the other evaluators. &amp;#x200B; Tip: call b.{Stop,Start}Timer around the setup code in your benchmarks to avoid skewing the results. The only code you should be timing is the loop of b.N iterations.
&gt; I'm sure there is no malicious intent here. Are you [Mozilla](https://twitter.com/johnath/status/1116871231792455686)? Or maybe you are [Microsoft](https://news.ycombinator.com/item?id=18697824)?
Yes tus is good. I have also written a tutorial about using tus protocol recently. [https://golangbot.com/resumable-file-uploader/](https://golangbot.com/resumable-file-uploader/) hope it helps
Looool
Exactly this, Golang is just so nice. I know JavaScript gets a bad wrap but there are nice parts about it. And i feel Golang has a similar ease to it as JavaScript does, you don’t need to explicitly write what everything is, but still provides the type safety of a compiled language.
Since when does JavaScript provide the type safety of a compiled language? Typescript, sure...
Sorry it may have come off incorrectly, I’m saying JavaScript allows for less specifying of what is what, Golang provides the type safety.
Until you need to write the same struct 5 times because there’s no generics! Hopefully this will be fixed soon
I’m still learning but I’ve had a few “whoa that’s cool” moments, especially when I learned about interfaces. Still getting caught up a bit by thinking in terms of inheritance though.
I agree, I’m hoping this does get solved soon. It feels imminent, but who knows.
It will be for sure, I just hope they choose the right generics implementation for Go (which idk exactly that one is)
Thank you for the link. Apparently it's temporary: &gt; That's right - the privacy policy for the servers is currently Google's standard privacy policy, so that URL is a simple redirect. We very much want to provide more specific information in the future. When that happens, proxy.golang.org/privacy will be updated to either redirect to the more specific policy or serve it directly. That's all I can say right now. -Russ Cox
Write just one function, not a method
Thank you for the help and thoughts. For images, the 'substitution' is made more clearly in that it checks each delta individually against the actual pixel color values. When it finds a match that is suitable for that byte value, it writes those values and coordinates back in the message. For bytes, the purpose is to basically supplement those deltas since there just isn't much else to go off of. You're right, and I appreciate the criticism on much of this. My differing opinion in this is that I think those things can absolutely be overcome with this same idea. The basic answer is to use a larger key, in both instances. As far as copying and pasting, they would need to analyze each instance of a coordinate, and that means they would have to be able to infer both coordinate values, which means knowing part of the message or what some of the coordinates mean. It is definitely a problem if you see a repeat of a coordinate, and I intend to do more work on allowing key analysis for a better picture of how useful a key is based on number of differing bytes and length. The ECB Penguin was really helpful for me. I should probably read up further on much of this, but after spending a few hours at it, I found the basic issue being that I initialize my searching for values in a very predictable way and went through them the same every time. After making changes to my byte encoder, I managed to get this image: [https://i.imgur.com/HDPcnYq.png](https://i.imgur.com/HDPcnYq.png) . To be clear this was using a random 256 byte key against a random 256 byte key. After reproducing your assertion, I was able to change the initial search and iterators to make it slightly less predictable. I also have made changes to not allow bytes under the size of 64 bytes to be used, or images under the size of 300x300 to be used. There is a lot more work to be done, but these are the initial steps in making this a much better encoder. I think this could be useful in conjunction with other methods to obfuscate data further, and I hope you'll find it more useful after the changes I've made, and further changes I intend to make as I continue on this. I would like to eventually write an article on lessons learned and possibly a more useful analysis and demonstration of how this works, but there's still a lot to and for all intents and purposes this is a side project for me. Sorry to get back with you so late after your message, but I wanted to get this all fixed on master.
Most engineers don't need generics and they add a ton of complexity to the language. Part of why Go is the way it is is because the language follows that mindset. If you need generics so bad use another language.
TS is one of the best things that happened to the JS ecosystem.
👍️👍️👍️
Didn't you mean Python? I came into Golang from Python background and it feels so much more like Java, which I used in a past for a bit.
Well that and JavaScript not really doing multi threading. Also race mitigation, channels, static binaries, there's so many nice things I like about go.
Full time Go developer since 2018, almost year now :)
Spoken like a person with very little understanding of why generics would be useful.
Care to enlighten me, or would you rather say the only reason I could possibly not want generics in Go is because I don't understand their utility?
To name just two examples: any sort of container type would benefit as you'd get rid of runtime type assertions, as would anything like `math` so you don't have to convert everything to `float64`. Basically most places where people are copy-pasting code and/or using `interface{}` + runtime type asserts to handle multiple different types
I also come from java too and I enjoy Golang too. I kind of miss try/catches though.
Yes, those would be nice. I think those are fairly obvious examples of applications of generics. I understand why generics could be nice, I just don't think they're worth the complexity. You can disagree with that without saying that I must just not understand.
Maybe if you're comparing it with 90's Java. Modern Java is really quite expressive, and much of the verbosity is cut down with the `var` keyword, try-with-resources, fluent APIs, etc. I personally find GoLang to be quite verbose for some sorts of things, such as manipulating strings, and generally the error handling. That's obviously not to say I don't find Go useful - there are many places it's the ideal language (writing agents, sidecars, proxies, Docker entry points / health checks).
Go has [generics](https://github.com/google/gvisor/tree/master/tools/go_generics). There is no reason to write the same method 5 times. It is just that the implementation leaves a lot to be desired, which will hopefully be improved upon with time.
Few words* \* you have to type over and over and over and over.
Interesting proposal. You can likely get fairly far on the genetics problem with this approach. I do have some questions, as some things aren't as clear to me. How do you deal with the same type being referenced multiple times within a function definition? It seems to me that the idea is to only specify `gen T` once in the definition. So would I be specifying the `gen T` at most once? ``` func Add(a gen T, b T) T ``` Would this work with the potential short form of the function? ``` func Add(a, b gen T) T ``` I would imagine that the parse results would be slightly different in those two cases. Or are you allowed to do it in both ways? ``` func Add(a gen T, b gen T) T ``` Next, you specify that the mechanism for passing a type is to just specify the type place holder as ```gen T``` within the definition. ``` func Zero(gen T) T ``` I think this potentially causes a little bit of ambiquity with how some of golang's current definitions work. I understand that the generic is only meant to be applied at a package level definition, but the following is currently valid in golang: ``` type MyFunc(int) int ``` Vs ``` type MyFunc(a int) int ``` If you begin naming your parameters, then the ast tree for the function definition expects all parameters to be named (as it currently stands). Since the difference between passing a type vs passing a value is the apparent lack of a named parameter, this seems like it might be ambiguous writing golang's current parsing ruleset. In addition, it seems like the generic array size syntax it's essentially identical to the type. How would one know if `gen n` is supposed to refer to a type or a value? As specified within the proposal `gen T` refers to a generic Type being passed into a function like an `int`. Yet, at the same time `gen n` allows you to pass a value and not a tie for virtually the same syntax. It's the capitalization meant to indicate the difference? That seems like that could be problematic potentially. ``` func FillArray(gen n, gen T, zero func() T) [n]T { // ... } FillArray(5, int, func() { return 0 }) ``` Beyond those potentially confusing points the proposal send fairly well thought out. I'm not certain it would be any simpler to implement, but it does seem like it would have components that are earlier to understand for the implementer and maintainer. Please forgive any formatting errors, I posted this on mobile.
Thanks!
Very well written article, thanks for sharing!
I don't understand why `GOPROXY=direct` is not the default ? We can then choose the proxy we want... Also to make a proxy by default will break if we have a private repo...
demo [http://felix.mojotv.cn/#/ssh](http://felix.mojotv.cn/#/ssh) both password and user are \`admin\`
if err != nil { .... }
what exactly are you passing to exec, can you show real data of what 'command' includes ? &amp;#x200B; note you seem to be just executing a shell (sh) - if you want sh to execute something you would need to add -c to it for it to execute something.
I like it!
We are in 2019. We learned in the hard way how code repetition is bad, dangerous and expensive. If a __new__ programming language do not provide tools to avoid this in a secure manner, this language is not a good one.
Channels only work within a single program. Now, it seems to me like you'd be better off just implementing a function instead of combining two programs.
I can't agree more. I too find go to be verbose and less type safe than Java. But small, static binary and fast compile times is cool.
Less type safe?
I don't think this is the best way to describe Go. There are many cases in Java or other languages where Go actually forces you to write _more_ code. (the lack of polymorphism comes to mind here) I think Go would be better described as spartan and opinionated. It doesn't have certain features or syntactic sugar, and forces you to write and structure code in a very specific manner.
I find interfaces a bit weak in golang. May be because of Java background though. But I think Rust's way is much better than java and golang
We do in London team (only 3 of us), the rest of the company doesn't at all though
I know, but that is not the officially standard way. As a matter of fact 7 fields are useless(as far as i know). So i kinda enforced the standard here :p
im certain you still need to realize implicitness of golang interfaces :)
My first feeling after using Golang is like you, but after couple months, i realized that's so annoying 'cause Go is lack of many important features. Go is the best candidate for backend, and no more. Lacking of Generics, try/catch make me type more useless core. Using composition, not fully OOP make Go can't be a good for UI development. &amp;#x200B; Swift, Dart or Rust are the best candidate for general purpose language so far.
Argo
The `...xs` syntax takes multiple arguments and turns them into a slice. E.g. the invocation it expects is `f(a, b, c, d)` where it sounds like you're giving it `f([]t{a, b, c, d})` So basically the syntax you used expects naked structs implementing your interface and they're consumed in your function as a slice
I wouldn't really call that "generics", it's just code generation by replacing concrete types in existing code (and it requires `go generate` to be run beforehand).
The `...xs` syntax takes multiple arguments and turns them into a slice. E.g. the invocation it expects is `f(a, b, c, d)` where it sounds like you're giving it `f([]t{a, b, c, d})` So basically the syntax you used expects naked structs implementing your interface and they're consumed in your function as a slice
No like I said I used the spread operator `t...`
The `...xs` syntax takes multiple arguments and turns them into a slice. E.g. the invocation it expects is `f(a, b, c, d)` where it sounds like you're giving it `f([]t{a, b, c, d})` So basically the syntax you used expects naked structs implementing your interface and they're consumed in your function as a slice
Damn I didn't see the playground link, ignore me!
i edited the post with a go playground link and a new case that works (as it should)
I'm mobile so it's hard to get a playground for it, but I just tested some things and it looks like go doesn't support type casting of slices. So you can't []Inner([]Obj{}) or even []int64([]int{}). No slice types are considered compatible (maybe because of how the bytes are laid out and the size needs to be known/can't change?). You'd have to make `ts := []Inner{Obj{}, Obj{}}` from what I can tell :(
It's what I've been doing till now, however I find it very frustrating that I need to convert my slice of `Obj` into `Inner` element by element just to be able to pass it into a function. Seems very inefficient too
I agree. For me the deal breaker is lack of higher level collections and iterators. I really can't stand having to write a basic for loop for everything.. No map/filter/ reduce, find, etc like Java / just/ python. Actually go is what reignited my love for python
I'm totally aware of this. That's why I added a new section to [README.md](https://github.com/KeyLo99/God#faq) for preventing the misunderstandings.
https://stackoverflow.com/questions/12994679/golang-slice-of-struct-slice-of-interface-it-implements mentions reasonings behind this. It sounds like it is indeed because of the memory layout and also because it's expensive (and doesn't want to hide that from the author)
There are several advantages to my syntax: 1. No extra parentheses, more readable. 2. It's always clear where the generic type gets inferred and whether it needs to be specified manually. In your syntax, it's ambiguous when the user needs to specify the type manually and when it can be inferred. 3. Having to mark only the first occurrence let's me state rules like 'no gen in the return types' easily.
Ahh thanks for the link, that explains it
&gt; So would I be specifying the gen T at most once? &gt; &gt; `func Add(a gen T, b T) T` Yes, that's exactly how you'd write it. &gt; Or are you allowed to do it in both ways? &gt; &gt; `func Add(a gen T, b gen T) T` Nope, you are only allowed to mark the first occurrence. &gt; Next, you specify that the mechanism for passing a type is to just specify the type place holder as gen T within the definition. I think this potentially causes a little bit of ambiquity with how some of golang's current definitions work. Right, a bit. But since `gen` is a keyword, the parsing rules can be altered when the parser encounters it. &gt; How would one know if gen n is supposed to refer to a type or a value? Right now, just by context. Since a `gen n` is always used in some context in the signature, it's always possible to determine whether it's a type or an integer constant. Another option would be to distinguish them based on capitalization. Thanks for the comment! I enjoyed replying to it.
5 fields allow you to be as precise as a day of the week... what about hourly cron jobs ? Or running a job twice a day Also, you probably shouldn’t enforce anything in a tool, in order to prevent ppl from not using it.
This is because `Obj` and `Inner` values have different representation. Yes, it's true that `Obj` implements `Inner`, but whenever you pass an `Obj` value to a function that accepts `Inner`, an implicit conversion to the interface form occurs. Now, you may already see that such a conversion would be very problematic for slices. The compiler would need to insert code to convert the whole slice, which would be quite costly. So, that's why. If you want to convert the slice of `Obj`s to a slice of `Inner`s, you're free to do it explicitly. That way, there are no hidden costs.
I've used the kardianos template successfully in the past. I typically don't start it through the EXE. Instead I start it through the Windows Services control panel. Before I started using kardianos, I used a fork of the GO provided windows service. I wrote about that here: [https://billg.sqlteam.com/2018/07/16/running-go-as-a-windows-service/](https://billg.sqlteam.com/2018/07/16/running-go-as-a-windows-service/) . Some of the same principals apply. I would definitely stick with the kardianos template. &amp;#x200B; In that post I suggest four things to check: 1. Verify the service is running in the directory you think. It runs in C:\\windows\\system32 by default 2. Make sure the start up account is configured properly 3. Grant that start up account permissions on the directory 4. The Windows Event Log often writes additional information about the failure. I've used this to help track down stuff like this.
[removed]
So... the same as C++? Good luck convincing us that C++ doesn't have generics. Although I agree, as most do, that C++ does not have a very good implementation for generics.
you have step values for that. like 0 \*/2 \* \* \* is scheduled for every 2hours
Seriously. Go is verbose as fuck. It has a lot of great things about it, but don't tell me it's not verbose solely because it has the most primitive form of type inference - the one thing that makes Java so verbose. Well that, and people doing batshit crazy OOP shit.
C++ has generics like Scala has type classes. Yeah you can encode the concept using some language/compiler feature, but.. no.. you really don't have generics in C++. You have templating. And Scala has implicit resolution.
C++ doesn't require an extra step, it's part of the language. That tool you linked is not part of Go, and a built-in language feature would not require said extra step to generate additional code.
You never stop learning... thanks :)
I gave a detailed explanation of that [in this blog post](https://blog.merovius.de/2018/06/03/why-doesnt-go-have-variance-in.html). The tldr is: If you want to support that, you either have to give up mutability, or type-safety. i.e. the problem is that if you pass an `[]Inner` to a function, that function would be able to write *any* `Inner` to it - but the underlying slice is `[]Obj`, so that doesn't work.
look into proxying. create-react-app has it set up already if you happen to be using that. https://facebook.github.io/create-react-app/docs/proxying-api-requests-in-development otherwise you can do some google searching on how to get your local web server to send certain requests over to the backend.
When you pass a list of arguments to a ...T parameter, they get bundled up in a []T and that slice gets passed into the function. When you use v... to "expand" a slice, what you're really doing is telling the compiler to pass that slice directly. []Obj can't be passed as a []Inner because of memory representation differences. Allocating a new []Inner and copying an arbitrary number of elements from a []Obj is a significantly more costly operation than just directly passing the slice, so the compiler won't do that implicitly.
I like that phrasing “spartan and opinionated”
Yeah the “auto implement” thing can be use in many ways. Very nice.
Oh, interesting. I figured if one of them were pure Go, the compile times would be better, but if they're both effectively linking cgo stuff, then yours seems better :-)
I've never had this come up in 3 years of using Go. The handful of times I've needed to use the same function for multiple types I've just used an interface. Can you give an example of where you've needed to write the same function multiple times?
Typically, I would aim to have the lexer capture the entire string as a single token. Since you're using regex to describe your tokens, you would need a regex that can describe a full string, including both starting and ending quotes. I've used something like `"(\\\\"|\[\^"\])\*"` before: [https://regex101.com/r/cZbU0N/1](https://regex101.com/r/cZbU0N/1)
Not that guy but I’m writing a restful API in Go rn and I’m having to rewrite a lot of very similar handlers for endpoints for different resources. For example the basic GET for a list of all resources of a certain type They basically come down to: Make a slice of that type Run the query against the database, return err if there is one Iterate over rows, map them to the struct that represents the resource (return err if there is one) Return the slice (sorry for formatting I njys woke up and I’m on my phone) Basically the whole method is rewritten when the only thing that changes is the type of struct in the slice it returns, and the query. Same for the basic creating of a new resource via POST. The algorithm is essentially the same each time. Parse form Map form values to struct that represents the resource Validate it a bit Execute the insert statement on the database Checking for errors and returning them if they happen (centralized error handling takes place elsewhere) Basically the same function each time (at least with simple resources). Edit: granted, this could just be because I’m not writing it the most optimal way, but I’ve been reading tons of articles and blog posts on rest with go and I have yet to find a better way
They’re kind of stank Tim’s. I think in go they use method to refer to a method receiver and function for a regular function that isn’t defined on a type, but in most languages the two terms are interchangeable
Great job on the video, one minor nit was that in the beginning you talked about the size of the XML and JSON objects yet you neglected to contrast the wire size of the protobuf you generated. Other than that it was a great introduction to protobufs.
And streams (unless that’s what fluid APIs are?)
They’re both statically typed dawg
Streams are a fluent API, yes 🙂
Isn’t swift only able to be compiled for Apple OSs? I’d say that makes it not a great candidate for general purpose. To me, a great general purpose language is all the things you mentioned but also able to be ran on pretty much any platform.
&gt; For example the basic GET for a list of all resources of a certain type &gt; &gt; &gt; &gt; They basically come down to: &gt; &gt; &gt; &gt; Make a slice of that type &gt; &gt; &gt; &gt; Run the query against the database, return err if there is one &gt; &gt; &gt; &gt; Iterate over rows, map them to the struct that represents the resource (return err if there is one) &gt; &gt; &gt; &gt; Return the slice (sorry for formatting I njys woke up and I’m on my phone) &gt; &gt; &gt; &gt; Basically the whole method is rewritten when the only thing that changes is the type of struct in the slice it returns, and the query. Instead of returning a slice of structs, could you return a slice of strings?
&gt; C++ doesn't require an extra step, it's part of the language Depends on the compiler you use. Some C++ implementations really do leave it as a pre-compilation step that is up to the user. &gt; would not require said extra step to generate additional code. Depends on the compiler you use, although you are right that the standard distribution does not include this functionality. That does not preclude it from being generics though.
man i had a BEAR of a time getting my app to work with an almost identical setup. &amp;#x200B; here are my front end and back end repos: &amp;#x200B; [https://github.com/Arithmetics/got\_boardgame\_client](https://github.com/Arithmetics/got_boardgame_client) &amp;#x200B; [https://github.com/Arithmetics/got\_boardgame](https://github.com/Arithmetics/got_boardgame) &amp;#x200B; &amp;#x200B; not sure if this will help or not
Depends on how strictly you define type safe. Our codebase is filthy with type switches, which tend to fail at runtime rather than compile-time.
No, that's pretty standard stuff across languages. Methods and functions are similar, but are not the same as you've outlined.
Thanks, this regex is perfect!
I am all for generics and better error handling but this is funny. This is exactly what Go did not want to do in the first place. I guess you are tied to your other language habit, take some time. Every language has its own way of doing things.
I think there are a couple of things that seem to be going on here. The reason you see '\[2\]' when you directly print inputBuffer is because it is a slice and it is just showing the single element within the slice. &amp;#x200B; According to the docs: [https://golang.org/pkg/builtin/#byte](https://golang.org/pkg/builtin/#byte), the `byte` type is just an alias for uint8. I think the code you would want for the case where your slice contains a single element is something like this: &amp;#x200B; `first := uint8(inputBuffer[0])` `return fmt.Sprintf("%d", first), nil` &amp;#x200B; I'm pretty sure the cast to uint8 is probably unnecessary and you could probably just pass `inputBuffer[0]` to your `Sprintf` call. &amp;#x200B; EDIT: Apparently idk how to post code blocks to reddit
You're implying: * You can't write DRY code without generics * Generics are the only way to solve the problem they solve * DRY is always desirable
Go variable names get to be shorter because their scope is narrower. In Java, everything is a method, so all unqualified identifiers could either be locals or members, which means that everything has to be a little more wordy (or you adopt a convention of prefixing or whatever).
working !! thank you !!
OP (Endtest) is spamming up tech subs, every day with multiple accounts [1,](https://www.reddit.com/user/boss_scarbos) [2,](https://www.reddit.com/user/dragnea_presedinte) [3,](https://www.reddit.com/user/llupei) [4](https://www.reddit.com/user/wernerklaus), [5](https://www.reddit.com/user/jos_cu_klaus) with focused self promotion spam like this that clearly breaks [reddits self promotion rules](https://www.reddit.com/wiki/selfpromotion) See for yourself. Vote and report accordingly.
[removed]
Nope. Swift can be used on backend too. Try vapor, perfect or kitura. Since its open source , its potential to run on any platform
My biggest complaint is a lack of good efficient collections, and the lack of generics is what prevents it. I find myself often needing to remove duplicates from a slice, for example. You can’t do this easily with an interface, and a []interface{} can not be used in place of a []string for a function. It has to use type checking and reflection, which IMO makes a simple problem very tedious and have runtime costs associated. This problem in rust is solved in the compile time phase using generics.
Once again, they're sending ill-formed JSON as `application/json`. Go to their [linked](https://index.golang.org/index?since=2019-03-04T18:00:15.161182-07:00) index example. They're sending a list of JSON objects without an array. Any JSON parser is going to barf with that input.
I agree that each language has its own approach. But if they took generics and error handling away, they should provide another solution for it. Like Go did well or its best with Goroutines for thread execution compared to Java. Google released golang 1st version since 2009 then Dart 2011 but they chose Dart for Flutter and Fuschia ,one of the reasons is Go isnt suitable for GUI development. Go is good for system or backend, high performance. But Dart can be used everywhere. Dart is the java-replacement for Google as a general purpose language.
Uhm not sure how you reach all those conclusions from what I write, but OK: &gt; * You can't write DRY code without generics Not quite. I write 'in a secure manner'. Generics is a way to do that in a type safe way. In Go you can have a non-type safe way to avoid some DRY using interfaces. But this is not desirable, as you move the bug detection at run time, instead of a compile time. Not a feature that you want for a typed language. &gt; * Generics are the only way to solve the problem they solve Well, no, as commented previously. But is a type safe way that many other languages in the same spectrum that Go implements. You cannot play the card that there is an alternative to generic yet to discover, ergo better not to do anything until this is discovered. AFAIK the team that design Go agrees that generic is a must, and that is a mechanism desired for the language. But cannot be implemented in any way without introducing some incompatibilities the Go 1, and this is not allowed. Note that the logical conclusion is that some of the early decision made in Go7s design were taken without consideration of generics, and this says something about the language design, and not about the good or bad features of generics. &gt; * DRY is always desirable Non-sense. Having a mechanism to safety avoid DRY do not exclude that the developer can copy and paste ad-nauseam. But on the contrary, not having this mechanism open the door to all the bugs that copy and pasting code bring with it.
It's json-stream isn'it ?
Honestly, I'm glad they're taking a careful, considered approach. I don't know what's best either, but I've faith they'll make a reasonable decision. On a related note: eat a dick, javascript.
They’re good to take the time to examine. I’ve got to say, I really love functional programming and hope they implement Type Classes. They are very powerful constructs and allow for very predictable code. For a language created in 10 days and only meant to be used as a small browser scripting language, JS was alright. For quick scripts, I really don’t mind JS and it’s continuation passing style. TypeScript, React and Async/Await have made building front end applications using it a lot better. I wouldn’t use JS on the backend other than serving content, since that is where Event Driven languages shine. I also wouldn’t want to use Golang to build a front end application. Languages are just tools and you’ve got to use the right tool for the job at hand
and for the post handlers?
I don't actually find Go that verbose. Compared to Java, it seems better thanks to fewer factoryfactoryfactory patterns. Compared to C or C++, being able to pass err back in addition to other arguments reduces the need for separate error surfacing functions. That's not to say that the err != nil can't be improved. But it definitely doesn't feel verbose compared to Java/C/C++ in my opinion.
I've gotten more insight than I could have hoped for by reading the conversation here. Thank you all for that. I posted this mostly out of frustration at repeatedly making the mistake of typing "This[]" instead of "[]That" and "null" instead of "nil". Disclaimer: I don't design languages, I mostly just use them. Sometimes it seems like some constructs/syntax are changed just for the sake of making them different though they are semantically identical. And though I'll have double the experience (after today) in Go than I had yesterday, I'm still very new to the language. I'm curious if after getting more experience I'll find that those constructs have added to the language's expressiveness, or have they simply made the switch more of a pain than it had to be?
anytime :)
Go does have polymorphism
It can also be annoying. We use interfaces quite a bit, and we have stuff like this strewn about the code: var _ &lt;Interface&gt; = new(&lt;Type&gt;) This way we have the compiler guarantee that &lt;Type&gt; implements &lt;Interface&gt;, and we've found that we need to do that in a lot of places so we don't forget to change all implementations when we change the interface. In Rust, this just isn't a problem because you have to manually implement each Trait for each type you want to use it with, so you get compile errors when the trait changes and you forgot to change an implementation. Also, Traits in Rust can implement a lot of convenience functions for you w/o needing any additional input from the type (e.g. the `Read` trait in Rust implements everything in terms of the `read()` function, giving you stuff like `read_to_string` for free). Interfaces in Go are nice, I just wish they were nicer. Features I'd like: - implement methods on an interface (so you can have an `io.Reader()` implement stuff from `io/ioutil`, like `ReadAll`) - allow types to explicitly declare that they implement an interface so you get compile-time checks - have checks against `nil` succeed if the data within the interface is nil ([example](https://play.golang.org/p/6gsVifO66SW)) They're nice, but they could be nicer. I prefer Rust Traits though.
I use kardianos successfully on many thousands of Windows endpoints, servers and workstations. I found that I needed to have a dedicated installer. It downloads my service binary, installs and starts the service with kardianos, then exits.
Not only that, but it just makes the code clearer. ie. I immediately know what interfaces a type implements. Good luck trying to convince the community to adopt explicit interface declarations though.
What about sorting a list of `int64`? `sort.Ints(...)` does `[]int`, but not `int64`, so you'd have to implement that yourself on a new type: type myList []int64 func (l myList) Less(i, j int) bool { return l[i] &lt; l[j] } func (l myList) Swap(i, j int) { l[i], l[j] = l[j], l[i] } func (l myList) Len() int { return len(l) } Or if you have a list of some custom type, you'd need to implement it for the collection, not the type: type myList []customType ... In Java, you just implement `Comparable` on your type and you get everything else for free, and built-in types already implement it. If you do lots of sorting, Go is _extremely_ verbose, and it requires you to make custom types everywhere. Likewise for thread-safe things, if you only need to protect one piece of code from concurrent access, `synchronized {}` is _much_ more concise than making a mutex (and no, channels don't work for everything). Whether something is more verbose in Java or Go really comes down how you model your code, and what the problem domain is. I have a bunch of stupid `defer func() { cleanup code here }()` that would be simpler as `try { } finally { cleanup code here }`, but others where the `defer` is simpler. Likewise for errors, if they're usually passed back and handled in a higher scope. I absolutely prefer Go to Java, but that doesn't mean it's always more concise or even simpler for modeling a solution.
&gt;Go actually forces you to write more code Yep. Golang itself is simple, but the code you write with it tends to be more complicated than in other laguages.
Or even removing an element from a slice and shifting everything down (i.e. when order matters, otherwise I'd swap the last element and slice it off). Collections in general kind of suck in Go, whereas in Rust I can choose between a slice, vector, or some other collection without a ton of boilerplate.
It looks like you are right. However, for that, according to [RFC 7464](https://tools.ietf.org/html/rfc7464#section-4), the Content Type should be `application/json-seq` since it's not valid JSON. **Edit**: That's for another form of JSON sequences, not JSON lines. Unfortunately JSON lines hasn't standardized any form of Content Type and it looks like people are (incorrectly) just saying `application/json` :/
&gt;factoryfactoryfactory So I've found Go's verbosity *forced* by the language itself, as opposed to a programmer's choice of pattern as you've described here. Basically, you're comparing apples to oranges.
An implementation separating out parts of the compilation step isn't the same as using a separate compile step for something that isn't part of the language. Arguably, adding "generics" to Go makes it a new language, just like SCSS/Less is a different language than CSS, and TypeScript is a different language than JavaScript. Yes, you _can_ use generics with Go code, but Go doesn't have generics (in the language).
&gt;The handful of times I've needed to use the same function for multiple types I've just used an interface. You misunderstand (and i think it's common). Every single time you have filtered/mapped/etc an array or a map, you could've benefited by a generic algorithm instead of having to manually roll your own for loops.
&gt; For a language created in 10 days and only meant to be used as a small browser scripting language, JS was alright. If it were still just for mouseover nonsense in browsers or whatnot, sure. Its scope has grown so much that now those minor flaws are no longer minor. I just hate writing JavaScript because I'm always thinking "this could have been so much better..."
They might accept it if it was completely optional. Basically, I want the compiler to essentially generate my example above. If I intend for my type to be used with a specific interface, there should be an obvious way for the compiler to check that, and `var _ ...` isn't obvious...
In Java you can have small methods *and small classes*. No need for compound names if you manage to stick to it.
&gt; An implementation separating out parts of the compilation step isn't the same as using a separate compile step for something that isn't part of the language. In the case of C++ it is – sometimes. Of course, it depends on which compiler you are using. &gt; Arguably, adding "generics" to Go makes it a new language You are right that generics do require some syntactical mechanism to define the generic types. Does that make it a new language? Go has already added a small number of new syntactical features over the versions. Does that mean that, even ignoring generics, that there are multiple languages all under the Go umbrella? &gt; Yes, you can use generics with Go code, but Go doesn't have generics (in the language). The Go language doesn't have a generate feature either, but you mentioned it earlier as a feature of Go. Clearly you were able to earlier recognize the difference between the language and the ecosystem, the latter of which is what we are talking about. Why the sudden change of tune in not understanding the topic at hand?
Which particular areas are you interested in? What is your previous experience?
&gt; Does that mean that, even ignoring generics, that there are multiple languages all under the Go umbrella? Yes? There's the Go 1.0 language, 1.1, etc. Each language change has a version attached to it, just like C++. C++17 is a different language than C++11 because there are new language features. However, that's quite a bit different than using a separate pre-compile step to generate Go code. There's a difference between Go tooling and the language. If doesn't work OOTB with `go build`, it's not "part of the language".
Go slices are not covariant, so you can’t pass a slice of structs as a slice of interfaces.
Your example is out of date. Now Go has sort.Slice.
Ah, I actually missed that. However, you have to pay a runtime cost to use it (uses `reflect`), which isn't ideal. In any case, I think it's more ergonomic to put comparators on data items, not containers. If Go was able to coerce `[]type` to `[]interface{}`, it could easily abstract this through coercing `[]type` -&gt; `[]Comparator` and checking it at compile time, instead of having a runtime check that could panic. So, instead of being able to do `sort.Slice([]Comparator)`, you need to do `sort.Slice(interface{}, func (i, j int) bool)`, which is way more messy. I don't like writing in-line comparators, and I don't think I should have to pass one in either if I want the default behavior.
Maybe make the number of workers configurable?
Github for Argo: https://github.com/argoproj/argo
Have you never created a complex Data Structure then write the same method to update the structure depending on the type that was written to it? It's a fairly common problem. Described by /u/partkyle in his reply to you
Index Exchange hires for them. I also know the Economist's stack is Golang. [https://www.welovegolang.com/](https://www.welovegolang.com/)
This is hilarious Is e.g. \`**public static void** main(String\[\] argv) \` vs \`func main()\` forced by programmer?
That's not the reason. It's just the common practice which says that variable names shouldn't be abbreviated. When it comes to the scope - it's actually the opposite. In Go an unqualified variable identifier can be a variable anywhere inside the same package.
&gt;I’m still learning but I’ve had a few “whoa that’s cool” moments, especially when I learned about interfaces. Still getting caught up a bit by thinking in terms of inheritance though. I've had those, but I've had a lot of "should I go to the eye doctor because my eyes hurt from all the rolling?" For example, var s \[\]string. Null, but appendable slice of strings. var m map\[string\]string. Panic inducing mistake.
ThreadLocal variables. Oh my goodness context passing sucks. Have you ever tried having a transaction? Either make a closure that does all of its work with one transaction ala Node, or Factories to create structs with the tx as variable. Or screw the type system Tx(context context.Context) \*sql.Tx.
Both languages have symbols in the unqualified scope and both languages have block scoping. I recognize the common practice, but in my experience the reasons behind the naming schemes in most major languages stem from the nuances of the languages themselves. The primary difference that I see in Go vs Java (with respect to naming) is that the space for collisions is more narrow in practice. Single word names like "count" and "parent" and "config" and such that might have a colliding field are clarified in Go with the receiver but in Java with a longer name. This has led to a slightly more verbose naming convention, and radically different capitalization of course, which tends to prevent such collisions from arising in the first place.
Using a proxy would make your life a lot easier by eliminating your CORS problem. In development you can use something simple like this middleware https://www.npmjs.com/package/express-http-proxy With the proxy set up, you should now be able to make the same post request to your front end (e.g. http://localhost:3000/authenticate) and let the proxy carry to your Go backend server at local host:8000. Your browser will be none the wiser, the cookie will just be written because now it's coming from the same domain. Happy life.
It seems like the other comment helped you, and also you've got something that \_works\_. Sure you might have taken longer than others might, but \_you\_ wrote something that works. That's good. &amp;#x200B; I'd suggest you read this ebook if you can track it down - [https://interpreterbook.com/](https://interpreterbook.com/) \- it covers not just lexing, and parsing, but also evaluating. The writing is clear and the code clearer-still. &amp;#x200B; I came up with my own (improved) interpreter after reading it, and it stood me in good stead to write a couple of similar programs - a simple deployment tool, and a BASIC interpreter for example - even though the code is different the core principles are useful. &amp;#x200B; The biggest change between the book-sample, and your sample, is the lack of regular expressions. I suspect you'd benefit from the increased flexibility of doing it "properly", but also at the same time you did good. You wrote something you understand, and you learned. That's good. Remember that :)
I have web-development experience and on my final year of Computer Science major. I just want to learn from the best to boost my knowledge in backend engineering. It could be paid or unpaid.
Thanks :) I was actually looking at buying a copy of this book, but I committed to writing my own mini language first so I could understand the struggle and appreciate the ‘proper’ way when I get that book.
Thanks! I will definitely check this.
lol why generics when copy paste work
1. 4/5/6 should be unnecessary unless you've made local changes that you want to revert - you've already checked out the latest master. 2. `git stash` ; `git checkout -b newbranch` ; `git stash pop`; will stash your changes, switch to the new branch, then restore your changes. In though general, try to remember to start all new work on a branch.
Thanks! 1. What I meant is that before I make any changes make sure the master hasn't changed...e.g. I might have pushed some changes a couple of days ago...and someone may have made a change yesterday...just sync it up b/f I make another change. 2. Can you clarify..."try to remember to start all new work on a branch".
I would like to bring attention to functions passed as arguments in other functions or set as types of map values... Unbelievably and annoyingly verbose
Assuming upstream points to the original repo you can resync with master with: git fetch upstream git merge upstream/master
Not sure about more complicated. Definitely more repetitive.
1. Never push to the master branch of a fork. If you've done this, you will probably want to perform these steps (4/5/6) to revert your local master to the upstream master before creating a branch, so that you have a common ancestor for your branch and pull request. Once you've created your new branch, you can restore your existing commits using `git cherry-pick &lt;commit-hash&gt;`, but your life will be much simpler if you just don't put yourself in this situation (see 2). 2. Never commit to a branch that exists upstream, always commit to a feature branch, don't start work until you've created a branch to work on. These are not really specific to Go, but just good practice in general for working with git/Github forks. If master on the upstream moves before you're ready to send your pull request, you may need to use git rebase then force-push your branch, to move your changes up to the tip and fix any conflicts. There are tutorials available for this (the git book has some I'm pretty sure, and you should probably read some of it anyway).
That's a one-time function declaration so its contribution to the overall verbosity is negligible. Aside from the point of generics repeated many times over in this thread, here are some more points that add to Go's verbosity (off the top of my head): * No covariance * lots of `if err != nil` checks on code that just returns the error * Type inference not extended to anonymous functions as arguments * No anonymous interface implementations * Cannot call pointer methods on struct literals (need to enclose literal in parenthesis or use `new`) * Appending elements to slices (`s = append(s, elm)` vs `s.add(elm)`)
I conflated "complexity" with "verbosity".
I'll check it out thanks!
I'll have a look, cheers.
Just curious but are your interfaces defined by the API provider or consumer?
I love how spartan go is, I love how the go creators don’t just bolt on language features like generics .. you don’t need it. Go is a language with a very specific purpose, concurrent backend / services. Want a good general purpose language, rust, c++, c#..
Do I need a kubernetes cluster for it?
&gt; You have to implement logic for switching methods Indeed but depending on the API this can range from no code to a single switch case. I do not think that having to write an extra switch case (only in the worst case) justifies importing a 3rd party library. &gt; You have to implement logic for popping stuff from the path This I think is the biggest reason why people are using 3rd party muxers and I totally understand it. My argument is that in order to get up to 2 parameters from the path, it is no longer than 20 lines of a helper function. Again I do not think that having to write that helper function justifies importing a 3rd party library. You may argue that "what if there are 3 or more parameters in the path?". To that I say, call me lucky but I've never worked with (or even seen) an API that had more than 2 parameters and I do not like writing code for imaginary cases. &gt; You lose out on having a SSOT for your entire API, instead of looking at one function that registers your handlers you have to &lt;gd&gt; to your handler while following along with whatever logic happening to do the above two things This I totally understand. You'd rather have all the API "nicely" appear all in one place in your code which is fine. My argument is that importing a 3rd party library just for that is using the wrong tool for the job. Especially when we are talking large APIs, the API documentation (Swagger file or anything similar) I think is much more appropriate.
Go has pretty good free online resources. My suggestion is to spend some time to learn the language and contribute to open source projects. Open source contributions will easily get you a first job with Go.
There are also Thanos and Cortex. We have plans for benchmarking agains these TSDBs later.
I'd recommend trying it as a long-term storage for Prometheus if you use Prometheus :)
Type parameters allow for better type safety at compile time than what Go is currently offering. Even if it's not in your own code, you're likely using libraries that rely on reflection and type switches somewhere.
Nope never tried. I'm still new to golang and just writing pet projects with it. Now I'm scared hahah
While I guess I don't need generics, in that I clearly have functioning code without them, generics reduce redundancy. For example, in Clean Architecture a common paradigm, in Go, is UseCase.Execute(context, input, Presenter), where Presenter has the form Presenter.Present(Result). Every business process is a UseCase. Every Use Case has a different Input. Every Use Case presents a different Result. But this is the the pattern. In Go, I have a million UseCases, with their own definition or Input, Presenter, and Result. While all Presenters get a struct with a Result through composition, each needs its own specific type UC1Result{Result, other fields}. In Java this is all defined once. Same for Python and C#. &amp;#x200B; It's annoying.
I get conflicting information about Dart, how is Dart Java replacement?
Many of the APIs I write have 2-4 methods per route, and with more than more than 2 path parameters. Using `http.ServeMux` adds up to a lot of work. And when you end up get sick of that, you basically end up writing something like this library (or just importing another muxer). I wouldn't say that swagger totally solves the SSOT issue (helps though) since when you look at swagger you're reading what the API _should_ be, not what it is. Not to say that docs becoming stale means you should use a muxer, but its nice when you have a single place to look at how the routes are _actually_ registered. It sounds like for your use cases `http.ServeMux` is fine, so you should totally just use that. I just think this library is a good choice for many of the APIs I deal with where if you tried to use `http.ServeMux` you would end up spending a lot of time switching methods, popping path parameters, etc, but a dependency like `gorilla/mux` would be way too much. It's all about tradeoffs: is importing a muxer dependency going to be worth it for you? P.S. I appreciate how respectful and level-headed your response was. I agree with pretty much everything you said, except for maybe what we each deal with on an everyday basis (which is obviously going to be different).
Yea, i can agree that its a little confusing, but a big difference is you're comparing the append() function with the assignment (=) operator. s[0] = "oops" Would panic just the same way.
While there are uses for containers with nil values, I've found that in almost literally every case, I am better served by initializing the variables to be empty rather than nil. In this particular examples: s := []string{} m := map[string]string{} And, one of my personal favorites: i := interface{}{} Look at how cute it is! Seriously though, I almost never just declare variables without having a value to put into them. And of the times I do declare a variable, an actual majority of those times is declaring err at the top of a function to avoid weird shadowing problems. :P
&gt; This way we have the compiler guarantee that &lt;Type&gt; implements &lt;Interface&gt; This may be more Javathink slipping into your Go code. In Go, what you have done with this line is slightly more than what you've said; you are having the compiler guarantee the type implements the interface _despite the fact that no code ever attempts to use that type with that interface_. Why do you need to do that? If you just... didn't... then the Go compiler would still tell you it's a problem when you tried to actually use it. Maybe I'm missing something (probably) and the situation is more complicated, but it sounds to me like this just shouldn't be necessary.
&gt; I immediately know what interfaces a type implements. Well, sort of, but it also breaks some fundamental parts of how Go interfaces work. Imagine you write a struct that has a `stuff` method. It's your only struct, so you don't bother creating an interface. You publish the code to github for everyone to use. Later, I use your code, but I also want to be able to replace your struct with my new struct sometimes, so I create a `stuffer` interface. Your struct (whose code I don't want to change) still implements that interface.
As I commented elsewhere I'm not sure it buys anything, but if you do this anyway, rather than dropping it in the module somewhere it's likely to get lost you could instead put that line in a unit test called something like Test&lt;Type&gt;Implements&lt;Interface&gt;
Yes but then in rust you have to TYPE ERROR YOU DIDN'T DO THIS EXACTLY RIGHT VARIABLE IS EXPIRED NOW YOU EXPIRE
Looking at [this](https://github.com/juliscrazy/Quick-Resize/blob/master/resizer/resizer.go#L14) I don't think it will compile (`img` declared in wrong scope)?
[removed]
[removed]
I'm very happy with Go. It's the one language where you can step into almost any codebase and understand it immediately. No programmers trying to be clever with some weird syntax or pattern noone else uses. No exotic language features popping up everytime you open the next file. Go may be a little restrictive or limited in some aspects, but it forces people to write pretty straightforward code. I've been a C++ developer for about 7 years, and a Rust hobbyist for about 2. I love programming in Rust, but it feels like everytime I open someone else's crate, it's almost incomprehensible. Especially if you've taken a break for a few months and come back to discover everyone has embraced some new crates with heavy use of fancy macros. Let's not even start about C++ or Java.
Surprised this comment isn't more highly rated. Half the people here think you're being sarcastic and the other half agree with you.
Came here to link to this. I've just set it up alongside our main PHP application and using [tus-js-client](https://github.com/tus/tus-js-client) on the frontend, and the experience has been an absolute pleasure.
Nothing a good type declaration or two can't solve?
My thoughts exactly. Go starts to shine when reading code that others have written.
With math-like code you might want to have an "add" function that works with vectors, quaternions and matrices. Overloading "+" would also be helpful. This type of code is easy to write in Julia or C++, but impossible in Go. The closest you can get in Go is to embed a small DSL that can do this.
For mobile, I guess.
For mobile, I guess.
&gt; Many of the APIs I write have 2-4 methods per route, and with more than more than 2 path parameters. I went back and looked at the helper method and it can actually handle any number of parameters and it is even smaller than I remembered. Also I'd be really interested to see these APIs you are working with that have more than 2 path parameters. &gt; Using http.ServeMux adds up to a lot of work. I highly disagree on that. Unless you consider a lot of work writing a helper method and some switch cases. &gt; It sounds like for your use cases http.ServeMux is fine, so you should totally just use that. I just think this library is a good choice for many of the APIs I deal with You are suggesting that we have different use cases. I cannot prove it obviously but please allow me to have some doubts on that. &gt; where if you tried to use http.ServeMux you would end up spending a lot of time switching methods, popping path parameters, etc I don't see how you spend "a lot of time" to write a helper method and some switch cases. Might it be possible that you have not tried to use ServeMux on a serious API yet? &gt; It's all about tradeoffs: is importing a muxer dependency going to be worth it for you? Usually not. I mean, I do see your argument. Your package is much smaller than other 3rd party routers. You might not be able to see it because it is your package but from my perspective a 3rd party dependency adds a whole lot of headache. How do I know you won't do breaking changes? What if you decide to change its name or even take it off the net? What if you decide that you stop maintaining your package 2 years from now? Meanwhile ServeMux is guaranteed to be there, it has been tested and has been used in production for more than 10 years. I suppose the best way to summarize my argument is the Go proverb: [A little copying is better than a little dependency.](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s)
Here's an example since you asked. Not the largest API I've worked on, but the largest open source one: https://petstore.swagger.io/?url=https://raw.githubusercontent.com/Pigmice2733/peregrine-backend/develop/internal/server/openapi.yaml It's definitely not perfect, but then again, most of the APIs I've used/worked with aren't either. I understand that dependencies add headache, and I know that go proverb. Still think it's worth it for most APIs. I would love to see an example of a large API you've written with the standard mux if you have an open source one.
I mean less compile time type safety. For somebody who used Rust/Haskell/Scala will definitely find golang much less statically typed. But someone coming from javascript or python will definitely find it more static typed.
Yeah that clearly won't work. Also in the case where the extension is neither `png` nor `jpg`, the code does `img := "None"`... No way that could ever work
I'm also using it on Windows 10 and the same code on Linux. Normally control it through Windows services applet.
You don't need else there, just check if the error is not nil, and go on with your function.
So the difference in each case is the md5Statement , sha1Statement, and the clearStatement ? If so then you need to write a function that takes the statement as a parameter. `if \`a\` { fn(md5Statement, ...) }` `else if \`b\` { fn(sha1Statement, ...)}` `...` And so on, also you're testing `utf8.ValidString(username) &amp;&amp; utf8.ValidString(password)` every time, you can put this in its own block at the top. Finally if I ever saw an obscenity in any of the code that I review I'd make it a disciplinary issue, don't do it there's no reason for it and its a very bad habit to get into. And I say this as someone who swears profusely.
[removed]
Although there is a way to access both values, this is not an idiomatic way in Go. A more appropriate way would be: result, err := something() if err != nil { // handle error and possibly return } // handle result and continue
It just needs splitting up into more functions is all from a quick glance. Each branch in the if statement could be it's own function probably.
"net/http"
&gt;net/http I also looked at "fasthttp", but they both kinda very low level I have to implement stuff on my own, or I missed something? I saw FastHTTP has compressing, does it has caching and Etags support? And do you recommend "fasthttp" over "net/http" or other way? :)
Basically you have to hold onto the transaction struct for the duration of the transaction manually. Whichever struct you started the transaction has to be used for all DB actions you want involved in the transaction. You have to either use the context to pass the transaction around, or use some other mechanism like a factory that takes a transaction and gives you all the components tied to the transaction.
Others have already given good feedback on the quality of the code itself, but here's a couple words on performance (which might or might not be relevant to you, but maybe you'll find them interesting at least) Inserting stuff into SQL databases quickly is a bit of a science unto itself. What you're doing is almost certainly going to be pretty dang slow if you want to ingest millions of rows, because you're using individual transactions. One way to get around this is to insert in batches of e.g. a couple thousand rows per transaction. If you want to go really fast, you could also look into postgres' server-side CSV batch ingest. This will allow you to ingest CSV data into a table without streaming it through the client at all. postgres is pretty powerful, so you can easily e.g. materialize a table afterwards that contains additional computed columns like the md5, sha1, ... of the row, etc, or compute these in a trigger. If raw ingest perf is really important though, I'd pre-process these in go first and spit out CSV for the server to ingest, I think. For larger workloads we often pre-process the data in spark and then export it into postgres (often in an aggregated form) -- but that's most likely overkill, unless you have many gigabytes or even terabytes of lists.
Thanks for your response, in fact I'm working with roughly 1TB of data and speed is a concern. Am I not inserting x amount of rows per transaction? &amp;#x200B; I'll probably go for your pre-process to CSV route after I'm done with this project. This is a perfect project to learn Go and Postgres in general.
&gt; The problem is that in the else clause, err will go out of scope, thus be lost. No: https://play.golang.org/p/wR3kyK0omWo
Thank you for taking your time and looking at my code. I'm sorry about the obscenity it was the first thing I've removed. Could you have a look at my interpretation of your suggestion? Don't I have to return the newly created txn if lineCount%copySize == 0 as I create a new transaction? I've created a pastebin with the involved sections: [https://pastebin.com/mXpqR0a6](https://pastebin.com/mXpqR0a6) Or check out my updated repo: [https://github.com/jLemmings/GoTxtToPostgres/blob/dev/Import.go](https://github.com/jLemmings/GoTxtToPostgres/blob/dev/Import.go)
Err will still be in scope for this code: if v, err := f(); err == nil { // Handle result } else { // Handle error } However, you would normally do this (note how I flipped the `err == nil` to `err != nil`): v, err := f() if err != nil { // Handle error } // Handle result Have a look at this section of Go's CodeReviewComments document (which I can highly recommend reading in full): https://github.com/golang/go/wiki/CodeReviewComments#indent-error-flow It's good to keep the "happy path" at minimal indentation: this makes the code very easy to read/scan. In case you're interested in reading more about this, check: https://medium.com/@matryer/line-of-sight-in-code-186dd7cdea88
Sorry, I didn't read the code very carefully, you might already be doing that. If you have that much data, I think you'll want to use server-side CSV import for sure. You might want to look into directly ingesting from a compressed CSV file as well, so that you never have to deal with the uncompressed data anywhere (on disk). I don't know if postgres' CSV import can do this natively, but if not, postgres can import from a pipe (so you can pipe the CSV data through `gunzip` or similar) using `COPY FROM PROGRAM`. If you think the data volume will grow, it might actually be worth to use something else though, like for instance cassandra. Cassandra has pretty good ingest perf, and you can run an unreplicated cluster of N nodes, and then have e.g. N processes ingesting into those nodes as fast as you can. If you want to stay with postgres, I'd recommend having a look at the available index types like GIN/BRIN -- using normal btree indices will likely have more space overhead than you'd be willing to have, so you'll probably want some probabilistic index types.
Nginx ¯\\\_(ツ)\_/¯
FYI, you can use [image.Decode](https://golang.org/pkg/image/#Decode) without having to care about figuring out the image type yourself.
It’s not Go-specific, but I’d also point out that your git commit messages are a lot less useful than they ought to be. You’ve got four different commits where the entirety of the commit message is just “Update import.go” with no hint as to the scope or nature of the change. Good commit messages are just as vital as comments in your code in order to ensure the long-term health and maintainability of your codebase. Commit messages can be vital tools when debugging unexpected behavior or tracking down bugs in the code. https://chris.beams.io/posts/git-commit/ is a great primer on the how’s and why’s of commit messages. It’s a valuable habit to develop.
Thanks for you for pointing this out. To be hones I didn't bother giving reasonable commit message when I removed unnecessary log.Println. I know I'm should stop doing ASAP to not let it becoming a bad habit...
 err &amp;#x200B; isn't out of scope in the else block.
just use and learn net/http. It's very high level and if you're just looking for fully complete solutions to every single problem using libraries you'll never learn and have seemingly misunderstood programming as a whole.
This is a good read on how to structure Go code to keep the happy path: &amp;#x200B; [https://medium.com/@matryer/line-of-sight-in-code-186dd7cdea88](https://medium.com/@matryer/line-of-sight-in-code-186dd7cdea88)
Other people have pointed out how to properly handle errors but not *why* the go creators chose this way. The idea is that you handle your errors as soon as they appear, so - call this function to get your result - if an error is returned, deal with it - carry on as opposed to the Java/C# way of having try-catch blocks where *something*goes wrong in a block of code and then you have your handling in the catch block. You could of course have try-catch blocks around every function with exceptions defined for all scenarios (this is the cleanest way) but that's even more boilerplate than Golangs `if err != nil`. So, you might find you spend a lot of time handling errors - you'll often find your code looks like lots of little pyramids as you call functions and then handle any errors. This is how idiomatic go should look, and you'll find the code you write has fewer bugs and surprises since you've been coerced into thinking about the non-happy path in your code more often.
Caddy
What's about something like this (using postgres copy)? &amp;#x200B; `type Postgres struct {` `db *sql.DB` `dbTimer time.Duration` `bulkCnt int` `}` &amp;#x200B; `const qCopy = "COPY table_name(date,row1,row2,row3,row4) FROM STDIN"` &amp;#x200B; `func (p *Postgres) setup() error {` `p.db, err := setupYOURDB()` `if err != nil {` `return err` `}` `p.db.SetMaxOpenConns(50)` `p.db.SetMaxIdleConns(20)` &amp;#x200B; `p.bulkCnt = 1000` `p.dbTimer = time.Duration(config.Setting.DBTimer) * time.Second` `return nil` `}` &amp;#x200B; `func (p *Postgres) insert(hCh chan YOURTYPE) {` `var (` `qCnt int` `qRows = make([]string, 0, p.bulkCnt)` `maxWait = p.dbTimer` `)` &amp;#x200B; `timer := time.NewTimer(maxWait)` `stop := func() {` `if !timer.Stop() {` `select {` `case &lt;-timer.C:` `default:` `}` `}` `}` `defer stop()` &amp;#x200B; `for {` `select {` `case pkt, ok := &lt;-hCh:` `if !ok {` `if p.db != nil {` `p.db.Close()` `}` `return` `}` &amp;#x200B; `date := pkt.Timestamp.Format(time.RFC3339Nano)` `qRows = append(qRows, date, pkt.row1, pkt.row2, pkt.row3, pkt.row4)` `qCnt++` `if qCnt == p.bulkCnt {` `p.bulkInsert(qCopy, qRows)` `qRows = []string{}` `qCnt = 0` `}` `case &lt;-timer.C:` `timer.Reset(maxWait)` `if qCnt &gt; 0 {` `l := len(qRows)` `p.bulkInsert(qCopy, qRows[:l])` `qRows = []string{}` `qCnt = 0` `}` `}` `}` `}` &amp;#x200B; `func (p *Postgres) bulkInsert(query string, rows []string) {` `tx, err := p.db.Begin()` `if err != nil || tx == nil {` `logp.Err("%v", err)` `return` `}` &amp;#x200B; `stmt, err := tx.Prepare(query)` `if err != nil {` `logp.Err("%v", err)` `err := tx.Rollback()` `if err != nil {` `//handle error` `}` `return` `}` &amp;#x200B; `for i := 0; i &lt; len(rows); i = i + 5 {` `_, err = stmt.Exec(rows[i], rows[i+1], rows[i+2], rows[i+3], rows[i+4])` `if err != nil {` `//handle error` `continue` `}` `}` &amp;#x200B; `_, err = stmt.Exec()` `if err != nil {` `//handle error` `}` `err = stmt.Close()` `if err != nil {` `//handle error` `}` `err = tx.Commit()` `if err != nil {` `//handle error` `}` `}`
I have a generic query method that returns an array of maps representing the datasets from the SQL. This keeps me from having to build temp struct models and I can just JSON encode the map as an HTTP response. func QueryGeneric(db *sql.DB, query string, args ...interface{}) ([]map[string]interface{}, error) {
Yea instead of updated file you can put like. Removed print statements
I've been following the documentation of pq: [https://godoc.org/github.com/lib/pq#hdr-Bulk\_imports](https://godoc.org/github.com/lib/pq#hdr-Bulk_imports)
I actually wrote two apps using both \`net/http\` and \`fasthttp\` to try them out and compare performance. But before implementing gzip compression, Etag and caching etc on my own, I wanted to see if there are any community-built solution that is battle-tested and trusted by many for this purpose, also not to reinvent the wheel. Anyway, thanks for the help!
Yeah, I too love Nginx. But I see Golang has better performance over Nginx. If this Golang thing troubles me too much, then it is definitely Nginx! :D
Nginx is a very solid and tested product. I really doubt that some simple Go implementation is going to have better performance than it. Nginx is used a lot by AWS - their Application Load Balancer is Nginx-based. I understand that setting up your application will be harder, but I'm sure that it's worth it.
A few things for you friend.. ------------------ If you were returning an `err` you could begin with `defer func(){ if err != nil { log.Fatal(err) }()` However, you're always bailing so a func to handle it ends up cleaning you up a touch.. func handleErr(err error) { if err != nil { log.Fatal(err) } } So all of your `if err != nil {...}` just becomes `handleErr(err)` ------------------ This tidbit is redundant, and still unsafe, as you may find yourself with a nil pointer reference. &gt;var txnMap map[string]*sql. &gt;txnMap = make(map[string]*sql.Tx) `var t Type` is the same as `t := new(Type)` Either of these are safe so long as `t` itself, or something within (struct) it does not need to be initialized as to avoid a nil pointer exception. For anything that is of type slice/map, it's best to just use `make`. If you were to print the value of a non-initialized slice/map, you'd get nil, not that type of length zero. `t := make(Type, 0)` infers both the declaration and the initialization of length 0. In the end though, I don't see the need for `txnMap` as it will only ever hold an index of three, just declare those separately and be good with it.. You do this again with the statements, its just extra steps IMO since everything lives in this function. clear, md5, sha1 := initTxs(db) func initTxs(db *sql.DB) (clear *sql.Tx, md5 *sql.Tx, sha *sql.Tx, err error) { // make Tx's using db } Even with that said though, not sure I see the need to have separate identifiers for _"This transaction var can only be used with this map reference"_ ------------------ `var lineCount int64 = 0` zero value of int64 is 0, no need to declare it. --------------- I noticed you were using a pointer to an `int64`.. again, this can lead to a nil reference. The only time I have ever come across the need/use of pointer arithmetic is if I potentially want a `nil` or `null` value. ------------- You're passing a `txn` in `insertToDb` but you're creating it here too? Nah son ------------ Wrap `insertToDb` with `lineCount%int64(int(copySize)) == 0` ------------ Given that you're unsure of the input, go ahead and validate all of it at once, and do it before passing it into your `lineChannel`to return a `type creds struct { user, pass string }` and this is now your `credsChannel` as you will have split by line, split by delimiter, validated input and then `credsChannel &lt;- &amp;creds {user: "user", pass: "pass"}` --------------- Scrap your prepared statements and all that jazz.. Go does this for you. http://go-database-sql.org/prepared.html ---------- #TLDR https://pastebin.com/JDXwXLVq If you have any questions about what I did above, feel free to ask. I certainly would take it for a grain of salt, as I literally wrote it in Pastebin.. Cheers friend!
Funnily enough I just released a tool with the sole purpose of addressing the problem of exposing static files and http servers under one port in order to avoid cross origin issues: https://github.com/jsdw/weave I wonder if you might find it useful while hacking away at these things :)
Hey _jsdw, I hope you have a wonderful day.
There are often significantly faster routes to insert data than standard statements one by one. It goes as far as allowing the DB to truncate the table at the start to clear all indexes, and defer index building and any other checks/triggers until all the data has been loaded, disabling transaction logging and ensuring a full table lock rather than row based. Sometimes even hints that the source data is already sorted will help (see MS-SQL BCP utility documentation). The difference of leveraging these sorts of optimizations can be hugely significant on large sets of data, and are worth understanding before you worry about how your code looks.
Yeah, agree! All my apps use Nginx. I thought of trying out this new approach for this my new app after seeing the performance comparisons like this [https://gist.github.com/yosssi/4d719cccdf185259ea1d](https://gist.github.com/yosssi/4d719cccdf185259ea1d) &amp;#x200B; But as you suggest, I think I better stick to Nginx! Thanks for the help!
Thank you so much for taking your time and write such en elaborate response. I'll need some time to understand everything. The reason I've done a prepare statement was as it's in the pq documentation ([https://godoc.org/github.com/lib/pq#hdr-Bulk\_imports](https://godoc.org/github.com/lib/pq#hdr-Bulk_imports)).
Pretty interesting benchmark. I will take a look. Thanks!
We try to have everything defined by the provider (e.g. return/pass interface, not concrete type), but sometimes it makes more sense to have the consumer do it. Think of something like an ECS, but the needs of the ECS evolve as customers demand more features. Sometimes we can add functionality to the main ECS interface, but sometimes we just want to expose some other functionality specific to some subset of components, so we do a bit of duck-typing (e.g. think "weapon" vs "armor"). We intend for certain components to always implement certain interfaces used elsewhere, so we make sure they do with `var _ &lt;Interface&gt; = new(&lt;Type&gt;)`. Some pieces need to use the concrete type so they do type assertions, but we try to avoid that as much as possible to make adding new components seamless, so we instead try to do type assertions to other interfaces. I just want to do something like this: type myType &lt;base type&gt; : internal.Component, internal.RareComponent `myType` is typically used as an `internal.Component`, but it _also_ implements other interfaces as well, like `internal.RareComponent`. We don't want a developer to change one of those methods and have the component silently stop implementing `internal.RareComponent`, and we also want to make sure that modifying the definition of `internal.RareComponent` gives compile errors if we miss an implementer of the interface. This would essentially be syntax sugar for: type myType &lt;baseType&gt; var _ internal.Component = new(myType) var _ internal.RareComponent = new(myType) I find this a little ugly, so I want that syntax sugar.
I'd prefer to get a compile error when building the code than a compile error when running the tests. I usually don't run the tests until I'm ready to submit my code for review, and it's nice to get that feedback as early in the process as possible. Also, having syntax for it gives static analysis tools (say, IDEs) more information about a type, which is nice. I personally don't use that, but I have coworkers who do.
Wew honestly.. I'm not sure why I even gave you transactions! You have a single insert (assuming thats it? "md5" "user" pass").. so you don't even need the tx or Commit/Rollback. One sec.. we can speed this up even more.
I'm working with passwordlists of roughly 1TB. The idea is to insert the lines into the three different tables (clear, MD5, SHA1). I've used transactions to not insert every line but wait until x-amount of rows are ready to be inserted.
I've already answered that [here](https://www.reddit.com/r/golang/comments/bv35yy/starting_to_program_in_golang_coming_from_a_java/epq9q7r/), but basically I want to do this: &gt; type myType &lt;base type&gt; : internal.Component, internal.RareComponent `internal.Component` is used everywhere, but some components implement additional features. The first is checked because it's used, the second is type asserted. I just want to make sure that changing `RareComponent` will produce compile errors everywhere that it's intended to be implemented, and I want to make sure that a developer doesn't accidentally stop a component from implementing `RareComponent` by changing a method. We only have a few insntances where we do this, but it's still common enough that some syntax sugar for it would be nice.
&gt; Any JSON parser is going to barf with that input. When you say “barf”, are you suggesting it would produce an error? I would expect a JSON parser to successfully parse the first JSON object and stop there, before getting to EOF. To parse the second JSON object, you’d have to invoke it again. But I don’t expect it would error. Using Go’s JSON parser, the json.Decoder is a good fit for the task. I agree that “application/json” is not an accurate description of the entire output, but I’m not aware of a more representative Content-Type value.
https://pastebin.com/k6S2eCNA So, removed tx as they should only be used in.. transactional logic, meaning _I have multiple queries, and another system requires that they all execute without err. If one of them fails, then rollback any changes I made during this transaction._ whereas you have a list of the same type of query, so why not just make it a single insert capped at X iterations? Now, this looks like a script.. so in turn, I doubt you actually need to make use of a channel, and if not, you can make these inserts in bulk by writing a func that will iterate through a `[]credentials` slice, and based on what the password matches, pass it to a `credentialMap map[string]credential` Take this map, and build your queries in bulk.. func queryBuilder(credMap map[string][]credentials) []string { queries := make([]string,0) count := 0 var b strings.Builder b.WriteString("INSERT INTO creds VALUES ") for k, v := range credMap { for _, c := range v { // I believe this is your copySize? if count == queryLimit { // we've reached your limit for this single query // make sure we don't add an extra comma.. queries = append(queries, strings.TrimSuffix(b.String(), ",") // empty the buffer and start again b.Flush() b.WriteString("INSERT INTO creds VALUES ") count = 0 } b.WriteString(fmt.Sprintf("(%s, %s, %s), ", k, c.user, c.pass)) count++ } } return queries } It's not to say you can't use transactions, but if this table doesn't have any particular contraints.. lets just say, I use to have a habit of "covering my basis" and looking for "what could happen". If you write your code to cover every angle, you'll either over complicate it's purpose or miss the bigger picture. When there is a problem, adapt.. but that's me.
Sth like the proven keypass? How does it compare to gopass from a security perspective?
Yes it's like keypass but just from cli and with a syntax "git-like". About security - encryption is Twofish and keys are derived using an equivalent of PBKDF2 with SHA-256. Here the full PWSafe DB format specification: https://raw.githubusercontent.com/jpvasquez/PasswordSafe/master/docs/formatV3.txt. gopass does many more things.
Code gen
I feel like Go's interfaces design is somewhat misunderstood. The first important thing about is it that it recognizes that the location that interfaces should be defined, is by the consumer of that interface. To borrow from Uncle Bob, if I have code that knows how to "switch" things, and only needs to know that they are switchable, the interface of my requirements belongs with that. A light switch shouldn't have to know about everything that can switch it, as well as somehow share code with every other switchable object. Requiring an explicit "implements" like statement on a type that satisfies an interface rules out the ability for someone to create an abstraction over code that they have not written or across multiple libraries. In order to do that, I now need wrappers in my code, and if I'm adapting two libraries to work together I would need to import both of them, one for the code I want to use, and one for the interface I need to implement. Things like io.Reader are great examples of Go interface design, but not good examples of how interfaces function outside of a standard library that everyone agrees on and can import. In fact, it is possible to use io.Reader without importing io, simply by declaring your own interface that has the equivalent requirements. If those interfaces are no longer equivalent, the assignment fails at compile time ([https://play.golang.org/p/5ogoXiVzJmE](https://play.golang.org/p/5ogoXiVzJmE)). This allows insulation from coupling to a change in an interface you don't control, where another project could add to or change it, and giving you the error at the point that the problem actually is - the fact that their definition has changed even if your requirements have not. This is a reason against implementing functions on interfaces, because then they would cease to be equivalent and convertible simply based on requirement. The nil check issue is unfortunately not immediately obvious (and a bit annoying), but does fall out of the general assumption that 0 values are usable. You can write some code in such a way that a nil pointer has perfectly usable set of functions, and it's pretty avoidable once you know to avoid any potential typecasts of nils to interfaces (prefer explictly returning nil).
What is internal.Component? Like a struct? Or interface? Cause I could be wrong but are you making a God type? I always relate back to the standard library on how to struct code. If it is a struct then it shouldn't matter what methods it has. If it is an interface then you shouldn't be holding data inside it. You can but that's not how they do it in the standard docs. They pretty much have a few types to a package. I'm trying to think where you need a God type interface to pull through all your packages that isn't a struct.
Thanks bro
Yeah that licensing is a no for me dawg
Good stuff! That's looking a lot cleaner (both code and language! ;-) If you're going to create a new txn in a function you could use a pointer, then you don't have to return anything as the pointer will be updated to the address of the new transaction, and the garbage collector will free up the old one. I'm very much a fan of returning errors from functions, rather than doing a `log.Fatal(...)` you could use `errors.Wrap(err, "description")`. Why? Well it makes the function more re-usable and allows you to wrap certain methods in a retry pattern rather than to exit the executable. It may sound like nit picking but its all about making your code the best it can be... You're may not realise but you're putting a public repo together, and prospective employers may well look at it, I always ask for an applicants Github repo details, if, they haven't already passed it to me. Full disclosure: [https://github.com/RobHumphris](https://github.com/RobHumphris)
[two month old re-post](https://old.reddit.com/r/golang/comments/b8513o/why_are_my_go_executable_files_so_large/?submit_url=https%3A%2F%2Fscience.raphael.poss.name%2Fgo-executable-size-visualization-with-d3.html&amp;already_submitted=true&amp;submit_title=Why+are+my+Go+executable+files+so+large%3F)
If changing those things is requiring many updates all over your code, your code and your database representation may be too coupled, and this can cause you a lot of issues down the road where you have existing records with one name, and have to update everything before your code will work again. $0.01 You should strongly consider abstracting your persistent storage away from your code to isolate it.
Holy moly guys! Thanks for all the help. Looks like I still have some (a lot :D ) of learning to do.
Wrote this because I kept getting bit by adding parameters to constructors/receiver methods and then not actually using them. It's much more aggressive than unparam, so it may have a higher number of false positives depending on your coding/style standards (see the README for more info). It might be useful to someone else, so I figured I'd share :)
Sure, I agree. I was mostly just commenting on Viper's relative size when you have an actual microservice running. If your app is 2MB and adding a configuration app increases the size almost 3 times, that's significant. As your app gets larger, the library size matters a lot less.
http.Handle("/", http.FileServer(http.Dir("assets")))
Can it output only the password to stdout? I see that pull shows the password, but surrounded by a lot of things that would need to be filtered out.
I would recommend looking into generating Mandelbrot sets. The formula is well documented and generating the is satisfying. The problem lends itself well to the use of concurrency because each pixel in the resulting image can be calculated independent of all the others.
Thinking about it more, I think I might extend the Go API to also pre-render the pages by having it serve up the fronend as well and ask chromedp / puppetteer to pre-render the page, then the Go API can cache it for 5 minutes, and then return that result instead of serving up the empty index.html + static assets. This would avoid needing to run a node server to pre-render each page since I only care about doing it for non-logged in users (search engines). Regular uses will need to have JavaScript enabled if they want to interact - but not to browse/read content. \`\`\` Go &lt;- client requests page &lt;- client if not cache Go -&gt; serve static frontend build -&gt; chromedp Go &lt;- sends back compiled html &lt;- chromedp cache &lt; - page Go -&gt; send pre-compiled page + static assets -&gt; client \`\`\`
It looks like the project is managed using Gazelle: [https://github.com/bazelbuild/bazel-gazelle/](https://github.com/bazelbuild/bazel-gazelle/)
It looks like this make target will update both the go.mod file and the BUILD.bazel file for you. https://github.com/kubernetes-sigs/k8s-container-image-promoter/blob/859d30bc7a4d2ccedf188daa969cce5856e0b634/Makefile#L16-L26
Thanks, that helped me find a way to fix it but I still need to read up. [https://github.com/kubernetes-sigs/k8s-container-image-promoter/pull/56/commits/7b8f37b72b156aeae559b122263a1b781bb8fe68](https://github.com/kubernetes-sigs/k8s-container-image-promoter/pull/56/commits/7b8f37b72b156aeae559b122263a1b781bb8fe68) I ran `bazel run //:gazelle -- update-repos` [`k8s.io/klog`](https://k8s.io/klog) which produced the following in my WORKSPACE file: go_repository( name = "io_k8s_klog", commit = "78315d914a8af2453db4864e69230b647b1ff711", importpath = "k8s.io/klog", ) And then I manually added the following to the relevant BUILD.bazel and the tests now function. `"@io_k8s_klog//:go_default_library",` &amp;#x200B; How can I perform the second part of this in a non-manual fashion? Is there another gazelle/bazel command that should update the specific BUILD.bazel for me?
This newlsetter is easily becoming my favourite source of Go news.
&gt; Is there another gazelle/bazel command that should update the specific BUILD.bazel for me? I think that's the `update` command.
I ran it through here as well but it didn't actually change the BUILD.bazel file. All that did was update was WORKSPACE, add vendor/k8s.io/klog, and update vendor/modules.txt. I still had to manually update the BUILD.bazel file but I feel like that can't be the proper route.
Addendum: Only when using `gccgo`.
`fix` is what it ended up in this case, I had tried that but didn't realize I could specify a target as well. Thanks for the quick responses here!
Google bots now uses the latest chromium, so they should understand SPAs https://webmasters.googleblog.com/2019/05/the-new-evergreen-googlebot.html?m=1
Great news for the big issue: Google SEO. However, SSR is still an issue for social sharing as the rest of the platforms don't all use chrome when fetching pages for link/image/share metadata (Facebook, Twitter, Reddit, etc..)
Yes, but it's a big improvement worth mentioning in this thread :)
Here is one way... Prerendering using puppeteer. Here is info about that https://web.dev/prerender-with-react-snap/
Meaning regular Go compiler wasn't affected in the first place or hasn't received the optimization yet?
Oh nice. I'll definitely check it out. Cheers.
[removed]
I've only used up to thrift 0.11 because of compatability with other languages like python, but there should be zero need to hand edit the generated go files as long as you are using the correct version of the Go thrift library that matches the thrift generator. Having errors in the generated code, in my experience, usually indicates that either the thrift executable version or the Go thrift version has been changed independently of the other. Or the generated code is stale.
[removed]
[removed]
[removed]
All you need are meta tags, really.
I'd recommend using plain go over bazel unless you have specific requirements that really necessitate it.
Unaffected, I think
`gc` works very differently from `gccgo`. AFAIK it already uses hand-crafted assembly routines for that. In any case, the article talks about `GCC` specifically and `libc` function, neither of which have anything to do with `gc`. So yeah, the former; if you never call `setcontext`/`getcontext`, you can't be affected by them being slower than needed :)
Great! Although you might wanna write it at dev.to rather than Medium but it's your choice. I'm also learning Go look forward to reading your blog.
I' ve never heard of dev.to, whats the benefits over medium?
Medium is losing popularity (especially amongs Devs) freecodecamp migrated (controversially) to their own hosted blogs and hackernoon seems to be planning one. Dev.to is a community of all developers sharing stuff and interacting and a lot more,I highly recommend you check it out
[https://dev.to/adil\_w3nomad/gopher-gym-quiz-game-part-1-4lbo](https://dev.to/adil_w3nomad/gopher-gym-quiz-game-part-1-4lbo) Done it! And love the fact I can drop in an MD file and not have to worry about anything else. LOVE IT! What's your name of their?
Learn Javascript + Solidity, how to write smart contracts (ERC20 + ICO contract is a popular combo obviously), and how to use web3 with Javascript to interact with those contracts. Then learn how to use the go-ethereum client to deploy contracts, including the abigen tool ([https://github.com/ethereum/go-ethereum/wiki/Native-DApps:-Go-bindings-to-Ethereum-contracts](https://github.com/ethereum/go-ethereum/wiki/Native-DApps:-Go-bindings-to-Ethereum-contracts)). Learn how to create private keys on Ethereum, securely store them, and then use them to sign transactions. Microservice architecture is key with crypto, so something like your signer would be the only service having access to the keys, and then your web API wouldn't know a damn thing about it. Increases security which is a huge part of a crypto app if you're holding private keys.
I've used https://github.com/buger/jsonparser and been pretty happy with it.
Wait, is this a thing? What if you have an interface method that doesn't need all the params?
Why all this fuss about performance? You're not Google or Facebook.
Nice, i hadn't seen that library before, will check it out. Thanks
Go doesn't have type casts the way C does; instead, we have [type conversions][1] and [type assertions][2], and you need to choose the one that's right for the situation. (Both would be a cast in C) Conversions ask the compiler to change the representation of one value into another. For example, truncating a float32 into an int. This is required whenever the underlying types are different, or if the types have different names but the same underlying type. This is generally pretty performant, with the exception of converting between byte slice and string, which incurs an allocation and copy, which can be quite costly. What you are using here, though, is a type assertion, which is required when you have an interface but need to pull out the concrete type from it (or check if it matches a different / broader interface). For a concrete type check, this is pretty fast, because an interface is basically a type pointer and a value pointer, so you can think of it like a conditional... If the type pointer matches, extract the value. So, could this be slow? Yes, but generally your latency to your user and/or the database will be much larger, so unless you are doing it millions or billions of times, there are probably other things which can be optimized first if you find it is getting slow. [1]: https://golang.org/ref/spec#Conversions [2]: https://golang.org/ref/spec#Type_assertions
Plain type assertions are pretty quick, not much slower than the unsafe trickery. Reflection on the other hand is pretty slow and allocation heavy. A type assertion gets you back a more concrete type given an abstract type. Type conversion really changes the concrete type.
A small suggestion: You can rewrite this using the go/analysis API, allowing the tool to be reused throughout the ecosystem without any special need. And it will integrate directly with the `go vet` command.
I was thinking about this too...maybe something like the 'pwsafe clip' command where we can specify which field..something like this 'pwsafe pull -url or -user or -pass if nothing is specified -pass will be the default'...and a plain output just the filed content, what do you think?
Type assertions to concrete types should be very fast, yes. Type assertions to interface types are probably a bit slower, though.
Casting in Go is possible with \`unsafe.Pointer\`. For example: \`\`\` var i int ptr := unsafe.Pointer(&amp;i) \`\`\`
Why does this context switching code need mitigations at all? Both threads run in the same address space after all, so there is no information that could leak that wasn't available in the first place.
&gt; So, could this be slow? Yes, but (...) there are probably other things which can be optimized first Yes, in other words: do not optimize prematurely. If you are curious or paranoid and an alternative way to get your data from the mongo driver exists, you could benchmark both and see which one performs better.
Thanks for sharing. May be we can make our lives a bit easier with introducing docker image to build project and plugins? Thus, environment will be the same for project, and third-parties.
I had that when I learned about channels. It's like some sort of magical force that I still don't fully believe in.
If you're asserting to an interface though, there are a few extra steps to look up and possibly compute the itable. https://research.swtch.com/interfaces
From my experimentation it seems like: `array[from:upto:capacity]`, is this correct?
array[:length:cap] resizes the slice to use the underlying array and sets the length and cap to new values. Both should be Bellow or equal the max length of the array.
That is awesome! I hadn’t heard of that API - thanks for the suggestion!
You can find the definition of this at [https://golang.org/ref/spec#Slice\_expressions](https://golang.org/ref/spec#Slice_expressions) ("Full slice expressions"). Generally slicing expressions follow the format: a[low : high : max] The `max` parameter controls the resulting slice's capacity by setting it to `max` \- `low`. Please note that `max` it cannot exceed the capacity of the original slice. I [played](https://play.golang.org/p/bQg5YzMcFlb) with it a bit: package main import ( "fmt" ) func main() { a := make([]int, 10, 20) for i := 0; i &lt; len(a); i++ { a[i] = i } fmt.Printf("a: %v\n", a) fmt.Printf("len: %d\n", len(a)) fmt.Printf("cap: %d\n", cap(a)) b := a[:10:10] fmt.Printf("b: %v\n", b) fmt.Printf("len: %d\n", len(b)) fmt.Printf("cap: %d\n", cap(b)) c := a[5:10:20] fmt.Printf("c: %v\n", c) fmt.Printf("len: %d\n", len(c)) fmt.Printf("cap: %d\n", cap(c)) } which yields: a: [0 1 2 3 4 5 6 7 8 9] len: 10 cap: 20 b: [0 1 2 3 4 5 6 7 8 9] len: 10 cap: 10 c: [5 6 7 8 9] len: 5 cap: 15
Great reply. Simple and kind. Thank you!
Some of those were theory but it still was hard.
How does this relate to [pass](https://www.passwordstore.org/) (i.e. feature wise)?
This example code is invalid.
There are different types of casts (which C++ is explicit about, but the descriptions still apply in C), and I'd say it's worth being specific - this is the equivalent of a reinterpret cast
Mainly in pass each password lives inside of a gpg encrypted file while pwsafe use a single encrypted file. Besides pass has many others plugins (but we can do them for pwsafe too). Pass can also generate passwords I left this feature off intentionally since I'm working on another tool 'pwgen' in order to generate password using different strategies.
a humble correction for next time. `:` are colons. `;` is a semicolon
Whenever I see threads like this one, where the conversation has gone, I don't understand why anyone uses Go. Personally, I love the way the language is designed. I would absolutely agree that it can be more verbose than Java or many other languages. However, I also find Go to be the most readable and easy to follow language generally speaking.
This mishandles (or at least strangely handles) input like "\\".
Funny, it works in the playground: &amp;#x200B; [https://play.golang.org/p/tlECKvAZqVe](https://play.golang.org/p/tlECKvAZqVe) &amp;#x200B; What do you mean by invalid?
Type assertion is VERY fast. See my post about it: https://www.reddit.com/r/golang/comments/9xs0r2/why_is_type_assertion_so_fast/
&gt; Funny, it works in the playground: ​Funny someone thinks "works" implies valid code. The code is invalid because it violates the rules under which conversions of unsafe pointers are valid. In particular right the first one.
That was why I asked what you meant by invalid. &amp;#x200B; Your attitude is toxic.
I was not talking about your points. I only said your code is invalid. Which it is.
[let me google that for you](http://www.letmegooglethat.com/?q=go+diff)
&gt; What is internal.Component? Interface. The syntax would be: `type &lt;T&gt; &lt;base&gt; : &lt;interface...&gt;` Here are some examples for an RPG: type Component interface { ID() string String() string } type Character interface { Component Inventory() []Component Equipment() []Component Health() int DealDamage(Weapon) } type Equipment interface { Component Durability() int Defense() int } type Weapon interface { Damage() int } And then some code: func doDamage(to, from Character) { for _, e := range from.Equipment() { if w, ok := e.(Weapon); ok { to.DealDamage(w) } } } Or something like that.
Omg! Yay!
Let's break the example ```go var theCArray *C.YourType = C.getTheArray() length := C.getTheArrayLength() slice := (*[1 &lt;&lt; 28]C.YourType)(unsafe.Pointer(theCArray))[:length:length] ``` down: 1. The statement `var theCArray *C.YourType = C.getTheArray()` declares the variable `theCArray` which has the pointer type `*C.YourType`, and assigns to it a memory address returned by the call to `C.getTheArray()`. "Has the pointer type" means it contains an address of a block of 0 to ∞ number of elements of the "base" type of the pointer, `C.YourType` in this case. 1. The statement `length := C.getTheArrayLength()` declares a variable `length` and assigns it the length of the array dealt with on the 1st step. 1. The statement `slice := (*[1 &lt;&lt; 28]C.YourType)(unsafe.Pointer(theCArray))[:length:length]` does the following: 1. The value of the variable `theCArray` is type-converted to the type `unsafe.Pointer`, which, in Go, is defined to mean "a pointer of any type" which is still considered by the GC as a valid reference to some memory block (as opposed to values of the `uintptr` type). Note that the value itself was not changed, — only its type was. 1. The resulting value is again type-converted — this time to the type `*[1 &lt;&lt; 28]C.YourType`. This type means "a pointer (`*`) to an array of length 2^28 containing elements of type `C.YourType`. 2^28 is 268435456, and it was picked merely because in Go, the length is an integral part of any array type and hence it must be constant, and hence you cannot legitimately write `[length]C.YourType` since `length` is not a constant, and hence "the trick" is to merely declare the array's type to contain a "huge enough" number of elements. 1. The resulting value which is now have the type "a pointer to a very long array of elements of type `C.YourType` is now "sliced" — by applying that `[...]` construct to it. Slicing is creating a [slice value](https://blog.golang.org/go-slices-usage-and-internals) which is basically a small `struct` consisting of the three fields: - A pointer to the underlying memory block (the so-called "backing array"). - The length of the block in that array the slice users allowed to use — by applying the indexing operation to the slice. Counted in elements of the slice's type. - "The capacity": the length of the block in that array which is available to be used past the length of the slice. It can be used either by reslicing the original slice or by `append`-ing data to the original slice. Note that both reslicing and growing return a _new_ slice which shares the underlying array with the original one. In the example, slicing uses the "full" — three-argument — form which merely omits the first argument which is defined to be `0` in this case. That is, it could have been spelled `[0:length:length]`. So, that `pointerValue[0:length:length]` means "create a slice pointing to the memory at the address `pointerValue`, at offset `0`, having `length` elements` and having the capacity of `length` elements. Hence, to recap: 1. We receive a pointer to an array from the C side. 1. To fullfill the Go's strict typing rules, in the series of type-conversions of the received memory address we "virtualize" the size of the array passed to us—pretending it is very long, and then… 1. …we create a slice "over" that memory block—"chopping" it back to the actual size provided by the C side. Setting the correct capacity is paramount here since if we would ever call `append` on the resulting slice, the `append` code would notice there is no room in the original memory block to append the new element(s), and hence it would allocate a new—large enough—one, in the Go memory, copy the source elements over and then write there the appended one(s). Otherwise, `append` could simply write the new elements past the end of the block causing all sorts of "interesting" behaviour typical for C code.
"Resizes" is not quite the correct word to use here: we're not resizing a slice here—we rather create a new one.
pclntab stripping has been discussed on golang-nuts: https://groups.google.com/d/msg/golang-nuts/hEdGYnqokZc/ltonS9eAAwAJ
I’d like to mention that converting between byte slices and strings does not always require an allocation. See, eg, the bytes package for Go 1.13 or map[(string(x)]. The compiler is getting smarter.
Can you please elaborate on the meaning of the title—is this about "JSON events" or "event processing"? If you _do not_ ask about some sort of events generated by some JSON parser watching an infinite stream of JSON data—upon encountering certain patterns,—but rather merely about a way to partially parse a JSON document to extract a particular subset of data from it, you may start researching from [this internet search query](https://www.google.com/search?q=golang+jsonpath). Also note that "stock" JSON decoder is able to decode any document representing a JSON object into a value of type `map[string]json.RawMessage` which makes the decoder perform only the most shallow decoding possible; you may then "dig deeper" by finding the entry of interest in the decoded object and then recursively decode its `json.RawMessage` (which is basically an alias for `[]byte` with a handful of methods).
It is normal for the TCP stack to handle the handshake and establish the connection regardless of whether the client calls accept or not.
The title makes it seem like it's for Go 1.0.0, not that it's "for Go, and at version 1.0.0" :P
Yes, something like clip, but that would just send the output to stdout, because that allows someone to use your program with other scripts easily
That is so awesome, thank you very much for your work!
Haha very true. Oh well. Can’t win em all.
Oh yes, completely forgot that the restic compression discussion was one of the motivators to implement this. I hope it will be helpful to you! As a sidenote, I have actually been thinking of adding a `PadToMultipleOf(n)` function to make the information leak from compression smaller/unusable. Could be a nice, relaxing thing to do now.
Congrats, Klaus! When zstandard was first announced, I was wary of it because of how complex it is. Complex standards tend to have fewer independent implementations, which means a single point of failure. So I'm very happy to see a pure-Go implementation, especially one written by a performance-obsessed developer like yourself. :)
Nop... Accepting the connection is always upto us... If we reach maximum clients then we simply come out of the infinite accept loop. There is a solution tho, you can close the server via Close() call on the server. This won't affect connected clients but this isn't a correct way of doing it. One should always be binded to the port they are using and this effectively gives up the port so some other program is free to use it.
Premature optimization is the root of all evil.
I believe there is a limit in number of connection queued in Accept. So, if limit is reached and client try to connect, Accept will return a nil and error (this is one of reason why we have an error on Accept) and client connection will refused.
I create a [diff library](https://godoc.org/github.com/shuLhan/share/lib/text/diff) for diff-ing changes on Wikipedia article long time ago. The documentation is not quite good, I think if you clone and can read the [test files](https://github.com/shuLhan/share/blob/master/lib/text/diff/diff_test.go), it will be self explanatory.
this is completely broken, there are issues on the extension's github but they don't really care I'm buying the (https://www.jetbrains.com/go/buy/#edition=personal)[GoLand IDE], fuck those idiots
I think thats something totally different. You are talking about the blacklog but here, I never even call Accept but if someone tries to connect, for them they just connect successfully as if i just accepted them.
I am curious about the decision to use context for reading and writing messages. It seems like the use case is for setting a deadline on the time to read or write a message. Typical code will be: ctx, cancel := context.WithTimeout(ctx, writeTimeout) wc, err := conn.Writer(ctx, websocket.MessageText) if err != nil { cancel() return err } err = wc.Write(message); if err == nil { err = wc.Close() } cancel() return err This requires that the connection run a goroutine to handle the cancelation. This makes for a complex implementation and it burns memory on a goroutine. Also, context.WithTimeout does a bunch of stuff. It seems simpler to pass a timeout to the function and use deadlines internally: wc, err := conn.Writer(writeTimeout, websocket.MessageText) if err != nil { return err } err = wc.Write(message); if err == nil { err = wc.Close() } return err The API is easier to use. The implementation will be less complex. It will use less memory.
So what's wrong with the suggestions from u/moocat and u/rv77ax? The kernel accepts the clients for your socket unless it reaches the configured backlog cutoff, and then stops doing that (the new clients get rejected).
Run it under `strace`, or the equivalent for your OS, and you'll see Go is sitting on `read(2)` and not completing any system calls despite the handshake completing for the other side of the socket.
I must say I quite like it. It seems to have all the right elements - and unlike others it doesn't seem to specialized and, most important, it is extremely flexible. There are a lot of factors that makes it great. Not at least the great decompression speed, which is often seem as a side note. For services I often see decompression speed become a bottleneck and force people to use pure LZ compressors like LZ4 or Snappy.
Added: https://github.com/klauspost/compress/pull/108
Please update the title with the word "web" to not mislead the readers.
That's exactly what it shouldn't be doing... The backlog means those connections are queued and not accepted till I reach them with Accept()... If it were like you said then there would be no real purpose for calling Aceept() manually. Ps there is no way to configure any backlog value so I would assume its decided by the runtime, what shouldn't be happening is the accepting clients automatically before I even get the chance to call Accept().
Do you have a programming language or operating system that behave like what you said? I would like to know more about it.
This is cool project, good job!
I don't know. I'm sorry if I seemed rude but from personal experience I thought Accept() would mean accepting a client. Its literal name is "Accept" so why wouldn't it be final function or deciding function to accept the next connection or not. But if it is the way you say then how should I effectively limit max players without calling Close() which would free the port.
The reason you need to call `accept` is both so you know when a new client connects and to provide you with a `Conn` object so you communicate with that client. AFAIK, that is the standard semantics for sockets. If you absolutely hate that, you can try rolling your own TCP stack.
The name „accept“ is a little bit confusing, but all connections in the backlog queue are already established by the os. That means the TCP handshake is already completed and in the context of TCP the connection is already „accepted“.
Ahh I see, well then I guess that solves it.
I feel like you’re the kind of guy that would discover middle-out
[https://mholt.github.io/json-to-go/](https://mholt.github.io/json-to-go/) ``` type AwsEvent struct { Version string `json:"version"` ID string `json:"id"` DetailType string `json:"detail-type"` Source string `json:"source"` Account string `json:"account"` Time time.Time `json:"time"` Region string `json:"region"` Resources []string `json:"resources"` Detail json.RawMessage `json:"detail"` } ``` switch on DetailType and do the same extraction for any event types you want by Unmarshalling the Detail field.
You can learn the language in a couple of days, enough to be productive anyway. What I think takes longer is figuring out how alter the programming patterns you've used in the past in light of Go's more limited OO approach. If you're still a student, that might not be an issue with you.
Thanks, I hope so!
:D No - I'll just be happy if I understand what the really brilliant people figure out. Yann Collet who made Zstandard (and LZ4) is really good at turning theory into really well performing implementation. He took "Asymmetric numeral systems" (by Jarek Duda) and turned it info one of the first good implementations - Finite State Entropy (FSE), used for part of the compression. Matt Mahoney is another guy that is really inventing great stuff. He is behind the only real innovation in lossless compression for many, many years, called "Context mixing", which, however is still considered too slow for real world application. I could go on - my only point being, that these people invent stuff - I mostly just try to understand it - but that is also fun enough for me :)
Locking a repo usually means it's end of life and no longer maintained. I think want you mean is version 1.0, which means you are now committed to not break downstream user's code with incompatible changes.
You make a great point and it was something I thought about as well when writing the library. 1. Context's are a standard way to perform cancellation with any API. Its also nice to be able to thread your context through to everything and know that when the parent cancels, everything in the call stack below will eventually unblock. 2. The implementation is actually very simple in regards to contexts. There isn't really much to be done there, you just have a goroutine running that closes the context if a timeout is hit. [https://github.com/nhooyr/websocket/blob/e79f3501021508ff5b0f03805d16f5059fcda841/websocket.go#L127-L156](https://github.com/nhooyr/websocket/blob/e79f3501021508ff5b0f03805d16f5059fcda841/websocket.go#L127-L156) 3. Goroutines are very cheap, its only an extra 2KB per connection and I do mention this in the README. For most applications, its really not something to think about. If it is, you ought to use gobwas/ws 4. context.WithTimeout is very cheap as well, doesn't do much. It just registers itself on the parent context to be cancelled when it is. 5. Your example can be simplified with contexts to be about the same as with a timeout: &amp;#8203; ctx, cancel := context.WithTimeout(ctx, writeTimeout) defer cancel() wc, err := conn.Writer(ctx, websocket.MessageText) if err != nil { return err } err = wc.Write(message); if err == nil { return err } return wc.Close() It's an additional two lines and sometimes no lines at all because the parent context already has an acceptable timeout.
I don’t think many are confused by the post title. Good job OP!
Start building, write tests, analyze profile / benchmarking data. Once a thing is working tweak it and repeat analysis. Having the raw experience that has seen what changes made what improvements in various situations may be nuanced and hard to teach but once you have a small taste of how to find better ways (as opposed to "knowing the right way") you'll have more confidence than the window shopper who just executes on sales' pitches.
Are you the one asking the question or not?
\&gt; Its literal name is "Accept" so why wouldn't it be final function or deciding function to accept the next connection or not &amp;#x200B; Its an API between programming language and kernel (another layer of abstraction provided by language), which is derived from POSIX. &amp;#x200B; \&gt; But if it is the way you say then how should I effectively limit max players without calling Close() which would free the port. &amp;#x200B; The easy way, that most people will do, is by counting how many active clients currently live on your server (increased when Accept, decreased when client socket Close called or Read/Write to client socket return io.EOF).
It's not misleading. Apps that are not on the web can still leverage browser technology. Doing so also makes for a nice transition to the web should one ever wish that.
Read and learn [https://golang.org/doc/effective\_go.html](https://golang.org/doc/effective_go.html) and you'll be on par with most of go coders.
Correct. I meant that the spec itself is still a draft and open for feedback. The repo is marked as not production ready, with a release ETA. Thanks for pointing out the nuance though - updated the post to be more specific.
Are contexts the standard for timeouts when writing to a network connection? The net,Conn interface uses deadlines, not context. The primary functionality provided by context compared to deadlines/timeouts is that cancel is propagated from the parent down to the write operation on the connection. Given that cancel can kill the connection, that does not seem like something that applications will want. The decision to kill the connection will typically be based a write operation taking too long, not that some larger operation was completed or canceled.
I think `thedevsaddam/jsonq` is a good fit here. Cloudwatch events, as far as I can tell from a brief look, have lots and lots of event types with some common fields and some type-specific fields. `jsonq` would be a quite convenient way of picking a few fields from the various structs, especially if these are the common fields like id, source, time, etc. But I have to point out that I have no practical experience with using jsonq for cloudwatch events, and based on what exactly you need to achieve, parsing might solve your problem as well as querying. So maybe you would want to set up some tests to see which of the two approaches feel more applicable to your problem.
I don't think you can conclude anything from the net.Con interface because the net.Conn interface predates context by years. &amp;#x200B; I agree regarding your point about propagation.
Have a look at a tool like chromedp which allows you to control the browser via code. https://github.com/chromedp/chromedp
This may be just me but the font on that article is horrible in Chrome.
I was mislead.
&gt; // lol &gt; const arrayLength = 1&lt;&lt;30 I don't get it. What's the pun?
Very nice! I was just looking for a pure Go implementation of Zstandard last week and now here it is.
Expectations are at the root of all heartache.
Irrelevant.
Like this thread.
Finally, something I can agree with!
yes, I think that is. Do you have some advise?
I have split between from my business and storage. The business level call storage level functions. Storage level function like this: func (db \*Database) RemoveUser(userId string) error{ err := db.collection.Remove(bson.M{"user\_id": userId}) return err } func (db \*Database) DeleteUser(userList\[\]string) error { err := db.collection.Remove(bson.M{"userId": bson.M{"$in": userList}}) return err } &amp;#x200B; I think this have isolate business and storage. Did you have good ideas ?
[removed]
Maybe try playing with cloudflare workers?
The tutorial series below should get you basics in couple of days. [https://golangbot.com/learn-golang-series/](https://golangbot.com/learn-golang-series/)
Look into using protobuf then you can integrate code gen around that to create mongo specific methods. However, choosing to use protobufs for this reason alone is probably not a good idea but that is one way if you are already considerinn it
All links on the [dev.to version](https://dev.to/adil_w3nomad/gopher-gym-quiz-game-part-1-4lbo) of the page seem broken, for example: [https://dev.to/adil_w3nomad/_https://gophercises.com_](https://dev.to/adil_w3nomad/_https://gophercises.com_). I only get a dev.to page saying "You have lost your way. Return to Home Page"
I think this was on the road map when I last used badger. I ended up writing an ultra basic CLI query tool for my particular project/data model to fill the gap. Unsure if one exists nowadays.
Thanks!
Yes, create a second Lister on port 80 with the handler to the endpoint you want to serve.
I don't think this is possible as certificate exchange is handled first before the url is sent to the server therefore a port is either covered by https or not, but can't have both based on the url.
Let's break the example ```go var theCArray *C.YourType = C.getTheArray() length := C.getTheArrayLength() slice := (*[1 &lt;&lt; 28]C.YourType)(unsafe.Pointer(theCArray))[:length:length] ``` down: 1. The statement `var theCArray *C.YourType = C.getTheArray()` declares the variable `theCArray` which has the pointer type `*C.YourType`, and assigns to it a memory address returned by the call to `C.getTheArray()`. "Has the pointer type" means it contains an address of a block of 0 to ∞ number of elements of the "base" type of the pointer, `C.YourType` in this case. 1. The statement `length := C.getTheArrayLength()` declares a variable `length` and assigns it the length of the array dealt with on the 1st step. 1. The statement `slice := (*[1 &lt;&lt; 28]C.YourType)(unsafe.Pointer(theCArray))[:length:length]` does the following: 1. The value of the variable `theCArray` is type-converted to the type `unsafe.Pointer`, which, in Go, is defined to mean "a pointer of any type" which is still considered by the GC as a valid reference to some memory block (as opposed to values of the `uintptr` type). Note that the value itself was not changed, — only its type was. 1. The resulting value is again type-converted — this time to the type `*[1 &lt;&lt; 28]C.YourType`. This type means "a pointer (`*`) to an array of length 2^28 containing elements of type `C.YourType`. 2^28 is 268435456, and it was picked merely because in Go, the length is an integral part of any array type and hence it must be constant, and hence you cannot legitimately write `[length]C.YourType` since `length` is not a constant, and hence "the trick" is to merely declare the array's type to contain a "huge enough" number of elements. It supposedly worth keeping in mind that in Go, a pointer to an array also points to the first element of that array (at index 0). (This is unlike slices—see below.) 1. The resulting value which now has the type "a pointer to a very long array of elements of type `C.YourType`" is now "sliced" — by applying that `[a:b:c]` construct to it. Slicing is creating a [slice value](https://golang.org/ref/spec#Slice_expressions) which is basically a small `struct` consisting of the three fields: - A pointer to the underlying memory block (the so-called "backing array"). - The length of the block in that array the slice users allowed to use — by applying the indexing operation to the slice. Counted in elements of the slice's type. - "The capacity": the length of the block in that array which is available to be used past the length of the slice. It can be used either by reslicing the original slice or by `append`-ing data to the original slice. Note that both reslicing and growing return a _new_ slice which shares the underlying array with the original one. In the example, slicing uses the "full" — three-argument — form which merely omits the first argument which is defined to be `0` in this case. That is, it could have been spelled `[0:length:length]`. So, that `pointerValue[0:length:length]` means "create a slice pointing to the memory at the address `pointerValue`, at offset `0`, having `length` elements and having the capacity of `length` elements—meaning the slice's length and the capacity are the same and so there is no free room in the underlying array beyond the slice's length. Hence, to recap: 1. We receive a pointer to an array from the C side. 1. To fullfill the Go's strict typing rules, in the series of type-conversions of the received memory address we "virtualize" the size of the array passed to us—pretending it is very long, and then… 1. …we create a slice "over" that memory block—"chopping" it back to the actual size provided by the C side. Setting the correct capacity is paramount here since if we were to to create a slice using a more common two-argument form—`[0:length]` or `[:length]`—the capacity of the resulting slice would have been "inherited" from the original memory block and would be 2^28. Obviously, that number has no real sense and was picked only to "sure be greater than" `length`. If we were to not set the slice's capacity when creating it, and then were to call `append` on that slice, the `append` code would notice there is plenty of room in the slice's backing array (2²⁸-`length`) and then would simplemindedly write the elements to be appended past the "legal" memory block causing all sorts of "interesting" behaviour typical for C code. But since we've capped the slice, any call to `append` on the slice will cause `append` to allocate a new—large enough—memory block, copy the source elements over into it and then write there the appended one(s). Further reading: - &lt;https://blog.golang.org/go-slices-usage-and-internals&gt; - &lt;https://blog.golang.org/slices&gt;
&gt; dev.to version Thanks!!! I'll fix it now
have gone through it all and its located the right place and running on the right accounts - but inspecting the eventviewer i can see this :[https://i.imgur.com/VG2YJm7.png](https://i.imgur.com/VG2YJm7.png) &amp;#x200B; `"The Go Service Example for Logging service depends on the following service:` [`After=network-online.target`](https://After=network-online.target) [`syslog.target`](https://syslog.target)`. This service might not be installed."` &amp;#x200B; inspecting the registry i can see it has these 2 - is this something for linux that doesnt exists on windows or is this normal on windows ? &amp;#x200B; [https://i.imgur.com/34BvdBb.png](https://i.imgur.com/34BvdBb.png)
I'm assuming you want to expose your Go service to the network directly, and don't have a load balancer/reverse proxy/... in front of your backend infrastructure. Like mentioned before, key exchange is a low-level detail that's handled before high-level request interpretation (such as parsing the request path) is handled. You can therefore not decide whether TLS is required based on the request path/URL. What you can do is expose two different ports and require TLS on one of them. This is sometimes useful to do, e.g. for providing a health check for probing. Here's an example that exposes one secure port and one insecure port. This example should be fairly straight forward (remember to always wrap your handlers in a `http.Server`, especially when the requests go straight to your Go service without any LB/reverse proxy in front): https://play.golang.org/p/rDL7SeLyyBr
1. My own preference but I prefer to over package I to to have the main.go file and main package only responsible for app level items (loading config, starting app). I would move all other functionality into packages. 2. JSON is totally ok for config. You do lose the ability to change config on the fly though without a reload so definitely consider that. 3. Noice
Yes, I thought the best way to organize my code was with packages. However, in my opinion, the program is too small for starting to refactor on that way. As you can see on my github I have some other projects that are structured on this way. Thanks!
I've liked using Redis so far, so I'd suggest to give that a look. It's fast, persists to disk if desired, simple (key value look-up) but supports more advanced stuff, noSQL, etc. Redis: https://redis.io/ Go-lib: https://github.com/mediocregopher/radix --&gt; Other libs exist of course, this is just one I've used before.
 &gt;\- safe to call from different channels and go routines &gt; Usually most of the database options offer a client that is goroutine safe and handles the synchronised access. &gt;\- if possible - allowed to be accessed by other processes ( this i can live without, just a nice to have ) &gt; You might want to drop this requirement and expect to just host access through your app. If an embedded db does let you have multiple open handles to the same db, it would likely restrict it to one writer. &gt; &gt;Ive been reading through and looked around and there are many out there it seems, had almost pulled the trigger on BoltDB &gt;... &gt;Also Badger etc but thats abit on the same line as BoltDB. &gt; I have a Queue application that does a high rate of adds/removes. It started with using Boltdb. When the database gets very big it can take a bit of time to start up again, depending on the mmap settings and whether you want it full read-ahead or to take hits accessing it later. So I started looking into Badger and did an alternate backend implementation. It seemed to work great and I was getting better performance in most areas so I started deploying it. Then I started seeing some big slow downs in production and tried getting help with it via this issue: https://github.com/dgraph-io/badger/issues/768 Long story short, it seemed with my access patterns, I was getting really slow access with the iterators and didn't get an acceptable solution. So I switched back to Bolt.
Looking forward to the rest of the series.
Thank you, this is very comprehensive, I'm rereading multiple times
Redis is far from embedded.
But Redis runs as its own service right ? so i would need to install it first and then run my client towards it ? was thinking more of an embedded db that i doesnt require to have a seperate db service installed.
Thanks! I'm close to finishing the second post, if you have questions or comments feel free to send them my way :)
beside the starting up time for BoltDB you are satisfied with its performance ?
Yes.
thanks
And "random" does not mean "random with uniform distribution". Could we say iteration order is "undefined but random with undefined distribution"? And if yes: Is this helpful somehow? It boils down to "You must not rely on map iteration order."
It is hard to suggest anything with only generic details provided, specifically about project platform, architecture, expected load, queue size, number of queue clients etc. But what makes you looking at embedded solutions only? I mean, embedded might still do the job, and in some cases is the perfect choice, but there is always a price to pay (functionality, availability, management). Imho, the right tools for the right task is what makes a system shine. If going embedded is not carved in stone, than aforementioned Redis is a good place to start and has a decent go api libs. If you are aiming towards a more robust processing platform, you could take a look at Apache Kafka (but that will most likely require more code changes and the go library landscape for it is far from perfect)
Which, like...it isn't that hard to use a slice and shuffle the indices.
Oh yes, that's true. I read over that bit in your request I believe, sorry!
Thank you, I want to get into Go Kit but it's a steep slope.
The best way is to test on your own workload and see the results. Maybe bolt is good _enough_ for your purposes ? How do you know ? Try it out first :) I guess you have read https://github.com/boltdb/bolt#caveats--limitations ? Especially - &gt; Bolt is good for read intensive workloads. Sequential write performance is also fast but random writes can be slow. You can use DB.Batch() or add a write-ahead log to help mitigate this issue. On your note on Badger: &gt; Also Badger etc but thats abit on the same line as BoltDB. No I don't believe so. Read the documentation yourself and analyze. BoltDB is based on LMDB which uses B+ trees, hence they are read optimized. Badger is based on rocksDB which uses LSM-trees, hence they are write optimized. There are tradeoffs for everything. You cannot get fast reads and fast writes at the same time. Understand your workload, see if you want to optimize reads or writes. Use each tool and see the results, maybe Badger has issues which come up during your tests, maybe Bolt is very stable. Maybe using SSD helps a lot. You will never know without trying them out first. :)
try bbolt a boltdb fork from etcd, i had very good experience with it. https://github.com/etcd-io/bbolt, i tried badgerDB but my use case had lot of deletes and it got very slow after 100k deletes,
There are definitely a bunch of conventions to get used to. They have a tool called Kitgen that is meant to help with some of the boiler plate but it has some bugs, I didn’t include it because I could get it work with their examples.
No, it's undefined, full stop. In one implementation it may be uniformly random, in another it may be random with a non-uniform distribution (that legitimately can potentially include things like this: [https://twitter.com/CAFxX/status/1135339266798604288](https://twitter.com/CAFxX/status/1135339266798604288)), and in another it can be constant and ordered. They would all be equally valid under the language spec.
Yeah I started to change something and committed it without finishing it for some reason. I should put a bit more work into it \^\^
You actually don't even need that: picking a uniformly random number \`n\` from \`0\` to \`len(m)-1\` inclusive and taking the key/value in the \`n\`-th iteration should be enough. If you need to do this many many times and the map does not change, sure: use a slice.
I don't think that entry in the DependsOnService is right. I looked at a few other services I have and the entries were in a different format. Can you try removing those and see if it works? It looks vaguely "Linux-ish" but my Linux skills aren't so good.
Without actually looking at the source code behind map, I wondered if that bias is due to the value or the insertion order. Google's implementation of Go is currently biased towards elements inserted first. Here's the distribution when the map is built backwards: https://i.imgur.com/KTJsSZO.png
I like to use the word "indeterminate". To me that means that there is probably a fixed order, but we don't know it. Random has a specific meaning.
\&gt; Are contexts the standard for timeouts when writing to a network connection? The net,Conn interface uses deadlines, not context. &amp;#x200B; Like DryCauliflower4 replied below, net.Conn predates Context. See [https://github.com/golang/go/issues/20280](https://github.com/golang/go/issues/20280) for more discussion regarding this. &amp;#x200B; \&gt; The primary functionality provided by context compared to deadlines/timeouts is that cancel is propagated from the parent down to the write operation on the connection. Given that cancel can kill the connection, that does not seem like something that applications will want. The decision to kill the connection will typically be based a write operation taking too long, not that some larger operation was completed or canceled. &amp;#x200B; cancel killing the connection is not intended, its just a limitation because net/http.Client only gives a io.ReadWriteCloser for upgrades and so the library cannot unblock a read or write without closing the connection. With net.Conn, you can just set the deadline to some time in the past. See [https://go-review.googlesource.com/c/go/+/31173/7/src/net/http/server.go#624](https://go-review.googlesource.com/c/go/+/31173/7/src/net/http/server.go#624) &amp;#x200B; Its true, most of the time, the decision to abort will only be based on the write taking too long but I still argue its nicer to have a consistent and well known API for cancellation and there are times where you want to close the connection based on a larger operation so its nice to be able to know statically that the context has been passed through and things will unblock in a reasonable amount of time. In fact, your same criticism applies to most uses of context, most of the time you do only want a timeout on the current operation, whether it be a query, a HTTP request or whatever. But when you want to ensure everything in the call stack below gets unblocked, its becomes annoying and fragile to manually cancel these various operations. context makes it natural and easy.
Could you be more specific about what it you're looking for? You can't have one endpoint be HTTP on an HTTPS port. But there are some possibilities you can play with TLS, depending on your needs. It's not clear what a "certificate request" is.
&gt;No, it's undefined, full stop. It's undefined in the spec. But it's still fair to talk about what a particular implementation does, because that is a concrete thing that can be reasonably discussed. Of course, what that thing is could well change between Go x.y.z and Go x.y.z+1.
Linked to the wrong repo FYI
&gt; Could we say iteration order is "undefined but random with undefined distribution"? And if yes: Is this helpful somehow? If that was guaranteed behavior, sure. I'm guessing the OP didn't try on every system configuration, but my 20+ years of programming in various languages has taught me that an implementation of "undefined behavior" in one platform has absolutely zero bearing on any other platform.
Do we know that? Go binary not always is self contained, depending if it was compiled by go or cgo.
I compiled some articles, examples, and benchmarks on different embedded stores you might find useful: https://github.com/Xeoncross/go-embeddable-stores Tim Shannon (https://github.com/timshannon/bolthold) wrote a good article about his experience porting the codebase to Badger: https://tech.townsourced.com/post/boltdb-vs-badger/
Or between platforms...
&gt; I thought a type alias would be more elegant than embedding a struct. What? Why? This doesn't really make any sense. You've created a new type, not a type alias. But it's not clear you have anything to gain doing either.
Why would you compile code that you're writing if not to test it? Everyone's work environment is different but personally, I don't find "this code has no syntax errors but may or may not work" to be tremendously useful information.
I've used github.com/nlopes/slack in the past and like your example bawt.Listener. Any features beside helpful listener processing that you're improves on?
Well, if I went into detail why the new type was necessary at all, about go-swagger and how it needs an extra method, it wouldn't be the point of this question, which is about getting Set to work.
I forgot that I can dereference the pointer receiver /left hand side of the = sign as well. This does exactly what I wanted... ``` // Set makes a BigInt equal to a given big.Int. func (b *BigInt) Set(i *big.Int) *BigInt { iB := BigInt(*i) *b = iB return b } ```
I suggest reading [https://golang.org/ref/spec#Type\_definitions](https://golang.org/ref/spec#Type_definitions), especially the part about type definititions. You're trying to do a type definition, but that leads to an empty method set: // NewMutex has the same composition as Mutex but its method set is empty. type NewMutex Mutex I don't understand what you are trying to achieve, by creating a \`BigInt\` type, could you elaborate on that?
Part of this trouble may be swimming against the stream in terms of Go language design. Interfaces are intended to be *things a type can do*, not *a thing a type is*. Interfaces are not intended to be used as abstract base classes--they are APIs, essentially. If you look at the standard library, most interfaces literally have one method, and the interface is named after that method. More concretely, if I were designing the RPG from your example, I'd rather write a \`Damager\` interface, a \`HealthHaver\` interface, and a \`InventoryHaver\` interface (actual names TBD). I probably wouldn't create a \`Character\` interface at all. A side benefit of the slim interface design is it much more flexible and allows you to assemble entities through composition rather than inheritance. NPCs with no inventory? No problem, just implement Damager and HasHealth. Breakable treasure boxes? HasHealth and Inventory. Environmental hazards? Just Damager. With just a Character interface (and especially with an inheritance-inspired design) you either have to copy/paste part of the interface for new interfaces, or you have to make those things Characters with do-nothing implementations of some methods. Also look at what that does to your code. Instead of passing in \`from Character\` you pass in \`from InventoryHaver\`. Everything else stays the same but the function "just works" for invulnerable NPCs or anything else that has an inventory but isn't quite a character.
which go
would versions matter? I'm sure I can write it to specify a version 🤔
Which will return if the go executable is in your path. You can then call version on it to determine version. This won't find multiple versions. Use locate or find to be more thorough.
which go: Installed: `/usr/bin/go` Not Installed: `which: no go in (/usr/local/sbin:/usr/local/bin:/usr/bin:/usr/bin/site_perl:/usr /bin/vendor_perl:/usr/bin/core_perl)` &amp;#x200B; It's a command you can use to find installed binaries etc.
I've slightly edited the bit about the slice capacity in my answer to make it more clear, but I highly advise you to digest the information at those two links first.
Just to spell it out: `type A = B` is a “type alias” and `type A B` is a new type. You probably don’t want to use an alias unless you have some old code that expects a certain type that you want to move or rename.
To clarify with markup to prevent this from becoming any more of a hilarious "who's on first" style misunderstanding: &amp;#x200B; \`\`\`
And you don't even need to parse the output, just look at the exit code. 0==it's there.
 *adjective* 1. 1.made, done, happening, or chosen without method or conscious decision. Note that there are different definitions in different domains. You're applying the statistical definition to the non-statistical usage.
Absolutely! I was working on page on the project website that will make this a lot more clear. - The API is intentionally simple as you said, but I also expose the Slack/RTM client if you wanted to do more brazen things. - The plug-in API has support for a web server and web based plugins - There are patterns for communicating between web based plugins and chat plugins - I'm in the process of working through a permissions system based on Slack groups Much of this you can probably do on your own as you said. As a framework I aim to solve three things: 1. Ease of use
I always thought ranging a map did smart things like start where the last range/modify left off so it's a better chance of being in local cpu cache.
https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
I am using Redis on a Docker container with a mounted volume for a similar requirement what you mentioned.
Wow thanks man!
The documentation is very sparse, but isn't this just a reverse proxy?
Sounds like you’re on a project that does database first development (as opposed to object first). There are tools for that: https://github.com/volatiletech/sqlboiler If you have a strong case of NIH and prefer to build it yourself, it would also be pretty easy to write a quick go code generator that looked at INFORMATION_SCHEMA.COLUMNS in your database and stubbed out some structs from that dataset.
Not always true. Use \`command -v go\` Source: [https://stackoverflow.com/questions/592620/how-to-check-if-a-program-exists-from-a-bash-script](https://stackoverflow.com/questions/592620/how-to-check-if-a-program-exists-from-a-bash-script)
This proposal seems _way_ too simplistic to me. When I used `golang.org/x/xerrors`, I've used `As` almost as much as `Is`, because the initial error often doesn't have enough information. To say nothing about the fact that different levels up the stack might look for different error types. I _need_ the whole error chain.
Do you want to go low-level and set up your custom DB engine tailored to the task? Space management + transactions: https://godoc.org/modernc.org/file#File Data structures built on top of the previous: https://godoc.org/modernc.org/db#Storage
Do you want to go low-level and set up your own custom DB engine tailored to the task? Space management + transactions: https://godoc.org/modernc.org/file Data structures built on top of the previous: https://godoc.org/modernc.org/db
&gt;Let me know what you think and if you can recommend any similar libraries that make it easy to create such applications or maybe simple games :) How about github.com/hajimehoshi/ebiten (ebiten.org)? (Disclaimer: I am the author)
Neat! I’ve been looking for something like this. The only thing I missed was an explaination of what RPC is. Looking forward to part 2!
Really interesting packages, it didn't came out when doing generic googling about databases with go. I'll go through its documentation later but at first glance it seems very interesting! Thanks for the suggestion!
Ah, good point. It's always hard figuring what is general knowledge and what isn't. I'll add a short explanation to it soon, thanks for the feedback :)
Yep, the performance was great.
Thanks for responding. I'd be interested to hear more about specific use cases where you need the whole error chain. Can you point to some code where you make significant use of this property?
This sounds exactly like my experience with badger as well. The deletes produce a garbage of versions that don't seem to really be cleaned up without a full compact and restart of the database.
What does each axis represent?
Ledisdb uses a redis api in front of a few swappable storage engines and can be embedded. I'm using it right now for a case where I don't need transactions. And it means it is pretty easy to swap it for an external redis at any time.
If someone has an intermediate case of NIH, they can use [https://github.com/gnormal/gnorm](https://github.com/gnormal/gnorm) which automates reading your database and creating data structures that you can use to fill out templates (using Go's text/templates package). I strongly recommend it. I use Gnorm to autogenerate gRPC proto files, a gRPC server, a matching web-server with table specific handlers, and html templates.
I don't have the code with me at the moment, so I will try to respond tomorrow.
It's a histogram, so, if it helps, imagine it's a bar graph. There are 1000 possible values to draw from the map (0–999), and the X axis represents these values in order. The Y axis is how many times that value was drawn. I created this map 1 million times and used `range` to draw a single value from each one to build this histogram. package main import "fmt" func main() { hist := make(map[int]int) for j := 0; j &lt; 1000000; j++ { m := make(map[int]bool) for i := 999; i &gt;= 0; i-- { m[i] = true } for i := range m { hist[i]++ break } } for k, v := range hist { fmt.Printf("%d %d\n", k, v) } }
[removed]
I started working on a similar project: [https://github.com/256dpi/quasar](https://github.com/256dpi/quasar). It's not yet 100% finished but I'm happy to get some feedback. :-)
Thanks for the detailed explanation makes perfect sense now!
This stack overflow answer has stuck with me that recommends avoiding `which` in scripts for various reasons; of which the one that seemed most significant to me was the warning that some platforms apparently have a `which` command which doesn't set an exit status, which makes it impossible to use reliably in scripts for this purpose: https://stackoverflow.com/a/677212
IIRC the only thing that's randomized is the first bucket that gets picked, everything else is in fixed order. Let's say you iterate a map of four elements and get [1,2,3,4] that means you can also get [2,3,4,1], [3,4,1,2] and [4,1,2,3] but never [1,3,2,4]. The randomness is further reduced when you have collisions, because keys inside the same bucket will always be returned in the same order. I think what you are seeing in those histograms is just the fact that elements added later are more likely to end up in an overflow bucket where they will never be picked first. This is all fine for picking the order of talks, though. Choosing and arbitrary hash function and sorting the names based on its output would have been fine too.
Maybe do something simple like find / -name go to find if go is somewhere in the file system. If it is not in your $PATH variable where it belong.
I'm using go-swagger for an API which is mostly used by programming languages which have integers of unlimited range. go-swagger needs a type to cast these unlimited range integers to in Go, and it can't be `big.Int` because it needs a `Validate(formats strfmt.Registry) error` method. So I define a custom type, which has some functionality from big.Int, and add the required `Validate()` method. At first I used an embedded `big.Int`, but I found that defining a whole new type worked better because casting it to a `big.Int` was easier.
Thanks, the spec succinctly spells out many small details which other sites spend a whole page/several paragraphs on.
Ok, so then you can do something like type BigInt struct { big.Int } func (bigInt *BigInt) Validate(formats strfmt.Registry) error { // ... } This way you can still keep the method set from big.Int, while also satisfying the inteface requiring Validate().
as i wrote i had one going with SQLite which is working and probably will be fine handling the load, but i also do recognize in a scaled solution that it wont work - thats why im asking people with experience as Golang has alot of packages and its not always easy to spot which ones are mature and production stable. I hope it comes across in my post that i already read alot so im asking people with experience in whats mature and whats not mature here.
if its too broad - then what model do you suggest to what i wrote as parameters ? its not a very complicated task for a database so what do you suggest is mature and the proper direction for me to move forward on ? you got any production experience at all you can share ?
Well the thing is I already received that suggestion, so I tried it out for a few months. Embedding `big.Int` has problems. Firstly, you always need to make sure the embedded `Int` is initialized. This means constructors and modifications to `UnmarshalJSON`. Then when you try to use `big.Int` methods, they expect a `big.Int` as an argument, not my custom `BigInt`. So now every code above has to be aware that `BigInt` has a `big.Int` that they need to pass into its methods. Which is ugly. Thankfully I only needed some of the `big.Int` methods, so I changed the role of the `BigInt` class as less of a replacement for `big.Int` and more of a shim, to be casted into `big.Int` as soon as possible.
Can we stop using Twitter to communicate stuff like this? Write a post.
redis is cool but i just find it overkill, i have a service running where i want to keep track of the jobs in queue and the ones finished and the one that is currently processing - i find that abit over the top to run on redis - so thats why im asking for embedded models. the concept isnt that complex, but the thing is that you can have have many writes and reads ( switching from incoming jobs vs worker starting and finishing a job ) so theres a need of being able to write and read fast while being able to have it persistant on disk too. &amp;#x200B; redis is overkill in this case here - i would say boltDB, goqueue etc is more along the lines - but i would like to get someone with experience when things are scaled - currently i got a very basic thing based on SQLite which is just fine in my local tests - i dont know, but i am pretty sure if i launch that on broad scale SQLite wont be close to be able to follow in such a setup.
yes went through them also, and about there where i got in doubt about bolt vs badger
\&gt; It's undefined in the spec. Yes. That's why it makes no sense to say much more. The spec is really all that matters. \&gt; could well change between Go x.y.z and Go x.y.z+1. Or between platforms/OS, or between processors (e.g. if you CPU does not have hardware AES), or between runtime flags (e.g. -race). I can even imagine good reasons why it would be desirable to change it based on the size of the map, or on memory pressure...
I didn't say anything about using it for a specific purpose. My gripe is with the wrong comment in the gist, where it says that the order is "random". It's not random, it's undefined.
&gt;Firstly, you always need to make sure the embedded Int is initialized. [https://golang.org/pkg/math/big/#Int](https://golang.org/pkg/math/big/#Int) says "The zero value for an Int represents the value 0". So what is the problem, am I missing something? &amp;#x200B; &gt;Then when you try to use big.Int (...) Which is ugly. While I agree it's ugly, it would solve your problem. &amp;#x200B; &gt;So I changed the role of the BigInt as (...) more of a shim. This will work in this case as you only need only a (small) specific subset of the functions that come with big.Int In general I think this is an uglier solution. If you need more big.Int functionality later in your BigInt, you have to write more code. In the other solution, you don't have to do anything.
I had the same issue and ended up putting everything into one file for now. You can find my now.json here: https://github.com/elsesiy/qrgo
Thanks for answering I went to see the github link but you're not using an external non-go file Plus, I don't understand how with I only one file, you can have multiple endpoints... Could explain me?
I haven't had much time to look thoroughly through the code (in my car about to drive to the store). I do believe you're going to need to return the nonce though (unless that package appends it in the return and expects it on the incoming data when you decrypt... which I'll have to look into). Other than that it does look correct upon glance. Will have to check later and get back to you.
&gt; You do lose the ability to change config on the fly though What config format supports reloading? Just thinking, if you create an interface that defines loading the config you can use a struct with a muxtex and have it reaload the file on detected changes (or every time.After(time.Minute)). I've used this approach in node as well.
&gt; Side note: Is there a specific name for Google's implementation, just as the "main" implementation of Python is CPython? It's simply called "gc". There is another implementation called gccgo, also maintained by the Go team.
That's why I x-posted on reddit...
Thanks!
How is that relevant to the point that iteration order is undefined?
Haha, my bad. I should've been more clear. You posted a link to Twitter and Twitter doesn't really make sense as a platform for disseminating or presenting technical knowledge/findings. Make a blog post or something. Again, this was a really great finding. I appreciate it.
In Go, "gc" stands for Go Compiler, and garbage collector is capitalized as GC.
I've tried sqlboiler, it is something more than just structs. I prefer to use: https://github.com/achiku/dgw with https://github.com/gocraft/dbr
I used to have a file that contained the html template and changed that to the multiline string in the same file. Do you have a repo I can look at?
Yeah, here it is https://www.github.com/komfy/api
If I'm not mistaken, bolt uses exclusive write locks. Is this server supposed to be single instance and process one request at a time? Managing several threads trying to write with locks seems like a sure way to deadlock issues.
what's the difference between the [https://github.com/goproxyio/goproxy](https://github.com/goproxyio/goproxy)
+1. We are using xerrors to see if there is an error that defines an http response code and user facing error message by using As() to check if any of the errors in the stack satisfies that interface. I also don't think the argument about reflection works given how json, fmt and other very common packages use it. All you need to know if how you can use it, not how to write it yourself.
Yeah I'm trying to learn another language so I don't become so mono but it's hard because of how good it is.
I'm not overly familiar with the AES API in the stdlib but one issue I see is that the input key is not validated for its length. Secretbox is a lot nicer to use overall. Here's a wrapper I wrote for it: https://github.com/awnumar/memguard/blob/master/core/crypto.go#L25-L77
[removed]
[…] no libraries, except the library that you need to write to send the HTTP request 😄
This is an ad plug and has absolutely nothing to do with Go.
What package is gcm here?
I’m on mobile but AES GCM is probably not what you want if you are not tracking nonces. Check out the aead construct of https://godoc.org/golang.org/x/crypto/chacha20poly1305
How many times do you need to advertise this?
yes single process with writes for each incoming clients (adding to queue) and write for each time a job has been taken off a queue.
Absolutely. The config is set to use JSON so you can't really do multi-user in the current context. If you broke it out into the app level more, maybe more DB oriented, you could handle multiple users with multiple concurrent delete requests.
My guess is so that clients cannot accidentally copy the contents of the (lowercase) seed struct. Only (capital) Seed is accessible to clients of package seed; passing a Seed by value will only copy the pointer to the internal seed, rather than copying all of the internal seed's contents.
There are a lot of reasons. I use this trick when I unmarshall multiple json to a same struct. (if you use the omit empty) Only the struct that match the json will have "data" vs empty values
I find it useful when using 'omitempty' field tag. In the case of a pointer, the marshaller can establish if it's en empty value (nil interface). Since empty structs must be empty, that field would never be omitted. As an example, if you look at protobuf generated structs with inner structs, they're all pointers.
Are you plannng some kind of DHT? 1. Run the node+tracker together? 2. Allow multi-tracker communication? (node can talk to multiple trackers) 3. Allow nodes to identify themselves to the network and share peers/trackers?
Next time, consider that if you are certain what the best approach is, but do not know the language well enough to do it, you're probably missing the better answer. But, nobody can help you get there if you're insisting on following your original idea instead of describing the actual problem you're trying to solve.
You raise some very good points. Yes, I'm evaluating the Kademlia DHT which is the current thing I'm working on. 1. Yes, the way I've tested it is by running a tracker+node on one client and few more nodes on other machines. But, of course, the tracker can be standalone in itself. 2. As of now, code is written only for a single tracker. But, there's nothing stopping you if you want to put a bunch of trackers behind a single DNS. 3. This is the challenging part and it's going to be implemented in the DHT integration phase. It's part of the Kademlia protocol. There are some more challenges, of course - like downloading a single file in chunks from multiple peers, but I'd consider that an advanced version, something that would have to wait until the basics are implemented. &amp;#x200B; Do you have any inputs on the implementation and don't mind sharing? DM me if you'd like.
You're right! Go's JSON decoder actually doesn't even error out, it just pops out once it gets a valid object. Firefox's JSON parser for `application/json` does barf and gives up. [A playground link](https://play.golang.org/p/Tpk-ywuUJ-n)
Just another implementation of the [https://golang.org/cmd/go/#hdr-Module\_proxy\_protocol](https://golang.org/cmd/go/#hdr-Module_proxy_protocol)
Easier to use, I guess? But we generally only compare with the [Athens](https://github.com/gomods/athens), not the one you said. :-)
I don’t understand why you‘d use multiple files in the first place considering that these Handlers are very basic. Without using gorilla/mux for more advanced path matching via regex etc you can just use the ServeMux of net/http for different paths handlers. https://cryptic.io/go-http/
think i will try go with boltdb/bbolt - thanks alot guys for the feedback
Nonce is pretended to the ciphertext. It doesn’t need to be kept secret.
Stdlib
Hi. You can use the Hugo framework for building your required web application. Hugo is a static site generator which is built on top of the Go programming language. Check out my video here. Building a stunning and fast website with Hugo and GitHub. No Html, CSS, JS knowledge required. https://youtu.be/5GnFZ8XpMak
@OP, read this to decide: https://crypto.stackexchange.com/questions/42982/safety-of-random-nonce-with-aes-gcm
Cool thanks, gonna check that one out too!
nice but seems a little bit too advanced for me at this point in time :)
Interesting, is it just me or does anyone else find most of those examples to be harder to read after the refactor? I'm totally on board with removing 'else' but I'm not really into the ID types or the one line functions which I think are harder to grep. In particular I found the nested for loop to be preferable to the refactored version. What is everyone else's opinions?
done! if you want to give it a shot here the link: https://github.com/lucasepe/pwsafe/releases/tag/v1.0.1
That's great! I'll check it out
Thanks, I'm going to try making this work without multiple files, can I get to you later if I have troubles ? Btw have you any idea about how to solve my initial problem, which is that I can't use an static file inside my randDict.go file when I'm using Now.
&gt; +1. We are using xerrors to see if there is an error that defines an http response code and user facing error message by using As() to check if any of the errors in the stack satisfies that interface. Would you be able to share a few more details about this? I'm particularly interested in how many significant levels of error you have in the chain and what those layers mean. It's my hypothesis that this kind of arbitrary layer-agnostic error inspection is a sign of potential layer/concern violation, but I'd be very interested to be proved wrong. Thanks for your input.
To check for the nil value.
Ring buffers are really helpful, but setting up interop with io.ReadWriter gives you a few options for handling write overflows and none of them are great: * panic/return an error: standard tools that take an io.Writer stop writing when they hit an error, so that'll probably break things * move the write head past the read head: now you have some bytes missing and other ones that come in out of order * advance the write head and the read head: now you have some bytes missing * wait for reads and block until the entire write is done: now your read end has to notify the write end whenever it moves and the write end yields to the scheduler. In practice, this can be slower than allocating a new buffer. Circular buffers are nice, but you'd better be damn sure that the write end doesn't outpace the read end or you'll have perf/correctness problems.
It's really shitty to delete your post after you get an answer. Please don't do that.
oh sorry, after a while I realized the question was quite stupid so I deleted it. Again apologies for that, won't happen again.
For a brand new library, why not use go mod?
I have never particularly been a fan of methods (although definitely implemented them) that are the plural of another. `collectRow` and `collectRows` are just named too similarly mistakes to happen. The skipping `else` I would probably write it that way but I don't particularly see an issue with that example. I tend to avoid else as it can lead to additional nesting. I, unfortunately, would say most of it makes sense in certain circumstances. For the simple examples they show, I wouldn't bother, if it was something a bit more complex I might implement some of what they talk about. I think that goes for a lot of paradigms. They should be used more as guidelines rather than strict rules.
My code is basically something like var serr FooServiceError if xerrors.As(err, &amp;serr) &amp;&amp; xerrors.Is(err, ErrNotFound) { return nil, nil } Several services returning the same generic `ErrNotFound` wrapped into some service-related context wrapper. Another pattern is something like var verr ValidationError if xerrors.As(err, &amp;verr) { return nil, ErrBadRequest } else if xerrors.Is(err, ErrNotFound) { return nil, nil } Where `ErrNotFound` may be a part of a validation error (e.g. an owning entity not found by ID), or it may be returned as is, and we need to respond differently in these situations. An example that I personally haven't encountered, but which seems likely, is a parser that returns `unexpected character 'X'`, but when parsing a particular token (which is the error's wrapping context), we can return a better error message than a simple “parsing foo: unexpected character 'X'”.
It looks like it doesn't have a single test. How do you know that it works?
You make try https://github.com/itcomusic/winsvc and you must have a .bat file and use a tool sc.exe for creating service and setting params.
You can use this: if ! [ -x "$(command -v go)" ]; then echo 'Go is not installed.' &gt;&amp;2 exit 1 fi
Good point. Other related issues are: * Panics. A panic during the write operation usually leaves an incomplete or broken file on disk; * If the write operation actually overwrites an existing file, then any error will again result in incomplete or broken file with no way of restoring the original one; * File buffering that people tend to forget, resulting in slow writes especially obvious on large files. I have developed a [sample code](https://github.com/maxim2266/xlib/blob/master/file.go?ts=4) that attempts to address the above problems in addition to those from the article by writing to a temporary file first, and only renaming it to the target file if no error has occurred during the write.
I made a thing: https://godoc.org/github.com/carlmjohnson/errors#example-Defer
This problem is already solved by many other providers, and they don't spam on reddit. I'll continue using them for this reason.
I'm aware of that. It's generated in this function and needs to be known for the decryption process. Only one slice of bytes is returned. So I'm going to assume the Seal function at the end includes the nonce with the ciphertext before it's returned?
This isn't even Go-related is it? It's just an API for sending text messages.
You're right. Tested all flows with real connectors (examples folder). Will need to add coverage (PRs are more than welcome)
Crisp article. That needed to be said, and you made a good case for if.
to my knowledge, close isn't safe to run on multiple files. the freebsd man page for `close()` says the following: &gt; In case of any error except EBADF, the supplied file descriptor is deallocated and therefore is no longer valid. So the file descriptor is invalid after closing. The linux man page is a little more explicit: &gt; Retrying the close() after a failure return is the wrong thing to do, since this may cause a reused file descriptor from another thread to be closed. This can occur because the Linux kernel always releases the file descriptor early in the close operation, freeing it for reuse; the steps that may return an error, such as flushing data to the filesystem or device, occur only later in the close operation. I think simply returning the result of `T.Close()` is the best you can and should do.
Thanks for input. Will migrate to go mod.
It would probably be pretty challenging to have it work for many people that since everyone will be using different serealization formats. If you use Bleve with it, for indexing, you can probably make your own solution relatively easily.
Sure. Our webservices will default to a 500 (internal error) if the handlers return an error by default (without knowing about the specifics of the handler). Within the web services, there is a handler layer, which should be the only layer that knows about http, then business layers underneath. Beneath those business layers are repositories that are injected as dependencies into interfaces that the business layer provides. With the repository layer (ideally as a wrapper), there may be code that specifies a specific error that implies handling to the handler layer when things don't go as expected. I'd argue that it's not a layer violation because knowledge of those things is injected and wrapped, not spread between packages in the codebase.
Yup
Gotcha. Thanks...
You're right about the close system call, but that's not what the article is about. It's about `*os.File.Close`, and that *is* safe to call multiple times because it clear its file descriptor after the first time and is subsequently a no-op.
My team is deeply interested in this project. Potentially perfect for what we're working on. We use Sarama for kafka; do you know off the top of your head if this will work with sarama? The new consumer code for sarama isn't channel based, so I'm thinking it might not.
Worse than a panic leaving the file in a broken state on disk is not closing the file while having some recover mechanism that kind of "catches all" (like recovering panics during service call handling), and in that case file descriptors won't be freed up. Typically after a few thousand iterations (actually depends on your max descriptor count allowed for your process) your process won't to be able to do anything useful and fail even in the most atypical places that require FDs. What I do is not only check all Writes but also Close with and without defer. I don't like the advice of calling it multiple times as that is implementation dependent so what I do is something like creating a closure that calls Close and writes (in non-blocking mode) the resulting error to a buffered error channel (capacity=1). Then I defer that in case all fails (in which case the error won't matter) and will call that in the happy case in which case I will just return the err in the channel. You could do differently with just some state variables.
My team is in the same boat, but we wouldn't be opposed to switching to confluent-kafka-go in order to get this functionality. My bigger concern is that I can't use a library that isn't battle tested, unit tested, and written by just one contributor - at least not in production. I'll be keeping an eye on this in the meantime.
I've implemented kafka connector on top of Confluent's client. But it can definitely work with any kafka client available. You'll need to implement Source and Sink interfaces which is pretty simple. Will also look into Sarama client library.
Thanks for input. Coverage will be added in near future. For any concern please open an issue and I'll be happy to help. PRs are welcome in any time.
Thanks! I'll take a look!
We're in the same spot, but we have the flexibility of experimenting with the package and making contributions back if we find any deficiencies.
I can’t tell from this code, so I’ll just say what the most common mistake is. If you see a variable named IV (or Initialization Vector), you need to set it to a cryptographically random value every time you encrypt something. A big mistake is to set this to some constant. If there is no IV, it may be set for you internal to Seal, in which case you’re okay.
Thanks! ISTM that your first example isn't quite testing what you're intending to. It sounds like you're wanting to check that you're getting an error from your FooService that wraps a ErrNotFound error. But the test is more lenient than that. It can also trigger [in other cases too](https://play.golang.org/p/ofcSDTYu7nU). In your case, wouldn't a test like this be more appropriate? ``` if e, ok := errors.E(err).(FooServiceError); ok &amp;&amp; errors.E(e.Err) == ErrNotFound { ``` The second case should be straightforward if you use the same kind of approach I used for os package errors in my proposal. If you make ValidationError implement an HTTPError interface, then you could do: ``` switch errors.E(err).(type) { case ValidationError: return nil, ErrBadRequest case HTTPError: if err.HTTPError() == ErrNotFound { return nil, nil } } ``` That is, any given error can explicitly opt in to some particular domain-specific wrapping scheme, but that doesn't happen by default. Of course, if you _really_ want to, you could still use the same scheme as the current proposal uses too. I haven't seen a good motivating case for it yet though.
Opened an issue to update the docs https://github.com/golang/go/issues/32427
It's hard to say without a few more specifics, but I believe this use case would probably be solved by making the wrapper errors defined by the business layers implement some common interface type that exposes the underlying error as required. You're defining your own error domain here. If you really need `xerrors.Wrapper`, that's just another such interface - it's still available and there's nothing stopping you using it. I don't believe the entire ecosystem needs to buy into that approach though, which is what the current proposal is suggesting.
If you look, `:637968.1.27` is `192.168.1.27` with the first five characters overwritten with `:6379`. I have a sneaking suspicion that what's actually happening is you're getting carriage return characters in the environment variables, or you're printing newline as carriage return on an OS that expects CR/LF. So let's try and eliminate the string concatenation and simplify the problem. Try this and make sure you're really getting what you expect in the environment: package main import ( "encoding/hex" "fmt" "os" ) func show(envvar string, val string) { fmt.Println(envvar) hexstr := hex.EncodeToString([]byte(val)) for i := 0; i &lt; len(hexstr); i += 2 { bite := hexstr[i : i+2] fmt.Printf("%s ", bite) } fmt.Printf("= %d bytes\n", len(val)) fmt.Printf("= \"%s\"\n\n", val) } func init() { fmt.Println("Environment from init:") show("REDIS_HOST", os.Getenv("REDIS_HOST")) show("REDIS_PORT", os.Getenv("REDIS_PORT")) } func main() { fmt.Println("Environment from main:") show("REDIS_HOST", os.Getenv("REDIS_HOST")) show("REDIS_PORT", os.Getenv("REDIS_PORT")) }
right -- i understand this. what i was thinking (which i failed to get across) is that it doesn't make much sense to call `T.Close()` more than once.
Have you tried making your env variables strings? REDIS_HOST="192.168.1.27" REDIS_PORT="4000"
I'm sorry if my lazy wording did set you up. I meant to say: "undefined by the language spec and random with undefined distribution in gc and gcc" While it is true that it is undefined in the language any actual implementation does implement one iteration order.
Oh, I didn't think of the carriage return. I have my editor configured to have LF even though I'm on Windows because I use a linux server for the execution. Seems like you right, some char are added to the values : ``` Environment from init: REDIS_HOST 31 39 32 2e 31 36 38 2e 31 2e 31 30 0d = 13 bytes " "192.168.1.10 REDIS_PORT 36 33 37 39 = 4 bytes = "6379" Environment from main: REDIS_HOST 31 39 32 2e 31 36 38 2e 31 2e 31 30 0d = 13 bytes " "192.168.1.10 REDIS_PORT 36 33 37 39 = 4 bytes = "6379" printenv | grep REDIS REDIS_HOST=192.168.1.10 REDIS_PORT=6379 ``` Thanks for the help, I'm going to follow this path and search why this is happening.
It looks like your REDIS\_HOST definition has a CR/LF line ending which may not be what you want: ~/EnvVarProblem$ cat -vet .env.dist REDIS_HOST="192.168.1.10"^M$ REDIS_PORT=6379
These rules are plain nonsense. No wonder the code is unreadable afterwards. `else` is perfectly fine it has a mathematical, sharp meaning which is consistent with everyday usage. Is "MASER" an abbreviation? If so: "Laser" too? What about "HTTP", "HTML" and "TCP" or "RSA"? Wrapping a bool does help how? And these childish line number metrics.
Yes, I've just noticed that too. For an unknown reason this file was created in CR/LF. Thanks you.
[removed]
The differences are in the tens of ns, so whether that difference will be noticeable will largely depend on algorithms and scale. &amp;#x200B; Generic caveat about premature optimization.
[https://github.com/james-antill/rename-on-close](https://github.com/james-antill/rename-on-close)
That was cute... can’t deny it.
Defer doesn't ignore return values, that is what named returns are for. You can set that in the defer if it errors. Something like this fixed that issue, where there is a named return called err. defer func(){ if err2:=f.Close();err2!=nil{ err = f.Close() } }
I've come up with the following for writing io.Reader streams to files. ``` func WriteToFile(filename string, reader io.Reader, perm os.FileMode) (err error) { var f *os.File f, err = os.OpenFile(filename, os.O_RDWR|os.O_CREATE|os.O_EXCL, perm) if err != nil { return } // Handle resource panic as well defer func() { if p := recover(); p != nil { os.Remove(f.Name()) panic(p) } if err != nil { os.Remove(f.Name()) } }() _, err = io.Copy(f, reader) if err != nil { return } err = f.Sync() // Close the file regardless if e := f.Close(); e == nil { err = e } return } ```
thankyou so much ! it made me jump around abit and i saw a similar solution using kardianos - also using the sc.exe approach and just tested it and this actually works ! &amp;#x200B; [https://npm.pkg.github.com/giansalex/go-winservice](https://npm.pkg.github.com/giansalex/go-winservice) &amp;#x200B; Do like your code though it seems cleaner so will try it out :)
not quite sure where i can remove them i cant see they are actively added in their example
Thanks for responding and considering my case. &gt; But the test is more lenient than that. That is not a bug, it's a feature, which I require. In your code, I don't care if `FooServiceError` is wrapped yet again with `OtherNotFoundError`. In several places in my code it _is_ wrapped yet again by a call to `fmt.Errorf` with the infamous `%w` verb. &gt; `if e, ok := errors.E(err).(FooServiceError); ok &amp;&amp; errors.E(e.Err) == ErrNotFound` That's just `Unwrap` with extra steps. Your very own code shows that error chains exist and need to be considered. To say nothing about the fact that `xerrors` version is much more readable. &gt; That is, any given error can explicitly opt in to some particular domain-specific wrapping scheme, but that doesn't happen by default. That obviously depends on the architecture, but both my intuition and my experience tell me that 80% of all cases will eventually boil down to wrapping. If that's the case, I would rather have a unified wrapping interface. Just look at [upspin](https://commandcenter.blogspot.com/2017/12/error-handling-in-upspin.html).
I don't write go a ton these days, but when I did, I would do something like defer func() { if err := something.Close(); err != nil { HandleError(err) } }()
[removed]
I'm a bit surprised that works, actually... The example shadows `err`, then takes its address and not the named return. Without executing, I would expect this code to never assign the value of `Close` to the return value. I almost think it works only because the compiler is choosing to reuse the memory for another `err error`...
Lol “God Bro”.
You know when you get stuck with one name and is to late on the game to change it... Thats me lol
Having a guarantee that the file is cleaned up on exit from the function regardless of error is a very good thing, though. It's a little annoying to repeat yourself once but it's much better than repeating yourself every time you return, and this way you can't have a bug sneak in later when the function is changed by someone who doesn't notice that they need to do it.
What do people think about something like: func withCreate(filepath string, f func(w io.Writer) error) error { file, err := os.Create(filepath) if err != nil { return err } if err := f(file); err != nil { if cerr := file.Close(); cerr != nil { return cerr } return err } return file.Close() }
Ah, yes, you'll want your env file to have quotes around the values to guard against that sort of thing happening.
This is in the article.
In context of your medium post title. The biggest reason you see people use byte slice over string, is not because it’s more performant in operations, but rather to avoid creating extra load on the garbage collector.
This isn't my medium post, just an article I found. &gt; is not because it’s more performant in operations, but rather to avoid creating extra load on the garbage collector. Are these kinds of preferred GC optimizations documented somewhere?
2 months later and this project has almost 15k stars. That bastard is getting away with it. Thanks for this information, I was a user of the framework until now.