&gt; I'm sure the answer is, keep going, and at some point you'll have enough knowledge that problems get easier and easier, and you'll start to feel confident in your ability. Yes that is the answer, with a few caveats. Read on for details. &gt; There's likely no path towards making this happen any faster than putting in the work of breaking apart different concepts until you've internalized enough of them. Think of software development a sort of computational Lego. First you build the thing in the box with the instructions, then you do it without the instructions, and at one point you toss the box, you mix all your Lego sets inside a big basket and you build whatever the hell you feel like. :D The thing is, the learning will take time, and practicing will take more time. You have a ton of things to learn (structured programming, OOP, functional programming, algorithms, complexity, concurrent/distributed systems, development methodologies, etc...) and the amount of things you'll have to learn grows everyday. You'll never run out of topics to learn about as a software developer so focus on what's really important at the beginning stage: understanding, self sufficiency and figuring out what your optimal learning strategy is. Because of the shortage of developers in the job market, there are some people promoting these 12 week boot camps and similar crap, which ultimately are just a disservice to the poor souls who enroll them. These are not useful to people who are trying to join the industry from zero knowledge, because they'll fail to pass on very essential knowledge due to the shortage of time. But the most egregious of all flaws of these boot camp style teaching environments, is that they pass on the idea that programming is easy, that everyone can do it, and therefore you are going to be self sufficient within a few days of starting to learn how to code. First, software dev./eng. is hard and takes years to master, on average. Sure there are some truly gifted people in the field. But these are very rare, just like truly gifted people in all areas. The fact that the average computer person is, in general, smarter than the average person is also not helping here because it skews the perception of competence a bit, especially for beginners. Another thing is that some people will just be miserable if they have to stare at a monitor with code for 8hr/day * 45 years. I'm not gonna tell you or anyone what to do, but if the day ever comes that I want to stop writing code, you can't pay me enough to to keep me doing it. Finally, on average, it usually takes 6-24 months of *supervised* professional programming practice for new programmers to get to the "I just need to ask a couple of questions here and there" stage, plus a few more years to get to the "oh, I just realized I can build ANY software" stage. You seem to be struggling more with understanding other people's code at this stage, but that's where your more senior co-workers can (and must) provide input. The way you phrased your question kind of hints that you are not being given enough good mentoring by your peers. Other than that, everything looks normal to me.
Tell me about it! As an old enterprise dog, you have my sympathies re UI dev. üòâ
But other services can also scale up and down, right? And other services integrate with other storage products and services? I believe AWS also have scaling and storage, so what sets App Engine apart from that, for instance?
If you don‚Äôt need to implement new methods for the types, type aliases might work 
(Google Cloud Solutions Architect here) App Engine *generally* has faster startup and shutdown times and is constantly adding new support for more languages. There is also a bottom line (cost) benefit to using App Engine when looking at different systems from the competition. There's also a significantly lower barrier of entry when using App Engine when compared to some other services -- a very basic deploy needs an incredibly small YAML file along side your app, and a single command line action to deploy it. I definitely encourage you to sign up for a free account -- we'll automagically toss you 300 dollars in credits for you to play around with, :)
Very good ! Thank you
&gt; `which -a go` This helped me track down the problem. Even though it was complaining about /usr/lib for GOROOT, the go binary was install was actually in /usr/bin/. Weird. Anyways, it's all working now. Thanks!
I wrote this in the port ```go type Users adapter.Users ``` and a wild error appeared `cannot use adapter.GetUsers (type func() ([]adapter.Users) as type func() (Users)` I think type casting must be made explicitly, i.e somewhere in the code `adapter.User(User)`
agreed, shared ASTs are the way of the \_future\_.
I'd say learn the math first before learning libraries like [Gorgonia](https://gorgonia.org/gorgonia). 
Out of my experience it‚Äôs good to describe model and train it with Python (TensorFlow, Caffe, or Keras) and layer serve API for the trained model with Go. Both languages play well together. 
Problem is, one can only use trained models in Go.
Though all those new features sound awesome, this doesn't really answer my question. I'm a regular App Engine user, I'm specifically interest in the socket restrictions. Can you touch on what has changed regarding sockets? &amp;#x200B;
is there a pmml library for golang?
Don‚Äôt do it. [Don't communicate by sharing memory, share memory by communicating.](https://go-proverbs.github.io)
No. I‚Äôm not referring to QT‚Äôs license. I‚Äôm referring to that specific repo you posted. Go read the license file. The owner is (was) in my opinion, a money grubbing d bag. 
Basically you can use net and net/http libs like normal. No need for URLFetch.
We still enforce the same external ACLs as before except sockets behave more like native sockets on a VM. Raw sockets are not allowed but any arbitrary TCP/UDP based protocol should work.
Is this an app version of the web playground, or are you actually compiling and running the code inside the iPhone ?
Sockets should behave like native sockets in a VM. We still enforce the same ACLs but any arbitrary TCP/UDP based protocol should work.
I planned to include this in my "Go says Wat" talk at GopherCon this year (https://www.youtube.com/watch?v=zPd0Cxzsslk), but it was cut for time. It might return when I write the blog post.
Do WebSockets now work on app engine?
Thanks a lot this is useful for hobbyist like me who learn on their phone 
FWFW, I once used plain Go to train a [single perceptron](https://appliedgo.net/perceptron/). Granted, this did not produce the sort of trained model you are thinking of, but still... :-)
Glad to hear you were able to resolve it! 
Any plans on exposing memcache to the second generation deployments? It seems like almost every other "gen 1" service has adequate alternatives (search is also left in the dark too) 
Hey, am I missing something? Qt seems to recommend projects built on it use LGPL, which is what therecipe/Qt is under, and that doesn't seem money grabbing, and the one I linked to (and is my repo) is under MIT. My understanding is that MIT is "use it as is for whatever", if I've got that wrong I'm happy to change the license, as my intention was not to be money grabbing but the opposite, therecipe/Qt seems to just meet qts license recommendation... Am I wrong? 
You're not wrong, Walter, you're just an asshole.
Google wants to collect all my information. Why is integration with even more Google services an advantage?
As someone who's just getting into Go and literally discovered gvisor two days ago; awesome!
Interesting project. I am a bit confused by the readme. &gt; MeQ is written in pure go and standard library, nearly no messy dependencies. &gt; so you can easily deploy a standalone binary in linux„ÄÅunix„ÄÅmacos„ÄÅwindows. I have started to read the code and noticed that there are plenty of dependencies. Once you will compile the project to a single binary it does not matter how many dependencies you have. Maybe this sentence is not needed? meq $ find vendor -mindepth 2 -maxdepth 2 -type d | sort vendor/github.com/apple vendor/github.com/bwmarrin vendor/github.com/golang vendor/github.com/gorilla vendor/github.com/labstack vendor/github.com/mattn vendor/github.com/spf13 vendor/github.com/sunface vendor/github.com/valyala vendor/github.com/weaveworks vendor/go.uber.org/atomic vendor/go.uber.org/multierr vendor/go.uber.org/zap vendor/golang.org/x vendor/gopkg.in/yaml.v2 
So you're sending requests there and receiving answers, without compiling anything yourself. Is that right?
Yes. Unless I'm not mistaken, compiling / evaluating go source code on mobile is not possible yet. 
Im playing around with App engine first generation Go 1.9 Environment for a while now. Still couldnt figure out what "does not allow native code" means :) what do you mean with "native code"?
Thanks, I'll give it a shot!
Thanks for this- really useful idea for an app. 
Actually it worked like a charm. Thanks a lot, you're a life saver
ow, apologies, somehow I missed that! &amp;#x200B; of course in that case that's how I would've done it
I tried vscode out for like half a day and then somehow never switched back. I'm definitely not fully used to the keyboard shortcuts yet but I'm getting there (long time sublime text user) I tend to have very long uptimes with it but it does eventually crawl a bit.
Oh... Google Cloud Build seems not to be available for none-payed project. I pray that merciful Google will improve this situation and I will go to bed today.
Hello, This is great news. Im trying to migrate my flexible environment apps now, &amp;#x200B; Hit a few snags, the profiler no longer seems to work as it cannot resolve the instance/hostname. Im using the Google Cloud client libraries and it works fine on flexible. Am I missing something
&gt; particular, when your app does not receive any request, the number of instances goes down to 0, which mean you only pay when it is used. &gt; &gt; Another benefit is that App Engine is part of Google Cloud, which provide you many other products and services to build your application (Cloud Storage, ML...) What's the advantage of Flex Environment compared to AppEngine Standard Go 1.11 (second gen. runtime)? Is it going to get deprecated?
big whooosh if true
there is also a list of packages inside the standard library, maybe some other packages will be surprising as well: https://golang.org/pkg/
[removed]
Brad Fitzpatrick had some good advice on 5his (in Coders at Work I think?). Start by making a trivial change. Perhaps purely cosmetic,then making sure you can build, test and run the code after. Then build up from there.
Go isn't statically linked by default, and Qt is not dynamically linked in the binary created by the recipe... I've checked it 
Just started reading. Pure gold! XD
I have seen that page probably a thousand times. Somehow, didn't notice the package. Came across this while I was looking at another CL which added an "internal/fmtsort" package. So inside the src folder, I typed "in" and tabbed, and it immediately didn't go to internal. I was like huh .. there is something other than internal ? Wait .. there is index ? What is inside index ? A suffixarray package ?! I was so pleasantly surprised that I had to share. :D
Now answer me this, if you can‚Äôt dynamically link your go code to the repo library (since go makes it difficult to impossible to dynamically link), is it really released under the LGPL? And if the repo author admits (via github comments) that‚Äôs intentional and offers a commercial license for money, does that change your mind?
Now answer me this, if you can‚Äôt dynamically link your go code to the repo library (since go makes it difficult to impossible to dynamically link), is it really released under the LGPL? And if the repo author admits (via github comments) that‚Äôs intentional and offers a commercial license for money, does that change your mind?
Huh? Go *is* statically linked by default. 
I am pleasantly surprised by the breadth of the standard library almost daily. It's pretty great.
What I think you‚Äôll find: you can‚Äôt easily or feasibly dynamically link under current go tooling. I haven‚Äôt investigated it in about a year as my use of go has gone down as my proficiency in rust climbs. 
&gt; because why not Perhaps not applicable here, but that phrase reminds me of the aphorism: "Just because you *can* do a thing doesn't mean you *should* do a thing." 
Oops missed that. Thanks. 
This is amazing. I just started a project yesterday that needs this functionality, so this will save me a lot of time.
In the second and final part of the series, you learn how to convert good Go code into bad code, using the Fall and Outboy frameworks. I appreciate all of the reads and comments. Again, please let me know what you think!
Copy + pasting 
It's like a burrito
That's a known issue, a fix is prepared but I'm not sure we've cut the release yet. Does updating to the latest version of the profiler package work?
I guess I came across as a hail corporate shill ü§ë
Why would anyone publicly release their commercial integration? Besides something like stripe integration is rather easy to do anyway.
I updated the deps and it did do something. The deployment now fails with error3 Updating service \[default\]...failed. ERROR: (gcloud.app.deploy) Error Response: \[3\] The following errors occurred while copying files to App Engine: So im not sure what exactly that means, the rest of the details are not too helpful. So dont know if the new profiler works or not.
Am using deo in prod. Works well
Could someone please tl;dr what happened in a comment. 
Why do you even need dep or godep if you can use go mod (go1.11). More info here: [https://github.com/golang/go/wiki/Modules](https://github.com/golang/go/wiki/Modules)
Cool stuff! I like how the files are separated to be checked into versioncontrol. Are file/directory names encrypted too? That would be really good. Without that you could infere Info from the store without having the password. Good Job on the readme. Love it to see projects actually give you Info on the readme 
It ran into the halting problem. They got into a situation that they feel is recursive. The program didn't terminate (because both opponents recognized that passing was the optimal move).
Can you send me the details and verbose logs at [sbuss@google.com](mailto:sbuss@google.com)? I confirmed the 0.30.0 release of [cloud.google.com/go](https://cloud.google.com/go) contains the fix.
Our old security sanbox didn't allow using things like "unsafe", which contains platform-specific implementation details; you could only run pure go. This limitation has been removed with Go 1.11.
I doubt there is an example out there as what you're after is usually pretty specific. You can find examples of the individual components e.g. billing and auth but you'll need to integrate them based on your needs. 
[removed]
I think a lot of us here already know about that book, and your post didn't really add any valuable information. I think people would upvote you a bit more if you had written a more in-depth review. Anyway, I might buy it. I'm looking for a good book about building Go REST APIs. I already know the basics, but I want to know everything there is.
already using go mod.
Not looking for specifically a twitter clone, but rather just an example of any paywalled SaaS app. I'd like to learn best practices from something that is already built.
If you are stating a new project, or switching dependency managers, or if in doubt, use go modules.
Author of the book here. The focus is on building a 'traditional' web application, rather than a RESTful API, although there's naturally quite a lot of overlap between the two things. So it's probably not exactly what you're looking for. For example, it doesn't cover dealing with JSON request/response bodies, but it does cover things like managing configuration, application organization and working with SQL which do overlap. The topics are covered step-by-step in quite nitty-gritty detail.
&gt; but the function I'm interested in using is a standard library function (http.NewServeMux().HandleFunc) and I won't be able to supply it with the channel. Sure you can. serveMux.HandleFunc("/path", func(w http.ResponseWriter, r *http.Request) { doSomethingWith(w, r, t) }) 
Easy cheaty way, make the channel a global var. Possible alternative, make a struct that contains a channel, and have extRead be a method of that struct, something like [https://play.golang.org/p/Te1yjQtGrO3](https://play.golang.org/p/Te1yjQtGrO3) maybe?
I don't think this is possible the way it is written. Try defining extread in the same scope that defined t instead of at the package level, and it will probably work.
Maybe the pages about Dep project (readme, roadmap, blog and doc) should be updated ?
In case you missed it, Sam Boyer, the lead author of Dep, is engaged in an emotional crusade against Go modules. Don't expect an endorsement there.
Ok, great example. I'm still trying to expand my mind when it comes to things like this. So taking your input into account I can accomplish what I need. [Example](https://play.golang.org/p/g3BZTy_Szy_M) Do you see anything blatantly wrong with this?
Your goroutine that feeds time into the channel is going to spin very fast and burn cpu when a receiver is not pulling a value. This is because you are using a select with a default case. Also there is no reason to wrap the main listen logic in an anonymous function. 
Something like https://play.golang.org/p/BZC3oQBDH-k ?
You should look at examples of golang REST APIs that interact with a database. From there it'll be straightforward to use an SDK for payment and then you can return an error if a user tries to access a pay walled endpoint. 
Great catch, I could add a 100 millisecond sleep to slow it down. As far as the anonymous function, I was half-ass mimicking my other environment, you make a great point here too.
That's great, URLFetch has been a pain in the neck.
Can anyone think of a more elaborate pun? I like a good pun as much as the rest of you, but this dude takes it to another level.
I think the biggest problem I have here is that its difficult to wrap my head around variables defined prior to an anonymous function are accessible to that anonymous function.
One day when Go for DEC's Alpha architecture is available, you can run AlphaGo written on Go for Alpha
Also using dep, also happy with it. Has at least one feature that modules doesn't have that we commonly use in our development flow, so I'm in no rush to switch to modules. Not sure why you got downvoted.
&gt; When you ask your question, display the fact that you have done these things first; this will help establish that you're not being a lazy sponge and wasting people's time. http://www.catb.org/esr/faqs/smart-questions.html
Thanks for the info. I'll probably give it a try in a month or so. Just bought "The Go Programming Language" book and it will take a while to go through it. Are you still adding chapters to your book, or are you mainly correcting errors and keeping the existing content up-to-date?
really? What do you compare it against? Because if you compare it to pythons stdlib go can't even remotely compete. Heck, it didn't even have a rounding function for quite a while
index/suffixarray was added to support godoc. It has niche use cases and may be removed in Go2. It is also not a fast implementation.
It doesn't. It's being worked on for Go 1.12. See https://golang.org/issue/9671.
Nice app! I like that it includes a truckload of sample code. Minor nitpick: I see that the app uses the term "Golang" in some places. I really don't care if someone calls Go "Golang" in a forum, chat group, or tweet, but an app (as well as blog articles, books, videos, talks etc) should always use the correct name of the language, Go. Especially when the app/book/etc is focused towards newcomers.
How much space does this require? Is it N^2/2?
Package? Install the Google Cloud SDK: https://cloud.google.com/sdk/install There's an installer. It should probably work on Arch. You can also run the SDK from a Docker container: https://github.com/GoogleCloudPlatform/cloud-sdk-docker
Hey, not all of us were aware that this book existed. Now I do, and I‚Äôll purchase a copy in the morning. Thanks!
https://github.com/jgallagher/gosaca is a faster suffix array implementation. https://i.imgur.com/tlrXmRD.png
Ye, sorry, didn't mean that everyone knew about it of course. And I'm not trying to say that it was bad to post it in this subreddit, I was just trying to provide feedback since he was getting downvoted.
Huh, interesting graph. It seems to indicate that qsufsort is O(n), when it should be O(n log(n)). Reference: [http://www.larsson.dogma.net/ssrev-tr.pdf](http://www.larsson.dogma.net/ssrev-tr.pdf) &amp;#x200B; The \`gosaca\` definitely seems linear as I would expect since it uses the SAIS algorithm under the hood, which is O(n). Reference: r/https://sites.google.com/site/yuta256/sais &amp;#x200B;
I woulda named the types readBuf/writeBuf instead of rbuffer/wbuffer but to each his own.
&gt;Go Playground lets you interactively edit &amp; run Go snippets on your mobile device. It‚Äôs ideal as a companion for learning the Go programming language, for code reviews and for collaboration with teammates. Thanks for the pointing that out. I just noticed that the app store screenshot was using the term "Golang". I'll get it fixed the next release.
I might help, but do you know what you want that echo doesn't offer yet ? Definitely give echo a try, it's good, simple software that doesn't try to do everything. And definitely get in touch when you need to improve it and if I can help, but it's possible I would have the same problem as the current maintainer (I'm already falling behind on my own open source projects' feature requests and find it tough to find time sometimes)
I beleive it's $GOPATH/src/mod, defaulting to $HOME/go/src/mod
Need to use ruby to test go comes from sharing the same database between two apps, which is from my opinion is a horrible idea. Don't do that. 
Ill try my best to explain, sometime easier with a more working example. Pear is an interface, and describes an interface, you dont actually "create" interface objects, the only describe a "contract". Apple on the other hand is (from what I can tell) is a struct or value of some kind, and you have associated/attached the allTheFruit function to it. Therefore, Apple complies with the Pear contract, and therefore can be passed into functions that accept Pear "contracts". &amp;#x200B; I have tried to alter your example, and added a few comments to hopefully help. [https://play.golang.org/p/CO5D-s\_fo6q](https://play.golang.org/p/CO5D-s_fo6q) &amp;#x200B; Cheers &amp;#x200B; &amp;#x200B; &amp;#x200B;
Qshufsort is O(n log n) the same way quicksort is O(n^2). Expected/average performance is O(n) for qshufsort and O(n log n) for quicksort.
Arch Linux users normally only install applications from packages, either official or unofficial ones. If there is no package, users usually create an unofficial package, upload it to the unofficial package repository so that everyone can use it, and then install it. All applications over a certain popularity limit has an official or unofficial package in Arch Linux. Installing applications directly, without packaging them, clutters up the filesystem.
It‚Äôs probably pretty confusing that you named your interface ‚ÄúPear‚Äù. Let‚Äôs pretend that you named the interface ‚ÄúFruit‚Äù instead. Then rename your allTheFruit() method Peel(). Now, you have an Apple that can call Peel(). Maybe next you make a Banana struct that also contains a function called Peel(). Cool. Now, you want to give your object to a Gorilla(food Fruit) function. The Gorilla can call Peel() and both a Banana and an Apple will be perfectly fine to give to the Gorilla(). Cool! Now, let‚Äôs say you make a Skin struct and give it a Sunburn() and a Peel() method. Uh-oh! Now you can pass skin to a Gorilla() method. Ew! That‚Äôs wrong. Change your Fruit Interface to have an Eat() function and add it to both Apple and Banana. Now, you can call Gorilla() and pass it a Banana and an Apple and that‚Äôs fine - Peel() and Eat(), but passing Skin() makes for a compile error. Double cool! One last thing - pointers. See that `func (a Apple) Peel()` part? Well, if you call Peel() on Apple, that function cannot permanently change Apple. Apple is effectively read only. If Peel() needs to change Apple (day by setting a peeled variable to true) then you have to use a pointer like so: `func (a *Apple) Peel()`. Hope this helps (my best 5 year old explanation on mobile - forgive syntax please!)
/u/chewxy wrote a go library called gorgonia that's sorta like tensorflow in order to try implementing alphago in go. In the process, he had some very interesting insights about the applicability of the alphago algorithm to artificial general intelligence. 
I thought it is. If you are interested in neural networks, AI and all that jazz, the first 18 minutes of the 36 minute video explains quite a bit of it. It references Go, the programming language in a few slides. And surprisingly, there were fewer references to Go the game than in the latter half of the video
[https://github.com/chewxy](https://github.com/chewxy) the speaker is a prominent gopher making golang libs for dealing with neural nets etc.
Nicely explained, I really liked your examples. To add on for the OP: Go will always pass by value, as in a copy, and not by reference (a pointer). Go‚Äôs primary focus is concurrency, so passing copies or manipulating memory with channels is always preferred.
Great presentation btw... Congrats.
What feature?
I wouldn't suggest writing code like this but here is an example of go behavior. https://play.golang.org/p/IA09xBX7dYF Here is more info https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
Forget the anonymous function level of things, and let's talk about HandleFunc for a moment. HandleFunc is actually just syntactic sugar for [mux.Handle](https://golang.org/pkg/net/http/#ServeMux.Handle). Now, the `Handle()` method accepts the path and a `Handler`, which is an interface. The interface implementer just needs a `ServeHTTP(ResponseWriter, *Request)` function. What does that mean? It means that you need to define a struct like this to get your work done: type someHandler struct { myChannel chan int } func (s *someHandler) ServeHTTP(rw http.ResponseWriter, r *http.Request) { someVar := &lt;- s.myChannel // do something with someVar }
I wouldn't even bother with the method value - just make the struct implement the net/http.Handler interface and use [ServeMux.Handle](https://golang.org/pkg/net/http/#ServeMux.Handle) instead of HandleFunc.
I've been looking through that project and I'm wondering where you handle routing.
You are right, this is an old time sentence which need to be updated. I will resolve later, or you can commit a pull request
That's an option too if you want one path to a struct. :)
I don‚Äôt understand many of today‚Äôs MS design. Is MS supposed to be separation of responsibility and maintainability? If so the whole nginx + web + web cache should be one service and the database should be another. Complex site would have gateway server and load balancer and complex data would have dedicated cache service and that‚Äôs where the original front/back design could lead to. Or if the login service is used by multiple services it can be separated. Otherwise hell no since it segregate the team and developers.
Can you compare and contrast it to Jon Calhoun's book /u/joncalhoun? https://www.usegolang.com This has been out a while and covers web application development in Go also, from scratch. As someone who has read his book would there be any value in me purchasing your book? Will I learn anything new? I love learning others ways and possibly new ideas, so I'm genuinely curious. 
Could someone explain to me why would you ever not use pointer receivers? They prevent a copy and they allow the variable to be modified... It just seems better overall.
Mutability by default isn't always desired. What if you want to ensure that your receiver isn't able to be modified?
Feels really fast. Just curious, what did you use in your stack?
I think of struct as a being with its own behavior, while interface is like a piece of clothing -- interface X doesn't care what you are, as long as you have 2 arms and a head you can wear it. And if you wear that interface, you can go and interact with these other beings. But that's a shitty anology because interface cares about what you can do and not what you have
When you really do want immutability. 
I always found myself forgetting about how -L works and also wanted the ssh client to pick a free local port to listen to on my behalf.
I‚Äôm hiring :)
What would you be able to tell us about hiring Go developers as an employer? :)
I all seriousness. Don‚Äôt pick a job based on a language choice, learn to be a good software developer and be flexible. Pick the right tool for the job and learn how to use it well. 
Honestly, I‚Äôm don‚Äôt see a lot of entry-level jobs working with golang. I think it‚Äôs about important to learn multiple languages early on, and I think golang is a good compliment to the other languages you mention. However, you probably shouldn‚Äôt focus on it to the exclusion of other languages. 
Close, but that doesn‚Äôt work since container file systems are ephemeral. I need to specifically mount a persistent volume to the cache directory so the downloaded modules persist across container invocations.
Ah, this seems to work. Will test more when I get a chance (camping)
In general unless you're a junior developer or the position is highly specialized, the language you work in shouldn't matter. For junior developers, companies don't want to hire someone who has to learn fundamentals of working in a team at scale while also learning a new language. For specialization, sometimes companies are looking for people who know specific aspects of a language because they're dealing with a problem that needs a very optimized solution. Unless you're one of those 2 then you shouldn't worry about language specifics.
I wouldn't even consider myself close to the level of a junior developer yet, I'm still learning.
Another option is to have a local caching proxy, such as [athens](https://github.com/gomods/athens). Then you just point GOPROXY there and it will download modules through the caching proxy.
I have drilled this a few times and added the func Eat and Peel with a receiver of Banana. That really is helping solidify my understanding ! Very good explanation. Thank you so much!
Great example even with my terrible fruit structs and funcs. Its starting to make more sense now. Thank you so much!
I actually got a little confused by the example. Some others had posted some code that was a little easier for me to digest. This example threw me off with all the nested structs. But the resources look great! I'll book mark these! Thanks!
First time reading this, [https://gph.is/2oRAEqy](https://gph.is/2oRAEqy). second time reading this, [https://gph.is/2oRAEqy](https://gph.is/2oRAEqy). It makes sense when I can keep track of the types and values of the interface but man that was hard to read lol!
Well, here on Brazil java and php are still kings. Only really big players are using Go here (major tv channel or topfreegames). I setup a google alert on Brazil jobs with Go keyword and rarely get any e-mail.
Golang in industrial world is still starting and not many opportunities available. If you learn Go to land a job, you have the wrong target.
I know I'm late to this thread, but what is the warm up time for a scale up to 1? Are we talking milliseconds or seconds or minutes to spin up an instance? Because honestly, spinning down to 0 is very neat and I didn't know the engine runtime even supported that.
&gt; They prevent a copy and they allow the variable to be modified... It just seems better overall. Preventing a copy is not _always_ better. A PUSH/POP operation on the stack is much faster than GC operations. So if the struct is small, prefer to use value receivers. It will reduce the amount of garbage generated. Run your code through escape analysis to find out what escapes and what doesn't. Here is the complete answer - https://github.com/golang/go/wiki/CodeReviewComments#receiver-type
From my observations, it:s usually a matter of a few seconds.
I've heard good things about liquibase https://www.liquibase.org/ Haven't used it myself though
Thank you. LMK where to improve
Maybe it will be helpful https://www.reddit.com/r/golang/comments/9nt203/when_we_should_use_a_method_receiver_instead_of_a/
We're using https://github.com/golang-migrate/migrate for DB migrations. there's a few advises how to prepare migration sources https://github.com/golang-migrate/migrate/blob/master/MIGRATIONS.md
In the database I've a table `version` with date and number. Each time I run my app, at start it run one function for each number after current. Something like `function v5(tx \*sqlx.Tx) { tx.Exec("alter table ...") }` Then it's easy to upgrade the schema or adjust anything else.
I've enjoyed [Go: The Complete Developer's Guide](https://www.udemy.com/go-the-complete-developers-guide/).
A **Struct** is a physical piece of (contiguous) memory that holds data. Each struct type is like a unique bookcase in an Ikea catalog. The bookcase "specification" tells you how many cubby holes it will have, and how big each cubby is. One cubby in the bookcase can only hold a paperback (int), another part might only hold a textbook (float). When you order a specific type of bookcase, it's always the same size, and comes pre-filled with a book named "zero" in each cubby (the "zero value" for each type). You can replace the book (data) in any cubby, as long as you have a book that is the right size for that cubby. Ordering different bookcase types (struct types) can get you different sizes of bookcases with a different cubby-hole pattern. You can also also attach functions on your struct (or any data type). So instead of saying \`Process(mystruct)\`, you can call \`mystruct.Process()\`. An **Interface** doesn't take up a specific amount of space. It is actually a "type" that filters (restricts) the kinds of objects that can fit into a cubby (or a variable). So if you say "this var (or cubby in a struct) must contain an object that can be \`Peel()\`ed", then it will be an error if you try to put something in that cubby that doesn't have a \`.Peel()\` function. &amp;#x200B;
But it is
hmm, yeah, that's pretty full-featured. I like their points about database diffs. but... writing changesets in xml... takes me back to 2001 ;)
I've been writing go since before 1.0 and I think pointer receivers have been the better default for most of that time, and I still think it should be until you have a good reason to use a value receiver. Failures can return nil, interface implementation on function call is not dependent on the variable type, etc. Just a lot less confusion. Value receivers are a false sense of security because you can still get copies of references like maps and slices and cause side effect.
check out goose, its a simple dB migration tool written in go so you can use it both as a binary or integrated into other code 
A common pattern is to: * put migrations in sql files with unique names * have a metadata table in your db to record migrations run * write a script (say make migrate) to run any outstanding migrations and record them in the db (this can be v simple) I definitely would not work with db dumps or diffs thereof. Migrations often need to change data, not just schemas. I also wouldn't bother with explicit rollbacks. That way you always know which migrations are run, can check changes into version control, can run them out of order, and can rerun easily when testing. Here is an example https://github.com/fragmenta/fragmenta/blob/master/migrate.go
Having tried a few systems I think just simple sql files are best. They are simple, portable, explicit and don't introduce more dependencies. If you're worried about validity test on the dev db before running on live. 
Also make sure you run integration tests and make sure the migration is part of these tests.
Fantastic explanation! With your permission I will use it to explain interfaces in Go to some java guys üòä 
` select { case s &lt;- i: case &lt;-time.After(1 * time): } `
When you stop learning you don't become senior. You are already out. You should never stop learning.
I noticed github.com/gorgonia/agogo is pretty empty. Do you have an estimate when you'll be able/willing to share the code?
thanks, that's interesting.
I am confused. Do you mean programming language (such as Go, Rust etc.) or natural language (English, French etc.)?
first programming languages then natural languages
nobody said anything bad about dep though?
except that if your struct contains a pointer to something else, that pointer will be copied and the other thing can be mutated. So... type Thing struct { OtherThing *string } func(theThing Thing) changeTheThing() { *theThing.OtherThing = "this changes everything" } func main() { immutableThing := "this can't change" myThing := Thing{ OtherThing: &amp;immutableThing, } myThing.changeTheThing() log.Println("the thing changed!", *myThing.OtherThing) } pointers are fun :) 
So... let's talk about Elephants: An Elephant is a struct. It occupies space, you can poke it with a stick, it has a trunk and four legs and big flappy ears. That description of an Elephant is an interface... it defines things that anything "Elephant-like" must have. If you try and refer to a mouse (a different struct) using the "Elephant-like" interface (description) the compiler will refuse to let you, and tell you that a mouse is not Elephant-like because it doesn't have a trunk. If you glued a trunk onto a mouse, then (because computers are stupid) it will suddenly be accepted as Elephant-like by the compiler, because it satisfies the description (it occupies space, you can poke it with a stick, it has a trunk, and big flappy ears). Go's interface is referred to as "duck typing" because as far as the compiler is concerned, if it looks like a duck and quacks like a duck, then it's a duck. Same with our mouse. If it satisfies the Elephant-like interface (description), then your code can treat it as Elephant-like. 
Indeed, I agree, but to resolve ambiguity I put golang, because go for many people is not clear enough
And no one cares. He decided to call it golang and everyone understood.
http://golang.cafe/blog/my-5-favourite-online-resources-to-learn-golang-from-scratch.html
started using it in latest project, don't have many migrations yet but I love its simplicity compared to other tools that have yml files or code to describe schema. and because it's also just usable as a go package we can run our tests against a clean slate database every time which is super handy because mocking your entire database layer is a pita. 
Oh my gosh, that makes my day! If you‚Äôve used Java or C#, Go‚Äôs interfaces are a breath of fresh air. Compile time type safety without all the fuss and code pollution. Have fun. Tell all your Java friends.
hi raplang9998
[removed]
Depends how you see it. I don't see much difference between Java and golang in this example, except that before adding `Eat()` go would allow skin to be given. Java here is better IMO. 
Xml sure is a pain but the full changelog makes it super easy to time travel (for instance revert some changes) not to mention that you can recreate the schema at your local machine in matter of minutes with just xmls and csvs. Also tracking where that 1 change comes from and who broke what is really fast :) 
fixed. Turns out I forgot to push the commit
I think that approach would be too fragile and convoluted. Clean, comprehensible migrations based on a schema version are definitely the way to go, IMHO. One advantage of that is that you can (and should) wrap the migrations from one version to the next into transactions and thus progress cleanly through a series of well-defined schema versions. It also facilitates logging the progress in a fashion you can later make sense of.
I use liquibase for all my projects (using SQL files instead of XML). It is SO nice not having to learn new migration tools for every language.
It's not about breadth, it's about quality and picking the right things to put in.
If you use CQRS/ES, you avoid the mess that db migrations are. Sorry for the short answer but I just wanted to point out an out of the box thinking approach.
oh that is good to hear. I will give it a try :) Thanks for the good news.
oh that is good to hear. I will give it a try :) Thanks for the good news
As of now very bad. No one wants to use Go, despite knowing its benefits. I spent 2 years getting expertise on it. But no use. 
Sure, I agree - this particular example doesn't really highlight the places where externally defined interfaces are amazing. It's not until you add an interface to someone else's library, or use interfaces just for your tests to easily handle mocks, or realize that you are finally free of throwing NotImplementedExceptions() on shell methods for poorly defined interfaces that you see the true benefits of Go's way of doing interfaces.
go + go code = static binary, by default go + cgo code = dynamically linked. your go code + therecipe/qt go code + therecipe/qt cgo code + Qt5 = static (your go code + therecipe/qt go code) + dynamic (therecipe/qt cgo code + Qt5) I hope, this is enough. you don't have to buy Qt5 license, because Qt5 is dynamically linked. but, you have to buy a license for therecipe/qt which is statically linked. though, it is possible to create a dynamically linked binary for therecipe/qt with extra tooling according to the author of therecipe/qt. 
&gt; most people will take the time to implement a sorting function themselves That's not in the instructions. I wouldn't trust the input from someone who, when faced with the problem of sorting an array, does anything other than to call a built in function. In fact thinking back when I helped evaluate candidates for hiring we actually rejected people who rolled their own solutions when a standard library function call would have been enough. 
It's really simple but we just keep our ALTERs and what not in SQL files and run them sequentially at release. We've been doing it this way for years and it hasn't burned us yet.
But it's OK if u open source ur code that uses therecipe, as I understand? 
Please remind us of the results or the presentation you are going to do ! :-) 
Truth. Best thing to be is be someone who can jump into new stuff and learn quick. Be flexible, take knowledge between languages and between disciplines, etc.
I use goose for mine.
What kind of array? Strings, ints or something else?
r/https://github.com/averagesecurityguy/scrape \- It's a paste site scraper that uses boltdb on the backend.
Many good explanations here already. Just chiming in with one of the things that helped me understand interfaces: Types define what things are and what they can do. Interfaces describe \_where things can be used.\_ So in the above example, the whole point of the Fruit interface is to say that there's this place where we want to be able to use anything that can be peeled. In the example, this is saying let's think about what's really important when handing a fruit to a gorilla: it's Peelable, or a Peeler (this may be a better name for the interface). In the real world I use interfaces \_all the time\_ to make my code testable. Instead of hard requiring the exact functions and types I make sure to require interfaces. This way I can mock out anything in my code with test functions and pass them in through my test files (see dependency injection.)
Seconded. As mentioned, use the fork by pressly
This depends on the execution flow of your program. If you pass vars through many routines and need the immutability, you probably don't want pointer receivers. If you're writing a network/web app and have a request-&gt;response flow where vars are created and destroyed in the process you'd probably want a pointer receiver. Exceptions and other examples abound. It's important to think about this on a case by case basis.
Thank you for that input, I specified in the question that you should write the method yourself
doesn't matter
I will :-) 
Nowadays, I would argue that "the right tool for the job" is a weighted combination of factors including the language that is best suited to the job for whatever reason, as well as the language that gives you the most enjoyment or that you know best. If you're an expert in a language that isn't perfectly suited otherwise you'll probably be better off than if you're a total novice in a language that is :) 
All the comments that mention dep positively are being downvoted (or were, when I posted the first comment)
Glad I could help!
We use this approach in production for last 10 years, and it works just fine. Our migrations are done from the server code ... during server startup it simply checks if all migrations were done already, and does the missing ones. Price we pay is that server is down until migration finishes, but typically they don't take longer than couple of seconds, sometimes minutes.
ye, we use pressly fork too 
Oh my god, where are your parents?
You don‚Äôt need a sleep or a select. The channel is unbuffered so your write will block. Just write to it.
The article missed the opportunity to mention that you can append to a nil slice. var a []string a = append(a, "x") 
I don't do anything in Go, but this is not really a Go-specific problem. What I do, is have a stored procedure in my database that returns a version number. Then I have an app that gets a lot of update scripts built in to it as embedded files; when I run it against a database, it calls that stored procedure. Then, every update file is just named with the version that it updates (NOT what it updates TO, but what it updates FROM). So, for example, if the version is '1_0_33', then it looks in its embedded scripts for 1_0_33.sql, if it finds it, it runs it. If there are any errors, it reports them and stops, otherwise, it runs the stored procedure again. And maybe this time the version is '1_0_34'... or in the case of early versions, it may upgrade from 1_0_1 to 1_0_20, etc. And it repeats, until it does not find a sql file for that version number. As for creating those files, every time I make a database change, I save the change script to a folder. Then I have another program that takes two version numbers as parameters, and just goes and packages up all those scripts from the folder into a folder named for the version I specify, appends everything in that folder to a single file and tacks on an update to the version stored procedure at the end to the second version number specified, and adds it to the build setup so it gets included in the next build of my database updater. I do have to do a bit of manual munging to those update scripts - adding tests for existence, for example, or fixing up the positions of 'GO' statements, but on the whole, it has worked well for going on fifteen years now. 
other's projects: * One of the most popular Go projects used widely would be \[CoreOS Etcd\]([https://github.com/etcd-io/etcd](https://github.com/etcd-io/etcd)), it has seen major evolution from v2 to v3 on codebase front. * Then there is a simple small project \[hey\]([https://github.com/rakyll/hey](https://github.com/rakyll/hey)), an http load generator with good cli interface. &amp;#x200B; shameless self plug: * Wrote \[Ogi\]([https://github.com/gojekfarm/ogi](https://github.com/gojekfarm/ogi)) which utilizes Golang plug-ins to create any combination of workflows using modular consumer, transformer and producer; like a flexible framework to create re-usable ETL flows. It uses \[bouk/monkey\](r/https://github.com/bouk/monkey) for real mocked unit tests, instead of piling everything with interfaces even if it doesn't need it yet. * \[Dory\]([https://github.com/abhishekkr/dory](https://github.com/abhishekkr/dory)) is a secret sharing service with memory and disk based datastores allowing only user to be able to have access to their data. It's missing unit tests as of now.
Nice write. It would help your reader if just above/below your sample code examples you provide a link to those code samples on sites like [https://play.golang.org](https://play.golang.org/p/HmnNoBf0p1z) This would help them quickly open it up and make changes around to learn more.
If you‚Äôre not motivated to learn how to do something right then you‚Äôll just end up being bad at your job. 
So i assume you want to compile go source Code? I'd take a Look at the package that go Provides for parsing source Code. Then go from there to compile to assembly of one specific machine. Then you only need to figure out how to link stuff with the go runtime and how to write that into an elf file and youre done! 
I use goose and am not thrilled with it. My biggest gripe is that it only starts checking for timestamps after the last one it ran, and this can be a problem if somebody in another branch created a migration before you but merged it after. Running all "pending" migrations is a feature I'm used to from Rails, Phoenix, and other migration systems I've used. The goose version I use has also been abandoned. Have they fixed this issue in any of the popular forks? Maybe I'll switch if the API is otherwise compatible.
Is the on-disk format different from the streaming one? 
We use https://github.com/jackc/tern at work. It's very simple, works as either a binary or integrated into your server, just SQL in a series of numbered files, very simple config to get DB info, and tern will run only what files need to be run to ensure your DB is up to date. 
Oh, I'm curious about how you performed polygons only with DrawImage function.
Render a triangle image with DrawImage? That's interesting, thanks.
https://remark42.com - self-hosted disqus
Yes this is better if more than one person is merging code. 
A general-purpose reliable UDP library might have a tough time to be sufficiently better than modern TCP. There are a few things that can be done (mostly forward error correction), but the margin is narrow. Specific-purpose (reliable) UDP, now that's a different story. QUIC et al can start a session quicker than TLS over TCP.
I would go on a limb and say it's unlikely they differ. I'll check.
We're using the same with a custom CLI tool to run the migrations. The simplicity is great.
what does the custom CLI tool do? I'm curious about how to generate migrations...
It feels like I'm the only one here that doesn't like the tour of Go. To me it felt like they introduced things in the wrong order, didn't give enough details, and on top of that, the website looks like it was built in 2005. I'll probably get downvoted, but I'm a bit confused to why everyone recommends it. Maybe I'm the only one that dislikes it.
I'm an idiot, though, I can't be trusted to munge a migration script by hand (because I'm trying to get away from munging a set of psql commands over an ssh connection by hand). How do I check that I haven't made a horrible mistake?
'cept when you're dealing with reference types like maps, apparently.
Do you mean errors/breakages during migrations? We (usually) catch those in testing, before they go to production. Code is not written to handle that... if migration fails, server doesn't start.
I'm not familiar with either of those acronyms... what are you referring to? 
yeah, how do you verify that a migration won't break? How do you write tests for that?
Why would using CQRS or event sourcing mean you don't need schema migrations?
You would have them at mapping a version of an event to the next bastion of the event. 
This is awesome. The ability to develop games in Go and deliver via web assembly is so slick. The frame rate on my iPhone 8 is about 60fps. How does this compare feature wise to 8bit virtual machines like PICO-8? Making an open source virtual console would be awesome.
That‚Äôs a fab explanation! Props! üíé
That‚Äôs a fab explanation! Props! üíé
I like github.com/BurntSushi/migration - I never see it mentioned and it's deliciously simple. Migrations automatically run when you open a connection. If that model doesn't work for you, the code is super simple and you could just use it as a base for your own lib
Essential Go - https://www.programming-books.io/essential/go/
It's recursive only if you encode the data in certain ways. The program... well, it's a program that's being written with each iteration, so you never really know if the program is recursive. 
Command Query Responsibility Segregation and Event Sourcing. The latter was first written about by Martin Fowler in Dec 2005. The idea was refined into a set of applicable approaches by Greg Young in the following few years. I introduced Paxos (see Leslie Lamport's work) as a way to get consensus on the command side in 2008. In recent years it's been adopted by many as a standard way to write Information Systems.
We don't write tests for migrations. We test them by deploying server to test environment and verifying there. Schema of our test database mirrors production DB, so this works fine.
It also didn't point out that a the \`len\` function on a nil slice returns zero, so one can check for \`nil or empty\` with len(s) == 0.
A pointer is still a value that can be copied 
The term in the literature for what notary does is [Trusted Timestamping](https://en.wikipedia.org/wiki/Trusted_timestamping), which is pretty confusing when used in combination with roughtime :) It's essentially a client-implementation of the roughtime protocol in Go, together with a tiny tool to abuse it to get timestamped proofs of ownership for a file.
Why do you need something like Wire for unit tests? Normally you don't need a large dependency graph for unit tests, so it definitely looks like an overkill.
If you are solely using SQL based relational databases (Maria/Oracle/Postgres, etc.) and fairly standard queries using database/sql, you could get by with just writing different functions to make the connection for each database and pass back a \*sql.DB and then just write the interaction via database/SQL once. Incorporating both NoSQL systems like MongoDB and SQL databases and trying to use them from a common code base would be considerably more difficult; but perhaps an ORM implementation would make that possible.
Yeah, maybe it wouldn't be that bad to write up the initialization code for every controller that takes 2-3 arguments. I mean in the sense of maintaining this code - i can just auto-generate the interfaces, then generate the DI based on `wire` and `mockgen` seems very painless. When you have maybe 10 controllers, stores and models and have some other external dependencies it adds up having to type the whole thing out for all of them. I definitely feel like it is easier just adding a constructor argument and adding a constructor to the Set needing it. Regardless i agree that the real benefit of wire lies in initializing the entire dependency graph which gets pretty big naturally, and it is annoying having to figure out the order of initialization. 
No I haven't actually, mind giving me a quick brief overview? Otherwise I'll look into it tomorrow when I clock in at work, thanks so much!
Alright I'll be sure to look into it then, thanks for the suggestion, I don't seem to be very clear with what ORM is but I feel like I'm getting on a path where I can start researching and figuring this out thank you!
[removed]
[removed]
[removed]
Where can I find flappy gopher sample code?
[removed]
Oh, interesting, I was not aware of the cloudflare package either. Which, in retrospect, was kinda‚Ä¶ dumb =D My reasons to not use the Google one where a) go-get (fixable), b) didn't know (unfixable) and c) fun (working as intended). :) Implementing protocols and file formats somehow tickles my brain the right way :)
Congratulations on the new release! Ebiten is a brilliant 2D game engine for Go.
What has that got to do with DB schemas? Event sourcing doesn't mean schemaless DB
Why would you think that what I'm trying to do is an awful workaround? 
So you're resisting to avoid doing what Ruby on Rail's Active Record has done? Why if I may ask? Because this seems exactly what I was asked to develop, but with valid points I may argue against the feature. 
You aren't sucking anything up (IDs are just inserted wherever) nor are you processing things at the database (FKs just enforce insert/update/delete rules for data integrity - your ORM still needs to write stuff across all the tables). It's all about how you model your data models. If you think in terms of Cats, Dogs, Aminal, Cars, Fords, MINI - then you are creating a source of truth, not a database for websites. Nothing wrong with that DB, just don't write a website on top of it if you ever want it to scale. If you can change your data models thoughts to be like: Dashboard, UserProfile, Messages, Homepage and alike ppages, and store only the data you need to render those pages, you'll significantly scale better. However, this is not how most people think of databases. It's the "Q" part of CQRS (as posted elsewhere below). And judging by the downvotes to their and mine answers, it's obvious people don't give a rats ass about scale and just want a DB to represent their data model as they are locked in the RDMS world of thinking. Break out of the box... Design and build for scale... 
How does this compare with https://GitHub.com/spf13/viper? Does it provide most of the same functionality and create a smaller binary?
Here you are [https://github.com/hajimehoshi/ebiten/tree/master/examples/flappy](https://github.com/hajimehoshi/ebiten/tree/master/examples/flappy)
Thank you for trying it on iPhone. I'm happy that Ebiten keeps 60FPS on mobile browsers :-) &amp;#x200B; PICO-8 is to develop old-school style games with an easy interpreter language. For example, PICO-8 has limited resolution screen. On the other hand, I aim to make Ebiten to develop general 2D games, so I try to add necessary and sufficient features to develop 2D games (Actually Ebiten **was** for old-school games, but I have changed the policy). Next big feature might be shaders, but I'm really careful since this would degrade portability. &amp;#x200B; BTW, there is a project that name is like PICO-8 on Ebiten: [https://github.com/telecoda/pico-go](https://github.com/telecoda/pico-go) 
We use [https://github.com/golang-migrate/migrate](https://github.com/golang-migrate/migrate) and have a cmd/migrate tool for running migrations. &amp;#x200B; [https://github.com/Pigmice2733/peregrine-backend](https://github.com/Pigmice2733/peregrine-backend)
Thanks!
https://github.com/netlify/gotrue
It's all handled in the fmt package: https://golang.org/src/fmt/format.go 
Agree. This is a nightmare requirement, because different databases are designed to do different jobs, and you'll have to cope with them all. SQL databases are big on schema, and to query them you need to know the exact schema. No-SQL databases ignore schema almost entirely, and to query them you only need to know the criteria. An API that supports both is going to have to deal with schema in a MongoDB environment (and that's just the start of your problems, with just querying... there's a lot more difficulty in there). Why is the client requiring this? If it's just a hand-wavy "ooo but our customers might want to use MongoDB" or a "we don't know what database our customers will use, can't we just support them all?" then it will be a *LOT* easier to do more market research and remove the requirement than solve the massive technical problems involved.
I meant database version, not schema version. I was working at a place a couple of years ago that had a great database for schema changes, could do them on the fly, etc. Then we had to upgrade from MariaDB v4 to v5 (iirc) and there was no way of doing that without taking the database down. It doesn't happen often, I know, but there will always be a reason to take the database down sometime.
And there's a giant type switch: https://golang.org/src/fmt/print.go?r#L637 
&gt; It lacks a lot of compile time checks and compile time logic. Its lack of destruction logic leads to a lot of boilerplate and runtime errors. Its interfaces aren‚Äôt very expressive. It has first-class-citizen data structures (slices and maps) that can‚Äôt be replicated as a library using the language itself. It forces mutability upon the user in many situations where mutability isn‚Äôt needed. It comes with a pseudo dependency manager that lacks independent versioning for separate projects. It‚Äôs very slow compared to most other popular system programming language, namely C, C++, Ada, Fortran and Rust. He throws a lot of this out there like it‚Äôs self evident. I‚Äôbe honestly got no idea what he means. I agree about dependency management, and I see what he means about maps, but he fails to explain why that matters. The rest is just lobbing stuff out there and I wish he got into actual detail.
&gt; Opinions? Well, I think the title of this post is taken out of context. Outside of the first couple paragraphs, the author seems to like Go. Even mentions it's a "desert island" language.
the title had me worried that binary-only packages will become a thing but thankfully this is about dropping support for them
Anything by Greg Young - especially on YouTube.
It means you don't need to worry about schema migrations like you do with a canonical model. Multiple simple models means you have an easier job or you simply recreate from source events to the new schema. There's a book on the subject: https://leanpub.com/esversioning
Ah, software versions. Yeah, there's no getting around that on a single node. You need replication to avoid it. In our master-master-slaves-x10 replicas setup, when we wanted to upgrade we'd just one of the masters offline
I know this is going to get a lot more downvotes.. but there's a method to this madness of knowing DDD, CQRS, ES, etc... Within GoLang, you pick the best of the bunch and implement minimal approaches. That's why I've gone all in with Go - I can skip all the hardcore plumbing that was needed for DDD, CQRS, ES, etc and just focus on the bare minimals of these concepts and get sh\*t done. With strong software modeling (I like to refer to DDD, for my Domain objects), you enforce integrity with business rules. Add a Post to a Blog? The Blog must be valid first, which means it needs a GUID - which is issued from &lt;DB|DS|Counter|etc&gt;. In DDD, these are called Bounded Contexts. While Eric Evan's DDD book is quite the bedtime read, I highly recommend this very short 90 page large font summary of DDD which can be zipped through in a day or two: [http://www.carfield.com.hk/document/software+design/dddquickly.pdf](http://www.carfield.com.hk/document/software+design/dddquickly.pdf) You can skip to "Preserving Model Integrity." Coming from .NET Enterprise development for 14 years, when I jumped ship to GoLang I threw most of these DDD, CQRS, ES concepts out the window - as it was all overburdening. However, there are basic concepts that can translate to GoLang quite well, like the event sourcing model. With Event Sourcing, your "Domain" is treated like a write-only domain - you don't read from it nor do you represent any data with the objects. You simply write to the bus the Event (after strong validation). Then you have 100s of subscribers listening to that one event - and they all update their data store, whatever it is (json tables for APIs, html partial tables for web, html page tables for mobile, etc). The point is that ensuring data integrity within your Domain model enforces all of your business rules where it belongs: in code, versioned and diff-able as well as testable. Then you don't need no stinking database and FKs. &amp;#x200B;
Thank you for your reply! I am definetely looking up onion/hexagonal architecture.
You've basically hit it right on the nail with your two quotes there, thanks for the response I'll be sure to speak up about this and see how it flies tomorrow.
My opinion is that people should stop comparing programming languages and use right tool for the job, sweet jesus, every subreddit of any programming language is half comparing this to that, benchmark this to that. 
Haha, I am wondering if Go is actually environmentally friendly now! Compared to Java/C#, it certainly is a small nifty hybrid, whereas JVM/.NET Runtime are container ships.. 
viper is a nice full featured project, mconfig is not pretending to cover all the features. Mainly mconfig is easy (only one function exposed via facade) and an opinionated solution to solve the typical antipattern of many files for each environment (config.dev.json, config.ci.json, config.prod.json) a keep your small/mid projects in a twelve-factor way. No getters, and with a default setup. One code call + config file + env = filled struct.
Yeah, I was hired in a C# shop after doing Java/Go for a while(we also use Go where I currently am, though). Prove you have solid software engineering capabilities; learning the language is just a small detail, assuming the domain won't differ too much. The hard part of being a software engineer isn't syntax or details to a given language and eco-system. It's the non-tech stuff: Requirements, communication with non-tech stakeholders, and breaking down requirements into technical specifications.
confirmed.
Opinion : usual troll about the language. If go was that bad, it wouldn't be used. If it is used, it's because its design choice fulfill a need, a niche among programmers. There are moments when using go is better than using C++. Or python. Or javascript. Or java. Or rust. Or... Oh, and despite being old, Ada is not a bad language. I learned programming with Ada, I love it. It fits a very different niche than go, and for that niche (life critical embedded software that must be proven true), I'd use Ada without thinking twice.
Binary distribution still can be done through plugins probably
yeah. 
well there are some interesting things in Go that makes it stands out : * Go's approach to concurrency * Go's approach to Objects * Channel * Go's single loop ('while' is merge with 'for') * Go's approach to package * Go's approach to dependency * ... It might not be really new, but it's different than the classic C-based languages, and it create a very unique way to architecture the code. It shifts our thinking On this regard, it is a good choice for the subject I'm talking about.
I saw the type switch, but where it converts to string for printing?
Line number?
I disagree with the notion that event sourcing or CQRS means schemaless. I think people unnecessarily mix up the two. CQRS or event sourcing can work equally well with both RDBMS or document oriented DBs. There is nothing about ES and/or CQRS that dictates one must use document oriented DB.
Could not have said better!
The rise of "devops" has had an unintended side effect of reducing proficiency in shell and CLI based tools. It's not just a Java problem. 
I never said it's schema-less. It has, however, a huge impact on migrations. I wrote about it first in 2008 where meta events are used to pin-point a schema change for a read model - regardless of what type of storage you used.
Thanks. This feels like premature optimisation at this point - we've not even released the MVP yet, and the code is still a monolith. But this gives me a really good direction to aim for as it all matures. I can start incorporating the event stream stuff into the audit log now, and then future services can also subscribe to it if that makes more sense than building them into the monolith (I can already think of one that this will be useful for). Good stuff, thanks again :)
If you're event sourcing, you are doing CQRS as well. For example, querying an event store directly to satisfy what a read model would give you if you made one via CQRS is just a temporary read model that's thrown away immediately. People like to separate CQRS from ES and vice versa because of the solutions they saw for either side did not fit what they wanted. But fundamentally the concepts don't go away.
This looks really useful, and might be a good step to move to the version control copy being authoritative, and DNS deployed from that. I've used tools like [dnscontrol](https://github.com/StackExchange/dnscontrol) to deploy before, using [convertzone](https://stackexchange.github.io/dnscontrol/migrating) to migrate from BIND-style files to their own DSL. `dnscontrol push` can then be part of the CI's deployment phase.
Go is, from a practical perspective, a very good language, even compared to new languages.
Exactly this!
Similar background. Almost 30 years of c/c++/object pascal, python, html/js. go is my "go to" language. Love it for the reasons you gave. 
For my last devils job most of my time was working with the command line. Maybe it‚Äôs application programmers who see devops as a means for abstracting everything to some sort of gui? 
I said shell - as in bash scripting - not just CLI tools. Scripting tools like Puppet / Chef have fallen out of favor for higher level frameworks like Kubernetes. I miss my old sysadmin teams tbh 
It also doesn't mention that deriving from a nil slice is valid and the result is still a nil slice. ``` var a []string b := a[:] println(b == nil) // true ```
I see DevOps exactly as the term implies Developers that handle Operations and since we can code instead of writing a bunch of shell scripts and use tools like Ansible/Puppet/Chef for automation, we solve Ops problems by writing code that solves our business specific needs.
Not sure if it was just an accident, but `ls -al` would be enough. `-all` isn't an option on it's own, it's applying the `-a` and `-l` options (I normally throw an `h` in for good measure, `ls -lah`).
Highly opinionated text to follow: Google published a nice little book about Site Reliability Engineering. In it you'll see a common theme of developers who maintain systems being separate from developers that write systems. This was more/less the structure that built the dot-com boom throughout the 90's and mid-2000s. In startup and corporate IT land, the DevOps model is a horribly ill-conceived sales pitch that 1 developer can do both jobs, and that engineering teams can function with onesey twosey DevOps hires while fully supporting a production environment 24x7. It doesn't work for every team for the same reason you wouldn't write every application on top of Lambda. Speaking of which, Amazon in particular has championed this model giving rise to it's legitimacy. Having worked there as a developer I think it was used more as a political tool to punish team members who had no business logging into prod than it was healthy engineering practice. Unfortunately, like Scrum, DevOps enjoys wide support through zealous recruiters and middle managers. A rapidly diminishing market for program managers, project managers, and QA engineers exacerbates the problem making the role attractive for non-developers. my .03 
Looks like it's implemented in `format.go`. For example, here's `fmtInteger`: https://github.com/golang/go/blob/ff99a61e5e892dedb88f9f80bce9cc102d2f50b2/src/fmt/format.go#L194
a non-developer can't do DevOps
Here's my response to that bit you've quoted. &gt; It lacks a lot of compile time checks and compile time logic. Compared to languages with generics perhaps, but it's safer than many other languages too - and definitely more accessible than truly low-level languages like C, C++, and Rust (and even some higher level languages like Scala). &gt; Its lack of destruction logic leads to a lot of boilerplate and runtime errors. Literally never had problems with this. &gt; It has first-class-citizen data structures (slices and maps) that can‚Äôt be replicated as a library using the language itself. Yeah, like you said /u/mattmc3, is this a problem? I mean, the solution to it would potentially be nice (i.e. generics), but this hasn't stopped me being a productive Go developer, in fact, understanding how these things work has helped me write far more efficient code. &gt; It forces mutability upon the user in many situations where mutability isn‚Äôt needed. Immutability is nice, but it also transforms the way you'd have to write code. Dynamic languages like JavaScript can work well with immutability, as can languages with far more advanced type systems like Haskell and Scala - but for my use-cases, Go is fantastic. The barrier to entry is low (i.e. unlike Haskell and Scala), the performance is great, and it's simple and easy to build and deploy (unlike JavaScript). &gt; It comes with a pseudo dependency manager that lacks independent versioning for separate projects. I think this must be referring to `go get` as it is/was before Go Modules. This is a fair criticism, but that's also why it's changing now. Go Modules are looking like a great solution, and I'm looking forward to when it has widespread adoption. &gt; It‚Äôs very slow compared to most other popular system programming language, namely C, C++, Ada, Fortran and Rust. Alright, but it _is_ fast, and certainly fast enough for what it's intended to be used for (i.e. tooling, and services). I wouldn't try to build something like an operating system in it, but you can definitely build very high performance applications with Go. On top of that, the tooling that Go has makes it easier to get the most out of the language. It's trivial to test and compare things like how fast a certain operation is or how much memory something uses with benchmarks and pprof.
I'm not sure what neck of the woods you work in, but I have met many who are little more than AWS console clickers. I like your thinkin', though. Upvoted! 
\&gt; it‚Äôs quite hard to understand its tremendous success. &amp;#x200B; Programmers are all very different, and work on a huge space of very different problems, as such it is very common for them to disagree on seemingly fundamental ideas. &amp;#x200B; Go has a unique (or nearly so) set of features that some programmers are just dying for, and so Go is very appealing. Other programmers have no need/want for these things at all, and so Go seems silly. Those features, in my opinion are the following: &amp;#x200B; * A garbage collected language where a type can be a reference or value at will, with simple syntax. (Compare to Java, no choice, or C#, where types must be struct or class ahead of time) * a garbage collector that minimizes pause times instead of maximizes throughput * native stand alone exes rather than requiring a runtime ala C#/Java * very fast compile times * Simple syntax, quick to learn, easy to understand other's code &amp;#x200B; For some programmers a few of those things are very important, and so Go is extremely attractive, even if you wish it had generics or better safety features or better performance. &amp;#x200B; But a large set of programmers would have not the slightest interest in any of those features, and so Go would seem a rather mysterious language to choose. &amp;#x200B; There are other benefits of Go like very easy to use multi threading tools when you are doing simple to medium complex things. It covers a lot of use cases with no drama and pain which is nice. &amp;#x200B; I've been amused at myself because I've taken quite an interest in both Go and Rust, despite them being so different. I like both for their opposite attributes. I like Rust because I can do quite clever things with the various meta-programming features, things that would be extremely painful to do in Go. But I like go because there isn't any meta programing, and I understand the whole language while rust is still a mysterious fairy land to me. &amp;#x200B; &amp;#x200B; &amp;#x200B;
I assume packets in the same pcap are time sorted, why would you think otherwise?
Use [GORM](https://github.com/jinzhu/gorm/) it has [AutoMigrate](https://github.com/jinzhu/gorm/blob/0fd395ab37aefd2d50854f0556a4311dccc6f45a/main.go#L583:14)
Nice that you noticed, I usually use an alias `l`, although at the last second when I was recording I thought better to use a full command, hence the extra `l`. ```bash $ which l l: aliased to ls -lah ```
Yeah the tight coupling was an understandable compromise to keep it simple. I had a big eureka moment when I slightly refactored Snippetbox to the structure outlined in the talks I linked, it felt like everything slotted together idiomatically and I've used it as a blueprint in my own systems since. The improvements you are making sound great, can those who have already bought the book download the v2 when its released? I'll be really interested to see how the additions work out.
Not sure we follow? 
I have professional experience with c, c++, pascal, erlang, ruby, JavaScript, Java, objective c and go... and I have a very similar opinion. I think the author of the article still miss the point of Go. 
Because you're trying to force it to work, and having trouble with it? I think your central problem is trying to write your business logic with gorm-annotated types. That means you just taught the core of your onion about something that is on the outermost level -&gt; that ain't "hexagonal architecture". The fix is to not do that.
remember to filter if err =! nil
In microservices environments that are working together on common networks, TLS is my first choice. See here for basic examples. https://grpc.io/docs/guides/auth Next up would be to use JWT. An alternative to TLS behind the firewall is to employ IPSec over ipv6 addresses, and encrypt at the packet level. Both IPSec and TLS require care to get right. If you have a network engineer around, I‚Äôd also push for isolating your services and public networks with vxlans. Failing all that, a humble LDAP server can make quick work of this problem and allow you to slice up the api into roles by checking for group membership of the client. Lots of options there. Exposing gRPC to the public internet probably isn‚Äôt the best method if you need that. Go with graphQL or REST in that case which give you standard authentication schemes over SSL. 
&gt; objective c Oh yeah, I have some of that too. :-)
&gt; Immutability is nice, but it also transforms the way you'd have to write code If immutability is what you're after, don't mutate anything! üòÉ In that case, mutability is a bug like any other... Would it be nice? Sure, I guess. Is it a big deal? No -- not compared to community standards and code reviews that enforce immutability.
Wholeheartedly agree.
Sorry I haven't played with it: Does it use a standard file format ‚Äìor a format that only this tool knows how to work with?
Just about every solution works at scale and Buffalo is not a bad option, but to provide a good response we will need a bit more of an idea of the general workload. Do you have an idea of what your scale will be? Type of workload and volume? Are you just wanting a fleet of webservers backed by databases for persistence or are you looking at full blown microservice environment?
That's hilarious.. love the sound effects.
I'm looking at lot of real time stuff. Realtime communication, notification and collaboration. I'm gonna be using websockets a lot. Webrtc is also in mind. I'm gonna be using both in-memory and traditional databases.
I want the exact opposite of that. There are domain types, and gorm_adapter types. They are exactly the same, but gorm types has gorm tags. What I wanted to do is to figure how to call functions from gormadapter (that return values of gorm annotated type) from the domain - domain-&gt;dataport-&gt;gormadapter - without importing the types directly from gormadapter.
looks like it exports into BIND zone format, which should work with basically anything
Thanks. Wasn‚Äôt clear from the readme. 
If you look at highest performance possible Buffalo might not be perfect as it focuses more on development speed than on execution speed much like rails. If you look at max performance only Iris might be right for you even tough the author is a douche. 
This is great! It might be worth noting that the TLS method has the added benefit of doing mutual authentication via mutual TLS. This means the client and the server get to feel good about the connection as well. The post focuses more on the server validating the client.
Via reflection you can get their base type and then have special print functions for each one. Example: `my_int` is actually an `int64` and then you get a string form it by using `strconv.Itoa`. You can implement your own one if your are interested. It isn't that hard.
I know people probably have already asked you before. But did you ever consider using mostly net/http? And only use small&amp;specific libraries for the specific issues you may encounter? (if at all)
Net/http is under most consideration. But the easy scaffolding of buffalo is hard to miss.
Just try it, you'll know soon enough if it fits your requirements in terms of "large scale" or not. 
Without looking at it yet, it sounds extremely useful.
Thanks. It seemed so small/generic that I assumed it had to have already existed but I couldn't find another tool doing that. I've used it for a number of small things but the most useful case was clearing Kubernetes namespaces that are stuck terminating. The github issue has a multi-step, manual process where you download json, edit it, then post it back. But using jaq+jq you can do all those things in a single (piped) command.
I don't want to be spammy, so I'm happy to remove the post if mods want, but I am fairly active here so I'm hoping it is okay (it seemed to be in the past). Anyway, the course isn't 100% done but a vast majority (~17hrs of video) is available, but I'm still looking for new material to add. For instance, if you have ever had trouble testing something in particular in Go I'd love to hear about it. The more details the better :) Just a few examples that come to mind: - Several people have asked about testing database integrations, especially when the company has a `db` package with a lot of global state. - A few users have asked about testing with gRPC, so I'll probably try to add some examples in the mocking sections that illustrate how gRPC generates interfaces in Go and those can be easily mocked out for tests. - Testing timeouts can be a pain, especially with contexts, so I want to add some examples showing how to test your timeout logic when also using `context.WithTimeout` Anything else come to mind? Even if it stems from poorly designed code, I often find learning how to refactor those things and understanding why it is hard to test is a great way to learn more about testing.
This is my first *completed* project in Go, so feedback would be very much appreciated!
Thanks a lot!
I've not looked into "Test with Go" yet, but Jon's "Web Development with Go" is really good.
If you want to use the right tool for the job, you kind of need to be well informed about the tools (languages) and their relative strengths/weaknesses.
no, I'm not willing to make the compromises that using an ORM needs me to make
honestly, you'll find yourself in 6 months time fighting the framework and wishing you'd just used net/http from the start. Frameworks are great for proof-of-concept stuff to get going quickly. But they \*always\* have tradeoffs. And once you reach the point that those tradeoffs start to bite you, refactoring away from the framework is long and painful. If you think about it for a minute, it makes sense. The framework saves you a ton of time at the start by making some assumptions about your application. They're common-sense, reasonable assumptions, suitable for most web applications. But, sooner or later, your application is going to want to do something where the framework has taken a different path. And then you're stuck with either fighting your application so you don't fight the framework, or fighting the framework to make it do what your application needs. All the time you saved at the start is now gone because you're fighting the framework or the application. And worse, you will \*always\* have to fight the framework from then onwards. Your best choice at that point is to start the long and complex refactor away from the framework and back to net/http so you don't have to fight it any more. Building the whole thing from scratch using net/http is a bit painful, sure, but only for the first month or so, and at the end of that time you have perfect, complete knowledge of everything your application is doing. No magic, no hidden stuff that you don't understand, nothing to bite you later. It's a great position to be in :)
This looks great and will be interested in checking it out. Just wanted you to clarify something. - Is this course and introduction to Go from the stance of testing ala TDD for beginners to the language? - Or, is this a course about the testing API and how to apply it to various situations? And do you need basic knowledge of the language?
Ever since Google Reader died I always wanted to have my own feed aggregator so I've been coding this for a couple of weeks now. It's meant to be just a simple command-line tool without databases, configuration files or HTTP servers. It reads feeds URLs from `index.html`, fetches their items and writes back to the same file. As index.html grows big it moves old items to `page#.html` files. I'd love some input on the code since I'm learning Go.
The latter - you need an understanding of the language basics and the course focuses on the testing API, then later on how to apply different techniques to come up with better tests or more testable code.
swift
I think HAProxy should be able to do this. Did you have a look at it?
I can't point to anything specific, but there were a bunch of niggles which made that approach seem like it was optimising for the wrong thing. In BASIC, unless you use the "structured" kind, you need to care about line-numbers a little. Because they're used for GOTO/GOSUB. But except for the GOSUB/GOTO you can largely ignore them. If you did have a structure like that described I guess it would be a map, with the key being an int, and the value being an array of tokens/statements. (You can restrict yourself to one statement per line if you like, but even then you have to have multiple tokens for things like "FOR I=2 TO 20 STEP 2") If you had the program: blah[10] = 'PRINT "OK"' blah[20] = 'PRINT "Still OK"' blah[30] = 'END' One of the problems is how do you move forward? If you're at `line := 10` you can't just say `line++` because line 11 doesn't exist. So each time you step forward a line you have to scan your keys to look for the next biggest line. You've made it trivial to jump to line N, but made it harder to merely advance. (I guess the solution there is to have a second array "`lines = []int{ 10, 20, 30}`" but now you have a layer of indirection to manage and it becomes less clean.) Another memorable complication is handling for-loops where you need to maintain position of things. My current approach is pretty simple: * The [runFOR](https://github.com/skx/gobasic/blob/release-0.1/eval/eval.go#L312) function is a bit noisy. * But [this comment](https://github.com/skx/gobasic/blob/release-0.1/eval/eval.go#L384) As it suggests all the real handling happens when you hit a NEXT token, so the [runNEXT](https://github.com/skx/gobasic/blob/release-0.1/eval/eval.go#L697) function is where you loop-back, if you need to. If you see how simple that implementation is, and then consider how you'd do things if you had to remember the statement position in a line __and__ the line involved, it gets a bit ropier. In short when I had that plan I found lots of small problems. None of them terrible, but I suspect I didn't spot them all because I never got very far, and I think the approach would have been a mistake.
My guess is the author is referring to using an array to store the lines of code, and indexing the array on line number. I'm trying to remember my basic coding days, not only 20 odd years ago, but also when I was aged about 10, and convention is line numbers are in 10s, not units, ie lines 10,20,30 not 1,2,3... This means u are missing out 9 array positions in the array making it excruciatingly inefficient. I think that's what he is referring to anyway... 
Yeah I [added a map/cache](https://github.com/skx/gobasic/issues/7) of lines-&gt;statements as a speedup, the implementation didn't necessitate it though. (I guess you could scan from "here -&gt; end" if the destination was in "the future", rather than always scanning the program from start-&gt;finish.)
I like this idea of storing everything in the outputted file and then load everything from it again on the next update, thanks!
honest question: why does a language need new features to be useful? languages are, IMO, much more about the design tradeoffs they choose to make than the number of things the compiler needs to support.
Have you ever tried to make changes to an \`\*ast.File\` and save the changes? If so, you probably soon realised that the \`go/ast\` package wasn't created with this use-case in mind. Comments are not stored with nodes, so re-arranging nodes breaks the output. I created github.com/dave/dst to solve this, and it's now ready for you to give it a try.
Suggestion: go write some significant applications in Go, then see if you are still confused about the logic behind Go.
In addition, you can‚Äôt bolt on CSP as a library and expect good results. It has to be in the language runtime to be effective and work across projects. If you don‚Äôt plan for it from the beginning, you end up with a GIL like Python and Ruby. If it‚Äôs just a library, you have fragmentation and packages that can‚Äôt work together. 
How should I setup my initial list of feeds, and then ongoing add/remove from this list?
I would say bringing CSP into the language and the reasoning behind creating new language are to some extent orthogonal. The main reasoning was the general direction towards increasing complexity of the languages, I believe. &amp;#x200B; There is a great blog post with details on how and why Go was born: [https://commandcenter.blogspot.com/2012/06/less-is-exponentially-more.html](https://commandcenter.blogspot.com/2012/06/less-is-exponentially-more.html)
For those that don't know CSP: https://en.m.wikipedia.org/wiki/Communicating_sequential_processes
Non-Mobile link: https://en.wikipedia.org/wiki/Communicating_sequential_processes *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^221322
Why to create new languages instead of benefiting of the existing infrastructure already. Like why to write your own compiler backend and "reinvent the wheel" when you can leverage LLVM?
&gt;Single static binary (avoiding linking mess) What kind of linking are you talking about? &amp;#x200B; &gt;no syntactic sugar (as you pointed before) very arguable "selling point" &amp;#x200B; &gt;Compiled language (like C, C++) but safe and with quick compilation. What do you mean by safe? For me Rust is safe. &amp;#x200B; Well quick compilation is obviously a good point, but since Go is not meant for the huge projects but rather for little things, very arguable "pro"
&gt;It has to be in the language runtime to be effective and work across projects Can you elaborate and bring more arguments. I don't see how you can not write your own "green threads" framework around an already existing language
&gt;I would say bringing CSP into the language and the reasoning behind creating new language are to some extent orthogonal This is exactly what I think. Meaning, for me, CSP is the only selling point of Go. But since CSP is not bounded by any language and can be implemented anywhere, then why to create a new language? &amp;#x200B;
You have this exactly backwards. Go was made for large projects. See the blog post linked above.
When you run it the first time it creates `news/index.html` containing 2 sample feeds. To add your own you just have to open `index.html` in your favorite editor, scroll to the bottom and add/remove lines like these: &lt;a class="feed" href="https://www.reddit.com/r/golang/.rss"&gt;/r/golang&lt;/a&gt; It knows this is a feed URL because of `class="feed"`.
Take Python‚Äôs asyncio for example. It can‚Äôt coordinate OS threads with green threads, which sucks. The GIL remains. It has [red-green functions](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/). Different libraries and runtimes are incompatible, so you need to use a library that matches your scheduler. They‚Äôre trying to make more compatible HTTP libraries by just making everything immutable, which is fine, but it‚Äôs basically a needless complication. 
I wanted to do this in different languages. I remember when I was a kid and wrote basic code all the time to just explore what a computer could do. 
Russ Cox in 2014 about choices developing Go: https://news.ycombinator.com/item?id=8817990 My opinion: &gt; Why not embed CSP in Java for instance, or Kotlin, or Groovy After Oracle vs Google [Java/Android fiasco](https://en.wikipedia.org/wiki/Oracle_America,_Inc._v._Google,_Inc.), there's no chance Google would invest heavily in Java again. Not to mention JVMs tend to be memory hungry and have relatively slow start times. Monkeypatching other languages with CSP doesn't make them simpler, faster nor free of legal battles over IP and license shenanigans.
* fast compile times
Because basically none of the development tools work with them yet. Source: https://github.com/golang/go/issues/24661
Thank you. The realization that I could skip databases and configuration files was quite the aha moment for me :)
CSP is much easier to understand and get correct than locks and mutexes.
Clojure is a good example of providing CSP concurrency model as a framework, which is not inside of the Clojure.core repository. Link: [https://github.com/clojure/core.async](https://github.com/clojure/core.async) &amp;#x200B;
You can be super productive in Go and never or barely use channels or CSP concepts. Writing something in Go does not imply that you need channels. This is a myth that needs to go away. 
Then how I can be more productive in Go than I would be with language like Kotlin? Having no syntactical sugar makes you write more boilerplate code, how is that good?
Go is about simplicity and concurrency. CSP helps with concurrency. Creating a new language that avoids the complexity of existing languages helps with simplicity. Adding CSP to an existing language would not likely result in a language as simple as Go.
Yup. Not a bad book at all, and the author was very responsive when I reported a bug / design-issue with the code. 
Some languages are easier to write interpreters/compilers for than others. In the past I've written a (toy) Lisp and (pretty complete) FORTH interpreter - the latter in Perl to start with. Even though BASIC isn't very practical, there is definitely a lot of nostalgia there. Since it is [how I started to program](https://blog.steve.fi/how_i_started_programming.html).
FYI, I updated the post with your feedback and gave you a shoutout at the bottom. I only added a toy example because testing is an expansive topic which is mostly outside of the scope of this article.
FYI, I updated the post with your feedback and gave you a shoutout at the bottom. üëç
I also got a long history of variety of languages, and discovering Go was a fresh breath of air. I'd say many with experiences in many languages says the same because it's true.
\&gt; for me, CSP is the only selling point of Go It is not. I assume you've read the linked article, but tl;dr is that Go authors were frustrated with the direction where mainstream languages are going. They believed language could me much simpler, offering only the minimal set of orthogonal concepts. That was the main reason of creating Go, which is captured by "less is exponentially more" title of the article. It was just a good timing (multicore processors became an ubiquity only in 2005) and, probably even coincidence, that Pike had been experimenting with incorporating CSP into languages for the long time, which resulted in Go having CSP model in the runtime. And by the way, I also believe that's one of the reasons why it really rocks ‚Äì it's in the runtime, rather than offered as external libraries.
What if you had a large array instead, and stored things at arr[10] and arr[20]. Advancing to the next non nil in an array should be fast enough. And having a relatively large array should also be fine.
It's funny since they targeted as the "new C++", but somehow strange that they didn't foresee it that people use C++ because of it's manual memory management capabilities and pay-only-for-what-you-use guarantees. Nobody is going to write databases, kernels, drivers, etc systems while using language with GC. Ain't gonna happen. &amp;#x200B; Actually Rust is targeting it and not Go, but because Rust is harder to write, since writing high-performance and safe programs is hard, it is the reason why Rust is not getting that traction. &amp;#x200B; It feels that Go follows the Pareto rule by writing 20% of equivalent C++/Rust code you are getting 80% of performance. &amp;#x200B; Go vs Rust performance: [https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/rust-go.html](https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/rust-go.html)
What do you mean by understand go? Any person can understand go without programming in Go
Can you post a play.golang.org link with an example ciphertext and your current best guess at how to decrypt it?
\&gt; they didn't foresee it that people use C++ because of it's manual memory management capabilities &amp;#x200B; That's not that only reason why people use C++. I've been writing C++ for \~10 years, so for me Go, yes, was a "new C++" ‚Äì it's statically typed, object oriented, fast, reasonably verbose, cross-compiled, well-suited for networking software, etc. Writing software for home security market (mostly networking/protocols stuff), in pre-Go era you didn't have a lot of options: Python (readable, but slow), Java (JVM was a no-go), C (too verbose, error prone, but fast) and C++ (overcomplicated, but more or less familiar and fast). We didn't do High Frequency Trading or some extreme workloads that really required squeezing nanoseconds out from the hardware. Manual memory management was not a bless, it was a burden taking up 80% of cognitive skills and time during development. With a time C++ generics also made our codebase an unreadable template magic maze, no one except its creator could really decipher. And it was relatively simple TCP protocol 10K-capable servers stuff. So yeah, we used C++ not because it's a perfect fit, rather of lack of other options. To me, Go was an absolutely perfect fit in this niche. It's not that fast as C, but it's not an order of magnitude slower, like Python. But the readability and speed of development and easiness of refactoring was way much better than in any other languages on the market. &amp;#x200B; \&gt; Nobody is going to write databases, kernels, drivers, etc systems while using language with GC. Ain't gonna happen &amp;#x200B; Apart of the fact that there [tons of databases written in Go](https://github.com/gostor/awesome-go-storage), and also [some](https://github.com/achilleasa/bare-metal-gophers) POC [kernels](https://github.com/jjyr/bootgo) and [OS](https://github.com/achilleasa/gopher-os) attempts, you're right ‚Äì there always will be a niche for low-level things like drivers, or software requiring extreme performance, and Rust probably will be a good fit there. &amp;#x200B;
For the Windows installer, look at [Inno Setup](http://www.jrsoftware.org/isinfo.php). This is what we use to compile [Relica](https://relicabackup.com) binaries (along with its GUI, but it's not Qt) for Windows.
Perhaps I misunderstand, but if you could only store one item per array-entry that wouldn't be enough. Consider this input: 10 PRINT "HELLO, WORLD\n" You could store `PRINT "HELLO, WORLD\n"` at arr[10], but you couldn't store the two distinct tokens: * `PRINT` * `"HELLO,WORLD\n"` (Unless you had a two-dimensional array, or an array of arrays of course.) Perhaps getting too bogged down in the details of how it could go wrong, or be hard, was why I stopped working for so long. But I guess the end result makes it worthwhile!
and how do you think buffalo is going to help you with that? it won't.
&gt;tons of databases written in Go Commercial ones, not for "fun" or POC. You can write DB in Python, but nobody will use it in production if performance matters. Again depends on the workloads of course, but when it comes to performance, Go is not the choice to make. &amp;#x200B; You can write any program in any programing language which is Turing Complete, but this is not the point, right? &amp;#x200B; &gt;Java (JVM was a no-go) Why was it a no go? Because all other points equally apply to Java &amp;#x200B; Maybe I'm just disappointed because I would expect a powerful language from Google, not C on steroids. But I can clearly understand why somebody would ran away from C++ to Go. Less stressing (because of GC) with not so bad performance.
tried to sign up multiple times it said 'Email not allowed'
Does using the QT GUI library force you to either pay for a license or GPL your code? I‚Äôve been wanting to play around with desktop GUI dev again (VB was horrible in a lot of ways, but dang GUI dev was amazing in it and I really miss that). A windowing library forcing my choice of license is a non-starter which is why I usually stick with Tk, but I‚Äôd give QT a shot if I‚Äôm wrong on the licensing.
Qt is mostly LGPL, the Qt bindings are LGPLv3.
I would say I never bought such a significant piece of knowledge for such a low price. Priceless!
\&gt; but nobody will use it in production if performance matter A lot of companies are using databases written in Go in production. As you said, "if performance matters" ‚Äì and if you truly trying to understand why Go was created and why so many people using it, that's the key to your question. "Performance" has very broad definition, and from my experience, developers with different backgrounds have different biases. People coming from embedded software world, tend to demonize GC as an idea, and they were taught that every byte and every CPU tact matters. At the same time, JS or Ruby developers mostly never worry about things like memory layout or CPU cache misses ‚Äì if adding two numbers takes kilobyte of memory and thousands CPU instructions ‚Äì it's just fine, they never find this out. Turns out this spectrum of "acceptable performance" is incredibly huge and dynamic. 10 years ago you would be willing to spend 3 months to optimize your server or algorithm to make 2x improvements, now you just scale up your cluster in a single click and go to the next JIRA ticket. Go offers here a good tradeoff between productivity and performance. Look, you can do in a few lines of code a server that easily holds 10K connections on a single box. Is it performant? Yes. If you write command line tool and it wastes a few kilobytes and 0.1% CPU more than C++ implementation ‚Äì that's absolutely fine in 9.99% use cases. Go gives you decent performance out of the box for 90% of cases, and offers huge space for optimizing it later, if you need to (it could be seen as desincentivizing premature optimization measure as well). \&gt; Why was it a no go? Because all other points equally apply to Java First reason is JVM. Idea of "yet another layer" between hardware was terrifying to me (I came from C originally) Also, and this is funny and even cautionary, but I developed a long time bias against Java due to experience with desktop Java apps. It had always been the worst experience I could find ‚Äì if the app is ugly, slow and eats tons of memory, I knew it's a Java app. Qt/C++ apps, at the same time, were offering a drastic difference in performance and overall look. So when I first looked at Java, I never saw a benefit over C++. Many years later I found out that networking Java software is quite performant, but it was too late. :)
this; it's a requirement for Windows. And on linux it might work but if you don't sync the calls to the GUI library you could end up in a bad state.
All developers should be aware of [this](https://www.gnu.org/licenses/gpl-faq.html#PortProgramToGPL). &gt; **If I port my program to GNU/Linux, does that mean I have to release it as free software under the GPL or some other Free Software license? (#PortProgramToGPL)** &gt; &gt; In general, the answer is no‚Äîthis is not a legal requirement. In specific, the answer depends on which libraries you want to use and what their licenses are. Most system libraries either use the GNU Lesser GPL, or use the GNU GPL plus an exception permitting linking the library with anything. These libraries can be used in nonfree programs; but in the case of the Lesser GPL, it does have some requirements you must follow. &gt; &gt; Some libraries are released under the GNU GPL alone; you must use a GPL-compatible license to use those libraries. But these are normally the more specialized libraries, and you would not have had anything much like them on another platform, so you probably won't find yourself wanting to use these libraries for simple porting. &gt; &gt; Of course, your software is not a contribution to our community if it is not free, and people who value their freedom will refuse to use it. Only people willing to give up their freedom will use your software, which means that it will effectively function as an inducement for people to lose their freedom. &gt; &gt; If you hope some day to look back on your career and feel that it has contributed to the growth of a good and free society, you need to make your software free. So, you really do need to check the licenses of everything you link to, and if you're writing proprietary software then pay attention to everything you link with. Qt will be ok, as will be linking to the main system libraries in most cases, but do check.
Thanks that looks great!
For even more fun, check out [Inno Script Studio](https://www.kymoto.org/products/inno-script-studio/).
I find that digital ocean was a good choice for me. There's a new k8s offering which is in some pre-release mode, https://www.digitalocean.com/products/kubernetes/ - something like a 3 node k8s cluster will cost around $5/mo from what I've seen, but I'm not sure how much stuff you will be able to run on it. I tend to spin up a lot of hot spot instances there, in addition to the few permanent ones which I have running, they even have [nice cli tooling for that](https://github.com/bjc/goctl). I'm very happy with it and their service so far. Also, since it's hacktoberfest, you get $100 in credits over the next 60 days with a [referral link](https://m.do.co/c/021b61109d56). I get $25 if you spend $25 on the service after that. Just sign up, try it out and if you don't like it that's a done deal. I've also used Scaleway in the past, and I can't recommend it. While I expect their service is improving (and you do get more in terms of ram and disk space), the provisioning of "spot" instances there was just too long. In some cases 20+ minutes, while in DO usually I have one running in about a minute. Also it's bare metal so adjust your backup strategy accordingly. Supposedly DO is subject to critical failure as well, so ... moral of the story: always backup your stuff. I should emphasize that I'm not in any way employed or partnered with DO, because this stuff just reads like some marketing dude is trying to pitch you. TL;DR; DigitalOcean yes, Scaleway no.
It looks like you have binaries for each architecture the Go supports. Can you please share your script that you use to create each of your (multi-platform) releases? Thanks.
it's missing fasthttp, gojay, pgx which are marketed as fastest alternatives. 
Yes, that's a great feature of gRPC. The only caveat is that *debugging* the setup is a pain in the ass. When first using this setup (we have a bunch of devices that talk securely to a service in AWS) I was banging my head against a wall for a couple days because somehow the devices would send their certificates as a string without line delimiters, but the Go part was expecting newlines in it. Eventually I figured it out, but the errors gRPC (and libssl, etc) would show were *super* obscure.
Security is the opposite of convenience.
Do I understand that to go with Google I'd need App Engine, Domains, and GSuite?
No. They are all separate, you don't have to go all in. Also if you use a more expensive Compute Engine you can also just run Go directly without App Engine (on free tier you are theoretically also able to do that, but the CPU is just so weak that compiling go source code will likely hang everything else)
This seems like a great project for Go. I would just aim to get each module/part working together, and then get the pipeline between those pieces working before you throw concurrency in. Then you can focus on performance. 
&gt; Now I just need to find a good way to easily make a Windows installer! Inno. &gt; Are you sure? Inno &gt; Really? Inno &gt; Are there better alternatives? Inno!
A bit vague, but yes, it is required on windows. *Interacting* with UI element needs to be on the UI thread. *Responding to UI events* does **not** need to be on the UI thread. If said respond results in a UI update, the UI update itself needs to be called from the UI thread. Not sure what tool support Go has for it. For c# its pretty much a one-liner to wrap an update statement into running on the UI thread.
Your code stores a whole bunch of packets on the heap. I assumed this was so you could sort them, otherwise why bother?
Will it be possible to implement like a .crocrc file in which one could specify a relay server, to avoid all that typing?
https://play.golang.org/p/qEQ92pozpbS Sorry for the delay, had to get on a computer with the legacy code.
Was easy to use Qt with Go? I need something quite simple with drag n drop support, but Qt looks so hostile to me lol
Sure, I use \[goreleaser\]([https://goreleaser.com/](https://goreleaser.com/)), here's my \[goreleaser.yml\]([https://github.com/schollz/croc/blob/master/goreleaser.yml](https://github.com/schollz/croc/blob/master/goreleaser.yml)). The GUIs are a different build though so I have a separate \[Makefile\]([https://github.com/schollz/croc/blob/master/src/win/Makefile](https://github.com/schollz/croc/blob/master/src/win/Makefile)).
It was okay - I think there is a bit of a learning curve. I wish there was something with drag-and-drop too
Goreleaser looks really cool. Thanks for sharing your scripts.
[removed]
I know you‚Äôre looking at some very low level documentation, but I recently watched a gophercon video from this year about something similar. https://youtu.be/YHRO5WQGh0k I know it might not be exactly what you‚Äôre looking for, but I have seen a decent amount of articles on Hacker News derailing the go runtime in depth if you are curious. Good luck!
To clarify, Inno, can create exe installers using xml files to tell it what to do and the studio let's you create those xml files more easily?
It's really helpful to put the \_why\_ with the benchmarks. \`httprouter\` uses a radix tree which is why it beats Gorilla Mux in your example. \`fasthttp\` is missing HTTP/2 support. Each of these libraries is \_not\_ the same code and approach, they have trade-offs.
You gotta write us up some blog posts when you get this all figured out! Please
Kavya Joshi had an excellent talk about the runtime scheduler at GopherCon this year: https://youtu.be/YHRO5WQGh0k She walks through a naive approach, taking steps to build a model closer and closer to the actual thing which she reaches at the end. It's pretty accessible and comprehensive. She had another talk a year or so before that about channels. 
Unrelated but I just wanted to tell you that I'm a huge fan of your work. I've used and/or deployed your wiki, peerdiscovery, croc and countless others. I love how your code is efficient, compact, easy to deploy and well documented!
needs more explanation in the readme, or even in these posts
You can be closed source, but you'll need to dynamically link to QT. Meaning QT will need to be installed alongside your software.
There's also the maintenance and security thing with dependencies, that no-one seems to acknowledge. Every time we include a dependency in our code, we're basically running someone else's code within our system, with full access to everything. If that code is malicious, then our whole system becomes malicious. If we're writing a secure system, or even a system that handles user information, then we need to be sure that the code is not malicious. There are two ways of being sure: we either vet the code, or trust the author. Go's standard library is written by the same team that writes the language itself. At this point, we are trusting them not to do bad things. The standard library is also used by lots of people, and reviewed by lots of people, and it's extremely unlikely that any malicious code could be inserted without uproar. But for third-party dependencies, this isn't true. So we need to review the code to make sure it's not doing bad things. So including a third-party library may save some time, but only if you trust it completely. I don't, so I only use third-party libraries when I couldn't write the code myself. And then there's the maintenance problem. If you find a bug in a third-party dependency, what do you do? You have three choices: 1. Refactor away from the dependency 2. Raise a ticket and hope it gets fixed soon 3. Dive into the dependency source code and work out how to fix it yourself, then either fork or raise a PR (probably both). If you fork then you just inherited the task of maintaining a ton of someone else's code. If you raise a PR then you still have to wait for the maintainer to accept it. If your project has deadlines, then none of these are going to be good for those deadlines. And finally, using a dependency makes my project dependent on their project. If they decide to mess up their project somehow, then what happens to my project? If I include go-pg to save some time coding my project, and the maintainer of go-pg decides that they really want to make it more of an ORM and start adding lots of features that I don't need, and the thing slows down, then suddenly I've got to either refactor my code, or live with it slowing down for no reason. My project becomes dependent on their project, and I have no idea who these people are or what they want to do with their project. So, yeah, I'm happy to write some extra boilerplate and stick with the standard library. It's a bit more work, but it's much much safer in the long run.
Out of curiosity why? I know some terminal emulators are written in things like Python (e.g., [Terminator](https://launchpad.net/terminator)) and can feel sluggish. Do you expect this to be more performant and available given the portability of Go?
Thanks for that.I actually forgot :D.Updated description in readme.md
 &gt;Not sure what tool support Go has for it. For c# its pretty much a one-liner to wrap an update statement into running on the UI thread. If using Qt, the framework provides multiple ways to run code on the main event loop: http://doc.qt.io/qt-5/qcoreapplication.html#postEvent http://doc.qt.io/qt-5/qtimer.html#singleShot-6 
The link to the telegram bot API is broken (remove the `www.`).
Hello! I just wanted to let anyone who might be interested know that v0.3 of resolv is out! For anyone who might not know, resolv is my collision testing and resolution library that I've been working on for about a month or so, I suppose. It's turning out pretty well! Among other things, this version brings Line Shapes, which means you can do ramps and things easily now. It also brings the ability to use entire Spaces as Shapes themselves, allowing you to do compound Shapes easily.
Good job thanks!
I use Scaleway for pretty much all of my side projects. It's not perfect by any means, but it's been improving and the price/performance difference is just too large for a poor student to ignore. Additionally, each 1 vCPU and 1GB RAM droplet running in the cluster costs the usual $5 in DO, so the smallest 3 node cluster costs $15/mo. 
I'm not sure what all is going on with the framing or the "arbitrary length" part of this cryptosystem, but the code you posted seems basically right (though the play link had N and D swapped). I see "test123" twice at the end of both the expected and actual. So, I'd probably suggest digging into the other parts of the legacy code that prepare and reconstruct the inputs/outputs of the RSA, I suspect that's where the interop is failing. https://play.golang.org/p/Z9b-7kxPEZ0
Just a note: the name is a little bit confusing. [Raft](https://raft.github.io) is a consensus protocol.
I get that. I'm sure it's been an awesome learning experience.
thank you again for pointing this out, readme updated: https://github.com/lfaoro/flares/commit/9c1c44521127c64b57880a200dd755a8c774794c#diff-04c6e90faac2675aa89e2176d2eec7d8
Cool
I‚Äôm basing my $5/k8s 3 node cluster on this tweet: https://twitter.com/dexterchief/status/1053097296991264768?s=21 ; alas I‚Äôm still on the waiting list for the limited release, so I can‚Äôt comment pricing yet. I also feel like there‚Äôs a lot you can do without even renting hardware/vms; netlify is good and free for static sites (gohugo generated blog for example), and there‚Äôs a lot of things you can implement in faas (aws golang) and still be covered by the free tier afaik. There are free custom-domain email providers as well, so if you really want to optimize costs, you can go effectively to zero. As a student there are also free tier grants available, which basically get you a lot of free credits if you want to go all in - it just gets to be a pain if you go over or when you stop being a student (but hopefully you‚Äôre working with business goals in mind). https://education.github.com/pack https://cloud.google.com/free/ Etc. Also: pooling money together with other friends/students and setting up some shared infrastructure is always a good option to optimize costs, if it‚Äôs acceptable to you. Using scaleway is basically the DIY route, I feel it‚Äôs slightly better to move towards gce and aws since those particular skillsets are in demand.
Could you explain a little bit about this please to a newbie to Go? Is using a GOPATH setup not the recommended way?
Awesome, cheers mate! Having to put everything in my GOPATH is one of the few things I haven‚Äôt liked about Go so far, so this is really cool 
Ok, you might be right that completely cutting it out of the basics is not the best idea.
Just factored it out of [yeetgif](https://github.com/sgreben/yeetgif) since it's so small and self-contained. I expect it to be reasonably efficient, also, but I haven't run any benchmarks yet.
Oh, brilliant, finally a Qt binding for Go that looks actively maintained! Is there an API reference for all the overloaded methods that have a different name in Go? Also what's the API for signal and slot declaration and connection?
&gt; Yes, this leads to boilerplate, but it also means a developer can get their head around how to code in Go in a couple of hours. My congrulations, you've just spent less time learning programming language. Too bad that now you spend 4x more time actually writing and reading code. &gt; I played with Rust a bit a couple of years ago. Rust changed dramastically since that, your previous experience would hardly be applicable to modern Rust.
How do you plan to deploy this? 
&gt;It looks like you're trying to argue that devs have no business understanding how their specific application runs in production Believe what you want, but smaller companies are absolutely hiring for miracle workers. Big companies will do what they want. MSN ops teams were legendary for being an iron fence between developers and operations. Don't conflate the two. &gt;Because devs shouldn't have to worry about *systems level infrastructure*. **Devs should worry about application level infrastructure.** A nice idea, and there's a big push for making "serverless" app deployments the norm. AWS Lambda and the Fn project, sponsored by Oracle (who are doing amazingly woke things for a slow moving incumbent, like GraalVM) are two big examples. In these schemes you have a clean split between feature / app-logic developers and infrastructure engineers as you're rooting for. Hey, I'm all for it, and for some projects it's fantastic ... but it doesn't work for everything or everyone. It requires the ability to write your applications from scratch to support the paradigm, and unless you're well funded, you're probably inheriting a crappy LAMP stack application that had it's back end swapped over to RDS to keep scaling on AWS. This is the space where DevOps guys are thrown into the mix to "help" dev groups be on-call for production and end up making things worse, or being relegated to maintaining a couple of docker files and a handful of AMI images that serve no real purpose. The point is: **systems level infrastructure requires code to automate.** That is the entire point of SRE. Next level down from serverless we have the well established model of app engines, google being the biggest but not the first. There was a time in SV that if you weren't running on EngineYard or Heroku you'd just get laughed out of the room. At least until some crappy AR migration broke :P This was about the time that "DevOps" became a thing. For each feature promising "one less thing that devs have to worry about", a scalability or integration issue was lurking just around the corner. Then came Docker. Docker has made the world a better place, and now we can have big container orchestration schemes like Kubernetes and Mesosphere, which handle automated application deployment, high-availability patterns, and provide monitoring plugins. When it works and well staffed, it's beautiful. But there's a big lie in thinking that it works well for companies with tech orgs less than about 50 people. &amp;#x200B; In the post docker world: can you tell me where a developer is supposed to concentrate on feature development in all that mess? A lot of people are scared to even maintain their own docker images much less be on pager duty for production issues or service disruptions. DevOps is a model, not a role, but it somehow turned into one while keeping pressure on feature developers. Here are the problems you face: 1) Train entire team to know the full production stack, dependencies, and deployment automation tools. This takes time, attention spans, and rehearsals that nobody has time for with the ruthless pursuit of SCRUM led orgs squeezing blood from stone. (different rant). 2) DevOps role guy: it's never their problem. reams and reams of text in the post mortem, 10 programming tasks to keep it from happening again, and no skills to fix it. 3) Of 5 people on a team, maybe 2 can be trusted to actually restore system state after a production event. The other three will, without fail, SMS the other 2 during an outage as they're incapable of diagnosing what's wrong, how to recover, or how to mitigate the damage. 4) Hiring good DevOps people is like looking for unicorns. You want a software developer who is also a security engineer, network engineer, and also has good old fashioned SysAdmin skills. Good Luck. In the meantime, your infra is on fire, and PMs are yelling at devs to make their deadline. 5) IT and Ops managers have been eliminated. With their elimination went any semblance of a realistic budget and staff plan to maintain a production environment. "But that's why we use AWS, so we don't *need an ops team!"*. Or QA, because that SDET unicorn you've been recruiting for longer than the good DevOps one quit 2 months after she started for more money and less responsibility at a big national bank. So to recap we have no Ops group. No QA group. Everybody is "an engineer", and suddenly one engineering group is responsible for deploying, testing, and maintaining "one" code base. It's an unmitigated disaster at a lot of tech companies. My request to SME tech orgs is: Hire engineers for QA. Hire engineers for Ops. Stop asking feature development teams for miracles. cheers 
What makes the deployment of flex environments so much slower?
This is a minimum heap, containing exactly one packet from each input pcap, sorted by packet timestamp. This is how joincap knows from where to read the next packet.
congrats! considering that I couldn't make it work (qt just didn't start/install properly).
This post was on this sub a few days ago, really good overview of how modules work: https://weberc2.bitbucket.io/posts/go-getting-started.html Like people said though, it's probably not a bad idea to have both methods in mind for now while modules are still relatively early
Very cool. 
u/rookan \- At some point in the past, i did this [https://github.com/twisted1919/evs-go](https://github.com/twisted1919/evs-go) which might help you get started ;)
Sorry, but GOPATH (or at least HOME) is still mandatory.
that looks awful tbh. what was wrong with the old one, i was very happy with it.
Hey @sbuss and @Panninini I played around with appengine standard. It looks much more upstream-golang compatible now. Thanks. One question though. I want to connect to postgres (via Google hosted database) which requires an username/password and I have some other sensitive data (API Keys etc.), which I do not want to commit to my vcs. Now, the docs seem to say that I should put such sensitive data in either app.yaml or read from google datastore. I do not want to do the former for security and the latter for avoiding vendor lockin. Now is there a way to get environment variables in any other way for appengine ? Also, the official doc does not seem to mention about connecting via postgres. It mentions only about mysql. Is postgres not officially supported ? https://cloud.google.com/appengine/docs/standard/go/cloud-sql/using-cloud-sql-mysql
I'm not optimistic about the potential of whole-program static analysis for revealing deep concurrency problems in Go or any other language. To accurately model the things that matter in concurrent programs---loop iteration counts, dynamic memory allocation, aliasing, and so on---requires a flow- and context-sensitive model of the heap, which is already prohibitively expensive even before you begin the analysis proper. It's fine to explain an algorithm using a 100-line program, but it must scale at least 1000x further to justify the terms "practical" and "real-world". IMHO the gap between the sophistication of the abstractions we express in comments and conversation, and those we express directly in code, is wider than ever and growing, leaving classical analysis techniques less and less to work with. I do wonder whether machine learning could be made to extract some meaning from all the clues in comments, identifier names, and stylistic choices that signify so much to human readers but are routinely discarded in the first step of static analysis.
This is great for me! However I think I see a small typo in zero values float 34? You mean 32?
Haven‚Äôt used the package yet but the blog post looks really good. I like the way you organised the packages and their abstractions.
Yo. Great eye! Thanks, will fix that.
Very useful application, however it requires Qt libraries installed on your system, and not every distro has them installed by default.
&gt;Believe what you want, but smaller companies are absolutely hiring for miracle workers. I agree. My point is, how has this changed? Small companies are always trying to hire miracle worker developers and have been for 30+ years. &gt; The point is: **systems level infrastructure requires code to automate.** That is the entire point of SRE. I agree. And that's why there is still an SRE role separate from development in larger companies. It requires a different set of skills to maintain that across multiple applications in multiple environments. And most large companies also have a separate hardware team and a separate NOC team (or maybe a sub-role of SRE). &gt; When it works and well staffed, it's beautiful. But there's a big lie in thinking that it works well for companies with tech orgs less than about 50 people. IMO the mistake you're making with this statement is assuming that the devs are stupid enough to out-build their size/capability in terms of applications that have to be supported. Maybe if you staff up with an army of mid-level devs that have only worked in large-scale corporations in the past they would think that spreading themselves thin is the best way to do development. Hopefully you have at least one senior/principal level person that can tell them they are Doing It Wrong ‚Ñ¢ . If not, you probably need to hire some new staff. &gt; can you tell me where a developer is supposed to concentrate on feature development in all that mess? Yes, I can. Because "feature development" should exist in **applications**, and how an application deploys should also be an aspect of an **application**. If you're talking about improving the build/integration/release lifecycle, that would be a cooperative effort between devs and SREs. &gt; Train entire team to know the full production stack, dependencies, and deployment automation tools. Okay, but the problem is that devs should know all of those aspects of the application. Devs not caring about how something gets into or runs in production is a huge source of production problems. In today's world, this is like saying a Dev shouldn't know how their application runs *in development*. Which is really nonsensical if you think about it. &gt; DevOps role guy: In my experience, teams that still have "DevOps" roles are still trying to figure out what DevOps actually is. &gt; Of 5 people on a team, maybe 2 can be trusted to actually restore system state after a production event. I agree but this is often a failure of crosstraining new or less seasoned team members and these events help to crosstrain them on troubleshooting steps and handling outages without involving seasoned team members. How else would they learn this stuff? If they are consistently unable to figure it out, then it might be time to look for new team members. &gt; Hiring good DevOps people is like looking for unicorns. I would agree that hiring people who are already comfortable and skilled in modern development environments is still difficult. However, again, that is largely a lack of training. Good engineers want to learn this stuff because it pads their resume and makes work more interesting. &gt; IT and Ops managers have been eliminated. I have heard this dream or dilemma many times, but have yet to see it play out in a way that the business decides to keep supporting long term. When I've seen DevOps principles begin to be embraced, often the IT team gets scared of the SRE team. However, it's easy to find ways that the teams can co-exist, at least at scale. Most large companies haven't completely given up classic IT infrastructure, it has just changed into a slightly different role. Also in my experience, having distinct QA roles causes problems for devs who then see testing as "not their job". i can agree with not treating every dev as a miracle worker. thats a different culture to change. &amp;#x200B;
Thanks! Will keep going!
If I understood the code correctly, it is not harmful only if WriteHeader is called from the same goroutine. If not, there is a race condition.
That seems generally true for most Go code, not just WriteHeader. It is unusual and probably bad form for multiple goroutines to handle a single HTTP request's ResponseWriter. I recommend assuming there will be a race condition unless the Go standard lib docs state that it's safe for concurrent use.
You could return error as in 1. You could use a managed list of error codes and return it in your error object. Stable codes can potentially be localized to different languages if the client needs it and perhaps use composition to keep the details when they are available? Especially in IO, the things that can go wrong is pretty stable over time. const ( IllegalDeviceNumber = 9 MissingFilename = 8 ) type TCPError struct { Code int When time.Time What string net.OpError net.ParseError } // This is the only method required to satisfy the error interface. func (e TCPError) Error() string { return fmt.Sprintf("%v: Code: %v %v", e.Code, e.When, e.What) } &amp;#x200B; &amp;#x200B;
Sounds awesome! Since im a techno producer, the vst2 feature sounds really interesting to me &amp;#x200B; gonna try it out tomorrow
Is that a fellow fish shell user I see?
I also use digital ocean, but I find that a basic virtual linux server goes a long way. The setup is * Write an init.d script to keep things going even after reboot. * nginx to proxy everything from https to a port. * My ssl automation is done through sslmate, but since you have multiple domains the free Let's Encrypt is more economical. * I stopped running my own email server many years ago, its a full time job to do it well (I have Google Apps for domains, which is reliable). Digital ocean has an interface to set up the MX entries you need for a 3. party provider. * Basic monitoring through pingdom, and also some video on KeyCDN. Also, AWS and Google support golang, but getting into lamda functions and such for the simple things I do is overkill. Dropping an executable in a directory is about as close to DevOps I want to get :-) &amp;#x200B;
Dependency injection and composition by any other name smells as sweet...
So turns out I'm retarded, nevermind me.
&gt; Go's type system cannot express that P will pass-through errors from package net. Which is why #1 is the wrong answer. #2 gets my vote but would prefer errors.Wrap() from the x package.
Came here to say this!
So you've written wireshark's mergecap tool in go then?
Who are you using for email?
In december 22. of december 2006 i got this invite from the google apps team (I probably was on a waiting list to try it out). *"You've been invited to use Google Apps for* [*tovare.com*](http://tovare.com/)*, and we're excited to help you offer email accounts and/or other communication and sharing tools to all of your users."* Its currently called g-suite now and mostly intended for business use, but they allow me to keep it for free. :-) I can say that in those years it has worked flawlessly ! Google is a great email provider. &amp;#x200B;
As the top comment on that tweet says, it's $5/node/month. I have verified this myself because I already have access and have played around with it a bit. Beyond that, I 110% agree with you though. I use netlify for most of my websites. For email I use a mix between zoho and gsuite because I find any downtime or reputation issue for email is just the worst. I also agree with your point about AWS and GCP. Those skillsets are is very high demand from what I've seen and they're very nice to work with. If they weren't so damn expensive compared to Scaleway/DO, I'd be using them for all my side projects. Hell, I'm taking the AWS CSA Associate exam soon. Scaleway definitely is the more DIY route. I probably should have mentioned that I definitely don't mind spending time setting up my servers. To come back to the OP: it really depends on the project requirements, budget and technical skill level. This is why I settled on Scaleway for my needs.
&gt; on free tier you are theoretically also able to do that, but the CPU is just so weak that compiling go source code will likely hang everything else Couldn't you just cross-compile the Go binary on your development machine, and scp it to GCE?
I guess, but that's no justification for shitty error messages.
Yes, but why bother with all the hassle when there are free app engine to use? 
&gt; My congrulations, you've just spent less time learning programming language. Too bad that now you spend 4x more time actually writing and reading code. The thing that people regularly comment on with Go is how easy it is to read. Because of its simplicity, lack of magic, and common (enforced) formatting style, picking up someone else's code and reading it is remarkably easy. The thing about writing the code... well... I don't know about you, but the actual amount of time typing is the least of my concerns when writing code. I must rewrite every line 3 times anyway by the time I've got it working. And there are snippets in the editor to help with the boilerplate. It's actually not a problem. And did you have a genuine point to make to the Go community here, or did you just want to troll?
The main reason to pick free GCE over free GAE, I imagine, is if you want to be able to write to a filesystem.
With 2nd gen runtime there's no real advantage of GCE over GAE (for go apps). On GCE you'll need to do a lot by yourself: reverse proxy, monitoring, log rotation, etc. And also scaling. 
&gt;t I wish you like it.
And the lambda theme :-)
For personal projects I recommend scaleway. It's got a modern UI and really good prices for what they offer. Digitalocean was too espensive for me in the long run. 
Reading the tech docs on the Go website is one thing, knowing how to write good tests is another.
Hey, can you please share more about why you'd prefer mux instead of gin. I've dealt with gin's way of confusing similar prefixes in routes. But one could get around that. However, in mux, the verbosity of sending a simple JSON response (setting up headers, marshalling/unmarshalling) appeared very counter - productive to me.
Although this post is now old but I have a question out of curiosity. Being a developer at a start-up (assuming common early to mid-stage startups not dealing something requiring great scale or immense performance), should one care about delivering fast. I mean why not use simpler tools like NodeJS and Express. The benefits there is not just simplicity but the easy availability of talent (both cheap and qualified) to maintain your code in near future. Although, you can switch at a later stage when stable enough. I have read about go being the tool people come back later when things go complex. However, they need to make sure that they deliver fast enough to reach that point. Views?
Damn. I was hoping for some preemtive-instance like pricing for node 2 and 3. Thanks for the info :)
Hey, I couldn't access the link.
https://github.com/golang/go/wiki/Errors
`error` is an [interface](https://golang.org/pkg/builtin/#error) so any type that implements `Error() string` method can be of type `error`. And for the alien syntax this should clear it up: https://tour.golang.org/methods/15 
It's a simple type assertion. If err is a *Error, ok will be true and e will be the *Error. https://tour.golang.org/methods/15
This is a cast to the app-defined struct Error, see the definition above ( type Error struct)
I think we should use the golang idiomatic name of this operation, which is "type assertion". 
OK, then why bother putting online "a demo" if people can't even try it? 
I have some projects with Qt GUI used, you can check them. https://github.com/gen2brain/bukanir/tree/master/desktop https://github.com/gen2brain/crtaci/tree/master/frontend/go Both have .iss for Inno Setup installer, and a script that use wine in Linux for that. Also, I didn't use qtdeploy, and binaries are compiled with static build of Qt, so everything is in one .exe file.
Using error type assertion like this is a bit of an antipattern; check out Don Cheney's blog post titled [Don‚Äôt just check errors, handle them gracefully](https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully). Really great opinions on how to write more idiomatic error handling
Will check that too, tx!
You can also use `go mod vendor` to just keep the current working vendor version in your own vcs. No depdencies for CI/docker builds, no hassle when something breaks on github again.
You can't go wrong with HAproxy
"Why is it called that? Because it's like... You know, collision resolution? To resolve a collision? So... That's the name. I juste took an e off because I misplaced it somewhere." &amp;#x200B; LOL. Love it. Definitely will check this out.
&gt; Cygses sets out to correct the pain points of web development in Go. Some of us don't know what these are. I would better understand the project if I knew what these pain points were specifically.
Essentially, a lack of built in support for session management and few options for third party packages. A lot of the third party packages out there are bloated and hard to use in my opinion. Thanks for asking!
Thank you for the contribution. Your code looks clean and easy to read. Good comments too. Here's an opinion from someone with little experience in Go which you might consider relevant or not: I don't like that the library has unnecessary global state and silently spawns a goroutine like this: var sessionBin sbc var scope chan string func init() { // ... go overseer() } Perhaps it would be best to put everything in some kind of Session{} struct which a New() constructor returns. This tends to make code more robust and allow for easier testing, specially if you have 2 constructors like I usually do. Just an example: New() // Default way to use the library. Instantiates with working default values NewWithCustom(mySessionStorage, myOtherExplicitDependency, ...) // Allows for customization both for users and testing It might look like more code and more complexity for little return and there's certainly a sensible limit to how much encapsulation and dependency injection is good but it tends to pay dividends. It took me over a decade to learn this. As for the overseer() func, I'd put it inside the suggested Session{} struct and let the user of the library call it explicitly whenever is best for him. It would also be nice to have a graceful way to stop it. Perhaps a cancel() func or a context of some sort. I hope I made sense. I love minimalist approaches like your library!
The author is casting it to `*myapp.Error` in order to get access to `e.Code`.
Thanks, I got it after I read about the "type assertion" syntax (links posted above). Wasn't aware of it.
Hi, not encrypting file/directorynames ( and therefore being able to check them in ) was a kind of tradeoff i've made here. Otherwise i would end up with a single file again. To keep it short: you can not have both. cheers, &amp;#x200B; Matthias
Few quick comments... Check out sync.RWLock. No need to block your entire map when reading a session. That said, you‚Äôre locking an awful lot, and you‚Äôre doing it all over the place. You may want to look for ways to tone that down, or your performance will be garbage at more than a few dozen users and your code difficult to maintain without accidental races. Not sure why you need two cookies for session management. First library I‚Äôve seen to require two cookies. Why the ID and validation? You shouldn‚Äôt validate against a user‚Äôs remote address. Many different users could be sharing the same IP behind a firewall or NAT, and those IPs could rotate, particularly on mobile clients. You might want to sign and rotate cookies, so you‚Äôre not as vulnerable to session hijacking. Since you‚Äôre saving to memory, if your server reboots (either crashes, or you need to update), you‚Äôll kill everyone‚Äôs session. This won‚Äôt scale beyond a single server. Look at storing the data in the cookie as a secure hash, or adding an external service like Redis or a database. 
Thanks for the advice. I actually considered doing something like this. There are a few reasons why I didn't go this route. 1. Overseer runs constantly so that is a user does not access the website for an extended period of time, their session will still be systematically removed from memory 2. I plan on creating a feature that only allows one user to have one session at any given point. E.g. if a user logs in on a new computer, their session on their old computer will end. This means having an easy way of mapping a user to a session, calling the old session, ending it, and letting overseer eventually find it as a dead session and remove it from memory. Allowing a user to control overseer might add unnecessary complexities to code to manage memory. One of the goal's in creating this was making it simple to use, and as I said earlier, familiar to web developers. A PHP and ASP developer don't have to worry about these type of things, they just call $SESSION\["name"\] and bam. I wouldn't mind coding a better solution for this problem. I just need the solution to be in the scope of the goals. I really appreciate the feedback!
Few quick comments... Check out sync.RWMutex. No need to block your entire map when reading a session. That said, you‚Äôre locking an awful lot, and you‚Äôre doing it all over the place. You may want to look for ways to tone that down, or your performance will be garbage at more than a few dozen users and your code difficult to maintain without accidental races. Not sure why you need two cookies for session management. First library I‚Äôve seen to require two cookies. Why the ID and validation? You shouldn‚Äôt validate against a user‚Äôs remote address. Many different users could be sharing the same IP behind a firewall or NAT, and those IPs could rotate, particularly on mobile clients. You might want to sign and rotate cookies, so you‚Äôre not as vulnerable to session hijacking. Since you‚Äôre saving to memory, if your server reboots (either crashes, or you need to update), you‚Äôll kill everyone‚Äôs session. This won‚Äôt scale beyond a single server. Look at storing the data in the cookie as a secure hash, or adding an external service like Redis or a database. You mention other libraries are complicated. There‚Äôs reason for this. Session management is directly related to site security and a limiting factor on scaling. Just don‚Äôt discount these other libraries too quickly before understanding the entire problem domain. 
fasthttp doesn't do 2.0 iirc.
I think it's a great advice to novice programmers that you should minimize the concurrant interfaces, but ... I disagree with your use of channel as a throttling mechanism. For one, you can't increase the number of go routines dynamically. Two, it introduces another component to the system with no _real_ value. Unless this has some form of advantage in term of performance (due to the scheduling behaviour), I'd say this approach is counter intuitive. on a side note, the first example with this code: ``` for _, url := range coffees { wg.Add(1) tokens &lt;- struct{}{} url := url // &lt;- this here go func() { // omitted }() } ``` is going to confuse new programmer in a way that won't lead them to finding the correct reason for why you did this (i.e. the value assigned from the range will change before the goroutine starts) , however: ``` for _, url := range coffees { wg.Add(1) tokens &lt;- struct{}{} go func(coffeUrl string) { // omitted }(url) } ``` may just lead to people discovering about closures, the semantics of range loop and `go` keyword's evaluation of arguments. :)
This is very terribly written code
Posted 25 minutes ago with very weak bot-like posts in random subreddits, with this post gaining a lot of upvotes for this sub. Not shady at all.
the "else" statements after the returns made me twitch. It could just be a series of if's, which would read a lot easier imho
1. So if a user is inactive for a long period of time, the overseer can still find the session and kill it 2. The thinking behind it is simply preventing a session name from being predictably the same. 3. No, I will look into that, thanks! 4. Working on it! This is still very much in the early stages of development but I am working on this. 5. I've tested it against race conditions and deadlocks. The only reason I lock it so much is so that overseer doesn't delete a session whilst it is still being retrieved by GetSession(). Running build with the race flag yields no errors. 6. I will be adding this feature, but I haven't began on it yet. This will be in there before version 1.
I don't think gorilla sessions is very well documented. I wish it was though.
Yep, I think Session management is my biggest painpoint. Let me know how I can contribute. 
Do you have an in depth tutorial on Gorilla mux sessions?
Thanks. Removed.
I just opened an issue tracker. My email is on the bottom of the bitbucket page. Contribute in any way you can and I'll really appreciate it. 
**Link Summary:** The Go2 Error Handling Overview gives only four rather vague "goals": small-footprint error checks, developer-friendly error handlers, explicit checks &amp; handlers, and compatibility with existing code. The above offers a comprehensive list of *possible* requirements...
No. But I'm planning to write tutorials on server side app development in Go. Will publish them soon.
So what would be the use case for this? Sorry for asking but the only one that comes to mind is illegal sort of stuff...
 I've been practicing with Go, and actually built something that me and a couple other people have been using on a day-to-day basis. I'm looking forward to feedback and observations. Any suggestions on how to make the code more idiomatic Golang-like, as well as pointers on the best way to get started with writing tests are especially encouraged! 
I can imagine it being used legitimately for something like [WhatPulse](https://whatpulse.org/) (i.e. statistics).
Thanks for keeping this sub clean!
&gt; Two, it introduces another component to the system with no *real* value. What do you mean by that?
&gt; The application requires root permissions. 
[removed]
After moving from AzOps to Github for it immediately to fail that weekend. My company finally sees the light of not trusting these services for our business lively hood.
I think my use of words have been misleading. I've updated my comment to reflect this.
[removed]
Like 10% of this document is about requirements. The rest describes a fairly specific implementation.
I usually just map a directory to the container, and pass a GOCACHE env variable that uses that directory. As an example (not from real config): --volume=/tmp/build/:/tmp/build:delegated \ --env="GOCACHE=/tmp/build/cache"
Pentesting is a career field ya know =)
Not sure I understand that requirement yet. You build an app in go that is almost 100% compatible between mac and linux, yet you want to reuse the golang prebuild vendors? Why not just build the app nativley on mac until it works and create a usable docker image once its ready? I'm not involved in any large scale solutions but for all the mediocre stuff I did the rebuild time of the go build step was never above 30s. Not sure that fiddeling with the build process in any way is a good idea, you might produce conflicts with optimizations/pruning durcing compilation. Regardless of my concerns, why not just use a fixed GOCACHE path, like kevin\_nisbet suggested and write a bash script that go builds every single dependency in the vendor directory in a serial matter? Then create a prior multi-stage build, copy over that script, the vendor directory and execute it, as long as the file hashes do not change, the multi-stage will be cached.
Most programmers are familiar with catch blocks (or `err != nil` blocks :-) which can continue the function and therefore accommodate recoverable errors. Go has generally avoided novelty in the language, but check/handle departs from that principle. Regarding your rewritten example, it looks clean by itself, but I don't think a mix of these styles yields clarity: v, err := f1() // the redeclaration problem again if err ... { ... } v = check f2()
 RUN mkdir /hello WORKDIR /hello WORDIR creates a path if it doesn‚Äôt exist. Why do people not read the documentation when they learn Docker?
In our case docker and the https://github.com/GoogleContainerTools/skaffold binary are the only build/development dependencies required to keep setting up a development environment as simple as possible despite using a boat load of languages. Not all of us have a local Go environment because not everyone is writing Go daily (or even monthly).
Check out the blog, he explains it
IsBad should return an error type, not a bool, if the error is bad and then you just write `check isBad(err)`. Pkg/errors uses this pattern quite extensively. 
[removed]
https://golang.org/pkg/sort is your friend Basically you need to define a type SuggestionSlice []Suggestion and define Len(), Swap(), and Less() receivers for it.
isBad(err) is a shorthand for something like if e, ok := err.(T); ok &amp;&amp; e.m == kBad { ... }
Yeah, in the ‚Ä¶ do `return err` and outside the if do `return nil`. Now it‚Äôs easy to use with check. 
Is there any way you could provide an example? I'm pretty new to go so I understand the reasoning behind len(), swap() and less(). But I'm not sure what you mean by "define a type SuggestionSlice \[\]Suggestion"
&gt; func GetSession(w http.ResponseWriter, r *http.Request) (error, *Session) Error goes at the end. &gt; The error does not need to be handled because Cygses automatically handles it. They explain why a session was replaced. Maybe there shouldn't be an error, then?
I like the \`flag.StringVar\` version, to avoid things like \`ip := \*ipPtr\`.... like: `var ip string` `flag.StringVar(&amp;ip, "i", "`[`127.0.0`](https://127.0.0.1)`1", "the ip address to serve from")` then you can just use \`ip\` and all the pointer-ing goes away 
type SuggestionSlice []Suggestion func (s SuggestionSlice) Len() int { return len(s) } func (s SuggestionSlice) Swap(i, j int) { s[i], s[j] = s[j], s[i] } func (s SuggestionSlice) Less(i, j int) bool { return s.[i].votes &lt; s[j].votes }
(also this is a cool app and I will be using it)
[removed]
Ah, well that explains it. Different worlds. It's docker and scaffold against a simple folder of go-distributables, but hey ;) Just checked it myself using `golang:1.11.1-alpine3.8`, `go env GOCACHE` resolves to `/root/.cache/go-build` so all you would need to do is to mount that folder to a local one and you should be good to go as a docker/skaffold developer or not?
&gt; First, we disabled the dedicated garbage collector worker threads so that application threads don‚Äôt compete with garbage collector threads for CPU cycles. So, as far as I understand: assuming no idle cores are available, this avoids hurting pure-userspace apps, while syscalls may end up a bit slower. In a system that often has idle cores (i.e. anything that isn't being benchmarked to the fullest), this seems like the wrong decision. I guess that's where fully relying on the Go scheduler starts hurting; it seems you'd really want to run kernel gc worker threads with lower-than-userspace idle priority, to help syscalls be fast more often.
Very nice! Was wondering when a Go port would appear. :) Looking forward to trying this.
This is the worst downtime I've ever seen, even worse than when S3 failed two years ago. 
thanks for sharing
well yeah. why would you let any random user on your computer start recording keystrokes? it can't tell the difference between user a and user b so it can't just record "your" keystrokes. this would be one of the biggest security holes on the planet.
Certainly it might take 2+ reads to absorb; it's a design space, not a design. I re-used what I could from the draft design: `handle err { ... }`
The general way I check is by using a database comparison tool. I run my database setup script against a brand new database, and we compare that against a development database for differences.
X11 is authenticated. It's totally possible to write a key-logger that only records the keystrokes of the user running an active X session.
and you would end up only recording the keystrokes of X, not the terminal. this guy didn't write an X11 keylogger, he wrote a systemwide keylogger. cmdFlags.StringVar(&amp;eventPath, "eventPath", "/dev/input/event0", "Event device path") 
I'm guessing you're writing an error status in an endpoint and not calling return before evaluating another condition and writing a different status header. You can only have one header, so it's just letting you know that you're doing something invalid. Both headers can't be used. I haven't tested to see which it uses--first or last--but it would be a pretty quick thing to check.
Here they'd be using `tokens` to avoid overloading the number of connections -- you still have a bunch of goroutines, but you only let a limited number run at once. Doesn't seem like that big a difference to me, honestly. More compact example: ``` // call f(0), f(1), ..., f(n-1) on separate goroutines; run up to numCores goroutines at once. func parallelDo(n int, numCores int, f func(int)) { wg := sync.WaitGroup{} wg.Add(n) sema := make(chan struct{}, numCores) for i := 0; i &lt; n; i++ { i := i // sigh go func() { sema &lt;- struct{}{} f(i) &lt;-sema wg.Done() }() } wg.Wait() } ```
Hah nice! Very similar to my repo https://github.com/brianmoran/mockify
I attempted to do this... sort.Slice(suggestions, func(i, j int) bool { return suggestions\[i\].votes &lt; suggestions\[j\].votes }) But I received this error... invalid operation: suggestions\[j\] (type \*\[\]Suggestion does not support indexing)
Supports openapi spec?
Ah, don't use a pointer to a slice. Use the slice value directly. The error is telling you that a pointer doesn't support indexing, which makes sense.
Yeah, that made sense to me. I just didn't know if changing it from a pointer would mess with the rest of the program. But it didn't. I used this line of code and it's not throwing any errors anymore. sort.Slice(suggestions, func(i, j int) bool { return suggestions[i].Votes &lt; suggestions[j].Votes }) But it's not sorting by the votes that I'm looking for. So, I'm going to have to look into it a little more. Thank you for your help! 
Understood, It's basically the compiler telling me to not write bad code. I was trying to find another example of a variable being initialized in a switch statement, and that was the first one I could come up with.
&gt;i := i // sigh Why are you doing i := i? 
Indeed it‚Äôs a common problem! 
Try using double quotes instead of single. The query is being interpreted as a raw string literal. See https://golang.org/ref/spec#String_literals "SELECT id, username, password, business, person, created FROM users WHERE id = $1 AND business = $2;" 
Mine too :) https://github.com/schigh/fony 
I'm actually afk now, but I believe I also tried this and it still did the same thing.
trynna fail as fast as possible, bruh
That's awesome! Thanks for sharing
It creates a copy of i that we will not mutate, which the goroutine will read. Without that, the goroutine would race w/ the for loop (which is modifying i), for undefined results. https://play.golang.org/p/kiLczG2ornJ This is because the semantics of the for loop are equivalent to doing: i := 0 while i &lt; n { go func() { ... } } which is, in my opinion, a wart in the Go language spec. It'd be much nicer if the for was defined as giving you a new variable each time, and the compiler could optimize it down to a single variable when it could prove the results would be equivalent. (When the results are not equivalent, you basically always want a new variable.)
The fact that the loop variable i in initialized only at the beginning of the loop. Without that i will always be 0 in all the goroutines spawned. Alternatively I prefer ‚Äò‚Äô‚Äô go func(i int) { ... }(i) ‚Äò‚Äô‚Äô
Always 10 in practice, since the loop will finish before any of the goroutines have had a chance to get going. And technically undefined, since we could be reading and writing to i simultaneously.
That would be great. With auto-generated dummy content and list support.
That would be great. With auto-generated dummy content and list support.
ok, for a few seconds i didn't see the subreddit this was posted on and thought "what kind of a bad person would attempt to mock their server, and what kind of an app is 'localroast'? something about roasting your neighbours?" 
I find this is generally true of languages that have good examples in their docs. Go and Rust do this really well.
``` const Size = 64 func Checksum(seed uint64, data []byte) [Size]byte ``` That's pretty cool. I didn't know you could specify the size of a returned slice in the function signature. TIL. https://godoc.org/github.com/mmcloughlin/meow
Yeah that's fair. I got this from an anecdote at gophercon where someone had hundreds of idle goroutines and a panic. Their screen was huge and it was hard to find out what was actually wrong. If you don't have idle goroutines, that wouldn't happen. But to each their own!
Arg I totally forgot to mention the url := url oddity! I've gotten so used to it that I forgot about it! As for the channel thing, I don't love it myself, but it's from the Kerninghan book so I've stuck with it so far.
I was thinking the same thing. There are tons of questions to answer on stackoverflow about the C++ language. The questions that are there about Go are generally about the applications of Go, (e.g microservices) rather than the about language itself. People just don't have much difficulty with the Go language. With C++, perhaps it has something to do with lots of spare time while you wait for your code to build!
What I like most about go is, you can refactor an app a whole day, without compiling even once. Next day when all is done and vs-code shows no errors any more, you just start your app and it‚Äòs working ... you have some logical errors but get them fixed in minutes... Working with .net in the other hand means, rebuilding your code on minutely basis and debugging. And even then you sometimes don‚Äòt know why it behaves like it does. For me this comes from the complexity of dependencies you can build with oo languages. 
I never thought of pythons standard library docs are bad until I looked at go. It‚Äôs really just amazing!
for such a syntactically elegant language, the library docs for Python are surprisingly bad. They're lengthy, but somehow manage to not communicate much useful info.
By using the disque instead of redis :). Disque will become an extension for redis 6 next year.
Go is way closer to C. I feel it goes wrong as i search for complicated solutions.
I don't know any.
It looks like you need heavy rate limiting for your task. I would not recommend you yo use Redis, try maybe NATS/STAN?
Just to add to it, look at `hugo`. It is simple, fast and elegant. On top of that, it is super easy to extend the source as well. Boy! I am in love with `Go`.
I feel you bro, i spending my time mostly on docs page
This is not a slice, it‚Äôs an array https://golangbot.com/arrays-and-slices/
I don't think StackOverflow post count is a good measurement source in this matter. You have to take language popularity into account. You could also check asian forums, where Go is vastly more popular than in other countries (for some mysterious reason), especially chineese groups.
Why not use \`http.Fileserver\` ?
Do not agree, python docs are very good and still the best in my opinion. Otherwise name an example of places where the docs are bad! Go has also good docs, not taking anything from that. There are a lot of languages which have spotty or non-existent docs.
A few weeks ago I wrote such task queue, albeit for handling Slack API requests. A REST endpoint would receive requests from Slack, then `LPUSH` the request body to a Redis queue. A script then perpetually watches the queue by means of `BRPOP` ing the queue in an infinite loop. If there's stuff in the queue (ie. BRPOP returns something), then it gets processed. This ensures only 1 task gets processed at a time (for however long it takes), and then moves on to the next available stuff in the queue once it's done. &amp;#x200B;
Node.js is still single-threaded, right? So the questions are whether your workload can peg a single core of your CPU, and whether you have multiple cores to work with. If the the answer to both these things is yes, use a runtime that allows you to schedule work on multiple cores, like Go.
algorythms?
This one works (even if a bit inconsistent): https://play.golang.org/p/UdWPTivEjil
And mine! https://github.com/quii/mockingjay-server
This is evident in the Redmonk Language Survey, where Go and C# are equally popular on Github, but Go is far less so on Stack Overflow. [https://redmonk.com/sogrady/2018/08/10/language-rankings-6-18/](https://redmonk.com/sogrady/2018/08/10/language-rankings-6-18/) PS: You should *attribute* this to the success of Go :-)
Thanks for the note, I'll look into it a bit more! The way the application works is you define the &lt;count&gt; amount of times you want the file to be available. If you set `-c 3`, the link it provides can be used only three times. I toyed around with using `http.Fileserver` but couldn't straightforwardly implement this, i.e. bring it up and shut it down gracefully every time someone reaches out and downloads from the link, using a goroutine. Finally, it is my hunch that io.Copy is more lightweight than http.Fileserver, and that it 'streams' the file, instead of loading it onto memory all at once, though I'm not sure about how http.Fileserver handles the same task.
Hi it's going to interface with a Python backend actually for a bit of ML, but mostly it's just going to be database calls/redis calls for most of the API calls.
Hi it's going to interface with a Python backend actually for a bit of ML, but mostly it's just going to be database calls/redis calls for most of the API calls. I was thinking of deploying a cluster of Node JS servers if ever actually. Oh I see! How many instances did you have to implement for that 5000k+ concurrent connections? I'm admittedly still starting out with web dev hehe. I'm thinking of learning docker sometime in the future too. When time allows, for now the only excuse I could give myself for not learning it is my currrent time is split between ML/microcontrollers/and web dev like literally.
Really doesn't mean that the pattern isn't usable in applications as well, for the reasons he explains
Thanks for the feedback and the suggestions! I'll check into doing without the pointers immediately, it seems quite cleaner in the end. Hope you find it useful!
Absolutely agree on this! I had (still having actually) this issue with C#. Extreme versatility usually comes hand in hand with complexity which in turn ends up being an issue. Although to be fair .net core eased things quite a bit and I think that was one of the wisest moves from Microsoft in years. I'm still a Go rookie but I already appreciate it's simplicity and straightforwardness. What I really like about this language is that it's extremely well balanced - it emphases on simplification of complex concepts(concurrency,parallelism etc.) without oversimplifying to the point where you have no idea what is it that it's doing.
budget issue.
People are afraid of Stack Overflow assholes. I wouldn't be surprised if that were the reason you didn't see much Go chatter on top of not being as widespread as C# or something like Java, Javascript and/or Python.
It helps that Go is a comparatively small language without a lot of features. I find that this helps me quite a bit. There's usually only one clear way to do something and I've never had any problems with Go there weren't inherited issues from poorly designed products.
&gt; Otherwise name an example of places where the docs are bad! Perl.
Surprisingly, some people can even take Go and misuse it. In my org, there are people who treat go like an interpreted language. One project I worked on recently was cleaning up a config file loader. Instead of properly declaring structs and unmarshaling the JSON into those, they were unmarshaling into something like `map[string]map[string]string`. It was awful and unwieldy to work with.
And my axe
Maybe a [Shotgun-Axe](https://streamable.com/b59ft) combination of some sort.
PHP‚Äôs docs come with random exploits in the comments for you to copy. Very convenient. 
One of the architectural constraints that define REST is statelessness. So the state should always be on the client side, not the server.
Given it sounds like the bulk of the work will be IO in that case, Node.js will probably be fine for that. Besides, with Node you could still use the [clustering](https://nodejs.org/api/cluster.html) which in the past I've found is very effective at increasing throughput. There are other perks to using Go though in the long run, the statically linked binary that you can produce, the real concurrency if you do need it, fantastic tooling and ease of doing things like benchmarking, testing, and debugging performance and race issues. It's a great environment to work in.
I'd argue the age of the language plays a very large part in what you're seeing. 
Anything displayed in red [here](https://codecov.io/gh/illenial/binlookup-go/src/master/binlookup.go) is simply never executed through your tests.
Not checking what your go rutines are doing ‚ò∫Ô∏è
Cut him some slack. He has obviously spent too much time on reddit.
Go code has a habit of looking low in code coverage reports compared to other languages. This is because of all the error handling blocks. Check out my courtney project that removes excluding some of the less important parts: https://github.com/dave/courtney/
I really don't like adding check and handle for errors and contracts for generics. It seems like they finally acknowledged the problem and added a bad solution.
Make sure to post the job on these also if not already: * https://www.golangprojects.com/ * https://www.welovegolang.com/
Having your code panic rather than simply returning an error. This one's fairly obvious to people who've been using Go for a while. But it's a bit against the grain for Go beginners if you're coming from another language where you are used to "throwing" your errors/exceptions when they happen.
&gt; `(*[]Suggestion, error)` You almost never want to use a pointer to a slice, especially as a return value. One of the very few cases where a pointer to a slice makes sense is as a receiver to a method that needs to mutate the slice length and/or capacity (e.g. when implementing [`heap.Interface`](https://golang.org/pkg/container/heap/#example__intHeap) on a slice).
The mux libraries usually offer features the stdlib doesn't have. For example, pulling ID's from the URL: r := mux.NewRouter() r.Methods("PATCH").Path("/customers/{customerId}").HandlerFunc(updateUserCustomer(customerRepo)) // You can then pull out the ID v := mux.Vars(r) id, ok := v["customerId"]
Go home Dave, you're drunk. 
Not sure that's true. Python's scipy, sklearn, and numpy have great docs despite being pretty complex. The problem with Python's stdlib docs is the format they're written in.
Some offer more efficient trie-based algorithms for routing URLs. I don't think the added complexity is worth it for most use cases, though.
Really interesting that the asm file is generated by a Go program. What's the rationale for this? To make it easier to change parameters of the hash later? Also, might be cool to see the asm generation code split out into its own package (if such a package does not already exist).
I use it both to extract parts of paths and to route on HTTP method. Using it for content negotiation (Accept headers) is also useful sometimes.
Not sure if this is sarcasm... But its not that mysterious... Its because how Golang treats unicode characters.
Python also has very good unicode support and doesn't seem to be as popular as Go in Asia.
# My Go stack is underflow, bitch!
Agree, and it spreads some bad vibes by design: I have seen some of my old questions marked as duplicates to questions asked more recently, sometimes years later. There might be a solid editorial reason to just keep the newer question, but being marked as a duplicate: I asked this question **9 years, 9 months ago** [https://stackoverflow.com/questions/476342/converting-a-localized-date-of-the-form-12-okt-2007](https://stackoverflow.com/questions/476342/converting-a-localized-date-of-the-form-12-okt-2007) Apparently it¬¥s a duplicate of a question asked **5 years, 10 months ago!** They could have found said something that felt less wrong than: "**This question already has an answer here:**". &amp;#x200B; It doesn¬¥t make it fun to participate on stackoverflow. &amp;#x200B;
Nothing is ‚Äúbad‚Äù per we, but for example, if the datetime docs were better, there would be no http://strftime.org/. 
I would like to ask something about the clustering though, how do you compute or test how much Node JS clusters you actually need? Those benefits with Go do sound great. What I found a chore with Node JS is actually the debugging really. Sounds like a real nice thing to consider. Well, along with I suppose with Go things are not as messy as the different kinds of coding paradigms with Node JS right now. Is Go similar to Django with how things seem to be standardized? How high would you say is the learning curve of Go btw?
Oh absolutely, those libraries are brilliantly documented. But they're mostly written in C. I'm not saying that's the main reason, but fact is that they're also very well structured code wise. Parts of the main Python internals on the other hand are incredibly cryptic. Generators, for instance, are scary.
[removed]
&gt; If the the answer to both these things is yes, use a runtime that allows you to schedule work on multiple cores, like Go. I read more of your reply again, and was wondering on what does this mean? About the runtime and scheduling?
OCaml and F# are easy to learn.
And exhaustiveness and redundancy checking by the pattern match compiler.
See [here](http://www.ffconsultancy.com/ocaml/benefits/pattern_matching.html).
&gt; I believe the advantages of pattern matching languages are superficial Compare the code from this book with [this interpreter](http://www.ffconsultancy.com/ocaml/benefits/interpreter.html) written in OCaml. 
Preemptively "wrapping" your types in interfaces, and returning those interfaces from functions rather than concrete types. Usually looks something like: package api type API interface { Foo() (Foo, error) SetFoo(f Foo) Bar() (Bar, error) SetBar(b Bar) Close() error // 20 more methods... } type apiImpl struct { // ... } func NewAPI() API { return &amp;apiImpl{ // ... } } There are a few things wrong here. First, if there's really only a single type that implements your interface (stubs/mocks don't count), you probably don't need an interface. And the more methods an interface has, the less likely it is that there will be multiple types implementing it. Second, returning an interface introduces an abstraction where you don't necessarily need one. It also prevents the compiler from inlining the method calls (or doing escape analysis on their arguments), which can hurt performance significantly. Try benchmarking `(io.Writer).Write` vs `(*bytes.Buffer).Write`.
&gt;I add the parameter types (so `where id = $1::uuid and business =$2::uuid`) but otherwise that looks OK to me. Tried this but not luck. I bet it's some stupid thing I'm overlooking. &gt;Are you sure you've got the driver library imported? I am able to insert into the database.
A question being marked as a duplicate is *not* personal, and not directed at you. You're right in your assumption, it's because it's helpful for the reader who arrives at the question. Especially in this case, since the more recent question has *much* better answers. I feel like a lot of people dislike SO because they take every action, from votes to comments, personal. But it really isn't personal. I did the same mistake when I started out on the site, but once I got over it and started looking at it in a purely *technical Q&amp;A* kind of way it became much more enjoyable.
ha I was doing that at one point in a desperate effort to avoiding declaring structs. one function dynamically reading any json, but using interfaces and casting anything more than a string got REALLY unweildy. Don't resist structs. They are a key in Go. 
`argparse` is also a mess. The worst one I've had to deal with recently though is `asyncio`. It's got a completely different structure to the rest of the docs, and since it was introduced in 3.3 the interface has changed almost completely.
To answer the title: overuse of pointers :) To answer the body of your post: not sure yet :) (love Go)
You know something is weird when you google the person's name and the first link is his stack overflow profile.
Right, but my point is that this is every bit as complex as a series of goroutines sharing work. Also, a nicer alternative to `i := i // sigh` is passing `i` as a parameter to your goroutine function: for i := 0; i &lt; n; i++ { go func(i int) { ... }(i) }
Hey everyone, this is still very much a work in progress but wanted to release it anyway for some early feedback. I made this because I just don't write GoDoc comments often enough to be fluent in their syntax so whenever I do I inevitably end up committing something that looks ugly when viewed on [godoc.org](godoc.org) Now I can just write GoDoc comments and see them rendered in real time using the actual GoDoc renderer.
Is there an accompanying talk that goes with this? It's really painful to scroll through loads of slides with grey text on black background.
Disagree. I've tried both (in earnest) and they both have show stoppers. For F#, you pretty much need to know C# since you'll be interfacing with it all the time. Besides, the build/deploy story is pretty complex (you need to learn msbuild and the rest of the dotnet toolchain, and you still can't reasonably target native binaries; getting better all the time though). OCaml has competing standard libraries, poor documentation, no good build tooling, no shared memory parallelism, and the community is comparably toxic. The languages have a lot to offer, but without a good build / test / deploy / profile / etc story, it's all in vain.
Trying to emulate a class hierarchy using struct embedding. 
My goal was to provide a similar interface to other standard library hash functions. See `sha1` for example https://golang.org/pkg/crypto/sha1/
Use a queueing service, Kafka, Nats.Io, I don't know how your service runs but if it is restarted than the queue is lost. This is a best practice when developing in cloud or microservices. I never used Nats.Io but I will try it with the first chance I get. 
It's using the Go program as an extended assembly macro system to make it easier to do things like unroll loops. Lots of systems generate repetitive asm with scripts. OpenSSL notoriously has a significant build dependency on Perl. I've written a bunch of optimized routines using https://github.com/Maratyszcza/PeachPy . Assembly is annoying to write. Tools that make it easier are great.
&gt; I would like to ask something about the clustering though, how do you compute or test how much Node JS clusters along with server instances you actually need? What I did was just trial and error, and that's because it so happened that I had access to all the clients (nodes in my case) that should run together :)) I did a timer lol. I'm not sure I understand here; the cluster module basically simplifies running the same process on the same machine, using the same port for example for an HTTP server. When I've used it I've had the Node.js app count the number of CPU cores available and then start that many workers. Do you mean, how do you do capacity planning? If so, I'd load test with some realistic load, then base how many replicas of an application I need on that. &gt; Is Go similar to Django with how things seem to be standardized? I've not used Django personally (love their docs website though). In terms of standardisation, at least with things like HTTP servers and the like, the standard library of Go sets the style that should be used. A lot of people use the same set of libraries in the same sort of way. I think one of the trickiest things though is how you structure the app - it's totally free-form, so you can do it how you want. It's a bit of a blessing and a curse. I have "patterns" that work for me now that I've developed over the last few years. &gt; How high would you say is the learning curve of Go btw? Extremely low barrier to entry. The language is very simple. Writing idiomatic Go can be tricky to get your head around at first, but I go out and read other people's code often to see how other people are structuring things and the kinds of patterns people use to solve new problems I have. I was writing Go that I was actually using for real stuff in the first couple of days of using it. I tried learning Scala before that and about a year in I'd still not written anything I'd say was all that useful :|
You used an idiom! &gt; trial and error Attempting to achieve a satisfactory result by testing and eliminating various methods until the best one is found.
Also this was a great excuse to have a play with compiling to web assembly: the entire thing runs in the browser. You can check it out here: https://github.com/bradleyjkemp/godoc-playground/blob/master/wasm.go
I actually wrote this for this [CL 136896](https://go-review.googlesource.com/c/go/+/136896) . In that case the generated code is far larger, so the need for code generation is more obvious. However since I had it already, I figured I could use it for meow hash too. I think this will bring benefits when I implement the AVX-512 versions. /u/dgryski has used [PeachPy](https://github.com/Maratyszcza/PeachPy) to great effect. However, if possible I tend to prefer to stick to pure Go even for supporting code. Something like [dave/jennifer](https://github.com/dave/jennifer) for asm would be great. 
And really, if your requirements are so broad that you can't lay out your JSON data structures ahead of time, you need to re-think the solution.
To me it seems maybe a little bit easier, but as I said &gt; Doesn't seem like that big a difference to me, honestly. Personally I like "i := i" a bit more than passing in the argument explicitly, because I don't have to repeat the type and the implementation is restricted to a single line (vs the function argument, where it's spread out a bit in source). 
In my book I showed how to build a simple 50 lines of code web engine with routing that uses only Go's standard library. I think that it seems simpler at first to use a 3rd party. And also developers are used to use 3rd party library from other languages where, generally speaking, you always have frameworks to accomplish what Go's net/http is capable of doing. I'm not sure there's really much to gain overall after using some libraries, there's almost always something that does not feels right. Whereas the standard library gets out of your way.
Fair enough :)
\&gt; Consol oops
My favourite feature of peachpy is the register allocator combined with the instruction database. It makes writing assembly code so much easier to just create an unlimited number of virtual registers and have peachpy figure out which physical registers they need to be in. Maybe writing a linear scan register allocator should be my next big project. Having a reimplementation of PeachPy in Go would let us solve some of the outstanding Go-specific issues in the current version. So tempting...
Not sure if there are devs that are similar to me... But coming from C/C++ land I find Golang more refreshing than Python. Not to mention the performance gains you get from a compiled typed language.
What's the name of your book? 
Perfectly ok to weed out old stuff on a Q&amp;A site. I don¬¥t expect a 10 year old question to be relevant .. but it didn¬¥t already have an answer. And to take it personally, I wasn¬¥t lazy at the time by not searching first :-) In the beginning stackoverflow was carefully gamified.
Perhaps conform to the common Hash interface? [https://golang.org/pkg/hash/#Hash](https://golang.org/pkg/hash/#Hash) Then (among other things) your hash becomes an io.Writer, with easier substitutability for FNV, Adler, etc.
[removed]
&gt; For F#, you pretty much need to know C# since you'll be interfacing with it all the time. I've been using F# professionally for 12 years and still haven't learned C#. &gt; you need to learn msbuild and the rest of the dotnet toolchain I don't know msbuild either. I just do CTRL+F5 in VS or run it directly in FSI. &gt; and you still can't reasonably target native binaries True. &gt; OCaml has competing standard libraries, Yeah, that sucks. &gt; poor documentation, True. &gt; no good build tooling, OCaml has many build tools! But, yes, they all suck. On the other hand the compiler is so fast I just recompile from scratch every time. &gt; no shared memory parallelism, Lame, lame, lame. &gt; and the community is comparably toxic Toxic?! I always loved the OCaml community. &gt; The languages have a lot to offer, but without a good build / test / deploy / profile / etc story, it's all in vain. I'm working on a new language to replace them, at least where I work. 
People just prefer to import a 3rd party library than writing the 3 lines of code you need to get the key from the path.
A streaming interface is non-trivial because the length is part of the IV. See this issue on the official repo: https://github.com/cmuratori/meow_hash/issues/2
Have you seen the [Rust port](https://github.com/pauldix/monkey-rust)?
How would I go about mocking such type in unittests? With interface it's easy.
it's Build a SaaS app in Go https://buildsaasappingo.com/
The nice thing about using interfaces though is that you can control exactly what methods are supposed to be used outside of the class, even if they are in the same package. The Java programmer in me has a hard time letting go of OO concepts like encapsulation which have proved to be very useful. 
Some people might answer that this is valuable for internal use. I know I've had to send a lot of emails internally and couldn't be in communication with the Outlook Exchange Server (for a fairly arbitrary reason, but perhaps there are also valid reasons). What I found was that it's difficult to mark these homegrown emails as safe even when you control BOTH servers.
Thank you, will definitely check this one out. 
I've asked the same question while using the standard library happily. But in the end, developers are REAL good at having strong opinions. It's hard to know what the majority of companies do in production systems, though, because most developers that write Go have also been working in other languages and have only used Go in one or two jobs.
So, my question is: how does "check" work in a multi-value return context? 
C++.org is pretty good docs. Apple‚Äôs docs is trash until you know what you‚Äôre doing. 
&gt; To support this, you need to add new file named ./kudo-oos/pkg/http/handlers.go and define your HTTP handlers using the fabulous httprouter library. For such a simple use-case, why? Seems like it wouldn't be too tough to add a check in the handler functions for the request method and reject with an \`HTTP 405 Method Not Allowed\` , and therefore not depend upon a library outside the stdlib. &amp;#x200B; I'm also noticing a number of places where errors are ignored, tsk tsk :)
This is answered in the post linked in the post above. &gt; A great rule of thumb for Go is accept interfaces, return structs. As long as functions accept interfaces you can still use fakes in tests.
Thank you for the tutorial. It's unfortunate that modern JavaScript projects require so many tools though. For people who do more JavaScript than Go, OP's tutorial looks better. I wrote this tutorial [1] for people who write more Go than JavaScript. [1] https://cixtor.com/blog/go-vuejs
they are just proposals. Welcome to improve them.
This is impressive. As a developer who works mostly with C# and is a fan is Python, I think that Python documentation is awesome. I've been trying to learn go in my free time and I think go concepts are great. 
Could you explain why they are bad solutions?
[removed]
https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling.md It works as you might expect. "For multi-valued expressions, check yields all but the last value as its result." "For functions with unnamed results, the default handler returns zero values for all leading results and the error value for the final result." "For functions with named results, the default handler returns the current values of all leading results and the error value for the final result." 
lol, like the go team welcomes any suggestions from outside the go team when it comes to language design. No, the proposals are exactly what you'll be getting.
&gt; I'm not particularly well-versed in dotnet and I oversimplified. You definitely need to deal with specific implementation details between C# and F# and it leads to a lot of unnecessary complexity in the language (for example, objects, inheritance, and all that nonsense). I generally regard objects and inheritance as the FFI so it replaces low-level C stubs that must work in harmony with the GC. &gt; No idea what ctrl+f5 does Compile+Run in VS. &gt; someone on your team needs to know how msbuild works (if only to operate your build/package/deploy automation). The fact that you've been programming in this language for 12 years and never learned your own build tooling makes you an outlier. I just use Visual Studio's GUI. Point and click. Deploy is copy-paste `FSharp.Core.dll` and `foo.exe` somewhere else. For testing I use custom code written in F#. Once I used BDD with an F# tool. 
Any chance you could port it to other languages? I'd love to see an OCaml version!
&gt; type statefn func(*lexer) statefn That's a [trampoline](https://en.wikipedia.org/wiki/Trampoline_(computing)) which is an inefficient way to emulate tail calls. 
Do you think it‚Äôs possible to write a webassembly port of something like vue / vuex / vue-router / vuetify with go bindings? What would the closest architecture of purely go-wasm web app framework look like? How about a wasm-based front end framework?
C# is super easy. It‚Äôs literally one of the most hand holding framework out there and nothing is there to surprise you. If you think c# and asp.net and .net core I question your ability in development.
Lol this is the first time I have ever saw anyone who has worked in c# and .net a Say that it‚Äôs too complicated and hard to make it work. It‚Äôs often attributed to being a very hand holding framework. If you can‚Äôt get a .net project running within an hour then perhaps you are not in the right field. 
A good go programmer thinks of a solution in terms of data types. read that somewhere
Thank you for the helpful replies! Yes, I was asking about the capacity planning. I may have phrased that awkwardly hehe sorry. I see, so Go is similar to Node JS such that everyone's APIs tend to look different, and even different even if using the same framework like Express JS. I was hoping for a bit that go is like Django in the way that people's code are usually structured pretty similarly due to set patterns. I see, so it has a low barrier to entry. About the patterns, wow I didn't know that Go has been widely used for years already since you've said that you have developed patterns since then. I suppose I'll go look for more references in the meantime just to get a gauge of how learning Go to build a REST API is these days. Thanks for the help btw! Although if you don't mind me asking, how did you learn Go? I've heard their website's docs is pretty informative. There's even a post here that this person didn't need stackoverflow since the Go docs were really good. Or did you do a mix with online tutorials and their website? Hehe just finding a lead on what I should probably look more into first.
golang.cafe
It's the first time I saw something like `&lt;-make(chan struct{})`, in wasm.go. is there a reason to use that instead of an empty select block? Efficiency/doesn't work in wwsm/etc?
By 2020 we will write SPA 100% in Go. Wasm in coming.
Your node.js app is statefull if it's holding state... If state is in redis, then it's not in the node.js app, so your app is stateless. Stateless apps make clustering super easy, while statefull apps make it complex: if state is being held in a process memory, then it's better if that process can use all cores, which is why stateful apps can be a better use case for go than node.js. 5000+ connections spread on 3 servers (4 processes each)... It could run on less, but spare capacity is important for this use case. For your use case, I think node.js will be perfect.
Yes, it is already in the works. https://github.com/HuckRidgeSW/hvue
&gt; I made this because I just don't write GoDoc comments often enough to be fluent in their syntax so whenever I do I inevitably end up committing something that looks ugly when viewed on godoc.org You can always view them in your local godoc server first. But great project anyways !
Interesting... Ok, thanks!
Go is still a very young language. I'd rather they bit the bullet age made backwards incompatible changes sooner than later (with a focus on the tooling handling the transition). The other difference with python is that your code had to run on an environment you couldn't control (and since it was shipped with the OS it would be stale). Compare with go, where you're shipping binaries and your users don't even know what it was written in. 
I will say, I hate all the proposals for the new error handling methods. I guess I'm weird for being ok with the current way of doing things. 
I'm hoping this thread is useful for that- I really wish I looked at more examples!
I just had to consult the [Qt docs](https://doc.qt.io/qt-5.11/) and then check (Ctl+F mostly) the Qt Go bindings for the analogous function. I also was able to find some things in the issues on that repo. Not ideal, but it worked.
Thanks. I gave serious thought to using a browser as a GUI. Its not such a bad solution I think, everyone seems to have a browser nowadays. I just kinda long for the days 15 years ago when I could give my friends a native app...
Agreed!
Thank you for sharing!
Go on the server and Vue on the client sounds nice, but isn't GraphQL the new cool thing, instead of REST?
If you have parts of your go project that do work independently of each other, put them into packages, and woosh you got real private and public methods. Not only go, but also Java and C# favor the Accept an interface return a concrete implementation - if you only need a subset of that implementation, then var butler Butler butler = butlers.NewFemaleButler() This is a common pattern in other languages to restrict the use of concrete implementations, also you should not need to create a butler inside a method that works with a butler, but instead use IoC to pass the butler into a method that only accepts the Butler interface.
Thanks for sharing. I too feel this knee-jerk reaction to grab a dependency way to common. It‚Äôs almost like upkeep don‚Äôt enter the equation. 
I agree, I also really like the way go handles errors.
Me too, people need to start using snippets... not like you should actually type this stuff. It doesn't add much value and errors should almost always be wrapped for context anyway. 
The implementation. They are surprisingly complex, and their use as a base for the new coroutines kind of shows that.
what's the issue with a dependency, especially one which is as popular as httprouter? There's no point in reinventing the wheel. Just vendor the dep so that it can't disappear and you won't encounter a leftpad issue
Yup. I also dislike the contracts idea. It introduces a completely new language inside the existing one, and breaks the feature that a function's constraints are completely obvious from the signature alone. Honestly, I feel like the requirements for a generics solution make all of the proposals awkward to use. I've also only ever seen one case where a problem could not be solved without generics or runtime reflection, and that was 100% a design problem earlier in the process.
&gt;1. Did you audit the included code to ensure it doesn't contain anything malicious? As I am sure you read through the millions of lines of the Linux Kernel and each and every utility you use on the server, compiled from scratch without bootstrapping it with a binary component... Paranoia is one thing but be realistic, httprouter has quite a few users so changes are one can trust it. Same as gorilla/mux For two, whatever is quicker, report it and monkey patch it for the moment, still quicker than writing your own and having more bugs than a mature project 3 doesn't the compiler strip those things?
There was a talk at Gophercon 2017 about this subject actually. It's worth a watch/read: [https://about.sourcegraph.com/go/idiomatic-go](https://about.sourcegraph.com/go/idiomatic-go) (video link is at the top)
no, I didn't read the Linux source code, and I accept a certain amount of risk because of it. At least I have the choice. I also run Windows, and I know there is malicious code in there because they've admitted to it. It's not paranoia if they really are out to get you ;) My point is that your system now includes a ton of code that you actually have no idea about. It appears to do something you want, but it could do a lot of other stuff besides. This gives me the heeby-jeebies. No the compiler won't strip code that isn't run, unless the code is structured in a particular way that allows the compiler to work out that it will never be run. E.g. using config flags to determine the features used. The compiler can't strip out unused features because it doesn't compile the config, and the config can change at runtime.
I hate the proposals I've seen and I hate the current version as well. I don't think there's any nice way around the pattern (which itself is good).
Mainly just legacy tbh. Originally I based the wasm running/loading on https://github.com/agnivade/shimmer which blocked main by listening on a shutdown channel. Later I realised there wasn't any reason you'd want to shutdown the previewer so I made the smallest fix possible. For background: callbacks can only be processed by the go code while main has not yet returned.
I think the problem is that the noise ratio because of ‚Äúif err != nil‚Äù is significantly higher. Compare that to a language like Rust (or even Scala?) which use a monadic approach to errors and combined with the ‚Äú?‚Äù in Rust makes the code read much better and handles error propagation really well. If each error is to be handled instead of propagated upwards then that option is there too. At this point, my brain is wired to transparently ignore the error checking bits to read what the code is actually doing. I wouldn‚Äôt mind a better solution. 
Upkeep. The less dependencies the better. I was talking generally here. I have nothing against `httprouter` itself. 
Hold up now you are changing the topic. Basically saying well .net is good at x but not good at y, I never said it that it was the master solution to everything. That‚Äôs just the silliest thing I ever heard someone think anyone assumed. I said it is extremely easy to use with the basic assumption that you are using normal use cases of which it is great at. If you decided to build some thing that .net isn‚Äôt normally used for does not automatically how is that anyone else‚Äôs fault but yours and how does that mean everyone does not have appreciate for different technologies. Again nobody approaches anything and say I‚Äôm gunna build that in c# no matter what it takes. Lol
Very cool project, looking forward for part2 and the release of the source !
Just look at the documentation *index* for Python: https://docs.python.org/3/contents.html I have to scroll past "What‚Äôs New in Python 2.1" to even get to the actual documentation. That's not good organization. As for my personal favourite: subprocess module. It starts with (current recommended API), whatever that API is at the moment, then you get *frequently* used arguments, then more constructors, then in passing "security considerations", then more random objects, then *obsolete* random objects, ‚Ä¶ compare that to Go's much more concise `exec` module. Though the Python docs are better now than they used to be in Python 2.x days. 
Same here 
That‚Äôs not accurate. Web assembly even states in its docs that it is not meant to be a replacement for JavaScript. It‚Äôs supposed to work along side it. It‚Äôs on the front page. 
And mine too - with the least verbose syntax: https://github.com/sspencer/mock
A tool (written in go) for exploring the contents of a docker image, and each layer within that image. It is aimed at folks that are trying to identify ways to shrink their docker image. It reports on how efficient your image is and lists out each file that may be leading to inefficiencies (e.g. when adding a file in one layer and later removing it... this file still takes up space in the image). 
So, both C and C++ with their care of compatibility are overloaded. But simplicity is main point of the Go. So, no one need Go that is not simple as it is. And any compatibility kills the simplicity. And, if we (they, actually) are going to make Go 2 compatible with Go 1, then Go 2 turns to be useless for new users. I think it's better to make it incompatible as big as it possible. Otherwise, who need the Go 2, not Go1.12.
Holy crap, that is awesome! I never thought of this type of feature for pipe composition. Is this an entirely new idea? Or are there other Unix tools that this is attempting to one-up?
There are a number of existing workflow/pipeline systems written in Golang. The ones that come off my mind are: * [Pachyderm](http://pachyderm.io/) \- Building on Kubernetes to provide a container-based pipeline system * [Reflow](https://github.com/grailbio/reflow) \- Focused a lot on simplifying running pipelines on Amazon EC2 * [SciPipe](http://scipipe.org/) \- A lightweight pipelineing system focused primarily on shell command based tasks, but with ability to run custom Go code as well, by setting the CustomExecute field to a Go func (See [docs here](http://scipipe.org/howtos/golang_components/)) Me, Jon Ander Novella and Daniel Whitenack wrote up [a comparison of the above systems specifically for the bioinformatics domain here](http://gopherdata.io/post/more_go_based_workflow_tools_in_bioinformatics/), but these are in fact completely domain independent. Full disclosure: I developed / develop the SciPipe library. I do have many plans for developing it further, making it more suited also for more general pipelines (not only shell command / disk - based workflows). Possibly this more general development will be done in the [FlowBase library](http://flowbase.org) I started, but expect more things to happen during the coming year. 
Because your "essential" is not everyone else's "essential". Go embraces simplicity - when someone who hasn't written Go for particularly long comes in, guns ablaze, saying, "Go is so stupid, it doesn't have generics, and I can't just write Java again", of course your points won't be taken well. I've written Go since before 1.0 was released, and I definitely don't find it lacking "essential" features or to be particularly quirky. I know many other people feel the same way.
The thing that makes Go attractive is the \*lack\* of "features" that add complexity to other languages. The simpler a language is the harder it is to fuck up, and the easier it is for an opinionated community to arrive at clear standards for how to do things. The net result is a language that is efficient on the computers it runs on, in the communities that discuss it, AND in the minds it gets manipulated in. Attempts to add "missing" features are therefor met with hostility because you're looking to mess up my beautiful car with a ridiculous spoiler, or whatever metaphor of hacking things onto something clean and pretty you want to use.
Your other post got caught by reddit's rather bad spam filter. Possibly because you used language like "eat shit". That's not useful to the discussion, please strike a more polite tone (yes even to go language critics).
I'm not hostile myself but I think people should take the time to understand the why behind those things they consider a language weakness or lack of "essential" features before expressing their opinions so strongly. Go is a very simple language that people can learn to read very quickly, the problem is when those people think that everything they know about their language should apply to Go because of it. 
&gt; I generally regard objects and inheritance as the FFI so it replaces low-level C stubs that must work in harmony with the GC. Suffice to say, I prefer the high-level type-safe memory-safe FFI of the Common Language Runtime. I definitely think it's a nicer FFI, but I suppose my objection is its proliferation. I can write a lot of Go code without ever touching FFI, but I can't seem to write much useful F# at all. Tradeoffs. &gt; Deploy is copy-paste FSharp.Core.dll and foo.exe somewhere else. Most of our industry has automation around building and deploying. Putting VS in the loop is not best practice.
What incompatible change is so important to make that it can't be handled by having the compiler operate in a reverse compatible mode on old source instead? Honest question, not sarcasm. I don't see any reason to make it so that Go 2 can't use Go 1 modules. Python kinda sorta did have reasons, because they redefined their string hierarchy pretty deeply, along with I believe a couple of other fundamental changes. (Note "print" was not one of them; that would have been trivial to have backwards compatible. Real changes to how strings worked would have been more problematic.)
Shouldn't the third node be `godown_3`?
I have retrieved these for you _ _ *** ^^&amp;#32;To&amp;#32;prevent&amp;#32;anymore&amp;#32;lost&amp;#32;limbs&amp;#32;throughout&amp;#32;Reddit,&amp;#32;correctly&amp;#32;escape&amp;#32;the&amp;#32;arms&amp;#32;and&amp;#32;shoulders&amp;#32;by&amp;#32;typing&amp;#32;the&amp;#32;shrug&amp;#32;as&amp;#32;`¬Ø\\\_(„ÉÑ)_/¬Ø`&amp;#32;or&amp;#32;`¬Ø\\\_(„ÉÑ)\_/¬Ø` [^^Click&amp;#32;here&amp;#32;to&amp;#32;see&amp;#32;why&amp;#32;this&amp;#32;is&amp;#32;necessary](https://np.reddit.com/r/OutOfTheLoop/comments/3fbrg3/is_there_a_reason_why_the_arm_is_always_missing/ctn5gbf/)
I love the new error handling stuff, and I'm a bit iffy on contracts but generally appreciate the idea. I'm not trying to change your mind, which is why I proved no evidence or argumentation. I'm just uncomfortable with leaving the negative assertions out there all by themselves. I particularly really want some sort of forward motion on these matters because I think the status quo isn't great, and don't just negative responses to be out there, even if it isn't these exact proposals. (Though I really think the error proposal is quite good.)
No need for that. Tinygo can compile your frontend app to ~3kb! https://github.com/aykevl/tinygo/issues/53
Impressive. Tons of tests too. Congrats! Would you say there were any pain points caused by the language or standard library while developing the project?
You can learn C++ a whole life and know half of it only.
I think it largely comes down to how the criticism is structured. The vast majority of it comes across as "I hate Go because its not language &lt;X&gt;." Well, no. It's not. It's not meant to be. When people have taken the time to understand why Go was designed the way it was, and used it for things it was meant for complain about things, it is received much better. You kind of already started down the first path by commenting how it "lacks many essential features." Most people won't view it that way, as it was never designed to be language that had every feature. ¬Ø\\_(„ÉÑ)_/¬Ø
you don't need to know whole c++, also you can probably say that any language around so long will be complex; c++ vs go is not a great comparison
&gt;Would you say there were any pain points caused by the language or standard library while developing the project? Thanks! I would not say that I had any pain. I did NOT even feel the need for generics :). What can I say, it was a little bit hard to switch my brain to use duck typing.
Nice! Looks like it was built by the Google Chrome team: https://github.com/GoogleChromeLabs/go-hackernews
" especially when it comes to lack of many essential features, language quirks and bad performance at many benchmarks?" You answered your own question.
&gt;My point is that your system now includes a ton of code that you actually have no idea about. It appears to do something you want, but it could do a lot of other stuff besides. This gives me the heeby-jeebies. I fail to comprehend your priorities. On one hand you use a closed source OS and have no issues with it, and on the other you are afraid of a popular package where you can check the source?
Error propagation should occur infrequently - handle errors right where they happen most of the time. In Rust you still have to perform pattern match to check if there was an error. The "?", while convenient, simply passes the error on if present. The proper handling would be to wrap error with additional information because it's a different location in code now. Besides, the function you are currently in may have a different return values signature compared to function that returned the error so blind pass-through is not going to work. ```go func Bar(int n) (*Baz, error) { if err := Foo(n); err != nil { return nil, err } ... } ```
Golang was design to be a batteries not included language. Meaning it was meant to be light in size. The import make it super easy to include anything package, even with a URL link. I am not sure what you mean by bad performance and 'quirks'. Golang is meant to be used to solve problems that benefit from being distributed and concurrent. It can do lots of things but that is what it is designed for.
Thanks! :) Generally kinda new idea, but I've already learnt not really *that* new actually (see "prior art" in the readme). Also, "Bret Victor this" and "Bret Victor that", and [Luna](https://luna-lang.org), eventually...
I removed your posts because neither your tone nor the resulting comments were productive.
Hard to say without more details. I've found Go's community to be mostly pretty good about receiving \_real\_ criticism, but much of what is called "criticism" is really just trolling. To answer some of your questions: 1. "Lack of many essential features" -&gt; Go doesn't lack any essential features. It doesn't have some nice-to-have features, like generics and sum types. This makes some things a little tedious sometimes. It also lacks a lot of harmful features, like inheritance and pointer arithmetic. 2. "Why does Go perform badly at many benchmarks?" -&gt; Not sure which benchmarks you're talking about, but the benchmark game benchmarks that Go does poorly in are generally measuring some library implementation (e.g., the regex benchmark) where Go's library happens to not be very optimized, or the benchmark has rules that prohibit Go from optimizing while allowing other languages. The specific example of the latter that comes to mind is the binary trees benchmark which incurs a lot of allocations; languages like C, C++, and Rust are allowed to preallocate memory; most other GC languages don't have Go's ability to collocate memory so they need fast allocators. The benchmark rules prohibit Go from using its memory collocation features to preallocate memory (which is an easy, idiomatic optimization), so Go performs badly. (Technically the rules allow preallocation if there is a popular library, but Go doesn't have such a library because it would only be useful to defeat the arbitrary rules of this benchmark). I'm happy to address other concerns (assuming they're sincere) as well.
I'd really love some evidence and arguments. If you can open my eyes to the beauty of the new system, I'd be totally stoked. I'm not saying we have to end at a point of agreement, but I'm always down to hear a new point of view!
Given errors don‚Äôt have type information how would you even know what error occurred? Look at the os stat method, it returns an error if the file is missing then you gotta know to call back to a special function that checks the error string for what type it is. That‚Äôs a horrible, unintuitive design. Without real error type info all you know is that the call failed. There‚Äôs no real way to properly determine if a retry or whatever should happen cause that kind of logic depends on the error itself
no, I have issues with a closed-source OS, I just accept that I have issues with it and only run Steam and games on it. The worst that can happen is that I'm compromised and my shit is stolen. Accepting someone else's code into my project is a whole different kettle of bananas. I want to know exactly what they did there, because other people trust me, and the worst that can happen is that I'm responsible for a ton of other people getting their shit stolen. World of difference there.
Douche.
And if you don't want multiple versions installed at once, just an easy way to install/update, there's [goup](https://github.com/lpar/goup).
Obvious question: What do your firewall tables look like? (`iptables -L` in Linux.)
QED.
&gt; lack of many essential features If you're the tenth person today making the same lazy complaints people are much less likely to spoon feed you through how to behave like a productive, professional human being, work with you to find out what your actual concerns, if any, are and so on. If you're indistinguishable from the trolls, you'll get treated as one.
You can at least give one concrete example.
You don't know what error occurred, but you know the circumstances under which it occurred, because it occurred in the context of some of your code. So you report the error that was passed back to you, and you decorate it with information about that context; info which the called method wouldn't or might not provide in its own message. e.g. userList, err := mymodel.GetUsers(siteName, "admin") if err != nil { return fmt.Errorf("PermissionCheck can't get admin users for %s: %v", siteName, err) } 
I only use gvm on Linux OSes. It's pretty convenient.
Another Golang newbie here. I recently learned about [`errors.Wrap`](https://godoc.org/github.com/pkg/errors#Wrap) for annotating caught errors.
You can also do the following for most versions, which puts a binary with the version name in $GOBIN: $ go get golang.org/dl/[version] $ [version] download $ [version] version For example: $ go get golang.org/dl/go1.10.3 $ go1.10.3 download $ go1.10.3 version go version go1.10.3 darwin/amd64 It's fairly quick to script this up to install lots of versions, and they don't clash with each other.
Yes, that‚Äôs obvious. My point was to the parent comment regarding doing contextual actions from an error. A single call can fail in many ways, even in your example you don‚Äôt know if it‚Äôs a permissions error. What if the network is down, the db is broken, the permissions are wrong, the site doesn‚Äôt exist, etc You made an assumption but without the actual context of the error you can‚Äôt make reasonable choices whether to bubble the error up or to retry or ignore, etc 
So much this. I use Vue but refuse to add a dependency on npm/yarn.
Mux is more flexible with route wildcards. Usually you can work around it, but occasionally at the expense of oddly named routes that don't seem to follow whatever convention you had started with. Mux is easier to build tests against in my experience than gin (minimal experience testing against mux, but seemed easier). Gin uses Set() and Get() methods to store things in context, but doesn't implement context.Value() properly (IMO), and you must pass a string as the key, instead of a "comparable". Minor, yes usually, but it's a needless restriction, and it bit me during crunch time and I'm bitter now. What Mux doesn't handle as easily out of the box are usually trivial to add the same functionality as gin (json/other marshaling/marshaling, handling api headers) with an added func or two to your codebase. Mux routers/handlers can be generated by swagger.io, and if api documentation is something you care about for api gateway or similar, it's a +1 to use mux in order to prove your api tests out/scaffolds the way you expect given your api documentation. None of this is "dealbreaker" stuff, but I've come to wish I'd used mux. maybe I wouldn't say that if I'd done it the other way around from the get-go...IDK. Sorry for the delay on this. Been super busy. 
thank you! I know about best practice to add context to the errors) maybe I‚Äôve forgot in some place to do it. Thank you for your comment!) 
Yeah, that‚Äôs a very good package. I‚Äôm going to use it in my next project
No problem! I shall write some more code using mux.
I think (hope) some of it is a defensive posture that will keep Go from going the way of some other programming ecosystems that have been victims of their own success. I'm thinking of Ruby (+ Rails) and Javascript (+ Node.js). I'm a full time sysadmin with a background in web development that stretches back to the PERL/CGI days. Every now and then I'll script up a little something that makes life easier around here. The "every now and then" part of that has been a problem as web development has exploded. I usually don't have any problem picking up a new scripting language, but keeping up with the rate of change in tool sets these days could be a full time job. I did a small project in Rails, and it sat in a corner here doing its thing on a seldom-updated Linux box for a couple of years. Then one of our vice presidents suggested a few small changes. No problem, I thought, and also an opportunity to move to new hardware, etc. Except that literally every single aspect of the development environment had changed. Very little of the previous effort was salvageable. I made a similar mistake whipping up a sign-in/sign out board using Node and an Angular 1 front end. Go is appealing to me for what ISN'T there, and for the dependency-free static images I can build with it. It's got potential to be a great systems language, and something like Ansible built in Go would be a game-changer (agentless AND dependency free? yes, please). I don't think I'm alone in fearing that if the stewards of Go cave in and add what's "missing" that we will get something I'm happy to miss-- hordes of developers who reinvent the wheel every few months. I know you can get burned at the stake for saying it, but sometimes a little cut and paste code is actually more maintainable than a generic implementation buried in the bowels of a 5 GB class library. Especially if that class library is going to be rewritten in its entirety twice a year (with the documentation a full three development cycles behind, natch). Code reuse is an expensive myth. I've dipped a toe into Go development, and I like it. But what makes Go appealing for me is its simplicity. This is in large part what distinguishes it from the alternatives, and if they aren't very careful about the path they take going forward they can lose that distinction. Rust has the "multi-paradigm everything included compiled language" front covered. I'd be very happy for Go to stay in the (very nice, very useful) niche it has carved out for itself. I know language versioned environments and the move towards running things in containers mitigate my complaints to some extent, but the bottom line is that the tools are orders of magnitude more complex than the applications that are being built with them, and it's hard for me to believe all this complexity is paying its freight. A long time ago I worked as an intern for a company that was doing research and development for a robot. Toward the end of the year one of the managers took us out on the test room floor to look at the bin of parts that didn't work out for various reasons. He asked us to think about the value of all the time and effort that went into building that scrap pile. He encouraged us to be very careful about what we sent to the machine shop to build. Someone should make (and I'm sure someone has) a list of all the deprecated "web stack" components and their associated lifespans. Seeing it all in one place might give us some things to think about. Go doesn't need to get caught up in the hype cycle, and much of the criticism seems to be focused on pulling it into the mix of hot web technologies. A little defensiveness is probably appropriate if you take agree with the expressed intent of the folks who designed the language. &amp;#x200B;
Interesting read. Thank you!
&gt;Also, sometimes I feel like critics perceive Gophers as being hostile when the critics' concerns aren't taken as seriously as they feel like they should be. Like, "how dare you say that nil pointers aren't a critical failure of language design?!?!!" This is pretty much it. Go seems to attract pragmatists. All of the Gophers I've met use other languages, Go is just the first choice for their projects unless some constraint or requirement makes it much easier in another language. The answer to 99.99% of all posts in the nature of OP is that the compromises Go made line up with what they currently need.
[removed]
[removed]
Thanks for this! I currently have the task of creating a struct from a really long and convoluted XML, and it was being a very tedious task. I will give your tool a try. 
Could you give me some code examples? I'd love to see
Here is how I would approach this problem: remove all lines other than the correct line, test and it should pass, then add the other lines back until you find the offending line. Then, make a test with just the correct and the offending line, this makes your bug much easier to find.
This is awesome! Thanks! You wouldn't happen to have a CLI tool available that does the same thing?
Interestingly my office's internet blocks your domain for "Unknown Reasons"
If I remember correctly you need to take into account spaces in your frequency counts. Check out https://github.com/averagesecurityguy/cryptopals/blob/master/cryptopals-1-4.go And https://github.com/asggo/cryptanalysis/blob/master/analysis.go
Very neat that you implemented Bitmap, Map, List beside plain key-values. A really important feature for many is the ability to iterate through keys/value pairs in a given range. This is useful for searching for groups (date range, user props, etc...) &gt; FROM comment:2018-10-20 TO comment:2018-10-24 
In altering the code to meet up with what xiego said I did also add in the space, but its still not quite meeting it :(
Most linear algebra work on modern computers with von Neumann architectures is done with BLAS of some sort. In Go, [gonum](https://gonum.org/v1/gonum) implements ALL of BLAS. If you want to build artificial neural networks, [gorgonia](https://gorgonia.org/gorgonia) is a good library that comes with support for automatic and symbolic differentiation - relieving you of the need to do so yourself.
As an aside, I found a really [interesting article](https://www.kylehq.com/2017/05/golang-templates---what-i-missed/) about using a [custom yield function](https://gitlab.com/snippets/1662623) + glob file walking to prevent templates with the same name from being overwritten.
Awesome! Since you seem to really know this stuff, my project is basically to do a form of visual recognition: my prof has given us a series of images which include a cardboard box, and we need to recognize if there is a cardboard box present or not within the photo. 
This is dope. Going to start using this.
I understand the best practice of returning error instead of panic() or Fatalf() in a library. I make some "opinionated" decision to call Fatalf() for those unrecoverable errors like cert file is missing since the designed use case is for a console interactive tool like rake or make. I did a count, there were 4 Fatalf() call. 2 of them are in the sample code or test code. 2 are in the library calls, which are those non recoverable errors... Thanks for your feedback. 
Also https://github.com/miku/zek
I love this. I want to do more multistage builds, but I'm often afraid to do so because I don't know which files are created or required. 
[removed]
Honestly, this very much goes against Go conventions. Promises are difficult to read and reason with and often result in buggy code.
this is way more interesting that I thought it will be. I am interested in the source and the performance of the rendering as well.
Thanks for the well written reply. I very much appreciate it. I took a stab at undoing some of the code I recently wrote with this anti-pattern. The necessary changes weren‚Äôt quite as bad as I thought it might be, even when factoring in the unit tests. This new way of thinking will take a bit of getting used to though. Go has forced me to rethink a lot of the things that years of OO programming has burned into my brain. I would say the jury is still out on if I think Go is actually more fun to work with. 
[removed]
Ron?
I‚Äôm pretty excited about wire. It has the DI features without the magic. It's been nice to generate the glue code instead of hand rolling it every time (and screwing it up).
I could see this as an interesting learning exercise coming from node.js. I'd love to see the same functionality expressed using go conventions as a contrast that may help people making the leap from node to go.
You don't have to implement "promises" in Go, because promises are a solution to the problem that single-threaded languages can't thread, so they have to implement an [inner platform](https://en.wikipedia.org/wiki/Inner-platform_effect) that can do threading. Go can thread. You don't need to layer handling promises on top of Go, because Go already does those things natively. Idiomatic uses of channels can do everything promises do, and more, and more clearly. It may sometimes take two channels, or a channel and a context.Context for cancellation, but it's still better. Don't use promises in Go.
This may interest you: https://medium.com/@mdlayher/network-protocol-breakdown-ndp-and-go-3dc2900b1c20
Rust object notation. Very similar to json but fixes some ambiguities and allows comments. 
Built by someone on the team :) &amp;#x200B; There's no affiliation with Google or Google Chrome
It's probably more common to use the standard library mux than you think. You just don't see it, because it's in applications you can't see. All my green-field web server projects use the standard mux, because either it's just too simple to bother with anything else, or because staying limited to what the default mux does isn't a bad idea. (In a way, if you're using "all" the features of a complicated mux, you've probably overcomplicated your API.) The exception is if I have to fit into some pre-defined URL scheme for which the default mux just doesn't cut it. There are some tricks that make the default mux a bit more powerful than meets the eye, in particular that all muxes are also handlers. You can create a mux for "/user", which dispatches to another mux that defines all the user routing, which then also has a middleware http.Handler wrapped around it to validate permissions for the entire /user tree in one shot. It still doesn't do everything the competition does, but more can be expressed by the standard mux if you use it properly than you may initially think.
how does it fare compared to rg-grep?
Ouch! But I actually agree with that, sadly. 
Thanks everyone! Finally I decided to develop distributed filesystem as my project :)
Thanks for your comment! I‚Äôll add this feature to my todo list. I believe that it will be interesting to implement. 
Generics is feature of a pre-processors. Generics can be added without any changes in language and compiler core (excluding go/ast, go/parser, etc, etc packages). Just an add-on.
Yes and I agree that wire isn't preventing bugs. Just saving some typing.
This is awesome. Just submitted two PRs.
Just as a quick aside, here is a short video on how to turn serial matrix multiplication into concurrent code by applying a few trivial changes: [AppliedGo Quick Bits 006: goroutines](https://youtu.be/vyYPU9UE-OI?list=PLziDvf7ydaamzllb3ezcNYYsX9UHDjs_y) Bottom line: matrix operations are a quite natural fit for concurrency.
&gt; you seem to really know this stuff /u/chewxy is the author of Gorgonia :-)
I was looking for this a few days ago. Thanks!
&gt; language quirks [many of them](http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/)
Expanding on what's already been said- If you are hoping to write code from scratch in go that approaches the performance of e.g. numpy, it's not going to happen. For any of the expensive operations, Python is mostly structuring and passing data back and forth from BLAS, LAPACK, CUDA, etc- which have had many many people working on them for a very long time. The first portion of BLAS was released in 1979, for example. Go is also operating with some restrictions that these libraries in C, FORTRAN et al don't have- garbage collection, for one, along with bounds checking, a much less optimizing compiler, a runtime looking for deadlocks and race conditions, and more. That said, if you can do those kinds of things outside of go, it can be helpful for specific cases. I've yet to find an instance with go where it was easier to develop a machine learning model than in Python, though- go takes significantly longer to write the same code and a large part of that is, frankly, boilerplate and having to reimplement small things that, although small on their own, add up to a significant amount of reinventing the wheel. For the most part, you're always going to be spending more time writing the code than running it. I would highly recommend sticking with Python for your class. It will certainly be sufficient, and you'll have a much more mature, flexible ecosystem of libraries and tools that will make experimenting much easier. The models I've had great success with go for were ones that had non-trivial parallelism or required iterating over multiple loops with logic and calculations that were inherently serial, like Gibbs sampling for a topic model or a graph problem, finding the max path with multiplicative weights to all other vertices within k steps from multiple sources on a graph of several million vertices.
nope. that looks weird as hell to me...
This is the expected output from the code. It'll basically just output the raw data to stdout. If you look on page 15, you should see how they use it. Which is: &gt; go build gopl.io/ch1/lissajous &gt; ./lissajous &gt;out.gif doing the &gt; out.gif will toss that raw data into a out.gif file. should be fine with doing `go run main.go &gt; out.gif`
That makes sense thank you
Great tool, thanks a lot! It's quite tiresome to use zek since it's necessary to save the data to a file.. If you accept feature requests then I would love if you supported loading XML input from URL (since it's not possibe to ctrl-a the XML output).
Docker is not only a packaging system as it provides also resources constraints, some level of isolations (process, network, ...). On top of that, since docker is a standard interface, you can do things such as orchestration.
I'd also add: - filesystem isolation + "goodies" (volumes, e.g. pre-defined tmpfs mounts via docker-compose.yml) - build caching (esp. with multi-stage builds) - distribution (repository/tags) Also, it's still possible (though of course not good) to have global environment dependencies with a single binary - e.g. paths ("my config must be at /opt/myapp/config.json") or ports ("i must run on port 8231") or users ("i must run as myappuser, with uid 1231"). In this case you can wrap it with Docker to e.g. run multiple instances on one host, or to spare yourself the "host-setup" hacks.
Depending on your application, Docker can also still help with dependency chains. The application I'm working on needs jsonenums and go-bindata for building, and then thanks to multi-stage builds it allows the final build to be tiny and not need those tools installed in the prod image. Docker also provides the ability for me to run in the second environment on any OS. 
So, lets say you have an instagram bot that relies on a go client and a central postgres database for keyword/tag/image collection. What would be the easier solution, build the multi-account feature into the bot or isolate the bot into a clean environment that can be configured by setting environment variables? I like the second approach much more. Every container lives on its own. No matter if you do it through swarm or docker-compose, you can a complete set of features that a simple system.d service would require some work: restart-on-failure, separated logfiles, isolated system resources, ability to spawn and configure processes and keep a minimal implementation. Its much easier to spawn 1000 instagram bots then setting up 1000 system.d controlled clients.
"Why do they put the warning at the end?"
On production it is mainly for security and HA (deployment, migrations). On development it is mainly for automated builds and testing (clean environment) and security (isolation from builder OS).
Cool !!!
Don‚Äôt return a slice of reflect.Values. Your users shouldn‚Äôt know or care about the reflect package. 
Nice exercise, looking forward to seeing the final version! :-) I'm not sure if you are aware of it, but using the MapBox API in this way is actually in violation with their terms of service...
You can use the [BashOperator in Airflow](https://github.com/apache/incubator-airflow/blob/f5e3b03aa6b902898148e88fb9d90ecebcadc226/docs/howto/operator.rst#bashoperator) to run your Go workflow steps. It's a feasible way to include your workflow step into Airflow. This [SO answer](https://stackoverflow.com/questions/40146934/how-to-run-bash-script-file-in-airflow) might be more helpful as to how you do that.
Because "Fuck you, we're Apple, that's why!" Standards aren't really Apple's thing. Apple was built on one founding principal: NIH syndrome.
Docker solves a lot of problems for go services. I run a project that uses Go based microservices. I have a cluster of 3 servers that run redundant copies of about 30 distinct services (about 60 containers after redundancy). Each container has only the Go binaries and the SSL Certs package so it can establish https connections. Docker takes care of provisioning my services onto the hosts then networking the containers together, so I don't have to worry about where each one is running. I can upgrade my hosts by adding a new host to my docker cluster, then shutting down an old one. Docker will move the containers to the new host, and thanks to the redundancy I never have downtime. I can upgrade my containers similarly. I just start a new version of the container, then shut down the old one. Maybe it was on the same host, maybe not. I don't have to care. I can also scale my host cluster up, increase the number of instances of a given service, and increase the throughput of my services. Lastly, sometimes a service gets into a weird state. Rather than worrying about recovering, I just have my services panic and terminate. Docker restarts the service after it dies, the initialization process takes care of those state issues, and we're back up and running without any complex recovery process. 
Do you use Docker swarm mode?
Whoops... That is actually something I didn't know! :-/
I appreciate your honesty and input! 
&gt; For some reason the if !unicode.IsPrint line was rejecting it Well, the newline at the end of the string (`"Now that the party is jumping\n"`) isn't printable: https://play.golang.org/p/jOktRSTMMkP 
even if you consider deploying the binaries to normal machines (other people have already given many arguments why docker in prod can also be useful) then at least building the binaries inside reproducable environments should sound alluring to you
Great lib, and the code looks extraordinary clean :) Maybe some stuff I would change would be: 1) Not to commit vendor folder. Vendor packages can be retrieved using dep ensure (Gopkg.lock helps with version locking) 2) When importing your own packages you should use relative path instead of absolute ("github.com/namreg/godown/internal/api" -&gt; "internal/api"). This might mess up if someone would use your as a library (not this code, but any code you write) and uses GOPATH. Go searches for multiple places in GOPATH for the library and the same project might end up using different code (from different version of the same library) :)
\m/
Cool stuff.
It's also much easier to hit a rate limit with 1000 instagram bots. *: Bad example because instagram doesn't have a public api anymore
\&gt; Something like [this](https://github.com/katzien/go-structure-examples/tree/master/domain-hex) really useful! However, I don't understand why the Beer and Review structs are redeclared so many times. Couldn't you just have two declarations for each struct: one for internal use of the storage, and the other for client exposal? 
It still provides a number of benefits: 1) segmentation from the outer system - you can run the go app without it having access to the entire filesystem 2) repeatability - you can run a go app in production in the exact same way you'd run a python or Ruby app. Go is easy to run, but not everything is. There's a benefit to being able to run any app in the exact same way.
- packaging dependencies or configuration with your application - orchestrating deployment using something like kubernetes
Sometimes you just don't have a choice. At work we use a tool with lots and lots of data, and it supports xml and json as input, but outputs only xml data. So i end up parsing XML all the time, although i really don't want to. 
OK, I get that. But you could do that with, say, Ansible and set up a VM for each instance. What does containerisation bring to the party here?
Thank you, I was looking for comments like this.
ok, that makes sense. So I can run a stripped-down OS as my target environment if I use Docker, and test using that container on localhost, knowing that it'll be identical in prod. That's something I couldn't do otherwise. thanks
If you‚Äôre making a cross-platform game engine with sufficient budget, you‚Äôd likely create your own custom rendering API and implement it using Vulkan on Linux, D3D12 on Windows, and Metal on macOS. Having different very low overhead APIs that target their underlying platform‚Äôs hardware isn‚Äôt a completely bad idea. End users aren‚Äôt expected to consume them directly.
I need to do something similar, which go bot do you use? 
I use makefile at the moment to manage building everything. I develop and deploy on the same version of Linux. But I get your point. If I had a larger team with a disparate set of development environments, then a single docker image everyone could use to test would be useful. Thanks.
Yeah, I get that microservices architecture needs something like Docker to manage all the services. That will be useful when I start breaking services out of the monolith at some future point. Thanks
&gt; what's the advantage of running docker images as containers vs running complete VMs? Docker containers use fewer resources and are quicker to start/restart. But it definitely sounds like for your project Docker does not bring a whole lot to the table, and if it is easier for you to handle deploy and orchestration without it then you should probably stick to what has been working so far.
hehe, ahh a fellow cynic ;) Yeah I've waited until the hype calmed down about it to start looking at it. Serious people who's opinions I respect are still using it even after the hype, so I figure there must be something there that adds some benefit, even if I struggle to see it.
This means, on long time WebGL won't be supported on MacOS machines, that's for sure.
Would start with https://github.com/ahmdrz/goinsta and go from there. Has some loose ends, you might need to fix one or two things, but worked (and might still work) but it was a good base package to get started.
There's a ton of tutorials about how to write a webserver in Go out there. Up to you whether you prefer video or written, or whatever, but you'll find a lot of them. Node doesn't really have a standard library (well, it does, but.. it's complicated), so people coming to Go for the first time from JS (and Rails, PHP and Python to be honest) expect their main tools to be 3rd-party libraries and frameworks. Go has an awesome standard library, so Gophers tend not to use 3rd party tools unless we have to. I used to write servers in Express, and net/http is about as simple as that. Give it a go. Write a webserver using just the standard library and see how it feels. You'll have the usual struggles with the language, but I guarantee when you get that first webserver up and running in a few hours using just the basic net/http library, you'll go "wow... that's amazing". It really is simple, easy, and stupidly fast compared to JS.
I'm working on a project that will allow people to 'attach' files to something they are working on by emailing files to a unique one-off email address associated with the item then are sending. This looks like it could be a great way to implement that cleanly. Thanks! &amp;#x200B;
&gt; Docker containers use fewer resources and are quicker to start/restart. Citation needed. 
Yes, and if you‚Äôre using Kubernetes in production (or Docker Swarm too) the Docker images you‚Äôre building to test locally will be the same environment on production as ind dev. That is immensely helpful for ensuring things work on production as they worked in dev. 
One thing I didn‚Äôt see anybody else mention is that usually your single go binary is not the only output of your dev team. In addition to your binary, you probably need caching, database, etc. Even more in addition to that, I‚Äôm a huge fan of ‚Äúthe right tool for the right job‚Äù. That means we also have things running in PHP, Perl, Python and Node. There‚Äôs something to be said for consistency - if everything is on containers, the logistics are much simpler for everyone involved, including the ops team, onboarding new devs or switching teams. You don‚Äôt have to remember which ones are in containers and which ones aren‚Äôt and how to deploy a new server for the only project that isn‚Äôt.
Tangential, but why do Go graphics APIs (OpenGL, Vulkan, etc) have to go through CGo? Is there a lot of complicated logic in the C bindings that would be infeasible to port/maintain? Is there something fundamentally low-level that can't easily be reproduced in Go, even with asm?
\&gt; I wrote a robot in C# , not a smart move, &amp;#x200B; why not? &amp;#x200B; \&gt; Is it a smart move to start straight from goBot? &amp;#x200B; What are you trying to do exactly? Control your 3d printers? 
What are you hoping to achieve with this comment? Is it a feeling you‚Äôd share face-to-face with an Apple engineer who worked hard on that Metal API? If the engineer explained why they had to build their own API, do you think their explanation would simply be ‚Äúfuck you‚Äù? Or might they have some really solid reasoning behind their decisions? Perhaps one way to effect change is to welcome people with their APIs and platforms into the Go community, even if the design decisions behind their creation aren‚Äôt clear to you. 
For choice of framework vs straight net/http, I'd say just use a framework. I've had a lot of luck with Negroni: it provides a base system for writing http middlewares and your endpoint handlers are standard http.HandlerFunc's. it's easy to bring external modules like gorilla/mux (better url routing) and gorilla/sessions (tamper resistant session cookies) to build out exactly what you need. I've wasted many hours trying to drink the Go net/http Kool aid. You can write your own stuff with bare net/http but you'll end up programming your own custom router (if you need path parameters), your own custom middlewares to do sessions and parsing json inputs... All the while wiring up your own framework to make your code halfway sane. In Node you can write a raw http server, too, but it's an uphill battle. Use net/http if you want to learn about very low level http. Use a framework if the goal is to actually produce an app. Tip: for keeping to standard http.HandlerFunc: if you need other resources like a DB connection, make your HandlerFunc a method on a struct where you keep those things. `func (a *MyApp) LoginHandler(w http.ResponseWriter, r *http.Request)`
I didnt find any good package for it in C#, And i am trying to build a walking Robot (via sensors )
This is an interesting idea.
Thanks
If you're only running one webserver (i.e., a single processor on a single host--as opposed to a single webserver \_service\_ running on N hosts) then you're not going to benefit as much from Docker. In my opinion, Docker makes deployment quite a lot nicer since it's just a single artifact as opposed to the binary, static assets, supervisor scripts/config, environment variables, etc. But if you have solutions to these problems already, then it's likely not going to pay dividends until you start to need scale (either scaling a single service or scaling several services and you just want one relatively straightforward way to build/deploy/run them all with zero downtime).
Be it a docker or openshift container, it's getting increasingly easy to deploy containers as opposed to executeables. Especially if your setup is already configured for it, due to other services from other languages.
Right; the real value of Docker is the orchestration tools that are built on top of it. &amp;#x200B;
Maintaining a VM is more upkeep. If you're already using Ansible, perhaps its within acceptable limits, perhaps it's not. There's some pros/cons to each approach, the end result most likely depending on the fervor of your developers.
I've installed docker but I don't really know what it's for, so I understand the concept of containers, everything in one place, easy to manage.. but if I develop something and want to put it out for production how does docker help with that? Is there an ELI5 for docker?
In a microservices hell atm. I use Docker to help my group to spawn all of the services inside Docker for development purposes. And then I take the same image, tag it properly, and deploy them in prod. No more, but but but they all work in my laptop.
I don't blame the engineers who made it, I blame the asshole who saw a perfectly good, open source, platform neutral library and said "No, fuck it, I want our own." I would gladly say that to their face. That's a dickish thing to do. There's no magical reason why Metal needed to be written. It's textbook NIH syndrome, and Apple are known for it. Wouldn't be so bad if it didn't hurt developers.
I've done a few minutes of digging, and I think I have the answer. You'll notice that the problem arises whenever home is parsed before layout. This is because of how the "block" action works. From the [text/template docs](https://godoc.org/text/template): {{block "name" pipeline}} T1 {{end}} A block is shorthand for defining a template {{define "name"}} T1 {{end}} and then executing it in place {{template "name" pipeline}} The key is that, in the definition of layout, the "block" action defines a template named home. In the bad cases, this overwrites your intended definition of home. In the good cases, this happens before your intended definition, so your intended definition overwrites the other one. You can solve this problem by, of course, always parsing layout before home, or by removing the default content. ([playground](https://play.golang.org/p/Ah77SWqI583)) There may be another way to conditionally render "default" if the "home" template isn't already defined, but I'll leave that to you since I've already spent a bit of work time on this. ;)
You are aware metal predates Vulkan, right?
Interesting, so empty blocks (or templates?) won't overwrite other populated blocks with the same name. ``` {{block "home" .}}{{end}} vs {{block "home" .}}valuehere{{end}} ```
&gt;Traefic &amp;#x200B; Should be Traefik
At my work, we use docker for tests in the cloud (continuous-whatever), then copy the binary out and deploy that. So it‚Äôs great for everything before deploy, then not necessarily needed for deploying and running :) There is perhaps a consistency advantage, so you don‚Äôt have to build a binary specific for your server env (like GOOS=linux), which is nice.
Oh I didn't think to keep reading but once I did I ended up finding it. Still doesn't work for me. Is it supposed to run in the terminal? Or in a separate window? Thanks for helping btw
Linux windows and macos have the same underlying hardware.
Yeah, you're right... I missed that the context was docker vs VMs not docker vs binary. :)
lol. OpenGL was a shit show for decades. You could make OpenGL fast but it was very much a headache, you to know the magic incantations and prey that you didn‚Äôt release a buggy piece of shit because everyone had a totally different buggy api layer. Also nobody liked OpenGL, the vendors hate it because it has no relation to the real hardware architecture and is a colossal work of engineering, which frankly no one really wanted to use. And DX11 was eating OpenGLs lunch on the dev side as well, since it‚Äôs 10x as nice to use. A replacement was due but Kronos was too mired in politics to do shut until Apple forced their hand. 
This is exactly how I‚Äôd word this too. It might be best to try out net/http first then give a framework a go. I worked a lot with express, I used it so much that I eventually built express-vue, but the big difference between node and go is that go has almost everything you need in the standard library. so why use the standard lib over a library. Well it‚Äôs up to you. Libraries have more nuanced features for specific use cases, or tooling that you might want. But the standard library has almost everything you‚Äôll need... and it‚Äôs suuuuuuper fast. Also another recommendation for libraries. Would be Attach√©. https://github.com/attache/attache 
There still is a thing that I haven't find yet a way to implement well using Docker. When using systemd we are able to create a socket that a Go application can serve, instead of listen and serve, because the systemd socket is listening for your application and it creates a connection queue, it means if your application break and "restart" for any reason your server does not go down. &amp;#x200B; If I place a load balance in front of the containers it will try to communicate with the applications listening will the port be connectable for the load balance TCP health check but the application will not be ready to serve. At least it is what I have experienced.
I would recommend to try use just the systemd with socket activation.
How do I reproduce it?
I'm writing a small web app in go, and last night I docketed the build process using a multistage build. The first stage is the build process, starting from golang-alpine. I install necessary packages for the build, `go mod download` for my dependencies, then build the app itself. The second stage is the actual app itself from the basic alpine image (which is only 5MB to start). I copy the resulting executable from the first layer, open necessary ports and declare volumes, set an entry point. There are a couple main benefits from doing this: * The resulting deliverable is an image that's only 25ish MB, which effectively includes the "VM" itself (it's not a VM, but from the container it has its own process list, devices, mounts, filesystem, etc.) * I can upload the image to (say) docker hub, and anyone can download and run it. * I can give anyone a link to my repo and they can repeat the build process themselves, very easily. They don't even need go installed, just docker * I can deploy this container through Kubernetes or another orchestration. A lot of this isn't particular to Go, but they are still benefits
Docker is a fancy `chroot`. Of course a process uses less resources than a kernel.
Yup, empty templates can be defined, but they don't overwrite populated templates. This is described in the [docs for the Parse method](https://godoc.org/text/template#Template.Parse): &gt; Templates can be redefined in successive calls to Parse. A template definition with a body containing only white space and comments is considered empty and will not replace an existing template's body.
The graphics API is just that, it's an interface, so there's no real code behind it, the reason you have to use Cgo is purely that the interface is a C interface, so expects to talk the way C does. In practice the whole graphics API is implemented in C/C++ and is bundled with your graphics driver, which varies based on what GPU and OS you have, so there's not one single codebase for you to reimplement in Go - you'd have to reimplement every graphics driver in Go if you wanted to avoid ever crossing a Go-C boundary. When you compile code that uses, say, OpenGL, there's not really any OpenGL 'code' in your binary: at program startup the init code contacts the graphics driver which hands it a bunch function pointers to its implementation of OpenGL. 
Also, things that only work in Linux, like tensorflow for go, or that are a pain in the ass, like installing Qt, are made possible by running them in go. It‚Äôs not necessary, but sometimes I‚Äôll put my entire build process in docker so that I can use the same procedure in my CI pipeline. Also saves from downloading all the protoc/swagger tools... node et al usually. Also docker is written in go. Also they are #1 and #2 on my list for the most amazing software tools in recent history. 
This isn't really an argument for Docker, this is an argument for service orchestration. None of these are Docker-specific, and, in fact, none of these are even built into Docker at all. Most orchestration systems (Mesos/Marathon, ECS, Kubernetes, etc. (support orchestrating Docker containers because they're a popular way of packaging services, but you can also use lots of those systems without Docker as well.
Ah, that makes sense. How disappointed should I be then? It sounds like it will always be a C-API, which implies that it will always require CGo and thus always be unnecessarily slow, but is this performance cost prohibitive for some set of applications (e.g., high-end games)?
it shouldn't output anything in console, it'll just create that out.gif
For me, its because it becomes trivial to build your Dockerfile "from scratch". My last application I wrote was a 5MB container, that started nearly instantly, from scratch. My Dockerfile is only 5 lines of code too. Go was built for containers as well. Review the 12 factor app principles and see how many GoLang solves for natively.
mux gives you kind of like express feeling
Nothing shows up when I run the command, no errors either. I'm also having problems with the server examples to work correctly. Really curious about what I'm doing wrong.
Interestingly, with AWS Lambda, [you just deploy](https://docs.aws.amazon.com/lambda/latest/dg/lambda-go-how-to-create-deployment-package.html) your binary executable in a zip. So, I think in some cases you are right.
\`\`\` go get -v [go.opencensus.io/exporter/jaeger](https://go.opencensus.io/exporter/jaeger) go get -u -v all \`\`\`
I shouldn't think it would be too bad, Cgo performance has improved over time. There's already inherently a certain amount of overhead to each API call where the driver has to verify what you're doing makes sense and is correct, and because of that they develop API calls that let you get more done in one batch (eg instead of making N function calls to render a model N times, you could make 1 function call and give it a list of N positions to put the model). If function call overhead were to end up a problem for you, you could use that same strategy to reduce the number of calls out to C and get same work done. 
I would say just to streamline the way you do things... If you're doing it for Rails, Python, etc, then just do it for Go as well since now you have one less thing to think about. Also, if you'd like to deploy like it's not 2005 anymore then it's kinda crazy how much nicer it is to deploy Docker containers.
Looking back, I would add one thing- I would also highly recommend (on your own time!) trying to implement a few models of different kinds in go and Python. It can be very instructive to see the differences in approach needed between languages with different style and the contrast will make the benefits and drawbacks of each much clearer. Specifically, Python can end up hiding much of the implementation details through abstraction, and go can force you to write the code in a way that exposes that- which can make the mechanics much clearer. Consequently, the go code is typically going to have much more in the way of bookkeeping and more mundane code, which can obscure (or just take time away from) the higher level processes, and the benefits of python's higher level abstractions can be more obvious. Either way, it will make you a better programmer and the lessons you learn from each will transfer. Go is a great language, but it's opinionated- and taking many clear stands in the design of a language can heavily shape the kinds of things that are expressive. And lastly, as an aside, you may find Cython interesting and helpful in cases where implementing the entire thing in another language isn't a good option but python is struggling with particular pieces. 
It'd be a new file. Nothing will print to console. I was able to get it to work by doing this: &gt; copy the contents of https://raw.githubusercontent.com/adonovan/gopl.io/master/ch1/lissajous/main.go &gt; go to console, and type `pbpaste &gt; test.go` (it'll create a new file, test.go) &gt; `go run test.go &gt; out.gif` (it'll create a new file out.gif) view that folder in finder, should see the out.gif
Oh whoops haha of course thank you
Cool, but note that the content you paste in is sent to their server -- so if you have anything sensitive, might want to do it locally instead.
i went to business school. spend your money on something more useful like chocolate or video games.
I was similarly OO-minded when I first tried go and struggled with code organisation and really using the language for anything other than a toy. Now I've come back to it and feel a lot more comfortable with how interfaces work and when to use them. 
I've been leaning towards pointers too, purely to avoid the copying. Is there anything I should be watching out for?
&gt; Your tone is angry and passive-aggressive at best. After getting his post removed twice that's kind of understandable, don't you think?
Yep. It does load balancing out of the box. No config needed. The service will pass traffic to whatever pod assigned to it when that pod is ready to receive it. 
channels are thread safe queues. I assume they are array back but I don't actually know that. &amp;#x200B;
Seems like RSON :) https://github.com/rson-rs/rson/blob/master/README.md (Or the other way around?)
Thanks! :) I will try to upload a binary for macOSX on next release.
I've submitted some example as a feedback / "experience report" for the Go2 draft before ‚Äî I think it more or less fits my comment above, so I'll let myself just link to it here: ["Converting a fragment of real code with error handling to Go 2 'design draft'"](https://gist.github.com/akavel/62d90bdc43088574c638eb3b16301a92)
Yeah thanks for the new information R-tard!
This is what I was looking for, thanks
Use a Mutex, or use a channel
Welcome! There's no turning back now.
\&gt; append + slice off the front will leak memory Eventually an append() reaches cap, and reallocates, releasing the old slice and anything it was holding.
Its like C on steroids. :-)
Odd can't reproduce it. ‚ûú ocs go get -v go.opencensus.io/exporter/jaeger go get -u -v all go: extracting git.apache.org/thrift.git v0.0.0-20181019115558-cd829a0b9a5c Fetching https://go.opencensus.io?go-get=1 Fetching https://go.opencensus.io/exporter/jaeger?go-get=1 go get -v: unrecognized import path "-v" (import path does not begin with hostname) go get get: unrecognized import path "get" (import path does not begin with hostname) go get -u: unrecognized import path "-u" (import path does not begin with hostname) Fetching https://golang.org/x/net?go-get=1 Fetching https://golang.org/x/sync?go-get=1 go get go: unrecognized import path "go" (import path does not begin with hostname) Fetching https://google.golang.org/api?go-get=1 Parsing meta tags from https://golang.org/x/net?go-get=1 (status code 200) get "golang.org/x/net": found meta tag get.metaImport{Prefix:"golang.org/x/net", VCS:"git", RepoRoot:"https://go.googlesource.com/net"} at https://golang.org/x/net?go-get=1 Parsing meta tags from https://golang.org/x/sync?go-get=1 (status code 200) get "golang.org/x/sync": found meta tag get.metaImport{Prefix:"golang.org/x/sync", VCS:"git", RepoRoot:"https://go.googlesource.com/sync"} at https://golang.org/x/sync?go-get=1 Parsing meta tags from https://google.golang.org/api?go-get=1 (status code 200) get "google.golang.org/api": found meta tag get.metaImport{Prefix:"google.golang.org/api", VCS:"git", RepoRoot:"https://code.googlesource.com/google-api-go-client"} at https://google.golang.org/api?go-get=1 Parsing meta tags from https://go.opencensus.io/exporter/jaeger?go-get=1 (status code 200) get "go.opencensus.io/exporter/jaeger": found meta tag get.metaImport{Prefix:"go.opencensus.io", VCS:"git", RepoRoot:"https://github.com/census-instrumentation/opencensus-go"} at https://go.opencensus.io/exporter/jaeger?go-get=1 get "go.opencensus.io/exporter/jaeger": verifying non-authoritative meta tag Fetching https://go.opencensus.io?go-get=1 Parsing meta tags from https://go.opencensus.io?go-get=1 (status code 200) get "go.opencensus.io": found meta tag get.metaImport{Prefix:"go.opencensus.io", VCS:"git", RepoRoot:"https://github.com/census-instrumentation/opencensus-go"} at https://go.opencensus.io?go-get=1 Parsing meta tags from https://go.opencensus.io?go-get=1 (status code 200) go: finding golang.org/x/net latest go: finding google.golang.org/api latest go: finding go.opencensus.io/exporter/jaeger latest Fetching https://go.opencensus.io/exporter?go-get=1 Parsing meta tags from https://go.opencensus.io/exporter?go-get=1 (status code 200) get "go.opencensus.io/exporter": found meta tag get.metaImport{Prefix:"go.opencensus.io", VCS:"git", RepoRoot:"https://github.com/census-instrumentation/opencensus-go"} at https://go.opencensus.io/exporter?go-get=1 get "go.opencensus.io/exporter": verifying non-authoritative meta tag go: finding go.opencensus.io/exporter latest go: finding git.apache.org/thrift.git latest go: finding golang.org/x/sync latest
You don't want docker. You MAY want orchestration, that usually happens to use docker. For orchestration, though, there are many reasons (not apply to all, etc.)
\&gt; The idea that you can compile to a single binary and do so much is amazing &amp;#x200B; It kind of illustrates how absurd some ecosystems have gotten that this idea is amazing. It should just be normal but it isn't! &amp;#x200B;
Containers are much, much more lightweight. Can start in 1 second instead of 30. 
Go is a programming language that runs as a program on an operating system. Docker provided you a container that serves as a container operating system that you can configure and reuse to make any future modifications across deployments easier. It can even make deployments for a single server easier because you can run containers locally. I.e. I run windows and I can configure a Linux container. I'm sure there's more but that's what I like.
There's also (if you take care to not undo it) a documentation benefit -- if your docker build is self-contained and minimally-indirect (e.g. no `curl`ed shell scripts being `RUN`), the Dockerfile (+build context) **precisely** and **verifiably** documents your dependencies! How do I know whether there really are _no_ dependencies beyond the single binary without looking at the source? By having the application's "official" Dockerfile contain nothing except the binary.
Think of Docker as a "universal server executable".
Good way to maintain consistency across environments if your go apps have any C bindings. Orchestration as others have mentioned.
It‚Äôs amazing isn‚Äôt it? I like go and c# a lot. For some reason, I could never get behind python. 
In `handleConn`, you defer `conn.Close()`, which runs when `handleConn` completes. You then run in a goroutine your scanner, but the original goroutine then continues on without waiting for that, exits `handleConn`, and runs through its defer stack, thus closing the connection. For what you have written here, the ideal solution is to get rid of the second `go` wrapper. What you want to do depends on more details, though you must certainly be careful; Go may be multithreaded, but TCP sockets are intrinsically serial.
Or using docker multi-stage builds with alpine and making a 20mb container, yes please.
Haha. The `Dockerfile` for these is far smaller than any dynamically typed language deployment.
Thanks for helping me, Jerf. I was following a tutorial and I realized that they were adding to a channel variable and iterating/ranging over it to keep the thread open. I was basically trying to recreate this source code from a tutorial - https://github.com/mycoralhealth/blockchain-tutorial/blob/master/networking/main.go I don't know enough about networking/multithreading to understand what you mean by TCP sockets are intrinsically serial. Any good reference for learning more about this?
Because Docker. It is just where the industry is going. Just let in happen. Build from scratch and there won‚Äôt be really much of a learning curve. 
20mb? Use [UPX](https://upx.github.io) and you'll probably reduce your container to 5mb!
Well the executable itself is 16mb, I've compiled all of my static assets into it instead of having them as files around it the executable.
This is the exact reason I fell I love with the language.
It only ever gets better, really. That's coming from an engineer working full time with Go for more than 4 years.
Look out for functions you call with a pointer to a struct sneakily changing the fields of the struct. Sometimes people do that and it's quite annoying to debug.
This also gives me the heeby-jeebies. Every time I hear someone say "I have a problem with using X ..." and hear the response "you're not doing it right, you need Y to manage X properly..." it makes me shudder. If a tool is so hard to use that it needs another tool to manage it's use, then something's not right.
good thoughts, thanks
Zero need for multi-stage, just build it FROM scratch.
And now that container can run ANYWHERE. ‚úÖ
Standardized interface regardless of language inside, port remapping, run the same artifact anywhere.
Be careful of falling into the trap of thinking that any __one__ language is perfect, and the best ever. That's something that seems common with junior developers, and people who know one/two/three languages. There are _many_ languages out there, and with their own pros, cons, and niches.. Learn go. Be happy. You'll not see complains here on /r/golang. 
&gt; Citation needed. That Docker uses fewer resources than a VM? I think you don‚Äôt understand how Docker works. Take a closer look. I misunderstood it at first too.
What‚Äôs the point of extracting the binary? Build your container FROM scratch...
&gt;Tip: for keeping to standard http.HandlerFunc: if you need other resources like a DB connection, make your HandlerFunc a method on a struct where you keep those things. &gt; &gt;func (a \*MyApp) LoginHandler(w http.ResponseWriter, r \*http.Request) Just be aware that Go calls handlers as goroutines, so that single struct will be shared between all the handlers responding to requests at that time. You can end up with some resource locks and race conditions really easily if you're not aware of this. It's one of the big differences coming from Node, because Node is single-threaded and only one piece of code is running at any one time.
ffgrep focused on speeding up "grep". It consumes one single file parallelly (read it at different offsets). Supporting regex pattern is a bonus feature.
Because you are opening a new connection with `sql.Open` in every HTTP request. You should call `sql.Open` only one time, in main, and pass `db` to the HTTP handlers. A better version of your code can be seen below _(I've removed error checks for simplicity)_: type Application struct { db *sql.DB } func main() { runtime.GOMAXPROCS(runtime.NumCPU()) r := mux.NewRouter() app := NewApp() r.HandleFunc("/clients/show/{id}", app.showClient).Methods("GET") http.ListenAndServe(":8080", r) } func NewApp() *Application { app := new(Application) db, err := sql.Open(‚Ä¶) app.db = db return app } func (app *Application) showClient(w http.ResponseWriter, r *http.Request) { err := app.db.QueryRow(‚Ä¶) }
Because you are opening a new connection with `sql.Open` in every HTTP request. You should call `sql.Open` only one time, in main, and pass `db` to the HTTP handlers. A better version of your code can be seen below _(I've removed error checks for simplicity)_: type Application struct { db *sql.DB } func main() { app := NewApp() r := mux.NewRouter() r.HandleFunc("/clients/show/{id}", app.showClient).Methods("GET") http.ListenAndServe(":8080", r) } func NewApp() *Application { db, err := sql.Open(‚Ä¶) return &amp;Application{db: db} } func (app *Application) showClient(w http.ResponseWriter, r *http.Request) { err := app.db.QueryRow(‚Ä¶) }
To be fair it is not that exciting. It has great concurrency support. But a ton of languages in the functional programming regime do this for decades now. Compiling to a single executable is done by a bunch of languages if you step just a bit outside the really interpreted popular ones. Rust is much more of a paradigm shift and at the same time is fun and easy to pick up. Google support though. 
It's not inherently wrong to have 1 connection per call. These connections are pooled and handled by driver. The issue is that there is still a limit of how many calls (connections to the database) can be handled by code and the database engine itself. The `db` package states that it's [unlimited](https://golang.org/pkg/database/sql/#DB.SetMaxOpenConns), however, my experience states differently. Also, most ORMs will have some value default against this - just in case something goes wrong. This is a pretty good [blog post](https://www.alexedwards.net/blog/configuring-sqldb) about this. [unix15e8](https://new.reddit.com/user/unix15e8) suggestion also works, however, database might end up closing connection from it's side, because (depending on server) there are default options how long connection is kept alive from server side.
True indeed, but on the other hand, if you had to decide for single language to use, I guess that for most of us Go would be it.
The actual go binary itself is the same size that you would expect. It's just `go build` at the end of the day, right? The extra size comes from the containerization, which has its own benefits and drawbacks. If you are building something for personal use, it's probably overkill. Most of the time, I'm not building with Docker, because the projects don't need it. Other tasks require a bit more, and docker's Infrastructure-As-Code is a huge boon.
&gt; but is it novel? Wrong question. Novelty is not a factor in judging the quality of a language. The concept of Javascript was novel back then, and look how flawed that concept is in many aspects. Sure, for each of Go's features there is another language that implements the same or a similar feature in some way. The point is which set of language features have been chosen from all possible language features, and how they were orchestrated together. Go is unique on that part. Go isn't perfect, but no language is. If you prefer Rust, that's fine. Everyone can choose their own favorite language. I bet there are even Gophers that also use Rust (and vice versa). 
&gt; go get -v go.opencensus.io/exporter/jaeger go get -u -v all If you're going to run it as one command, you need a semicolon in between those: `go get -v go.opencensus.io/exporter/jaeger; go get -u -v all` It's the update all after the fetch that throws a fatal error.
Be careful with "Go should have X" requests. One part of the languages success is that it *doesn't* incorporate each and every language feature on the planet. Sure, everyone of us has their pet language feature that is "badly" (?) missing in Go, but if all of them were implemented in Go, then Go would just be another C++ (read: a feature behemoth with a 1300+ pages specification). You would not be able to understand other people's code anymore because every programmer would use their own favourite set of obscure features that the language offers somewhere in their specs.
Python
Thanks for the suggestion. I've added a way to download XML from an URL, give it a try and let me know if there are problems.
[removed]
Glad to hear that, since i'm planing totally switching my main focus to Go, i enjoy working with GO lately, but so did i with Python, C, PHP, Node. But i feel kind different now
Yeah, I used UPX to build the production project and it's really useful..
Thankfully, I've never encountered anything other than x86_64 :)