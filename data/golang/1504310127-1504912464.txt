You can close the last gap by trusting the self signed cert in your client instead of ignoring it, like this: https://forfuncsake.github.io/post/2017/08/trust-extra-ca-cert-in-go-app/
This sounds really great, I wish there was a crystal version of this. How hard would it be to port this to crystal?
Is there a sample app or a writeup someplace that I can look at?
&gt;.Also you can integrate the gateway directly into your grpc server, it doesn't have to be rolled out in a separate binary Is there a sample app or a writeup someplace to do this? If you are going to deploy the gateway anyway why not use this tooling?
Sorry, I've meant to create one but never have. Essentially you tie together: - https://github.com/grpc-ecosystem/grpc-gateway - https://github.com/swagger-api/swagger-codegen - https://github.com/golang/protobuf Start with the grpc-gateway and use it to generate the grpc and a swager file, then use swagger-codegen to generate a TypeScript clent.
Release Notes: https://docs.aahframework.org/v0.8/release-notes.html
[removed]
&gt; What do you use to make sure you have different configs for different environments I keep different configs and/or I use [build tags](https://dave.cheney.net/2013/10/12/how-to-use-conditional-compilation-with-the-go-build-tool). They are part of the [standard tooling](https://golang.org/pkg/go/build/#hdr-Build_Constraints). For example check the [debug tag on this project](https://github.com/upspin/upspin/blob/master/errors/debug.go). You can do stuff like that to setup different environments. I also use build tags to guard my system/integration tests. &gt; and dynamically compiling and reloading your app while you develop? Personally nothing because Go compiles so fast that starting and stopping the app manually doesn't bother me. But I've heard people have great success with [gin](https://github.com/codegangsta/gin) and there are many others to choose from.
&gt;Personally nothing because Go compiles so fast that starting and stopping the app manually doesn't bother me. That seems insane to me. 
&gt; That seems insane to me. Then you should use a tool like [gin](https://github.com/codegangsta/gin).
Or you can use `println` that doesn't even need an import. :D But seriously, `Printf` is about formatting. Check the different ways you can print structs. foo := struct{ name string }{"foo"} fmt.Printf("%v\n", foo) fmt.Printf("%+v\n", foo) fmt.Printf("%#v\n", foo) fmt.Printf("foo is of type %T\n", foo) [Playground link](https://play.golang.org/p/sxT3ab1aEU)
`Printf` is for printing `f`formatted strings. Such as `fmt.Printf("%X", 0xFF)` with print a number in hex. And it can lead to more readable printing `fmt.Printf("(%d/%d) operations on %s succeeded", successes, failures, ops)`. I fully listing of formatters is available in the [`fmt` godoc.](https://golang.org/pkg/fmt/#hdr-Printing) There are related functions for printing to strings and files in general.
Umm what? package main import ( "fmt" ) func main() { num := 3 fmt.Printf("I have %d apples\n", num) } https://play.golang.org/p/Hi6rXaNGZI The f in printf stands for formatted. It can print any variable type.
Anyone using this? How is it?
For anything running Linux/BSD/Windows/Solaris, yes. And the article is about Go, so one of those is a given.
/u/netzdamon Thank you for your interest. I'm the author of aah framework. So far I'm receiving good feedback and suggestions. Please go through: Features: https://aahframework.org/features.html Documentation: https://docs.aahframework.org Give it try and share your feedback. If you have any questions; please reach out via gitter or github.
I always use `Printf()` because it is faster/more efficient in the most common case where you just want to print a string. This is because the first argument is a `string` instead of an `interface{}` so the fast path doesn't require a `reflect.TypeOf()` etc. to print. It just prints the string.
Isn't this implementation 100% faster rather than 50%
This DTO pattern comes from a different language ecosystem. In Java you might really need it. Not so much in Go. I mean yeah sure you can use it but then you go and mess with the dark arts of reflection to write a generic mapper. And all this because you are trying to force a Java pattern in Go. But why? Compared to Java where an object needs its own class on its own file with a bunch of useless setters and getters which you need your IDE to generate for you, in Go structs are small, compact and cheap.
- crystal doesn't thread, microthread ~~or coroutine~~ - elixir is functional paradigm - it's a cool idea to add parallelism and channels to ruby-inspired language disclaimer: I could be wrong, haven't checked status of crystal for a while and shame on y'all for downvoting OP.
False efficiency and potentially a bug. If you have ``` var s string = f() fmt.Printf(s) ``` or even just ``` fmt.Printf(f()) ``` the result will be incorrect and ugly if the string contains an unexpected percent sign. Use ``` fmt.Printf("%s", s) ``` or ``` fmt.Print(s) ``` because that's what it's for. By the way, the fast path for that doesn't use reflection either. You're doing premature optimization, the root of all bad /r/ posts.
Oh, there are many many more reasons for bad posts than that.
I wanted be generous, but the true is that on average this gain can be even more than 100%. Loading first time in the browser the JS version is more than 100% slower, but after a few reload this drop to around 50%. 
Interesting. I didn't think I was getting the whole picture in my definitions. That helps a lot. Thanks.
What's wrong with go's gRPC? It haven't run into any problems yet
I completely agree. Forcing patterns that are mostly for Java/C# can be counterproductive in Go quite often, and I have been debating whether Go is actually making design patterns language dependent since Go provides a lot of mechanisms that reduce over-engineered design patterns that are mostly for Java/C#.
The point of the post was to compare sizes, not performance. But as you point out, the gzipped proto was missing so I updated the post with gzipped proto as well. Regarding size, it seems like protobuf is smaller both in "raw format" and in gzipped format when comparing to json.
Do you? 0 is a valid index.
Well the new slice you reference doesn't really start **at** the end, it's **after** the end of the initial slice, which I don't find intuitive at all.
That's actually the subject of the next article. Thank you!
&gt; I have been debating whether Go is actually making design patterns language dependent You could say that's [more or less true](https://www.youtube.com/watch?v=zzAdEt3xZ1M).
Do you have any apps in production on this framework? I'm sure a lot of hard work went into creating this, but it feels massive to me (like most Go web frameworks). Do you mind if I ask why you would recommend your framework over a vanilla Go setup?
Go has a complex runtime to handle 1. Garbage Collection and 2. Goroutine scheduling. C's runtime is comparatively miniscule. There are certainly other factors but that's probably the most significant one.
Thanks, that cleared up a lot of things. I have just one last question and then I go away - How do I find the raw hexcode the the `VMOVSD` instruction which loads a constant into a register ? I can find the code of `VMOVSD xmm0 xmm1 xmm2` by typing it into a `.asm` file and running `yasm` on it. But when I write something like `VMOVSD $-8.750608600031904122785e-01, xmm0` and run `yasm`, it prints `invalid combination of opcode and operands`. I have to do this because Go doesn't have the VMOVSD instruction and I have to write the instruction in raw hex. 
&gt;"my website is obscure so it won't be attacked" "my website is obscure so it's less likely to be attacked by a sophisticated attacker and instead most likely to get attacked by drive-by skids and bots" &gt;You do you. I'm never pulling anything from any of your domains, but after all, why would I in the first place? &gt;With this kind of "no u" logic, nothing would ever be fixed. I'm happy that the Go developers do not share your limited view. Did I hurt or attack you in any way? As I previously mentioned, you are free to use the github repos instead as long as you adjust or symlink the proper import paths. You seem to imply I'm out to attack you.
printf seems like a sane default considering one often comes back to expand print statements with state
Plus: the runtime is statically linked, if I'm not mistaken.
correct. The runtime will statically link all dependencies of your project into the binary. Unused functions and types are stripped if it can be reasonably determined they are unused. The result is a binary which only really depends on the glibc (or another libc if you link against it) and has no other external dependencies in of itself. If you want to go all the way you can (IIRC) link the muslc statically against go binaries which enables them to run on any system with a linux kernel (provided the binary only uses syscalls the kernel understands). On the other hand this results in larger binaries where you can't easily patch out vulnerabilities in security dependencies. I do hope this will be solved by plugin systems and more open source.
There is another difference between Print and Println. Println will add a space between printed values and Print won't. Println("a","b","c") -&gt; "a b c\n" Print("a","b","c") -&gt; "abc"
/u/everdev Thank you for your time. aah is new, gradaully features are getting added into it. I'm very activitly working on to make it better. I don't have particulars around no. of apps in production. As of now only one organization disclosed details with me. They are going golive next month with API services also they planning to rewrite one of their existing web app in aah. &gt; Do you mind if I ask why you would recommend your framework over a vanilla Go setup? I will describe with my beliefs and experience. I hope you got a chance to review the features and capabilities provided by aah. Each module/feature are improtant components and seamless integration between modules are key in the Web/API applications. For eg.: configuration, routes (authentication and authorization,...), security (roles, permission, sessions,...), views (authorization, internationalization, csrf,...), and so on. In aah every aspects is configurable and extensible, it won't stand in developer way. aah provides ready to start infrastructure, less boilerplate, etc. Typically we will start with vanilla setup and we do everything starting from app infrastructure and gradually we will reach the mini framework or framework. I'm sure I'm biased since I'm the author. Please feel free evaluate aah and share your view points it would help me improve. Thanks again!
/u/iroflmaowtf Thank you for your interest. Yes, aah supports multiple levels deep. Please refer to `rest-api` tutorial routes configuration. Feel free post your question in Gitter or Github, I will do my best to explain.
Link your so small C++ code statically and see how small the program really is.
The language spec size (for some definition of "size") and a compilers binary output size have basically no correlation. In Go's case, it is the size it is because of the runtime included for garbage collection and scheduling.
Ouch! This really smarts. First: Of course you're right, that was a bad post. So, I *completely* agree that this is premature optimization and I actually complain about this sort of thing. I saw an opportunity to talk about how `Printf()` with one argument doesn't use reflection but frankly the few ns of speedup is *not* why I do this. I think I replied with this mainly as a way to signal, "hey -- I know this thing..." I do tend to use `Printf()` but mainly because I come from C and it is almost a habit. Though I never use `Printf()` without a format string -- I'm aware of the pitfalls of that. I'm sorry for the crappy post and point taken! I'll try to be more thoughtful in the future.
as I said, there's physically 32-64-128 kb of ram on some popular microcontrollers :)
thanks. do you (anyone here) think microcontrollers need concurrency? I realize it would not be full Go without, but full Go is orders of magnitude (1.5) too big for microcontrollers....
Arduino is normally programmed in C++ish. IIRC a compiled hello world clocks in to a few hundred **bytes** (yes, bytes, not KBs). Obviously all code is statically compiled, since there's no OS.
Like always, be wise and choose the right tool for the job. IMHO - Go is not the right choice to write code for microcontrollers. Its C.
&gt; C's runtime Is there one? (in microcontrollers)
No, a statically linked Go binary doesn't depends on libc.
I meant the empty array at the end of it. For an exercise, let A and B be 2 slices of the same type and length L. Write a function that returns a 3rd slice of the same length that is composed of a random number of elements of A followed the remaining (if any) of B. Ex.: A = [1, 2, 3] B = [7, 8, 9] Possible results: [1, 8, 9] [1, 2, 9] [1, 2, 3] [7, 8, 9] All you have to do is select a "pivot" between [0, L+1) and concatenate the 2 sub slices. You would not be able to generalize this solution if it weren't for this language feature. EDIT: pivot range clarified
But it has to be noted, if you import net or any package that in turn imports net, e.g. some crypto packages, you won't get a static binary by default. You have to set CGO_ENABLED=0 in the environment then. As I often build docker images with Go programs I end up setting that flag a lot. 
Besides the 'rich' runtime, there are some noticeable differences compared with typical C executables. For example, a Go executable includes a 'pcln' section which usually accounts for the largest data section. I am not sure if it would be eliminated when it's built with '-ldflags -s -w'. Also, almost every function is padded with a sequence of '0xc' or 'INT $0x3' to have 16-byte alignment, which would add ~10% extra size. The metadata for GC and reflection could have some contribution as well.
&gt; here's what I've gathered about That's your problem. Don't "gather", don't guess, [just RTFM](https://golang.org/pkg/fmt#Printf) and it should be completely clear and obvious.
The requirement for reflection increases the size of binaries considerably. Information about types (like the names of struct fields) needs to be recorded. Also, the possibility of an exported function being called using reflection means that the linker can't strip out exported functions that are never statically called.
Thanks for noticing this. I tried the upper boundary assignment, however no real benefits from it. Anyway the Go version is much faster then the JS implementation.
Hey, I know Im late to the party, but yeah, the original implementer and creator of node js, Ryan Dahl made sure that golang is now his language of choice to build web servers! you can read it here https://www.mappingthejourney.com/single-post/2017/08/31/Episode-8-Interview-with-Ryan-Dahl-Creator-of-Nodejs
That's a really interesting point I had never considered. Kind of hurts your tree shaking abilities.
Not really.
This loses the absolutely massive advantages of HTTP/2 and the binary on the wire protocol buffers tho
The vet tool can find shadowed variables. It cannot be a compile time error because sometimes shadowing is intentional.
Well, of course. No runtime, 8bit programming (less space occupied by instructions), no need to handle concurrency, it doesn't surprise me. Maybe go language itself can be useful on embedded stuff, but it will require a specific compiler.
&gt; VMOVSD $-8.750608600031904122785e-01, xmm0 What is this instruction supposed to achieve? And is this Intel Syntax or AT&amp;T syntax (the operand order differs!). Note that there is no instruction to move a floating point immediate into an `xmm` register. You either have to use a memory operand or use a register to store the data. Anyway, the first step to finding out how an instruction is encoded is to look in the manual (e.g. [here](http://www.felixcloutier.com/x86/MOVSD.html)). There you find that `vmovsd xmm0,xmm1,xmm2` probably doesn't do what you want and you want `vmovsd xmm0,m64` instead. Then you check what concrete instruction you want, in this case e.g. `vmovsd xmm0,[rbp]`. So you look up the encoding which is `VEX.LIG.F2.0F.WIG 10 /r`. This means: First, we have a `VEX` prefix encoding with the `L` field set to zero, an encoded prefix of `F2 0F` (indicated by `m` = 0 and `p` = 3) and a `W` field set to zero. Then an opcode 10 and lastly a modr/m byte encoding our operands. Look this up in the [encoding scheme](https://en.wikipedia.org/wiki/VEX_prefix) and it gives `c5 fb` for the VEX prefix. Next, we add the opcode which is `10`. Then we add a modr/m byte indicating our choice of operands. `[rbp]` cannot be encoded directly, so we have to use `[rbp+00h]`. This gives an operand byte of `45` followed by an 8 bit immediate `00`. Our complete instruction is c5 fb 10 45 00 It is probably easier to let the assembler do this for you.
Is there a correct, succinct syntax to do what's expected in the above code snippet?
There are many cases where shadowing is desired (or even needed) so having this powerful tool removed would do good to nobody. Your example is one of many ways to have shadowing done. What if the code would be: for i := 0; i &lt; 1; i++ { foo := someOtherFunction() fmt.Println(i, foo) } foo is declared inside the loop as well now. Should it be flagged or not? Or in this case, where a function is shadowed? package main func demo() { println("this is a function") } func main() { demo() demo := "this is not a function anymore" for i, demo := 0, "hello"; i &lt; 10; i++ { println(i, demo) } println(demo) } As /u/patrickdlogan pointed out, you can use ` go vet -shadow ` or ` go vet -shadowstrict ` to see some of the shadowed identifiers. The next version of Gogland IDE will also support shadowing detection, disabled as using a separate algorithm and there's an ongoing discussion on how to make this better, see: https://youtrack.jetbrains.com/issue/GO-4403 Depending on the editor you are using there are various ways you can better spot shadowing, see the different color for example in Gogland: https://i.imgur.com/PCacLxz.png I don't think there's an algorithm that can detect shadowed identifiers without false positives and that is why this can never be in the compiler. As for warnings, the Go Team said they do not want to have warnings present the compiler so there's not much that can be done there.
Here: package main import "fmt" func main() { var i int var foo string for i, foo = 0, "Foo"; i &lt; 1; i++ { fmt.Println(i, foo) } fmt.Printf("%s", foo) }
very interesting also.
Are you using the latest Go version on your computer?
Alright, now I verified it on my computer and Go playground and I get the same difference. It's not your mistake, but it's weird. I think it might be a bug. Consider filing an issue on the GitHub tracker.
Thanks for your answer. I completely agree about shadowing (i use it a lot with the **err** checking); my only doubt is that it can create confusion if a shadowed variable has the same name of an upper variable.
protobufs don't have to send the keys, just the values. This means you can't really compare size. E.g 'super_long_key_name_for_intenger:0'... 99.9% of the storage is the key .. Build a large collection of these with millions or billions of rows and JSON becomes unusable. Also worth noting that people use something called json row value. This is an all array implementation where the first row are the keys and the next rows are values. Helps out quite a bit in web dev where you really need JSON support.
There often is. On all but the simplest micro controllers you often have at least a malloc implementation and basic filehandle facilities to support printf etc. 
Yeah. I personally like the feature because you don't need to include extra dll files with the exe (for Windows).
I wouldn't consider it to really be a bug, the Go spec does not specify how capacity of slices should increase when they hit their maximum size. Regardless, I replicated it on a 64-bit Linux machine: # go run run.go len=0 cap=0 [] len=1 cap=1 [0] len=2 cap=2 [0 1] len=5 cap=6 [0 1 2 3 4] # GOARCH=386 go build run.go # ./run len=0 cap=0 [] len=1 cap=2 [0] len=2 cap=2 [0 1] len=5 cap=8 [0 1 2 3 4] I'd say it's just an optimisation done on 32-bit Linux machines. EDIT: I'll add a bit more to my comment to explain what's happening here, and why the difference in capacity in this example doesn't really matter. It really comes down to the problem of optimising memory allocations. For dynamically sized arrays (slices in Go for instance) there is a compromise between memory use efficiency, and amount of time spent resizing a slice. ## Optimising for memory use For sake of example, let's look at the case where we optimise for memory use, the slice re-sizer would have the following logic when you try to append something to the slice: 1. Ask the OS to allocate space for additional element at the end of my existing slice in memory. 2. If it could, go to 5. 3. If it couldn't, ask the OS to allocate a new chunk of len(slice) + 1 elements of memory. 4. Copy the current slice into the newly generated slice. 5. Copy the element that you're trying to append, to the newly allocated space in memory. The problem with this scenario, is that "asking the OS" (or a syscall) is considered slow, in fact if you're trying to insert a lot of elements at once, it will cause very significant overhead. So although this solution uses the minimal amount of memory required to store the array, it can also be significantly slower to use, so this isn't ideal for most use cases. ## Optimising for time To optimise for time, you would simply pre-allocate as much space as you can, and then keep track with a pointer where the head of the array is. When you append a new element, you simply copy the element to where the head is pointing to, and increment the head. This requires the minimal amount of time, since it doesn't require asking the OS anything upon appending something, minimizing the time overhead. This however clearly is impractical due to you pre-allocating as much memory as you can, as most of the allocated memory will likely never be used. This could be memory that is used for another program, or to cache data to make your system perform better. ## A compromise between memory use and time What Go is doing here (and many other list implementations) is using a compromise between the two strategies. Slices have 2 sizes, its length, which represents the number of items you've put into the slice, and a capacity, which represents the amount of memory you have asked the OS to allocate for the slice. When the length of the slice reaches it capacity and you try to append something, Go must ask the OS to allocate more memory. This is where the compromise occurs, it must choose a small enough amount of additional memory such that not too much of it becomes wasted as it is unused, yet large enough such that Go doesn't need to ask the OS too frequently to allocate more memory, as it is a slow operation. There's a whole bunch of processor and memory optimisations that I don't really know that ends up determining the amount that Go chooses. However it is roughly exponential. So it should roughly multiply the amount of allocated memory each time by a constant factor whenever the length hits the capacity. For example, exponentiating by 2 you get: 1, 2, 4, 8, 16, 32, and so on. So for example if I have 8 elements (and a capacity of 8) in this theoretical slice implementation, and I try to append another element, the implementation will ask to allocate 8 additional elements for a total of 16 elements. For this specific case, it appears that it's more optimal to allocate a capacity of a different pattern for 32-bit Linux than 64-bit Linux. In the end though, it shouldn't impact your program or how it really behaves. I'm sure it's just an optimisation that the Go team has decided to make based on all of the factors and compromises.
&gt; my only doubt is that it can create confusion if a shadowed variable has the same name of an upper variable. You are contradicting yourself in the same sentence while describing exactly how shadowing works: &gt; I completely agree about shadowing (i use it a lot with the err checking) And if you completely agree about shadowing, and you supposedly know all of this already, why would you propose something that you know it's not good? And have you seen the previous threads here or on golang-nuts about the very same problem? Unless there's anything new that I'm missing then this is pretty much a rehash of all those previous threads and it will also lead to the same point: nowhere.
Thank you so much ! I will see what I can do.
You can see the explanation here: https://github.com/golang/go/blob/f3e0d143131dc318a173f4f5cc4e4b96de93318d/src/runtime/slice.go#L72 TL;DR: it grows using a predetermined pattern in order to avoid moving the slice elements too much in memory when called in for loops for example.
so there is not, thank you.
&gt; The reason Go might still be interesting, of course, is because it's such a small and "correct" language. It's possible to code it after a bit of experience with very high confidence regarding what it is doing.... Go is neither small nor correct and is certainly not adapted for programming micro-controllers. Unsafe API cannot be relied upon to do stuff like pointer arithmetic. Go isn't a 0 cost abstraction language at all. So the "correct" moniker is ridiculous. "small" obviously does not apply either because it's bundle with a runtime. I don't understand why anybody would think programming micro-controllers with a garbage collected language is a good idea to begin with, it's a stupid idea. You have C if you don't like C++ so use it. You shouldn't need more than that for embed programming.
PHP, Python, C++ , Delphi, all have good soap server implementations ...
It looks like code generation would be better fit for such case.
I think it comes down to a definition of what a 'runtime' is exactly; probably not worth arguing about.
I have some open source bitcoin libraries (forks) that you can use to help with your project: https://github.com/njones/base58 https://github.com/njones/bitcoin-crypto it's an open source fast base58 and secp256k1 implementation.
Here is the relevant section of the spec: https://golang.org/ref/spec#Appending_and_copying_slices. The only requirement is that there is enough capacity to hold the values. &gt; If the capacity of s is not large enough to fit the additional values, append allocates a new, sufficiently large underlying array that fits both the existing slice elements and the additional values. Otherwise, append re-uses the underlying array.
It has a reputation of not being very performant, though it seems optimization has recently become one of the main concerns of the team: https://www.reddit.com/r/golang/comments/6uw1xq/go_grpc_performance_compare_to_java_and_c/dlwiq4d/
I meant small in terms of the language specification. And I meant correct in that the code does what was intended, the code isn't broken. (the programmer didn't add mistakes while writing it.) thanks for writing.
Looks like a great library. Makes me wonder how it compares to [sqlboiler](https://github.com/volatiletech/sqlboiler).
Wow. This one looks good too!
Hi, Apologies for bothering you again. But I spent a couple of hours on this and could not figure this out. With `VMOVSD $-8.750608600031904122785e-01, xmm0`, I want to load this floating point no. into `X0`. For MOVSD, the documentation clearly states the instruction to be - `MOVSD xmm1, xmm2/m64` which means I can do `MOVSD X0, $-8.750608600031904122785e-01` which will load that floating point no. into X0. Similarly, for VMOVSD, the documentation states - `VMOVSD xmm1, m64`. Which means I should be able to load $-8.750608600031904122785e-01 into xmm0 directly. Right ? You mention - &gt; You either have to use a memory operand or use a register to store the data. So then if anyway first I have to load the no. into something(either memory or register), and then use the `VMOVSD` instruction, won't it cause more delay ? I mean this is a 2-step process instead of a 1-step process that I do with `MOVSD`. I am only stuck with this part. Otherwise, the `VMULSD` and `VDIVSD` are done. 
An operand of type `m64` means “64 bit memory operand.” The operand `$-8.750608600031904122785e-01` is an *immediate operand,* not a *memory operand* and thus can't be used for `movsd`. Instead, you need to store this constant in a global variable and reference it from your assembly. Note that this could be a bit tricky to assemble manually because the address passed to the memory operand is IP-relative. 
Spec is actually small but heavily relies on GC. This one thing is enough to exclude any language from the interest of most microcontroller programmers. Size of your simple "hello world" example is heavily affected by GC, type information (need by interfaces and reflection) and big fmt package which has huge dependences. If you have on mind the size of ELF file, add to account the debuging data that allows to print beautiful stack traces and much more. You can try Emgo language, which supposed to be something between lightweight Go and smart C. It strongly bends Spec but you still feel strong taste of Go.
Crystal has go style channels as well as threads and forks. As of today the only way to multiple cores is to use a shard but the core team is working on it.
Sounds like you want https://github.com/gtank/cryptopasta :)
Will it still work after four years?
Ha, don't worry this Nexus-7...so 5 years shelf-life. ;)
Depends what your goal is I suppose. While that solution is certainly doable...the goal here is more in line with a tool like Python Fabric where the intent is running commands from some host that you control. Additionally this gives you flexibility to inject flags to change the behavior if need be and to share recipes with other folks. Uploading bash scripts to all of your infrastructure can seem unwieldy once your cluster size is large enough...now scripts are dispersed in different versions all through your server fleet. I'm not saying this is wrong but probably not the use case I'm aiming for. Bladerunner is more in the area of say Fab or Knife...when running remote commands.
I think what is different here is that in this case there's really no need to upload files to the remote servers. The commands are sent on demand as an ssh connection is opened to each host. Additionally and it's not well documented yet but the TOML files allow you to define a lot more semantics in regards to the script such as: concurrency control in relation to your cluster, retry behavior should one or more commands fail, user interaction logic in terms of prompts and help info and eventually some level of fallback behavior and notifications. Executing commands is really just the tip of the iceberg for this tool. But yes uploading bash scripts is one way to do it. ;)
Awesome, if you have suggestions please file an issue...there's a lot I'd like to do with this tool and it's actually quite usable now but I'd consider unstable in terms of API stability. Thanks for your questions by the way!
The TOML files for each command can have a Resilience section for failure behavior similar to what your describing. It's not implemented yet but eventually I'll be looking to support such behavior similar to what you mention. Thanks for the suggestion!
I'm really happy when I downvote downright stupid posts, others have their own reasons. Not down voting them would make me unhappy. I prefer down voting to telling people they are wrong because it's time consuming and many times frustrating (mostly because they don't bother using the very essential tool called: search before you post). I'm part of the community. How do you keep me happy given this condition? If you get sad because your post is down voted then the correct question to ask is: how can I improve my post? What can I do better next time? Can I learn something from this? You also have to take into account that sometimes people are just assholes like me and downvote for the fun of it. Other times downvoting is used to keep people away from truly bad content. Why not have such a tool? Or do you suggest that the admins should remove low quality content? That would be worse right? So yeah, I see your point but how about having people to do some research before they post? Or maybe, just maybe, realize than nothing in life is all nice and shinny and negative votes are not the end of the world but rather an opportunity to keep improving themselves? P. S. Ordering people what to do (the ! At the end of the post title) is another good way to attract downvotes.
That actually does not address the question asked in any way, shape or form.
When I have a complex string I want to print out it's just easier using fmt.Printf. Example: // println fmt.Println("Last Name: "+lastName+", First Name: " + firstName + ", Age: "+age+", Service: "+service+", Rank: "+rank+", Unit: "+unit+".") // printf fmt.Printf("Last Name: %s, First Name: %s, Age: %s, Service: %s, Rank: %s, Unit: %s.\n",lastName,firstName,age,service,rank,unit) https://play.golang.org/p/lyV5CN9bhS To me its a lot easier to write that line using fmt.Printf over fmt.Println. In generating the example I had a much harder time with the println than I did with the printf. Another example would be if you only want to print out 2 decimals from a float: a:=100.0/3.0 fmt.Println("A=",a) fmt.Printf("A= %.2f\n",a) It's a lot easier (for me at least) to just stick the raw number in to Printf and let it do the work and format it with 2 decimals. My advice is to read the manual. Printf is MUCH more powerful than Println, and nearly every time I use println most of the time before the program is done I've changed it to Printf because it just can't do what I want it to do. 
thank you!
Welcome to /r/golang, one of the most toxic programming communities on reddit. I completely agree.
You know, I wrote a whole spiel, but I realize there's not much I can say - you're an asshole and you yourself admit to that. So why would anyone want to be a part of this community?
Wow, I didn't expect much in the way of responses, but what dlsniper completely caught me by surprise.
We're using it at Mattel with extremely customized templates. I really love code generation, so it works well for me. That being said, I'm also working on my own replacement for it that does things a little differently.
Use the html/template package. If you don't need templating, you can just use the html package. (html.EscapeString) If you mean to strip tags, then you probably want to check out x/net/html or goquery
My problem with sqlboiler is twofold... one, I hate fluent APIs. Two, it doesn't give you any assurances that the code you're writing will actually work.... Where("age &gt; ?", 30) ^^ This is terrible. What if you change the name of the age column? You won't know unless you have tests running against the database. And then you have to manually go find all the places you used the old name and change them to a new name. It's spewing magic strings all over your codebase. Just say no.
[bluemonday](https://github.com/microcosm-cc/bluemonday)
If you're just removing arbitrary strings then I think you want `strings.Replace` or `regexp`.
So you say you down vote because you dont want to spend effort in telling someone they haven't spent more efforts on the post ? Second, if there is no feedback, is the OP supposed to guess what is wrong and learn from his own guesses ? Wouldn't it be more productive to spend 5 minutes and tell someone how they can improve ? You're just a very lazy asshole. I hope you dont ever be in a position to teach anybody anyone with that attitude
Probably not a good idea to "roll your own" HTML escaping code, especially not if the input is untrusted (like Reddit comments).
Is there any reason using bluemonday when using html/template which already escapes dangerous characters?
https://github.com/doug-martin/goqu has served me well on multiple go projects when connecting to pg. 
The pointer situation is enforced by proto2. Switch to proto3. However, in proto3 there is no difference between a field not present and a default value. There is plenty literature as to why this is.
I had the same choice a year ago. Went with gRPC/Proto. Never regretted it.
One difference between the Go compiler as written in C and the self hosted compiler is the C compiler only allocated, it never did any clean up because it assumed that it would die before it needed to do garbage collection. C can do tricks like that! It's hard to beat C in part because C can bring a gun (no memory deallocation!) to a knife fight (garbage collection). 
Sanitizing and escaping are two totally different concepts. OP is asking about sanitizing. If they only need to strip newlines and things that look like HTML character entity references, then `regexp` should work fine.
Looks like the question was edited (or there was a *very* similar question asking about why the result was 6 on their computer and 8 on the Tour). There is no restriction on how the capacity is grown. Different architectures and implementations may have different strategies.
html/template escapes everything, bluemonday only escapes XSS. The differences are detailed in its README.
The standard way to get comments from the Reddit API without the escaping is to use the "raw_json" query string parameter. For example: https://www.reddit.com/user/kjnkjnkjnkjnkjnkjn.json?raw_json=1
Okay so since html/template also covers XSS there no reason to use bluemonday on top.
OP isn't 100% clear on what the input looks like, but mention of `&amp;gt;` makes it sound like there could be embeded HTML in there. I would *expect* that the Reddit API removes most of the truly harmful `&lt;script&gt;...&lt;/script&gt;` and `onload=..` stuff, but you can never be sure. Either way, I don't really see a *downside* to using an established library; so why *not* use it, just to be on the safe side?
Having a few arseholes around keeps away the emotionally fragile SJWs, like the ones currently making a mess of the Node community.
Yes it would be pointless to use bluemonday on top of html/template. You would only use bluemonday by itself to escape HTML (and then possibly pass it to html/template as type template.HTML).
Honestly, I'm not here to hoard upvotes so I don't really care about the occasional downvotes. Sure, it's being misused by some people and some are downright pessimists. You can compensate by giving upvotes ;-) PS.: don't new posts start at 0 anyways?
&gt; So you say you down vote because you dont want to spend effort in telling someone they haven't spent more efforts on the post ? If it's the nth time a question or subject comes up, with no new ideas behind it, yes. How does that make me different than the poster who didn't took 10 seconds to check for similar questions? &gt; if there is no feedback, is the OP supposed to guess what is wrong and learn from his own guesses ? And if I leave feedback to use the search functionality I get downvoted as well, sometimes more than the OP. &gt; Wouldn't it be more productive to spend 5 minutes and tell someone how they can improve ? Of course it would be. And I do that nor am I encouraging people to do it. But what I've done with my comment was to push an extreme out and show the OP another side of the conversation. Do you think than everyone has the time for that? Can people not be allowed to be lazy assholes and still be part of a community? If that's the case, can you not see the moral problem of policing the community like that? Imho, any community should be a self regulated one. One that allows for silly questions to be asked and answered over and over again while really toxic behavior is not allowed. Downvotes are not toxic, last I've checked, and anyone should be able to handle negativity because not everything is a free lunch. &gt; I hope you dont ever be in a position to teach anybody anyone with that attitude That is because of my very blunt response? Or because you've never seen me teaching people and you are just like that lazy asshole I'm describing that doesn't bother to leave feedback? See how difficult it is?
&gt; PS.: don't new posts start at 0 anyways? At least here start at 1 because of the self-upvote that's done automatically.
Just to be totally clear: this is a really shitty and toxic attitude, and the less of it we have in this subreddit, the better.
&gt; Having a few arseholes around keeps away the emotionally fragile SJWs, like the ones currently making a mess of the Node community. Oh, but this is so not what I said. It's the people like you that people should be cautious of, not the drive-by downvoting ones.
&gt; So why would anyone want to be a part of this community? So... Based on a single response, of a single person in the community, you just judged and decided against the whole community? And you think that's good? Or fair to the community? The one which, by the way, you are ordering not to act or react as they are allowed to do? How does that make you better than me? Or the person I'm describing in the comment? You try to take the moral high ground but the yourself say: nah, I won't help this person out, I won't have a discussion, I'll just back out in a way that makes me look superior to those who are really shallow and I'm done. I've raised a number of points, and instead of a discussion you offer me the same reaction as the person I describe in my comment and then, after commanding a whole community how to behave (the ! at the end of the title is still there) you say naah, I'm better. Guess what. You are not.
&gt; Just to be totally clear: this is a really shitty and toxic attitude, and the less of it we have in this subreddit, the better. Wait, what? Why? Because I downvote posts? Or because I challenge the assumptions of someone and offer another point of view. Someone that's trying to order a whole community how to behave, nonetheless. Which by the way, it's not the first time it's being discussed. Is it toxic to be different?
That's a cool idea, actually
Downvotes are not in themselves a sign of toxicity. The idea that we should not vote something down because "1 is better than 0" is silly, that just arbitrarily changes the number the community determines something with no value should have. 
&gt; I'm really happy when I downvote downright stupid posts &gt; I prefer down voting to telling people they are wrong because it's time consuming &gt; sometimes people are just assholes like me and downvote for the fun of it. &gt; If you get sad because your post is down voted [_because I think you're downright stupid, or because I'm being an asshole_] then the correct question to ask is: how can I improve my post? What can I do better next time? Can I learn something from this? This toxicity is exactly what gives this subreddit a terrible reputation.
The whole application server thing is more of a java quirk. I don't have a solution for you that is as "effortless" as the java approach, and nothing for go is going to be nearly as tightly integrated unless you developed your own tools/standards for this sort of thing. Overall though, I'd say docker is simple enough and hits the mark for networking between microservices.
Note the change from for i, foo := ... to for i, foo = ... (plus the now required declaration of i outside the loop).
Stupid posts != stupid people. Big difference, and you are putting words in my mouth with this one. Also, nobody has any right to tell people how to use the voting feature. I prefer someone that downvotes without leaving a comment than to have to deal with someone that calls people stupid. You chose to see toxicity where there was none. I drove an extreme point and this is comes up, people that would be more happy to hide their thoughts and feelings (or do it for others) than have them enabled to express themselves. Why do you think the Slack and Reddit communities are so different? A lot of people here are there and vice-versa. And yet in Slack we don't have these kind of issues. And people are really nice to each-other and helpful. And even there you can still -1 a question / answer but people rarely do it. Maybe because there it's not anonymous but here it is. Who knows?
Big thanks! I have been waiting for this for quite a while for github.com/chrislusf/gleam, which was encoding/decoding data via msgpack. But the weak number typing was annoying and inconvenient. I have switched to greenpack in this commit, which is fairly easy. https://github.com/chrislusf/gleam/commit/36c3dda58ef2159e9c270bf578d7bf0259ff9733 It will be good to have a "used by" section in the readme. 
Please don't put too much stock in the toxic responses of an admitted asshole. He doesn't speak for the community, and certainly not for the moderation team.
Looks good, nice!!
Proudly downvoted.
Thanks very much!! :-) Appreciate it!
&gt; Please don't put too much stock in the toxic responses of an admitted asshole. He doesn't speak for the community, and certainly not for the moderation team. No one speaks for the community even though some self-appointees pretend they do. Also, I'm quite surprised that an moderator calls anyone here an "admitted asshole". Exempla trahunt. I wonder, do you have the decency to step down?
It looks line a great alternative to code everything by hand. I'll try it next time I have to tackle this kind of problems. Thank you
If you follow an inductive chain of reasoning it becomes clear there's no other way for indexes to work. 1. You want to be able to specify empty slices using indexes. So s[0:0] must be valid and empty. It emerges that the end index must be exclusive. 2. You want to be able to specify the whole slice. So s[0:len(s)] must be valid and represent the full slice. 3. You want the same logic from point 1 to apply to slices ending in len(s) so s[len(s):len(s)] must be valid and empty. The intuition that emerges is simple: indexes in slice ranges represent the points between elements (element boundaries), not the elements themselves. If you have a slice with 3 elements you have 4 element boundaries that you can use in ranges. C++ iterators have the same behavior. The end iterator is valid (in ranges, not when accessing single elements) and points right past the last element: https://repl.it/KeaH/0
why haven't you deleted this comment, like all the others, coward!
Serious question. How come you started your own framework when you could have contributed to say Buffalo?
If you have a similar scenario (short lived, lots of allocation but no need to free anything) you can either set `GOGC=off` in the environment or you can use [`SetGCPercent(-1)`](https://golang.org/pkg/runtime/debug/#SetGCPercent) at program start to disable Go's garbage collection. This (I think) only disables GC runs but doesn't remove the bookkeeping requirements on allocations.
I was annoyed at the same experience in Go...
&gt; with a MD5 digest for verification Why would anyone still use [MD5](https://en.wikipedia.org/wiki/MD5#Security) for something like this when far superior and non-broken hashes exist? For something like this you should be using a secure digital signature (e.g. an OpenPGP signed executable, or for MS Windows or Mac a signed executable that the OS recognises). [See Wikipedia's [Code signing](https://en.wikipedia.org/wiki/Code_signing) entry.]
thanks Chris. I've long admired your seaweedfs.
What does "toxic" even mean anymore? I can't even tell if I agree or disagree with you because it seems to only mean "things I don't like, and my opinions are absolute".
I don't see anything wrong with noting that someone called themselves an asshole. On the other hand, your post is simply rude.
Because I'm not signing code I'm just verifying a downloaded file. It's simple, easy, fast and anyone can use it. :-)
Here's a few things you can fix: https://goreportcard.com/report/github.com/ishanjain28/instamojo You really need to write tests, ideally both Unit tests and integration tests that call the live API. I'd also suggest to improve the documentation. Preferably instead of just linking to the godoc and call it a day, you could have the documentation directly in the readme. I mean there's nothing wrong with a link to godoc but when I went to godoc to read the documentation I had only this line to read: &gt; "Package instamojo aims to provide a Wrapper for instamojo.com's API It is a work in progress and all remaining endpoints shall be added soon" You need to make the usage of the package more obvious for the end user. A great way to do that is with [testable examples](https://blog.golang.org/examples).
Relevant [video](https://www.youtube.com/watch?v=rFejpH_tAHM) showcasing how complex is Go behind the scenes just to offer this simplicity to the programmers.
I know there is already a secure cookie package in [gorilla](http://www.gorillatoolkit.org/pkg/securecookie). The exercise was for me to create a more compact secure cookie. I expect it also to be faster, but I didn't benchmark yet. It would be great if you could provide a quick feedback on my code. The primary goal is for me to learn from this experience. 
I usually only downvote outright trolliing or uneducated guesses which presented as facts. Yes - I hate when people willingly spread ignorance. There is enough of it already. Other than that - golang sub may not seem as good place at glace, but if you look closer then, you will find out that, when people take their time to properly express their thoughts, they will usually get proper response or an interesting discussion. That includes golang runtime internals, proper use of crypto, networking and so on. But when you didn't bother with search option and didn't take the time to explain what do you want - why should I bother with you? Also - keep in mind that many of us here are professionals. We value our time - we like to spent it in quality fashion. Yes - thats includes tutoring and explaining stuff. But when the same question comes more than fifty times - you know that person didn't come here to learn or to explore. Again - if you didn't bother, why should I? BTW - welcome to the internet. Most of the people here are an assholes. Sometimes with a heart of gold tho... 
Can anyone not equally use a SHA1 hash? That would be much more secure than MD5.
dlsniper literally called himself an asshole in a comment elsewhere in the thread.
Examples, Tests and some documentation on github as well. Got it. Calling their API requires tokens, But I can't really put my tokens in the test files. Thanks for your input. 
&gt; Calling their API requires tokens, But I can't really put my tokens in the test files. No you can't. But since these are integration tests anyways, you can use the flag package and receive them as input. If the person that tries to run the integration tests does not provide the flags, you just fail the tests and exit with a friendly message that shows what flags should be used.
Yes, I can definitely do that. I am now writing tests and examples for it. Thank you so much.
I totally agree with your point, but how do you avoid this string problem and use a SQL database in Go? 
&gt; There are no named captured groups in Go regexes, [...] https://golang.org/pkg/regexp/#Regexp.SubexpNames
Why not just use [`http.Cookie`](https://golang.org/pkg/net/http/#Cookie)?
You can make strongly typed db wrappers that serialize to the right string so you only have the column name in one place, and that place is generated directly from the DB schema, thus ensuring it's always correct. We do this at Mattel, with xo, albeit with our own custom templates. 
Thank you for the fast response. Good suggestion for MaxAge. It's simpler and more compact. Regarding copy and append I had the wrong assumption that copy was faster. I just made a benchmark and they are equivalent. Append is indeed simpler and the intend is more obvious. I'm not fully sure that the benchmark is valid. The append and copy could have been optimized away. 
I meant something like ``` map[string][]byte ``` or ``` map[string]string ``` The way named groups treated in Go stdlib makes them nearly useless in usage other than text juggling within regex.
Why not use AEAD to handle mac and encrypting? https://golang.org/pkg/crypto/cipher/#NewGCM
I'm using a slightly patched version of it with some custom templates to work with [pgx](https://godoc.org/github.com/jackc/pgx). It's pretty decent, if you're mostly doing CRUD or you're prepared to build a little infrastructure around generating boilerplate for a list of SQL queries. I'd compare with [sqlgen](https://github.com/drone/sqlgen) for a new project if struct-first (rather than schema-first) generation were a goal.
Or you know, just write SQL queries. I'm not sure why people keep trying to obfuscate them. Now i'm not saying saving and fetching data with Go isn't a pain in the ass, it absolutely is, but the writing query part is not a problem.
Ragel is a a powerful parser generator that is more general than this. It now generates Go code as well. http://www.colm.net/open-source/ragel/
I would say that if beginner level questions come up very often, perhaps it's wise to create a new subreddit for those and direct questions/content that seem to belong there.
Somewhat agree (I only care about how it effects people new to Go). For the people of /r/golang, please go easy on new gophers. And for mods, please make pinned threads aimed at them with like FAQ/Small questions threads. Hope our community becomes as friendly as /r/rust but that's a long way to go. ✌️
I wasn't saying that you shouldn't down-vote. I was saying that the number of posts with a 0 score on this sub is quite abnormal.
You can build that map with a very short function, if you so desire.
I think the conclusion I've reached from this is similar. There definitely is a problem, which is that newbies to Go aren't really able to start useful discussions (since they get downvoted). So perhaps a subreddit more suitable for those kinds of questions is appropriate. 
To make them (regexes) even slower? Go's regexes are absolutely worthless when you need to deal with billions of lines. Do you remember we are talking about data extraction?
You're the one insisting on a map, don't blame me for any slowness caused by it.
&gt; It now generates Go code as well. http://www.colm.net/news/2016/07/31/ragel-target-langs.html And, as I noted, regexes (and thus finite state machines) are overkill - they are too noisy for this kind of work (log processing). This generator has limited functionality, but it is usually more than enough in absolute majority of cases and it also makes a lot of boilerplating (error handling, type conversions, optional fields handling, data structure generation) behind the scene. I used this performance check on TSV file: https://github.com/sirkon/ldetool/blob/master/PERFORMANCE.md Here's the ragel template: package main // parser autogenerated parser type Line struct { rest []byte Name []byte Count []byte } %% machine fields; %% write data; // Extract extracts field from func (l *Line) Extract(data []byte) (ok bool, error error) { cs, p, pe := 0, 0, len(data) l.rest = data var pos = 0 %%{ action shot { pos = p + 1 } action take_name { l.Name = l.rest[pos:p+1] } action take_count { l.Count = l.rest[pos:p+1] } field = (any -- ( "|" ))* ; main := field@take_name "|" field "|" field "|" field "|"@shot field@take_count ; write init; write exec; }%% return true, nil } Compare it to LDE script which actually does a lot more. parser = Name(string) '|' _ '|' _ '|' _ '|' Count(string) '|'; And now compare their performance, ragel version first. $ time ./ragel &lt; ~/Sources/gotest/data | wc -l 100000000 real 0m22.396s user 0m22.676s sys 0m1.032s LDETool version second $ time ./lde &lt; ~/Sources/gotest/data | wc -l 100000000 real 0m10.501s user 0m10.528s sys 0m0.896s So, you see, ragel generated program is twice slower even though the benchmark data is sparing for its approach. The difference will grow a lot with larger fields values (bytes.IndexByte is a lot faster than manual scanning). Also, Ragel template is much more harder to write. It is more generic, but its extended functionality 1. Not actually needed 2. Comes at cost a lot of boilerplate code saving values, a lot of boilerplate code signaling errors. 3. Not having an ability to benefit from optimized lookup functions
Or sha256 which is not that old as sha1?
The extra work you are going through to ensure you don't allocate isn't worth the potential for mistakes and the lack of readability. You have error propagation in functions just because of buffer capacity, duplicate branches of accessing the same field just to calculate length. Finally you imported unsafe- which you should never do JUST to save an allocation in a security sensitive context like this. **By doing so you have caused a severe secure vulnerability by displaying users "secure" cookies insecurely to another user.** The security issue is because you are using the slice of bytes you get from the sync.Pool as the backing for the header: encVal, err := encodeValue(b[pos:], *(*string)(unsafe.Pointer(&amp;c.Value)), key) w.Header().Add("Set-Cookie", *(*string)(unsafe.Pointer(&amp;b))) But you may have concurrent requests coming in and the buffer could be recycled and made available to a new request before the string is done being read. The Value has the same problem, honestly there is endless issues with providing an API that the user has to think of their strings as mutable. It's just not safe or worth it. Suggestion, remove unsafe obviously. Next since the entire purpose of sync.Pool is to amortize the cost of allocations when it matters, use it and simply append your bytes. When you need a string, convert it to a string. Let the security sensitive context have strong visual indicators of proof of correctness. After you get your buffer, reset it: b = b[0:0] Now when you really don't want to cause extra allocs like during high traffic, your appends will not allocate. When your application is idle, it won't matter. For testing this, write a benchmark that simply Sets and Gets the cookie in RunParallel with -race flag, I imagine it emerges but you may need to tweak the test a little or run it a few times for it to emerge depending on how long you hold onto the backings for. Edit: Since I'm home I created you [issue#1](https://github.com/chmike/cookie/issues/1) with a script to reproduce it. It is fixed by replacing: *(*string)(unsafe.Pointer(&amp;b)) With: string(b) I would suggest also to remove the usage in Value as well. In fact I think the api should probably be changed, because just writing the example I realized even though the only thing I'll ever want to change in "Params" is the value, I'll be forced to create an entirely new Params object each time. Perhaps a "Cookie" struct that contains the default values, including the crypto key that I could create a "Cookie" setter with would make for a nicer API. So I could then: // func New(w http.ResponseWriter, c *Params, key []byte) (*OvenYouKnowFreshBakedCookies, error) // func SetSecure(w http.ResponseWriter, v interface{}) error // SetSecure could be interface{}, encoding.TextMarshaler, json.Marshaler, string, []byte, whatever // you want, interface might be best because you can accept a few different interfaces and nicely // marshal simple structures. o := cookie.New(key Params{}) o.SetSecure(w, "somevalue") 
I believe that it would be wrong to do so. Beginner questions are / should be welcomed everywhere. However, the "come up very often" is really hard to solve. What makes you think that if people are not searching here, in this huge archive of knowledge before posting, they will do so in the new subreddit? And I don't have any problem with beginner questions, I'm always happy to help on Slack whenever my time permits, same as here or any other environment. Unfortunately you are either ignoring the points I've made or you've missed them. 
I've asked /u/peterbourgon and I'll ask you and anyone else that want to answer the same question: why does the Slack community thrive and helps all the people in it while the Reddit one doesn't? There are a lot of cross-accounts between these communities yet only here we seem to be having this problem.
Do you mean Go regexes are fast?
It sounds like you're just going to have to write a web app from scratch. I'm not really sure what you're after here? Typically you'd just store the data in a database instead of spreadsheet, but honestly it sounds like you've not done this kind of work before. If that's the case your question shouldn't be "can I do this in go?", but rather "how to I go about making a data driven web application?". 
I'm looking for something like http://pandas.pydata.org/ but for go. And yes, i did some apps that have database access :) for the last 25 years or so ... But i just started go recently, so i am not very familar with the libraries yet.
https://www.reddit.com/r/golang/comments/6xq9rx/downvoting_posts_is_a_really_discouraging/dmhp39u/ is a fine example of the toxicity I was talking about. &gt; You also have to take into account that sometimes people are just assholes like me and downvote for the fun of it. That happens a lot more than you think.
I was expressing a point of view, albeit an extreme one. One that's different from the OP's POV and different than most of others. Would it have been toxic if I would have talked about an imaginary persona instead of myself? Would that have made a difference? Is it really toxic to think different than other people? Who decides that? I think that's a very dangerous slope to go down on. People should be allowed to express themselves as long as they are not actually doing harm to people. But the person that posted this thread wanted to impose behavior on others: "If you don't like it just don't upvote!" To me this whole thread really does seem like just another good way to get more self-righteous people come up and say: oh but I'm so much better than you are because I don't downvote people.
GraphQL with gRPC...🤔 This is arguably something I've never thought about before, tbh. And seems like it could be promising.
I'll just leave it here: https://pressly.github.io/sup
The only library I'm familiar with is https://github.com/tealeg/xlsx which lets you read/write XLSX files (so only the "new" Office Open XML based format). W.r.t VB macro's though, that seems extremely unlikely to work unless you want to build a VB interpreter in Go, similarly w.r.t using formulae.
I'm actually the author of that library, I don't think it will be of any use at all in this case - you could obviously use it to have an XLSX file as a "database" for your application, but frankly it's not an approach I'd advise, and as you correctly summarise, executing the VB macros would be a *ahem* non-trivial task. 
I can totally understand what you mean. All too often I see innocent questions or links to someone's repository downvoted for no apparent reason. This is a technical subreddit where professionals discuss topics around a programming language. I know that it can be difficult sometimes to take a professional attitude when answering a post--or when up- or downvoting, but it really can make a difference.
So uh, yeah, you should seek the help of a good psychiatrist, buddy.
What does that have to do with whether subgroups have names or not? Also, fast *at what*? https://swtch.com/~rsc/regexp/regexp1.html
There is /r/learngolang but it's more or less dead. The Gophers discord channel #golang-newbies is probably the best place.
Nice! Really like the results. Do you mind sharing a bit about the algorithm you use? Also, mind talking about the performance, i.e, how long it takes to generate an image?
Well, this isn't really a Go question per se, rather you're asking how make a frontend talk to a backend. Usually, if you're building your frontend in Javascript then you would use something to make HTTP requests to a backend. There are lots of options out there, ranging from good ol' AJAX requests, as well to nicer libraries like axios, the built-in fetch, etc.
I don't really get the interface here with returning Requester that then returns a interface? You lose typing when all you are really doing is providing a chain of calls based on cancellation. I also don't really understand the purpose, the only way for the slaves result to return is if the Context is canceled: https://github.com/regeda/go.failover/blob/master/master_slave.go#L24 If the context is canceled the request has been canceled. So shouldn't it return once the "shift timeout" has been met? Otherwise if a slave is completely down the "shift timeout" might as well be Forever as the function blocks until the context is canceled, losing the benefit of a slave. I would probably have the function signature: func MasterSlave(ctx context.Context, d time.Duration, fn ...func(context.Context) error) error The user can propagate their own return values, having to assert them through an empty interface is not very idiomatic. I can do that myself with a local variable really easily.
&gt; So uh, yeah, you should seek the help of a good psychiatrist, buddy. /u/GentooMonk this is a prime example of why downvoting is better than speaking sometimes. But it's also a good example that you cannot actually handle a discussion without lowering yourself to direct insults. And you are literally just doing exactly what I said, taking a moral high ground by saying &gt; https://www.reddit.com/r/golang/comments/6xq9rx/downvoting_posts_is_a_really_discouraging/dmhp39u/ is a fine example of the toxicity I was talking about. then you took the bar and lowered into the ground with your next reply. I wonder which one of us is more toxic? Someone that wants to have an open dialog or someone that when faced with a different point of view attacks the person making that point?
Nice did not know this existed! I'll check it out.
https://rationalwiki.org/wiki/Don't_feed_the_Troll
Hey I remember someone posted this a while ago High-performance PHP-to-Golang RPC bridge https://github.com/spiral/goridge 
How come you chose to make `Config` the object which makes requests? I'd assume it would be something like `Client` which accepts a `Config` upon initialization. Another thing I find useful is making your `Config` (or `Client`) an interface so that it can be mocked by others using your library.
&gt; dlsniper literally called himself an asshole in a comment elsewhere in the thread. That however does not imply you should call me as such. You could have used other ways to communicate your message. You've made your choice, much like when you said "this is a really shitty and toxic attitude" instead of "unfortunate and unwelcoming attitude". Lead by example :)
&gt; https://rationalwiki.org/wiki/Don't_feed_the_Troll /u/GentooMonk so... you think I'm trolling thus it's ok to say: &gt; So uh, yeah, you should seek the help of a good psychiatrist, buddy. I'm inviting / asking for a dialog and you offer nothing but cheap one liners and personal insults. This is so unfortunate.
I just wanna chime in and say.. Reading through posts in this subreddit, it doesn't take too long to see that you participate in many discussions, providing generous feedback and advice regardless of other's familiarity with Go. It's clear that you have lied to us - I don't think you're an a**hole at all! It's unfortunate that this post has degraded to insults, perhaps it would be better if none of this happened.
Yes. I figured it would be useful to use a interface instead of a struct when I was writing tests. But I still don't know if I should use httpmock to mock instamojo api or use a fake makeRequest method I thought a bit about the second option but I don't know how to implement that.
&gt; Also, fast at what? Even in the USA software developers usually have high enough salaries to afford some sort of medical care. I strongly suggest you to go to neurologists to fix your memory and concentration. You obviously have problems based on your questions. Again: we are talking about data extraction. We need to locate particular chunks of data and extract them. Fast. There can be dozens or even hundreds of these chunks, they can change their relative positions, thus accessing them via indexes is error prone and there should be a way to access them via some name: structure field, map key, etc. 
"When in doubt, shell out". Build a CLI using golang and [cobra](https://github.com/spf13/cobra). Then call the CLI using a PHP [system call](http://php.net/manual/en/function.system.php).
Enjoy your downvotes.
I'm not sure I understand the second option. But for the first, there is a trick I like to use to mock external APIs: type Doer interface { Do(req *http.Request) (*http.Response, error) } This interface is implemented by `http.Client`, so if your `InstamojoClient` takes a `Doer` to make all of it's http requests, you can easily provide it with a mock `Doer` that returns whatever you'd expect the actual API to return. Not sure whether this is better then `httpmock` or not.
This is what happens when you have a different point of view than others. Either find people that are willing to take the time and have a discussion or get people that would rather cast you away because you don't share their viewpoints. You see now why I said that downvoting is actually better than having comments sometimes? It's so strange that the Slack, Forum and golang-nuts communities are so much better than Reddit in this regard. Nothing like this, or other similar cases in the past, has happened there. Maybe it's the anonymity Reddit provides compared to the other environments?
How is that a valid response to a question that asked you to specify your benchmarks?
Would you happen to have a good resource for comparing my options? Is there a framework or something that makes it easy to connect with a golang backend?
The go guide doesn't jump into OOP patterns with any depth. It just says that adding a receiver to a function creates a method and this method is a function on an instance of an object. Since go doesn't have classes you create methods on struct types. http://www.golangbootcamp.com/book/methods 
It's a safe bet to say that anonymity plays a factor here. That said, and to each his own, I'd take constructive criticism, even if it's a one-liner saying "Use search!" over a downvote.
You could get SO many different answers to that question. If you are used to using PHP, you could use that to build your frontend (I'm not familiar with PHP so can't help you there). My weapon of choice for frontend applications is React, the official tutorial is pretty great for getting started and you should be able to make a request to a backend server in no time.
I will response to that douchebag if he would read the whole text. This creature read #1 and came here without reading further. He would find a link to a primitive benchmark what is quite sparing to regex implementation in Go if he wouldn't stop.
It would be a lot more respectful to just link the person you were replying to to your performance file.
Seems Curt, but hardly typical of this sub. I don't doubt that there is a lot of downvoting here, and I've been the recipient of my share. But I think "toxic" is pretty hyperbolic for gratuitous downvoting.
Seems Curt, but hardly typical of this sub. I don't doubt that there is a lot of downvoting here, and I've been the recipient of my share. But I think "toxic" is pretty hyperbolic for gratuitous downvoting.
Well said. 👍
worth noting though is that you will almost always want a *pointer* to a struct to be passed into a function rather than the struct literal. Coming from C, that saves stack space (I'm not too sure about Go). The real non-performance reason to prefer it is because then you can modify the struct that's passed in because it's not actually copied and you then operate on the original. If you specifically want to prohibit that possibility inside of you functions, that's a different matter. Another thing to note that I learned recently is that interface arguments are *always* passed as pointers so there's no need to specify a pointer to an interface in a function signature.
He was replying about factual error in my text, not about the benchmark. It was rather a quibble because these group names are hardly a good way to access these groups' captured values.
How about exposing your code as a service over HTTP or gRPC? I've seen Go being called from PHP before via shell commands, and the tight coupling caused a lot of problems long-term. It doesn't matter which languages we're talking about, this way always ends up sucking.
Your statement doesn't appear to be true to me. If I pass the parameter **word** of the string type into a function called **greeting**, I would type the following: greeting(word string) That's not what's happening with struct. With struct (as in the example from the Go Tour), you're taking the parameter **v** and placing the name of the struct (Vertex) after it: Abs(v Vertex) That's not how all the data types I've seen so far in the tutorial are passed in as a parameter to a function. For your statement to be true, the code snippet in question would need to look like this: Abs(v struct) I know I'm probably missing something but just trying to clarify my point of confusion with you. To recap: I've been seeing/expecting: &lt;func&gt;(&lt;name of param&gt; &lt;type&gt;) but this example is showing me &lt;func&gt;(&lt;name of param&gt; &lt;name of struct&gt;) 
Ah. reading a little closer, I see the article is talking about compiling the go code into something that looks like a C shared library, then calling the library as if it were written in C. They do it that way because all sorts of languages support calling native (C) shared libraries. PHP supports this via [Zend](http://php.net/manual/en/internals2.ze1.zendapi.php), but it means you'll have to build a module to extend PHP.
My problem with queries is that they're magic strings. You get no guarantees about anything. Did you typo something? Did you pass a string to a column expecting an int? Did you remember to update the name of the column when you migrated the database to the new schema? Yes, sure, tests will catch this. But I program in a statically typed language so I don't have to worry about that junk. 
named types vs unnamed types : `type Vertex struct { X,Y int }` is a type definition of the named type Vertex. so you just reused the type Vertex you just defined. `func Abs(v struct){}` is not valid Go syntax anyway. `func Abs(v struct { X,Y int }){}` would be valid, but why would you bother typing struct {X,Y int} over and over again when you can just reference it by a name? imagine your struct having 30 fields ... &gt; but this example is showing me &gt; &lt;func&gt;(&lt;name of param&gt; &lt;name of struct&gt;) No , it's not name of struct , it is the type Vertex you just defined. It's a named struct type, not the name of struct. edit : why would it be surprising? did you ever write C code or Java code ? if you define a class Foo, then you reference the classname Foo as the type of the argument, you just don't use the keyword class .
Might be best to extract current data and use something like csv to import it into a new database like (maybe using go) system. Go is general purpose enough to be able to do something like this, however you would be way better off writing it anew. Legacy code has all kinds of issues typically, and excel worksheets are more fragile that most (this is from experience btw). Look at gonum as a tool to make this happen. It's likely got everything you need. 
Man this explanation makes a lot of sense. I had to read up a little on named types vs unnamed types. That, in addition to your answer, clears it up. Thank you!
Ha ha, yep that's my fallback plan. :)
If PHP has an efi library that can call c-style functions then you should be able to do that. I didn't look into PHP but will and update that write up you referred to above.
Yeah, I don't want to shell out if I can avoid it. This code needs to run in the context of a web server. . . Django, nodejs, RoR etc. and I need to support PHP frameworks too. So I need to be able to call my compiled Go code from a PHP app server. A locally running gRPC/http service could work but I'd rather not deal with spinning up an additional service on a local machine - it may be difficult to do as this code needs to run on environments I don't control - difficult from the IT/operations side of things. EDIT: on second thought, it might not be such a pain doing something like this: https://www.reddit.com/r/golang/comments/6xwc75/anyone_know_a_good_way_to_call_golang_library/dmixig0/?context=3
Interesting. . . I'd still prefer the native library approach if I can find a good/clean solution. Thanks.
Oh wait, you wrote up that medium.com post? EDIT: just looked at your history, it was you! Wow, thank you so much for that article, it's super helpful!
Yes!
Nice. It's times like these when I really appreciate reddit and the Internet. :)
Right, probably obvious but I'm looking for a clean and simple solution which doesn't involve a complicated build system. Golang makes this a lot easier because I can cross-compile for different operating systems (from one build host) easily. I need Linux support right now but might need to support Windows too. Also, I prefer Golang to C/C++ for plenty of other reasons. :)
slack is dead. hundreds of channels with very little activity in any of them. This community is thriving. This community had its very existence threatened by deviant Go core team members. Right now, 273 people are reading this sub, sometimes the visitor count reaches into the 500s. I am sure that this sub gets thousands of unique visitors on a daily basis. The biggest issue I see with this sub is the lack of effort by the moderators in key areas, and overtly aggressive moderation of stupid little things.
Which key areas do you feel are being undermoderated?
This thread is very hypocritical in nature. And even more so when you consider parts of past conversations of yours.
The algorithm is briefly explained on my page here: https://www.michaelfogleman.com/static/quads/
I wouldn't consider any other approach then exposing Go as a service honestly. If you implement a native client for every single language (ruby, php, python, ..) have a completely different system for native extensions / modules. Native modules will be different across different versions of those languages, multiply that possibly by different platforms, THEN potentially by various language runtime containers (for PHP you use to have the SAPI which provides different memory ownership models and constraints vs the CLI) and all the quirks with endianness and so on. This is before you even started to write any Go and typed import C; after that you have to deal with making a interface that can hold up to the hostility of all the various callers. I imagine you will end up making several Go packages to write your primary business logic to satisfy the diversity in interfaces provided by the native clients. I promise that you will without a doubt spend 99.99% of time your time very annoyed debugging EVERYTHING except the Go code you wrote. To add insult to injury your users don't want to use native client libraries either. I'm sure you don't like to pip install a python module and see swig pop up with 400 lines of red gcc errors. Make a service. Have the service listen on a addr. Let addr be a unix socket or URL. Finally use GRPC to spin up a server and have a client maintained for EVERY language by google and GRPC contributors for free, that your users may ALREADY be importing and familiar with. They also have the freedom then to start your Go binary anywhere, docker containers on TCP, bare metal unix socket, put it on a separate pair of machines all together, start it up on their own local dev boxes for testing, etc. Just food for thought. gl either way.
Well, then ask them, what's their alternative? Of course if you can get a cryptographer to do the design or even the implementation for you it's better, but concretely that's not going to be always possible. That's one of my peeves with the "security minded" community: quick to say what's wrong when they have no better alternative. There's a lot of ego playing into it, too. ("Only I am smart enough to use crypto!") (A lot of thought went into that library to shield you from most common mistakes.)
Holy shit, it's Fogleman! I love your work, dude.
Haha, thanks!
this is now supported https://github.com/yl2chen/cidranger/issues/2
The purpose of the interface is to allow easy testing against simple base implementations, and also a way to allow addition of other implementations in the future.
lost me at point 1. 'regexes are hard to read and debug' No. No they aren't. This is always a lie. Even a complex difficult to read regular expression is far easier to debug than the alternative using loops and multiple conditional statements in any programming language. 
For testing, you can define an interface in the tests.
[removed]
[removed]
[removed]
Initial rough cut here, would love to collaborate if this might be useful to anyone.
Wow! Didn't expect this at all. Definitely all the credit to you for the idea - I thought it was so cool I had to see if I could do it myself!
Just from some quick trials on my computer: Small image (512x512 px) 250 iterations: 1 s; 1000 iterations: 2.3 s Larger image (2048x2048 px) 250 iterations: 17 s; 1000 iterations: 45 s Maybe @FogleMonster could share how long his Python version takes in comparison
Your project is difficult to setup but it's easy to fix. You should probably vendor or at the strict minimum list your go dependencies. I would recommend that you document that python can be used to *enhance* the program to allow gif creation, it's not required strictly speaking for the program to function and it just adds more dependencies (bash and python aren't standard on windows ;) ). You should also document where we should put that python script. Looking at the code it seems to only look in the local directory but in my case I build the executable somewhere else and the script remained in the `quads/` folder. There's also an error in your requirements file as it requires double equals. As a last note, and this is more about the code itself, check that the ``.out`` folder exists and create it if it doesn't. I thought your program wasn't working until I peaked in the code and realized that I needed that folder. The default iteration is 20 and not 200 ;) It works great though!
If you're talking only a couple hundred chunks in the result it might be faster and more cache friendly to simply use a slice. Maps don't make everything magically fast. 
Thanks for your help! This is one of my first go projects/ projects used by os community so the setup steps definitely need some tweaking and feedback.
Perhaps you can add a benchmark using the `testing` package so that it can be done simply by `go test -bench ...`. (Also a good exercise about the idiomatic testing if you're learning Go)
Recommending to do something one way "always" is wrong almost always. "Pointer vs value" is a: It depends.
I didn't just complained, I also sent some PR love in your way :)
https://en.wikipedia.org/wiki/Crt0
**Crt0** crt0 (also known as c0) is a set of execution startup routines linked into a C program that performs any initialization work required before calling the program's main function. It generally takes the form of an object file called crt0.o, often written in assembly language, which is automatically included by the linker into every executable file it builds. crt0 contains the most basic parts of the runtime library. As such, the exact work it performs depends on the program's compiler, operating system and C standard library implementation. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
this has been done.
I would find two features useful: 1. Recognize schema changes and therefore attach triggers to new tables too. 2. Make it filterable on the producer site.
You are right – context cancellation shouldn't hide shifted slave complete. I have changed it. Actually, a frozen slave can block the function at all. But I prefer to delegate context following to functions itself. What about the function signature? I really don't like anonymous interfaces. It looks poor. But it helps to instantiate the behavior once and it saves memory and time.
You must talk about a different Slack then. There's a lot more content generated in a week than here and the golang-nuts combined. As for users, there are usually around 2k users at any time active. I can publish the stats if you want. So please, before you make such statements, make sure you have your facts right.
[removed]
You lost the context.
Go applications are just binaries, you dont need a runtime like Java or .Net. If you want a microservice architecture i would suggest Docker
Because the value is not encrypted and authenticated. The remote user can modify the value at will. If we only stored a random number in the cookie like a session id, the user wouldn't be able to do much with it. But then we need to get the associated information on the server side. This incurs a shared resource access like a database with a cache at each request. Secure cookie, which are cookies with encrypted values, allow to store sensible value in the cookie. The price to pay is to decrypt and check the validity of the value for each request. But this minimize access to a shared resource like a cache or database. There are pros and cons for both strategies. The optimal choice depends on the backend architecture and load.
Ah, ok, my bad. I think that could be a bit clearer in the docs.
For real time communication you would use websockets. And for interactive ui you can use a front-end framework(Vue, React etc.) of your choice or just jquery. Resources: + [Javascript API for websockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) + Libraries/Frameworks: [gorilla websockets](https://github.com/gorilla/websocket), [melody](https://github.com/olahol/melody) + Examples: melody's readme, [wsrooms](https://github.com/godwhoa/wsrooms), [chat](https://github.com/gorilla/websocket/tree/master/examples/chat) (search around github you'll find more examples) + [Freecode camp for learning front-end dev.](https://www.freecodecamp.org/) Good luck!
Thank you very much for taking the time to review my code with scrutiny and providing such a detailed report. I already change my code to use append everywhere. This simplifies code since the precise computation of the buffer size could be removed. I made the mistake to assume that the string passed to the w.Header().Add() would be used and released immediately. You are right. This is an error and something to change ASAP. The API you suggest is very elegant. I'll adopt it. But I'm not so sure about interface{}. I don't see the benefit to support types beyond string and []byte. I thus plan to provide only a SetSecureString(http.ResponseWriter, string) and SetSecure(http.ResponseWriter, []byte). 
Added benchmarking https://github.com/sirkon/ldetool/tree/master/benchmarking . `go test -v github.com/sirkon/ldetool/benchmarking` 1. Simplest case for Ragel and stdlib regex: BenchmarkLDE-4 20000 61720 ns/op BenchmarkRagel-4 10000 141298 ns/op BenchmarkRegex-4 500 3911240 ns/op 2. Harder case for Ragel and stdlib regex BenchmarkLDE-4 20000 89507 ns/op BenchmarkRagel-4 2000 624023 ns/op BenchmarkRegex-4 100 20075473 ns/op And the LDE is the most easy to use, while Ragel is the hardest since it is barely an improvement over manual code writing with `bytes.IndexByte`, etc, just slower.
Not really complex in this case. But it's convinient to not to have to think about what data to offer in what endpoint and in which amount and it's very nice to have a statically typed contract upfront in form of the schema.
Oh, please... - No, quite often, you'd want to pass struct values "as is"--making copies at the call site. If your struct type contains just a few small fields, that's absolutely OK, and won't result in performance drops. - "Interface arguments" are *not* "passed as pointers". If a formal argument of a function has interface type, the actual argument might first get "boxed" (but only if needed) into *a value* of interface type, which presently, in the Go implementation known as `gc` (that one originally from Google), is a struct of two pointers, and that value will be *copied* at the call site -- just like any other value would. So yes, most of the time pointers to interfaces are useless but not due to the reasons you described they are.
Please add more information to the README. How does it work behind the scenes? Does it use a PostgreSQL feature?
I know my facts. Slack is dead - even the irc channel gets more traffic than go slack. 33,307 readers(33,307 idle users to your 2000 idle users) 302 users here now(302 users actively engaged in a task that directly relates to /r/golang, to your possibly a few hundred messages an hour across all channels, of which most is crosstalk)
[removed]
[removed]
[removed]
What happens when pqstream looses connection to the Postgres database? will it resume at that point in time or just resume where Postgres is at?
&gt; I know my facts. Slack is dead - even the irc channel gets more traffic than go slack. &gt; 33,307 readers(33,307 idle users to your 2000 idle users) 302 users here now(302 users actively engaged in a task that directly relates to /r/golang, to your possibly a few hundred messages an hour across all channels, of which most is crosstalk) Here are the numbers from the Admin console of Slack. I believe there's no need to say other words :) Active users: https://i.imgur.com/UF6WmrZ.png Messages: https://i.imgur.com/zCHCRmi.png Slack is dead. Long live Slack! :)
A good question would be, why wouldn't you rely on connection/read timeouts to notify you if the connection has gone dead. The peer object has a Close function [which is invoked when that happens](https://github.com/jcelliott/turnpike/blob/v2/client.go#L104). Peer is an [interface with a Close function](https://github.com/jcelliott/turnpike/blob/v2/peer.go#L18) which I strongly suspect that you can implement by yourself. For example, you could take [websocket.go](https://github.com/jcelliott/turnpike/blob/7e538cf1709832669045b8a68ebeda27582858fb/websocket.go), put it into your project and update whatever you need in the Close function. Maybe I'm just misunderstanding your exact issue with it? As always with open source, if you can't get the support from the original author (against payment or whatever), research if you're willing to fork the project, add the functionality you need and submit a pull request back to the original project.
like i said, its idle users and crosstalk.
PHP doesn't have a FFI, but LUA does, and [LUA is available as a PHP extension](http://php.net/manual/en/book.lua.php). While I haven't used PHP and LUA in this way, I did actually [contribute the LUA example](https://github.com/vladimirvivien/go-cshared-examples#from-lua-contributed). Technically you might need LUA JIT which PHP might not have (there's a C toolchain behind it...)
&gt; like i said, its idle users and crosstalk. You are assuming that 600 people are actively doing something here. Most of them are reading the messages and that's it. Exactly like in Slack. The only difference is that Slack generates more content than this place and golang-nuts combined and there are a lot more topics discussed.
Haha, he wrote it and &amp; contributed the LUA part ;)... we're all here
One big Golang party!
Interesting. . . thanks for the info. I did find this which seems like my easiest/most viable option atm: https://github.com/kitech/php-go
I'm not the author, but I've used Postgres to do exactly this in the past. It's using the built in [Notify](https://www.postgresql.org/docs/9.0/static/sql-notify.html) feature, which allows notifications to be broadcast to all connections listening to developer named channels. To do this, the package is automatically creating triggers for update operations on the specified table. It's a very useful feature, however has a few drawbacks: Firstly, it's possible that the queue will become full (although rare for most workloads, the queue is ~8GB), causing transactions to fail because of a slow or blocked client (see the notes section in the docs for details - we did get hit by this a few times). Secondly, there is a maximum payload length (8000 bytes, hard coded into postgres), so updates to large rows (for example, JSON documents) can fail. Finally, it requires the client to stay connected to receive all updates - a disconnect means missing any updates broadcast during that time. We eventually wrote a wrapper around our core database operations and now use RabbitMQ to broadcast updates, which has its own set of drawbacks but suits us better, whereas PostgreSQL's Notify feature is probably suitable for a lot of cases.
So is [this](https://stackoverflow.com/questions/29805583/how-can-i-pass-struct-to-function-as-parameter-in-go-lang?answertab=votes#tab-top) heresy or both ways are identical in behind the curtains?
On go slack, I see crosstalk and idle users. On /r/golang, I see informative posts created by members of this community about topics that span the entire Go ecosystem, posts to content made by prominent devs within the greater Go community. I see self posts asking for help and a community answering the call. I see posts about new projects - hobby and production quality. I see posts announcing upcoming events. Posts by /u/campoy, that link to high quality content produced by him for us. Many people within the go community post original content here, and many topics get here by way of others that enjoyed the content, so decided to share it here. /r/golang trumps all. However, I also see people like you. People that are mean and bitter. People that attack others about silly stuff like reposts. People that nestle asteisms within their comments. People that attempt to destroy this community from within for some ulterior motive. You have shown your cards, your motive is no longer hidden. However others like you still hide in the shadows waiting for their chance at an attempt to weaken us. 
It'll resume from whatever point Postgres is at. If you want durability, you'd be better of wrapping your database operations and using a message queue like RabbitMQ.
512x512, 1000 iterations: 1.7 seconds 2048x2048, 1000 iterations: 2.1 seconds 
And if rabbitmq fails... Wish databases had this built in 
No problem glad to help, I can't argue against []byte over an eface either. Looks like this cleaned up into a solid package good work.
separating the application from the quad-generating library would be great. Then you can try to use your quadgenerator as a library for another application.
RabbitMQ allows you to have a cluster of nodes, and unless they all go down at once, your messages are safe. Even if you have just a single instance, RabbitMQ can be configured to write messages to disk, so even if it does go down, you shouldn't lose anything, and the producers can resend anything that wasn't acked by the server. At least, that's the theory.
Perhaps https://github.com/mgdm/MFFI or https://github.com/m6w6/ext-psi would work for you. Even with a 1y+ commit date, MFFI could be stable on the usual PHP versions, unless you want to run cutting edge PHP &gt;7.0 stuff I guess. The module system doesn't get changed as often as PHP versions get released, I think it only changed twice during the 5.x branch. Mileage may vary.
There are few Go serverless frameworks around, I guess it is closest you can get. Not sure how mature/stable they are though
Very true but that does not protect against network interruptions. Unless the local client on the postgres server does local disk caching
There’s also ANTLR: https://github.com/antlr/antlr4/blob/master/doc/go-target.md
Do you plan on making a video? I'm having a hard time following the logic without visuals and audio.
Not so sure about that; I've been burned too many times trying to write some kind of regexp, pulling my hair out trying to debug an edge case and finally end up rewriting it into "non-regexp" code, that's easier to read than weird symbol combinations a la regexp.
Very enlightening !
I know that, I didn't mean I need runtime or VM. Just a click-and-deploy container for them, something simpler than deploying docker images, updating them etc.
And regexp is super slow
Cool makes more sense now with that change, master fails, shift elapsed, slave can return immediately after retrieving a result, got it. So for the function signature API design is subjective, so at the end of the day you should design the way that makes sense to you. I am just saying I personally from experience know that any API that proxies your result for you in Go is very unpleasant to use. This is because the only way to do this is with the empty interface. So the user has to type assert as well as cause heap allocations for things that may have been stack allocated. It causes multiple return values which means you are forced to use: if eface, err := something(); err != nil { ... } if t, ok := eface.(T); ok { ... } Verse me using a local var: var t T if err = something(&amp;t); err != nil { ... } This makes for nicer API's in Go and this general principle of pass a ref applies for your libraries problem space as well. x/sync/errgroup is a good example of a similar problem space as yours, but in a more idiomatic API. Returning values as you are is natural in dynamic languages, or static languages with generics, but in Go pass by ref combined with first class functions and channels for synchronization in local closures is what I and many others prefer. I tend to provide any utility functions that help with control flow, concurrency, error propagation etc one of two signatures: errfn: func() error ctxfn: func(Context) error These two function signatures can be used as powerful buidling blocks along with language primitives to solve any problem I've come across. So I use them everywhere throughout my code base, since functions are values it allows me to do things like: // has methods: type Service interface { Stop(Context) error Start(Context) error } func StartServices(svc ...Service) error { var g errgroup.Group for _, s := range svc { g.Go(s.Start) } ... Same for your package: MasterSlave(ctx, timeout, masterSvc.Start, slaveSvc.Start) By using common function signatures that people already use and only enforcing new interfaces when absolutely necessary you make it easier to use your library. I import it and it does the thing I need it to, I don't have to stop and honor your interface even though I won't use it. In fact just writing this example showed me you anyone who doesn't want to return a value at all now has to return "nil" for no real reason. Hope this makes a stronger case for what I was trying to explain. Happy coding. Edit: Almost forgot to mention that there are groups of SJW's that will request you to change the name from MasterSlave. They don't actually care of course and are only hoping you refuse, so that way they have a reason to be angry so they can lash out and try to hurt you the way they feel hurt with their own tiny unhappy lives. They have been known to call people out to get fired, death threats, on and on. They are essentially terrorists. Are you afraid yet, lol? It's not worth provoking them so I would name it something like **"failover"** since that may be closer to the actually computer science mechanisms in motion here anyways. Replacing any references to Master or Slave with primary / secondary.
You made a significant contribution to it. You now share part of the merit :)
Using Python and Pandas might be a better fit to be honest.
I think the proposal is to distinguish between var declarations and := declarations if I'm reading the top post correctly, for the shadowing variables search.
The problem is that that's not the only way to shadow identifiers. And even if there would be a distinction, I don't see how that would not generate a false positive (I might be missing something as well). Improving go vet or other tools is definitely something that can be done. However scoping makes things really tricky and that's why this cannot be done at a compiler level (and it's disabled by default in go vet). That's why I was asking about previous discussions on this subject.
Yeah I was thinking of 1 from the start -- got the simplest thing out first. 2 is obvious and got the same treatment. Thanks for the feedback!
Thanks for following up here. I'll try to get some of this into project docs. edit: There is a now a fallback to query separately by id if it appears the 8000 byte limit has been met.
This is built using listen/notify and has no notion of resumption, time, cursors, etc. I'm not opposed to adding some of these concepts.
In your example you are shadowing the retryValue variable. The ones in init belongs to the scope in the init function. As you already mentioned, the solution to this is changing it by declaring the error up front and using `=` instead of `:=`.
Thank, bro! I'm looking for a more elegant solution for this! :)
Figuring out a message guaranteed system with this is I think impossible, but this is already a fantastic debugging tool and to record certain processes. Have a third party server application that you are going to upgrade with a black box install package. This will give you a fantastic insight 
I was hoping nobody would mention the SJWs, getting quite sick of this frankly. If the repo is small enough it might not have been noticed. Or move to another service, I don't know how Gitlab is with SJWs. SJWs have pushed me to stop releasing things as open source and just do private gitlab repos, look what they have done those SJWs! Edit: there are over 1190 Github repositories with "Master Slave" in it, I would leave it until an SJW actually comes around and then deal with it. I would dash, move to another service if that happened to me, but renaming it to something else is always an option and bowing down to the SJWs even though Master Slave more accurately describes the pattern. Edit 2: it seems that Gitlab is no better for having an SJW problem, it seems like we have lost already, which is why I have started new things as closed source essentially.
His answer pretty much is the cleanest way aside from ```Must``` take a look at the ```text/tenplate``` or ```html/template``` packages. 
I'm not sure how your program looks but using init functions seems a bit weird to me. It is better to avoid using global variables and to do this kind of parsing in your main function and then passing it on as a parameter to the `a` function.
Not sure if it's specific to this EAP, but with Go 1.9 and the latest Delve (bundled) compiling for debugging takes significantly longer. It used to be like 1-2 seconds, now it's several times that. Probably has something to do with Delve trying to recompile the Go runtime...
Love it!!! Time to brush off that ol midi card
Hi /u/callcifer. TL;DR yes, that's correct. Gogland will build the debug binary with "go build -a .... package/name ...." in order to debug it. If you want the old behavior, then you need to go in Settings | Build, Execution, Deployment | Debugger | Delve and toggle Rebuild transitive dependencies. However, this is discouraged and for any debugging issue you have you'll need to first turn that back on and then report the issue. This is because Gogland will bypass what Delve would otherwise do when running "dlv debug package/name". There are plans to have better support in Go 1.10, hopefully, but this depends on work from the Go team as well. Now for the longer version: You are correct, the compilation speed has degraded a bit when using the EAP 12+ because of improved debugging support. What happened is that Go 1.9 can now do a better job at compiling the transitive dependencies with all the optimizations turned off which means Delve can work better on your application. This means everything in GOPATH/pkg and GOROOT/pkg is recompiled for debugging in order to ensure that there's no package that has been included accidentally with the optimizations on. If that would happen, then you could potentially end up with a package that does not debug as well, and sometimes that could even be one of your packages. Unfortunately, for now, optimizations off builds are not cacheable, due to how "-a" works. This means "go build -i -a -gcflags '-N -l' ... package/name ... " is not possible at the moment. Delve itself would apply the "-a" flag when running "dlv debug ... package/name .... " so, while you can turn the "-a" flag off in Gogland, I would advise against it (or you'd have to redo the debugging session using it in case you encounter any bugs since this is not a mode supported by Delve officially). For a link to the original issue, please see: https://youtrack.jetbrains.com/issue/GO-4249 Hope this helps.
I see, thanks for the explanation :)
This was released a few days ago and seems interesting. Anyone have any experience with it? How does X-Ray compare to New Relic and their Go agent?
Is there a general purpose private key wallet? Is the closet thing available pgp? I would be nice to have a general purpose and portable private key wallet that could then be used with other applications like Bitcoin or Ethereum. 
that just means you don't know regex. programming in any language you don't know is always more error prone than learning the language in which you are programming.
Use gogos implementation. About 10x faster than json.
~~Regarding performance, how close is this to release?~~ ~~I opened up a simple ~5 file go project and after a few minutes Gogland is using 856MB of memory and feels a little sluggish. I opened a 56 line file and it took somewhere between half a second to a full second for the text to show up with colors matching the theme. Is that just the cost of an IDE or will there be improvements before release?~~ See below
/u/dlsniper helped me on multiple occasions in the gophers slack #golang-newbies like 2-3 years ago (I had a different username there). As far as I recall, he was very patient and took the time to explain technical details, even with code snippets. The general atmosphere of the gopher slack made me stick with golang for the long term. I just wanted to say thanks dlsniper, for helping go newbies like me progress and grow.
Thanks, after some research I think I might use Vue.
Yes! :) Let me know if you need any help.
Can you please open an issue following the instructions here: https://intellij-support.jetbrains.com/hc/en-us/articles/207241235-Reporting-performance-problems Also make sure you provide the log files via Help | Show logs in... Was the IDE still indexing the project? How big is your GOPATH? Is the project open source or can you provide a minimal example to reproduce the issue?
I played around a little bit and figured out the text issue is just a delay when switching themes. I switched from the IntelliJ theme to Darcula with a project open. After the switch the text in each file takes around half a second to update to the new theme when first opened. I may have been a little quick to give up on it. I just assumed it was slow when I opened 3-4 files and they all took a second to display properly. Having played around with it a little more it doesn't feel so bad. I will definitely keep trying it out.
Been using Gogland since early EAP builds. It's been progressing really well and certainly my go-to IDE for Go.
Could you do a benchmark that does more than look for single characters?
Really enjoying this for the past few months. Will be an easily justified purchase!
I just use systemctl. On a application that I write that will be deployed by other people I typically have an install flag that will install the default definition files. I've seen a few process managers around, but they are usually abandon because they are providing the same functionality as systemctl or similar anyway.
&gt; You should probably vendor or at the strict minimum list your go dependencies. If you are unsure about what dependencies a project needs, let go figure it out for you: In the project root: go get -v -u -t ./... -v is verbose, to show what packages are pulled -u updates packages already in your go/src tree -t also pulls packages only used in *_test.go files and ./... travels the directory hierarchy go help get for more info!
I love a good regex and have never found them hard to read or debug. They're great. That said, they are simply slow in Go. I had to parse several dozen million lines and using a capture regex was rather slow. In fact I lazily benchmarked it against python2.7 and python actually ended up faster (no go routines and the like, just a big ole loop). I checked into this a little and from what I could tell the underlying C regex functions for python were simply faster than Go's. Hardly a big deal - the speed and beauty of Go is not geared towards that example. But if you are doing a ton of line parsing it is way faster to do as this library does and forgo the regex in favor of string extraction. Get that shit in some go routines and watch it fly. 
Yeah, this looks interesting. I'll be sure to play around with it.
How it's in comparasion with VS Code? Who used both?
`vendor` is inside `/quads`
Is there a reason benchmarks are not one-iteration-per-line ? I was trying to compare it with few [ugly regexes](https://github.com/efigence/go-haproxy/blob/master/httplog.go) (which still somehow takes "only" 15us per line) and was wondering why mine were faster till I looked at the code of how benchmarks are made. If you really want to iterate over different examples in same benchmarks (IMO those should just be separate ones) you can always extract it inside the loop like that: for n := 0; n &lt; b.N; n++ { line := sample[n % sample_count] ... } 
Yes, I found it. Was just adding some useful info in reply to /u/Kraigius
proto2, can't just switch in a jiffy because of dependencies and published IDL definitions as protobuf files.
Just saw this and it sparked my curiosity, I break down my programming by "workspace" as well using env vars. I was curious what approach your project took, do you have any write ups that show the technical details of what you are doing to users machines? Specifically I'm extra curious about the bindfs, given the flexibility of the GOPATH I'm curious if or how it is required. My workspace user is jailed and (apparmor|selinux) rules won't allow access block devices or bind mount with the device mapper. If for example on a more detailed document page if you had the output of: command -v vg &gt;/dev/null 2&gt;&amp;1 &amp;&amp; eval "$(vg eval --shell bash)" I could probably fill in the blanks from there. My apologies if you have a document and I missed it.
Would love to see this feature in one of the very next releases 8-) https://youtrack.jetbrains.com/issue/GO-2953 GO-2953 Add text/template and html/template syntax highlighting 
/u/markharrisuk99 Thanks for your question. I hope you got a chance to have a look on features, documentation of `aah`. aah design and implementation is unique among other framework. It is highly configurable, extensible modules (configuration env profile, security, internationalization/localization, server extension points, event publisher, go template engine with inheritance, error handling, so on). Seamless integration between modules. It's long way to go to achieve my goals. BTW last year June 2016 I started my work on aah framework and first release to audience on May 2017. Before I started aah framework I was core developer of known framework.
Performance wise and hotkey wise, I prefer vs code. Try running Gogland on MacBook Pro and it stutters like crazy. (For me at least). 
yeah its god damn slow on MBP
&gt; my go-to IDE for Go. \^_^
A design document is probably a good idea, but I'll answer your questions for now. The output of the command you ask for can be found here: https://github.com/GetStream/vg/blob/master/data/sh. (This does not contain the code generated for tab completions by `cobra`, but that's not the interesting part). All commands that are not implemented there are implemented in the go code in the `cmd` directory (some are partially implemented there), this is to allows me to not have to write everything in shell code twice, once for bash/zsh and once for fish. At it's core `vg` is just a very easy to use wrapper around GOPATH manipulation. It basically creates a new GOPATH for each workspace. If global fallback import mode is enabled it falls back to the global GOPATH by setting GOPATH to `/new/path:/old/path`. So it's probably not much different from what you're doing now except for [the points noted in the README](https://github.com/GetStream/vg#advantages-over-manually-managing-multiple-gopaths). Regarding `bindfs`, it's only used when using [full isolation import mode](https://github.com/GetStream/vg#workspace-import-modes) or when using the `localInstall` command. In the previous version a symlink to a project outside the workspace would be created inside the workspace in both of those cases. There's some [issues with symlinks inside the GOPATH](https://github.com/GetStream/vg#without-bindfs-installed) that `bindfs` solves. It is not required to install it but full isolation mode is not recommended at all without it. A package installed with `localInstall` will have the same issues as described in that section. However, this is usually not as bad since it's not the main package you're developing on. Also, I'm not familiar with your jailed setup. But are you sure that you are not allowed to use [`bindfs`](http://bindfs.org/)? It's based on [FUSE](https://github.com/libfuse/libfuse) (Filesystem in Userspace). This is the reason why I chose to use it instead of `mount --bind` which requires `sudo` on a lot of setups (and is not available on OSX).
Sorry, I am not sure I understand the question. Warpwallet is a brainwallet for Bitcoin. Do you mean it would be nice to add support for Ethereum as well? 
My main issue with VS Code is that it missed code dependencies within my project. Tossed it after it only refactored half my code when renaming a variable.. And currently, Gogland is getting quite great performance-wise that it's not really an issue anymore. It used to be though.
I'm sorry you are having these issues with the IDE. Have you tried the the latest version or was this for a past version? When you try it next time, if ever, can you please take a minute to help improve it? You can open an issue following the instructions here: https://intellij-support.jetbrains.com/hc/en-us/articles/207241235-Reporting-performance-problems Also make sure you provide the log files via Help | Show logs in... Some additional information would be helpful as well: Was the IDE still indexing the project? How big is your GOPATH? Is the project open source or can you provide a minimal example to reproduce the issue? Thank you.
I'm sorry you are having these issues with the IDE. Have you tried the the latest version or was this for a past version? When you try it next time, if ever, can you please take a minute to help improve it? You can open an issue following the instructions here: https://intellij-support.jetbrains.com/hc/en-us/articles/207241235-Reporting-performance-problems Also make sure you provide the log files via Help | Show logs in... Some additional information would be helpful as well: Was the IDE still indexing the project? How big is your GOPATH? Is the project open source or can you provide a minimal example to reproduce the issue? Thank you.
&gt; What is a better way to handle the database connection The answer depends a lot on your definition of "better".
beginner issues: a slice is a pointer to an underlying array, so people think that because the slice itself or enclosing structure is not passed as a pointer, they assume that all the slices would be copied to the function. Alas, modifying the slice from such a function, would leave the slice modified after the function return as well. not only should you know *when* to use pointers, you should also know *when you actually are using pointers without explicit intent*. Edit: [Go tips and tricks: the thing about slices](https://scene-si.org/2017/08/06/the-thing-about-slices/).
Read this post "Practical Persistence in Go: Organising Database Access" by Alex Edwards. It gives you good directions, http://www.alexedwards.net/blog/organising-database-access
I came from Java to Go so obviously I'm bootstrapping my applications using dependency injection: https://godoc.org/github.com/facebookgo/inject Inject from Facebook is a useful tool which also offers named dependencies so you can have different sql.DB objects injected into your handlers. In my opinion it's not the easiest way to solve the problem but its a clean one.
Updated on windows, now always freezes when trying to boot up. Had a few IDE errors which I was able to report before it froze, regarding some FS stuff and a stackoverflow. Can't browse the file system basically. It doesn't show child folders of my main project root folder. What's up? Can I give you any debugging information to help resolve this? Edit: rebooting my laptop resolved the issue it seems
What is your definition of better? I'm mostly looking for different approaches and views on the topic
This is exactly the kind of thing I was hoping for. Thanks!
It's a shame it doesn't use opentracing, thought I imagine it would be relatively easy to build a wrapper.
Hi, I'm sorry you are having issues with the IDE. Can you please open an issue at https://youtrack.jetbrains.com/issues/Go with your logs attached? You can find them under: Help | Show logs in... and zip up the folder that opens up. Please let me know if you need any further help. Thank you 
It is generally a good practice to [avoid init](https://peter.bourgon.org/blog/2017/06/09/theory-of-modern-go.html) and pass your dependencies explicitly. 
Done: https://youtrack.jetbrains.com/issue/GO-4439
I know enough regexp, thank you very much.
Just so you know this attitude does drive many people away - regular downvoting of reasonable posts/comments, hostile comments, and aggressive arguments over meta-drama like this are the reasons I don't visit here often. Yes, healthy communities have rules, and someone to enforce them. Reddit has IMO failed badly on this except in certain subreddits. It's a hard balance to get right, but endless meta discussions don't help. For this reason you'll find most people steer clear of this sort of meta-discussion and just don't engage, so the voices you do hear won't be any sort of consensus. No it's not toxic to be different (wat?!), it's toxic to discourage others because you can't be bothered to respond to them properly, it's toxic and juvenile to downvote for the fun of it. It's toxic to see a community as your playground which is supposed to make *you* happy, without considering the effect of your actions on others. 
Or write a factory? relying on reflection will make your code slower and harder to read.
I tried to approach real world practice with buffered readers. Take a look at sampleData function: it generates lines first, then pack them into one large area. Then I go through it, just like buffered reader will scan its buffer again and again.
Thank you so much for reporting.
I took a look at the code generated by `lde` for that benchmark, it is clear why it is so fast. In this case it is a quick way to write performant code. Some notes: * regex `FindSubmatch` allocates memory. Unfortunately there doesn't seem to be a way to avoid that. On a tight loop like this it probably contributes badly to perf. * Your regular expression as implemented requires backtracking, even though you use a non-greedy modifier. For such simple structure (essentially just a bytes.Split), I don't think there is a nice way to write a performant regex. I tried making the groups `[^|]*` instead of `.*?`. Did not effect perf (maybe perf is dominated by memory?) * The golang regex library is generally really fast. I think your example regex is somewhere it does badly (eg it can't use LiteralPrefix perf optimization)). Also golang regex library is missing many of the perf optimizations that its ancestor RE2 has. * If any of your values contain `|`, your LDE will implementation will split at that point. * I added a simple benchmark using `bytes.SplitN(line, []byte{'|'}, 6)`. It was faster than ragel, but about half the speed of LDE. I assume that was due to allocating memory, since it is essentially the same as what LDE generated, except not loop unrolled. Also I am interested in how often you are writing custom log parsers?
I've been enjoying this IDE a lot. Never thought I'd say that a year ago about an IDE, if anything being able to follow the entire development cycle of Gogland made it much easier to discover features. This type of staged exposure to new features removes analysis paralysis I normally have when looking at an IDE. I'll definitely be buying this IDE when it gets released.
Thank you very much!
&gt; I assume that was due to allocating memory Yes, memory allocation at each line is always a major performance hit. &gt; Also I am interested in how often you are writing custom log parsers? A lot, this was a part of my responsibilities at last job where I did a migration from legacy statistical infrastructure to `[ Custom Go parsers ] -&gt; [Clickhouse] -&gt; [ Custom CH queries runner ]` three.
For Mongodb this guide has a decent structure. http://goinbigdata.com/how-to-build-microservice-with-mongodb-in-golang/
This can be done without Go in nginx configs. Since vts is not a default module, I don't see the issue in adding LUA to transform the existing vts json response and not adding another service to the mix? Not that I mind very much, tbh I have quite a few Go microservices by now. What's one more...
Using HTTP2 in this way is really interesting. The potential privacy aspects of HTTP2s multiplexing have been discussed before, but this is a real, easily deployable implementation that really works. Thank you caddy contributors for all of your hard work, on this and all of the many other cool features.
Thanks but it's not just knowing the dep but also locking it to a specific version (or taking note of that version) otherwise your project can silently break at any moment.
I always find it interesting, because Stackless Python used channels and tasklets back in ~2000, and CCP Games built StacklessIO network libraries using non-blocking IO on top in ~2008 to run one of the larger single-universe MMOs around. It feels like trying to convince people that non-blocking network operations were a good thing in 2012 was long after the ship had sailed on that one.
I like to pass it around via a [composed environment object](http://www.jerf.org/iri/post/2929). I wrote that article before the popularity of the Context object, but I would simply compose any relevant Context objects into my local environment. The environment object is not really a particular object as the Context is, it's just "whatever I need for this particular bit of code", which may include Contexts or not. As you get more used to composition, you will tend to find that you are explicitly passing around a *DB a lot less often than you'd expect to than inheritance-based intuition would lead you to believe. (I know composition isn't news to the Go community but I still think there's more juice in the idea than is often understood. However, I also find that it's hard to extract the reasons why into cute little blog posts; I just find that as you build programs with composition that it tends to work itself out on this front pretty well.)
I am tempted to make a write up of how I use sqlx, with a different kind of pattern. I have a connection manager (ie, factory model) where you'd request an `sqlx.DB` from a package that serves as a factory. import "app/factory" main() { factory.Database.Add(name, dsn) ... } somefunc() { db := factory.Database.Get("name") db.Exec("...") } I'm oversimplifying a bit, but I'm dealing more with the fact of how and where to create the database handle, rather than how I would move it from `somefunc` further down the execution stack. For those purposes, the above article is very valid :)
I've seen many URL patterns that included `\d+.json` where the `.` is accidentally not escaped, but no one notices because the intended URL also works. Regexes are an okay tool. TBH, I think if we were starting over today we could do better: non-greedy by default, less common special characters, don't use backslashes because that conflicts with string literals… But it is what it is.
Please retitle as "Web frameworks for Go, most starred on Github", otherwise its subtly misteading—suggesting that there exist a correlation between the amount of stars on Github and the quality of the code (or the fact of the project being idiomatic etc), which there isn't.
I got it. I retitled the Github repository description. Should I also rewrite the title on README.md?
But I can't retitle the Reddit post
To avoid error handling one would need to do calls that wont return errors. Sometimes you can, sometimes you can't. Every func has a different use case, but for example in startup/init calls, errors always ends up in a log and an exit. In those cases I like to wrap calls in musts, like that one : https://golang.org/pkg/html/template/#Must Another good example is that get call here on a lib that implemented a functionality I needed : https://github.com/stathat/consistent/blob/75142be0209ec69bb014c7a1ac7d1a3c892c6424/consistent.go#L144 It turns out an error can only happen if the list is empty because you can add/remove items from the list. Those add/remove features cornered the dev into supporting error handling. I forked the lib and made that list read only. It made that RWMutex unnecessary &amp; allowed to remove so much error handling. Now the creator only can receive error(s). You always have to think hard about error handling. It's a set of mind that go will give to you, which is great.
I don't understand the purpose of this repo. A simple search provides up to date results: https://golanglibs.com/top?q=web%20framework
Read VividCortex' excellent eBook (email registration required): https://www.vividcortex.com/blog/2015/01/14/the-ultimate-guide-to-building-database-driven-apps-with-go/
I just ranked the Go web framework.. But, I did not know above link. :(
Should that instead be `ItemsInserted` in the readme?
I like to create a struct type that only has an anonymous *sqlx.Db in it, add functions to that new struct for your database calls (separated into categories such as users, posts, tags, etc), then use Context.WithValue to pass it up and down the stack. Create the instance in main.go, then pass it to your handler generator functions so they can be used in the http.HandlerFunc's. PM me if you want more detail! TL;DR the context package was designed for this: use it. 
The purpose was probably to build something in Go. To use Go, and learn Go.That is the easy part. The hard part is thinking of projects that can exercise the knowledge learned and bolstering the understanding of the new found knowledge. Sometimes the projects are silly. I see no reason why this project couldn't have over time morphed itself into something similar.
thanks, fixed :)
I see thanks for the explanation, the script paints a clear picture. For bindfs yea I couldn't use it as my workspace user, but I like to keep all my workspaces in one directory so it works out okay. Thanks for sharing.
&gt; TL;DR the context package was designed for this: use it. No. You should NOT use the context package for this. Please read: http://www.alexedwards.net/blog/organising-database-access &gt; Personally I'm not a fan of storing application-level variables in request-scoped context – it feels clunky and burdensome to me. The x/net/context documentation kinda advises against it too: &gt;&gt;Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions. Instead add methods to your struct type that contains the anonymous *sql.DB.
It's fast enough for a web application.
Cool, I'll take a look.
Nice, I'd to add mine too https://github.com/bnkamalesh/webgo! :D
[removed]
[removed]
Thanks. Could you send me a PR for that?
As a heads up, EAP 14 has been released to solve a critical issue in EAP 13: https://twitter.com/GoglandIDE/status/905046993034203136
Kind of surprised it has not been brought up yet but the Iris framework has a huge amount of controversy surrounding uncredited code reuse and general disregard of Licensing. It's your repo so I'm not saying you should do anything you don't want but you should be aware of the issues.
Pointer vs non-pointers is a question of tradeoff. Garbage collector is a separate program or in Go case, integrated in the runtime as part of the binary you run. It still is a separate piece of code from what we write. It looks for escape analysis generate by the Compiler to decide what to do with the memory references across function and scope boundaries. If you use a pointer vs a value, it is just fine for most of the programs. When you build programs which serve like 100s of thousands of QPS, these tiny differences add up. Since GC has to keep track of the heap memory, anything which is a pointer or escapes a function boundary needs to be constantly checked by the GC. Anything on stack just dies when the function exits. For small objects the difference usually will be negligible, but again it depends on your workload. This difference may become apparent if you do not have a powerful enough CPU or the objects being passed around are big in size. How big? Can't say for sure, measure it for yourself. There are always pros and cons. How does this affect the program? Well the CPU cycles GC spends in validating and keeping track of Heap memory can perhaps be used somewhere else, unless the tradeoff is big enough to warrant passing objects by pointer. Like I said everything is theory, unless you benchmark. PS:- I am not an expert, these are just my observations from benchmarking same programs across different environments from dual core to 64 core machines. YMMV 
yes, I've heard the issue a couple of months ago. As rethink, I should have to seriously consider whether list the iris framework in the README. Thanks for remind 
Why should users not use `context` package for this? I haven't seen any failures that this approach cause and it is very trivial to construct a `context` object using per-environment-config files. Once that's done, the `context` object is available everywhere. It's a very simple to understand Dependency Injection.
Sure thing, if you run into any problems please file an issue and we'll look into it.
I'll send the request to the devs (they are watching this as well). Meanwhile, you can see the https://plugins.jetbrains.com/plugin/8006-material-theme-ui for a different theme, albeit a more complex way to do it.
Thank you for your help. This has been addressed in EAP 14, released a few hours ago.
Your code works perfectly fine for me, assuming I'm using the same username in both places (line 69 and 114). I receive a gzip blob that decodes to ``&lt;html op="upvoted"&gt;&lt;head&gt;&lt;meta name="referrer" content="origin"&gt;&lt;meta name=".....``. Maybe I did not understand your issue?
&gt; https://gist.github.com/ns-cweber/20033179b75e3c0e301062c85b2d35e4 Maybe the "non-HTML garbage" I was receiving is simply gzipped HTML, and I was expecting the HTTP client to un-gzip it for me? I'll look into this when I get a moment. Thanks for taking the time to run it!
Actually I think GopherJS's runtime with wasm modules for builtins would outperform a "pure" wasm runtime for basically every case you'd want to run Go in a browser.
&gt; It's a very simple to understand Dependency Injection. Package context was not designed for dependency injection. From the official docs: &gt; Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions. Also please read: https://medium.com/@cep21/how-to-correctly-use-context-context-in-go-1-7-8f2c0fafdf39 &gt;The most contentious part of Context is Value, which allows arbitrary values placed into a Context. The intended use for Context.Value, from the original blog post, is request-scoped values. A request scoped value is one derived from data in the incoming request and goes away when the request is over. As a request bounces between services, this data is often maintained between RPC calls. Let’s first try to clarify what is or is not a request scoped value. &gt; Obvious request scoped data could be who is making the request (user ID), how they are making it (internal or external), from where they are making it (user IP),and how important this request should be. &gt; A database connection is not a request scoped value because it is global for the entire server. 
Agreed. I don't see any IDEs or text editors supporting that, and I have high hopes Goglang will be the first one to do it.
I've just added a ``ioutil.WriteFile("foo.gz", data, 0644)`` at the end of ``main`` and took a look at the file. Before changing the username in the ``upvoted`` function, I received the "Cannot display that" gzip blob, after changing it, it worked as intended.
The general reason for not doing this is it hides dependencies and can make testing and maintaining code much harder. https://www.calhoun.io/pitfalls-of-context-values-and-how-to-avoid-or-mitigate-them/ goes into this a bit and for longer lasting variables like a db connection the most common approach I see is to make your http handlers methods on a struct that has a db connection as a field.
You ask for a gzip response with: values.Set("accept-encoding", "gzip, deflate, br") in the client but the default Go http client doesn't support gzip response. Remove that header you will be fine. If you want to handle gzip response: https://github.com/NYTimes/gziphandler
You can write it in exponential format if that's more readable for you: https://play.golang.org/p/Of9j4fwqkG
Yeah, gzip was the problem. Thanks very much.
Awesome, thanks!
^ This makes it pretty easy... so like, the number OP mentioned is 44 billion, you can write it as 44e9 And 44 million is 44e6. You can also write it as 44 * 1000 * 1000 * 1000, which can be computed just a single time at runtime if it's marked as a constant (note that you can declare constants inside a function: https://play.golang.org/p/eHUDHy0Nro
Do you use the factory for managing sharding and the likes? 
I've written up a solution that I've used before on my blog http://blog.mobimic.com/posts/golang-composition-and-channels the main thing I did was extend the ListenAndServe method to block on a channel and not the http.Serve method.
I use https://github.com/cortesi/modd and like it
The value is actually computed at compile time, not runtime. This means you don't need to consider the complexity of the math involved – so long as it's a constant expression it'll be precomputed into the binary when it's compiled, just as if you had written the value yourself wherever the constant is used. Another interesting points is that Go constants have arbitrary integer precision so you can technically do this :) const x = 1e100 fmt.Println(x) // prints 1e+100 Note that you can't assign such a value to any of the number types: var i int64 = x // error: constant 10000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 overflows int64 But you can combine constants that result in a valid number: const y = 1e95 var i int64 = x / y // i is now 100000 Have a look at the `time` package source code which uses integer constants nicely: https://golang.org/src/time/time.go?s=21095:21114#L610
You can also use decimal places as well, even for integers, but it'll coerce to a `float64` if you don't specify the type: https://play.golang.org/p/YVT54XSXo3
[removed]
&gt; Since our ID isn’t auto incrementing we need to manually check if it has already been taken. To do this we need to open a connection to the database and query the user table to check that our ID doesn’t match an ID that already exists in the user table. That's racy.
Just use https://github.com/alizain/ulid
I've been using it for 4 years now, 3 Of which where it has been my primary language of choice for backend development or tooling. I absolutely love how easy it is to cross-compile and how fast it runs. My experience is that I spend a little more time upfront writing more verbose code; but FAR less time in trying to understand/interpret it later. Go doesn't have a ton of magic (especially compared to something like Ruby) and I've come to really appreciate the lack of magic as a feature. I've really started to embrace code generation to speed things along where in other languages you might have generics. My wife (a relatively new developer) was able to pick it up in about 2-3 weeks and I think I had a working understanding of it in a few days. It's VERY easy to pick up. What hasn't gone well? Well, the community still has a bit of distance to cover before we have dependency management wrangled. This was probably my biggest disappointment with Go (though, not *really* a language feature). Go did incredibly well with so much of their tooling. I've been really impressed with almost all of it. And then you come to dependency management and there wasn't much there, *especially* because it's a problem that has been solved before with good results. Not only would I do projects again in Go, I'll probably end up porting some clients over to Go to help lower their server costs. I hope some of that helps :) -- if you have any more specific questions, feel free to ask. **EDIT** I'd also like to qualify the above by saying: Go is still very young and showing signs of continued growth; but it also has a relatively mature standard lib. HTTP routing seems to be one of the bigger things missing from the stdlib. In any case, there are quite a few HTTP routers out there to make up for it not being present and renders this issue moot. 
IMO the best way to learn any programming language is to use it. So you should try finding exercises or programs you personally want to have and try writing them in Go. This subreddit's sidebar has links to good resources, such as http://dave.cheney.net/resources-for-new-go-programmers. Personally http://golang.org/doc/effective_go.html is a must read, and I always recommend https://gobyexample.com/.
/u/junajted The pattern described (i.e. env.Index or index(env)) in the blog post can get messy if you have a lot of middlewares. I use a adapter pattern combined with some of what he has suggested in his blog post. It is a lot more flexible, Code looks pretty good and it scales well in a large application A quick example can be found here: https://gist.github.com/ishanjain28/f85345455cf7b08af422156eb1cbc828
Most importantly, Start building projects in go. 1. Justforfunc on youtube 2. Dave cheney's blog 3. #go-nuts on chat.freenode.org 4. golang slack channel 5. This subreddit I have found Go communities pretty much everywhere to be very helpful and welcoming. There are communities on discord and telegram as well with a lot of really nice people. 
I've been watching justforfunc on YouTube whenever he releases new content. Also, keep an eye on Udemy for sales. Sometimes they will have sales on their courses for $10 each and I got a couple of Go courses on there that are pretty good. Ultimately, just like I would recommend with any programming language, just dig in and try to do a project. Start with some simple console projects and once you feel comfortable with the basics, try to tackle something more complex.
/u/tural-esger here is a sample nginx reverse proxy config to get started, https://gist.github.com/ishanjain28/615b38a4ae7720f966a00cb73c7614d8 Change the server_name to whatever domain you want to use and change proxy_pass to change the server it should direct to when someone visits one of the website
Thank you very much!
Mostly positive. I've been using Go since 2012 and since 2015 I'm using it professionally. I tend to miss some things. Most importantly - a good package manager. Proper debugging would be nice tho both delve and Go is getting there. From the language perspective: the slices are a bit tricky to properly explain and use. Same thing about interfaces - typed nil comes to mind. I don't miss generics that much, tho having them would be nice. On the good side I really, really enjoy compile time and garbage collection time. Compile - because its so fast. Garbage collector - because it's predictable. Goroutines and channels are extremely addictive and I miss them when I work with other languages. From the company standpoint - Go is extremely easy to pick up and learn. It compiles down to a single binary - which is very useful even with docker. Most of my job involves networking so I'm incredibly happy that I can focus at the task at hand, and not at the language features. And while the resulting code can be verbose from time to time, it very easy to read and understand. Which is really important when you are using third party libraries and something go wrong. People tend to forget that most of the time you work with another's people code. And that code is not perfect. Go community is a colorful one . It has bad sides. It has good sides. Go is constantly attracting people. And when people don't like what they see, they start to explain why Go is bad. At best. At worst they start to explain why everyone who is writing soft using Go is wrong or dumb. That left some mark - one of them is that community is quite defensive and somewhat conservative. A bit too paranoid about trolls. But and the same time people tend to use Go is very different areas and this results in the good and innovative discussions. Even newcomers tend to bring a interesting ideas to the table, or reveal pain points. Many libraries has sub-par quality, but at the same time are already written. I can improve and help solidify existing foundation rather than roll my own. This saves a lot of time when you work professionally with a young language, because we all have a limited amount of time and focus per day. Overall: yeah, I enjoy working with Go. And with incoming improvements and recent announcements, I hope it will get even better. 
Maybe https://github.com/cespare/reflex would fit your needs
Have a look at https://github.com/dustin/go-humanize
+1 for ease of cross-compilation; SO easy... +1 for dependency management as an issue
Love it. Using it for about 4 years now. It solves so many of my problems so well.
People have different opinions on how to build web stuff with Go. You can do it with frameworks, you can can do it without. You can do it with just better routers. The benchmarking issue is exacerbated by the fact that many people do not understand how these things work and what they are measuring. There are **very** few workloads where a few microseconds will make the difference. There are few workloads where 2-3KB of more garbage generated by the router will make the difference (especially with Go 1.9 GC being better than ever). From my experience in teaching people / helping them profile code / profiling my own code, I will usually hit the limits in other parts of the app before I can even see anything related to the router of choice in the profile. But that hasn't stopped people from trying and do things in different ways in search for their own version of what fits their views of how things should work / look like. Personally I've used gorilla/mux since 4-5 years now and never had any problems with it. It is a **very** stable and battle tested router and has a rock solid API. So I've had no reason to look anywhere else. Others found their own choice and used that first.
Pretty cool! I was thinking of something like this over the weekend (while I was away from my computer) and when I looked today I found it "done" :) One thing: I have tried to test it on my Mac, with this http://supertintin.net/midikey.html. The app listens to the notes but never plays anything. Trying to debug... (and I have verified that portmidi can playback via MidiKey) 
I think it is absolutely aweseome, I have been writing a web application that is portable (windows, linux and MAC) and it just makes this task so easy in comparison to other technology stacks I have used. I had to write a simple proxy server for out communications layer running on raspberry pi, and voila, easy peasy, write it on my desktop, test it, and then cross compile to the pi, and it really did simply work out of the box. All my tooling that our customers will need are written in it too, this way they work anywhere. The only thing I am really missing a lot is a great debugger, I am getting around it, and have been for the past 1-1.5 years, but really miss visual studios, or even XCodes debugger. It is getting better however, and gogland seems to be making better strides in this area as time moves on, except I us VSCode. And yes, it can be a bit more verbose, but as I read somewhere else, it pays off when you revisit the code, and you are able to understand it immediately.
The solution that I currently use it to watch the binary – and *only* the binary – the application was started from for changes, and recompile &amp; restart the application when that changes. I find that this works well for me; I can just use `go install` (or `:make` from Vim) to recompile and restart the application, and it doesn't do thousands of unnecessary (and sometimes unwanted) recompiles every day. It's also a *lot* more performant over "remote" network drives (e.g. when using Vagrant or Docker mounts). Here's the code I use; it's not a public repo (yet) as I need to remove the dependency on our very organisation-specific `log` package first; I put it in a gist for now (the code is very simple): https://gist.github.com/Carpetsmoker/983d6526307e0a08f78635474a7dc58d You'll want to replace those two `log.*` lines. Start it in a goroutine. The downside of this method is that you need to modify the application's code. Some of my co-workers have been using https://github.com/canthefason/go-watcher . 
As a noob to go I agree. It's hard to know where to start and frankly none of the ones I have seen are comparable to ruby, python, elixir or Java frameworks. They all seem like they were slapped together in a day and none of them are suitable for writing a real world app. I would love to be proven wrong but if somebody came to me and said they needed to build a web app I would say go with elixir or rails not go 
I'd like to echo all the points made here, and modify one: &gt; I will usually hit the limits in other parts of the app before I can even see anything related to the router of choice in the profile. I will *always* hit the limits in other parts of the app before I see anything related to the router. 100% of the time. Performance benchmarks in this arena are ridiculous.
Haha I wouldn't call it "done". I think there are lot of cool things to do, with this program or writing a new one. I wrote a python version of this that automatically determines chords and tries to play certain scales over songs - I will probably add this in the future. Feel free to fork, you should be able to throw out the ai modules and add in your own pretty easily (I tried to be good about commenting). I can help you debug - though I don't have a mac so I replicate anything. Feel free to make an issue. Also add `--debug` when you run so it is more verbose about what is happening. I think maybe you don't have enough notes (it requires &gt;50 key presses before it will start).
Sorry yes, compile time. I thought one thing and typed the other :)
if you are looking to rebuild/restart your app during dev mode, I have been using https://github.com/sqs/rego hasn't had updates in a long time because it just does one thing and does it well. If you are looking at production, +1 to what https://www.reddit.com/user/hell_0n_wheel said. We use ansible, called from a jenkins instance
For fun I built Operation Go: http://gocode.io It's an interactive game to test your programming skills, similar to the Untrusted game for JavaScript.
Is this for development purposes? If so, Atom's Go package will do this automatically.
https://plugins.jetbrains.com/plugin/7055-color-ide works pretty well for me. My real project: https://www.dropbox.com/s/3sqlkdfm4nfy9sd/Screenshot%202017-09-06%2002.48.35.png?dl=0
I have a new one coming out soon called Vanilla. It's basically a tutorial on how to do it yourself so you don't need to get bogged down with boosted packages or extra functionality that you don't need. So far I haven't found any packaged web frameworks that do it right.
Thanks, we're appreciated to have such customers like you.
I've been programming since 95 and it's hands down the best language I've used. It's not perfect, but the language design, community and tooling is incredibly helpful imo.
You are probably looking for this: https://blog.cloudflare.com/exposing-go-on-the-internet/ Even if you decide to migrate later, you'll still have a production ready in-app server.
This would be a great addition to the community, please post when completed :)
&gt; As a noob to go I agree. It's hard to know where to start and frankly none of the ones I have seen are comparable to ruby, python, elixir or Java frameworks. Try the Go way before trying to bring your habits from other languages. It's the hardest thing to do but once you've done it, you'll be a better programmer in those languages as well, not just Go. &gt; They all seem like they were slapped together in a day and none of them are suitable for writing a real world app. That depends on what you value. Go programmers usually prefer simplicity and clarity versus a lot of magic. Magic usually bites you really hard, regardless of framework / language. With that being said, if you really need to write "real world apps" (I guess all the community has been writing only toy demos so far?) have a look at https://gobuffalo.io It's probably the best RAD Framework for developing Web Apps in Go. And if you need a CMS, then try https://github.com/ponzu-cms/ponzu Hope this helps.
Nope... if there wasn't a good diversity of people putting different approaches out there for something so ubiquitous, I would take it as a sign that Go isn't worth bothering with. I don't see anything to get frustrated over — the ones I don't use don't do me any harm.
I believe that this explosion of routers written in Go has been caused by the Go team's decision to [keep the http.ServeMux simple](https://groups.google.com/d/msg/golang-nuts/T6lJ5iXwyjw/VxwsrqgcrCUJ). 
[removed]
dep is really close to being great. I'm hopeful that it will get stamped official soon. I've been able to download a ton of code then just run dep init and have everything vendored and building in about a minute.
&gt;Try the Go way before trying to bring your habits from other languages. It's the hardest thing to do but once you've done it, you'll be a better programmer in those languages as well, not just Go. I am not talking about style. I am talking about functionality. If you want to build a non trivial app you need to have a certain amount of functionality from the start. You need good security, a way to handle secrets, a way to handle different environments such as development, staging, production, CI etc, you need a solid configuration system, you need caching, database pooling, templating, page partials, etc. Frameworks like Rails, Django, Phoenix, Spring and a slew of PHP ones provide those for you in a unified and well documented way. Last time I brought this topic up at /r/golang the consensus was that "the go way" was to not write a web app but only to write an API and then to hand assemble all the bits you need from the hundreds of packages out there that proport to do the same thing. I don't mean big components like caching and database pooling either but I mean down to the smallest detail like routing and parsing parameters. Thanks for the heads up on gorilla. I currently have about two dozen tabs open in my browser with web frameworks so I will add it to that and read about it too. It does seem like this process should be easier for a noob like me. It's hard to know where to start. With Java or Ruby or Python or Elixir it's easy. You get batteries included and amazing documentation and a rich community to help you. With go you don't get any of that. Look at how scant the documentation is on Buffalo. That tells me it's very young and doesn't have a large community around it. Correct me if I am wrong.
Hmmm, I tried to run in manual, and played more than 50 notes before the magic C 108 and got this: INFO[0062] Adding {On:true Pitch:123 Velocity:127 Beat:31395} function=Player.Listen INFO[0063] Sending history to AI function=Player.Teach INFO[0063] Getting improvisation function=Player.Improvisation INFO[0063] Added 24 notes from AI function=Player.Improvisation Still nothing playing :( I'll do more experiments and I can't find anything I'll create a Github issue. Thanks! 
`reflex` is nice. I use it for running `go tests` on code changes. For deployment though I often use a Makefile which tests, builds, creates containers and deploys. The deploy process is often as simple as using ssh to copy config and binaries up to hosts, and restarting a process.
Lua in nginx should be a good choice, but I prefer the go way :) which is also recommended by prometheus group
FWIW you can supply a regexp for table names to match now.
Hi, First, in Go, you don't normally named a variable `Mgo_user`, instead you would use `MGOUser` or `MgoUser`, no underscores in names. Now, I don't know how you call `urlinfo` from your router, but, seeing that you are passing a `Settings` struct, I would instead pass a mongo session already initiated from main(). That way, you only start one session to mongodb, mgo will create a pool of connections to use, and then each handler will reuse those connections instead of starting a new one for each http request. Hope that helps. 
I've been using it on and off for a little over 2 years, and I am ambivalent. There are some very nice aspects, like cross compilation and a fast garbage collector that doesn't require tuning. The native support for concurrency is also very nice. But there are a few things I miss too: I really like dependency injection using Spring Boot as it leads to much better code design and testing. But the big weakness, in my mind, is the availability of SDKs for common services. Are you using AWS Dynamo DB? Have fun writing native queries instead of using the Java query builder. I think this will change given another couple years, but right now, there are drawbacks to Go that force you to write a lot of your own libraries. But the language is fun to use, so there is that.
You've right, but Go people are different, we like simple things that just works very well. If you're looking for MVC web framework, the only one is the Iris web framework: https://iris-go.com (we despite code generation and "magic"). It's also one of the fastest if not the fastest out there, it's the best you can find in Go world so far. Disclaimer: Iris was built by co-workers and me and it's being used by a US Television station for a year as well!
I've been hosting my personal site and some other sites via a simple Go program [1] (as opposed to something like nginx) for the last 1-2 years, and have not had any known issues as a result of that that would drive me away from it. [1] https://gist.github.com/d3b1c1c2215bf5b34190 (and https://gist.github.com/bf19e90ca5cf502c7de2 for HTTP-&gt;HTTPS redirection).
I would add for the dependency issues before dep became more official I used glide. I still am using glide at this moment and it's working out quite well, if you're doing a new project then dep will meet your needs.
&gt;You've right, but Go people are different, we like simple things that just works very well. That seems facile and arrogant. Are you saying people who use other languages don't like simple things that just work well? I submit that go things are not simple because they require cobbling together of many tiny projects most of whom have little documentation and support. This is hardly simple for somebody who is starting out because they have to figure out which routing to use, which caching to use, which asset management to use etc. So they have to evaluate fifty or so existing projects to settle on the "best set". Hardly simple. As for Iris I think you are the only one here recommending it. Almost everybody says to avoid it because of some stolen code or something like that. So your recommendation is a prime example of what I am talking about. There are umpteen frameworks, there is no consensus on which one is most suitable for what kind of use. Am I supposed to listen to you or to some other person on reddit. Or maybe I am supposed to download and play with all fifty of the projects to see which one is most usable. 
Well, that's a lovely first comment. How about this instead, I think it's great that there's enough emphasis on community to have this type of group.
We all make mistakes, even people who have been doing go for a long time. :)
I've used it for 3 years and quickly felt it was optimized for readability. It doesn't have many frills and it compiles very quickly to allow quick iterations.
I've used https://github.com/codegangsta/gin before. Works really well for http servers.
[removed]
14 seconds? ... That's *some* initialization logic you've got there.
Been using Elixir for 3 years and Go for 2 years. Almost all of the points I make in this response are subjective. Cons against Go vs Elixir: - Boilerplate code - Programs can and do crash - No package manager (unless I missed something?) - Shared memory for data structure access can cause issues. - Use of interfaces can be a little hard to grasp if you've never seen it before. Cons against Elixir vs Go: - Static analysis is not easy and not complete. Sorry, Dialyzer. - Computation can be much slower. - Functional programming can be a big paradigm shift. - Interop with Erlang can be a bit frustrating and Erlang's error messages can suck. Pros for Go vs Elixir: - Static analysis and very short compile times make refactoring very quick and very solid. - Computationally very fast. - Cross-compilation and statically linked binaries can make deployments extremely easy. Pros for Elixir vs Go: - One command-line tool to rule them all (mix). - Version controlled package manager. - Robust and easy-to-use web framework (phoenix). - Immutable code is extremely easy to reason about. I can't recommend one over the other. I tend to use my Elixir as a "central" server that coordinates my Go, Python, and other-languaged services. I tend to write small Golang projects as micro services. Building a fully functional (no pun intended) web application for me is much quicker in Elixir. Websockets in Elixir/Phoenix are very straight forward compared to Go. Deploying a binary built in Go tends to be a easier than deploying an Elixir app. Go seems to be better supported as a main-stream language for companies that provide DevOps/Cloud services (there are official SDKs for Go more than for Elixir). 
The Go Programming Language is a good (e-)book.
[removed]
I've been using Go since 2009. It became my main language of choice, barring project-specific constraints, pretty quickly. I've tried to switch to other languages, such as Rust, several times, but I always wind up back at Go. In my opinion, the best part of Go is how much it manages to do with so little. This is really helped along by a good standard library. For example, the whole `io` package and how it's used is fantastic; every time I need to do stream processing in another language, especially Java or Rust, I just want to strangle someone. Oddly, I'm not really a big fan of the whole channels thing. The `go` keyword is fantastic, but a lot of other concurrency features I usually find kind of lacking. If I had to pick a specific single feature as a favorite, I think it would have to be interfaces. Despite seeming kind of similar to Java interfaces, they're the secret to Go's managing to feel like a scripting language, a topic I mentioned in [a blog post](https://deedlefake.com/2017/07/the-problem-with-interfaces/) I wrote recently, actually. I also like Go's error handling. It seems awkward at first, but try implementing fine-grained error handling in a `try/catch` model language and tell me that it's better with a straight face. Along with that, there are a bunch of little tweaks to normal things from other languages that really help. Methods being decoupled from 'classes', making it much clearer that they're basically just syntactic sugar, minus interfaces. In a similar vein, being able to pass a `nil` pointer receiver is *really* nice. Go's switch is also the best one out there. Well, except maybe the one in [my little scripting language](https://deedlefake.com/2017/08/introducing-wdte/)... ^(For some odd reason, I like that one.) Insanely easy cross-compilation and static binaries are also really nice. The biggest problems I've had with Go projects usually comes from GUIs and other graphical components. Most libraries out there are just bindings for C libraries, which usually doesn't work so well. For example, trying to use SDL from Go is kind of painful thanks primarily to SDL's basically non-existent threading model. GTK+is a bit better, but it still feels like it could just randomly fail. Shiny's nice, but is so early in development that it's unusable for a lot of things.
AWS has an official repository for Go clients to their services. The root repository may be found [here](https://github.com/aws/aws-sdk-go/). The DynamoDB client is documented [here](https://docs.aws.amazon.com/sdk-for-go/api/service/dynamodb/). If you are aware of these packages and use them, then I'm honestly not sure what you mean by "native" queries. In my opinion, the DynamoDB package is fairly comprehensive in how it does its job.
&gt; No package manager (unless I missed something?) Nope still missing that... gopkg.in is my go-to personally for versioning, however. &gt; Shared memory for data structure access can cause issues. I'm a little confused on this bit. What do you mean by "shared memory"? When I see that term, I think two or more separate processes attempting to pass data between themselves or trying to communicate with each other.
I have been an embedded programmer in college and a full stack developer ever since. I have used go for 3 years now for every project I can, and I am proud to say I was instrumental in bringing the language into my company as a new primary language. I am so enamored with go's lack of special cases, low learning curve, and fantastic tooling. My favorite feature is the simplicity that comes from *not* having things like exceptions. My previous higher level language was C#, so this is an absolute dream to read and write. Another excellent facet is the incredible developer/community response around problems like "compilation time has increased" or "GC pauses are too long" has been "let's fix it and make it stellar" I would highly suggest making new programs in go. 
[removed]
Sorry "shared memory for data structure access" is very poorly worded. What I meant was "concurrent access of a data structure by two or more goroutines can cause issues". An example of would be two goroutines accessing the same map structure at the same time. Concurrent access of a map can cause a panic. It's not something that is exclusive to Golang though. The way to prevent concurrent access for something like a map is to use a Mutex or put the map in a goroutine, pass messages to the goroutine via a channel, and await a message back from the goroutine via a channel.
We're on it :)
[removed]
You can start with short examples also from http://www.golangprograms.com/
I think he meant how long it takes to go from zero to coding a "hello world" server and launching it.
[removed]
That makes a lot more sense now. :P
Used it for almost 5 years, 4 of that working 40 hours a week in it, putting things into production. It's awesome. Here's a blog post I wrote about it - https://npf.io/2017/03/3.5yrs-500k-lines-of-go/
Not every language is the same, maybe you want a battery include framework like the mainstreams in other languages but most of the time that extra code that you don't use is just a code that you have to maintain. Go was built for simplicity, the batteries include are in the language itself, so you don't have to be navigating looking for libraries and only work with what you need. I have come from OOP language like Java and Kotlin and try to implement stuff that I did in other languages and just don't work, if you try a new language adapt to the way the language works. Not the other way around.
I've been using Go for 3 years. I had a project that needed high concurrency so I decided to give Go a go. After one week I knew it was my favorite language. I like it because it makes me a better programmer. It forces me to think through what I'm writing more, but not in a burdensome way. Instead of searching for the perfect library I often find myself just writing everything. This is important for me because I am a self-taught programmer. I've never worked as a salaried developer, so I need all the learning I can get. I find that Go is easy to read, even for the most complicated applications, so my learning efficiency is much better than it is in something like Java.
I am writing tutorials at https://golangbot.com/, please do check it
It really depends on what you're doing. If a tool I'm using was written in Go, then it's great since I can patch or extend those things in Go. However, if they're in python, it's nice to still know python for the same reason. So Go is no silverbullet but I definitely tend to now think "Can I start with this project in Go?" because Go is generally a joy to program in, thanks to gofmt, its methods, stdlib, performance and standalone/portable binaries. No more having to deal with java style design patterns in java/php or dealing with callback hell in node. I've had no major issues with vendoring, sql migrations, and the usual software engineering tasks.
We stopped using nginx proxy sometime after 1.4.2 and never looked back. 
I guess the Go client is still more bare bones than the Java client. For instance, in Java, you can [create a get request with a builder](http://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/examples-dynamodb-items.html) (setting the key and table). In the Go SDK, you have a [GetItemRequest](http://docs.aws.amazon.com/sdk-for-go/api/service/dynamodb/#DynamoDB.GetItemRequest) that accepts a [GetItemInput](http://docs.aws.amazon.com/sdk-for-go/api/service/dynamodb/#GetItemInput) structure that is just a collection of primitives and maps that you need to set manually. Yes, it works, but requires a lot more boilerplate for it to work. When I was referring to the "raw query" I was talking about manually populating a structure that looks like [this](http://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html). I guess I just see the Go SDK as a lot closer to the "raw" query than the Java builder is.
Or you can use the new sync.Map type in go 1.9
Those debug messages don't indicate any errors to me. Two things to check: 1. You aren't playing any notes above middle E (thats the default threshold for melody detection) when the improvisation is starts. If you start playing, the improvisation will be silent to yield to you. Though it doesn't say in the message, the improvisation immediately should start after saying "Added 24 notes from AI." 2. When the program starts up make sure that it picks the right MIDI in/out. Right now it is done automatically but I only can test it against my setup which is not the same as yours.
&gt; Instead of searching for the perfect library I often find myself just writing everything. This should not be the case to develop effectively...you should rather focus on your core and rely on libraries provided by language. 
I was doing web dev before go. I got lazy and just configure gulp watch to run go build....
It's all good my dude. Frankly even before 1.9, and knowing the map type was unsafe for concurrency, it felt pretty basic to just wrap it under a package or struct. I know it may sound patronizing to read that, but its not my intent. Every language has its quirks, Go particularly. A hash map that is safe for concurrent use takes up a wee bit more of the stack. Its not much, but think from the side of the language designer. "Do I want to assume that a programmer will always want concurrent safety at a cost, or do I want to give them the tools to ensure it if they need it?" Just a thought. Not saying x is better than y, just offering my opinion.
3 years now. Mostly migrated my company's performance sensitive code from Python to Go. 80% of the productivity of Python, 80% the speed of C. Excellent community, very high code quality. Sane concurrency story, necessary in the post-Moore's law era. The main thing I think missing is a proper debugger (delve is not available on my platform of choice), hopefully they will make progress on GDB compatibility. Love the simplicity of the language, hope they hold the line on the kitchen-sink approach of, say, generics weenies.
While it's true that there are a lot of HTTP frameworks, it doesn't need we need to try them all: just pick one which looks good to you and start using it. When I first needed one, I tried Gin, looked good, got me almost where we needed but then stumbled on some restrictions with httprouter (routes can't be ambiguous because httprouter doesn't try to be smart about resolving conflicts, which I understand, but still the specs needed it as we were migrating a production API already receiving a few million requests a month). So we switched to Echo and all was good and we never looked back. I don't suggest to put on a blindfold, but you don't need to try all of them. If you have a real use case for which you need one, just try the one which looks more promising to you and give it a try. In the end, most of them are ok and as long as they don't get in the way, you should be good. I understand that for people coming from other languages it might look intimidating, but really, most of them are fine and, anyways, you'll soon learn that the Go community doesn't try to have just one way to do things: you have options and that's great, but you need to make your own decisions, the community won't make them for you like for Ruby and Rails (which I come from and still use it and think it has its reasons to exist and be loved).
Please don't recommend this as a general purpose concurrent-safe map. It has trade-offs and only really suited towards scenarios that are dominated by reads. It can even perform worse than just wrapping a map with a mutex, if you aren't aware of how it works.
thumbs up! =)
What I like? - tooling is top notch. What I don't like? - primitive Compiler which cannot optimize seemingly trivial stuff, plus escape analysis is not very good. Also, Google doesn't treat Go as first class citizen for it's projects like gRPC and protobuf. Rant over
Go doesn't have something as convenient as Rails or Django, I agree, but the truth is you can easily accomplish what you said (i.e. caching, database pooling, templating, page partials, etc.) with just a few lines of code. We're currently running several Go microservices handling on average 10 million requests a month and we definitely needed db pooling, caching, security, etc: we have our own internal packages which provide us everything we need and they're probably less than 100 LOC in total. Take something like caching and Rails: the rails cache store is super convenient, but is fairly limited. As soon as you need to handle something which doesn't fall into what the Rails team thinks is the right way to do caching, you'll need to right your own logic and it's not going to be as straightforward as with Go (trust me, I did it). IMHO, big assumptions are more difficult to work around them; no assumptions looks daunting at first, but it will force you to be more pro-active and will ultimately lead you (again, my opinion), to better code.
To each his own. For me, I like having the extra control over what goes down. Having prior experience with EntityFramework and the lot, it's refreshing to be able to tweak small code behaviors in the database level to suit my needs. No language is perfect, and I see where you're coming from. It's a good point these days in the area. It does take more time in Go to get where you're going sometimes, but you're in control, not some third party package. It feels easy enough (to me) to prototype something that fits my purpose. Go is sill super immature, so cleaning up the third party packages and pulling out the good ones will take a while. Give it a try occasionally, you might like it more!
Mainly I use it for multiple connection endpoints, but at least round-robin sharding would be very easy to introduce. A bit more tricky would be algorithmic sharding or host ejection, because you would have to introduce some sharding algorythm that requires a key to determine the shard host, and to keep track of host connection status... Easy to do, harder to get right...
https://github.com/pilu/fresh
I still have things that are larger than a single server, so I need a reverse proxy of sorts. Having used many different ones in the past (pound, haproxy,...), I'm very comfortable of having nginx to sit there, because it adds extended functionality (caching, LUA, redis,...). That's very useful for assets which aren't the Go service, but let's say several over 1TB of an image archive. To implement some of these things in Go isn't exactly what you want to do when starting up, and if you grow very fast, it's still better to take nginx and put it in front of a pool of Go services in a few hours, instead of developing and hardening the set of features which you need. There are of course Go attempts that aim as a nginx replacement, notably [traefik](https://traefik.io/). It still doesn't do caching, but then again, there are go-land solutions for that as well. Like this one, which was on the subreddit a few weeks ago: [multi master distributed caching layer for amazon s3](https://www.reddit.com/r/golang/comments/6wnxhc/a_multimaster_distributed_caching_layer_for/). I'm sure it could be adapted to have a more general purpose within your app.
At least the ftoa example is redundant: fmt.Printf("%f", 2.24) // 2.240000 fmt.Printf("%s", humanize.Ftoa(2.24)) // 2.24 S/Printf already supports fixed decimal points formatting with `%.Xf`, here's a [playground example](https://play.golang.org/p/oTkDZOubwM). But that's not what the OP asked, so get an upvote. It doesn't however help him to read numbers from his code, only ones that he prints out :)
&gt; Go community is a colorful one. It has bad sides. It has good sides. I have started contributing to Go recently. My experience has been wonderful. The key point while doing open-source is to always be appreciative and humble. There is only a limited no. of people in the core team and there are only 24 hours in a day. Words can mean completely different to people from other cultural backgrounds, especially to those for whom English is not the first language. Going the extra mile in being extra-polite goes a long way IMO. I always keep these factors in mind while contributing to open-source in general. Helps me appreciate the work we all are doing.
On and off for 3 years. My overall feeling is it's one of the most solid and reliable tools in my toolbox. I feel like a better developer for it, like if i need to make something that is robust, performant and hassle free then I have something to turn to. That's not to say it's perfect. Go would be wonderful in my eyes if it had - A canonical dependencies solution - Generics Type safety is important to me and while my background (Scala) will always find Go having short-comings I do feel like generics isn't too high a bar to set for a modern programming language.
Been using for over three years now. Coming from primarily Python, with some C experience a long time before that. I absolutely love the passive interface satisfaction instead of declared interfaces. For me, once this "clicked" programming in Go became an absolute joy. For a web stack, CRUD is a pain with Go, but complicated stuff is really easy. In general that's been my experience actually. Simple stuff takes a long time with a lot of boilerplate that's incredibly frustrating compared to other non-typed languages or typed languages with generics. On the flip side, the language itself is such a great balance of simplicity and power that complicated tasks are so easy to build out. In a large part, it's because you never need to worry about inheritance and can isolate areas of your program elegantly with interfaces that describe what's "expected" instead of what's "provided." This all can be accomplished in some other languages as well, but Go is so "dumb" that it's refreshingly easy to do things without thinking much about architecture beyond broad strokes. I also happen to love Typescript, especially since await/async, but in general feel like JavaScript/Typescript are in such stages of constant alteration, iteration, and morphing best practices that I wouldn't personally want to use them for backend stuff. No experience with Elixir, clojure, or .NET, so can't speak to those. Would definitely use Go in the future whenever possible. Would really really like to see generics in Go 2, or at least a more codified approach to code generation.
https://scene-si.org for the blog, https://leanpub.com/12fa-docker-golang and https://leanpub.com/api-foundations for the ebooks ;) If you're still in the basics area, it's well worth to go over go by example and create something in each section that will give you some hands on practice. https://gobyexample.com/ - don't just read them, try writing your own examples, so the knowledge will be used and stick inside your head a bit more.
What about [dep](https://github.com/golang/dep) (the dependency management tool from the Go team) and [glide](https://glide.sh) (a widely-used third-party dependency management tool)? Admittedly, dep isn't an "official" tool (yet), but it more than likely will be in the future, and it's at a point now where it's "safe for production use".
This looks pretty cool. Just a hint: the first mission gives me a false negative if I do it this way: agents = append(agents, Agent{name: "Dee Fercloze", equipment: "full"}) agents = agents[1:] Yes, this is not smart and you should probably do it like this: agents[0].equipment = "full" But the first solution should still pass the test. :)
I enjoyed doing todd mcleod's course on udemy, which is a gentle introduction to programming and go. The latest version is on his website https://greatercommons.com.
&gt; I retitled the Github repository description. Thank you! &gt; Should I also rewrite the title on README.md? Uh, well, that's definitely should be your own decision. I would retitle it as well but that's just my opininion. Basically the reasoning is that it's better to have a "low drama" title which is to the point rather than attempting "to sell" something--you're not selling something, right? ;-)
…and while we're at it, there was recently an announcement of the new version of &lt;https://github.com/go-aah/aah&gt;. `&lt;rant&gt;`On a side note, Go still does not have a robust PDF generation library or a cross-platform GUI tookit akin to Tk but we have myriads of mostly useless web frameworks constantly reinventing the same wheel over and over again`&lt;/rant&gt;` ;-)
This is the wrong way to deploy a Go Application with Docker. The docker container doesn't need to have any source code it it, just the binary. This has been addressed many times over in this subreddit or the Internet at large. Please do not use this method and do a minimum research step before you recommend people how to do things. If your Dockerfile looks different than this: https://github.com/gopheracademy/gopher/blob/master/Dockerfile you are most likely doing it wrong.
Would do it even more minimal, something like: https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/
Depending on your needs yes, that's even more compact.
&gt; Instead of searching for the perfect library I often find myself just writing everything. That's not the best way of doing things, though... In programming, you ideally shouldn't reinvent the wheel.
5 years here - about two of them where Go was my main language (currently it's C, but I'm still writing some Go). I love it *for some tasks* but I still code in Python for things where performance is not an issue but portability is (i.e. I don't want to distribute binaries for multiple platforms), and in C where Go's performance is not good enough. 
&gt; it's being used by a US Television station for a year as well Doesn't mean the quality of your framework is good at all.
Parser combinators got me interested a while ago but I couldn't find any complete libraries written in Go, so I started to write one. The main algorithms are based on the paper Parser Combinators for Ambiguous Left-Recursive Grammars (2007) by Frost R.A., Hafiz R., and Callaghan P. The library is mostly stable and tested. As I'm fairly new with Go the API may be not the most elegant one, but you have to start somewhere :) I wrote a full interpolation language using it: https://github.com/opsidian/flint. I really enjoyed making these two libraries and I hope it can be useful to some people even if they are only interested in an example how parser combinators and interpolators work. 
Another tool for this job is https://github.com/tockins/realize Can't say anything about how it compares to similar tools posted in here. 
I needed an easy to use and powerful interpolation language for a project I'm working on. I was looking into the Terraform interpolation language (https://github.com/hashicorp/hil), some Jinja 2 implementations but eventually decided to write my own. Most of the libraries lacked features, documentation, stability and/or tests. It uses the Parsley parser combinator library (https://github.com/opsidian/parsley). I hope it can be useful for some people even as just an example of how to write an interpolation language and use a parser combinator library.
Covers all practical needs. It's more verbose than Perl, but much less error-prone than Perl, C and less verbose/annoying and better to deploy than Java (my previously used languages). Main drawback: its code generation/optimization is not SotA and probably never will be, but there's (somewhat limited(?) gccgo. It's awesome that I can compile for my armv5tel NAS by just setting environment variables and deploy without any dependencies/extra installation, where the target box is a PITA to even find and install a working gcc for. I'm slightly worried that Go might pile on some "popular" new features over the coming years and turn into something less pleasant to work with. 
Hmm - is there any additions to Go 1.9 GC besides improvements about big object allocation?
&gt;Not every language is the same, maybe you want a battery include framework like the mainstreams in other languages but most of the time that extra code that you don't use is just a code that you have to maintain. No you don't have to maintain code you don't use. You don't have to maintain the framework code at all. That's the whole point of using a framework. You want to rely on the expertise of others. &gt;Go was built for simplicity, the batteries include are in the language itself, so you don't have to be navigating looking for libraries and only work with what you need. But I need all that. I need routing, I need security, I need CORS, I need Cross Site safety, I need secure cookies, I need rate limiting, I need live reload, I need caching, I need database pools, I need asset management. I need all of that and more. &gt;if you try a new language adapt to the way the language works. Not the other way around. Here I disagree but that's not the point. The answer seems to be that nobody should use frameworks in go and that everybody should just rebuild everything themselves over and over. I guess that's why there are so many duplicate libraries in go.
I haven't been annoyed by it. I think the reason for so many frameworks is simply how complete the HTTP library is already in Go. Everyone at my company uses only the standard library for web apis. The routing you see in a URL is taken care of by the front-end framework for us. In our case that is Angular. I don't mind using the standard library to get parameters from the query string portion of a request for an API. If our frontends were not Angular and we still needed to manage the routing on a frontend, I would definitely choose the most prominent framework to maximize available documentation, community support, and validation of quality. gorilla/mux seems to be the best candidate for the top leading framework in terms of popularity even if the important metrics place quite a few other frameworks equal with it. The most time-consuming thing in getting from boilerplate to sensible skeleton functionality is always authentication regardless of language. However, even in a framework such as asp.net I do not see a solution that saves a lot of additional development despite being one of the most complete authentication solutions in any language I've seen. Once humans need to do account management and set permissions for each other there just isn't a way to provide a boilerplate solution that works for everything. Luckily for a private site you can add portions of an authentication, authorization, and account system as your site grows. For an Enterprise site you you probably aren't making authentication etc every time. You probably make it for one API that acts as your centralized authentication system, which means the burden is not repeated.
There's also https://mholt.github.io/json-to-go/
Yes I know. I have taken the inspiration from that only. I have properly mentioned this to him https://github.com/mholt/json-to-go/issues/27#issuecomment-327000414 . It was not being actively maintained and now that it is under an org, I hope it is actively maintained.
Oh cool!
&gt; I will usually hit the limits in other parts of the app before I can even see anything related to the router of choice in the profile. I did the math around this a couple of times. Even if you are at the scale of Google, you spend the equivalent of a small handful of engineering hours *per year* on routing, with a naive approach. Definitely not enough to justify optimizing that.
I'm falling a bit short on what's the best way to stay up to date with the COWG? Follow the github repo?
Obligatory: [I agree](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html).
It's not the best way to write production code, but it is the best way to learn.
Depends on what the goal is. If the goal is to write production code, then yes, libraries are the better option. But that's not what I'm doing.
Honestly, regarding logging, I would use Go. Yes, you have to roll your own logs. Yes, Nginx has a pretty robust logging capability. But you get to control *exactly* what is logged in Go, because you get to wrote your own logging feature. And if you're building this site as a way to hone your skill, building a proper logger (or implementing a library for logging) is going to *serve* you better than just editing a configuration file. (Ha, see what I did there? I'll see myself out) 
&gt;If your Dockerfile looks different than this: https://github.com/gopheracademy/gopher/blob/master/Dockerfile you are most likely doing it wrong. This assumes that you've built your binary already. [multi stage builds](https://docs.docker.com/engine/userguide/eng-image/multistage-build/) overcome this by allowing you to define your build stage and container image stage in one Dockerfile.
Or build the binary in a different container and use the after that, like Gopher does :)
That's true. In practice, it likely won't matter (if you use sufficiently long ids, e.g. 120 bit, giving 20 characters) as collisions should be exceedingly rare and conflicts should be caught on insert anyway (and can then be retried. Or an insert fails once every blue moon). So, personally, I just wouldn't check for a taken ID anyway, add a UNIQUE constraint on the column and retry with a different ID on failures.
Mixed, on the positive side. I like how easy to write and read go code is. Sometimes miss the flexibility of Python, or the over-the-top-power of Scala, especially when I'm working in something which would be easier in these languages. But overall, I like it being part of my stack and I like the language simplicity, even with its drawbacks
I came from Java to Go because my company started doing docker based micro services and the JVM footprint was too big. Using it for about a year now ( a lot though) I lile go a lot. It is easy to learn, yet I still learn new things every week. It makes me very productive, and writing concurrent logic has never been nearly as fun as it is with go. Downsides are package management, although not as bad as in the early maven days. And it is getting better. Dep is almost ready. Elixir: I recently ported an Elixir micro service to go. I have no programming experience with it. However the service ate 46gig of Ram occasionally. Doing some research on Elixir/Erlang gave me the impression that it is hard to master. And if you don't... Terrible things can happen. Erlang seems like an interesting VM though...if you have the time
It's not exactly great with objects that are meant to be unstructured, obviously because there's no way to type hint that something should be a map[string]string, no? "errors": { "E_HTTPS": "Call must to be delivered over HTTPS." },
&gt; but the default Go http client doesn't support gzip response This isn't accurate. If you don't provide your own "Accept-Encoding" header and if you don't override `http.Transport.DisableCompression` then the default `http.Transport` will add the header and transparently decompress the response. From [`http.Transport.DisableCompression`](https://golang.org/pkg/net/http#Transport.DisableCompression): &gt; DisableCompression, if true, prevents the Transport from &gt; requesting compression with an "Accept-Encoding: gzip" &gt; request header when the Request contains no existing &gt; Accept-Encoding value. If the Transport requests gzip on &gt; its own and gets a gzipped response, it's transparently &gt; decoded in the Response.Body. However, if the user &gt; explicitly requested gzip it is not automatically &gt; uncompressed. 
&gt; "errors": { &gt; "E_HTTPS": "Call must to be delivered over HTTPS." &gt; }, Yes. But I should hande it in a better way.
this isn't one VS the other. They have 2 very different roles.
http router =/= web framework, Everybody can write an http router, it takes 2 hours. And everybody SHOULD write its own http router, or are you against diversity in an language ecosystem?
Thank you for the quick fix :) great job!
[removed]
Have you tried [caddy](https://caddyserver.com/) as a reverse proxy? I'm currently considering it to replace `nginx` since it seems easier to setup and use (especially the automatic SSL). Probably isn't as fast as nginx, but would like to know your thoughts.
I would keep sharding logic out of my app and use something like [Vitess](http://vitess.io) for MySQL or [Citus](https://www.citusdata.com/) for Postgres.
You forgot that Erlang is a dynamic language, it's a huge difference that I would put in Cons.
hmm interesting, thanks :) Is this new?
Great article! You make some great points about route handling being a little mysterious in libraries.
Anyone know of something similar from xml to struct? edit: this page has xml -&gt; json -&gt; go. I guess what I'm really looking for is xml schema -&gt; go (or other language).
You didn't carry over the gofmt code?
And WSDL to struct(s) too for those of us still having to integrate with ancient SOAP web services.
The examples show 80 bits used, which is in the realm of collisions. If you're gonna properly handle collisions on insert, the whole `userIdTaken` stuff is unnecessary.
*sympathetic fist bump*
Why would a new thing with no backwards compatibility requirements to Microsoft or Sun use GUID/UUID? Just use raw random data, no format bits set. As for the textual output, my favorite these days is z-base-32. https://github.com/tv42/zbase32 / http://philzimmermann.com/docs/human-oriented-base-32-encoding.txt
Yep. Basically initialize one main session and pass around a [clone](https://godoc.org/labix.org/v2/mgo#Session.Clone) or [copy](https://godoc.org/labix.org/v2/mgo#Session.Copy) of the session depending on your need. If you pass around the main session you might accidentally close it off so that's why I prefer keeping the main session in my main, hehehe. Here's some explanation about the difference because I think the mgo doc is not clear on the subject: https://stackoverflow.com/questions/33275357/should-i-copy-session-for-each-operation-in-mgo &gt; First of all, we need to see the difference between mgo.Session.Copy() and mgo.Session.Clone(). While go.Session.Clone() returns a new session, the session uses the same socket connection. That isn't necessarily a bad thing, but keep in mind that on the server side, a stack is allocated per connection. So the sessions would share the same stack. Depending on your use cases, that may make a big difference. &gt; &gt; And here is the problem – if you open a new socket connect for each record, this leads to a three way handshake, which is slowish. Reusing the same socket reduces this overhead, but there still is some and has the drawback described above. &gt; &gt; What I tend to do is to establish a new connection per long(er) running unit of work. https://groups.google.com/forum/#!topic/mgo-users/pk9IsU2bb8o &gt; * The dial call will establish a pool of socket connections to the underlying cluster &gt; &gt; * Session New and Copy will be given independent connections from that pool to use. &gt; &gt; * The operations within a given session have consistency guarantees &gt; &gt; * New and Copy create sessions that would not have consistency guarantees between each other &gt; &gt; * Clone will have consistency guarantees with the other session it cloned 
I've been educated in .NET and I'm a .NET dev. I think Go and .NET are both unsuitable if you are thinking of building dynamic websites. .NET is hell when it comes to making web services while Go is very very good at it. I had experience with TypeScript+Node that made me write error and I far prefer dealing with them on compilation before a deploy than when something is being executed. I can go into more detail if requested.
...can also be used together with https://github.com/cortesi/devd in live reload mode to get browser reload/update on changes to go code, templates, stylesheet, javascript etc. Can post modd.conf example if someone is interested.
While the testing piece of that is always compelling, I feel like that abstraction layer ends up being complex, while hiding any unique functionality your database has. How often do people end up changing databases?
7 years. * Stable, no surprise implementation of runtime, compilers, and standard libraries. * The vendor folder is exactly what my projects need, so no issue with dependency management. * No arch/os runtime behavior exceptions, few standard library exceptions. * No libc required, direct to OS. * Solid stability. * Cross compilation is trivial. The language is okay. The implementation is great. 
Ooh! This is awesome. Was fiddling with API.ai stuff over the summer and annoyed that I had to trudge through NodeJS to do it.
* Announcing Android Go which has nothing to do with the Go programming language * Announcing new language for Android: Kotlin These announcements crushed the hopes and dreams of all gophers.
I've used this in the past https://github.com/hooklift/gowsdl I don't remember the details, but it wasn't perfect, though I think that was more that the SOAP API I was integrated with sucked. It was really straight forward though!
&gt; The examples show 80 bits used, which is in the realm of collisions. Well. Rough estimation is, that it would take O(1 trillion) requests for a collision. Not impossible, but meh :) It won't matter practically, especially if the worst case scenario is an error or some log entry being overwritten. Well within SLO. Of course, you should just handle it properly. Just saying that practically it likely won't matter :) &gt; If you're gonna properly handle collisions on insert, the whole userIdTaken stuff is unnecessary. Yes. And I agree that it should be done properly.
The Go code isn't formatted. You might want to look at https://github.com/mholt/json-to-go/commit/472b527d98c2c0a3b72c3efb30bbcd06b485d2dc and https://dmitri.shuralyov.com/blog/24 as inspiration, if you'd like to improve that. :)
also favoring realize as it does a really good job. It has many options, allows to define env variables and arguments and the ability to watch multiple projects at the same time. The Web interface is a also nice-to-have...
Spot on. My experience has largely been the same, though I've used it a little less. I think my first project was in 2014 and I've used Go at work since late-2015. As far as package management, [dep](https://github.com/golang/dep) is really starting to show promise. It still abides by all the standard Go rules ($GOPATH, `vendor/`'d dependencies) but manages to provide a neat interface for tracking your project's dependencies. I'm betting the future is bright for Go. 
Distro repo are usually very slow to update..if they ever do. I don't see the point of managing ulterior versions of go since every updates only improve it and doesn't break the API. If it can be used to version a virtual GOPATH to store the ``/bin``that's great if not, then I'm not sure what's the point now that we got vendor + dep. I mean, beside on a build server or to do benchmark between go versions. Maybe I'm missing something? I use the Download + export path way.
[removed]
let me know what you think about it if you use it! happy to accept issues and PRs
If you are going to modify anything in a struct you either pass it as pointer or return the new object. It all depends on how you want to design the API. Yes, using pointers is efficient but for small objects the difference is almost nil. That said, if you keep using pointers when it is not needed in a program which calls the same function perhaps 500000 times per second, maybe it is better to benchmark and see which one is better. e.g Code we wrote we pass around a big enough slice by pointer because we do not want to keep making copies of same slice and returning slice when the contents of the slice will be changed at every subsequent function boundary. This got us a nice ~30%-40% boost in QPS on a 16 core machine, with high contention for resources from other processes. I am a C programmer, where pointers are one of the USPs of C which make it fast and I assumed same coming to Go, untill I saw mallocgc showing up in CPU profiles. (due to combination of a lot of heap allocation for even trivial *bool or *int for proto2 objects during marshalling and unmarshalling, which makes me sad to no end). As always benchmark for yourself. Good luck
Ooooh. dep looks great. Thanks!
I build from source, using makefiles similar to how BSD ports work.
Hi u/campoy, I really enjoy your justforfunc tutorials and am still learning a lot of go's standard library. I was wondering why you didn't use one of go 1.9's concurrent maps and opted to go for a map/mutex combo?
It is fixed now. Thanks a lot.
logical units in different files. Are you sure that you need all those methods or maybe you can split up the struct into more meaningful types?
Whoosh? Edit: whoosh!
That's what a multistage build is about.
I'm mostly using go at work since the last four years. I use it for admin tasks on web servers (generating content for a static website, but also more traditional web server stuff), and for AI research prototypes. I don't regret my choices for the following reasons : - the mix of static typing, dumb simple language and gofmt makes my code (and other people's I work with) incredibly readable and maintainable. Sure, go can seem lacking in a few departments when you write your code (not only the famous generics, but also basic functionalities on slices), but that's a blessing when you must maintain code (you never wonder "wow, you can do that in that language ? What does that mean ?"), since the meaning of any code is straightforward. - deployment on servers is dead easy. Cross-compile on your dev machine, scp to the target, you're done. No more "oh, wait, I have to install that lib, oh, but I can't it's not compatible with our version of PHP/Python". Distributing to coworkers is dead easy, too. Just mail the executable and you're done. - regarding execution speed, it's a sweet spot between dynamic languages, which tend to be too slow for the stuff I do, and C/C++, which tend to be too verbose and hard to debug for prototyping. EDIT : - the language is so dead simple that anyone can learn in a few days enough of it to debug/maintain your code even if they don't know it. Counterintuitive but true story : I have cowerkers who know C++ and not go, but could not understand my C++ code (because everybody uses his own subset of the language) *and* could understand most of my Go code (not enough to maintain it, but enough to understand what is happening).
I know only that in the day of the announce http://github.com/xlab/android-go got ~100 more stars xD
This guys is a known thief and liar. https://github.com/avelino/awesome-go/pull/1135 Its "written" by one guy who steals code, edit history, and paid for github stars. dont be fooled into it. He also cheats on benchmarks by caching results.
I hear good things, give it a spin if you like :)
You have `gometalinter` in go, which includes a bunch of static analysis programs. I know there is a sonarqube plugin for go currently under development, too.
kotlin will be android future. And I'm curious about kotlin native integration with android
I think android Go is just a side effect of Go being a common word. Kotlin was another companies effort all together wasn't it? With Google not really having to do much other than official say this is okay and update their official IDE maybe? Didn't follow any of that closely so not sure. I did hope for a while when Go android support was spinning up while the oracle google legal battle was raging that it would result in massive resources into shifting towards Go. Did not happen :|
&gt; Why would a new thing with no backwards compatibility requirements to Microsoft or Sun use GUID/UUID? I think you missread the readme for ULID. It's not based on UUID, it's a completely new format. And it has also a nice timestamp prefix too, so the ULIDs can be neatly sorted if you want. A bunch more ways to generate unique IDs [was posted some time ago here](https://www.reddit.com/r/golang/comments/6iew4x/generating_good_random_and_unique_ids_in_go/).
? I always like more tutorials
Then why does it say &gt; 128-bit compatibility with UUID 
/u/everdev sounded like he made a joke, kinda like http://vanilla-js.com/
This is a struct that is encapsulating the logic for querying our database. That struct is put into a map[string]DBStruct since we need to have multiple DB connections that's segregated by the string (sorry for being a bit elusive on the details of that string, but I can't give out a whole lot of info on that part of the design). Ultimately I need some way of querying the database in a bunch of different ways that is going to be constrained by that string. At the moment, we're thinking about just splitting the functions across multiple files to segregate different functional areas, but I'm hoping that there is a better solution.
I would say that line was poorly/sparsely worded in the readme. That line explains that ULID generates the same amount of entropy like a regular UUID. But they still generate completely different output that's not compatible: * UUID v4 = 5b52d72c-82b3-4f8e-beb5-437a974842c * ULID = 01BJMVNPBBZC3E36FJTGVF0C4S Edit: Speaking of output formatting, have you heard of ye ole [Crockford's Base32](http://www.crockford.com/wrmg/base32.html)? :p
that's actually a great question, and I used it initially! it is a great match for the use case Unfortunately 1.9 is not running still in some places (such as App Engine which runs Go 1.8) and I wanted this package to work in as many places as possible. I considered using build tags to provide both implementations ... but then I got lazy :) 
ha ha!! let's embrace the confusion:)
&gt; This assumes that you've built your binary already. multi stage builds overcome this by allowing you to define your build stage and container image stage in one Dockerfile. Unless I'm missing something obvious, the Dockerfile in the original article have does not have the multistage approach. &gt; From golang:latest &gt; &gt; ADD . /go/src/github.com/agiratech/contact_registry &gt; &gt; \# Build the contact_registry command inside the container. &gt; &gt; RUN go install github.com/agiratech/contact_registry &gt; &gt; \# Run the contact_registry command when the container starts. &gt; &gt; ENTRYPOINT /go/bin/contact_registry &gt; &gt; \# http server listens on port 8080. &gt; &gt; EXPOSE 8080 
Except the article is not using a multistage Dockerfile as an example for how to do it. This is an example of what a multistage container is and how it looks like: https://github.com/dlsniper/webinar/blob/master/Dockerfile
Sidenote: I am so disappointed by New Relic's Go agent. My company is investigating switching to Data Dog because of it.
It does. This tool opens up additional possibilities, such as generation of SIMD code using C and compiler intrinsics.
i need to make it like this https://go.hotlibs.com/github.com/go-oauth2/gin-server/package this using gin-server , i need to use it in http.HandleFunc 
I was referring to /u/arnaouti's comment that mentions multi stage builds. (Edit: conciseness)
I'm not OP...?
Something like this? https://godoc.org/crypto/rand?importers
Sorry, Reddit on phone + Train = mistakes. I've edited that part out.
Love what I see with this project so far. The shadow variable warning will help a lot. I don't know if this is already an option but I also get bitten with the for v := range y instead of for _,v := range y and would like to get warned when I do this. One thing I couldn't figure out how to to is have imports automatically added (goimports/emacs does this) when I start using a package. I also couldn't figure out how to add an import myself with a key combo instead of having to go to the top of the file.
Exactly that, thanks a bunch. How did you figure that out? Argh nvm, found it in the footer. Can't believe I missed that. Thanks again!
I just download the `tar.gz` file and do `sudo tar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz`. 
X-Ray is distributed tracing. New Relic is exception tracking. They really have nothing to do with each other.
&gt; a side effect of Go being a common word Perhaps *Go* needs to officially change its name to *Golang*, that might solve these types of probs. 
Thanks for sharing ;)
Sorry, but if you think New Relic is just exception tracking, you haven't explored/used it fully. New Relic supports cross application tracing as well and my question was intended for people who used both.
&gt; Sidenote: I am so disappointed by New Relic's Go agent. My company is investigating switching to Data Dog because of it. At a previous company, we used to "encourage" them to release a proper Go agent for years (we had a fairly sizeable account). Initially, when there was no official agent, there was only a very barebones third party library that used New Relic's very limited plugin API so we had to make do with that. When we were told they were about to release an official agent we got very excited and then... disappointment. The functionality of the agent is - still - nothing close to what they offer for other languages like Java and PHP. Some of this is due to lack of functionality in the Go runtime (i.e, there is no way to intercept arbitrary function calls), but there is still a ton they could improve on.
&gt; I don't know if this is already an option but I also get bitten with the for v := range y instead of for _,v := range y and would like to get warned when I do this. Please vote / watch for updates on this issue: https://youtrack.jetbrains.com/issue/GO-2149 &gt; One thing I couldn't figure out how to to is have imports automatically added (goimports/emacs does this) when I start using a package. Please see this video: https://youtu.be/LGe8qDm760w Hope this helps.
It depends what level of abstraction you have. If you have an interface for each of your single responsibility functions, like `StoreMyThingThisWay interface`, then yes, most of the work is done, though that has its own downsides. Usually people try to abstract at the database level, which ends up being a lot of work for minimal gain.
I do something similar, I have: /opt/ /opt/go-X.X.X/ /opt/go -&gt; go-X.X.X That way I place the new version in `/opt/go-1.9.1` and symlink `/opt/go` to the latest release. If I want to go back to a previous one I can just change the symlink - and leave my PATH pointing to `/opt/go/bin`, my `GOROOT=/opt/go`, etc. 
The functions in question are ultimately wrappers around the DB queries. We've written these functions such that they have a request/response interface (such as: func GetThing(ThingRequest) ThingResponse ) so at least that part of the interface is clean. The struct that these functions are on takes in a DB client (which is elasticsearch so there isn't a persistent conection) as a part of its construction. So where it creates the connection to elasticsearch is handled at the map layer. That map layer is another struct that is really just a glorified map[string]OurDBClient.
Use delve, https://github.com/derekparker/delve, or an editor which properly integrates with it, like Gogland https://www.jetbrains.com/go/ You could also vendor the dependency and change it as you need but you'll need to be careful on how you upgrade it as you could replace it by mistake when you do the upgrade. The loading order of packages since Go 1.6 is: - vendor/ - GOPATH/ - GOROOT/ Hope this helps.
Could be.
No interface bigger than a few methods is clean. The best interfaces in Go have a single method (think of io.Writer or io.Reader). Please take the advice previously received and try to break your habit from previous languages and adopt a Go way to do it. You can pass the DB connection to the dependencies which need it and they can be decoupled from each-other so that you don't have a God-struct which holes so many methods. Split your struct to have a single responsibility for the functionality it takes care of, not n different ones.
I've never heard the term "Interpolation language" for a templating language. Was there a real reason why [text/template](https://golang.org/pkg/text/template/) wasn't good enough? That's a lot of work for very similar functionality.
This is not directly related to the code itself but I couldn't help but notice the copyright header. Is all code written by Google employees - whether at/for work or not - is automatically owned by Google? If not, why is this code specifically owned by Google?
As much as Pokemon Go.
It's Apache v2, so you can do anything that the license allows you to 
Bit of feedback wrt data presentation, having the text on the X axis rotated at 90 degrees makes my neck hurt because I need to bend it 45 degrees to be able to read it. Instead, consider putting the legend at about a 30-45 degree angle instead. If you want to keep it as it is then the text on the X axis should flow away from the axis instead of towards (the start of the word should be at the X axis, so mirror it over both the X and Y axis) as that helps with reading too. &gt; they encourage people to update their packages freely without regard to version numbers Considering the amount of work currently going on to provide a proper package manager, semver version ranges etc this might not hold true anymore. There's been quite some activism lately on ensuring people tag releases and version things in anticipation of `dep` getting more and more usage.
Sorry, I'm well aware of that but that wasn't my question?
Usually most employment contracts stipulate that anything done under working hours, any work that naturally emanates from your employment or any work done using company equipment is owned by the company. A Google employee building a framework for a Google service(, in Google's programming language,) seems to be covered by that.
The code belongs to Google because I wrote it as a Google employee using Google resources and time. That's not always the case, and you can actually release code and keep ownership, but I've personally never done it, since at the end the code is Apache V2 anyway
I see, thanks!
I understand all that, my question is more about the specific Google policy in place. As in, if I'm a Google employee who wants to publish some Go code I wrote in my own time on my personal machine, is that: - allowed (I can just do it) - "allowed" (ok in theory, but you need to get permission from 3 teammates, 5 superiors and sacrifice a goat to in-house legal counsel) - or just outright impossible
I came from a c# background and made a few structs like this because I couldn't come up with a clean way to manage dependency injection and I was used to having classes with methods. My methodology has drastically changed once I got a good handle on closures and higher-order functions. Now when I need to manage a dependency, I create a func type for the end function I want to end up with, then create a function which takes the dependency as a parameter and returns an instance of the function type. This function instance will have access to the dependency via the closure, and the rest of the code where it's used is none the wiser. I can cook up a link on the playground, or send the link to a helpful article if that would be helpful. 
Simple key/value operations are easy to mock out. How do you handle more complex queries that use multiple joins? This looks like your struct, not an interface, so I'm assuming that `NewDB()` returns this struct? type MyDB struct { db *DB stmts map[Statement]*sql.Stmt }
&gt; How would you suggest putting an interface in front of a DB that facilitates dozens of different queries? I could argue that if database/sql.*Db would need to be abstracted, which for some reason it seems to be the case, then one could create 3 interfaces with about 7-8 different methods between them? One would be open/close, one for queryctx, execctx and queryrowctx and one for the transaction part. But if I understand correctly, the author created this megastructre to hold a God-object for every DB interaction, such as SelectUse, UpdateCart, DeleteSomething. In that case, I would decouple the user from the cart from the something functionality. And finally, this could be also done as a collection of functions in different packages, because hopefully the functions are isolated and don't share state between each-other (other than the DB connection, ofc). More over, because the user needs an interface this leads me to the obvious conclusion that it's testing time and some mocking might become involved. And what would you prefer to mock? Something that has 2-3 functions or something that has 30+? If the response is the later one, please consider revisiting your response until you say the first one. Continuing with the assumption that testing is involved, it becomes apparent that rather than using the code in the application, the user chooses to trust the code in the mock. Instead of mocking the database (at most), a lot of pointless code will be created to hide code that's already there. &gt; This is just blind application of dogma. This all comes from years upon years of practice and seeing a lot of code bases and learning what works and what doesn't. It's nothing new nor Go specific. It also happily coincides with a lot of what Go gets good. 
could you elaborate? would you run both at the same time?
Color me confused but isn't Eclipse an IDE, why is it compared to programming languages?
I get what you're doing, I'm just trying to decide how I feel about it. For a larger app, we'd need hundreds, if not thousands of those interfaces, given all the various query patterns we have. That's a ton of extra code to maintain. I promise I'm not trolling, I'm legitimately trying to decide how to do better testing on our database layer. Right now my leading candidate is using [https://github.com/ory/dockertest](https://github.com/ory/dockertest). That eliminates the need for mocks + tests the actual generated sql. Back to the original question of how to inject it, we defined our own interface and explicitly pass that into functions that need it, which is what makes injecting a test db connection fairly simple. // Queryer lets most functions accept a DB or a Tx without knowing the difference type Queryer interface { Exec(c *ctx.Context, stmt string, args ...interface{}) (result sql.Result, err error) Query(c *ctx.Context, stmt string, args ...interface{}) (rows *sql.Rows, err error) QueryRow(c *ctx.Context, stmt string, args ...interface{}) (row *sql.Row) Prepare(c *ctx.Context, stmt string) (*Stmt, error) }
With the database/sql binding libraries you must use `.Scan()` and pull into each variable separately. You may want to look into sqlx, specifically something like https://godoc.org/github.com/jmoiron/sqlx#StructScan.
Yes, Kotlin is from JetBrains
Haha. "Please don't use it.". Inevitably I get bug reports and pull requests whenever I try that.
Remote ok or onsite only?
I think people talk about web dev because a lot of programming in general is making web servers. However, Go's sweet spot is writing servers in general, that might not web servers. Kubernetes is the biggest and most popular Go project I can think of. It's a cloud orchestration system that manages docker containers. Juju is a similar project, a bit older, much less popular, still very large. There's also a ton of CLI tools, like Github's hub cli tool, which are written in go.
Note that you probably mean "authorized to work in the US" not "US citizen". i.e. not H1B visa or living in another country. There are green card holders etc that are not citizens but still can work in the US.... and it's technically illegal to discriminate against people based on citizenship. I made the same mistake when I posted a job, so just passing on what I learned.
I know this, and agree vendoring might be useful to teach newcomers about. But from 3+ years daily go programming I can count the times I've seen it happen on my left hand, so I usually don't bother. However, in other languages it seems very popular to fully break API:s regularly, I've witnessed it countless times in both javascript and php. I believe the effect relates to the general seniority of many gophers, as the skill of making thoughtful but minimal API:s and extend them over time, takes some time to master. The same thing can be observed in the rust ecosystem, and as go is rising in popularity, I guess this will become less true.
Aye, it happens very frequently in my shop as well (.NET).
I should start doing that on my projects. I rarely get pull requests...
I'm using go and typescript for a web game I'm working on, the combination is a great fit. Most of the communication I do with websockets, and the performance is spectacular, compared to similar implementations I've done with php and node. There's lots to love with go, but my favorites is the tooling (gofmt!), the super fast compile times, multi-os support and IDE support (I use vscode). I built a prototype game (desktop application) using go and it runs the same in Windows, mac or Linux, without a single line of OS-specific code. However I retired the project as I was hitting performance issues, which profiling revealed is related to golang translating call conventions when calling C code. The language itself is also quite interesting, with a interesting take on the interface type. I do not miss generics at all.
FWIW, generating the libraries from the XSDs was something I always planned to do with https://github.com/tealeg/xlsx but I never got around to it. Nice to see there are now at least two newer implementations after all these years! 
They probably should have posted the ranges for the jr and sr positions separately...
I've been working on this project for a while now. It's similar to a few existing projects, like github.com/knq/xo and github.com/volatiletech/sqlboiler The difference is that gnorm is not confined to generating Go code. It can be used to generate any text at all that you want from a database schema. It could be docs or an API or an ORM-like database wrapper. And since it uses templates you edit, you can make it output whatever language you want, in exactly the format you like. This is my major problem with SQLBoiler. It enforces its own fluent-API style, which I just don't like. xo is a pretty good generator, but it's pretty limited in its output, it assumes you're generating go code, and it only outputs files to a single directory. Gnorm can output to a directory that depends on the schema name and table name that you're generating for. This can be really useful for namespacing. Gnorm does this for its own code. The code to read the database schema is generated using gnorm itself, and generates code in multiple directories so that we have package namespacing to ensure no collisions, which simplifies naming a lot. Currently, Gnorm supports Postgres and MySQL, but other relational databases could be added easily.
Or generate that sql code with Gnorm: Gnorm.org
Looked at the site and git on my phone and didn't see any examples. As such I'm not even sure what it generates. I think you should provide some examples (not whole code by just some stubs will do)
My hopes and dreams are just fine. Then again, my hopes and dreams never included mobile dev :)
What do you do?
Ahh thanks for the feedback. For now, a simple example is how gnorm is using it's own generating capability to create a database wrapper for Postgres and mysql. Here's the Postgres version: https://github.com/gnormal/gnorm/tree/master/database/drivers/postgres Note the gnorm.toml configuration file and the templates under the templates dir the output files are under the Postgres/Gnorm directory. 
Kind of exactly like that :)
I would be interested!
If you added the types of problems people would work on or the industry, it might help.
[removed]
clever! never heard that approach before but it allows going back old versions.
Chucking the fork into vendor to debug would be pretty easy. I've ended up having to do this a few times and it works with no issue. The biggest pitfall as outline above is working with maintaining either a monkey patched version, or flat out forking it. The worst I've seen is a project checking in the vendor dir to put off refactoring. It can lead to a lot of build time headaches if managed poorly and should be generally avoided at all costs.
There's no point in a discussion with you as regardless of what arguments I bring you are just stuck in the opposition.
It is highly unlikely that a usecase like this would profit at all from sync.Map. There will be at most a handful of operations on that map anyway and in 99% of usecases they'll be from a single goroutine. sync.Map is pretty rarely useful (despite being hyped). I recommend [this video](https://www.youtube.com/watch?v=C1EtfDnsdDs) for an overview of when you *might* benefit from it. Personally, I'd probably just ditch the mutex and tell people that Register can't be called concurrently with ServeHTTP.
Google has released their guidelines about this a while back. You can read everything [here](https://opensource.google.com/docs/creating/). There are multiple options if you want to release open source software, depending on the specifics. The employment contract specifies that all code you develop while employed by Google is owned by Google (even if you do it in your spare time with your own resources). Whether that clause is actually valid in its phrased reach, what its limits are and whether you could fight it is… contentious and depends on the jurisdiction you are in. You can, however, request a copyright-assignment from them in a process called [IARC](https://opensource.google.com/docs/iarc/). It's usually pretty painless and quick, I went through it a couple of times. It boils down to filling out a form with some general information about the project and usually hearing back inside a week that you get the copyright assigned. In that case you can't use any company resources (whether it's machines, time or Googlers time) on it. I know several people who got denied the Copyright, though. The other common alternative is to use a [different process](https://opensource.google.com/docs/releasing/) to release your code as open source but leave the copyright with Google. I never used it, because it actually seems more complicated than IARC and will henceforth require contributors to sign the CLA (as far as I know), which is a bit of a hassle. On the other hand, it can also be advantageous, as you can work on it in company time, using your company-issued machines.
To name a few in no particular order: - https://www.ubuntu.com/cloud/juju - http://rancher.com - https://www.cockroachlabs.com/ - https://istio.io/ - https://upspin.io/ - https://camlistore.org/ - https://blogs.dropbox.com/tech/2014/07/open-sourcing-our-go-libraries/ - https://coreos.com has - https://coreos.com/etcd/ - https://coreos.com/rkt/ - …and so on. - https://linuxcontainers.org/lxd/ - https://kubernetes.io/ - https://security.googleblog.com/2017/01/security-through-transparency.html - …and so on. There's even a virus written in Go :-) https://news.drweb.com/show/?i=10140&amp;c=5&amp;lng=en&amp;p=0 So yes, I'm with @natefinch on this: Go unfortunately lacks a robust universal desktop GUI solution (like Tk) and this severely limits its adoption for writing desktop stuff (even though extensive bindings for GTK3 and Qt/QML do exist) but on the server side Go pretty much kicks asses. ---- Also note that when you analyze actitity happening on public forums devoted to software development, there always will be a natural bias towards the so-called "vocal part of the community" which will get over-represented in the results: sure, those hardcore folks which are busy developing high-profile solutions are seldom seen asking on such forums about which web framework to pick for the next bedroom project ;-) And since much education (and self-education) in programming these days comes through web programming in particular (and often gets stuck at that phase), that's what you often see being discussed. 
The term stuck with me from Terraform (and HIL, the HashiCorp Interpolation Language). The reasons text/template doesn't fit my purpose: - Flint is primarily created to evaluate short expressions in configuration files and I don't need iterators, ifs, variable definitions, etc. Maybe I'll need some of these features later, but I still want the two use-case separated like Jinja 2 does it: {{ ... }} and {% ... %}. - I need complex, but easy to read arithmetics - In my opinion text/template's primary focus is not user-friendliness and in my case it was important that the learning curve is minimal and it's easy to read Edit: formatting
What is the start ups name?
Hi, I am interested. I want to develop my own home automation system based on Raspberry Pi 3 . This guide will be very helpful for me. I know Go basics and want to learn more. Now I work on UI using BeeGo as backend - it is in very early stage.
Thanks!
Thanks for the info! 
I like that the project doesn't force you to use its template. Is it possible to have it as a package that return all the database information in a typed struct and you decide what you want to generate?
some jobs for government contractors require us citizenship to pass the security clearance, and H1B/remote are never eligible for those positions
This was the answer I was looking for, thank you.
Please consider my reply as a substitute for the site's inability to have me perform multiple upvotes.
If necessary, then I'd make it a composition of multiple sub structs containing tightly coupled items.
Wouldn't the scp fail in this case ? Saying that the file is open and cannot be deleted ?
I use rsync but yes you can replace a running binary then restart without problems. 
If you know how many colums are there you can use somtehing like this: const numOfCols = your_nums_of_cols type Data struct{ Items[]interface{} `json:"items"` } func (p *product) getProduct(db *sql.DB) (Data, error){ row := db.QueryRow("SELECT name, price FROM products WHERE id=$1", p.ID) var data Data data.Items = make([]interface{}, numOfCols) for i := range data.Items { data.Items[i] = &amp;data.Items[i] } err = row.Scan(data.Items...) if err != nil { return data, err } return data, nil } If you don't know number of columns, you can use some kind of query to count it and base your numOfCols on it :)
I really enjoyed using gorm in a few projects. Just wish the sqlite adapter was pure go so cross compiling wasn't such a pita.
Well, that's sort of what it already does. But if you need more control, you can use it as a library. I made the generation code completely separate from the database reading code, so you can totally do that. 
[removed]
It's a lot to get around to, the XSDs are painful to deal with. The ECMA-376 XSDs in particular use all of the expressiveness of the XSD language in lots of different ways which means you really need to parse it and then make multiple passes to resolve types, groupings, element references, etc. Some of the odd constructs are then only used in a single type or two.
I don't think generating structs from tables is the most painful thing when dealing with RDBMS in Go. The actual querying and data mapping is a fucking pain in the ass on the other hand. But libraries like sqlx are a good solution when it comes to data mapping. ORM are usually a collection of tools that do query building, data mapping, resolving relationships between data, migration from code and generating code based on a schema. A good ORM will allow most of its features to be opt-in. Of course, a good type system allows better ORM. 
Building on an item of this list: upspin.io Upspin.io is in my opinion one of the most conceptually important projects using Go. I suspect that they do have a hidden goal of testing Go's limits in the process of developing Upspin. Take a look at its error package and how their error package uses empty interfaces to handle a mixed set of parameters. Also, it is also one of the few, if not the only one, project in Go's ecosystem that's tackling the problem of a fully distributed file system. Take some time to read its cacheserver and its client implementation. Go also has a solid story on visibility tools. Rakyll's work on gops and the whole pprof and tracing. One of the best I've seen in my somewhat not so extensive experience. 
Wow thanks! Way more helpful then stackoverflow
You mean how to use some Pi-specific features like the GPIO pins from Go? Yeah, I'd be interested in that.
"How do I make a clean and neat big ball of mud?" You don't. https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1
Great name. 
Gnorm can let you do all of that, without a lot of reflect nastiness that slows your code down and makes it prone to errors. I'm not sure what you mean by data mapping, if that's different than mapping a struct's fields to columns in a database... gnorm can generate code for that. Gnorm can let you build queries from strongly typed objects so that you literally cannot pass in the wrong information. Most ORMs I've seen go one of two ways - 1. Their queries are often basically just strings, e.g. foo.Select("bar = ?", someVal) - this is bad in two ways: you have no guarantees that "bar" is a valid column name, and you have no guarantee that the value you're passing into the select is of the right type. this is how GORM works 2. You have to select using a whole struct, and then the code tries to figure out how to make a SQL statement out of that, which is obscure and error prone.
https://gobot.io/
You can get the number of columns using the `(*Row).Columns()` method.
Not new, it [was added pre-Go1](https://golang.org/cl/4389048) in [April 2011](https://github.com/golang/go/commit/92210eefb2fad766f4fe1664495a3c351a32eb89).
Gnorm can also generate a protobuf representation of your database, and the API to feed into it. That's something I plan on using it for at work.
&gt; Personally I've used gorilla/mux since 4-5 years now and never had any problems with it Agreed. I've used is since day one, and haven't run into a reason to look elsewhere. Easy to use, meets all my routing needs, and has good docs. I'm sure the others are great, but I haven't run into a compelling reason to learning something else. To enforce you comment on needing a framework. It's amazing how much you really don't need a framework with Go. Import 3rd party packages as you need them, and Go's standard library takes care of the rest. It really is that simple.
Not what you're looking for since it only looks in `$GOPATH`, but related and highly useful: go list -f '{{.ImportPath}} {{join .Imports " "}}' ... | digraph reverse `go list` Where digraph is `golang.org/x/tools/cmd/digraph`.
That looks pretty cool, though I'm not sure you're going to convince people to start making a lot of functions in their database. 
Here is someone who worked at Google and Amazon giving a breakdown of the policy: https://news.ycombinator.com/item?id=1970226
Here's [one of my more recent non-web projects](https://www.github.com/DeedleFake/wdte). I also threw together a 'script' to sort something yesterday.
Yeah, me neither :)
What's the value this provides over connecting to the database as a database? Adding an adapter layer has to make things slower. What does the slowness buy you? "Easier to work with than an ORM"—maybe but then why are you using Postgres if your objects aren't relational? Just use a key-value store to store serialized objects. 
thanks :) I was also kind of proud of the GSoC proposal's title: - http://hepsoftwarefoundation.org/gsoc/proposal_GoInterpreterWagon.html &gt; Launching Wagon, a WebAssembly interpreter in Go :} 
A playground example would be super useful. This sounds like it's a pure functional approach and I'm intrigued how you expand on this approach for many functions.
note that, ATM, `wagon` does not implement the whole Go language. Mostly because `wasm` doesn't provide all the buiding blocks to do that just yet (e.g. threads, goroutines, garbage collector, ...) Also, the input of `wagon` is `wasm` bytecode. There is no `Go source -&gt; wasm` toolchain yet: we are missing either a `gopherjs`-like transpiler or a new `GOARCH` target in the `gc` official toolchain. But that will be fixed eventually.
It's an API. On top of your database. So that other people can generate a client in whatever gRPC-supported language they like, and access it without needing to hand code a bunch of sql interaction, or set up a whole ORM etc.
&gt; Items[]interface{} `json:"items"` Do you mind explaining what this is? or the terminology so I could google it? EDIT: I think I figured it, out. it's for JSON or to create a map?
I use a shell script. #!/bin/bash # Customise the following variables if needed. HOME=~; INSTALLATION_DIR=${HOME}/Applications; WORKING_DIR=${HOME}/Code/go; GO_VERSION=1.9; # Start installation PACKAGE=go${GO_VERSION}.linux-amd64.tar.gz; PROFILE=/etc/profile.d/go.sh; echo "Installing Go v${GO_VERSION}"; cd ${HOME}/Desktop/; echo "Downloading ${PACKAGE}"; wget -c https://storage.googleapis.com/golang/${PACKAGE}; echo "Installing Go to ${INSTALLATION_DIR}"; mkdir -p ${WORKING_DIR}; mkdir -p ${INSTALLATION_DIR}; rm -rf ${INSTALLATION_DIR}/go; tar -xf ${HOME}/Desktop/${PACKAGE} -C ${INSTALLATION_DIR}; if [ ! -f ${PROFILE} ]; then echo "Installing profile to ${PROFILE}"; touch temp; echo "export GOROOT=${INSTALLATION_DIR}/go;" &gt;&gt; temp; echo "export GOPATH=${WORKING_DIR};" &gt;&gt; temp; echo "export PATH=\$PATH:\$GOROOT/bin:\$GOPATH/bin;" &gt;&gt; temp; sudo mv temp ${PROFILE}; echo "You will need to restart for this to take effect!"; fi rm ${HOME}/Desktop/${PACKAGE};
Looks like the go imports support was added in the latest goggland drop. Fantastic!
So I hate to be the slow one, but does this mean, outside of some smaller pages, complex go to web assembly isn't there yet?
I 'm more interested into create a guide for Go beginners which isn't a web based topic.. In my view most resources for beginners in Go are only about building web apps with it.. I think it would be great to have a little Guide with Rasperry based projects I have my Pi since 3 months now and I run just basic web apps with it but also stuff like using it as a little game console playing go based games with an SNES controller.. I think it would be awesome to have a beginner guide for Go wich isn't built your next web app with it but also show the other stuff you can do with Go just for fun.. Not all programming beginners want wo write web services...
We surveyed people who develop plugins for Eclipse, rather than people who use Eclipse as an IDE.
It's called a struct tag
The functionality in the video was there before goimports was added :)
I appropriate your work! One aspect of Go is that it statically links libraries, and while I appreciate your effort and ownership (along with doing whatever you want with the code), l AGPL is a no-go for many projects (including mine). Many are bound to not even look at AGPL code. However, your description above looks great! Thanks for your hard work. 
Yeah, it will definetely be slower, but how much? Most of my applications can tolerate that, they are not that high performant. Also, I can write custom stored procedures that can make use of relations and aggregations etc. so it is a little different from just key-value stores. Actually, my whole point is to write the logic as stored procedures so that you call your functions.
Thanks! I realize the AGPL isn't for every circumstance, and we do offer a commercial license without the AGPL restrictions. I also debated between the GPL and AGPL, changing my mind several times in the process. It wouldn't take much to convince me to change the license to GPL.
I'm not familiar with aiohttp and these newfangled python keywords, but are all of those equivalent in terms of their concurrency pattern? It almost looks like the aiohttp example is awaiting sequential requests...
If you encapsulate the db &amp; connection details in objects for different uses, you can still reuse the connection under the hood. However, you've bought yourself small and more easily replaced units that can be tested independently and change the storage engine. Having smaller interfaces also makes sense, because you want the consumer of an interface to define what it needs only, not define a massive one at the site of the implementer (and then have to import the implementation to the thing that's supposed to use it). Putting the interface with the consumer removes the need for the consumer to know anything about the other implementations or queries you may or may not provide, and also makes it very clear that they're not overlapping and using other queries that happen to be available. 
I am new to Go. Being a Python developer, I just wanted to understand the performance difference between Python's coroutine and Goroutine. I thought, maybe by making requests I can do a comparison. Obviously, nothing revolutionary is done here. Yes, I understand your concern. Can you suggest me what can be a better way to benchmark? BTW, the results I've posted are the average of 10 iterations of each code. I would love to know your insights. I wrote this post because while writing such things I come across a lot of nitty-gritties of both the worlds. Don't know if it was worth enough to post this here but anyway, I would love to know about everyone's views.
Yeah, that would be nice info to have. Please do. 
Surely wasm supports *building* a GC; it just doesn't have one built in, right?
Thanks, that sure are important details to keep in mind.
I don't understand what the use of channels in the Go example achieves. Can't you just print the error at the end of the goroutine, if it exists?
correct. AFAIK, there is no tool to transform *any* kind of Go source code (complex nor simple) into wasm. For a GSoC project, I figured writing a decoder of the wasm format was tractable in the alloted time (3 months), but a compiler? ... probably not. :)
I wanted to wait until the goroutines complete the execution. I read about it here: [https://gobyexample.com/channel-synchronization](https://gobyexample.com/channel-synchronization) Is this not the right way to deal with it? BTW, I am new to Go and I would love to know your views.
AFAIK, wasm doesn't support *yet*, in a portable manner, the building blocks to build a GC. The (WIP) specs to build that (the post Minimal Viable Product) are there: http://webassembly.org/docs/future-features/ 
I would be very interested in something like that!
So if I understand correctly, wagon is (atm) a WASM interpreter? Also, are there plans for a Go bytecode representation between Go AST and WASM? It seems like it could make for a really awesome target language.
&gt; wagon is (atm) a WASM interpreter? correct. &gt; are there plans for a Go bytecode representation between Go AST and WASM? perhaps not at the AST level, probably more at the SSA level, but, yeah, that's the overall plan.
What is go sync / async??
Oh, I missed that in the README. Are you able to advertise the terms of sale? There is a chance I will need an xlsx with chart capabilities in the near future. 
To summarise the comments: type Job struct { Salary int Industry string Keywords []string RemoteWorking bool }
A function *num* as coded below, which takes an arbitrary number of integers, e.g. *num(78, 901, 234))* to mean *78,901,234*, might work. I doubt it would be inlined, though. package main import "fmt" func num(ds ...int) (e int) { n := 1 for i := len(ds); i &gt; 0; i-- { g := ds[i-1] if g &lt; 0 || g &gt;= 1000 { panic("Out of range!") } e += int(g) * n n *= 1000 } return } func main() { fmt.Println(num(123)) // 123 fmt.Println(num(7, 123)) // 7123 fmt.Println(num(7, 23)) // 7023 fmt.Println(num(7, 023)) // Whoops: 023 is octal, so 7019 fmt.Println(num(78, 901, 234)) // 78,901,234 fmt.Println(num(-1)) // Panic } 
PM sent.
How do I view the contents of the data? I was to print out the values from the table.
Why not compare the simple worker-pool implementation here - https://gobyexample.com/worker-pools ? It's pretty simple. There is no network call. Though not sure if you can easily map it to python. This will not test your concurrency though, as all code is pure blocking. To test concurrency, setup a simple web server and benchmark that.
Yeh I realize that now ha, I think what I meant is removing imports that are no longer used, you can run go imports manually via the menu option but I'd like to add a hook in save like I have in emac 
Interesting.. I'll have to review more carefully this evening, so apologies up front if this feedback is incorrect. At first glance though this doesn't really seem to favor data at rest. It has a lot of semantics around small chunks of moving data, things I would expect to see over the wire. Specifically the repeated headers layered on top of a symmetric block cipher in the name of anti tampering, akin to TLS. The fact the definition for the format has no true header I think reinforces this and makes it a bit less friendly for at rest data. You can't use pbkdf or create any ACL, multi key slots, and most of all arbitrary payload sizes and the AF diffusion along with it or make updates to existing data. I guess my point is this seems like at most a weak fusion between transport security and data at rest encryption, verse something favoring data at rest from the ground up. The biggest thing to place me in this position is the fact arbitrary payloads are not supported and the data seems immutable. If there was a way to specify chunk size, as well as the first pkg changed to be a "pkg master header" so to speak with support for some meta data so you could use a single master key and derive a new random key for each file used and store it securely in the master header I would like this much more. Then you can delete all the lines about key reuse. You can also then update existing data of course and maintain diffusion.
Missed that in a cursory read. Great idea, especially if building large scale lakes for consumption of things like Aurora. 
&gt; I'd like to add a hook in save like I have in emac Settings | Go | On Save Or if you are using the editor: Optimize imports or Code | Show reformat code dialog... and check Optimize imports (if it's not already).
https://www.welovegolang.com/
I'm wondering if these results would differ from Go 1.8. I thought one of the big things with 1.9 was more inlining.
Nice article. There is also a fairly interesting [comment](https://lemire.me/blog/2017/09/05/go-does-not-inline-functions-when-it-should/#comment-285483): &gt; Go is especially interesting to me because Go applications are impressively fast for a GC language, yet at the same time it’s clear that Go could be *much faster*. &gt; The language’s ethos is full of contradictions. It’s new, but it feels old in so many ways. Go is… dusty. When I looked at the compiler source a couple of years ago, I was surprised to see what looked like Rob Pike’s old Plan9 asm files. At the time Go was seemingly unaware of CPU instructions introduced since 2000 or so – there was no vectorization, no BMI, not even string compare instructions from SSE 4.2. &gt; A lot has improved since then. For example, Klaus Post’s SIMD optimizations of deflate and gzip made it into Go 1.7. &gt; But there’s still a lack of modernity in the language that keeps is slower than it should be. Interrelated problems: the lack of good inlining makes PGO less useful, and not surprisingly Go doesn’t have PGO. The lack of attention to vectorization, on both the front-end (explicit vectorization syntax or hints that a developer could employ), and the back-end wrt auto-vectorization, is another area where Go seems out of step with modern computer science and optimization. &gt; The good news is that Go has lots of headroom, still! They’ve proved that you can build a precompiled language with GC that is much faster than Python and Ruby, and as fast as Java and C# – and that you can also have a much simpler and faster build process and toolchain along with the unusually fast runtime speed. &gt; Go has served as a very useful demonstration of what’s possible, of how much better we can do than Python, Ruby, Java, .NET, etc. I feel like the next step is to show that we can have all the good things about Go along with much faster applications, vectorization, GPU/OpenCL, and the trappings of modernity like generics and much better syntax. &gt; In fact, I think with the right team, a proprietary Go compiler and IDE could thrive in the marketplace. Go can be a lot faster, and some people would be willing to pay for it.
You might want to split the `site` dir into a different repo, right now Github is claiming your project is only 9.8% Go.
Thank you!
Yes, I think so. From the article: &gt; The Count benchmark in Go is about two times faster than it was prior to Go 1.9, but it is still far from Java.
Three points: JVM excels at microbenchmarks. It's the nature of JITs to do that. As far as Java vs Go comparisons go, a macrobenchmark might show very different results. I want a pony, too! The Go compiler isn't all that great at optimizing things. It's still pretty new, as compilers go, and simple. Do you realistically think the core devs haven't thought of this concept, ever? Optimizations get added in every release. Back in my kernel hacking days, there were lots of times when less inlining meant faster code. The right amount of inlining depends on icache pressure.
Awesome.
github.com/tmc/watcher might fit your needs I typically do something like `watcher -v sh rebuild` and rebuild is a small shell script, also: $ cat bin/reloadtab.sh #!/bin/bash set -euo pipefail osascript -e 'tell application "Google Chrome" reload active tab of window 1 end tell' 
&gt; modernity I hate the trend where everything the writer likes is called "modern" or "elegant". Remember, at the other end of embracing all that "modern" complexity is C++.
For less whining and more constructive conversation, read the linked https://github.com/golang/go/issues/17566 instead.
I'm sorry but the person that wrote comment doesn't have a basic understating on how compilers and languages. I've been in the same position and wrote those kinds of comments myself but I've learned so much since then...
This sort of comment would be much more useful if you explained why they are wrong and what is it that you learned that changed your comments.
We are using https://github.com/perseas/Pyrseas for that
The mid-stack inlining didn't make it into Go 1.9. The performance improvements mentioned in the article is from the `math/bits` package.
You should post both sync/async code in your blog. I was really confused by your graph until I realized that the rest of your code is in a repo.
He didn't post all the code in the article. https://github.com/vipul-sharma20/async-go-py
What's the motivation behind not having zero values?
Mostly because they seem out of place in a functional language, where an Option type could represent the same thing with more safety. That said, I haven't thought thoroughly about this, and I would love to hear any opinions.
What about performance? For instance, how fast examples/json in compare with encoding/json from standard library?
Any plan to support opentracing-go?
The thing is that "runtime performance" is just one metric; there are many other related ones as well: - Compilation speeds. - Startup performance. - Memory usage. - Determinism of performance. - Stability and reliability of compilers (yes, compilers have bugs too!). - Portability of the compiler to different platforms. - Quality of error messages. - ... and probably some more... Java for example tends to do very well on "runtime performance", but usually not so well on startup performance and memory usage. I always feel that these sort of "language foo can bang more bits together than language bar!" benchmarks kind of miss the bigger picture. Sure, banging bits together very fast *is* important, but it's just *one* thing that's important, out of many. Often times compiler authors need to make trade-offs.
&gt; JVM excels at microbenchmarks. It's the nature of JITs to do that. As far as Java vs Go comparisons go, a macrobenchmark might show very different results. &gt; Personally I care more about memory footprint/cpu usage than raw speed and there is no debate, Go beats Java in that perspective. Go is still mostly fast, but clearly slower than Java, in a real world web app serializing or communicating with a DB, because of the slowness of some packages in the stdlib,or its features ( all the type asserting,converting,implicit interfaces,reflection and co are slow). But as long as it lets me run 10 servers on a micro instance with great performances... you just can't do that with a servlet container running JEE.
&gt; Next generation of CMS data replication system https://github.com/vkuznet/transfer2go/ [as in Large Hadron Collider, not Content Management System] &gt; Launching Wagon, a WebAssembly Interpreter in Go https://github.com/go-interpreter/wagon &gt; Jet Clustering Optimizations in Fads [High Energy Physics] &gt; Updating gopy to support Python3 and PyPy
Bit of a shit show, tbh. aiohttp's Session implements per-host limits by default (which is why it appears to be slow, when it is actually super-fast). The version of Go used is old. Probably doesn't make much difference, but a modicum of processing of the received data would strongly favour Go's ability to use multiple cores vs Python. And a typical amount of data transferred, plus like-with-like connection limits, would have shown aiohttp's (and asyncio's) speed.
I haven't used it, but I've heard good things about [viper](https://github.com/spf13/viper)
I have used viper and it is good. That isn't the [configuration management](https://en.wikipedia.org/wiki/Configuration_management) I was referring to though.
**Configuration management** Configuration management (CM) is a systems engineering process for establishing and maintaining consistency of a product's performance, functional, and physical attributes with its requirements, design, and operational information throughout its life. The CM process is widely used by military engineering organizations to manage changes throughout the system lifecycle of complex systems, such as weapon systems, military vehicles, and information systems. Outside the military, the CM process is also used with IT service management as defined by ITIL, and with other domain models in the civil engineering and other industrial engineering segments such as roads, bridges, canals, dams, and buildings. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Have you looked at Haxe? It doesn't have a Go target that I know of, but could give you some ideas based on how it generates code for other targets (C++, Lua, PHP, etc)
I've heard of it. Maybe I'm naive, but I'm thinking it should be easy enough to target Go. Pretty much everything in the hypothetical Gallium AST *should* compile neatly into a Go AST.
https://github.com/purpleidea/mgmt Sponsored by RedHat as well (in that they hired the guy writing it)
I've posted on https://www.golangprojects.com/ (I believe) on behalf of my company before. If you can swing it, GopherCon is good for networking. Also, the sponsors are there for recruitment (mostly.) You could try looking up job postings for those companies.
This is actually the one I was looking for originally. Thanks.
_This is actually_ _The one I was looking for_ _Originally. Thanks._ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^netzdamon ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haiku.
Neatly may be the hardest part. Especially if you're expecting to use the Go code natively. Code generators typically aren't great at generating idiomatic code.
As far as I can see you're comment points out "missing features" - like key-management, ACL a.s.o. From my point of view managing keys or doing access control should not be the responsibility of the encryption format itself. Those features can/should be implemented on top of the format. Otherwise you probably end up with another complex format which still address only a subset of use cases and/or implement e.g. key management in a incompatible way. What would you support PKI, Kerberos,...? Further additional meta data like the proposed master header would make the format unusable for many use cases. E.g. completely variable chunk size and master meta data would make random access very hard to implement. As far as I can see you want features provided by the aws-encryption-sdk. But we tried to not include this features to make the format usable in many different use cases. It a little bit like a pragmatic vs. an enterprise solution. 
Why on earth are you still using Go 1.6 to compare with Python 3.6, that is like staying on Python 3.2 because you are happy enough. You really should use an upto date version of Go for this sort of experiment, 1.9 or 1.8 maybe but not 1.6 it's too old.
 * ./bitset.go:126:6: cannot inline (*BitSet).extendSetMaybe: function too complex * ./bitset.go:151:6: cannot inline (*BitSet).Set: non-leaf method There's the reasons. Set calls extendSetMaybe. If worried about CALLs then maybe not have functions that maybe do something, and inline the test whether the set needs extending first. Maybe.
Have your tried a Spring Boot or similar server setup? The VM should get by with about 16 MB. 
I disagree wholly with your premise that satisfying the rust compiler takes more time than debugging Go concurrency bugs. In my experience writing Go (2 years professionally at Google and at Square) the time spent identifying and resolving concurrency bugs dwarfs the time spent making something correct enough to compile in rust by orders of magnitude. I can't count how many times I have found nondeterministic behavior because someone closed over mutable state when launching goroutines for example. It's perfectly possible to just not learn why you're having problems, whether it's how you're writing concurrency bugs in Go, or why rustc won't give you a break. For that developer rustc will feel like a time hog because Go will let you think you got it done even if you didn't. Now I don't mean to say that one is necessarily better than the other; it just depends on how much bugs matter in the big picture. For a lot of organizations it matters more that they can launch fast and get productivity out of junior engineers than it does to be bug free, and that's a perfect situation for Go. But you should recognize the tradeoff you are making: gaining ease of use and development speed at the cost of bugs; you wouldn't be reducing time spent achieving correctness in your programs.
This seems really similar to xo https://github.com/knq/xo
I'd use sync.WaitGroup. It basically works like a counter and blocks until all goroutine have completed. 
You give conflicting signals on whether you mean this as a language you seriously want other people to use for some definition of "real work" or whether this is a learning project. I'm going to give feedback as if it is the latter, because right now even if you had everything in hand that you have sketched in your README.md, you wouldn't get anywhere because you'd be overshadowed by Go itself. You would need substantially more differentiation than providing those features, many of which can be half-done right now either with existing packages for Go or half attained via semi-clever use of existing features. _But jerf, having the *entire* features for those things would be qualitatively different and what's on github now are just hacks by comparison..._ Yes, I get it and I agree (Go is _far_ from my only language, I've spent quite a bit of time with Haskell, I understand those things quite well), but I'm not talking about the desirability or goodness of the resulting language, I'm talking about the fact that without sufficient differentiation you're not going to escape from Go's gravitational attraction within the Go ecosystem, which is, unsurprisingly, fairly large. So instead I would give some suggestions on how to do something useful which will teach you some things, maybe even turn into an interesting Go code generator project, and be useful at almost every step along the way. 1. Create a Go-to-Go compiler. As a really hacky first pass you can use the existing Go parser and code generator, but that would just be a getting-your-feet-wet thing. What I mean here is that you need to write a parser for Go code that emits into your own AST, which does not use the ast package at all. Then you convert that AST into Go's existing AST types and emit Go code. It would be an ideal learning exercise to do this parser from scratch from the language implementation, but if you want to come at it more as an engineer you can copy/paste the existing one. However, while that will speed you up in this step, it will slow you down a lot in the next one. One suggestion I'd make: Consider ignoring and just stripping out comments, or at least making your peace with the fact they might not all make it through. The Go parser's handling of them is quite idiosyncratic and bizarre. (I understand _why_ it does what it does, but it still makes it bizarre for your use case here.) The downside of this is that if you do this from the beginning you may have a really hard time retrofitting the comment behavior entirely and correctly. But you may consider just living with the fact that in your final compiler some comments may disappear during compilation. After all, this is ultimately a full compilation process, not a `gofmt` run. It will feel weird to "convert" your AST types into the Go AST types when all it is is a straight conversion. Bear with me. At this point you have (Your New Parser) -&gt; (Your AST) -&gt; (Go AST) -&gt; (Go prettyprinter) -&gt; (Go compiler). 2. Start modifying the parser to generate the constructs for your new features. I would suggest the true sum types is the way to go. I'd suggest making it easy on yourself and using a unique symbol to differentiate them so the parser doesn't have to be too hard or ambiguous. Then, once you have parsed the symbols, you need to insert a new phase: (Your New Parser) -&gt; (Your AST) -&gt; ([Lower](http://mattwarren.org/2017/05/25/Lowering-in-the-C-Compiler/) Sum Types) -&gt; (Go AST) -&gt; (Go prettyprinter) -&gt; (Go compiler). At this point you now have a language that clearly enhances Go and can be dropped in anywhere you like because the output is real Go, and now it has Sum Types too. 3. Next, you can try blocking zero values, though with this plan you will certainly still get them from the rest of the Go you're interoping with. By the time you close all those holes I _think_ you'll find this is actually more complicated than adding Sum Types, which is why I put this second. 4. Next, implement generics this way. It is ideal to try to work out a way to do this so that each of these features is a distinct lowering phase, rather than trying to do it all in one shot, but that's easier said than done. 5. Next, implement the traits support. 6. And should you get this far, you'll pretty much know what you want to do next. In step 1, you may be tempted to try to beat on one or another layer of Go's existing code to try to avoid having to write your own parser. I strongly suggest resisting this temptation. I've tried it before, not in Go but in other places, and it just never seems to work out well. The parser always has more context in it than you realize and more hard-coded decisions, and usually you can't even make what you want really work right, and even if you can sort of get something, it will always be immensely compromised vs. having a real parser. The end result of this plan is that you don't really have a _language_ per se, but you _do_ have a freakishly powerful code processor that others may be interested in expanding on. Going full-on macro processor is not out of the question. (An alternative would be to make step 2 "implement a macro processor" and do the rest in terms of macros, except "blocking zero values" won't be able to be done that way. You can add things with macros but you can't really take them away like that.) In terms of convincing people to use your stuff, if you are interested in that, that may be an easier sell than a full "language", because you can always examine the output of the code processor and satisfy yourself that it's working correctly and/or fix bugs, whereas languages are intrinsically a huge risk to take on any serious project. Hypothetically you could keep iterating this way, with a working language the entire way past step 1 (an advantage of the plan I outline here over most of the alternatives), until you are meaningfully differentiated enough from Go. In particular, with no particular offense intended nor any impugnment of your dedication, having a functioning system means you can put it on GitHub and drop it with peace-of-mind at any time. This is not something to take lightly. :) (Oh, one other thing: Apologies if you already know this, but: **TEST SUITE**. You need one on **DAY ONE**. I strongly recommend setting up a pre-commit hook in Git to run them all on every commit. I'm not a fan of TDD but this isn't a bad domain to use it in. Crib any samples you can from the one the Go compiler has as they will already exercise a lot of corner cases. It won't be all _your_ corner cases, but it's still a great start.)
Fair enough, I had a different experience. Maybe I'm just not learning quickly as you suggest. But it's not a matter of Go being too permissive; as I mentioned, most code isn't concurrent, so in these cases, Rust's pedantry isn't keeping you safe. If you write a lot of concurrent code, then Rust is probably a good deal. If you're a slow learner who writes mostly sequential code, Go may be the better bargain.
I mostly agree with that. My comment about not learning is not meant as a slight to anyone; in this particular context I think what someone learns is almost more an organizational responsibility than an individual responsibility. If you're in the position of choosing to learn something, you don't know it, and whether you learn it is largely a product of whether the more experienced people you trust tell you it is worth learning.
Highly Aggressive? What does that even mean? Does it growl at you if you make eye contact? Does it bite children and need to be put down?
All other downloaders only try 10-20 times when an error occurs, But this tool just keeps trying unless the error is not recoverable(like a 404, 400 status code or permission denied errors)
You can range over the slice and do switch on interface types. Still, i don't think this it is good practice to scan data from your queries like that. The only way where i found it handy was when i had like 12 columns of the SAME type, so i could just run over slice without fear about data types.
The Gophers Slack community has a jobs channel. A reasonable amount of both onsite and remote Go jobs get shared there. 
I've been looking for an answer for the last 4 years too. This is the best I've found. But I'm still looking for a better way. https://github.com/shurcooL/cmd/blob/3775d1a67e78fba6a8380e30337340465a0b30e3/gorepogen/main.go#L80-L93
Check out http://golang.org/s/types-tutorial, specifically https://github.com/golang/example/tree/master/gotypes#an-example :)
If you’re using Go ≥ 1.9, `importer.For("source", nil)` is the most useful/correct importer (because it doesn’t require up-to-date export data files to be present), but also slower than `importer.Default()`.
I recommend looking at cmd/vet or cmd/lint source as an example. They are an easy read: https://github.com/golang/go/tree/master/src/cmd/vet
The issue is definitely a nice read, but how is the article whining in any way? Why is it that whenever someone writes a post that says Go is anything less than 100% perfect, some people get extremely defensive?
I quickly composed a benchmark (1k and 10k json files), which showed what I expected, that it's much-much (20-25x times) slower. As you can see there are a lot more allocations, so saying there is definitely room for improvement is a gross understatement :) BenchmarkParsleyJSON1k-4 2000 675279 ns/op 836351 B/op 5699 allocs/op BenchmarkParsleyJSON10k-4 300 5179790 ns/op 5051039 B/op 41830 allocs/op BenchmarkEncodingJSON1k-4 50000 25363 ns/op 5952 B/op 120 allocs/op BenchmarkEncodingJSON10k-4 10000 207244 ns/op 44432 B/op 918 allocs/op
That's not very friendly, is it? You really *need* to hit a server with more than 32 simultaneous connections?
That's not very friendly, is it? You really *need* to hit a server with more than 32 simultaneous connections?
I got hired through Stack Overflow Jobs last year (as a Go dev).
&gt; At the time Go was seemingly unaware of CPU instructions introduced since 2000 or so – there was no vectorization, no BMI, not even string compare instructions from SSE 4.2. SSE4 instructions are nearly complete. I believe this is the last instruction that got missed out - https://go-review.googlesource.com/c/go/+/57490. I myself have added a few AVX2 instructions. The main issue is that if the compiler were to emit these, the minimum requirement for processor needs to be raised because now the processor has to support all these instructions. Certainly, you can conditionally check for cpuid flags and then emit instructions, but I think the compiler folks have yet to tackle this in an elegant fashion. On the other hand, using these instructions are very easy to use in raw assembly because the control there is much easier. As a result, you will see lot of fast path implementations in the crypto package using AVX2 instructions. Relevant comment from Keith on a golang-dev thread regarding addind FMA to am64. &gt; It is unlikely that the compiler would generate FMA on amd64 because the instructions involved are not guaranteed to be available on every amd64 we support. Any FMA would need to be guarded by CPUID instructions. Guarding in assembly is easier because we can do it at larger granularity. Again, I know of no one working on it.
Why stop at 32?
That is a debatable point. Development of a lot of famous/established download managers started at a time when internet connections weren't as fast as they are today and maybe the authors of those tools thought that 32 connection is plenty and increasing it would likely result in a connection drop and so they set max limit to 32. My internet connection is 50mbit up/down, And I have tested and noticed it multiple times, when I am downloading a file via IDM(32 parts) it gives about 20-25mbit down, And when I was using pluto(100 parts) It just shot all the way up to 48mbps and stayed there the whole time except in the end when most parts have finished downloading and only some are left. I could improve it by doing what IDM does by reducing what remaining workers have to download an distributing it to workers which have finished their job. But I am not very good at writing clean code and implementing this will get really messy. So, I'll just figure out a good way to implement it and then do it. :) 
RPC is not REST. That's one of the things that's confusing you. Using raw RPC is considered a bit of a smell these days, most people would consider for these use cases gRPC. I recommend you take a read of https://grpc.io Now, add protobufs. https://developers.google.com/protocol-buffers/docs/overview So, now you have an object representation being shared everywhere in a way that is very fast, and you can automatically generate client SDKs for. When you implement your server, you can generate the SDK and hand it to another team/developer and they're off to the races, with a ton of decisions made for you. Should you use it everywhere? No. But REST is not a golden goose, it has drawbacks, and when compared next to gRPC, you can see some occasions where you'd choose one over the other or vice versa.
42 appears to be a well thought-out pick.
"Stitching" a file is not too interesting: if bittorrent clients would work this way, we'd be out of disk space. What's preferred is using `fallocate(2)` (see [this](https://golang.org/pkg/syscall/#Fallocate)) and then writing the downloaded parts right _into_ the file (using, say, [`io.WriterAt`](https://golang.org/pkg/io/#WriterAt)); all this — while keeping a temporary file containing the bookkeeping information — aside with the downloaded one.
Yeah, I noticed that too. I don't care that much, and the reason I am keeping them together is that then I know the source and the website are always in sync. When I get to a stable release, I'll be making a version of the site per release, so that you can see the docs that relate to the version you're using and not have to figure out what features your version actually has. 
Yeah... I realized that my initial project parameters were off
BoltDB for life
There are also GopherJS, TARDIS Go and llgo as actual compilers. `go/types`, too, if you count just the type checking part. As for why there aren't more: because writing compilers isn't intrinsically fun, nor does there seem to be a real need for more Go compilers. If you wanted to write your own compiler, the specification and memory model would definitely be enough to do so, they're well written and complete.
Yes, it's very similar with some distinct differences. I actually built Gnorm after being dissatisfied with xo. xo is built to generate go code specifically, which hinders it when trying to generate other things like protobufs or documentation or any other language. xo is built only to output to a single directory. This hinders namespacing so you end up with long horrible names to avoid collisions. Finally, the documentation for xo is very limited. From my work on Hugo and running a site built with Hugo, I know how important documentation is for a tool that requires you to write your own templates, or use someone else's. And that's why https://gnorm.org exists and is constantly updated.
Sorry, I failed to explain it correctly, So, I'll try again. I create a partFile where the data in a particular range is copied. When a worker finishes downloading bytes in a range, All the data from partFile is read and then written to completeFile using writerAt. 
I've never used the Amazon sdk, but LUKS comes to mind. What is hard about random access for variable chunk size, this is exactly what it best suits. You read the header then know exactly how large the file is, so your random access is simply header size + offset. If you have multiple chunks and decide to allow the user to write each chunk differently then well I suppose you must read each chunk of random sized data, and have successfully created your own problem. But anyone reasonable would in 99% of cases for at rest data know the entire size of their data up front. In those cases only a single continigious block and single seek after the header is read. This is literally the way the solutions that do exist perform encryption for at rest data, Forcing 64kb chunks does not make sense to me given that in most uses cases for at rest data you know your chunk size in advance. As for the missing features comment, I'm pointing out your spec dedicates a large section of text to rules around key management, translating to rules around external state synchronization. External state synchronization being bound to a cryptography specification is dangerous, which we both agree on... or you would have several paragraphs dedicated to this problem area. I simply offered you a reasonable way to avoid his while making the entire system less error prone by removing the complexities of secure key derivation. I have no idea how this has anything to do with PKI being managed in a incompatible way. Or how it changes kubernetes you would need to be more specific. I only removed the steps you already have to do one way or another. I disagree in general with the premise of your arguments and feel this very similar to a session based transport security scheme, but with the added drawback it doesn't provide mechanisms to derive the session establishment from a symmetric or asymmetric key pair. Leaving a very critical and complicated processs to the end user. I'm not a cryptologist though, I'm a security engineer with a lot of experience in crypto systems and would be willing to concede my point of view to expert review. Has a cryptologist reviewed this specification yet? What is the experience of the main contributor and or contributors? Please don't mistake my scrutiny for hostility here though, have a gander at my post history I primarily participate in security related discussion here so im not targeting your specification specifically. I find it interesting and I really love security related contributions to the Go ecosystem and think you're doing a good thing here. So my main point here is most your arguments don't really provide quantifiable counter arguments. I want to understand how the suggestions I've made COST more to the specification than gained by removed all of the text around key deriviation to support your spec. Your specification is not self contained, it requires use of external cryptographic primitives and as it stands I don't see around storing at least the data that will exist in the header I suggested in storage system anyways- there must be this one to one mapping invariant held for security. Why not enforce this invariant in the only enforceable place- the scheme? Remember while you may be a cloud company and it's a easy thing for your to achieve and get right- the majority of the people who will benefit from your hard work are not. I won't comment further or attempt to strongarm you to sway your position, I imagine I won't be the last to raise these concerns.
Also, a large portion of the docs are generated from the source, so it's a lot easier to just keep them together.
Tribalism and an us-versus-them mentality?
&gt; I disagree wholly with your premise that satisfying the rust compiler takes more time than debugging Go concurrency bugs. I suspect some of it is experience level, both with programming the "harder" languages in general, and Rust in particular. Once Rust is done rewiring how you think about data flow at all, it gets easier. (It's similar in Haskell; at first it seems like nobody could ever do anything with this language, but once you rewire yourself it gets a lot easier and can even become your preference.) &gt; I can't count how many times I have found nondeterministic behavior because someone closed over mutable state when launching goroutines for example. I know Go2 == generics in a lot of people's minds, but I'd actually much rather see something helpful for concurrency come out. I recognize that it can't be something like "import Rust lifetimes", but something like "label this goroutine's interaction with the world as 'non-shared' and have the compiler verify that all communication in or out either correctly transfers ownership (i.e., once sent, it is no longer accessed by the original goroutine) or is fully deeply copied" or something would be _awesome_. In fact, going to the OP's question again, this is something I'd _love_ to see come out of my wall of text suggestion I gave, much moreso than the features listed on the GitHub readme. Like, I might seriously use a preprocessor that gave me `go_safe` that worked just like `go` except statically verified to the extent possible that I didn't accidentally overshare with a closure, or pass in messages with pointers that didn't get copied like I expected, or use things after I passed them in, etc. (Though in terms of difficulty it probably actually rates even higher than the generics + traits; removing things in the preprocessor is generally harder than adding them.) I've been using Go for a long time, and I have a bit of an advantage in that I came into it with ~5 years of Erlang experience already, so _I personally_ have had less concurrency trouble than most people because I already knew how to think in this world, and even if Go didn't really _help_ me, it doesn't stop me either. But I was disappointed when I first read about it when it came out and I saw that it was really just another shared-memory-with-threading language, and while I suppose I've made my peace with that, the disappointment still lingers.
I changed it to sha256 :)
Changed it to shasum -a 256 :)
Because it can be hard. I suggest you [this video](https://www.youtube.com/watch?v=rFejpH_tAHM) to understand how complex something like Go compiler can be.
Here is an example of a struct that gets passed both by JSON and inserted/retrieved into mongodb. The difference being the id field. Mongodb uses _id, my JSON uses id. Not sure if this is what you are looking for. type poll struct { ID bson.ObjectId `bson:"_id" json:"id"` Title string `json:"title"` Options []string `json:"options"` Results map[string]int `json:"results,omitempty"` APIKey string `json:"apikey"` }
You can write the commod fields into a struct and then nest them into another struct. Example: type CommonFields struct { Foo string Blah string } type DBFields struct { ID string CommonFields } type SensorFields struct { Token string CommonFields } 
You can use tags on your struct definition to tell the json package to ignore or rename certain fields in the struct. The following will output OtherField when encoding to json, but not field. type t struct { Field int `json:"-"` OtherField int } More examples in the [docs](https://golang.org/pkg/encoding/json/#Marshal)
The extra B is for BYOBB.
Dgraph's [badger](https://github.com/dgraph-io/badger) might also be interesting for people.
as you are using channels to get the data from those two databases, you don't actually need sync.WaitGroup. pseudo code: func GetUserDetailsHandler(c *gin.Context) { userChannel := make(chan User); billingChannel := make(chan Billing) go func() { userChannel &lt;- UserRepository.FindById( c.getInt("user_id") ) }() go func(){ billingChannel &lt;- BillingRepository.FindById( c.getInt("user_id") ) }() // Up to here, go code went to both databases and is searching for data userInfo := &lt;- userChannel // here we blok until userChannel gets data // we don't fill in billing info until userChannel has data, but // that doesn't mean we didn't go to get it from the database already billingInfo := &lt;- billingChannel // we get here only when both, user and billingInfo have data you may also want to add a timeout channel, in case either user or billing never finish. c.JSON(http.StatusOK, gin.H { user_data : userResult, billing_data : billingInfo, }) return } As for boilerplate, you need to see if this is worth in your actual app, if getting user and billing info take just 50ns, users probably won't notice the diff between waiting 100ns or 60ms if you run them concurrently
I think this is the best option in my case. I had been writing my functions like this: func (api *Api) someHttpHandler(w http.ResponseWriter, r *http.Request) error { var input struct { ... } var output struct { ... } } but now I wanted to test and had to make input and output into public types..
To give some background, CoreOS requested some substantial changes to BoltDB that I wasn't willing to support long term. Bolt is also used by a lot of people and I didn't want to push features that would adversely affect the existing user base. BoltDB still exists and works the same as it always has. In my opinion, if you want a database that is stable and has broad usage then the original BoltDB is probably still the best option. If you need the additional features provided by `bbolt` then you should use the fork.
The JVM is just pretty damn good. Decades of work have gone into it. If Go's runtime gets as fast as the JVM then that's already very impressive.
Badger does not support transactions so it's in a different boat than BoltDB. If you don't need transactions then Bolt is probably overkill.
Hey jerf, thanks for taking the time to critique; your comments here and on HN are always informed and insightful, and particularly welcome in this thread. You're right that I was unclear; I would like for this language to become a "real work" language, but I also understand that a language is a huge amount of work, so I would be content if this doesn't evolve past a conversation phase. Thanks also for raising the point about being sufficiently different to escape Go's gravity--I hadn't considered that because it seems self-evident to me that generics and sum types on top of Go's runtime would be broadly appealing. I need to rethink that assumption, but I wonder if your opinion might also be changed by thinking about this less as Go + some functional features and more as a functional language that is syntactically and idiomatically familiar, benefits from Go's runtime (including no-VM dependency). In other words, my target market isn't just Go programmers who want a couple of extra features, but also the broader market of programmers who want a pragmatic functional language and who find Haskell and Rust too strict (and other options failing for ecosystem/tooling reasons). Maybe this market is still too narrow, but at least this is the perspective I was coming from, which seems to be different than the one you addressed with your "escaping Go's gravity" critique. Hopefully this helps to clarify my intent. 
The spec is actually very well defined. There have been two major implementations from early on - gccgo and gc. We used both at Canonical for a few years (until gc's platforms caught up to gccgo's). There have been only a few times in my memory that there has been a difference in behavior between the two, and only once was that because of an ambiguity in the spec.... and they updated the spec at that time (don't ask me what it was, I forget... some weird edge case IIRC). There are some things which are intentionally not specified, but there's nothing that is vague just because no one decided on a specific behavior.
BoltDB is the on-device datastore for our mobile app (Zenly). We love it. Thank you for the work!
I think I have a good idea about how the generated code should look, since I implement these features in Go as patterns already (minus the unsafe tagged union, but this is a private detail even if the generated code is interfaced with from Go). I'm sure there will come a time when I realize my assumptions were bad, but without specific concerns to be wary of, I can hardly be proactive. :)
Thanks for the feedback, this is very interesting to know. So the fork is not a smooth continuation but rather quite disruptive. 
I think this title and description are extremely misleading. The title implies that BoltDB has changed names. It has not. The description implies that unfixed bugs are being left to rot in BoltDB. That is also not true. What is true is that BoltDB is not getting new features. BoltDB is a complete project. It's stable and well-tested. The lack of new features is a good thing, similar to the lack of new features in Go. It means your stuff won't break because someone wanted a new shiny. Yes, if there are new features that you want, go check out bbolt. If you want what BoltDB provides in a battle-tested DB, use BoltDB. 
For what it's worth, my proposal is roughly sum types plus generics and no ownership model (because Go has a GC, which is less a burden on the developer in most cases). With generics and sum types, you can trivially build an option type.
^^^ Creator of BoltDB in case any didn't know :)
&gt; The title implies that BoltDB has changed names. I did not want to imply that, apologies if this impression arises. The title should indicate a handover from `boltdb/bolt` to `coreos/bbolt`, which was how I interpreted the announcement. Unfortunately, as you all know, Reddit won't let me change the title. &gt; The description implies that unfixed bugs are being left to rot in BoltDB. This is indeed what I understand from the announcement. Plus, the `bbolt` readme calls `boltdb/bolt` "moribund", which further added to my impression that even bug fixes will stop. Thanks for clarifying that this is not the case. EDIT: Updated the original post accordingly. EDIT2: Added more clarification. EDIT3: Typo.
That's a good point! I'm still pretty new to Go, and I had completely forgotten that receiving from a channel blocks! I was so busy looking for a "Promise.all()" equivalent in Go that I didn't even question if I needed one at all. Thanks!
I believe the update is still incorrect regarding backwards compatibility. From https://github.com/coreos/bbolt readme: &gt; and features not found in Bolt **while preserving backwards compatibility with the Bolt API**.
Best of luck to you. Another thing you might want to look at carefully, if you haven't already, is Scala, and how it interacts with Java. One of the problems you'll have with trying to wrap FP around Go is that if you want to interact with the underlying Go libraries, they aren't FP and that will leak out in a lot of ways. I know the Haskell way of doing it, but that is, in a weird sort of way, a really easy way. Trying to deeply weave it into a language I don't have much experience with. (Also consider that the general Haskell community consensus on Scala is that it is "too complex", so, you know, bear that in mind as you study it and don't take too many ideas from it at once. :) ) Like I said, if you keep going down this path and mutating the language one step at a time, you would eventually end up with something differentiated enough, but it's a long road.
Reliable might be debatable... There are a number of caches out there that don't deal well with HTTP1.1 ranged requests, and can then cache and serve corrupt data. Without hash checking and/or HTTPS terminated somewhere you know handles it correctly, I wouldn't be super confident.
`viper.WatchConfig()` is essentially [broken](https://github.com/spf13/viper/issues/174)
I'm not the maintainer, but I looked at the history, and some changes have gone in semi-recently, so I assume it's not entirely unmaintained. I would think that bugfixes would still be considered, but that's not up to me.
OK, so RPC is effectively "magic function calls that work across networks". That's what it stands for - Remote Procedure Calls. This is different than REST which is basically "map URLs to resource types, and HTTP methods to CRUD operations". REST traditionally only functions on resources... "Create this resource" "delete this resource". Which is all fine and good until you want to do something that's not just CRUD... like "transfer $500 from account 1 to account 2". Now what do you do? You could easily make a URL that lets you do that, but it's pretty ugly, and goes against the REST ethos. Some people will say you can make a "Transaction" objects that debits from one account and adds to another... but then you're getting into ugly "let's make objects for things that aren't actually objects". What you want is function calls. Like Transfer(acct1 string, acct2 string, money int) RPC lets you do that. RPC is defined as just functions. The functions take values that get serialized to some wire format (JSON GOB protobuf, whatever), and sent over the wire to the server, which deserializes them, runs the function, and serializes a return value. This is honestly how a lot of people use REST anyway, it just cuts out the middle man of poor mapping of URLs and HTTP methods to things that go beyond that scope. The main drawback of RPC, and the main draw of REST, is that with REST you have URLs you can hit with a browser for easy testing. RPC... not so much. You need a real client programmed in some language. Depending on your use cases, one or the other might be better... though in my opinion, REST has run its course, and should basically never be used anymore. No one has a pure CRUD website/server, so don't use a pure CRUD API technology like REST.
JSON RPC is a much easier learning curve, I'd recommend starting there, and there's support for it in the stdlib.
note that the OP mentioned go RPC, not gRPC... different things. 
curious: what changes?
This is what the `bbolt` readme says, but as /u/benbjohnson said in another comment, &gt; CoreOS requested some **substantial changes** to BoltDB that I wasn't willing to support long term. Bolt is also used by a lot of people and I didn't want to push features that would **adversely affect the existing user base.** which is a very clear sign to me that the `bbolt` project may introduce changes that have the potential to break existing BoltDB client software. This does not necessarily mean API changes. The API may stay the same but subtle changes to the behavior beneath may still break functionality that is not covered by the API definitions. 
I know, /u/benbjohnson is... or rather, was the maintainer. Your previous comment sounds quite confident about the continuation of bug fixing, and so I assumed you are involved in the projects somehow. So all we can say right now is that current and new bugs in BoltDB may or may not get fixed, and nobody knows for sure - am I right?
In the last case, the main goroutine is in a race with the two that you spawn to call the say function. The main goroutine ends up finishing before the other two can print their messages. 
[removed]
You're right, my apologies. I am not the maintainer, so I can't say for sure. From looking at commit history, some changes are making it in. I didn't mean to imply that there are no bugs left.
The CNC server of Mirai is build with Go. https://github.com/jgamblin/Mirai-Source-Code/tree/master/mirai/cnc
All the hashicorp stuff : https://github.com/hashicorp
1. the goroutine which you create is printing "world", while the main thread continues to print "hello", 2. the main execution thread is printing "world", and the goroutine never starts, because you're "stuck" in the say function, 3. both goroutines start, but the main execution thread doesn't wait for them to complete, so the program exits with little or no output I use the term "thread" mainly to reference an execution thread. Think of functions when you prefix them with `go` as running in the background. The only way to wait for them to exit is either to set up [channel receivers](https://gobyexample.com/channels) for each of them, or something like `sync.WaitGroup`. If you, or somebody else with a deeper understanding of Go wants to read more about this, I also include a section with more real-world-y examples in my book, [API Foundations in Go](https://leanpub.com/api-foundations). You can also checkout my blog on other various Go-related topics: https://scene-si.org. There's also the Gophers discord if you want some real-time help: https://discord.gg/PxwHvBS
Transactions aren't *hard* if you only need a simple lock on trees. The only thing you need to make transactions simple are atomic writes and reads.
Clickbaity article, I don't know If I should... Edit: yeah, as expected, clickbait title &amp; then off topic to a comparison of goroutines in Go vs. Erlang. Worth a read tho if you're into comparing those two things.
I think that's true of any codebase, to be honest :) But yes, I don't know for sure.
Thank you. Those links look like awesome resources btw.
Yep. API stability does not necessarily mean behavior won't change. By definition, if they're fixing bugs, the behavior will change (though hopefully for the better).
I can't recommend [go by example](https://gobyexample.com) enough. It's a very practical resouce for people who want to learn go. It has short examples, concise explanations, and in case you didn't notice it the first time, there's an icon in the top-right corner of the examples that will take you to the Go-playground, where you can change, edit and run the examples from your browser.
You should totally make a go version of that :D
Omitting struct field names and struct names is detrimental to how much you understand just by reading the code. You could set just `[]Bar { { 0 } }` and you realize that it tells you nothing aside from the enclosing struct. If reading code is important (and sometimes it is), you should definitely consider being more explicit/verbose in such cases. Depending on what you're doing however, there might be no need for it and you can omit just about everything - let's say if you are generating some code from external sources (like rainbow tables or something).
[removed]
The author didn't mention acquire/release object approach, which might help his use case: value, err := map.AcquireKey(k) // only one acquire at the time is possible, wait if already acquired by other goroutine if err != nil { defer value.Close() // release the key-value pair back into map so other blocked goroutines may acquire // use value } Avoid acquiring more than one resource at a time to avoid deadlocks. There are other ways to avoid deadlocks like lock ordering or timeout-retry, but I won't go into details right now. Use RW locks to get good performance for read heavy long lasting locks. Erlang is nice but immutability means lower performance. YMMV
Ha, that's EXACTLY what I did as a workaround! That's funny. :) It leaves ast.Package.Imports empty, though, and, presumably, as the NewPackage doc says, undeclared identifiers unresolved. I was hoping to do it the "right" way, if you know what I mean. Edit: I think there's a Package.Scope that it also leaves nil.
Why did you not simply implement the same interface as the one from github.com/pkg/errors? What we do is wrap github.com/pkg/errors instead of forking it. This has worked incredibly well so far. 
Do you really think nobody thought more optimizations should get added? If not, and you think more optimizations are gonna get added as people have time to do the work, what does the article contribute?
I think the idea that channels are simple until you have to deal with failure is a reasonable one, you can spend quite a lot of time making some pretty simple concurrency patterns robust and cancelable.
This is https://github.com/golang/go/issues/21496 ftr
Desire to convert Go into more faimilar language is understandable. But I find this article useful as a bug report for documentation. Person claiming writing Go for a year still haven't discovered Wiki page https://github.com/golang/go/wiki/MutexOrChannel or talks on the subject Mutexes vs Channels or Go proverbs. There is a line in Effective Go on that: &gt; This approach can be taken too far. Reference counts may be best done by putting a mutex around an integer variable, for instance. But as a high-level approach, using channels to control access makes it easier to write clear, correct programs. But that's probably not enough. That said, it's really sad if the author really were doing Go for a year and nobody pointed him at overusing channels and misunderstanding its use cases.
To implement the same interface, I would have to import pkg/errors. Then it's not really a fork. Also, it prevents me from modifying the StackTrace object that's returned, for example adding new behavior or features. From the perspective of rollbar, it doesn't need a pkg/errors StackTrace(), it just needs something that has a Stack() function that returns the stack trace.
That might or might not be true, but the article does a poor job of making this point. All of the difficulties described are due to use of an unsuitable synchronization primitive. Basically, the article sets out to prove that go channels aren't good for all usecases. Instead of accepting the obvious implication "then don't use it for all usecases, that's what the sync package exists for" (which is also explicitly mentioned in the motivating effective go paragraph), they conclude the pretty far-fetched implication "let's change channels".
Clickbaity title, but the article contains some genuine problems in Go. Don't just downvote because of the title. Read it, it's a good article.
What is "ftr"
Let me try to see If I can be of some help, when I am a newbie who codes in C, Go and Rust. Seriously, we all know Go has some flaws but expecting your Mental model of perfection to fit in Go is an exercise in futile. If you want to fit Erlang model in Go, here is the tip - DON'T. Sharing by communicating is not a Lie, it is a suggestion. It is one of the tools from Go's toolbox. Plenty of people use a Maps and mutexes to avoid channels when performance is of utmost importance. No one forces you to use it, it is a suggestion, the Compiler does not enforce it on you, just like Compiler does not enforce you to always use non-pointers. Choose what is best for you. There are very few bounded data structures which can be used without locks, Go's data structures are no exception. Other languages just give you illusion that you are not using locks, either there is a per processor lock you are not exposed to or an bounded data structure with large enough limits which do not show up when you use your data structure. Context is a hack, I would not use context to control child goroutines when parent goroutine goes AWOL, I would perhaps use a dedicated channel for this sole purpose. On the contrary, perhaps Author would have preferred a Compiler which would enforce you to avoid this. Hey, but that comes at a cost, which is not what Go was designed for. Try Rust and see if you find it a correct fit. I personally like Rust's idea for enforcing directive and guidelines via Compile time errors so that people understand what the right way is and stop fitting this OO or Functional Mental Models in Rust as it is. 
The title is a play on many more titles "* considered harmful". It started in the 60s I think with "GOTO considered harmful". This same author wrote "[RHEL] considered harmful". I think we need to abandon this style of title, since it has been abused so much. The title itself isn't even necessarily the point of the article. It should be something like "Concurrent access to values not ready to Go". If you're into that kind of thing. Either way, comparing Erlang to Go is a bit of a non-starter for me, since Erlang is 30-some years old. It solved an entirely different set of problems, in an entirely different generation of computers, for entirely different reasons than Go was developed to address. Not that we can't learn valuable lessons from Erlang, but it's a little like saying Go isn't as stable as C.
I think the author should craft a bug for Go 2.0 (or comment on an existing one) to add native support for concurrent access of primitive data types. It seems like that would solve this exact problem for a lot of us, would cut down on a large amount of boilerplate we've all had to write, and would generally make life a little bit easier. Having said that, each case is different and there's unlikely to be a single solution that works for us all. So I'd be ready for some pretty heated debate in any such bug report's comment section.
In general, this is a good experience report. Thank you :) I do believe that a better solution to your problems wouldn't be to do a hard-fork though, but instead do what [x/image/draw](https://godoc.org/golang.org/x/image/draw) does. Provide a drop-in wrapper, using type-aliases. That is one of the reasons they exists.
In the case of `[]Bar { { 0 } }` you have a solid point. It is less clear to me that the cost/benefit tradeoff comes out in favor of writing the types down when you've got `[]Bar{ {0}, {4}, {3}, {88}, {23}, {-1}, ...}` etc. Though this mostly bites me only during table-based testing. Some elision is allowed but I find myself wishing for a bit more then. (Also, if I meant to say "cost/benefits clearly favor not having to spell out the type", I would have. I am truly conflicted between the convenience of the read vs. the write here.)
I read it, and then I still downvoted due to title. 
There were other things I wanted to change about pkg/errors. In general, how does one fork a package while still getting optional behavior? From my experience, go has no best practice or solution around the combination of: 1. Package specific types in function signatures. 2. Implicit type conversion for optional behavior. 3. Code forks and reduced package dependency chains.
The question is, how much of those other things could be done *without* doing that breakage? Why is aliasing the types and replacing the functions not an option? It seems non-obvious to me. The [issue you link](https://github.com/pkg/errors/issues/75), to me, seems to be perfectly solvable by the type of wrapper I suggest.
https://talks.golang.org/2012/concurrency.slide https://godoc.org/golang.org/x/sync/errgroup import "golang.org/x/sync/errgroup" ... var u User var b Billing g, ctx := errgroup.WithContext(request.Context()) g.Go(func() error { rows, err := db.QueryContext(ctx, "SELECT foo FROM users WHERE id=?", ...) ... u = ... return nil }) g.Go(func() error { rows, err := db.QueryContext(ctx, "SELECT bar FROM invoices WHERE ...", ...) ... b = ... return nil }) if err := g.Wait(); err != nil { return nil, err } // use u and b like normal 
Aaand the post was removed
Yeah, I'm not saying I agree with it wholeheartedly, just that I think it's constructive to read past some of the bits I disagree with.
Thank you for all the hard work on BoltDB. It is amazing. I work on both etcd and `bbolt`. Here are some of my thoughts on the fork. `bbolt` is the datastore for etcd. The primary goal of etcd project is stability and reliability. So we absolutely want `bbolt` to be as stable as possible. On the other hand, we also hope `bbolt` to be flexible enough to serve different kinds of workload better. That means more configuration knobs and subtle optimizations. The new features/enhancement we added are mostly gated by feature options. The options are not enabled by default until we feel confident about it. With all that, we fully understand that adding features might introduce instabilities and unexpected results. So we will be careful to identify potential problems, and be responsible to fix problems the new features introduce. We want to help build a better BoltDB for more kinds of workloads.
Yes you would need to import the errors library. However, I don't understand why you explicitly want a hard fork instead of a library that builds on top of pkg/errors. You could have a method on your error that returns your better stacktrace with extra features, while simultaneously keep the old behaviour for the original method.
I see what you're saying and it makes sense that I could write a wrapper in another package, but there are other downsides to not being a fork. I didn't fully explore them, but there are other things I want to modify. Many of them use private variables in pkg/errors. I could copy/paste that code, but then I'm a fork without the advantages of easy code merges. And I'm never allowed to modify pgk/errors.StackFrame() since it's an alias. There are also cascading issues, with rollbar requiring an import of pkg/errors even if it strictly doesn't need one. These cause problems with package management libraries: forcing imports that other consumers of the rollbar library don't need, complicating the dependency chain. Seeing how clean of a solution https://github.com/pkg/errors/issues/79 does to resolve all of this at once, for me points to a bigger issues trying to use custom types in function signatures. 
&gt; Do you really think nobody thought more optimizations should get added? I'm sure they did. How is that relevant to the article? Different people can write about the current state of optimizations. It doesn't make that - in any way - whining. &gt; what does the article contribute? It raises awareness. I don't know about you, but I don't sit by the issue tracker refreshing every five minutes to see what new issue is being discussed.
Thanks for the advice. The interop between Gallium and Go is something I'm particularly concerned about. I'm thinking the compiler could have an unsafe-like mechanism for interacting with vanilla Go. I haven't through this through very well yet, however. I'll definitely look to Scala/Java when the time comes.
What problems have you had with developing RESTful services? I'm just curious.
I think the real answer is "it depends". If my database server has 16 CPUs, most of them are sitting idle at any given moment, and I've got a RAID array and heavy RAM caching so there's no major I/O bottleneck, then executing two queries in parallel might be faster than executing them one after the other. If my database server is heavily loaded, then executing two queries in parallel isn't likely to result in any speed increase.
Lol
(And, pedantically, durability and the ability to rollback at least consistency violations.)
Well you can kinda cheat yourself into durability if you can do atomic writes as long as you are guaranteed that they operate serializable, ie if you have the writes A B and C and you crash, you will have them in that order and not writes A and C but not B. Once you have atomic, serialized writes, you can make durability and rollback and transactions on top of that. There isn't terribly that much you need to get ACID.
That may depend on what you see as a quirk, but maybe http://havelang.org/. It's not stable and I haven't used it though.
&gt; master meta data would make random access very hard to implement. I disagree. A master header with a chunk/package size value makes random access much more performant. Currently, to seek to byte X this library must read the header of every package between byte 0 and byte X. Switching to a global header that sets the package size allows the readers/writers to seek to the header for the start of the package that holds byte X. This would allow support for the io.ReaderAt and io.WriterAt interfaces, which are the io interfaces for random read/write access. Adding a padding field to the package/chunk header would allow for variable sized package data within the stream of packages/chunks. Also, I agree that key derivation should be moved into this library. Every example i've seen has the consumer use hkdf to generate the encryption key for a package based on a master key and package sequence. Using hkdf is complicated and easy to screw up. There are big wins in keeping the api for users as simple as possible. A global stream header also allows the kdf operations to be moved into this library. It could even support something like https://github.com/codahale/sskg so that key derivation also supports seek. Finally, the docs could do a better job at explaining that the 8 byte nonce value is a suffix, and that the real nonce is the 4 byte seq number concated to the 8 byte value. I had to look at the code to figure out why the nonce value in headers was only 8 bytes.
I don't understand this sort of defensiveness. This post isn't attacking Go, it's simply saying "Go isn't optimizing in this case; Java demonstrates that it's possible to get a 2X speedup". Even if it *were* attacking Go, responding defensively is silly--who cares what someone else thinks about a PL you like?
Each additional connection just adds overhead eating your bandwidth and wasting router/NIC resources. "Download managers" were popular in the end of 90s/beginning of 2000s for two reasons: 1. connections were unreliable, and they implemented resumable downloads before browsers did, and 2. servers severely limited download speed per connection, so multiple connections sped things up. Both of these reasons are not relevant today. Browsers got smarter and services mostly use cloud/cdn to pump data as fast as clients can consume it.
There are some things that are quite difficult to express - I had a system that was an interface, it had to do a fast, weak checksum lookup, and if there was a weak match, then do a strong checksum match. The problem was that it was very difficult to express that there was a type that should be returned from the weak checksum, which should be passed to the strong checksum lookup as an optimization. You can see it here: https://github.com/Redundancy/go-sync/blob/8931874cad5cacc627b94fcbcb182460e174aeef/comparer/comparer.go#L43 the empty interface was the only thing I could really come up with that allowed me to output something that I expected to be passed back in, where the user wasn't expected to interact with it. I used it to hold a list of potential matches from the weak test, to give back to the strong test. It's fairly easy to define an interface for something when the parameter and return types are basic types, but far more difficult if they are package types etc.
Could you please provide a example which you already have tried and version of Go - would be appreciated.
havelang is abandoned
Random comments: 1. Don't pass bi-directional channels to functions. This almost never makes sense, and here you only want the function to put. 2. Using the same channel means you'll get a "random" order of get/put operations. 3. Using an unbuffered channel means all the calls will block, although it's probably not obvious here it might be in real code. 4. In real code you probably want to select between get/timeout or put/timeout. 5. In real code you'll often want to close the c when all of the puts are done.
I followed this [article](https://dominik.honnef.co/posts/2015/06/go-musl/) to learn how to do it. In the end I created a Dockerfile that used the golang base image, installed musl, then a build command with: `CC=/usr/local/musl/bin/musl-gcc GOOS=linux go build --ldflags '-linkmode external -extldflags "-static"' github.com/company/project`
Sorry, I am on version 1.9. I've used "CGO_ENABLED=0 GOOS=linux go build -a -ldflags '-extldflags "-static"' " as well as the same flags with cgo.
yup. i also use erlang at my day job. its a nice language but the performance...oh boy
`os.Args[0]` is still "wrong". This matters sometimes when you want to get some file relative to the running script. Another issue is that you generally want all your packages to be valid; that is, having two `script1.go` and `script2.go` files next to each other which both have a `main()` will confuse some tools, even if they're not being directly referenced. I believe `gorename` will break for example. You can fix this by making subdirs, but it's kinda cumbersome if you have a whole bunch of small scripts IMHO. I love Go, but in the end I found using it as a "scripting language" to be tedious and cumbersome. Besides, scripts are usually short so the advantages of dynamic programming languages such as Python or Ruby are stronger while the drawbacks are smaller. It's a matter of "right tool for the job", I think.
I recognize that referenced issue :). I care somewhat less about being able to run a go file directly... But the fact that go run munges the output and error code really grinds my gears. Someday I may fork go run to fix those two specific issues.... But today's not that day. As for python or whatever being better.. Maybe if you're really comfortable in those languages, but personally, I find the reliability of go's error handling and the readability of it's code makes it an excellent "scripting" language.
This illustrates the problem with many interfaces: if your interface references any type in it's own package, any implementor must import the package to implement it. If you want a truly universal interface, it can only reference built in types and types from the stdlib. This was touched on in the article, though I didn't xactly understand the problem with that implementation (other than the fact that pkg/errors would have to change).
I'm not sure why you read my post as defensive, it was meant as explanatory, "this is not the whole picture". Here, let me walk you through it point by point: 1. If you're reading the article, see the author's benchmark in which he got a ~2x faster result for Java, please don't jump to conclusions, that doesn't generalize to mean Java is ~2x faster than Go. (Java might be 100x faster in general, too; it's just not deducible from a single microbenchmark.) 2. Article says Go should have more optimizations. Core devs agree. It takes actual humans actual effort, and progress is being made. 3. The trade-offs are significantly more complicated than "inlining = good".
Likely a common property of transpilers to go. 
I don't see the article being in any way newsworthy or interesting, and have downvoted accordingly. I'd rather see /r/golang full of articles like https://www.reddit.com/r/golang/comments/6nsmbh/strace_in_60_lines_of_go_liz_rice_medium/ or https://www.reddit.com/r/golang/comments/6yjap6/playing_with_kernel_tls_in_linux_413_and_go/ or https://www.reddit.com/r/golang/comments/60dik1/a_utility_for_running_exhaustiveness_checks_on/
I usually use parser.ParseDir like this: https://play.golang.org/p/nbqLAolgbT Though it does not run on the playground, complaining that $GOPATH's not set. 
For what it's worth, Go core devs are talking about ways to inline only part of a function, to get the same benefit automatically. Of course, it's not exactly simple..
&gt; having two script1.go and script2.go files next to each other which both have a main() will confuse some tools A lot of that can be worked around with `// +build ignore`.
Here's a very alternative take on a similar idea: https://github.com/tv42/demand It shares some of the pros, like getting going faster on a new machine, but doesn't pretend Go is a scripting language, or fight the build system.
If you're proposing a new language, you might benefit from 1) omitting details of your plan for its initial implementation (or pushing them to an appendix) and 2) talking to /r/programming.