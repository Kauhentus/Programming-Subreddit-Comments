really PEBKAC here :) very good point, put it all in a separate "api" package for reuse. maybe can symlink in the generated `pb.go`'s for the same kind of reusability
What is printf?
&gt;abused far too much You can write C++ in any language, it's not like avoiding useful features which "can" be abused will automagically make everyone better programmers...
Sure, that brings Kernighan and his ideas to Go - but what brought Go to Kernighan? Why is he an expert as he seems to be? Is he a heavy user? He is not at Google and wasn't mentioned as someone who developed Go... So was he following along from the sidelines and then decided to explain it all?
&gt; It's like pro chefs arguing that you should only have 1 knife and it should be dull. Helps not cut yourself that way... No professional chef would argue for a dull knife, because of how difficult/dangerous it is to use a dull knife compared to a sharp one.
You're more likely to cut yourself with a dull knife than with a sharp knife. With a dull knife, more force is required, and it's more likely to slip. A pro chef would never say that. However, that's a bit of a tangent.
Take a look at the comments in `sync.WaitGroup`'s structure. 
Oh, maybe they are. Now that I reread it, I def could have misunderstood 
Well you clearly don't know what you're talking about. No use continuing this discussion then. Have a nice day
Yes, the term he used is 'bloat without distinction'. Or something like that. Which is why this whole Go 2 thing surprises me. Why not just call it something different? Could be a name that is somewhat related, and would save the whole python 2/3 thing.
You make it sound like it's some heroic feat to implement a generics system
Pretty much every functional language has great concurrency support. Clojure has channels similar to go for example...
I imagine it is a heroic feat to implement a generics system that doesn't complicate the language and tooling. It's about trade offs and they don't seem to think the trade offs are worth it currently. 
You make it sound like you never read http://research.swtch.com/generic
I understand the challenges. My point is that it's still not *that* hard (multiple languages have done it before, there's a lot of research on the subject) even though it's not trivial (especially from a Go type system point of view)
If you can't accept being in the same company as a person who disagrees with you, well… good luck finding a new job.
I get really, really tired of "don't like generics/inheritance/operator overloading? Don't use it!" If it's in the language, I'm going to inherit a code base full of it and not be allowed to remove it to simplify the code. Source: 8 years as a programmer in languages like C++ and Java.
I don't think anybody said that it makes everyone a better programmer. I certainly didn't. It is my opinion that the number of use cases where operator overloading causes more confusion and eats up more developer time would be greater than the number of cases where it clarifies and reduces dev time. As a result, I wouldn't advocate for adding it. This opinion is based on my experience in ruby. I also believe there are much bigger issues in worth addressing in Go.
... just use commas. fmt.Println is variadic and accepts interface{} values. fmt.Println("You are", user.String(), "and this is an example.")
Give me a strictly typed system for Map/Filter/Reduce and I'll be happy... although you'll need generics for that.
https://rkrishnan.org/posts/2016-03-07-how-is-gopl-typeset.html
[removed]
If you're using a lot of interface{}, you're probably wiring code too abstractly in Go.
I hope he is.
I'm really sad I only get to upvote you once.
&gt; Dear white men who thinks they are marginalized, my single eye lash is more marginalized in tech than all of you. Seems Google has taken position in favor of free speech. I hope she stick to her position and leave.
https://blog.golang.org/errors-are-values
I'm with you. I may be the minority; however, I love Go just the way it is. I find it highly enjoyable to code with, and am blown away by the standard library|packages and the community support it has. I know there's always going to be growth; however, I came from the other languages because I hated the other languages (I'm looking at you in particular, .NET). Now I see all these Microsoft 'enthusiast' jumpin' on the Go bandwagon, and they're voicing their support to add all these things to the language. Leave it alone! You've guys got your .NET core (15 years too late) and other toys to play with.
Dude, seriously? Joke or not, this is the kind of stuff we don't need in this subreddit.
This isn't programming. I'd prefer this sub to remain focused on programming, rather than drama.
Use nginx proxy_pass, https://www.nginx.com/resources/admin-guide/reverse-proxy/ So you could make the go process for turalasgar.pro listen on port 8000, and engossip.com listen on port 8001, nginx listens on port 80/443. In the nginx site configurations you define two server blocks, one for each site and in the appropriate location block you proxy_pass to the right go process, say proxy_pass http://localhost:8000; Make sure the go processes communications are bound to the local interface, so that they cannot be accessed directly from the outside.
[removed]
Thanks, this makes total sense.
Thank you very much for your attention. But I am new on nginx. I don't know exactly how my configuration file will be. I know what I will do on Go side. But is it possible to write a configuration file here? 
The stdlib uses interface{} quite a bit. Some features (like generics) would actually lead to a slimmer, simpler language with more orthogonality and fewer special cases, since today's exceptions like slice and map (and append etc) would be implementable.
[print format](https://en.wikipedia.org/wiki/Printf_format_string)
**Printf format string** Printf format string (of which "printf" stands for "print formatted") refers to a control parameter used by a class of functions in the string-processing libraries of various programming languages. The format string is written in a simple template language, and specifies a method for rendering an arbitrary number of varied data type parameters into a string. This string is then by default printed on the standard output stream, but variants exist that perform other tasks with the result, such as returning it as the value of the function. Characters in the format string are usually copied literally into the function's output, as is usual for templates, with the other parameters being rendered into the resulting text in place of certain placeholders – points marked by format specifiers, which are typically introduced by a % character, though syntax varies. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
Anyone is free to post anything. She is a prolific member in the Go community, who also helps others in many other ways. So instead of attacking her maybe you should try to understand her?
I for one *really* appreciate Go attempting to be a very simple language, like a modernized early C. I haven't seen a concrete proposal that would inflict less than C++ levels of horrors. Whining doesn't make those concrete proposals appear, and the Go core devs have stated they don't currently see a way to make that happen either.
Meet us half way. Watch the the documentary The Red Pill directed by Cassie Jaye. Try to understand us. 
If it was called something else, it wouldn't work as a flytrap for all the drive-by generic pony requests.
Just curious, and I know this is tangential, but why do you "only need nginx"? One of the points of Caddy is to be easier to configure.
What is her message? What does she want? Her twitter history to someone unfamiliar with her cause seems like she's angry and spiteful towards white men. No one is attacking her as far as I see, but she is constantly attacking the demographic I fall into from a public outlet; least that is how it appears from where I am standing. She may have a fair position with a proposed solution that is reasonable, but there is nothing to hint at either for someone who isn't deeply familiar with her cause, whatever it may be.
&gt; the number of use cases where operator overloading causes more confusion and eats up more developer time would be greater than the number of cases where it clarifies and reduces dev time Well, yes, if you try to use it for everything (like the `dataManager += data.record()` example above) it can get a bit out of hand. But it has a few niches where it is _very_ useful - custom math types, nice-looking query abstractions, matrix libraries, etc. It can be abused, yes. But the people who are abusing it will write bad code anyway, and it only helps the people who are benifiting from it. See, I'm a rust person - I prefer things like, for example, giving warnings about unused variables instead of erroring out, and putting the option to use `unsafe` in the hands of the programmer. &gt; much bigger issues worth addressing Like lack of generics.
[This](https://www.youtube.com/watch?v=de2Hsvxaf8M) and [this](https://www.youtube.com/watch?v=Sg4U4r_AgJU) might have some hints in there. Maybe you could ask computerphile to ask the question directly?
This sort of drama apparently brings out people to come to this subreddit trying to spread their political beliefs. We probably shouldn't have this sort of content here, just so we don't get drastically off topic from the goal of this community.
Just because I want to learn how it is done without using ready-made things. Maybe after I learn how it is done with it, I will be using Caddy who knows.
Hasn't rsc taken over?
Haskell.
For what it's worth, node has even easier concurrency than Go.
No, not that hard!
Elixir is pretty nice, but it's way behind go in popularity. There is a whole range of applications that people are using Go for that would be better suited to Elixir (although vice-versa too, I'm sure). Although, lack of static typing is kinda of a bummer...but hey you can get something out of dialyzer. Oh, I guess deploying Elixir/Erlang is meh too, but that's something you only have to figure out once and then the process is repeatable.
Fair enough. Nginx is a good skill to have.
There might be a more detailed resource than this random tutorial (but I just saw it the other day): https://www.digitalocean.com/community/tutorials/how-to-host-ghost-with-nginx-on-digitalocean ctrl-f "proxy_pass" (The above tutorial is about a node.js app, but the concepts are the same).
Go has a pretty good standard library. Node does not.
I'm not attacking anyone mate, I just don't want drama in a programming subreddit.
Brian likes to try new things and likes to write books.
&gt; She may have a fair position with a proposed solution that is reasonable, but there is nothing to hint at either for someone who isn't deeply familiar with her cause, whatever it may be. Turns out, Twitter is a terrible medium for anything more complicated than a "your mom" joke.
I encountered a similar issue when iterating over the range of `time.Tick()` in a for loop, and then exiting the function on some exit condition. I didn't think about the fact that a goroutine was still trying to produce into the ticker channel. I solved it by creating a ticker using `time.NewTicker()` and then closing the ticker before exiting the function. This was a very interesting blog post and also a general warning to not ignore return values as a matter of practice :)
One of the issues here is that you often have to read others' code. Case in point, try to read any scala codebase and be ready to have your eyes bleed trying to figure out where an implicit was resolved, or how this overloaded operator works, and so on. That being said, I'd really love to see a nice implementation of generics in golang that still maintained the simplicity of the language. I'm not sure if it's possible, though.
+1 for ternary operators. edit: lol at the downvotes
Subsequently following this new discovery, we may safely conclude that she should not attempt to use it as a medium to convey topics more complicated than a your mom joke.
As an alternative I propose a drinking game: Drink a shot every time someone mentions The Red Pill. After three threads, everyone in the subreddit will have died of acute alcohol poisoning.
i guess if you don't mind framing your flow control around callbacks. I personally do, and prefer to think about things from a "thread" perspective which go does well. 
Watch the the documentary The Red Pill directed by Cassie Jaye. Don't be a bigot, listen to both sides of the issue. 
Hey if you still need help to setup nginx let me know I will be happy to help you Im running my https://golang.zone at DO(digitalocean) with a nginx reverse proxy in front of my go app 👍 
&gt; think about specifying what format tag I've yet to be disappointed with the output of `%v` as a default :)
Look, I've been to a subreddit of a similar name and I know I don't agree with anything you agree with with respect to that topic. I'm not inclined to watch it and I'd recommend if you would like other people to watch it, you tell them as such somewhere dedicated to that topic or a similar topic, not on this subreddit.
It at least seems appropriate that the generics are the wings.
&gt; We can say there's virtue in performing the for loop ourselves every time we want to remove an element from a collection Where n is the element index a = append(a[:n], a[n+1:]...)
It is very good that YouTubers start talking about Go. It will help the language grow even more.
&gt; Gaps in Go tooling made investigating difficult. Debugging this issue was hampered by a notable gap in Go tooling that we would not have faced were our code running on the JVM. All signs pointed to this issue being a fairly classic memory leak but Go does not really have tooling to dump and analyze heaps. While the pprof tool can be useful to find some memory issues, and did give some useful hints in this case, it is limited: it gives statistics on where objects are allocated but not what is retaining them. The article was a good walk through but I don't agree with that quote. I think you would have had a different experience if you didn't limit yourself to only profiling data. Profiling is great for a holistic view of your application and to pin areas that may be causing performance issues or leaks. But for drilling down into something like a memory leak you will want to use tracing as well. The trace files will contain a list of events, in this case you would have seen the goroutines for cancellation used by context firing as [EvGoCreate](https://github.com/cstockton/go-trace/blob/master/event/event.go#L35) as well as a Start when it started the select, but would have noticed they were not closed with [EvGoEnd](https://github.com/cstockton/go-trace/blob/master/event/event.go#L37). So you would see a ton of active goroutines- the great thing here is that the EvGoCreate event contains a stack trace which would have shown you the exact location of each leak. In addition it also shows the GC start and stop events, which you can correlate to profiling data or EvHeapAlloc to take a best guess on when your leaky allocs happen and find events that seem relevant to them. Just my opinion, but I'm biased as I think runtime tracing is invaluable already, and still has a huge degree of untapped potential. Considering you can conditionally turn it off or on while your program runs it could make for a great unicorn-in-production catcher, once you think the unicorn is showing itself.. enbale tracing until it's gone! No sifting gigabytes of traffic or trying to reproduce locally with no success. Just food for thought- next time your struggling to find a issue keep trace in mind!
A good generics system is better than 10 different codegen tools to write all the stuff you shouldn't need to write in the first place.
More features wouldn't necessarily be a bad thing. The problem is that a lot of people feel that they don't need generics for various reasons (don't realize that they already use the builtin 'generic' types, write tiny applications, duplicate code where needed, are perfectly fine with dealing with the issue at runtime, etc). And since they don't need it, it's obviously a useless feature and should never be added.
If you have been to that sub then you should really watch the documentary. That sub is vile. You really need a fresh look at the mens rights movement. That sub and this film are two sides of the same coin. Just watch the film. The thing is that I am pretty sure all the hate directed at my comments are because of a misunderstanding about the usage of the term "The Red Pill". 
lol have you read the standard library?
Please take this elsewhere
[removed]
[removed]
Implementing generics in Go is not so simple especially when it requires re-working the standard library to take advantage of generics (and it would be very unprofessional of the core devs to not do so).
They run in a VM
If you "need" generics you're just a bad programmer. 
Again, I'm not saying it's simple. I'm saying it's not nearly as complex as some people make it out to be. I mean, of course it'll involve work just like any major language change, but my (and many others') opinion is that the amount of coder time it would save would be worth the amount of work they'd have to put in (type system, compiler, standard library etc.) In any case, it's likely most parts of the standard libraries wouldn't need to be changed, and a lot of it could likely be done automatically with proper tooling; old functionality would still stay the same for backwards compatibility anyhow
Reminds me I have a nginx server I haven't been able to get serving "real" apps beyond static (503 errors) I either need help, or I need to read more closely lol.
I ask these questions genuinely: 1. What projects have you shipped with Go? 2. How many kLOC were they? 3. How many developers worked on the project with you?
[removed]
This only speaks to part of your comment, but there was a proposal to make `int` arbitrary precision.
It bloats the language with added syntax that literally adds zero functionality to the language. Shorter is not better.
ternaries are too easy to screw up and don't actually add any functionality to the language. One company I was at had a hole in authorization that would let you act as admin because of a messed up ternary operator. The problem is that they start off simple but then they evolve into a tangled mass of craziness... all to avoid using the standard old if/else.
Go version with basically no allocations: https://github.com/sirkon/snippets/blob/master/main.go It finishes in 0.6 second on my machine (core i5 7600). This C++ version https://github.com/sirkon/snippets/blob/master/main.cpp is twice as fast: 0.3s The algorithm is practically the same. I used map[string]*int instead of map[string]int in Go version to avoid allocations: map lookup someMap[string(someByteSlice)] will not create a string (compiler level optimization). On the other hand someMap[string(someByteSlice)] += value will allocate a string. So, it is cheaper to take value pointer via lookup and increase it if found and you only need to allocate on new map node creation. This gave about ×2 acceleration compared to naive version. Still, C++ with its fine control on allocations and state of the art optimizer put itself far ahead of Go. But Go is actually got a lot better in last two releases. Go 1.6 code was about 3-4 times slower. Go 1.8 accelerates it in two times and now it is possible to achieve nearly ½ speed of pure C++ — it is nearly sufficient for real world tasks: in reality we didn't parse files paged into RAM as it happens with the testing file. In real world practice we take compressed data (gzip, zstd, lz4, whatever), unpack it and feed to parsing method. Decompressing is not easy, so thus we actually decompress rather than parse most of the time. Next, nowdays data pre-aggregation makes no sense: there are great tools like Yandex' Clickhouse which compress data so eficiently and then work with it so fast you better just to feed it and do all the work looking for the key with maximal sum via Clickhouse SELECT argMax(key, valsum), max(valsum) FROM ( SELECT key, sum(val) AS valsum FROM googe_tsv GROUP BY key ); Clickhouse can handle millions inserts per second, still packing data is not exactly an easy task — it is actually harder than unpacking, so thus we actually stuck with data insertion, it is our main bottleneck.
I know this is a bit old, but removing /usr/local/go before installing the new version fixed this for me, thank you.
Okay? 
Elixer is definitely very good lol. My point was that people want easy concurrency.
This is obviously a contrived example. How are you going to do this in your example? https://play.golang.org/p/BRaXpcl1g9 package main import ( "fmt" ) type Foo struct { } type Bar struct { } type Item interface { } type Action interface { execute() } func (self *Foo) execute() { fmt.Println("Hello") } func executeIfAction(i Item) { if action, ok := i.(Action); ok { action.execute() } } func main() { executeIfAction(Foo{}) executeIfAction(&amp;Foo{}) // &lt;--- Notice only this executes executeIfAction(&amp;Bar{}) } Not so simple as function pointers is it? Sure, you can create an `item` method on Foo and Bar that returns a function pointer if it implements action... but really, you're just manually implementing the same mechanic as interfaces provide at that point. So... if you prefer to manually do that, go for it; but that's why interfaces are useful.
We could also avoid crap like this: var foo int if condition { foo = 1 } else { foo = 2 } And instead have something simpler and less error-prone such as: foo := 1 if condition else 2 Ultimately I think you have to rely on programmers to be reasonable. There's a reason why code review is standard practice within the industry, and it should be able to catch cases abuse/misuse. It's possible to write bad code in any language, and I don't feel like we should a language's toolbox because it's possible for bad programmers to misuse it.
So how are you finding that element index?
The more I think about it the more my opinion has changed. While I was using Go, I could think of all kinds of things that other languages had that I would find useful. But really, if I think about the things I really like about Go (clarity, a solid and contemporary stdlib, gofmt, compiled, great concurrency, etc), there's no reason other languages couldn't make those things happen. All the things I want in Go would just make it a different language, so really, I think I just need to be shopping for a different language.
Nobody "needed" anything beyond assembly. Simplicity, safety, and abstraction are usually good things to move towards though. If I'm a bad programmer for wanting that's then so be it.
you are being down-voted but I wonder sometimes if it is true. Are all these complainers about generics actually full time Go developers? My own anecdotal frame of reference has proven that a lot of the time the answer is no. It's just a couple of prominent community members, followed by a heck of a lot of bikeshedders, and salty Java or C# developers that feel the need to be validated by the "intellectual superiority" of their respective languages despite the fact that they won't admit to themselves 90% of their work is writing glorified business specific CRUD APIs that has no need for generics, and the only time they ever cross generics is when a library they use makes them use it. The rest of us are silently going off and doing our thing. (incoming "just because you don't need generics comment, &lt;rationale&gt;" comment)
[go 2 considered harmful](http://www.u.arizona.edu/~rubinson/copyright_violations/Go_To_Considered_Harmful.html)?
 foo := 2 if condition { foo = 1 } Line returns are not the enemy. This is way simpler to read, much less likely to get mangled if you need to modify it later, much easier to see what the default value is, and works better with line by line diffs.
lest we forget, swift 4 is out soon...
Also check out his interview on the software engineering daily podcast, I believe he talks about how he got involved a bit if memory serves me.
1) All the professional projects are pieces of a proprietary system. (For work) 2) Overall, maybe 8k lines after tests? I don't care enough to get on the VPN to check it out. 3) I believe we are at about 40 engineers in dev. I hope this information helps you?
Isn't Go full of all kinds of features from other language? * package and import from many languages, most from python. * interface/reflection from Java. * slice from python * map from many other languages. * function/closure from JavaScript * pointer from C * struct from C * type deduce from C++ * multiple returns from many other languages * garbage collection from many other languages. The problem of many other languages isn't to borrow features, it is just to borrow anything, or borrow something without carefully thinking about it. The same is for generic (and other possible future new Go features), it is a pain without it, and it will also be a pain if Go supports it without carefully designing it. 
Was he involved with early design discussions? Or did you just let him know 2 years in, "look what we made"? What was his initial reaction to the language?
Keep in mind that nothing about programming languages is strictly necessary. Anything other than straight machine code is simply a convenience for us humans, so every feature of every language is, on some level, just syntactic sugar. This doesn't answer your question, but hopefully it provides some context and perspective to someone.
Thanks - do you have a link?
He talks a bit about Go and GOPL in at the start of [this video](https://www.youtube.com/watch?v=6v6wdK2EbIQ).
And that's what happened to C++ and C# Edit: I mean, both languages got pretty complex.
&gt; Not so simple as function pointers is it? I didn't say that simply passing funcion pointers would solve the general case. Your example is still simple enough that you can use function pointers, though. &gt; Sure, you can create an item method on Foo and Bar that returns a function pointer if it implements action... but really, you're just manually implementing the same mechanic as interfaces provide at that point. Yes, my point isn't that you should, it's that it isn't extremely difficult, and that someone interested in how it works might benefit from an explanation that doesn't allude to the extreme difficulty of the use case it solves. Interfaces are in essence structs of a receiver pointer, a bunch of function pointers and a conrete type enum. It's a common pattern in C.
C# isn't a bad language. C++ has its warts for sure and the amount of baggage it has is ridiculous I agree. But generics aren't esoteric. They're standard and pragmatic.
Agreed.
I didn't intend to imply either was bad. Both, however, are complex. I like Go's simplicity and I hope it stays that way.
I think how this relates to C is basically irrelevant, but I see your point. 'extreme difficulty' is perhaps an over exaggeration, but I think you're being pedantic for the sake of it. Interfaces make code simpler. ...but yes, indeed, you don't have to use them. As with basically all other abstractions, you can always just roll your own version of the same thing if you don't want to use the commonly used version for... whatever reason. (heck, look at the crazy stuff you can do in rust faking object pointers to create a linked list using an array of index ints to avoid the borrow checker problems. /shrug; you're just trading complexity that other people have abstracted for complexity that you're writing by hand, yourself)
&gt; I for one really appreciate Go attempting to be a very simple language, like a modernized early C. C is simple because it's a thin abstraction over the machine. Go is... not that. At all. There's no real reason to pretend it is except for a fetishization of "simplicity". A language with a modern typesystem - including generics - and Go 1's green threads and ad-hoc interfaces would be excellent. Go 2 could be that.
Changing go from what it is now will bring it closer to all the other popular languages and it will be more apperant that it is not a good language in terms of features. There is a reason why languages start to be more similar in features and that is because they adopt features that the users love and use. Go doesn't have those features because it wants to be "simple". The simplicity is also limiting for people who like to have ex: proper generics or exception handling. I have been programming in a lot of languages and I did give Go a chance but since it is missing some of the key features I could not continue. Go has been popularised in the docker community thanks to the Docker project but other than that the adoption isn't that impressive compared to ex Rust. My prediction is that Go will either get those language features but then die because it will be like Java or C# but worse. The other alternative is that it stays like it is and be a niche language that most programmers will avoid because of the lacking features. *Edit:* _I just realized i was replying in the golang subreddit_ 
an FYI "The go vet tool checks that CancelFuncs are used on all control-flow paths."
Most of these are never going to happen in Go, because it would go against the design philosophy of Go. Some _might_ happen, but probably should not. People who are prepared to sacrifice clarity and readability in the name of DRY have no business writing maintainable software. Solutions that allow a developer to be "very clever" when writing software means the rest of us are dumb-founded when maintaining it a year or three later. Generics, Mixins and Lambdas can all fall into this class. Polymorphism would too, but Go actually has this. We just call them interfaces: they abstract concrete behaviour on concrete types in a way that allows data (and specifically its type) to expose behaviour. The way Go does polymorphism through the interface type is probably better than any other implementation I've seen - others should borrow it from Go. We should not borrow other implementations from other languages. try/catch is so philosophically removed from Go's principles around integrity and correctness, its introduction would literally ruin much of the point of the language. The rest I can take or leave, but would probably leave. In all seriousness, we need to ask: why do we need a Go 2?
&gt; I think how this relates to C is basically irrelevant, but I see your point. Taking the feature OP is confused about and implementing it in a language that doesn't feature such high level abstractions can be a more useful way of explaining it than conceding that the problem it solves is hard. &gt; 'extreme difficulty' is perhaps an over exaggeration, but I think you're being pedantic for the sake of it. I can't account for your suspicions, and I'm frankly not interested. Can we please stay on topic? &gt; Interfaces make code simpler. Agreed, and I've never implied otherwise. &gt; ...but yes, indeed, you don't have to use them. As with basically all other abstractions, you can always just roll your own version of the same thing if you don't want to use the commonly used version for... whatever reason. In this case, the reason is discussion. OP is asking us to "suppose interfaces were not in the language" for the sake of discussing the feature, what problems it solves and how.
&gt; implementing it in a language that doesn't feature such high level abstractions can be a more useful way of explaining it than conceding that the problem it solves is hard. Since you can implement it just as well in go to demonstrate the point, that seems, as I said, entirely irrelevant; you're just introducing more complexity into the topic by bring a whole new language into it. Who cares if you can implement it in C? &gt; Can we please stay on topic? We'll just have to disagree.
The only thing I want from golang is more runtime safety. I love interfaces. Generics are overrated.
"just because you don't need generics comment, ..." but seriously, i often wonder about something similar. are all those people saying that the language doesn't need generics full time Go developers? Or are they just writing simple http servers all day, and that has caused them to believe that everything is all and well with the world? The thing about generics is, it doesn't matter whether you or I need it. The compiler and the standard library do. There's currently a lot of special magic being done on behalf of the few containers and builtin functions being provided by the compiler, and the list of std packages that would benefit immensely is growing with each release. The word 'simplicity' that every opponent of extending the language is throwing around would actually apply here, since it would make the compiler quite a bit simpler. However, since quite a few Go developers have most like immigrated from dynamic languages, and haven't had any exposure to strongly typed ones, such a point would be lost. Go is currently very well suited for writing network apps and pushing bytes around. But that's mostly the extent of it. If it doesn't grow, it will likely die out eventually, because other languages are also good at these things, but they are also quite capable of being general-purpose. And once you start writing big applications, the later will almost always win, since they allow you to do other things much easier than Go currently does.
&gt;is it just me Probably not
&gt; Since you can implement it just as well in go, that seems, as I said, entirely irrelevant; you're just introducing more complexity into the topic by bring a whole new language into it. I think that C is great for demonstrating these concepts, because its design is rather simple and ubiquitous. Anyone with half a CS degree will have used C at some point, while a self identified go beginner may not be entirely familiar with the language. That said, you can do it in Go almost like you would in C by using `unsafe`. Here's a bit more complex of an example (two method interface): package main import ( "fmt" "unsafe" ) type ActionInterface struct { receiver unsafe.Pointer foo func(unsafe.Pointer) int bar func(unsafe.Pointer) string } type MyAction struct { val float32 greeting string } type MyOtherAction struct{ val int } func MyAction_foo(a unsafe.Pointer) int { return int((*MyAction)(a).val) } func MyAction_bar(a unsafe.Pointer) string { return fmt.Sprintf("%s, World", (*MyAction)(a).greeting) } func MyOtherAction_foo(a unsafe.Pointer) int { return (*MyOtherAction)(a).val } func MyOtherAction_bar(a unsafe.Pointer) string { return "asdf" } func execute(a ActionInterface) int { fmt.Println(a.bar(a.receiver)) return a.foo(a.receiver) } func main() { a := MyAction{7.5, "Good day"} b := MyOtherAction{1000} a_wrapped := ActionInterface{unsafe.Pointer(&amp;a), MyAction_foo, MyAction_bar} b_wrapped := ActionInterface{unsafe.Pointer(&amp;b), MyOtherAction_foo, MyOtherAction_bar} fmt.Printf("%d\n", execute(a_wrapped)) fmt.Printf("%d\n", execute(b_wrapped)) } You could do away with another level of abstraction in Go, since receivers are implicitly passed along with function pointers: package main import "fmt" type ActionInterface struct { foo func() int bar func() string } type MyAction struct { val float32 greeting string } type MyOtherAction struct{ val int } func (a *MyAction) foo() int { return int(a.val) } func (a *MyAction) bar() string { return fmt.Sprintf("%s, World", a.greeting) } func (a *MyOtherAction) foo() int { return a.val } func (a *MyOtherAction) bar() string { return "asdf" } func execute(a ActionInterface) int { fmt.Println(a.bar()) return a.foo() } func main() { a := MyAction{7.5, "Good day"} b := MyOtherAction{1000} fmt.Printf("%d\n", execute(ActionInterface{a.foo, a.bar})) fmt.Printf("%d\n", execute(ActionInterface{b.foo, b.bar})) } Of course, since you also have closures, you could use that, too: package main import "fmt" type ActionInterface struct { foo func() int bar func() string } type MyAction struct { val float32 greeting string } type MyOtherAction struct{ val int } func ActionInterfaceFromMyAction(a *MyAction) ActionInterface { return ActionInterface{ func() int { return int(a.val) }, func() string { return fmt.Sprintf("%s, World", a.greeting) }, } } func ActionInterfaceFromMyOtherAction(a *MyOtherAction) ActionInterface { return ActionInterface{ func() int { return a.val }, func() string { return "asdf" }, } } func execute(a ActionInterface) int { fmt.Println(a.bar()) return a.foo() } func main() { a := MyAction{7.5, "Good day"} b := MyOtherAction{1000} fmt.Printf("%d\n", execute(ActionInterfaceFromMyAction(&amp;a))) fmt.Printf("%d\n", execute(ActionInterfaceFromMyOtherAction(&amp;b))) }
This is Go 1.x: http://i.imgur.com/ilBsLgo.png
I don't blame you there. Simple is good. Simple gets shit done. And generics are simple.
Well, maybe :-) Validating is not very different from asserting: - For validating input data in application code, it's validating. - For validating output data in testing code, it's asserting. So it largely depends on how you look at them and where you do the validating.
I think there's an argument for a limited form of operator overloading, that I described in [here](https://dev.to/loderunner/go-i-love-you-but-youre-bringing-me-down) along with some other ideas. TL;DR Clear semantics baked into the language could prevent operator overloading abuse. Sameer Ajmani [mentioned](https://twitter.com/Sajma/status/889584792660045825) seeing a similar proposal
* Key may not be a number * Key column must be configurable * Value column must be configurable
what is unsafe about the runtime, right now, other than `nil` being a thing?
I guess you think that context will persist across different requests. It won't. You should use cookies / local storage for that. Context is request-scoped, _each_ request will spawn a new, empty context.
OP assumes context persists on different requests, which isn't true.
The thing is OP assumes that context persists between different HTTP requests.
One can always stay civil and be open to others arguments right ? We aren't animals :)
+1 for not using "reflection" and some great ideas -1 for no tests and no benchmarks
You make a fair point about the compiler and standard library. But I think, as somebody who implemented networking apps in other "general-purpose" languages, that you overestimate them. There hasn't been a networking service (server, api, client, tcp, http, etc.) that was implemented in a general purpose language which would be as-good as even a basic Go implementation. The rare examples which I've seen have all been in C, and have at least a decade of development - which these "general-purpose" languages don't. Not to mention that maybe generics isn't even a problem about these languages. Sure, there's no compile-time safety, but if I'd point a finger I'd just point it at a poor ecosystem. Node/NPM is broken with all their stupid packages like `isarray` and `is-array` and `left-pad` and whatever, PHP/Composer is (as much of PHP) even worse (but thankfully adoption is much lower as well). Considering how recent EcmaScript standards have been implemented in Node, I'd rather advocate for a pre-compiler toolchain integration for `go build`. That way code generation would be a first class citizen. One could implement a completely different syntax and just make sure with something like `//+build` to pass it through some kind of precompiler toolchain. Since most of the generics discussion is about providing a concrete type for `T` (templates), I think that this would be an elegant way to solve it. Go stays Go. The question is, does Go need some *additions* that can't be solved with a precompiler.
&gt; 2. /regex/ Regular expressions are already massively overused, making such abuse easier is not a good idea.
Thanks for the +1 and -1, this library is a quick proof of concept, tests and benchmarks will be added later.
[removed]
If you don't "need" productivity, re-usability, abstraction and safety you are wasting yours and your employers time and you should consider another line of work.
 rand.Seed(time.Now().UnixNano()) n := rand.Intn(len(a)) :p 
Are you on the gophers slack channel? Then we can take a look at your nginx configuration :) my username is the same as on here 
They talk about Go a bit and his involvement, can't remember the details but still worth a listen. https://softwareengineeringdaily.com/2016/01/06/language-design-with-brian-kernighan/
I am :) I'll keep an eye out!
If you "need" a garbage collector you're just a bad programmer.
[removed]
Maybe I failed for wanting to put this too succinctly. I suggest you watch the video I mentioned, it's really good. Of course they borrow features from other languages, the alternative would be redesigning everything from the ground up, from syntax to data structures and compiler design. The difference is that Go features are there as a result of a top-down approach for designing a simple, productive language with orthogonal features and great tooling. Other languages strive for other things such as expressiveness, ease of read and homoiconity and then add more features to further versions because "C#/Python/R/Ruby/perl6 has it, why shouldn't we?". That results in a more complex language, more complex tooling and unproductive discussions of for loops vs. map/reduce/fold/comprehensions or the optimal Tab size.
Hello, What about generics makes it a stupid and unnecessary feature? Thanks! edit: no response, that's cool I guess.
Brian was not involved in the design. Some of his first experiments with the language, after it was already public, led us to make some additions to the library, most notably bufio.Scanner. I know from experience that if you sit near Brian the odds improve you will co-author a book with him. Alan Donovan sat near Brian for a little while.
Thank you for this thorough answer!
You should avoid using context.Context to pass objects around. Why: https://faiface.github.io/post/context-should-go-away-go2/ Solution: https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html
I hope they at least fix encoding/xml - that library is a complete mess. I consider myself a victim of it. Although to be fair, this is likely a consequence of being a victim of XML in general.
I tend to agree. Baked-in cancellation may be great, the only worry is how to make it fit without complicating the language too much. As such, I'm greatly interested in your proposal, keep us posted !
Although I mostly agree I have a couple of comments: 1. you can avoid context collisions if you create a specific, unexported type for each thing that wants to put stuff into the context. A map's key contains the type so even if two keys are the same string if they have a different type they will not collide. You probably also need to provide exported functions for getting things out of the context if the type is unexported. e.g. `GetLogger(ctx context.Context) log.Logger` or whatever. 2. I think context makes a lot of sense for HTTP requests since you do usually want to have arbitrary "stuff" passed between middlewares/handlers via the request context.
Relevant proposal: https://github.com/golang/go/issues/21195
In such cases, it can be kept within the HTTP requests, if it's so useful there (although I expect it can be avoided). The reason why Context spreads to libraries outside HTTP requests themselves is cancelation. So, if Go 2 solves cancelation, context for request-scoped values will no longer need to spread outside the requests.
I agree with your assessment. If putty could use normal private keys there would be no need to format them. My suggestion is to turn it back into private keys.
Also, localization. Shift + 2 != '@' on most keyboards. Had that problem once. Not a fun one.
&gt; If the Go language ever comes to the point where I’d have to write this &gt; n, err := r.Read(context.TODO(), p) &gt; put a bullet in my head, please. that seems ... strong. &gt; If you use ctx.Value in my (non-existent) company, you’re fired &gt; An obvious one, it’s not statically typed at all. This argument is _incredibly_ weak. If you want typesafe usage of `ctx.Value`, you can have it by writing accessor methods. &gt; It requires documenting which values (keys and their types) a certain function supports and uses. As we all know, documentation is mostly a code that never runs. it really doesn't. Write a function that reads and writes what you need: the keys are an implementation detail, they don't _need_ to be a part of the API. This is a solved problem. `context` is warty. Its existence and its increased reach signals a legitimate design problem. I'd agree that the suggestion that `io.Reader` should take a `context` is a canary, but the overall tone of this post strikes me as very accusatory, like "context is bad and you are bad and you should feel bad".
Cancelation is one nice thing you get with context, but another thing I use for it is logging. Inside Google (so I can't show you, sorry) I created a package that lets me add keywords to the context so that when I log, those keywords are added to the message as a list. I find this feature extremely useful. I don't want to blow up this keyword list, so I only add a few things to it - specifically the entry point (such and such a request, or some background batch processor, etc) and IDs for resources being modified (all these log messages have to do with widget XYZ - so if there is a problem with XYZ I can easy filter logs to show only things relevant).
What if cancellation was baked in? I know you disagree with having a context as an argument, but I think being able to cancel Read operation from an io.Reader could be tremendously useful. I wonder what the implications of that would be. func myFunc() { time.Sleep(10 * time.Second) } myFuncRef := cancellable(go myFunc()) // gives you a copy of either an identifer, memory address, whatever makes sense -- something to refer back to the currently executing function with it's current execution scope/context cancel(myFuncRef) JavaScript has something similar when you setInterval or setTimeout, you are given the ID which you can later operate on to cancel the interval for example. Another way maybe is in the function signature, but I don't know the language implementation implications for that cancellable func myFunc() // ... 
What do you used perl (6) for? Don't recall seeing any local listings for perl programmer in my area. Is the documentation and community around perl 6 good? And is it worthwhile to dive into? I've played with perl plenty but I feel like I never really had it click with me. 
Sorry, I should have clarified, I use perl5 at work. I'm not aware of any Perl6 jobs since I don't think it's at that stage yet, nor is the community very big. I believe an O'Reilly book on it is out or coming out soon, and my experience with it is very minor playing with it and reading articles about the various features. Perl5 is tough to wrap your head around, but once it clicks it's a breeze to use, sometimes despite its quirks, sometimes because of them. I use it mainly for processing large volumes of data, but there is a team working on an MMO (I think text-based) called [Tau Station](https://taustation.space/blog/).
The tone is not meant seriously, it's mostly to keep the reader awake :). And ok, I agree with your counter-arguments, thanks for enlightening me, I'm not a server person. But I still believe ctx.Value can be avoided. The main problem with Context, as mentioned by the post, is not the values, but spreading. And the spreading occurs because of cancelation. So, if Go 2 solves cancelation and Context will remain only for values, it will no longer spread.
I have managed to do a few small projects in perl and it wasn't that bad. It's just I don't think I've used it enough for it to click and be productive in it. I just wish there was better tooling for it like there is for python/java/etc 
Any io.Reader for the most part that cancelation is possible already implements timeouts via SetDeadline. I think it would be real hard to make an intuitive generic cancelation builtin. How would you safely interrupt memory only io in busy loops like bytes.Buffer? Compiler would need intrinsics it could inject for signaling but how would you select a safe break point? Would need to be after a function call but that leads to all the infinite problems of stack unwinding, without the luxury of an explicit recovery point. You would basically need a function like recover that took some sort of arguments and crash that part of the program I think.
How does your library compare/compete with https://github.com/pengux/check ? This has been around for a long time now, and appears to share many of the same sensibilities. Similar question for https://github.com/gima/govalid . I think I like your API better, but it's probably worth at least looking at these two to see how you're beating them.
Actually, it could look even easier! Just make `go` return a cancel `func()`: cancel := go doStuff() defer cancel() // do other stuff Or make it return routine ref, or anything else. This way return param can be ignored if cancellation isn't needed and won't add clutter if it is.
I very much agree with this article. The reason I fell in love with Go is because of its simplicity. This kind of BS makes me think that the Go team is giving into community pressure instead of holding their ground. I have begun fearing that I'll be in the radical minority that refuses to work with Go2.
&gt; This argument is incredibly weak. If you want typesafe usage of ctx.Value, you can have it by writing accessor methods. It's not weak at all; if you change the type on a context to give it those accessor methods, it's no longer a "context" as far as the type system is concerned, and you can't compile. If you meant "create methods on some other thing that know how to take a context and return typed values", that isn't type safe, as it doesn't give you any guarantees that the value your method expects is actually on the context. For example, if my middleware is Foo and it depends on middleware Bar being invoked before it, then all of the helper methods in the world won't prevent a runtime error if the caller fails to ensure that Bar is invoked before Foo. Static types exist for the very purpose of ensuring that these sorts of contracts aren't violated. 
At the point where people are seriously discussing changing io.Reader to include a context, and indeed, by that logic, slathering contexts in dozens of other places too, I'd submit that maybe it's time to reconsider the argument against goroutine-local data. As it happens, I've also had the exact use case where I would have _loved_ to have a context passed into my BinaryUnmarshaler implementation, but there's no way to do it. (I'm using Gob to deserialize something that may need to depend on some local state, but because I'm getting my UnmarshalBinary function called with no state or context whatsoever other than the bytes in the binary, I only have access to global state.) Include a community-driven standard on where cancellation lives in that context. Basically, every place someone wants to stick one of these "ctx" parameters is an argument in favor of goroutine-local data. (Also, "let's have a generic cancellation mechanism" leads one quickly to the idea of asynchronous exceptions, or asynchronous panics in Go's parlance. But such things aren't possible in Go. [See this writeup I've done](http://www.jerf.org/iri/post/2930#no_async_exceptions), and let me reiterate here on Reddit that the discussion there is not the result of desk-chair theory, but the hard experience of several very well-funded efforts to add them to languages that are, for this purpose, basically identical to Go.)
I have some ideas for a general cancelation mechanism which don't require any asynchronous exceptions or any bad stuff like that. I'll post/propose the ideas later.
Language magic should be avoided if at all possible. Though I agree that `context` is pretty clunky.
Context as a context is fine I think, but like I've said here in the past the package could have had more thought out in the design and implementation. The biggest thing is Value should NOT exist in context.Context interface. Instead context.Value should have been replaced with Parent. Making a cleaner interface like: Deadline() (time.Time, bool) Done() &lt;-chan struct{} Err() error Parent() context.Context // don't think ok bool is needed Now you have opened up a opportunity for user space implementations of not just Context values, but actual context. Part of the reason no better context library has emerged (trust me it could be implemented much better, without 3-7 allocs depending on the method, that number could be 1 to zero for just cancelations) is due to the fact the context package is tightly coupled to itself to find parent context. It even has cancel as a internal implementation only, using the Typed CancelFunc in place of an interface such as: type Canceler interface { Cancel() } So one can not implement a user context from top down that plays well at all with the std lib or optimizes away any inefficiencies. You can't make a map to use for context.Value for example to store just your app state to prevent the 6-8 allocs that come with stdlib. With a Parent method you could, and all existing instances of (context.Context).Value(...) simply get changed to context.Value(...) a top level function call implemented using context.Parent() to walk up the tree until it asserts it's own private valuecontext type. Tooling could do this task very easily.. and then we can finally implement our own context and perhaps a set of context packages outside of std library can emerge for special purpose cases. Just my opinion, context is great and shouldn't Go anywhere. It just needs the design adjusted to be friendlier to integrate and specialize.
If need pronouns, are a baby.
Just switch to CML/SML and call it a day.
To be honest, I did not know [check](https://github.com/pengux/check) and [govalid](https://github.com/gima/govalid) before. After taking a quick look at both the libraries, there are at least two differences I can tell: 1. (the big one) both the two libraries use reflection 2. (the small one) cross-field validation seems impossible
(a) Cancellation and (b) per-request values for HTTP handlers are totally different problems, and I found it really confusing when Context was introduced as the solution to both problems. I feel like it was an unfortunate case of "Well, here's one hack which will let people work around two big issues without changing any APIs, so let's do it".
that sounds like a role of the logger, not every function in the enire codebase
So show us a good generics system which doesn't have a horrible complicated syntax. Someone must have done it, right? And please don't reply with Java or C++ unless you want howls of derisive laughter.
It's also what's happened to JavaScript. And before that, it happened to Perl. Perl 6 drove me to switch to Ruby.
That is one benefit of Scheme-like, Ruby-like, expressions over traditional C-style statements! It's probably safe to add this to Go, but would confuse some systems programmers unfamiliar with this semantic.
If you "need" the mnemonics of assembly instead of just inputting op codes through toggle switches then you're just a bad programmer.
Wow that was the issue! I didn't know you could convert Putty to SSH, that's great! I did it and I have no longer the error. Thank you!
I like this. My intention in the example I gave was to make it explicit which functions were cancellable and which were not. I imagine you wouldn't want every function to be able to be cancelled, just like you don't want people who CTRL+C out of your app to leave it in a corrupting state, most people intercept the signal and do some cleanup.
Give it time. JavaScript got class-based inheritance because so many people kept asking for it. Grr.
&gt; If you "need" generics you're just a bad programmer. The Go compiler / stdlib uses generics. Also, Go has some builtin generic types. Are Go authors and users bad programmers? 
It's estimated that to become fluent in C++, and able to program in it reliably and safely, requires around 5 years of experience. The language is huge, has many features which can be extremely dangerous if misused, and so on. This makes C++ development expensive. It's why there's so much interest in Rust, Vala, Swift, and Go -- people want something with performance comparable to C++, but without the difficulty and expense. (And without the JVM, because Oracle.)
I was taken aback by some of the points too. We use the value method quite effectively in our entire product... no engineers fired thus far. It is a hugely useful mechanism for achieving the ability to pass out of band data through the call stack without requiring that every method deal with it explicitly. Also, while one might argue that this is because we dont have "goroutine local storage" I understand the pros/cons of not having GLS too... goroutines should not have identify. If they had, I would not be able to spin up goroutines as casually as I can do right now. So, given the pros/cons of the overall situation, I am glad that context.Value exists.
I would have assumed this article was written by someone who didn't write server code, even if he hadn't mentioned it. The fact that he thinks `.Values` is useless is ridiculous. However, I do agree with his points about passing around a context in general. A much more elegant solution is to have goroutine-local data. Lets just start having the `go` keyword return a context-like object that will optionally block when we check it. That would be much simpler/cleaner.
This is actually a part of one of my ideas :). The other part is how the canceled goroutine should handle it's cancelation.
weren't most of those features in lisp first? :D
Haskell, Typescript, Kotlin. I don't know where using a dozen slightly incompatible codegen tools is a step up from using a reasonable amount of generic code to define the few polymorphic functions that are needed for generic collections and so on. It's certainly a *way* easier problem that understanding the subtle semantic gotchas in channels.
I rarely write servers and network interfaction. My mostly used io.Readers and io.Writers are os.File and heavy processing of input/output data. File IO is blocking in Linux, heavy processing is blocking as well, thus any ctx is totally out of place at least for these. Let these people use their own context.Reader and context.Writer and don't touch sane io primitives. The issue itself is just a consequence of poor match between synchronous semantic of Go and asynchronous events it processes. The best place to resolve these is runtime itself. Mindless API complication which will reflect into performance drop (you will need to start an OS thread per file read/write) is just a poor choice of entry point. They better add optional parameters for goroutines (timeout + timeout handler, for instance).
How about making context an implicit first parameter to every function, essentially as a dynamic-scoped global variable. Or just add dynamically scoped globals and let people do what they want with them? That gets you something like Value, but with types and packages in the names. i.e. you declare package foo dynamic Bar string and then you can do: foo.Bar = "blah" but only functions you call (and the rest of the current scope) will see that value. 
That's cool :) looking forward for the post/proposal!
I believe that linked list was chosen instead of a map so that child context won't be able to mutate its parent's state.
I'd swap your 1 and 2, but they're both valid points. :) I've been using go-validator, but the struct tags have been a bit limiting in scenarios (cross-field validation is clunky there). Good enough reason for me to give this library a try!
Maybe I'm missing something, but [Kotlin generics](https://kotlinlang.org/docs/reference/generics.html) seem to have more complexity than Java's, and TypeScript's seems basically the same as Java.
Go has a lot of runtime magic anyway. Just because of the CSP model. Yet another runtime trick won't change much.
One thing that strikes me, as I look at what I have in go-validator land, is that having a mode that operates in tags that can generate this schema internally might be an easy way for people to move from other validation systems to this approach for simpler use cases. Potentially as an independent package, since you probably want to keep the primary package clean of reflection. Your primary mode of operation is the more powerful and flexible one, mapping tags to the simpler use cases of it could potentially give the best of both worlds.
What? Do you have a source or something?
Yes. Titles require inference. This is literature, not programming.
I think context is super awesome and has greatly simplified much software I interact with and also made it more reliable. I agree it does too many things (holding a value is questionable, but beneficial for some of its important use cases), but the thing I find it primarily most useful in is something the author seems to think is secondary -- deadlines. Setting a deadline on a set of work is not just a thing for servers, it's generally useful and critical to writing reliable software of all kinds. While you could implement some types of deadlines with cancellation, propagating deadlines via cancellation is woefully insufficient. Deadlines are very useful for clients and anything using `os.exec`. Before deadlines, I'd end up with a bad connection hung for a while, or a subprocess failing to terminate properly, or other such things that were increasingly difficult to make reliable. Now, I just set a 30s deadline for something I expect to take 10s, and it finishes or errors. That deadline propagates properly downstream to things that may be making connections, running programs, etc... In distributed systems, that deadline propagates across system boarders as well so my program (a client) communicates to another server and sends its deadline. That other system can simply refuse to do any work whatsoever if the deadline is unreasonable, and it can do this before it starts. If some bit in the middle doesn't handle a cancellation properly, this means all the client requests it attempts to send can just fail fast. If you rely on some kind of local timer to call all of your cancel functions, are you also relying on that cancellation to send a request to any systems you're talking to to tell them to stop working? This gets complicated fast. In practice, context has made it really clear how timeouts are propagating and simplified my work. I do wish more things supported them.
slice, map, channels are all generic.
IMO context is essentially an alternative to dynamic-scoping implemented on top of lexical-scoping because language doesn't support it. This context type is really unnecessary if Emacs like dynamic-scoping is supported by the language. That said, I also see that Go routines make it very difficult to get them right at language level. For example, if request processing creates a new goroutine, users may expect the goroutine to inherit caller goroutine's dynamic-scope values as they are at the point of invocation -- which can make goroutines expensive. 
Do IO readers not have a method to check whether the stream has closed? Seems like an oversight.
Don't really need exceptions. Just a way to reduce the boilerplate. Something like a macro. If you want to keep it simple, you can just make it built-in
Cool. This is close to how I use context: In my codebase, log package defines this: type LogContext interface { context.Context Infof(...) Warningf(...) Errorf(...) } func GetLogContext(ctx context.Context) LogContext {...} func WithLogBackend(ctx context.Context, backend LogBackend) LogContext {...} func WithLogPrefix(ctx context.Context, prefix string) LogContext {...} I have plans for other type of extensions to contexts, like: type CommandContext interface { } type ProgramContext interface { } type RequestContext interface { } type TransactionContext interface { } etc. IMO just because a function takes context doesn't necessary mean it must handle Deadlines, Cancellations, etc. 
IIUC, deadlines can be easily implemented on top of cancelations. Here's how: ctx, cancel := context.WithCancel(ctx) go func() { time.Sleep(timeout) // timeout can be easily calculated from deadline cancel() }() If I'm wrong, correct me please. Btw, cancelation is the one thing I find very useful about context, although, not done right.
The standard lib could still enforce that easily using a map with composite keys- or they simply keep the implementation they have today. My point isn't to change the stdlib value implementation but free users from being confined to it. Then more specialized context packages can be used with better cooperation in std lib. 
I agree that context implementation must've been better, but I beg to differ on Parent. IMO users should not be aware of existence of a parent context. Perhaps, making context a language level construct (like string or make) may enable better implementations in the background.
I disagree that there's "a lot". There's just enough to support the concurrency model, new data structures (maps, etc) and GC. Otherwise it's pretty much straight C.
Oh, that. I understood that generic types (not only slices, maps and channels) were used in the compiler’s code.
But Value is exactly that- coupling a child context to its parent. WithValue simply stores Parent ctx for child to call if it doesn't have its value, it forces a inflexible tail recursion pattern AND forces children to be aware of their parents. Changing Value to Parent() allows you to implement more efficient value fetching. I wouldn't really care how it's done though and would be fine without a parent method as long as it was more flexible.
I can get behind this write-up, even if I don't agree with all of it. I agree that people tend to use logging as a cover for bad usage of metrics and events, especially when they have access to something like Splunk. Your application behaviour (including alerting) should not be driven in any way by logs that can be disabled. Use metrics, tracing, things like Sentry and use systems that have the correct guarantees and behaviour. Some things you should even store for very long periods in a data-store of some sort (probably like login history). However, while I agree that those are frequent issues, I don't agree that doing them correctly precludes the use-case for structured logging. As you correctly note, something like a contextID is often necessary - especially when we start talking about services and applications that are distributed or handle a large amount of concurrent work as applications written in Go are prone to do. The idea of human-readable stdout becomes a little less sensible when 10s of contexts are interleaved. Even as I don't believe that you should alert on counting up your 200 status codes vs your 5XX's from your logs, I think you should be able to go back later and analyse where you might need better metrics (maybe you weren't collecting them per-endpoint?). You might also want to trace the actions of a particular user. I don't think that having these other systems removes the need for adding more context to logs, and I really hate the pattern of spitting things into text logs and then having to put in regexes or extractors to get them back again. logrus actually has a pretty nice API, in that if a library accepts a logger-like object, you could pass it in. Part of the issue that I have is that there's no standard that a logger should be treated like a context object and passed along in a context-bounded way.
The nice thing about context is that it leaves control in the hands of the goroutine to work out when to check it and act, and doesn't preempt control flow like an exception / panic. While I've worked with Python Stackless tasklets that could be cancelled from outside before through exceptions, that wouldn't be at all idiomatic for Go.
Do you ***have*** to use a Putty key? I use regular SSH keys just fine on Windows. I use Git bash instead of putty for any ssh needs.
And reflection, and task switching on function calls, and interface nil that is exactly (nil, nil) but (nil, table reference), and a[string(byteSlice)] += 2 that allocates a string while b := a[string(byteSlice)] doesn't allocate anything, etc. Hardly a C Go is.
I have only been writing golang for a year now, so I am fairly new. I have created 10+ go apps, 6 are taking production workloads. In the last four or five months, I think my go code has improved dramatically and I attribute it to one key questions I keep in mind while writing go code, "How would the standard library do this?". To put the thought this questions invokes in other terms, when another golang developer looks at this code, will they know what is happening **without** me explaining it to them. 
That sounds like a pretty good idea. I hope its followed up by a proposal.
Go strives for simplicity. Although a gopher could understand that. Having to use append to remove an element is odd at first sight.
`such as failing to open a file, as exceptional` exception != panic. exceptions = error in go sense, in java and C#
I'm not a fan of Go, but Go certainly has a larger adoption than Rust, that's a fact.
The backing from Google does help in that. But Rust was just an example. In reality Go is probably more competing against C#,Scala, Kotlin or Java. All of them have automatic memory management in their runtime.
This picture is pretty funny, but in seriousness it assumes a future version where the designers will turn the language into _not_ Go to the point we can't recognize anymore (or enjoy it like we enjoy Go 1.x). I don't think that that will be the case. I look forward to Go 2.
That's the correct attitude, my friend. Thanks for putting work into _vim-go_ and giving it away for free.
A built-in calcelation mechanism doesn't have to be preemptive.
Well, time.AfterFunc would be way cheaper, but you're still missing a lot of information. The remaining code doesn't know how long it has. It's going to waste a lot of work and have more edge cases that behave poorly. I put timeouts on everything I can. Scheduling tons of async cancellations to tell remote systems, or processes, or even simple compute functions will be expensive. Right now, we use deadlines to prevent work. How much time you have to complete a task is known a priori and if you know with sufficient certainty that you can't do what's requested in that time, you just error. Remote systems do the same with what's left. Attempting to express a cancellation longer than the current timeout is a noop. Your strategy doesn't allow this. Every attempt to add a deadline creates an additional call to cancel. There will always be at least two, and user retested cancellation becomes indistinguishable from timeouts. This model leads to lots of information loss, additional work, and lower reliability.
The first step for me is to write what I want the user's code to look like when they use the library, so that it's painless and clear what the code is doing. This has the benefit of being convertible into tests later. After that, I think its just iteration. A little planning ahead is good, but too much planning ahead and you might find you've written yourself into a corner when an unexpected problem comes up. 
The key with goroutines is that their life cycle is cooperative. You don't want to just "cancel" a goroutine" and context can control far more then just a goroutine. 
You wouldn't want to parse each thing from HTTP requests each time, such as authorization. Authorization parsing and checking is almost always relatively expensive. I would suspect many types of values being put into the context, but Authorization is one that is great to have. There are others depending on the application that are useful, but expensive. This isn't just about an easy way to parse an ID from a URL query string. And some things (such as an HTTP body) can only be read once.
Known deadlines can be passed through arguments or through context values (context for values can possibly be kept). Cancelation itself is the reason why context spreads like a virus, so if cancelation is solved by the language, context for values wouldn't need to spread beyond requests. Such context with values could carry deadline informations too.
Haha, Go-ize all the things! Keep at it, Kris!
Well articulated points.
I'm not saying, that these things shouldn't be stored or collected; just that I don't consider them logging. In my view, they are trace-annotations. logrus (and similar packages) just conflate the two notions. In my opinion, you want to have annotated traces on the one hand, and textual logging on the other. And yes, you want to be able to correlate the textual logs to spans in the trace, so you definitely want to add the current span to any log-line output. But everything after that (arguably even the current time) does not belong to the *logging* API, but to the *tracing* API. If you will, it's simply the difference between saying log.WithFields("ResponseCode", 200).Log("Responded 200") and log.Printf("Responded 200") trace.Annotate("ResponseCode", 200) The difference in usage might seem trivial, but it clearly separates the concerns and reduces the API for logging to the essential part: Putting out text. It also means, that you don't associate the fields with any verbosity; while the log-line itself might be dropped, the trace-annotation won't be. Separating the concerns makes it clearer what fields are useful, what they will be used for and what amount of logging is useful. But, YMMV :) The title is "what *I* want…" for a reason :)
Context also causes library fragmentation; there are some packages that support context and those that don't. Since context is promoted to the stdlib, some packages that only need "cancel" try to add context everywhere. 
&gt;not being Go How does that even happen lmao
I agree that we should see if it's possible to improve the design of `Context` in Go 2. But I disagree with almost everything else you wrote! # On the intro... While I agree that adding `Context` to the `Reader.Read` function would make it less composable and generally more annoying to use, the proposal isn't entirely without merit. It's definitely useful to be able to cancel some IO operation if it takes longer than expected! It is pretty easy to just launch your own goroutine to handle this case, though, so I agree that it doesn't absolutely _need_ to be focused on right now. # On "Go is a general purpose language" I think maybe you haven't thought about some of the other non-server situations in which a `Context` object is useful. There are many! This is probably a failing of the documentation that people aren't thinking about other places where `Context` can be used. In general, whenever you have some sort of an independent "transaction" (though that's not even the best word because it's overloaded by databases) then a `Context` object might be a good idea. Let's say you're writing a GUI app, for example. Generally, a modern GUI app will use events to deal with things like button presses and mouse clicks. When an event occurs, one might launch a new goroutine, who's job is to handle the event. You probably don't want to let your event handler run forever, right? Here's a simple solution: use a `Context` object with a deadline, so goroutines know to automatically exit after some amount of time has passed. Another example: maybe you're writing some background process that watches for new files in a directory, and then uploads those files to some server (like Dropbox). You probably want to make sure each file upload completes within a certain amount of time - that way, you don't have to babysit the process and manually restart it if it gets stuck on something. Again, you can use a `Context` object with a deadline to help coordinate. So you see that `context.Context` is actually really useful even outside of servers! But is it really a virus? Well, maybe. But only because the ability to cancel a blocking call is pretty essential. The fact is, if you write a library that makes blocking API calls and doesn't provide some means of cancellation, then your library is much less useful than it could be. So yeah, I probably won't use it in a server, because it isn't safe. But I also probably won't use it in any other program either, unless absolutely necessary. If your call takes too long and you don't provide some means of cancellation, then I probably have to just restart the whole process, potentially losing a large amount of work and wasting a great deal of energy! In most other languages, people have recognized the danger that blocking calls pose, so many functions provide their own unique interface for cancellation and timeouts, which makes them harder to use. I think `Context` is a great way to provide a standardized solution for that problem. # On "If you use ctx.Value in my (non-existent) company, you’re fired" So I agree that, at first, this seems pretty messy. In practice, though, I find it greatly increases the composability of my code by making it easy to setup middleware. Let's go back to the GUI example. Maybe you're using some third party GUI framework that handles launching event handling goroutines for you, and every event handler you have also requires access to your SQLite database. Instead of repeating the transaction setup code in every handler, wouldn't it be nice if you could add some middleware that adds the transaction to a `Context`? Well, if you're passing `Context` around everywhere, now it's easy! To refute some of your specific points: 1. I agree, it's unfortunate that it isn't statically typed. At the same time though, if you don't know what type you're inserting into the `Context`, then you might have bigger problems! 2. I agree that the documentation bit is annoying. On the bright side though, if someone misunderstands the documentation, it will be obvious, because the key they're looking for won't be present, or the value being set will be of the wrong type. 3. It's really not like thread-local storage at all? In fact, the whole point is it's easy to share the data in a `Context` object across multiple threads. I guess I don't really understand your point here. 4. Name collisions won't happen if you use a custom type, as specified in the documentation. Even if one were to happen, you'll probably get a panic when you try casting the value to the wrong type. 5. Again, I don't really know how to refute this... # On "Context is mostly an inefficient linked list" Well, I mean sure, it's basically a linked list, but... who cares? If the major performance problem in your program is it takes too long to retrieve a value from `Context`, then your program is probably ridiculously fast already, and maybe you should start looking into assembly. Okay, that response was a little frivolous. But seriously, this won't be noticeable for almost everyone. # On "What does the 'context' package actually solve?" It seems like we've solved cancellation already with `Context` (or if you don't want to use `Context`, then "done" channels)? I'm not sure why you're posing it as some major unsolved problem we are still struggling with. I suppose you might struggle with it if you refuse to use `Context` and also refuse to use channels, but then isn't that your choice? Other imperative programming languages don't have any alternative solutions. Ultimately, the only ways to provide cancellation are a) force everyone to write code as if it may die at any time, so that you might kill their thread at any time or b) have the ability to nicely ask some code to exit, and establish some standards around that idea. a) is really hard to get right and significantly decreases programmer productivity; b) is flexible and makes for a more extensible, approachable, and productive language. Nowadays, since `Context` has emerged as a standard, the whole issue of people not accepting cancelation channels has largely gone away. While it's always going to be possible that a thread is doing some work which absolutely can't be interrupted, this problem comes from the OS APIs, which traditionally are always blocking. So it isn't really something we can fix in Go, even in Go 2. On the "tree of goroutines" issue, I'm not sure what other solution you have in mind? If you think about it logically, you're always going to need another variable in order to communicate the idea that some separate tree of goroutines/threads should terminate ASAP. Context lets you do this using the "WithCancel" functionality, but even if you choose to avoid `Context` and channels altogether, you're still going to need some sort of variable to store this information. So I really don't see how this can be improved.
The whole interface would be leaky then though. If you alone want to get rid of immutability then every programmer anywhere will need to think which implementation is plugged in right now in the current service. 
Can you provide a example? I'm having trouble filling in the blanks for either of your statements. What does leaky mean and how does it get rid of immutability? The interface today is more mutable, it's tail recursion through parent ascension via interface method that ANY implementation between your context containing the value and your call site could intercept. By forcing Parent() to be called the withvalue implementation would need to assert on the parent to check for its concrete unexported type, meaning storing a value with context.Value forces immutability by design rather than relying on convention and cooperation across interface implementations like we have today.
First of all, thanks for a really involved response, I appreciate! Regarding usability of Context outside servers, I agree, I even wrote about it in the article: &gt; Now, I’m not trying to say that context is only useful for server people. But mostly, it is. &gt; Solving it is usually necessary anytime a decent usage of goroutines is involved. Other thing, I'm not sure if this wasn't clear from the article, but yes, Context does solve the cancelation problem. &gt; Despite all of the bad things described above, the "context" package is genuinely useful, because it solves one thing that is kinda hard to do in Go: cancelation. I just don't like it for all the reasons mentioned in the article. Your points are generally right, but none of them really goes against my main argument, which is that Context is a virus that spreads into libraries where people mostly don't need it. As I proposed in the article, the cancelation problem should be solved by the language instead of Context. Language can provide a much cleaner and non-infectious (rather healing) solution, which cannot be provided by something like Context. PS: your fonts are really big.
&gt; How do you practice good design? Sweat, blood and tears. Is there any other way? 
I think it's valuable to have your perspective, I'm just noting that I have a slightly different one. Perhaps my biggest issue is that I have no idea what you're talking about with trace annotations. When you say trace, I think of something like Zipkin that gives me timing info in a distributed manner. Given the toolbox of (say): * Sentry * Zipkin * Splunk * Prometheus I will still count my response codes per endpoint in Prometheus, time my requests in Zipkin, categorize my errors in Sentry and still want my structured logging. More likely than your example, would be something along the lines of: { "path": "/foo/bar", "method": "POST", "filteredArguments": { "bar": 1789, }, "authenticatedUser": 1234, "context": "&lt;guid&gt;", "responseTime": 30, "responseCode": 500, "errorCode": "Floppy Hare", "error": "Failed to get session: Timeout connecting to redis" }
I'm not really versed in putty vs SSH. The previous tool was created before I came in function at htis job, and was a .bat file calling winscp and using a .ppk private key generate by putty. My solution was to convert it back to SSH. I stumbled upon error and errors following this. I nearly got it to work, then when I got the stuck for good. When I use ssh.dial, I get stuck, nothing happens, not even an error. :( 
The fact that it's useful doesn't mean it has no downsides. Many useful features have been left out of the Go language because of their downsides. Regarding goroutine-local storage... I don't think that's a good idea. I think the right solution would be a language provided cancelation mechanism (probably non-preemptive).
I rarely care about cancellation, but I want contexts everywhere specifically for deadlines. It is for this that I wish the virus to spread further. Passing a deadline as an additional argument is confusing and inconsistent. The context provides a) a simple way to express the deadline (if any), b) an easy way to tell if the deadline has passed, c) an easy way to wait for the deadline, d) a consistent way to pass the deadline down to other methods, e) APIs for passing that deadline to remote systems (e.g. RPC calls). I do understand that cancellation and deadlines (and values) are distinct roles of cancellation. Right now, they've only helped me improve code, and reliability of systems using them. If I could see a clearer view of what cancellation looked like in this implicit-propagating model, I might change my mind. As it is, the explicit propagation of contexts makes things very clear. e.g., when I see a bit of code that spawns some goroutines in an errgroup that has a cancellation function, I know what is canceled and when. What does this code look like in a situation where cancellation is propagated implicitly? ctx, cancel := context.WithTimeout(time.Minute) defer cancel() g, gctx := errgroup.WithContext(ctx) for x := range makeWork(gctx) { x := x g.Go(doStuffWith(gctx, x)) } err := g.Wait() This is really straightforward as the context exists *before* the workers start, there can be an arbitrary number of workers, and the cancellation of that context from the errgroup cancels both the work producer and the workers, so of which may not have even been *scheduled* yet, so you don't necessarily have their cancellation function to call. Also, many of them have finished, so calling their cancellation function is unnecessary overhead. Both current progress *and* production cease the first time worker fails. Everything stops in one minute. It's super obvious to me what's happening and what the cost is. How does this code work with implicit cancellation that's handled by a calling implicit cancellations + timeouts?
I'll come with a concrete post or a proposal later and I'll definitely address what you're asking in this message. Stay tuned!
Oh sorry, I've misunderstood you - had to reread the root post. Yeah, forcing Parent()+iterator at the pkg level would be better and cleaner solution. :) I was speaking of http://wiki.c2.com/?LeakyAbstraction
Is it helpful, if I'd say "request logs", instead of "trace annotations" (the two are semantically very similar in my mind, but I understand that it's confusing) and distinguish them from "debug logs"? What you describe (and what structured logging seems to be used for) is request logging; providing some aggregate information about how a request was handled. Every request will have one (and only one) of those entries in some database that can then be searched via BigQuery/Apache Drill/… And then, there is the separate concern of debug logs: A stream of textual lines, giving a detailed timeline of what happened inside the server (or CLI, or whatever) when handling a request, that can be used to debug it. These two are often conflated; but they don't belong conflated, in my opinion. So, of the list you mentioned, I'd split Splunk (IIUC) into two: One system to manage the structured analytics data about requests and the other to dump stderr into and make it searchable.
The only place where you have to seriously think about complexity in generics is when you're the creator of custom data structures and have to consider multiple type parameters and unusual weirdness that frankly constitutes an irrelevant minority of edge cases. As a consumer of generics and user you don't even have to have that knowledge in your head. You're going to be hitting contention and semantics issues in channels way sooner than this but nobody complains that proper channels are deep down not trivial at all.
When you try to read a closed stream, you get an error.
Exactly! I also hate how they brought in this obscure, ivory tower concurrency system (CSP). I wish for once we could get a language that's easy for programmers from all backgrounds to learn, rather than more academic wankery.
I wish I had the time to contribute more. I've never written a proposal, but I had thought about it on several occasions. Frankly, Go is such an elegantly simple language created by people much more capable than me, I worry that I'd just be proposing cruft. But, for your edification, an example of what I think it should look like: type MyGoContext struct { a string b int } c := go (MyGoContext{a: "1", b: 2}) func() { fmt.Printf("%s: %d", gocontext.(MyGoContext).a, gocontext.(MyGoContext).b) }() &lt;-c.Done() Changes to the context do not propagate to other goroutines. ^ This goes one step further and replaces `context.Values` with a strongly typed struct. 
You are making two points here &gt; The key with goroutines is that their life cycle is cooperative. You don't want to just "cancel" a goroutine" Yes but how is this any different in a situation where two goroutines are cooperating and one abruptly terminates or panics? &gt; context can control far more then just a goroutine. agreed, but thinking of a simple solution to fit a case like io.Reader you wouldn't need much more 
Well, there's the builtin types and then they also use some weird annotations in the [SSA code](https://github.com/golang/go/tree/master/src/cmd/compile/internal/ssa) that look very generics-like. It's in comments only, but seems machine-processed. I don't really know what it's for. *edit*: Not sure why you were downvoted. Wasn't me, FTR.
&gt; Go is currently very well suited for writing network apps and pushing bytes around. But that's mostly the extent of it. If it doesn't grow, it will likely die out eventually, because other languages are also good at these things, but they are also quite capable of being general-purpose You have mixed your outcomes. Go is growing _because_ other languages try to be everything for everyone languages and no one ever feels like they have mastery, meanwhile the cognitive burden is immense, the top comment on this thread explains it better than I could https://www.reddit.com/r/golang/comments/6nlc4r/would_generics_help_c_developers_move_to_go/ &gt; And once you start writing big applications, the later will almost always win, since they allow you to do other things much easier than Go currently does. I (along with my other coworker) currently have 4 application servers as well as other scheduled based tasks, all written in go that serves 39+ million users. I think Go was just splendid. At no point did we think to use another language. For kickers, this was a legacy rewrite, and the original application was written in Java. (J2EE, to be fair, running in WebSphere, with Spring 3 monstrosities everywhere, but nonetheless, Java)
Changelog between RC1 and RC2: https://github.com/golang/go/compare/go1.9rc1...go1.9rc2 Also, please note: &gt; We still need more people to test, especially on production workloads. &gt; &gt; Your help is invaluable.
&gt; Yes but how is this any different in a situation where two goroutines are cooperating and one abruptly terminates or panics? The underlying context that spawned both go routines will be canceled (because `defer cancel()` ) and then the other goroutine will stop at a good point because it also uses ctx. You don't just "cancel" a thread, green or full. Doing so makes it impossible (really hard) to reason about it.
But on a more serious note. If you're not doing an iterative loop in order to determine item index in order to remove said item then it seems likely that the language you're using is doing it under the hood in some fashion or other. All we're really doing in Go is elaborating on that logic and making it more obvious.
Honestly, as someone new to Go and really loving it, I also hope this isn't what happens with Go 2. As others have stated, I would probably go to C# for everything listed here...
A fair point. The logic above is obviously only useful if you know your indices but in terms of optimisation it's not a bad pattern. You could just as well do: for n, p := range a { if p == condition { a = append(a[:n], a[n+1:]...) break } } It would certainly be more efficient than re-allocating an entirely new slice that simply iterates and omits the item you want to exclude.
neat project. i'm curious, what purpose does `csprngMutex` serve? similarly with `unsafe` instead of just reslicing the slice?
Hey, this is actually really cool! I think the reason why almost nobody noticed is that the title "Introducing WDTE" says almost nothing. Link to the GitHub page also helps.
&gt; Hey, this is actually really cool! Thanks. &gt; I think the reason why almost nobody noticed is that the title "Introducing WDTE" says almost nothing. Yeah... Unfortunately, I can't change the title. Ah well. Now I know for next time. &gt; Link to the GitHub page also helps. Good idea. There's one in the blog post, but I can put one in a comment, too.
[GitHub repo.](https://github.com/DeedleFake/wdte)
This would allow you to detect if there were any errors, but not to correct them. Berlekamp-Welch allows you do detect and fix errors up to the threshold defined by the number of extra chunks you get.
I'm a most of the time go developer, and it's been the main language I've been using at work for the last 18 months. While it's possible to get by without them, I definitely miss having higher kinded types and paramedic polymorphism. I'd also really like support for parametric interfaces. Simplicity is a great goal to strive for, but adding features doesn't necessarily mean losing simplicity as long as the semantics of the language are consistent and the features are baked in. Much of the argument against generics feels like the typical arguments of blub developers against useful features higher up the power curve than they want to learn or think about.
Sure but if you can reconstruct the original data, you can regenerate the corrupted chunks. The B-W algo might have a smaller big-O cost, but likely more complexity. I was wondering about the real world implications.
Go is a reasonably thin abstraction over the machine too. Many things about C are true in Go; for example, you can reason about how structs, arrays and such reside in memory, and you can lay them out in an advantageous way. Slices and interfaces are just small structs, internals of which are hidden from you for type-safety. Also, I would like to state that I hate it when people think "that I like" and instead type "modern". What next, elegant? Go straight for artisanally crafted, while you're at it.
Yes, “validating input data in application” is the original intention, but it's also ok to use this library in testing if it works :-)
&gt; The compiler and the standard library do. There's currently a lot of special magic being done on behalf of the few containers and builtin functions being provided by the compiler, Yes, there is. But it's 1) probably less than you think 2) often needed anyway, because e.g. map is pretty well optimized on that level, and e.g. `append` is more of an AST transformation than a function 3) as a whole *simpler than implementing generics would be*. Please please please consider the idea that doing it this way was an explicit trade-off.
So to focus on what we agree on - I agree that the primary consumer of logging is the developer, where the data is ephemeral. But I think that the above information would be very useful to a developer in the same system that handles their other logs, and an impediment not to have them in the same system as other information. I'd be happy to treat it as "big data" for business analytics as well, but I'd rather give developers one system to look at and analyse the differences in application behaviour between this week and the last, and almost all centralized logging systems handle structured logs (particularly json) well. To me, there is a single system, the log system, which is intended to provide an ephemeral store of a certain moving window of information from a system, with the primary consumer being the developer. Some information may be fatter - like request / response summaries, messages from the queue, work started as a consequence of time our outside conditions... these things provide bookends to the stream of thinner events, almost all of which (in a suitably concurrent system) must have at least a context identifier in order that you can read and track a single logical sequence of events. It's possible that this view is shaped by having spent years with access to Splunk at various places, which tends to spoil you for what you can do with the queries compared to some of the alternatives.
An observation: the macOS installer grew from 94.9 MB to 97.5 MB between RC 1 and RC 2. That's a 2.8% increase. I wonder what changes it's related to.
Auto-generating schemas from tags for migration is really a good idea! As you have mentioned, this should be implemented in an independent package, and it's not that hard. I would like to encourage you to create one if you are interested :-)
I don't know what other answer I should have expected for an open source project. :) We'll see if I get enough itch-scratching time to convert one of my project's currently tagged validator setups over.
 Have you checked out Robert Martin's 'Clean Code' [book](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882/ref=sr_1_1?ie=UTF8&amp;qid=1502160024&amp;sr=8-1&amp;keywords=clean+code) and/or [videos](https://cleancoders.com/videos)? I've found Martin's material to be very helpful in actually identifying the attributes of clean code (and conversely, code smells). His examples are all in Java, which would be good for you, given your Java background. Despite his focus on Java and OOP more broadly, I think the fundamentals of clean code are language agnostic and there is plenty of carry-over to Go. He starts with rules around naming things and moves all the way through higher level design principles. Fair warning though -- Martin goes totally overboard with props, green screens, theatrics, and astronomy history lessons in his videos. The book is more concise, but I'm a better visual learner, so after reading the book I started going through the videos. 
[removed]
Can you elaborate? When you accept a context you have a variable passed in that clearly notifies your code to cancel. If you had for example the reader interface where would this signal to cancel come from? It would end up looking/feeling very similar to a recover I suspect, but I'm not sure. It might also be odd in the sense that in the SQL package it is clear which functions support cancellation, but if this is more of a global thing I'm not sure how a function could signify, "yes, this func supports cancellation". I know not all funcs that take a context do but it is often a helpful hints that it may. Ps - I'm not opposed to your suggestions but I'm trying to understand alternative options a bit better.
 &gt;but what I definitely don't want is what happened to C++... Lots of keywords introduced over years to try to describe and work with types. I don't think anyone really wants a C++ repeat, for any language really. A lot of game engine programmers sigh and accept it because that's the standard. I use C++, but my C++ isn't as modern as it could be, and avoids a lot of meta language features because the project I'm working on has never used them and I won't have a reason to really learn modern C++ until I'm finished with it. I can tell you that it's not really something I'm stoked about. C is much nicer, and far more elegant. But C++ provides very key features which make it still worth investing in, and it's prevelant everywhere. C++ is a lot like JavaScript in that sense: a language a lot of people love to hate, but accept using because it's still the most sane choice for the given domains it's being used in. 
Looking forward to no more of these: fatal error: concurrent map read and map write mutex all the things! Edit: only on Reddit do you get downvoted for cheering for a new language feature that solves actual problems in real code. Edit2: I'm really getting tired of defending concurrent maps. If you don't want to use them, you don't have to use them. Find a better hobby than downvoting people who use language features you don't want to use. I recommend fishing.
I like the idea that it's automatic by default (does checks in the same code that does voluntary task switches) but if a function contains manual cancellation handling at all, it has opted into being a completely manually managed function.
It's definitely a fair criticism to say that "modern" isn't meaningful, so here's what I mean. In my opinion, a type system is modern if it has: * ML-style sum types, a.k.a algebraic tagged unions, and allows pattern matching based on sum types and values. Go **does not** have this. * a non-inheritance system that allows grouping types by behavior. Go **does** have this, and makes a major advance among mainstream languages by having ad-hoc interface fulfillment. * compile-time type-multiplexing code generation (a.k.a. monomorphized generics) constrained by the system mentioned above, both in data (i.e. structs that have a generic field) and in behavior (functions/methods with generically-typed formal parameters and/or return values). Go does **not** have this. I called this "modern" because many recently created languages provide all of these features without being otherwise bloated, while few older languages do.
&gt; function/closure from JavaScript (._. )
csprngMutex just prevents multiple people from reading from random.Reader at once. I wasn't 100% sure about whether this was needed, but there was a nasty recurring crash a while back and that seemed to fix it. And unsafe is pretty much used where I want to avoid making a copy of the data, or I'm doing some pointer arithmetic.
if `rand.Read` isn't goroutine safe you should definitely file a bug report (or run with `-race`...). i didn't take too long of a look at the pointer arithmetic (so, sorry if comment is blindingly obvious :-), but could you do the same pointer arithmetic with reslicing? afaik some platforms like GAE don't allow `unsafe` :/
I'll have a look at that bug again. Hmm, I'll look into it. I'm using pointer arithmetic as a "clean" solution to accessing the start of the related memory, memory *before* where the slice is. I could probably store the entire memory in its own slice cheaply, but it isn't as clean. But I'm not sure if it's worth it. Doesn't GAE also remove syscall? I'm not confident in it working on the platform at all. But if you're confident, drop me an email and we can try and test it.
&gt; I'd submit that maybe it's time to reconsider the argument against goroutine-local data. I'd be interested to know what those are. To me, goroutine-local data seems like being literally the best of both worlds; allowing the benefits of context.Context, while being type-safe and performant…
I saw an interesting comment on one of the issues tracking this: https://github.com/golang/go/issues/20282#issuecomment-320842211
&gt; In such cases, it can be kept within the HTTP requests It is. Via context.Context. And *any* such mechanism is functionally equivalent to context.Context, just that the latter provides a universal interface to it. &gt; The reason why Context spreads to libraries outside HTTP requests themselves is cancelation. Not really. At Google, pretty much any IO requires context, because basically nothing happens without involving the network. It is very much intentional that context.Value exists.
&gt; The fact that it's useful doesn't mean it has no downsides. And I'd argue that the fact that `context.Context` was written, published *and* put into the stdlib, means that it has been widely accepted that the benefits outweigh the downsides. Now, IMO, instead of arguing to drop `context.Context`, we should talk about how to eliminate the downsides. And TLS is the answer to that. &gt; Regarding goroutine-local storage... I don't think that's a good idea. Why? You are making this broad assertion in your post, but seems pretty unfounded to me. What are the specific arguments here? &gt; I think the right solution would be a language provided cancelation mechanism (probably non-preemptive). You are outright disregarding the importance of `context.Value`.
Difficult to say what is idiomatic here. IMHO, as you are using gocraft/work, your code first and foremost has to follow the patterns/idioms of the gocraft/work API (on which I cannot comment as I am not familiar with it). 
ah yeah, you're right they do remove syscall. maybe i'll fiddle with it this weekend. anyway, i appreciate the library—definitely going to be taking a look into using it!
&gt; If they had, I would not be able to spin up goroutines as casually as I can do right now. Why not? You are already creating several K of a new stack and copying over a bunch of state; adding a pointer or something to that wouldn't hurt… Honestly, to me, the existence of context.Value conclusively proofs, that we really want some variant of GLS…
True, but the thing is I wanted to abstract the API so that I could decouple my application from it, making it easier for testing. Right now I would have to mock out the `*work.Enqueuer` somehow if I did not want tests to depend on redis.
Another small problem of context is that it's values are like global variables. It's an open door to bad programming. I don't use context because I don't understand how it works and should be used. It's not trivial and not least surprize like all other Go features. I'm writing a server with persistant connections a tree of goroutines. I can confirm that handling correct canceling and termination of these go routine in case of error makes the code unpleasantly complex. I fully agree with the OP that we need a solution and a better one than Context. But I have no idea how we could do it better. 
If you are willing to spend some money I can recommend www.usegolang.com made by Jon Calhoun he is on here as well you can watch the first chapter for free and see if I its something you like :) he is running a dedicated slack group for the course as well great guy 👍 
Context.Context is not idiomatic because of the stutter.
That is exactly one of the problem of Context. It transgress the [single responsibility principle](https://en.m.wikipedia.org/wiki/Single_responsibility_principle).
**Single responsibility principle** The single responsibility principle is a computer programming principle that states that every module or class should have responsibility over a single part of the functionality provided by the software, and that responsibility should be entirely encapsulated by the class. All its services should be narrowly aligned with that responsibility. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
&gt; www.usegolang.com I just visited the site. I swear he hit all my frustrations on the first few paragraphs! I'm definitely going to give this a shot. Thank you so much for the recommendation!
Then look forward to panics caused by bad type assertion :)
You don't automatically get better programmers, but on the other hand, by excluding some constructs that are commonly abused you can guarantee that you'll never come across them in a code base. I wouldn't abuse operator overloading, and I'd like to think that I work with people that wouldn't, but I read code by people that are not me or people I work with, and it's nice to be able to jump into a code base confident that + means + and not something else because someone made a bad decision at some point. If you weighed the convenience of being able to use operators to execute some custom code against the inconvenience of not being certain of what an operator does in a particular context, I think the former would fly off the scale like a carcass off a catapult.
Actually he should. His AddContext function works as a middleware and using WithValue is one of clearest solutions. Author of article you've mentioned said that he wasn't working with servers, so his opinion about context is biased. Second article on the other hand is good, there's way too many different routers.
`man 3 printf` if you're on a Unix-like development system
Yeah I've read Clean Code though maybe not slow enough. It was actually the book which got me started to try to formalize the way I think about design. Maybe I should just revisit the book and try to get one of my old projects and try to re-do it. It is a pity that the videos are rather expensive for students but it's understandable, everyone's gotta make a buck somehow^^
Well, the only guaranteed end result there is a huge loss of body fluids :D
This is a good thought, the only problem I see here that the quality of your result is always limited by your own horizon in terms of design capabilities. What I mean is, that if there is something you do not know how to do right or worse do not even recognize it might be bad design you will not discover it either.
Aiming for testability is probably one of the key things I learned since I started out with go. In my former company all testing was done by hand and no Unit tests were required which also meant that I was not forced to structure my code clearly and just had a 'code and fix' approach till the end result was ok. I think that you should always do at least some planning or be really proficient at refactoring. Would you agree?
Love your shows!
This is a typical use case for interfaces (like you already did with Job/Dispatcher). If you create an interface for the Enqueuer struct, you then can write a mock Enqueuer to substitute for the real thing. (It just seems a bit difficult to come up with a good name for the interface, as "Enqueuer" is already taken by the struct. Usually, names ending in "-er" should denote an interface rather than a concrete data type.)
So what does creating an interface for the `Enqueuer` struct mean? Would that interface (say `EnqueuerProvider`) have to specify the same methods currently implemented on the struct? Apologies for the stupid sounding questions, things are a little confusing right now :)
&gt; It is a hugely useful mechanism for achieving the ability to pass out of band data through the call stack without requiring that every method deal with it explicitly. This sounds a lot like what aspect-oriented programming is meant to solve. Gah I dislike seeing context passed all through the call stack. It's an untyped grab bag with multiple responsibilities that makes code far more difficult to understand. I really dislike context.
Yes, that's the point. Your functions can then accept an `EnqueuerProvider`interface instead of an `Enqueuer` struct. Then you can write your `MockEnqueuer` with all methods required to satisfy the interface, and use this one instead of the real `Enqueuer`. [This blog article](https://8thlight.com/blog/javier-saldana/2015/02/06/loose-coupling-in-go-lang.html) provides a good, brief overview with an easy example.
Operator overloading is great for linear algebra though, especially when doing vector calculations. I find in practice that people hardly ever abuse operator overloading to that extent, and that sort of thing should be caught by a code review anyway.
What are your thoughts on `err` checking then? Surely something try/catch is "meant" to solve?
Thanks for that link. That explained a lot. But wouldn't it become cumbersome to define interfaces when they have a lot of methods?
Sweet. I bought two so they're not alone. ;-)
In Go, interfaces tend to be small - very small. The most famous examples perhaps are the interfaces in package `io` that contain one to three methods, like `io.Reader`, `io.Writer`, `io.ReadWriter` etc. This is indeed part of the philosophy behind Go's interfaces. And since interfaces in Go do not need to be [preemptive](https://medium.com/@cep21/preemptive-interface-anti-pattern-in-go-54c18ac0668a) (that is, you do not need to define them in advance), you are free to pick the methods you need. For example, if your code never uses the "...Unique..." methods of `Enqueuer`, you can define an interface with only `Enqueue` and `EnqueueIn`. An `Enqueuer` would then still satisfy the interface.
I am open to accepting that ctx.Value is useful, but there are downsides. The main one is composability. When functions depend on an implicit context, such as global variables, their thread ID, or context.Context, it makes it harder to arbitrarily compose them together. Composition is one of the main ways of achieving flexible APIs. But perhaps this does not apply to ctx.Value, but I'm not convinced yet.
It is not kept within the HTTP requests themselves. It spreads to databases, and other libraries and some proposed to spread it into io.Reader/Writer, etc. And why is context present in `"database/sql"`? Values? No, cancelation. Why did people propose to include it in `io.Reader`? Values? No, calcelation. I'm pretty convinced, that cancelation is the reason why context spreads. For values, context can be kept as a simple inferface with a single method: `Value`, which would work same as now. A context like this would not need to spread anywhere, it would probably not even need to be in the stdlib.
Ah the preemptive part makes it pretty cool. Thanks this helped a lot. I've begun writing some basic packages for storing a job in the DB before dispatching it. I will have to read up more on interfaces before moving to writing tests for the same.
&gt; It spreads to databases, and other libraries and some proposed to spread it into io.Reader/Writer, etc. Because it's needed there. &gt; And why is context present in "database/sql"? Values? No, cancelation. Are you sure? Google Cloud SQL uses `database/sql`. I am not entirely familiar with the implementation, but at least if it uses a grpc API I would, a priori, assume that it might put some request-specific authentication info into the context (because, at least internally, it is possible to make requests on behalf of other users, so there is request-scoped auth). I would, at the very least, be very careful to rule out off the bat, that there is *any* sql driver that uses it for more or would be interested to use it for more. &gt; Why did people propose to include it in io.Reader? Values? No, calcelation. That might or might not be the reason to propose it, but what I *can* tell you, is that all Google-internal file-IO requires a context not primarily for cancellation but, again, authorization and more. Because approximately all files are accessed via the network and fine-grained auth is needed. This leads to very awkward code, because all the go stdlib IO doesn't use contexts, so weird workarounds are needed. &gt; I'm pretty convinced, that cancelation is the reason why context spreads. Context spreads, because it is important to have a unified way for cancellation *and* to pass data through unrelated APIs. It was never a coincidence, that both are in the same package. Just outright discarding this use case, just because *you are not using it* is unhelpful. &gt; For values, context can be kept as a simple inferface with a single method: Value, which would work same as now. How would that help, at all? You would still need context in any single function, just like before. Just that now, you are removing the one use case that *is* implemented well by it and moving it instead into a language feature. Without any real benefit. It makes more sense, to instead move the `Value` part of it into a language feature. With TLS/dynamic scoping, cancellation is trivially implemented. Whereas an efficient and type-safe version of `Value` is not possible without compiler and/or runtime support.
Where do I buy one
[Presented without endorsement](https://groups.google.com/d/msg/golang-nuts/fOGYNEKLZ4w/Cb5D1ea22-gJ). I don't disagree that thread-local storage is sometimes risky and has been abused in the past, but I think that issue is fixable with a community consensus of "use this as a last resort, not a first". It's just that I rate the global variables I've had to use as already worse than that, and, again, if we were seriously considering slathering context.Context into the dozens of places in the standard library and the unbounded number of places it belongs in the other libraries, I'd call that unambiguously far worse than thread-local storage. (And if I may say so, I _reeeeaaaalllly_ don't like global variables and I'm fairly decent at avoiding them. I've clocked a lot of time with FP and passing extra context parameters doesn't really bother me; I was passing around ["environments"](http://www.jerf.org/iri/post/2929) since before context.Context was public, or possibly even existed. So if I'm using globals, it truly was a last resort, it's not just that I was too lazy to do the right thing.) I'm also, to be clear, open to other solutions that may present themselves; I just have no idea what they may be. If someone presents one, I'll give it a fair shake (but bear in mind a "fair shake" may be a substantial listing of issues with the proposal, which is really the default situation here including for a thread-local proposal; such is the nature of this sort of change).
&gt; The main one is composability. When functions depend on an implicit context, such as global variables, their thread ID, or context.Context, it makes it harder to arbitrarily compose them together. This seem completely counter intuitive to me; the exact *opposite* seems to be the case. HTTP middleware that uses `func(http.Handler) http.Handler` is infinitely composeable, exactly *because* it can use the request-context to pass data down the stack implicitly. A middleware I write does not need to know or care about data your middleware injects into the context, because it will just transparently pass it on. Even `http.Handler` itself is a perfect example of that; the `ResponseWriter` contains additional, optional behavior not expressed in types. If we would have instead different types for each class of `ResponseWriter`, you couldn't use a `http2.ResponseWriter` with a `http.Handler` and vice-versa. Putting non-essential information *outside* of strict type information is what *enhances* composability. And if the data/behavior is *not* optional, but indeed required further up the stack, you already have the restriction of needing the provider and consumer of the data together. So a lack of composability is problem-inherent in that case (but it's also not what context.Value is meant for). (Ab-)using `context.Value` in that case is the only thing that makes such a case even *possible* in the first place.
Good thinking, think I need to do the same so my gopher doesn't feel lonely when I leave the office =)
bought mine here https://gopher.golangmarket.com/
Of course the golang market is a thing
I think that thread agrees, that the introduction and spread of context should lead to reconsider TLS, then. I've been considering it to be strictly worse anyway. FWIW, I was planning to write down how *I* would imagine that to look before all of this discussion started ^^ So I'm fairly amused by the debate and that I'm not alone in my conclusions :)
Well [hello there](https://goo.gl/photos/cK6R4sWCHr465EXd7)!
So, there are three important concepts here: 1. Errors 2. Exceptions 3. Conditions (as seen in Lisp) Bad programmers can abuse all three. And it seems one of the arguments against exceptions in Go thus far has been that bad programmers will abuse them. Fair enough, "protecting" the average programmer from their self is in Go's founding DNA. See [Go at Google: Language Design in the Service of Software Engineering](https://talks.golang.org/2012/splash.article). **Errors and Exceptions** Exceptions have their place and they are extremely useful. They're simply misunderstood. Even Rob Pike misunderstands the purpose of exceptions, as written in [1]: &gt; First, there is nothing truly exceptional about errors in computer programs. For instance, the inability to open a file is a common issue that does not deserve special linguistic constructs [...] That's a half-truth... you see, the purpose of exceptions are to signal a breach of your **invariants**. They mean you've entered an inconsistent state. So if a piece of code or structure or package *depends* on a specific file being present that it cannot possibly operate without, then for that file not to open is a violation of its *invariant*, thus it *should* throw an exception signaling as such. Good programmers understand how to design with invariants. If a piece of code may need the network but it's not an invariant, then you report an error. If the network being reachable is an invariant, then you report an exception. Invariants are part of your software's design. Errors and exceptions both have their place. **Errors in Go** When you write code that uses errors for what should be exceptions, then you'll find yourself checking and forwarding... checking and forwarding... all the way up the call stack. And in an N deep call stack with say an average 3-way branching factor, then you're checking and forwarding 3*N times. It's just noise. Panic/recover is plain clunky (on purpose) compared to first-class support for exceptional error handling. In fact, I'd love to see an analysis on what percentage of the time Go programmers actually *work* with a returned error, i.e., use it to respond in some way vs. simply printing/logging and forwarding. I'd bet forwarding accounts for a large percentage of all Go error handling code. Error checking adds a lot of noise most of the time and Rob admits as much: &gt; Although in contrast Go makes it more verbose to check errors, the explicit design keeps the flow of control straightforward However, I can't agree with the assertion that error checking forces programmers to think about and deal with errors anymore than exceptions do. &gt; Explicit error checking forces the programmer to think about errors—and deal with them—when they arise. Exceptions make it too easy to ignore them rather than handle them, passing the buck up the call stack until it is too late to fix the problem or diagnose it well. It's all too easy to forward errors up the call stack. Not to mention, Go has plenty of warts around errors that make working with third-party code a pain sometimes, when the code doesn't follow good practice. See my [previous comments](https://www.reddit.com/r/golang/comments/649o0c/syncx_go_library_that_extends_standard_sync/dg0neoo/?st=j63k65xr&amp;sh=4d6b26f2) on that matter. **Bonus: Conditions** Now, I absolutely don't expect Go to ever support this and that's fine, but conditions are cool! The idea is that the *site* that throws the exception has the best context available on how to return to a consistent state. Thus along with an exception, it throws a list of available options for the exception handler to choose from. The exception handler will choose which option to respond with, and then the *site* of the thrown exception will restart and proceed forward -- using that option -- to return to a consistent state. [Beyond Exception Handling: Conditions and Restarts](http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html) is a great article on the concept.
I mean this with zero snark, but honestly if you miss them so much why do you not just use a language that has them? You either must be really productive and enjoy the speed and simplicity and don't miss them as much as you think you do, or you will switch to language that has them and be able to pick up speed. It's a win-win either way.
may I ask what is that editor or theme ? also why there is `json: "name"` for every field ? and why you do rename them to small letters ? edit: looks like vim, right ? 
are you using ctags / tagbar in vim there 
vim indeed, you are correct. using elflord colorscheme
you have a good eye, I'm using vim-easytags and tagbar plugins and nerdtree of course :)
One can make an argument about what "should" be. In the meantime, this feature is invaluable and has made effective logging really easy for me.
It's a fair question, but the answer is simply that the tech market I'm in (Midwest) doesn't have a lot of opportunities to work with languages I like. I like the people I work with, and the company is very kind and treats us very well. I'm slowly working on getting other people on my team comfortable with other languages, but in the mean time Go is the lingua franca of the team and it would be irresponsible to just go off and write things in e.g. haskell when nobody else knows it. Blub languages tend to be gravity wells for exactly this reason- being in the middle of the power curve and not particularly interesting, they tend to be the language that the most people on a team happen to know. Teaching people a new language (and new way of writing code) takes time, and a lot of trust from your team in order to get buy in from them to learn at all.
My eyes are dying, please gofmt your code!
I should look into that tagbar thing Seems helpful
A [plush gopher debugging buddy](https://en.wikipedia.org/wiki/Rubber_duck_debugging), more like. Getting one for myself now!
**Rubber duck debugging** In software engineering, rubber duck debugging or rubber ducking is a method of debugging code. The name is a reference to a story in the book The Pragmatic Programmer in which a programmer would carry around a rubber duck and debug their code by forcing themselves to explain it, line-by-line, to the duck. Many other terms exist for this technique, often involving different inanimate objects. Many programmers have had the experience of explaining a programming problem to someone else, possibly even to someone who knows nothing about programming, and then hitting upon the solution in the process of explaining the problem. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
I had a couple from two different Gopher cons, they were popular with others on the team and have since disappeared. I'm going to pretend they burrowed their way out in to the world and are now happily prepping for the long winter ahead. 
plush gopher debugging buddy....that's freaking brilliant! 
When he decodes Json into structs the naming is in camel case so he needs to provide the name to map from. (Source: my limited Go knowledge)
Of course. But if go had generics, we could make a remove function which does that. That is what abstractions are for. 
That seems optional, you don't have to assert the wrong type.
Ooh... I might gopher two.
The [database/sql](https://golang.org/pkg/database/sql/) package provides you with a connection pool that handles this stuff for you.
I would simply set `tls.Config.ClientAuth` to `tls.VerifyClientCertIfGiven` and then access(&amp; verify if needed) `TLS.PeerCertificates` on your `*http.Request` in your /login handler.
Yes, it's important to try to structure your code in a way that uses structs and interfaces (and etc) well, and some planning should guarantee that. When I say don't overplan I mean don't plan for what the library will look like next year before you've written any functionality-- it might turn out that because of a strict plan or lofty goals you give yourself you'll resist taking a smarter approach when a functionality problem comes up with the design.
Well we are talking about Go 2 and thus what "should" be is essentially the entire discussion.
I didn't downvote you, but I'm not really looking forward to the sync map because you almost always could use your own struct with strict types for better performance.
&gt; The vertical access is logarithmic access → axis
I really like the thorough unit-tests. Kudos!!
Me selling that plush here. One of the main reasons I sell the plush is so I can reinvest the money to build the Golang Market site (and be able to create other cool things in Go). The Golang Market site itself I think will be very beneficial to all involved. People can make money doing some cool things in Go, and others save a lot of time just buying creations. That is my vision with it at least. :)
In fact it is, you just use sync.Mutex as suggested in my first post. The new concurrent maps give you a method that doesn't require it any more. 
I haven't seen any benchmarks on it yet. Maps are generally pretty fast on their own, things get less clear when you have high lock contention on it. I've gone both ways on it, writing the mutxes to do it in a concurrent way, and also running a goroutine that owns the map and accepts work through a channel. Both work fine, but not having to do either sounds like a good option too.
In the benchmark I've written (which could be flawed), the sync map takes twice as much time as a map with a RWMutex around all accesses. If you'd like to try this out, it's here but it uses some libraries I wrote for randomized key/values and won't run in the go playground: https://play.golang.org/p/EAD4lCoiiy
If you care enough to be using this library, you shouldn't be running it on cloud hardware anyhow. If you're OK running it on cloud hardware, you don't need this library. Having a key stolen from your cloud hardware is probably one of the more likely vectors for attack. (And still very, very improbable. But more way more probable than, say, "I generate a key on my desktop and the NSA runs in, freezes my RAM, and reads it with an electron microscope.") I wouldn't even say "you shouldn't ever generate keys on cloud hardware" necessarily... just, be aware that it is a real tradeoff for convenience vs. security.
Unless in the future it somehow becomes typed like map, I think I'd still rather use RWMutex.
I just tried it (used to use it with c/c++). vim works really well with golang. 
As an individual (rather than a large game studio), after 4 years of trying to push Go to its limits where the GC would prove to be a show-stopping problem, I've failed. In practice, I feel like you can have better average performance because with Go, it's quite feasible for 1 person to write a concurrent game engine that utilizes more CPU cores rather than just the one. Doing the same with C++ would require a lot more of your time and other resources, and you'd probably never get around to doing it. Some little hobby games I've been working on so far: - https://github.com/shurcooL/Hover#readme - little 3D hovercraft racer (not finished) - https://github.com/shurcooL/eX0/tree/master/eX0-go#readme - little 2D tactical shooter (not finished) All of them run at steady 60 FPS easily even on old hardware, without me doing much of optimization yet. So yes, if you enjoy the language (which you should), I wouldn't be afraid of using Go for building a hobby game. If you care about performance, Go gives you great tools to write high quality, performant and readable code, it's easy to refactor, and easy to put all CPUs to work. The GC is not a bottleneck. Maybe it would be if you're building AAA games (but maybe not, no one has tried yet).
Generally when I hear about high performance I think about c/c++, but c shouldn't be used for everything. If you're interested in graphics, games and so on, you can try faiface/pixel who's a very well mantained go library that has a lot of features or go for sfml/sdl in c. I've worked with all of them and tbh, SFML seemed to be the easiest to use and has great documentation as well;)
Depends. GC pauses are 100 microseconds at most, so they're not a trouble at all. High fidelity 3D games might be a problem (although I haven't tried). 2D games are definitely not a problem. Right now I'm doing real-time audio processing with my beep library and it goes just fine (and I do decoding, encoding, resampling, 3D audio, and samples are in float64, everything on-the-fly).
That's pretty impressive (especially the hover port). I realistically wont be doing anything AAA or advanced than the hover port so it's exciting to see Go work well. How about cross platform support? Do you think it would be easy to have your game run on multiple platforms or would I need to compile separately on the machines I want to support?
Careful. They multiply like rabbits.
You definitely will need to compile separate binaries for different platforms, that's just how Go does compilation. Most Go game engines use OpenGL, so the presence of that platform support is usually taken for granted.
Right, but then it also requests the client cert for /. Maybe it's not a big deal, but feels a bit unpolished to me.
http://vimcasts.org/blog/2013/01/oil-and-vinegar-split-windows-and-project-drawer/ don't know if you've seen this, but it convinced me to swap away from nerdtree.
has he? i trust rsc, too. honestly my biggest fear is that they feel compelled to listen to the community too much. too many cooks and all that.
Slice operator creates _new_ slice, but as you observed it, it doesn't copy underlying array.
We'll see. It's a first revision, and there will be no shortage of people wanting better type safety.
Hey! Another great show. That nano stuff had me cracking up. Here is how to set default editor: export EDITOR=vim
yeah, this is the fun side of using a freshly created VM :)
&gt; would I need to compile separately on the machines I want to support? You would need to compile separate binaries, but, depending on the amount of Cgo used, you might not need to actually have access to those platforms in order to compile for them. Go's cross-compiling support is pretty darn good. For example, to compile for 32-bit Windows, just use `GOOS=windows GOARCH=i386 go build`, assuming Bash syntax. That'll work on anything if there's no Cgo. Edit: Actually, since there's some Cgo usage in the standard library, that might not work. You might also need `CGO_ENABLED=0`.
It does. Usually people that work on small projects don't see a need for exceptions -- or other formal techniques like enforcing/documenting/reasoning about invariants. Rightfully so, I might add. So, I was just curious whether my initial hunch was correct.
And the second chart has an unlabeled Y axis, with the title roughly where you might expect the axis label to be, so it looks like a Threads to Threads chart..
That's assuming it'd be used for keys, though, and I agree—that'd be a bad choice. Without having tested it and its overhead, I personally would use this in places where I'm already zeroing out buffers. 
Haha...that eX0 screenshot on github... solid de_dust remake ... :)
Me right now: https://www.youtube.com/watch?v=Ccoj5lhLmSQ
Do you use GVim or in the console? I'm struggling to get the colorschemes to work in the console as it only has 256 colors.. =/
The TLS connection is established before any HTTP requests are made, so there's no path information yet... you could try a subdomain instead.
http://www.informit.com/store/ultimate-go-programming-livelessons-9780134757483
Go has excellent performance with GC and calculations in general. Using it for years for some heavy load professional work I can say for certain GC or CPU/memory usage will not be your problem. But there are some cold hard facts when it comes to game programing. First, graphic quality will be as good as with other languages as this is done by graphic hardware/libs and depend on modeling skills, shaders etc. not the programming language. What is important is that OpenGL and most of high end graphic libs are C only. Go's way to use them is via CGO (which is like a wrapper to cal C functions). There is serious downside: each CGO call currently has ~100ns overhead per call. *Meaning - all these Go graphic libs that communicate with underlying C libs using 1 to 1 CGO wrapper calls (and most of them are like that to my knowledge) are not good enough for high intensity work.* For simpler Go games without lot of C calls, like https://nnm.itch.io/block-pong this can work nicely. But once you move to more call intensive games, that make 1000s of C calls per second, you have to get creative to reduce number. If you don't, your time per frame will suffer. Eg. 50000 C calls per second will incur 5ms/sec of overhead only. That is dead, unused time in main loop. High end games have *a lot* more calls per second than that. There are ways to circumvent that problem. One is to use batch calls, or handle data Go side then pass it to C functions. Other way is to use gccgo which is alternative Go compiler (with GCC as backed) that has no call overhead due to different GC/linking. Both solutions add extra complexity and require more knowledge and work. Is it worth it? IMO yes, if you are interested in simpler / indie games. Go is great language with lot of qualities. Working in it, compared to C++, is far more productive, even with this limitation. But as is, Go still lacks rich dev environment for games compared to C++, Java or C#, which will hopefully change in future. 
&gt; I might have misunderstood the data component, &gt; does it store data and run the database process or &gt; is it a component that provides an API which in &gt; turn calls the database in a separate persistent &gt; container? It is the second one. There is always an owned API between the actual database and business logic. I think the database, logic, static UI Container approach is a good choice for abstraction. This also worked very well in my experiences. Scaling individual parts can be cool if different parts of the SCS need different resources. If a Microservice has very intense CPU usage we could decide in scaling just this one Microservice and spread the usage over the cluster. The other services should not be adapted in this case. Horizontal autoscaling is also a good Choice, where the scaling of persistent containers could be a bit hard. I think up to 5 hops are okay. For sure the latency between the cluster Nodes should be very low (&lt;10ms), but using data efficient protocols (like protobuf) and reducing the amount of calls can also boost the performance. Generally we also have the option to split an SCS up into two if the performance problems can not be solved with simple scaling. :) Performance testing is not an easy topic. We write these SCS for real people and can’t say how they will actually behave or how many of them will use it simultaneously. For the day X where an application will be used instantly by many people we firstly use the Kubernetes scaling and monitoring possibilities. But for now we saw no real big performance issues. It is impressive how low the Kubernetes performance overhead is for the container orchestration. I guess we could extend the blog later on with deeper performance insights. :) 🙏🏼 
Well spotted. ;)
I have yet to dive into this myself (I want to run a remote command to dump database and download the dump for practice) but have not done anything thus far. I've found http://blog.ralch.com/tutorial/golang-ssh-connection/ article very useful as well as https://stackoverflow.com/questions/38242598/golang-scp-file-using-crypto-ssh
&gt; How about cross platform support? It's the best I've ever experienced. Specifically, just because they're written in Go, both those games I mentioned can run on: - macOS - Linux - Windows - Browsers (on macOS, Linux, Windows, iOS, Android)! - (with additional work, not yet) iOS, Android The three big OSes are supported by standard Go compiler. You do have to compile binaries, since Go is a compiled language, but that is not hard compared to the effort of building a game. Browser support can be achieved via GopherJS compiler. You can try (an older build) of Hover in browser at: https://dmitri.shuralyov.com/projects/Hover-Demo/ And eX0, with multiplayer support (try opening 2 tabs), also runs in browser: https://dmitri.shuralyov.com/projects/eX0/eX0-go-client/ The OpenGL API is implemented via WebGL in browser, and networking is done via websockets.
Nailed it :) The struct vars need to be exported so you camel case em, The lowercase part on the right is the name of the json field that will contain the data. It works the same way with xml but you would use `xml:"attribute"` and of course import encodings/xml
Ahaha that is exactly what I'm using, the first link. I'm using his code, and I get stuck because the target server seems to return a "banner" and I have no idea what it is.
That is a good point. I think I do not have this issue because I assume any code I write is wrong/antipattern unless I can point to a reason for it to not be. This assumption means I always have something to improve.
just plain console vim. yeah depends on how fancy you want it to be, I played around with the solarized colorscheme before, but could never get it to work satisfactory. I use the elflord color which is provided out-of-the-box and it fulfills my needs at least
agreed, also the vim-go plugin is simply awesome. nothing beats vim as an IDE for go 
Technically, you can just ignore it and return from processing the message (proceed to next step). That's according to RFC. Presenting it to user is optional.
Spent quite a lot of time on that hover game. It performed pretty well for being on the web.
Sounds great for what I aim to do. As for the CGO call being ~100ns, is there a chance of this improving? (not that it's that bad)
They are improving it, Go 1.8 has it halved compared to 1.7. But there will always be some overhead as Go and C are different worlds (stack, threads etc. issues).
what I found out is, when trying to authentificate, it get a return banner, but it should also receive a lsit of remaining authentification methods to try, but I don't. I can't get to publickey (my auth type) authentification because before this I get a banner and no return auth type.
New concurent map solves race condition errors but at the expense of type safety. Imagine you buy a new car and it's missing front left wheel. How would you solve it? By taking out front right wheel and putting it in the front left position? No, of course not, but this is exactly what sync.Map does.
http://i.imgur.com/GOh8Irz.jpg
error is an interface. nil is a value. im not a fan of a bunch of shortcuts, I already hate the ones the language already has.
I mean, you can make that argument that race conditions and type safety are both valid issues and of equal importance to you, but you're suggesting that not having both results in something unusable. I'm sure you can determine for yourself when you want to compromise on one to have the other, or if you want to just write a wrapper around maps to have both. Nobody is taking your wheels off, you're getting an option you didn't have before.
Performance of Golang is not quite top-notch. It is on Java's level, ±
Are you following instructions from "SSH certificate file" section of the article and pass the respective config. Looks like maybe SSH server does not recognize what type of authentication you are trying to use. Using proper config should result into sending SSH_MSG_USERAUTH_REQUEST (http://www.faqs.org/rfcs/rfc4252.html) with "publickey" and TRUE, I believe. Ahh, and also if you are using the latest RC of `go`, you may need to set HostKeyCallback: ssh.InsecureIgnoreHostKey() in ClientConfig.
I didn't look at the code at all, but what happens if the message is something like: Cc: spam_victim@example.com, spam_victim2@example.com the message :-) Will this send emails to the addresses in `Cc`, or will it be part of the body? This is a problem with PHP's `mail()` function (which this seems to be modelled after) and commonly exploited by spammers to send spam using vulnerable webforms and such. It's one reason I generally discourage people from using `mail()`. IMHO A much better design would be to accept a separate `map[string][]string` (or Array in PHP) for the headers.
No problem, got a Minion too who's looking after them. ;-)
Of course it requires it; it's just hidden from you. I still hold that locking belongs to semantic actions, not in a single data type, and syncmap is likely to introduce a different class of bugs in naive code.
Looks like a + here: https://benchmarksgame.alioth.debian.org/u64q/go.html
Yep I had to add the insecureignorehostkey thing. The only thing that I differ, is that I had to add sshConfig.Ciphers = append(sshConfig.Ciphers, "aes128-cbc") Because my sftp server only have cbc ciphers.
So I got it to bypass the banner, and now I think my publickey isnt working. I will check what is happening with it. Thanks for helping me! :)
This is such a frustrating thread. It's fine, ignore the context (you know, having to do it in the lines of code you type myself). This whole discussion has devolved into brain melting sludge.
&gt; needs to provide the name to map from And the name to map to when encoding structs into JSON. Go use caps by default, yet I use lower case in JSON, so I need to map every field I want to write out. This is my main complaint with the JSON library, my second being that it's difficult to conditionally output certain fields (e.g. accept a password field, but don't include it in the JSON output).
I just watched a video of him on youtube and man can he get side-tracked
But still I found references that other servers are capable of this, like Apache HTTPd
Oh, yes... Using TLS renegotiation. It can be slow. But it is the only way to do what you want, I think.
I quickly put a Go application together to test it and got everything working. I am on Windows but I do use MSYS2. So I launched `bash` , used `ssh-keygen`, copied public key to Debian server I am running and put it where it belongs (added to authorized_keys). I did not configure a banner on my SSH server but the keys are working. I can run commands on the server. I think using `ssh` from MSYS2 helped generating proper keys. 
Unless you are heavy on heap allocation, you won't feel significant performance difference. You generally see 1-2x slower perf than gcc. Benchmarks game shows this trend quite well https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=go&amp;lang2=gcc. But there are ways of avoiding issues with heap-allocations. There's one other potential issue... heavy usage of C libraries. Last I remember, each C call has 50ns overhead (someone can correct me if I'm wrong). e.g. If you intend to heavily integrate with existing C libs, this might be problematic. I've tried to write real-time audio code in Java -- it ended badly... Go seems to handle it quite well for now. So there's that.
This sounds right, as per the GopherCon 2017 lightning talk by Bryan C Mills, who authored sync.Map: https://www.youtube.com/watch?v=C1EtfDnsdDs Note that the docs have been updated since sync.Map was first included in Go. They now state: &gt; It is optimized for use in concurrent loops with keys that are stable over time, and either few steady-state stores, or stores localized to one goroutine per key. &gt; For use cases that do not share these attributes, it will likely have comparable or worse performance and worse type safety than an ordinary map paired with a read-write mutex. 
Have you considered how many developers chose not to use Go due its lack of generics, exceptions, etc?
That's exactly what I needed to know, thanks!
Could you please point me in the right direction for a good go vim setup, I've recently switched to Linux and started teaching myself vim and I can somewhat see how vim would be better since I'm not a wizard at it yet and would like to know roughly what's needed to make it a vscode go killer so I won't miss that application when coding go and can force myself to learn more of vim's features. 
Just a couple of drive-by suggestions: - How about allowing to do the same thing that libsodium [allows][1] you to do, i.e. keeping the secret data page (not just the guard pages) as noaccess and then marking it as read or read/write only when needed? something like: buf.MarkAsReadOnly() defer buf.MarkAsNoAccess() - Adding automatic finalizers so that the "off-heap" allocations can't leak (same thing that is done for e.g. file descriptors...). This wouldn't replace (as it doesn't for FDs) the need to call Destroy() explicitly. It would boil down to call something like the following at *LockedBuffer creation time: // ideally the finalizer should be on an internal field, // for the sake of example brevity it's on the *LockedBuffer runtime.SetFinalizer(buf, func(o interface{}) { o.(*LockedBuffer).Destroy() }) edit: I just noticed your LockedBuffers slice. It complicates things a bit but it's still doable [1]: https://download.libsodium.org/doc/helpers/memory_management.html
I tried a few things ... I figured the assets part, but still can't build a binary with the sdl2 libs shipped inside it ... https://github.com/topheman/gopher-ball/pull/1/files
Oh another thing: you may want to look into madvise MADV_DONTDUMP to avoid having to completely disable core dumps for the whole process. (core dumps may be disabled by default, but it's one of the things you enable when troubleshooting non-obvious crashes)
Thanks for submitting this! &gt; My post gives a straight-forward introduction to Serverless computing, then covers my top 3 features introduced to FaaS over the last 500 commits and finishes on what's coming next and how to get involved.
Go is pretty bad in allocations.
&gt; Have you considered how many developers chose not to use x because of y? No because I could spend an eternity enumerating those possibilities. Go is a different language. It's not Java. It's not C#. It's not Rust. It's not C++. It's Go.
Spending years in the software development industry is not very strongly correlated with practicing good design :-(
See https://github.com/g3n/engine and https://github.com/danaugrs/gokoban
Beware, most of the Design Pattern Cult is best left in Java-land.
First example has a race. Second example uses condition variables, which are notoriously hard to get right, unnecessary for most scenarios, and definitely not something you should expose newbies to.
See also https://github.com/gedex/go-imgplaceholder
See https://golang.org/src/runtime/alg.go and https://golang.org/src/runtime/hash64.go e.g. `strhash`, `memhash`
Our high frequency services are built in go and run beautifully
_Our high frequency_ _Services are built in go_ _And run beautifully_ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^itsmontoya ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haiku.
Fantastic job as always Francesc! 
 Read(ctx context.Context, p []byte) (n int, err error) Sort of unrelated to the main article, but a trick that apparently came from Google, and that seems to still not be widely known, is this: func (*m MyFileLikeThing) IO(ctx context.Context) IO type IO struct { ... } func (i IO) Read(p []byte) (n int, err error) { ... } Essentially, currying the context, getting back to `io.Reader` etc APIs. (Feel free to name the `IO` type something else.)
Goroutine local storage is the wrong level for per-request data. There are often multiple goroutines collaborating on fulfilling a single request.
Cool write up, but not sure your benchmarks are very useful if they were ran using the tests [here](https://github.com/dzyp/slice/blob/master/sort/sort_test.go#L70). You're just benchmarking the effectiveness of reversing an array using two different sort methods. In the first loop every key is less than the previous key, you then reverse it causing identical properties. This means your testing a single permutation of this length which is 1m in your test, which the total permutations for the start of a sort state (math nerds can correct me) for a million makes our estimate for total number of atoms in the universe look so tiny it might as well not exist when beside it. While it's good to test the performance of each element being it's maximum distance from its sorted position, you also want to test other common cases too (already sorted, small clusters of adjacent elements at head and or tail etc) as well as some general permutations. One way to easily do this would be sort.IntSlice(rand.Perms(N)) for a ready to go slice of ints using seed to ensure determinism. You could stop the timer each iteration while you populate it to avoid the reverse call each iteration. Oh also I imagine there is no reason for sortChunk to be a pointer since I don't see you mutate it, meaning there is no need for a sync pool. So your chan can be chan sortChunk and you don't pay for allocations and buffpool spinup / contention. It's a small cost in a million elements but gets measurable at edge of your sort boundary I imagine.
Goroutines cannot be preemptively killed -- they might be holding locks. They need to cooperate, so there needs to be a way for them to discover they should exit, and clean up.
This looks great, I wish there were some tests.
Your first nano tutorial: - `ctrl - o` to save. 
I don't think this will happen, the Go team has expressed a deep concern about this; minimising disruption and compatibility with Go 1 is the top of the list in terms of constraints (according to the Go 2 blog post).
http://go-database-sql.org/
Oh man this is awesome, I haven't seen any 3D game examples beyond hello-spinning-cube type stuff. Thanks for sharing this, I use to love hobby game dev nice to know I can play around with Go next time I want to.
&gt;error is an interface. nil is a value. Then the snippet makes even less sense. 
VSCode would like a word with you
Maybe if we had.. generics
I don't think anybody has accused the Google Go team of ever listening to the community TOO much. In fact, it usually goes the other way.
You can't directly insert an object like you might hope, but there's some third party packages that can help with this: https://jmoiron.github.io/sqlx/ type Book struct { id int name string } book := Book{0, "Example"} db = sqlx.MustConnect("mysql", dsn) db.NamedExec(`INSERT INTO books (id, name) VALUES (:id, :name)`, &amp;book)
j'accuse! :) no i think that's part of the problem. they'll try to be responsive to criticism and go to far the other way. that's what i fear, anyway.
Well, the old "but performance" question. If raw performance is _realy_ needed: Have yourself some custom hardware built. You know: special CPUs like GPU for graphics but for your very performance hungry application. If such a multimillion (or even billion) dollar project is out of your scope then do what everybody sane does: Write in what matches your knowledge and problem domain and focus on the 2-10% of code which are performance sensitive after profiling.
Sure, new built-in returning a channel would be needed there.
This may be caused by the concurrent GC, the other side of the sword. 
I wouldn't agree, some languages aren't well suited for some projects - even for non professionals. Let's say you'd build some local dns cache, you wouldn't accept latency spikes every 30s when it's GC stops the world. I would go insane in such case. Go seems to be great for low latency applications, not for those where you need to build your own garbage strategy. 
We run a ad serving platform on Go which uses cgo for zmq socket library because that's what every other existing service uses in our code. As of now, Go is not the limiting factor our benchmark test tools written in C are. In the end, bench everything, it leads to clean and efficient design. Good luck
Isn't the gopher way to put the map communication to its own goroutine and communicate via channels to it? In this case you don't need to sync. See: https://blog.golang.org/share-memory-by-communicating
I don't find the README very clear about what this tool does. It mostly show how to use it's command line interface. Is it some sort of build server you run locally?
This is actually very valid point. I think that I will follow this suggestion. My goal was to have something simple to use, but not necessarily insecure ;)
I made a small cli a while back which would give me image crops for 16:9, 4:3, 1:1 and 3:4 ratios, for an image archive system that can produce any ratio/resolution on request. At least the cli part is here: https://github.com/titpetric/smartcrop - and as far as "Good crops" goes, that's a bit of an overreach. It may be just slightly better than putting a center point on the image and cropping it to a wanted ratio,... but sometimes, it's exactly that. ...which raises the question, could a machine learned model be trained from historical training data? I have about 1TB of images out of which I suspect there's a small (but significant) percentage of custom-cropped ones where I keep the crop coordinates and the original image. The images have licensing restrictions (as fuck), but I'd gladly train some machine learning thingy on them if there's interest.
Nice! Would be pretty cool to do an explain for each unique queuy and display the results!
https://github.com/fatih/vim-go-tutorial I used Plugin instead of Plug. (https://github.com/VundleVim/Vundle.vim) something here about using buffers instead of tabs http://joshldavis.com/2014/04/05/vim-tab-madness-buffers-vs-tabs/ i installed exuberant-tags on ubuntu also here is my .vimrc (some things are commented and commented out) https://pastebin.com/CzRdZma5
Ok, but it being slow for /login wouldn't be much of a problem. At least it's less of a problem than it being slow for everything else. How would one do TLS regenotiation in Go?
I'd one up you on this - since this is Go, it would be cool if it was an actually high performance proxy like a part of [vitess](http://vitess.io/), saving memory on the mysql connection pool as it serializes these only to a few connections. Other than that, there's some tooling like [anemometer](https://github.com/box/Anemometer) which does what you want for slow queries. The thing that's usually harder to come by is to do the same for fast queries that have a very high frequency. Enter port mirroring, tcpdump, and application instrumentation. As a man-in-the-middle proxy, there's significant opportunity for performance logging and tuning. I think the original mysql-proxy project actually rewrote queries and blocked things like queries without a where/limit clause/used index. A bit too-nazi for me, because not all queries are created equal :).
How does this look? The struct is type Data. dat, err = models.ParseDashboardPacket(buf[:47]) if err == nil { models.PrintDashboard(dat) tx := db.MustBegin() tx.NamedExec("INSERT INTO Data (status, acceleration, position, velocity, battery_voltage, battery_current, battery_temperature, pod_temperature, stripe_count, pod_pressure, switch_states, pr_p1, pr_p2, br_p1, br_p2, br_p3) VALUES (:id, :team_id, :status, :acceleration, :position,:velocity, :battery_voltage, :battery_current, :battery_temperature, :pod_temperature, :stripe_count, :pod_pressure, :switch_states, :pr_p1,:pr_p2, :br_p1, :br_p2,:br_p3,:br_p4)", &amp;dat) tx.Commit() func ParseDashboardPacket(buf []byte) (Data, error) { ret := Data{} if len(buf) != 47 { return ret, errors.New("Dashboard Packet: incorrect slice length") } ret, err := ParsePacket(buf[:34]) if err != nil { return ret, err } // TODO: parse rest of packet return ret, nil }
Pretty much. I use it for its file watcher feature that will rebuild my code every time I save a file.
Thanks a bunch :). I'll check it out when I get home. 
As it is always with algorithms: when they work, they do so magically and if they fail, they fail spectacularly. The sample data set I test smartcrop against has a fairly wide range of varied photos and I'm pretty happy with the results. At times it may feel like it's preferring the center-cut, but I believe that's just proof that it works correctly: as humans we just tend to put the object of interest in the center of our photos, too. It gets interesting when the algorithm decides to focus on a butterfly in the corner of the picture, or a church in a city's aerial. I agree that machine learning may come up with even better results, esp with a larger training-set. A lot of amazing things are happening in this area of CS right now. EDIT: Looking at your sources I just realized that you actually use a fork of my project - which is known to have a couple of bugs (like mixing up height and width in the middle of calculations). I'd encourage you to give it a spin with my upstream repo, you'll probably get to see better results.
Exactly
first realize that it you will need to invest time and energy to become proficient with vim. start with the basics; navigation, yank and paste text, delete and undo, visual mode, the most useful shortcommands etc etc. After that becomes muscle-memory start playing around to customize the .vimrc. Later explore useful plugins, start by choosing plugin manager (Vundle &amp; Pathogen are popular choices). Install the excellent vim-go plugin and read it's tutorial. Don't go supernuts on the vimrc in the beginning, try to understand everything you add there. 
by the way i started using Plug (as described in the vim-go-tutorial, but then i had trouble installing a plugin (im no expert at all on vim), so then i just installed vundle instead as you can see in my .vimrc. This means i have Plug installed and also vundle (which i use to install plugins). Some of my leader shortcuts are linked to Plug. 
I think you're dismissing a very practical benefit for a principle that is not well-defined. I used scare quotes to indicate that you were being to abstract and were losing track (in my opinion only, to be clear) of real usage. I think go2 updates should be grounded in real usage.
I used to have a quick and dirty shell script with inotify for that: https://github.com/garotosopa/dotfiles/blob/master/bin/runonmodifypath
Uhm, I forgot why that was the reason, I'll double check. As a side question, I thought the smartcrop project here was basically a port of the [smartcrop.js](https://github.com/jwagner/smartcrop.js/) counterpart? Edit: I think I remember the reason now, from artyom/smartcrop: &gt; smartcrop implementation in pure Go without opencv dependency From what I see, the dependency was removed from your project a few days ago (along with face detection). I'll see if I can get to it in the next few days, and hopefully test it out a bit :)
I think blank interface and unset pointer should have different names. You could call blank interface “none” or unset pointer “null”. Either change solves the problem. 
In this blog post I'm going to show you how to inject variables into your Golang executable at build-time. This is most useful for tagging your binary with a version or Git shasum or digest from version control. 
Thanks for the heads up, I updated my CLI repo. In simple tests it runs fine so I'm guessing I'll push this up to production :) thanks for the (very random) heads up!
What about nil slices, maps, channels and functions?
You are missing a link in your SSL certificate chain.
&gt; Typed nils are an entirely logical result of the way dynamic types, aka interfaces, are implemented, but are almost never what the programmer wanted. I'd be interested for someone to quantify this. The argument brought forth against this, in general, is that a nil-pointer (or nil-slice/map/channel/func…) can be a perfectly reasonable implementation of an interface. I'd be interested to know whether that happens and if so, how often.
Reported an issue to the developer (that's not me).
Nothing stops them from sharing. Contexts already require explicit management, so the fact that you'd have to explicitly manage local storage isn't much of a downside by comparison. Also, I remind you that I suggest this as a last resort, not the first thing you reach for. If you can solve the problem with passing contexts around, then do that. We're discussing the increasing number of cases for which that is not working. If there was an obviously-correct solution, we wouldn't have to be having this discussion.
If you "need" toggle switches instead of just placing the electrons where they need to be then you're just a bad programmer.
&gt; I'd be interested to know whether that happens and if so, how often. Yes, I do it with some frequency. Not "all the time", but enough that I would certainly guarantee beyond a shadow of a doubt that this can't go into Go 2 because it would be a massively breaking change for no gain. (Massively breaking changes would need a gain bigger than the cost to even be considered.) I have a [memory pool implementation](https://github.com/thejerf/gomempool) where the pool is a pointer pointing to a struct with its bookkeeping data. If you have a nil pointer, the pool methods degenerate into simply allocating on every request and ignoring attempts to return things to the non-existant pool. It's fantastic for debugging. I think that's the only public one I have, but I've got a number of other private places where I have a meaningful nil implementation. Since Go lets you declare interfaces that existing data types implement implicitly, all such meaningful nil implementations are automatically things that _could_ be wrapped in an interface, to say nothing of `interface{}`. Personally, I think the solution is better user education; too many Go programmers carry over the idea that a nil pointer is automatically invalid and crashes a program if used. Go programmers need to know that in reality, there is no such thing as the C NULL pointer in Go; all pointers are at least (TYPE, nil), which means that while they can still be dangerous they aren't _as_ dangerous as the C version. Whether it's a good idea to make nil pointers a legal value for a type is a style discussion. (Though I'd suggest the style discussion is pretty inevitably going to settle on "it depends" of one sort or another, rather than "never ever ever do it". I do make it a point to _always_ document right on the type and/or constructor for that type that nil is a valid pointer for this type, since it is uncommon.) 
OK, changed. I just took `http.Header` to handle headers. Header separation also allowed to handle UTF-8 encoding better. 
So my issue is really with the ssh key. You seem to be a lot better then me with this. I don't know if you can help me. I didn't start the old project, so I have no idea how it went. But It used a ppk file as private key, generate with Putty. How do I get this key to work with the ssh module in golang? When I put the file in PublicKeyFile("C:\\GoDev\\src\\Texel.ca\\Bnc_Ftp\\.ssh\\id_rsa"), It return empty. I tried to generate a private key and parse it, still nothing. 
- NoAccess was originally in earlier versions but it didn't play well on Windows so I removed it. - Finalisers wouldn't work since a reference to all created LockedBuffers is always kept, thereby preventing them from running out of scope. Thanks for the suggestions though, if you have a way of implementing them or you'd like to discuss the approach more, feel free to open an issue or drop me an email.
Thanks, great example.
Wouldn't using `textproto.MIMEHeader` or `mail.Header` make more sense than `http.Header` for an email package? Or is there some specific functionality in `http.Header` that those packages don't have?
This is a really good example of what I understand the Go team is really after for user experience reports for Go 2. Since the announcement of the beginning of work on Go 2 I've seen lots of "I want this feature that other languages have to be present in Go 2", but few user experience reports like they're really asking for. They're not asking (yet) for the community to propose solutions, but to first understand the problems. The solution Go arrives at will likely be different than how other languages handle them. This article is closer to the Monotonic Clock issue that has a fix in 1.9. It would be ideal if there were some additional analysis done on public projects to identify cases where nil is tested incorrectly, or the project does ugly gymnastics to determine if the value of an interface type is nil. 
Yes I mentioned that earlier, https://www.reddit.com/r/golang/comments/6s9297/go_19_rc2_is_out/dlc221q It's a good model that fits a lot of things, until the single thread and channel communication become your bottleneck.
You can't change the value of a const, they are read-only after the initialization. You should get a compiler error "cannot assign to constUrl" if you try to. Here is my take on the minimal modifications to your code to work. var ( url = "default" ) func main () { props := properties.LoadPropertiesFromLocalJsonFile() url = props.Url }
`mail.Header` doesn't have `Set()` function, only `Get()`. Probably it was designed for parsing only.
thank you verry much ... I had never seen in all of my examples the var () declaration ......... 
law demeter is a pretty well defined programming principle. you shouldn't be putting your logging variables anywhere near your task cancellation code. I get WHY you did it, having a random map of un-typed data being passed around was too tempting for you, and you lost all self-discipline. However, your use case, I think, exemplifies why context needs to go, because it's been transformed from a simple object that allows for thread cancellation in to this behemoth of an object which is now supposed to serve every purpose under the son. The fact that is was easier for you to just lump that logging data into context rather than write a contextual logger, is the very reason it needs to go.
I have been successful at cross compiling with cgo to windows targets from a Linux host, after a bit of trial and effort to get the libraries in the right location for the mingw compiler. I have not yet had success cross compiling to a macos target.
if you "need" to place electrons where they need to be instead of having the universe evolve such that your program is already written then you're just a bad programmer.
I experience something like Dave described in his post - I don't run into this enough to know that I have (or don't have) incorrect code, so it fills me with a general sense of unease. I almost feel like I need a Go playground walkthrough where I can see, debug and play with this issue on a regular basis to keep myself comfortable with it... but that also raises the issue that I've been writing Go code since release, and this is one of the few parts of the language that still makes me nervous and isn't obvious to me.
One suggestion I would have is to be in the habit of using print-debugging that will distinguish the cases. Here's a [Go playground snippet with the difference between %v and %#v in format strings](https://play.golang.org/p/_ztDJZUdWL), for instance. `%v` prints `&lt;nil&gt;` for both cases of interest, but `%#v` prints `&lt;nil&gt;` for the truly nil interface and `(*pkg.StructName)(nil)` for the case of an interface that is containing a nil pointer of another type. I'd suggest (though I can't prove) that it may be possible to avoid this problem by making that your habit, on the grounds that I use `%#v` as my bare minimum output verbosity during debugging (if not [go-spew](https://github.com/davecgh/go-spew)), and I personally haven't gotten stuck on this issue in a long time. And again let me emphasize this is just a theory; I don't have proof.
[Disclaimer: I didn't look at your code] Since `textproto.MIMEHeader`, `mail.Header`, and `http.Header` are all just `map[string][]string`, you can cast between them as needed to get at whatever methods you need. That's actually how [`http.Header.Set` is implemented](https://golang.org/src/net/http/header.go?s=1124:1162#L30). That would give you access to the mail specific `AddressList` and `Data` methods. E.g. perhaps something like this: https://play.golang.org/p/VD5xUFst9x Or perhaps (probably better) make your own complete type something like this: https://play.golang.org/p/i_QWxNuV2F type Header map[string][]string func (h Header) Add(key, value string) { textproto.MIMEHeader(h).Add(key, value) } func (h Header) Del(key string) { textproto.MIMEHeader(h).Del(key) } func (h Header) Get(key string) string { return textproto.MIMEHeader(h).Get(key) } func (h Header) Set(key, value string) { textproto.MIMEHeader(h).Set(key, value) } func (h Header) Date() (time.Time, error) { return mail.Header(h).Date() } func (h Header) AddressList(key string) ([]*mail.Address, error) { return mail.Header(h).AddressList(key) }
Makes sense to me
Couldn't understand the use case quite well.
Thanks, didn't know you could do this trick with `-ldflags`!
Yeah, I haven't run into it for a very long time, but I can't really prove that's because I'm doing things correctly. I attempt to make sure that I return a literal nil from functions, but I can't say for certain that this isn't lurking somewhere ready to bite me.
You don't need to use the GIT_COMMIT variable. You can just use the git command in place of the variable usage.
Pass a context, cancel it when a result is found maybe.
There's an emacs command for that, though. Good ol' C-x M-c M-universal_constants
Probably making own type makes sense because right now I'm also using `http.Header.Write(w io.Writer)` which is not implemented in `textproto.MIMEHeader`.
Damn, I never knew you could do this
Maybe I'm biased as I just started learning Go, but perhaps you don't have to like every language that's available? That's why there are so many. I like Go because it's simple. As an embedded software developer, my work revolves around telling a Microcontroller what to do; it's my domain, and it only does what I say. With web development, and how fast it changes, I don't want to have to keep up with every new change that happens. Here's a new API, here's an RFC changing how we've done this, but it's faster! With Go, the language writers provided me a tried and true, and most importantly a _tested_ http server, so that I can focus on what matters: writing code. Coming from C, I've never had genetics, and that doesn't bother me. I've used C++, and Rust for smaller projects, and I can see why it's useful for collections and type-safety, but at the end of the day it isn't make-or-break for me. You aren't forced to use any given language, so go with the one that suits you best.
Actually I don't need access to `AddressList()` or `Data()` because they are used for email parsing. It may sound weird, but `http.Header`suits here better than `textproto.MIMEHeader` or `mail.Header`.
&gt;Despite being highly controversial, I prefer to model similar behaviour of objects by using class hierachies. Opinion discarded. &gt;For example, my SAP analysis web interface uses three different product group structures, as the required amount of details varies between user stories. Go forces me to maintain the same code in three different places. Oh, he really blames Go for his own mediocrity, and he pretends to review it. &gt;Interfaces help to solve the problem with methods of objects, but not with data members. Additionally, I don’t like the implicity of interface implementations, **as most editors are not capable of providing a helpful suggestion** and you have to do a lot of manual documentation lookups. Wait, is it troll?
Thanks for the reply, I guess projects like Docker have been doing this for some time and when I came to need it I thought I better tell the world about it too. :-)
&gt; nil is a compile time constant which is converted to whatever type is required, ... In fact, nil is declared as a variable in Go, https://golang.org/pkg/builtin/#pkg-variables
This isn't a particularity interesting read - it doesn't say anything that hasn't been said a thousands times already by more informed sources, and seems to be based on some very subjective measures, and some (objectively) wrong claims. On formatting: &gt; According to my opinion, a programming language should let a developer use his or her style. A heavy influence on the programmer’s style is okay, but a fanactic, religious-like enforcement is inacceptable. That's a great opinion to have if you never work with anyone else, but it doesn't work at scale, which is one of the key design principals for Go. On broken package management: Go does have issues with package management - it's very much a weak spot. Vendoring is the official workaround, and whilst it's not perfect, it does work. On the lack of inheritance, the author doesn't seem to mention type composition which is one of my favourite features of Go and frankly sounds like the solution to the very vague issue they're describing. I've always found composition to be much more powerful than inheritance so I'm not sure what the author's issue is here. I'm not going to bother addressing generics. This is also the first time I've ever heard anyone call Go's built in HTTP package "lacking" because it doesn't come with helper functions for a REST library...? Go's standard library is excellent, and the HTTP package is one of the best parts of it.
Yeah but if I don't like it why should it exists?
&gt; They're not asking (yet) for the community to propose solutions, but to first understand the problems. ... This article is closer to the Monotonic Clock issue that has a fix in 1.9. No, that's not what the go team has done at all. The problems with non monotonic time were clearly stated on multiple issues over the years, and they were dismissed with a fair bit of hostility and arrogance. It wasn't until CloudFlare got bit publicly, in *exactly* the way people warned, that they shed the arrogance and took the issue seriously. And then they make a keynote speech praising themselves for their cleverness and project management.
This is boring.
&gt; That's a great opinion to have if you never work with anyone else, but it doesn't work at scale... Large scale projects are capable of enforcing their own internal coding standards. Having it enforced across the entire language community is a bit much, IMO. The dogmatic vibe in the community isn't illusory. That said, the author seems be complaining about the placement of the opening curly brace, which isn't so much of a coding-style issue in Go as it is an issue of the design of Go's ASI. There's still room for disagreement, but it's not a style-zealot issue. &gt; Go's standard library is excellent, and the HTTP package is one of the best parts of it. The library is very good, but there are things I wish we could do. For example, I wish we could `Reset()` a `http.ResponseWriter` in order to reuse its underlying buffer. I'm sure they don't allow this because people will get it wrong and end up sharing bytes between requests, but stuff like this that reduce allocations would be nice.
They'd still have the same zero value as pointers. The idea is just to have interfaces have a different zero value from any types they might contain. If you have var t T = nil var i I = t fmt.Println(i == nil) where `T` is a nilable non-interface type and `I` is an interface type, then the compiler can emit an error: "`Cannot compare value of interface type I to untyped nil.`" They'll either have to write: fmt.Println(i == T(nil)) in which case it will work as expected, or else fmt.Println(i == none) in which case it's intuitive that `T(nil) != none`, so there's no problem. The exact choice of names is arbitrary, of course, it only matters that a different untyped constant is needed for interfaces compared to every other type.
&gt; perhaps you don't have to like every language that's available? That's why there are so many. You're exactly right. That seems to be the author's conclusion too. Some people get way too upset when others describe why they've decided to not use Go.
I love me some good popcorn moments, but this article is just...bad. &gt; I now consider every line of Go code I have ever written as deprecated code. *views author's github go repos* *sees hardly any go code written* Some nice conclusions considering it looks (at least from the outside, could be wrong) that you have barely written any Go. Anyways, let's start with &gt; Strict Enforcement of the Google Code Guidelines This is one of the best parts. No more bikeshedding about formatting. It's done. No longer a concern. &gt; Broken Package Management... Go’s included “package manager” BRRRT...wrong. It's not a package manager, it's package retrieval. There is no package manager (although dep looks promising) &gt; No Inheritance Feature not a bug. &gt; Missing Generics This horse has already been beaten to death, with much better bats. &gt; Feature-Lacking HTTP Library The biggest signal to me that the author has written very little http code with Go.
A few things that jumped out at me from a cursory look: I recommend reading through the [Go Code Review Comments](https://github.com/golang/go/wiki/CodeReviewComments). Although those apply to Go code for the Go project itself (the Go standard libraries and golang.org/x subpros) you make your code much easier to read and use by other Gophers if you consider them. Your `Shard` type should probably use [`sync/atomic.AddInt32`](https://golang.org/pkg/sync/atomic/#AddInt32) with a delta of `1` and `-1` instead of mutexes. Similarly for your `Stat` type. You probably don't want to be using `MAX_WORKERS = 50` as a fixed number of go routine workers. Is 50 really better than 8 for my 4-core [`runtime.NumCPU()==8`](https://golang.org/pkg/runtime#NumCPU) machine? What if someone wants to run this on a 64 or 128 core machine? Either use `runtime.NumCPU` directly or (if benchmarks indicate it helps) use a multiple of that (e.g. perhaps due to blocking or some-such `2*runtime.NumCPU` works "best" with some algorithm); that's how things like [`testing.B.SetParallelism`](https://golang.org/pkg/testing/#B.SetParallelism) work. For the `essid` field is it correct to skip zero bytes or stop at the first zero? For other fields, is there a reason have this pattern: for i := 48; i &lt;= 79; i++ { self.snonce = append(self.snonce, self.Raw[i]) } instead of something like this: rh.snonce = rh.Raw[48:80] // or rh.snonce = rh.Raw[48:80:80] (See the "Full slice expressions" sub-section of the [Go Language Spec](https://golang.org/ref/spec#Slice_expressions) for what the later does if you're unfamiliar with it.) Instead of using `log.Print…` followed by `os.Exit` use [`log.Fatal`](https://golang.org/pkg/log#Fatal). I also strongly recommend getting used to only doing that directly (or very nearly directly) from `main` and in all other places (such as your `LoadFromFile` method) returning the `error` (where `main` will likely do a `log.Fatal`). That makes future refactoring, especially into a package which should not be panicing or exiting, much easier. You have: self.PKE = append(self.PKE, []byte("Pairwise key expansion")...) self.PKE = append(self.PKE, []byte{0}...) Why can't that just be: rh.PKE = []byte("Pairwise key expansion\000") or if you really want/need to re-use memory you probably need to reset it first (otherwise you can't re-call that method), either with a `rh.PKE = rh.PKE[:0]` at the start of `RH.initPKE` or something like: rh.PKE = append(rh.PKE[:0], []byte("Pairwise key expansion\000")) 
I was thinking of something similar the other day but a `-vendor` flag that saves the repo to the vendor directory rather than `$GOPATH` 0 - The `-v` flag is already taken though
This might be the best concrete solution I've seen, yet. I'm not at all convinced it fits all the things that have been stated as goals for the Go2 transition, but it's darn simple.
Hey /u/muesli, we're testing an application in staging right now, which uses your great lib (kudos). Hopefully we're going live in a few weeks. Seeing your post here, I realized that you removed the openCV dep a few days ago. Will there be any option to make it optional? When I tested the lib weeks ago, I also tried artyom/smartcrop, which had awful results comparing to openCV. I'm not a fan of having this dependency, but on the other hand, the customer is not a fan of awful results ;) What are your thoughts on that? Also I'll take a look at the code this evening, maybe your solution is just better than artyoms and works fine. That would be great :D
Well, on an anecdotal level, I've definitely used a nil *T to implement the default, unconfigured, functionality of a thing. Non-nil was only needed when actually customized.
The things you see in pkg/builtin are not the reality, they're just an attempt to document builtins in a way godoc understands.
If you "need" bad programmers you're just a generic.
Why do they need to be nilable in the first place? slices and maps already have a sensible zero value (empty) that would also make their semantics closer to strings. Functions and channels can just use pointers instead.
While we're talking solutions, another one might be to not make concrete types assignable to interfaces. That is, require an explicit type-conversion. Hey, I didn't say it's a *good* solution. :)
The current state of Go dependency management (which includes versioning) is [here](https://github.com/golang/dep). I think the `dep` tool already does a decent job around version pinning. Your suggestion seems to be on the same line as [gopkg.in](http://labix.org/gopkg.in) (only without the need for an extra server), so the concept should have the same pros and cons as gopkg.in. The biggest drawback I see here is that if you have a large project with 20 versioned import statements and you decide to switch to a newer version, then you need to update 20 import statements in 20 files (and make sure not to miss one). 
Zero slices, sure. A nil slice already behaves identically to a zero capacity slice aside from comparisons to nil, and doesn't require any allocation/initialization. The only value added by having nil slices is having a built-in initialization flag, but other types where that would be equally useful don't have it, so it wouldn't be a big loss. Empty maps can't be zero maps, because a map requires initialization, including allocation, in order to be useable. So an empty map doesn't work as a zero value. A nil map works as an empty map as long as you only read from it, but it cannot support insertion because no backing storage has been allocated. So a nil map is not interchangeable with an empty map.
why not ask on the `nats` slack?
List of cons is pretty good in exposing the mediocricity of writer.
&gt; Empty maps can't be zero maps, because a map requires initialization, including allocation, in order to be useable. So an empty map doesn't work as a zero value. A nil map works as an empty map as long as you only read from it, but it cannot support insertion because no backing storage has been allocated. So a nil map is not interchangeable with an empty map. Any insertion to a map can allocate. I'm not sure why an empty one has to. If you want it to be more deterministic you can use `make`.
That wouldn't make this work: func setFoo(m map[string]int, v int) { m["foo"] = v } ... var m map[string]int setFoo(m, 5) fmt.Println(m["foo"]) // prints 0 under your proposal All arguments in Go are passed as a copy. If `setFoo` has to allocate a new map because the one it was passed was uninitialized, anything it inserts will not be inserted into the original map that was passed to it. 
Then pass it by a pointer if you want to share it like every other value type in go.
For *any other map value* than the zero value, the code I posted would work. func setFoo(m map[string]int, v int) { m["foo"] = v } ... var m map[string]int = make(map[string]int) setFoo(m, 5) fmt.Println(m["foo"]) // prints 5 Having the zero value behave inconsistently without any way to detect it (i.e. comparing to `nil` or panicking on insertion as is the case today) would be a terrible design.
I'm failing to understand what Turtle Graphics Mode is. I have been using _goplay.space_ for a while new, but what is the difference with _goplay.space/#draw_ apart from the code area being empty?
I think I'm missing something then. Why can't you make an empty map behave the same way? What's the difference between the first allocation and a reallocation in terms of data sharing? I feel like this has to do with the specifics of go's map implementation. Would you care to shed light on it?
I have more of a critique to your blog design that to your article. On my laptop with width of the screen of 768 pixels, the side pane takes half the screen and does absolutely nothing worthwhile while I scroll your article on the right half of the screen. It goes away to the top of the page if I magnify page, but then I left with font that's way too big. Your blog's design, honestly, is fucking terrible, and you may need to rethink it. General idea of permanent sidebar to the side is, frankly, mindnumbingly idiotic, but people decide to parrot it, for some undecipherable reason. I want to use all my screen real estate, for I have very little of it, and your take on that feels even worse than usual. Especially due to contrast between halves.
I encourage you to explore ways to disagree without being insulting. There is plenty to talk about, but the principles you refer to are not fundamental; saying I was too "tempted" and "lost all self-discipline" does nothing other than make me not want to engage further.
There's some truth to this, but I don't take as dim a view. The initial response was just, "hey run your data center like google, don't let time go backwards". Eventually they realized that was a shitty response. Yeah, ideally the initial response would have been better, but it's hard for everyone to really empathize with outside conditions, and they were good about changing their minds and admitting they were wrong, which is also hard for everyone.
It's not specific to maps. Any type containing a pointer will be the same in Go. func set(p *int, v int) { if p == nil { p = new(int) } *p = v } func get(p *int) int { if p == nil { return 0 } return *p } ... var p1 *int set(p1, 4) var p2 *int = new(int) set(p2, 5) fmt.Println(get(p1), get(p2)) // prints 0 5 As long as you're writing to memory through the same pointer *without having to write to the pointer itself*, all copies of the value (`p`/`pn` in this example, or `m` in the previous ones) will observe any changes, whether it's setting an int to 5 or inserting an entry into a map. As soon as you have to change the pointer itself, which you need to do if you allocate new backing storage, then copies of the value can no longer observe any changes you make. Maps are implemented as a pointer to backing storage. They have to be implemented this way because the backing storage can be any size and can grow and shrink as you use the map, so it has to be stored indirectly. Edit: Essentially, the difference between the "initial" allocation and any subsequent (re)allocations is that the initial allocation occurs before any copies are made through which you can observe the difference between assigning *to* a pointer and assigning *through* a pointer.
I don't think we even need to support `i == T(nil)`. You'll usually never care, and if for some reason you really do, you can do : ``` if t, ok := i.(T); ok &amp;&amp; t == nil { } ``` The root confusion is if we do t = nil i = t we expect intuitively to have `i == nil`, which isn't true for interfaces. If we just require that interfaces be compared to `none` (or `empty` or `unset` -- pick your keyword) instead of nil, all is good. (That said, I'm not sure fixing warts like this is a good idea for Go 2. While it's undoubtedly nicer in isolation, it's very confusing when considered in the context of existing Go 1 code. Maybe, *maybe* if you had a perfect Go1 -&gt; Go2 compiler and got everyone to basically immediately run it on all their code this would be alright.)
Nice. You can also press "t" and you will get a searchable list of files in the repo. Press "?" for even more shortcuts.
Hi, yes you are correct: `kickFlusher()` is using a buffered channel to signal a `Flush()` of the `bufio.Writer` so that the commands are sent to the server. If there are no pending flushes, then the flusher loop will go back to waiting to be signaled that there is another flush or return in case the connection was closed.
Thank you, glad to hear you like it and work with it! I indeed did remove the face recognition via opencv a couple of days ago, while keeping the existing smartcrop API stable. The plan is to add an additional (but optional) FaceAnalyzer in the next few days, so you can install smartcrop without having to depend on opencv. Apart from the ugly cgo dependency that opencv comes with, pairing edge/skin/saturation detection with face recognition was a bit hacky. With a second analyzer, there's a clean abstraction via an interface and you could first try to recognize faces and only then fallback to the StandardAnalyzer. artyom/smartcrop has a few bugs, but I've cherry-picked the performance improvements into upstream in the last couple of days. Let me know how muesli/smartcrop works for you now!
As far as I know working C cross compiler from Linux to Mac is a pain in the arse to find, if possible at all. 
&gt; I don't think we even need to support `i == T(nil)`. It's already supported. The concrete value is converted to an interface and then it's just interface comparison. Also, this kind of thing isn't a big deal as far as source incompatibility is concerned. Go 1 files can easily be compiled in the same project just by allowing `nil` to be used in place of `none` in those files. Converting files to Go 2 can be accomplished with simple type-directed text substitution. Accidentally compiling a Go 1 file as a Go 2 file or vice versa will produce a straightforward compiler error rather than silently being wrong. There aren't any real hazards here.
Try the examples.
Not bad, but it requires a custom go build/install command. It doesn't work with a standard `go install package/name` invocation. 
I don't think there's another way to define variables at compile time. You could of course generate a separate go file with the same data but that too would require another command
In my experience Putty generated keys have different format that Go would not understand. In the Puttygen, once you generated key pair, click Conversions -&gt; Export OpenSSH key in the menu and save the file. That will be the private key that you are going to feed to Go program. If you already have the keys, you can load one (*.ppk) from the menu and then export for OpenSSH. That way you won't have to deploy the new public key to server.
I found out how to do it like 10 mins before you replied ahah, the timing. :) Now with openssh key, in ssh-sa format, my authentification fail at handshake. This is a never ending adventure. If my ppk private key words in winscp with my server, my openssh conversion from that ppk should also work with the same server when using sftp right?
Hi guys, this is the first thing I'd say I've semi-finished in Go (just started learning the language). Any tips are appreciated!
Thanks for commenting. This does work with `go install` - I just tried it, it's going to be the following: ``` $ export GIT_COMMIT=$(git rev-list -1 HEAD) &amp;&amp; go install -ldflags "-X main.GitCommit=$GIT_COMMIT" ``` You're correct in saying that an override is required. That's how Golang handles ldflags. 
I think the page was cached so I couldn't see the examples. Now I got some of the examples running, though a bit buggy I'd say. It is an interesting feature regardless.
I love how good first opinion directly contradicts Go's core design principals. Like, maybe you should have read a bit on what Go is first.
So this mother fucker wants typed nils, but not generics? Some people want to just watch the world burn. 
&gt; So this mother fucker wants typed nils, but not generics? Some people want to just watch the world burn. Dave Cheney doesn't want generics? Source please.
Here is [one](https://dave.cheney.net/2017/06/15/simplicity-debt)
if you mean `gonum`, then just get the `.Data` field, and iterate manually through that. Here's the equivalent you can do with [gorgonia/tensor](https://github.com/chewxy/gorgonia) import T "github.com/chewxy/gorgonia/tensor" mat := T.New(T.WithShape(95,356), T.Of(T.Byte)) dat := mat.Data().([]byte) // will return []byte var count int for i := range dat { if dat[i] == 1 { count++ } if count == THRESHOLD { coord, _ := T.Itol(i-THRESHOLD, mat.Shape(), mat.Strides()) log.Printf("Start of series found at %v", coord) } } You can do a similar iteration using Gonum, but you'd have to write your own `Itol` function
Yes, I wanted to write gonum :-D. Thanks! Will have a look into that.
The real solution to this is a type system with sum types, not weird magic with `nil` specifically. This is a general problem (representing a type of data that can take more than one form with more than one kind of associated data) that sounds like it's going to be met with a special-case solution. Go has a lot of things like this, and it makes the language unsuitable for a number of situations. If Go had real enumeration types, a lot of things would be easier. Consider the example of HTTP requests. In many cases, they result in success, so you might define a type `HTTPResponse`: type HTTPResponse struct { status int headers map[string]string body map[string]string } But a `body` isn't really sensible for HTTP errors, so either the status code is redundant (always 200) or the data is. A nicer abstraction over an HTTP response would be something like: type HTTPResult enum { Success (string) Error (int) } which could be returned by any route handling function and eventually wrapped by the server in type HTTPResponse struct { HTTPResult headers map[string]string } To make the program even more expressive, one could create an enum for error types instead of using an int: type HTTPError enum { NotFound, Internal, Moved, // ... more errors here } This is an incredibly useful feature and makes almost any program more expressive, and because of the Go language team's fetishistic focus on "simplicity" it'll likely never be implemented. Combined with generics, it also solves the problem of nils. An `Option` or `Maybe` type, as in Haskell or Rust, can wrap _any_ other type in a typechecked way. EDIT: Someone pointed out to me that this example was bad. That's what I get for writing an example in a domain I'm not intimately familiar with. The actual issue I've had that makes me want sum types so badly is writing a testing specification language. I can deserailize from JSON, but only to a single struct; if I want many different _types_ of tests, I have to use `interface{}` and _whole_ lot of runtime guessing. The better example, then, is rather than a struct: type Test struct { type string soa_target string // applicable to a certain type, A docker_action string // applicable to a different type, B, body string // applicable to both A and B bodyFile string // mutually exclusive with body // many other fields elided } along with much validation and mutual exclusivity logic performed at runtime, I could have something like this: type BodyData enum { Literal string File string // could easily add more things like Regex, etc } type TestAction enum { SOA string Docker string // again, trivial to add more } type Test struct { TestAction BodyData // many fields elided } In addition, this would allow me to enforce at compile time that all allowed Test types were handled; that both literal and file body types were loaded; and anything else I added.
Look, just because he says "we have to reason about this carefully" doesn't mean he doesn't want it. There is a lot of nuance in what Dave's talking about
If you only ever need float64 matrices, then use gonum, don't use `tensor`. 
Where on this article does he claim that he doesn't want generics?
No, really tiny numbers only. Thanks for the hint :)
If you read through this and the redux, his overall view of generics making go too complex is pretty clear. There are misc excerpts from posts/talks/etc by Dave which have a strong tone of not wanting generics. 
then package [`tensor`](https://github.com/chewxy/gorgonia) might be more your thing. It's a generic multidimensional array package. Might be a bit heavy for your usecase tho
&gt; If you read through this and the redux, his overall view of generics making go too complex is pretty clear. Sure he writes about the potential readability loss and increased complexity but nowhere in the article he argues that they shouldn't be added. On the contrary after reading this article it gave me the impression that he wants generics but he wants them 'right'. Look at these quotes: &gt; *"...just as I have no doubt that* ***not*** *adding them would be a mistake"* &gt; *"The question is, how can we pay down the cost in complexity of adding templated types or immutability to Go?"* &gt; *"We have to build up a bankroll to spend on the complexity generics and immutability would add, otherwise Go 2 will start its life in simplicity debt."* To me it just seems that he wants people to discuss and make sure we get them right. &gt; There are misc excerpts from posts/talks/etc by Dave which have a strong tone of not wanting generics. The article didn't convince me at all about Cheney not wanting generics, so if you find any of those other sources please share.
Author says he's using Go at work. Did you even read the article?
Just use golang/dep.
&gt; Go's standard library is excellent, and the HTTP package is one of the best parts of it. `http.NewRequest` returns `error` because it takes `string` instead of `URL`. It has to parse that string which could be an invalid URL. Excellent design, duh. Have an URL and wanna make a request? Convert it to string and parse again! Why not have two functions which take both string and URL? Because the language has no function overloading!
&gt; &gt; I don't think we even need to support i == T(nil). &gt; It's already supported. The concrete value is converted to an interface and then it's just interface comparison. Right you are! I've been using Go for years now and I had no idea you could compare an interface to a value like that. Neat. (And...useless?) Here's the relevant bit from the spec, if anyone else is curious: &gt; A value x of non-interface type X and a value t of interface type T are comparable when values of type X are comparable and X implements T. They are equal if t's dynamic type is identical to X and t's dynamic value is equal to x. My concern about mixing `none` instead of `nil` in Go 1 and Go 2 code is not so much about the practicality of it, but more the human confusion cost -- unless we get everyone to en masse move their code to Go 2, we'll be stuck with the old subtle behavior and the newer behavior, resulting in a higher total subtly. To put it another way, I think it makes a lot more sense to add capabilities to a language than fix warts, because old code and the warts will be around forever anyway, so you're not really fixing it, you're just complicating the situation further. (Side note, I've so internalized the current behavior it's hard for me to think of writing anything other than `i == nil` as the correct thing -- `i == none` feels so weird. Why call `nil` `none` just for an interface? Requiring something ungainly like `i == I(nil)` seems more consistent, but ugly af...)
Here is another cons. Go has `go generate`. But it has no proper build system, when we use `go get` - it just downloads files. Have a ton of generate source files, e.g. from protobuf? Put'em into the repository. Wanna have a custom build step - easy, good ol' makefiles! ...for a library?
LoGo
I found this pretty hard to read, but if the issue is that you don't want to have to implement every function of an interface to generate a mock that only requires a subset, you can use embedding to do that for you. Take [os.FileInfo](https://golang.org/pkg/os/#FileInfo), for example: type FileInfo interface { Name() string // base name of the file Size() int64 // length in bytes for regular files; system-dependent for others Mode() FileMode // file mode bits ModTime() time.Time // modification time IsDir() bool // abbreviation for Mode().IsDir() Sys() interface{} // underlying data source (can return nil) } I want to mock this, but I only want the mock to return a name, so I can do: type MockFileInfo struct { os.FileInfo name string } func (m MockFileInfo) Name() string { return m.name } Calls to anything but `Name()` will fail, and I didn't have to write out all the functions. This is useful in some, but definitely not all cases.
That's all clear, but what I'm not understanding is why do map reallocs not obey one set of rules but normal pointers don't? For instance if I do `make(map[int]int, 0, 0)` this shouldn't allocate and should behave identically to its nil value like slices do. Other languages with pervasive stack objects seem to implement this just fine (off the top of my head C++ and Rust). I think this [playground](https://play.golang.org/p/lAQnpEyAhY) illustrates what I'm asking better. Why do we need to have sharing implicitly baked into maps when we already have a language construct that serves that purpose, pointers?
Author here. Please share your bug reports (here, in private, or on GitHub).
Thanks for the report, I'll have a look.
Stopped reading after "no inheritance". Also, the "enforced style" being too strict. If you consider that a "con", I don't want to work with you on any project involving more than 2 people. I've had enough of "my own special style is best" types... 
Shhhhhhh! Do not utter the G-word!
Huh. Interesting. It seems like a *very* specialized used-case data structure. Doesn't jive with the "the standard library had a very high bar for getting something accepted" spiel. 
If the dynamic scopes are immutable (like context), then you're just copying a pointer to the current dynamic scope. Is an extra pointer copy too expensive for goroutine spawning? (I don't know how heavy they are.) Or am I missing something? This would make assignment to dynamic variables a little more expensive. It could be done as a linked list of scopes, like context (and I presume emacs) or a hash trie / functional RB-tree, like clojure uses for its immutable maps (for O(log N) lookup). If the cost could be made negligible (especially for those who don't use it), I think I'd prefer this to having to pass around context everywhere. And it may be generally useful. 
As someone who loves both languages, one does wonder at what point we're just asking for Rust, though. :) I do want a type system that can handle `Some(T)|None` instead of `T|nil` though, because nil pointers remain the biggest source of BS in an otherwise great, scalable language.
wow, I started using Go at 1.0 release and found the example counter-intuitive (i expected true). Ive also never encountered this in my own code but the possibility actually bothers me.
In general, our data access layer returns every column. We only create a new method if performance becomes a problem. I’d say, in most instances, limiting the return columns for every use case is a premature optimization.
Can't have "Some&lt;T&gt;" without implementing the feature-that-cant-be-named though.
I had no idea this was possible, but it does seem to be a logical outcome of the type system. Do you get some sort of nil pointer panic when the methods are called?
Yeah, I see your concern. The big features - and complexities - of Rust are generics and lifetimes. Go can forgo lifetimes entirely thanks to its rather advanced garbage collection, and while I personally would appreciate generics being added in Go 2, it's not an absolute must. Sum types, however, are immensely useful and not having them is, clearly, causing major issues for the language.
Yep, that's correct. You get a panic just as though you've called a function on an interface that was never assigned to (like https://play.golang.org/p/dBheZEWL_B), which is exactly what is happening. It should panic at the call site itself, so you'll see immediately where your code has called something unexpected. I used this when I was testing something that used a protobuf client, but I only wanted a couple functions, and calling others would have been an error anyway.
I don't think anyone here will lose any sleep over the fact that someone decided to not use Go. The part that might rub the Go community the wrong way was the clickbaitish, non-substantive fashion in which it was described. It's just adding to the noise at this point, and feels more like it is capitalizing on a transitional/evolutional period in Go's short history.
Parent (me) said &gt; (at least from the outside, could be wrong) So now I ask you, did you even read the comment? Also, I mentioned the excerpt author wrote about the "feature lacking" http package as the biggest signal that the author has written very little Go, or at least haven't given a genuine "college try" as some like to say in order to write an article like this. REST-style parameters or sessions are not http libraries typically provide, and it's not something Java provide standard either either. Accessing cookies are provided via http.Cookie (https://golang.org/src/net/http/cookie.go) this analogous to java.net.CookieManager. If you need more, you need to import another Jar, just like in Go, if you need more, you need to use a package. Then talk about error handling is bad and mention Dropwizard? Seems as if author wants a programming language to be a complete batteries included experience. I think author may have confused standard library with framework.
Yeah honestly I was surprised to discover that I was able to compile for WIndows but not for Mac. The particular app I needed to compile went without a current Mac version for a few months.
Fixed.
Thanks, this can be useful. I've always known it's possible. From `encoding/gob` doc: &gt; A stream of gobs is self-describing. Each data item in the stream is preceded by a specification of its type, expressed in terms of a small set of predefined types. So it's always been just a matter of implementing that. I'm surprised it wasn't done earlier. But thanks for your work doing it now.
thanks! its great to get an authoritative answer 
I guess it isn't a particularly common need. The only other reference I even saw to someone wanting to do it was met with mostly silence a couple years ago. I thought it was a little odd that [Debug](https://golang.org/src/encoding/gob/debug.go) function that I found in the Go source didn't work correctly, but I guess that is why you have to rebuild the package yourself to use it.
The last time I used Debug, which was quite a while ago I admit, it worked fine. If it's broken I'd like to see it fixed. Please file an issue with a reproducible example at https://github.com/golang/go/issues/new. 
Thank you, this is genuinely useful.
So, there are two questions here: 1. Why is a map different from a slice? 2. Why isn't a map shared via an explicit pointer? ---- __1. Why is a map different from a slice?__ When you receive a slice value, there are two ways to change it. The first is to alter an element already in the slice (e.g. `slice[2] = "foo"`). The other is to extend the slice (e.g. `slice = append(slice, "bar")`). In the first case, all copies of the slice observe the change. In the second case, you're creating a *new* slice, so any copies of the original slice will not observe the change. - *__Note:__ If the new slice shares the same backing array, then the copies of the original slice can be resliced to include the new elements. This also creates new slices, though, so it's still true that the copies of the original slice cannot be used to observe the extension.* This distinction exists because slices contain a fixed number of reachable elements which are all presently in use. Any new elements added to one copy of the slice are not reachable from any other copy of the slice because they're outside that fixed number of elements. Maps are different. A map is implemented (essentially) as a hash table. This means is that, for each key/value pair you put in the map, a *hash function* is applied to the key to derive the index in the backing storage where the key/value pair will be stored. This allows for constant time insertion/lookup. The implication of this is that not every reachable space in the backing storage will be filled at any given time: m1 := make(map[string]int) m1["foo"] = 1 m1["bar"] = 2 // 0 1 2 // m1: |-------|"bar"/2|------- // 3 4 5 // |-------|-------|"foo"/1| If I make a copy of `m1`, it will use the same backing storage: m2 := m1 // 0 1 2 // m2: |-------|"bar"/2|------- // 3 4 5 // |-------|-------|"foo"/1| Now if I insert another entry into m2, one of two things can happen. m2["baz"] = 3 This key/value pair might end up inserted into the same backing storage: // 0 1 2 // m2: |-------|"bar"/2|------- // 3 4 5 // |-------|"baz"/3|"foo"/1| *or* the implementation might decide that my table is getting too dense. A dense table means that it becomes too likely that two different keys will hash to the same index (called a "collision"). The more this happens, the less efficient map accesses become, since now instead of just applying the hash function to the key and doing a constant time access of the table at the resulting index, we have to find a different place to put the second key/value pair corresponding to a given index, and then we need to find that other place whenever we look up that key. To reduce the risk of collisions, the map implementation will allocate a larger table and insert all the entries into the new table whenever the table gets too dense. So, we might instead end up with // 0 1 2 // m2: |-------|-------|"baz"/3 // 3 4 5 // |-------|"foo"/1|------- // 6 7 8 // |-------|-------|------- // 9 10 11 // |-------|"bar"/2|-------| This means that whether or not an inserted entry is reachable through a copy of the pointer to a table depends on very particular properties of how the map is implemented. You can neither rely on copies observing the insertion nor on copies *not* observing the insertion. In order to get around this, the map implementation uses double indirection so that all copies of a map can observe when a new table is allocated, ensuring that insertions are always observable through all copies of a map. A map is essentially a pointer to a slice of a backing array (it's even more complicated in reality), and you need this level of indirection in order for it to behave in any consistent way with regards to sharing. The slice is shared by all copies of the map (the pointer), so when you reallocate the slice to make more room, all copies of the map can see the changes. But if you don't initialize the pointer to the slice in advance of making copies of the map (i.e. you make copies of a nil map), then there's no shared slice which you can update so that all copies of the map see the new backing storage. __2. Why isn't a map shared via an explicit pointer?__ Because of the aforementioned complexity involved as regards sharing. If you remove a layer of indirection, copies of the table (the slice of the backing array) won't demonstrate any consistent behaviour as far as inserting entries. There's simply no value in exposing that internal representation. You could do it, and then just make it illegal to copy map values, *forcing* you to pass them around via a pointer, but that would also infect any structs or arrays containing maps. They would each become non-copyable, so you would have to pass them around via a pointer as well. The way the language is presently designed removes this entire potential source of complexity.
That is definitely helpful if you are calling a function that takes an excessively large interface where you don't control/own the function. If you do control/own the target function though, I _strongly_ recommend that you practice the technique in the post until it is second-nature to you. The testing thing is really just a easily-explained hook; the real reason to do it is that it has hard-to-explain highly beneficial results to your code's architecture and quality. Your technique leads to shorter testing code; this technique leads to better code overall. This is one of the secrets to effective Go programming that makes it more powerful than some of the people who just get stuck on "doesn't have generics" realize. (Another one is preferring composition over inheritance.) The seemingly-tiny difference between having to declare conformance to an interface versus implicit satisfaction turns out to have huge consequences as it starts manifesting at scale.
But nil can't be called a Go constant from any view. Call it (in fact, them) immutable variable is better.
Interesting. It definitely doesn't work correctly with the gobs I was trying to read. It was only confusing numeric values (as far as I could tell). uints were being printed as ints. I'll see if I can find an example. I didn't think to file a bug report because I assume the Go authors were already tepid about exposing it since you have to remove the build guard from the file (EDIT: oh oops I didn't realize I was responding to Rob Pike, I guess I'll file a report). EDIT2: Here is a much more stripped down one, these bytes: `0x3 0x6 0x0 0xa` should decode as a uint 10 but they print as 5 (they're being decoded as an int, `10 &gt;&gt; 1`). Start of debugging 5 
&gt; But a body isn't really sensible for HTTP errors I think this is a bad example, because a body is very sensible for HTTP errors. A status code can't always provide enough detail about what went wrong for the client to correct their fault (or decide they should give up).
I suppose the third question is "why is Go different from (1) C++ and (2) Rust?" 1. Go is different from C++ because C++ has copy constructors. This is code which is run whenever a value is copied, and generally performs a deep copy so that e.g. a copy of a hashmap always has separate backing storage. In Go, copies are always shallow, bitwise copies. This is a tradeoff. On the one hand, it means that the cost of an operation is predictable: when you pass an argument or copy an array, you don't have to execute arbitrary code or potentially traverse deep pointer-linked data structures. On the other hand, you have to add an extra level of indirection to types like maps so that these copies exhibit sane sharing behaviour. The Go authors preferred the simplicity of shallow copies everywhere. C++ also has constructors. This means that, when you declare a hashmap, it implicitly runs arbitrary code which allocates the backing storage. So while it appears that you're just declaring a variable, you're also initializing it to a non-zero value. Similar to not calling arbitrary code each time you copy a value, Go decided not to call arbitrary code each time you declare a variable, opting instead to default to the zero value (literally just the value with all bits set to 0). It forces you to explicitly initialize a variable if you want a non-zero value, including if you want to allocate any backing storage. 2. Go is different from Rust because Rust has ownership and borrowing semantics. When you pass a data structure like a hashmap by value, *the original becomes invalid*. It solves the Go/C++ choice between extra indirection and unpredictable copy complexity by just making (implicit) copying impossible. You're forced to either explicitly share the hashmap with an extra layer of indirection, or explicitly execute arbitrary code to perform a deep copy. This all has its benefits—I really like Rust as a language—but it's very far from the direction the Go authors wanted to go. The complexity introduced by this has a tendency to infect every aspect of an API. Rust also has initialization tracking. Rather than implicitly running arbitrary code to initialize variables like C++, or initializing them to a zero value by default like Go, Rust requires you to explicitly assign a value to each variable before you use it. Go decided not to bother with initialization tracking, falling back on the zero value if you don't do it. This makes array initialization simpler, for example, since the compiler doesn't need a way to ensure you've initialized all the elements of the array before you use it. It's up to each type to decide what should happen if you end up using a zero value. I should also note that C++ has been moving in a similar direction as Rust, preferring to *move* values with explicit ownership and borrowing over making copies. But implicit deep copying using arbitrary code is still pervasive.
Please file it, as Rob asked: &gt; Please file an issue with a reproducible example at https://github.com/golang/go/issues/new. 
np!
Yep, I will.
Check out kotlin. You don't really need Some/None/Option if you just put null safety inside the language. 
Gogs has beautiful, simple interface. Gitea has more features(like 2-steps Auth), contributors. But the interface is getting worse since everyone can modify the interface easily via a Pull Request and not really everyone is good at the UI design.
And for those appends, you can simplify further by omitting the `[]byte` and do something like `buf = append(buf, "foobar"...)`(https://play.golang.org/p/vFSkeez2c1).
that is awesome, thanks to the Go team and all the mentors
 * Too broad- need to define "it", prod and dev tend to be the same as far as the Go process, using docker to bring up service dependencies. * I don't speak for everyone but I don't see a point in it unless your existing infrastructure makes it the path of least resistance. * I personally use as much of std lib as possible, making sure any dependency I pull in is worth its weight in gold. Exceptions being a handful of libraries to common problems that I wrote, contributed to, or have reviewed thoroughly to ensure it meets my own criteria for quality. * What you mean? You should have heard of goroutines by now, are you asking about how goroutines are scheduled processing time? * No test frameworks needed, Go test is all I use .. no assertions libraries or anything, see my dependencies rules. * Yes, cgo, but you will probably need it much less often. * Yes, I suggest you go through the [tour](https://tour.golang.org/welcome/1) , then [how to write Go code](https://golang.org/doc/code.html) and [effective Go](https://golang.org/doc/effective_go.html). Skimming through them doesn't take any time at all but you can get a good idea about most your questions here and maybe lead you to ones with more substance. I've been doing "backend" development for just about 15 years now and out of every mainstream language (I.e, c, perl, Java, Php, c#, node, Python and lots of random things between) and Go is my favorite. I write so much more software using Go. Every other language is full of people's diversions they created because they were sick of the diversions other people created. The Go tool chain gives you everything you need to not only produce quality software, but maintain and iterate on. Testing, linting, formatting, Compiling, cross compiling, performance profiling, tracing.. its all maintained by the Go authors and contributors. It's solidified and everyone agrees and uses these tools, so you immediately solve so many problems that other languages are constantly competeting with themselves in. Just my two cents. Take it easy.
But we're not going to get rust. There's clearly a need for a faster, non draconic, albeit correct, compiler, such as the go over. But there's also a need for features that make the developer's life easier as well 😀
And here I just want slices and maps to be comparable, by making the compiler do what I seem to do on a regular basis instead
You could put it in a library somewhere. It's actually a pretty niche thing
Thanks for answering this. Yes, I see the multi-core problem doesn't make sense here. I didn't know that goroutines supported multiple CPUs. Also, what's your opinion about dependency management in go? I'm not very fond of the idea of committing all my dependencies. I looked into "dep", and it seemed pretty good. Any issues I should know about other than the fact that its not official as of yet?
&gt; But a body isn't really sensible for HTTP errors Says who? The vast majority of websites [deliver a body on HTTP errors](https://github.com/thisisa404).
You are perfectly illustrating the frustration of all of these discussions. You say generics are not a must, but sum types are immensely useful. The next developer says not having generics is stupid and who cares about sum types. I say sum types *or* generics are both actively harmful to the goals of go and dynamic scoping is a necessity. What set of features are "absolutely necessary", "you can do without" or "don't belong in the language" is 100% determined by personal preference. And pretending that your personal preference has any sense of objectivity to it is just futile.
Good post, but I would recommend to use git describe (--tags) to get a version string that includes the last tag 
I don't know if you're arguing for adding function overloading or getting rid of the the `error` return but if it's the former: no. just no... and if it's the latter, then your argument is quite frankly, weaker than a dead horse. There are many more cases where `http.NewRequest()` returns an error and if they aren't relevant then there is no reason for you to check it. I also don't see what's stopping you from creating the `&amp;Request{}` yourself if the helper function doesn't do what you want...
&gt; But it has no proper build system, when we use go get - it just downloads files. I think what you're trying to say is that `go get` doesn't expose your system to arbitrary code execution just because you downloaded one piece of code.
As you say, Gogs is great for a personal repository. If anything, I'd suggest you bitbucket, which gives you unlimited private repos + a team up to 5 people. It's amazing at $0/month, which I suspect you're paying more for your VPS. If you're fine with running Gogs, keep running Gogs, it's nice.
Thanks a lot for the feedback.. I would try out this technique in some projects and see how it goes. PS -&gt; I would like to know why it was hard to read.. What can/should I improve on
I personally like gitea more for its features and more active development. Lots of bugfixes went into it too, it's like half of change lists between releases 
&gt; When building a server in NodeJs, we tend to leave caching, gzipping, most of the HTTP part to the web server (nginx or such). Some people put nginx/haproxy instances in front of Go for SSL and/or caching or special routing and that's fine, but not necessary. I personally have two nginx instances load balancing access to my backend (for redundancy) just so I can cache some static assets and do some fancy routing (let's say, have requests from /api/v1/ to go a set of backends, /api/v2/ go to another set of backends, have the institutional website go to yet another set of backends, etc). If you don't have any special need for nginx, you CAN deploy Go directly to the world using it's native http server, which is production-grade, as long as you observe some [good practices](https://blog.cloudflare.com/exposing-go-on-the-internet/), specially in regards to [timeouts](https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/) to keep misbehaving clients from messing with your resources. For your internal webservices, using Go's native http server is super-fine and standard (no need to have anything in front of them). &gt; In production, we deploy a cluster of the app server (which is asynchronous by design) to multiple cores. There's no need for that in Go, a single instance will already use multiple cores by default. &gt; Use frameworks like Koa/Express for handling routes and middlewares etc. You can use only the standard library if you wish and there are people that advocate for using only the standard library and no other frameworks. I personally like to use frameworks because more often than not they save me time (at the cost of getting tied to it forever - and the framework's opinion on how things should be done). I personally like [go-rest-json](https://github.com/ant0ine/go-json-rest) which makes creating REST services a breeze and has support for a lot of middlewares. There are other libraries/frameworks that people use a lot like [Gorilla](http://www.gorillatoolkit.org/) and [Iris](http://iris-go.com/). Iris had some community-related issues a while ago, not sure how they are faring now, but it seems to be [actively maintained](https://github.com/kataras/iris). Iris is fast, but it uses [fasthttp](https://github.com/valyala/fasthttp) as http server, not the standard one. It is focused on raw performance (at the cost of some compatibility with exotic clients, I think?). [It is pretty fast though](https://www.techempower.com/benchmarks/#section=data-r12&amp;hw=peak&amp;test=plaintext). [Gin](https://github.com/gin-gonic/gin) is a popular web framework. Another up-and-coming web framework that seems nice and full-featured is [aah](https://aahframework.org/). 
&gt; What are things one should keep in mind when putting go in production. Any guides on it? What are the major differences between your production and development environments? I already linked to some best-practice guides on how to expose Go directly to the public Internet. As for environments, I try to keep my development and production environments as close as possible - usually there will be an environment variable that I pass to it that points to an [etcd server](https://coreos.com/etcd/docs/latest/) from where configuration is pulled. If I'm running under development, it will be pointing to my 'development etcd' (database passwords, etc, are pulled from there and cached locally). I have all my services use [NATS](http://nats.io/) so I get service discovery and message queueing/passing for free with it between the components of my system. It also supports streaming (think Kafka). Imagine that you have a webservice in your system called 'urlsnapper' that receives an URL and dimensions (width and height) and a destination (S3 or minio or local filesystem or some gluster mountpoint or whatever) and it takes a snapshot of the webpage at the URL using a viewframe of widthXheight and saves it to the destination and returns a message signaling success of failure to the caller. The backend workers for 'urlsnapper' will run on their containers. When initialized, they check an environment variable (let's say, 'ETCD_URL') and fail if it's not present. From that ETCD_URL, it pulls all the environment information (so it knows it's running in "development" mode, knows where the ELK stack is to send event metrics and logs to, etc). From etcd, it also pulls the address of the [gnatsd](https://github.com/nats-io/gnatsd) server(s) from the development environment. It connects to that gnatsd and announces that it is online and that it is serving 'urlsnapper' requests. In your main application, whenever you want to take a screenshot of a page, you can call on NATS to either run it in the background (fire and forget), asynchronously (run it and be notified in a channel when it has finished) or synchronously (wait for it to complete, then move on). You call 'urlsnapper' by sending a request to gnatsd and it load balances the request to an available 'urlsnapper' backend - so you don't need to worry yourself about the IP addresses of your microservices. Note that this is just my personal preference - you might use Kubernetes for service discovery/routing, or Consul, or something else. I suppose one can consider [gRPC](https://www.youtube.com/watch?v=YiNt4kUnnIM) the de-facto [RPC framework](https://www.youtube.com/watch?v=sZx3oZt7LVg) for webservices in Go (but you'll still need something else for the service discovery part - knowing where to send your request to). Note that in Node, if you run a synchronous operation (like reading from a local file) or some heavy computation, your whole server freezes because you block the event loop. In Go, that doesn't happen - if you read from a local file, that goroutine gets automatically suspended and the processor does something else until that file read finishes. When the read finishes, the go runtime wakes up the goroutine and your code keeps on running from where it left off - so there's no need for callbacks, the runtime manages the illusion of serial code execution for you (by scheduling and rescheduling goroutines for you behind the scenes). You get concurrency and parallelism for free, without having to think hard about it (and no callback hell). 
&gt; Is it common to use a reverse proxy for HTTP heavylifting, or handling it in Go itself? &gt; I see a lot of references using go's http library directly. Is it advisable to use it straight rather than frameworks as in most of the other languages (not very common)? Already explained. &gt; How does go take advantage of multiple cores? (natively, not containers). If you write a [simple hello world web server](https://gowebexamples.github.io/hello-world/) in Go, it will already be concurrent and parallel: whenever a new client connection comes, a new goroutine will be spawned to handle it and run on an available core (paralellism). Suppose you have something more complex than a 'hello world', something that queries a MySQL server, for example: after you write the query request to the network, your application will wait for an answer from MySQL. At this point, your 'goroutine' is suspended and another goroutine that is ready to do some work is awakened, and it's execution resumes from where it left off. Once MySQL performs the query and replies with data, the event loop that runs inside the Go runtime will notice that there is data available to be read in the socket and will wake up your goroutine for you to deal with that data, and you'll work with the query rows. No need for callbacks or explicit async/await or futures, the runtime manages it for you. As far as your code is concerned, everything happened without interruption. A lot of things will take advantage of multiple cores automatically for you: the webserver will spawn new goroutines to handle new clients (you don't need to do that yourself), when sorting integers from an array, the sorting implementation is already "multithreaded", etc. To take advantage of multiple cores explicitly in your code, you basically just need to spawn goroutines to do the work that needs to be done and have a way to communicate with your goroutines (channels, usually) and a way to know when those goroutines are done with their work (sync.WaitGroup). There are a ton of great articles and talks on this subject: * [A Tour of Go - Goroutines](https://tour.golang.org/concurrency/1) * [Learn Concurrency](https://github.com/golang/go/wiki/LearnConcurrency) * [Denis Uraganov - Concurrency: goroutines and channels](https://www.youtube.com/watch?v=zbFDjCHzN50) * [Evan Huus - Complex Concurrency Patterns with Go](https://www.youtube.com/watch?v=2HOO5gIgyMg) * [Sameer Ajmani - Advanced Go Concurrency Patterns](https://www.youtube.com/watch?v=QDDwwePbDtw) * [Rob Pike - Concurrency Is Not Parallelism](https://www.youtube.com/watch?v=cN_DpYBzKso) * [Fun with Channels in Golang](https://www.youtube.com/watch?v=CUG1vfnO3zI) * [Golang Concurrency](https://www.youtube.com/watch?v=UP8agyrTeok) &gt; Testing. Are test runners common, or go has something built in for unit tests. Is the ecosystem mature? Yes, tests are common and a first class citizen in Go - Go has a built-in testing/benchmarking framework. Some talks on it: * [Testing Techniques](https://www.youtube.com/watch?v=ndmB0bj7eyw) * [Mitchell Hashimoto - Advanced Testing with Go](https://www.youtube.com/watch?v=8hQG7QlcLBk) &gt; C bindings? (JNI/swig in other languages) Yes, it's possible, but too complicated to explain here and I don't have a lot of experience with it. Basically the Go compiler also includes a small C compiler (!) to interface with C at compile-time (you can include C header files inside your Go code, or embed C code, for example). One thing to note is that because the Go ABI differs from the C ABI, there's a small extra overhead when making foreign calls. Some references: * [C? Go? Cgo!](https://blog.golang.org/c-go-cgo) * [cgo](https://golang.org/cmd/cgo/) * [How to include C code in your Go package](https://dave.cheney.net/2013/09/07/how-to-include-c-code-in-your-go-package) * [Go Bindings for Various External APIs](http://go-lang.cat-v.org/library-bindings) &gt; Anything else you'd like me to know? * the official [Tour of Go](https://tour.golang.org/welcome/1) is a great place to start. * [The Go Programming Language](https://www.amazon.com/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440) is a great book to read When writing Go applications: * Logging is very important, I recommend [logrus](https://github.com/sirupsen/logrus) logging to a local JSON file that gets forwarded to a centralized logging stack like [ELK](https://www.elastic.co/). * [metrics](https://www.youtube.com/watch?v=HkEZ1LJ7kzQ) will give you observability on the state, performance and health of your systems * I use [spew](https://github.com/davecgh/go-spew) a lot for debugging too (think Python's `pprint` or PHP's `print_r`). * [gorm](https://github.com/jinzhu/gorm) makes working with databases easier. * so does [upper](https://upper.io) * learning to [profile](https://www.youtube.com/watch?v=2h_NFBFrciI) and [optimize](https://www.youtube.com/watch?v=xxDZuPEgbBU) your applications will come in handy * so will learning about how the [Go race detector](https://www.youtube.com/watch?v=UgQvmBuOUPQ) and optionally, [how it works](https://www.youtube.com/watch?v=5erqWdlhQLA) * and learning how to detect [memory leaks](https://www.youtube.com/watch?v=ydWFpcoYraU) * Go comes with great tooling by default, [learn about it](https://www.youtube.com/watch?v=uBjoTxosSys) * working with weird/non-standard JSON can be a pain sometimes - I like to [gjson](https://github.com/tidwall/gjson) and [sjson](https://github.com/tidwall/sjson) when it makes sense * [GopherCon 2014 Best Practices for Production Environments by Peter Bourgon](https://www.youtube.com/watch?v=Y1-RLAl7iOI) 
Videos linked by /u/bonekeeper: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Golang UK Conference 2015 - Evan Huus - Complex Concurrency Patterns with Go](https://youtube.com/watch?v=2HOO5gIgyMg)|Golang UK Conference|2015-09-10|0:53:46|53+ (94%)|7,941 [Google I/O 2013 - Advanced Go Concurrency Patterns](https://youtube.com/watch?v=QDDwwePbDtw)|Google Developers|2013-05-18|0:34:11|552+ (99%)|83,305 [Rob Pike - 'Concurrency Is Not Parallelism'](https://youtube.com/watch?v=cN_DpYBzKso)|afriza na|2013-10-20|0:31:22|1,361+ (99%)|99,978 [GopherCon 2017: Mitchell Hashimoto - Advanced Testing with Go](https://youtube.com/watch?v=8hQG7QlcLBk)|Gopher Academy|2017-07-24|0:44:59|61+ (96%)|2,897 [Golang UK Conf. 2016 - Björn Rabenstein - Grand Treatise of Modern Instrumentation and Orchestration](https://youtube.com/watch?v=HkEZ1LJ7kzQ)|Golang UK Conference|2016-09-09|0:26:57|5+ (83%)|565 [Golang UK Conference 2016 - Dave Cheney - Seven ways to Profile Go Applications](https://youtube.com/watch?v=2h_NFBFrciI)|Golang UK Conference|2016-09-09|0:30:04|65+ (97%)|4,413 [Profiling &amp; Optimizing in Go / Brad Fitzpatrick](https://youtube.com/watch?v=xxDZuPEgbBU)|yapcasia|2015-08-28|0:59:24|136+ (100%)|7,233 ["The Go Race Detector" by Robert Knight](https://youtube.com/watch?v=UgQvmBuOUPQ)|Go London User Group|2014-06-17|0:34:19|1+ (100%)|127 [""go test -race" Under the Hood" by Kavya Joshi](https://youtube.com/watch?v=5erqWdlhQLA)|Strange Loop|2016-09-18|0:44:14|0+ (0%)|3,079 [Finding Memory Leaks in Go Programs - Oleg Shaldybin](https://youtube.com/watch?v=ydWFpcoYraU)|Hakka Labs|2014-08-13|0:28:27|67+ (98%)|6,520 [Go Tooling in Action](https://youtube.com/watch?v=uBjoTxosSys)|JustForFunc: Programming in Go|2016-06-02|0:41:51|1,061+ (99%)|39,598 --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/bonekeeper ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dlf2e9m\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.3b
FWIW, I like [vscode](https://code.visualstudio.com/) with lukehoban's [Go extension](https://marketplace.visualstudio.com/items?itemName=lukehoban.Go) - it looks [like this](https://www.youtube.com/watch?v=c5ufcpTGIJM).
So taking `string` instead of `URL` is a good design? &gt; many more cases where http.NewRequest() &gt; what's stopping you from creating the &amp;Request{} Did you see [the implementation of NewRequest](https://golang.org/src/net/http/request.go) ?
And yet, thanks to `gofmt`, I have NEVER had a single conversation about code-style, and all that useless stuff with my coworkers. I agree with the point that it is a bit dogmatic, but in my experience, if you leave it to programmers to argue among themselves about formatting, it never ends, and friendships die.
Hey /u/muesli, I tried your current version and in most cases it works like a charm. Usually it fails to find something good if I try to crop out something in portrait mode (e.g. source image is 16:9, crop something out that is 2:4), the old version with openCV does a way better job here, but that's fine. I can send you some examples if you like. I think you can never rely on algorithms 100% though. You always need a fallback on manual cropping for a customer. On a side note, would be great if you could add tags/releases on github for such bigger changes. Would make it easier to switch versions with dependency tools etc. Nonetheless, great job, thanks for the lib, it's really helpful. And it got faster without openCV ;)
Congratulation to consider Go. It's worth the exploration effort. You won't regret it. The ecosystem is rich, but not as much as with npm. Howerver, code is usually good. The rule of thumb is to stick to the standard libraries to avoid the versionning issue until it's solved properly. The language is very simple to learn. What took me a longer time to learn is to write simple code and get away of classes and the inheritence mind set. It is also good to know that some topics are subject to (excessively) passionate debates like the absence of generics and use of the Iris frameWork for instance. ;) Go is not just a language and compiler. It comes along with a large set of amazing and powerfull tools to help you produce high quality and reliable code. They help you investigate what your program is doing behind the scene. I only scratched the surface. 
I'd recommend Gitea instead of Gogs, because it is more actively developed. But be warned that you may not be able to migrate the same installation from Gogs to Gitea, because of incompatible database migrations between the two systems. (In the beggining of the fork this was possible). You can watch this issue about it if you want: https://github.com/go-gitea/gitea/issues/2206 The recommended path is make a backup, create a new Gitea installation and manually import repositories to new the installation. I know it's a pain, but worth if you have few repos.
My team uses go, and we find development speed to be pretty rapid. Also, as long as the code is well written, it's extremely easy to read.
* Have you had instances where the code has not been well written? * If so, in what way?
Not really. The people in the team that have shown an interest in writing Go code have been pretty good at following the idiomiatic go guidelines, and have produced pretty good stuff.
Do you have a mixed team of less and more experienced developers? Maybe from different stacks (java,php, ...)?
We're not really a team of developers, we're devops engineers. That means some people will writing in bash or ruby, but more and more people have been picking up go to get the jobs done. 
You don't have to commit your dependencies with most go package management systems, including dep. You can just commit the one or two files used by the tool and bring down the dependencies at compile time. Dep is good, you should use it.
Well, there's definitely an adjustment period before you're writing idiomatic Go. People are generally used to learning what feature to do the thing they want, in Go you spend more time learning how to combine the relatively few features that exist instead. That's very unusual for a modern imperative language.
here's my experience: https://npf.io/2017/03/3.5yrs-500k-lines-of-go/
Fun! https://goplay.space/#o9XSl8xvlM
I wouldn't advise someone asking this kind of question to use Docker. Also my two cents. Take it easy :) 
Go is really easy to program in and it's easy to learn. It's very productive, but I wouldn't call programming in go itself fun. After 1-2 months you learnt most of the tricks on how to program quite well in go and there's not much fun in the programming itself. I'm not thinking of good solutions on how to some thing in go anymore. The way to do it is normally quite obvious, so no challenge and thus no fun. I do consider this a good thing however, because that way I have more time for the challenges inherent to the thing I'm building, e.g. architecture or complexity. There's are definitely some gotchas in go though. The main ones are all caused by go being just to simple by default in some cases. Four things stand out: - Versioning of dependencies is not available by default. I can definitely recommend [dep](https://github.com/golang/dep) and also my own tool [virtualgo](https://github.com/GetStream/vg), which adds some extra functionality to dep. - Testing works quite well, but it's just a bit too awkward by default. I can heavily recommend [testify](https://github.com/stretchr/testify). Especially the suite package makes testing much nicer, while keeping the go simplicity. - Logging is also a bit to simple usually for production apps. We use [logrus](https://github.com/sirupsen/logrus/) which I'm fairly happy about. - Error handling in go is done using values instead of using exceptions. The default error values are too simple though, because they don't have stack traces. You should really use https://github.com/pkg/errors, to all errors in your applications.
my past coworkers managed to find things to argue about with style... the most egregious being how many spaces to put after a period in comments. Yeesh. Programmers will always find something to argue about :) But yes, I agree, I love gofmt.
They really will. Though I've never had that specific debate I've got to admit! I'm curious as to what the consensus was in the end. For us it's simple: does it render in a readable way on `godoc`? yes? then it's good.
They're not saying that the only reason NewRequest returns an error is because it calls url.Parse. Literally none of the rest of the implementation can error. If it took a URL, which is arguably more correct anyway, then it wouldn't need to error at all. They're not arguing for overloading, but maybe just a second method NewURLRequest(?) that takes a URL and can't fail. I've definitely done similar things before... the value of not returning an error is quite high, since errors tend to propagate up your return values. If you already parse a URL elsewhere in your stack (and handle the error, of course), then this error is spurious.
This last point is not even correct. Gogland does a fantastic job at helping you with interfaces. So does Vim, VSCode, Atom etc etc...
Nice response. I'd like to add that https://github.com/pkg/errors is pretty nice, but i personally like https://github.com/juju/errors more, though it's less known.
headsup: juju is gpl encumbered
Hmm, hadn't heard of juju/errors. Looks cool indeed, but GPL is not really an option for us. We actually wrap https://github.com/pkg/errors ourselves because we needed more functionality and we want to be able to rewrap an error without adding a stack trace if one already exists. 
The main program is exiting before the goroutine has had an opportunity to execute. See https://nathanleclaire.com/blog/2014/02/15/how-to-wait-for-all-goroutines-to-finish-executing-before-continuing/
Copying part of my response to another post on the frontpage right now: There's are definitely some gotchas in go though. The main ones are all caused by go being just to simple by default in some cases. Four things stand out: - Versioning of dependencies is not available by default. I can definitely recommend [dep](https://github.com/golang/dep) and also my own tool [virtualgo](https://github.com/GetStream/vg), which adds some extra functionality to dep. - Testing works quite well, but it's just a bit too awkward by default. I can heavily recommend [testify](https://github.com/stretchr/testify). Especially the suite package makes testing much nicer, while keeping the go simplicity. - Logging is also a bit to simple usually for production apps. We use [logrus](https://github.com/sirupsen/logrus/) which I'm fairly happy about. - Error handling in go is done using values instead of using exceptions. The default error values are too simple though, because they don't have stack traces. You should really use https://github.com/pkg/errors, to all errors in your applications.
See this for line endings https://github.com/golang/go/issues/16355. Gofmt is to standardize what code should look like and that includes no carriage returns. Notepad++ and wordpad both know how to handle no carriage returns
This article is great for explaining go routines.
* Maintainability - since the code is relatively simple and split into independent packages with no clear dependencies, it's easier to maintain than some other codebases I've worked on. Not an order of magnitude, but definitely better. * Pkg management - no official solution at present, doing it by hand * Onboarding - very simple so far, even with quite large projects, have had developers pick it up without prior experience and be very happy with the language. For those attached to inheritance they'll have to let go, which may take time. For those attached to generic code they may not be happy with the enforced simplicity. We haven't had problems with either. * We're building booking software and full stack websites with it, millions of users so medium scale * Project scale - 100kloc or so over several projects * Team size &lt; 5 devs * Problems/Bugs - we have seen a few panics due to nil pointers, a few bugs due to errors ignored, not many type errors, majority of bugs are logic errors or business logic being wrongly interpreted rather than caused by deficiencies of the language. Should so some more work classifying our bugs though, it'd be interesting to see what the causes are in aggregate. * Bugs per deploy - we don't track this metric (probably should), probably around 0.6 from a quick guess. * Performance - we're very happy with it, most performance issues are related to db or io not cpu or gc pressure * Complaints - had to write a bit of the http plumbing ourselves (routing, auth, validation, secure cookies) as a few years ago it was pretty bare bones (this has improved and it was not a huge burden), error handling is sometimes verbose/ugly, containers are limited, unboxing slices of types can be a pain - these very minor niggles are the only complaints I have. We have not regretted choosing go. * Testing - happy with stdlib for this, it's simple and effective 
Hey just wanted to say I really enjoy your blog and I'm looking forward to further posts in the future.
I think you've misunderstood. Go routines do all the things listed, but they also terminate when the main program terminates. This is true of all threaded progammes.
&gt; our users are, for better or worse, remarkably sensitive to the time it takes to compile their programs. :joy: very true. 
TBH, I wouldn't give up on Go. It's a pretty awesome language, and recruiters are clambering to find people with those skills.
None of what's written in that spec is broken. The only, small culprint of your example above is that the main routing (main() in itself is one as well) ends - due to the keeping the promise of a goroutine started being non-blocking - before the started goroutine had a chance to execute the actual "print" and - here comes the actual issue in the example - all goroutines are terminated when the main() ends/exits. Goroutines are not forked out as fully seperate, selfsustaining threads, they might behave like it but they are still running in the context and as part of the original process.
_That's fine, it's just not_ _What the specification_ _Says very clearly._ &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ^- ^throwawaybeginr ------------------------------ ^^I'm ^^a ^^bot ^^made ^^by ^^/u/Eight1911. ^^I ^^detect ^^haiku.
Sorry to see you frustrated. The spec is correct. It never says that the function is allowed (or even required) to terminate. It describes what happens once the function terminates. If the whole program terminates before a goroutine is done then this goroutine is terminated too (obviously) . You clearly marked in green that "upcoming lines in the program are evaluated" so you are aware that the program terminates once the end of main is reached (described elsewhere in the spec). The "independent concurrent thread of control" exist only during the lifetime of the whole program which finishes at the end of main.
I tried to argue that it didn't matter, but I think we ended up on a single space. (personally I usually like double spaces, but I really just didn't want any policy, except maybe no more than two spaces ;)
Awesome, thank you :)
juju/errors is LGPL, so it's not really a big deal. It's not the same as GPL or AGPL. I'm not a lawyer, but to my understanding, you can use LGPL from, for example, an MIT codebase, and it won't cause the rest of your code to be copy-lefted. You can also use it in proprietary code and again, not need to release your proprietary code.
In a nutshell, an instance of the data structure use case. Personally, I'm OK with most of the absence of "generics" in Go; what I want is _some_ solution to this problem, though, be it generics or otherwise. The thing about data structures is they're actually _waaaay_ harder than they look to get right. It's pretty easy to pick up a sophomore computer science book and bash together, say, a Heap that _seems_ like it's working OK in your use cases, and it works OK in your production deployment which hits your data structure literally trillions of times (in some stereotyped pattern for your use case), and you could pass that Heap off to somebody else with a different use case and they could have the thing throwing panics in ten minutes, or for _them_ the memory explodes, or in some other way it is revealed that your "shipped" data structure is actually tissue-thin as data structures go. Data structures that are correct _and_ have well-optimized run times _and_ have well-optimized memory usage _and_ have well optimized garbage behavior _and_ have a good API _and_ any other property you want in a data structure library you download is really tough. Having a language that affords/encourages you to bash together your own data structures on demand, each of them that has some major flaw by probably at least 3 of the standards I just gave, is the worst C-like aspect of Go. It also strikes me as a weird weakness in Go given Go's affinity for writing network servers. Network servers end up in high-performance applications, where you might really want a real btree or have a _specific_ desire for a Red-Black tree, or want a really fancy high-performance concurrent lockless data structure, or a fancy [succinct data structure](https://en.wikipedia.org/wiki/Succinct_data_structure) to save memory, or any number of other such things. It's not a command-line scripting language where you can say with a straight face "Oh, those are just people abusing the a language ultimately meant to be a command-line utility on a desktop UNIX system", it's a language designed to go into the spaces where this is the sort of thing you need to do to hit performance needs.
The spec does cover this: &gt; Program execution begins by initializing the main package and then invoking the function main. When that function invocation returns, the program exits. It does not wait for other (non-main) goroutines to complete. https://golang.org/ref/spec#Program_execution They could perhaps link to this from the goroutine section, but it is covered. 
/u/throwdemawaaay nailed it. Basically, the language is dying. When you have to fight so hard to get a legit flaw fixed then people tend to move to greener pastures. With all honesty, I think the time fix is hackish.
This is a false equivocation. As it stands there's no way to make type safe general purpose containers in golang without resorting to go generate. That's not simply a matter of subjective preference.
plus the ones in github.com/vektah/goparsify
Also not a lawyer so I don't really know, but I thought it only applied to dynamic linking. Static linking would be a problem: https://groups.google.com/forum/#!topic/golang-nuts/JqOAWBpL-70 Turns out there's an exception in the LICENSE: As a special exception to the GNU Lesser General Public License version 3 ("LGPL3"), the copyright holders of this Library give you permission to convey to a third party a Combined Work that links statically or dynamically to this Library without providing any Minimal Corresponding Source or Minimal Application Code as set out in 4d or providing the installation information set out in section 4e, provided that you comply with the other provisions of LGPL3 and provided that you meet, for the Application the terms and conditions of the license(s) which apply to the Application. So it's probably ok. TIL. 
I don't get it, what does asking about a language you never used have to do with using docker? 
&gt; What set of features are "absolutely necessary", "you can do without" or "don't belong in the language" is 100% determined by personal preference. No. Sum types present the only sound solution I know of to the problem presented in the post I'm replying to; thus they are essential to solving that problem, unless someone presents another solution. In addition they improve expressiveness in the language.
I'd been wanting to contribute better documentation and examples, perhaps now I'll follow the steps and actually do it.
You're right, someone needs to make the final decision for a group. Having `gofmt` does provide a path of least resistance in arriving at a decision, so it's certainly helpful in that regard.
your missing my point that something work with `go install pkgname` and no other flags.
not another command. `go generate` does this such that you can implement a solution which works with `go install pkgname`
That's what I get for writing an example in a domain I'm not intimately familiar with. The actual issue I've had that makes me want sum types so badly is writing a testing specification language. I can deserailize from JSON, but only to a single struct; if I want many different _types_ of tests, I have to use `interface{}` and _whole_ lot of runtime guessing. The better example, then, is rather than a struct: type Test struct { type string soa_target string // applicable to a certain type, A docker_action string // applicable to a different type, B, body string // applicable to both A and B bodyFile string // mutually exclusive with body // many other fields elided } along with much validation and mutual exclusivity logic performed at runtime, I could have something like this: type BodyData enum { Literal string File string // could easily add more things like Regex, etc } type TestAction enum { SOA string Docker string // again, trivial to add more } type Test struct { TestAction BodyData // many fields elided } In addition, this would allow me to enforce at compile time that all allowed Test types were handled; that both literal and file body types were loaded; and anything else I added.
That's actually exactly what I meant when I said "not some magic with nil specifically". Why have specific functionality around `nil` when the general purpose solution adds so much more expressiveness? It makes sense in Kotlin, which is explicitly object-oriented, but Go is not that.
You're right. I'll replace the example.
Very valuable answer, thank you. 
I think it’s quite elegant. We’ll see how it works out in practice...
What's `go generate`if not another command to run ? You need to call it before running `go install package/name` so it's still not standard. In any case I don't see how it's a problem
&gt; Sum types present the only sound solution I know of to the problem presented in the post I'm replying to So… what makes that problem "absolutely necessary" to be solved? I never cared about it at all, so to me, personally, it seems like wasted effort. &gt; In addition they improve expressiveness in the language. But, again, my point wasn't whether they help or not, but that it is very much personal preference how *important* that help is considered. And, just so that we have this clear: They also *directly* contradict the goals of go outlined [here](https://talks.golang.org/2016/refactor.article). So at the very least you are making it impossible to solve one problem by solving another. Again, which you weigh heavier is personal preference. Personally, I prefer to solve the refactoring problem. But I am aware that this is a *personal* preference.
You wouldn't count the lines in flex towards a parser it built, but perhaps the title is a little clickbaity 😳
Go is productive in the sense that libraries are well written, standard library is fine, compilation is fast and dependable. But its not "productive" like Python or JS. In that sense, its so unproductive that many (myself included) write Python scripts to populate/test/interact with Golang servers, since its so much faster than writing Go.
Absolutely. Rob Pike said himself: Gofmt’s style is no one’s favorite, yet gofmt is everyone’s favorite. I agree with this more and more as time goes on 
Thanks. I'm aware of Bitbucket. I prefer to host my own. I pay $5/month for a VPS and run many services off of it.
Thanks. I'm running an older version of Gogs so I imagine an upgrade is possible, even if I have to start with an older version of Gitea and upgrade from there. :)
Good to know. I thought I heard Gogs implemented 2FA as well. 2FA is very important to me however. The interface in the screenshots on their Github doesn't look too bad... I guess maybe I'll give it a shot. If I hate it, I'll have a Gogs backup to fall back on.
&gt; So… what makes that problem "absolutely necessary" to be solved? I never cared about it at all, so to me, personally, it seems like wasted effort. You're right. I was taking that as a given, which I thought would be clear given that I was commenting on a blog post about the problem and how Dave Cheney wants to solve it. If the eventual decision is that it's not worth solving, then no solution will be implemented, obviously. &gt; And, just so that we have this clear: They also directly contradict the goals of go outlined here. So at the very least you are making it impossible to solve one problem by solving another. Having sum types doesn't preclude type aliases and other gradual refactoring measures. 
I'd really love that Gogland doesn't just ignore conditional build file suffixes for the system that doesn't match the target. When I'm on windows writing for my _linux files it doesn't even try to check missing import or functions called with the wrong parameter.
[related answers in another post](https://www.reddit.com/r/golang/comments/6sqi3u/backend_developers_whats_your_workflow_when/dlf2d56/). Go was created with long-term maintainability in mind - so it's very opinionated on how things should be, to create a standard (things like code formatting, etc) and there's usually only one "good way" of doing things (just one kind of loop for everything, for example). The intention is to pick someone else's code and feel like it could've been written by you. Bugs are rare (once things compile, they usually work) and new members can learn Go in a couple days if they are already seasoned developers. Development speed is a bit lower than Python/PHP IMO, but the resulting performance and sturdiness (from having a typed language, etc) more than pays for it IMO. And yes, coding in Go is pretty fun, once you get the hang of it!
There should be a big yellow band which tells you that the build system selected doesn't match the curent file target and ask you if you want to configure it. Have you tried that? Also see Settings | Go | Vendor &amp; Build (iirc)
&gt; was taking that as a given, which I thought would be clear given that I was commenting on a blog post about the problem and how Dave Cheney wants to solve it. If that's the problem you are referring to, I don't even see how sum types have literally anything to do with the issue, much less why they would be better than what he suggests. If I do `type T sum { Something(A); Nothing }`, then `Nothing` would still be of type `T` and thus will have a specific dynamic type when put into an interface. Unless you are talking about baking `Nothing` as something special into the language. In which case you are suggesting the same as what Dave is suggesting ("Nothing" would currently be called "nil"), just also trying to smuggle sum types along. &gt; Having sum types doesn't preclude type aliases and other gradual refactoring measures. The very idea of sum types is that the build will fail if you don't check exhaustively in a switch. Meaning if you define a sum type, you will never be able to add a new element to it or remove an old one without immediately breaking dependencies. Precluding gradual repair. By its very idea, a sum type will never be able to change gradually. Contrast that with the workaround of using interfaces (i.e. open sums). If you want to add a new possibility to the sum, you can just define a new type implementing that interface. Old code will just use the default case of any type-switch and can then be gradually updated. If you want to remove a possibility, you can mark it as deprecated, remove it from all switches in dependent code (instead handling it via the default case) and then remove it from upstream.
Oops, didn't see this comment. We already automatically Madvise on UNIX systems. The disable core dumps is there for explicitly disabling core dumps for the whole process. I think a developer that is concerned about troubleshooting could do something like: ` if debugMode { /* don't disable */ } `
Sure. I have no idea why I was so massively downvoted. I strayed too much offtopic?
Thanks for your thoughts. Is it common in your team that code is maintained by someone else than the creator? Is there a hard curve for juniors to get the seniors code?
https://i.imgur.com/yP2T6to.png "IDE will use these values to decide which files should be ignored during validation, resolving and suggesting symbols". However there isn't any option to validate and resolve regardless of OS or Arch. I have all the dependencies in my vendor so I don't see why it wouldn't be capable.
&gt; Is it common in your team that code is maintained by someone else than the creator? No, it's not common, because we own whatever microservices we write. This way other developers don't waste time having to learn what it does first, to then work on it. Sometimes it happens (let's say, someone left the company or is in vacation), but it's the exception more than the rule. With that said, reading other people's Go code usually feels very clear because the language doesn't have a lot of magic that usually lets people write messy code. It's a bless and a curse - the language is kept simple for this purpose (readability and maintainability and to have a lower barrier of entry) at the cost of not having **that fancy language feature** that you might love in another language (generics, list comprehensions, variant types, etc). &gt; Is there a hard curve for juniors to get the seniors code? Depends on the senior and the junior. Usually, no, there isn't, unless the complex nature of the project itself creates a hard curve - but that's not the language's fault. Something else that helps in this regard is that Go linters will require that you document everything - your functions, your exported values, etc. So usually your junior developer will be working on a fully-documented code that is easier to understand. [Example of fairly complex code written by a senior developer](https://github.com/davecgh/go-spew/blob/master/spew/dump.go)
Are you capturing `err` from call to `ssh.Dial()`? It should tell you details if there were any problems during handshake and what authentication methods it tried if ti failed to authenticate. Also, I recommend not setting cipher in the client config - server should know the cipher from the public key of the pair. That eliminates one potential issue.
https://play.golang.org/p/koMxQK9-pR
Things has been answered but let me simply answer anyway. You can see the "go" keyword as setting up what follows it in a separate "thin thread", while continuing on with the program. And since your program ends before it has the time to actually execute that statement, nothing gets printed. I would recommend using VSCode as your editor for Go code. There is an extension that helps a lot developing in Go there. Auto formating when saving the file, and all other nice checks for the code written.
I don't mean that the only purpose of the language is to write network servers. I mean that is very clearly one of the core purposes the authors have in mind, so given that, I find the claim that arrays and maps are enough for everyone to be a bit bizarre. &gt; If you look at the usecases of go it's almost always people using it to replace scripting languages or to write things that best suit scripting languages. Also, while I'm not going to argue, I do want to say that I don't agree. But it's hard for anyone to get a complete overview of what Go is being used for, and for the same reason that's true, it's hard for me to so much as provide solid evidence for my disagreement, let alone proof.
Yep, Canonical had their lawyers add a specific static linking exception to LGPL. (I used to work for Canonical on Juju).
Yes I'm capturing it, but it's only saying Auth failed. Failed to dial: ssh: handshake failed: ssh: unable to authenticate, attempted methods [none publickey], no supported methods remain I'm forced to set my cipher as my host is still using cbc siphers, and they are disabled by default in sFtp. 
I would say that the "fun" comes in being able to be creative and create things rather quickly, while also know that it is rather safe and stable. Also, depending on what you create, you will stumble upon things you probably should think things through to end up with a better solution instead of a hack. This solution might require you to be creative which could be fun.
&gt; But none of those uses include stuff like kernels, drivers, game-engines... etc. That doesn't sound like &gt;&gt;&gt; writing network servers It sounds more like you were expecting me to say "systems language" so hard that you didn't read what I actually wrote and are now giving me the pre-canned "Go isn't _really_ a system language" spiel that is pretty much a dead topic. (Labels on a thing are way less interesting that what a thing truly is.)
Talking with my colleague this morning about the timing of defer in relation to return statements, I realized you could stumble into some pretty unreadable code messing with named return values. Looking at each of those methods, I don't think there's anything too hard to puzzle through, but it made me aware of how bad an idea it is to muck with return values in a defer statement.
Clickbaity title, but still very cool!
Wow that looks almost Haskell-esque. Never seen Go code like that before, honestly. I don't know how I feel about this.
GitLab had this problem for a long time, too.
idk, it seems like people generally have a distaste for bitbucket. Not bad advice though, I would personally recommend GitLab for a free &amp; hosted solution. Sounds like OP is set on self-hosting though.
I don't think you should be doing stuff like that. It is bad design as far as I am concerned and if the language allowed you to do it, it would indirectly encourage that bad design. Use table driven tests in combination with [good design](https://dave.cheney.net/2016/08/20/solid-go-design) in your code (like find a common interface to have as a parameter in your functions).
I would wager that implicit interface implementation makes things _harder_ to refactor. This is one of the few things I don't like about Go.
Dave Cheney works at Atlassian, and GitLab had a major data loss outage only recently this year. I don't know man, Bitbucket is cost effective and reliable is what I'm saying. I'm hosting somewhere around 300-400 repositories (don't ask) and we lived on the free tier for something like 6-7 years before we moved to $10/month. It's amazing and I'll recommend it to anyone :)
it runs itself. it is automatically executed by `go install`
&gt; Contrast that with the workaround of using interfaces (i.e. open sums). If you want to add a new possibility to the sum, you can just define a new type implementing that interface. Old code will just use the default case of any type-switch and can then be gradually updated. If you want to remove a possibility, you can mark it as deprecated, remove it from all switches in dependent code (instead handling it via the default case) and then remove it from upstream. Any sensible implementation of sum types will let you opt out of to compile-time-checked implementation completeness. I don't want to keep inventing syntax, so here's some Rust code: enum State { A, B, // will add C later } fn needs_to_be_complete(s: State) { match s { State::A =&gt; { //something }, State::B =&gt; { // something else}, // will fail to compile when C variant is added }; } fn does_not_need_to_be_complete(s: State) { match s { State::A =&gt; { //something }, State::B =&gt; { // something else}, _ =&gt; { // Some third option } // will still compile when C variant is added }; } 
Have you used the search function on... Reddit? Or Google? 
Golang is fair good for web development and general network projects, big or smaller. We use Iris web framework in our company: http://iris-go.com , a year ago we used Gin web framework but Iris proved to be a better option for our needs. It's pretty active and it has quite a long list of unique features, it has got many examples for new gophers, here you're: http://iris-go.com/v8/recipe 
We've been using Go since 1.2, and it has been great to work with. I think the number one issue we had (and still have a bit on some teams) is when someone tries to write Go like Ruby or Java. It takes a bit of time to "get" the Go way, but it really is not all that long. Maintainability: one story sticks out. We ported over a python/twisted service to Go. Debugging concurrency issues in twisted was a pain. We had a concurrency bug come up and we had a fix out that day. We estimated it would have been nearly a week to have found and fixed the issue in the previous code base. Most bugs are logic bugs (you did not consider something). Like we did not know that order was important on one feature, so we used a map. Oops, turns out order was important, so we re-implemented the data structure as a slice. The compiler and gometalinter get just about everything, oh, and the -race flag. I really like that one. We've onboarded jr and sr developers with ease. Go is simple and can be fully kept in your head. Related, we've had users switch teams and we've moved small and large projects to other teams. There have been no issues. The biggest pains in moving projects come in testing where some team new to Go wants some bdd style tests and their tests are terrible to work with. I think development speed is helped by having some good skeleton code and common libraries that different teams all use in the same organization. A hello-world service that you can copy over as a base. There can be some tediousness to initial project set up (go-metrics, logging, routing, monitoring, alerting) that a default collection of libraries helps get you passed. Outside of that, the way I think is very well supported by the way Go writes. So it is easy to see how something will likely need to be implemented. In this sense, development speed is increased. Performance. We moved (and are moving still) from perl+anyevent and python+twisted to Go (with no framework). We had a fleet of some 130 or so python nodes be able to be covered by 1 Go node. Yeah. We ended up having more for failover and more for reducing latency to different locations and we've grown some, but still very performant. I just wrote a small microservice that routinely spikes to 12k+ queries per second on a given instance no problem. We smooth that out with a load balancer, but expect even our poorest performing services to at least handle 4 or 5k rps for the most part. Artifact: single binary. :). We actually do a bit more than that because we want to package configurations and such and have the same procedure work for python, perl, php, and any of the other languages we have at work. So we package everything up in an RPM and deploy that. Fun. It is not a fun language in of itself. What I find fun is getting product out that works, works well, and works fast. I like writing tests where the tests are fast. One test spins up a dozen instances of an SMTP server, gets a message payload to different parts of the SMTP conversation, times out each one, and verifies proper handling. The test runs in under 10ms. We work in a SaaS system handling billions of events per day and we need to be up at all times. We have over 100 engineers, many teams, and several products. Nearly every team works with Go to some capacity. Every event that goes through our system will touch multiple Go services. I think it is fair to say that Go is my favorite language. There are some warts and things can get verbose. There are some missing features that could make things better. But if you are writing server software, you should absolutely be considering Go. 
Why is it bad design? I'm not challenging you, I've just genuinely never heard that explicitly typing things is bad when already using a statically typed language. The only principle in that article it might violate is rigidity, but it's not actually hard to modify, since the compiler will tell you if you've forgotten to add an implementation for a variant (unlike the combinatorial explosion of valid and invalid combinations of fields that the current Go language forces onto my program).
It seems like a typeless constant, like 0 or 42 except with no default type, to me. https://blog.golang.org/constants
Nice. I'm desperately looking for an alternative to Node and was on the fence with Go. It seems everyone is hating the lack of generics on HN but your post gave me confidence to invest some time to seriously consider it.
yay.... promoting super shady software maintained by a super shady guy.... software no prof. company should use: iris.
I am a lawyer and LGPL is pretty much the same virally as GPL if you can't dynamically link. 
I've switched from PHP (mostly Symfony..) to Go and so far i haven't encountered anything where i'd ditch Go. On the opposite: i couldn't be happier. I'm more productive, write better code etc. etc. pp. Wondering if i hit a wall at some day.
both
From your example, it seems to me that your functions attempt to do way too much. &gt; The actual issue I've had that makes me want sum types so badly is writing a testing specification language. It feels like you are trying to do something very general and abstract whereas you could just write normal plain old boring table driven tests.
There are a number of drivers and game engines on this list that would disagree with you: https://github.com/avelino/awesome-go
And what did it tell you? Is Go used for web dev at all? Or did you manage to see all the duplicate questions exactly like yours? 
rdmin is kataras
&gt; A further issue is the bad error handling. For example, the default Dropwizard HTTP client has GZIP compression turned on by default. However, Go’s HTTP library did not recognize the GZIP headers and tried to read the compressed payload as plain data. This was the start of an hour of troubleshooting. It is a 100% fact that Go transparently handles GZIP compression. If for some reason it didn't ungzip the contents from DropWizard, the bug has got to be theirs, not Go's. 
&gt; From your example, it seems to me that your functions attempt to do way too much. I really don't see what you mean. That functionality has to be somewhere; it's implemented in a bunch of specific functions for each type of test/test action/test expectation. The deserializer figures out which enum/sum type variant each is, either by types or by tag, and then the test runner dispatches to those specialized functions in a match expression. &gt; It feels like you are trying to do something very general and abstract whereas you could just write normal plain old boring table driven tests. Actually, I couldn't. The test runner I was writing was for a fully asynchronous Service Oriented Architecture-based, extremely complex system, where the _most basic_ real world test would look like: 1. Call some SOA action "a". 2. Make sure that the following three things happen, in any order: {SOA action "b" is called with a body matching a given literal; SOA action "c" is called with a body matching a given regexp; an HTTP GET request to the following URL is performed}. 3. Make sure that "a" returns a body matching a given regexp _only after_ (2) is complete. I couldn't find a testing system that supports this and was possible to integrate with the system.
Haha...oh god...this guy is so desperate....
Yes, if you have an old version of Gogs you should be able to easily upgrade. (Do a backup before anyway!). You shouldn't need to upgrade to an older version of Gitea first in this case. Have fun!
Am I missing something ? Because putting [that](https://gist.github.com/vrischmann/705f2c1af4a3dd1888a2b3479cd8b54f) in a package and running `go install` does not automatically call `go generate`.
&gt; I just wrote a small microservice that routinely spikes to 12k+ queries per second on a given instance no problem. This is really impressive. Thank you for sharing! 
&gt; but it's much easier to read than tons of if type == "something" {} else if type == "something else" {} else if ... If you really have to do this then a switch might be more readable. Though I am pretty sure there are alternatives. &gt; Actually, I couldn't. &gt; The test runner I was writing was for a fully asynchronous Service Oriented Architecture-based, extremely complex system, where the _most basic_ real world test would look like: &gt; 1. Call some SOA action "a". 2. Make sure that the following three things happen, in any order: {SOA action "b" is called with a body matching a given literal; SOA action "c" is called with a body matching a given regexp; an HTTP GET request to the following URL is performed}. 3. Make sure that "a" returns a body matching a given regexp _only after_ (2) is complete. &gt; I couldn't find a testing system that supports this and was possible to integrate with the system. Alright, I can feel your pain in this. One of the areas I also experienced some have trouble with Go was when I tried to write code that had to communicate with such a general, overly complex (and in my opinion badly engineered) system like the one you described. Of course the lingering question in my mind was always that, is it really Go that has the problem or the system? Regardless we do not live in a perfect world so if Go had some more flexibility maybe it would help for these special cases. Maybe you should consider writing an experience report.
Why? Even if the guy is shady, b/c of reasons not given, why does that make the software bad, and a bad fit for anyone?
&gt; Personally, I'm OK with most of the absence of "generics" in Go; what I want is some solution to this problem, though, be it generics or otherwise. Yes, exactly. I'm definitely not one of those people who say that generics (as implemented in other popular languages) must exist in Go. But I want a better solution to the same kinds of problems that other people using other popular languages use generics for. And for which it seems to be a good and effective solution. I don't really care what form the final solution for Go is... maybe someone can think of something that integrates nicely with what we've got now, and requires minimal changes otherwise. That would be awesome. Right now, my preferred solution is explicit code generation. But I'd like Go 2.0 to have a big, fat data structures library with priority queues, trees, tries, stacks and everything. And the means to write my own in a straight-forward, succinct, and type-safe way.
Unfortunately just today I noticed [this person](https://www.reddit.com/r/golang/comments/6sqi3u/backend_developers_whats_your_workflow_when/dlf2d56/). Either he is totally clueless or has been blinded by the 7k fake stars kataras put on iris through bots. I wouldn't be surprised if he had some connection with kataras either. It makes me feel sad for the future of our ecosystem.
i'd be interested who actually uses Iris in a serious prod. environment.... like... who would?! :D
It's not a stupid question, it was something I struggled with initially too when I first started contributing. Let's suppose you have the go source checked out in: /home/rawr/Projects/go Let's build the toolchain first: (cd /home/rawr/Projects/go/src &amp;&amp; ./make.bash) Then we can use the toolchain we just build to run tests: /home/rawr/Projects/go/bin/go test fmt -bench =. This assumes that your GOROOT is not explicitly set. Otherwise, you can explicitly set it before running: GOROOT=/home/rawr/Projects/go /home/rawr/Projects/go/bin/go ...
&gt; That's not simply a matter of subjective preference. Whether that's actually a problem, however, is. Case in point: Personally, I couldn't care less.
&gt;- sqlx [...] There's [squirrel](https://github.com/Masterminds/squirrel) and derivatives. &gt;- [...] How are you managing authorization between frontend and backend session [...] There's [Gorilla sessions](https://github.com/gorilla/sessions) and implementing your own interface is trivial.
&gt; b/c of reasons not given [Here's all the reasons you need](http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html). 
&gt; Regardless we do not live in a perfect world so if Go had some more flexibility maybe it would help for these special cases. Maybe you should consider writing an experience report. This is a good idea, thanks.
 $ cd $(go env GOROO)/src/fmt $ go test -bench . -benchmem | tee ~/old $ git checkout -b mybranch ... $ go test -bench . -benchmem | tee ~/new $ benchcmp -mag -changed ~/old ~/new 
Fair enough! However, I should point out that in your example you would need to edit the deferred function to modify `bought` instead of using a direct return.
Bitbucket allowed a corporation add me to their team, it polluted my repos, and wouldn't allow me to remove them. I had to migrate everything off and delete my account. I would recommend staying far away from bitbucket. 
Gross a ```.``` import :(
Any additional info on that? Edit: yes, i'm part of an org, just there's no "pollution" I'm aware of. There are perms settings on everything. And repo ownership etc. so what was the circumstance where you experienced issues?
defer is also slow and there's not many places you ever need it
That sounds good. Are you working for a company? Do you have anything that might help me with the structuring and the architectural patterns? I am a C# dev. When it comes to Golang, I am a bit clueless on where to start. Lets say I want to start developing an Angular2 SPA with Golang as back-end...
&gt; notepad is not an appropriate text editor Just use Atom or vscode, there are plenty of options, all better than notepad. &gt; far from what it is written on the tin It does exactly what is written on the tin. It starts a goroutine. Your program exists before the goroutine has finished. Code execution does not stop and wait magically. Try adding a time.Sleep(time.Second)) after your statement, and see for yourself, then look into how to do this properly with `sync.WaitGroup` and other methods. All very well detailed on [Go By Example](https://gobyexample.com/)
I like the [gocraft](https://github.com/gocraft) stack for routing/sql/logging/user input handling. &gt; At the time, I used JWT but it always gave me a pretty "icky" feeling security wise. What do you mean by that? What problems do you have with its security?
A good choice for a router/middleware framework would be chi: https://github.com/go-chi/chi For a pure Go embedded database, I highly recommend Bolt: https://github.com/boltdb/bolt If you want a higher-level toolkit for working with Bolt, try Storm: https://github.com/asdine/storm As for JavaScript frameworks, unless you're looking to spend *a lot* of time in what will often seem like a compsci seminar taught by a bored non-native English speaker, I'd avoid using Angular, and I'd think hard about adopting React. For actually getting work done, a more pragmatic and comprehensible alternative is Mithril: https://mithril.js.org/
And usually it is overused in places, that require efficiency Metrics: https://github.com/rcrowley/go-metrics/blob/master/meter.go#L201 Even std example: https://github.com/golang/go/blob/master/src/expvar/expvar.go#L133
grpc does context over the network doesn't it? I &lt;3 https://grpc.io/
Thanks! Squirrel looks interesting. Any comment on how suitable it would be for a production system? Gorilla sessions was what I was using in the past. It worked well. I was referring more to JWT. I think it had to do with the particular implementation I was using. And, on reflection, has nothing to do with go. 
I'll check it out. Thanks! Check out my previous comment about JWT. I'm conflating the javascript implementation I was using with Go, and the RFC. My bad.
Chi looks like the spiritual success to goji. Awesome. I looked at Bolt in the past. Unfortunately, the nature of what I'm doing is highly relational. SQL makes sense here. I'll take another look at it though and see if I can't flatten my schema. &gt; unless you're looking to spend a lot of time in what will often seem like a compsci seminar taught by a bored non-native English speaker, I'd avoid using Angular Oh my god, hahahaha, thanks for the laugh. I've watched a few talks so I know exactly what you are talking about. Curious of your thoughts on vue? How does that compare with Mithril? Thanks!
Comes at a cost of less safety and more hard to figure out bugs (compared to rust)
The go-systemd activation package doesn't really have good error reporting. This lines is executed: https://github.com/coreos/go-systemd/blob/master/activation/files.go#L37 which down the line will give me an empty array of net.Listener here: https://github.com/coreos/go-systemd/blob/master/activation/listeners.go#L30 I still have no clue why it's happening. **edit**: strconv.Atoi: parsing "": invalid syntax. Seems like LISTEN_PID isn't being set. Not sure why or how to fix.
Go is not a systems programming language(in the usual sense. This term was used by Go creators for marketing purposes) like Rust. You cannot compare them. 
I'm not sure why they get so much hate. Used very sparingly they improve legibility a lot: `properties = Some(Seq(StringLit(`"`), ":", &amp;_value), ",")` vs `properties = goparsify.Some(goparsify.Seq(goparsify.StringLit(`"`), ":", &amp;_value), ",")` And `. importing`importing a package in the same repo, so there are no BC issues. But maybe its bad in an example?
I have not used Vue. I walked through a tutorial a few months ago and it seems to share many concepts from Angular, and also some with React. It's simpler than Angular, but there's still quite a bit of complexity. But it might be a good choice, depending on your application and how you want the front end &amp; back end to interact. There's an effort to port SQLite to Go: https://github.com/cznic/sqlite I'm not sure what state it's in. (I keep hoping to see an announcement that it's done and ready for use, because it would be *awesome*.) 
The fact that you found the easiest tool for you to accomplish some needs does not necessarily mean does not mean that it's the best tool for every need, nor does it mean it's the best tool for someone else to accomplish those same needs. Depending on chance people here might agree or disagree on your statement, but they are themselves not correct, since nobody know how you think and we don't know what your needs are. It's normal that your first response to a language you like is to praise it, however praising it will not help you understand it better, stretching it and finding negatives about it will. Asking questions about the areas where a language is weak will bring out the people who truly understand and can converse about said language Lastly, if you are a programmer, keep in mind that your goal shouldn't be to learn a single tool very well, but rather to have an arsenal of dozens, maybe hundreds of tools at your disposal for any situation.
https://github.com/mcandre/toys yeah i been around the block a few times
Happy to take a look, but why not put the code on play.golang.org and share a link? There people could see it easily, and you could remain anonymous.
Rather than forking Go, it would probably be easier to write a pre-processor that allows you to write code that "has generics" and converts it into valid Go code. Then you don't have to worry about your code not working with other Go code and we could at least explore the use cases for generics and see how much they get used in the wild. Edit: I can't answer your original question, just suggesting an alternative approach to solving the same problem
&gt; I'd think hard about adopting React Care to elaborate? React can be one-way with Redux or two-way binding with MobX. There's so many packages in the React ecosystem compared to what you're suggesting. React is the safest choice of any the frameworks. It just works.
I've use Rust and it's definitely not easier to debug than Go. If anything it's much more difficult. The main reason Rust is unpopular is because it's notoriously hard to reason about rust code and the code bases are always atrocious. 
Where did you see gRPC is Alpha?
I'm referring to the memory safety that rust guarantees. As in a rust program will not compile if it has a whole class of bugs which go does nothing to protect you from
I'd recommend breaking the application into an API backend and a static HTML/CSS/JS front-end.
Separate your application into an API backend and a static HTML/CSS/JS frontend. You'll be happy you did. :-)
How do you plan to add generics? What kind of generics? Which problems do they solve? What are the disadvantages of your solution? What are the benefits? How does it compare with the 4 decline implementation of generics in Go proposed by one of the Go Team members? 
We've used Go for almost 4 years in my group at day-job. I don't think anyone in my group had done any substantial work in Go before starting. Our experience has been very few bugs. Lots of things run for many months or even years and just need changes as other things change or when we want to add feature. More than anything else I've worked with it's been easy to pick up "old" code and continue development/maintenance as needed. We are a little over a dozen people in the group now and do software development and SRE type work for "infrastructure services". Lots of network daemons and related utilities.
I think the best thing that does what generics do is actually generics. It's kinda like trying to replace a screw with something that's different but still has the same uses. Inevitably you're just gonna have a slightly different screw. And that's ok. To me it's pretty obvious that Go needs generics. There's all sorts of little cases where generics would make life more pleasant. Sure you can sometimes flip things around like sort.Interface. But the honest truth is that sort.Interface is ugly. sort.Slice has a nicer interface but it uses reflection. It's one thing for the stdlib to have some ugly bit's to gloss things over, but I'd really rather limit it in my code. Also, I don't think the confusing situations of generics in other languages need have the same impact on Go. Much like Go encourages reduced garbage creation. I suspect it could also encourage more judicious use of generics. We'd still have interfaces, Composition over inheritance and meaningful zero values.
Everybody wrote custom compilers. Have you ever implemented generics in a compiled language? because that's a totally different endeavor.
If you understand the compiler details enough to complete this task, then you will also know where to start.
&gt; To me it's pretty obvious that Go needs generics. I can't argue with that position. But I don't want to constrain the design more than necessary either. At this point, if be happy to see any progress on this front. Even if it it's just a glorified code generation system, as long as it is officially sanctioned. 
Cue the haters (why are you reading /r/golang?)
hehehe i mean there isnt really an r/polyglot for programming eh
 Hi! This is just a friendly reminder letting you know that you should type it as `¯\\\_(ツ)_/¯` to format it correctly. When trying to type the shoulder shrug emote, the \ makes the special character in front of it disappear. So if you typed the shoulder shrug guy with one backslash, it removes the formatting that the two underscores would do. If you typed two backslashes, then the second backslash cancels out the first backslash, making them both disappear, as well as the two underscores disappear as they make the face turn in to italics. By having three backslashes, the third backslash cancels out the second backslash, but still allows the first backslash to remove the formatting, but still appear visible. One backslash - ¯\_(ツ)_/¯ Two backslashes - ¯\\_(ツ)_/¯ Three backslashes - ¯\\\_(ツ)_/¯ --- *^I ^am ^a ^bot. ^If ^I ^have ^done ^something ^wrong, ^please ^message ^my ^owner, ^[John_Yuki](https://www.reddit.com/user/John_Yuki/).* *^If ^you ^want ^me ^to ^ignore ^all ^of ^your ^comments ^in ^the ^future, ^reply ^to ^this ^comment ^with ^`!ignoreme`* 
&gt; Care to elaborate? What you said: "There's so many packages in the React ecosystem compared to what you're suggesting." There's at least a hundred different ways to build something with React, depending on the combinations of packages you choose to use. That's a hundred combinations of just the most popular options for just core functionality. And what's popular changes frequently over time. If you move beyond the popular/core packages the number of different ways you might approach building something with React is effectively infinite. Personally I don't find it appealing to have to spend a month researching different alternatives for achieving core functionality, then constantly wondering if you made the right choice, and revisiting your choices every couple months because there's some new hip package that everyone's talking about. Your tolerances and tastes may differ. 
Thanks for the clarification, you're right. I forgot Canonical uses a modified LGPL license for Go code. There's an added clause that allows for static linking. Would love your thoughts - https://github.com/juju/errors/blob/master/LICENSE
It really was never a big deal. A few times it was slightly annoying, but definitely far and away worth all the other benefits.
Thanks. Btw, [this is the HN post I was referring to](https://news.ycombinator.com/item?id=14763111).
The best place to start is the “fork” button on Github. I don’t think there is any board or secret group you need to get permission from. 
To go further off this. If you need to ask such a question you simply do not currently have the knowledge / know how needed to do so.
I think this is really just comfort with the language. I can bang out go code as fast as any similarly experienced pythonista can sling python, and do similar jobs in similar times. If python was more than 10% faster to write in general, I'd be surprised (except for some limited cases).
We're using Gitea in our local development. To be fair, I have to made some changes in Gitea UI but all other things works great. The only thing I miss in both Gogs and Gitea is the comment section for git commits but Gitea contributors is working on it so I will vote for Gitea :)
This or something like this. How is localization of strings an issue? Since its a legacy app you should already have the means to do this. If you're adding it as a feature you'll need to do more research and probably some restructuring of your data, but I assure you its very possible.
Strings are immutable, meaning you can't alter them in Go. Instead you will need to create a new string, much like you are doing. That said, you can do this a little simpler with something like this: https://play.golang.org/p/ZRKxTyLGhk
There are gotchas with any language, Go isn't immune to them. Ones that have burned me at various points: . Maps can't be used concurrently, if 2 goroutines are both accessing it, your program will eventually panic from contention. . OSX cross compilation doesn't work if you need cgo. . Spawning goroutines with an iterator as an argument [probably won't do what you expect it to do.](https://play.golang.org/p/lr7VZny412) Etc. Again, nothing unique to Go.
&gt; claims that Golang is not good for web application development Where? Golang is fantastic for web apps. There are multimillion dollar companies using Go to power their production backends. Compared with the current fare of webdev languages such as PHP, Ruby, and JS - Go is a dream. In general, with Go you'll have less bugs, good to excellent speed, and a highly maintainable system. My only gripe is that it doesn't have much in the way of baked-in higher order functions. Those these were left out intentionally in the interest of simplicity.
Thanks, that's perfect! 1 small follow-up. You had used b[i] = '*' which I casually changed to b[i] = "*" Which throws error cannot use "*" (type string) as type byte in assignment What's the real difference between single and double quotes here? Are both not strings?
HN is a special special place :\ 
No. The `'*'` is a byte, whereas `"*"` is a string composed of a byte slice of length 1 (plus some other data). In other words, `"*"` is conceptually similar to `[]byte{'*'}`. The difference is subtle, and most of the time you probably don't really need to think about it, but it is important in this case. It is also different than many other languages that allow you to use `'` and `"` very similarly. 
Are you distributing the package to outside your org? as the GPL cross over only applies then. 
We've had some code that was not great. very not great. Incredibly racy, not tested, poorly structured and leaky. Once we rewrote that it's been really great.
Thanks a bunch. Yeah I'm coming over from ruby where `'` and `"` are almost identical (except that the latter allows interpolation). I have to get into the mindset of thinking about what *type* each variable is, which is probably been the most difficult part of the transition
Go is amazing for web apps.
The challenge in Go with having `Some(T) | None`, is that the real value then comes from guaranteeing `T` can't be `nil`. But there's no sensible zero value for interfaces which *isn't* `nil` (or equivalent). If there's no sensible zero value, then the compiler has to ensure that you've initialized each interface value before use. This is easy enough for variables, but becomes tricky when you're dealing with e.g. arrays. And it's contagious, since any struct containing a non-zeroable field is also non-zeroable. Maps and channels wouldn't be able to give you a zero value by default, either, or else you'd have to constrain the types you can use with them to zeroable types (forcing non-zeroable types to be stored as optionals). Everywhere where there's comma-ok return values would have to become `Some(T) | None` (you'd probably prefer this anyways, but still). As far as design churn, having types without zero values disturbs things quite a bit. All the complexity that was avoided by having zero initialization would be introduced into the language. In languages which have this, it can be great, it's just a big change for Go.
There is actually a book called "Go Web Programming". 
What I meant was: There's *obviously* a million ways to do this, but there's not *one* obvious answer. That's why I'm interested in how other people did it. I'm also capable of doing and caching some queries. It reads "architecture" in the title because that's where I'm not sure. And, indeed, I need to do research: That's the *whole point* of me asking for recommendations to look into because I'm having a hard time finding that stuff.
err named shadowing QQ
Thank you! This worked for me too!
Ahh .. right. You have to use the toolchain go. Thanks ! makes total sense. 
Squirrel merely does string concatenation correctly for you and appears plenty mature. I haven't had any problems, while the ability to dynamically alter queries fundamentally and with ease made for significant increases in development speed and clarity whenever I had something like a base query that I needed to alter with a list of optional clauses depending on user input. With regards to JWT: You may want to look into [fernet](http://blog.dolphm.com/openstack-keystone-fernet-tokens/). There's an official [go version.](https://github.com/fernet/fernet-go) From what I understand, JWT is not a good choice if you're not an InfoSec person because there's a lot you can mess up. Fernet is simple and a pleasure to use and the critical parts have been taken care of for you.
Rust code that compiles is fairly straightforward to reason about. Figuring out why Rust code *isn't* compiling is where it can get difficult ;).
The term was used by the original team because of a difference in internal languages and language as used by other orgs. 
The strings package is your friend. https://play.golang.org/p/E4k4zT9ATK package main import ( "fmt" "strings" ) func main() { str := "hello123abc" fmt.Println(mask(str)) } func mask(s string) string { if len(s) &lt;= 4 { return s } return strings.Repeat("*", len(s)-4) + s[len(s)-4:] } 
* [syncmap if you need that special case](https://www.youtube.com/watch?v=C1EtfDnsdDs) or wrap your map accesses with locks. * cgo :\ * https://play.golang.org/p/5-2P7ntH7t 
I couldn't leave the "org". There was no way for me to leave. Bitbucket's interface for repos included everything. I had to filter just to see my stuff. And there was no way for me to remove myself from the org. Also, I believe they kicked me out twice. I had some sensitive stuff on there. This kind of bug was complely unacceptable. I've used Gogs in it's place. 
Not sure why you're being downvoted, your repo there does indeed have a ton of languages in it...
&gt; Should I build/compile this code into an executable and run it? Yes. In fact I would suggest that you use **go build** locally. **go run** caches stuff between runs (I think) and as a result sometimes you get different outcomes &gt; how does one build and run the binary? go build main.go (assuming main.go is the file that contains your main function) &gt; would my page automatically be available at http://123.123.50.50:8080/hello Yes &gt; do I need to set up something like nginx to route all the incoming requests to my Go process that's running as a daemon I'd say that depends on a couple of other factors (load balancing, application architecture, security, etc) but **net.http** is solid enough to be used on its own 
Wohoo double comments :D. Good answer though. 
I would propose that none of these items are unique to go.
Ian Lance Taylor wrote a [proposal for type parameters](https://github.com/golang/proposal/blob/master/design/15292/2013-12-type-params.md) which is very good and also contains extensive implementation notes. So, I'd start with that. When it comes to "what are the specific steps to add a new feature like that", I'd watch [Robert Griesemer's Talk](https://www.youtube.com/watch?v=vLxX3yZmw5Q) from dotGo about prototyping go designs. He outlines a bunch of useful steps that you can work from. I'd also think very hard about how you intend to maintain your fork. You need people to actually use it, so you should build a good community around it from the start. Otherwise it's just going to be a lot of wasted efforts… This part is going to be the hardest but also the most important.
We make a large effort to avoid knowledge silos, and will intentionally punt smaller objectives to get them up to speed. It requires a minimal amount of coaching from the author, but has the added benefit of raising skill levels across the board.
I have had zero performance issues in go. We deploy our binaries on alpine via docker so we have a very nice micro service platform.
Thanks! It looks like `go build main.go` will build it. Is there a particular way to execute the binary? Perhaps with `go run` ?
Parse it with `encoding/xml` and handle the resulting Go structures 
High five! I agree and I'm glad you appreciate it for these things as well. :)
Do you mean something like this ? https://www.goinggo.net/2013/06/reading-xml-documents-in-go.html am I forced to define all the node and child or can i just define a struct for my needed node ? &lt;Products&gt; &lt;Product&gt; ... ... &lt;/Product&gt; &lt;Product&gt; ... ... &lt;/Product&gt; &lt;/Products&gt; Could i define only Products and Products even if i have ton of child under Product ? My final purpose is to write 1000 Product into seperate file.
Tools that do this already exist though: - https://github.com/cheekybits/genny - https://clipperhouse.github.io/gen/
assuming your OS is linux, to run it just do: $ ./nameOfYourExecutable note that "$" is the terminal prompt 
woohoo, thanks a lot. Done, works like a charm.
I think this is just a lame answer. There's a big difference in knowing how to write generics support for a compiler and knowing where to start writing them in a code base you haven't worked on before.
use os.OpenFile to get a file handler, and then use that in place of os.Stdout. That's all you need.
About my organization: We're using Go substantially at [openebs](https://github.com/openebs). We have projects like [maya](https://github.com/openebs/maya), [maya-apiserver](https://github.com/openebs/mayaserver), [longhorn](https://github.com/openebs/longhorn)(fork of rancher/longhorn) etc. You can have a look at our Go projects. Our experience: * Go is easy and reliable. Go has very helpful as well as welcoming community. * Go code is easy to maintain as there are many built-in tools which help you to maintain those. You can always follow standard practices to maintain your code. I think [blog post](https://blog.openebs.io/openebs-building-golang-storage-kit-project-maya-6cbdce2c4df5 ) will be useful for you to get started. * Go has tools like go fmt, go lint, go vet etc. which will refactor your Go code to remove any unwanted bugs or code. Garbage collector is smart enough to grasp the errors and complain about those. All you need to do is to focus on your logical flow of your program. * The simplicity of Go is attracting new talent towards it. We have fellow developers from intern to Architect (who mostly came from system programming background) have adopted Go in less than a month (Impressive, ain't it?). There are plenty of resources available on the web to get started. * Development speed in case of Go depends on what you're working. If the design/logical flow is ready then all you need to do is fire your machine up and grab the coffee. There are open source tools such as vim-go, vscode etc. will increase your productivity tremendously. * As you know Go is compiled and doesn't depend on any kind of interpreter. If your app is built in Go then it'll be easy for you to deploy it as it'll be single executable file/binary. Hence, hassle free deployment. * The only challenge we faced during development is dependency management. You need to be more careful about how you manage the dependencies! There are excellent tools available such as glide, go-vendor, go-deps etc. These tools will help you to manage dependencies but still, you should be wise enough to know what to use. Overall we're happy to use Go in our day-to-day life. Thanks to the Go community!
I personally would inject into your "thing" a `logDestination io.Writer`and then when logging use it with `fmt.Fprintf(logDestination, "hello world")` That way you can more or less send your logs anywhere and it's just a matter of configuration.
That's my point yet I got downvoted for it and you get upvotes :)
While both of these have their uses, I don't think either do what OP or I had in mind. These tools could possibly used for what I mean, but they aren't a complete solution. What I am referring to would be writing code as if generics were in the language - so maybe writing code that looks like: var a List&lt;int&gt; And having a tool automatically detect that you need an integer version of your list generated doing so, and then replacing your occurrences of that type before building your code with standard go tools. It would be like building a new language that compiles into go code and then into a binary. I suspect doing this would be a little easier than trying to fork go and add generics yourself with little knowledge of the codebase, and it would give us all a tool to experiment with to see what works well and what doesn't when it comes to generics and Go. It is also possible this is a shitty idea, but if I wanted to add generics to the language I would start here before forking.
Right. But there are languages (even one mentioned by OP) that will not compile if you don't do 2 of these things correctly And syncmap isn't type safe :/
Writing hello world and fizzbuzz doesn't show even basic understanding of a language...
Could you please give an example of this? I'm quite curious. I've worked with languages like Scala before, so understand things like option types, do you just mean that sort of thing?
It's not _just_ option types. I'm not a Rust programmer, so take this with a grain of salt, but I think the biggest thing is - you can only _"borrow"_ references. As in - you must return them or the code won't compile.
Then you create handlers for the different pathes you need, and serve the files for your spa as static files. 
I just find it funny how much hate this guy got by beeing a dick :D
You only need to define the fields in your struct that you need (and the parents to that field)
Well he didn't just write hello and fizzbuzz ...
Thank you for the reference.
I used the code in the link below, but i can display only the attributes of one or all product. I don't understand how to display a complete product node...
you probably want `[]Product` not just `Product`
&gt; git describe (--tags) So the aim of the post is to empower the reader to start using build-time arguments. If you prefer the tag-version of a commit, more power to you and the goal of the blog has worked. 
You can implement this however you like.. the blog is showing how to use the ldflags override. That's the only goal. 
See Docker / Moby and associated projects as a prime example of where `go install` is not the primary distribution method. If that is a deal-breaker I am not sure this is for you. YMMV Isn't Kubernetes the flagship project for Go? How about this? https://github.com/kubernetes/kubernetes/pull/1014/files#diff-9283775b0feecc10455ec28bd08983b0R44
In the first few minutes there seemed to be an influx of haters (their posts got upvoted, etc).
What's your purpose, for better maintainability or performance? I don't think Go will perform much better if your ruby code use XML library optimized by using C extension.
This is the sort of thing you see the Go team asking to park the idea indefinitely. It's been done in many languages and solves many problems. Just fork and implement the damn thing!
And destroy everything while you are at it. Because who cares for engineering when you have brilliant minds forking and just implementing? I hate that this language is becoming so much more popular with people like this.
This is not possible because in this case any symbol can be resolved in several declarations depending on OS or arch, and these declarations can have different types on different OSes/archs, having a wrong type in any point makes the whole further resolving/validation wrong. E.g. `os` package contains different `file` types for windows, unix and posix. Even if IDE resolved some symbol to `os#file`, without target OS it cannot say what fields and methods the type contains, so it cannot validate anything. You have to know exactly OS and arch to validate your code properly. You could think: but then just scan this for all the OSes/arches in the project. Imagine your project supports 3-4 of these combinations. Would you want everything to be slowed down 3-4 times while the IDE tries to validate the code all over again and again for ever combination?
It was a marketing term. Get over it. They don't use it anymore.
&gt; I'd love to swap out Stdout for something else, like a file or text buffer. I'd also love to be able to read from that buffer so I can validate output for certain functions. &gt; Problem is, I'm new to Go and I have no idea how to do that! The correct way to do this in Go is to implement the interface that `NewBackendFormatter` expects, in this case `io.Writer`: type Writer interface { Write(p []byte) (n int, err error) } That is, anything with a method matching the Write signature. Use (or create) a type that matches this interface and you can use it as well as `os.Stdout` as your backend. What you are looking for specifically is probably `bytes.Buffer`, or occasionally something that just discards the data: b := &amp;bytes.Buffer{} logging.NewLogBackend(b) // do something with b.String() or type discardwriter struct{} func (w discardwriter) Write(p []byte) (n int, err error) { return } // ... backend := logging.NewLogBackend(discardwriter{})
Hello, This is a common question in the Go community. Please [read my previous answer](https://www.reddit.com/r/golang/comments/56wk4v/structuring_go_api/d8n4axl/) on a similar topic. &gt; Will be this organization correct? &gt; main.go &gt; users/users.go I believe that instead of a generic package name `users` which would lead to `users.User`, it would be better if you used a package name that is relevant to your application or domain. So for example if your application is called `dpe` then you would have `dpe.User`. Using a single `main.go` on the root of your project is a common way to start a project. If later you decide that you need more commands, you might want to do something like this: cmd/dpetool/main.go cmd/dpeserver/main.go dpe/users.go A good project to draw inspiration about code organization is [Upspin](https://github.com/upspin/upspin).
&gt; Just fork and implement the damn thing! I agree. You are now, in this thread, already at least two people (you and OP) willing to put in the work to do it. I suggest setting up an E-Mail list and invite them, to coordinate the work.
I'd argue that it's not overused. Ensuring that a mutex is unlocked is good use of defer. Even if it looks like it's unnecessary, it makes code reading and habit consistent. Those cost way more than the few nanoseconds it'll save.
You can always check http://downforeveryoneorjustme.com/ for this. But yes it looks like its down.
Wow that's neat! Going to try it out!
Thanks a lot! Sorry for asking something already answered. I'll check the articles in your previous answer.
it just came back on
My purpose is performance. I handle a 20go xml file today, but this file could be 150Go in the future. I need to find a quickest solution than the ruby script.
Actually `'*'` is untyped rune or int32. The interesting thing is that it can be implicitly cast to the int16 or int8 type. But you should also remember that symbol can be a UTF-8 symbol - and if you try to represent it using byte type. bad things will happen. Case in the point: https://play.golang.org/p/YthQootOoj BUT! Go slices can be converted from strings and vice versa - the Unicode symbol will just occupy the 1-2-4 bytes it'll need.
That sounds like an interesting concept, I'll have to take a look into it more. I'm not sure I understand what you mean right now.
Run "godoc -http=:9000" and [hit your local machine](http://127.0.0.1:9000/pkg/). godoc.org still has some other useful features; I think it has the best "Go package search" around, even better than trying to use Google, and for that alone it deserves kudos. But you never have to worry about it going down, or being inaccessible if you're not on a network, because you carry your documentation with you.
for a web server type [project](https://bestfoodnearme.com) I use this structure below. I use the Makefile to build the binaries under main, to run all tests, to compile sass to css and minify it. / Makefile /sass/ /tmpl/ index.tmpl /css/ /js/ /images/ /main/ server.go microservice1.go microservice1.go /lib /database/ /config/ /controllers/ /models/ /utility/ /vendor/
Point taken.
It can be hard to explain if you've never been exposed to any of the related concepts, so I'd definitely suggest going and spending some time with Rust. If nothing else, it will sharpen your own understanding of Go, and many of the issues related to concurrency in general. Very handy even if you never use it. As much as I like go, which you can see from my /r/golang postings and blog posts, there is definitely a set of tasks that I would never dream of using Go for and Rust is a far better fit, even considering its additional complication and such. I'd _never_ dream of trying to write [Servo](https://github.com/servo/servo) in Go, for instance. Trying to write a browser engine in Go would be maddening. On the other hand, I've spent the last week bashing out a prototype for a network system, and writing it in Rust would be pretty maddening, too. (One could theoretically argue that the final product might be better in Rust, though given the concurrency levels I'm going for they might still have a hard time arguing that. But even a Rust expert isn't prototyping this as fast as I am in Go.)
Definitely not you, it's pretty wonky right now. I can establish a TLS session and send the request, only after a couple of minutes I get an Internal Server Error back.
Others have covered the proximal issue, so I'm going to step up one [level of "why?"](https://en.wikipedia.org/wiki/5_Whys) and suggest that it sounds like you're setting a global variable as your logger, which left you unsure how to deal with that in your tests. Your code snippet suggests that too, though I can't be 100% sure because often people simplify bits for posting. That is actually your core problem. You really should be passing that around, possibly bound together into other objects or composed in. You should find that once you start doing this, especially with composition, that it's easier than you think. But you do need to bite the bullet and start doing it before you can see that. :)
**5 Whys** 5 Whys is an iterative interrogative technique used to explore the cause-and-effect relationships underlying a particular problem. The primary goal of the technique is to determine the root cause of a defect or problem by repeating the question "Why?" Each answer forms the basis of the next question. The "5" in the name derives from an anecdotal observation on the number of iterations needed to resolve the problem. The technique was formally developed by Sakichi Toyoda and was used within the Toyota Motor Corporation during the evolution of its manufacturing methodologies. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
I've used grpc a bunch of times and it's the easiest way to create an API I've ever used. You can even multiplex multiple services on one tcp connection. Super nice. 
In both production at work and for personal projects, I use the std lib net/http for all endpoints. I use Angular 4.3+ now for front, and whenever possible we use asdine/storm for data. Embedded data like that takes out most of the dev time, bugs, and complexity from talking to SQL whereas it doesn't eliminate all the sorting, joining, and filtering of foregoing SQL. When we need a full SQL driver (which is still most of the time) for Postgres or SQL Server, I don't use SQLx and stick to standard library. We're considering SQLx, but we try to keep deps to a minimum, and we aren't huge fans of ORMs since we're pretty comfortable with SQL and like to use the power available to us in SQL. Generally we use a session token stored as an Auth header to allow for centralized invalidation, added to requests with Angular's Http Interceptor. If you can't stand net/http, Gorilla is mainstream enough to accept as a dep (and it seems to be pretty well written), but I don't feel like I personally gain much since query params are easy in net/http for GET requests, and since that only affects my URL for API calls (Angular takes care of anything in the URL bar), it doesn't affect anything I can see in a negative way.
It also won't compile for lots of valid code. It's a trade-off.
"serverless" is such a bullshit bingo word. What's it running on if not on a server? Banana? Cup of coffee? Thin air? Nevertheless, nice article ;)
React, Redux and choose your UI react-bootstrap or material-ui. While there are *many* choices those are the staple. 
NO, nil are many values. The word "nil" is just a literal to represent these values. Only boolean, numeric and string values can be used/called as constants in Go.
Personally, I use a lightweight leveled logging, with Info messages passed to stdout and Debug and Error passed to stderr. Then I have a DEBUG environment variable or command line argument to enable the Debug messages. Originally I set it up like that because of my cloud environment's log handling, but it works well for local purposes too. It allows me to run tests concisely, then add a -debug flag if I want to see all the details.
**GENERIIIIICCCCCCSSSSS!**
Still down, just tested from 70 machines across the world: https://pulse.turbobytes.com/results/598dba3aecbe405ffb020e7f/
I recently switched to chi. I started off with httprouter, but when Go introduced Context, I switched to [a fork of httprouter](http://bouk.co/blog/context/) which had been updated to use Context and the standard Handler interface. Unfortunately the fork never got any proper release, as I discovered when migrating my projects to `dep`, and [a year on](https://github.com/julienschmidt/httprouter/pull/147) httprouter still hasn't been updated (even given that the work was submitted as a pull request), and in fact [it looks like the project may be grinding to a halt](https://github.com/julienschmidt/httprouter/issues/207). I considered switching to stdlib ServeMux, but manually routing based on HTTP verb was a bit more work than I wanted to do when I'm trying to get a release out this week. Goji 2 looked good, but chi won me over with no external dependencies, closeness to ServeMux's API, useful middleware, and signs of recent activity.
This subreddit has a purity problem. You framed your comment in a way that gave the appearance of suggesting that a feature of another language might be an advantage. Contrast with the comment saying all Rust code bases are atrocious, which got upvotes, and it's pretty apparent that a lot of people here are of the language wars mindset.
. Native syncmap has its own caveats, it's slower in most cases and doesn't do types. It's also a new feature in a release candidate. . cgo is a necessary evil. As much as I don't like to use it, sometimes there is no alternative. . Knowing how to work around a gotcha doesn't make it not a gotcha. 
VueJs is great. I've used all the big players at this point, and it's my favorite. In particular, the "single file component" implementation. It works similar to web components al a Polymer, but without all the polyfills.
Just post it, we'll be gentle.
This is the least bad proposal for new error handling semantics I've seen. I'm still not convinced it's necessary for errors, but the defer handling seems nice.
I'm not sure what XML library you're using, as it's not Ruby's standard library XML handling (REXML). Anyway, use Nokogiri and you'll probably [get a good speedup](http://www.rubyinside.com/ruby-xml-performance-benchmarks-1641.html). Nokogiri uses compiled C libraries for the heavy lifting, so it should be close in speed to Go, if not faster. If you're using a wrapper over libxml, which it [looks like you might be](https://xml4r.github.io/libxml-ruby/rdoc/classes/LibXML/XML/Reader.html), then you're already using native C code for the bulk of the work, so you probably won't get a big speedup from Go.
Well actually, he wrote programs that print their args, generate fibonacci numbers, copy stdin to stdout, etc. What's your point?
It wouldn't happen if they were using iris /s
/r/Programming is a bunch of code monkeys that get paid 35k/year to maintain legacy java and c++ code bases. Most of them are monoglots who depend heavily on a powerful IDE to do everything for them. It could even be argued that they know the IDE better than they know the languages. Stick to mailing lists if you want to talk to good programmers. Even hacker news is complete shit because fanboys use it as a platform to push their dumb agendas.
truth. fizzbuzz is chump change, how bout a practical exercise in decrypting legacy cisco passwords https://github.com/mcandre/ios7crypt https://rosettacode.org/wiki/Multiline_shebang or check out some shallow quickcheck ports
 A lot of people end up noticing that the "valid code" that it blocks is often actually subtly incorrect. However, there are certainly situations where code which actually is correct is rejected by the compiler. There's currently a [proposal](https://github.com/nikomatsakis/nll-rfc/blob/master/0000-nonlexical-lifetimes.md) to fix some of the most glaring "it would work if you just let me" restrictions. There are always going to be situations where the set of invariants Rust enforces to ensure correctness won't be a good match for a particular use case, though. Certain code might be correct based on a different, incompatible set of invariants which the compiler can't/won't verify. On the other hand, code which is correct today due to a more specialized (but often undocumented) set of invariants is likely to be broken in the future by a maintainer who isn't aware/mindful of them. By imposing a fixed set of invariants which can be checked, Rust removes this particular risk.
/u/howeman maybe another shot at multi-dim slices -- in Go-2 ?
Run it in a docker container with --restart=unless-stopped That way, of the API dies, the docker container will also die, and docker will restart it. If you're running in Linux, systemd has similar options, but docker is easier and more portable.
[Of course, unless something like this is in a critical hot-path the best solution is likely the one that is easiest to read, understand, and maintain rather than what a benchmark says; so unless you're curious ignore this completely :)] Using `strings.Repeat` was my first thought as well, but I was curious so I ran some benchmarks and compared a few solutions. Using `strings.Repeat` like this is slower and uses more memory in all cases compared with using [`[]byte` loop with a final `string` cast](https://play.golang.org/p/ZRKxTyLGhk) as given previously. Minor gains can be made with fixed `"*****…"` constant string sliced in as needed (e.g. `return mask[:i] + s[i:]`) but only between ~32 bytes and the length of the constant; if the input token is known to always be of a fixed size this may be the fastest and easiest solution. After ~96 bytes a variation on the `[]byte` loop that starts with `bytes.Repeat([]byte{'*'}, len(s))` and then overwrites the last 4 bytes from `s` becomes faster. 
 Okay I have added you to my ignore list. This is the last comment I will ever reply to you. If you wish to be removed from the ignore list in the future, please PM my owner, whos profile can be found in the footer below. --- *^I ^am ^a ^bot. ^If ^I ^have ^done ^something ^wrong, ^please ^message ^my ^owner, ^[John_Yuki](https://www.reddit.com/user/John_Yuki/).* 
Some of us on /r/programming code JavaScript. I like a good IDE too. 
Maybe... I still think the proposal is the way to go, and that it's not good enough. I think the alternatives are to make slices strided (which could have nasty interactions with C but would fix the within-go problems), or to use the "index expressions" proposal. Index expressions plus some kind of range idea would be 95% of what we want. That said, an experience report about the issue is on my list.
I'm talking about the sections on sections [Ownership](https://doc.rust-lang.org/book/first-edition/ownership.html), [References and Borrowing](https://doc.rust-lang.org/book/first-edition/references-and-borrowing.html) and [Lifetimes](https://doc.rust-lang.org/book/first-edition/lifetimes.html) in the rust book. Funny enough the Meta section of those chapters includes this quote &gt; However, this system does have a certain cost: learning curve. Also funny that I use go more than any other language by a long ways and absolutely love it, but it does have it's downsides (as every language does)
A nice approach to keep things simple (or avoidable, maybe), but I don't think this is what the Go devs care about-- they're primarily concerned with the compiler / low level implementation of generics as opposed to usage and syntax.
&gt; `go run` caches stuff between runs (I think) I'm pretty sure it doesn't. But there are a bunch of other reasons it's often undesirable (e.g. with more than a single source file you need to list them all, but a niave `*.go` will include `*_test.go` files and ignore build constraints which is usually not what is intended or desired). &gt; `go build main.go` This keeps all the bad parts of using `go run` with respect to multiple files. You almost always want to just do a plain `go build` without any file arguments to build the package/program in the current directory (I'd say without any arguments but using package name(s) as arguments can be very useful). Also useful, if you use `go build` a lot without doing `go install` much, is to use `go build -i` so that your dependencies get installed so you are not re-building them needlessly. 
What is this Go 2.0 thing? Is it real? Or is it like that Go dependency manager which is not official but community based?
Nothing beats server side rendered pages. Why do people avoid this with Go? Why is Go not ideal for frontend? It even comes with templates in stdlib.
It's not that people avoid this in Go, it's that people avoid this currently in general. Hence the insane proliferation of front-end frameworks to render pages client-side. There are pros and cons and I can't say "nothing beats" either approach - just use the right tools for each job. Server-side rendering is great unless you want to do a lot of client-side shenanigans like soft refresh, in-page navigation (e.g. SPA), etc. If you're already significantly modifying the page after load, it's often simpler to just do all the rendering client-side rather than repeat your rendering code in the server and the client. There's also the fact that most web applications today include a full REST API; once you've built the API, the barrier to client-side rendering is drastically reduced. Plus, having the client-side code fully static gives you a lot of operational flexibility - host the UI in a CDN with long cache lifetimes, then scale the REST API service as necessary to handle just the service calls. It just depends on the particular needs of the project.
Ah, great idea. Thank you. I'm imagining having it behind an Apache server too? Forwarding requests to a port.
A couple of the examples don't use named return values, Eg. bar/baz
recently, I played with translating a little python analysis of a friend, seeing how it fare in Go: - https://github.com/rmadar/ADCTimeSeriePCA - https://github.com/rmadar/ADCTimeSeriePCA/blob/master/main.go one thing that was pretty painful was to extract columns out of my mat.Dense and plot them. using `[]float64` as franca lingua for `gonum/plot` is great, straightforward and simple, but then you need to "materialize" your biggish columns of matrix data into `[]float64`. every. single. time. and use more memory and cpu: this could be sidestepped with nice ndim-slices (with strides)... (with `gonum/plot` taking ndim-slices+strides as an API)
So?
go 2.0 is the next big version of go. The devs are collecting use cases for potential changes/additions.
&gt; Nothing beats server side rendered pages Surely you're joking. That's almost as antiquated as saying "nothing beats smoke signals." Breaking the app in two makes you really consider the operations it performs. These operations turn into API endpoint micro-services (which Go is fantastically well suited to), which can be re-used by iOS, Android, and third-party client applications. &gt; Why do people avoid this with Go? Because people who use Go are ahead of the curve in adopting great technology.
How is this different from the bitter backtalking of 'us Gophers' that just don't realize that Rust and Kotlin are so much better? Go isn't really moving as much as Rust, Kotlin and the other trendy languages of the general programming forums. Don't get me wrong, I really like Go. Generics would make it awesome, but for my use case – replacing clunky node.js servers hogging an order of magniture more memory than the equialent Go program would –, it does the job fantastically.
That's cool - sounds like a good trade-off if you have a lot of developers in your org and can afford the small extra overhead without impacting throughput.
very nice can factor into private keys as well k thanks
Nice write-up!
You can always put your process into its own function, and inside main(), use recover to catch any panics and call the function again to re-start it. Note that if this API is using net/http, it already recovers panics and logs them as errors, and the panic only crashes that request, not the whole process.
Depends on the app. Is it some backend dashboard, or a SaaS app? Sure, js frontend is fine. Is it something reddit? Nope. I do not want to render thousands of deep comment trees on the client phone.
Waiting for the code to pop up on GitHub... :)
Uhm no, you can not get a private key out of a public key.
It's like saying Legos aren't fun because you always know how they fit together. The fun isn't in the mechanics of operating the tool, it's in what you can use it to create.
&gt; Where? If you search in this very subreddit, you'll find those claims here too. People on #golang frequently make those claims too.
Righto, I wanted to draw attention to the differences in semantics there.
Why? Reddit has a mobile app, and I doubt it renders server-side HTML. It's not as though JSON is larger or harder to handle than HTML, and it's not as though phones can't run JS efficiently.
I think he may slightly perhaps possibly have been making a joke.
Need to see a video for this one, I think... I need to see the progress of untrained, somewhat trained, fully trained, etc...
See also [Package Templates](https://docs.google.com/document/d/1vrAy9gMpMoS3uaVphB32uVXX4pi-HnNjkMEgyAHX4N4/edit#heading=h.wko1dvdznk4y)
Up for me atm
You do have to extract, but we have `mat.Col` that easily gets the `[]float64`. The problem with `plot` is that it natively deals with `[]struct{X,Y float64}`. I use a custom `XYer` that works on slices (and having been advocating for that for a while). Gonum has `[]float64` as it's base type. This is not just plot, but also stat, graph, optimize, etc. It could alternately use `mat.Vector` as the base type. This would allow striding, but would cost in several ways. There's the overhead of slices. Every piece of code now indexed strides, instead of being able to use the much nicer `for`. The code is also then, on average, less legible (interfaces everywhere instead of a base type) and meshes less well with the rest of the Go ecosystem. If Go had strided slices, only and natively, it would be one thing. Having both `[]float64` and `[strided]float64` is a pretty big cost on the language. 
the public key has all the information necessary to calculate the private key... it just takes a while
&gt; Why? A lot of cpu, bad UX.
Prove it. Javascript is fast these days, and not all lightweight front-ends have horrific load times.