But then your system will fail with an error that is not the original one, it's only related, it's a symptom not the problem.
And here is stdlib code doing the same thing from bzip2.go if !bz2.setupDone { err = bz2.setup(true) brErr := bz2.br.Err() if brErr != nil { err = brErr } if err != nil { return 0, err } bz2.setupDone = true } If you review the code there can be err, and brErr, and if both are set, err if effectively swallowed and never reported. You should realize it is a limitation of the Go error handling system - the lack of exceptions - that would make this sort of stuff trivial. Even the stdlib authors end up doing stuff that is "not pure" because the language is missing important constructs. Attempting to denigrate my abilities when the stdlib authors are doing the same thing is disingenuous. In their striving for "simplicity" they completely missed the boat on error handling - it is 20 years backwards...
I used `goto` in Go just today: https://github.com/Carpetsmoker/hubhub/blob/master/hubhub.go#L86-L102 This could also be done with a `for` loop (see below), but I think the `goto` way is easier to follow: for { // ... // 202 Accepted: re-try the request after a short delay. if resp.StatusCode == http.StatusAccepted { if start.Sub(start) &gt; MaxWait { return resp, ErrWait } time.Sleep(2 * time.Second) continue // go back to top. } break // Only need to run this once for non-202 } Another example where I used `goto` is when parsing the Go ast; in my case, I just wanted to get some type information and didn't care if it's a pointer or not, so I did something like: sw := field.Type start: switch typ := sw.(type) { // Ignore * case *ast.StarExpr: sw = typ.X goto start } case *ast.Ident: // ... case *ast.StructType: // ... case *ast.SelectorExpr: // ... } These are the only two cases I used `goto` in my almost 3 years of Go; I think that in both cases it adds to the clarity and simplicity of the program. As for this proposal, I think it makes sense. It *effectively* keeps the same restriction to prevent foot-shooting, but with more practical rules.
Great, thanks for sharing. Pretty sad that they disable the comment section though. It prevents us from discussing the content and providing feedback on the recordings. For example, I would love if they actually showed the slideshows and code examples in full screen, because it's super hard to read the code in some examples.
As I pointed out in other discussions, my usage is typically related to error handling, as described as a valid use in Knuth's paper. It really required since the error handling in Go is poor IMO - and I hope it gets fixed. A nice benefit is that if it does, I only need to change the tail section of the method, not make changes throughout... 
Btw, Knuth discusses your case exactly - using synthetic loops to avoid goto and why it is problematic.
The date formatting is awful IMO - I have to look it up every time I need a format. It’s a good example if you want to claim contracts are obtuse and difficult to parse. The contracts stuff still feels unresolved at the moment, but it does seem to me as a language user that extending interfaces would be a better fit (something considered but dismissed in the draft) - don’t care about the syntax but the current proposal seems muddled - a formal contract should be far tighter than pseudo code, and should be very easy to read and parse (why one contract for all args?), which this is not. Far more people will read contracts than write them.
+1 for referencing Ada.
-1 for presuming bad faith.
was already referenced in the go2 draft design.
Also, by the way if you read the proposal on lifting the restrictions on goto in Go, https://github.com/golang/go/issues/27165 the example cited is exactly my use case. Honestly, the level of vitriol in defending misinformation is pretty unbelievable in this day and age. 
Thanks!
In general people can become rude in comments without adding any actual value to the conversation or allowing the speaker to receive quality feedback. You can probably find most of the speakers in Gophers Slack or Twitter so my advise is to just to them directly. If you want to provide feedback to the conference organizers, you can do the same. Hope it helps.
Thanks. Hope you enjoy it.
By that logic we should include all possible features in Go and hope developers know what to use and when.
The lack of generics is one of the biggest complaints from the Go community, but it seems Go 2 is set have them. Kubernetes contributors will be able to consider replacing those workarounds and improve the maintainability of the code. However, calling what they did magic is a bit of a strech. What it is is a workaround for a missing feature. In C, if you want a garbage collector you have to provide it, but a garbage collector isn't "magic". I haven't produced a line of Java since getting out of University, but that new syntax for maps doesn't make me want to operate even semi-complex data structures with it. Types aren't explicit and structs are non existent. The following inline expression: map[string]struct{ lat, lon float64 }{ "null island": {0, 0} } is not something I want to attempt to do in Java. Complex ad-hoc data structures are trivial to operate on in Go, which is extremely useful when scripting/prototyping or when OO doesn't fit the problem well, and you have to approach the problem from a procedural or functional angle.
Please don't use such straw man arguments, as they are easy to counter with the same approach, "By *your* logic, we should all program in C or assembly". What I meant is that a feature should solve a problem that either cannot be solved by present features, or the solution is suboptimal. One should also choose their battles. Go was designed with concurrent program design in mind, a hard task. There were very little languages with *concurrency* (not *parallelism*) in mind. So, the creators added a (possibly problematic) feature, preemptively scheduled coroutines with synchronised buffers as the means of communication. The Go team decided that the battles they need to choose for Go 2 are generic programming and error handling. Both hard to get right. Many people consider that the solutions to those problems provided by Go today are suboptimal. And so, the Go team decided that they need to add features, despite the possibility of complicating the language. I dislike change as much as the next guy. The designs are rough and definitely need more work. But it doesn't mean that the problems they solve aren't real.
I don't want Go to allow definitions of generic types. When I was learning Go I watched [https://www.youtube.com/watch?v=7VcArS4Wpqk](https://www.youtube.com/watch?v=7VcArS4Wpqk) and in the Q&amp;A portion I believe someone asked "why builtin functions instead of builtin methods" and if I recollect right the response was the designers didn't think it was important. I believe the topic of generics came up and if I recollect right the assertion was basically that interfaces are generic enough, but that might have been from another source. I disagree interfaces are generic enough, but only because things like `len` were implemented as functions with generic parameters instead of methods with generic receivers. I believe if the builtin functions were replaced with builtin methods and interfaces and user-defined types inherited builtin methods there'd be little call for generics. For example, the only thing I should have to implement in my \[\]T to satisfy sort.Interface is Less, the other methods are boilerplate with a slice, and \[\]byte, \[\]rune, and string should implement `interface{string() string}` automatically.
Nice! Are you manually adding job ads right now? If so, how are you planning to get companies to post jobs?
Websockets are significantly simpler than webRTC! 
GopherJS is more mature, the application I was trying to develop was mainly computing then DOM interaction. I assumed GopherJS would have been easier.
I am a huge proponent for adding generics to Go, mainly for type safe collections without wriring a ton of boilerplate. But without inheritance in Go, I am not sure it will truly help - and I agree with you in that I find the proposal seems confusing/cumbersome. Java generics are trivial to use, and to read/analyze code that uses them. I understand the difficulties with Go being statically compiled in trying to implement these - lest the entire stdlib just become STL... Still, I wonder if there wouldn't be an easier way - if everything is an interface{} under the covers - similar to java's type erasure - if there couldn't be a simpler - maybe less powerful way - that these just be resolved at compile time. Since most of Go seems to require the source code to packages anyway I would think it is possible. - since you essentially do this now with a bunch of casting, and a encapsulation of the generic collection. I am definately not a language or compiler designer, but the proposal does seem iffy from a user (developer) perspective. &amp;#x200B;
There are no links to that in the video description though, so how will people know? Also, it doesn't help with the problem that people can't discuss the videos.
Pretty cool article. I tend to design more in the Django way which has similarities to Rails. This gave me some good concepts to think about when I need a more complicated application.
you are checking the number of zero bits in your go code. my only guess is you are checking the number of zero hex characters in python. so 7 in your go code is grinding 7 bits, but your python code is grinding 28 bits (7*4) 128 hashes as compared to 268 million hashes.
The last time I comment on the Go2 drafts post everyone down voted me. I have exact same gripes author has summarized the problems really well. I would rather not have contracts keyword than having something that compromises quality of my code. 
To your last point, there is a Slice function in the sort package where you only have to implement the less function.
What kind of links are you looking for?
If you're interested in seeing a mature project that followed this model, look to https://github.com/influxdata/chronograf . It's deviated some with the stresses that complex features will bring, but you'll see that the same general structure held up pretty well.
Up voted for the preview image. 
thanks for sharing.
Okay, I read it now. It was a good overview.
Here is a adjustment mining demo https://play.tokublock.com/mining/2 
Yep, Todd Mcleod is on of the best Golang teachers. here's more [Golang tutorials](https://reactdon.com/go), if you need them.
[removed]
Great post. I agree completely re. contracts vs. interfaces. Additionally I would hope that Go would avoid one of the biggest issues with C++ templates; the compilation speed. The current proposal doesn’t seem to.
Thanks, this is fantastic. I did a quick perusal of mapstructure but didn't dive deep, I will take a longer look at it.
You can even optimize the binary using -ldflags="-s -w" flags on the compiler and upx to compress the binary.
Sounds right: C89: \&gt; A label name is the only kind of identifier that has function scope. It can be used (in a goto statement) anywhere in the function in which it appears, and is declared implicitly by its syntactic appearance (followed by a : and a statement). Label names shall be unique within a function. \&gt; The identifier in a goto statement shall name a label located somewhere in the current function.
Links to places you mentioned, gopher slack (which I not many know of) and where to reach the speakers/organizers. Anyway, I still think enabling comments is the best alternative, since it enables discussion. If anyone leaves mean comments you can always delete them, right?
\&gt; no other country uses Am/Pm &amp;#x200B; Seriously?
&gt; I'm pretty sure the C goto had the same limitation Go has more limitations that C didn't have. [Goto in Go can't jump over a variable declaration](https://play.golang.org/p/ix7JhR9epog).
I fully agree with the author. Honestly the contracts thing feels like someone at Google needs a promotion and thought by doing something like this they'd get it. The FP (authors term) / rust (my initial use of this kind of generics) makes so much sense and interfaces would get it there.
oh thanks a lot dude. Then what does it mean if the capacity of the channel is not given?
oh that's why. Got it. Thanks man.
I am also coming from a PHP background and it helped me alot
[removed]
Well, almost. It’s basically USA Candada UK Australia India. A day has 24 hours. It’s not like it’s difficult or confusing to count up to 24. On top of that, am/pm is also braindead in the way it treats 12 as a special case. Calendar is already difficult enough without adding this kind of gratuitous complications on top. 
&gt; Use crypto/rand for random inputs. No, use a properly seeded `math/rand.Rand`. It's faster than `crypto/rand` and this application doesn't need unpredictability, so there is no point paying for that.
In reality, the community now uses github.com/globalsign/mgo, which is actively maintained
&gt; I don't see a reason to keep the built-in append function, so will it be removed in Go 2? Backwards compatibility is a good reason IMHO ^^ I think the most likely outcome is that the builtin functions will stay, but be properly defined as generic functions, instead of compiler "magic".
there is no proposal, just a discussion, I personally don't want generics, hope won't make it in the language. 
The assumption is that adding generics, or changing error handling will most likely break the go compatibility guarantee,and thus require a major version increment. If there is a way to do both and maintain compatibility with existing code, then they can do them as point releases. 
D generics uses the same mechanism as C++ templates and doesn't suffer from the compilation speed. I remember some presentation from /u/WalterBright saying that it's the unfortunate combination of compile-time specialization AND macro expansion include system ala C++ which makes the compilation speed unbearable
Please please please please please can we continue expressing constraints on types using interfaces
That's true, if the decide to make Go 1 code compile with the Go 2 compiler then the built-in functions must stay. 
Fair enough.
I have noticed that not all gophers know about advantages of using data managers, so I wrote about it. I don't have much experience with blogging, so if you read it, please let me know what you think about it.
Wow man Wow
Hey ! That's *my* slides theme 😃
There are a number of questionable things about this, but the deadlock is happening because your `for` loops are out of sync. The one in `main()` counts from 0 to 225,000, but the one in `Generate()` counts from 2 to 225,000. That means that two of the `wg.Done()` calls never happen.
Yeah just resources I collect while I learn. You should do the same. Take these and add to your own. Make sure to share as well. You never know when you need a reference. 
Good question!
[removed]
I actually also hope, that they cut the backward compatibility. When I explicitly decide to use Go 2, I should explicitly change my code so it compiles with Go 2. And as you said, a simple script using sed should be enough there :)
we already have an example for that happening with python 2/3, as well as c# and the .net framework. It shows that keeping backwards incompatible changes to a minimum will lead to higher adoption of the new version. It's not just your own code that will need fixing, but also any library you use. You can't guarantee that will happen in a time frame that is suitable for you, so fewer breaking changes equals faster adoption rate.
He's also creating 250k goroutines, which is probably not a very good idea... 
That would be one of the questionable things. There's also a _ton_ of repeated work between them, and the order of results in undefined.
Its becoming clear that there's too much valid dissent against this proposal to build it any time soon. My fear is that so much of the conversation is focused around generics that no one is talking about the error handling proposal, and that might make it through without as much discourse. 
No. Don't close the channel until you are done sending items into it.
How do I know if I am done sending items into it? By using wg.Wait( ) ? If it is, where do I insert it?
[removed]
https://redis.io/commands/get https://redis.io/topics/protocol#bulk-string-reply 0xd8=216=b11011000 , just what you've set. 
[removed]
this is probably more of an exercice in concurrency rather than an exercice on writing a fast prime finder. You're still right though! 
If you are just doing Printf("%v", s) you may as well use just Print(s). If you need a string use the S functions, if you like to directly write to an io.Writer (bytes.Buffer, strings.Builder, os.File) use the F functions.
One thing to add is that both `cap` and `len` work on channels. Channels are not that useful in scenarios when you have just a single gorutine but they can be easily (ab)used as queues. In most non-concurrent context a slice is way better as they can't cause deadlocks. 
You know, `break` and `continue` both work with labels.
Sure, I will
Put it in a goroutine before you range over the prime channel, once wg.Wait() returns, you can close the prime channel as you know all the workers have finished. Then the range loop will be able to complete.
&gt; The Go team's great strengths are that they deliberate, experienced, and shrewd, and their great weakness is that they know it.
[removed]
I've looked at that - thanks. It is still hard to use because the routines don't have a name - so you need to look at every one - can't filter... It's much more difficult debugging concurrent Go than Java IMO.
0xd8=216=b11011000 Is there any package to do these conversions myself?
I'm not sure if 5x please is supposed to be sarcastic, or is there some actual proposal behind those words? Let's assume that all primitive types implement `fmt.Stringer` (for lack of a more generic interface), having `interface{}` replaced with `fmt.Stringer` doesn't actually change *anything* here, as the implementation still isn't concretely bound to a specific type. The whole run-around is just because it would be nice to implement a strong-typed instance of something like `sync.Map`. I don't want to give Java or C++ as an example, but one thing sticks - this should be achieved with parameters. Obviously, the syntax is very important, but I (and others) can't just throw some proposal out of a hat and solve world hunger. ``` type Map(Key, Value) map[&lt;Key&gt;]&lt;Value&gt; v := Map&lt;string, int&gt;{} type S(Key, Value) struct { key &lt;Key&gt; name &lt;Name&gt; } s := S&lt;uint64, string&gt;{5, "foo bar"} ``` I mean, what's wrong with this? Arguably, everything. It takes too much from c++/java, struct looks like a func, and probably many other things, like actual practicality. But one quality is valid, and that if somebody wants to produce a typed implementation from a generics one, the types have to be passed as parameters on creation - somehow. The more awkward questions arise how to pass these types to functions? `func TakeS(s S&lt;Key, Value&gt;)...`? Obviously, as soon as a concrete instance is typed, it should reflect this type in parameters. Would you need to create a concrete type out of a generics one? ``` type SUintString S&lt;uint64, string&gt; ``` I would be fine with that. I think it may be reasonable to create a few types by hand from a generic one? Obviously you can't predict them all, but you could use a generic from imported packages and produce a concrete for your case. And I'm pretty sure that these parameters *should*, nay, *must* be constrained by some interfaces (which is why contracts are ugh). (I enjoyed this tangent, thanks for a thought provoking comment :P)
Thanks for the advice, I will keep that in mind next time.
&gt;What's with the downvotes? We think your isPatronizing() func is calibrated wrong.
Makes a lot of sense, thanks for clarifying!
I think you can do something a little like what you're describing using labels with pprof. [https://rakyll.org/profiler-labels/](https://rakyll.org/profiler-labels/) It requires a bit of plumbing with contexts and such, but can be pretty useful when you have a lot of goroutines.
That's exactly the pattern which I've been using for several projects. Thanks for documenting it.
I like the iterations, I feel like my code evolves in a similar way. Good work. I also liked the "we". :)
There seems to be a lot of feedback on the [wiki](https://github.com/golang/go/wiki/Go2ErrorHandlingFeedback) regarding the error handling proposal.
`fmt.Sprint(s)` (to avoid having to parse a format string)
thanks for the comment, I'm about to publish a proofread version and also some nicer formatting for the code for the launch of the book tomorrow. You'll get an updated version very soon. Thanks
There will be a private Discourse forum available for the launch. So I will be adding more content, answer questions and do some live streaming in there all related to the book content and continuously improving the source code. Stay tuned for the announcement very soon :) Thanks
69.6ns/op doesn’t seem to be the fastest?
Looks like the bunny sign meme on Twitter
Yeah.... I used nose and eyes from that 😅 But its a cat... It can meow... I tested it... 
Please don't bikeshed syntax.
The pattern he describes isn't really SQL only. It's just the way he got the data, but not really the important part of this. You could also use this when you got it from a JSON API for example.
1. This doesn't appear to be bikeshedding, it appears to be thoughtful. 2. Syntax is important.
A lot of the source-level changes will be trivial to change with, say, `go fix`. In contrast, going from Python 2 to Python 3 is hard because of the str -&gt; str-or-bytes change.
The article was a pleasant read! I think the following sentence is worthy of a bit longer discussion: &gt; Defining interfaces together with the implementation might feel counterintuitive in Go. In most cases, it is better to declare an interface where it is used (not where it is implemented) to help to decouple functionalities and avoid dependencies. In fact, let's assume that `context.Context` would change, and add some function like `ID()` - as the interface is declared where it is implemented, it is obvious that some programs that are implementing a compatible interface (as a mock, fake,...) need to update to include the ID function. Anybody consuming the context package *doesn't care*, as adding a new function isn't a breaking change. In the mirrored case, let's assume that you're only interested in the context.Context `Done` function, and you implement your own interface that covers it: ``` type Doner interface { Done() &lt;-chan struct{} } ``` If the Done() signature changes (ie, a rename into `Wait` to match `sync.WaitGroup`), you'll have two updates to make in your code - fix the interface, and fix the function name. If you'd be using `context.Doner` if it existed, or just `context.Context` directly, you'd only need to change the function name to satisfy the modified interface. Another reason why interfaces are kept together with the implementation is also to make sure that the implementation conforms to the interface. Can you imagine the context struct not satisfying the interface it's promising to implement? :)
pull request: renamed to bunnysay
I really like this idea, it makes it simpler to read. The thing that might need some more thinking is the way you define contracts. Putting code in the type definition block does not make sense to me and might make it hard for the parser that will have to handle a mixture of fields defs and code. Perhaps keeping the contract syntax as it is in the proposal + this interface-like way of defining and using generic types would be better.
Why are you doing division here? `if res.StatusCode/100 == 4 || res.StatusCode/100 == 5 {`
Append is useful not just for a = append(a, b), but also for concatenating two slices, and a few other things
I think I have something under https://github.com/titpetric (something binary something)
&gt; This doesn't appear to be bikeshedding, it appears to be thoughtful. Bikeshedding isn't about how something is talked about, but what it's talked about and why. Instead of talking about the hard problem (semantics), this is talking about the easy problem (syntax). For example, this idea drops at least one important semantical question on the floor: In the Graph example of the design, `Node` and `Edge` are clearly related by a common contract. In this syntax idea, they are no longer related in that way. So, would this, for example, pass the type checker? type FooNode struct { /* … */ } func (n FooNode) Edges() []BarEdge { /* … */ } type BarNode struct { /* … */ } func (n BarNode) Edges() []BarEdge { /* … */ } type BarEdge struct { /* … */ } func (e BarEdge) Nodes() []BarNode { /* … */ } func main() { src, dst := FooNode{ /* … */ }, FooNode{ /* … */ } edges := ShortestPath(src, dst) } In the original design, it wouldn't. If it doesn't, here, why not? What are the rules? In isolation, the signatures seem to fulfill the generic type definitions. How about func Sum(x []Addable) Addable { return float64(42.0) } func main() { fmt.Println(Sum([]int{1,2,3})) } Presumably this shouldn't pass, even though both `int` and `float64` are Addable. Again, what are the rules? These questions can be answered in an ad-hoc manner. But, TBH, I don't think that's important. Semantics first, syntax later. &gt; Syntax is important. So is the color of the bikeshed. It still makes sense to first focus on the design of the reactor, because if we can't build that without it melting down immediately, we won't need a bikeshed.
So I've never worked with any kind of genetics, but looking at contacts, don't a lot of their functionality end up duplicating interfaces? Why not just allow interface declarations to contain the types of operators and built-in functions that can be used on them?
it's not about the money you make, it's about what you keep after taking expenses into account: https://www.nerdwallet.com/cost-of-living-calculator/compare/springfield-mo-vs-san-francisco For the same standard of living, you spent 50k in springfield and about 100k in san fransisco.
Contracts is part of the draft proposal, I don't think I showed any types with code in them (unless you count the shortand "==" and "+" as code). When you start needing code to define your types it might be powerful but it's also more complex and takes longer to compile. I don't know if having contracts with code in them is worth it.
This is really sweet. Any idea if Stackdriver Trace is supported in Go Cloud Functions?
&gt; (why one contract for all args?) Here's my understanding: it's very easy to delegate that out per-argument where needed (`contract foo(a A, b B) { bar(a); quux(b) }`), but impossible to go the other way.
looks like it: https://twitter.com/broady/status/1034837404912365573
[removed]
I had similar thoughts. I hope this gets explored more.
[removed]
Cowsay is even better. 
Ah, nice catch! Signed up for the alpha, have you had a chance to play with it yet? 
nope. don't really have a use for it.
[removed]
[removed]
I think contracts are a hard part of the proposal to swallow, but once you really understand why they are the way they are, it’s hard not to agree with the proposal as originally written. 
A contract is constrait on multiple types, not a single type. Your proposal is not just syntax change but less powerful semantic change.
I have just made a library just for this https://github.com/xiegeo/coloredgoroutine for Go routine and printf debugging. Basically, there is an unsupported way to get a unique id number of a Go routine and map that id to whatever data you want to associate with.
Weird, I was sure at least England did "Jan 31st, 2018" but even there that doesn't appear to be the default locale std. ... so that sucks much more than I thought it did :(.
Repository Pattern/DAO/Data Manager. So many names for what is essentially the exact same thing.
IIRC the goal was to have a mechanical translation possible: this way you can mix the two versions because legacy code can be compiled as go2 after (automatic?) mechanical translation.
&gt; It means that there must be something in go2 that behaves like append, and Append seem to be a likely candidate for that. Why? That seems like a completely meaningless and unnecessary change. Note that there are plenty of predeclared identifiers in Go (`nil`, `true`, `int`…), I don't think having a handful more or less is really relevant. &gt; Keep in mind that for go2 there are also plans to drop cruft from the standard library, so the incompatibilities don't stop at the language level (but also extend to the standard library). FWIW, my prediction is that this will happen in the form of a versioned standard library. i.e. the stdlib will become modules (a module?) and you get a newer version by depending on it. Personally, I think people are imagining the Go 2 transition to be much more jarring than it'll actually be. Most likely you'll hardly notice it.
&gt; with the number of people who've been practically foaming at the mouth over generics in Go, that'd make a pretty solid core group of users who will likely switch no matter what. I don't believe that using generics will require any backwards incompatibility. On the contrary, generics are most likely to go into the language before any breaking changes. Most likely, the backwards-compatible changes (generics, error handling…) of Go 2 will be spaced out over Go 1.12, …, 1.x and then all the breaking changes will go into one Go release Go 2.0. Though keep in mind, that it's still an open question whether there will actually be a "Go 2", instead of just Go 1.(x+1) being declared "Go 2 in spirit".
&gt; The strings.Join version has one less allocation. This is not true, at least for most cases. strings.Join is still need two allocations in Go 1.11.
What if S depends on T that depends on U, V that depends on W? And your init code is not thread safe.
\&gt; *No description, website, or topics provided.* &amp;#x200B; What is it good for? How is it used? Tip: If you want to increase interest in your tool, add a description to the repo and improve the readme.
[removed]
Made an issue for it. I am redesigning the cat. [https://github.com/muhammadmuzzammil1998/catsay/issues/3](https://github.com/muhammadmuzzammil1998/catsay/issues/3)
Hehe.. I am redesigning the cat. [https://github.com/muhammadmuzzammil1998/catsay/issues/3](https://github.com/muhammadmuzzammil1998/catsay/issues/3)
Issue: Cat looks like a bunny 😂😂😂 [https://github.com/muhammadmuzzammil1998/catsay/issues/3](https://github.com/muhammadmuzzammil1998/catsay/issues/3)
I fully agree with what you wrote. I also think that there is an another way to use interfaces. I think that it is a good practice in Go to keep interfaces small and general. `io.Writer` or `io.Reader` are great examples of that. They both provide just one method and use basic types. There is no main `io.Writer` nor `io.Reader` implementation. Everyone is encouraged to implement it for communication. It is also the way to use most of the standard library functionality. Interface that I wrote about is quite the opposite. Main implementation and tooling is implemented in the same place. Integration with other packages was not the reason to introduce the interface. Although I have not mentioned this, I expect the interface to grow. I think it should cover all methods required to interact with the database.
Yes, I was only talking about the changes in these benchmarks over time when I said there was one less allocation. Note strings.Join will only ever do one allocation from Go 1.12 onwards.
Never expected a stupid comment of mine would result in a GH issue, haha :)
you should use more cases in your benchmarks.
As most of the syntax suggestions this quickly falls apart once you consider a) the Graph example, b) the Sort example and c) generic types (e.g. `type Maybe(type T) …`).
WTF? It's not about making a "network request" (what is that, really?) — but rather it's about making an HTTP request. 
&gt; Why? That seems like a completely meaningless and unnecessary change. Note that there are plenty of predeclared identifiers in Go (nil, true, int…), I don't think having a handful more or less is really relevant. Because there's no reason to keep it apart from backwards compatibility and because the translation can be mechanical. &gt; Personally, I think people are imagining the Go 2 transition to be much more jarring than it'll actually be. Most likely you'll hardly notice it. Personally I would hope it's jarring if it allows to drop cruft from the stdlib.
&gt; Because there's no reason to keep it apart from backwards compatibility and because the translation can be mechanical. That is not "a reason to remove it". The default is always "do nothing". &gt; Personally, I hope it's going to be jarring if it allows dropping cruft from the stdlib You can get one without the other. My prediction is that the stdlib will become a versioned module, released mostly in lockstep with the toolchain. There will be at least a period where both v1 and v2 of the stdlib are maintained and v1 Go packages will continue to interoperate fine with v2 packages. An explicit design goal of the Go 2 process is to not run into the Python 2/3 mess, which will require something like this. But mostly, what I mean by "not jarring" is that the changes - breaking or not - will be spaced out over years.
there are no emojis in my commit messages, i have no idea why you are saying that
It's interesting that [one of the images](https://cdn-images-1.medium.com/max/800/1*qPIbs8KyGSmKuM-eAZQj_g.jpeg) in the article barely hides the [fraudulent nature](https://en.wikipedia.org/wiki/Pump_and_dump) of most crypto currency trading \^\^
Pushman is able to deliver 32M messages per second.
Its not the nature of crypto exchange, its the nature of traders and their strategies. We have to optimize for handling such situations sadly.
Thanks for the comment! What you've said is true, having an sorted []struct{hash int; *node} would definitely help with better cache locality, the main reason I implemented it using a Red-Black tree was because of the sorted nature of a balanced tree and I found it intuitive for such a case. Let me add your suggested method and do a comparison in terms of performance
&gt; Its not the nature of crypto exchange, its the nature of traders and their strategies. Well, agree to disagree then. I'd argue that a system who's main design goal is to avoid governmental regulation can't plausibly claim that financial fraud is a bug, not a feature. And an exchange that so obviously advertises said fraud in its own promotional material can't claim to be oblivious to that. But whatever lets you sleep at night.
You could introducing endless of features without requiring any backwards incompatibility just as java did before. Java chose to bloat language instead of breaking compatibility when introducing generics and other features (also introducing lots of unnecessary complexity). I always prefer to keep the language simple and clean even if it will break backwards compatibility. Considering there will be some Go2Cleanup bugs, backwards incompatibility seems unavoidable.
There will be a new slices package for you to operating on slices of any element type once generics introduced in according to Go 2 draft design document.
Could you elaborate on this please ? I don't see how it falls apart. I find that Dave's proposal is a huge improvement in readability. In this form, contracts would be static interfaces. This looks very smart to me. 
Such faith in government regulation and the financial system, the naivety is almost touching.
I'm not sure to understand what the call site would look like. For the `Print` example, would it be like this, with `contract{} = int` being inferred ? s := []int{1,2,3} Print(s)
As naïve as blind trust in those who seem to circumvent it.
Contracts are constraints on *multiple* types, so you cannot instantiate a contract object at run time as interface object.
a) falls apart similar to what I described [here](https://www.reddit.com/r/golang/comments/9cff2h/proposal_to_simplify_the_generics_draft_designs/e5afs51/). b) falls apart because `var x []int; Sort(x, func(string, string) bool { return false }`. c) falls apart because `func (m Maybe(T)) Value() contract{} { return 42 }`. The feature of parametric polymorphism isn't to express constraints (interfaces can do that just fine) but to have the consistency of parameters checked. The syntax Dave is suggesting may seem readable, but it doesn't actually express the semantics needed to be called generics. He doesn't talk about having multiple, interdependent type parameters or having a parameter checked for consistency between different parts of the program. In other words, he observed an overlap between interfaces and contracts and devised an alternative syntax for that overlap. But we already have a syntax for that - interfaces. What we need, is the stuff that *isn't* overlapping. He (and all the other "alternative syntax" ideas I've seen) elides that.
I didn't say I have "faith in government regulation and the financial system". I said you can't build a system that is explicitly designed to enable fraud, advertise that fraud in a blog post and then claim to be surprised or sad by that fraud happening. &gt; the naivety is almost touching. Save your condescension for occasions where you are actually replying to what I said, please. You're embarrassing yourself.
I see you have added 2 + 2 and come up with 5 as the answer.
I hope you are using the https://github.com/gobwas/ws library. It is absolutely essential if you are dealing with ~1M connections.
Yes, it is a really great connection. 
Kinda strange talking about "going live" without any content available at all. And I wonder, what does "Free" label near the greeting chapter mean? Is GophersLand a paid site?
I'm quite sure (At least, it feel intuitive to me) that In Dave proposal, just like in Russ proposal, a contract in not an interface. type foobar contract{} func doFoo(x foobar) foobar​ This does not mean that doFoo accept any parameter and can return any parameters but that doFoo return exactly the same type as its parameter.​ Just like in Russ proposal:​ func SliceFn(type Ele)(s \[\]Ele, f func(Ele, Ele) bool) { Sort(sliceFn(Ele){s, f}) } Ele must be the same type and you can not write var x \[\]int; Sort(x, func(string, string) bool { return false } too. Could you be more precise for **c)** ? Thanks
&gt; This does not mean that doFoo accept any parameter and can return any parameters but that doFoo return exactly the same type as its parameter.​ Where does it say that? How does the scoping work? How do I express if I *don't* want that? &gt; Just like in Russ proposal:​ Nit: It's neither a proposal (it's a design doc) nor is it from Russ (it's from Ian and Robert). But FWIW, in the design, these problems don't exist because you are explicit about a) what the type parameters are and b) how they are scoped. Any type parameter is scoped to the current declaration - and if that declaration is a type-declaration, it's scoped to all of that type's methods. In Dave's sketch, the type parameter isn't clearly scoped. Is it scoped to the file? The package? Any declaration? If the latter, then how do I express interdependencies between declarations (say, I have both `var M MyMap(K, V)` and a function `Serialize(m MyMap(K, V))` - are the `K` and `V` guaranteed to be consistent or not?). That's exactly what I'm saying. The syntax that people seem to be finding so abhorrent and just handwave away fulfills a function. You have to say something about how to replace that function. &gt; Could you be more precise for c) ? Sure. How do you declare parametric types in the proposal? Dave doesn't actually mention that (again, restricting what he's saying to the ways in which interfaces and contracts are *similar* and leaving out the ways in which they are *different* - and why we are discussing this in the first place). What makes sure that the parameter in (presumably) `type Maybe struct { valid bool; v contract{} }` is checked against the return type of `func (m Maybe) Value() contract{} { … }`? What is preventing me from returning anything I want from that method? Dave says that "maybe generics are about syntax after all". But his syntax is handwaved and meaningless, without actually talking about the semantics. And if you have to talk extensively about the semantics, before you can understand or discuss the syntax… is the central thesis of the article really justified? BTW, it has not escaped notice that you did not respond to a) ;)
[removed]
I thought your post was about adding optional types. 
It was originally designed as a [system programming language](https://en.wikipedia.org/wiki/System_programming_language) and the designers' dislike for C++ has been named a motivation for it. Many disagree that it can be called one though, because it requires a garbage collector and disallows raw pointers. I do believe that it could be used as one above a thin C/C++ kernel layer though. The major advantage is that it is "managed" (to use Microsoft terminology) and thus much more secure than C/C++. Anyway, it hasn't found the major use there, but rather in web development. Like for server backends and such. It is very convenient to use especially if the application is to handle multicore processors efficiently because of goroutines and channels.
Thanks for your answer. I only answered b) because it was the easiest one to understand were we don't agree and to have some base to start from. I agree that some important point is missing and the proposal is leaving to much on interpretation. All your questions are good so I'll have think more about it :)
My feeling is that you are dismissing Dave's proposal a bit harshly. It is an elegant solution, but it needs further refinement. I don't see a problem with the Graph example. We have the function `func ShortestPath(src, dst N) []E`, and the contracts `type E(x T) contract { var n []N = x.Nodes() }` and `type N(x T) contract { var e []E = x.Edges() }`. The relationship is defined in the contract. I also don't see a problem with the function `func Sum(a Addable, b Addable) Addable` . The contract type names are the same, and so should be the types. If we wanted to specify that b does not have to be the same type of a and the result, we would write `func Sum(a Addable, b contract{Addable}) Addable.` Are there other properties that Dave's proposal is still missing ? &amp;#x200B;
Instead of defining one contract, we would define one contract for each type and they would refer each other. I don't see a problem. 
I don't agree with your scope objection. The scope rule should be the same as for interfaces. All the functions using K and V contract refer to the same types. They are defined implicitly by the argument type. This is possible in Go because there is not implicit type conversion. I don't understand the point you are trying to make with the Maybe example. It would be rejected by the compiler because there are no constrains on the return type. There is no way to deduce the return type. I do think Dave's proposal is worth more consideration. It does solve a big problem of the actual proposal which is the loss of readability resulting form the parenthesis diarrhea. We have parenthesis for the target, parenthesis for the arguments, and parenthesis for the results. Don't you think this is enough ? There shouldn't be more than three. Do you have other *semantic* problems to report with Dave's proposal ? 
Why do you say that using url imports is impossible? It doesn't matter if the repo is a private one, if you setup the ssh keys properly then go get/mod will work.
Still need to set up a https server right? 
&gt; It is an elegant solution, but it needs further refinement. But there we disagree. I don't think it's elegant. Or even a solution. I would - no offense - characterize it as a "soundbite". It makes for a title that sounds deep, without actually saying anything. &gt; The relationship is defined in the contract. It's not, though. See the example I linked to. It *at least* requires further elaboration for how the semantics work here. And TBH I'm pretty sure that when you actually get around to that, there isn't much left; you'll end up with pretty much the same syntax as before (or you add a formal type system and unification algorithm, like other languages that don't require explicit quantification - e.g. Haskell). In Haskell, it's clear that `a -&gt; a` and `a -&gt; b` are different types, *and* that `a -&gt; a` and `b -&gt; b` are the same types. No matter how they are related by declarations or not and without explicitly providing quantifiers. Because in Haskell, there is a well-defined meaning to type parameters and a unification algorithm that specifies what the most general type for two expressions is - and when these are different. In Go, you have to explain whether and under what circumstances `func(A) A`, `func(B) B` and `func(A) B` are the same and when they are not. And it's not enough to rely on "they have the same name". &gt; The contract type names are the same, and so should be the types. So what does that mean for, e.g. `Filter` and `Reduce` defined in the same package with the same type names? &gt; Are there other properties that Dave's proposal is still missing? It's not a proposal. You are trying to come up with ad-hoc answers to my questions, but my point is specifically that ad-hoc answers aren't enough. You have to actually talk through the semantics. You are arguing from a naive POV ("they use the same name, so should be the same parameter"), but a naive POV is rarely enough to actually explore the full implications. Which is why I'm calling Dave's article a "soundbite". Dave is dismissive of a lot of brilliant peoples hard work (»The great irony is, after years of my bloviation that "adding generics to Go has nothing to do with the syntax", it turns out that, actually, yes, the syntax is crucial« - he talks about "his bloviation", but it applies just as much to what other people have said about it), without actually backing that up. And if I'm overly critical, then that's because TBH it rubs me the wrong way that that kind of attitude is celebrated or declared "elegant". Elegance is finding a (relatively) simple answer like contracts to a set of extremely complicated and interconnected problems. And explaining how it does that. And there's a reason it took a bunch of extremely bright people 8 years to come up with that design. (Disclaimer: I'm not even *in favor* of the contracts design. I'm - at best - extremely meh about it. But at least it's actually elegant and thought-through)
Considering the new generic package I ask myself: Do we need append anymore?
&gt; It would be rejected by the compiler because there are no constrains on the return type. There is no way to deduce the return type. I don't get this. If there are no constrains on the return type, why would it be invalid to return whatever I want? --- With contracts, you *can* write this: type Maybe(type T) struct { valid bool v T } func (m Maybe) Value() T { if !m.valid { panic("invalid") } return m.v } The `T` is explicitly scoped to the `Maybe` type, by being attached to its declaration. It's only valid in the declaration itself and methods of `Maybe` and it has to be substituted identically in all instances for a given `Maybe(T)` value (again, that's scoped). In Dave's description, this would look something like type T contract{} type Maybe struct { valid bool v T } func (m Maybe) Value() T { if !m.valid { panic("invalid") } return m.v } superficially, this looks the same. But it isn't. `T` is declared in a separate declaration from `Maybe`, so it's not actually bound to that type. Meaning you have to explain a) which occurences of `T` in this file have to actually be the same - if I have two `Maybe` values, do they need to have the same `T` then? Do `Maybe{true, 42}` and `Maybe{true, "foobar"}` have the same type? They certainly seem to use the same type name? Can I return 42 from `Value()`, given that it certainly satisfies `contract{}`? And b) which occurences of `T` *don't* have to be the same. If I add a `func(T) T`, does it need to have the same substitution as the `T` in `Maybe`? "Parametric polymorphism" is called parametric, because types and functions can have type *parameters*. And you have to explain how these parameters are defined and scoped. --- &gt; Don't you think this is enough? There shouldn't be more than three. I *completely* agree that the syntax is unfortunate and a problem. I would like it be solved. I would just prefer people would actually… solve it. Like, in a way that actually makes semantic sense and solves the actual problem. Decent syntax is important, but the semantics should still *work*, because we don't need good syntax for generics, if they can't actually be added to the language. It should IMO be *obvious* that Dave's description isn't very useful, given that he specifically restricts himself to the overlap between contracts and interfaces. But if that's all we cared about, why would we even need generics in the first place? We already have that overlap in the language - with interfaces.
Hey, man sorry but I think your understanding of "pump and dump" is not correct. Its not tied to an exchange by any kind. And these days, there are numerous exchanges. A pump and dump on any one of exchange will effect the global crypto market. So, we have to optimize for such scenarios. And, "pump and dump" is not fraud always.. it depends on the news redarding the cryptocurrency also. To prevent fraud, he have systems in place to prevent swap trading etc. 
&gt; Its not tied to an exchange by any kind. Didn't say that. I said that you are explicitly advertising it in your graphic. Of course financial fraud is not specific to your exchange - it's specific to cryptocurrencies. It's what they exist for. &gt; So, we have to optimize for such scenarios. I don't agree that you must. For example, I don't. I just opt not to participate in a systematically fraudulent system. &gt; And, "pump and dump" is not fraud always. Yes it is.
Sorry but don't agree with you one these points, &gt; Graphic is intended to have crypto buzzwords. &gt; We need to optimize because if a coin is surging globally, buyers and sellers will rush to the exchange to book positions that's the basic of any financial market, if you shut your shop at that point.. then it don't make sense at all.
Hey Cadabrum, thx for feedback. Well, you must start somewhere. Content will be progressively released! We are using Teachable.com engine to power the content in a form of a course so they automatically display, attach the "Free" label :)
Not clear to me. If I want to mix Import "github.com/xyz/mod" And Import "localhost/company/lib" I would need to set up a https server internally?
Thanks! Sub packages seems straightforward! It is referencing "sibling modules" locally without using and setting up a git server that seems problematic. (This was trivial with GOPATH). I understand that this might be "by design"
&gt; Why can't Go have at least unions? That's discussed in [convenient 233 comments](https://github.com/golang/go/issues/19412) for public consumption :)
You are missing point of contracts: contract is a predicate for type not a new type. So having that, function with generic parameter becomes function with one more implicit parameter - type. This is perfectly reflected in draft, and your proposal don't. Also you are making assumtions, like return type with this one, which is out of scope: ``` type Addable generic { Addable + Addable // shorthand for: add(Addable, Addable) Addable } ``` 
So is an AppleTalk request, a CIFS/SMB request, and NFS request, a DNS request, an ARP request and in general any request of any type performed as part of any type of protocol implemented on a potentially unbounded number of whatever technically constitutes "a network". Do you see a distinction now? 
&gt; Despite the way it looks in the usage, a contract is not the equivalent for type parameters of a type for normal parameters. A contract is a statement about the function itself. Part of the problem (and what the Rog/Dave's observation is based on) is that contracts are *both*. The contracts design is adding constrained parametric polymorphism. That's two parts: 1) parametricity - being able to have type parameters that are checked for consistency and their interdependence by the cmpiler. And 2) constraints - making the polymorphism useful, by allowing certain operations (and only those) on the values passed in. The issue, to a degree, is that the contracts design really do *both*. They add parametricity using the type-parameters for functions and types. And they add constraints with contracts that specify what operations are supposed to be valid. The problem now, is that interfaces *also* provide constraints (but only constraints). That is where the "unfortunate overlap" between interfaces and contracts lies: We have two mechanisms to do the same thing. In that way, Rog/Dave are correct - for specifying constraints, interfaces are a strict subset of contracts (as the latter *also* allow to constrain on existing fields and operators). The design overall, however, is not. That's why it's actually adding something significant to the language. We already have constrained polymorphism, but we don't have *parametric* polymorphism. Personally, I think, I'd be happier if the two are separated. Get rid of contracts and only allow constraining type parameters to interfaces. Interdependent interfaces can still be made possible, by having parametric interface types, e.g. type Graph(Node, Edge) interface { Nodes(Edge) []Node Edges(Node) []Edge } This would mean you can't use operators anymore (you'd have to wrap them). I'm not sure if it would solve all the other usecases as-is TBH (e.g. you couldn't really write a constraint on an `Equal`-method per se, but you may be able to use a `func(type T) (T, T) bool` instead). There *might* be an argument that performance would suffer because of having to box things. That *might* be countered by claiming that if the compiler can generate unboxed code for the generic function call, it can also devirtualize the interface (and then inline the wrappers around operators). So you *might* end up with equivalent performance anyway? Dunno. --- Anyway, to me it feels that Rog/Dave are trying to address the overlap by extending interfaces or restraining contracts. IMO it would be cleaner to address the overlap by addressing it: Make each thing do what it does best.
&gt; And IDK much about Haskell, but what's wrong with Python? Nothing :) It's a fine language. So much so, that I see no reason to add an identical one with Go 2 :) I was really just riffing on your comment a bit. If you are fine with *any* level of breakage/change, then there's IMO no good reason to still call it "Go 2" :) IMO, it's fine to add some breaking changes for Go 2, but there should be reasons for them (I see no reasons to change anything about the builtins, given that they are still super useful and would likely end up in the stdlib anyway - so you don't actually save any complexity by moving them there) and they should still be limited and done carefully. When type aliases where introduced, `rune` and `byte` weren't removed from the language or moved to some internal package. They were kept as is, but now with a formal relationship to their underlying types that can be expressed in the language itself. I think doing the same with `append` and `copy` is fine (and likely). They'll stay as they are, but now get an actual type-signature (`func append(type T)([]T, T...) []T` and `func(type T) ([]T, []T) int` respectively).
&gt; The issue, to a degree, is that the contracts design really do both. I agree that this is a problem. I'm not sure the solution, though, is to mostly throw out the more powerful variant. You're example is not how the `Graph` example was constructed, by the way. In particular, I'm not sure how your Graph implementation would be used cleanly. An interface variant of the example in the draft design is probable more like type Edge(type Node) interface { Nodes() (from, to Node) } type Node(type Edge) interface { Edges() []Edge } type Graph(type N Node(E), E Edge(N)) struct { /* ... */ } func New(type N Node(E), E Edge(N))(nodes []N) *Graph(N, E) func (g *Graph(N, E))ShortestPath(from, to N) []E Maybe this can be cleaned up a bit, but it seems like it introduces a bunch of pointless repetition and stutter to me. *** On a side note, am I missing something in the draft design's example for using `len()` and `append()`? It looks like it could be done a lot simpler and with less allocations and copies than they used fairly easily. For example, append(x, x...) copy([]byte(nil), x) len(x) T([]byte(nil)) } func Join(type T strseq)(a []T, sep T) (ret T) { if len(a) == 0 { return ret } if len(a) == 1 { return append(T(nil), a[0]...) } n := len(sep) * (len(a) - 1) for i := 0; i &lt; len(a); i++ { n += len(a[i]) } b := make([]byte, n) bp := copy(b, a[0]) for _, s := range a[1:] { bp += copy(b[bp:], sep) bp += copy(b[bp:], s) } return T(b) }
Metacomment: you are being overly critical and confrontational in this and other threads on contracts. Tone it down.
The current syntax is necessitated by the need to clarify param and return types and relationships (i.e. interactions) beyond individual type behavior (i.e. an interface). &amp;#x200B; I don't think it's possible to remove type params, but my initial feelings seem to generally match yours, and I made a concrete suggestion that culminated in the following (with additional syntax in parent comments) [https://www.reddit.com/r/golang/comments/9b07qu/comment/e5443k7](https://www.reddit.com/r/golang/comments/9b07qu/comment/e5443k7) &amp;#x200B; Snippets copied here: // contract definition contract convertible {_ To, f From}{ To(f) } // ... and, alternately contract convertible { _ To f From }{ To(f) } // func definition func {type T, S Addable} MyFunc1(x []T, y, z S) T { // method definition func (mt *myType) {type T Addable} Sum(x []T) T { // func call site mt.Sum(x){int} The slightly inconsistent location of params (pre func name, post func call) treats generics like they are special, but, in my opinion, they are and that's ok.
Yes, that would be absolutely fine and up to the point.
Well I appreciate the feedback. 
What do you mean by this? He is addressing the technicalities of the solution entirely. Are you suggesting the degree at which he disagrees with Dave's proposal is somehow offensive? As long as the argument is civil, and it seems to me that it is, I don't see how one can be "overly critical." Can you explain?
&gt; You're example is not how the Graph example was constructed, by the way. Does it matter? The question is if it solves the problem. Not if it solves the problem in exactly the same way :) FWIW, by focusing on parameters, the generics would be very close to how Rust's traits work. Or Haskell typeclasses - all that would really be needed to go all the way there are parameterized methods, but TBH I don't think that'd be a good idea \^\^ But given that the ideas are already battle-proven in other languages, I think it's easy to argue that they work. &gt; An interface variant of the example in the draft design is probably more like Not really. It's not type-checked for consistency. The parameterized interface is. That's pretty much the point I am trying to make :) There is no need for contracts to actually solve these problems. I agree that they model the Graph differently in the design doc. I don't agree that they model it *better*. You can even make the code pretty much identical, by doing (assuming you have an implementation like in the proposal): type MyGraph struct{} func (MyGraph) Edges(n MyNode) []MyEdge { return n.Edges() } func (MyGraph) Nodes(e MyEdge) []MyNode { return e.Nodes() } (Note that in practice, this isn't what you'd do. In practice, you couldn't declare the methods on MyNode and MyEdge, but inline the code into the MyGraph methods. It's just to illustrate that the implementation possibilities carry over). The parameterized interface makes the implicit relationship between `MyEdge` and `MyNode` explicit. Note that the relationship is still *there* in the contract design doc (given that they need to return each other's concrete type). 
Without seeing context of that code we can't see a reason either.
Shouldn't this rather be asked in /r/python ?
The explanation is great and supported by great visuals. But I would prefer to see a few words of warning that the presented `insert` and `operations` may end up creating "degenerated" trees that are essentially linked lists. The article does mention balancing, but it does not give any indication how it could be done. During my bachelors degree this was where I struggled: getting along with red-black trees or AVL trees.
If you are under a Unix/Linux-System you could just use a Link (Hard-Link if the Soft-Link doesn't work) ln -s is your friend
&gt; The slightly inconsistent location of params (pre func name, post func call) It is indeed inconsistent, and I don't see why this should be desirable. This also discards the nice property that a generic function can be interpreted as a function which takes types as parameters and returns a new function: intSum := Sum(int) s := intSum([]int{1, 2, 3}) 
I have never seen 'go get' invoking ssh connections, but I might have missed it. Would appreciate an example of that.
Dave appears to misunderstand generics here. The idea is to describe objects that are parameterized with a type and can be instantiated. You should be able to have a generic interface. 
&gt; It is indeed inconsistent, and I don't see why this should be desirable. Human readbility. Type params are not normal params. They are special and should be treated as such. More so, (in the spirit of Dave's post) using the syntax I am suggesting, the generic function is treated more similarly to a type (yes, a slightly exotic/special type). intSum := Sum{int}
This should work relatively easily with the existing syntax since function and type names exist in the same "namespace" unless otherwise altered within a specific scope. [https://play.golang.org/p/KOyDGWcyiOe](https://play.golang.org/p/KOyDGWcyiOe)
Maybe I should just write a medium article on it haha
&gt; Type params are not normal params. Not a good reason why they should reverse evaluation order. They have to be applied first, so the type parameter list should be before the normal parameter list at the call site, not after.
**TL;DR** &gt; I'm a C++ programmer, I like the way C++ handles it; let's write Go in C++ style. 
Type params are about structuring/destructuring an exotic "type" which controls function args/returns, so the syntax is well within reason semantically.
[removed]
How about one word? Yes. &amp;#x200B; Learning any language is a good thing, good developers are polygots.
You're right!
Yes, unfortunately the setup you’re using is an advantage of the GOPATH style environment that isn’t easily translated to the module environment. Your options are: - Stand up a git server, - Copy private packages in as sub packages, - Link private packages in as sub packages. I also am not sure if the third option will work, Go has so far been largely incompatible with symlinks. 
For me it works pretty well &gt;One way of doing that cleanly is probably defining an interface and a mock structure that would return error when you need it. &amp;#x200B; \&gt;But if I already have a significant amount of code that doesn't work with interfaces, bringing them just for the sake of testing a couple of scenarios seems tiresome. It means your code can be still simplified / broken into smaller services, thats how you make the code easier to read and test as well 
One downside I can see to that is how it would work with documentation. With separate contracts, you can just show the contents of the contract, much like you would for an interface: $ go doc pkg.somefunctionwithacontract $ go doc pkg.thecontractthatfunctionuses
/u/ianlancetaylor - I'm curious to know your thoughts on this thread now that the basis has more explanation.
Hah! I sat down the other day and was going to make the exact same thing after I saw this tweet: https://twitter.com/akachela/status/1026969621994319879 Unfortunately I never got past "cute idea" and on to "type code" Bravo!
Me neither. It's difficult to judge if the comparison is completely correct, but the explanation is clear, and the conclusions are objective. There are advantages to C++'s exception mechanism.
Cool will do by this weekend. Thanks for the tip.👍
Thanks! 😂 Coincidentally, I saw a tweet which encouraged me to make it too! Tweet: https://twitter.com/Pilskalns/status/1033229593359122432
Done.
&gt; They are checkouts from a git repository, but this git repository is not in any way public, so referring to the URL in imports is not possible. From the Go compiler's perspective, never ever did an import path referred to an URL since the first public release in 2009 - no exceptions.
package != module. You can just have one module rooted at your top level private package namespace.
\&gt; Is GOPATH really dead? No, not yet. They are experimenting right now, and if people like the new module system, they will remove the GOPATH stuff. \&gt; But how do people handle "local" non-public packages with Go modules? Nothing in Go assumes import paths are public. Obviously, if you are hitting a private server, you will need creds to that server. &amp;#x200B; I have moved one of my projects to building with Go 1.11, and under Docker. The dockerfile looks like this: `FROM golang:1.11 AS build` `WORKDIR /app` `# Require $GITHUB_TOKEN to be defined` `ARG GITHUB_TOKEN` `RUN test -n "$GITHUB_TOKEN" &amp;&amp; \` `git config --global url."https://${GITHUB_TOKEN}:@github.com/".insteadOf "git@github.com:"` `COPY go.sum go.mod ./` `RUN go mod download` `# Then install the rest of the code` `COPY . .` `RUN go build` Because of Docker caching, the "go mod download" only runs once (per box). During the download, it can grab stuff from your private github account because it's authenticated. Boom, it all works seamlessly.
Also posted here: https://stackoverflow.com/q/52155374/660921
Definitely. Gos error handling is one of its biggest weakness compared to exception based error handling. At least Go 2 looks to improve this somewhat but only for code writing, but the capabilities are still really bad. 
That requires you are able to know where a particular go routine might be in terms of the stack trace. In complex systems like a web server where the stack traces are large this is not workable, thus the need for a name or context - name is just a very simple context and I believe it is sufficient. 
The lib is cool but I don’t think it solves the problem of difficult debugging. Logging is not a substitute for debugging IMO. 
You can also use insteadOf config options in your .gitconfig to rewrite the URLs in git.
In the small amount of testing I've done over the past week, having a GOPROXY outside the container yields faster builds than having a separate download step. Plus it's shareable.
`Graphable`?
One way to add methods to builtin types is to give them special builtin names. interface { builtin.len() int } These would only potentially conflict with private methods (assuming you can call them as `arr.len()`), minimizing problems arising from user methods overlapping with builtins. You could then allow people to implement the builtin methods for their own types as a hook for operator overloading or whatever. I'm not sure how something like this would be inherently "ugh"-worthy.
I am not a Go expert but I found it pretty generic. You can do whatever you need with it as you can just write code. I use it in scc https://github.com/boyter/scc/ in order to transform the languages.json file into something that can be bundled into the compiled application It literally reads the json file, confirms it is valid, base64 encodes it then writes out to a Go file so it can be used by the application. I have seen other uses such as auto-generating the code required to do functional programming in Go where it would look at slice struts and create map/filter/reduce.
An unbuffered channel works as an synchronization point of goroutines. Sometimes this is useful sometimes not. A wait-group is a synchronization point at goroutine termination which is useful in its own aspect. Think of what you need than measure performance to see what fits your specific problem best.
Your intuition is correct. `go generate` and its supporting directive `//go:generate &lt;command&gt;` are simply a mechanism to define and invoke the code generation, but they purposefully delegate the actual generation to an external command so as to not impose artificial restrictions. In theory, this means that you can use `go generate` to any effect by running arbitrary commands. In practice it's not common though, because it can be confusing to the reader of the code. Typically, you'd use `go generate` to create code programmatically from data, code templates or both. Here's an example, something I wrote a while back, of using a data-based DIC generator: &lt;https://gitlab.com/carlosdavidepto/godic/blob/master/examples/diuse/main.go&gt; It is a good example of what `go generate` was created for because it relies on the `go generate` mechanism to create the part of the DIC you don't want to write by hand (i.e. the registry/multiton methods). `go-kallax` uses the same strategy to generate data access methods for tagged structs which you provide.
IMO this should be better called 'An sMark to html parser in Go' or something along that because currently it is not apparent how this is related to Go. Can you provide some ideas why someone would choose sMark over lets say Markdown or AsciiDoc?
I really don't understand this. Why is this even important? Errors mostly occur in cold codepath and therefore effect performance very little. Besides that if you really value performance that much that you care about these tiny gains and freely trade readability for performance, I am sorry to tell you Go might not be the language for you. Go's primary goal is scalability and of course a reasonable performance is one aspect of scalable software. Personally I'd always trade predictable performance over raw performance. 
Errors occur in the cold path but the checking of errors (`if err != nil`) occurs on every call. This is costly and unnecessary. That's what the entire analysis is about.
I've probably not been reading up on this as much as I should. Is it likely that deprecating GOPATH would lead to it not working for legacy configurations? I understood that backwards compatibility was a major goal for the Go project - although whether that extends beyond the language itself, I'm unsure.
Postgres has an array datatype, if switching is a possibility 
Interesting use case, I've typically only seen this feature employed for build versioning. Would you be building the binary server side for each trial download? &amp;#x200B;
I advise against unbuffered channels for passing data in general (signal channels with no payload don't count for this). Like you say, it creates a synchronization point that is sometimes like sequential execution. It basically hides or prevents data races that would occur with a buffer size greater than zero. Why is that a problem? If you habitually use zero size channels, and eventually you need to increase their size for performance reasons, you will suddenly have to solve a bunch of race conditions. It's a form of tech debt. Some examples of where you'd be forced to increase the buffer size is are: to make good use of multiple CPU cores; or because you've introduced a dependency that invokes a C library, causing a context switch which needs to be amortized over a batch of operations to have acceptable cost. Hidden race conditions are also a form of tech debt. They tend to become visible when operating conditions or the data changes (i.e. operations are bigger, they have less uniform size, they are more numerous). That's a recipe for getting crashes in production.
Thanks for clarifying a bit on this. It affirms what I read and generators make a bit more sense now. I think I'll have to stray away from using them, because I could see this being a bit confusing for someone to pickup on in my code. 
Also, a daguerreotype made using a DSLR. 
https://blog.carlmjohnson.net/post/2016-11-27-how-to-use-go-generate/
Really awesome to see an article like this. It's definitely made some of the magic of low level libraries a little more clear. 
Makes sense, and you can always give them the extra few hours on that last day if you felt so inclined.
Right, so I've just been building the trial versions once per day, advertise it as being a 2 week trial and set the trial period for 15 days so that users actually get more time than they think they have.
Exactly.
&gt; I understood that backwards compatibility was a major goal for the Go project You are thinking of the [Go 1 Compatibility Promise](https://golang.org/doc/go1compat). We are now just starting to design Go 2.0, so it's quite possible that GOPATH will be on the chopping block. I'm confident that Go won't become like C/C++: Adding interesting stuff, while simultaneously supporting every bad decision they ever made. Trying to please everyone means you will end up pleasing no one.
People are so mean to Ruby haha... I'd put it much higher on the scale of beautiful code than python There does seem to be a large population of gophers that came from Ruby
Excellent article, thank you!
[removed]
Thanks I will add disclaimer statement. 
We already have so many markdown variations with slight differences just to confuse you. Fun project, but I hope it won’t take off for all of our sanity.
Ultimately, "go generate" is just a standardized way of running certain commands upon request. You may note that ultimately, the same thing can be said about shell itself. I disagree with people who say it should have any sort of standard meaning, because it really doesn't have much meaning at all; where you typed "go generate" you could just as easily have typed any other command to do something. I use go generate in one place to generate swagger docs using the swagger package and validate them. Since it's in a pre-commit hook anyhow, there's essentially no difference between doing that and simply running the commands directly. Since it doesn't integrate with the build process in any way, it's really not that useful. This is one of those rare cases in programming where if you feel like you're having trouble understanding this particular feature, it's because there's _less_ than meets the eye, rather than more. The use of the word "generate" in particular is very leading... that's little more than a suggestion. (I'm not saying go generate is _bad_... it just isn't very much _good_, either.)
As a network engineer learning go. This is fantastic thanks!
thanks @mhausenblas!
Benchmark it, but I'd go with 1., with a 3 loop FindAll: one for each table, starting with trips, filling each additional array in a separate for loop. 2 is a candidate too, but adds complexity and work on both sides: server, and client side, too.
Is this official application from MaxMind or just using their name?
You can do this in PostgreSQL: select jsonb_build_object( 'ID', id, 'Name', name, ... 'Users', (select array_agg(user_id) from ...), 'Waypoints', (select array_agg(waypoint_id) from ...) ) from ... 
You can't refer to other types in the same package inside contract body.
You should at least briefly describe the service you’re targeting in your landing documentions, if it’s not particularly well-known. At the very least a parsible link so I don’t have to then type it in the bar myself :)
Thanks for the feedback. I’ll add some documentation. I’ve been using it for some time across several companies so I’m biased and over-familiar. 
This is a really good write-up. Thanks a ton, learning by example is always so great. 
Unless the mobile version is just really bad for some reason, the sMark page linked to from this package is pretty half-baked. “Introduction” is misspelled, and the markup itself doesn’t seem to be displayed, most of the time, merely the rendering. I have no clue what sMark looks like from that page. 
Someone already asked this question 4 years ago on StackOverflow [1]. [1] https://stackoverflow.com/a/24095983
Average message size is around 3000 bytes. Doing the math for the peak load 32M, we will require a total network bandwidth of 96 GB for that we will m4.2xlarge won't do due to the network I/O limitations. We upgrade to higher instances in such load conditions as we don't get them pretty often. We use a central redis, in most of the cases we need to deliver a single message to a large pool of users. So we read that message from the redis. Redis has a 65K fd limit, you can hit that if you are opening a new connection for every channel. But to prevent that we are doing TCP connection multiplexing. 
What you are saying is true, especially if the time to fill and empty the channel is less than the scheduler quantum, which means that a typical cycle is that the producer fills the channel and then yields and the consumer empties the channel and yields. One would hope that multi-threading will allow both producer and consumer to execute at once. It would be nice to see a "time based" channel to allow auto-tuning. Something like a "1 millisecond" channel that allows any number of writes, but blocks if the last read was more than 1 millisecond back, perhaps with some smoothing/averaging.
Agreed. One benefit that I think is mentioned in the official blog post is that anyone building your application would necessarily already have the Go compiler installed. So instead of relying on a specific shell, Make, etc., build process requirements are already met and cross platform. But of course documenting that go generate must be run is not much different than documenting that "go run cmd/setup.go" must be run, or something similar.
It would also require special-casing calling unexported methods. And doesn't map well to `+` etc.
So, say you'd only use buffered channels. What is the correct capacity to use? You are worried about synchronization, but if that's a problem for unbuffered channels, it's a problem for buffered channels just as well. Because for it to be a problem you need to have slower consumers than producers (the other way around isn't a *problem*, because, well, if there's no data there's no data). But if your consumer is slower than your producer, your buffer will fill, eventually - and suddenly your channel is *functionally* unbuffered, just that it's harder to reason about. In theory you can build an unlimited buffer, but that's in general frowned upon, because when you run into this problem *then*, it'll manifest as an OOM, not just a slower program. I would argue that the cases where you need a *buffered* channel are more limited. What I can think of is a) collecting a variable number of results from a fixed number of fanouts (e.g. kicking off N backend requests and returning any of the errors), b) as a semaphore (making a buffered channel of N - writing to the channel increments, reading decrements), c) … sometimes I use a channel with capacity one to have an idempotent event trigger. But whenever it's about communicating a variable length stream of things or signalling asynchronous events from one goroutine to another, an unbuffered channel is usually better.
I don't see how it is anything like try/catch .... Also, you are adding plenty of context to each error. Supposedly your fetchFrom... function already adds a "fetching ..." message context to the error, so repeating that will only make the error message weirder to read. So in the end, it looks like your code would in fact be less verbose and clearer, since you don't have Errorf twice, and your message is better as well.
Yes. Coming from embedded Go was one of the few “new” languages really appealing to me: Clean and readable, it compiles and has tons of standard packages. And it compiles, did I mention that? Also VERY nice for concurrency. Implementing server side applications is really easy and works without 3rd party packages - something missing completely in other languages. Try running gRPC with a websocket server in python vs. Go and you’ll see what I mean.
You don't need to change existing code, check is only useful where you don't need extra context or you want to handle multiple errors in the same way in a larger function. 
If you pass your process's stdin/out/err to the sudo subprocess (via exec.Cmd's fields), you'll be able to enter your password interactively, but you might not get the fancy terminal mode-setting features that hide what you type.
I understand your argument, but disagree that it is a show stopper. Formally, the problem you point is about defining relationship constrains between function arguments, return value and target of methods. It is the same class of problem, but one that is a little more complex. The other one that you gave is when one of the argument is a generic function. You are right that Dave's proposal did not address this type of requirement. Live him time to publish a refined proposal. But I don't think you example is correct. The method should be define like this : `func (m Maybe(T)) Value() T` Dave's proposal addressed the generic functions and not the generic types. I currently think that we can't avoid parenthesis for generic types. We the method signature I gave, the relationship constrain between the return value type and the generic target type would be made obvious. What I meant by saying that the compiler should not accept it, is this example: `func (m Maybe(T)) Value() contract{}` In this case the type of the return value can't be inferred by the compiler because it is unrelated to the generic target type. We probably would have to introduce the concept of anonymous and named contracts. An anonymous contract would be defined as `contract{...}` and a named contract as `T contract {...}`. Named contracts would usually be defined type definition. Named contracts would allow to specify what is same type and what is a different type. See my examples `func Sum(a Addable, b Addable) Addable` and `func Sum(a Addable, b contract{Addable}) Addable`. In the former example, a, b and the return value have all the sane types. In the later example, b respect the contract of Addable but may be a type different of a and the result. 
It isn't easy to progress with this discussion when you only give examples and don't formally state what is the required semantic property that can't be addressed by Dave's proposal. In front of examples, I can only describe how I think each example car be solved by Dave's proposal. I agree that Dave did not address the issue of relationship constrains between arguments, results and target type of methods. But I still disagree with your stance that his proposal is invalid because you don't clearly say *why* it is invalid. For instance, I don't understand *why* a sane contract name can't be used to define relationship constrains. You only give examples, but don't get to the root cause. I don't know Haskell, and this reference tells nothing about the problem. Could you try to be more explicit ? * What are the requirements that a generic system must be able to cover ? * What would be needed to satisfy those requirements ? * Why Dave's proposal *can't* satisfy it ? Dave's proposal is currently incomplete, but it doesn't mean that it *can't* satisfy the requirement. See the difference ? 
I hope, that design will evolve in something less 'opinionated', because for now it looks like mechanism to merge parts of interfaces. Besides that, any contract will be tailored to function (it duplicates body of target function) or will be too restrictive (duplicates bodies of few functions) to be somewhat usable across few functions.
The impression that u/TheMerovius is confrontational and critical is partly due to the fact that he doesn't clearly say *why* there is a problem. He mainly express himself through examples an a critique about Dave's reference to *syntax*. He claim we should analyze and discuss at the *semantic* level. But he doesn't express himself at the *semantic* level. This looks like a critic on the form, and not the content. I try to understand the problems that u/TheMerovius is pointing too, and it's not easy. I now understood that the problem is that Dave's proposal, in its current state, does not allow to define relationship constrains between function arguments, result and method target. He is right about that. I would then call Dave's proposal incomplete, and not invalid. Some of the requirements of generics are not satisfied by his proposal. I find u/TheMerovius a bit harsh in his dismissing of Dave's proposal. It is not a constructive discussion. 
&gt; This is costly and unnecessary. &gt; unnecessary. Industry practice led to the different conclusion.
Let me cite the bottom part of the last (i.e. summary) table at the end of the document: &gt; case: Performance-sensitive code, where short latencies and/or high throughput matter &gt; &gt; approaches: &gt; - "Error returns": &gt; - Pros: **none** (emphasis mine). &gt; - Cons: &gt; - *makes the code slower,* increases latency and reduces throughput &gt; - boilerplate, repetitive code &gt; - cumbersome to write &gt; - lots of noise when reading and maintaining the code &gt; - Exceptions (“panics” in Go) &gt; - Pros: &gt; - *makes the code faster* &gt; - condenses the code, makes it **easier to read and maintain over time** (emphasis mine). &gt; - Cons: &gt; - needs discipline and use defer consistently to ensure RAII &gt; - needs empirical analysis of which level is adequate to catch exceptions and turn them into errors Let me now summarise it for you: - "Error returns"—how the author calls explicit processing of error values—has exactly zero positive qualities with the negative ones ranging from slowness to boilerplate, lots of noise blah blah. - "Exceptions"—on the contrary—are fast, easy to maintain and make code clear. This world view is typical for a typical C++ programmer. Constant comparison of Go with C++ (and not something else) may not be a specific indicator of the author's unconscious bias, but using the term RAII does. (The term was born within the C++ community when it tried to invent workarounds to deal with the need to explicitly manage memory and other resources in C++ code.) The Go community does not use the term: for example, there are 22 posts mentioning this term on the mailing list since its creation in 2009, and of course they are both come from folks dropping by with a typical "why Go is not language X?" questions. The problem indicated by the summary I made above is that the overwhelming majority of the Go programmers (I mean those are attracted by the language features, not somehow forced to program in them for living) maintain an opposite stance w.r.t. that "direct handling of errors vs exception" debate. This stance is well formulated in the [recent design draft on the error hndling for Go 2](https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md#problem)—specifically in its "Problem" section. I kindly invite you to read it. 
&gt; But I don't think you example is correct. The method should be define like this: Says who? It's not in his proposal. &gt; Dave's proposal addressed the generic functions and not the generic types. Then let me refer to [my first comment](https://www.reddit.com/r/golang/comments/9cjw98/maybe_adding_generics_to_go_is_about_syntax_after/e5b8akq/). That's exactly the criticism. He isn't talking about generic types, even though they are fundamental to generics and is then claiming, that the solution to generics is easier than we thought. &gt; We probably would have to introduce the concept of anonymous and named contracts. There are lots of things you can do to make this into an actually workable proposal. I'm pretty sure that you'll end up with something similar in syntactical complexity as the design by the Go team - but I'm willing to be proven wrong. I'm repeating myself, but the central criticism is, that Dave claims the syntax could be much simpler and semantics don't matter. If you have to add more syntax and ad-hoc justify that you may be able to assign conistent semantics eventually, you are effectively disproving his claims. :) &gt; Named contracts would usually be defined type definition. Named contracts would allow to specify what is same type and what is a different type. What if I need multiple, potentially different parameters, of the same generic type? For example, a generic `func Map(s []A, f func(A) B) []B`? Does that imply I have to write multiple empty contracts, just so I can get more identifiers to use? And (to repeat myself) where does the scope end? Would I need more extra identifiers if I want to have a generic `Reduce` in the same package? Type-parameters exist and work, because they are parameters, scoped to the current declaration. You say "we have identifiers x, y, z, that stand for any type fulfilling constraints Foo, Bar, Baz. All occurences of these must have the same type". Dave's description *somehow* wants to make these parameters package-scoped. I'm saying that might be aspirational, but he actually has to describe (at least) how the scoping works. If a parameter is scoped to the package, intuitively that would mean it has to be consistent in the whole package. But what does that mean, if it is used in two different generic declarations? So it *can't* actually apply to the whole package or need to be consistent over the whole package. But what does *that* mean, if an identifier is used multiple times in the same declaration? Is it consistency-checked there? There is a realm of possibilities in between the two and he should actually say something about how the compiler is supposed to infer the scope of a type-parameter, if we don't give it explicitly anymore. Without that, I'm pretty sure that an actual full description won't really simplify anything.
FWIW, I'm not actually trying to say that much about the content of his description. But his approach to the problem and his claim that the problem is easier than it seems (while ignoring all the things that make it hard). TBH, even if the title of his blog post was just "I dislike parenthesis, I wish we could come up with something nicer", I'd be less critical. &gt; But he doesn't express himself at the semantic level. If you want an example of what I consider a semantic discussion, see [this subthread for example](https://www.reddit.com/r/golang/comments/9cjw98/maybe_adding_generics_to_go_is_about_syntax_after/e5bl1f6/). It starts from a semantical perspective - where do interfaces and contracts overlap and where do they differ? It provides some syntactical examples, but it mentions there limitations and implications for the semantics. It doesn't just try to come up with nice-looking code, but it dissects the problem and talks about what properties of generics we do and do not want. Syntax is then mostly a consequence of that.
&gt;What you're trying to say (I believe) is that as long as there is a potential proposal that is compatible with Dave's description, criticizing his approach isn't justified. That's not what I think, but it could be that what I wrote could be understood that way. If you agree, let's leave this meta discussion on the side and go back to your argumentation. I finally understood one of your main point. Dave's proposal doesn't address the relationship between arguments, result and targets of methods. You a right about that and I agree with you. You gave two additional arguments that I don't understand. a. **Using contract naming to define argument relationship constrains** In C++ we define a template like this : `template &lt;typename T,typename U&gt; U foo(a T, b T)`. This makes it clear that a and b have the same type, and the result is of a different type. The extension to Dave's I suggested by using the same contract name would do the same thing. U and T would be contracts. You seam to say that this is not a valid proposal, but I don't understand why. Could you please try to explain it again ? b. **Parametric Polymorphism** Could you be more specific ? I suspect it's the possibility to define relationship between generic types that is indeed missing in Dave's proposal. Is there something else that is missing ? Go generics is for sure a subset of what is possible in C++ and D templates. But contracts is new and a valuable addition. To be honest, Dave's proposal has a draw back. When we would have `func foo(a A)` there is no direct way to know if foo is a generic function or not. We have to lookup the definition of A to know. If A is a contract, than foo is generic. But on the other hand, it's a light way to define a generic. 
Please start from using `CombinedOutput()` instead of just `Output()` as with the current approach you do not see what the `sudo` program dumps to its standard error stream. Otherwise, u/unix15e8 appears to have pointed you to the right direction. OTOH, the problem might actually lay elsewhere: by default, the command run with `exec.Command` will have its [standard I/O streams](https://en.wikipedia.org/wiki/Standard_streams) "connected to nowhere": to the special `/dev/null` device, reading from which immediately results in EOF, and writing to which succeeds with the data discarded. The problem with `sudo` is that it _may_ want to ask you for a password, and in order to do that, it needs to 1) ask you about it by printing the prompt to its `stdout` and then 2) read the password back from its `stdin`. Now there might be another problem with that—`sudo` might want its `stdin` be a real terminal (or pseudo-terminal) device—not just a data stream, but let's try to solve one problem at a time.
Finally someone alike :) 
That is a rule for contracts in the draft proposal. In Dave's proposal, this rule can't stand because it wouldn't be possible to define relationship constrains between contracts.
How's this look? https://play.golang.org/p/3pJcZ6eRnvo
&gt; If you agree, let's leave this meta discussion on the side and go back to your argumentation. The meta discussion *is* my argument :) All the examples and detailed problems I see with his descriptions are simply illustrative of why I think the way he approaches the problem is counterproductive. I'm not really interested to dissect whether there *is* a full proposal compatible with the syntax he describes. I'm criticizing syntactical starting points exactly *because* they force us into these weeds. That's why the designs start with a [Problem overview](https://go.googlesource.com/proposal/+/master/design/go2draft-generics-overview.md). By first defining what the semantical goals are and what should and shouldn't be possible to do, you enable a more streamlined discussion - you can use them as starting points to evaluate any idea against. FWIW, Dave has updated his post by now to point out some of these problems himself.
You raise valid points that will need an answer. Dave's current proposal is falling short on a few aspects that are critical for a generic system. But I didn't see a blocking problem. His proposal has a significant added value in term of readability and lightness. In my opinion, this should justify further investigation of his proposal. Regarding the scope of contracts, as I understood, it would follow the same rules as interfaces. When the identifier start with a lowercase, the scope is limited to the package. When it starts with an uppercase, it would be exported. I don't see a problem there. Regarding contract naming to identify relationship constrains between contract types, you are right that this needs further thinking. I don't see a show stopper yet, but this is a valid point that needs to be addressed if Dave's proposal is refined.
If you are just using the standard library there isn't really a difference in using CTR or GCM. But if you would implement it yourself it would be one or two extra steps to CTR.
Are you doing this for practice only, for your own use, or do you intend for other people are going to use it? How much and what kind of feedback I will give depends on the answer to that. I will give you this one bit of feedback for any of those: "join". An ORM that makes joins hard is an antipattern. Such ORMs take the "relational" out of "relational database", at which point you might as well be using a non-relational db.
There's two benefits. One is that the commands can be physically near the code they affect. The other is that there's a $GOFILE (IIRC) environment variable that is set to the current file's name which can simplify the command you need to call. 
[removed]
I would argue that the majority of Go programmers have not written large systems, either web fronts or low level systems code, and thus do not understand the value of properly used exceptions. It’s almost the same for all the JavaScript proponents - after they had enough experience writing large systems, they came together and said this is nuts, and came up with typescript, and now nearly every major js project uses it - because not using it is just staying in the dark ages. Now that even the performance argument can be put to bed, the only reason people hold on to the current error handling is ignorance or stubbornness. 
Chapter 5 kind of crashed it for me... Just mathematically prove it, the first few billion integers is not better than the first 5
Otherwise, that’s pretty damn smart
No NPM! Big selling point. One thing though I think many long time js people like is complicated method structures. Go has them but they are hidden. 
I've just learnt (on gophers slack) that this is possible by using replace in go.mod, which maps the module name/path to a directory. The module name/path does not need to be a real URL. &amp;#x200B; Sample here: [https://groups.google.com/forum/#!msg/golang-nuts/1nYoAMFZVVM/eppaRW2rCAAJ](https://groups.google.com/forum/#!msg/golang-nuts/1nYoAMFZVVM/eppaRW2rCAAJ)
No JS yay, Go is better than JS imo
*Examples:* House Members: https://jivesearch.com/?q=utah+congress Senators: https://jivesearch.com/?q=utah+senators
Depends on where you want to deploy it to. Is say it's much easier than seeing up a project with node and installing it not on in the dev and prod environment.
It depends on what you consider easy because you seem to imply that deploying JS is easy, but to deploy a Node server you'd need to install node, restore packages, and hope the restore doesn't encounter deleted packages. That doesn't seem easy at all. For Go, the runtime and application code is all in a single small binary file. You don't need to install a dependency or restore stuff.
I use mostly only unbuffered channels and I have not experienced the data races or performance bottlenecks you describe. If I need to spread load across cores then I just spawn goroutines to speed up channel intake. Go is pretty good about this and I've found that introducing buffered channels can inevitably lead to capacity planning issues (eg: your buffer eventually fills up without you knowing it's full.) If you structure your code such that it works with unbuffered channels then you'll catch these things sooner than later.
People are more familiar with python and java, a lot of times there’s no need to relearn something when what you already know can get the job done.
But why would someone publish an algorithm without formal proof that it works? „Look at the description, it’s logically deductible“ will not work anywhere
Unexported identifiers are already special cased by builtin functions and types. For `+`, I was assuming it would be implemented by a method like contract Adder(t T) { interface { builtin.add(T) T }(t) } Of course, for overloading, there's the question of whether to change the signature so that you can reuse results, like in the case of big ints and such.
[removed]
Lack of generics, C style error handling.
I believe you can use Go for most anything, just like Python or Java. The reason to choose another language is likely more about your requirements, both from the software's perspective and yourself as a coder. For example, if I'm doing some quick analysis of some files and might be parsing config files (JSON, YAML, etc.) I'll usually reach for Python. I've programmed Python for a long time and the dynamism lends itself to generically dealing with arbitrary data without much boilerplate or type casting like I might have to do in Go. That said, that is due to my own experiences more than anything. If you know Go really well, you likely have become accustomed to dealing with generic data within the confines of a static type system, so your bar for what is unwieldy is different. &amp;#x200B; For server side programming, I'm a fan of Go because it allows for a single binary, unlike Python where I needed to sort out having a virtualenv, dependencies and most likely proxy along with a process manager to keep multiple versions of my app up and running. None of that is terribly hard, but it is one less thing to mess with. I also have been happier with Go's performance over time where the Go code last longer than the Python code, where I might need to think about adopting an async I/O library and/or deal with coordinated multiprocessing. For a small, personal project, I don't really care, but if I'm at work, I'll reach for Go. As for Java, I think I'd prefer Go mainly because testing things would feel "lighter" since you don't have to use the JVM to start the process. Generally, Go seems easier to work within your editor of choice where Java often benefits from an IDE. Again, though, IDEs are great and just because my hands are likely never going to be able to use something other than Emacs, it doesn't mean that someone else might be a wizard with IntelliJ or some other tools that make working in Java a great experience. &amp;#x200B; At a higher level, use what you want to unless you can't. Worse case scenario is you have rewrite the code with a better understanding of the problem.
Having deployed both JS and Go apps, I can assure you that it is much easier to deploy a Go binary than it is a JS app. 
Yep, I received your new release. Will check it out ;)
Who made you the discussion police?
Open sourced and written in go... wanted to know if anyone would find this interesting
&gt; Unexported identifiers are already special cased by builtin functions and types. Not *quite*. The predeclared identifiers are declared in the universe scope and are thus closed over. They are not - technically - in "a different package". There's a different problem with your suggestion. Specifically the "len" one: Only defined types have methods. len and indexing and all that stuff only works on composite types though, which are not defined. You could change the spec to allow methods on certain unnamed types, but only if the method is in the universe block and also, they don't have a type-signature and need to be dynamically generated (because the set of possible slice types is infinite) and… Or you could change the composite types to instead be generic types in the sense of the spec, which is a syntactical breaking change of all Go code and… I'm not saying these problems can't be solved. They obviously can. Just that the incision you have to do to the language is quite severe.
This should be upvoted. Looks like a great way to refer to a sibling module without the need of a PROXY, Github account or server.
Yeah, I did check it out. The only feature of it I like is the AutoMigrate. Aside from that I spent more time learning it than using it. I keep running into issues and having to go back to the docs for basic CRUD ops that I thought I understood, so I'm not going to use it. :(
I'm writing this for myself first and foremost for my production applications. Joins will be easy. I spent all night on this and actually implemented boilerplate for my pseudo-code. However it was a bit more limited than I wanted it to be. Though it was worth-while to write that version. Now I'm translating what I made so that a struct can be used like this: ``` type Users struct { myorm.MODEL Id int64 `options:"NOT NULL" PRIMARY_KEY AUTO_INCREMENT` Name string Email string `type:"VARCHAR(255)"` //myorm.JOIN_FRAGMENT `LEFT JOIN users_xtrainfo ON users.id = users_xtrainfo.` //OtherData // retrieved from join myorm.TABLE `users` myorm.OPTIONS `ENGINE=InnoDB CHARACTER SET utf8` } var user Users user.Init(&amp;user) user.Name = "John Smith" user.Email = "john.smith@abc.xyz" user.Create() // create user.FindWhere("name = ?", "John Smith") // retrieve for user.Each() { fmt.Println(user.Id) fmt.Println(user.Name) fmt.Println(user.Email) user.Name = "Bob Saget" user.Save() // update user.Delete() // delete } ``` Joins are fairly easy. I do have some type-conversion issues that need to be hashed out, I figure once I slap the code on github, I'll accept merge requests if anyone wants to fix/modify it.
var person Person // default value is Person{}, NOT nil
https://play.golang.org/p/XFfAIQIKM1e
What?
&gt; Yes, but the current language is the one we're talking about :) Honestly, no one wants to throw Go away and start new. This is really hyperbolic. What I'm describing doesn't require throwing the existing language away; it's strictly additive. What you're saying amounts to saying "Go doesn't have type aliases" as a justification not to add type aliases. Go now has type aliases. They didn't have to throw out the language to do it. Saying "these types now have methods which don't conflict with any existing methods" doesn't throw away the language either. &gt; The method's code differs for every T, though. Not len, but indexing, slicing… The compiler has to generate that code anyways. Usually it would still be inlined, as it is today. 
[Proof](https://imgur.com/gallery/970N0Lf) 
A very important thing to keep in mind is that nothing is set in stone. Java now is very different than when it first started, and much better IMO. I like Go a lot, I think it has some limitations that will be addressed over time or it won’t survive. Go 2 is a big step in the right direction. 
Nice
&gt;return bits.LeadingZeros32(source\_uint) &gt;= DIFFICULTY It looks like you are comparing 15 bits when a typical PoW algorithm compares bytes. I'm not sure how your Python script works but it may be testing 7 bytes which would be 56 bits. [https://en.bitcoin.it/wiki/Proof\_of\_work#Example](https://en.bitcoin.it/wiki/Proof_of_work#Example) ``` package main import ( "crypto/sha1" "strings" "encoding/hex" "fmt" "math/rand" "time" ) var DIFFICULTY int = 7 func main() { rand.Seed(time.Now().UnixNano()) diffStr := strings.Repeat("0", DIFFICULTY) fmt.Printf("Difficulty %d - %s\n", DIFFICULTY, diffStr) for { nonce := getNonce() sum := sha1.Sum(nonce) sumStr := hex.EncodeToString(sum[:]) if strings.HasPrefix(sumStr, diffStr) { fmt.Println("Nonce: ", hex.EncodeToString(nonce)) fmt.Println("Sum: ", sumStr) } } } func getNonce() []byte { source := make([]byte, 20) rand.Read(source) return source } ```
Great explanation! &amp;#x200B; With this you can do lots of cool stuff. Like checking at which position the first n-consecutive bits start: func ffstrl(x uint64, n uint) int { var s uint for n &gt; 1 { s = n &gt;&gt; 1 x = x &amp; (x &lt;&lt; s) n = n - s } return bits.LeadingZeros64(x) } [Source](http://www.hackersdelight.org/hdcode.htm)
I agree. Go will cease to be Go if they go forward as they're discussing. It will become a mediocre Rust clone. People who want generics should just learn Rust (which is an awesome language too)
The method from §4 is what immediately came to my mind when I read the post's title. Is it really that hard to find this? Any seasoned programmer should come up with this in less than an hour.
This is something I can actually make use of right now. Thank you for your work! 
Aww, missed my lightning talk on Mage, I guess? I was first of the first block :) 
I guess whoever made me a moderator.
&gt; restore packages, no you don't do that. You copy whatever is in your staging/testing environment. you don't do `npm install` in production ,that's crazy.
No there really isn't
Another interesting thing is that the author is against a feature because of a hypothetical. That really says enough.
[removed]
It doesn't save on typing at a glance or work how I like my projects to work. I don't want to type MySQL stuff. All MySQL transactions should be abstracted away in models. On a site note I already made my thing man. It works like the example in this comment: https://www.reddit.com/r/golang/comments/9csmla/mysql_orm_solution_what_im_making_feedback_will/e5dpi0o I'll be throwing it up on Github later today for people to contribute to it. It does the basic stuff I need. I just need to write basic usage documentation when I get off work before I throw it up.
any idea when the videos will be published?
Another big + is the standard library. Most things you'd wanna do in a Go program already have modules available there, so your dependency graph can stay surprisingly tiny (&lt; a dozen dependencies for a typical web application, needing external things only for your Postgres DB, tools like negroni/gorilla, and maybe a domain specific dependency and that's all). Contrasted to JavaScript/npm where, even if _your_ app only has 2 external dependencies, those will bring in an entire _tree_ of `node_modules` weighing 200MB and including such gems as `is-even` and `is-string`. Such simple modules being so pervasive on npm is a _huge_ security issue if a dependency gets compromised, which happens from time to time.
[removed]
Found it. &gt;&gt; [StackOverflow Go Get using SSH](https://stackoverflow.com/a/27501039/2146905) Sorry for the delay. Honestly, you just exploit the system underneath. `go get ...` is just a wrapper on top of `git clone ...`. So all you need to do is setup a shell environment capable of cloning a private repo.
Playlist here https://www.youtube.com/playlist?list=PLDWZ5uzn69ewsMyuGjVsAnpQIjyud1Cv9 Enjoy :)
What about the special case with 2 leading zeros? This is about uint32s after all. The MSB gets lost in the left shift, so the result is wrong in this case: [https://play.golang.org/p/cQgkZGAQBqH](https://play.golang.org/p/cQgkZGAQBqH)
Nope!
Actually I did see it; definitely a cool talk, and I especially like how it uses build tags. I just am fine with Makefiles already :)
That is the UK conference, this post is about the one that was in Denver.
Read up on the default comment format in go. // something does this and that func something(a string) { No need for /* and always start the comment with the functions name
Thanks. The print copies at the conference sold out on Tuesday, with two days left to go. Altogether Get Programming with Go raised over $1500 for the GopherCon Diversity Fund. https://www.patreon.com/posts/gophercon-fund-21136624 
It's like working with ES 5 or Java 7, its just a nightmare working with collections, filtering them etc. None of the convenience. Back to the stone age.
I agree with this, though I think I would just call them built-in interfaces so they can be combined with regular interfaces. Then you could define something like an enum thusly: &amp;#x200B; type Enum interface { numeric String() string } &amp;#x200B; If we want to keep them out of the global namespace (and we probably do), they could live in a stdlib package somewhere (preferably one with a very short name).
Here is my feedback: • Be careful with `ioutil.ReadAll()` [1], • Remove useless []bytes to String casting [2][3][4], • Follow Godoc formatting to document your code properly [5], • Drop unnecessary code by simplifying your return statements [6], • Delete `example.go` and move the code into the README file [1] https://haisum.github.io/2017/09/11/golang-ioutil-readall/ [2] https://blog.golang.org/strings [3] https://www.reddit.com/r/golang/comments/4ologg/a/ [4] https://stackoverflow.com/a/10965399 [5] https://blog.golang.org/godoc-documenting-go-code [6] https://pastebin.com/raw/mj4WvXxw
I'd suggest adding some tests. This may not be easy but for me tests are very important to prove everything works as expected.
I was excited for a second
I'll look into testing in the future :) Thanks!
I'm missing A LOT apparently :) Thank you very much I'll take a loot at every single link
&gt; I would not go to Gophercon on my own dime. Amen. It's crazy expensive for the knowledge you get from it. It's a great convention, but not worth the cost unless it's being covered &gt; Another really impressive thing about Gophercon was the diversity. Both the audience and the speakers were way more diverse than a typical tech conference, which is both refreshing and encouraging. Maybe things are getting better? This is an intentional push by Google and plenty other silicon valley companies to advocate for more minority presenters. In signups for 2017 Gophercon there was verbiage to the effect of (paraphrasing) "we welcome presenters of all kinds, but please allow women or minorities to sign up first" I have no opinion on whether that's good or bad, just pointing out that the "diversity" isn't organic.
Start with [https://golang.org/pkg/testing/](https://golang.org/pkg/testing/) and also look into the concept of mocking.
I think the final solution was rather obvious.
That is great! I'll check it out right now
Elm has exactly 3 typeclasses (number, comparable, appendable) so that the types of the basic operators and the Dict (map) type in the stdlib can be written down: https://package.elm-lang.org/packages/elm/core/latest/Basics
&gt; No NPM! Big selling point. 🤔 not sure that would count as a selling point for js community. These are people who need leftpad in a package.
Amazing! Thank you for this! This is immensely helpful when optimizing images for size and figuring size of files in layers.
Hey folks, presenter here! Happy to answer any questions you all may have, and thanks again to Sourcegraph for the live blog!
I'm going to make my own TCP protocol that will run over Ethernet LAN. The devices are going to be raspberry pies.
That's very nice to hear :) I've just finished learning it today
So basically... You are locally connecting a bunch of Raspberries. Are you going to build an intermediate layer or will every device have point to point connections with each other device? Anyway, sure Go will work. I’d say pick a language which you are familiar with.
The software will basically create an upper layer to manage coordination between the devices so I'd say there will be an upper layer. I'm most familiar with Python but it's not the best choice for threading IMO.
Oh wait, I could python on PyPy which supports threads, mmmm
I’m in software since 2001 and I never finished learning a language, just saying 🤗
Yeah should've said I finished learning the very very basics 😅
Wouldn't you need something like `indexable` as well to cover mapping types and lists?
I feel like this solution, though elegant in what little it adds to the language, solves the wrong problem. Please tell me if there's something I'm missing. The proposed typeclasses basically suggest codifying the following interfaces: type Equaller interface { Equals(Equaller) bool } type Arith interface { Add(Arith) Arith Sub(Arith) Arith Div(Arith) Arith ... } Is this really the main point of generics? Because this can all still be done without much work right now. I never thought of generics as a way to abstract out numbers, I thought of it as a way to run diverse datasets without getting bogged down in the details for each struct, and a way of avoiding empty interfaces for something like a load balancer, where type information is not important. If what you want to do can be achieved using a compound interface, use a compound interface. 
Maybe use a good linter :)
Are you aware of this [https://gobot.io/](https://gobot.io/) ?
No but it looks really cool! The raspberry pi was actually original intended to talk to a PLC via serial connection. I wonder if this framework could help with that
Being able to express generic algorithms on maps with two type parameters seems like too useful of a feature to give up. 
Thanks for the clarification.
You know what would be neat and just a wish thing. A map of data types that is static that is of most used datatypes that you can let leverage to use to narrow the scope of the datatypes. [string, int16, float32, byte, interface, bool, rune] T[1:5] //would be to be determined choices. This way everyone knows the slice index for those types. Maybe use it like context package in that you can later determine the type though it's context.
I started with using gorilla stack http://www.gorillatoolkit.org/ which has tons of useful libraries for secure web development (routing, encrypted cookies, websocket etc). Their site has all the info but no tutorials so it can be hard to get started.
I don't think this works with a custom type without having operator functions. We can have a built in type that uses ==, or i could define my own struct which has a .Equal() method. What is the signature of that Equal method? Contracts gets you essentially the same thing, but definable for anything. You could start to create packages that have defined contracts that others can use and it was mentioned in the draft proposal: &gt;**Why not define contracts in a standard package?** &gt; &gt;*Instead of writing out contracts, use names like* *contracts.Arithmetic and* *contracts.Comparable.* &gt; &gt;Listing all the possible combinations of types gets rather lengthy. It also introduces a new set of names that not only the writer of generic code, but, more importantly, the reader, must remember. One of the driving goals of this design is to not introduce new names. Instead we introduce one new keyword and some new syntax. &gt; &gt;We expect that if people find such names useful, we can introduce a package contracts that defines the useful names in the form of contracts that can be used by other types and functions and embedded in other contracts. &amp;#x200B;
Can you suggest one? :)
Clearly someone with poor judgement.
Contracts in their current form aren't really the main point of generics either. The main point of generics is that the logic of your function is independent of the parameter's type. I'd honestly be fine with no ability to add constraints on your generics for the initial release. Once we have contracts, we're stuck with them, and as someone who's been very pro generics, I am not a fan of the current contract draft. &amp;#x200B; However, I recognize the usefulness in being able to bound by types that at least support the core operators, and if we want that ability, I'd much prefer this typeclass idea (they don't have to call it typeclasses. They can implement them as super special interfaces that we can't replicate for all I care). From my perspective, it seems like contracts are just a means to deal with the fact that Go doesn't have type hierarchies, and it's a way to *fake it* instead of implementing them. &amp;#x200B; I would love if they just conceded that, yes, there are a few built in types (mainly the ones that support operators) that are basically under a type umbrella together, and expose those umbrellas to us as type constraints as the author of this article suggests.
Agreed. My biggest grievance. I know it's still a way off, but generics should allow us to write \`.Map\`, \`.Filter\`, etc. pretty trivially. I assume a defacto library will spring up shortly after the Go 2 release for functional collections.
I love this idea, especially if these typeclasses you suggest were just special builtin interfaces that described the behavior of primitive types. Interfaces already fill the role of describing behavior. The only reason we need contracts is to describe behavior that involves operators. Adding a few of special interface types makes the language much more simple than adding mostly redundant contracts. I would also add that this change would allow us to improve certain parts of the standard library. For example, many functions in the math package such as math.Abs could be rewritten to use the Numeric typeclass/interface and not be so float64-centric.
I deleted that line for now, because apparently we aren't getting any data back anyway. I added an if statement to check the length of `inputs`, which works because now i have it printing a line that says the input is less than 1. Still unsure at how i can fix the actual problem of there being nothing pulled back via the api through the client
 func ToCsv(inputs []interface{}, output io.Writer) { w := csv.NewWriter(output) defer w.Flush() if len(inputs) &gt; 0 { // Get Header r := reflect.ValueOf(inputs[0]) val := reflect.Indirect(reflect.ValueOf(inputs[0])) var headers []string for i := 0; i &lt; r.NumField(); i++ { headers = append(headers, val.Type().Field(i).Name) } w.Write(headers) // Get Content for _, input := range inputs { ri := reflect.ValueOf(input) var result []string for i := 0; i &lt; ri.NumField(); i++ { switch ri.Field(i).Interface().(type) { case bool: result = append(result, strconv.FormatBool(ri.Field(i).Interface().(bool))) case int32: result = append(result, strconv.FormatInt(int64(ri.Field(i).Interface().(int32)), 10)) case string: result = append(result, ri.Field(i).Interface().(string)) default: result = append(result, "") } } w.Write(result) } } else { fmt.Println("Input is null, bad response") } } &amp;#x200B;
Something common you will see in Go programs is early escaping. You are more likely to see something like this: &amp;#x200B; `if len(inputs) == 0 {` `return` `}` &amp;#x200B; `...`
Would i just print that object to the console or something (again, excuse my ignorance)? I tried to print that object and i just get \[\]
Is there any documentation for this library you are using? You can also print the object using `fmt.Printf("%+v", reportsPage)`, which will add field names from the struct. My guess is that you are supposed to be using some sort of authentication, but it appears you are not. Especially since you have `rapid7vmconsole.ContextBasicAuth` and `rapid7vmconsole.BasicAuth`.
Also, printed the reporstPage and got this: `{Links:[] Page:&lt;nil&gt;` 
I really don't understand why you were downvoted for responding to my question!
I have been doing this for a few years. For IoT, server, and even some client side stuff. It's the most stable part of my stack.
[removed]
Welcome to Reddit!
That is not true - you are using errors in this case for flow-control - that is a poor design/usage. Otherwise you are treating both "customer does not have enough money to pay", and "a disk error occurred" at the same level - the former are not exceptional errors - they are expected! The vast majority of errors in the stdlib are exceptional conditions (io errors, bad parameters, etc.)
Transitioning to serverless was actually a great simplification of our maintenance burden, both administrative and developer. I don't advocate making the switch without serious consideration though. Always chose the correct tool for the job!
I have found that serverless fits nicely in place of "glue" scripts for orchestration or administration.
The edgex foundry project, aka the future platform for just about any industrial iot embedded Linux application, is actively refactoring their codebase from Java into go and are seeing massive improvements to performance and memory footprint. It's not hard real time but then again neither is vanilla Linux. Hopefully that gives you confidence in your choice
Thank you guys for all your thoughts. Please, take my assumptions below here with a grain of salt. Please, feel free to correct me wherever I might be wrong. My struggle with unbuffered channels that it synchronizes what supposed to be parallel streams of execution. If that happens, it feels like we are using channels as a procedural call, or a function call if you may. At this point, Synchronization in my mind guarantees a sequence of events to happen in an exact order. In that case we are no longer processing in parallel. Most of the time different goroutines might be waiting for one another. At this point, I feel that the complexity incurred by using goroutines and channels has a cost higher than the perceived parallelism. On the other hand, to my experience at lest, it is rarely that consumers and producers are are in a state where ones are faster or slower than the others all the time. If the case is always that the producer is faster than the consumer. Then we reach the same conclusion, the system is almost fully synchronized and we get to the same point again. Does it worth the complexity? The only promise of parallelism is that there is no guaranteed order of execution, and to gain the most potential performance gain, the system should be designed as such, i.e. asynchronous. At this point, we can utilize multiple cores in the best way and potentially create resilient distributed systems. For an example, a goroutine or a group of goroutines can be split off to a separate service entirely with minimal effort. In a perfect world, buffers should never be empty nor they should ever be full, at least for the most of the time.
That's the general rule of thumb: if you can avoid code generation, avoid it, but don't go through the gates of hell for it. `go-kallax` and `godic` fall into that special "you must not have anything better to do if you're writing this by hand" bucket, though. As others pointed out, `go generate` can be used for other things like documentation. In this case it is the best option unless you are already using some other build tool like make.
Go doesn't have good support for UI and python/Java are much better supported for analytics
&gt; As far as I can tell, this idea doesn't let you create an ordering on two []byte slices. because the author decided orderable = integer | float | string Yeh, because this doesn't work: x := []byte{'x'} y := []byte{'y'} if x &gt; y {} ...you can still obey sort.Interface.
[removed]
&gt; Will the proposed Go generics enable static dispatch, with accompanying speed increase, in the case of interface types (as above), as well as for generic types? Both essentially run into the same problem, in that they require whole-program analysis. In trivial cases (such as the one you are presenting here) that seems clear, but in more complicated cases it's less so - where "more complicated" can be as simple as a branch with an extra assignment. I'm not sure the simple cases are common enough to justify the cost, personally. FWIW, the design doc intentionally doesn't answer this question, so that it becomes a compiler optimization, which can be tuned with heuristics over time. (BTW, the word you are looking for is "devirtualization". There is [an issue about it](https://github.com/golang/go/issues/19361))
Great answers! Here's a list of curated [best resources to learn Go](https://reactdom.com/go)
Cookies in Go are not used differently than in any other language. If you have any specific question: Just ask.
I've been thinking along the same lines about this for a while (put https://gist.github.com/jimmyfrasche/656f3f47f2496e6b49e041cd8ac716e4 in the generic issue thread last night after much work). You made a lot of great points and articulated my discontent with the contracts proposal and a lot of the motivation behind the decisions in my proposal better than I ever could. Having pushed these ideas around for a while there are some points that you'd run into if you tried to work this out further. For the most part operators don't matter. There aren't that many types with operators and you can turn an operator into a func/method but not vice versa. But comparability is the one that mucks everything up. Most types have `==`/`!=` and it's really hard to work around the absence. Most importantly, though, you can't use type arguments as the key type for a map unless you know statically that the type is comparable. You either need a way to specify comparability or to infer it. I'm not a fan of that kind of inference. You should be able to glance at the type parameters and know what types you can use. So you either need a way to denote that an interface only accepts comparable types in general or a separate notation for type parameters to limit them to comparable types. The other thing that is hard to work around is convertibility. It's the only simple property between types that causes issues (or, rather, severely limits usefulness). There needs to be a way to specify that a type argument for `A` is convertible to a type argument of `B`. Interfaces alone are tantalizing close but fail in some subtle ways that makes them unfit for purpose, but if you can additionally model comparability and convertibility then you have a nice simple language for expressing generic constraints. Also, re `T Ordered(T)` if you expand `Ordered(T)` out, which you need to do to type check it anyway, that's the same as `T interface{ Less(T) bool }` so it makes a lot of sense to allow it. The psuedo-interfaces concept looks intriguing. That could be used as the means to specify comparability. I'm unclear how they would work when not used as the constraints on type arguments, though. If they are special interfaces but with additional operators, would `a &lt; 0` panic if `a == nil`? I'd imagine there'd be a lot of nuts-and-bolts details to work out for how those work. I imagine it would be a good-sized section in the language spec to describe them all, like how an interface only has a `+` operator iff it is or embeds `arith`. (The same doesn't apply to comparability alone since interfaces always have `==` anyway). It would be nice but I don't see it happening :(. I'm totally fine with passing in funcs and `Less` methods, though.
This doesn't appear to allow for generic abstraction over structs with specific named fields, unless I'm missing something, since interfaces only allow you to specify methods. I think the current version of contracts allow contracts over struct fields, although there's no actual examples of that that I could spot in the draft.
I think you might be looking for something like Emgo. https://github.com/ziutek/emgo
Easier and you don't need any third party library to try to make it easier like with js. Here are the deploy steps for most Go applications: 1) copy binary to server or docker image 2) run binary
I like this a lot. It solves the weird ambiguity that comes out of having to express contracts as examples. What I'm missing here is why we can't go full steam ahead with *actual* typeclasses to cover the need for "orderable", "comparable", and so on. The time.Duration example seems like a bad excuse not to go in that direction; after all, it could just implement the necessary interfaces, at the cost of some boilerplate code. Or we could do like Haskell and Rust, and support default implementations ("deriving Eq, Ord"). If anything, the built-in semantics aren't well codified, and would benefit from being so. These pseudo-interfaces would accomplish this, but a more Gophery way would be to express the semantics as true interfaces.
In a week or two.
Famous last words.
Don’t do this. There are plenty of editing protocols that can be leveraged. For example: https://golang.org/pkg/net/rpc/
haters gonna hate
1) interfaces are just methods the other structs have to implement; so you dont need all the funcs, just the minimum, userlist.GetUsers and adminUsers.GetUsers, etc 2) you can just use a method pointer, and use it anyways, so for users.SimpleFunc you do: func (m *user) SimpleFunc() *user` and it works anyway, you can now use users.SimpleFunc (but it wont work for adminUsers.SimpleFunc` unless you put it in the interface and/or you write another func for the other type (i think)
Why is UserService an interface? Just so you can mock it more easily? My understanding is that interfaces are for defining types that can be met by several different implementations. When would you have another implementation of a the UserService outside of testing? 
By the way what I like about big interfaces is the convenience. It makes it easy to access all the funcs from everywhere: &amp;#x200B; type Env struct { DB DatabaseClient } type DatabaseClient interface { UserService() UserService } type UserService interface { GetUser(id int) (\*User, error) } func GetUserHandler(env whatever.Env) func(w http.ResponseWriter, r \*http.Request) { return func(w http.ResponseWriter, r \*http.Request) { user, err := env.DB.UserService().GetUser(id) fmt.Fprintf(w, "User ID: %d, Email: %s", [user.ID](https://user.ID), [user.Email](https://user.Email)) } }
I have to agree with this, by and large. The more I've played attend with contracts the more oddities and awkward edge cases I've run into. It's an interesting idea, but I think it'll be rather odd, at least at first, in practice. My personal favorite solution to the operator problem is to introduce the pseudo-interfaces, but don't give access to the actual operators using them. Instead, have methods in there that become available for built-in types only when they're used with them. For example: // Built-in pseudo-interface: type Plus interface { Add(Self) Self } func NormalFunc() { var i int i.Add(3) // Not valid. GenericFunc(i) // Valid. } func GenericFunc(type T Plus)(n T) { n + 3 // Not valid. n.Add(3) // Valid. } This automatically solves the use case of handling both built-in types and types with custom addition/equality/whatever support without requiring either operator overloading or explicit methods on built-in types. That being said, I'm not really sure how 'possible to use as a map key' would work, since an `Equals()` method would be indistinguishable from an equals operator once inside the generic function. Might need to add an extra, impossible to implement manually pseudo-interface, such as 'mappable', that's only 'implemented' by the right types.
When deciding on an interface, I would think about what it's intention is. &amp;#x200B; For example, thinking about io.Writer or io.Reader, they can be used in place anywhere where reading or writing will occur and it's very convienient that it's a small interface. &amp;#x200B; However, an interface like you are using here is probably only going to be used in a single place or 2, handlers for example, or in tests. I personally use a similar approach and see nothing wrong with a larger set of methods for an interface if it makes sense to bunch the methods together, unless the intention is that specific methods are meant to be re-used in multiple places without using the other methods. &amp;#x200B; I hope that makes sense!
Thanks, that makes sense. In another app I'm using this approach: type GetPhotoAuthorizer interface { CanGetPhoto(userID, photoID uuid.UUID) bool } type UpdatePhotoAuthorizer interface { CanUpdatePhoto(userID, photoID uuid.UUID) bool } type Authorizer interface { GetPhotoAuthorizer UpdatePhotoAuthorizer // ... many more embedded interfaces } This leads to many small interfaces and a few big. What do you think about this?
Dumb ques alert : Why can't interfaces be extended for types too? Also, why can't interfaces be enforced by Compiler at compile time, rather than at runtime? This way, any type which has a + operator defined can be passed to an interface accepting any type which supports + operation. I think problem arises for complex types. Perhaps they can inherit traits of the underlying constitutent elemnts. Sorry if I am not verbose enough.
Awesome read, thank you!
Here's a good general guide to building web applications with Go: [https://astaxie.gitbooks.io/build-web-application-with-golang/content/en/](https://astaxie.gitbooks.io/build-web-application-with-golang/content/en/) &amp;#x200B; Architecture and implementation is on you, you'd be lucky to find any tutorial aimed at card games. Start small and build up one feature at a time. You'll learn a lot along the way. &amp;#x200B;
check out mosquitto and mqtt. go has libs for mqtt, and its a very popular pupsub protocol
Is the Authorizer interface meant to hold permissions for all resource types across your application, or just for the Photo resource? If it's for everything, I would suggest against using a large interface and only pass the interfaces that are needed at a resource type level, for example: &amp;#x200B; `type PhotoAuthorizer interface {` `CanGetPhoto(userID, photoID uuid.UUID) bool` `// etc` `}` `type OtherTypeAuthorizer interface {` `CanGetOtherThing(userID, photoID uuid.UUID) bool` `// etc,` `}` `type Handler struct {` `pa PhotoAuthorizer` `other OtherTypeAuthorizer` `}`
Also consider in this case whether an interface like the following may be a simpler approach (depending on how you are actually authorizing in your app: &amp;#x200B; type Authorizer interface { CanGetResource(resourceType string, userID, resourceID uuid.UUID) CanUpdateResource(resourceType string, userID, resourceID uuid.UUID) // etc } &amp;#x200B;
Hmmm 
Yes compiled languages for the win !!!!
You're right, sorry
Yes !!!!!
Contracts apply constraints over *MULTIPLE* types, not single one.
I don't think I have any data flow that would make MQTT viable
I remember Brian Ketelsen saying in his Gophercon Moscow talk that sometimes it's unavoidable. But if you really want to factor something out, I see at least two options: * Split the interface further by its functions. So you would have `UserQuerier` for queries and `UserModifier` for creating/updating/deleting. * Generalise your `Get...` methods into one method like `GetUsers(q UserQuery) ([]*User, error)`.
RPC looks basically perfect for what I intended to do. Thanks!
Perfect, so the OS is already marshalling them into some sort of loose order despite the organised chaos of UDP!
Imagine the complete chaos if application developers had to do it by hand!
Well yeah!!! I was dreading having to think about this!!!!
Thanks for sharing your thoughts. I feel that now contracts are restricted by everybody not wanting to alter type system, because everything contracts can use already present in reflection API. Also there is C++, which is great example for type system gone wrong and scarecrow for any bold design.
There are several people who came up with more or less the same thing (but different names) independently :) So'd feel weird taking credit \^\^
There are multiple frameworks and ORMs in Go. But you could easily just grab an HTTP router and sqlx if you want more than the standard library. Those are more than enough for even complex projects.
&gt; Most importantly, though, you can't use type arguments as the key type for a map unless you know statically that the type is comparable. One thought I had for this is that if you take a `map[K]V` as a parameter, you wouldn't actually have to care about this. That's because the user can't actually construct a value of that type, so couldn't instantiate your function with invalid types anyway. Then I remembered the existence of `nil` and got slightly annoyed :) &gt; There needs to be a way to specify that a type argument for `A` is convertible to a type argument of `B`. Why? I'm having trouble coming up with a use requiring this - except the hack for mini-sum-types of unifying the strings and bytes package, by having `contract stringly(t T) { var _, _ = string(t), []byte(t) }`. If you need to convert to `B`, just take a `B` from the beginning and let your user convert. Yes, that means calling the function is slightly more cumbersome, but it's a bit cumbersome anyway. In terms of the article, FWIW, you could have a `convertible(T)` parametric pseudo-interface. Technically speaking. But honestly, I'm not sure it's a bright idea (and I don't think the Go team wants this kind of "creating a mini-language for constraints"). &gt; I'm unclear how they would work when not used as the constraints on type arguments, though. If they are special interfaces but with additional operators, would `a &lt; 0` panic if `a == nil`? That's a pretty good question. I have not thought of the fact that, technically, pseudo-interfaces could be nil. In theory, you might work around that by having well-formed zero-values for them, but it's not entirely clear what that would be e.g. with `comparable`. So… yes, I think it would have to panic. I mean, it's at least obvious behavior. &gt; I imagine it would be a good-sized section in the language spec to describe them all, like how an interface only has a `+` operator iff it is or embeds `arith`. I'm not sure. Because you can also use the new vocabulary to simplify some of the prose. For example, [this section](https://golang.org/ref/spec#Arithmetic_operators) is equivalent to defining `arith` itself. So you could replace the prose with saying "the operators apply to anything implementing `arith`" and (in the one section describing pseudo-interfaces) say that pseudo-interfaces are embeddable. It's an addition, but I don't think it'd require lots of new text.
The fact you're not content with the action of this particular moderator is no excuse for a personal attack, please stop. 
&gt; What are some reasons people choose to use Python/Java for their server-side programming? because there are 20+ years of codebases in these languages and someone has to maintain these?
&gt; There are multiple frameworks and ORMs in Go. Of the quality of Django? no. But that's not going to happen because of Go's type system. And I personally do not like libraries that rely on code generation.
&gt; Unfortunately, I also didn't manage to understand your proposal. That is not a good sign if I represent the average programmer. Contracts has the advantage to be a clear concept easy to grasp. Can you clarify what you didn't understand? Because ISTM that in terms of concepts to understand, this design is mostly a subset of contracts. IMO, if this is less understandable than contracts to you, I clearly need to rephrase some things :)
This seems really interesting. Could you elaborate upon the use-cases for DH-RCP? When is this a good fit? &amp;#x200B; Also, is this really for _decentralized_ (as opposed to P2P or distributed) applications? 
&gt; What I'm missing here is why we can't go full steam ahead with *actual typeclasses* to cover the need for "orderable", "comparable", and so on. I'm not entirely sure what you mean here, so I'll just work by analogy to Haskell (which is the canonical language with "actual typeclasses" I know), if that's okay. To a decent approximation, Go interfaces *are* typeclasses. There are differences though: 1. In Haskell, you write an instance of a class and can write an instance of any class for any type you like. In Go, methods are attached to the type itself and can only be provided by the package defining the type. This is largely based on how scoping works in Haskell and Go and to support the "large scale engineering" goal of Go: By disallowing any package to attach methods to any type, you don't get breakage at a distance, when multiple packages provide conflicting instances of a class for the same type. It's not a loss in power, though, because in Go, you can always use embedding to provide a new type with different instances. 2. Members of type-classes can be any function, so they are not restricted to methods (which pretty much™ are functions taking the receiver-type as the first argument), but can have any order of arguments. In Go, an instance of an interface necessarily needs to take the instantiated type as the first argument. This isn't, again, a loss in power, though. You can always ignore the receiver (so you can have `type Equal interface { Eq(T, T) bool }` and instantiate that as `func (MyType) Eq(a, b MyType) bool`). 3. Type-classes can have type-parameters (though I guess it could be argued that that's `{-# LANGUAGE MultiParamTypeClasses #-}`). This is what all this fuzz is about: Adding generics to Go. This allows to have parametric interfaces, which make this possible. 4. Type-classes can have parametric methods. This is the real difference (and what prevents us from implementing e.g. `Functor` in Go, even with contracts). The reason for not having this is mentioned in the [problem overview](https://go.googlesource.com/proposal/+/master/design/go2draft-generics-overview.md) under "Dual implementation" (not a particularly natural place to look). Haskell avoids these by a mixture of lazy evaluation, boxing everything and its actual, formal, (extended) HM type-theory. So, the answer to the question "why can't we have actual typeclasses" AIUI comes down to a mixture of 1. Because Go wants to allow control over memory layout 2. We don't want to have methods on foreign types 3. We want identifiers to be scoped and qualified to a package 4. We don't want to have a full type-theory with hard to understand and costly to implement inference
&gt; Trying to read […] doesn't seem very fun to me. TBH, I agree, but that's largely due to the fact that I have no idea what you're trying to do. FWIW, I don't really understand your point about iterators, I think they'd work just fine: type Map(type K, V) interface { Get(K) V Set(K, V) Range() Iterator(K, V) } type Iterator(type K, V) interface { Next() bool Key() K Value() V }
YetAnother "Famous last words" :)
\&gt; Will the messages ever be garbled Maybe the reason you're confused is because you're ignoring some returned data. ReadFromUDP(b []byte) (int, *UDPAddr, error) [ReadFromUDP](https://golang.org/pkg/net/#UDPConn.ReadFromUDP) returns three values, the first one is how many data has been written to the buffer `b`, the second one is the ***claimed*** UDP address of the sender from the received packet, the last one is error. After the [ReadFromUDP](https://golang.org/pkg/net/#UDPConn.ReadFromUDP) has returned, you need to keep track on who sent whose data by yourself and act accordingly.
It's sentences like these one that confuses me: &gt; Contracts add two things: One, a way to add type-parameters to functions and types. And two, a syntax to constrain those type-parameters to a subset that allows specific operations. Contracts don't add type-parameters to functions and types. 
You're right, I was imprecise. I meant "[the Contracts design doc](https://go.googlesource.com/proposal/+/master/design/go2draft-contracts.md)". It's a bit confusing that the title of the doc is only one half of the concepts it introduces :) Untangling the two was one of the main goals of writing that article. I will correct that, thanks.
A Raspberry Pi is a small computer more than an "embedded device". As long as you keep it's limitations on mind, you can run pretty much anything on it just fine, including Go. I've run production Perl code on smaller machines than a Pi. A long time ago, but still, the principle holds.
I updated an example for 2 nodes sending messages with 1 tracker running DHT for ECDH. The traditional key exchange like TLS or SSL needs a CA to ensure key exchange run safely. But in DH-RPC I use a DHT to do that. You can see the sequence chart and example in the GitHub page.
The question I'm asking is whether interfaces will allow for static dispatch ("devirtualization"), just as generic types will. Not whether the compiler will always do it, just will interfaces be considered as generic types, or whether call\_bar would have to be re-written as: &gt;func call\_bar (type T) (value T) { T.bar() } I'm guessing it would have to be re-written.
Why isn't this upstreamed? ISTM that you could avoid the explicit initialization by doing it lazily on first use.
&gt; The question I'm asking is whether interfaces will allow for static dispatch ("devirtualization"), just as generic types will. And what I'm answering is, that, yes - they will allow for devirtualization iff generic types will :) But also, again, most of the implementation questions are completely open. In general, questions like these are unanswerable by design. &gt; I'm guessing it would have to be re-written. I don't see why. 
Perhaps consider adding the post to https://github.com/golang/go/wiki/Go2GenericsFeedback, as it seems to be a lot better thought out than some of the other posts in there.
Are any places actually using all of those methods, or do most only use a subset? If the latter, you can use that to split things into smaller interfaces. For instance, it seems unlikely that most places both Get and Destroy a user, or Get and Create or Create and Destroy, suggesting a UserGetter, UserCreator and a UserDestroyer interface. You have many GetUserByX methods, suggesting a UserFactory. As you split them up, you can still compose the new interfaces into your UserService interface to keep things backwards compatible while you go through your code and update signatures to take the smaller, more focused interfaces.
Someone else already did, apparently :) I'm always hesitant to add myself to these sort of lists; I don't feel I should judge whether my own input is that helpful ;)
thanks! Can't wait for them to be out..
strconv.ParseUInt and FormatUInt look pretty efficient to me, but perhaps this is a good situation to write a benchmark for your actual usage.
As we all know, Elliptic Curve Public Key is computed form Private Key ECPubKey := ECPrivKey.Pub() DH-RPC node is generated by hash of NodePublicKey and an Uint256 Nonce: NodeID := sha256(blake2b-512(NodePublicKey + Uint256Nonce)) DHT is used to hold the NodeID:PublicKey NodeID:Addr map. A RPC connection will do ECDH to get shared secret after TCP connection established. GenECDHSharedSecret(Trackerub, APriv) == GenECDHSharedSecret(APub, Trackerriv) The main procedure is described as sequence chart [here](https://github.com/CovenantSQL/CovenantSQL/blob/develop/logo/rpc.png) So anyone tries to fake NodeB by overwriting the address or public key on DHT without the private key of NodeB will be failed to get the correct shared secret.
ReadFromUDP will read a single packet. Since all you're doing is printing, that means the data within the packet won't be garbled, but data across many packets on different connections will be intermingled. 
Why convert `bootstrap` to a pointer instead of removing it entirely and allocating `buf` instead?
I'm working now using it (with VS Code), I'm making much more progress and the code is getting better and better Thank you!
Well if it's specifically just used for testing cause it's a mock then do what you want really. For actual code you want to probably create a function that takes in types as params encase it's a data service API. Obviously the type names too. ``` Func (context, user, service, interface{}){ //From here take from the types you need and do a type check statement to proceed. } ```
That looks perfect, thanks for the guidance.
Don't be so hard on following the 'right' way. You are painting the picture, feel freedom. Some ideas on naming: \`\`\` type UserService interface{ Get(id int64) (\*User, error) GetByEmail(email string) (\*User, error) GetMany(ids ...int64) (\[\]\*User, error) Create(email string) (\*User, error) Update(email string) (\*User, error) Destroy(id int64) error } \`\`\`
Are you using your own redis server installation or AWS elastic cache?
Just out of interest, what approach would you use if you were encoding to binary and then to hex? Wouldn't the output from that be the hex for the binary representation of the int, not the hex for the actual int itself?
Variable length allocations are always heap allocated. So having a fixed width bootstrap can avoid the heap, and be on the stack.
Great to hear. Good thing I bought it on Monday, then! Also, good I read this post on Monday, otherwise, I would never have known the book was being sold (not sure I would have known the booth existed).
Surely it can't be on the stack if it needs to exist after `New()` returns.
Wrap it, maybe Adapter pattern? (Coming from Java, don’t know if this is common go practice)
I'm showing a usage of an implementation of some of the standard functional iterator functionality. The implementation, assuming generic methods, would usually look something like this: type Interface(type T) interface { Next() (T, bool) } type Iter(type T) struct { Interface(T) } func (iter Iter(T)) Map(type R)(f func(T) R) Iter(R) { return Iter{ Interface: mapper{ prev: iter.Interface, f: f, }, } } // Etc. The `Map()` definition is illegal under the current draft.
Yeah, but how many side channel attacks does this unlock?
Or even, consider a standard 'Slice' type: `type Slice(type T) []T func (s Slice(T)) Map(f func(T) R) Slice(R) { ... }`
RSS does not provide curation: You can't decide to receive only the top stories in a time window. On a more subtle level, as being a chatbot, you receive a notification at 6:30 and 18:30 with all the filtered content, but unlike in an RSS aggregator app you are not able to explore and spend more time than the 12 received stories.
I wrote one too except using sqleet instead of sqlcipher: https://github.com/cretz/go-sqleet
What about authorization system like `IsAuthorized(userID uuid.UUID, permission string) bool`, and the permissions are things like `"photo.read"` `"photo.write"` etc.? Seems like it would keep you from having to reinvent authorization for each different part of the system while still being easily mockable.
New() gets inlined
I would make `GetMany` a function that uses an optional interface if it exists (which it would for the database) but falls back to just making a bunch of `GetByID` calls if it doesn't (e.g. in your testing mock).
Is "top stories" taken from HN or decided on by the bot?
The only way to do what you want (literally reuse the symbol "endian" for both types" is to make "endian" an empty interface{}, then use type assertions and type switches when you need to do things with it. ``` var endian interface{} endian = binary.BigEndian // read check and compare endianes. binary.Read(file, endian.(binary.BigEndian), &amp;header.check) if header.check == 0x01020304 { fmt.Printf("Yeah success: %x\n", header.check) } else { // read check again but with LittelEndian endian = binary.LittleEndian _, err := file.Seek(0, 0) if err != nil { log.Fatal(err) } binary.Read(file, endian.(binary.LittleEndian), &amp;header.check) fmt.Printf("No success: %x\n", header.check) } ```
It's taken me a while to internalize this, but in general it's not worth stressing about the interface details. What you want to get to is a point where you don't mind declaring type destroysUser interface { DestroyUser(id int) error } in some other package that only wants to destroy users or something. If it's convenient within a given package to have one big interface, go ahead and do it. It is convenient after all. But maybe you just plain don't export that interface at all. Other packages can declare their own little interfaces just fine. This is not "the interface". It's just _an_ interface. I think if you internalize this idea, and get more used to packages declaring local interfaces that just describe what _they_ happen to need, then the need to worry about or be proscriptive about the nature of interfaces mostly goes away. Big, little, who cares if the package using the interface is just going to declare exactly what it needs anyhow. You may also want to write the package more in terms of the little interfaces it needs, rather than insisting that it has to have an entire user. It depends on what you have. The exception is for interfaces like io.Writer where you deliberately want the interface to be very widespread within a community. Pretty much by definition, your own end-user application never has this concern, though.
Thanks for advise. I just moved the interfaces to the consumers. Here's what I did: I removed `whatever.Env`. Instead the handler gets a `handler.UserGetter` passed in. This also makes `whatever.UserService` and `whatever.DatabaseClient` obsolete. See this [branch](https://github.com/kschaper/go-issues/tree/define-interfaces-where-used/big-interfaces) if you are interested. 
Another case would be if you want a caching version and an eager implementation. Depending upon how it's organized, this might be how different datastores are abstracted around. Or perhaps a way to abstract around SQL vs document stores (though I don't personally think you should do that--but that's another topic).
Thanks for the hint. actually binary provides an interface for this: binary.ByteOrder so i only have to define: `var endian binary.ByteOrder` &amp;#x200B;
I will definitely think about this. It feels better to pass in what's actually required. Note: I used the autorizer just as an example for a large interface. I'm not sure authorisation should be handled within a handler. I'm thinking of using a middleware. But that's for another post.
I don't know if I like using strings to distinguish between resources. Maybe I should give it a try to see how it looks. But thanks anyway.
https://play.golang.org/p/UPiNueqX6gO
Yes, splitting up the interface is probably the easiest change. I just got rid of `whatever.*` interfaces completely. See this [branch](https://github.com/kschaper/go-issues/tree/define-interfaces-where-used/big-interfaces) if you are interested. The reason why I have methods like `GetUserByEmail` is simplicity and readability. But when the app grows flexibility is sometimes more important. So a `UserQuery` would ensure that. Thanks for the tip.
No, all of the methods are not used in one single place. They are defined in one big interface just to make them accessible everywhere (via `Env.DB`). But yes, splitting up and composition whould make sense.
I'm not sure it's a good idea to use `interface{}`. This basically means I can pass in whatever I want. To see what's accepted I would have to check the function body instead of the signature. Or is this meant to be used in tests only? 
Even better. I've not used that package much, but glad you got it worked out.
Trying to find the "right" way for me is actually a curse ;) I'd love to just hack stuff together and finish apps.
I'm afrait I can't follow. Could you please explain a bit more?
You appear to be correct. How odd that the compiler can see it's safe for both the buffer and bootstrap array to be placed on the stack, but fails when they're combined into a single structure.
According to the link: &gt; With updated escape analysis, it's possible to actually take benefits of bootstrap array, but only if it's not "inlined" into Buffer object. So, we need a pointer to array instead of normal array. &gt; This makes it impossible to use zero value though, hence New function. Unfortunately, it means that we can't merge this into golang bytes package, it would be a breaking change in package API.
I've been playing with an idea, where struct fields automatically map to interface methods, such that a struct field called Foo of type Bar would automatically implement interface methods Foo() Bar (for reading) and SetFoo(Bar) (for writing). You'd only have the magic methods if you are accessing the struct as an interface, so there's no collision of names of methods and fields. 
Yeah I mean I just meant it as a general guideline but I'm guessing down the line some where some how you might need another param but I guess you could just make a different function and yeah it can be abused. Just use what you need. I was thinking on the way to work about the params. I mean I think it might be a bad idea to do it per service. I would think it would be more reusable for parts of services or columns from your db. Maybe I'm going to linear here but having something to separate services without rewriting APIs will save you a ton of work. My work sadly in php did everything in multidimensional arrays and the problem turned into that you can't later delete an API field because some where down that line of it being mutated a certain service needed that field or is checking for it. So when you only need part of it, you have to add something only. Which leads to this god array that is 10 level deep and makes working with it terrible. And if it is vital to everyone else it turns into this monster of time wasting.
Sorry, I mean that VS Code has amazing support to problem detection in Go apps. And having stuff as an interface can help give you more verbose errors than if you used functions or structs instead. 
It's taken from the https://hn.algolia.com API, it's kind of better than taking directly from HN thanks to the filtering capabilities ("SELECT * FROM stories WHERE publish_time &lt; 12H ORDER BY votes LIMIT 12)
I tried the psuedo-methods when I was playing around with things. I dropped it because it was ultimately orthogonal to the stuff I needed. I had some open questions that made me slightly uncomfortable like what happens if you do `type Int int` and define your own `Add` method and do these always show up in reflection and does that have any implications? Ultimately, I had to single out comparability as something special because it was something special. You can already use `==` with interfaces but it may panic if the dynamic type is incomparable. If there's a way to specify in the interface type that, in addition to the method set, it only accepts comparable types then you get an interface value where `==` never panics. Using types like this as constraints let's you use `==` in function/method bodies and you can use them as map key types. They're also useful on their own if you have something that needs to use interfaces even with generics and be a map key. In my proposal there are generic methods. I made it work in interfaces by letting interfaces specify generic methods. If an interface has a generic method parameterized over `T` like `Foo(T)`, it only accepts a type with a generic method with the same parameterization. That implies that you always need to compile a generic implementation of the method (practically a 100% chance you were going to have to anyway) and always need to use it when dispatched through an interface but otherwise the compiler is still free to create specialized versions. Accepting that you always need to compile the generic implementation means everything works with reflection, too, including the possibility of creating new instantiations at runtime. (Even if we go with the contracts proposal, please still this, Go team!)
Yes! https://github.com/avelino/awesome-go
[here](https://github.com/avelino/awesome-go).
[Still though, removing `bootstrap` and setting `buf` directly still seems to be just as many allocations.](https://pastebin.com/aPZ5HN8A)
I wonder what you mean "the hex for the actual int itself". A uint64 with the value 257 is represented by the hardware with the two LSBs of value 1, and the rest of the bytes all zeroes. binary.BigEndian.PutUint64 turns this into a []byte that looks like [ 0, 0, 0, 0, 0, 0, 1, 1 ]. Putting this into hex.Encode yields a []byte representing the ASCII string "0000000000000101". Which is what I want. Which is 257 in hex. Yes having the leading zeroes is different, strconv doesn't add those. But that's completely ignorable from my viewpoint. It's pretty easy to prepare the unmarshaler for no leading zeroes.
Stackless Python is a Python implementation with the same threading model as Go. That may be of interest.
Hey, this is neat! I've been working on a similar problem but approaching it from a fairly different angle. Skimming through the code, looks like we have a lot of overlap too (please steal any good parts that I have!). I also needed P2P RPC with secp256k1 signing (ostensibly what I think you're solving here). My solution ended up as [a custom JSONRPC2 server that supported bidirectional RPC (something that nothing else seems to support? even gRPC isn't bidirectional for RPC, frustrating!) and a signing convention that fits within JSONRPC2. - jsonrpc2 with bidirectional rpc: https://github.com/vipnode/vipnode/tree/master/jsonrpc2 (warning: very unstable code/api at the moment!) - request signing using secp256k1 EC: https://github.com/vipnode/vipnode/blob/master/request/request.go (should be stable) It gets the job done for now but I'm not super happy with it. I'm excited to see more p2p-focused RPC protocols! My idea for improvement in the future: Separate the signing protocol from the RPC protocol into a composable layer. I'm imagining a "message envelope" format that just focuses on safe p2p federation. My working name for it is "jsonp2p", which would complement jsonrpc.
Yes also came to mind that I could use the `multiprocessing` module. I should talk about this to my boss since I know Python much better and could be more productive. Wonder if these Python implementations are reliable as much as go though.
When I was working on my proposal I tried writing code I would want to write. I started with only interfaces and the lack of comparability and convertibility. It wasn't entirely unworkable but it wasn't pleasant and it felt very restricted and unnatural. Not being able to create a map made things awkward, and, if nothing else, I wanted a `type Set map[T]struct{}` for some parameter T. How do you take a `map[K]V` as a parameter if you can't guarantee `K` is legal? You have to infer comparability of `K` and that was a no-go for me. I tried many versions to get operators to work and ultimately realized that `==` was the only necessary one (or at least the *minimally* necessary one) and the only one that really fit with interfaces as they were since they had `==` anyway—the only operational difference between a regular interface and a comparable interface is that with a comparable interface `==` never panics because you can't stick something like a `func()` in it. I considered it a design goal to change interfaces as little as possible (but if interfaces did happen to unrelatedly change later and get operators and fields or anything like that, instantly usable by the generics system). Convertibility came up in a lot of places, too. It seemed natural to write something like func SliceConvert(src []T) []S { dst := make([]S, len(src)) for i := range dst { dst[i] = S(src[i]) } return dst } for some parameters `S` and `T` with neither type restricted individually and the only restriction that you could convert a `T` to an `S`. That requirement belongs to neither parameter as it is a relation between the two parameters. It also doesn't belong to the interfaces: it belongs to the types satisfying them. The constraint for that func would be "any type T and any type S such that you can convert a `T` to an `S`". That's kind of a philosophical point. It *would* work if you chose one of those types and had it specify that it must be converted to the other but what does that mean for the interface used as a regular interface? I think it would mean something different than when that interface was used as a generic constraint in some subtle ways, but I haven't sat down with pen and paper and worked it out. Taking a `func(T) S` there would work and be more general since it could be used as a combined map-and-convert. And that's a somewhat synthetic example because it's job is to convert so, yeah, it wants to specify convertibility. But it just kept coming up when I sketched example code or when I looked at old code I'd want to generic-ify. Maybe it would be better to drop it but it was the only thing like that that kept popping up. Ultimately, I think writing generic code should be as close to writing non-generic code as is possible and conversion is something that comes up in regular code. 
I would really like to see this internal unsafe pointer technique used for iterating ranges on slices without having to convert (i.e. no allocation) from \[\]MyType to \[\]MyInterface. That alone would satisfy more than half of the cases where I reach for generics and find them unavailable. type Ider interface { Id() int } type MyType struct { id int } func (myType *MyType) Id() int { return myType.id } func showIds(anyIdList []Ider) { for _, v := range anyIdList { fmt.Println(v) } } func main() { var MyList []*MyType MyList = append(MyList, &amp;MyType{id: 1}) MyList = append(MyList, &amp;MyType{id: 2}) MyList = append(MyList, &amp;MyType{id: 3}) showIds(MyList) // GLORIOUS BE THE LIGHT } &amp;#x200B;
I don’t think this answers the question, though. Buffer.bootstrap can be checked inside Buffer.grow and allocated on-demand. Unless that breaks the performance, I don’t see why it couldn’t be allocated lazily. 
See /u/elagergren's comment. I'm aware of that part, I'm not clear on why this can't be done lazily.
Can you elaborate? I don't see how this would enable a side-channel attack (any more than *any* optimization)
The title is a bit inaccurate: the test is about concurrent caching using maps (or channels). With regard to the results: have you tried to remove the defer statements and lock at the end of the functions ? defer is the idiomatic way of writing the code but you may be hitting a performance issue with defer. I am curious to see if that would impact the results. 
The goal was to test the concurrency primitives - thus the very simple but useful use case. I will make the suggested changes an re-run the tests.
I use `context.Context` mainly to cancel ongoing goroutines in order to prevent them to leak or to keep running even if their result won't be used anymore, but only because I still couldn't find/study another way of doing so (please if anyone has any suggestions, a little help here would be appreciated).
Pretty sure OP is referring to the Meltdown and Spectre debacle and Intel's "special" role in that. E.g. speculative execution was once thought as a good way to optimize CPUs, well, not anymore. 
Oh uh, what's your username on there?
I removed the defer, and it made an appreciable difference in those tests. Thank you.
The down-votes without comment are pretty amazing - says a lot about some members of the Go community. If you think there is a problem with the tests/methods, please share. If you are down-voting because you don't like the message, that is not doing anything to advance the platform forward, and probably dissuades people who might be capable of making improvement to stick around... &amp;#x200B;
I upvoted even though I personally didn't understand the tests, just to get the post some more visibility. Anything that can lead to language improvements is a good thing imo.
&gt; I don't see why. In Rust you have to explicitly write it as a generic call to get static dispatch. trait Foo { fn bar(&amp;self); } impl Foo for int { fn bar(&amp;self) {} } impl Foo for String { fn bar(&amp;self) {} } In Rust you have to explicitly write it as a generic callt. fn main() { call_bar(1i); call_bar("foo".to_string()); } &amp;#x200B;
&gt; How do you take a map[K]V as a parameter if you can't guarantee K is legal? You have to infer comparability of K and that was a no-go for me. Alternative question: How do you take a `map[K]V` if `K` *is* legal? Like, what are you worried about? That someone `make`s a map with an illegal key-type and passes it to you? ;) But as I said, I am slightly annoyed. Personally, I don't consider it an insurmountable problem. We could add a pseudo-interface, or we could infer that particular constraint from the function-signature or type-declaration (I don't understand why that would be a no-go). You could also take a `func() Map(K,V)` as a parameter (where `Map` is an interface with the methods you're interested in). I think there are ways around this problem, if need be. Each with their own set of advantages and disadvantages. &gt; It seemed natural to write something like `func SliceConvert` IMO it would be fine to have a tiny bit of boilerplate for this use-case, and write `Map(s, func(v S) R { return R(s) })`. You could (theoretically, but blegh) make `T` in an expression context equivalent to `func(v X) T { return T(v)` on a language level, if `X` is convertible (similar in spirit to method-expressions) and then use `Map(s, T)`. But no, seriously, a bit of boilerplate is fine, IMO \^\^ That's kind of the spirit of my post. Make the most common stuff simple and make the rest possible. It's not super nice that there are still some cases requiring additional boilerplate, but you can't have everything and at least it buys you conceptual simplicity. &gt; It also doesn't belong to the interfaces It can be added to the interfaces though (if you choose so) via `interface Convertible { T() T }`. Or, as I said, have a `convertible(T)` pseudo-interface and specify func SliceConvert(type S convertible(T), T) (s []S) []T { var out []T for _, v := range s { out = append(out, T(v)) } return out } --- I don't know. It just doesn't seem a show-stopper to me. It might be, who knows. IMO it seems clear enough that there are *some* solutions to table it until after one has committed to investigate the idea further. Keep in mind, that so far this is just some rando's rambling on the internet, I have heard exactly zero opinions by anyone on the Go team about this so far :)
Forget about it I requested back then to be anonymous. Lets keep it that way. Sorry for the post on reddit. If I can help Go beginners here I will do nothing more.
Very well written blog, with very good analysis of the existing design. However, I prefer the existing design for a few reasons. 1. I really like that Go's basic types don't have any builtin methods and that derived types don't inherit methods, so changing that sounds like a lot of extra complexity with little extra benefit. 2. Without the addition of basic type methods, we lose the ability to specify basic operations like equality, addition, etc. 3. While I agree that the existing design prioritises grammar over vocabulary (as you put it), vocabulary is generally an easy problem to solve, as we can have things like reference sheets for common vocab (do `var _ int = len(t); var _ int = t[0]` to specify slice/array/map/string but not channel), while having an expressive grammar gives us a lot of precision with which to express the requirements we need. 4. Although contracts specify behaviour more than types (doing `var _ int = len(t)` lets you use slices, arrays, maps, strings, and channels), I think that's actually the right behaviour. If the requirements you give allow more types than you were expecting, that's actually fine if they all behave correctly. If they don't behave correctly, that's just a sign that you might want to specify more requirements. All in all, I agree with many of your frustrations with contracts but I still feel that it actually gives you more options and more control over what happens, while remaining orthogonal with Go's existing features. I'm sure it'll take a while for people to get use to expressing contracts but with some shared knowledge, cheat sheets, and good examples, I think the ecosystem will be better off overall.
&gt; while having an expressive grammar gives us a lot of precision with which to express the requirements we need. I would only agree with that. I don't anymore. For that to work, there would have to be an easy to understand 1-to-1 mapping between constraints and syntactical constructs, which simply isn't there. &gt; If the requirements you give allow more types than you were expecting, that's actually fine if they all behave correctly. If they don't behave correctly, that's just a sign that you might want to specify more requirements. But that's just the thing. That's not type-safe constraints. If the type-system allows an operation that then suddenly breaks, because the type turned out to be unsuitable, the type-system wasn't safe. I think it's fine if the type-system is not always safe (which is why I'm fine with nil-pointers, for example), but contracts make it unnecessarily hard to write type-safe code. And given that the whole idea behind this topic is to make it possible to write type-safe generic code, I consider that a huge downside. &gt; while remaining orthogonal with Go's existing features. Contracts are by no measure orthogonal to interfaces.
I'll have to try this again, when I did it earlier I got two vastly different results, but maybe I was just doing something wrong.
For background, here is the link to the original Github Issue: https://github.com/golang/go/issues/7921 
make a channel and close it when you want your goroutines to exit. select { case &lt;-quit: return default: } Basically that is all the context does under the hood
I don't remember the user name just my email if this helps
Thanks for your input, I have fixed the stutter. 
I have been trying to make sense of context.Context trying to use a custom DNS resolver. Is there a good tutorial on the usage of context.Context especially when building client/server architectures?
Thanks, I appreciate the overview. I'm not really suggesting typeclasses as implemented in Haskell, but some approximation of typeclasses that (1) lets them be defined for primitives, and (2) still works within Go's worldview of controlled memory layout, predictable breakage and so on. As a model, Rust's traits are quite similar to typeclasses, but retain control over memory layout, and I don't think they are tied to Rust's lifetime system. To rephrase my original question: Rather than these "pseudo-interfaces", which imply that they are built in and special cases, can one come up with a *generalized* typeclass construct that fits Go and solves this challenge? 
Are you using twemproxy infront of elastic cache or is it able to handle the 65k connections without dropping any of them?
I have never used context for termination, and I don't see a valid use case for it. If it's http, it should be fast. If it's web sockets, check the reader and writer for errors. For timeouts, set your tcp stack to be more reasonable and use application level liveness checks. 
Sorry, I was not clear enough about the way I use context. I do use the cancellation but I also like to allow other people to plug their own context to short-circuit whatever is going on in my code (when there are goroutines involved) if they want, which may be through a deadline...
&gt; How do you take a `map[K]V` if `K` is illegal? Like, what are you worried about? That someone makes a map with an illegal key-type and passes it to you? ;) Fair point! It's less clear what happen if `K` is a parameter on a type and one of its methods takes the map, though. Can you use the other methods but not that one? Then it satisfies fewer interfaces than if it were instantiated with a comparable type so you have to infer the comparability. &gt; we could infer that particular constraint from the function-signature or type-declaration (I don't understand why that would be a no-go). Say you call `F` that uses a `G` which calls `H` that constructs a map from the type argument. You can infer the constraint but you're going to get an annoying long error message. Not the end of the world, but if the constraint is explicit you can just look at the signature and say "oh, I can't use a `func()` here" and plan accordingly instead of waiting for the compiler to figure out that you can't use it. &gt; IMO it would be fine to have a tiny bit of boilerplate for this use-case, and write `Map(s, func(v S) R { return R(s) })`. Yeah, I may have a little bit of tunnel-vision on this one. I think if there are convertibility constraints they should be separate but maybe it would be okay if they weren't or just didn't exist at all. Something for me to ponder. 
[removed]
[removed]
[removed]
This is kind of what I was getting at. I have certainly be part of building slower/longer-running endpoints, but most of them usually are ultimately refactored and/or cached. HTTP requests need to be light/fast anyway.
Aside from the interface size, IMHO your naming has a lot of redundant `User` in it. It is *already* a `UserService`; so that information is already there. It's the same as having a `GetUser()` function inside a `user` package. I would use just `Get` instead of `GetUser`: type UserService interface { Get(id int) (*User, error) Create(email string) (*User, error) Update(email string) (*User, error) Destroy(id int) error ByEmail(email string) (*User, error) List(ids []int) ([]*User, error) // ... many more methods }
Cool, but this can also extremely easily be done with a bunch of Promises and a Promise.all call in Node. This will concurrently do as many network requests as you want and wait for them all to resolve. So Go is definitely not a must here. Not dissing the write up, I love Go and also Node and use Lambda quite a lot. 
If you do any of the following, thread a context to it: * Run os/exec * Network operation (database, key-value, REST client or server) * A (potentially) long analysis operation (interpreter, ETL) This isn't about handling large load. This is about ensuring your service or process is responsive to a request to restart to stop. context is not a contamination.
the language wasn't your problem here. occupying an entire lambda function waiting for a single synchronous network call to return was the problem. although I do agree dealing with it is simpler in Go
&gt;But that's just the thing. That's not type-safe constraints. If the type-system allows an operation that then suddenly breaks, because the value turned out to be unsuitable, the type-system wasn't safe. I don't understand what you mean here. Surely if the compiler ensures that anything done in a generic function can be done to any type, or is an operation specified in the contract, then the type must be guaranteed to be suitable. &gt;contracts make it unnecessarily hard to write type-safe code I may well be missing something but it feels fairly simple to me; you decide which operations you need to be able to do with your types and then give examples of those operations in the contract. To me, this drives the focus onto _behaviours_, rather than _types_. Rather than thinking really hard about which types you accept/return, you think about what you need to be able to _do_ with your inputs/outputs. This feels like the right kind of incentive to me and the king of thing that differentiates Go from many other languages. Hopefully the compiler will help a lot here and be very descriptive in its error messages if a particular input/output isn't suitable for the contract given ("the contract says you must be able to do X but type Foo passed into the function on file.go:line can't do X"). &gt;Contracts are by no measure orthogonal to interfaces. I would disagree with this very strongly; the introduction of contracts doesn't change how interfaces work and the presence of interfaces doesn't change how contracts work.
I have two thoughts: 1. This, like all other posts saying "let's use interfaces not contracts" doesn't actually _mean_ interfaces. Interfaces can only talk about methods. They mean some new concept that's like interfaces, might be called interfaces, but would make interfaces themselves more complicated. I like the idea of having a separate name for the parametric type limiting thing -- let's call those contracts, and *then* debate about what the contracts should look like. 2. This seems to completely ignore that contracts are about multiple types and their relationships, not just about a single type. Now, if you rewrote this as "let's add a bunch of predefined contracts for things like equality, and use those instead of fake-code like `a == a`", that'd be a worthy direction. Somebody would need to think pretty hard about *what* predefined contracts would be needed, to express (many of) the things the by-syntax-example contracts in the go2draft can do.
There's a bit of sleight of hand going on there, though. You aren't constraining the type parameters at all. All the operations involving them are part of the graph type, which is an interface value instead of a type parameter. This only works because you have exactly one Graph value as an input to the function. If you needed a slice of graphs of the same kind, or if you needed to perform operations on the nodes which were orthogonal to the graph type itself, you'd hit a wall. But yes, a model where you use interfaces (or pseudo-interfaces) as constraints can work. Several languages that do this have adopted where clauses to organize the constraints for a particular function: func F(type T, U)(t T, uU) where T SomeInterface(U), U OtherInterface { ... } One way to think about the role of contracts is to create a name for the combination of constraints used by a function. So rather than listing them out in the function signature, you put them in their own declaration (I'm changing how contract bodies work for illustrative purposes): contract C(T, U) { T SomeInterface(U) U OtherInterface } func F(type T, U C)(t T, u U) { } This serves to clean up the function signature somewhat, but it also serves a secondary purpose in that, where a contract represents a common concept involving multiple types, you can reuse that concept as [part of] the contract on multiple functions.
Welcome! No worries about your english, it's better than my Spanish or German or Russian or anything except English :) Both Go and Python have "batteries included". I'd actually say that Go's batteries are a lot more applicable to programming in 2018 than Python's.... but that's not really a knock against python, you can do anything in python. I know pythonistas that love Go and rarely go back to Python. I know Pythonistas that wrote Go for 2-3 years and then went back to python and don't miss Go at all. It's really personal taste. I think that either one would be a good language for you to learn. They're both different enough from Java to give you some different points of view. Python is interesting because it is dynamically typed, and super flexible. Go is interesting because it doesn't have exceptions or inheritance, so how you approach problems will be different. &amp;#x200B;
&gt; I don't understand what you mean here. Surely if the compiler ensures that anything done in a generic function can be done to any type, or is an operation specified in the contract, then the type must be guaranteed to be suitable. But the premise was that it didn't because your constraints didn't match your problem. I responded to "maybe you just need more constraints" and that's what that says: Maybe if your code compiles, but then breaks, your constraints didn't match your code. Think about it this way: You can write a generic `Max(a, b interface{}) interface{}` function. But it's not type-safe, because `Max(42, "babybel")` compiles, but then has to panic at runtime. That's because your types (`interface{}`) don't match your problem. That's why we are introducing type-parameters, so that we get more power to express the constraints of our problem, that the compiler can check. Now we can write `Max(type T ordered) (a, b T) T` and that type-checks just fine. Now, say I write this code: contract Rangeable(v T) { for key := range v { } } func PrintKeys(type T Rangeable) (v T) { for k := range v { fmt.Println(k) } } This would compile just fine. And it *looks* fine, on a superficial level. But now, this program func main() { var ch chan bool PrintKeys(ch) } compiles, but crashes because it has a deadlock. So it's not type-safe: The types we gave, don't give a full picture of the constraints we need (no turing complete language can ever be *fully* type-safe, FWIW, but there's a continuum and this is a datapoint making it less typesafe). Now, yes, we can fix our contract: contract Rangeable(v T) { var _ int = len(v) for key := range v { } } making it a bit more type-safe. It's still not really correct though… because if we pass in `string`, it doesn't really make sense to print indices for UTF-8 runes (it *might* make sense printing indices for slices though, as they are "keys" in a way). So, that's what I mean by "contracts make it hard to write type-safe(r) code". Type-safe code is code, where the mechanically checked types are more precise in modeling the domain of values our code works with. Contracts make it hard to tell from their syntax, what the actual domain of values it allows are, so they make it harder to be more precise about what that domain is, so they make it harder to write type-safe code. &gt; you decide which operations you need to be able to do with your types and then give examples of those operations in the contract. The problem is that "capacity of a channel" and "capacity of a slice" are *very* different semantic operations, but are syntactically indistinguishable. "range over a channel", "range over a map", "range over a slice" and "range over a string" are very different semantic operations, but are syntactically indistinguishable. Making a slice with some length or a channel with some capacity are semantically very different operations, but syntactically indistinguishable. This is why I'm saying you'd need a 1-to-1 translation between syntactical constructs and semantic operations, which Go doesn't provide. Yes, you *can* add more to the contract to be more precise, but the more I thought and talked about it, the more I got the message that there are super non-trivial questions about all of this. &gt; Rather than thinking really hard about which types you accept/return, you think about what you need to be able to do with your inputs/outputs. FTR, (pseudo-)interfaces do that *much* better. Because they actually *only* give you access to exactly those operations explicitly contained in them. It's not clear whether contracts will do that too - and from the "use `==` if you want to make a map" example, it seems that the intention is not to. &gt; I would disagree with this very strongly; the introduction of contracts doesn't change how interfaces work and the presence of interfaces doesn't change how contracts work. But that's not the definition of orthogonality. By that definition, I could introduce a new concept, called "MethodCollections", that are indistinguishable from interfaces and that would be orthogonal to interfaces. Orthogonality is about using the fewest numbers of features, to span the largest space of expressible concepts (roughly). i.e. (wow, this is going to be a fun "analogy") two planes intersecting. They could be identical, but that would mean they span only a very small space - namely a plane. You can't combine any two vectors contained in them to ever leave a single plane. On the other hand, they could also be intersecting in a line. In that case, they span a three-dimensional space. By adding a vector from one plane to a vector of the other plane, you can actually leave the single plane and reach more room. But you can do even better, because in four-dimensional space (told you this will be fun), they might even just intersect in a single point. They then span the full four-dimensional space and are "fully orthogonal", so to speak, because you get the maximum amount of covered space out of two planes. That's basically the analogy for the "orthogonal" term. You can think of interfaces and contracts as the two planes. But there are use-cases that are covered by both; e.g. contract Readable(v T) { var ( n int err error ) n, err = v.Read([]byte{}) } func ReadContract(type T Readable) (r T) { // … } type Reader interface { Read([]byte) (int, error) } func ReadInterface(r Reader) { // .... } These two do semantically the same thing (or at least *extremely similar* things). But that means, that the "planes" they span don't just intersect in a point - there is a non-zero intersection between the two. They are not fully orthogonal; with the same number of concepts, you could span a larger space, if you wouldn't have overlap. "Orthogonal" doesn't mean "unrelated" or "different" or "independent", when applied to features. It has a more specific meaning, about "can you do the same thing with either".
I don't think so, since the channels are unbuffered - there should be a one to one link between the request and response. I've changed the implementation slightly to reduce the channels to 2, and it has made a performance improvement (probably by removing the select call on the channels)
It is a hard package cause it's specifically used on concurrency. Which is hard enough. The examples are kinda miss leading as well. I tried to write an article on it but my examples were wrong because I didn't use channels. So it's kinda weird. https://vimeo.com/115309491 https://golang.org/pkg/context https://blog.golang.org/context
I've been a python programmer for over 12 years and I had first discovered Go when it was still in its weekly pre-1.0 release cycle. Today I promote Go at my studio as a safer and more performant alternative to python. The type safety and compile time checks save you from seeing silly mistakes cause crashes at runtime. In python, unless you have very high test coverage, it is easier to make a mistake in a branch of code that only runs later under certain conditions. Refactoring Go is so much easier with the ability to safely extract and rename code, and to let the compiler check you. And sharing a project between devs is a very positive experience since code continues to have the same style. Tooling is excellent. Concurrency is also easier to do in a way that yields better performance. I still love python, but I trust Go code more for long running services. For command line tools I also would rather have a compiled binary instead of a program that needs a virtual env to find its dependencies. 
&gt; If you needed a slice of graphs of the same kind, func (type T Graph(Edge, Node), Edge, Node) (graphs []T) {} &gt; or if you needed to perform operations on the nodes which were orthogonal to the graph type itself, func (type T Graph(Edge, Node), Node NeededInterface, Edge) (g T) {} or, potentially (harder to use, simpler to write) func (type T Graph(Edge, NeededInterface), Edge) (g T) {} (this requires the graph-implementation to actually return `NeededInterfaces` from its methods, so it would be harder to use/less generic. So I wouldn't advertise it, but it's entirely possible) &gt; you'd hit a wall. Yeah, but it's made out of paper :) &gt; One way to think about the role of contracts is to create a name for the combination of constraints used by a function. So rather than listing them out in the function signature, you put them in their own declaration (I'm changing how contract bodies work for illustrative purposes): You don't even have to change how interface-syntax works for that interface Concept(T, U) { SomeInterface(U) OtherInterface(T) } func F(type C Concept) (v C) { } func main() { u := makeSomeInterface(int)() t := makeOtherInterface(string)() c := struct{ SomeInterface(int); OtherInterface(string)}{u,t} F(c) } But, TBH, I would just… not use that. I don't think, personally, that there is much use for something like this. Just pass them individually, if they are unrelated, or put them into one interface, if they are coupled. FTR, the reason I'm so sure that all of this actually works, is that it's (apart from the restriction on parametric methods) exactly how these things are expressed with type-classes. e.g. the equivalent Haskell type-class would be - with a bit of squinting - something like (assuming multi-parameter type-classes): class Graph g e n where edges :: n -&gt; [e] nodes :: e -&gt; [n] shortestPath :: Graph g e n =&gt; g -&gt; [e] You might recognize what I'm doing. The class-definition is exactly the interface we have: `g` is the variable of the concrete type implementing `Graph` (implicit in an interface-declaration as the receiver). `e` and `n` are parameters for the edge/node-types. `Graph g e n =&gt;` names the type-parameters of `shortestPath`. The function takes a graph and returns a list of edges.¹ As I said in the article, these ideas aren't really *novel*. They are pretty battle-tested in other languages. This sort of modeling works quite well in practice. We can squabble about beauty, or syntax or Go-ish-nes. But both power and type-safety I'm pretty sure of. --- [1] there is a slight difference here, just as in the class, because in Go the receiver type is implicit in the interface, whereas in Haskell it's explicit. That's because Haskell allows you to define instances of type-classes for any type, so you actually need to specify what instance you want to use.
This is kind of the crux of the mater. If you are doing certain questionable tasks (1 &amp; 3), or have such scale (FANG) that every request stopped creates a mountain of cash saved (2), then `ctx` seems to be the most vetted approach.
Fixed it for you :) [https://play.golang.org/p/dodqGKnneGt](https://play.golang.org/p/dodqGKnneGt)
Thank you very much for such a thorough and considered response. I see now what you mean about contracts not necessarily being type-safe. Likewise with orthogonality; thanks for explaining that to me. I'm still really uncomfortable about builtin methods on basic types and methods on basic types being inherited by custom types. Hopefully we can improve the design further as a community.
&gt; Also, to call functions in this way, you have to tell it what type you’re passing, so like you’d call `Print` above by doing `Print(int)([]int{1,2,3})`. Why can’t we have type inference here? [We can and we have](https://go.googlesource.com/proposal/+/master/design/go2draft-contracts.md#function-argument-type-inference) :) You managed to pick exactly an example where we have type-inference.
LMFAO! Logical error on my part, looking at it I knew it should have been &amp;&amp; and not ||. I completely missed that. Thanks for that. It was driving me a bit crazy that it was yielding different results than what I thought and what is stated theoretically.
lol. We're reaching levels of soy that shouldn't be possible.
Here is another way to demonstrate the result over a large number of simulations: [https://play.golang.org/p/Egoqm6HlAke](https://play.golang.org/p/Egoqm6HlAke)
I'm not concerned with type safety. The empty interface kinda blows that concern out of the water as it is. I just want a way to iterate over a "list" of interfaces without having to create a new list from my concrete types each time.
&gt; Here’s my fix… since contracts are basically like interfaces, let’s actually use interfaces. And let’s make the contracty part last, since it’s least important: I… don't like it. It has all the same problems discussed [here, ad nauseam](https://www.reddit.com/r/golang/comments/9cjw98/maybe_adding_generics_to_go_is_about_syntax_after/) (sorry in advance). I'm also not quite sure if it's unambiguous for composite types, but can't put my finger quite on it, so ignore this :)
That doesn't simulate the 4 scenarios I aimed to simulate. 1 - The winning prize door is always 1. The player randomly selects a door. 1 non-winning door is taken away. Player changes selection. - Win rate is about 66% 2 - The winning prize door is always 1. The player randomly selects a door. 1 non-winning door is taken away. Player does not change selection. - Win rate is about 33% 3 - The winning prize door is random. The player randomly selects a door. 1 non-winning door is taken away. Player changes selection. - Win rate is about 66% 4 - The winning prize door is random. The player randomly selects a door. 1 non-winning door is taken away. Player does not change selection. - Win rate is about 33% However... I do find it odd that it's getting 66% win rates. Looking at it, I'm pretty sure what you are calculating is a `loss rate` for scenario #4.
The theoretical win rate for this problem is 2/3, so the code I linked should approach that value (which it does). Your comment is partially correct in that my result is related to your fourth scenario, but your interpretation is incorrect. You are correct that if the play does NOT change their door, they win 33% of the time. Conversely, if the DO change their door, they win 1 - 1/3 = 2/3 of the time. The variable is binary and the probability we are calculating is the probability of winning.
&gt; This isn't the same thing. You've introduced a third type and constrained it in relation to the other two, rather than constraining just the two types in relation to each other. You are moving the goal post. You have no trouble introducing a separate contract, but somehow you have a problem with introducing a separate interface. Yes, if you definitionally make contracts the only way to pass the bar you're setting, nothing but contracts can jump over it. I recommend focusing on what concepts can and can not be expressed and how that happens, instead of getting hung up on what things "are". The fact of the matter is, that you set up a bunch of things as impossible to express and I showed you that you can express them just fine, with exactly the same amount of type-safety as with contracts. &gt; This isn't slight, it's the whole problem I'm trying to highlight. A contract maps closer to a type class because it can constrain multiple types in relation to each other. So can interfaces (as shown). If you want to make a case, that my solutions are less type-safe than contracts, then show me an example where my solution type-checks but blows up and where the contract equivalent does not type-check. Note, that type-classes do in absolutely no way "constrain multiple types in relation to each other" - they define a set of methods that need to be implemented by an instance of that class. You still have a) a concrete type and b) attach methods to it (via an `instance` declaration). Type-classes are interfaces (they are actually closer to C++ or Java classes than to Go interfaces, because they can have both virtual and non-virtual methods, but I mean, that just puts them even further away from contracts…).
My initial thought was wrong, but my idea for testing this was right (my code just had a logical error). However what your simulating isn't: ``` Game selects winning prize door Player selects door Game removes a door Player selects a new door ``` What you are simulating is: ``` Game selects a winning door Player selects a door Game removes a door -- This is not in your code, but is assumed Player sticks with original selection ``` Therefore, you're simulating `lose rate`, not `win rate`.
This isn't about saving money (my clients run their code on dedicated HW). This is knowing how something stops in a predictable, reliable way.
Sure, I am not simulating your four scenarios. What I am simulating is the win rate for a player that *always* changes their door selection. However, your interpretation of my code is incorrect. * What we want to test: player always changes which door they want * Under this assumption, the only time the player loses is when they correctly guess the correct door * Thus, if the player door and the prize door are the same initially, the player loses. Otherwise, the player wins (captured by my if statement in `sim()`) My code counts the number of wins and divides by the total number of plays -- this yields an estimate of the probability of winning. If my code were as you describe, the result would approach 1/3, which is the theoretical win rate under this scenario. As I mentioned in my previous post, the theoretical win rate under switching doors is 2/3, which is what my code approaches.
When comparing python to Go, these are the biggest tradeoffs/differences in my opinion. * Readability - slight edge to python (assuming the python code clearly and correctly documents all function signatures) * Performance - Go (except in some rare cases when your hot paths are all C anyway) * Concurrency and Parallelism - Go by a mile (cough GIL cough) * Deployment - Go (single stand-alone binaries FTW, and no worrying about what python runtime will be used) * Backwards compatibility - Go (cough python3 cough) * Ecosystem - depends/debatable (Python had this hands down before the 2/3 split, but fractured ecosystems suck hard. That aside, each language has "sweet spots" in it's ecosystem where it beats out the other. NumPy is a good example for python while containers are a good example for Go) * Functional programming paradigms - Python (Go is unabashedly imperative) * Highly generic code - python (for now) * Error handling - preference/debatable * Type system - preference/debatable Personally, I find go's type system to fall within the "Goldilocks zone" but others think it is too little or too much. Full disclosure, I'm generally pro static typing. I've wasted way too much time in both JavaScript and python on bugs that a compiler should be catching for me. Summary: So if you want a fast, statically typed language, that compiles to a easy to deploy stand-alone binary and is almost as readable as python, Go is a good fit. If your problem is heavily concurrent and especially if it can be parallelized, then Go is a really good fit. If your problem is in a weaker part of the Go ecosystem (like a gui desktop program) or is much easier to express using generics or functional paradigms, then Python may be a better choice.
\&gt; Somebody would need to think pretty hard about *what* predefined contracts would be needed &amp;#x200B; Yeah, for example in C# you cannot constrain a type to be "something that the regular + operator can operate on", in F# you can. This means if you want to do something like collection.sum() with good perf in C# you have to write it \~11 times one for each primitive type that can be summed. In F# you can write it once. &amp;#x200B; I think back to the C# library I wrote that did a lot of this kind of thing with SIMD acceleration and what a pain it was when people debate about generics in a language...and C# had generics! Just not ones I could use. &amp;#x200B; &amp;#x200B;
You're calculating how often a player that doesn't change his mind loses.
&gt; I'm not concerned with type safety. The language certainly is. Allowing to do what you do as is, would allow you to write to arbitrary memory accidentally. &gt; As an example, say the magic converts each concrete type to an MyInterface{} as it steps each element behind the scenes. That's probably no less type safe that what's there now. On the contrary, that would be perfectly type-safe. Because you would either get a `[]MyInterface{}` that you could modify at will (as it shares no memory with the original slice, that has a different layout), but that then gets discarded (unless you explicitly type-assert/unpack and assign to the original slice). Or you would provide a read-only interface to do that - say (in pseudo-syntax): func ForEach(s []T, f func(MyInterface{})) { // mumblemumbleunsafe } Because `f` gets passed a `MyInterface{}`, but can't actually return anything or write anything back to `s`, this would be fine. It's a read-only operation and read-only data structures can be made covariant in a perfectly type-safe manner (as I describe in the article). The problem is, that `[]MyInterface{}` is a read-write data-structure. *That's* what makes it not type-safe, to share it's memory with a `[]*MyType`. The read-part makes `[]` covariant, the write-part makes it contravariant, but it can't be both. Note, that you can write the thing you want just fine, using `reflect` (that's exactly the "unsafe magic" you are referring to). But it's not type-safe.
You'll have to explain to me how 'encoded in the architecture' solves this problem... I don't think it does. Conversely, it is trivial to handle the exceptions that a method/operation is prepared to handle, and if not, throw the exception higher. With Go, this requires a switch on EVERY method call to do this, and it is really ugly when you can handle/expect more than one. The only workable solution is code like: func Method() { err := someMethod() if err!= nil { goto handleError } err = someOtherMethod() if err!=nil { goto handleError } return nil handleError: do error type checking, and handling... unlike to be able to handle/recover from a disk crash here or even know what to do if the balance is out of date, possibly retry, or report another error requiring a goto up top, or wrapping this in another method... possibly still return err } and the caller of this Method has no clue what errors might be return from Method() because the syntax doesn't allow it - nor does godoc really support it
That is actually a very nice way to explain the Monty Hall paradox. Also a good example of a rare case where comments in the code are actually necessary :)
1. Reader A requests key X, and begins waiting on the result. 2. Reader B requests key Y, and begins waiting on the result. 3. Key lookup X finishes and sends out value "x". 4. Both A &amp; B are reading from the channel, and Reader B has 50/50 odds to get the "x". 5. Key lookup Y finishes and sends out value "y". 6. Reader A gets the "y".
Oh, yeah, I meant to delete that bit. That was written a couple days ago before I saw that they supported type inference in the official design.
&gt; doesn't actually mean interfaces It means interfaces 2.0. yes, they're different than 1.0 interfaces, but *crucially* are backwards compatible with existing interfaces. &gt; like the idea of having a separate name for the parametric type limiting thing -- let's call those contracts But the problem with that is that then you can't combine them with existing interfaces. I want to be able to compose these new capability definitions with existing interfaces, so I can say that a fmt.Stringer is also a Numeric. &gt; if you rewrote this as "let's add a bunch of predefined contracts for things like equality, and use those instead of fake-code like a == a", that'd be a worthy direction ...I thought that's what I did. I just don't call them contracts, and I want them to be composable with interfaces. Maybe I just wasn't clear enough (totally possible.. this was written in 3 chunks across 3 days, which may have been a mistake). 
I think part of it was a failure to properly express myself in a way that was understandable to people outside my own head :) Mostly I want three things: * Make contracts composable with interfaces * Create built-in contract/interfaces that define things that users can (like x == x) * Use notation in function signatures (and types) to show which interfaces are contractually obligated to be the same type, and therefore aren't boxed. 
On a Raspberry Pi I'd choose Go but use GCCGO for best performance on ARM.
As I understand it only with generic functions and types will the compiler choose whether to use static or dynamic dispatch. Interfaces will be dynamicly dispatched as always.
&gt; Use notation in function signatures (and types) to show which interfaces are contractually obligated to be the same type, and therefore aren't boxed. I think the post would benefit from some examples :) AFAICT you are only ever using one generic argument. Maybe something like `Max` would be instructive. And I'm also of the opinion that showing the `Graph` example is important - multiple interdependent types are, for better or for worse, part of the problem overview. So you should either show/explain how they work or make explicit that/why you don't think it needs to be solved. IMHO, IANAL, ETC, PP. My litmus test for evaluating generics ideas is roughly: 1. Show how to do `Max` (covers consistency checking and "operators" (or interfaces)) 2. Show how to do `Graph` (covers multiple interdependent types) 3. Show how to do generic types (which I didn't do in my post, TBF, because there isn't really any difference to the design doc). I think these three cases give a quick sanity-check, because they cover the main features that generics are there to provide :) It's of course also fine to make a case against covering either. These will be the first questions I'll ask anyway, though, so might as well answer them upfront :)
That's because operations on the `Buffer` object cause one of its members to point into the `bootstrap` member—a kind of cyclic reference. This confuses the escape analysis so much, it forces a heap allocation.
[removed]
How you massively reduced your AWS Lambda bill with _concurrency_.
I'm not being unfair to you in any of the ways you've accused me of being, either in "moving goalposts" or "bucketing" you with anyone. I'm saying you're using trickery to work around an unnecessarily limited design, and that a proper design shouldn't need this. 
[removed]
Good point. I can do max right now: func Max(a, b Numeric:T) Numeric:T { Numeric being a new style built-in interface declaring that it can take a numeric types, and thus support comparison via &lt;. :T names the type and shows that a, b, and the return value must have the same type and will not be boxed. I'll see if this works for graph after I put the kids to bed :)
Maybe I'll amend my test with 4. Show `func Map(type A, B) ([]A, func(A) B) []B`. :)
func Map(a []interface{}:X, func(a interface {}:X) interface{}:Y) []interface {}:Y { 
I am utterly unconvinced there can ever be methods on builtins *and* a road leading there from Go1.
&gt; This is knowing how something stops in a predictable, reliable way. That sounds good, but what are you actually talking about? Request tracing/life cycle with context values?
Do exactly what the comment said, just allow the user to pass a channel in, wait for it to close, and then close your interal channel. Essentially, you'll end up with context.WithCancel(userCtx) - which is what you should be using.
&gt; Now, if you rewrote this as "let's add a bunch of predefined contracts for things like equality, and use those instead of fake-code like a == a", that'd be a worthy direction. Somebody would need to think pretty hard about what predefined contracts would be needed, to express (many of) the things the by-syntax-example contracts in the go2draft can do. Swift uses this exact approach and has a rich set of interfaces defined in the standard library. OTOH Swift supports operator overloading so the interfaces don’t need to do anything “magic”.
One big difference is that it's far more editable. For example, try swapping the `Filter()` and `Map()` calls, and maybe insert a `Skip()` call in the middle. It's rather annoying to do with top-level function calls, but with methods it's pretty easy. You can easily see where each call starts and ends, and each is a self-contained section that can be easily moved around or have things placed around it.
I was thinking that the operators would only satisfy the interfaces if the interfaces were used in a generic context, and that manually implemented methods matching the interfaces would take precedence. Reflection would be a non-issue then as well, because any interaction reflection had with them would have to be through whatever support for generics gets added to the `reflect` package.
[removed]
&gt; But in order to call the methods, you need to have a value of that this "type-class instance" type. It's a distinction without a difference. type G(Edge, Node) struct{} func (G) Edges(n Node) []Edge { // Exactly the same as in the contracts code } func (G) Nodes(e Edge) []Node { // Exactly the same as in the contracts code } &gt; You don't handle type-class instances as values in Haskell, or even as types, you just say an instance exists for the specified parameters. Of course you do. For example: main :: IO () `main` is a value, that returns an IO-Monad value wrapping a `()`. Note that that is 1-to-1 equivalent to above Graph example using `struct{}` (which is Go's `()`). F :: Functor f =&gt; f a -&gt; (a -&gt; b) -&gt; f b `F` takes a value of some concrete, parametric type `f` implementing `Functor` with parameter `a` and a function `a -&gt; b` and returns a value of type `f` with parameter `b`. You call it like G :: [Int] -&gt; [String] G x = F x show In this example, `f` is `[]`, `a` is `Int` and `b` is `String`. You have to actually call the function with a *value* of a type having an instance of `Functor` (or, you know, a value of a type implementing the interface…). There's no difference between interfaces and type-classes, except a) the way methods are attached, b) that types in Go can't have parameters (yet) and c) that methods in Go can't be parametric (probably ever). &gt; Imagine explaining to a newcomer "yeah, I had to declare a variable of this parameter type just so I could call the interface methods which really have nothing to do with this value". I disagree strongly with this characterization. One reason I find the Graph example for contracts so fundamentally weird is that `func (type Edge, Node) Nodes(Edge) []Node` and `func (type Edge, Node) Edges(Node) []Edge` have to *know about each other* (to return the correct concrete types) and have to have access to common state (so that they actually know what nodes are attached to what edge and vice versa), but that they are not described as having any connection at all. `ShortestPath` should calculate the path between two nodes in *a specific graph*, not on "some function to query what edges a node have and some function to query what nodes an edge has". It's not a clean model. In practice, the Graph example in particular (but I'd predict the vast majority of all generic code with multiple parameters) will have to be implemented either as a) some closures over common state, or b) methods on a type holding the state and by passing method expressions to `ShortestPath`. i.e. in practice, the contracts-code will be used something like type AdjacencyList [][]int func (g AdjacencyList) Edges(from int) [][2]int { // See my post } func (g AdjacencyList) Nodes(e int) []int { // See my Post } func main() { g := AdjacencyList{…} path := ShortestPath(g.Edges, g.Nodes) fmt.Println(path) } If you *actually* at some point have a contract implementation where you don't have state, just implement it on `struct{}`, as I showed above (which is exactly what Haskell does with instances that doesn't need to hold any value. It's just not particularly useful, except in `IO` code). I agree that if you really have truly independent interfaces in one contract, that the interface-embedding-approach would seem like a kludge. I just can't think of any example where that would make sense - and you wouldn't just have two separate interface parameters. &gt; However, since we're still designing this feature, we should design it to support the desired use cases directly in a way that's consistent with the rest of the language rather than requiring a kludgey workaround. Again, I strongly disagree both that a) contracts are "consistent with the rest of the language" and b) that this is a kludgey workaround.
\&gt;&gt; The language certainly is. No doubt. That's why my musings will never be. :-( \&gt;&gt; On the contrary, that would be perfectly type-safe. We have a different definition of type safety. If I can crash an application at run time because of an the application of a wrong type I don't consider it to be particularly type safe. \&gt;&gt; The problem is, that \[\]MyInterface{} is a read-write data-structure. That's fine. As long as I can call the methods implemented on the concrete type them I'm good with that. \&gt;&gt; The problem is, that \[\]MyInterface{} is a read-write data-structure. That's what makes it not type-safe ... Again, that's okay with me. I get that's what the designers don't want but if I can crash with the empty interface then what's the difference (to me). \&gt;&gt; using reflect That means it can't be used. Reflect is too slow and too cumbersome. I've never once written it in end user application slated code outside of marshalling and unmarshalling code. Thanks for the insight. &amp;#x200B;
&gt; One big difference is that it's far more editable. I don't find either particularly editable though :) Honestly, I don't want code like you wrote to exist in either variant. I just have to accept the cost of that invariably happening, if we get generics for the cases where they are actually improving things ;)
Thanks, helpful :) I suggest adding it to the post.
Instead of strings you can make a custom type like an enum. Ints or strings would be fine for those, i.e. // ints type resourceType int const ( // values for it PhotoType resourceType = iota TextType VideoType OtherType ) // or strings if you wanted type resourceType string const ( PhotoType resourceType = "photo" ) // and... type Authorizer interface { CanGetResource(type resourceType, userId, resourceId uuid.UUID) }
Care to share your reasons? :)
Also, everything else aside, why is it the responsibility of the Node to construct the Edges between itself and the vertices in its neighborhood in a particular graph? That example is so strange.
Thanks, fixed
Are they of any use when not used as the constraint on a type parameter then? I mean, that would work, but it would be somewhat strange.
Yeah, it would be a bit strange. I haven't really sat down and worked through this as a concrete proposal; it's more just an idea. I'm not really sure if it makes more sense for them to work as just normal interfaces, too. I think it probably would be cleaner if they _don't_, though.
&gt; Of course you do. For example: &gt; main :: IO () `IO ()` is a datatype, not a typeclass instance. We say `Monad IO` meaning "there exists an instance of `Monad m` with the (higher kinded) argument `IO`". The instance itself is unnamed. What you're describing is as if `Monad` were defined class Monad i m where (&gt;&gt;=) :: forall a b. i -&gt; m a -&gt; (a -&gt; m b) -&gt; m b (&gt;&gt;) :: forall a b. i -&gt; m a -&gt; m b -&gt; m b return :: i -&gt; a -&gt; m a fail :: i -&gt; String -&gt; m a &gt;It's a distinction without a difference. The difference is that you need a dummy value of a dummy type in order to access the operations defined by the typeclass. Needing dummy values is usually a big flashing neon sign saying "this is a hack!". &gt; One reason I find the Graph example for contracts so fundamentally weird is that `func (type Edge, Node) Nodes(Edge) []Node` and `func (type Edge, Node) Edges(Node) []Edge` have to *know about each other* (to return the correct concrete types) and have to have access to common state (so that they actually know what nodes are attached to what edge and vice versa) Graph in particular does suit itself to having a `Graph` typeclass. In fact, there should be a functional dependency `Graph g n e | g -&gt; n e`, or in terms of associated types: type Graph interface { type Node /* implements */ interface { ... } type Edge /* implements */ interface { ... } .... } Then you'd only need to take one type parameter: func ShortestPath(type G Graph)(g G, from, to G.Node) []G.Edge { ... } 
Not sure, best to post this on the golang-nuts or golang-dev mailing list or open a GitHub issue.
&gt;It means interfaces 2.0. yes, they're different than 1.0 interfaces, but *crucially* are backwards compatible with existing interfaces. ...sort of. If you're familiar with Rust, interfaces 1.0 are like object types, essentially meaning you can pass around an individual value whose type is determined at runtime that supports method calls through dynamic dispatch, with the static type of this value being an object type, or interface type. In Rust, object types are specified by traits, and traits that can be used for object types are called "object safe". However, there is another set of traits which *aren't* object safe and can only be used as generic constraints and not in an object type. Interfaces 1.0 includes only object safe interfaces. Interfaces 2.0 allows you to specify operations in interfaces that cannot be meaningfully applied to a single value of unknown type through dynamic dispatch, and so would result in the creation of interfaces that aren't "object safe" and thus can only be meaningfully used as generic constraints. If you see interfaces as object types, then the interfaces introduced under interfaces 2.0 *aren't* interfaces.
It’s all about Single Responsibility Principle, interface segregation, and composition. Don’t build big things. Build small things that work together to do big things. Why would you need one thing that does all those things? And even if you did, a simpler interface might be to simply call Serve on a big things that contains those other things.
&gt; `IO ()` is a datatype, not a typeclass instance. We say `Monad IO` meaning "there exists an instance of Monad m with the (higher kinded) argument `IO`". Okay. Any language is free to use whatever nomenclature they'd like to use. But that doesn't change anything about there not being an actual difference in power, expressiveness or implementation between what you said and saying "`IO` is a defined type implementing the `Monad` interface`, which is Go nomenclature for exactly the same thing. &gt; What you're describing is as if Monad were defined No, it's not. That's what you apparently want me to say, but it's not what I'm actually saying. I'm saying that if we look past nomenclature, the actual definition of the Monad typeclass is equivalent to having an interface and that saying "there is an instance of `Monad m` with the argument `IO`" is equivalent to saying "`IO` implements the `Monad` interface" - modulo nomenclature. There *are* some caveats, but as far as this discussion is concerned, they don't matter. &gt; Needing dummy values is usually a big flashing neon sign saying "this is a hack!". You mean like `IO ()` needs a dummy value of a dummy type? --- For realz, though, I don't think this is leading anywhere. We are obviously getting lost in irrelevant semantics here. Again, what this (or any) design should be measured against is the [Problem overview](https://go.googlesource.com/proposal/+/master/design/go2draft-generics-overview.md), i.e. a) what are the kinds of code we want a generics design to enable to write, b) how would one model that in this design and c) do we find that acceptable. Clearly, you don't find it acceptable to model this using interfaces, which, I guess, is fine. I don't really understand *why*, given that the code looks mostly identical, safe for a different keyword here and there. But I am also pretty frustrated with trying to get an answer to that, so I'll just never know.
This is a very good summary. I’ll just add that I prefer to write command line tools in Go because they can be packaged up as a binary instead of requiring a virtualenv or some complicated setup. 
It took dialing this problem up to 100 (literally) for me to intuitively grok it back in college. Think of the more general problem, you have N doors, you pick one of them, we’ll call you choice door A. The host open (N-2) doors with the guarantee that those opened doors will not include A or the door with the prize. You’re then given a choice between A and the other remaining closed door, we’ll call it B. With the larger scale, I found it much more intuitive that “of course there’s a 99%” probability that the prize is behind a door other than A.” Following on from that, it also becomes much clearer that the probability of A doesn’t suddenly shoot up to 50% (from a measly 1%) just because some of the doors were opened. Try coding up that generic solution and see if it helps you intuitively understand the problem. 
For this example: contract stringOrBytes(s S) { string(s) s[0] s[:] S([]byte{}) } I might try: contract stringOrBytes(s S) { var x interface{} = s _, ok := x.([]string) _, ok1 := x.([]byte) ok || ok1 } &amp;#x200B;
You can make single file binaries with Python, I’ve done it for some very simple GUI apps. They have to package up the interpreter but as far as the end user is concerned they can’t differentiate it from a Go binary at a superficial glance (obviously if you start picking it apart it’s very clear very quickly). Not saying it’s better/worse (it is worse, I’d much rather ship a Go binary), just that it’s possible. 
I agree with you on everything except readability. Between gofmt and the removal of all ambiguity of execution path in Go I’ve felt it has superior readability vs Python. I’ve encountered the odd Python case where somebody accidentally (de)indented a line at the end of a block and things blew up. Without looking at VCS history it’s not always obvious what the error was. Sure more tests or more comprehensive code review might have caught it, but so does removing all ambiguity through sufficiently rigorous syntax. Go does not have any ambiguity, hence why we can have nice tools like gofmt. 
&gt; than contaminate my codebase with `ctx context.Context` Like it or not, this is basically the reason `context.Context` exists. In some ways it is an alternative to globals and singletons that is much cleaner (easier to test and easier to understand). Context seems to have two purposes. The first is cancellation. Context gives you some simple tools to cancel an operation. Cancellation might be a result of the client giving up and going away, or it could be due to some other trigger (the process receives a signal, a deadline was reached, other goroutines have completed work or given up on work). Not every program has a need for cancellation, but many do. Deadlines (think timeouts) are especially important any time you make a network call. The second is for "scoped" values (https://golang.org/pkg/context/#WithValue and `Context.Value()`). Frameworks like `grpc` use it to support passing request scoped data that was received from a request to any outgoing requests. That API calls can be traced through the system. I've also found it to be very useful for cross cutting concerns like logging or recording metrics. Contextual data can be build up as the context is passed through different calls so that every log entry and metric that is recorded includes relevant data (think request ids). Most programs would benefit from using `Context` for this purpose. 
I have anecdotal evidence that channels on Mac have platform-specific perf issues. I did two implementations of [this library](https://github.com/clipperhouse/jargon) with and without channels — channels was quite a bit slower and pprof showed a lot of time in the mach kernel. A friend did similar on Linux and did not see the same kernel issues (though I don’t recall overall perf results). I’d love to see the OP’s test on Linux.
Thanks, I wasn't sure about that.
[removed]
I see your point, but Ruby being a dynamically-typed language is inherently generic.
If I’m performing an expensive API request and the TCP connection breaks, I want to be able to cancel and clean up part way through. Or if the user hits ctrl+c on a CLI app. Tracing is another benefit of Context, although when passing tracing IDs across server boundaries it’s usually converted into an HTTP header. 
Totally agree. Not to get too much in the semantics, but in my opinion, interfaces describe a shape., whereas contracts - or whatever term the community lands on - describe capabilities. I think there’s a fundamental difference between the two. Interfaces are implemented in types to make them compatible with an abstraction. Contracts are a test to determine whether two or more different types can be grouped and processed indifferently. Where the complexity of an interface stops at the number of methods it needs to be fulfilled, every statement in a contract can have more effects than that just the literal expression it represents. 
The design doc says that the inside of a contract is only type checked, it's not run. So the type assertions there don't actually check if it's a string or not. (Also, ok could be false)
I don't have a Linux box at the moment, and it wouldn't be fair under a VM. I did wonder if the performance issues were related to OSX - honestly I am more concerned about the general performance in these tests compared to Java. I've updated the readme based on some other input. 
&gt; Clearly, you don't find it acceptable to model this using interfaces, which, I guess, is fine. I actually think modelling generic constraints mostly with interfaces and pseudo-interfaces (traits? properties? capabilities?) is the right direction for Go. I'm interested to see if conversions can be fit in there somewhere as well. I do think a model where each type parameter can be independently constrained by an interface that potentially takes other type parameters as arguments is a workable solution. I also think that generic code written in this model can often get unwieldy because you often have to wire up all the relationships between type parameters manually in each function signature, including making sure each parameter meets the constraints needed by each other's constraints. Other languages have sought to mitigate this problem without really solving it by having where clauses. There's a lot I dislike about the contracts proposal—I disagree with using arbitrary example code to constrain types, particularly all the weird complications involved in using a method call expression as a constraint—but one thing I find intriguing is how it can factor more complex inter-parameter relationships into an easily reusable form and remove that complexity from individual function signatures. I think it's worthwhile pursuing a version of contracts which is tailored for this purpose while leaning on interfaces in order to specify the actual operations a given type supports. I don't think using an interface satisfied by a dummy type is a good substitute for this functionality. It adds another type parameter to the parameter list which isn't inferable unless you *also* pass an extra value into each function using it, and it requires you to lift operations that might more naturally reside with a different type into this dummy type just so that you can get away with having only one interface constraint. It also looks a lot like an explicit conformance declaration, which goes against Go's design goals. This pattern can be useful if there are operations which don't properly belong to any particular type but still potentially need multiple implementations (so that you can't just use free functions), I just don't think this is a *general* solution to the unwieldy generic function signature problem. My original objection was that the code in your post doesn't serve as an adequate rejection of the argument in favour of having something like contracts in addition to interfaces because you found clever ways to avoid having to constrain type parameters at all, concealing the very issue that contracts might help address. Generic code in general usually does need to constrain type parameters, and in potentially complex ways, so pointing to code that has been cleverly crafted not to need type parameter constraints doesn't really help.
This is a really important question, and I think other people here have done a great job of encouraging some of the shift in mindset that accompanies implicit interfaces. I like to encourage people to try defining the interface as a property or a variable instead of as a type to start. Looking at your updated example: // UserGetter represents a service to get a user. type UserGetter interface { GetUser(int) (*whatever.User, error) } // GetUserHandler handles GET /user/123 func GetUserHandler(userGetter UserGetter) func(w http.ResponseWriter, r *http.Request) Could also be written as: // GetUserHandler handles GET /user/123 func GetUserHandler(userGetter interface { GetUser(int) (*whatever.User, error) }) func(w http.ResponseWriter, r *http.Request) And, while that is not very pretty to look at, it sometimes helps with the concept. It's also a bit nicer when dependencies are expressed as properties on a struct instead of function arguments, especially as the number of dependencies grows.
https://ziutek.github.io/2018/03/30/go_on_very_small_hardware.html
Yes, the readme has been updated to cite some "known issues" with sync.Map. Thanks for the link, but that map only supports string keys. That being said, rather than just pointing things out, I'm working on a concurrent map that would hopefully address the deficiencies - the problem is, like sync.Map, the easiest way to an implementation is to leverage the built in map, but that has limitations - like no "copy a map", or "bulk insert". The real problem is that Go's unsynchronized map is slower than Java's concurrent map - I've updated the readme to address this, but I believe it stems from Java's ability to aggressively inline...
Btw, the jargon library is pretty cool.
&gt; If you use an editor like VS Code, you can often root out issues easily between packages if you only use the exported interfaces of a package. I primarily use VS Code and I don't understand how it would be any easier to debug an exported interface than an exported struct. Can you offer an example? 
The first case does sound interesting. 
\&gt; a simpler interface might be to simply call Serve on a big things that contains those other things. &amp;#x200B; I'd be interested in seeing an example of this if you know any good ones.
Excellent breakdown!
Good point, I should avoit the stutter.
LMAO! Okay, I see what you're getting at here. That makes sense... however, this still has the an inverse property of being a lose rate. Without the comments, I read this earlier: ``` // Returns 0 if the player loses, 1 if the player wins func sim() int { // Initial user selection (0, 1, or 2) userDoor := rand.Intn(3) // Door containing the prize (0, 1, or 2) prizeDoor := rand.Intn(3) // user does not change their mind and they win. if userDoor == prizeDoor { return 0 } // Player loses because they suck at this game return 1 } ``` I really just hate this math problem at this point. The problem is definitely answered and solved for. =/
I get the basic intrinsic properties already. Scaling it (from like 3 doors to 100 doors) doesn't matter to me as much just proving the percents. It's not an exercise, I just didn't believe someone. I had an opinion. I disproved my opinion and am okay with knowing what's provably correct. :)
&gt;Unless that breaks the performance Based on the discussion thread here, I believe it does. The key is that the allocation in the New call gets inlined, so the bootstrap array gets allocated on the stack in the same frame as the Buffer. Buffer.grow probably won't get inlined, so it would allocate bootstrap, defeating the purpose.
&gt;The idea of almost every use-case (or even implementation-level) function in my codebase requiring a ctx parameter seems really distasteful Assuming you want to be able to signal cancellation to any of your function, you're going to have to pass in something, and Context is the standard way to do so. If you are absolutely sure you never want to cancel anything, you don't have to use context. But be careful what you wish for.
All Slack users are anonymous, since we don't ask for official papers to check if your name is Gopher McGopherFace or not. Either drop an email to the support address with your email address for the account, or create a new account with a different email address such as: instead of gopher@gmail.com use gopher+slack@gmail.com
My english is worse than yours, sorry if something is missing in translation. I've read a lot about golang but I never step into really. Golang have only one method of concurrency and this is a good thing because all golang libraries use it. But sometimes chose between async, threading or fork model can better. [Here](https://docs.google.com/presentation/d/1LO_WI3N-3p2Wp9PDWyv5B6EGFZ8XTOTNJ7Hd40WOUHo/mobilepresent?pli=1#slide=id.g70b0035b2_1_119) a fail story with go. But its better to have a library for your database than a couple of them (this one works with twisted, this one with asyncio, this one is thread safe and can be monkey patched by gevent, this one... aaaarrrgggg). Maybe is easier get things done in golang. Deployment in go is very easy, you create a binary (you can use cross compilation easily) and distribute it. In python you'll need to fight with virtualenvs, package managers (how to distribute my binary dependencies of C compiled modules),... But sometimes you create a simple binary version of your code with not frozen version of his dependencies and his binaries start to fail. You can version dependencies in golang too, but I don't know which one is the good one. Respect to error handling I like more good python code. Is less verbose. But in python its easy to forgot defensive programming and code bad python. Or maybe you expend a lot of time asking which fucking exception can raise a piece of code. When to use a exception or not its controversial with python. For example an http library can return a response with status code 400 if you make a bad request, but raises a exception if can't resolve a domain. Golang don't make you think about, so its better here. Types are good. If you see a python code without types annotated (optional thing) you don't known which type is each variable. How many text you must read in [this function](https://docs.python.org/3/library/shutil.html#shutil.copytree) to see how to ignore files? With annotated types it will be a fraction of second. In golang you have types, so usually its better. Other times you'll see a interface{} type and you feel like reading old python. If you bet for python use [mypy](http://mypy-lang.org/). Golang runtime has a garbage collector. It's a good thing to have. Pypy (a python interpreter with just in time compilation) implements one. But both have costs with interoperability with other languages. Cpython (the standard python interpreter) has less overhead calling c libraries than cgo. This can affect to performance and the availability of libraries (usually ported to go). You can write performant code in cython, nim, rust, c, c++ called from python. Python is interpreted. Yes this is a bad thing from a performance point of view, but it allow to have a REPL (Read-Evaluate-Print-Loop or fucking awesome console). In some scenarios it's very good. Start a django console (python console with models preloaded) and interactively perform some task without need to code a one-time run script. Or you are building scrapers with scrapy and you can open a [console](https://doc.scrapy.org/en/latest/topics/shell.html) with one response to test your xpath or css rules. You can open a [jupyter notebook](http://nbviewer.jupyter.org/github/brianckeegan/Bechdel/blob/master/Bechdel_test.ipynb) to analyze some data interactively. Or... anything awesome rapid development that you can imagine. Python is really slow, but usually it's not a problem for me. My webapps are mostly of time waiting to database (or solr, mongo,...). Transcoding video or resizing images are done with fast c libraries wrapped in python. My ETL's can handle required work loads and are maintainable. My automation tasks are glue code to consume apis that do the hard things. Sometimes I really need a fast language or dream with some mb docker images or hate read thousand of no typed code. Then I try to do something in rust or golang, but I finish in python because I'm too lazy.
Hi friend, "./controllers" "./middleware" &amp;#x200B; change these imports to "github.com/myUserName/myAppName/controllers" "github.com/myUserName/myAppName/middleware" &amp;#x200B; then remove go get ./ from your Dockerfile, instead of this use any go vendoring tool or [github.com/golang/dep](https://github.com/golang/dep) for dependencies. &amp;#x200B;
There are lots of ifs and buts in this. But very little "thats". I don't really think any of what you mentioned is particularly likely to happen in practice - and when it does, I'm pretty sure there's a more natural alternative that works just as well. That's exactly why I asked for actual examples of something where the model doesn't fit. Because the examples we have so far, clearly *do* fit and have natural solutions. It's hard to prove a negative, even more so, if you're arguing about something as subjective as aesthetics. And FTR, by your standards, interfaces are a [kludgey hack](https://golang.org/src/io/ioutil/ioutil.go#L161). And I'm honestly fine with not passing such standards.
`type G interface{}` :D
&gt; build with escape analysis displayed Can you provide a reference for that? I couldn't figure out how to do that from the first page of Google results or `go help build`.
Thanks for the writeup. I think it addresses my concerns with the initial proposal better than I could have done. Hope to see this adopted.
 go build -gcflags "-m -m" go tool compile 2&gt;&amp;1 | grep "\-m" -m print optimization decisions ...
Couldn’t the same thing be said of import paths?
What’s the connection to bash? Is this a scenario where a go.mod is being generated with bash strings? If so, that’s pretty rare, and Go uses quotes in other places anyway. Why doesn’t that argument also apply to import paths?
Thanks for the heads up!
Why do you make them `*someStruct` and not `someStruct`? And does `someStruct` contain pointers (/maps/channels/slices/strings)? If no, make the array `someStruct` and just initialize it in a loop (instead of returning it, it's a global variable after all) and there's no GC scanning. Startup will be slow, though, and with that many 9s you'll use a lot of memory (depending on `someStruct`, but even with just two or three `int`s we're talking GBs).
I mean it does make them more performant. 
Yeah, but you're using a New (inlineable) function to preallocated the buffer. This is not how bytes.Buffer is used, it's mostly about being zero value. Removing bootstrap array is still an option and I'm investigating all the consequences and collecting benchmarks data right now, as well as preparing a explanation why this is better than proposed pointer to an array with lazy initialization.
Sure, that's why I said it was a "good" way rather than "efficient" - it still is efficient, but nowadays it's kind of a CVE pinata... every time someone hits it, some more side-channel attacks fall out. 
This is an explanation why working with unquoted strings is easier. And go.mod might be interesting for lots of tools. Go code is different. You basically never want to work on Go code with non-Go-tools. go.mod might be different. Thats why it is called go.mod and not mod.go.
Are you really returning a 99999999 element _array_ from `initGlobalVar` _by value_?
Because in my real case it's actually a tree.
Not actually 99,999,999, but the number is large enough to rise concern. I surely hoping Go could have some magic in the future so it can automatically "execute" the `initGlobalVar` function during compilation.
Well, then you'll get GC scanning. There is one way to deal with that, which is to allocate a large enough space block of memory using `syscall.Mmap` and then use `unsafe`. The GC does not scan memory outside its heap, AFAIK.
&gt; I surely hoping Go could have some magic in the future so it can automatically "execute" the initGlobalVar function during compilation. I'm pretty sure it won't. Don't keep that hope up, if you need that to solve your problem, Go likely isn't the right language. Reason being that Go wants to keep compilation times low and executing user-provided code during compilation is a sure-fire way to trash that.
\&gt;&gt; using unsafe to provide type-safe access-functions you might actually be looking for range. Yes, that's it! I'd like to range over an arbitrary concrete slice as if it were a (non empty in my cases) interface using the same hidden magic style unsafe pointers as the map article mentioned. That is, without having to ever explicitly convert my concrete slice to another slice type with another memory structure.
You can still avoid pointers: use a []someStruct, and ibstead of *someStruct, use its index in the slice. But I'd do it only is GC really turns out to be a problem!
What bothers me most is transitive contracts. Suppose my generic function in my package calls a generic function in another. Do I have to write a contract for my type T that indicates it also fulfills all the contracts of the generic function I'm calling? The draft spec doesn't have a single example of a generic calling a generic. They say they don't want generics to work like C++ templates, but I think C++ templates and concepts are the only way.
Sounds like a good idea. I'll try that, thanks.
some general high level comments about the benchmarks i think would be improvements: \- "val, ok := m.m\[key%MaxMapSize\]" MaxMapSize would better be enforced by the test data set then as in the tested implementation. Otherwise this attributes overhead to the implementation that is really added by the benchmark. \- the benchmark loops should not change the load on the map in relation to b.N ( "for i:=0; i&lt; b.N; i++ { um.Put(i,i)" ): you can add an inner loop independent of b.N that tests different map sizes. The idea is that b.N is getting increased until the benchmark numbers are stable which is complicated when what is benchmarked is a moving target. Example for size independent of b.N benchmark with maps: [https://github.com/golang/go/blob/22afb3571c4bb6268664ecc5da4416ec58d3e060/src/runtime/map\_benchmark\_test.go#L312](https://github.com/golang/go/blob/22afb3571c4bb6268664ecc5da4416ec58d3e060/src/runtime/map_benchmark_test.go#L312) \- instead of creating large maps at the start of the program its nicer to create them size appropriate within the benchmark and use b.ResetTimer() to exclude their generation time from the benchmark. This way they can better average out noise and variance over multiple runs from allocation properties, hash seeds, .... [https://github.com/golang/go/blob/22afb3571c4bb6268664ecc5da4416ec58d3e060/src/runtime/map\_benchmark\_test.go#L247](https://github.com/golang/go/blob/22afb3571c4bb6268664ecc5da4416ec58d3e060/src/runtime/map_benchmark_test.go#L247) \- "if sum&lt;0 {" ... in benchmarks. I find it better to keep tests and benchmarks separate. If there is worry the compiler would optimize out the sum assignment then assign the result to a package level exported variable (e.g. "var Sum int") and "Sum = sum" at the end of the benchmark. &amp;#x200B; Please run the benchmarks on a quiet machine (no network, no other open apps) 10 to 20 times and then use benchstat to see variance that might be introduced to a bad of good run of the binary with less or more interruptions: [https://godoc.org/golang.org/x/perf/cmd/benchstat](https://godoc.org/golang.org/x/perf/cmd/benchstat)
[https://go-review.googlesource.com/c/go/+/133715](https://go-review.googlesource.com/c/go/+/133715)
May I ask why you want to do this? 
Thanks for comment. I cache some responses and I suspected this is the case, but the graphics lead me somewhere else. Also from first sight the cache should be ok. &amp;#x200B; defer `response.Body.Close()` is there. I was considering some defer-ing when calling Unmarshal, but there is nothing to call.
In my own opinion, go is currently in a very different place than python, community/ecosystem-wise. For python, apart from the python 2/3 split that everyone has already talked about, I think they are starting to head into the direction in which c++ took when it was at the pinnacle of adding features. The BDFL and creator of python, Guido Van R. recently stepped down from active development due to an enhancement proposal largely "dealing with a new equals assignment sign" ( := ) that's used in a lot of procedural languages such as Pascal and go. The problem isn't really regarding the implementation of this proposal, but it's just that many involved devs see python heading into a particular way that it's going to make it overly-complex. We've seen it before with the python 2/3 split, many devs were turned off by it and ended up ceasing development in the language altogether; who knows what's going to happen between python 3/"4" Aside from the recent discussion of `contract` in go, the semantics/syntax of the language are very straightforward and have not seen anything near to the level of what python has gone through. Usually there's one way to do something in go and it's usually the best way to do it. I guess in all my point is that I learned early on that usually when picking a language, you also "subscribe" to the community and take an investment in active development of it. Just something to consider -- but again, just my thought.
#REPORT FINDS JUDGE KAVANAUGH RULED AGAINST PUBLIC INTEREST IN ALMOST ALL OF HIS DISTRICT COURT CASES #A TREE DOESN'T NECESSARILY MEAN A BUNCH OF POINTERS. HOW ABOUT ALLOCATING A LARGE SLICE FOR THE ITEMS AND USING INDICES INSTEAD OF POINTERS?
To avoid hitting the hard cap, we are maintaining connection pool of redis connections which is less than 65K and we are doing multiple subscriptions over a single redis connection. We make sure we don't do many subscriptions over the same redis connection to avoid increase in latency.
Just to warm up the data so I can read it later. In my _real_ case, it's a search tree which contains a "map" for data processing. The tree itself just need to be build once, so I thought it is logical to build it during start up.
That's a great synopsis of the concerns with contracts. As several others have noted here and elsewhere, this is very similar to Swift's protocols, and IMO aligns nicely with Go's interfaces. Also like others here, I wrote a [similar proposal](https://gist.github.com/alecthomas/27135d8b8f2caed5b94da0c0e87312aa) a while back.
The answer is simple: benchmark it! Go scales well on big heaps but keep in mind it does not have a generational GC. And better build a slice than an array. 
for k, v := range myMap { .... } Also, check out http://golang.org/pkg/encoding/csv 
Happy Cake Day DocMerlin! Stay positive and happy. Work hard and don't give up hope. Be open to criticism and keep learning. Surround yourself with happy, warm and genuine people.
&gt;benchmark it! This. &amp;#x200B; Not sure Go would be a good option, although if the array itself is quite static and contains long-living objects, that could work. It will consume a lot of memory though...
Thank you so much for responding. I will address each of your concerns, and then hopefully you will change your mind and upvote. First off, I needed to delete many of your comments - please don't do that inline - already reached the maximum message size of reddit, and no one wants to re-read what they've written. &gt;The claims made in the summary are pretty bold statements about two languages who are generally considered to be on eye-level for real world applications... In a broad case, yes, but what I was addressing here was concurrent data structures. Please show me the other studies that show these are on par? &gt;Let's start with the litmus test: How does the code look like... This is a test benchmark. Even the stdlib test cases emit errors from golint. I;m sorry if the style was not to your liking but it doesn't change the results. The code is not designed as a library/package, why would it be? &gt;sync.Cache which provides a cache There is no sync.Cache structure, so I am not sure what you were analyzing? Also, all of them are used to provide a "map/cache". The "unshared" is not a shared cache, but could be a local one, and is used as a baseline (the standard Go map) to test the concurrent versions. &gt;Your code tests just sync.Map... At this point it is clear you don't understand the code, or what it is doing. The primitives must be used to "do something", otherwise in the case of Java anyway, they are going to be eliminated during compilation/runtime. So they were used to implement a shared memory cache. &gt;sync.Map: implementation looks fine. But it is clear that it will perform badly on the given benchmarks. From the documentation This is you biggest mistake. As noticed in the analysis, I was most concerned with the performance of "Get" here, which is EXACTLY where the documentation says it should excel. The map is pre-built outside of the test, and all the test does is reads. And with multi. concurrent reads. Compare the performance here to Get under Java... especially the "multi" versions. &gt;The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, or (2) when multiple goroutines read, write, and overwrite entries for disjoint sets of keys. In these two cases, use of a Map may significantly reduce lock contention compared to a Go map paired with a separate Mutex or RWMutex. This is why there is the "lock" version, which should perform better in the "multi PutGet" test - and guess what - it does ! As expected. But still falls far short of the Java performance. &gt;Lets analyze the access pattern executed by the benchmarks a bit more in detail... This was done intentionally to provide a baseline for the concurrent access. Again, the same access pattern is used in the Java implementation with far better performance. We are half way through and you still have not grasped that. &gt;LockCache. The if !ok { return 0 } I just read the language specification [index expressions](https://golang.org/ref/spec#Index_expressions), and I don't see anywhere where it states a constraint on the variable if the index access is not found. Thus the check. Please show me where that is not the case. Regardless, probably not material performance difference. &gt;Why does LockCache use a sync.RWMutex if no benchmark ever mixes Reads and Writes?... The PutGet do mix under multi. Again, I don't think you understand the tests. RWMutex are the right mutex if you have few Writes and lots of Reads. The benchmarks are read-only or write-only. Implementation is sensible but the benchmarks are maybe a bit too micro here. &gt;ChannelCache: No, no, no.... You are just completely incorrect here. The fact that the structure being managed by the channels is a cache, is inconsequential. If you read the concurrency statement the Go authors are tending to "do not share data". so the entire "shared cache" is not idiomatic - thus the performance test with channels. As for the select, it was a hold over from when there were multiple in bound channels. I have removed it. No real change in performance, since I would expect the compiler to essentially remove a single case select anyway, but thank you for the edit. &gt;What makes you think that map access is "a single indirection and a load or store"? How does the outcome of the benchmarks (Get 63ns/op, Put 69ns/op, PutGet 93ns/op) indicate that go bench is unsuitable? Why do you attribute the 63+69-93 = 39 to go bench? Did you measure go bench's overhead? Because that is the way a map of this size would would - there would be an indexed lookup, and list search, or tree search with very few elements. Again, compare to the performance of Java. &gt;The documentation of sync.Map clearly states... Just wrong. See MultiGet. Again, compare to the Java performance, and if you review the sync.Map code you will see that it attempts to just be a map lookup in the common case (many reads), so in the MultiGet test it should perform equally to the unshared Get case.... That is the crux of the problem! &gt;... "this should only be a volatile load"... When talking concurrency, it is like BIGO notation - it was a generalization. &gt;You start with the implication that go bench might broken or at least not good enough for your test. Such a claim might trigger some backreaction. The reason for this claim, and the question is valid, is due to the performance difference between the "unshared map", and the Java concurrent version. I would expect Go to easily win here, and it doesn't. Even the raw performance of a map lookup being 70+ ns is hard to believe - thus the conjecture that there might be something broken in 'go bench'. &amp;#x200B; After speaking with others, it appears many of the sync.Map problems are because the implementation is not ideal because the underlying Go Maps do not offer bulk copy or insert. So it is a poor implementation (certainly when compared to Java), but it is probably the best that can be done right now. &gt;In summary: A very bad microbenchmark, bad implementation, wrong conclusions, false assumptions but bold claims. Not worth reading. I think you are incorrect on almost all accounts. I think the basic thing you are missing - because you failed to bring it up a single time - is the relatively poor performance compared to Java. The fact you can't mention it or understand it, I think says a lot about your bias. I want Go to be better, and that is why I did this. I hope I have addressed you concerns. If you decide to ask additional questions, please just isolate them, as reading quoted text is pretty annoying. Thanks. &amp;#x200B;
Thankee!
&gt; I cache some responses and I suspected this is the case, but the graphics lead me somewhere else. Note that the profile (AFAIK) tells you where stuff was allocated from, not where it's now referenced. There is no way to know the latter, really. So I assume you're unmarshalling something and then leak that data (maybe through a blocking goroutine or by appending to a slice that you don't shrink back again). I think for you it's probably more helpful to use the list-view, then the graph-view (use `weblist`, I think?). This will tell you at least which handler/line is the one that is doing the allocation and you might be able to follow the data-flow from there.
Thanks for your input. - The mod was used because it worked well with the b.N usage pattern. The data set size is still capped. The load is not changed, since the keys already exists - since they are pre-populated. - Thank you for the reset timer notes, that will make further tests easier. - The sum check is there for deadcode elimination. In Go your solution is a better one, but under Java it will dig deep to find out if the method does anything, and if not, remove the entire loop - so I wanted the code to be the same between both, and the call to print ensures this. - I did run them MULTIPLE times - in this way jmh is superior IMO as it will manage the runs and produce the stats - I'd love to see 'go bench' get there... - I will look into 'benchstat'. In this case though, I'm very certain the numbers are representative, with the only big hole being that OSX concurrency primitives are not as good as linux - it wouldn't be the first time. Thank you for the comments. 
Yes, I should add screenshots. In the meantime, native controls are used under the hood, so they GUI look fairly standard. No, it does not work on Macs. I don't have the experience or the hardware to develop for Macs, but I'd be very interested in PRs! If anyone is interested, I can provide some guidance on how to start a port.
Please s/sync.Cache/sync.Pool/ and take my excuses for the stupid typo. For the rest: I won't get dragged into "Someone's wrong on the internet" wormhole.
I wrote this up a while ago: https://gist.github.com/jonbodner/4b99bc3ccc024d74babf
[removed]
If you want to gain exposure, you probably should be on github as well. I know vimeo is higher quality, but public exposure is found on youtube.
Hmm. Not much of a cross-platform UI if it requires libgtk and doesn't have Mac support.
A lot of these responses haven't really addressed the global/local thing... To be honest that won't have much of an impact but you just as well could initialize that globalVar in your actual code (not via an init function) and just pass it to whoever needs it.
Yeah, I was thinking about that. :/ Perhaps it could be allocated and set inside New, like buf = bootstrap[:] or something. Not sure if the compiler would think it escapes, though. 
Did you apply CL 133375 ?
If you find the answer I wouldn't mind an update on what the problem was and how you find out. I think that might be a good instructional blog post or something :)
wat
This is just an example to remind you that 'errors are just values' ([Go-Proverb](https://go-proverbs.github.io/)). You can literally do anything with them and almost any value can become an error by implementing the error interface. I'd actually like to see more creative error handling in the Go-community, like the above.
&gt; It means interfaces 2.0. yes, they're different than 1.0 interfaces, but crucially are backwards compatible with existing interfaces. I'm wondering if it should just be interfaces 1.0 myself. We already have the characteristic that int can't participate in interfaces; would it be that catastrophic if they also couldn't participate in generics without some wrapping? Having to write a type around int16 is inconvenient, but it gets easier as you get used it. (I am a bit biased by already passing through this gateway and writing my code with a lot of little types already. There is a period of time where you have to adjust your code a bit to avoid writing conversions everywhere, but on the other side of that time, you might be surprised at how successful I am at using lots of little types around ints, yet how few conversions I actually have to write.) If there is a solution that allows us to use int(8/16/32/64/) directly, hey, that's great, but contracts are scaring me too. Of the two I might just prefer basing generics on interfaces 1.0.
&gt; Noticeably absent from any talks this year was Go 1.11’s other headlining feature — support for Web Assembly. Unfortunately, I am not in US. Otherwise would have given a talk on it.
Caching / Eager loading. 
thanks for the reply. some followup comments: * the modulo in the implementation still adds CPU overhead that would usually not be there for normal map accesses. e.g. for divisions on amd64 these can be in the order of 10ns. Since a const is used here the effect might be small \~1ns as the compiler can optimize them away to multiplication and shifts. * while the b.N might not matter much here there can still be cache size effects whether 1000 or 500000 keys are probed from a pre-populated map. e.g. the map bucket array sizes tested I think are larger than per core L1 or L2 cache sizes of the CPU used for benchmarking. * it was not clear from the bench output that these were run multiple times. benchstat will add that information and some measure of variance. The numbers are likely representative, its still nice to know if there is a 1% or 10% spread between runs.
&gt;What makes you think that map access is "a single indirection and a load or store"? How does the outcome of the benchmarks (Get 63ns/op, Put 69ns/op, PutGet 93ns/op) indicate that go bench is unsuitable? Why do you attribute the 63+69-93 = 39 to go bench? Did you measure go bench's overhead? Also, in case someone is actually reading this stuff, the reason the above matters is that PutGet does the exact same operations as Get and Put, so you would expect the PutGet times (no multiple threads) to equals the combined Put and Get times. The fact that they don't, and are drastically off, is indicative of one of two things: the cache locality is different, which might be the case (since the put follwed by the get), or that the test harness is not properly accounting for the method call overhead when calling the bench method, interating over b.N, etc. - essentially the work being performed that is not the methods work. To address, I am going to change the PutGet to read from opposite ends and see if the times line-up then,
Yes it is. The point is that they chose a polymorphic (interface) approach to handle the same case that Go 2 contracts were proposed for. I'm 100% in agreement that this would be a FAR SIMPLER and FAR MORE COHERENT way to provide generic support. It's basically a compiler transformation. a + b -&gt; a.Add(b) a &lt; b -&gt; a.Compare(b) &lt; 0 etc.
Maybe off topic here, but if you are caching a graph or a tree, then why not use a proper graph database to do it for you? then your Go app can be stateless.
For an update, the PutGet cache locality was the issue, not a 'go bench' accuracy one. The tests, timings, and analysis have been updated.
Applicable: https://arp242.net/weblog/i-dont-like-git-but-im-going-to-migrate-my-projects-to-it.html, specifically [this section](https://arp242.net/weblog/i-dont-like-git-but-im-going-to-migrate-my-projects-to-it.html#why-switch-to-git-then). I've actually had people upload "forks" of my repos to GitHub instead of making a PR on BitBucket :-/
&gt; Also, to call functions in this way, you have to tell it what type you’re passing, so like you’d call Print above by doing `Print(int)([]int{1,2,3})`. Why can’t we have type inference here? The draft proposal you refer to covers this, using this exact example: "In many cases, when calling a function with type parameters, we can use type inference to avoid having to explicitly write out the type arguments." &gt; Here’s my fix… since contracts are basically like interfaces, let’s actually use interfaces. And let’s make the contracty part last, since it’s least important: First off I don't agree with using an empty interface for functionality that has nothing to do with empty interfaces. Second, while not using contracts at all seems reasonable for a small example like this, you either need to read the function or enter a compile-fix cycle to find out what operations your concrete types need to support to satisfy what is *still* a contract, but now implicit and hidden away in the function implementation. Imagine that you have a large package of generic functions to perform a set of related operations. Then an explicit contract makes it a lot easier to get an overview of the operations the types you throw at it need to support. &gt; Is that a map of int to something? Or is it a slice? Is that just invalid? What would the error message say, if so? Would it change if I put a 1 in the index? Or -1? Or “1”? Indexing is an operator and I don't see why it should be treated any different than `+` or `-`. Just like `uint64` and `uint8` support adding a constant integer, both thus satisfying the contract constraint `n + 1`, `map[int]t`, `[]t` and `[10]t` all support integer indexing, thus all of them satisfy the contract constraint `s := s[0]`. If integer indexing is all you specify in the contract (thus all you'll use in the generic function), why should you care whether the concrete type is a map or a slice? &gt; Would it change if I put a 1 in the index? Or -1? Or “1”? Yes. First of all, `"1"` is of a completely different type, and obviously only maps can be indexed by strings. `1` would work for arrays of length 2 and greater, slices and maps with integer type keys alike, but not for arrays of length 1 or 0. `-1` wouldn't work with slices and arrays because their indices must be non-negative, but it would work for maps with integer type keys. These are all compile-time constraints that the Go compiler will already error out on if you put the contract constraints as is in a function body, so it's not some sort of black magic. You can try them out now: package main func main() { x := [1]string{} // type of your choice s := x[-1] // constraint of your choice } &gt; Take a contract that says you can accept a string or a []byte… what do you think it would look like? The purpose of a contract is to declare the operations you need to be able to perform on the values, not their types. You don't need to know (let alone deliberately limit) the types a generic function can operate on as long as the types satisfy the contract constraints. So you put `s[0]` in the contract if you *need* to use integer indexing, you put `string(s)` if you *need* it to be string convertible, and don't think for a second about what exact concrete types satisfy these constraints. If you try to use contracts as a sum type of byte slices and strings, yeah, it'll suck, but I don't see why you would want to do that. &gt; Lack of Names and Documentations Lack of names? &gt; The biggest problem with contracts defined as random blocks of code is their lack of documentation. You document things by documenting things. How is this different from documenting any other code? &gt; Is this the same contract as above? In what real world case do you need to know that in the first place? To use a generic function I only need to know that the type of my parameters satisfy the constraints of the contract. If I use it with another function I might have to be sure that they satisfy another contract. The only reason I see to make it easier to compare contracts for equivalence is if you want to avoid repetition. &gt; Look at the lack of a Logging interface, and how that affected logging across the ecosystem. io.Reader and io.Writer make writing and reading streams of bytes so nice because they’re standardized, because they are discoverable. The standardization means that everyone who writes streams of bytes uses the exact same signature, so we can compose readers and writers trivially, and discover new ways to compose them just by looking for the terms io.Reader and io.Writer. A contract could be standardized and discoverable, so I don't see where this critique is coming from. I think that's the point of them, actually, so you don't need to find out at compilation or by reading the whole function body that the parameterized types implement the operations you'll use. &gt; My solution is to mainly just use interfaces and tag them with :T to denote they’re a parameterized type. Interfaces have nothing to do with parameterized types. The syntax you suggest is confusing. "This is an empty interface, `:`, oh no, it's actually a parameterized type, two concepts that have absolutely nothing to do with each other. &gt; For contracts that don’t distill to “has a method”, make built-in contract/interfaces that can be well-documented and well-known. What are some of your ideas for built-in contracts? The way I see it, a contract is only there for documentation and run-time type substitution. They are proposed so that you don't have to read a whole package to figure out what operations your concrete types need to support to be able to work with the generic function using the contract. If you "standardize" contracts like you would interfaces, you'll end up over-specifying things. Maybe there's an `Slicelike` contract in the standard library but all you really need is for the type to have a `len()`. I guess you could create a lot of smaller contracts and compose them like the standard library does with interfaces (Writer, Reader, Closer, ReadWriter, ReadWriteCloser etc.) but at that point the contract example will end up being more readable. Overall I think this feature would be nice, but I hope that people won't overuse it. Off the bat, creating and reusing container types will be a lot easier, and a lot of empty interface crap can be removed. The practical overlap between contracts+generics and interfaces grate me a bit as there is now more than one way to say that your function accepts types satisfying some method constraints, but it's not too bad.
thank you. - yes the modulo does affect things, but since I was comparing to Java as a reference (I could of used C, but I wanted to use a GC env) and did the same there I figured the relative difference was negligible. - I will try some various inlining options - as I've stated, I think that is a prime reason the Java version was faster, but as I've run the benchmarks using the profiler I'm seeing more GC activity than I would of expected (I think) - someone else pointed out the issue with the "if !ok"... I reviewed the language specs and I can't see where it states the value will be the 0 value ??? - since I was running on the same hardware, and looking at relative performance, I wasn't too concerned about the map size, but I did make it an option, so that it should fit within the L3 (based on others input), but in the case of Java where the objects are much larger, it doesn't come close to fitting... - I am reviewing the bench options in terms of multiple runs, and the variance. thanks! I will attempt to do the same as the Java and update the timings. I appreciate your feedback.
&gt; (I am a bit biased by already passing through this gateway and writing my code with a lot of little types already. There is a period of time where you have to adjust your code a bit to avoid writing conversions everywhere, but on the other side of that time, you might be surprised at how successful I am at using lots of little types around ints, yet how few conversions I actually have to write.) This is a digression, but that sounds like a great topic for a blog post.
What the other guy said about type checking vs evaluation, but what is the point of a stringOrBytes contract in the first place? Should it matter to the generic function that the types are either strings or bytes as long as they satisfy the constraints?
[removed]
I believe a 3rd variable is used. Unless [uhmmm](https://en.wikipedia.org/wiki/XOR_swap_algorithm).
Provide an example using the password “changeme”. Give us the password you got from hashing with bcrypt, how it looks in the database and how it looks when you read it again in the model. That way we can see what is happening.
&gt;since I was running on the same hardware, and looking at relative &gt; &gt;performance, I was not suggesting this would be better to change because of the relative performance difference between Go and Java. go test will increase b.N until some stabilization criteria is met or time criteria. This assumes each benchmark iteration inside the for loop for b.N is stable in terms of work load. By increasing the cache pressure with larger b.N this is not the case. That is why often sub benchmarks are made with different sizes for the outer loop and then an inner loop for b.N as linked in an earlier example. [https://blog.golang.org/subtests](https://blog.golang.org/subtests) see also the notes about sub tests and RunParallel for benchmarks in: [https://godoc.org/testing](https://godoc.org/testing) Your current benchmarks might run 8 instances of the benchmark in parallel where each is using NGOS go rountines which would skew the actual throughput of each benchmark instance when run on its own. Not sure if this mimics the work load of the java benchmark also running 8 independent benchmarks in parallel with 2 threads(?) each. &gt;someone else pointed out the issue with the "if !ok"... I reviewed the language specs and I can't see where it states the value will be the 0 value ??? I am going to remove it and re-run the tests. [https://golang.org/ref/spec#Index\_expressions](https://golang.org/ref/spec#Index_expressions) "if the map is nil or does not contain such an entry, a\[x\] is the [zero value](https://golang.org/ref/spec#The_zero_value) for the element type of M"
If he wants it done at compile time, he's essentially already asserting that the value is computable statically.
Executing go code to generate static structures at (before) compile time? As a sibling comment mentioned, it sounds like he's describing `go generate`. I'd say go _already_ supports this use case, you just need to do a little bit of extra leg work rather than wanting it to happen automatically when you `go build`.
Thanks to all commenters. All replies are very much appreciated. 
Looks like this is documented in the [CGO](https://golang.org/cmd/cgo/) documentation, search for `CC_FOR_TARGET` on that page to find what you need to configure.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://golang.org/cmd/cgo/) - Previous text "CGO" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20e5i3pcn) 
What happens when you run the go get command directly?
Summarizing the stackoverflow post (which is an excellent post, go read it if you are curious about the details), the values of a and b (integers) will be read into two CPU registers, then written from the CPU registers back to the opposite variables. The leftmost variable is written first in that example--but the compiler likely has the freedom to reorder them if it thinks that will result in an optimization. The situation would be more interesting if the type of a and b were a complex struct--in that case I expect there would probably be a compiler-generated temporary variable.
My two cent on your problem, I had a similar looking pprof graph at some point with \`json.Decode\` having a arrow back to itself. And so having a recursive call to itself. And it was also after building a cache system, for gorm using its "plugin" capabilities. Don't, gorm doesn't define interface for this type of usage. in my case it crashed the server, it was because \`json.Decode\` and the encoding/json package in general doesn't handle circular reference. From memory (don't quote me) it was for performance reasons.
It sounds like you're storing it in the database in a field that truncates it. Is your field limited to a certain length? For example, in MySQL you'll want to make sure you're using CHAR(60), BINARY, or BINARY(60) and for SQL Server VARCHAR(60), etc. Besides there, check your stored procedure parameters if you're using an SP to store things. If you are using anything short of 60 characters, you are losing data and won't be able to verify a hash. Otherwise make sure you aren't hashing the password a second time before storing it or passing something in a way where you aren't passing the data because of a type in a parameter or passing the wrong parameter, etc.
&gt; As a sibling comment mentioned, it sounds like he's describing go generate. I'd say go already supports this use case That depends on the details. Given that they want to have pointers between elements, I'm not entirely sure. But yeah, it might do.
Okay I'll try that out. Looks like we can't reference local packages in Golang. That means if I ever want to include a local package, I would have to push it up to Github first before I can reference it in my project.
I am pretty sure that is not the case. The -8 refers to the MAXGOPROCS. In order to actually get parallel tests, you need to set the parallelism which defaults to 1. I tried it with -cpu=1 and no difference. And then, it is only used when b.RunParallel is used - at least according to my reading of the code. Thanks for the missing map key reference. I removed the code - didn't make much difference.
I'll share my perspective. I have a web dev background (Perl, Python, JavaScript) and while I've dabbled in other classes of languages (C and C++ for compiled, Java for VM) I _really_ hated to program in either one when used to how _nice_ it was to use Python and other similar languages. Web dev is one thing but I also had a passing interest in making desktop apps or games and things. Python would be a fun language to use, but when using it on the client side (the end user's own devices), it begins to get complicated if you wanna think about making the source code hard to access. On server-side web apps this is a non-issue, but on the client side you have like py2exe and things, but at the end of the day, you end up with a zipfile-equivalent from which you can extract the Python source files (or the `*.pyc` bytecode which can be decompiled) and Python can't even be obfuscated because its whitespace formatting is so important. Go fills a very nice niche somewhere between C++ and Java, it runs circles around Python by default (you can write crappy code that isn't optimized and it would still likely run several times faster than equivalent Python, and then you can re-optimize for even better performance). It compiles to probably-ugly machine code (I don't mind if the best users can get is ugly assembly code) which is plenty enough for me without summoning the dark lords of hell to create an obfuscated Windows binary. I use it in place for Python on any project that I might like to keep closed source.
I figured it used .mod because the module syntax isn’t in the language spec. It’s purely a tool artifact that isn’t covered by Go 1 compat and could be abandoned in a couple years.
User this https://github.com/karalabe/xgo
[removed]
Just use go-modules. Why did you even use go generate for dependencies? If they are passive better import them with an underscore.
I complain about that. Version is wholly orthogonal to identifier/name, just as time is an orthogonal dimension to space. Collapsing the two into one is a frustrating and inelegant end-run around problems better solved through tooling.
&gt; This talk occurred during another that I had attended, so I’m sad to have missed it When they switched from single track to multitrack, I too started to run into missed sessions.
Actually, now I'm fairly certain that is not the case. A more thorough review of the stdlib, and also, if it were the case, every test anyone wrote would need to be "thread safe" - which is not the case. test methods are only run in parallel if RunParallel is used. I also wrote a simple test to verify :) so I cheated. You would think the docs would be more explicit about this as it's pretty important.
Even though I use bitbucket as well, I always forget to search for repos there: `go golang matrix storage site:github.com !g`
I use go generate to download these specific dependencies to simplify the construction of the application without any previous commands.
Same issue unfortunately 
Déjà vu... Not only is it likely that space and time are actually one thing, it is plainly more rational to understand a subject's version as being intrinsically related to it's identity. Baby Peter's API certainly didn't include DriveTruck or BeResponsible. Treating version as orthogonal to identity would only be valid if versioning itself had no effect on how a subject was engaged. In that case, what would the point be to version something?
Thanks for checking. Then it was just me misremembering how/when parallel benchmarks are executed.
Not directly the topic, [but mentioned in this one](http://www.jerf.org/iri/post/2945). The other key observation is just that, yes, it's a pain when you first start, and retrofitting it on to existing code can be a pain, but if you develop a bit of skill in it and start a new code base with that skill, it's actually quite easy in Go. My codebase is nowhere near as shot through with conversions as someone who's only been trying to do this for a couple of days would think. And a lot of them are around the "edges" where stuff is going in or out and I want to be careful anyhow.
No problem - I really though I had s**t the bed there for a second...
This is we use for a project that also needs CGO for sqlite and it works well. There's another tool called "gox" that has a bit of a nicer interface but I had issues with the binaries it produced. Never had an issue with xgo though.
And white text for the link gets lost over the gophers' eyes.
Question for someone who has experience with both: What's the pros/cons of this vs. Goose?
I [wrote this a few months ago](https://medium.com/def-repr-self/cross-compiling-go-and-cgo-targeting-armv7l-musl-libc-f96c610834a8) with info on cross-compiling go + cgo for rpi. Hopefully this helps. 
&gt; the values of a and b (integers) will be read into two CPU registers Well, yes if they fit. In the general case, they don't and the solution is not as easy as allocating a CPU register. Which the SO answer sadly fails to ever mention.
Checkout golang/go repo recent commits. :) We've just merged a patch to bytes.Buffer: [https://github.com/golang/go/commit/9c2be4c22d78cebc52458ba7298a470a3be0cdce](https://github.com/golang/go/commit/9c2be4c22d78cebc52458ba7298a470a3be0cdce) Makes bytebuf kinda obsolete (and it's a good thing). 
You can import packages and not use them with `import _ "fmt"`. This is not an error.
&gt; just as time is an orthogonal dimension to space. ...
I also like `var _ someInterface = someStruct{}` to ensure at compile time that you've implemented an interface correctly that may have not been otherwise discovered until you used your package in another package.
Not that familiar with windows anymore but older windows you can check your path in the environment variables and see which one you are using now, also check your GOPATH and see which one is set there
Without updating the identifier related to a version it would be impossible to use two major versions of the same package within the application/library at once. For larger applications this is a very real consideration.
&gt; I don't agree with using an empty interface for functionality that has nothing to do with empty interfaces. I didn't make it clear... interface{} here literally means interface{} like it does today. i.e. it restricts what types you can pass in (in this case, there's no restriction). But you could just as easily use io.Reader or whatever. This is the mechanism that I'm using to restrict what types can be passed into the function, where the design docs use blocks of code defining contracts instead. &gt; If integer indexing is all you specify in the contract (thus all you'll use in the generic function), why should you care whether the concrete type is a map or a slice? Because when you then decide to call `delete(m, 1)` on the input and you realize people have been using your function with slices... then you're gonna be screwed. The problem is that blocks of code are not good indications of what people really mean. Maybe you meant to only work with map[int]... but you didn't realize you needed to specify delete(m, 1) in the body in order to exclude slices. This is different than interfaces where they're very obvious and concrete "I only want to allow types with these methods". &gt; If I use it with another function I might have to be sure that they satisfy another contract. That's part of the point. When generic functions get more popular, then we need to know if the type I pass into Foo will also work in Bar. And we shouldn't need a degree in programming language theory to do so. &gt; The syntax you suggest is confusing. "This is an empty interface, :, oh no, it's actually a parameterized type, two concepts that have absolutely nothing to do with each other. They do have something to do with one another, but clearly I didn't explain well enough. The interface is the filter that determines what types you can pass in. The :T gives that type a name in the local scope, so that you can know when two types must be the same, like func Equal(a, b fmt.Stringer:T) &gt; so you don't need to find out at compilation or by reading the whole function body that the parameterized types implement the operations you'll use But you do need to read a whole function body, but that body is the body of the contract, and it's in some wacky format with no actual logic that you can hang your hat on. x == x var y string := x.String() ^^ This code is hard to read because it doesn't actually *mean* anything. It's not code that *does* anything. It's imperative code trying to be used declaratively. &gt; What are some of your ideas for built-in contracts? You mentioned some that I think would be useful - equatable, comparable... yes, maybe you only need len()... but if you only need len(), you could probably take an integer instead :) I'm not saying my solution is complete or perfect.... but it's nearer what I'd like to see. I write it as a suggestion that hopefully people smarter than I am can take in the right direction... and mostly as a way to say "whoa, contracts look way complicated and not as intuitive as the authors seem to think). To be honest, I'm not sure we even really need generics. There's only been a few times when I have implemented a generic type that would have been improved with generics..... and I've been writing go 40 hours a week for 5 years.
&gt; Without updating the identifier related to a major version it would be impossible to use two major versions of the same package within the application/library at once. That's true. &gt; For larger applications this is a very real consideration. I know this argument, but I don't buy it.
&gt; it is plainly more rational to understand a subject's version as being intrinsically related to it's identity. I agree, which is why a dependency management system should have _separate_ dials for the space (identifier) and time (version) dimensions. &gt; Baby Peter's API certainly didn't include DriveTruck or BeResponsible. Treating version as orthogonal to identity would only be valid if versioning itself had no effect on how a subject was engaged. Your second sentence doesn't follow from your first. 
I'm also a fan of just writing it out, but combined with [code generation of the SQL into a vfs interface](http://termbin.com/qucg) to keep the "data" out of the code. Just a little bit of convenience for source control purposes.
I can't, go-bindata and goversioninfo are programs, not importable packages
Ok it works if I import the whole package `github.com/jteeuwen/go-bindata` and I have to exec a simple `go install` to create the program : ```golang //go:generate go install -v -i github.com/jteeuwen/go-bindata/go-bindata //go:generate go-bindata -pkg bindata -o app/bindata/bindata.go nodejs-portable.conf //go:generate go install -v -i github.com/josephspurrier/goversioninfo/cmd/goversioninfo //go:generate goversioninfo -icon=res/app.ico package main import ( _ "github.com/josephspurrier/goversioninfo" _ "github.com/jteeuwen/go-bindata" ... ``` It's better than [my solution](https://www.reddit.com/r/golang/comments/9djywl/go_generate_with_go_111/e5icisd/) because I can preserve compatibility thanks to go mod.
To be real 99% of webassembly stuff is probably going to be written in Rust
GTK is cross-platform (including the Mac) and I suspect OP just meant he didn't have the hardware to compile and test this on on the Mac. Not saying your comment is totally wrong, just think the negative attitude is unwarranted.
I think the argument for multiple major versions of a library within an application is highlighted when a major version of a library is not fully feature complete with the previous major version. Specifically in the case of significant major breaking changes, or rewrites. A major versioned library may choose not to support certain patterns at all or iteratively back fill over time previous functionality that existed in old major versions into the new major version.
Why?
Mozilla is investing HUGE amount of resources to ensure Rust will be THE webassembly language, for Go and other languages it's more bolted on. There's a reason you don't see the Go community talking about it, all the resources are going into Rust https://hacks.mozilla.org/2018/03/making-webassembly-better-for-rust-for-all-languages/
Yep already done i have switched to a stable fork : https://github.com/kevinburke/go-bindata
If you are typing this verbatim: gvm use go1.10.3 [--default] Try removing the brackets: gvm use go1.10.3 --default (in help output, brackets typically denote optional parameters)
to whomever. :)
Surely BabyPeter has a different identity than AdultPeter. That idea overlays quite well with "LibV1 versus LibV2". I'm fairly confident that an analog is free from sequential concerns, so I'm putting aside the claim of anything "not following". &amp;#x200B; I cannot think of any useful way to clarify what identity means; Your position violates it's meaning. "Collapsing space and time together" is the concept that is a non-sequitur. Or so says our current understanding of physics and, in this case, identity.
ya stuff like that is usually either a) you replaced go and you have to reinstall your deps, b) the repo is gone or updated since go 1.9, and/or doesnt compile, or c) you have a dependency problem (like library isnt or the json int he 2nd line is in a new folder now)... or d) GOPATH is wrong again cuz you were running it as root or reinstalled go &amp;#x200B; &amp;#x200B; &amp;#x200B;
It’s such a shock people dislike the Go community 
Did that for a project of mine. Found this useful: https://github.com/mattn/go-sqlite3/issues/384#issuecomment-290291449
&gt; I didn't make it clear... interface{} here literally means interface{} like it does today. i.e. it restricts what types you can pass in (in this case, there's no restriction). But you could just as easily use io.Reader or whatever. This is the mechanism that I'm using to restrict what types can be passed into the function, where the design docs use blocks of code defining contracts instead. Still not clear to me. Your examples are trivial (and don't need contracts per the draft proposal) so neither of them seems to show how an interface is supposed to express that, say, T1 can be subtracted from T2. You make an example for a "Convertible" contract but it makes no sense because the only type information it provides is `type Convertible:T contract` which in itself doesn't mean anything. &gt; Because when you then decide to call delete(m, 1) on the input and you realize people have been using your function with slices... then you're gonna be screwed. &gt; The problem is that blocks of code are not good indications of what people really mean. Maybe you meant to only work with map[int]... but you didn't realize you needed to specify delete(m, 1) in the body in order to exclude slices. Create a new function for a new contract if you're going to fundamentally change what your generic function does. This is not a problem unique to the draft proposal. As for this specific example, if you only meant to work with `map[int]...`, you keep that part of the type concrete and have functions that operate on `map[int]T` for a generic type T. &gt; That's part of the point. When generic functions get more popular, then we need to know if the type I pass into Foo will also work in Bar. And we shouldn't need a degree in programming language theory to do so. So you read both their contracts and make sure that they are satisfied. At no point do you need to know whether Foo or Bar are equivalent to do this. I'm not sure what you mean by needing a degree in programming language theory. As I said before, the contracts work like the static type checking already works in Go today. You can literally take the body of a contract and put it into a function and have Go compile it and fail for a given type error out for the same reason that a type wouldn't satisfy the contract. &gt; They do have something to do with one another, but clearly I didn't explain well enough. The interface is the filter that determines what types you can pass in. The :T gives that type a name in the local scope, so that you can know when two types must be the same, like func Equal(a, b fmt.Stringer:T) Then where do we learn whether T needs to support addition, `len()` etc.? Without that you suddenly have *two* filters: a) the interface which is plain and simple to read and b) what operators are actually used on the values in the code. If you mean that this information should be contained in the interfaces, then it's either not at all "interface{} like it is today" or you are suggesting that operators should be broken out into methods. Moreover, empty interfaces are a pretty hefty data structure with multiple levels of indirection, which compared to just passing values around as-is to generic functions that were concretized at compile time is slow and needlessly complex. An interface *contains* a pointer to the actual data and a pointer to its type information. You don't need that for compile time generics. &gt; But you do need to read a whole function body, but that body is the body of the contract, and it's in some wacky format with no actual logic that you can hang your hat on. No, you have to read a contract body. Do you expect many contracts to outgrow all the functions that use them? &gt; ^ This code is hard to read because it doesn't actually mean anything. It's not code that does anything. It's imperative code trying to be used declaratively. Code that doesn't *mean* anything is very different from code that doesn't *do* anything imperatively. Maybe it's hard for you to read, but it isn't for me. Do you look at C structs and get confused by the fact that what superficially looks like a auto lifetime variable declaration statements inside it aren't? For what it's worth, I think it's ugly and conceptually grating, too, but I can't think of any more straight forward way to declare contracts, and I think contracts are a good idea for the same reason interfaces are. &gt; You mentioned some that I think would be useful - equatable, comparable... How would those be expressed with an interface, and what is the difference between equatable and comparable in this context? &gt; I'm not saying my solution is complete or perfect.... It doesn't look like a solution to me because you barely describe how it works. Maybe you should give it some more thought and write something up on it when you have a concrete theory for how it should work that provably covers more than the trivial container type examples. &gt; To be honest, I'm not sure we even really need generics. "Need" is a bit strong a word here. I don't *need* a type system at all, but that's not to say that it can't be helpful. &gt; There's only been a few times when I have implemented a generic type that would have been improved with generics..... and I've been writing go 40 hours a week for 5 years. I can think of a few places in the standard library that could be improved with generics. Off the bat, `sort.Interface` (which then needn't the Swap or Len methods or even be an interface at all) and `sync.Map` (so you don't have to unbox and type check an empty interface every time you retrieve something from the map). Then there are a whole bunch of libraries for type safe containers that currently have multiple implementations for different types. On the other hand, that there may only be a few cases where they would be useful is only good IMO. Personally, I hope their use will be very occasional.
&gt;Also, ok could be false ok and ok1 can't both be true
For the record, you are an asshole.
Oh thanks indeed!
Not that I'm aware of. You'd have to manually wire it all up.
You're right, my tone could have been better. I'll be better in future.
best practices for any language: 1. don't run out of memory 2. set up monitoring and alerting (like grafana) to keep track of 1. 3. ensure numbers 1 and 2. if you're out of memory, there's guaranteed to be nothing useful you can do in the overwhelming majority of server applications. You can have your application poll the OS occasionally to see how much free RAM is available to decide how likely you are to run out, but modern OSes overcommit memory, so even these numbers are half truths... and you should not disable overcommit without an incredibly good reason. Overcommit is incredibly important.
No need. You need to understand $GOPATH/src, give a chance to package naming and path in docs.
This is also a recent favorite trick of mine. The details are covered in this official doc: [https://golang.org/doc/effective\_go.html#blank\_implements](https://golang.org/doc/effective_go.html#blank_implements)
[removed]
I think I remember reading that the compiler optimises it away due to the `_` variable name. I.e. the contract is verified at compile-time but the code doesn't exist at run-time so nothing is allocated in either case.
It's fine if you don't want to write in Go. But comments like these - &gt; There's a reason you don't see the Go community talking about it is just outright false. Feel free to hop in to the #webassembly channel in slack, I can assure you there is lots going on. People are porting vuejs in Go, and all sorts of crazy and fun stuff. Rust has had wasm support for quite some time. And for Go, it has not even been a month since 1.11 is released. So obviously, it takes some time for the broader public to take in stuff and spread the word. And lastly, just because Rust is investing lot of resources in wasm, doesn't mean that Go users should not. WebAssembly may be one of the few things which was _completely_ written by a non core-team member. Google did not need it. "We" did. Because "we" want to see more people use Go in other exciting areas. And "we" will continue to use it and talk about it in conferences.
Too many gophers, just one group in the center would have been better.
Why would you want to catch it? What's your plan once its caught? Recover somehow? How exactly? Report it to some monitoring service? How you going to do that if you don't have any memory left to even form the report? You can't recover from an OOM. Its an OS kill signal. The process is dead, may it rest in peace, and nothing can bring it back. "Recovery" and reporting is the job of the supervisor. Recovery involves restarting the process/container/whatever. 
Those src, pkg and bin directories are not really your project directories. It just something Go needs/expects (it will actually create the bin and pkg directories for you) in the location the GOPATH env variable points to (which defaults to $HOME/go). You create your project root directory in src and structure what goes in that project directory any way you want. Here's a blog post that might give you some ideas: https://medium.com/golang-learn/go-project-layout-e5213cdcfaa2 
If you suspect your application is leaking memory or similar, don't wait for it to OOM your box before your start profiling.
I think the best I can suggest is to [regularly collect heap-profiles](https://godoc.org/net/http/pprof). You might even be able to do that in production. You *could* then dump these on a large enough storage for a while, so that when your server OOMs, you can analyze the most recent collected heap profile. Or try and analyze it directly and store the relevant information in a more compact manner. It's not a trivial problem, sadly, and I don't think there are good off-the-shelf solutions, that I know of. I don't know anything you could use to analyze, e.g. a coredump. If delve is able to use them, it *might* be usable for this, but I doubt it. Sorry :-| OOMs suck.
Honestly as I'm quite new to golang, I expect this will be some beginners mistake :) Nothing really interesting...
This is an excellent post
I don't have any circular dependencies. I just call remote API and I request more than needed because it's much more efficient. So I need to cache the results. Just decode json and cache 5k items. Next time the same. I couldn't imagine there are some circular dependencies. In your case (I don't know if I understand it correctly) - there were dependencies between the items in cache? So removing one item from cache didn't mean it is removed completely as other item was referencing it?
Is there a web page for Utah Go meetups?
[previously](https://www.reddit.com/r/golang/comments/9c7w40/a_critique_of_the_go_generics_proposal/). 
The thing is, that these proposals are so, _under_whelming. I mean, is this what we've been waiting for since Go 1.0? The official proposal just feels like the standard Java generics (with the one good thing that it doesn't have to be backwards compatible with old bytecode), with an implementation defined detail that it can be inlined. But the big loss would be the "One and only one way to do things". The special thing that Go does very well, much better than any other language, is that it tries to force a consistent style for everything, and while you _can_ force it, it'll be such a kludge only most dictatorial PM would argue. So, for example, what is the "canonical" way to loop over integers in Kotlin? You can write a for loop `for(i in 1..100){`, or a `(1..1000).forEach`. They'll both work, and they'll be equally fast. But while one PM loves for loops, and insists on for loops, another loves functional programming and push that. Go, on the other hand, is designed that you simply must use a for loop. And while you can[1] create a `map`, `zip`, `reduce`, and `forEach` function, it'll be so ugly (and slow) that you have to be a masochist to avoid a simple for loop and go functional. Now the thing with generics is that it's possible to implement it only for passing through (useful to implement generic containers, but not the whole shebang). So you can create a function like func NewContainer(T Type) (v T) &amp;Container(T){ } If you _really_[2] need something. But even then, it'll be cheaper to stick with native types (you don't need a function call to access elements). [1]. I'm almost positive Rob Pike did just that. [2]. Even then, there's still a risk of fragmentation, that you'll have half the libraries working with slices, and the other half with some kind of custom types, such as immutable arrays or whatever.
You should at least take a peek at Go Modules support in 1.11 which will make Go act more like you are used to.
For readability, I would put these "assertion" in a \_test.go file.
I recommend the following: https://github.com/golang-standards/project-layout
* whom'st'd've'nt
I didn't mean for my comment to be disparaging - I meant it as legitimate advice. As the original comment in this thread points out, if you're OOM, it's almost certain to be impossible to allocate additional memory to produce cores or similar, and they likely won't tell you anything useful anyway. It may not even be your process that caused the OOM condition, but if you suspect (or know) it is, understanding your application's behaviour ahead of time is the only way to deal with it.
No problem, text can be an imprecise medium. The best answer I have is still to profile before you hit OOM - you can't fix your code without understanding where you're allocating memory. And it's typically too late once your application is killed because you need heap data in a form that can be analysed by the language tools, and that requires runtime cooperation.
This is a really poor argument. For starters, you have no way of knowing whether adding generics will actually produce your fears. Yes, new containers will be created, but they will most likely be created to fill missing functionality: Sets, Queues, etc. Why would anyone recreate a slice as a container when the former already exists and works? And since you are clearly against such new containers, you apparently have no need for them, so why are you against other people having them when they are needed? As for functional iterator functions, they have their place. I have my doubts that they will be created, since the proposal itself doesn't allow for generic methods. Then being ugly is very debatable, and if they are slow, no one will use them anyway. Finally, no one is going to be rewriting any existing codebases to integrate them if they spring up, because why would you?
changeme Hash from bcrypt when creating password: \`$2a$14$lQ9m7c3HCxtv6nTB2gdOyuNWEg8T9Y2MCGjF87Gkb6lWUREkcghpG\` &amp;#x200B; Hash in DB: \`$2a$14$lQ9m7c3HCxtv6nTB2gdOyuNWEg8T9Y2MCGjF87Gkb6lWUREkcghpG\` &amp;#x200B; Hash in Model: \`$2a$14$lQ9m7c3HCxtv6nTB2gdOyuNWEg8T9Y2MCGjF87Gkb6lWUREkcghpG\` &amp;#x200B; I'm storing them all as VARCHAR(100) in the DB.
I only added this once I read someone having a similar issue on Stackoverflow and someone suggested this - I've removed it now but same issue.
I'm storing them in VARCHAR(100) field.
I'd add to what u/Merovius said, that [recently it was mentioned](https://blog.golang.org/ismmkeynote) that Go will likely to have [special means](https://github.com/golang/go/issues/16843) to notify the running application about memory pressure it's experiencing so it could [put backpressure onto its clients or start to shed load](https://ferd.ca/queues-don-t-fix-overload.html). As to monitoring, I'd note that for Go applications, it's almost useless to monitor RSS (the only sensible measure of memory which can be taken "externally") as the Go's GC do not return the freed memory to the OS immediately but rather keeps it for itself for some time (like, ISTR, 5 minutes), and after that it starts marking the free pages as "okay for being reclaimed by the OS". All these pages still count as part os RSS, so the only sensible metrics are those provided by `runtime.MemStats`](https://golang.org/pkg/runtime/#MemStats)—especially its `HeapAlloc` metric. (`HeapIdle` is what was collected but not "returned" to the OS by marking as explained above; `HeapReleased` is what was marked as such but not actually reclaimed by the OS.) IOW, in production, one should instrument its service to periodically collect the memory stats of its own runtime and somehow make them available for the monitoring service in use. ---- The bottom line is that you first need to identify whether you have any direct leaks or woefully ineffective data handling; once you've identified and fixed such cases, the only thing you can do against memory exhaustion is _quenching the rate of the data you are handling._ Exactly what constitutes the "data rate" is a complex question (as it depends on the nature of the data and the way you handle it) but you need to at least start somewhere. [Memory profiling](https://blog.golang.org/profiling-go-programs) is a good starting point. Also see [this](https://dave.cheney.net/2014/07/11/visualising-the-go-garbage-collector). And try to make yourself acquainted with how the Go's GC works by reading, in the indicated order, these pieces: 1. https://making.pusher.com/golangs-real-time-gc-in-theory-and-practice/ 1. https://golang.org/s/go15gcpacing 
You might have used the varint encoding?
Yep I decided to do benchmarking. Will post results here. :)
[removed]
Before your run OOM the kernel will most probably page out parts of your process. It then runs so slow that you can't do anything. You get your OOM a lot later than that. At least it will not crash the OS so if you have a process monitor it will restart it. But you have a way bigger prbolem then.
We’ve been adopting github.com/oklog/run for managing multiple internal services and signal handling. It’s really helped to organize the setup code and make sure things gracefully shutdown.
I think I have read most Go generics feedback posts and there seems to be some consensus in removing contracts in favor of some short of built-in interfaces (or pseudo-interfaces, or typeclasses). I wonder what's the opinion of Ian and the rest of the Go team on that. Has this ever been discussed in some issue or golang-dev thread? Is there any important drawback of this approach?
It's nice to see that I'm not an outlier in this. The current proposal lacks clarity and finesse. What I keep coming back to is the solution-focused approach Go seems to champion, and how current ideas for generics all seem to bypass that in favour of a more problem-focused one. A lot of the time, asking "what are you trying to do" when someone wants a generic something-or-other reveals that they're breaking the YAGNI principle, and that the non-generic solution would be a lot quicker. This is not a case that generics need to address, in my opinion. This is a matter of general programmer knowledge. Really, the first priority (and possibly the only one needed) is to design a system that makes every built-in function non-magic in as uncluttered a way as possible. I think that may actually get us most of the way to a working solution.
we are looking to implement backpressure in service so if OOM happens it will return 503 to the upstream caller to retry later. we have tried memory and cpu profiling using ```pprof``` but were wondering if go has memory and CPU dump automatically dumped to analyze later in cases of OOM.
all good points! thanks!
Yep, that is what I did. Fair enough :) Depends what you're after then I suppose, as I think you're already aware at this point. The `strconv` route is probably a little slower, but is also probably easier to work with, less code, and easier to read.
go 1.12 will include a test implementation of contracts without any changes whatsoever :)
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [how to add string in existing variable of an array](https://www.reddit.com/r/programming/comments/9dub1f/how_to_add_string_in_existing_variable_of_an_array/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Does Go have a 'dump heap on OOM' like Java? And then a tool to inspect the heap and references? If not, it should... very useful tool for debugging OOM errors. Java doesn't have global vars. so understanding who holds what is a little easier, but it is just as easy to create OOM in Go as it is in Java, and any robust platform needs tools to identify and correct it. &amp;#x200B; In lieu of that now, you need to do what others have said, and periodically pull heap dumps and analyze them before the OOM occurs.
This was posted 5 days ago [/r/golang/comments/9c7w40/a\_critique\_of\_the\_go\_generics\_proposal/](https://www.reddit.com/r/golang/comments/9c7w40/a_critique_of_the_go_generics_proposal/)
Is RPC the best option out there for inter-server communication? Are there any alternatives to compare it to?
[removed]
&gt; https://github.com/golang-standards/project-layout Thanks for the link! Been using it "professionally" for years now and my companies standards were vague on many fronts. Will be glad to use this as reference!
Sorry, but no. If we add some kind of "special" interfaces we would have to either enable operator overloading (equality, comparable, etc) or face the fact that we cannot implement those special interfaces, which is very bad thing from type system perspective. There is lot to work with this proposal, but one thing it does good is that it doesn't break existing assumptions about interfaces. Syntax could use some work but because interfaces in Go are actually types themselves I'm strongly against using them in their current form for parametric polymorphism. 
How are you a spammer?
I recommend the third way or second way if you are loading a lot of requests, but benchmark it. The first is the easiest and most general purpose but depending on your requirements it may not be fast enough. 
&gt;github.com/oklog/run That looks ok (pun intended), though I still don't understand the aversion to just using context for managing lifecycles.
Instead of keeping pointers in someStruct and pointers in the array: 1. make array entries someStruct 2. use indices (offsets) instead of pointers in someStruct &amp;#x200B; `type someStruct struct {` `children []uint # Indexes.` `}` &amp;#x200B; You look up a child by its index in `globalVar`. This way GC is not overwhelmed with references. Do profile this though, know the cost. &amp;#x200B; &amp;#x200B;
I have to say, The multitrack was a bad idea, if not for the fact alone that many times people would pop into a room, decide they were more interested in another topic, and pop out, which I can imagine was very distracting, at the very minimum apparent, to the speakers. You also forced attendees to be in this position in the first place, which makes the attendee also uncomfortable in this scenario. Please don't do multitrack again next year -- it's better for the speakers and the attendees. It gives the speakers the full audience, and it allows the attendees to not be in awkward positions.
&gt; Go developers watch videos like Gary Bernhardt's Wat and feel smug. Some of them do. Some people recognize that video for the pure idiocy it is. We call that second group "professionals".
Thanks :)
For configuration, I highly recommend github.com/spf13/viper
Gary Bernhardt is definitely a professional. It was jovial in nature, designed to highlight some corner cases and create a deeper understanding of the internals, just like this talk was. Just having a little fun.
Isn't viper for reading configurations from files such as jsons and the like? Thats not the issue I'm having, my problem is that I receive say 2 or 3 flags through the command line and these change the values my functions will be receiving. So instead of passing to each function 3 string parameters, to put an example, I wrapped those parameters in a sort of "context" structure and I'm passing that around to my functions. Now my issue is that they are all receiving this same structure, and I don't know if this is the best way to do this or if theres anything wrong with what I am doing.
The article linked from the README provides a nice overview of what it's for: https://www.anishathalye.com/2017/06/04/testing-distributed-systems-for-linearizability/
Why pass the whole struct around? If you have long lived values required by a function attach that function to a struct with only the values it requires. Then create this struct in your setup code and pass it around (possibly by placing it in other structs with functions attached). As well as just passing in the values to some of the simpler functions when you call them. This way each function as access to the values it needs that are only loaded once at the start of the program (or possibly via other means if required) rather than the entire config struct. The big advantage of this over passing around a context object is that it is clearer what each function requires to run and you can more clearly follow where each value is used in your code base. A single config object can make it very hard to see when you no longer require a config value or easily tell everywhere that it might be used from your main function.
Btw you can also integrate flags into your confit with viper afaik
See my comment below, I misclicked, sorry 
Yeah, these are nowhere near the level of a wat. Let me refresh your memory of Javascript wats: &amp;#x200B; \[\] + \[\] = '' \[\] + {} = '\[object Object\]' {} + \[\] = 0 {} + {} = NaN Array(16).join('wat' - 1) + ' Batman' = 'NaNNaNNaNNaNNaNNaNNaNNaNNaNNaNNaNNaNNaNNaNNaN Batman' 
And you’re comparing them using the bcrypt compare method?
Nobody talks about adding operator overloading - that was my point. But without it, it would be impossible to create required constraints with current interfaces for generic collections (which original design document touches), like check for equality for both user defined types (which do not support semantic comparing using ==) and built-in types like int which do not have methods defined on them. As a quick example try to think a generic collection which would work for both builtin types and your custom struct which contains function pointers as fields ;) The best thing about current proposal is that it doesn't change existing interfaces and their semantic - this way we can guarantee backwards compatibility in all possible senses. As your point about append and make builtins - they are ad-hocs but could be made generic facilities quite easily. Passing types as a "function arguments" have a strong resembles to what we have today with append and make. 
One way is to copy them to each struct, with one or two this is easy enough, more than that and you can create a wrapper struct that you can embed into each other struct. Much like your original context, it needs to be copied around everywhere, but at least now you are only copying around what is actually required by everything and not copying everything everywhere. Aim to keep this struct as small as possible. But you may also consider globals the few values you have that are truly global, it is fine if you only have a few and they are truly global objects, like loggers. But for everything else you should pass around as function arguments or in structs.
It really does look good with just the one. https://i.imgur.com/u98vS9K.png
Yes
&gt; This is a really poor argument. For starters, you have no way of knowing whether adding generics will actually produce your fears. Sure we don't. But it is a _major_ language change, and reading what people want from Go, it looks like it will go in that direction. &gt;Why would anyone recreate a slice as a container when the former already exists and works? Because they can now make a `LinkedList`, or an `ImmutableList`, or an `Iterator`. &gt;so why are you against other people having them when they are needed? If I wanted options and freedom, I'd use C++. &gt;Then being ugly is very debatable, and if they are slow, no one will use them anyway. Unless someone decides that it's worth sacrificing speed for immutability, or because, well, _reasons_. And I don't think that generic code is inherently ugly. I just think that Go 2.0 will either be different enough of a language that it might as well change its name (like a C++ -&gt; Rust "upgrade"), or be a hodgepodge of styles with lots of backwards compatibility warts (C -&gt; C++). 
thanks for the imgur link! I'm sticking to the "old" UI and saw no banner
Ooh alright I think i got a much clearer picture of what I need to do, thanks for the advice I'll be getting back to coding this has been of a lot of help!
Ian has weighed in on this idea in the golang-nuts mailing list, where there's a lot of other good discussion on this as well. There are definitely a fair number of people who are in favor of this interface-based approach but there's still a lot of open discussion about how one could use interfaces to enforce the ability to use operators (==, &gt;,&lt;, etc) on a type. That's something contracts can enforce already. It seems that Ian is not yet convinced by those saying that contracts are too complicated or too unreadable to warrant a change to interfaces, but there's a lot of healthy discussion going on. I encourage you to check it out yourself and see what you think.
These are my slides for the Denver GopherCon 2018 Kickoff party. It specifically talks about some patterns to decouple your code from the target platform (using AWS Lambda as an example) to make it more portable and testable in serverless/hybrid deployments. Feedback most welcome!
Show me the code used to compare. It should work flawlessly.
UberCool! This is a great idea.
Do you think you're going to get language-unbiased answers on a language-specific subreddit? That's the real question.
I think you're not asking in the best place if you want an impartial answer. &amp;#x200B; I'd say that based on your limited description, Go is perfectly capable of doing the job and would be a great choice. I can't say whether it would be a better choice than Rust because my Rust is very poor so I'm not really qualified to say.
Which ever language you use, remember to fuzz your implementation.
So OOM happens when you're under load due to legitimate resource usage and not a leak? If that's the case, why don't you use resource pooling to ensure you never use more memory than available? For example, if you limit the number of connections using a channel-based pool ([https://stackoverflow.com/questions/22625367/how-to-limit-the-connection-count-of-an-http-server-implemented-in-go](https://stackoverflow.com/questions/22625367/how-to-limit-the-connection-count-of-an-http-server-implemented-in-go)) and you got your backpressure. Similar solutions can be used for worker queues etc. If you don't know the size of each individual "task" (e.g. memory required by a single HTTP connection), it becomes harder but what I'd personally do is make sure memory usage is bound anyway with constant-size buffers (for example by not loading large files into memory but processing them in chunks, using streaming parsers etc.).
I've been to 3 GopherCons. Two earlier that were single track and awesome, and one multi-track . &amp;#x200B; I've been to a dozen or so enormous conferences for Microsoft, Google and others - that are all 100% multi-track. So this "missed sessions" is nothing new. &amp;#x200B; However, what bothers me about GopherCon being multi-track is that GoLang always felt JustRight(tm). Not too big of a language, not too small. Powerful. Perfect. The single-track conference followed this same feeling. You can gleen a sense of completion knowing you can take it all in. &amp;#x200B; However, when they went multi-track, it feels now that we are missing out on parts. "Oh, I'll watch it online later" I tell myself - only to forget all about it. Some I have looked up and watched later on. But it's just not the same. &amp;#x200B; I will not be returning to GopherCon again as long as it remains multitrack, at least not out of my own pocket.
https://gist.github.com/chrisgreg/bf83aa439ee2ec631e57e5e59c244595
ooh, only slides? But we want to see your first talk!
You probably want to use a mutex to restrict access to the connection to only one goroutine at a time.
Thank you. Newish to programming and golang in particular.. all I need to do for that is this? var mutex = &amp;sync.Mutex{} Then in goroutine I do this? mutex.Lock() conn.WriteJSON(torrentlistArray) mutex.Unlock() I have around 10 other commands that do NOT run in a goroutine (since they do not tie up IO much at all), so do I only need to mutex lock this.. or any time I run conn.WriteJSON?
Going to chime in to say that how you do it matters a lot more than what language you use. Any decent protocol should have a specification that includes the protocol grammar (in appropriate EBNF format). Most modern parser combinator libraries can take that and spit out a performant, verifably-correct implementation regardless of the language you use. Go has `Marpa` and Rust has `nom`. Remember: You can't get arbitrary execution exploits if your parsing engine isn't Turing complete. Context-sensitive grammars ruin this property, but research is ongoing on how to tackle even that problem.
I tried to sign up to check what this is about, but got stuck. After login I am sent back to the home page, and after clicking "Enter kingdom" I am sent back to the login screen, and over and over.
Hah! Well, there is technically a video, but it's [of the entire event](https://www.twitch.tv/videos/302697340##) My talk is right at the end, starting at ~2h:59. 
I'm on mobile (Android). Tried Firefox instead of Chrome, same issue.
[removed]
A more idomatic Go way would be to create another channel that accepts json, while a go routine that read the channel and writes the json to the conn - then all output generators just send the json to the channel...
Go aside, this is a very good summary of the ecosystem surrounding X. 
But if I can do this [https://play.golang.org/p/oy09p9t0m5D](https://play.golang.org/p/oy09p9t0m5D) why can't the compiler just do this for me? &amp;#x200B;
This is a great read! I’m excited for this project, and to help if I can. 
I am hyped at least there is a good GUI framework
BabyPeter and AdultPeter have the same identity: that’s precisely my point! They have different _capabilities_, which is why a separate axis of classification—time, or version—is valuable.
You could probably easily write this yourself.
I actually just forked a pretty good starting point that I can use for this and contribute a few changes to at the same time. [https://github.com/rakanalh/scheduler](https://github.com/rakanalh/scheduler) 
There is a major problem with your design I think, and that multiple instances of the scheduler pointing to the same db will executes the tasks more than once. Systems like Quartz offer a queue - where the execution can be controlled, because typically if you want task X to execute every N seconds, you don't want it to execute multiple times.. so the locking and task retrieval/execution is a bit more sophisticated I think.
&gt; I've come to the realization that I really only ever create one variable of configuration struct so is it a type of singleton or am I mistaken? You may only have one instance of this struct when the code is running outside of tests. I expect you would create many different versions of this struct when you are testing the application, since it is used by many functions, and most functions will have at least one test. Making code easy to test is important, which is a big reason not to use a singleton. A singleton is a very specific pattern where you can only have one instance of it per process: https://en.wikipedia.org/wiki/Singleton_pattern. Over time the requirements of the program may change and you might find out that you need to create multiple instances of the struct. &gt; I've got a structure I'm passing into all my functions, is there a way to circumvent or reduce that? If each function uses all or most of the fields in the struct (and assuming the functions are well structured and don't have a bunch of duplicate logic) than I think that sounds just fine. If you find that some functions use different fields you probably want to create more structures. Instead of a single `struct` with all the fields, find groups of fields that are used together a majority of the time and seem to be related in some way. Then change the `Config` struct to have fields with the type of the new structures you created. This way you can pass around those smaller structures to the functions that need them. 
yes, until now go is the best choice for network things, rust is still on its way to async/await
Generally solid suggestions. &gt; Why pass the whole struct around? If you have long lived values required by a function attach that function to a struct with only the values it requires. I don't understand this part. Why would this ```go func (s mystruct) DoThing() { ... } // s.DoThing() ``` be an improvement over ```go func DoThing(s mystruct) { ... } ``` They are effectively the same thing, with a slightly different implication. The method implies the functionality is a behaviour or dynamic property of some type, where as the function implies the struct is data required to perform some operation. I think both have their use cases, however if the struct really is configuration the function is probably more correct.
Generally solid suggestions. &gt; Why pass the whole struct around? If you have long lived values required by a function attach that function to a struct with only the values it requires. I don't understand this part. Why would this ```go func (s mystruct) DoThing() { ... } // s.DoThing() ``` be an improvement over ```go func DoThing(s mystruct) { ... } ``` They are effectively the same thing, with a slightly different implication. The method implies the functionality is a behaviour or dynamic property of some type, where as the function implies the struct is data required to perform some operation. I think both have their use cases, however if the struct really is configuration the function is probably more correct.
So why not just use https://github.com/kitech/qt.go ?
Just noticed this in the readme: &amp;#x200B; \&gt; go get -u github.com/skx/deployr \&gt; go install github.com/skx/deployr &amp;#x200B; `go get` already does a `go install` under the hood, and so the second line is not strictly required.
As somebody who has used qt.go and also used Qt in C++, it is a huge pita to build and use.
That last one is definitely the WAT-test of them all :) package main import "fmt" func main() { true := false fmt.Println(true) }
I don't understand what that has to do with anything. You are not actually using an `[]*MyType` as an `[]Ider`, you are constructing a new `[]Ider`. The two don't share any relationship, so of course that's type-safe. But slices are writable, so to *actually* just use a `[]*MyType` as an `[]Ider`, you'd also need to do this: https://play.golang.org/p/TQiEryy6yn1 -- but that isn't type-safe, because nothing is preventing the callee to instead to this: https://play.golang.org/p/doqolXZbFZL To make slices covariant, you'd need to either a) make them read-only (the Haskell choice and essentially what your code is doing, by making the function operate on a deep copy) or b) not be type-safe, i.e. have compiling programs that type-check but panic at runtime (the Java choice and essentially what my code is doing). So the answer for why the compiler can't do what you asked is: It could, but that's not "using a slice of concrete types as a slice of interfaces", it's "converting a slice of concrete types to a new slice of interfaces" (in particular, it allocates a new slice, copies the values from the old and potentially allocates N objects on the heap in the course). *That*, on the other hand, would be possible, but it has other downside. For example code might suddenly break, even though you only changed a concrete type to an interface (because the code relied on slices being read-write and suddenly they became read-only, because the function was operating on a copy). Also, it means that `x = T(y)` might now be an extremely expensive operation, incurring `N` allocations, generation of wrapper-methods and the copy itself. Making expensive operations look cheap is not very Go-ish.
PHP, no. Python, no. Given Google’s track record they might give up on it and focus on flutter and dartlang. Cloud flare said they basically hated it, but now they use it so I don’t know what changed their mind. 
Because it's LGPL and if that does static build, we'll then be prepared to also ship proprietary sources to whomever you distributed your binaries.
Interesting, but their website has terrible grammar and a few typos.
&gt; Do you believe in 10 years or so it can completely replace PHP and Phyton? If that happens, it'd be unintentional ;-)
There are many possible futures. Go is a fantastic language with lots of popular support and adoption from several major companies. You won’t go wrong with it. Now if only they could sort out their approach to vendoring. It feels like in 3 months we’ve gone from dep to vgo to modules and I’m getting pretty fed up. 
I don't mean to sound like a hater, but coming from sourcegraph, I was expecting a better quality post. There is no educational content in this post IMHO, and no comparison to other languages that prove the programmers intuition is "wrong" (therefore a WAT). What is the basis of the naive guess? The crowd got 10/16 correct. Most of the other 6 was because the code was intentionally complicated, and is almost always not found in actual programs.
Php is already declining heavily, Go is being adopted more and more everywhere, the go repo has more contributions from non-golang team, so at this rate, even if google dropped it, the community has such a large % of contributions that theyd be able to continue it
Thank you for your reply. Array type is string. And its my bad I didn't specify it earlier that it was 2d array. Also it has many values other than **(((**, so above solution might now work. Is there any way in go to use variables inside string like in JavaScript like **\`${variable}\`?** 
modules is actually part of bringing vgo to mainstream go, and test it well. there is actually a progressing line in this work.
Well I work with php and I study golang religiously. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk After about 7 years of php inheritance and creating new files for each object it gets way out of hand. I mean really big. To the point where you have to read for at least an hour before you touch anything. Also, because of composer they made dependency files everywhere cause you don't have to keep track of file structure. Also, there are god objects that are bootstrapped everywhere cause there isn't a good way to spread it like go. Then there are apis that are so huge you can only add to them and never delete anything cause abstraction of types is really limited and hard. So whenever you want to borrow from an API you have to grab that object and just add another level of demension to it. Which I'm sure you can imagine is rough 10 levels deep. Then, since they rely on an interpreter instead of building containers cause php has a management system (go doesn't) meaning you can make errors in php and not bring down the whole system every time but that made them not use containers and used clusters of nodes connected, so when you do make a big enough error it all goes down. Cause they figured why containers? 
I think that entirely depends on the area where you are looking for work. You should do some research on your local area and see what skills jobs are looking for. In Berlin and London for example there is plenty of Go jobs and if anything not enough people to fill them.
Fuzzers are welcome. Please tell me if you can break it in any way.
Thank you!
Thanks man!
This depends on a branch that's waiting for a pull request into github.com/jzelinskie/geddit. In the mean time you can pull the branch from my repo here: https://github.com/jpclark/geddit/tree/user-comments-submissions
This a a nice talk from somebody that works as Joyent, enjoy: [https://www.youtube.com/watch?v=LjFM8vw3pbU&amp;list=WL&amp;index=9&amp;t=0s](https://www.youtube.com/watch?v=LjFM8vw3pbU&amp;list=WL&amp;index=9&amp;t=0s)
I've always used blackfriday in the past. What is the difference/advantage of your library over blackfriday?
Yes, that is exactly the problem, why should I need to do this? It is a VERY common pattern - yes, it is not efficient, although it is the same efficiency if I do it myself, (and I would hope the compiler could be even more efficient) , and I do not know why with some escape analysis it could not be very cheap - like the unsafe pointer using in the built-in map. I've only written two systems in go, and already i've have to use the 'create a new slice, copy the concrete to the slice of interfaces, in order to call the 'generic method'. It's pretty annoying... especially since the compiler only needs to create the copy and call when using a compatible concrete type. I think the read only is a fair trade-off here, and probably the most common pattern anyway - and it is only the slice that is read-only, the structs themselves are still mutable. The language syntax does not need to change, as the read-only could be enforced at runtime. Things would not suddenly break - they would break on first usage, unless you changed the method later - which is a risk of breakage in many other ways. Also, forgive me because I am new to Go, but aren't all passed slices read-only anyway - unless you return and assign them? Just like the append() method. Yes you can mutate at a particular index, and it affects the underlying array, but if the array grows, the caller would have the old copy of the values, no ? ***edit: I read your code, and see the "copy after" for the mutability concerns. I can see how this would be more of an issue. Still, then why doesn't the compiler pass an 'accessor' to the method as part of the slice parameter. In the common case it would be a no-op, in this case it would cast each reference access into an interface.
Well, it's... slower, for one thing. But more modular. It strives to follow the [CommonMark](https://commonmark.org/) specification, which tries to resolve many Markdown ambiguities and inconsistencies by providing a comprehensive test suite.
&gt; Yes, that is exactly the problem, why should I need to do this? I told you though. &gt; yes, it is not efficient, although it is the same efficiency if I do it myself The difference is, that if you do it yourself, it's *obvious* that it's inefficient, but if the compiler does it, it's not. I used to TA an algorithm class in Python and I can't count the number of times I had to mark off solutions as wrong, because they used `if x in y` and `y` was a list (which often made linear algorithms into quadratic or even cubic ones, which *clearly* is important in an algorithms class). &gt; and I do not know why with some escape analysis it could not be very cheap Again, I told you, because slices *can't* be covariant. There is no language that supports this. Escape analysis doesn't help, because it's not a cleverness problem, but a semantic one. The compiler *could* devirtualize the interface (and eventually it likely is going to) but even that requires full-program analysis and will significantly worsen compile-time. &gt; like the unsafe pointer using in the built-in map As I said, that already exists in Go and is done and it's called `range`. The "unsafe pointer using the built-in map" is only used and usable, if you use a map-type with language-provided built-ins. Those builtins also exist for slices and you use them every day. The question here is about *not* having that built in and write functions that can operate on slices covariantly. &gt; I think the read only is a fair trade-off here. There is an issue to add [read-only types to Go](https://github.com/golang/go/issues/22876). If that ever happens, we can talk about making this tradeoff, but we don't have it yet. &gt; The language syntax does not need to change, as the read-only could be enforced at runtime. You can already write that using reflection (as I said above), but that's not type-safe, which is exactly why this request exists. &gt; Also, forgive me because I am new to Go, but aren't all passed slices read-only anyway - unless you return and assign them? Slices are read-only, but they are read-write references. You can modify the values they are referencing, which is the problem. It's not modifying the slice that's the problem, it's modyfing one of its elements. &gt; Yes you can mutate at a particular index, and it affects the underlying array, but if the array grows, the caller would have the old copy of the values, no ? Yes. Which is why making a copy is okay. But that's not the request, the request is specifically about sharing the elements. --- Anyway, this is repeating itself. Hopefully generics will finally make these discussions die :)
The present and future of web programming is most of the logic implemented in JavaScript frameworks like React or Vue, with the server implementing only a thin API layer. For systems programming you need non-garbage-collected languages and I expect C, C++ and Rust to dominate. I would expect Go and Julia to replace Python, but I know from experience the superior technology does not always prevail. As for PHP, the PHP community is rather idiosyncratic and I doubt it will be abandoned completely, as it has become the Visual Basic of web programming.
I'm sorry, I think you replied before my edits - understandable. What about the 'accessor' behind the scenes idea? Then it could be read-write, and efficient - only paying a small penalty by the caller when it is used. Also, my specific idea was different than "the request", and was to make a copy, since the caller is doing that in all these cases anyway when they need to call the method in this pattern. I still think having the caller know that doing this will result in panic if the method mutates the elements is a understandable restriction. Other than sorting, etc. I don't think mutating is a common pattern because of the 'array growth' issues - people are almost always creating copies and returning them, with the bulk of the functions not doing this - just ranging over the elements using the interface.
thanks
&gt; Still, then why doesn't the compiler pass an 'accessor' to the method as part of the slice parameter. Because that's not the signature of the function. The signature of the function is "I want to be able to get a mutable slice of MyInterface", not "I want some function to get a MyInterface". Functions are compiled separately - possibly accross package boundaries. The function could already express that they only need read-only access, similar to how [sort.Search](https://godoc.org/sort#Search) does it. But as it is, the type of the function is `showIds([]Ider)` and thus specifically say it wants mutable access to a slice of `Ider`s. The Go type-system simply can't express read-only accesses. The problem is that no matter what, given that the type-system doesn't allow you to express read-only accesses and given that without that, the type-system can't allow you passing slices covariantly (even if the callee only reads) in general, you will *always* have to write that code. The compiler might be able to recognize a) that the callee doesn't write to the slice and b) that the caller is allocating and copying an `[]Iter` just for that call and then do that optimization to delete the latter and instead pass a sorta "read-only slice" in the manner you describe. However, that is always dependent on the relationship between caller and callee, so it means you will always have to compile them together - when the callee changes, the caller also has to change *and vice versa* (because otherwise, if you change the caller to, say, use the `[]Iter` again after changing the original slice, it can no longer do the optimization). So you pay a *huge* compilation time penalty in the form of whole-program-analysis and losing cached builds for a moderate runtime improvement in very occasional cases and zero improvement in convenience. Just doesn't seem worth it. FWIW, generics (or resolution of that issue) could enable the type-system to express the read-only constraint and at that point, this optimization becomes a *lot* more feasible. Until then, it *may* be possible, but it just isn't really worth it for the occasional case this is useful.
I think I wasn't clear - I meant that the 'slice internals' has an accessor, so when passing a slice to a method, the accessor can do the work to present the elements in a read-write manner as the type needed. When the type is already the correct type, the accessor is a no op. There is nothing to change in existing code, you would not change any method signatures, it would be an internal implementation detail of passing a slice to method, and how the compiler accesses the elements. Yes, in most cases there would be an additional function call on every access, but the compiler could easily generate the code both ways, and use a simple branch to avoid the overhead to match the current performance. The code size would be larger in all cases. I don't think it affects the cached build state at all, or the compilation times. very pseudo code type slice struct { elements *pointer accessor func (*pointer) interface } and then internally the compiler passes &amp;slice for []interface parameters. 
Thank you. Is it true that is hard to sell your Go skills? I heard that the demand for it is rapidly increasing and the salaries are pretty high.
Subscribed right away. This website has tons of great stuff. Thanks for sharing OP
Thanks for suggesting gin. It's poorly documented, but the API is exactly what I was looking for. It can do content negotiation, too: ```go n := gin.Negotiate{ Offered: []string{binding.MIMEJSON, binding.MIMEXML, binding.MIMEHTML}, Data: result, } c.Negotiate(200, n) ```
Not that I’ve been monitoring this specific market too closely, but I would assume the majority of the Go jobs are for experienced engineers with auxilliary work experience in something like Kubernetes etc., which of course you might have - I don’t know. You are right that the demand is rising, but the pay is always based on experience, not knowledge of language alone.
Why does unwinding the stack manually lead to more reliable code? What do you think of restart systems where you don't even have to unwind the stack to recover from certain errors?
Nice! That's pretty slick.
So blackfriday doesn't follow the CommonMark spec? I had always kind of assumed that it does(?)
PS good luck with your project I hope you opt for a immediate mode API, I think they are a good solution. 
Your example is more a DSL, or Domain Specific Language, which is closer to a programming language than a data format like YAML, JSON, etc. Creating a DSL is a well studied problem but has somewhat narrow applications in my opinion. I’m assuming this is just for fun tho?
Take a look at Destroy All Software: [A Compiler From Scratch](https://www.destroyallsoftware.com/screencasts/catalog/a-compiler-from-scratch) (currently free) for hints. Yes it's in Ruby but it's really easy to change to Go. Some additional keywords for what to look for: lexer, tokenizer, abstract syntax tree.
Generally solid suggestions. &gt; Why pass the whole struct around? If you have long lived values required by a function attach that function to a struct with only the values it requires. I don't understand this part. Why would this ```go func (s mystruct) DoThing() { ... } // s.DoThing() ``` be an improvement over ```go func DoThing(s mystruct) { ... } // DoThing(s) ``` They are effectively the same thing, with a slightly different implication. The method implies the functionality is a behaviour or property of some type, where as the function implies the struct is data required to perform some operation. I think both have their use cases, however if the struct really is configuration the function is probably more correct.
I thought the same thing during my recent job search. My criteria were specific and I assumed I would have to relax them but ultimately the market was ripe. The criteria were: - Remote - Go shop - Pretty high salary requirements, having been spoiled previously by a job with a major bank I ended up having multiple offers to choose from. It was really surprising because I’m no “rockstar” or whatever. The market seems hot for a dev with Go, docker, and cloud provider experience.
I didn't think it is an argument. And is it is solvable - any of the dynamic languages do this routinely, and the type is checked at runtime. Java essentially does this, although not for primitives, but there are languages where even int is an object and so it works as expected. The compiler won't let you pass []int as []SomeInterface if an int doesn't satisfy SomeInterface, but it should let you pass []objs as []SomeInterface if []objs satisfy the SomeInterface. Here is the working Java code: public class ArrayTest { private interface MyInterface { void dosomething(); } private static class MyObject implements MyInterface { @Override public void dosomething() { System.out.println("hello"); } } private static void myfunc(MyInterface[] array){ for(MyInterface a : array) { a.dosomething(); } } public static void main(String[] args) { MyObject[] array = { new MyObject() }; myfunc(array); } } 
Was this in the States or Europe? In Europe, I’ve found if you are after a remote, you have to compromise on the other criteria. Well, I had to anyway.
Nice video, very interesting! OT: It looks like Linux but which Desktop Environment are you using? Quite nice too! (not even sure you are the video maker haha)
Well if you use FFI there won’t be a static dependency.
Modules *is literally* vgo.
These forms are just syntactic sugar (if you ignore interfaces) so pick whichever one you like the most. However, the second form is not very common in go and so more idiomatic to use the first form (I am not aware of any part of the stdlib that uses that latter form, though I believe there are some third party libraries that do). But my point was not so much over which of the above is best, but what you include in the struct and to favor more specific structs with dedicated purposes. So rather than having one giant Config struct that you pass around to everything you split it up into meaningful structs that only contain the values that the functions associated with them require. So rather than: Config { A string, B string, C string /* etc */ } func DoJobA(config *Config) { /* do thing with A and C */ } func DoJobB(config *Config) { /* do thing with B and C */ } It would be better to have JobA { A string, C string } JobB { B string, C string } func (job *JobA) DoJobA() { /* do thing with A and C */ } func (job *JobB) DoJobB() { /* do thing with B and C */ } or JobA { A string, C string } JobB { B string, C string } func DoJobA(job *JobA) { /* do thing with A and C */ } func DoJobB(job *JobB) { /* do thing with B and C */ } Or even both of these where it makes sense. Or maybe even something like JobA { A string } JobB { B string } Context { C string } func (job *JobA) DoJobA(c *Context) { /* do thing with A and C */ } func (job *JobB) DoJobB(c *Context) { /* do thing with B and C */ } Depending on what the actual meaning of A B and C are and how they related to each other (and where these are likely groups of various related variables). As in the first case you have no clue that DoJobA does not actually use B and when you have 10s or 100s of config items in it it becomes very hard to tell what part of your application is using which config items. It is about encapsulation, one thing should only do one job and only have access to what it requires. You may also choose to pass something as arguments and some as structs - whatever makes sense for the code you are writing, but you should aim to group your structs by what the methods on them require from them.
I’m in the States, but the team I ended up with is about 50/50 between North America and Europe, including US, Canada, UK, Germany and Austria.
Indeed it is. I was using Gnome for a while just because most people prefer that. Once I tried KDE everything felt so much better and it is lot more customisable.
I always like to see someone invest so much time in investigating all possible solutions to build GUI. If author of post by any chance is watching this, I think at some point he will find that BurntSushi is not that efficient. I have a simple image viewer with X11 here https://github.com/gen2brain/goiv , and compared to similar apps like feh, meh, etc. performance is much much lower, and it is not about image decoding, I also tried with imagemagick instead of Go native libs. I would really like to found out if my usage of X11 is to blame or BurntSushi.
`viper` encourages a program to treat config values as individual scalar values instead of grouping things together into structs. It also encourages hiding config in a global or in a `Viper` blob instead of being passed around as a simple struct. Both of these make a problem worse.
&gt; I am not aware of any part of the stdlib that uses that latter form Generally I guess the stdlib uses an interface, but there are still examples of structs: * all the `WithX` functions in https://golang.org/pkg/context/ * https://golang.org/pkg/go/ast/ has a few that accept a `token.FileSet` &gt; So rather than having one giant Config struct that you pass around to everything you split it up into meaningful structs Yes, I completely agree. I [suggested something very similar](https://www.reddit.com/r/golang/comments/9dvyh3/need_advice_handling_configuration/e5lino5/) before I noticed your post.
Well, gopass has some features that make it better than plain pass. Multi-key signing being the most important.
Thanks for your answer. Can you tell me about the libraries availability of Go, compared to Python? Since you're involved for 12 years, and considering the huge Python ecosystem, promoting Go so far sounds very encouraging and (to me) scary, 'cause i don't (still) have the ability to build something totally from scratch. Anyway, apart for this, please check the original post!
Is this the Marpa implementation you're referring to for Go? https://github.com/pstuifzand/go-marpa
This is an excellent talk by Rob Pike that may get you on a good start [https://www.youtube.com/watch?v=HxaD\_trXwRE](https://www.youtube.com/watch?v=HxaD_trXwRE)
That's the one.
&gt;When to use a exception or not its controversial with python. For example an http library can return a response with status code 400 if you make a bad request, but raises a exception if can't resolve a domain. Golang don't make you think about, so its better here. You got me here. While reading the exceptions part from the official documentation, i was like "wtf", because seems that there's not a proper guideline on where/when you should use them. That was confusing af. I won't quote the rest, not because is not interesting, but because is too interesting and i'll be annoying with further questions. I want to personally thank you for the time and efforts you put in this exhaustive post, it really helped, a lot. Please check my original post, and thanks again, you're a true bro!
&gt;We've seen it before with the python 2/3 split, many devs were turned off by it and ended up ceasing development in the language altogether; who knows what's going to happen between python 3/"4" Indeed, i've noted the last part as one of the strongest point to (not totally) avoid Python, now and in the future. &gt;In go, the semantics/syntax of the language are very straightforward and have not seen anything near to the level of what python has gone through. Usually there's one way to do something in go and it's usually the best way to do it. As an ex Perl wannabe dev who wrote from scratch a few modules for Facebook (2014\~ API) and so, spaghetti code, the "there's one way to do something" is really a strong point. Thanks for these infos buddy, please check the original post for my final thought. P.S. can't agree more on the "turn scripts into standalone exe" part too.
From the Go spec: &gt; The interpretation of the ImportPath is implementation-dependent but it is typically a substring of the full file name of the compiled package and may be relative to a repository of installed packages. I think that’s clearly intentional. But maybe that’s the difference: go.mod won’t be in the language spec, it’s just part of the tooling, so they don’t have to be as flexible about representation.
[removed]
This is just classic software architecture in practice and nothing to do with Go. 
This post has 0 upvotes. Put that code to work!
&gt; private static void myfunc(MyInterface[] array) { &gt; for(MyInterface a : array) { &gt; a.dosomething(); &gt; } &gt; array[0] = new Integer(123); &gt; } THAT CODE WILL NOT COMPILE, so it is type-safe. What you are referring to was if you had : private static class MyObject2 implements MyInterface { @Override public void dosomething() { System.out.println("hello"); } } private static void myfunc(MyInterface[] array){ for(MyInterface a : array) { a.dosomething(); } // array[0]= new MyObject2(); if this is uncommented, you will get a runtime ArrayStoreException } which compiles but will fail at runtime. Given Java's dominance, it doesn't appear that this has held back it's adoption, and having similar support in Go would be fairly straightforward as I described - and it would be read-write, not read-only. Yes, a runtime exception if you try to put a different concrete class into the MyInterface[] other than the source type - but not completely, since Java has inheritance, it can be a subclass of the concrete type. 
&gt;Because it's LGPL and if that does static build, we'll then be prepared to also ship proprietary sources to whomever you distributed your binaries. LGPL doesn't require shipping proprietary sources to things that link to it. It only requires shipping the .o files so end-user can relink to a different version of the library. Source: am engineer in charge of license compliance for a large corp.
I'm sorry, do you mean the l = &amp;nl ?
I only use it to [downvote conspiracy theorists](https://old.reddit.com/r/greatawakening/search?q=downvotes&amp;restrict_sr=on&amp;sort=relevance&amp;t=all), so they think the "deep state" is onto their plans.
I didn't know much about viper but after reading this I think I'll stay away you and mdaffin have been very insightful in this conversation thank you both. 
Instead of pulling out `tl` and trying to put the updated value back later.just use `(*l)` everywhere, which will operate directly on the slice.
Every time I try to use *l directly as a slice I get: type *list does not support indexing
It won't compile because Java knows that an Integer cannot be used as a MyInterface. Sorry about the CAPS. I still don't think it is giving up type safety - if you set the wrong type in a array it will be a panic - not a memory overrun issue, or anything like that - just like Java. So you get convenience and safety. Also, I am not sure how generics solve this problem. I still want to be able to write a method that operates on an slice of a particular interface, not any interface. I still want to be able to create a slice of concrete types that implement that interface, and pass them to the method. How do generics resolve that?
Note the parenthesis: `(*l)[i]` is valid, `*l[i]` is not (in this case) because, without parenthesis, the compiler will do the index first and then the dereference, and you need the latter.
[removed]
[removed]
https://play.golang.org/p/XfMpmVcoAlC
PHP is slowly decline, thank you very much. People always seem to over estimate the dead of a language, in favor of their own. PHP is competing now against NodeJS, Go, more Java frameworks, so it stands to logic its declining. There is more specific competition then in the past. Cloud platforms that support compiled language drop-ins like Go, reduces the complexity ( no more need for a dedicated server for running compiled programs )... Part of the decline are self inflicted wounds. By still working with blocking processes in a world where even normal desktop pc's are running 8 high performance Cpu Cores and where you have languages like Go and NodeJS, it hurts PHP. As somebody that programmed with PHP for 20 years, i know all the flaws that PHP has. But for getting a website project out of the door fast, PHP still rules. The issue that i personally see with Go its future, is it seems to have plateaued right now ( in my opinion its growth has slowed ). Part of that reason is the same for PHP its decline. Go is mostly competing in the same web space that PHP, NodeJS, etc are occupying. Go is also not bringing a lot of new things to the table anymore. The Vgo/Module support is a massive improvement in my book ( i HATE gopath issues under Windows ) but for the most part every 6 months it feels like nothing much is improving/moving anymore with Go. Go Plugins feel abandoned and need to rely on 3th party development to make them more user friendly. Database drivers are still 3th party. It has a build in HTTP server but does not include the db drivers, i always found that strange. It feels like Google has what they want and are not so focused anymore on growing Go. Just my impression.
I will give a hint ... PHP by itself is not slow but the way its run is slow. https://www.techempower.com/benchmarks/#section=test&amp;runid=bd2d23c9-3d8c-4b6c-b7a2-cb900ed27e95 Notice how Swoole ( PHP Extention ) + PHP can beat Go. It something i mentioned above how part of PHP its decline is self inflicted. Swoole proves that by providing PHP with a build in webserver, making it non-blocking and removes the bootstrap loading, all things that Go does, that it performances matches Go and beats it even. The issue is again, you need to rely on a small team of Chinese developers for Swoole. All i see is for PHP 8.0 a JIT engine being build and some proposal for async type non-blocking to be build in. But it does not solve the other issues like its bootstrap loading on each request. Go is also not the magic solution because frankly, it took them WAY too long to get vgo/module support build in. And a lot of things in PHP are a few lines of code, where as Go forces you to almost to write half a book for the same effect. Personally i am keeping my eye out on Crystal ( crystal-lang.org ) but it takes some getting used to the Ruby like syntax ( its like looking at the devil from a PHP developer perspective and Ruby *lol* ). I find the way the crystal team combine static and dynamic interesting because you get best of both worlds. Its growing faster then i expected when looking at the crystalshards.xyz but yea, the syntax feels so ruby like *shivers/ Google is kind of dropping the ball with the slow direction they are taking Go. I hoped that they planned on reducing some of the syntax overhead and clutter but no, ...
Interesting! what happens if the connection limit exceeds? does this implementation return 503 to the caller? or it wont take no more connection and returns error. 
You usually have a lexer, a parser and then you generate an ast. It's actually pretty simple and the theory pretty interesting. The lexer is usually a regular automaton, the parser a stack-automaton and the ast is a simple tree data structure. All basics. You can create some really cool procedural automatons in Go. Rob Pikes talk on this is highly recommended. 
This looks way easier then it should, thank you
I don't think so. See https://github.com/russross/blackfriday/issues/114
Alright; thanks for the clarification!
Experimentation is great, but please don’t encourage any use of hand-rolled protocols. Protocols are harder to get right than things like NaCl itself. For example, this code is vulnerable to replay attacks, where a connection can just be replayed entirely the next time the same password is used, and is not a valid implementation of io.Reader, because it relies on the size of the buffer being exactly what the other side sent. Fixing the above is not simple, it requires handshakes (which in TLS are subject of academic proofs), framing for variable record sizes and buffering to handle timeouts. If TLS can work for you, please use it, otherwise, consider the Noise framework.
maybe gherkin/cucumber could work for you? https://github.com/DATA-DOG/godog/blob/master/README.md
Migrated to BitBucket: https://bitbucket.org/golang-commonmark/
Good content, thanks! If I may offer a suggestion for future recordings, it would be to use an external microphone, or at least an external keyboard, to get rid of the distracting keyboard noise.
jrwen probably does. That line (l = &amp;tn) is the one which doesn't do what you want for the reason jrwen describes. It changes the value of the local variable l, but not the called variable. Passing in a \*\*list is fine in Go, though you'd need to name the type in order to add methods to it. But when working with slices it's easier to pass the slices by value and return the new slices, like the built-in append() does. Lastly shift operates in-place mutates the list), while delete does not. I'm not sure why. If that was accidental then delete() can just be \`return l\[:len(l)-1\]\`. Do be careful about copies, though. The using unused capacity in different ways in copies will collide.
You can do a very similar thing in Go, you just use a form of inheritance \`\`\` type Stmt interface { } type If struct { Stmt } \`\`\` [https://medium.com/@simplyianm/why-gos-structs-are-superior-to-class-based-inheritance-b661ba897c67](https://medium.com/@simplyianm/why-gos-structs-are-superior-to-class-based-inheritance-b661ba897c67) Now the issue is, Go doesn't have generics the same as C++ or C#, which means you can't have an array of Stmt that might actually be If's or Block's
Go does not have a concept of inheritance, although it does have something that kind of works similarly, at least in one regard. The bottom line is that you'll have to structure your code a bit differently. Here's a quick overview. In general, inheritance serves two different purposes, providing common functionality to subclasses and providing subclass polymorphism. Go has no real direct equivalent for the first, although struct embedding appears to be similar at first glance. In actuality, though, that's are only mild syntactic differences between that and just having a named field of a type. If you want to provide functionality to multiple types, see if you can split that functionality out into its own type or function, and then just use that from the other types. You'll often find code becomes much cleaner once you're used to doing this, even in other languages. For subclass polymorphism, Go provided interfaces. I won't explain the basics of their syntax, as I assume you know that already, but with proper usage interfaces are a much cleaner way to implement this feature. One key design tip is to attempt to design your interfaces from the location that they're being used, such as in function definitions, rather than the other way around. Once you've done so, see if there are any standard interfaces, such as `io.Reader`, that would make sense there, as that'll make your code more easily compatible with other libraries. Good luck. If you have any specific questions, feel free to ask and I'll attempt to answer them when I can.
I tried to use goland but always come back to vscode. Goland interface looks bit cluttery to me. I know goland has lot more features but vscode has all the basic ones I need.
When programming languages compile down to machine code (raw binary instructions, not interpreted like in Python), there's no direction back "up" from there except to disassemble the program, into assembly code. That's about the best you can get, and the assembly code you do receive is hardly human readable, and definitely wouldn't have been written that way by a human on purpose. No useful names or comments or structure and the logic is so low level it's basically impossible to make sense of. Disassembly is enough if you're trying to crack a game that is trying to check if it's CD is in your drive. You can track down the section of the assembly gobbedlygook that checks that and dummy around it. But for making large scale modifications or trying to understand the program? With just a disassembly, this is an acceptable level of "difficult" to do. When your program is written in Python you don't have a chance at making the source code hard to access and understand.
There is a presentation mode where it makes it have a very simple interface and you get to keep all the awesome shortcuts.
&gt; but given your example, how does it prevent the Bar implementation from breaking the array as well - since Bar() could create a Foo that is not a MyConcreteType (some other thing that implement Foo) and put it into the slice? I don't understand the question. It does it in exactly the same way as it detects that this is illegal func Foo(s []string) { s[0] = 42 // Type error: can not assign int to string } In exactly the same way, the compiler knows that func Foo(type T) (s []T) { s[0] = 42 // Type error: Can not assign int to T } It's only possible, if you specifically tell the compiler that it *should* be possible: contract intable (v T) { v = int(0) } func Foo(type T intable) (s []T) { s[0] = 42 // legal, as per the contract, int is assignable to T s[0] = "foo" // illegal, as the contract does not // mention that string is assignable to T } That's just how types *work*: They specifically whitelist what's allowed. &gt; And how could the compiler ever detect/prevent this, as Bar() might call some other function that generates a Foo, and try to that result into the slice.. It can't. It can only pass the slice to generic function that takes a slice with the same (or a superset of the) contract. I.e. unless the compiler can prove that its a legal operation, its prohibited. --- Anyway. I'm honestly done here, now :)
In Go OOP concepts are used sparingly. Try to stick to Proceudural-Programming.
I think I like GitLab better: https://gitlab.com/golang-commonmark/
[removed]
[Participle](https://github.com/alecthomas/participle) was designed for exactly this kind of situation - that is, to allow any developer to write their own parser with relative ease. I've written up [an example parser](https://gist.github.com/alecthomas/a51b86b6b1d0a66393b2d3e75a6dae76#file-parser-go) that you can take a look at to get a feel for how Participle solves problems like this. Full disclosure: I am the author of Participle.
🙄 The acquisition hasn’t actually happened yet. Have you tried reaching out to support?
I've clicked that link and sent them a what-the-fuck message, like, 9 hours ago. I'm not expecting they'll reply any time soon, if at all. Anyway, #movingtogitlab
Using channels you decide when acquiring a connection token using select. You can block indefinitely (not a good idea), you can block using a timeout or fail immediately. And, yes, 503 if that happens.
I don´t think so because the default behaviour is to follow pointers and insert the values, so you need to be more explicit I think to optimize the output. Look at this example, it seem to work both ways as but causes redundancies in the json. [https://play.golang.org/p/wkFyVEevcYZ](https://play.golang.org/p/wkFyVEevcYZ) &amp;#x200B; PS: I´m a newbie as well. So I might have missed something. &amp;#x200B;
I'm sorry, but you need to read more clearly. What you had described previously will not work - for the same reasons it doesn't work in Java. You changed the aspects with this post. Go back and read the previous. Take some time, you'll realize, but yea, I'm done here too.
Take off your C# hat, put on the C one instead. Suddenly everything becomes clearer.
IMHO, a job description that fails to even spell the name of the language one is expected to work in is telling enough to walk away.
IMHO, a job description that fails to even spell correctly the name of the language one is expected to work in is telling enough to walk away.
Well, it is Sunday. Managing massive amounts of user-generated data is a hard problem. don't know what happened, but you're bound to have some false positives no matter what you do. The important bit is how you deal with it when you get a false positive.
Cool! I've actually been looking for exactly this. I ended up using go-swagger to describe my models and generate Go code from them, but it's only Swagger 2, not JSONSchema, and a bit crappy. One thing that go-swagger does that I like is that it generates unmarshalling code that validates the struct afterwards (required fields, etc.). Another thing I don't see in your code is any custom deserialization code to catch undefined fields (which Go's unmarshaller doesn't do). It's also be great to use the "description" fields from the schema for the generated Godoc comments.
You are mixing arrays and collections - they are different in Java. I think we got off track. All I wanted was to be able in Go to pass \[\]concrete to a method that takes \[\]someinterface when concrete implements someinterface. You said the current generics proposal will allow this. To be clear, even in Java I can't do this with collections - it must be arrays. This code does not compile: &amp;#x200B; import java.util.ArrayList; import java.util.List; public class CollectionTest { private interface MyInterface { void dosomething(); } private static class MyObject implements MyInterface { @Override public void dosomething() { System.out.println("hello"); } } private static void myfunc(List&lt;MyInterface&gt; array){ for(MyInterface a : array) { a.dosomething(); } } public static void main(String[] args) { List&lt;MyObject&gt; list = new ArrayList(); list.add(new MyObject()); myfunc(list); } } but this code compiles fine, and will fail at runtime: &amp;#x200B; public class ArrayTest { private interface MyInterface { void dosomething(); } private static class MyObject implements MyInterface { @Override public void dosomething() { System.out.println("hello"); } } private static class MyObject2 implements MyInterface { @Override public void dosomething() { System.out.println("hello"); } } private static void myfunc(MyInterface[] array){ for(MyInterface a : array) { a.dosomething(); } array[0]= new MyObject2(); // this will cause an ArrayStoreException } public static void main(String[] args) { MyObject[] array = { new MyObject() }; myfunc(array); } } &amp;#x200B;
Yeah it currently only generates types not functions. The description is used as comments.
In addition to the good advice here, I'd also suggest looking at the [go/ast](https://godoc.org/go/ast) library for inspiration.
You could have an array of type Stmt and then type cast when iterating.
I signed up but saw there's currently no content other than an introductory blurb lesson. How often will you be adding content? What sets this apart from other go online tutorials?
I know, this is why it's stated as naive and incomplete in the README. About the field descriptions, that should be an easy patch.
So mtr but with emojis?
&gt;Ping is for latency, mtr(traceroutes) it for hop analysis. &gt; &gt; &gt; &gt;Also I don't think mtr supports multiple targets concurrently.
The last hop on an mtr is the same as a ping, with much the same graphing as this though, no? Multi target is fair, though, but is it that important with tools like tmux, or split pane terminal emulators?
Where do they misspell it?
&gt; So we are talking about two completely different things and have been for a while. No we haven't. `int` implements `interface{}`.