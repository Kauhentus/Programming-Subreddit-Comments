Ah, i also came from Java, worked on Php MVC framework too. I am more biased towards MVC framework as it divides responsibility between different modules. To achieve same thing here, i planned to create different package for each module, one reason to create package is to divide responsibility. I don't want any function in controller package to directly call any function from model without specifying model package while calling. This way i know when controller is calling model and no one can call a function of other package without specifying it. I am also doing it so that in future when someone else join me in my quest of writing good code, he don't mess up by writing any function at any place. Every function should go to its respective package. My package struct is : 1. Main: Main.go 2. Controller: Which will handle all requests 3. Model: DB models. 4. Router: Router details 5. Config: Config variables which are used in webserver like port, mysql user name, password etc. 6. Log: Log file which will have all logs 7. Static: All HTML, CSS, JS and images goes here 8. Middleware: Using it for my specific middleware like my custom auth on each url hit. Please hit me with your confusion, if any. Lets discuss in detail about different approaches to bring the best one out. :)
Certainly. It's not necessarily bad to have a package for your models, but once you start to have many different models, you might want to create some sub-packages. I wrote a forum a few months ago and I didn't use a "model" package at all. I split the site into some of its logical components. For example, I had a "home" package, a "users" package and a "threads" package. The "users" package acts as a model for the users. It has functions for inserting records, retrieving, updating... I also had "userhandlers" package that had the HandlerFuncs in it. I found that this worked well. If I had to do it again, I might create a "models" package and put the "users" package within it. Essentially, I think MVC is good, but keep in mind that MVC is all about separation, not grouping. You separate your controller from your model. And you should also separate your models where it makes sense.
I completely agree with you in this. &gt;&gt;And you should also separate your models where it makes sense. Didn't think about this problem before, but agreed if i keep adding all model functions in one package, it might get messy. Just to make a visual difference, i am creating different files (one for each model like user, userlogin etc). Any suggestions here?
For cat, read a file into a buffered reader and then output to standard output. It is extremely simple. Echo just takes os.Args and outputs to standard output. These programs will show you just how nice Go's interfaces really are.
I turned it off about 30 minutes in, and it was painful lasting that long. That host is not cut out for hosting podcasts.
Thanks good link!
Virtualisation ? Benchmarking ? _/me bursts into tears_
Yep, it's a crazy world we live in. EMC will even make the case that you should run your big dedicated servers as VMs that just happen to match the capacity of the underlying hardware, so you can have v-motion and pay for 2 more licenses. That's really about the only way SMP VMs make sense.
...and the year of desktop Linux? Oh please let it be both!
Yes, I've read the changelogs/commits. Havent noticed anything there that warrants a upgrade. It might be your personal or companys recommendation to just use "master", until there is a commit that breaks something. I suppose your fork and own branch will prevent this. I'm just not that confident you can test all the aspects of a library you are not the author of. Have you read all the code of the library and understand the implications of each line in incoming commits? I'd rather wait for the author to tag a v1.1 when he feels that is needed and it is really stable from his point of view. I still find it weird that you don't use v1.0 for your end users.
It depends. Short code that's buggy is a drain. Overly verbose code is a drain to write. Terse code that's difficult to parse is a drain. Medium length code that's just annoying is a drain. LoC doesn't measure any of these things and all of those are way more important considerations than lines. A good language will balance all of these for the domain of problems it's trying to solve.
There are two parts of this question. 1. How can I stop accepting new requests while finalising existing request in fly ? 2. How can I restart my application without being temporarily unavailable ? My answer to both is the same: if you care about availability to that degree then you must use some sort of load balancer to proxy requests and balance them across multiple application servers. With that infrastructure in place the rest of the pieces become 1. Use some sort of middle-ware to keep a counter of requests in fly. 2. Close the listening socket, this will cause your load balancer to stop sending requests to your process. 3. Wait for the counter to drop to zero or a some timeout to fire 4. call os.Exit(0) and let your process manager (upstart, daemontools, systemd -- you are using one of those right ?) restart you.
Yes, the "start from a naive and stupid premise and arrive at a somewhat reasonable standpoint at the end of the piece". Hardly worth an article when the conclusion is pretty much common sense.
&gt; Thanks for answering! You seem to be against forking a new process, passing previous requests made to it and exiting. Why? Why is that a bad approach? My suggested approach is simple, it's used everywhere, not just in Go applications and most importantly, _does not let you cheat by trying to convince yourself that one application server is sufficient_.
A quote from https://github.com/robpike/filter Rob Pike &gt; Having written it a couple of years ago, I haven't had occasion to &gt; use it once. Instead, I just use "for" loops. &gt; &gt;You shouldn't use it either.
[underscore.go](http://tobyhede.github.io/underscore.go/)
One thing I don't understand is, with real user-defined generics vs. go generated "generics", aren't you basically accomplishing the same thing? You get code that is easier to read and container-like constructs that are DRY and more enjoyable to work with. The only difference I've thought of so far (and please do correct me if I'm wrong, as I very well may be...) is that one uses templates and gets handled before compile time, while the other doesn't, which means that you have to handle the complexity, lesser type safety, and performance concerns that come with it. The Go authors have even said that they just haven't found a strong reason for generics yet, and I've always assumed they meant generation with code templates was good enough. I see this library as proof of that. I don't see it as compensating for a lack of feature the language creators are ignoring, since it very much works within the bounds of the language and even a agrees with its core ideas (why else would they have introduced code generation into the toolchain?), and I can't see how it encourages developer segmentation since it uses Go code to generate actual Go code. Am I missing something? I come from a strong background of dynamically typed languages like Ruby, and I've pretty much just accepted that Go's ideas are different and I need to design and express myself differently as such.
I like Muxado, but lack of interoperability with other languages is a bummer. If the protocol were documented, third parties could build their own implementations.
We go through the commits and see what they do. Of course, author can better decide what goes there, but when we have confidence that some changes fix bugs without introducing new ones, we apply or backport them. You can see this with gorilla/securecookie, for example. During the code review, I have discovered a panicking bug with unnecessary changes and reverted the commit in the released version, asking the upstream to do the same: https://github.com/gorilla/securecookie/pull/15#issuecomment-86173686
The 'zip' pattern is a control structure now? 
&gt; Right now, much of the heavy lifting is in C because I never figured out how to properly perform IOCTLs using go. r1, r2, errno := syscall.Syscall(syscall.SYS_IOCTL, ...) Relevant thread: https://groups.google.com/forum/#!topic/golang-nuts/LTlOwzcn470
The comment wasn't meant to be a negative criticism of Dave Cheney, who I think is a good guy. But you are supposed to advocate for Go, even if it's not your job. This is part of a mantra by the Go team. See the 5 stages of learning Go: https://sourcegraph.com/blog/live/gopherconindia/112025389257 . The last stage (presumably, when you have become a Go master), you are supposed to advocate. I don't particularly think that this is a good thing. But to each of his own. 
https://github.com/anacrolix/torrent/tree/master/dht
The syscall lib is deprecated, you should use the sys library instead: https://github.com/golang/sys
This was the example i needed to explain the problem: code, code, code, no documentation and no example. So, actually, just bytes. &gt;code, code, code everywhere &gt;and not a single byte to use...
Very nice work, I do not particularly like the Haxe syntax but I adore the transpiler capability of it, so this is superb project - really wish you the best of luck with getting this baby fully off the ground!
https://github.com/nictuku/dht An example of it's use: https://github.com/jackpal/Taipei-Torrent 
Thanks for this, Siddon (and vitess guys for the initial work). I like this concept as it allows you to ad-hoc things to your MySQL architecture.
Yes this is the only library with an understandable example. thank you. 
This is a very interesting question for any language but the answer really depends on what you're comfortable with and what your infrastructure looks like. Here are a couple of approaches: 1. Start new ec2 instances, deploy the new app to them, add them to ebs (via api) and remove/stop the old ones. This is will work for any language but depends on the fact that you're able to set up new instances automatically. 2. Install nginx/haproxy/... on each instance. Start new instances on all hosts with new ports and tell your reverse proxy to switch to them. Haproxy has a nice api, but for nginx I'd recommend updating the config and reloading it. This also has a couple of drawbacks. If your nginx serves on port 80 your deploy script will need sudo access and you need to write a fairly complicated deploy script to manage the reverse proxy(similar to what you'll need for elb) 3. Use facebook's grace or any similar package to do the app restart. This looks fairly simple in theory but it also has a couple of problems. First, it's architecture specific, which means you'll have to find another way to do it if you'll decide to also deploy something not written in go. But the bigger drawback is that it assumes you can simply switch the application's binary, send an arbitrary signal (in case of grace it's usr2) to the process and that your process manager won't lose the track of the process if it changes the process id. So in your case where you run the application in docker you won't be able to switch the docker container, instead you'll have to switch the binary inside of it. Which is kind of awkward. If you (or anyone else reading this) runs their app under supervisor you're also out of luck since supervisor can't handle the change of pid and only the newest version supports arbitrary signals. So as a conclusion I'd recommend the option 1 even though it's aws specific and requires a fairly complicated deploy script. Now for some advertisment, I started working on a project which replaces the process control system but also includes the reverse proxy. It starts a new instance of your app, switches the traffic to it when the optional healthcheck passes and shuts down the old app when the number of open connections is 0. It's very simple to use and solves all major problems with approaches 1 and 2. It's also completely untested, lacks documentation and I only work on it when I have some down time from my day to day job, so I won't recommend using it yet. But if you want to try it, give me some feedback or even contribute code, I would be very grateful. Here is the link: https://github.com/hamaxx/gracevisor So yeah, sorry for not giving you a silver bullet (yet) but I hope this helps. Ps: I'm giving two talks on this subject this week so I'll attach the slides to this post when I'll have them.
SO_REUSEPORT
details: https://docs.google.com/document/d/1QXzI9I1pOfZPujQzxhyRy6EeHYTQitKKjHfpq0zpxZs/edit
Check the docs for the syscall library; it's in the Overview: http://golang.org/pkg/syscall/
Isn't MD5 from the stdlib faster than CRC64?
&gt; RecieveMessageCallback &gt; Recieve Somewhere an English teacher is crying.
WHY! but seriously i would be curious to see an example of the input and the output it generates.
Hello world translates to 700+ KB to pull in everything.
Check out https://github.com/jbenet/ipfs, too. Not NNTP but a lot of similar goals, and then some. The primary implementation is in go: https://github.com/jbenet/go-ipfs
I'm pretty sure every major language ends up getting one of these libraries. Someone somewhere always gets frustrated with context switching while building web apps and decides writing a JavaScript compiler is a better use of their time.
One could view this albeit like Apache Samza. While you currently are using it to fill the Elastic Search index it could be used to build other types of applications. It's especially nice when you want to subscribe to changes in MySQL.
I prefer [godoc](https://godoc.org/github.com/anacrolix/torrent/dht) myself, but [sourcegraph](https://sourcegraph.com/github.com/anacrolix/torrent@master/.godoc/dht) also provides usage examples.
For example if you program a card game and you want client and server side validation.
Ok, so. Either I am missing something or you all have something in mind **and I don't get it**. Since usually there is nothing like "everybody else is in the wrong lane", then the one in the wrong lane is me. In all the links you provided (thank you), I see code. But I don't see anything about "what the functions are doing exactly", neither how to use them, like an "example". Now, what I call an "example" is that: [dht example](https://github.com/nictuku/dht/blob/master/examples/find_infohash_and_wait/main.go) this _example_ shows me how to use the dht libraries from nictuku. Because it gives me an example of how to use. I see you _all_ are saying your repositories are **full of examples**. So... _it has to be **me** unable to find them_. Given what an example is, could you provide where is the example, exactly, in the links you posted? I start suspecting I am the one in the wrong lane, but I can't get why... 
You shouldn't ever really trust clients, especially for something multiplayer. People will cheat. So you'll still require server validations. Something like http://json-schema.org let's client code know what fields need to be populated before a request is sent. Really that's all we are trying to do anyway; reduce the number of requests that are doomed for failure.
Uhm... so this could help to share the hierarchy and align the spool. What is the difference between this and btsync, or syncthing, exactly?
Wrong subreddit? 
Aaahhh. Got it. Thanks. :) :) As usual, when you feel like everybody else is in the wrong lane, the one in the wrong lane is you. :) I'm getting classic.
This is my question also. Why on earth would anyone do this? Even from the docs, it seems like a horrible idea. The only thing I would be interested in gaining was the type-safety from go, but that is circumvented, at least in the examples given. A map[string]interface{} and the Global.Get(string)...
I wrote a similar utility some time ago but it's hard to get all of this stuff right and I wasn't really sure of the semantics I want to support. * Are hardlinks to the same file considered duplicates? Hopefully not. * It would be great to support a mode in which duplicates are replaced by hardlinks to the same file * How do I get this right if there are two files with various hardlinks and equal contents? * You might want to skip symbolic links
One example, as a quick and dirty hack to get things rolling, would be the IPFS guys who would absolutely love if they could compile a bunch of their libraries down and use them in the browser.
The semantics between Go and JS differ a lot. From what I recall TypeScript has basically "JS semantics with types checked where feasible" which is a totally different ballgame. It'd be more fair to compare against Scala.js or ClojureScript. Also GopherJS is essentially written by one guy in his spare time.
&gt; WHY! So you can have an Isomorphic web stack for Go. The instant you need business object validation and interaction in both the client and server, maintaining that logic in two different languages comes at a huge maintenance penalty. This means you either downgrade to web 1.0 (server-side page composting and server-side form validation only), or maintain everything in one language (usually JavaScript). GopherJS puts Go on the table for just such a situation, because really, do you want to write server-side JavaScript? A more obvious benefit is that you have one codebase for everything. MeteorJS makes a good case for how this is helpful. &gt; but seriously i would be curious to see an example of the input and the output it generates. I've followed this project for a while now... basically, the output is reliable but very heavyweight and rather ugly since it implements ALL of Go's features including goroutines. That means stack emulation and breaking Go functions down into mulitple JS functions so the scheduler can perform coooperative multitasking. From that vantage point, it's really quite an achievement.
&gt; You shouldn't ever really trust clients Yes. But, you should take advantage of the *acceleration* you can get by having the client head-off user mistakes ahead of a more expensive (time-wise) round-trip to the server. So in essence: distrust the client, but make the client work for you. There are also business-level validations that json-schema is unlikely to cover that must be done with good old-fashioned programmable logic. Schemas in general are great at data-type validation, but utterly fail at things that require relationships between entities. Things like: "this name must not exist in the database already", or "that password is weak", or "this object must be related to these other two specific objects because of it's type." 
This looks like it could be very useful for testing. But I'd be worried that a future version of Go would break it ...
That doesn't allow you to patch the standard library however
No, because you need to generate assembly with the replacing function address in it
Thanks a lot, i made some changes to your advice.
sure it does. var printf = fmt.Printf func doHardStuff(name string) { printf("Hi %s!", name) } func TestdoHardStuff(t *testing.T) { var format string var params []interface{} printf = func(s string, args interface...) { format = s params = args } doHardStuff("bob") expFormat := "Hi %s!" expArg := []interface{}{ "bob" } if format != expFormat { t.Errorf("Expected %q, got %q", expFormat, format) } if params != expArg { t.Errorf("Expected %#v, got %#v", expArgs, params) } }
This is admirable work in the pursuit of evil.
I think you've pretty much answered your own question. In addition to the fact that it's really unsafe, it's entirely unnecessary and it breaks the OOP principle of treating other modules as black boxes, since you're messing with their internals.
Brett Slatkin had a [nice explanation of http.HandlerFunc on his blog](http://www.onebigfluke.com/2014/04/gos-power-is-in-emergent-behavior.html). Highly recommended.
Not yet, may be in future. Router currently only supports add and find route. Add route is also not optimized yet.
&gt; I'm actually really surprised Go doesn't just let you add methods to arbitrary types that you don't own. That creates the [orphan instance problem](https://wiki.haskell.org/Orphan_instance); see also [Rust struggling with this problem](http://internals.rust-lang.org/t/orphan-rules/1322). Go would have the exact same problems, which is why I link these as relevant. In a nutshell, "what if two different packages try to add the same method to a type?", and it turns out that all the easy answers have serious problems. That includes "don't allow it at all" (Go's solution, which is annoying for the reasons you cite), "try to somehow scope it to the redefining package" (can cause problems when the two implementations are fundamentally different and trying to maintain differing invariants), "try to resolve which 'wins' somehow", and every other easy answer. I think the only answer that fits into Go's philosophy is the one it currently has. That doesn't mean I think it's _perfect_, just that it's the only one that fits.
It allows you to "dependency inject" the standard library, and this should be part of the standard toolbelt for every professional Go programmer. It doesn't let you _patch_ it. Incidentally, though, if you _really_ want to patch the stdlib the correct answer is to grab Go's source and build a custom Go, rather than do any of this. :)
So many routers....
There is an issue about this. https://github.com/go-authboss/authboss/issues/53 The hold up is my understanding of JWT to be honest. I've looked at and don't understand the advantages or why it can't easily be used in replay attacks since it includes all of your claims or authentication or what have you. However, Since we make no assumptions how or where you store your cookies (session OR remember me cookies; see the ClientStorer interface) you could implement this as a JWT I do believe without any help at all from Authboss (maybe with help from this: https://github.com/dgrijalva/jwt-go) If there's any friction in this approach let me know, I'd like to find out if we can get rid of this issue, or exactly what Authboss needs to do to support it.
new returns zeroed memory. This package will initialize the pointed to value with the passed value.
The only solution I've used is Scala's implicit classes. For those, you import the monkey-patching. If you import two things with the same method it will just not compile due to ambiguous implicit conversions. So it's some combination of the latter two solutions you state. It is a gnarly problem despite how attractive the common use cases are though. Go seems to have taken the same approach as Scala except you perform the implicit conversion explicitly. 
Ah yes, /u/Rivermind hit the nail on the head. `new` returns the zero value memory, but I wanted to be able to access the underlying values. I use type switching on interface values for some other projects and this library helps test pointers to values without having to declare new variables in the context of [table driven tests](https://github.com/golang/go/wiki/TableDrivenTests).
Anytime a router is posted here, there's always that 1 person who comments something like this. What are you trying to achieve? Are you actually bothered, or are you just fishing for upvotes? If it bothers you, just don't click the post, it's really that simple.
Thanks! Its cool that a stranger on the internet finds something I shared cool haha.
These are good points, currently it doesn't know the difference symbolic/hard links and actual files. This is definitely a bug, so thanks - will try to get to it soon. Edit: Pushed a quick fix so it only considers regular files.
Agreed, will try to address /u/FUZxxl points soon. Edit: Pushed a quick fix so it only considers regular files.
Ah "partial MD5 signatures" thats a good idea
It'll break today's Go. Replacing one function with another in this manner will cause memory corruption because the map the garbage collector uses to identify local variables of a function will no longer match.
This guy has a point. Golang suffers from lack of mature, community preferred, packages.
I have a plan to add sub routes with middleware which will also inherit parent middleware. I believe that will cover most of the cases. Let me know your thoughts. 
yes, it seems more like OOP to me .. using packages like static classes.
A language being statically or dynamically typed is no excuse for the available packages (like 1000+ routers, little else, a little bit exaggerated).
Go, golang or skunk tail in honey. Whatever. The name does not do something better or worse. If I can find information on "golang" request - I call it golang. No need to make a religion out of this questions. 
I am not bothered I am overwhelmed. I am currently learning Go and all these router choices are daunting.
Rust ... Rust-lang! Am I doing it right?
I prefer searching for golang. Go on its own is hard to search (it is a verb, it is a wonderful board game I suggest you check on /r/baduk , it actually is another programming language named go!... too many things to confuse.) Golang is clear, unique and we know the language is go, and for search purposes we add Golang somewhere in some tag or in the copy and we are happy to help everyone else.
Note, that appengine doesn't like using subpackages (it can create name collisions). Only if you have each subpackage in your project as a module.
This is not about SEO. This is about calling the language by its correct name in spoken and written form.
I can kinda answer your bonus question. There was a [netchan](https://godoc.org/golang.org/x/exp/old/netchan) package for emulating buffered channels over the network, but it's deprecated for some reason. There is also std's [net/rpc](http://golang.org/pkg/net/rpc/) package that can be used for inter-machine communication. As for your main question, I don't know enough about actor model, so I can't really answer that.
I really like this idea. Great work.
Thanks. Lots more work to be done. I've been using it in my daily workflow and it has performed extremely well.
If you'd like to look, here is my program: http://github.com/fuzxxl/fdup
Go can't produce a DLL for Windows, so you can't embed your code as a plug-in for a Web server or a game engine. Go does not have any "evaluation" function that allows to compute a golang strings into code, so you can't do any RAD development. For me these 2 issue are a deal breaker. To bad because I like the overall look concept.
is there any way to limit the size of file created using shell script and environment variables in linux?
Hello, we have recently started working on open-source GoLang CMS : https://github.com/divblocks/aquila The project is currently on its early stage, but we plan to evolve it rapidly. If you are interested, you can join our team. We are going to publish Software Arctitecture Document in nearest time.
stop bitching about something practical, and go back to code. 
Golang's not unix?
Looks cool, will probably setup in my current project.
 If anything seems unclear or confusing let me know.
ATM Machine
I'm confused - are you talking about Google's Go?
I thought it was spelled Rust
Would naming it something so ambiguous that search engines have a hard time distinguishing the results show the author doesn't know shit about search engines? Cause I heard the company behind bing is so stupid they named their framework after a domain TLD, thats' pretty laughable right? Good thing I never have to deal with that..
Plan 9/Go?
I humbly suggest busying yourself with more important (and more interesting) problems.
 &lt;meta name="keywords" content="go, golang"&gt;
Then why is everything here in Englishlang!
UNFORTUNATE WONTFIX
If you name your language something as stupid as "Go", you deserve what you get. I've always just called it "Google's GoLang Language" so everyone knows which language I'm talking about.
PIN number
ITT: Dave is Googling for Go and not getting results and we're to blame.
Should have called it issue 9. Even that is better searchable than go. 
yes, I think you might be right there, I overlooked sender identification within a message, which is present (and necessary) in the akka framework I use. 99% of the time the CSP model works great for me, I love that channel messages offers simple synchronization of go routines. I don't think it would be too hard at all to implement the actor model in go though, I may have a go as an interesting side project, and for some use cases it is just easier to use.
If this bothers you, I highly suggest never trying to pronounce 'gif' in the company of others 
Non-mobile: [http://en.wikipedia.org/wiki/S-Lang_(programming_library)](http://en.wikipedia.org/wiki/S-Lang_\(programming_library\)) ^That's ^why ^I'm ^here, ^I ^don't ^judge ^you. ^PM ^/u/xl0 ^if ^I'm ^causing ^any ^trouble. [^WUT?](https://github.com/xl0/LittleHelperRobot/wiki/What's-this-all-about%3F)
I've been trying to get the name changed to golang in the go meet ups I go to. There is no utility in a name like Go which cannot be searched.
There's [libchan](https://github.com/docker/libchan) these days. With a quick glimpse, buffering would need to be implemented manually.
agreed. In line of go, i want to make my code more structured so that anyone comes and work on my code and easily get how the code is structured in different submodules based on its type like user in user submodule, status in status submodule all belonging to controller module. Any better suggestion on how we can achieve desired results?
Personally I find Go (and C's) approach much simpler than Java's, for many of the reasons you describe. It sounds like what you're really trying to do is not just explore how pointers work in Go, but to sell your coworkers on the benefits of Go. You touch on it in #1, but I think this could go over well if you keep that theme and focus throughout covering your remaining points: how would this be done in Java/Python, and why is it better and more clear in Go? I'd have a side-by-side comparison to Go at the end of each section just to cover the problems you can run into in Java that don't plague Go developers.
Good for you. I still think he's being silly and wasting his time. The fact that he's a top contributor has literally nothing to do with this.
Why not? Go is still young and competition is necessary for it's further growth. Let Go's community choose the few preferred packages for every purpose, and in the long run, these will stand out above others.
I got fed up with the same situation (and needed a newer libsass) and threw together this library: [github.com/acsellers/sassy](https://github.com/acsellers/sassy). I built the library for a quick prototype that ended up not getting put into production. It's a mishmash of libsass code and go code, though I didn't copy the sass -&gt; scss library that libsass sometimes includes, because of license concerns. Basically I copied the libsass code into the same directory as the go code, then tweaked the go code to use the embedded libsass. So you should be able to just go get ... without having to install libsass as a shared library or whatever. It's not the prettiest library, but it was convenient enough at the time. I'm not sure I would use it today, instead I would probably end up going with [gcss](https://github.com/yosssi/gcss) if I wanted sass-type features in Go.
well, that was a reason why I moved out of appengine in a recent project :/
Please don't use `panic` and `recover` for error handling here. [Effective Go on `panic`](http://golang.org/doc/effective_go.html#panic): &gt; The usual way to report an error to a caller is to return an `error` as an extra return value. The canonical `Read` method is a well-known instance; it returns a byte count and an `error`. But what if the error is unrecoverable? Sometimes the program simply cannot continue. Write failures are expected and recoverable, which is why `Write()` can return an `error`. This limited-capacity buffer was built specifically to *make* writes fail. It should return an `error` in this case.
Avoid the phrase "pass by reference" when explaining pointers. Pointers are passed by value like everything else.. they're cheap because pointers are a single &lt;word size of platform here&gt; copy. Anyway, it becomes confusing very quickly for newcomers.
This is an exciting area for Go. Right now there are just a few machine learning libraries and some early stats libraries in Go. Much like Python ~6 years ago. 
&gt; /r/golang And what's your point?? There is no `/r/c`, and the existence of [/r/C_Programming](https://www.reddit.com/r/C_Programming/) doesn't mean that anyone saying something like "hey I wrote some C_Progamming code yesterday" isn't as ignorant and incorrect as someone saying something like "hey I wrote some golang code yesterday". Both are very wrong.
Download the latest version and don't put it in Applications directory.
Thanks hamax! The nginx reverse proxy is already setup to serve static files and to reverse-proxy to port 3000 on which the go app runs. I didn't want to be limited to Golang, so I kept my options open, to better maintain the app and make it easier to develop the app into components/micro-services. Supervisord runs nginx and golang, so using nginx given my setup isn't too farfetched. What I'm really aiming for is to just deploy the binary, which is the fastest time possible. Although hacking into docker to replace the binary is a backward approach, it might also be the fastest. My biggest concern with Option #1 is that the dockerfile needs about 20 mins (on elasticbeanstalk) to get all dependencies, the go dependencies, and run the app. 
Are you suggesting a tool that would automate submission of the challenge after running tests etc.?
That's what nicknames were invented for.
Work is ongoing on both tools for the Go Challenge. There is a [cli](https://github.com/GoChallenge/cli) that will fetch the challenge and run the tests(`go test`) before submitting. That part is done, while the [server](https://github.com/GoChallenge/gochallenge/tree/apiv1) should be complete by the time the third challenge rolls around. You're welcome to contribute :) Join the gophers channel on slack to join the discussion.
Doozer is not active and shouldn't be used.
This is broken code. It is not safe to have unsynchronized reads concurrent with writes, even if the writes themselves are mutually synchronized. **Edit:** Here's a runnable implementation: http://play.golang.org/p/KZQDewgkmu You can see the output of the race detector at the bottom.
For a good introduction into what you can get away with without locks, see Herb Sutter's talks at CppCon last year: https://www.youtube.com/watch?v=c1gO9aB9nbs https://www.youtube.com/watch?v=CmxkPChOcvw Jeff Preshing has two great blog post series, the first one starting at http://preshing.com/20120612/an-introduction-to-lock-free-programming/ and then again with http://preshing.com/20130505/introducing-mintomic-a-small-portable-lock-free-api/ And of course from Dmitry Vyukov https://software.intel.com/en-us/blogs/2013/01/06/benign-data-races-what-could-possibly-go-wrong and his personal website http://www.1024cores.net/ 
I rest my case [http://www.gopl.io/](http://www.gopl.io/)
Are you sure your example is incorrect in practice? line 34: Since you're not using the value retrieved from the map, it's not important whether that is corrupt or not. That leaves us with the "ok" boolean variable, which tells us whether the key was found in the map. Assuming "ok" has an incorrect value due to unsafe concurrency, we are left with 2 possibilties: - it's a false negative: ok == false, even though another goroutine is concurrently in the process of inserting an entry with the key -&gt; we end up locking and rechecking so it should be fine - it's a false positive: ok == true, even though no goroutine is actually inserting an entry with the key -&gt; can this even happen? the key is of type int, which should be atomic on all architectures, I don't think any hashmap implementation would return a false positive but I may be wrong here Please correct me if I'm wrong, but I think your example may actually be accidentally correct.
oh wow, I can edit the page!
&gt; Are you sure your example is incorrect in practice? I don't generally distinguish between "incorrect" and "incorrect in practice" :) But in any case, the race detector finds race conditions that *actually occur* (it may have false negatives, but it is not supposed to have false positives), so unless you're claiming that there is a race detector bug, this is code has a data race, and therefore has undefined behavior by the Go memory model. This is what I mean by broken. &gt; line 34: Since you're not using the value retrieved from the map, it's not important whether that is corrupt or not. That leaves us with the "ok" boolean variable, which tells us whether the key was found in the map. Assuming "ok" has an incorrect value due to unsafe concurrency, we are left with 2 possibilties: Oh, it's much worse than this. For instance, the map implementation is free to do some reorganization when there is a write. It's possible that the concurrent read could see an inconsistent map state and crash. And just because you don't observe this behavior today doesn't mean that it can't happen one out of a million times, or that a change in the map implementation in a future Go version wouldn't trigger it. This is why the race detector is so helpful for catching these kinds of bugs. An important thing to note is that a map indexing operation is a read operation over the whole map. For the purposes of the memory model, the following are essentially the same sorts of operations: x := m["k"] and x := y m["k"] = v and y = v In this way, maps are different from slices and structs; individual elements/fields of those types are addressable separately, so the following sorts of things are OK: x := make([]int, 10) x[0] = 123 concurrent with x[1] = 234 t := &amp;struct{x, y int}{} t.x = 123 concurrent with t.y = 234 &gt; the key is of type int, which should be atomic on all architectures, I don't think any hashmap implementation would return a false positive but I may be wrong here Careful. Even when writes of a type are atomic on your architecture, that doesn't mean the compiler won't make breaking optimizations by assuming race-free code. [Best not to assume any data race is benign.](https://software.intel.com/en-us/blogs/2013/01/06/benign-data-races-what-could-possibly-go-wrong)
Update described above now released for Haxe 3.2.0-rc2.
That is a rather false and condescending dichotomy. You can perfectly express abstract ideas that are simple. Portability is on a whole another level than the language interface/syntax. You _can_ write beautiful and expressive code that works, only sloppy people use "portability" and "simplicity" as an excuse to write suboptimal code.
thanks, added to the post.
Relevant https://github.com/omeid/slurp 
"Docker sux lol!" coming right up.
Author here. It was pointed out to me last night [on Twitter](https://twitter.com/PreetamJinka/status/583101019602710528) that this wasn't completely correct, so I've updated the post with the correct implementation. Another lesson learned!
https://github.com/firstrow/logvoyage/blob/master/web/web.go#L60 you have a hard-coded path here.
thanks. fixed.
I didn't say that you can't write to them. I said that new values may not be immediately seen by other goroutines working on other CPU cores. I think you misunderstood me. You're right that you can use separate elements/fields in concurrent goroutines, but that doesn't mean you can use one element/field in many goroutines without proper synchronization. Each CPU core has caches. Regular memory operations write to caches. If you don't synchronize data won't be sent to ram/other cores before cache needs to be flushed. Memory barriers make sure that data is sent to other cores/ram. Without memory barrier compiler may completely optimize out such write. https://golang.org/ref/mem#tmp_6 &lt;- writes in goroutine without synchronization may not be seen in others. https://www.kernel.org/doc/Documentation/memory-barriers.txt
By posting on reddit apparently, and once again pointing out that criticisms like this are rooted in cultural values and status, not pragmatic solutions to real problems. You can tell because they use technical arguments *to say something about themselves and the people who use the language*. Can you (sufficiently) prove adding things like Generics will increase programmer productivity or reduce errors? Computing soft costs like these are extremely complicated, as there's definitely a spectrum between the things which make an individual programmer productive in the short term, and a group of programmers productive in the long term. Where do Go and D fit on that spectrum? How do we even measure it beyond experience? I'd much rather see discussions on that as opposed to another defense of one's social status. That said, I'd like to see Generics in Go, or something like it.
Good point. Can you tell I used to be a Java dev? I forget that pointers &amp; references mean different things in C++ Ta
Yep, I see what you mean. I can easily show a java NPE on an uninitialised string variable, vs Go. Ta
lol @ post tags. go#, go++ anyone?
fuck i fell for it. this sounds amazing
Biggest laugh I've had all day, thanks 
I recently became infatuated with `go generate` and the idea of letting the compiler/pre-compiler do more work instead of using go's crazy introspection. This is my first experiment with it. Eager for feedback, suggestions, and pointers to similar projects!
so that's just the thing. it's independent of the underlying spec, which you can provide with a template. Though it would probably be a good idea for me to provide some "standard" templates that import net/rpc and probably jsonrpc too
Probably the though that O(1) == constant == atomic. 
This is JavaScript we are talking about. I would take the risk of developing a project with this.
I don't think it's wise to invite comparisons between Go and C++. C++ has a rich, expressive type system, while Go lacks generics. One language is a flash in the pan, a fad riding on the sponsorship of a big company, and the other is a long-lived, standardized language.
Please don't think I am a Go fanboy, cuz there not much that is farther from the truth. I am, by my own measure anyway, an "advanced" C++ user, very comfortable with many things that C++ has that Go does not, and not at all shy about my opinions. But in this case, Go wins in expressivity and simplicity, hands down. It's not often you will hear me say that. That said, I disagree with your dismissal of Go. It does some things very well, and it is actually surprisingly good for just getting things done, as long as you can work with one hand and hold your nose with the other. C++, by comparison, requires a military-grade gas mask, but at least you can work with both hands (you're gonna need them).
When that involves unsafe code that relies on reflection ... yes.
Hey dave, the link said that Go 1.5 will be the "most exciting release yet with big changes". Is that the case? I thought it was mostly under-the-hood changes to reduce GC latency.
This reminds me of another nice (though not very idiomatic IMO) thing that interface embedding can be (ab)used for, making generic *interface{}* based receivers a bit more explicit without implementing methods just for the sake of identification (think of Java's Serializable). Say I have a method that processes an *interface{}*, and I want to limit it to a few struct types that should be sent there, but they don't share an interface. I can force them to implement a special method, but if I don't want to implement methods, I can use interface embedding for it. Instead of writing my method as: func foo(v interface{}) I can use embedding of nil interfaces to make it a bit nicer looking for a developer who's not familiar with my library's internals. // This is the type our method will accept, but it's just a dummy type type Fooable interface { Foo() // whatever method works here } // now my func receives only fooables. But I'm not implementing any Fooable method in my code func foo(v Fooable) { ... // reflection based stuff here } but instead of making all my relevant structs implement Foo for no reason, I can just do: type Bar struct { Fooable // this is it. no methods or any special initialization code Wat string } func main() { // no Fooer initialization here, so basically Bar embeds a nil Fooer, which means it's also a Fooer b := Bar{Wat: "wat"} foo(b) } I haven't used it in real world code, though. Playground example - http://play.golang.org/p/IA-cN2m11w 
I assume that anyone who has done this in C++ knows the problem. If you haven't, then you are lucky.
&gt; Go 1.5 code freeze is May 1, 2015; release is August 1, 2015 Three months of code freeze for a minor release is impressive. I know many other open source projects that care less about quality.
My argument is not about Go nor C++; I'm well aware of the advantages of embedding. It's about the quality of examples. Essentially, a bad example can show an advantage of most features/patterns... also it provides no good discussion, e.g. whether that is indeed the correct/best way to model things. If the real-world situation is significantly different it might be hard to work with. Alternatively, what if the pseudo example never happens in real-life, what use is that feature, even if it can show something good?
does strikethrough mean done or cancelled? (or something else entirely)
Ours is about 2 months and well we are talking about a standard library and toolchain. They need to a bit more pragmatic then pur average project.
Compared to a major version release which would mean incompatible changes it is.
If you want to use the IntelliJ plugin, I recommend you to install the plugin following the instructions from here: https://github.com/go-lang-plugin-org/go-lang-idea-plugin#pre-release-builds The new version is a reworked version from the ground up and it's leaps and bounds over the previous 0.9.15 releases. The plugin allows you to configure the environment however you want it to be, either with a single GOPATH or with multiple GOPATHs. If you have any issues, you can always report them to the issue tracker. Just please ensure it's not a duplicate of an existing issue first :) Hope it helps.
Android NDK? Shared libraries? You've made me excited as hell :)
sadly I also discovered this kind of general hate of everything that is not golang on the gonuts irc channel when I dropped by a few weeks ago. I tried to have a balanced discussion for a little while and then just went into ignore mode. 
Let's take `type foo struct{}` and `type bar struct{}`. One of them is based on a real example with details omitted and the other one is a facilitated example. Can you tell which is which? And can you tell why it was useful? I'm not doubting that you have experienced this in first hand. The problem is that by omitting the use-case you are omitting the thing that makes the code valuable in the first place. Once you replace names with random placeholders, there's no easy translation to being of value, unless you knew the case in the first place. Of course the omitted details example actually doesn't show feature usefulness. E.g. let's take a variable `aaaaaaaaa` look how useful and more concise would be expressing the variable with `9a`, hence replacing repetitons with the number is much clearer. See how useful it is. As a reader there's no proof in that statement unless I know beforehand where it is useful. It offers no insight into how to use that feature nor where it might be useful nor convince anyone of its usefulness. It's impossible to improve on the feature in any practical way. Also it's impossible to see whether that problem can be solved in a different way or feature Y used instead. Or was the inital model faulty/inefficient and there actually wasn't a win with it, because after fixing the initial model (e.g. using better variable names) the feature is useless. For example in comparison for the embedding case Jonathan Blow showed a very interesting thing in Jai - `using` keyword which allows you to implicitly use a delegation function inside a struct (http://www.reddit.com/comments/2t6xqz). Maybe that would be even better in your case? Of course that discussion is hard to have without having an actual model to begin with.
Are you looking for something that is an academic problem to solve? Or, are you looking to build a tool that some people might find useful?
http://www.reddit.com/r/golang/comments/30jw0n/go_homework/ https://projecteuler.net https://www.google.com/search?q=code+challenge+sites
&gt; then it is a bug and I encourage you to report it Thank you captain, my point is now major Linux distribution decided to use different compiler, which I suspect none popular Go applications were tested with. Majority of hobby projects that happen to be more widely useful have no resources to ensure things work under gccgo.
Ok but such a release would be an entirely new language, Go 2. And it is unlikely to happen (at least I can hope).
Yes, [it is](http://semver.org/) according to SemVer. Go 2 would be a major release, while Go 1.5.1 - a patch.
10ms out of 50ms is not the same as 20ms out of 100ms. In sum yes, but you will never get a 20ms pause, there will always be 40ms of application code execution between two 10ms pauses (in the worst case), which is important for reactivity.
I have the same problem on windows too.
According to a comment by Russ Cox on HN, almost all GC pauses are less than 1ms. With Go 1.5, that minority of long pauses is guaranteed to be less than 10ms. To reiterate, 10ms is the worst case, not the mean or median case. Provided that you code well, its likely that GC pauses will always be well under 10ms.
Hi, can you please delete this as they *are* prizes available.
You can't just wait until the challenge is over?
Your best bet is probably to link to some c implementation. Video encoding is really all about speed. As fast as golang is, it's still not as good as c.
What does the cover art mean? Is it E.T. on a giant water slide?
Backend of service is in Go: https://github.com/peterbe/autocompeter 
I keep having ideas for cool apps I want to make that integrate with github, but never get past "first I gotta make all the endpioints for the oauth handshake work". My goal here is to have a drop in solution to let any web application integrate with github accounts as easily as possible. Any critique or suggestions are welcome.
Maybe this: https://github.com/jteeuwen/go-vlc
Also https://github.com/argusdusty/Ferret
I've been using https://github.com/3d0c/gmf with some success
Nice, thanks! I was just starting to think about using SSO today, so I'll be on the hunt for SSO libraries. Do you plan to support Facebook, Google, Twitter? Or if not, do you know of a lib that does?
It's working for me : $ ./main a bcd ef $ 6 Is that not what you were expecting?
Works fine for me 21:21:54 ~|⇒ go run args.go hello go 7
Cool!
Do you see that /u/enneff ?!!!!
mac, and the most recent version of go
Strange. Just ran it on my Mac w/ Yosemite and Go 1.4.1 and got the correct output. Also tried it on my Windows 8.1 machine w/ Go 1.4 and still got the correct result. Not sure what is happening in your case :\
You are counting the number of bytes in each argument. To count letters in a string, you must count the number of runes in the string
https://play.golang.org/p/h7zv1XVxy_ Maybe try to get a runtime not installed on your system to do this?
I misunderstood. If you run the program, it will have 1 Arguments. The program name itself will be args[0], but your loop goes for i &gt; 0. So not including argument 0. Now, 'go run' are arguments to the go process. Not Your program. My phone and I apologize for random capitalization. Rune is go lang way of dealing with utf strings while still being friendly to Bytes. See the rune package for help.
This really helped me.
Coming from a shop that runs both at Cassandra and Postgres at scale, the difference will really be in your use case and requirements. Need the ability to spread data across lots of nodes and don't necessarily need a relational data model? Cassandra is great. Don't have a lot of data (&lt;50-100G) and want to reap the benefits of SQL and relational data modeling? Postgres is great. They're both great tools, they just do things differently.
The profiling tools are really good, though. And Go is better at concurrency, which is arguably more important in order to get better performance. I think a pure Go implementation would perform adequately. In worst case, perhaps a function or two would have to be rewritten in C or Assembly and be used together with the Go code. 
Out of interest, how would one stop an HTTP listener gracefully? 
I stopped at Animal who can Speak. In idiomatic Go an interface with only Speak inside would be called Speaker. This stuff matters, and if the author doesn't know why, he/she is not yet ready to write about Go.
You could write a C function and use OpenMP for just the function(s) that would need extra optimization, then use Go for the rest. I think it could go fast enough with just Go, though. 
Hey I wrote this, hope it was helpful and any feedback is appreciated. 
The point is though you should be writing code for every piece of line of code you do (at least in theory). Before writing any error handling code ideally you should write a test which exercises the error condition which then lets you write code to handle it. I didn't mean to imply "ignore errors with a to do". I meant to imply "write a test, see it fail, write the code to pass the test and then refactor" - classic TDD. 
Well, you missed the point, I'm saying about ignored errors and not TDD. It does not matter where you ignore the errors, whether they might come from stdlib or your code, for code snippets they should not be ignored in the name of simplicity. The TDD is separate problem, no-one sane would write a test for every possible error upfront. 
I respectfully disagree with all three points. 1. Go might perform better. Only a good attempt at implementing this will conclude this. 2. Go can also use the GPU. Assembly can also be combined with Go, without the use of C. 3. Things can always be done better. "Hobby implementation" are your words. In short: you cannot know this, only attempt to discourage someone from trying.
- https://github.com/captncraig/ssgo/blob/master/hub/github.go#L62 - the hub package in "hub.NewGithubSSO" is non-relevant, you should consider renaming hub package to sso and dropping all SSO sufixes
&gt; Go might perform better. Not a chance. libavcodecs is essentially written in custom assembler where it matters. &gt; you cannot know this Yes we can. This is engineering, not magic. You are not going to beat avcodec. With all due respect, you may not have the necessary knowledge to make this determination, but others of us do. For us, this isn't even a hard question. You're basically claiming a semitruck "might" be able outrace a Formula One car, and we "can't know" the F1 will win unless we try it. Yes, we can in fact know the outcome. We don't need to actually physically race them to find out. And note how the semi's value to the world is not brought into question by the fact it can't outrace an F1 car. No person has ever failed to buy and use a semi because they sit there, stroke their chin, and go _yeah, but it just isn't as fast as an F1 car_. It isn't a problem that Go can't do this faster. It would have to be an _extremely_ different language to do so. &gt; only attempt to discourage someone from trying. Yes, absolutely I would discourage someone from trying to beat libavcodec's performance in Go! The ___absolute best case scenario___ is that you pour thousands upon thousands of hours into it, and either just tie the performance by writing in assembler or GPU code (i.e., "not Go"), or _lose badly_ by trying to write it in pure Go. Why would you encourage someone to pour that many thousands of hours into a goal that can't possibly be accomplished? Whatever it is you think you're doing, you're not doing it. You're not doing "advocacy", you're doing blind cheerleading. As for "what if they just want to learn about video codecs", yeah, sure, great, but they can do that in whatever language they like, then, since performance isn't really an issue.
I have a similar setup (haven't put it on github yet). &gt; A bashrc included in Amazon EC2 containers (which I don't use, I have my own secret bashrc, not part of this public release :-)) Can I suggest adding something like this to your .bashrc: if [ -f ~/.bashrc.local ]; then . ~/.bashrc.local fi You put what you're comfortable sharing in .bashrc, and put what you're not comfortable sharing in .bashrc.local. Then you can add "-v /path/to/bashrc.local:/root/.bashrc.local:ro" to the run command, or gitignore bashrc.local and add "COPY bashrc.local /root/.bashrc.local" to the Dockerfile. &gt; CMD ["/bin/bash"] Do you not use tmux or GNU screen? Using a terminal without a terminal multiplexer is like using a browser without tabs. CMD ["tmux", "-u2"]
The author just sucks at one of the two most difficult things in software development: naming things. Besides that it looks like a sound article although I only read half of it.
In C++, this would be a single function template, which would work for built-in and user-defined types. Once again, go's lack of generics leads to dozens of lines of boilerplate.
I've noticed the same thing lately. I hopped into irc to see if anyone knew what was up, but got no response :/
&gt; Go doesn’t have ternaries! Reason being, it’s sugar for an if-then, and if-then’s are statements, not expressions. This is just wrong. The conditional operator is not sugar for if-*else* (assuming the author meant if-else, the else is not optional) because it is *not* a statement but an expression.
Agree. Go just got this wrong.
I agree with you. But I also think ternaries sit on one of those syntactical grey areas where a lot of languages allow people to double-clawed-hammer themselves to death. If the rules surrounding ternaries were much much stricter, I think they wouldn't be so abused as they are in other languages. That said, Go is very good at defining a very narrow use case for language constructs, and Go developers seem to be perfectly OK with that. I think a ternary implemented in Go could easily be accepted even with strict rules around its usage. Besides, it's not like there's no precedent for ternaries. [This is a quasi-ternary statement](https://play.golang.org/p/YWoNsCyXgR) (line 12 specifically) This is I guess the one downside of a BDFL-driven ecosystem. I'd still a million times over prefer this over a language designed by committee though.
It's not wrong. You can transform every ternary conditional expression (be it ?: like in C or if/else like in Scala) into an equivalent if/else statement, e.g. with the help of a temporary variable.
You can transform a lot of things from expressions to statements. That doesn't mean the expression is syntactic sugar for the statement though (unless you consider the language syntactic sugar for machine code of course). Assume your language doesn't have a + operator but only an assignment statement (=) and an add-to-statement (+=). Then you'd have to express 'a = b + c' (an expression and a statement) as 'a = b; a += c' (two statements). Is the first syntactic sugar for the second? I don't think so.
In Go you usually aim for minimum packages. I see no problem with one sso package and several source files (sso/github.go, sso/github_test.go, sso/twitter.go, sso/twitter_test.go, etc.) and have sso.NewGithub(...), sso.NewTwitter(...), especially when implementation for each provider is not more than 100 LOC. Actually I would say one package is more user-friendly, as I would not need to jungle the packages and have everything in one place. Just a suggestion.
Right now 9fans.net is down [issue3](https://github.com/9fans/go/issues/3) which is why godef is not being able to build. For the github repo you might want to do: go get -u -v github.com/9fans/go/... Then just move 9fans out of github.com/ into 9fans.net and re-try the godef install it should work without issue. ex: mv $GOPATH/src/github.com/9fans $GOPATH/src/9fans.net That should be all you need to do, no need to change the import path in the godef code. 
I compiled it into my $GOPATH/bin (with go install) and have been running it from path. that is when i get the return of 0. I have even cd'd into $GOPATH/bin and run it directly from that folder, to no avail. Just now I tried with go build and running with ./foo, and that worked alright, same as go run foo.go, but still when I try and run the code from path it just doesn't work. what in the heck?! also, how do i check my path for executables of the same name? If I change the contents of foo.go to func main() { fmt.Println("FOO!") } run go install, and try and run it, it returns "FOO!" as expected. 
Very clever approach, I did not think about that (just recently got to workspaces/projects in the tutorial) 
... or just have a map to pointer type and then everything works as normal...
If you don't mind working around the language... But even in the case of String(), it's not always apparent that the "obvious" thing did not work.
Wow, cool! One suggestion: change the tagline "Select * from awesome." to something a little more descriptive for people like me who weren't already aware about what osquery is. Anyway, this looks really handy. Looking forward for a chance to use it.
Neat. I started building [something like this](https://github.com/maclennann/dashiell) in C++ using libosquery and libcfacter. Then osquery changed out from under me and I don't know enough C++ to get it compiling again :/. I'm glad to see someone else had the same idea.
Yea, I looked at that a bit while I was doing research. We should join forces - pm me if you're interested.
got it to work. Thanks!
I don't like it, but to be honest you will get much better community interaction on GitHub. 
You are asking two questions. First of all, if it is a non-git repo then it is a pain in my ass. I do know that homogenous ecosystems can be bad but git is so good that I don't know why someone wouldn't use it today. I don't even know what the heck dvcs is and while it may be interesting to learn I may want to just code instead. Second of all, any non github (or possibly bitbucket) repo means a decent amount of manual work to make sure I have an authoritative copy that I know works. I know it isn't much work but there are so many projects out there that any friction means I may look elsewhere. I know a lot of people just import from a repo they don't control, but that is bad practice. On github I can fork a project to a repo I control and know that it will never change under me and I know that I can easily pull in updates that I review. I don't want everything to be homogenous, so I do like when other people try different things. However you should be able to mirror your projects to github even if you personally use a different system.
Sorry to have involved you :/ Seems that it stopped those senseless criminal depictions.
&gt; Second of all, any non github (or possibly bitbucket) repo means a decent amount of manual work to make sure I have an authoritative copy that I know works. If you're going to make your own copy of code, why not just vendor?
I pretty much ignore non-git+github code. Not because it's not worth it, but simply because my attention and flow reside in Github and git's cli tools.
I don`t create any goroutine but seems like I got 5 gotoutines
Yes. And the OP wrote that he preferred another DVCS. Your point? 
Could not install package: 'UTILITY_PROCESS_CRASHED_WHILE_TRYING_TO_INSTALL'. Could not install package because a utility process crashed. Try restarting Chrome and trying again.
Left the tab open for a bit. My processors started getting pegged. Fan kicked on. Everything went back to normal after I closed play.golang.org. Chrome Version 41.0.2272.118 (64-bit), OS X 10.10.2
Maybe it should be called 9fan.
Not sure why you're downvoted. But if your attention and tooling revolve around GitHub, that does make alternatives not worth it doesn't it?
One here, just checking in while the cows get in the truck.
I could never get YouCompleteMe working reliably for me, due to all the python 2 vs python 3 mess. Thank you so much. Downloading now.
In case someone is looking for installation instructions: docker pull mrjn/godev docker run -t -i -v $GOPATH:/mnt mrjn/godev vi for opening any files in your host machine into the vi in the docker container 
I'm guessing that you should add: func init() { runtime.LockOSThread() } This ensures that the main function will run in the main-thread. Also GOMAXPROCS affects the number of threads not the number of goroutines.
Also, after taking a look at your code. * use go fmt/imports * use lower case names in files - that's the usual go way. * move non-specific things for current game to a sub package "game". This will make your code look nicer. I.e. you can use types such as `game.Object`, `game.Textures`, `game.Texture`, `game.State`, `game.StateMachine`, `game.Input`, `geom.V2`. * don't use "src". Use "intro_sdl" at the top-level.
Thanks for suggestion this is just play for learn Golang later I rebuild everything in more nice way. 
Thanks, finally got around to installing this.. seems to be working fine.
↑↑↑↑ THIS!!!! ↑↑↑↑ "Enjoy simpler programs."
Another important tool to prevent ignored errors : https://github.com/kisielk/errcheck
Thanks for reporting the issue (I guess I hadn't left the tab open long enough while developing the extension), I will try to get that fixed today.
Might be related the the issue /u/sethammons mentioned, ill fix it and get back to you.
Their point is this: &gt; I don't even know what the heck dvcs is
Ah, apparently I am the asshole then. I missed that line and thought the reply was trying to say something completely different. Downvote me and carry on. 
For some reason just modifying any of the existing elements on the page caused chrome to hang. This should now be fixed, let me know if you still have this issue.
I am currently in the process of switching my API handlers from Martini to simply http.ServeMux (and building on top of net/context) and find the code to be so much cleaner and, having an additional 18 months or so of Go experience, less clever. And that's a good thing. I also decided to go with just http.ServeMux after watching Blake's talk, but the takeaway I got from it was not "gorilla bad" or "all third party code is bad" but instead that dependencies are not free and you need to think critically about what a dependency buys you. If you really need sessions (and just not a simple cookie), then gorilla/sessions seems like a clear win to me. Is it really a good idea to implement signed values yourself? But if you're just storing something in a cookie, you don't need it. I don't really know enough about websockets implementations to have an opinion here. Is the one in gorilla a clear win over the one in golang.org/x/net/websockets? How about if the one in the net sub-repo were in the standard library?
http://www.reactiongifs.com/r/2011/09/mind_blown.gif
Right, I totally agree. Actually, looking at my code, it seems like I use a fair amount of gorilla/sessions, so that one is probably a keeper. However, gorilla/sessions, depends on either gorilla/mux or gorilla/context. The [overview](http://www.gorillatoolkit.org/pkg/sessions#overview) says, "If you aren't using gorilla/mux, you need to wrap your handlers with context.ClearHandler as or else you will leak memory!" This is the only gorilla/context code I use. http.ListenAndServe(":8080", context.ClearHandler(http.DefaultServeMux)) Also, what's up with sub-repo packages? I wonder what "may be developed under looser compatibility requirements" means and if the intention is to one day merge those into the standard library. http://golang.org/doc/go1compat#subrepos
I think most programmers, including myself, are inherently lazy, gluing libraries together gives the illusion of feeling you're focussing on your domain problem rather than the grunt work that surrounds it. Saying that though I don't think all dependencies are bad, I mean, writing a SQLite or POSTGRES driver seems like a massive pain in the ass, I'd rather pull that dependency in instead of writing my own. 
I'm the current maintainer of gorilla/mux, and even I don't use it all the time. for most web apps or APIs it's probably overkill, you only have a few end points. However for larger sets of routes I've found it does help keep things organized. Pick the right tool for the job :)
Looks very nice, and seems like it makes Go Playground work more like [Go Sandbox](https://www.go-sandbox.com/), I forget who made it but IIRC I stumbled upon it in this sub. One killer feature of Go Sandbox is that it leverages local storage to keep the last ran code snippet. Some people may or may not find that useful, but would something like that be possible to implement?
Are you getting blanks because you're not printing anything? {{ range $foo := index .FooCollections $user.ID }} {{$foo}} {{ end }} Also, have you implemented Stringer on Foo?
try {{ range $foo := index $.FooCollections $user.ID }} ?
Here's how I do it https://gist.github.com/icholy/dca5b9e079217f7446d1
I might be the only who thinks this, but laziness is exactly one of the reasons why I don't like learning frameworks. There are too many to learn and each one has its own patterns and language you must follow. Also, there's always a hip new framework that you should be using. (Glad I'm not a JavaScript developer! :P)
It may yield the same information but I would argue reading `/customers/{ckey}/orders/{okey}` is much more clear than `strings.Split(urlstring, '/')`
Is a little more readability worth a whole other dependency though? Maybe in some cases.
I haven't seen the talk, but from the snippet you posted, that way of doing things is *super* brittle. A little de-factoring and you can see why: func serveProducts(resp http.ResponseWriter, req *http.Request) { prefixLen := len("/products") key := req.URL.Path[prefixLen:] } This doesn't really match on anything prefixed with '/products', it matches on a huge number of URLs that happen to have at least as many characters as '/products'. By the time you write in more robust handling of URLs, your program converges on a big router, like Gorilla has. Only with less testing, and more (potential) bugs.
The serveProducts function is used as the handler for http.HandleFunc, most likely. That would do the pattern matching on the prefix.
Hi, I'm the author. The first one is called Animal instead of Speaker because I'm making fun of Java programmers.
this distinction seems overly pedantic and not all that useful. [http.FileSystem](http://golang.org/pkg/net/http/#FileSystem) only defines an `Open` method, but it's not called "Opener" because that wouldn't describe the *purpose* of the interface. [http.Handler](http://golang.org/pkg/net/http/#Handler) defines one method and it's `ServeHTTP`, not "Handle". [http.CookieJar](http://golang.org/pkg/net/http/#CookieJar) isn't called http.CookieGetterSetter because, let's be honest, that name would be silly.
I'm not implying that it's always a verb of the method – sometimes you do have a more complex interface. But I don't think it's a good starting point and especially not something as generic as `Entity`. For the sake of learning I would start describing the simple interfaces such as `Reader` &amp; co. I'm not here to be pedantic about your article, I'm relaying real problems of interface design that I've run into not only in Go but other languages. It really does matter how you name and design your interfaces, and good guidelines can help reduce code rot. The reason I mention this here is so that someone who reads your article might take that into consideration when they begin writing their code.
Many libraries solve non-existent problems and introduce new ones but there are some problems with naively doing everything using standard library with boilerplate code and duplication. For example if you use a switch to decode the method with a fallback for 405 handling that is fine until you decide you want to implement an Allow header or a CORS Access-Control-Allow-Methods header. Then you have to repeat yourself in the default section enumerating the methods you matched in your switch which could introduce errors. This could have been queried from a data structure. Using control structures instead you lost information.
You prefer Gophers, do you? So do I ;)
Really cool. When I first started looking into coding in Go this was the exact kind of thing I looked for to learn goroutines, but I couldn't find anything that helped. This would have been perfect. Chatservers make sense for learning concurrency. 
Here's a good article on the subject that explains the basics http://gary.burd.info/go-websocket-chat 
Nice, fyi i don't think the join and leave are safe. You're accessing the map directly should probably have a RWMutex for add remove (write), and use read when doing the broadcast.
Or channels like in my chat application: https://github.com/elcct/taillachat/blob/master/controllers/chat.go
Thanks!
That's a fantastic program for teaching a slew of Golang concepts, and wish I'd seen it back when I was first learning. I'll definitely be sharing it out with a few fellow neophytes for reference. Thanks for sharing!
I'm not sure we will ever. It's not a problem Google has. My biggest criticism of golang is how painful it can be when Google's use-case is different than mine, or yours.
This is interesting, but it seems like you're introducing a global lock on all actions by way of the channel. Locking on just the map access should be more performant.
I have had an excellent experience using http://godoc.org/github.com/mjibson/party It automates the "copy deps to a subdirectory and change all import paths" task, nothing else. No config file, no tags, no comments necessary. Manage your deps manually by updating them in your GOPATH using 'git' and 'go get', then update everything in your vendor dir with a single 'party' invocation.
I have a question. How would you go about securing something like this? If you're using js for the websocket, doesn't that mean every bit of information you send to the client is viewable by someone with even the most basic of knowledge? If you tried to implement something using tokens or salts all that information is accessible by the client.
Looks interesting! To make it more "Go" like, you should use a fully qualified path to the websocket package. I wasn't able to run go get github.com/indy-golang/simple-chat local import "./websocket" in non-local package
Not trying out the most simple and straight forward solution before creating something theoretical and computer sciency.
I think [golint](https://github.com/golang/lint) might be something you are looking for. Additionally you may find [go vet](https://godoc.org/golang.org/x/tools/cmd/vet) useful. These tools get you quite far.
http://gobot.io/ can run on arduinos, although now that I look at it I don't think anything is running on the arduino besides a bridge program of some kind. 
it doesn't run on arduinos sadly, it connects to them over serial and issues commands.
There is a recommended approach here from the Go team: https://groups.google.com/forum/m/#!topic/golang-dev/nMWoEAG55v8
And this is why I avoid YAML.
Cheaper than an rpi? If you have an rpi Model B(+), try [Model A+](http://www.raspberrypi.org/products/model-a-plus/)... Disclaimer: I don't own a Model A+, the cheapest decvice I run Go on is a Banana Pi. 
Read again please. OP already uses the RaspberryPi.
The worst I've seen can be lumped into one of two categories: * Trying to code with a formal *OOP* approach * Trying to code with a formal *functional* approach These approaches map very poorly onto Go at a certain scale and sophistication. Formal OOP requires lots of data hiding, and accessor/mutator functions (think Java). Formal functional programming in Go requires something like generics or template support, unless you're okay with casting everything to/from interface{}. Go deliberately cuts its own path by resembling "a better C" than a better Python, C++, Java, Haskell, etc. To that end, it works best with a C-coder's mindset of structures for data, and functions to manipulate that data. The addition of interfaces in the language makes some common casts and other common kinds of encapsulation easy to do. Now, one mistake I found myself making was trying too hard to accomplish *nested diagnostic contexts* for stack-based logging. I had the realization that, since goroutines can be created anytime, anywhere, these logging contexts could become huge under the right condictions. Nevermind that it's not possible to pull off without goroutine-local storage, or passing logggers around everywhere. I learned that it's better to be more simple and direct when logging, and just describe the context for the current function call; don't worry about what context you're in since you could just be the root of a goroutine's stack. Edit: failed to read your Edit, OP. Sorry about that. If I can recall anything specific, I'll post it here.
&gt;"a better C" That actually makes a lot of sense despite the fact that the only C I've ever written has been during an undergrad class. I'll be sure to bear this in mind, especially since I felt myself blush when you mentioned OOP and functional approaches... &gt;Now, one mistake I found myself making was trying too hard to accomplish nested diagnostic contexts for stack-based logging. I'm having trouble understanding exactly what you're talking about. Could you please elaborate?
Converting between []byte and string and back repeatedly.
&gt; Formal functional programming in Go requires something like generics or template support, unless you're okay with casting everything to/from interface{}. I don't understand why this would be true. Doesn't strict functional program only imply that functions are devoid of side effects and that state is passed as (generally immutable) objects? The lack of generics certainly makes DRY hard to follow, but it doesn't seem antithetical to functional programming. Am I missing something here?
Are you using the sublimetext plugin? I've installed gometalinter via `go get`, checked that it's discoverable via `which gometalinter`, but I can't seem to install `SublimeLinter-contrib-gometalinter` from ST3's package manager...
&gt; I'm having trouble understanding exactly what you're talking about. Could you please elaborate? I'll admit it's not a commonly used approach. Let me explain. Generally speaking, the industry does the wrong thing when generating log output for consumption by centralized logging aggregators like Splunk. Our typical approach is to just format a string with %s interpolations so a person can read a nicely formatted sentence. What you really want your web server to do is generate key=value sequences on a single line per log event so map/reduce can chew on the data and generate useful information and alerts: priority="DEBUG" message="user logged in" username="eanderton" last_login="1 Apr 2015" priority="ERROR" message="something bad happened" In this approach, for a *typical* multi-threaded application, it helps to provide additional context so you can distinguish one thread's logging from another. Rather than pass this contextual information down the stack to every possible call in the program, you use a *Nested Diagnostic Context* to build that into the thread's local storage, which is implicitly picked up on every call to the logger. Now we have really useful log lines, each one of which can be used *in isolation* to diagnose a potential error: priority="DEBUG" tid=12345 message="user logged in" username="eanderton" last_login="1 Apr 2015" priority="ERROR" tid=12345 message="something bad happened" username="omginternets" last_login="1 Apr 2015" session_id=7890 Now that error stands out as belonging to completely different user! Before we'd have to guess using timestamps, or to just try and re-create the error on a test box with nobody else logged in. What i learned is that the elegance of this approach relies on thread local storage, unless you explicitly pass loggers around all over the place. Go has no such animal for goroutines, and with good reason: an application can have many more times goroutines than any traditional application would have threads. Since it's possible for goroutines to yield goroutines, forever, you could wind up in a real mess if you tried to manage contexts in this way. At the same time, if you disallowed a goroutine from inheriting a parent's logging context, you severely limit the effectiveness of the approach. You simply can't get there from here without some bad consequences. More info: https://lizdouglass.wordpress.com/2009/12/09/nested-diagnostic-contexts/ TL;DR: NDCs provide implicit currying for log data. They rely on TLS which isn't available in Go for non-obvious reasons.
1. Concrete types where interfaces should be making it harder to test / stub. 2. (related to 1) Not doing tests from the start, tests impact program design -- hard to test code is probably not your best code. 3. Lots of embedding / confusing embedding with inheritance. 4. Trying to "tag" goroutines for various reasons, logging is the most common (and least atrocious), but I have seen far worse. 5. Channel-insanity is a condition that seems to be suffered by gophers with no experience in concurrency or threading prior to Go. They see channels and concurrency as the answer to all problems. They complicate up the simplest programs gaining no benefits and often huge downsides. 
This is something I have a hard time with. For example with http.Get() I always have to convert from []byte to a string in the response.Body because I'm really looking for some specific portion of the HTML. What should be done instead?
I tend to fork a lot and use forked versions
Not trying to pick an argument, but why would you be casting everywhere and using bare interfaces? Functional doesn't imply that the functions are generic, sure you repeat yourself when you write the same function for two different signatures to account type difference, but how much code do you write expecting that you won't know the type going into a given function? That seems like an anti-pattern, yah? I too find that lack of operator overriding to be bothersome, but I don't see what that has to do with functional programming either.
Yeah, also look at effective Go if you haven't already and try out the next Go challenge for this month!
&gt; Channel-insanity This is usually multiplied by the fact that "good" and "idomatic" channel-based code is extremely copy-happy. Reliable? Yes. Correct? Absolutely. Runs like molasses in January? You better believe it.
Here's one: Using panic/recover in the main flow of a program. This should be self-explanatory. :)
Fork Go and pull their lame GC and bug fixes.
Not sure I agree, I haven't found channels more copy happy than other go code, and in almost all cases we implemented them for performance gains. 
~~Just be careful because it's also eXperimental (/x/) and just as likely to change out from under you as anything~~ Edit: Don't listen to me I have no idea what I'm talking about.
In just about every case, you can do anything you can do with strings with []bytes. For instance, the "bytes" package has near equivalents for most of the functions available in the "strings" package. Are you using some HTML parsing library which only works with strings?
&gt; However, gorilla/sessions, depends on either gorilla/mux or gorilla/context. That's unfortunate. One of the strengths of gorilla is that it is meant to be small, useful, independent parts you could take or leave. When dependencies like this creep up you start straying into "framework" territory. &gt; Also, what's up with sub-repo packages? I wonder what "may be developed under looser compatibility requirements" means and if the intention is to one day merge those into the standard library. I think that is a possibility, but not necessarily the plan for all sub-repo packages.
what's the best practice to avoid this? 
I wish the Go project would adopt gopkg.in like they did godoc.org. Excellent project and core to the ecosystem IMO.
Too many packages, too many files.
stick with one as long as possible, which one doesn't really matter, choose the one that gives you the least conversions.
Thank you for the tips! I didn't think of a race condition there.
you probably want to wrap that []byte in a bytes.Reader and then pass it to something that consumes an io.Reader, not a string.
Raspberry Pi (any version) is pretty good, that's a real computer for $35 bucks. The Edison is interesting, it's an old P2 32bit intel machine in less than two square inches. Price is higher than the Pi, and it's much harder to use for real IO because of it's stupid 1v8 io voltage. I've love to be able to run Go on the cortex-M series microcontrollers, but we're not there yet.
It's working nicely for my use-case of adding plaintext versions to HTML emails. I couldn't find any pre-existing go packages which do this, if you know of any please chime in!
&gt; Functional doesn't imply that the functions are generic, Depends on your definition. If your idea of functional programming is the older idea of "first-class functions", sure, Go does that, but that is becoming a useless distinction since pretty much everything does. If you mean map/filter/reduce, then your definition of functional _does_ imply some form of generic, as the signature of map is something like `(a -&gt; b) -&gt; [a] -&gt; [b]`. I use Haskell since this is inexpressible in Go type signatures. Functional programming is theoretically possible with you manually writing the "map" definition every time, but that's not much fun.
copies are cheap, garbage collection is expensive; this is true even for very large values of copy.
Environment variable with a sensible default in its absence, such as ~/.yourprogram/ or something similar?
&gt; Gopkg.in requires the cooperation of the package author. For beyond v0, absolutely. I don't consider this a flaw. &gt; Many people think that gopkg.in solves problems that it does not actually solve. What is the misunderstanding people have about it?
I like gopkg.in -- but am not to the point I would like it blessed yet. 
Use the flags package and make it a command that you pass in when the program executes. Or just tell it where your config file lives via the flag and roll with that.
That looks like just the thing I need. 
Could you add to the README the text output from your sample program? I'm curious if the output is formatted in any way but can't test it out at the moment (on a phone)
i love that Rust is in there. it's like a communist Great Leader: nobody has seen him, but they all profess their love for him!
Perfect analogy.
Well, that question was about which language you want to use. The previous question covered the most popular languages in use (both rust and go are absent from that list, btw). And when you consider that it's not really unsurprising that rust and c++11 ranked so highly. Think of how many c++ programmers there are dealing with legacy codebases, and how many of them would want to update to a modern c++ toolchain or to a rust as a replacement.
how do you mean? All I'm doing here is providing the same interface over rpc that you would get if just calling the function natively, rather than having to pack an "arguments" struct and initialize a pointer to a response like the `net/rpc` does.
Absolutely, I have updated the README to include the output. Thanks for the feedback!
With NotePad++ being first in http://stackoverflow.com/research/developer-survey-2015#tech-editor I seriously doubt of this survey :D
could be wrong, but I feel that you can't iterate through the list like what Contains and the top of Add/Remove do, while being safe.
Go actually makes a distinction between slices and arrays. http://blog.golang.org/go-slices-usage-and-internals In Go it's more like: var s []byte = []byte("Hi this is a string") is *almost* the same as var s string = "Hi this is a string" They are both essentially a slice of bytes, but Go's typing means that they are not *exactly* the same, switching between the two requires a type conversion. https://golang.org/ref/spec#Conversions
I was under the understanding that the string doesn't actually hold runes, but that runes were decoded from the string which is a read-only slice of bytes. https://blog.golang.org/strings
Yah, my mistake. I knew something somewhere was experimental, and I recently had `golang.org/x/tools/astutil` move out from under me and I just correlated those two things in my mind.
So is C++11. :)
Haha apparently some devs never have the opportunity to use javascript
Tools that help enforce a convention (like golint) can be very helpful a great deal of the time. Such tools also lack the context of your mental model of the application and are therefore at a disadvantage some of the time. If "BufferAt" more effectively conveys what's going on under the covers, or if it aids readability of the surrounding code, or if there's some other good reason for keeping it that way then who cares what golint says? Do what you think is best. Sometimes brevity hurts more then helps, and repetition isn't always bad. Just my 2 cents (but be warned, [I still use "this" and "self" for receiver names](http://michaelwhatcott.com/go-code-that-stutters/)).
&gt; Upon closer examination of the data, a trend emerges: Developers increasingly prefer spaces *as they gain experience*. Stack Overflow reputation correlates with a preference for spaces, too: users who have 10,000 rep or more prefer spaces to tabs at a ratio of 3 to 1. I also prefered tabs for the first 5+ years programming. I finally saw the light and switched to spaces.
&gt;The whole damn thing just goes in /opt/&lt;my-project-name&gt; for the containers they run in. I don't see anything saying he's using containers. And anyway most of the world doesn't use containers, so it's not like that's a common pattern that you can look down upon for not using. &gt;Seriously, if you're going to fuck with the unix system FS, then use a damn package. Do you really think nobody used a Unix-like FS as it was intended before package managers came along? /etc, /usr/bin, /opt, /var, etc all predate package managers. And plenty of systems are deployed, configured, and maintained without package managers. You don't need to use apt to deploy an init script and binary.
"Saw the light"? Nope. You just deal with shitty editors and/or other people with shitty editors. A tab is an abstract representation of one level of indentation. How wide it actually is just depends on your editor's configuration. Embrace that. And if any of your tools somehow substitute tabs for spaces or vice versa or assume a certain amount of spaces for a tab, they are shitty tools and you should abandon them. Seriously, there is nothing enlightened about spaces for indentation, just self-limitation. Learn to resist bad tooling, instead of suffering from Stockholm syndrome and claiming that broken spaces are actually better.
This is a "perfect world" argument. "In a perfect world where everyone uses great tools... yadda yadda... we would use tabs." But we don't live in a perfect world. We do have to deal with other people's code, and they have to deal with ours. It would be nice if saying "use better tools" was like waving a magic wand over every programmer, but it makes more sense to adopt a common indentation strategy than make wishes. I didn't even learn about the tab/spaces debate until another programmer emailed me to complain about the way my code was indented in *his* editor. So it's not even a matter of what tools *I* choose to use. Other people have to read my code too, and again, I can't wave a magic wand and make every other programmer use better tools. I'm also not going to choose my tools based on their tab/space support. If the tool accomplishes 95% of my needs, then it's the tool I'm going to use. There's no perfect tool that does everything you want. You have to take the good with the bad sometimes.
Tabs for indentation, spaces for alignment.
Ok, so I haven't read your code but perhaps you could remove the stutter and use a word other than At. I have started to try and avoid stutters in code as for me they slow down reading and understanding. 
There's no reason to with `gofmt`. Just make it mandatory to run code through it before committing. This way I can have my apparently now uncool 4-space indenting in peace...
Because you can't do this. import "github.com/gorilla/websocket" func main() { websocket.ChatServer() } Gorilla websockets just buys you the websocket connection, not the whole chat server.
Sure, but I guess my question is, why re-invent the wheel and do the low-level websocket code again, when you could just build the chat server on top of existing gorilla websockets code. I guess I didn't quite word my question that well.
No, the survey was simply flawed. On windows we generally use an IDE like Visual Studio. But there was no option for "Visual Studio". So people marked Notepad++, which is also used for occasional text editing on windows.
Completely agreed. Envvars especially are the nicest solution for most PaaS offerings too: they are used extensively in Heroku and friends for service configuration. It also plays nicely with things like Upstart if you're going down the self-host route.
Generally I include a json config file at the same directory level as the binary. I will usually check for existence at start-up and error/exit if it doesn't' exist or is improperly configured. In some apps I include a command line option to generate a sample file. I haven't treed the ENV route because I wasn't sure how that works in relation to cross OS issues. It probably works fine but I didn't read up on it and I prefer a local JSON file because it's obvious where the config file is and there are no hidden config values (i.e. is it global, is it local to the user, bash_rc vs bash_profile etc)
I'm not sure what you mean by "it just breaks". You should see busy_dist_port errors telling you on the sending side of the connection that there were disterl timeouts happening.
I might integrate this into [fork](https://github.com/thrisp/fork/tree/develop)...but with interfaces. Certain kinds of functions benefit from being chainable.
&gt; You just deal with shitty editors and/or other people with shitty editors. Uh, not really. Everyone seems to have their own idea of what the ideal tab-width is, most especially code-editor authors (whom never seem to agree), coding standards notwithstanding. By using spaces instead of tabs, it makes it impossible for your code's formatting to be accidentally skewed or misunderstood in anyone else's editor. Should everyone standardize their environment to best receive all the great code that's out there? Sure. Will human nature get in the way of such a grand plan? Absolutely. Sometimes, it's best to engineer around stupid/lazy wherever possible. Now, if someone decides to use a non fixed-width font in their editor, they're beyond help.
Polls are often just popularity contests, and not indication of how good something is. Notepad++ is popular.
Nexx WT1520 - $15 (size tiny compared to pi). Just pita to use gccgo to compile for MIPS target. I am looking for cheaper option also, prefably arm and has wired ethernet. http://www.sajalkayan.com/post/golang-openwrt-mips.html
Sounds good. Does this work with Windows as well? I would guess at least that setting the environment variable might be more difficult there. But I could check whether it is set and if not use a default location depending on the detected OS...
Which uses tabs for indentation... 
oh excelllent......
Thanks for the link, it's worth a read.
&gt; But we don't live in a perfect world. We do have to deal with other people's code, and they have to deal with ours. It would be nice if saying "use better tools" was like waving a magic wand over every programmer, but it makes more sense to adopt a common indentation strategy than make wishes. Of course we don't live in a perfect world, but you're doing exactly nothing to even get closer to that perfection. Go and configure your editor properly, to insert tabs when you press tabs, and to show tabs in the width that _you_ prefer. If somebody commits or otherwise contributes code and messes up indentation, call them out and tell them to properly configure their editor. Without any effort, nothing is going to change! &gt; Other people have to read my code too, and again, I can't wave a magic wand and make every other programmer use better tools. Well, you can tell people that they should look into their editor configuration and set the tab-width to their own personal preference. You can't force anyone to do things, but you can still point out sensible ways of handling tabs in your editor.
Wow, such uppercase! Previously on reddit: https://www.reddit.com/r/golang/comments/304otq/stablelib_lts_distribution_of_curated_go_packages/ (Edit: I will answer your questions on either thread.)
Don't yell at me.
&gt; So I'm not sure where to ask this You might also try Stack Overflow and the mailing list. http://stackoverflow.com/questions/tagged/go https://groups.google.com/forum/#!forum/golang-nuts
That's the magic behind the JSON methods. Let me know if the subqueries can be optimized.
It's not clear from the initial documentation, how you would do arbitrary SQL operations. This feels a lot like an ORM - trying poorly to cover all the use cases you might want, and becoming a prison when you want to do something that isn't natively supported. On the other hand, for simple apps that don't have too much risk of outgrowing the framework, the performance may make it worthwhile. I'd love to see benchmarks for common databases.
While those stats may not be precisely what you're looking for, it's likely that "precisely what you're looking for" would turn out to be very difficult to define if push came to shove. There's a similar question that gets asked by new Linux administrators, "How much memory is a given process using?", and it's really difficult to nail down what that question even means in the presence of shared memory. Those numbers are probably close enough that optimizing them will tend to do what you're looking to do.
gofmt putting tabs into source files is the reason I don't use it on mine. The actual Go language is great though!
I'm a bit embarrassed to admit that hadn't occurred to me. Thanks!
is medium really the best website for posting technical, in-depth programming articles? you could just make a GitHub repo and write the article in Markdown there. GitHub will let you set up websites within repos, which is pretty nifty. Medium seems to be more focused on opinion pieces. But, maybe that's just the articles I've seen. Another reason it might not be the best for code stuff: &gt; I had to change the -&gt;; to a `:` because the formatting was crying about it, sorry!
Configuration must be separate from binary - because it leaves a very consistent structure for where to find things. Logs are in `/var/log`, configuration in `/etc`, binary in `/usr`, etc. This structure means that no matter what your service is, or in what format it logs, or where you deploy it, will always act the same as all the other services. It gives predictability to anyone else using, maintaining, or operating your binary. It's easy to jump onto a box and immediately understand what it can do, how it goes about doing it, and what it's been doing just by looking in a small amount of predictable locations. It also makes it easier to permission the different bits. You should want configuration to be editable by anyone, logs to be readable by anyone, and the binary should only ever be writable by people with deploy privileges. Throwing everything in one directory means that whomever owns the directory owns everything; a pretty large code smell / deployment fiasco / security risk. Finally, It gives you the freedom to size partitions as required - since your data and logs (which are ever-growing) don't sit on the same partition as your binary (which is hopefully static). If your goal is an executable that isn't dependent on any other files, you ought to be espousing *flags* (which can optionally be controlled by the init script). And if you want something that is operated by users who can't be expected to know any of the above, you should be encouraging a gui.
I'm not sure how useful this tutorial series will be. The first clue came when `go fmt` reformatted every file. When I examined the code for the lexer, I found some oddities in the way numbers and identifiers were tokenized. The lexer recognizes `.12.34` as a number. It does not recognize `x_` as an identifier. It looks like these were written by translating a regular expression instead of the EBNF. I've written my share of lexers, parses, and interpreters in other languages. I wanted to see how one would go about writing these in idiomatic Go. I still consider myself a beginner with Go, but I saw some coding practices that did not look like they used the full power of Go. What do more experienced Gopher think of this tutorial?
So it's hosted with heroku at http://www.dickbutt.in I expect you all to trash on it. Please do!
Vitess supplies [WriteFileAtomic](https://github.com/youtube/vitess/blob/master/go/ioutil2/ioutil.go), looks similar. 
Using [readthedocs.org](https://readthedocs.org/) would also be a good alternative.
Um, I'm currently writing an entire application stack using Docker and Kubernetes. Kubernetes themselves use Salt for most of their low level OS customization, and they certainly don't store everything in /opt . Container deployment practices don't replace OS package deployment practices. They're different, for many reasons.
How would you suggest doing so? I was just reading the source of [gorilla context](https://github.com/gorilla/context/blob/master/context.go) It looks like a good way of attaching a context to an http.request, but it doesn't actually wrap net/context. I read the [article by Sameer](http://blog.golang.org/context) that explains how they only pass contexts around in google. I was wondering how one would wrap the net/context in an http server.
which is totally fine - because people incorporating your code later can choose whether gofmt your code or not, and be happy with it.
The relevant [source](https://github.com/github/git-lfs?utm_source=gitlfs_site&amp;utm_medium=source_link&amp;utm_campaign=gitlfs) for the lazy.
I love you.
Why post it three times?
i'm with you. I much prefer "var" if i need to choose. Not that it matters, i'd still prefer a cool language with "let" over a bad language. That's just syntax
You mean, using `ioutil.TempFile` instead of our own `makeTempName` function? It was discussed in the bug tracker: the disadvantage of `TempFile` is that it requires an additional `Chmod`, and potentially produces guessable filenames (https://golang.org/src/io/ioutil/tempfile.go#L26), which I'd like to avoid.
For those of you interested in various http handlers provided in the framework so far: https://github.com/servemux
In fact, any help with wrapping net/context would be greatly appreciated! :-)
I also have a very stripped down one I've been using for a while: https://github.com/dgryski/gttp This one seems much more full-featured.
Hello, jazoff, I'm pretty new in Go development and because I don't have yet portfolio nor solid reputation in Community, I decided to join some OS projects in Go. So i serched in Google golang "contributors wanted" and your post appeared on the top of search results :-) I saw that you have no replies since 30 Jan. and I hope that you still search contributors. If you already found them, nevermind. I will be glad to make a contacts to you and another Go enthusiasts to help myself in earning experience and reputation. Best regards: Angel Naydenov
Awesome, thanks!
You might also want to try looking at golang.org/x/sys, which is where any new syscall development is occurring. https://github.com/golang/sys/blob/master/windows/syscall_windows.go
You can start building up a reputation helping closing issues on known projects... You can look at trending repos on github, for example: https://github.com/trending?l=go
I'm not a big fan of Polymer, but thanks for doing this. Please do a video on hosting Go on Compute Engine VMs. I'm a bit new to docker and I would honestly prefer watching a good video than reading the instructions since there are many moving parts. 
Yawn
I've been looking for something exactly like this... I'm working on a scheduling app for android and I'm new to this whole CalDAV standard protocol. So I recently got employed as a Go developer this past week.. I started about a month ago so very recent Go dev. Lol I searched "golang caldav" and found this.. Im with /u/adnaydenov hope you still are looking for contributors.. I can definitely benefit from this, It would be my first time working with open source.. I will be graduating this May so I can jump onto development roughly around June.
This was very informative! Thanks
Thanks for the suggestion.
I see what you mean, and it is a good point. I can point you to where the [proof](https://www.mpi-sws.org/~viktor/papers/ppopp2006-listrg.pdf) for this is but even I have not read the whole thing yet. I can also say that the nature of the operations is fault *tolerant*. Since Each operation returns True if and only if it was successful in either (locking, marking, then) removing, adding (and updating pointers), or finding and element, we can know when an operation failed and handle it accordingly. This is definitely something I will want to test for in the future, thanks! 
That's cool but what's with the makefile?
(slightly offtopic) I haven't looked at safefile at all so I can't comment on it, or its usefulness, but vitess is a **huge** project to vendor for something like that. I really wish they would break it up into smaller pieces, because there are quite a few useful packages in it (I'm looking at you, sqlparser)
what? curl *is* for humans... 
Aha, I copy many useful packages including sqlparser from Vitess too. 
I sent some code refactoring. Please take a look. :) https://github.com/arjun024/whats/pull/1
I admit that it may feel clunky to someone used to just doing a git tag to create a release, but I guess it works just as well for the user (and with less versioning confusion for the author perhaps :)
Not nearly as fast as Redis itself, but nice work. 
big file upload is not supported in httpie
Aha, I have not used uploading big file before. For httpie, I only use it with Elasticsearch. 
i'd prefer we just use godep's format
For some reason "grep | wc -l" instead of "grep -c" surprised me.
It's my repo. I am a C programmer and trying to learn golang. how do you do this thing the go way @/u/Raiyni
Older versions of grep did not have that many options... Last year I discovered grep had a recursive option (-r). 
Ah yes, that's for reminding me. I'm still using find and xargs for that.
Have a look at https://github.com/google/cayley it's graphDb written by google in Go. 
One of the best things about httpie is the pretty-printing (and colorization) it does for things like JSON. I hope this is on your roadmap. I also notice that the printing of the request isn't what is sent on the wire: $ bat -v GET https://api.serverdensity.io/alerts/configs/?token=XXXX filter='{"subjectID": "rfm-stage"}' GET /alerts/configs/?token=XXXX HTTP/1.1 Host: api.serverdensity.io Accept: application/json Accept-Encoding: gzip, deflate Filter={"subjectid": "rfm-stage"} User-Agent: bat/0.0.1 (maybe this is because I was trying to force bat to send a body with a GET request?)
yea, colorization is next feature in plan list. yea, you use Get request, and you spec the body which has colon , so bat treat it as a header
It has its own in memory and leveldb that come by default. It can use any key value store as a back end that you make an interface for. Its not terribly complete some querying features feel missing and labels don't have functionality.
*I* know how to do it ;) I was posing more of a question as to whether this framework (ServeMux) had an approach of its own—i.e. an approach that any "included" middleware would also use. As you point out, writing your own custom handler types is easy, but sharing context between your stuff + other's stuff is not. By the time you use CSRF middleware (often something you don't want to write yourself!), sessions/auth middleware, logging middleware and so on you may end up with 3-4 different context implementations that can't communicate with each other.
I am now pretty certain of the algorithm's safety. The calls to validate in each operation are the failsafe for if a process stops right before locking nodes. Once a it resumes it locks the nodes, then checks to make sure its the right node. Then it continues. I still plan on rigorously testing this to make sure my understanding is correct but I do appreciate you challenging me! This is what makes open source great.
I was confused when I first started using database/sql coming from other languages. Most All other languages refer to a database connection simply as connection. When I see DB, I think single database connection. I feel connection more accurately reflects that is is an acquired connection from a connection pool. Another reason is `dat` originally had two runners---sqlx and pgx. I didn't see the performance gains in pgx and stopped the effort. The original idea of a session was a single non-transacted connection akin to what is found in other language data access libraries. The benefit would be not having to acquire a connection each time. There is no concept of a session in `dabase/sql`. Session is just a transaction underneath. I may deprecate it for 1.0.
You need a hierarchy. So for example, on disk: $GOPATH/src/project1/pkg1 $GOPATH/src/project1/pkg2 $GOPATH/src/project2/pkg1 $GOPATH/src/project2/pkg2 you would then import those as import "project1/pkg1" or import "project2/pkg1" The import statement directly translates to a path on disk rooted at your $GOPATH/src If you use an online source control system like github, with a url like https://github.com/yourname/project1/pkg1 this would be put on disk by `go get` at $GOPATH/src/github.com/yourname/project1/pkg1 which you would import as import "github.com/yourname/project1/pkg1 
Nice read! Thanks for posting a well written article. 
I'm always glad to see more discussion around the sharp edges of actually using net/http properly in production. I would love a detailed guide in the spirit of http://gobyexample.com and http://go-database-sql.org as it relates to net/http and the related issues with Dial, Transport, timeouts, contexts, cancellation (http.Transport.CancelRequest), KeepAlive gotchas, etc. It's quite easy to leak resources by using things like http.DefaultClient
&gt; putting every package you ever write into the same namespace is insane No. **Not** making sure *every* package you write has a **globally unique import path** is insane because it's the right thing to do and it's also so trivial to do so.
Because it's simpler and more useful to use types with custom marshalling (e.g. in the example given have `LastSeen MyTime` and do the appropriate (un)marshalling on `MyTime` and re-use that type everywhere it's needed; that type would be either `type MyTime time.Time` or `type MyTime struct {time.Time}` depending on the specific needs).
Yeah, but then you need to cast everywhere you want to use it with the standard library.
The scientific term for this is "sleep sort"
You could scale the sleeping time down to get a faster sleep sort. 
But if you start scaling down to too small time values, the numbers would probably appear in the wrong order. If there was a time cap, some numbers could be lost, but it would guaranteed to run at a fixed time. Perhaps these errors would look interesting when applied as a 2D image filter, where some pixels were gone and some were in the wrong order? Perhaps there are uses for an overly optimized sleep sort algorithm? 
Yes, even 100 * time.Microsecond resolution does wrong order on my laptop. )
You really should accepts those first two commits from mattn. Not following the Go formatting and import standards is much like using goto-statements, it's not illegal but is highly frowned upon. If I can't `go get`your package I won't use it.
One way is to first start developing a project in, say, $GOPATH/src/github.com/username/myproject, where GOPATH might be ~/go. Then first start developing in one relatively large source file. Then refactor it into several source files, based on which types and functions fit where. Then create new packages for where functionality seems to be separate, for instance $GOPATH/src/github.com/username/myfileformat, with "package myfileformat" at the top of every source file. Then import that package in "myproject". It can be useful to have a script for testing and building code if source code in either package you are developing are changing, perhaps using inotifywait. There are also tools that help with building and developing, but the above worked for me. YMMV. 
This may be a noob question but what's the difference between passing `num` as an argument to the goroutine (as in the code sample) and just actually using num inside the closure (remove passing `num` into the goroutine and remove the requirement of an arg)?
The difference is between closing over a variable thus sharing it vs passing it by value thus copying it. If you close over the variable, the loop may change the value by the time the goroutine actually begins execution. (the "go" statement only guarantees that the goroutine will start execution after the statement but it doesn't say anything about when) see: http://golang.org/ref/mem#tmp_5
thanks, I'll have a look
Rewriting my rewrite above, this would close the channel appropriately: args := os.Args[1:] nums := make([]uint64, len(args)) for i, arg := range args { nums[i], _ = strconv.ParseUint(arg, 10, 0) } c := make(chan uint64) for _, num := range nums { go func(num uint64) { time.Sleep(time.Duration(num*resolution) * time.Microsecond) c &lt;- num }(num) } for i := range nums { nums[i] &lt;-c } close(c) fmt.Println(nums) Note that we know ahead of time exactly how many outputs we're expecting, so we can wait for that many values to come out of the channel and then close up shop.
I've never heard of it, thanks!
I ignore them and keep using Go when it's the right tool of choice. 
Sure, perhaps it's not the best benchmark, however Hello World in both pure JS and Go is under 100 bytes. Minified, the 700+ KB goes down to 440+ KB. Gzipped, it goes down to 110KB. Not terrible, but could be better.
This strikes me as a pretty big step backwards from some of the more modern cloud deployment setups that have become available in the past three years. I really can't imagine why I would ever want to use this over e.g. Ansible+Docker.
The WaitGroup should not be any more flexible, as it will wait until the appropriate number of goroutines have called Done (any fewer and it will wait indefinitely, any extra would not be waited for, which can lead to bugs depending on use). You could just as easily increment a counter in the for loop and loop up to that counter amount when receiving from the channel. In cases where the output and input amounts differ, your logic should increment and decrement the counter just as it would Add and Done the WaitGroup.
Would you mind posting this question/answer over on stackoverflow.com too?
This won't work for any CGO packages (gxui); from said article: &gt; Out of scope &gt; &gt; Cross compilation while linking to libraries via cgo is the holy grail for some. &gt; Sadly the changes mentioned above do not change the situation with respect to cgo. In fact you may still need to rebuild your Go installation in the traditional way to pass environment variables like CC_FOR_TARGET. Please try it out.
If the sleep is as small as possible, while not getting rid of it completely, it could be a very predictable algorithm with a fixed runtime, while not being that inefficient. All algorithms have advantages and tradeoffs. Perhaps sleep sort could have a use, somehow?
&gt; All algorithms have advantages and tradeoffs. Advantage: Funnier than most sort algorithms. Tradeoff: Not useful.
Positive advice for the relatively new: the Go folks have written a lot of *advice* about Go, not only straight-up documentation. Effective Go, the FAQ, code review comments, the blog, the relatively short spec, talks, etc. Versus the many hours coding takes, munching on these is cheap. Peek at code, too. Standard library is readable and linked right from the pages at golang.org/pkg/, and there's Github and the code you're actually using right in your $GOPATH/src/. Also, check the breadth of tools and resources out there. Libraries and talks and so forth not only from the Go team but others at Google, SoundCloud, Dropbox, Facebook, etc., and some independent tools that're well-respected (Negroni, Gorilla). There are all kinds of tools for statically checking and testing code, visibility into how it's running, etc. (go vet, golint, gofmt -r and gorename, go test -coverprofile, memstats, memprofile/goroutineprofile, etc.). Breadth can be as valuable as depth in any one area. From responding to a ton of Go StackOverflow q's, common problems: - Trying to make Go into $language, sometimes by using package reflect to make generic functions. Typically you just write a bit more code, or use a built-in feature like type assertions/switches, instead. - Trouble understanding pointers and pointer-containing types like slices, strings, etc.. Folks use pointers to, for example, slices, which you rarely want--at greater length: http://stackoverflow.com/questions/23542989/pointers-vs-values-in-parameters-and-return-values/23551970#23551970 - Discarding the error that made their code fail. Use https://github.com/kisielk/errcheck/ . - GC paranoia. There are real horror stories, but early fears often turn out unjustified, or the program can be fixed by pooling big objects or changing memory layout for fewer pointers. - Weak understanding of synchronization. Learn package sync; pass around larger chunks of work, not each of a billion items individually; assume *nothing* you don't enforce. Read http://golang.org/ref/mem -- the Zen of it is the order of all concurrent events is ¯\\_(ツ)_/¯ until you use something to force synchronization. - Relatedly, most APIs shouldn't be async (http://talks.golang.org/2013/bestpractices.slide#26). Your caller can make a blocking task async by running it in a goroutine. Consider that net/http is great for concurrent work but exposes no channels, etc. - In the same vein--a handy thing about interfaces is your caller can define one around a type in your package *even if you don't*. So export an interface if you need *others* to implement it; you don't have to preemptively wrap your concrete types in interfaces. https://medium.com/@rakyll/interface-pollution-in-go-7d58bccec275 - Trouble with dependency cycles. This isn't something I so much see folks get *wrong*, but going by votes, it's apparently thorny for a lot of people, so: http://stackoverflow.com/questions/20380333/cyclic-dependencies-and-interfaces-in-golang/20394211#20394211 - Panics: this has been gone over a lot. They're for crashing the task (app, Web request, etc.) after your code's core assumptions have been violated, often by a programming error (slice[-1]) or system-wide condition (RAM ran out). Not for: end-user data failed validation, item not found, flaky client from the Internet--those are frequent and/or recoverable enough to belong in normal flow control. Don't worry; I came from Python and my first app had this all wrong too. Contrary to some scolding, some tricks, including panic-using ones, are accepted by the Go folks to deal with extreme err != nil-itis: see http://blog.golang.org/errors-are-values, regexp discussion at http://golang.org/doc/effective_go.html#recover, http://golang.org/src/compress/bzip2/bit_reader.go#L12, and my blathering at https://news.ycombinator.com/item?id=8877673. More err checks than Python are to be expected, tho', and that's OK.
I know what charitable_view's talking about: folks use, for example, pointers strings, not realizing they're making a pointer to a pointer-length pair. More: http://stackoverflow.com/questions/23542989/pointers-vs-values-in-parameters-and-return-values/23551970#23551970
No, because what you're really doing is forcing the kernel (or perhaps the Go runtime in this case since it has its own green thread scheduler) to do a *real* sort in order to figure out which task to wake up next.
http://stackoverflow.com/questions/15205481/how-to-use-go-with-ldap-protocol
The runtime I specified pertains the naïve approach of calling all the `Is...` functions (one for each class). They take a constant time each since the classes are fixed.
You might want to have a look at https://www.arangodb.com/. It's multi purpose database but it supports graphs quite nicely. Beside the standard [HTTP API](https://docs.arangodb.com/HttpApi/README.html) there is a [Go driver](https://github.com/diegogub/aranGO) but I never used it so I can't comment on the quality.
I recently switched to using https://github.com/mjibson/party for this and I'm quite happy with its simplicity so far. Here's the project where I'm using it: https://github.com/daaku/rell. It allowed me to put all my deps in /internal/.
Package unicode in the standard library gives you the tools to identify the range a rune falls in. The actual unicode names are not available however. You would need to use the tools in golanh.org/x/text to parse the unicode db to find them.
Fixed now all the tools are are tested on the code ie vet, lint, test and goimports. Thants again for the feedback.
You seem to be confusing Bolt for a distributed system. It isn't.
Titan seems really nice, but can you point to any Go drivers or a way to access the database with Golang?
They discuss this in the readme: Bolt was originally a port of LMDB so it is architecturally similar. Both use a B+tree, have ACID semantics with fully serializable transactions, and support lock-free MVCC using a single writer and multiple readers. The two projects have somewhat diverged. LMDB heavily focuses on raw performance while Bolt has focused on simplicity and ease of use. For example, LMDB allows several unsafe actions such as direct writes for the sake of performance. Bolt opts to disallow actions which can leave the database in a corrupted state. The only exception to this in Bolt is DB.NoSync. There are also a few differences in API. LMDB requires a maximum mmap size when opening an mdb_env whereas Bolt will handle incremental mmap resizing automatically. LMDB overloads the getter and setter functions with multiple flags whereas Bolt splits these specialized cases into their own functions.
This is fantastic! I didn't think that Go was designed for embedded systems. What hardware are you running this on? Any chance of writing up the full build?
OP asked a very clear question: how to get the name and the Unicode properties. The hex representation isn't the name and isn't the properties.
&gt; Will CoreOS continue to ship Docker? &gt; &gt; Yes. 
Nice! I would be interested in controlling heating for brewing ales. It does seem though that the modulation of the temperature could be more closely controlled. Doesn't it just fluctuate between the minimum and maximum which is a fairly wide range. Can you develop some system where it tunes itself to a target more closely based on the rate the temperature changes over time? Say for example it takes 1 minute for the temp to drop 1C with the compressor on and 5 minutes for the temp to rise 1C with the compressor off, you could set a time for the compressor to run based on how far away it is from the desired temp, and then a minimum amount of time for the compressor to be off. This would allow a very tight bound without cycling the compressor too much.
The README.md on the Github page lists the hardware it's running on: * Raspberry Pi * Some temp sensors * An SSR kit from sparkfun * A standard chest freezer
If u mean Go not work on iphone? This going to be improved at August release
The thing you must understand is that people may have different motivation and that Reddit is not a workplace. With a background from the demoscene, I'm always on the lookout for algorithms that can be used for 2D or 3D effects. The sleep sort has the potential to be used for a 2D effect. Will it look interesting? That's to be seen, but who are you to discourage and demotivate a stranger?
I've parsed the unicode.org files in the past, for something related to a project that needed English, Arabic and Chinese languages in the GUI. The details are mostly lost now.
This project is interesting. The voluminous unicode data resides in a server process that you can start up as required. I would have thought to use an on-disk database rather than place the data in process memory. Once you choose a multi-process solution, a server in Python could server up the data without the need to parse and load the source data files. 
Cool, looking forward to your next part. Currently examining lexing/parsing, so I found it interesting. BTW for those interested: here is another blogpost from 2014 which was pretty insightful: http://blog.gopheracademy.com/advent-2014/parsers-lexers/ and it's accompanying [Github repository](https://github.com/benbjohnson/sql-parser). The code is heavily inspired by InfluxDB, apparently.
As far as I know this is not (yet) possible in the standard time library. A quick google gave me some hints about it being on the Roadmap but I can't find anything more on the subject. I did find a package https://github.com/mattbaird/go-i18n-formats but it doesn't look complete to me. Other i18n packages that I found seem to be only about translations tho... For now I would work with template functions to handle it... 
Yeah, this is exactly what I've found :). Hoped someone did have another answer though. Going to solve it like this for now :).
You chose a bad example—as far as I know, the Mongolian writing system doesn't distinguish between upper case and lower case.
Here be dragons, example c++ code that does... something like what the Go example does (kinda, not really, but it's funny) http://codepad.org/XxXpLtxo
what's wrong with https://tour.golang.org/welcome/1 ?
yeah you're right - that's also good advice :P
I was recently looking for a PEG generator and Pigeon, despite being brand new, is leagues more stable and usable than any of the alternatives. About the only real issue is that the error reporting is poor to nonexistent. Eg. "No match"
I was trying to _encourage_ a stranger to truly think, instead of doing something that superficially looks like thinking but is really a profound failure to apply judgment. But now I see you've fallen victim to the popular idea that any sort of judgment is somehow a threat to your self-image. Carry on then.
You are one 100% correct, I am actively building that system out now. The tricky part for me is detecting when it needs to "break out" of the algorithm on rapid temperature changes (this happens when I open the freezer door to change out a keg or grab a can). I am also trying to weigh the impact of short rapid compressor engagements. The short periodic starts aren't a problem for a burner, but its not awesome for a compressor. My genetic algorithm experience doesn't go much beyond a single course in school and some reading, so if you know of some good prior work throw it my way.
That's an inaccurate interpretation of the situation. You are the one that is unwilling to comprehend here. Lossy algorithms really can be useful for 2D effects. You are the one that is reacting like what I said is a threat instead of admitting you have no imagination and is incapable of understanding the motivations of others, and uses of algorithms thar you had not thought about. 
Slices themselves ar small enough to pass around by value and they were designed to be passed around by value. So a pointer to a slice wouldn't make that much sense. If your Job objects are already in a slice by value ([]Job) then creating and passing a []Job slice would be trivial. While creating and passing a []*Job slice would require a few more lines of code.
Creating a pointer to a slice is silly. Just create a slice of however you want to naturally store your objects.
That doesn't sound right. The slice will be copied but it carries a reference to the backing array. The reference will be copied but not the backing array. The jobs in the backing array would not get copied. The receiver would have a copied slice but full access to the original job backing array. Or am I missing something?
Local meetups?
Before you go all genetic on this thing, use what fridges already use, PID controllers. See godrone.io for a PID controller you can look at.
I am writing a reStructuredText parser for Go that uses the same principle. https://github.com/demizer/go-rst So far, Rob Pike's parser design is scaling pretty well!
IMO in the rare cases where something like this is desirable a better approach (which I got mostly completed in the past as an exercise) would be to take fully valid and compiling Go code (possibly with it's own test cases so you can test your "generic" implementation is correct), parse it with the existing ast package(s), change out the types, and write out the modified source to a new file. E.g. Take `set_stub.go` something like (a silly example with a trivial set implementation): // +build ignore package foo type T int // Placeholder // T_Set is a set of T type T_Set map[T]struct{} func New_T_Set(n int) { return make(T_Set, n) } // Add adds i to the T_Set. func (s T_Set) Add(i T) { s[i] = struct{}{} } // Remove removes i from the T_Set. func (s T_Set) Remove(i T) { delete(s, i) } // Has returns true if i is in the T_Set. func (s T_Set) Has(i T) bool { var x T // note, useless extra variable just for show x = T(i) _, ok := s[x] return ok } And with a gogenerate line containing something like `T=int` produce a file something like this: package foo // IntSet is a set of int type IntSet map[int]struct{} func NewIntSet(n int) { return make(IntSet, n) } // Add adds i to the IntSet. func (s IntSet) Add(i int) { s[i] = struct{}{} } // Remove removes i from the IntSet. func (s IntSet) Remove(i int) { delete(s, i) } // Has returns true if i is in the IntSet. func (s IntSet) Has(i int) bool { var x int x = int(i) _, ok := s[x] return ok } (note the extra variable in `Has` is just to show template re-writing) 
&gt;By using spaces instead of tabs, it makes it impossible for your code's formatting to be accidentally skewed or misunderstood in anyone else's editor. Thats the point of tabs though.. if everyone uses them, it doesn't matter how it looks in anyones editor because it is consistent. Imagine if the enter key on your keyboard worked like tabs. Instead of inserting a \n, it inserted some number of pixels down to the next line it should go. I'd rather let my editor decide what to do with the 'next line starts here' character, you know, some fonts need more spacing than others, some people like more crowded text than others, etc. I feel the same way about the 'this block of text is indented' character. Also, I'd never go non-fixed width, but I would count that as another win for \t as at least then you could make indentations still stand out.
None other than simplicity and repeatability. copy+paste with search and replace was how I was doing it before I wrote this :) Also was curious if it was doable. oh I so wish we had generics :( I love working in Go. It is the only thing in the entire workflow that really frustrates me.
One thing you might want to alter about you code is to use a value receiver for your MarshalJSON method. If someone passes MyUser{} instead of &amp;MyUser{} to json.Marshal right now, it'll use the default Marshal implementation instead of your custom method.
I too wrote the tool that does (most of) what I gave just as a proof of concept (and to play with the ast package). In practice I've never really needed anything like this (e.g. I call the set example I used "silly" since in practice when I need such a set I just write out the couple of lines it takes and often use a map of bools directly without methods. Just as whenever I need sorting I just write out the trivial one-liner `Len` and `Swap` methods in-front of the sometimes more involved `Less` method that are needed for `Sort.Interface`).
Do you have a contact e-mail?
Definetly, this is now how I've done it. Using a simple map[time.Month]string. Just was wondering if there was a simpeler way though :). Or if it was actually part of the standard Go packages, couldn't find it. Thanks for your input :).
Most of my search queries in fact ended up at Location instead of locale, indeed :D. Can imagine the confusion.
Well when you provide some such a simple and well proven system for this problem it makes me sad. I kind of want to go all rube goldberg on this thing, but I suppose a PID would be a much better idea. Thanks for the tip.
There are a lot of libraries for making RESTful APIs on Golang, what sets this one apart from the rest? Currently a Gin user and new to Golang, would love some input from a Gopher with some experience.
It responds with a 200, but it might be best to make that adjustable. I could envision cases where people might want to return a 202 or a 204.
Thanks for sharing. I must admit, though, I am not sure when assertions like these would be useful: expect(p).To.Have.Field("X") since types are checked at compile-time.
It's like a fun house full of mirrors with all the `reflect`ing going on.
Heh, I arrived at the exact same idea of using `_T_` in the method/function/type names to be replaced while implementing (never finished it) my own go generics implementation.
Not so fast. Wait till you have to tune it. And, also, you will need to incorporate hysteresis elements in order not to destroy your compressor. Perhaps you'll feed the sensed temperature to the hysteresis algorithm and use its output to feed the PID but that destroys the advantage of the PID. Perhaps you'll feed the output of the PID into the hysteresis algorithm and use its output as a signal to control the compressor. In the end you must reduce the output of the PID to start/stop (and hold) signals. Really up to you, but decisions, decisions, make sure to plot the behaviors under several scenarios and include the scenario where you open the fridge door. *But*, at least you will save a monstrous amount of work. And your contractee / employer will thank you for it. Fascinating nonetheless.
Why?
What is this I don't even
Username entry field seems to have some requirements (at least longer than three, not sure if more) but fails to tell them to the user. It even complains "Please match the requested format" but, alas, no format is ever requested.
The room and username textboxes would look better if they were aligned: http://i.imgur.com/pYsuKYF.png Also on the join room page, if you give a password that's too short it gives the same message, "Please match the requested format" but no format is specified. Those very small nitpicks aside, this is a really nice project. Simple, functional and useful -- great work! Also I like the fact that no logs are kept. This is one of the best things I've seen in this subreddit.
Yep looks fine after a no-cache refresh.
Let's try it out [here](https://niltalk.com/r/RqklS). Password: the site you're on, without the domain ending, all lower case. Edit: room is down. Thanks to the guy who joined, typed "neat" and then tried the "dispose room" functionality.
One more tiny nitpick on grammar: on the homepage (and in your OP edit) it should read "dispose **of** the room", not "dispose **off** the room".
Eek, fixed.
Which brings up the question if the "dispose" function shouldn't be restricted to the "owner" or at least provide some feedback to the owner about who closed the room.
I have used this, but switched to pigeon. I had the following issues: - Failure to parse my .peg grammar with no indication where the error occurred. - Generated invalid code with a switch on a byte with a case of '&lt;nil&gt;'. - The source is ... very difficult to comprehend. I tried to write some patches but gave up :(
There is no concept of ownership at all. When a room is created, it exists as a random piece of string with an encrypted password. Peers connect and disconnect. For an owner to be attached, there will have to be some form of registered users, which is goes against the idea of simple, ephemeral chats. A notification of who disposed of the room to all the connected users is a good idea.
Personally I find the [assert](http://godoc.org/github.com/stretchr/testify/assert) style of testing works much better with Go code than BDD...
Thanks for the link, I will definitely look at that. I'd love to make error reporting better.
Togglebox.
&gt; For an owner to be attached, there will have to be some form of registered users You could set a session cookie to identify the owner of the channel: http://www.gorillatoolkit.org/pkg/securecookie
what about a majority vote on room disposal? hitting the dispose button auto counts as a [yes] vote. everyone else sees: guest a has requested disposal: [yes] [no] or if only one person is in the room, and they hit dispose, no vote.
You don't have to run it to give feedback on the code.
I don't know if that works with the exact goals of Niltalk. A vote system, or any such dependency could be a problem in case of emergencies where one needs to quickly dispose of for privacy reasons. Then again, the service is intended to be used by small private groups of people who're explicitly invited to have a short conversation, unlike in a public context where someone could randomly hit dispose to annoy participants.
Thats against the best practice, you should have 1 workspace.
good point, i would expect people in the chat to be invited which would/will reduce trolling.
Hi folks, We are mostly a java shop and have been steadily migrating the client side utilities that we develop with golang based binaries. All things aside, being able to deliver a binary with no dependencies is hugely helpful, reduced support overhead significantly. This is our first attempt to provide a library to make it easier/consistent to build code that interact with our API. Any feedback will be much appreciated! 
Brand spanking new to encryption but I don't believe I am. A KDF would create (derive) all the keys from a constant correct? This system uses symmetric encryption where the user creates a key for the message and the server never records it. 
This is awesome! I have additional feature request: Instead of having password protected room you could implement SRP to protect conversation and only clients would know plain text. This is additional security since no plain text information is available on server. 
Mine uses whatever string is provided (e.g. "K=string V=int" or "T1=MyType T2=OtherType", etc) and replaces `T`, `Foo_T`, `T_Foo`, or `Foo_T_Bar` (Under the assumption that idiomatic Go code otherwise avoids "_" in identifiers). For types like "int" it capitalizes as appropriate (or an alternate can be specified). The annoying thing that I never bothered getting fully correct was editing the comments.
Have you seen talk.gg?
This article was well researched. Considering Golang's popularity in China, I'm glad the author highlighted that `go get` defaults to http instead of https. China has already been caught hijacking javascript and injecting their own malicious code into it.
Nice article, i hope we see much more of them as Go adoption grows. I would also be happy to see #infosec folks use Go for the nifty tools they now create using Python
Is it by design that most of the banners seem to get dense near the right end?
"As data is indexed only by time we decided not to include any dimensions as columns but rather as part of the series name. [...]" -&gt; This is luckily solved by tags in InfluxDB 0.9.0 (still not released), as those are efficiently queryable. However, the whole use case (dealing with purely numeric time series data instead of event data, wanting to drill down by dimension, and no downsampling) sounds very well fit for Prometheus[0]. It will need an order of magnitude less storage space[1], and I'd expect query and ingestion speeds to be higher too. For example, on a modern server with SSD, Prometheus sustained an ingestion rate of 340k samples per second, belonging to 2M time series, scraped from 1800 targets. (Full disclosure: Prometheus author here.) [0] http://prometheus.io [1] https://groups.google.com/forum/#!searchin/influxdb/prometheus/influxdb/qxgtzbmCNcY/HqZJllJAWB4J
http://i.imgur.com/puYHdJg.png
&gt; go get defaults to http instead of https. s/defaults/falls-back-to According to the issue, `go get` defaults to HTTPS but when it cannot connect via HTTPS, it _falls back_ to HTTP. It does not _default to_ using HTTP.
Coming from PHP land, where there are tons of bad examples, I think it ultimately doesn't matter. It isn't your job to make sure somebody else's code compiles or is even safe. The onus is on the programmer to make sure that their work is working and is safe in their environment. Excessively harping on them about handling errors, or down voting an otherwise helpful answer isn't conducive to someone learning something new. Edited to add: unless the question is specifically about how to handle some ~~error~~ boilerplate problem, ignoring boilerplate should be fine.
Anyone used it yet?
I somewhat agree but on the other hand I can't stand the outright incompetence I see all around the software industry. And it may not be my job but it is my (and everyone's) problem when we have to use software written by people that are barely competent. I'm reminded of: &gt; Weinberg's Second Law: &gt; If builders built buildings the way programmers wrote programs, &gt; then the first woodpecker that came along would destroy civilization. &gt; -- Gerald Weinberg
Critically, that is functionality equivalent to defaulting to HTTP (in the presence of an active attacker), as the standard tactic is to simply block the secure connection &amp; wait. IIRC, Moxie mentioned this during a Q&amp;A during his SSLStrip talks a few years back - someone asked if they could defeat his exploit by having browsers try HTTPS first by default. His response explained that if an insecure transport is even an option, the order of attempts is irrelevant. HSTS headers are a hack attempting to combat this, and can solve cases like accessing your bank from a coffee shop after accessing it *earlier* from home. This is of doubtful help to go get, given the usage model. Not a lot of great options here if the goal involves supporting a plaintext transport. I'd be in favor of requiring an --insecure flag (or similar) such that you have to explicitly demand insecure code delivery. 
Also, lol. :)
Loost the link?
Stop trying to make Go into Node. :/
I use vim/tmux/iterm2 exclusively. Well, I use XCode for some of my Obj-C work but only as much as required :) If you want the gory details here is the Apple reference material for FSEvents. https://developer.apple.com/library/mac/documentation/Darwin/Reference/FSEvents_Ref/
I have not dug into the internals of the fsnotify package asmuch as I did the fsevents. I am under the same impression as you that it uses kqueues and file descriptors. This also explains the "to many open files" error I often get when I watch my entire Go repo...
Sorry, I was being a dick and making fun of the "loosing" typo in your title. It's one of my pet hates when people say loosing instead of losing.
&gt; This is really cool. Do you plan to release the avatar generation as a stand alone library? Are you going to monetise this service? :) Thanks for your feedback, * Yes, I would like to release the avatar generation as its own library to separate it from the web site. * I won't monetise it (I like things that are free :) ) 
Then why vendor at all?
as a follow up, it was a good idea to code it myself, for the same task : btcrpcclient : 1448416 ns/op mine : 833563 ns/op Not that it'll matter but I prefer that way. 
They are database for time series, meaning that they are engineered for ingesting a costant flow of data and make aggregate queries over intervals. They are best suited for analytics purposes (es: monitoring cpu/memory usage over time) or measurement over time in general. Hope it's clear (and, well, correct)! 
I'm still studying the argument, but I'll try to respond at the best of my knowledge. No, they work with other requirements. Loss of data is acceptable when you are interested more in the aggregate than in the single data entry. A failed write is acceptable more than slowing the write rate. 
No, they're not transactional as you're just doing inserts that's independent of previous data. My [slides](http://www.slideshare.net/brianbrazil/devops-ireland-systems-monitoring-with-prometheus) from a talk two weeks back might help you understand the idea. (Another Prometheus author here.) 
Slices are references to arrays. They consist of a pointer to the backing array a capacity and a length. Just pass the slice around by value, unless you want to be able to modify the original slice.
&gt; This is currently an open issue for fsnotify. It may happen because when you save a file, at least on my OS X Vim configuration, Vim creates a new file and then renames it to test.txt (or at least that's my hypothesis, based on the reported issue). &gt; That is the way kqueue works, yes. The best work around right now is to watch the directory containing test.txt instead. On the other hand, FSEvents is really only for watching directories, so it's not really a problem there. Though BSD users (kqueue) with a similar Vim setup would still need that workaround. I'm not sure the long-term solution yet? Maybe to only allow watching directories in all cases? Maybe to drop kqueue altogether and resort to polling on BSD? Maybe there is some trick to get kqueue working that I don't know? Hard to say.
I don't see why you would ever use this :s
https://github.com/tools/godep
I like gopkg.in as an alternative to the others.
It says &gt; The approach endorsed by the Go project is "vendoring" (described below) and godep is a well-maintained tool for managing vendored dependencies. So go kind of recommends godep
Thanks Nathan. Very helpful blog posts. 
Why is the second example not appropriate? Seems pretty clear what you need to do. Error handling is its own topic and something the devneeds to think about.
Nice. I've probably got the worst workflow you can think off. One xterm with vim on one half of the screen, and another xterm where I type go run. Hm.
Git submodules.
I use GoSublime + SFTP plugins for Sublime Text, and my web framework watches for file changes on the server (running in tmux) and reloads itself with the updated code.
Go is a hobby of mine but would very much enjoy to get paid for it. I've probably written in excess of 100k LOC of Go. My main project in Go is around 50k LOC across 20-30 packages and I've been working on it in my spare time for nearly three years. My development machines are all Arch Linux (Gnome) tri-monitor desktops set up like the following: * Left monitor: portrait running terminator with two horizontal splits. Shell is zsh. * Central monitor: horizontal running gvim, single vertical split, looking very similar to OPs (molokai theme, vim-go, airline, bunch of plugins from Shougo.) * Right monitor: horizontal running chromium, with email and documentation practically permanently open. I switch editors quite frequently but always end up coming back to Vim. Was using Emacs for a week or so very recently, playing with Atom with vim-mode at the moment but feels a bit clunky. vim-mode in Atom is quite impressive though and definitely makes Atom usable, and go-plus works rather well.
1. Gvim + spf13 + vim-go 2. Tmux + zsh + guake 3. Vagrant + docker I like to run my dev environments in the Vagrant machine for production parity. (I use arch, whereas we generally have Ubuntu servers). GVim is good once it's set up with spf13. Feels sorta like an IDE, not quite as smooth as intellij or visual studio, but free OSS. Really excited at the prospect of NeoVim. Basically I code up in vim, hit F12 to bring up guake, and I'll have a couple of splits in my tmux. One with vagrant and another local. The local one I'll use for godoc or gofmt or whatever, and I'll build/run on my vagrant. With vim-go it runs gofmt on your files on save, which is nice. But I also add some git commit hooks to run gofmt, go vet, go build, and whatever unit tests I have. I don't have any watchers set up, mainly because of the issues with inotify and vagrant. I'd love to have something like this though, especially for tests. A couple of packages I use: 1. Ginkgo + Gomega for tests 2. Hopwatch for debugging (not a true step-through debugger, but has breaks and nicely formatted object dumps) 3. Godep for dependency management 
I use the Atom editor with the go-plus package, an xterm to run the application (mostly a server) and a browser.
Two terminals in i3. One using vim to code, the other to run and build the project. I see people using all sorts of tools and haven't really jumped on that train. I'm guessing the majority here are more advanced than me so let me know what I'm missing.
I've found the vim mode in atom less impressive than sublime personally. 
I'm not sure if an unhanded panic is considered a security risk or not, but it could give an attacker information about your application. The one thing I see with people's go code is that they don't handle panics correctly. Often, there will be a single panic catch at the top level of the application, but that won't catch any panics inside of goroutines (they need their own panic catch). If a goroutine panics in your app, it will bring down the entire thing. I usually use a goroutine wrapper in all of my code that catches panics and propagates them up to the main application. At first, I thought that a panicking goroutine would panic up to the main application automatically, but it doesn't. This is not a bug, but it's also not intuitive.
He said it's not inappropriate 
The advantage to this approach is that you could start over on a fresh system, and still be just as productive immediately after installing Go.
I have been using goimports for a while but never realized it also ran gofmt automatically as well! That would definitely improve my workflow, thanks. Also, I have a bootstrap file that I use for go vagrant machines. Basically installs go and sets up godep to use the dependencies in the file. If you want I can shoot you over the script. It has some specific things in there for my workflow, such as using godeps and installing some other dependancies, but you can tailor it for your personal use. If others are interested I can post it here as well. Man, I really need to start a blog or something.
* Airline with Powerline in vim. * Molokai colo but I change around a lot * I use a color scheme for iTerm2 called Atom. * I also use godlygeek/csapprox in vim to help approximate what MacVim would show. * 12pt Droid Sans Powerline Plus * The tmux line is configured to be out of the way and show very little. * zsh | edited for format and clarity
&gt; http://imgur.com/uQ2b8K9 The users slice should be of len(records) - 1 size.
I think you quoted the wrong image.
This: https://github.com/ziutek/emgo/tree/devel/egpath/src/stm32/examples/l1-discovery/heating piece of code controls my dh24100 flow heater and house heating system. It works on STM32L1-Discovery.
Lol, I knew that when I posted it but thought, "Who's going to notice?".
yes! And at least him and rsc from core go team are currently using it. The nice part of acme is that you can easy extend it wit go, or shell or anything you like.. check 9fans.net
Here it is. It's very simple, just installs go and builds the project. It is specific to a Debian-flavored distro because of the apt-get stuff. Installs Golang 1.4.2, you could parameterize that. There is probably a vagrant image with go already installed in their repos, but I wanted to start from a vanilla ubuntu box. You have to add the command to run the project yourself, if you want it to run after provisioning (like if you're running an API service): #!/bin/bash ############################################## ######### SETUP ############################################## if ! command -v git &gt;/dev/null 2&gt;&amp;1; then echo "INSTALL GIT" apt-get -y install git fi if ! command -v hg &gt;/dev/null 2&gt;&amp;1; then echo "INSTALL MERCURIAL" apt-get -y install mercurial fi ############################################### ######### BUILD STEPS ############################################### if ! command -v go &gt;/dev/null 2&gt;&amp;1; then echo "INSTALLING GO" cd /tmp/ wget -q https://storage.googleapis.com/golang/go1.4.2.linux-amd64.tar.gz tar -C /usr/local -xzf go1.4.2.linux-amd64.tar.gz ln -s /usr/local/go/bin/go /usr/bin/go mkdir -p /go/src/github.com/my_github_user ln -s /srv/projects/my_project/ /go/src/github.com/my_github_user/my_project GOPATH=/go/ go get github.com/tools/godep GOPATH=/go/ go get github.com/onsi/ginkgo/ginkgo GOPATH=/go/ go get github.com/onsi/gomega cd /go/src/github.com/my_github_user/my_project GOPATH=/go/ /go/bin/godep restore # Helps when ssh'ing into the box echo "export PATH=$PATH:/go/bin" &gt;&gt; /home/vagrant/.bashrc echo "export GOPATH=/go/" &gt;&gt; /home/vagrant/.bashrc echo "cd /go/src/github.com/my_github_user/my_project" &gt;&gt; /home/vagrant/.bashrc echo "sudo su" &gt;&gt; /home/vagrant/.bashrc echo "export PATH=$PATH:/go/bin" &gt;&gt; /root/.bashrc echo "export GOPATH=/go/" &gt;&gt; /root/.bashrc echo "cd /go/src/github.com/my_github_user/my_project" &gt;&gt; /root/.bashrc fi echo "BUILDING PROJECT" cd /go/src/github.com/my_github_user/my_project GOPATH=/go/ /go/bin/godep go build ############################################### ######### RUN ############################################### echo "RUNNING PROJECT" # PUT YOUR RUN COMMAND HERE 
I build using go 1.4.2 from MS Windows at work. My setup is gVim, "misc/vim" copied over from from go 1.3, and gocode. I tried installing "go-vim" but couldn't get it running after 10 minutes. I abandoned it for 1.3's "misc/vim" scripts and couldn't be happier.
D'oh, sorry. Reddit doesn't let me edit title text. I'll be more careful next time I post.
Honestly, I just want a highly available Log/Metrics layer that can survive a WAN partition or a BTTH on 40% of active nodes [e.g. 3/5 surviving]. So can you get your AlertManager/dedupe [which I believe is your SPOF?] to that level of capability so I can actually see if its usable. Thanks.
I use acme in full screen for everything too! Do you use a fixed-width font for Go? I gave variable-width fonts a try for a while (since variable-width was the default in acme), but gofmt-ed structs were not nice to look at, so I stuck with fixed-width in the end.
Ah ok, the article states "InfluxDB is receiving [...] 1.2 MB/s" and I took that to mean writing 1.2 MB/s. Either way, they're still looking at running out of disk within months, seemingly without a plan, which is still pretty scary.
Yes, making Alertmanager highly available is definitely the goal, but hasn't received high priority yet. Of course, you can always build your own component that either receives and handles alerts from Prometheus (in place of Alertmanager), or build something equivalent that periodically queries Prometheus instead of getting alerts pushed to it. As far as I can see, most of the other popular time series database solutions don't have built-in alerting at all, so that component would be missing there as well.
question about InfluxDB on StackOverflow http://stackoverflow.com/questions/29494195/how-to-make-influxdb-accept-cross-origin-requests
Sure - that's a fair point :)
An odd comparison, might i ask you to elaborate a bit more? _(I ask, because Node is a server application, where as Gopherjs would be designed for Browser)_
I see what you did there :)
One of the biggest reasons Node is so popular is it lets a web project be written ENTIRELY in javascript. Nothing else. That means one set of code standards, one repository of common company assets, and one (technical) criteria to evaluate contractors for. All very useful things. Go is immensely helpful for implementing projects on the server, but cannot be run in the browser, so any web project must involve at least two languages: the client-side people using Javascript and the server-side people using Go. Along with the aforementioned fragmentation issues, this tends to reinforce the divider between those groups of people, when for a successful project it's best to have everyone operating as a cohesive whole. Using a common language helps with that.
Node is a way to run javascript, traditionally meant for the browser, on the server. This is a way to run Go, traditionally meant for the server, in the browser. They're both a way to consolidate your tools and use the same language throughout your project.
I can see where he's coming from now, appreciated :) 
Sublime Text to write code. I use `docker-compose` to run my application, run unit tests, run cucumber tests, initialize my database, and even to run `go fmt`. Using `docker-compose` allows me to not have to keep track of a local go install and all the dependencies. I use a `Godep` file alongside `gvm` to install dependencies in my `docker` containers.
You need use [flags](http://golang.org/pkg/flag/), or build some user interface (command-line, gui, web-interface, etc).
Or use `net/http/httptest`: want := []byte("hello world") srv := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request){ w.Write(want) })) defer srv.Close() resp, _ := http.Get(srv.URL) defer resp.Body.Close() got, _ := ioutil.ReadAll(resp.Body) if !bytes.Equals(want, got) { log.Printf("want=%q", string(want)) log.Printf(" got=%q", string(got)) t.Error("want body, got something else") }
This is a great idea. Three recommendations: 2. Use full function names. Such as CelciusToFarenheit or MetersToMiles etc. You are going to have a *lot* of functions, and if you take shortcuts with the naming then users will have a hard time guessing the proper function name and will have to go back and look it up all the time. If you consistently use the long-form then I can just use PoundsToKilgrams or YearsToMilliseconds without thinking about it. 2. Use floats by default and provide an Int function. For example CelciusToFarenheit(c float) and CelciusToFarenheitInt(c int). 3. Make it a library, but also make it a command line utility (perhaps called convertunits). How cool would it be to be able to go type this in bash:. convertunits "10000 meters to parsecs". 
I use `ed` to edit my code, which I compile with `go build` and check in with `git` every once in a while.
Vim-go author here. Sorry to hear it. vim-go is now very stable and lots of fixes are merged. Binaries are not required if you don't use the specific features (such as oracle,godef, etc..). Let me know If I can help, I really want to deliver the best possible Vim experience :) Thanks
Thanks! Websocket already connects over 'wss'.
Write some [tests](http://golang.org/pkg/testing/) that covers your convert functions. 
There is no benefit from the use of echo (and similiar libraries) at all. Custom handler with custom properties (database connection pool, logger, extra services) plus net/context gives much better results or even gocraft/web.
Do you really need videos for systems/backend programming? 
Front-end JS or back-end JS? Blog posts about front-end JS frameworks would, unsurprisingly, have far more 'visual' aids than a posts about a server-side language...
There are a couple (so far) videos of Andrew Gerrand and Brad Fitzpatrick just hacking on some Go stuff, which I've found really entertaining and educational: * https://www.youtube.com/watch?v=1rZ-JorHJEY * https://www.youtube.com/watch?v=yG-UaBJXZ80 There's a whole official YouTube channel with lots of talks as well: https://www.youtube.com/user/gocoding/videos
I think vulcan is perfect for dynamic container routing, instead of hacking around Nginx using Lua.
Generally, when scaling this sort of thing, you want to have an underlying "canonical" temperature type. You convert everything coming in, and convert when the user asks for a temperature, but internally everything is always in the same format. package temperature type Temperature struct { kelvin float64 // note you can't get away with int here } func FromKelvin(t float64) Temperature { return Temperature{t} } func FromCelsius(t float64) Temperature { return Temperature{t - 273.15} } func (t Temperature) Celcius float64 { return t.kelvin + 273.15 } func (t Temperature) Kelvin float64 { return t.kelvin } Another approach that can work is: type Temperature interface { Kelvin() Kelvin } type Kelvin float64 func (k Kelvin) Kelvin() Kelvin { return k } func (k Kelvin) Celsius() Celsius { return Celsius(float64(Kelvin) + 273.15) } // rest of the various output formats here type Celsius float64 func (c Celsius) Kelvin() Kelvin { return Kelvin(float64(c) - 273.15) } // no other methods here The first is generally better if you really don't care about the unit a temperature is in, you just care about the heat content it represents. I'd go with the second if I do want to care about what unit and retain that a Celsius measurement is Celsius for some reason. In this _particular_ case I'd worry that was a code smell (values don't _really_ depend on what unit they're measured in, do they? Are you _sure_?), but I thought it worth showing the general pattern because sometimes it is a better solution.
 $ units 10000m parsecs\; 3.2407793e-13 parsecs Admittedly, the syntax on this old program was dodgier than I was hoping and the documentation, per GNU standards for obscure programs, might as well not have existed.
Yes. Some people are visual learners some are audio some spatial. Am I not allowed to be a programmer because I have a different learning style?
I'm not sure why you would need anything other than https://tour.golang.org/ If you you have any background in C-family languages you can learn the whole language in a weekend. 
Both, but server side stuff has more flow charts and things. I'm comparing this to articles about C# also. The articles sorta remind me of haskell articles at time.
What do you think should be shown in such "visual learning aids"? Logs? Profiling graphs? 
vim + tmux + rerun I use vim (sometimes atom or sublime text depending on how I am feeling that day), tmux and https://github.com/skelterjohn/rerun to iteratively build and test as I code. I highly suggest rerun no matter the environment. I even do Go GUI programming using it.
That would appear to be a bug, however I don't know when it would be fixed at this point since it would break a lot of code that already uses the function.
Yeah, assumed the same. Thought there might be more to it though :).
These are really good videos. Also OP this video is pretty good too: https://www.youtube.com/watch?v=AiRhWG-2nGU It was on the Go Weekly, and they have videos on there from time to time: http://golangweekly.com/
Anything else like these? 
Thanks for vim-go. It rocks, no seriously, it rocks :)
Have you tried this one? I'm not kidding... you'll learn everything you need to know about Go syntax from this.
If you use the standard library's parser to manipulate the AST of a source file, dumping it back writes it properly formatted by default. So any time you manipulate a source file properly you're getting gofmt for free :)
In the same vein I have tried to work around STW latency some time ago: https://plus.google.com/+VladDidenko/posts/HLkztWWXuZ4 To make these approaches reliable there is a need for stronger STW guarantees in go implementations - or runtime spec, if these approaches to be portable. Such guarantees are apparently a problem for go runtime spec as evidenced by the closing of the relevant issue: https://github.com/golang/go/issues/7868 and discussions: https://groups.google.com/forum/#!topic/golang-dev/yzBqc1RSzEw Frankly I do not see an idea of handing job to non-pausing workers as anything novel, whichever form it takes. I would love to see a runtime spec guarantee of STW boundaries which allows these designs to deliver. I am not even sure a special API is needed beyond STW being controlled and it's time boundaries well defined. It would be awesome for David Terei and Amit Levy publication to push whoever can make the call in that direction.
Has anyone found the actual code?
Nice to see academic publications with implementations in Go.. and I think the language is a great academic programming language in general.. not surprising since it's concurrency model was born out of Tony Hoare's work
Almost all of the Go standard library predates golint, and not all of it follows the naming guidelines we abide by nowadays, as they developed over time. Id vs ID is one such case where the guidelines changed. Go's compatibility guarantee makes it impossible to rename that function now, so the earliest it could be changed would be Go 2.0.
Link fails (nothing listening). You might be better served by putting the code up on GitHub or BitBucket rather than providing a zip file download.
Can't say I understood it all, though I'm excited about their potential benefits. Is it as good as it sounds, and any chance of improvements like these making it into the core language?
I know this is a bit old, but I recently put together an auth system for my webapp using gorilla, negroni and jwt-go. I ran into an issue where I didn't quite know how to work in social auth since all existing packages seemed to rely on sessions to handle the callback redirect from the provider. I eventually figured out a method that avoids using sessions and wrote a tutorial on it. For my SPA it meant a slightly cleaner UX. http://hobbyisthacker.com/golang-sessionless-authentication-with-google-oauth2-part-1/ 
Good point. But a platform independent tool would have to be written in another language and I was using `bash`. 
No doubt, but it's a race against time
If you are talking about fully automatic, machine-learning-style anomaly detection, that hasn't been proven to work very well yet in systems monitoring. The people I know and trust all recommend defining manual (albeit sometimes complex) alerting rules. E.g. in Prometheus, you have the full power of its expression language and its data model available to you for defining alerting rules.
it's an abbreviation, not an acronym (right? :) I have started lowercasing the d for all my Id fields... you could just name them Identity or Identifier. I lose my breath from holding shift through the two keystrokes... don't judge ;)
I was literally *JUST* thinking about whether there had been any updates on this front. Really happy you posted this, I'm looking forward to reading it!
&gt; The estimated pause time in our current Go implementation is derived by simple linear extrapolation from previous collection pause times at different heap sizes. I've seen other people argue that it's not the size, it's the number of pointers which decide GC times, and that it's possible to reduce latency drastically for multi-gb stacks with appropriate pointer use.
OSX+Sublime Text 3 + iterm2 Using this setup for professional as well as personal go development.
Because any abbreviation where you say the individual letters is supposed to be capitalized (e.g. ATM, BBC, PBS, CMS)
Once you have a good handle on Go, http://gocode.io is a visual / interactive programming game.
Go setup on DigitalOcean VPS Remote access in Vim on MacBooKAir ( tmux, xterm)
I gave it a shot (by it I mean the example you have in README.md), ended with: ~ $ goauto 2&gt;&amp;1 &gt; goauto.log ^C ~ $ grep 'too many open files' | wc -l 4740 I did not even get to the point where I could test how the OS X FSEvents implementation handles phantom events. If you care you could try out https://github.com/rjeczalik/notify, it should work with multiple disjoint large directory trees without a problem (disclaimer: I'm the author of the library).
I would probably start with a value/unit types https://play.golang.org/p/p0mXBhRPFd. Although it doesn't solve your conversion problem directly :P.
I added the new FSevent stuff exactly for that issue. It was driving me nutty. p := Pipeline{} p.OSX = true The author of fsevents sent me a link to your project yesterday and told me to check it out :) I will do just that. In the mean time try the flag and see if it helps. ~davin
I should add that as of about 12 hours ago, Prometheus has a standard deviation aggregation function. This makes it easy to detect how many standard deviations a given machine is from the average for latency/cpu/errors and notify someone about the anomaly.
it doesn't allow script elements, what is wrong? Only reason I don't escape html is so that you can type [pagename] and it auto inserts the link to that page. Im too lazy to implement a better algorithm for that.
Nothing. I was originally using my own implementation of Context and was adding things to it as I needed it. After a while it got messy and I extracted the common patterns I was using into Killable. Main things it adds: * Dead state &amp; Defer function * Linking each other together via common parent. If all you need is a channel to signal when to cancel and an error, then using this package is a mistake.
While we're on the topic, anyone want to overview nsswitch.conf and what this change would mean?
The CRC is calculated for each page. Each page can be up to 255 segments long, where each segment contains 255 bytes (except the last segment, which can contain fewer). That means that each page can be at most ~64 kilobytes long, which means that most audio streams wouldn't fit in a single page. So no, the CRC isn't calculated based on the stream per se. [More info](https://xiph.org/vorbis/doc/framing.html) In the case of the pages I'm working with, which are the metadata/Vorbis comment blocks, they're much short than 64KB, usually only one or two segments long.
I work completely in the terminal, with a vim-setup with auto-completion. What I like best about my setup is that it is all automated as a vagrant box, that provisions a docker image using Ansible (available at https://github.com/samuell/devbox-golang ... screenshot on the front). This might sound like I just try to use all the coolest tech together, but I in fact do it simply because it works so extremely well. Docker makes a very light-weight and fast setup of the environment, ansible lets me re-use the configuration script for other targets (like my host operating system, or a cloud image), and vagrant makes operating the combo so easy that anyone can do it: vagrant up, vagrant ssh, and off you go!
Thanks! Basically anything in the views needs to be translated: https://github.com/AlphaHat/sdc/tree/master/views/sdc Thankfully the model and the URL routes are all in English so it's just a matter of changing words. The original code is very specific to the original website. What I'd like to do is make the site name and text configurable somehow. Ideally we can make some kind of admin console to let the end user edit all these settings.
You can use Update: x := crc32.Update(0xFFFFFFFF, table, bytes) fmt.Printf("%x\n", ^x) But that doesn't seem to give the right answer. The algorithms look different: func OggCRC(crc uint32, data []byte, tab *crc32.Table) uint32 { crc = ^crc for i := range data { crc = tab[byte(crc&gt;&gt;24)^data[i]] ^ (crc &lt;&lt; 8) } return ^crc } vs: func update(crc uint32, tab *Table, p []byte) uint32 { crc = ^crc for _, v := range p { crc = tab[byte(crc)^v] ^ (crc &gt;&gt; 8) } return ^crc } But maybe you could modify the table in such a way that it comes out the same.
This is a client for consuming REST APIs rather than another framework for building them. The title of the post doesn't reflect what the package does.
Thanks for the info. How did you find `OggCRC()`? 
In short, that falls outside of the scope of what I want to do with this project. It's not quite as simple as an interface for "job persistence". The library relies very heavily on Redis for certain guarantees (for example, the fact that Redis is single-threaded and no other command can run in the middle of a transaction or lua script), and I'm not comfortable enough with every aspect of SQL or other NoSQL databases to be able to provide the same guarantees. As a specific example, at the core of the library is a sorted set which represents all the queued jobs, called the "queued set". Each worker pool periodically gets the next N jobs from the queued set and moves them to an "executing set". Because Redis is single-threaded, it's guaranteed that no two pools will attempt to start working on the same job. In addition, the jobs library relies on Redis pub/sub for communication between worker pools, and without that I think you would need to implement some sort of service discovery, which really complicates the implementation. If another developer really wanted to take this on and submit a PR, I would consider it. But the code would need to be heavily audited and I'm not sure I know enough to do that for other database implementations.
A solid answer.
The default is SQLite but it's configurable for PostgreSQL 
So when you build a Go program that depends on the net package, you don't actually get a static binary. It links in libc. This is because (iirc) the DNS resolver logic in libc is extremely complicated, and if it wasn't completely supported weird things would break. nsswitch.conf is a file that controls some of that logic. It tells the resolver to use local files, or DNS, or LDAP, or, I don't know, all kinds of weird stuff. My guess is Brad wants to axe that dependency, but needs a representative sample of the kinds of stuff the resolver will have to support.
I'm using brackets, from Adobe. Simple, powerful and lot of plugins for go and git. 
golang is amazing on raspberry with raspbian. on my ubuntu machine, I just set the GOARCH to arm and I get executables done. 
From the link you provided. I just rewrote it slightly to match the other one so I could compare them.
I know this great resource for basics: try.github.com
The problem stems from the fact that StackOverflow itself is not a place to teach. What I mean is that it's a place for questions to be answered. If I asked a question about how to do a certain thing that might error (or throw exceptions in other languages) I don't care nor do I expect the answers to be perfect examples of programs. I will add error handling and exception handling appropriate to my solution. On the other side, when posting code snippets I ignore error handling/exception handling and on some questions I've answered I've gone so for as to write code that contains SQL injection (with fair warning against it, still) because it all boils down to providing the information that really matters here, and that's not boilerplate. An equivalent requirement to this could be to make sure all you go sample code is wrapped in a main function and has a valid package line. That's pointless if your just demonstrating a method call right? If I'm just talking about how to do a thing, I don't need to explain anything else or I muddy the answer. Of course, all of this goes out the window if the answer or question is specifically focused on errors or error handling in which case you want to showcase it then. tl;dr StackOverflow is not for teaching, it's for answers to questions. Not all answers need boilerplate (nor questions). It's not the job of the person answering to make sure that someone knows the language asking about and just because some writes code doesn't mean you have to use. Let the lazy write bad code and let it go unused. 
thank you for both the tone and content of ^^^ this. 
You'll still get a dynamic binary. That part alone isn't bad. But calling into C is expensive and heavy: each outstanding DNS request requires a big heavy thread doing nothing while it waits. And C-based resolver code has bitten us a few times already (security bugs and concurrency bugs), so it's nicer to have safe, lightweight Go code doing DNS requests instead. Goroutines are so much cheaper than threads. People getting bitten by the DNS resolver's concurrency is a frequent topic on the mailing lists. Search for "netgo" to see how often people reply with that answer. (building with "netgo" forces the use of the pure-Go DNS resolver) So we're going to try to make that automatic, when the C configuration is boring and doesn't have any special config. The commit message at https://go-review.googlesource.com/8945 has been updated with more info and links to the earlier threads. 
What part of libc will still be used? Edit: oh, when it's boring. Got it.
We'll still use libc's DNS resolver when the machine's configuration is trickier than we can deal with. That is, if you have anything custom (special NSS modules, .local hostnames, etc) then we'll use libc as before.
I apologize for my naivety - I use .localhost for development domains and mange them in the BIND config. Since I do not alter nsswitch.conf, will my binaries be helped by this effort? Even more interesting to me; If not helped by this change, should I then build binaries on a different machine if I wish to see a benefit?
I'm 80% sure that OpenSSH does this already. See `~/.ssh/config`. [Here](http://nerderati.com/2011/03/17/simplify-your-life-with-an-ssh-config-file/). 
In summary, you don't need to worry. And where you build doesn't make a difference. It's a run-time change, but it'll only have faster behavior when it's safe to do so. 
Configure your editor to run `gofmt` or `goimports` on your code every time you save your changes. For this there are not a lot of changes but in the long run you and everyone else you work with will appreciate it.
The project README says that you don't know of a cross-platform tool, but is [godep](https://github.com/tools/godep) not cross-platform?
gotcha, thanks.
Yeah that's where I got the idea. I find re-creating system tools is a pretty solid way to learn a language.
About the cat bit, I think it really calls "hg cat", which the user needs to fetch the repositories anyway.
I wrote a quick tcp proxy that hexdumps the traffic. Useful for debugging network protocols. https://github.com/dgryski/dhd
The `runtime.Gosched()` call looks fishy. A good implementation needs to enforce some limits and likely has to do something about stalled connections.
Another: https://github.com/GoogleCloudPlatform/kubernetes/blob/master/pkg/proxy/proxier.go which handles UDP, too. Edit: updated URL to be correct
The link is broken.
I am confused about one thing, when there is an error you put it on the channel and then return, that causes the cp function to end, why do you need to set stop as well? stop can't be set from anyother place. also [wg.Wait()](https://github.com/BlueDragonX/go-proxy-example/blob/master/proxy.go#L34) is unreachable since you only get there when you break from the infinite loop which happens when there is an error, in which case the function returns. [This](https://github.com/BlueDragonX/go-proxy-example/blob/master/proxy.go#L31) should be a break in my opinion.
For some forwarding some protocols, you need to keep writing after you see an end of stream during reading. TCP supports half-closed connections, and some services rely on them.
Interesting. What happens when two different main packages specify different versions to the same package or different packages in the same repository? Does this mean you should always run go-getter before you build of between switching projects? Or are you also recommending a separate GOPATH for each project?
&gt;Because it sucks when you need to cut an emergency release and the code no longer compiles due to something out of your control. This is an argument for an internal proxy, not a commandline tool. If you are not in control of the repositories you're pulling from, you cannot guarantee a build today will ever be replicable tomorrow.
An internal proxy is awkward for open source projects as all contributors need to set it up. And it's awkward if you work on multiple projects that use different versions of packages as you need to switch your proxy. And it's hard to ramp versions in lock step with commits and switch between branches with multiple versions. Actually an internal proxy is pretty lousy. A better solution to the internal proxy is "vendoring" where you keep everything mirrored in your own repo. git subtree and submodules help with this. But again, it's complicated and creates bloat. go-getter is a pragmatic solution that sits between the lightweightyness and convenience of go get, but the safety of vendoring.
Echo's key is router which is performant. Rest are add-ons!
Sorry, I didn't mean to come off as ungrateful. I just don't know how to use this thing or even why I would? I'm very interested in routing trees for Golang. I've written my own, but I'm sure someone else will have done it better. Can't wait to see docs / examples / write up.
Why? I shouldn't add salt before hashing?
emacs prelude + evil mode
Cool how does it include a salt automatically? How does it reliably get the Salt?
&gt; I wish there were an open-source Go library for user auth that included registration, password resets via e-mail, and all the hashing and session tokens. Getting security right is tricky and I'm betting that most people who are doing it on their own are going to get some part of it wrong. Perhaps yours could be that library. The hard part is that doing so requires the library author to make a *ton* of assumptions about the underlying application. It's "easy" to write a lib like that for (say) Rails, Django, Flask because you can assume a lot of abstraction. ActiveRecord, for example. Go, on the other hand, is a language (and not a framework!) and users typically prefer to glue smaller libraries together instead of using 'kitchen sink' frameworks. Writing a complete authentication library with registration logic, user privs, password resets, etc means you need to either force an ORM onto your package users or tie yourself to a specific datastore (i.e. Postgres) because you need to store a lot of that data (users, password hashes, reset links) *somewhere*. I'm not saying it's impossible, but it's certainly a lot of work to abstract an authentication system to that extent, and you'd end up serving a very specific niche.
This https://github.com/go-authboss/authboss ?
You don't store the session on the server - you store it in HTTP cookies. There's no need to store a ticket or receipt, as the cookie will be authenticated at a minimum (if you use gorilla/sessions correctly). This means that only your application can modify it correctly, so you can "trust" what the cookie contains. The `User{ID, Username, Email, PasswordHash}` is stored in the database upon registration and then consulted during login only. 
Ok but the HTTP Cookie is stored in ram, right?
So true, but you gotta just let the angry bloggers blog.
Huh interesting. Thanks for pointing me in this direction. This is a much better solution, than my Tokens in RAM idea.
No i wasn't thinking it was slow, I was thinking my original idea was slow.... lol
Awesome man, implementation of Gorilla's Cookie library was eassssy af
Using a separate GOPATH for each project is an antipattern.
Just wanted to thank you for your explanation. This totally makes sense to me from a build stability perspective.
What you don't understand is that a simple salt is trivially defeated. Smart mechanisms like crypt add the salt to the password and then repeatedly hash many hundreds of times using this salt. This way a brute force has to redo each hash with the discovered salt for each potential key and each potential passphrase. Bcrypt uses a similar approach but with a configurable amount of re-hashing which allows you to make it hard in terms of CPU time. If you need to learn more about this, PM me or ask nicely in one of the security subreddits.
&gt; Also by trivial you mean very expensive and several decades for a single password. Nope. Few GPUs and a salt and hash is easily defeated.
Really even when properly salted hash with like sha512? But even bcrypt salts the input, the issue isn't salting it's weak algorithms.
I've never heard of anybody else that does this. More power to you, but your tools won't be very helpful for most other people because your environment is so different than the standard one
If you're using HTTPS, then there's really no worry of a MITM attack. If you're not, then hashing won't really help you either because the MITM could just capture the hashed password and it wouldn't be any different than him capturing the unhashed password.
The proxy helps with the external repo going away problem. This is not trying to solve that problem as it's not something that frequently hurts me. (Actually it hurt me once - the mass migration from Google Code to GitHub). The issue with the proxy is you still have a global set of versions. Lets say my main app rev 123 depends on lib rev 456. Now in main app rev 124 I make changes that need lib rev 457: I have to update the proxy. Problem is I cannot keep this in lockstep with my main app repo. If I ask the build server to release main app 123 it will build it with lib 457 which may have changed since lib 456 I originally intended it to build for. My opinion here is that it doesn't matter what the mechanism is for actually retrieving the versioned packages, so long as the version definitions are atomically versioned with the rest of the app code and each checkout will always link the defined versions. This has to account for multiple versioned checkouts on my own machine, on the build server (eg a fast incremental build may need different versions to that of a slower running full qa pipeline, but they're happening concurrently), and to developers across an open source ecosystem. So actually we're discussing two solutions to distinctly orthogonal problems: 1. Can I pin app revision X to lib revision Y? 2. Can I isolate myself from a repo moving, deletion? Really it comes down to how much do you value each of those and how much pain are you willing to go through to get it. So which solution for your needs? - Standard go get cmd: #1=no, #2=no, effort=none - Custom checkout tools (eg go-getter and others): #1=yes, #2=no, effort=small - Internal proxy: #1=no, #2=yes, effort=medium - Proxy + checkout tools: #1=yes, #2=no, effort=medium+small - Same repo vendoring with git submodules: #1=yes, #2=no, effort=small - Same repo vendoring with git subtrees: #1=yes, #2=yes, effort=small If you value #1=no, #2=yes then proxy may be a good solution for your needs. Though I personally value #1 much more than #2 and don't want the added complexity which is why the go-getter script suits me. If I was more concerned with #2, I would use vendoring with git subtrees instead due to the versioning atomicity. I hops that explains my thinking better. [edit: formatting]
I'm fascinated by this. I read and hear this a lot yet I've seen no good reasoning behind it other than it's the philosophy of Go. I consider a global GOPATH as a pattern, and a per-project GOPATH as another pattern. Both are valid depending and the ideals you subscribe to. My ideal is that every app (actually every versioned checkout of an app) should have an isolated and consistent set of dependencies and any behavioral changes to my app should be associated with a git revision. Changes external to my working repo (including other apps on my same machine, or upstream library changes) should be totally isolated. Or to put another way, given git revision X of my app, I want to know that wherever and whenever it gets built, the result will be the same. bertold: Please share your ideals and your anti-pattern reasoning. I'd like to learn more about your perspective.
True that! I don't recommend this for newcomers. For that it's better to go "all-in" with Go tools. This is a tool for experienced Go developers who value consistent and repeatable builds. I appreciate and respect that developers have different values. I should be more clear - I'll add that to the project page.
Take a look at this. It has the basic use of bcrypt with user authentication. https://github.com/vegax87/Negroni-Boilerplate Feel free to ping me if you have any questions. I wrote something similar but sends a one time use token for registration to the user's email for them to click on. Once they have clicked that link, they can proceed to use the system as a user. This is to avoid bots from signing up.
This sounds overly complicated compared to the (recommended) method of dependency vendoring. What are your thoughts on vendoring, vs the proxy you state?
Hello! As mentioned elsewhere in this thread there is: https://github.com/go-authboss/authboss - It has a pretty comprehensive usage guide in the readme. I'm actually one of the owners of project and I suggest you check it out as it achieves what you're trying to do and more. Even if you don't use it, it may be a good learning source for you to reference. Additionally, we have a sample blog that utilizes it (as well as gorilla mux, gorilla session, etc): https://github.com/go-authboss/authboss-sample Feel free to PM me, post an issue on Github, or talk to us on Gitter: https://gitter.im/go-authboss/authboss We're continually adding features as our spare time allows and are always looking for feedback.
It's not that the algorithms are weak. When brute forcing passwords, you aren't exploiting weaknesses in the hash function (e.g. by finding a hash collision), you are exploiting weaknesses in the password. Basically, if I can hash passwords fast enough, I'll eventually find the original passwords regardless of hash. Bcrypt and scrypt aren't necessarily stronger hashes, they are just more computationally intensive so that they better protect weak passwords by requiring more computing resources. They also have some bells and whistles suited specifically to passwords like automatic salt, variable work, and functions for verification. 
Check out these two articles by Matasano Security on which password scheme you should use - [from 2007](http://chargen.matasano.com/chargen/2007/9/7/enough-with-the-rainbow-tables-what-you-need-to-know-about-secure-password-schemes.html) and from earlier [this year](http://chargen.matasano.com/chargen/2015/3/26/enough-with-the-salts-updates-on-secure-password-schemes.html). Both are excellent articles and I feel that all developers should listen to what they say.
yeah you're right, it was just an easy way to express my question which revolved more around how packages worked. I somehow never came across the section of the language spec that cs-guy posted above so my mental model of packages has been shaky at best
Not to shoot down their idea, but this loses two of the primary benefits of a debugger: Being able to attach to a running program, and being able to use a crash dump of a program. The real advantage of debuggers like gdb or delve is that when you hit an unexpected, hard to reproduce bug, you don't need to restart the app with instrumentalisation, risking not being able to reproduce the issue again for another 10 days, while having to run way slower code in production.
I use init to initialize an unexported `map[string]func()` where the (relatively simple) functions in the map call functions that end up calling other functions in the map. Doing this outside of init creates an initialization loop error. `init()` is also nice for using the flag package outside the flow of your `main()` so you can keep it clean.
6 time the same Ubuntu default file. People should start reading before posting.
Well, I'm aware of go install ./..., but the point is 'go build' command is a synonym for 'compile and get binary in current dir', so I do expect the same when I run with ./... Now, I see in *go help build* this behavior is described, but I still wonder why it's made so. Why not build binaries for multiple packages as well on *go build ./...*?
Won't this make line numbers in stack traces unusable? Or does it somehow work around that?
It's better than (almost) nothing which we have today.
Beego works very well, though I skipped the ORM for using sqlx. You probably aren't ever going to get something like ActiveRecord in Go.
Beego is basically RoR but is slow as hell. 
It does mean that the 'real' backtraces, that panic might generate for example, will have wrong line numbers. edit: punctuation
Read the paper. They explain that they don't do this , and are aware that others do, and why their approach has wider applicabilty than this hack does.
also, patches are welcome if you want to contribution, you can add another [handler](https://github.com/thoas/picfit/blob/master/application/handlers.go)
[This stacksignal](https://github.com/surma/stacksignal) package was one interesting thing which makes use of init(). Just import the package, and you'll get a signal handler on SIGUSR1.
Its nice and useful to use init to add modules or plugins to other module must by importing the plugin in your main. If you look at the image decoders in the standard library you will see an example of this.
How bad is the performance loss?
Nice!
If you don't find one that's local, you can always look for something remote here: http://www.golangprojects.com/ 
So it's an etcd clone?
Thanks! I'm looking for a position where I can have some mentorship, I'm not quite sure that would be an option for a remote position.
First, I don't think there's anything wrong with using that so if that's the way you want to go then more power to you. As to the claim though my experience has been that this is more of a theoretical problem than a real life problem. 1. JSON isn't that hard to edit and if it is, it's probably more due to overly complex structure than JSON itself. If you can easily represent it in Toml you can easily represent it in JSON. 2. The skill level of anyone manually editing a config file is more than enough to handle editing JSON. If you need to target a level of skill that needs that, you should probably consider some kind of GUI or command line configuration tool because they're as likely to introduce a format busting typo in even a simple Toml or INI file as they are in JSON or anything else. So looping that back around, I don't feel going this route adds anything over using simple JSON and adding unnecessary libraries that you need to manage, particularly considering Go's "just vendor it" strategy, isn't a strategy I'd recommend.
&gt;What I got from reading the article is that it's meant to be used to compile a debug-only version and debug it locally. You shouldn't compile all your production code with this enabled. That's the point of your parent comment. It's not as useful as e.g. gdb or another real debugger because you can't attach to running processes. 
So i'm trying this in Windows 7 x86 with 32-bit go 1.4 and MinGW. I have a project dir that looks like this: $GOPATH/src/myusername/editor |-- editor.go |-- fizzle |-- renderer.go The editor.go file in the editor directory is the main package. The renderer.go file in the fizzle directory is part of the 'fizzle' package (editor.go imports "myusername/editor/fizzle"). When I set breakpoints in editor.go, things work as expected, though I can't print variables from 'fizzle'. When I set a breakpoint in renderer.go it doesn't get hit. From the editor directory above, I run godebug this way: $ godebug run -instrument=myusername/editor/fizzle editor.go -cf ../basic.json What am I missing with regards to instrumenting packages that aren't main?
No argument from me. I wasn't saying JSON is difficult to write and I certainly wasn't advocating for usage of this library. 
The biggest problem I have with JSON for config files is that it doesn't allow comments. Swapping out TOML for JSON is super easy and you get a few little bits of extra goodness in the format. Unless you're going to have zero 3rd party components (which is certainly preferred) you'll have to solve the vendoring story anyway.
Yep, the lack of comments is a consideration. I think that can likely be handled via an example file or documentation but if that's a compelling reason not to use it then at least it gives you a specific reason. Sure you have to deal with vendoring, it's not a matter of avoiding it altogether. Each library you add to that pile becomes something you are going to have to deal with in the future, in fact using that strategy pushes it far enough in the future that you've probably forgotten what it was at some point. So as a rule adopting an attitude of not adding things to that list unless there is a compelling reason is a good practice to advocate for in the Go community.
Awesome. Thank you!
I share your ideal. But the way to accomplish that is with vendoring, so that your packages are still `go get`-able. As long as `go get` works the way it does, and remains the canonical way to get Go code, per-project GOPATHs are an antipattern.
If you program with other languages, it's going to get confusing having a src directory in your home folder.
GOPATH can also contain multiple entries just like PATH.
&gt; Do not add GOPATH to PATH Perhaps s/he meant add $GOPATH/bin to PATH, which is recommended by [How to Write Go Code](https://golang.org/doc/code.html)
It really depends on how you organize your sourcecode. I would recommend the following approach: 1. Set `GOPATH=xyz` in your .profile or .bashrc file for your user account. This way, when you start a new shell, you have GOPATH pointing at your default workspace for all Go code. 2. Consider lightweight scripts to set GOPATH for discrete projects. I tend to wrap `go build` etc. in Makefiles, so GOPATH usually gets set to `pwd` for those projects. This way, I can build software with depenencies that are distinct from what's going on elsewhere. But a one-liner BASH script to set the environment would work too. 3. For one-off tasks, just `export GOPATH=$(pwd)` or set it inline (`GOPATH=$(pwd) go build`) when you need it. The reason why it's a variable is that you may have any number of strategies for managing your go code. Go doesn't care, just as long as it can find dependencies. Just pick what works for you and roll with it.
Yeah. This is what I meant. Sorry I wasn't clearer about it.
I don't?! I arrived at this thread because I'm working on a multi language project **right now** that uses go as the language for one of our projects internal components. It doesn't belong in go's project structure, and it's libraries may fall out of sync with bleeding edge. We have a Vagrant project that acts as a central hub for all our components, and it as such, does not fit with go's ordained structure. What do you mean *I don't*?
It should be noted that the instance of rack that performed marginally better than Go in the EC2 test was using JRuby and not straight Ruby, and it also was sitting behind a frontend server as well as using a stripped-down implementation to give the best result possible for the benchmark. Ninja edit: I was a bit surprised to see Python's WSGI performing far better than Go on the max one... It makes me wonder if there's some sort of caching going on internally in their code for that, given that as far as I'm aware they're just serializing the same test data then sending it over and over, or perhaps the serializer is written in C or C++ and the Python code for it is just dropping to lower-level code for the heavy lifting.
It's not the worst. `call()` in `dialer.go` could probably be moved into utilities? There are a few places where you could compress some lines by making the call and checking the error in the `if` statement. Like, change [this](https://github.com/jpoehls/go-conduit/blob/master/phid.go#L30) to be like [this](https://github.com/jpoehls/go-conduit/blob/master/phid.go#L66). There also seems to be an opportunity to use the reflect package to generalize all of the api endpoints + results but I'm sure there are plenty of good reasons not to.
I'm not surprised the data updates test on peak hardware performs better with node.js than Go. I wrote the node.js MySQL mapper which uses local interpolation to bypass prepared statement processing. There was a user who asked if there was any benefit to using local SQL interpolation v prepared statements. The proof is in the results. With so many frameworks in the test, who knows if the tests are on even ground. My guess is if the Go tests used `gocraft/dbr` or `mgutz/dat` with local interpolation, Go would better node.js in that specific test and improve across the board with data. That begs the question is it fair to game the test results? Obviously, we shouldn't read too much into benchmark results.
In addition to what ngrilly said, "go get" will put what it goes and gets into the first element of the GOPATH. Since I'm currently manually handling vendoring (not enough use of other code to make anything else worthwhile), I have the first element of the GOPATH point into something that gets .gitignore'd, so I don't pollute my repo with "go get". It's pretty easy then to fetch out just what I want explicitly, and I can still use "go get" to get binaries and stuff for gocode, goimports, etc.
Some people have been adamant that you should only have one GOPATH for everything. It seems to me that the community has toned this down, though you'll still hear it. Personally I've used multiple GOPATHs for a long time, and find myself suspecting that those who advocate so strongly for one big GOPATH simply don't have needs as complicated as mine. If nothing else, mixing "work" and "personal" is just a bad idea.
Thanks! Good catch on my `if` statements. I'm still getting use to the shorthand version and forget to use it most of the time. I've cleaned those up and moved `call()` as well.
&gt; lets say, I setup my GOPATH to "$HOME/go", and have my project repo in "$HOME/project". This doesn't work. If you GOPATH is `$HOME/go`, your project necessarily must live at `$HOME/go/src/project`, or (canonically, assuming your project is hosted on GitHub) `$HOME/go/src/github.com/username/project`. If you *insist* on keeping your project in `$HOME/project` — which, to be clear, without further information, you almost certainly shouldn't — then you need to subvert the Go toolchain to build your code, either by setting up a GOPATH-like structure within the project (i.e. put your Go code in `$HOME/project/src/packagename` and set GOPATH to `$HOME/project`) or by invoking the compiler and linker manually. But let me emphasize that this almost certainly is a bad idea and you should do it the other way.
I feel like businesses exploring golang for potential deployment and use into their existing infrastructure is a far more common use case than someone starting a stack from scratch. 
I hesitated when I was new at Go too. Eventually I just wound up using one GOPATH and organizing not only my Go code inside it, but ALL my code (except some website stuff). It is simple and has worked really, really well. Especially with $GOPATH/bin in my PATH.
Monsoon Commerce
I usually just do ``GOPATH=`pwd```. But I vendor all my dependencies anyways so using that just gets GOPATH out of the way so I can build and run my code without having to deal with environment dependent builds.
Thank you for feedback. I know that coffeescript is little awkward. For me as a backend programmer I wanted to give a try for coffeescript + angularjs.
IMHO GOPATH is one of the best and worst features of Go. Gopath is essentially what virtualenv is to Python and it is wonderful having development environments for Go projects. Unfortunately thanks to the go get command, a GOPATH can be quite rigid and frustrating to work with. But there are workarounds... The GOPATH per project is nice, and I have used it. The best thing about this is that only dependencies used by the current project are pulled in by go get and you know exactly what they are for. Another benefit is when using godoc -http=:6060 only the packages used by the project are picked up which makes for a cleaner documentation experience. However, it is expected that projects in the community be "go get-able", which is broken with the one-gopath-per-project technique. Also, the Go devs advise against this technique. Eventually I got tired of messing with it and just set GOPATH=$HOME. This is the best and most direct way for setting the GOPATH. I also would advise NOT using go get on arbitrary packages you find on Github because it and it's dependencies will clog your GOPATH. When I want to test a package, I set GOPATH=$PWD in a temporary directory and then use go get. I have a ceremony every year where I wipe my GOPATH and start back fresh. I love Go, and the simplicity and that's what keeps me coming back. Also, Godeps!
can't use no double negatives. 
&gt; Does this mean that all my Go code has to reside within this folder? Not has to, but probably should. &gt; What if I wanted to organise my code in a different way, lets say, by project; or have my Go code as a part of another project? Go is opinionated, about how you structure you code, and how you format your code. It is all at the end of the day optional -- you can use GNU formatting style (when it doesn't break syntax rules) and a hand tuned makefile without ever using the go command line tool or GOPATH, but I wouldn't recommend it. If you go off the reservation and want to do you own wild thing, awesome, do it! But don't expect help or sympathy -- one you go off the well worn path, you are on your own. If you are just learning, just follow the norms of the language you are using (be it Go or some other language) -- once you reach expert status in the language you can make decisions about where you want to break from language norms (or if you are high enough in the community, try to reshape those language norms).
Honestly just try going with the flow because otherwise you're just going to hate yourself because everything else in the Go ecosystem uses GOPATH paths. GOPATH is organized by project - under your ID and a URL. If you _really_ want to organize it with your other projects or inside of another project, you could just symlink those folders into your GOPATH or vice versa.
If a tool/compiler/etc is going to make demands of me, then there should be some benefit that I'm gaining. The only benefit I see here is not having to deal with the shortcomings of the tooling... 
Because it is. https://github.com/julienschmidt/go-http-routing-benchmark
The [gvm](https://github.com/moovweb/gvm) project allows you to have your Go applications scattered around your computer. Adding your local packages to your GOPATH is done via `gvm linkthis` command. Just try it, it's magnificent.
godebug author here. I'd be happy to help with the integration. Send me an email when you start working on it.
Andrew Gerrand, who works on the Go project at Google, has explicitly said that 1 GOPATH is the official supported way to do things. https://groups.google.com/forum/#!topic/golang-nuts/dxOFYPpJEXo
What you're describing sounds like it should work. Can you try reducing the example to this? editor.go: package main import "myusername/editor/fizzle" func main() { fizzle.Fizzle() } fizzle/renderer.go: package fizzle import "fmt" func Fizzle() { _ = "breakpoint" fmt.Println("fizzle") } And then see if you can hit the breakpoint: $ godebug run -instrument=myusername/editor/fizzle editor.go EDIT: Also note that (1) the command "print mypkg.ExportedVar" is currently not supported in godebug, even if mypkg is instrumented. And (2) until [an hour ago](https://github.com/mailgun/godebug/commit/4d9c28ae03f607cff34072ef13f28b86ff73395e), setting a breakpoint at the end of a function would not have stopped inside the function.
Nix uses GOPATH for composing libraries. Works very well and you just forget about the existence of GOPATH. You just tell nix which go packages you want for your project, and you have them ready to compile your project with `go build`: http://lethalman.blogspot.it/2015/02/developing-in-golang-with-nix-package.html Additionally, also the PATH is set automatically by nix in case some go dependencies has binaries. Think of it like a virtualenv of python, except for go (or anything else). Not sure if that might interest you :)
I'll give it a shot. I might not get to it today, it might have to wait until tomorrow. Thanks for the reply.
I mean avoid memory leaks or pause gc.
From what I read, he *gets* it. He just finds it weird. So do I. But every day that passes I find myself more understanding and welcoming of the "go ways". And I'm sure I'm going to LOVE IT three years down the road when maintaining code.
In this case we have python wrappers around C libs. Also wsgi works with uwsgi, which written in C. So from this point of view wsgi test shows how python slow, as most part of code is C lib and we see minimum python code for this case. But from other hand for JSON tests Go case could be executed with some json optimisation like: github.com/ugorji/go/codec. I've made simple test with JSON string ~17K symbols and this JSON lib show very good results.
&gt; For example, if you want an array with values of type Car, you need an array of pointers This is not true. https://play.golang.org/p/wJDg-bT4Le
&gt; When I program I usually think in C, that is, as I type I try to think about the C code that’s actually being executed when the program runs Funny, that's how I think when I program in C, that is, as I type I try to think about the assembler code that's actually being executed when the program runs.
The reasoning here is circular. Very similar to "what benefit do I get from following the law"..." because otherwise you'd be a criminal"
I use it for running tests/builds against godep saved workspace dir inside the same repo that should be on the gopath. I can reproduce builds and not have to do import path rewriting or copying the files first for each build.. I also have a makefile that mounts one project inside a docker container to do cross platform builds using native build chains for win/osx/win and do the same thing there..
I just set GOPATH=$HOME and put all my projects (go or otherwise) in src. It's actually made my organization a little more sane. 
Number of js devs &gt; number of cs devs and the difference is over 2 orders of magnitude.
While you may be right, learning coffeescript is rather easy and takes almost no effort. I agree that it might reduce contributions, but not drastically. 
Exactly! And because of the lack of feature W or Z, I can jump into your Go code and understand it with relatively little effort.
I liked this article. For anyone bugged by the unused imports you can always use the goimports command: https://github.com/bradfitz/goimports It does everything gofmt does, but it also fixes all your imports. (adds / removes them automatically) Just run it on save and you never have to worry about unused imports again.
It would be interesting to see the results after the survey, could you enable them please?
It is my understanding that they hope to have a vendor file spec defined this fall around when 1.5 is release. However, because google has a single source tree and runs from the head version, they have expressed a desire for the community to come up with a spec that they can then bless. So I think the timeline somewhat depends on the community.
Excellent talk. Although I'm not a C++ dev, it helped me a lot. Recommended!
Neat. Pipe and channels make the code very tense. You could also send the output to a channel, line by line, coupled with the process pointer. You'd save memory for processes that produce a lot of output. 
&gt;This is what encoding/binary[1] is for. Or better yet math.Float32frombits() and math.Float64frombits()
Short and sweet!
Does anyone else uses [Wercker](http://wercker.com) for builds/deployments? They're pretty neat (and currently free).
I really like the spec you have. One thing I'd really like to see is an easy ability to have project-specific GOPATH's since you may have different versions of packages for different projects.
That was tongue-n-cheek. It's the -race flag that makes it REALLY slow
You could but then you can't get line by line status/output. Plus, s.Kill() will kill the current process itself if you use bash or bin/sh commands.
Yes will do that next.
Because this one was funny and by a well known blogger. 
fixed the ordering and used go-shlex
What is pools?
&gt; Reduce memory allocations and copying. What this mean? &gt; Reduce casting between []byte and string. Why it is expensive to casting? &gt;Prevent too many function calls and indexing What this mean? Why prevent function calls? Thanks 
&gt; In this scenario, Go's error handling feels a bit like Java's checked exceptions. Just assume there's no IDE with autocompletion or you need to patch something quickly via SSH: how can you compare the need of grepping the code for error types to declare them thrown vs "if err != nil { return err }"?
Wercker, Drone, coveralls etc. want an awful lot of permissions to try in github (a lot due to github's fault). So I am not using any of these even though I would love to. I am using travis alone as that is open and also not asking too many things for permissions.
&gt; dnsParts := strings.Split(*dnsServer, ":") You should use "net.SplitHostPort" here instead.
I'm surprised to not see GoConvey here. It runs the compiler &amp; tests on save and shows output in an interactive web page that includes code coverage. + GoSublime, and GoOracle (call-graph)
Isn't the attraction of go that we can avoid enterprisey stuff like DI and Factories? If you like that stuff, use java?
Just realized I forgot to recliense this for you. It's now MIT: https://github.com/dgryski/go-discreterand/commit/57fa96b59f2a453d7341c5ba85cb02c1088beb89
See this [post]( https://blog.cloudflare.com/recycling-memory-buffers-in-go/)
It is a weird situation. Won't go into all the historical reasons but the plain text passwords are SHA1 before bcrypted. Legacy stuff...
Pretty cool! I'm gonna have to use this in a project of mine. 
I've written a similar package, called `envdecode`: https://github.com/joeshaw/envdecode Feel free to take a look at it for ideas.
I feel like the only one using Eclipse, but the Goclipse projects in the folder-under-src-in-GOPATH configuration and Egit make my life pretty easy and happy on win, osx and linux.
good article what do you gents think about something like this (code snippet) not real go code, my idea how it should be... just for ideas e := errorList { onAppend: printErrors(e); return nil, e; } a, e := f1() b, e := f2(a) // custom var type, assigning here actually just appends to array of items in errorList k, e := f3(b) return k, e.countOrNil() explanation: a type of var that appends to array instead of overwrriting edit: redid, + the fact it wasnt real go code to begin with :D
I don't think you can override assignment to do an append. Would you not have to pass the error to each function in order to get it appended to?
My first try was on my arch linux setup where I got a new copy of godebug this morning. 1. Without the -instrument arg I got a nice warning about a breakpoint being ignored. Yay! 2. With the -instrument arg it worked as expected and hit the breakpoint. I went back to my Win7 setup: 1. Confirmed with the code version I had 4/21 that there were no warnings of ignored breakpoints and that the breakpoints didn't get it. 2. Updated the package from github.com with a `go get -u` command. 3. Still don't have warnings of ignored break points and they do not function. So I guess it seems like a platform issue. Edit: Forgot to add that I tried your test. I called my function from the first line of main. No breakpoint. Test line was output to console.
The ssh client does handle keepalive requests from the server, but doesn't implement the client side automatically. The library intended for users to send these requests manually using a global SendRequest. IIRC you send an empty global request with any request-name that the server doesn't recognize (and I *think* you wait on the reply, but please try it out.) ok, _, err := conn.SendRequest("keepalive@golang.org", true, nil) 
The exact pattern you use won't work, because you're assigning `e` rather an appending to a list, but if `f1`, `f2`, and `f3` could all be methods on the same type you could use the pattern described in https://blog.golang.org/errors-are-values for `errWriter`. If you want to collect multiple errors (which is especially helpful when running independent things concurrently) there are multiple packages out there for that. https://github.com/joeshaw/multierror is mine.
yea your right i forgot i was dreaming of something like behaviors (clj?) where you could attach like errorlist.onModify: return e
Thanks ! I might take the same approach to implement default values, I'll have to see.
Thanks for the report. I'll look into it. My first guess is that this is somehow related to path separators. 
On the first pass I stopped reading when I saw "Factory". After giving it another pass I think you're misusing the using the word "injection" when you mean IOC or simply "good use of interfaces". Not very idiomatic code IMO and I like to think go programmers can employ ideas like this with out so my Ceremony(tm). 
I tried gocheck but switched back to the standard lib. I found it tedious to learn a new dsl and framework for little benefit. I say all this coming from Java and Junit.
Also, you can reduce verbosity with table based tests.
Probably tried to debug his application that uses a library and the error messages he got weren't very descriptive so he posted that on a whim.
This is the [tweet](https://twitter.com/zedshaw/status/591333865374941185)
[**@zedshaw**](https://twitter.com/zedshaw/) &gt; [2015-04-23 20:12 UTC](https://twitter.com/zedshaw/status/591333865374941185) &gt; Dear Golang Crew, &gt; &gt; Please stop using a robot to write your error messages. I'm sure there are humans who would do a much better job. &gt; &gt; Zed ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I was using [testify](https://github.com/stretchr/testify) but switched back to the std lib. I wanted to reduce dependencies and I found the std lib was often simpler to understand.
It would have made more sense (in the long term) to: - Verify the SHA1 as correct - While you still have the plaintext password "in flight" within the request, run it through bcrypt - Replace the SHA1 password with bcrypt - Next time around, either have your function check whether it's a SHA1 hash or a bcrypt key (and skip it if it's already been upgraded)
Someone in tech that's a celebrity.
HE SAID A TECH CELEBRITY
If you want to keep it simple, why add the nginx webserver ? Add the reason(s) why you think its good to do. Also, I think by default a Digital Ocean Ubuntu 14.04 distro has no firewall enabled ? In which case at least a link to this would be good to add: https://www.digitalocean.com/community/tutorials/how-to-setup-a-firewall-with-ufw-on-an-ubuntu-and-debian-cloud-server Finally I think some specific link to setting up ssh keys would be recommendable as well. 
&gt; ./demo_webapp &amp; If you're exposing your project to the internet you probably at least want your app to auto-restart when it crashes or when the server reboots. Also, it might be an idea to run it as nobody instead of with your usual user account.
His response was &gt;Well, reddit works fast. Simplest example is the "imports unrecognized import path" error that tells you nothing as to why. To me it seems pretty self explanatory.
Will.i.am?
Can you please clarify what you mean by table based tests? Like creating an `Eqaul` method for each struct and then testing it? edit: I found [this](https://github.com/golang/go/wiki/TableDrivenTests). I agree that it can reduce verbosity in certain cases.
I've been using testify for tests and benchmarks. No experience with other librarires, but I have no complaints
And this is where I point you to the proper documentation. http://blog.golang.org/errors-are-values EDIT: crap, joeshaw already did. 
Thanks, good advice.
`io.ReadFull`really is the bee's knees for network stuff. If you can _possibly_ harness it, do. Combined with sensible read timeouts you can really constrain a _lot_ of nasty network possibilities down to "either I get this many bytes before the timeout or I get an error", and that's a perfectly feasible possibility-space to handle. It's almost as easy as reading from the disk, modulo the timeout issue. (You do want `io.ReadFull`, though; a LimitedReader and an ioutil.ReadAll is more work to do the same thing.)
Can you explain what this package achieves? I'm interested because I use sync.WaitGroup, but I don't understand the example.
I participated, and while I thought about networking issues I decided against handling them because I was happy with how my code functioned and how it looked. I was definitely thinking happy path and I don't think that's wrong. This wasn't supposed to be a production application. If making one was the challenge I probably wouldn't have participated because I know that I don't know enough about Go to make something like that yet. The `io.ReadFull` suggestion was great and I plan on checking that out but was oblivious to it during the challenge. Expecting others to know about it seems a little ostentatious. I've only been programming in Go for a few months and really only in little challenges like this to have fun. Bottom line, these challenges should be judged for what they are, challenges. As an evaluator you're going to see a ton of code that looks exactly the same and that shouldn't be a bad thing. What you should really be looking for are the entries that solved the challenge in new or interesting ways. 
Thanks I added why to use nginx, and a small section on using ufw at the end. Good point about the SSH, I think I will write a paragraph or two about how to setup a deploy script so you can quickly push changes from dev to the server and that will require SSH setup to be explained.
That's a pretty excusable error to make, if you ask me. After all, it is golang.org, /r/golang, and "go" is not very searchable in my experience. People calling it golang doesn't damage the ecosystem or anything, does it?
There's a bug in the reviewer's one byte reader. The reviewer should consider using http://godoc.org/testing/iotest#OneByteReader. io.ReadFull is the usual way to read from the network, not the io.LimitedReader / ioutil.ReadAll combination as suggested by the reviewer.
If I had a gun to my head: Clojure, for the ecosystem. If all else fails, you'll have a very decent chance to find a good library made for Java that you can assimilate. I never used Clojure in "production" (but did create an amount of code (~3 kLOC) in an individual project), and now I'm working professionally with Go (few weeks). If I didn't have a gun to my head I'd pick Go for the personal experience. What I find is that both languages are very well-thought, sufficiently young to not have accumulated some cruft and opinionated in the correct amount to make readable, maintainable code by bending you towards its mindset. I prefer Clojure's immutable value mindset, which greatly improves tedious stuff like equality testing; and I'm enjoying Go's typing system to elaborate more structured data instead of lists of maps of maps. Feel free to ignore the following analogy: My general feeling is that Clojure models well a car factory, where pieces flow between stations where complex robots mutate and recreate them; and Go is appropriate to an open-floor office, where papers circulate between desks, workers do impromptu standup meetings while others sit alone to complete a task... and despite that complexity, stuff gets done.
We use Go in production at work, whereas my experience with clojure is limited to hobby projects. So I might not be the exact person you're looking for input from. They're both excellent languages, and I doubt you'd have any big regrets in picking either one. I lean towards Go simply because I like the static binaries and not dealing with the JVM. YMMV.
I write Go and Clojure every day. I don't enjoy Go very much; it reminds me too much of writing C. Clojure is my favorite now that I'm not programming in Common Lisp. There's a huge benefit in writing Clojure and Clojurescript for web apps. I find myself moving functionality between the client and server as a matter of convenience. It's nice to have the same code work equally well either place. 
I don't think he meant that you need lots of tests or you'll fail for not having enough tests. He meant that if you don't test enough you'll likely write a bad solution.
I don't know, my intention is to have multiple apps on 1 server so I can hit a subdomain on port 80 and it will route to a specific Go app running on port Y If I go to the main domain it will go to another app and so on I then don't have to bog down any of my individual apps with this routing logic and can let nginx handle it all
Yes, mainly because of http://learnpythonthehardway.org/. He has probably more experience in understanding what confuses beginners in programming than most of us. Also don't ever take everything on the internet seriously, sometimes articles are specifically written to be over-the-top.
It seems to me that the evaluator's main focus was on evaluating the challengers' familiarity with the problem domain rather than anything that was actually listed in the evaluation guidelines. If TCP short reads are such a well-known networking problem that all solutions should account for them, then intentionally omitting a test covering the case is just bad form. 
It's also a lot faster at serving static assets if you need to gain some performance there.
Person well known in the tech circles not necessary by his tech achievements.
Just want to mention that there are potential issues with pre-hashing passwords before sending them to bcrypt. Specifically when you end up passing the raw bytes to bcrypt directly. It looks like this might not affect you here, but it is something to be aware of. Combining cryptographic primitives in unintended ways can have unintended consequences. For more information see here: http://blog.ircmaxell.com/2015/03/security-issue-combining-bcrypt-with.html
more details plz
Go and GopherJS for web apps. Even unexpected stuff from the Go ecosystem just works on the client (like godebug: http://blog.mailgun.com/introducing-a-new-cross-platform-debugger-for-go/). 
Good point about json thanks, but link points to the "single query db access" test. 
FYI, https://groups.google.com/forum/#!searchin/golang-nuts/techempower/golang-nuts/W5yOfB_RF8I/E4u8_sFAQNAJ
That's basically just the bodies of workgroup.Go() and workgroup.Drain(). 
go is not optimized for running single process on many cpu cores. That is why it shines on small core system, and fails on Peak with 24 real cores 48 hiperthreads. If one runs 24 processes with GOMAXPROCS=2, that Go's result will be much better. To he fair, leaders on Peak software do mostly the same: lwan runs many fully independent threads, as well as other C and C++ frameworks; openresty works in many nginx worker processes; only Java shows real one process performance with shared state.
&gt; Goal of the challenge &gt; &gt; In order to prevent our competitor from spying on our network, we are going to write a small system that leverages NaCl to establish secure communication. NaCl is a crypto system that uses a public key for encryption and a private key for decryption. &gt; Your goal is to implement the functions in main.go and make it pass the provided tests in main_test.go. This doesn't give me impression that you're supposed to write production-quality code and think about different networking issues that may arise or write additional tests to cover them. Writing more tests does obviously make you think more about edge cases, but that's not something I expected to be evaluated. Lesson learned. Let's write some tests.
I suspect most of the other languages (besides Java, which has the JVM) have C implementations. Which is therefore Go vs. hand-crafted C.
The raft lib [github.com/goraft/raft](https://github.com/goraft/raft) is unmaintained, this may be risky. I prefer using [https://github.com/hashicorp/raft](https://github.com/hashicorp/raft) or you can use the raft lib in etcd or cockroachdb too.
Thanks for bringing up GopherJS. Didn't know about it. This fascinates and concerns me: "GopherJS does some heavy lifting to work around this restriction: Whenever an instruction is blocking (e.g. communicating with a channel that isn't ready), the whole stack will unwind (= all functions return) and the goroutine will be put to sleep. Then another goroutine which is ready to resume gets picked and its stack with all local variables will be restored. This is done by preserving each stack frame inside a closure." Clever, but what if any of those functions on the stack had side-effects? Is it up to the application programmer to ensure they're pure functions?
nginx is pretty good to learn, it's good for newbies to learn how to set up subdomains for their projects.
Aka middleware, in case anyone was wondering from the title.
I have to admit, it took me a little while to figure out what this package does, even with the comments you added. Here's my question: why bother limiting the number of goroutines? One of the purposes of goroutines (as opposed to threads) is to allow huge numbers of them.
For comparison, here's what the code might look like using only the standard library. package main import ( "log" "runtime" "sync" "time" ) func main() { workers := runtime.NumCPU() runtime.GOMAXPROCS(workers) group := new(sync.WaitGroup) group.Add(100) for i := 0; i &lt; 100; i++ { go func(i int){ log.Printf("%d Done : +%v", i, time.Now()) group.Done() }(i) } group.Wait() log.Printf("Done: elapsed:+%v", time.Now()) } main() has 12 lines of code, just like the example.
It's worth pointing out, since I keep seeing this in the context of http only, that this is a general technique. `io.Writer` and `io.Reader` can also be wrapped, for instance, and this can be used to create "pipelines" for encoding or something without any channels or additional goroutines.
Fascinating that the results changed quite a lot between 9 and 10. On 9, using i7 hardware, Go is more or less on top tier. It is no. 1 on JSON category.
I disagree with this. Lets say you have a handler function that depends on access to the database. That handler function now depends on access to a database! It doesn't make sense to call it on its own, it's no longer an http.HandlerFunc, it is an http.HandlerWithDatabaseFunc (better name TBA). Which is great! Because it means that you can't use it without wrapping it with some kind of thing that gives it a database of some kind. I don't know if shimming in the data by passing it through http.Request is such a good idea. What if you get collisions in your request? What if someone passes in nameOfThing and you needed that info for your handler? You'd have to change the front-end to not do that. maybe silly vendor prefixes? It's possible I've misunderstood this idea, but this seems like the kind of solution that appeals to a programmer who is use to dynamic languages. 
In this case, it's just calling a Google Speech API or executing an external command - not much overlap but not much code either.
Kind of a misleading title considering the library uses Google to do both of those things. &gt; A Google Translate and Google Speech library for Go FTFY
Ah ok, I didn't realize it was calling google-speech API.. I was thinking this was a much more ambitious project that actually aimed to do the processing itself. Thanks for the clarification.
Good call, I'm gonna try to sneak that in
OP here. I do have another unpushed branch that actually implements both in two libraries. In the future we will migrate to real go implementation, and google api is used as a stub here.
I needed this for a project, I ended up using OSX 'say' command to do tts. I wonder how good is Google at saying stuff.
What about #2, #3, and #4?
You're right on every count, although I'm pretty sure it takes even more than just nginx or Apache to stop DDoS attacks.
&gt; Each handler could have its own timeout which, if it's still running after x ms, it can terminate itself. Does that still work if there is middleware involved, how do they work together? &gt; *#4 - time.After signals after a certain duration has passed, regardless of operations that were happening during it (reads, writes, processing, whatever). time.After is precisely what I used to limit processing time in an autocomplete API that had to scan a massive index and return as many results as it could in less than 100ms. After that, time.After signaled all the workers to stop and the response was sent to the client. Works like a charm.****** Sounds great, I'll try and figure #4 out and will be back here if they don't.
Perhaps that's the kind of information you should have put in the readme before posting here?
Without the ability to set your own API key, this library is pretty useless since you'll be hitting the rate lilit fairly soon.
If the endpoint is accepting sha1 it's not a hash, it's a password.
I would like to see the "print" command augmented, or another command created which will display the variable type, or the variable type and value. On entering a function that accepts an interface pointer, I would like to be able to see the equivalent of: fmt.Printf("%s: %T %v\n", vname, v, v) So, echo back the variable name, and display it's type and value. An additional enhancement that would be useful is to allow expressions such as these below, ranging from the simplest to the more complex: godebug&gt; print v godebug&gt; print len(v) // built in for slices godebug&gt; print cap(v) // builtin for slices godebug&gt; print v[1] // for slices, arrays and maps godebug&gt; print v[3:5] // for slices, arrays godebug&gt; print v.field // for structs All of the allowable expressions must not be able to change the value of v, so you could not call a method or function on the value, or access a channel. And inline comments on commands, and an option to log all commands and output to a file. If I suggest anything more I'm going to have to provide some patches!
"But I know him in real life and he is nice to meee!", etc...
https://atom.io/packages/go-plus https://atom.io/packages/godef https://atom.io/packages/go-rename https://atom.io/packages/go-find-references Is what I use. I am also working on an Outline Package similar to Visual Assist Outline (see/move declarations around in files/packages), but that's not quite ready to be used yet (:
Does godef work for you? It does't for me. I've been waiting for go-plus to add this feature for a while, [luckily seems about to happen.](https://github.com/joefitzgerald/go-plus/pull/137) 
I'm having no problems with it. You did install the command line program, right?
https://github.com/awslabs/aws-sdk-go https://github.com/awslabs/aws-sdk-go/blob/master/service/sqs/service.go I've also used these for other stuff: https://github.com/mitchellh/goamz https://github.com/rlmcpherson/s3gof3r 
It used to be a confusing mess of forks and libraries with similar sounding names. AWS have backed this one though https://github.com/awslabs/aws-sdk-go (see the announcement from their blog here https://aws.amazon.com/blogs/aws/coming-soon-aws-sdk-for-go/)
Kwame's up to some different things these days, I see. 
I've been working on this blog engine in my spare time for the last few months. My blog has been running on it without hiccups for about a month now (low volume, 700 visits a day tops). I'd like some opinions if anyone has the time to try it out. (Worth pursuing? Any ideas for features? Should I die in a fire because my code quality sucks?) Thanks :) /Edit: There was a nasty bug in v0.1.1 that stopped a lot of Ghost themes from working (assets wouldn't load). That is fixed in **v0.1.2**, so please download that version or newer.
Also worth mentioning: there is an open PR for gorename in [go-plus](https://github.com/joefitzgerald/go-plus): https://github.com/joefitzgerald/go-plus/pull/174
Good work! I know how much effort it takes to get something like this off the ground. I'm looking forward to giving this a try when I start blogging again.
There's a lib here that simply signs requests to AWS, allowing you to craft your own: http://github.com/smartystreets/go-aws-auth
Just be cautious about the one AWS is backing. It's still under development and they let you know that. We use it in production and three times now have had to address changes they have pushed. It's a great library and easy to use. But they keep changing it up and sometimes it feels like they're just changing it because they like to not because it makes more sense. The most recent change took me about an hour and a half to resolve the issues they introduced. So not awful. 
Would it make more sense to require the server to be started as root, bind to the appropriate ports, then drop privileges? I think the concept of only allowing root to listen to ports &lt;1024 disallows users from starting their own service there, where as recommending firewall redirection from port 80 to the higher port is circumventing this.
I must be missing something because I swear I've tried the code like that. It works fine on dev? I heard when you're running it locally you see the objects in blob storage?
Also what are you importing? I'm hearing that some import paths are being depreciated. If you look at the article I posted, it's from a few days ago and is a completely different setup and method of uploading files. That's from the cloud files API docs, the example you posted looks more reminiscent of the app engine examples
Heroku uses Go and has a few remote employees (I am one of them) in the Portland area.
See http://www.reddit.com/r/golang/comments/33nwpa/my_little_syncwaitgroup_wrapperpackage/cqoj656 and http://www.reddit.com/r/golang/comments/33nwpa/my_little_syncwaitgroup_wrapperpackage/cqng6df
thanks! i was using the GCS library, it was due to a bug in goapp 1.9.18 like your link suggested, i updated to 1.9.19 and everything worked perfectly. Pissed I wasted 5 hours when I knew there was an update available, but glad I know I'm not crazy.
So nobody else wastes an afternoon writing a gopher protocol server in go as joke, I'll just leave this here: [Obligatory link to gogopherd](https://code.google.com/p/gogopherd/)
Does echo allow params that are more complex than `:singlevalue`? 
What a bad marketing.
Thanks for the feedback -- def helpful.
We use it in production. It should be stable. I'll fix the docs.
You may test out go-ide. IIRC it was super annoying to set up and use on OSX but, worked quite well on linux. http://go-ide.com
You lost the chance to call it "Gost" :)
You really need to package your application rather than manually creating all the scripts on the live server. There are various projects that make it easier to build all the package types from a single spec. Effing-package-manager is a popular one. Even if you don't actually package it as a deb or rpm you should still be able to install from source using a makefile or similar. It's pretty easy to do. Here is an example: https://github.com/warmans/fluentd-monitor/blob/master/Makefile#L17 
Someone in HN said Goul. So many missed opportunities!
I've gotten the most mileage from just having the vim-go plugin for vim. With the suggested key remappings I can jump deep into the code base very quickly. If you install Oracle you can also do some analysis like what things implement an interface and callers of a specific function. It's not a "fancy IDE" but it has almost all of the same capabilities. I mainly like being able to run go test on the test I'm currently writing and see a little pop up with the errors, if there are any. Debugging a running program has become a little harder over the years. Delve is probably one of the better projects right now, though it has some odd bugs and behaviors. I used to use GDB but apparently it's development has halted in favor lldb, which doesn't seem to want to use the Go runtime debugging file that comes with Go. It's worth fiddling with some more since it's the most control you can have over your process without having to use a third party lib like godebugger (which is very new). If you find anything that works well, please write back. I'm very interested in exploring proper debugging more. 
thats very cool, i love it when i see GoLang used. Thanks!!
Nice, lol! Those were the days, I can remember gopher from back then when all ftp servers worldwide have been fitting on one A4 paper :) Info: http://gopher.floodgap.com/gopher/ Browser plugin: http://gopher.floodgap.com/overbite/ 
Fun play, but ultimately that would be confusing when you're talking about it in real life. You'd always have to note that you mean Gost without the h, not Ghost. 
Did you forget that you [already posted this exact link to /r/golang](https://www.reddit.com/r/golang/comments/2yhvua/made_a_cool_script_to_get_go/) a month ago?
I assume the fact that Rob and Sameer just added this to their talks had to do with the paper being released? 
If https becomes ubiquitous this will lose its value, which is too bad. Google could use its ownership of Chrome's trusted root certificates to proxy https traffic, but the PR nightmare probably isn't worth it.
Makes sense. We don't announce which teams are using Go until they publicly disclose so themselves first. Suffice it to say that there are more Google projects using Go than just YouTube's Vitess, downloads, and Flywheel.
Headers are compressed with HPACK. Compression has some security implications because everything is encrypted: https://http2.github.io/http2-spec/#rfc.section.10.6
Yeah that's the section I was looking at. Everything involving encryption is fraught with peril.
Thanks for the elaborate answer! Much appreciated it, I guess I'll have to check my code then and try to speed it up.
How about this example? https://github.com/weSolution/gapi-example
This is fixed in the latest build of the library, btw.
This redirection is not good. GET variables are being stripped.
Spot on @peterhellberg @Margamel - It's Vim with NERDTree and vim-go. Here's my set up if anyone's interested. https://github.com/premjg/dotfiles
Serious question: what parts don't you understand in the top 5 Google results for "goroutine leak"? Or do you want someone to add a sixth explanation?
A quick Google search points out [this post](http://openmymind.net/Leaking-Goroutines/). Assuming what this author talks about and what you're asking about are the same thing, "goroutine leaks" occur when you create a goroutine but it falls out of scope. Here's the code given by the author: type Writer struct { queue chan []byte } func NewWriter() *Writer { w := &amp;Writer{ queue: make(chan []byte, 10), } go w.process() return w } func (w *Writer) Write(message []byte) { w.queue &lt;- message } func (w *Writer) process() { for { message := &lt;- w.queue // do something with message } } func main() { fmt.Println(runtime.NumGoroutine()) // 4 test() fmt.Println(runtime.NumGoroutine()) // 5 } func test() { NewWriter() } You can see in the code that the ```Writer``` returned by ```test()``` is not stored anywhere, causing it to fall out of scope. However, the goroutine is still running in the background but there's nothing we can do about it. This "leaks" goroutines. 
Spawning a goroutine without waiting for it to finish, exemplified by the error `All goroutines are asleep - deadlock!`. Normally a goroutine would finish on its own automatically, however if there are looping structures within it (eg: waiting on disk IO/network IO) then additional work is required to synchronize/schedule for its departure without triggering a deadlock. It is a necessary part of asynchronous programming -- momentarily having to resynchronize where appropriate.
yeah, I'm the author. I'd be glad to get some tips for doing this with zrangebylex. from my understanding it will only work when everything is added with the same score. it is kinda limiting if you want to sort by scores.. 
Yes, but the trick is this: you add all entries with a score of 0, but you encode the score as part of the prefix itself. i.e. the entry looks like: "term::score::docId". So if your prefix is "foo", you search for "foo-foo\xff" inclusive. This returns all entries with this prefix, ordered by score. You can reverse the order with ZREVRANGEBYLEX. If you want a full term search you search for "foo::-foo::\xff", etc. Then you extract the docId from each entry by splitting the suffix. The trick is that the score should be encoded in a way that preserves lexicographical order. This is done by encoding it as a big endian number, zero padded. There's also a method to do this for floats, I can give you the code if you want. 
&gt; "goroutine leak thanks so much.
I just ran into this issue this week-end :) Check out: https://github.com/golang/go/issues/10574 In short words, go routines are background running functions left behind. They never finish, or after a very long time, and will accumulate, eating resources (very slowly).
is there a trick for doing intersection between multiple search terms like the ZINTERSTORE trick ?
http://play.golang.org/p/upL9wTcojb
I don't want to project too much of how C works on to Go but a struct is essentially nothing but a label for a set of datatypes stacked next to each other in memory. A quick look at the playground seems to comfirm this http://play.golang.org/p/Q9t-MSch6h A map is a hashmap and will take a lot more memory to store the map.
I assume that the OP already Googled and didn't understand the existing answers. Since they all seemed pretty good I thought there must be some sticking point which was unlikely to be overcome with a re-wording or a linking. Hence asking what that sticking point was. Other replies in this thread lead me to believe that my faith that OP may have just googled the problem first was probably misguided.
Great work! I am surprised how many issues you were able to find in the default libraries, especially. I am shocked that this kind of testing is not already being conducted.
... I can't believe I didn't think of this. Guess i'm still stuck in the inheritance mindset. Thanks!
Just to expand on this point for clarification: The format that is being printed, i.e. {1254 2015-04-27 02:22:41 submitted final} {9999 2015-04-27 02:22:41 submitted midterm} is just the standard format that fmt uses when asked to print a struct. The data has successfully unmarshalled into the struct properly - it is just that the key:value pairs are not included when you print it.
Just a short reminder: The survey closes on Friday, May 1st. Results will be able available within a day or two. It's only 4 questions - [just fill it out already](https://docs.google.com/forms/d/1Y-hzAmurNemB1mYVZ2MbANuHZWdliDWQW0bjNkcxqZ8/viewform) ;-)
There's no question that a map takes more memory. On the other hand, if your use case involves using a key to find a value (and the values are all of the same type), a map fills the bill without additional effort. That's not true if you have your keys and values stored as structs in an array. 