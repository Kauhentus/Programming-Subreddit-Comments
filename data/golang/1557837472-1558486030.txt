if you look at the code for benchmarks: it is a joke. seriously. &amp;#x200B; code for each frwk is basically empty loop, in Docker? what do he benchmark? Not surprinsingly, results are as far from reality.
Yeah that does make a lot of sense! I didn't think of it from the perspective of maybe wanting to implement multiple interfaces for that struct. The whole structural interfaces threw me off for a bit even though I use typescript pretty heavily which has the same idea.
Honestly maybe the community pratical attitude is the best thing about golang. If you wrote these comments on a Java board no one would agree, most people there believe that a ConfigReaderFactoryBuilderStrategyBean is the best way to write code.
Those are some good suggestions. I guess I was trying to avoid pointers because I'm not that experienced with them, but it sounds like making it a pointer now will future proof it a little and should also be a little more efficient to pass around. Yeah I'm going to avoid returning the interface, I like the point /u/65a made above about returning a struct lets me implement multiple interfaces in the future if I needed to do so. I kept hearing "accept interfaces return structs" but didn't know what that was the case.
LOL. You are so right. I am working on a Java microservice developed by team of contractors and it has like 2 class worth of code written in 50 files and dozens of directories.
&gt; Go's GC is a non compacting generational GC. Go GC is not generational (yet, there is some work in Go repository). &gt; What I did notice from perf dashboard on grpc is that Go was at times better than Java for throughput but there is a CPU penalty. This depends on what kind of GC you are using for Java. If you really want to compare apples to apples use ZGC or Shenandoah.
Go gin is what you‚Äôre looking for, https://github.com/gin-gonic/gin
I use nothing for this. &amp;#x200B; Or really, there's a few packages that are useful for some of these tasks, but no need to get them from some pre-packaged "framework". Coming from PHP, I assumed it would help to have something like that...but after getting some experience with Revel I found out how over-complicated it is. &amp;#x200B; I use [github.com/bmizerany/pat](https://github.com/bmizerany/pat) for routing... "Controllers" are just functions... I write a few middleware for JWT auth... ORMs are the devil so no thanks there... &amp;#x200B; Frameworks seem like they add unnecessary complexity to Go web apps without really adding much in return.
I love go playground. Thanks for adding this feature.
Thank you :)
Hey! Just wanted to say your post helped me a lot! Thank you &amp;#x200B; \^ L.P.
Just need syntax highlighting now!
If you need highlighting today then you can use [goplay.space](https://goplay.space) instead: [https://goplay.space/#-LQxD\_2TQWw](https://goplay.space/#-LQxD_2TQWw)
My understanding is that it's been established that a generational GC would not benefit Go very much (relative to Java) because in Go, young objects tend to live and die on the stack.
Chi is light and idiomatic Maybe gorilla/mux ü§î
It would be more accurate to call it "GC optimized for latency and not collection throughput". If your language and idioms are geared towards reducing garbage generation as much as possible (eg, effective escape analysis), then GC throughput is less of a concern compared to pause latency.
Passing around a pointer is not "by reference". Take a look at the language spec: The word "reference" is never used in the sense of "a pointer to". Calling this "pass by reference" is just introducing an unnecessary and not even well-defined term without need and benefit.
Don't let Rob Pike hear you say that unless you wanna fight him!
V makes a LOT of promises that are going to be really hard to keep. I'm following it because I'm curious, and honestly want it to be as awesome as it promises. But for now I'm afraid it'll just be vaporware, and I'll be really if it even remotely delivers in the end.
\+1 for go-chi.
‚ÄúWith care‚Äù Definitely agreeing. Compared with the redundant npm packages.
No framework for first project but along side we used mux package for routes. We used revel on the second one. If one is familiar with a framework like sailsJS, it seemed similar. Current project is a queue worker and does not need any framework.
Definitely checking out chi for our next project! :)
I wonder if non-env variable configuration like YAML would work for a docker image of golang?
Do you build on the container build outside and copy into the container?
I don't understand the hate for syntax highlighting. I live by it.
I use echo for all of our production servers. [https://github.com/labstack/echo/](https://github.com/labstack/echo/)
I also don't get it
It can. Kubernetes has a secrets system that can load in any file you want, so that would work. It‚Äôs more of a challenge with something like compose or raw docker commands.
Awesome! Finally!
people at my office have started turning on B&amp;W mode on their macs because they think the colors are "distracting" these are relatively intelligent people I'm like, wtf. Our brains evolved to literally handle seeing colors.
&gt;Our brains evolved to literally handle seeing colors. That's exactly the point, actually. Our brains do not neutrally perceive colors. They have associations and buttons they push and meanings deep in the subconscious, and your conscious mind can't firewall that, or hardly even perceive it. That said, that is also precisely why I use syntax highlighting. (I don't have color turned off on my screens, but if you saw my native desktop setup with my tiled window manager, you would certainly agree there's not much there to turn off anyhow, so I'm at least sympathetic to the idea.)
I hope it‚Äôs not a vaporware as well, I like how rapidly the author update, its interesting that all of the planned developer apps will utilise V, can‚Äôt imagine if someone have in mind for building the new Internet with V, that will be a huge ambition.
[removed]
Thanks for all the adice Gentleman-Tech. In the end I have the function: ```go // EncryptAES encrypts some plaintext with a key using AES and returns the ciphertext func EncryptAES(plaintext []byte, key []byte) (ciphertext []byte, err error) { block, err := aes.NewCipher(key) if err != nil { return nil, fmt.Errorf("EncryptAES: %s", err) } ciphertext = make([]byte, aes.BlockSize+len(plaintext)) iv := ciphertext[:aes.BlockSize] _, err = io.ReadFull(rand.Reader, iv) if err != nil { return nil, fmt.Errorf("EncryptAES: %s", err) } stream := cipher.NewCFBEncrypter(block, iv) stream.XORKeyStream(ciphertext[aes.BlockSize:], plaintext) return ciphertext, nil } ``` and my unit test only checks for the error returned in the case of the bad key. I have another test, more of an integration one, testing that encrypting and decrypting yield the same content. It's however a bit disappointing that there is not an easy way or best practice to mock an internal function such as `io.ReadFull(rand.Reader, iv)` for unit testing.
`net/http`, `database/sql` (with `github.com/lib/pq`), and `html/template`.
As others have said string literals are kind of a special case and are often stored in a read only data section of the program. There could be many calls to foo that reuse that same memory. This is one of the reasons why strings are often immutable under the hood.
Shouldn‚Äôt roll your own when bufio is already very robust.
https://github.com/regorov/logwriter Check this out, may be it is what u are looking for.
Thx you ! But i've finally solve my problem because i use an io.Writer as argument to my log function. I can pass an instance of bytes.Buffer to make some unit tests of my logger. But logwriter seems pretty cool ! :D
yes it's already the case. I use io.Writer as parameter of log function. I'm going to push a new version which allow to define a specific io.Writer to log easily
Shorter language name = better
Except import versions...
I'd say because Ken Thompson did it. I mean he got more awards than i have reddit karma points, his shit certainly stands the test of time. Add Rob Pike and Robert Griesemer, probably more than 100 man-years of programming expertise. &amp;#x200B; In addition, i'd say that "Go", as any other programming language, consists of different parts &amp;#x200B; \- a language specification \- a compiler (well, if it is a compiled language) \- a standard library \- a build/ packaging system \- tooling (from type ahead in an editor to generating documentation to running unit tests) &amp;#x200B; Considering these, Go is my current choice as it offers the most complete coverage of all languages i am aware of, and i got paid for programming in Forth, Pascal, C, C++, Java, Smalltalk and Clojure. The language specification is easy to follow. The compiler is incredibly fast. 95% of my problems can be solved by the standard library alone, no need for external dependencies. If i need some esoteric stuff, packaging has become nice and easy with the addition of "go mod". Tooling is awesome, although my daily driver is just plain vim. Last but not least the Go 1 compatibility promise which makes my code work year after year after year. &amp;#x200B; If i had one wish it would be to remove the garbage collector instead of adding generics.
Btw VS Code (and others) support table driven tests via [https://github.com/cweill/gotests](https://github.com/cweill/gotests) as part of the go language support plugin.
unbearable
Grafana and Prometheus are great choices (although they might be a bit heavy if you're just trying to get data from a single webapp). The way it works is: 1. You'll have to write some prometheus code into your existing go code, telling your code what it should record and eventually export. [Prometheus has a whole instruction page for this](https://prometheus.io/docs/guides/go-application/) 2. In order to export the metrics you set up in the previous step, your binary will expose a port that will serve http content with the value of the metrics 3. Your Prometheus server will reach out and scrape those metrics periodically and store it in its time series DB 4. Prometheus will then make these metrics queryable, in which you can point a Grafana frontend to them and use grafana to display the metrics how you like
I don't know how frequently Rob uses the playground himself. My guess is that it will at least become available but no default if many people ask for it (also via code contribution). I like his kind of open source leadership but syntax highlighting is one of those fringe topics where he probably won't want to spend a lot of time arguing to be right.
You should ask what datasources they back grafana with. If it's prometheus there is a library you can use to expose metrics pretty easily https://prometheus.io/docs/guides/go-application/
Community is key, imo. JS isn‚Äôt batshit because the language is batshit, it‚Äôs batshit because the community is batshit.
That site needs attention for mobile users, imo
[removed]
&gt; That said, that is also precisely why I use syntax highlighting. yarp. 'zactly. I could never really get the hang of a tiling WM.
yes definitely, that's a bad usage of the vocabulary used in other languages that does not apply in go. thanks for noticing it, I will fix it
&gt;with allocations and without allocations That was the whole point of the article. What is the impact (with the GC) in using the heap instead of the stack- I will have a look at your suggestion :) thank you for the feedback
Thank you. I will integrate Prometheus and use Grafana to display the data.
This is a fantastic article on the topic. Thanks for sharing!
there are many ways to skin a pig....I think you should just start and if you build it the right way, you can separate stuff when you need too. It is depending on the number of tenants, the amount of data, the flexibility of your application. There is no wrong answer (and no correct one either)
So I need to have two go routines - one for the keyboard input **routineA** and the other for the long loop **routineB**. And both of these will be launched by the **main** func. I am thinking aloud here. * I need to create a channel **chanC** in the main func * pass this channel **chanC** on to both **routineA** and **routineB**. * Use this channel to communicate between the two routines What I am trying to find is if the channel created in the main func, passed into the routines can communicate data between the routines? or it has to use the main func to communicate between the two routines.
I used to work with Slim and you can easily make something like that, without any framework, which will be superfast. (For template engine, we use Cloudykit and the mux is httprouter) Just a plain, simple, maintainable application, without any fluff.
Second this. We also use echo for all our production servers.
How would it work if the command that I want to use, is running the program. (Which is a webserver that doesn't stop) Could you stop it/restart it when files change? &amp;#x200B; From the video stream, it looks like the commands aren't done in the order they are configured, but for me, it has no use to start the program if a test fails. &amp;#x200B; Perhaps it is possible to configure if the watching will stop on fail for each line, or will continue.
I‚Äôll third this. I use Echo for just about everything too.
He has made some pretty strong statements in the past about it, basically to the effect of "I don't write with crayons and I don't code in color"
1) It doesn't support endless running programs yet. But I think it can be a feature. 2) Yes and no. Watchers runs in parallel, but commands in watchers runs consistently. I think here I can add flag like \`continueOnFail\` that will be \`true\` by default.
Take a look here https://gist.github.com/longfellowone/5971edf87524fce88135c9b78ff6b40c
I added \`breakOnFail\` flag in this PR [https://github.com/Enapiuz/multiwatch/pull/5](https://github.com/Enapiuz/multiwatch/pull/5) Hope it can be useful
This probably isn't a good design for most applications. It is nice it has some retry, but what if the DB is up, the app comes up, then the DB goes down later for an hour for maintenance? &amp;#x200B; Maybe better: have your ingress check a /healthz endpoint on your go service. Have the /healthz run db.PingContext(ctx). That way it will route traffic to your endpoint only when it is up. Or you can do something similar but all within your app as a top level ServeHTTP handler. &amp;#x200B; So... The link presents something that will help make the DB and App not worry about which one comes up first. But I think you can do better without much fuss.
Modd (github.com/cortesi/modd) has this feature, perhaps you can see how it is done there (deamon.go)
Thank you, I'll check it out
Chi is nice, it takes standard `http` package types and is more of a utility than framework. We also use gorilla/sessions for cookies.
It's easy to get things done in it and has good tooling.
Actually, it isn't totally impossible to allocate dynamic memory on the stack. The Go spec doesn't prevent this. But it is very uncommon to put dynamic memory on the stack because C chose not to take this route, and most languages try to keep some amount of ABI compatibility with C. Plus you end up having to do weird tricks with the stack frame and stack pointer if you really want dynamic memory on the stack.
That‚Äôs literally the opposite of a multi tenant system
Was this talk recorded? Looks very interesting.
Thanks. I like this approach too. I have to compare btw, because Revel &amp; Chi seems a shot learning curve.
&gt;echo Echo vs Revel vs Chi, that is the new question - I will try to build a sample project with the 3.
\^\_\^ Plus gorilla/mux or bmizerany/pat for routing ? Sure, bloat-free combination ;-)
It matches the "case" statement. Without that match, you still have no context. Basically, it's like cutting `interfaceVal.(Type)` into two pieces, `interfaceType.(X)` and `X is Type`, and you need them both. Your example only provides the first.
What would it do without the case statement? If your goal is to print the type name, then `fmt.Printf("%T\n", x)`
I had a look at it. The doc seems poor, but there are a lot of relevant examples such as Chat server.
That was my goal, and I did not know I could do it that way.
That makes sense, thank you for explaining.
how many endpoints do you plan on having?
[removed]
&gt; I am ... looking for a ... light Microframework ... Spring in Java LOL! &amp;nbsp; The standard library will get you everything you asked for. Take a look at the [go wiki](https://golang.org/doc/articles/wiki/) for an example.
Great question. I've been working on an app lately thats deployed to AWS and am looking at using X-Ray as I dont want to setup a 3rd party service. I would also be keen to hear what other lightweight method people are using before going down a 3rd party service route.
Why a queue package rather than native channels?
From person experience, and years of diligently participating this sub, I can say with high confidence that you‚Äôll eventually hate this code you‚Äôre writing and wonder why you‚Äôre doing whatever it is you‚Äôre doing rather than simply accepting an interface. ü§∑‚Äç‚ôÇÔ∏è
It's really that I was looking for a way to output the type of a variable without reflection, which someone else helped me do
What are channels and how do I use them? Basically as long as I can send variables around to different modules like I‚Äôm doing here (but sort of unsuccessfully) that‚Äôd be great!
its not JS. hehe
I recommend you sticking with Prometheus + Grafana. To instrument your applications I would recommend you to try the OpenCensus Lib ([https://opencensus.io/stats/measure/](https://opencensus.io/stats/measure/)) the lib is pretty simple but very powerful. You can then export metrics to several backends like prometheus, stackdriver, aws x-ray, datadog and others ( [https://opencensus.io/exporters/supported-exporters/go/](https://opencensus.io/exporters/supported-exporters/go/)).
I was thinking a k8s cluster you can have a database server with several dbs on it, but each app gets its own set of one or more DBs and logins. Vs shared database using a magic table prefix in the the same DB, like cheap WordPress hosting. There are multiple tennants on the DB server and k8s puts things, pods, where it wants to, within limits , and you use a cni that does firewall rules for isolation from each other. But each thing is an orange not a wedge in an orange.
Very cool. Love the Go community. It‚Äôs frankly this kind of support that just puts the experience over the top. :)
...and the expand on that, does it play well their netdicom package?
Building it right way being the keyword here. That's exactly what I'm looking for.
\^\_\^ Light is not possible with Java. But SpringBoot is the lightest we can get right? Or do you use Rapidoid ? ;-)
Hard to say - I would say above 10, maybe close to 20
you would make the channel in main, and pass it to both goroutines. one would listen for key input and the other handles it.
Well technically it‚Äôs still using reflection. reflect.TypeOf(x)
Stick with the standard libraries. This approach will pay off in the long run. No dependencies, easier to maintain.
&gt;but each app gets its own set of one or more DBs and logins. You are thinking of microservices, which is not related to multi-tenant in any way. Multi-tenant means that you **never** need to create new database at run-time. If you are building SalesForce, you don't create a database for each company. If you are building Reddit, you don't create new databases per subreddit. Everything is in one Database, which means the application must figure out the permissions for each user: Users at company X can't see company Y's data. User A cannot see private subreddit Z, but user B can.
&gt;But looking for database design/architecture for maximum isolation &amp; security. &amp;#x200B; That's why you can't find anything. The DB arch has nothing to do with it. Nobody uses the database to enforce their multi-tenant architecture. (That would require creating a new Database user per user that signs up for your system. Databases can't handle that.) &amp;#x200B; Instead, all the multi-tenant work is handled at the application layer. Every time you access a resource, you must verify they have permission to actually view the object. That seems complicated, but in practice it's pretty trivial. Usually just a single clause on each query. For example, if you are building something like SalesForce, you would never say `"SELECT ? from sometable"`, you would always say `"SELECT ? FROM sometable WHERE companyID=?"` That way, the data would not be found if it didn't belong to your company, and users in other companies can't see your data. Worst case, you may need to do an extra join or two in order to check that the data is reachable by that user or company. You also tend to build a few extra indexes involving the companyID. In most apps, there are usually only a handful of ways to query data, so it doesn't take long to audit that each of them is appropriately scoped. The only time it might get tricky would be trying to give customers ad-hoc reporting on your database. (You'll have to build in higher level protections, and have a lot of white-lists.)
This was a talk at GopherCon Russia 2019 in April. The talk recordings don't seem to have been uploaded anywhere yet.
This was a talk at GopherCon Russia 2019 back in April. This talk's recording is here: https://www.youtube.com/watch?v=ewmUUC1rF28 YouTube has some limited auto-generated English captions if you'd like.
The biggest "gotcha" for me about moving to Go modules was finding out that `go get` no longer populates the `GOPATH/src` directory. It used to be how I would download (clone) Go projects into my GOPATH automatically and then start working on them; but now it just updates go.mod and puts the code into a read-only folder `GOPATH/pkg/mod`. So, now I manually need to create the folder tree of `GOPATH/src` and clone down repos manually if I want to continue using that structure (which I do, since I have dozens, if not hundreds, of dev repos organized in it and I'd rather not move them - heck, I put all my non-Go projects in GOPATH too).
Well if you use something like PostgreSQL, then you can have everything in one database and use a schema per tenant.
It's still tricky. Stack size is not universal across compilers and operating systems. How much of the stack is used? When to move the array to the heap? What's the upper limit of the array before it leaks to the heap? Etc.
Wouldn't say it was the first. Python was very much designed for maintainability in mind.
Looks like Python was designed with [extensibility in mind](https://www.artima.com/intv/python.html). That's not the same thing.
That's not its only feature. Python was very much designed with readability and long term maintainability in mind. This is why Guido wrote PEP-8 in 2001 and why you often hear code being described as Pythonic. Meaning there is only one obvious way to accomplish things. &gt; For many, Python‚Äôs focus on readability, coherence, and software quality in general sets it apart from other tools in the scripting world. Python code is designed to be readable, and hence, reusable and maintainable‚Äîmuch more so than traditional scripting languages. The uniformity of Python code makes it easy to understand, even if you did not write it. https://www.oreilly.com/library/view/learning-python-3rd/9780596513986/ch01.html
Do the simple thing until you find it's a problem by profiling.
This is channels https://gobyexample.com/channels There's a lot of information about go channels in the net
The only way to answer this question is to measure the two approaches using a realistic application workload. But don't do that until determine that there's actually a problem to fix. &amp;#x200B; it's possible that the pool will hurt performance.
Open for help :)
https://golang.org/doc/ While you‚Äôre at it, read up on goroutines.
Most editors will tell you what type something is...
Interesting. Thanks for the links. Looks like it was the first. That said, Go has been designed with modern software engineering in mind. Built in support for not just unit tests, but benchmarks too, as an example. My favourite features are types that implicitly satisfy interfaces, robust time computation and channels - they really are a beautiful way to write concurrent code that scales well.
any special requirements that would require a router more sophisticated than a `switch` block? i'm trying to get at: do you really need a fancy router?
ok I know, thank you for replying
ok I know, thank you for replying
I was hoping for it because it was so hard to test even simple code with output formatter or any common package libraries like protocol buffers etc. Finally!
I wrote a simple module you can import, which will submit basic metrics to a remote whisper/carbon host: http://github.com/skx/golang-metrics I use that in all my applications, so I get memory/cpu metrics and they can be displayed upon grafana dashboard.
what would `x.(type)` evaluate to? what if `x` is an `int` and you typed: ``` theType := x.(type) ``` what would the type and value of `theType` be?
But both are not multiple applications they are one app and you use the client customer unique ID as part of the unique user ID or as a filter on it, Corp id 123 with a CorpId==123 in the dB and static assets are stored under static/123/path/to/stuff. You need to make sure login cookie is only authenticated against Corp 123 items. Set up virtual hosts and ask certs correctly and you should be ok
This is a minor but really annoying thing about Go modules--they change how go get works. They should have made `go mod get` to install module dependencies
Just to add more options to the list you can also check ELK stack which is Elastic search with Kibana and Beats but if it's small app all those solutions could be overkill. We run stuff in docker so monitoring docker logs and nginx logs is mostly what's needed without heavy processing. Kibana can handle it nicely so does Grafana.
Not really. I share the general idea to avoid bloatware. ;-)
Radix sort on strings. * Something not already solved in the standard library? Check. * Documentation? Check. * Tests? Check. * Benchmarks? Check. Have an upvote!
You should add a `defer ticker.Stop()`, otherwise you'll have leaked a goroutine.
 Maybe better: have your ingress check a /healthz endpoint on your go service. Have the /healthz run db.PingContext(ctx). That way it will route traffic to your endpoint only when it is up. Or you can do something similar but all within your app as a top level ServeHTTP handler. I've thought about this a few times, but always come to the conclusion that apps should have 3 health states: * Healthy * Degraded * Unhealthy Healthy is obvious. Degraded would used for things like signalling that a dependency of the service being health checked is down. For example, if your database is failing. Unhealthy would ideally be if the current service is failing for some internal reason. The reason being, you can end up with a series of cascading failures if your health check ends up automatically terminating application instances. You might end up with fewer instances than you need, maybe even zero. In which case, other services that depend on that service also then start to fail, and so on. This is probably avoidable by reacting differently to an unhealthy service though.
Thanks! I've fixed the code.
Thanks for the info! Though, how about Schema/namespacing of RDBMS? (e.g. Postgres)
congrats and thank you!!
&gt; We have made changes to several of these dependencies (that are not appropriate for upstream pull-requests), and we need to keep those changes. Please do not ever do that. It's a nightmare for distro integrator. Also it's a bad security practice as you don't ever get the update from upstream which might fix security holes and other bugs.
The standard library does a lot of transparent reuse for you that isn‚Äôt immediately obvious, including transparent keep-alives with connection reuse. You don‚Äôt need the pool.
for instance, you could make a configuration file where all tenants are stored with their specific settings, or have 1 file per tenant. Inside the settings you could have a database name (each tenant has it's own), or a setting with a table-prefix. You could have common handlers they all could use, and make some special ones, that only a certain tenant can use (or a group, or... you name it) It all depends on what your plans are. But then again, you can always scale up to the next solution, as long as you keep the code clean.
could it also reload itself if the configuration has changed? This would actually be a cool option :-)
`go get` will still do the old thing of cloning and installing a repo, but only if you‚Äôre not in a directory with a go.mod file. It‚Äôs confusing.
Unless there‚Äôs a major bottleneck, I would say no. The biggest issue here is security. You‚Äôve gotta be 100% sure you clear the old one before reusing it, otherwise you‚Äôre liable to have session data leaking between user sessions.
Not yet, but I have thoughts about it
`type CustomError string func (err CustomError) Error() string { return string(err) }` error is an interface in golang, not a string. `type CustomError interface{}` if you do that, you can use `CustomError` like go native error.
&gt; young objects tend to live and die on the stack. Well, it all depends on escape analysis, which isn't so great in Go.
I know, I've been in this relationship far too long.
It‚Äôs remarkably confusing in a way that in un-Go-like.
OSS has value when leveraged any way in accordance with its license. The meta-level tail does not get to wag the dog.
if you need to work with your GOPATH inside of a module directory, you can do it with \`GO111MODULE=off go get -u xxxx\` for now. &amp;#x200B; alternatively cd into your GOPATH
[removed]
I probably reduced the number of repos I would have by over a hundred by having a misc repo that contains all my tinkering with individual concepts. I feel like you personally might be referring to that many actual libraries though, considering everything you've worked on in Go.
Spring Boot != Spring. Spring is a big beast that has become (arguably) worse than the thing it was created to kill (EJB's) I personally like Drop Wizard on the java side. I like to have a good reason to stay away from any of the Spring ecosystem. :-)
This pattern pops up a couple times: if cap(arr) &gt; len(arr) { arr = arr[:len(arr) + 1] } else { arr = append(arr, Value{}) } Isn't this already pretty much what append is doing? Is it just to avoid re-zeroing that element?
[removed]
Jeff Sessions? lol
I totally share your opinion about Spring. I got smthing like 16 years of projects using J2EE technologie: I now hate to use it. Verbosity everywhere. I never heard about dropwizard (mainly because I moved away from java) : it seems awesome -thanks [https://www.dropwizard.io](https://www.dropwizard.io/) &amp;#x200B; if you hate Java, you should consider Go ;-) Or anything that's not javascript \^\_\^
So I took a look at channels, and to my understanding they‚Äôre just pipes basically. However, the channel examples I see are for IPC between threads of the same program. Is there a way I could use a channel to send data from test.go to queue.go?
I see that https://github.com/abraithwaite/jeff/pull/5 supports extra session metadata (`err := s.j.Set(r.Context(), w, email, []byte(r.UserAgent()))`. I would love to see more added about actually using this for detecting hijacked sessions. For example, it's unlikely the user agent will change suddenly, or if someone's IP is in one country for 5 requests - then suddenly switches location (could be vpn/proxy, but most start/end the session while in the tunnel).
Those fields are not exported from the struct. Capitalizing a field on a struct allows it to be exported; i.e. change fullPath --&gt; FullPath. https://golang.org/ref/spec#Exported_identifiers
I like the mascot
`err = s.jeff.Clear(r.Context(), user.Email)` Explains so much. I just don't recall what.
This is a really bizarre way of switching a repo to modules. Particularly the part about manually issuing replace directives for each dependency + manually creating go.mod files seems needless and labor intensive.
I seriously doubt you can have tens of millions of schemas either. But tens of millions of users is pretty trivial on commodity hardware.
I use this https://github.com/motemen/ghq
It was indeed labor intensive. I wanted to be able to switch over incrementally, dependency by dependency, especially since much of the vendored code was quite out of date. It was the only way I thought I could do that. Are there other ways of accomplishing that?
Ah gotcha, thank you!
Actually! One feature I want to add is audit logging. I just haven't had the time. I don't think it's in the session libraries' domain to actually do enforcement of blocking, but it may make sense to add a hook to another function with the session context which can control block/allow behavior before actually calling the wrapped function. :-)
I've used [github.com/alexedwards/scs](https://github.com/alexedwards/scs) and it works pretty well, any reason why I should use yours over that one?
Not an answer (/u/guiltykolprit already took care of that) but when sharing go code, is recommendable to use https://play.golang.org/ , as it allows the people to execute and work better with your program
First time (before reading go docs), I was expecting something like: ```go x := 0 theType := x.(type) // my guess: theType == "int", but actually it's a compile-time error. ``` as well as in js: ```js console.log(typeof 123); // expected output: "number" ``` Now, I am aware of three ways of getting type: - string formatting; - reflect package; - type assertion. I don't know why, but I always write `x.(type)` and then rewrite it to `reflect.TypeOf(x)`...
;-)
There‚Äôs no way to answer that without knowing context. He‚Äôs not saying his library is better than all other libraries. He‚Äôs saying this is a new one that is lightweight and has some specific features. The readme does a good job of saying what those features are.
Has anyone tested tens of milions of schemas? There are **lots** of websites with 10s of millions of users. Even if you start with schemas for a handful of entities, you quickly find all kinds of corner cases that it can't handle: - Maybe you need to support departments that don't trust each-other within companies. Can schemas support inheritance? - Maybe you need a user with admin access all copies of one table but not the rest. Can you build a cross-cutting concern like this? (Sure, one-time, but how do you keep it up-to-date?) - Maybe you need to log admin access, but not regular access. The upshot is that you will quickly realize that parts of your security are implemented in the database, and parts are implemented in the application. Not only is that harder to change, but it's also harder to understand and document. But the biggest reason not to use Schemas is that **they only work for Monoliths.** In a microservice world, schemas from one service can't magically transfer over to all the other database servers for the other services. (And they should be different Database Servers, not just different databases on the same server). i.e. When you create a new Corporation ID, do you notify all other services so they can create a new schema? What about services that aren't using Postgres for a datastore? I'm *not* saying "don't ever use schemas". I'm saying they are not a good tool for large mult-tenant applications that you want to scale.
&gt;cho vs Revel vs Chi, that is the new question Check out the Echo guide and I think that's what won me over. [https://echo.labstack.com/guide](https://echo.labstack.com/guide)
Pretty much what d1str0 said. It's a good library but I believe mine is a bit more opinionated and slightly more extensible.
Yes and No. &amp;#x200B; If a database is not a hard dependency, then /healthz should still return an HTTP 200, even though it is "degraded". If the database is required for any application use /healthz should return an HTTP 500 because the application is effectively down. &amp;#x200B; /healthz is a pattern of of traffic routing, and for that you need a binary decision. This routing could be an external load balancer / proxy, or it could be the first step in a chained ServeHTTP. But it needs to still be a binary decision. &amp;#x200B; There are other tools and patterns you can use to prevent cascading cluster failures. &amp;#x200B; But again, I agree with the idea that applications and databases should be able to startup independently without an explicit ordering. That is important, regardless of how it is accomplished.
I imagine it's hiding the credentials to the original API from the frontend or something similar. Or it's just an exercise.
Ok, will do this in the future. Thanks
You greatly escalated it to the other way. I don't consider user a tenant. I consider something like a company as a tenant. I won't be running a million subdomains but I might a few thousand. also Nobody said you should put all of the companies into one database with a few thousand schemas. This would be difficult to scale. You could put a few hundred tenants int oone db and the next few hundred into the next one.... You will need to load balance on the front end either way. So this doesn't complicate things too much.
It makes a guy names Jeff forget his email address.
Long story short, the usual idea is to make interactions with the DB going through some sort of interface, so you can swap it out with a mock implementation. For example, maybe there's type UserStore interface { GetUser(id int) (*User, error) SaveUser(*User) error QueryForUsers(name string) ([]*User, error) // etc } type dbUserStore struct { db *sql.DB } // implements UserStore using SQL calling methods type mockUserStore struct{} // dummy implementations
The procedure I've developed is basically that I pipeline all my requests like so: 1. In the beginning of the handler, manipulate the request to extract a clean, coherent object that represents the request. 2. Process that request object in a single call that returns everything I need to return to the user. 3. At the end of the handler, do whatever I need to the HTTP response to send it out to the user. In many cases, what can "go wrong" is then all isolated to step 2, which I can test without having to worry about HTTP at all. It isn't too hard to also make "that one method call" something like an interface on the object that implements the handler, so you can also test the handler strictly from the point of view of "does the handler properly turn HTTP requests into this object the way I expect, and does it handle returns the way I expect". A lot of times this isn't even really that necessary, though; code that takes a few things off the query string and then dumps some object out as JSON can't have much go subtly wrong with it. The gateway of having to construct a properly-typed request object is a lot of validation on its own. Also, this isn't what I do in Go; it's what I do in web handlers now, in all languages. I understand the temptation in a web handler to just "get down to business and start doing things" but I've come to see it as an antipattern, and almost every time I fail to resist the temptation I've come to regret it.
for q := range congress.Question { s.jeff.Clear(r.Context(), Answer(q)) }
&gt;So this doesn't complicate things too much. Sure it does. You didn't address my question of "What if you realize that departments also need security?" and "What about Microservices?" &amp;#x200B; It also complicates migrations: You have to write code to run the migration for each copy of the table in each schema. That would prevent you from using a lot of off-the-shelf migration tools. You also have to write schema verification tools to verify that all your schemas are the same, or bad things happen. &amp;#x200B; I admit it's a trade-off: On the one hand, you get a tiny bit of security enforced by the database. But on the other hand, you are adding a lot of complexity (i.e. instead of "here is my table", you have to worry about the possibility of different companies having different table structures, even if only temporarily. Ick.) &amp;#x200B; Oh, and how does the system administrator do queries across companies? (Honest question, I didn't see anything relevant in the docs.)
Hey, I'm currently working for a small startup, wirting IoT services for custom radio MAC layers with cross interface integration. This is my first full time programming gig, although Im not sure if the marketing team can deliver what's needed to keep everything afloat. I have been primaraly working on auto scaling containerized microservices, if I sound like someone you want just let me know and in the next month I would have an answer. (Side note, I wrote said MAC layer, I love that low level nonesense)
True, and I assume that a simple `r.UserAgent()` check every page is probably good enough for now. However, it would be neat to see more ideas in this space for libraries like Jeff. Could also log a []slice of all seen IP's for this session allowing the user to see what User Agents + IP's are using a login for them.
so -- type assertion doesn't really get you the type -- it gives you a value of a specified type. type assertion is where you assert that an interface stores a value of a specific type like: ``` x, ok := somevar.(int) ``` notice that here we think we know it is of a particular type ahead of time. a type switch allows you to test if an interface is of a set of types: ``` switch somevar.(type) { case int: log.Printf("somevar is an int!") case io.Reader: log.Printf("somevar is a reader!") default: log.Printf("somevar is of some unexpected type %T", somevar) } ``` but in both cases, we have to know and specify which type we're looking for in advanced -- this way the compiler knows what type of symbol to allocate and how much space to allocate for it. notice that a type switch can be expanded to a series of type assertions. the above switch could be re-written as: ``` if _, ok := somevar.(int); ok { log.Printf("somevar is an int!") } else if _, ok := somevar.(io.Reader); ok { log.Printf("somevar is a reader!") } else { log.Printf("somevar is of some unexpected type %T", somevar) } ``` so type switches are just ways to express multiple assertions more succinctly. but to my point, there is really only one way to ascertain a type at runtime -- that is with reflection; `Printf()` uses reflection under the hood. type switches and type assertion do it at compile time since you can only assert or switch over types you expect.
For example, if you want to stream your comment replies and reply to them, all you need is this: package main import ( "github.com/thecsw/mira" "fmt" ) func main() { r, _ := mira.Init(mira.ReadCredsFromFile("login.conf")) c, _ := r.StreamCommentReplies() for { msg := &lt;- c r.Reply(msg.GetId(), "I got your message!") } }
Happy reddit-birthday benevolent moderator and performance mastermind dgryski!
Yeah luckily for me i am early in the process but not a pro at go yet. I want to find a better pattern here so that i can stub things as necessary when it comes to testing. 1 seems straight forward since i bind it to struct simple enough, or pull a query string. The 2nd part is what I will have to work on. I will try to abstract the commands away from the handler so it's not one to one it should just call another function that does all my db stuff for me. Thanks for your input
&gt; you should consider Go I've been doing Go fulltime for the past year, and loving it! I have to go back to java every now and then, and it reminds me of why I love Go!
A quick look at both libraries seems to show an important difference: a bufferedResponseWriter buffering _all output_ to catch session changes before headers are sent (https://github.com/alexedwards/scs/blob/master/session.go#L118). Which at one point supported websockets? (https://github.com/alexedwards/scs/pull/12). Jeff seems to handle this better (but not easier): - https://github.com/abraithwaite/jeff/blob/master/sessions.go#L143 - https://github.com/abraithwaite/jeff/blob/master/sessions.go#L174
nice !
I recently implemented an auth service in Go and ended up using Gorilla Sessions. This didn't even show up in Google and Github search AFAIR. Probably a better name or description might help discoverability .
@ruertar, helpful comment, thanks for clear explanation.
Anything for lord Canti
Thanks for your feedback. This seems far more practical than what i was doing. In my handler this is where i would be responding with a json or error. How would i make them use the mocked function over the real implementation what would that look like in the handler since it's not accepting a type UserStore? Say for example i have this block type UserStore interface { GetUser(id int) int } type Mock struct {} type Real struct {} func (Mock) GetUser(id int) int { return id+5 } func (Real) GetUser(id int) int { return id } func handler(w http.ResponseWriter, r *http.Request) { var t Real fmt.Println(t.GetUser(5)) } how would i stub out t Real here? i know you could do `UserStore.GetUser(mock, 5)` which would work but just curious how you would you go about this here since you can't inject it
Yeah, it's probably not a good idea altogether. You can start creeping close to the upper limit of the stack, and there are some performance tradeoffs arising from the non-trivial bookkeeping of the stack/frame pointers.
What do you think of gqlgen?
From the benchmarks I can see, Chi is far faster than Revel (like 2x). Revel seems to add heavy overhead. Go/Gin seems as slow as Revel. Echo guide is very good, it won me over as well. I need to compare on the performance side as well.
Go/Gin seems to add heavy overhead.
Let me know how it goes. For some reason, I get much better RPS on Echo than Chi. But I am sure Chi is slightly faster in the benchmarks test.
How does this compare to [https://github.com/turnage/graw](https://github.com/turnage/graw)? I've used that one quite a bit for building bots before...
i mean, bitmaps aren't really slices
Absolutely. Mira is a subproject of MIB, our website is meme.market We are planning on migrating the bot to Go and after doing some research into available Reddit Api libraries (graw was the first one), we found that most of them did not satisfy our needs and were a bit confusing to start with. So, we just started making our own version of it. We believe that mira is a simple alternative to work with Reddit Api. It‚Äôs simple to use and it works
love the idea, hate the name. its a clever pun, of course, but fuck Jeff Sessions.
Expected an SMS interface to MS-DOS.
couple things right off 1. Only works with scripts not web apps 2. No error handling if the authentication fails Had to modify code to spit out why Auth was failing {"error\_description": "Only script apps may use password auth", "error": "unauthorized\_client"} &amp;#x200B; will keep looking
True, we will work on a more verbose error handling. Well, we use OAuth for authentication and we update the creds before they expire
I have only used gqlgen for small personal projects; for those it mostly did what I needed. Wanting to avoid doing a lot of boiler plate work to add Relay specifications I came across [this issue](https://github.com/99designs/gqlgen/issues/228) on gqlgens GitHub. I unsucessfuly attempted to add Node interface support through gqlgens [current plugin system](https://github.com/99designs/gqlgen/tree/master/plugin). To do so I attempted to modify the existing [modelgen plugin](https://github.com/99designs/gqlgen/blob/master/plugin/modelgen/models.go) and the [config options](https://github.com/99designs/gqlgen/blob/master/codegen/config/config.go). This experience felt more difficult than my attempts at writing code generation plugins for protoc and significantly less flexible than what protoc allowed. The result was that I made this attempt to apply the protoc approach to the code generation from GraphQL inputs.
All hail!
I‚Äôm not sure 3rd party npm packages vs go core language features is an equal comparison. Instead, I‚Äôd compare against the ‚Äúeverything to everyone‚Äù evolution of JavaScript‚Äôs language constructs and syntax.
I‚Äôm sorry. What I mean are the third party packages of golang vs third party packages of node.
Please stop using alpine for go in containers. Unless you need cgo (which most systems dont), use SCRATCH. Time after time after time, I see tutorials and videos where people use alpine when you have a perfect opportunity to share a better option for go; it's one of the many things which makes go so much better for cloud native computing.
[removed]
There is [https://chrome.google.com/webstore/detail/better-go-playground/odfhkelcmblecfdnboahphiafolojmpl](https://chrome.google.com/webstore/detail/better-go-playground/odfhkelcmblecfdnboahphiafolojmpl)
Yeath, I did that. Thanks for our response
Thank you all for your suggestions and feedback, I have taken them all into account and released v2 \[here\]([https://github.com/itmayziii/robotstxt](https://github.com/itmayziii/robotstxt)).
I wish AWS had a method for deploying like app engine with go, but this is really helpfull thank you
- [Grafana][g] ([GitHub][ggh]) - Not only recommending this because it is written in Go but it's the most advanced monitoring tool out there and it's totally open source and extensible. - [Prometheus][p] - The most advanced tool when it comes to time-series based monitoring. Not directly related for error monitoring, but important for possible error sources like long-running or stuck requests. Also I don't think your goal should be to find a tool written in a specific language but finding the tool that best fits your needs. Anyway, since Go is awesome most of these great tools today are written in Go so this isn't that hard üòÉ [g]: https://grafana.com [ggh]: https://github.com/grafana/grafana [p]: https://prometheus.io [pgh]: https://github.com/prometheus/prometheus
In the README he affirms the issue with Gorilla is: 1. Single ultra-secret key. 2. Hard to revoke sessions. I say: 1. I honestly don't see a problem with this. There are way way more complex ways to stamp authority which suck. 2. in my experiment with gorilla sessions https://github.com/kaihendry/internal-google-login ... all I need to is change the secret. Yes, *everyone is logged out*, but it's typically painless (fast, 1 click) to log back in with Gauth.
Friend of mine asked me this question a few days ago. 1. Fairly lightweight syntax. It's not Python, but it's not the baroque intricacies of C++ 2. Non-dogmatic ecosystem right now, not the kind of boilerplate and ritual that Java has. 3. It has pointers. Java and other languages took the wrong path here. Pointers really help. 4. Fast compilation. 5. Decent tools, probably because the standard library has a Go parser and AST in it. 6. It's easier to get things correct than in C. I don't understand this, but it's true. 7. Statically-bound executables, although libc can slip in there.
Sentry can run on premise, no ? (as far as I rememeber it's completely open source) [https://github.com/getsentry/onpremise](https://github.com/getsentry/onpremise) And supports go [https://docs.sentry.io/clients/go/](https://docs.sentry.io/clients/go/) [https://docs.sentry.io/clients/go/usage/](https://docs.sentry.io/clients/go/usage/)
I always teach my student to have a very small handler, which just acts like a pass-through to a service layer, which contains the business logic. Those you can test without the hustle of "the web", so you don't need "difficult" stuff to test where it is all about. (B-Logic in a handler is for me a no-go)
Yeah I had some really tightly coupled logic which I didn't like, so I'm slowly breaking it out, just trying to find how I would mock the DB, the function itself should be testable and not have to work using the router at all
Go modules are not for installing binaries - you'll need to do this in a separate step in your build system.
This is my third project with Go. Actually, I made for myself to build a GraphQL API with graphql-go mod. Usually, I build a GraphQL API with the modularized schema for each function(resolvers). When I build it in Node.js, there are some tools to merge and stitch schema files into one. But, I failed to find a tool doing the same in Go ecosystem. Therefore I made this tool and hope this to help you to build your works.
I thought this post would be about learning to use sessions in go instead of ending up using a library
&gt; Lightweight, server-only API. Uncertain about what the purpose of the Manager interface is. Heavy use of naked interface. What is a naked interface ?
Hehe, just as fun exercise, please don't do it for real. - embed protoc into package with vfsgen - output content of binary into filesystem - add exec permission - run it ü§£
I think there's a pretty big difference between Grafana and Prometheus and something like Sentry, Raygun or Airbreak. While it's nice to monitor errors it's usually helpful to be able to dig into each individual error and see things like the stacktrace, user, etc...
https://tip.golang.org/pkg/errors/ What's left are `Is`, `As`, and the `Wrapper` interface. Opaque errors, custom formatting, and stack frames are removed (for now?).
Check out this book: https://lets-go.alexedwards.net/
A separate repo and git submodules is my way to go. https://git-scm.com/book/en/v2/Git-Tools-Submodules
This makes me very happy. The approach being taken really didn't feel like idiomatic Go, and the standard library is such a resoundingly great example of what idiomatic Go is, so it'd be a shame to see something that was so unclear make it's way in. Great stuff - now let's see if we can improve upon the old proposal, errors do still need work, that just wasn't the right approach IMO.
Really cool stuff here! I love it!
Prometheus + Grafana are awesome; but if you want simple monitoring you can use AWS Cloud watch for logging and metrics. The Go SDK makes it easy to create custom metrics for monitoring
What if idiomatic go is the problem?
Maintainability and python 2 3 fiasco. Kay. Kay kay kay.
Thank you
Totally agree, fmt.Errorf's %w looked to me too bogus.
there is a lot of languages to choose from i guess
There‚Äôs initial support for multiple files now: https://twitter.com/bradfitz/status/1128747022503165952
But things like CA certificates are such a pain in comparison on scratch images.
Python 2-&gt;3 migration being an issue is overblown. 2 is still supported and you really don't have to move your project to 3 if you don't want to. If you're starting a new project you should probably do it in 3 though. Golang is a young language, it's hard to predict the future.
No they're not. You have 2 options. 1) Put the certs in the appropriate folder location in the scratch image. 2) Mount a volume to the appropriate folder location from the host which has the certs Both work and are trivial.
Languages must evolve
id argue that if your requirements change, tool should change as well.
``` type NSFW interface { Public() bool } ```
Tip: You don‚Äôt get rid of the session.
If session can be used concurrently you may store one default instance inside the package. idk it is suitable in your case but http.Get does it for example.
Your handler gets the real data via a specific service UserHandler -&gt; UserService in your handler, you make a new UserService : ``` var userServ services.Service = &amp;services.UserService{Repo: &amp;repositories.UserRepo{}} ``` The service holds business logic, but gets it's data from a specific repository (which is the only part of the program that knows where the data is coming from) UserService -&gt; UserRepo Since it was injected (at the handler), the service tells the repo to do its work normally. In your Service you have a list all records function (example), so now you can do: ``` records, err := userServ.List() ``` But if you test the service itself, you can mock it, by injecting a MockRepo. That MockRepo doesn't have to be something that get's the data from a database, but gets it from a memory model. (Which makes testing super fast) and get rid of the need to test all the way to the database. My benchmark go up to 4.5 ops/ns, so I must be doing something good ;-) I hope this all makes a little bit of sense
Yeah, I thought it was clever at first, but now I regret it.
but does it fall back to normal output for non-interactive contexts?
Fuzzing is awesome. I've found bugs in many projects/programs just by setting a process going and waiting until the next morning to wade through the crash-reports. &amp;#x200B; There's nothing go-specific about this though, although the go-fuzz package makes it easy to add testing. &amp;#x200B; (For example I added fuzz-testing to a BASIC-interpreter I wrote, which gave me a lot of coverage of the parser/run-time.)
If it works for you, great! I just don't want to be in the business of managing secret keys. If the key gets compromised unknowingly though, then the attacker can impersonate _any_ user on your site, which I think is a pretty poor failure scenario.
SEO is hard. I think I need to do a few more talks about it, write about it and get a few more people using it before it gets into frontpage google results. I'd be surprised if the name had much to do with it, but I'm not a google search engineer so ¬Ø\_(„ÉÑ)_/¬Ø. I'd be curious to know how your experience implementing what you did in Gorilla Sessions was though, if you don't mind sharing!
It calls or.Exit (in it's own uilive) dependency that no sane library should ever do... You'll have lots of fun figuring out why your app silently exited if you don't know about it :)
Tell that to python 3
Drives me nuts how Go errors include dynamic content (filenames etc). When you wrap you have this information in scope, you can add it if you want, but the way they are as-is gets in the way for structured logging; error messages have unbounded cardinality. Maybe it‚Äôs a breaking change to fix that now but I‚Äôd love to see it.
Let's name something completely unrelated because we've heard it was bad.
Python experienced literally a decade of pain, but they made it through to the other side. Adoption on Python 3 is quite good now, Python as a language is as popular as ever, and the language is better for it and better poised for future popularity with things like the Unicode improvements. It was a super high risk move, but it looks like history shows it to have been the right one. If we are using Python as an example (note: I'm not saying we necessarily should, but the core maintainers have clearly left that door open by talking about Go 2), the lesson appears to be that a hard break is indeed the right answer to serious enough problems with the current language.
Why?
http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/
I think i am getting it, thank you very much for your help. This makes a lot of sense and will allow the ability to stub out the db. It is greatly appreciated, I am going to try and wrap my head around all this stuff now.
&gt; the core maintainers have clearly left that door open by talking about Go 2 The door has been left open, but there's also been a fairly strong statement that backwards compatibility would only be broken if absolutely necessary. At this point, I'm yet to see a "Go 2" proposal that even really *requires* a "Go 2", let alone something that would require truly breaking backwards compatibility. The only thing that would require that would be something like cleaning up the several ways to create and initialize a new variable, and I'm not seeing any proposals for that, nor do I expect to, since it's not a big enough problem to justify it.
ElasticSearch, APM and Kibana. Maybe Beat, maybe even logstash.
They'll make it back in, just need to rethink the API for making that happen, `: %w` was an abomination. This is the right move.
Even if the vendored dep is way out of date, you can still specify the specific rev you need in the top-level go.mod without a replace directive, and it should all work fine with packages that don't provide their own go.mod. Why did you need to use replace, and why did you need to add go.mod files to your deps?
Am I missing something? I don't see the Wrapper interface
It's a ‚Äúhidden‚Äù interface now. See source code for `Unwrap`. They will probably re-publish it soon.
`%w` is [still there](https://tip.golang.org/pkg/fmt/#Errorf).
That makes me sad :(
Actually I'm not sure how important Google search is for this. I personally use Github and package repositories a lot more to search for libraries. I'd suggest to get it to show up prominently in Github reslults (if it doesn't still) and worry about Google later.
There is value in stability and not breaking old code. Go recognizes this.
Cool stuff! Awesome work, man!
You can make a cookie with JWT as a part of "Login with XXX" flow. Take a look on [https://github.com/go-pkgz/auth](https://github.com/go-pkgz/auth) \- this package provides oauth2 and manages "auth state" with JWT. I've made it for the use cases you've described, i.e. login with "social" service, making a token extending social info and sending it back to the client. No sessions involved in this process at all.
In case people don't know, go has a [testing/quick](https://golang.org/pkg/testing/quick/) package.
mono-repo is the way to go.
Somewhat relevant... you can consider using [https://github.com/nilslice/protolock](https://github.com/nilslice/protolock) \- which tracks your .proto files and reports API incompatible changes made. This should help prevent you from breaking service2 if you change a shared proto for service1. &amp;#x200B; You can try it in the browser too: [https://protolock.dev](https://protolock.dev)
If you've never used C# I reccomend it. That language has do e a great job of evolving (generics, async/await, functional programming) while minting back-compat. It's not all or nothing
[removed]
Um depending on your experience, you may want to learn how to write code first. Then worry about mechanical sympathy and stuff. That's really for critical software that needs to be optimized. Really is the last thing you worry about.
&gt;Adoption on Python 3 is quite good now Arguably this was due more to the success of Jupyter and the sorry state of R (or at least, the fact that it's very idiosyncratic). Without data science, Python would be where it was \~15 years ago most likely.
IMO it could have done better. The way nested functions were introduced when Func&lt;&gt; and Action&lt;&gt; values were already there makes it seem like a very different language.
Seems to be generally unmaintained. Not updated in 3y, and not because it‚Äôs stable. It has lots of issues, and as another comment pointed out, this package depends on uilive (same author) which has an insane os.Exit assumption/problem. And that lib is also unmaintaned Don‚Äôt use this
From experience I‚Äôve learned you can‚Äôt assume people realize that API layers don‚Äôt add value just by existing.
Make a function that takes a string telling it which kind of UserStore to use that returns an http.Handler.
This seems to be a 404 now unfortunately
I didn't know about the ability to use specific revisions to accomplish what I needed. I've updated the post pointing to this comment. Thanks.
readability.
If you want really lightweight and fast...forget REST APIs. You can consume gRPC services with your client side javascript and get rid of a LOT of overhead. [https://medium.com/@aravindhanjay/a-todo-app-using-grpc-web-and-vue-js-4e0c18461a3e](https://medium.com/@aravindhanjay/a-todo-app-using-grpc-web-and-vue-js-4e0c18461a3e)
Man, first 3rd party imports, now multiple files, at this rate I won't need http://gist.github.com much longer.
You could use a combination of Prometheus (metrics) + Alertmanager (alerting, part of prom) + Grafana(UI for both Prometheus and Loki) + Loki(logs). But like others said don't restrict yourself to just stuff written in Go.
gin ...meh
&gt; there's also been a fairly strong statement that backwards compatibility would only be broken if absolutely necessary. I don't know if I made it clear, but this is more or less the whole point of the comparison. :) Python held off making breaking changes as long as they could, until it became apparent that certain decisions from the late 90s/early 00s were going to become upper limits on the productivity and possibly the popularity of the language as a whole.
Jupyter wasn't alone. With python having NLTK, Django, Blender, (etc..) solving actual business uses helped a lot as well.
That was fixed today, it seems: [https://github.com/gosuri/uilive/commit/4512d98b127f3f3a1b7c3cf1104969fdd17b31d9#diff-d791be678c8d8fb73ef58a9a7bf54b45](https://github.com/gosuri/uilive/commit/4512d98b127f3f3a1b7c3cf1104969fdd17b31d9#diff-d791be678c8d8fb73ef58a9a7bf54b45)
go generate is to be used by developers of the particular library, not by users of the developed library. just add the autogenerated file to your repo.
What's wrong with "%w"? I don't think it's any "more" of an abomination than "%v"?
Nice !
&gt;Python experienced literally a decade of pain, but they made it through to the other side. It wasn't always obvious that it was ever "going to make it". People held on to Python 2 as long as they could. At one point, writing Python was a night-mare - had to support 6 different packaging mechanisms, 2 different language syntaxes, and lots of idiotic "glue" libraries like 2to3 and tox had to be used to make code work on both versions. The Python 2 -&gt; 3 transition is *not* a success story.
&gt; I‚Äôm not sure if this is the correct place to ask such a question, so excuse me if it isn‚Äôt. This is the right place for almost any discussion. &gt; I‚Äôm pretty much new to programming, and have my eyes set on on Blockchain development. Please stay in the programming field but keep away (far away) from "Blockchain". Do yourself a favour and read D. GHerad "Attack of the 50 Feet Blockchain." &gt; I just wanted to hear some opinions on whether Golang would be a good first language, as I‚Äôve heard mixed opinions on whether ‚Äònewbies‚Äô should start off with it. It is. You will have to learn a lot anyway and the language itself does not matter that much. &gt; That being said, would I be better off using a language like Java first, or would it not matter? I‚Äôve read many things about Golang, given I‚Äôm not well technically versed but it seems cool, and if I shouldn‚Äôt learn it now, I‚Äôll definitely learn it in the future. It does not matter. Java is a trivial language and so is Go and C and Pascal and FORTRAN. Some people advice on learning Phyton first: It is a nice language, not much typing and fast success with good tutorials for beginners in lots of languages. I would consider only Python to be a language which differentiates enough to consider. And I would not recommend starting with Java or C# as these require heavy tooling. Stuff like C++ and Rust are too complicated, Lisp and Clojure too exotic and Haskel and F# much too exotic, and Prolog too different. And there is a reason I not even mentioned JavaScript.
I went over it, it is "Corba return". Sort of.. Corba is an old technology from the 90s. It is Corba for the Web. So I fully understand how it will be more efficient.
Hey I've used a tool called retool fairly successfully for this: [https://github.com/twitchtv/retool](https://github.com/twitchtv/retool) It's designed for "vendoring" tools used when building a project, e.g. `protoc` or `go-bindata` and allows everyone working on a project to ensure that they are using the same version of these tools. Once you have installed a tool using retool you can execute like `retool do protoc ...` and then it executes it using the specific version defined in the retool configuration. You'll probably have to ensure you have retool installed in your build environment, but that shouldn't be too taxing I'd hope.
Fuzzing seems less useful in Go than lower-level languages because you usually already have memory safety. You'll find bugs and crashes, but probably not exploits.
Hi drvd, Thank you for such an elaborate reply. I have a few questions. Is JS that bad? I was planning on learning it to get into solidity since the syntax is the same, I guess you don‚Äôt approve of this? Secondly, where can I even start to learn GoLang? It‚Äôs not on the more commercial coding websites that teach for free. Also, what is your opinion on Ruby? And thirdly, I actually bought that book the other day and it‚Äôs on my shelf, I‚Äôll give it a read. Thanks
Certain languages like Javascript, PHP, Java, and others have literally decades of misinformation spread around the internet teaching loads of bad practices and ideas. Javascript is huge these days, and there is a lot of good information but be careful. Pay for proper books and courses to avoid the free junk. One thing Go has is a fairly clean slate of modern best practices to go with it's simple syntax and development/deployment process. Unlike scripting languages, Go is is statically typed which means you might find it helps you avoid mistakes while learning. (Typescript would be the Javascript version of static typing)
Thanks for your input Xeon, I‚Äôve been scouting for beginner material regarding Go but it‚Äôs harder to find than other languages. I guess that‚Äôs because it‚Äôs much newer. Do you recommend any courses/books to start with go? I‚Äôm very much willing to invest in my education so any recommendations would be much appreciated. I was even thinking of getting a tutor, but then I was skeptical since I guess everyone just grinds it themselves.
why no windows support :(
Most people learning Go are coming from other languages. You might find learning basic programing easier with Python, Ruby, or Javascript. I think Go is a great first language, but it's not as filled with beginners to programing so there aren't a lot of "learn programing with Go" resources. However, here are some basic resources that are free related to Go: - https://tour.golang.org/welcome/1 - https://awesome-go.com/ - https://github.com/tuvtran/project-based-learning - https://github.com/yeasy/blockchain_guide - https://github.com/miguelmota/ethereum-development-with-go-book https://www.udemy.com/go-the-complete-developers-guide/
In response to your JS question--it's really not *that* bad. But there are lots of newbies who are attracted to JS because JS is all the rage these days (and lots of people are being promised jobs by scummy boot camps that say they can make you job-ready in 3 months by learning react) and so there are lots of newbies in JS who are pumping out not-so-good code. Javascript is also notorious for 'microlibraries' that provide very little functionality (leftpad.js) which means that other libraries often stitch together tens or hundreds of these packages together to create an application. E.g. my SCSS preprocessor using gulp and gulp-sass (two direct dependencies) requires I think something like 400 subdependencies and eventually results in like 90MB of deps. Speaking of leftpad, it also highlighted another immature aspect of the Javascript environment--when people are upset, they can simply just take their package down and break thousands of downstream applications that required that package (and can no longer find it). That was one of the most infamous events in recent Javascript history that put a bad taste in a lot of people's mouths. JS is also very 'flexible' which means you can write a feature in a million different ways. I think that final point is really one of the biggest issues--enterprise applications often change hands a lot and maintaining code is always easier when conventions are followed (PEP, PSR, etc.). Javascript doesn't really have any strong conventions or standards when writing code which means you have a million ways to skin a cat and everyone is doing something slightly different. It's also just a common joke to make fun of JS for all the reasons above.
Do you happen to have a live example of this pattern? Just trying to figure out how to do the UserRepo in UserService interface, and instantiating dbs
That was definitely informative, I had no idea. I‚Äôm guessing Go really is a clean slate compared to a lot of these older languages. In that case, would you recommend Go to someone new to code? It was mentioned in the comments that, Golang devs usually come from other programming languages, what‚Äôs your take on this? Again, thanks for replying.
Thank you, very much for taking time out and making this list. I‚Äôll have a look!
Better late than never :-)
Honestly unlike others, i won't recommend Go as first language, the batteries included philosophy is good as long you just want to get the things done and/or you're already pretty confident with programming. Starting with C for example, will give you a better overview of the interaction with memory, the spartan way of doing things, what's happening under the hood, the stack, the compiler, ecc. This is a big step toward the understanding of the overall picture. You don't really have to learn C, just get a clear idea, from [here](http://cs.yale.edu/homes/aspnes/classes/223/notes.html). &amp;#x200B; Also, never let someone to downplay your interests. You want to be in blockchain development? Well that's fine, it's a thing, as long you're really commited to it, you'll get the fuel to proceed through the learning curve. &amp;#x200B; Golang is very cool and a valid ally for everyday programming, not only for webdev - just come back when you're ready to not get confused by it. Being unable to choose is quite normal when you're starting, every opinion seems to be valid, that's why i'm just suggesting you to not get the things done but to get the ideas clear, for now.
I don't know why you assumed I don't know how to program. Im asking about those articles because that is what I feel I need to learn right now. I didn't mention anything about my experience level. Im taking an introductory course for go because im just starting with the language. I don't have a problem with the concepts. Do you know of any interesting articles?
I would recommend Go, except I have yet to see some beginner programming materials. Most of the things I‚Äôve seen have all been intros for experienced programmers. It‚Äôs a great, and very simple language. It would be easy to learn.
I disagree. The legacy decisions of Python 2, particularly with respect to Unicode, were going to be an ongoing drag on the correctness of Python code, the productivity of people processing text with Python (i.e. almost all web services), and potentially the overall popularity of the language as a whole. The 2 -&gt; 3 transition was painful (very painful--you don't need to explain it to me, I lived it) but necessary. The language is better for it, and has a brighter future because of it. \&gt; It wasn't always obvious that it was ever "going to make it" Completely agree. But that's history now. It did make it. It provides a powerful example of the risks, pain points, and potential benefits of other languages that want to consider similar jumps.
An apology if that came out as overly aggressive.
While Solidity is advertised to be "like" javascript, this is not true. Most bugs written in solidity stem from lack of experience on top of that assumption. I would advise you to understand the EVM execution model before writing production grade Solidity
It's not about the port, it's about the ressource (URL) Rest APIs serve resources on methods (get, post, put, delete, etc) Get example.com/v1/profile/id to get a profile by id Post example.com/v1/profile to create,update a profile Get example.com/v1/profile/id/name to get the name So rest works by combining paths and methods. In jsonrpc, the server listen only on a single path and looks at the request body to find the method and params. The request looks like { "Jsonrpc":"2.0", "method":"aMethodName", "params":[param1, param2,..., paramN], "id":"anID" } All request would hit example.com/v1/api/ for example. Usually POST is used for sending jsonrpc request
I use github.com/cheggaaa/pb instead
The better playground extension could separate them properly.
I really hope the interfaces (both `Wrap` and `Is`) will be published in the final version. If I'm implementing my own error type, I'd love to make sure I didn't break those interfaces silently (e.g. `var _ errors.Wrapper = (*MyError)(nil)`)
In your example, func seek(input int) (index int, found bool) declares found as the \*named\* return value of the function, so in that function, found is not the global variable. In Java, you would probably say that the global variable was shadowed. &amp;#x200B; As for organization, idiomatically you would generally not use global variables, except possibly as flag variables in your main file. &amp;#x200B; There is a binary search in the standard library already, and it has the form: func Search(n int, f func(int) bool) int [https://golang.org/pkg/sort/#Search](https://golang.org/pkg/sort/#Search) &amp;#x200B; What it is searching (be it a slice, an array, some more complex struct) is all implicit in the f func(int) bool that you pass to it. The algorithm itself is only concerned with performing a test, adjusting its internal markers, repeating the test, and doing that until it finds the point where the function switches states and returning that position.
I am not sure it will be faster. The todo example fires 2 HTTP requests for a single Todo insert (OPTION then POST). websockets seems not used at all, even though I saw from the code that it shall be SockJS under the hood. Generally speaking, I am afraid this techno will not get traction because it is too complicated for the youngsters. The only benefit is binary transport. Ok. So what?
&gt;In your example, func seek(input int) (index int, found bool) declares found as the \*named\* return value of the function, so in that function, found is not the global variable. In Java, you would probably say that the global variable was shadowed. Makes sense, thanks! &gt;As for organization, idiomatically you would generally not use global variables, except possibly as flag variables in your main file. So, would you pass list1, min, max as variables into the function? &amp;#x200B; &gt;There is a binary search in the standard library already, and it has the form: func Search(n int, f func(int) bool) int &gt; &gt;https://golang.org/pkg/sort/#Search &gt; &gt;What it is searching (be it a slice, an array, some more complex struct) is all implicit in the f func(int) bool that you pass to it. The algorithm itself is only concerned with performing a test, adjusting its internal markers, repeating the test, and doing that until it finds the point where the function switches states and returning that position. Doh. Was implementing this just to get familiar with go anyway, but good to know. It has function passing, something I haven't used yet. Will take a closer look. Thanks again
Honestly I don't know if Go would be my first recommendation--I've always recommended Python because you can get started even faster with Python (no need to set env variables such as GOROOT or GOPATH). With Python, you simply install the interpreter and start coding. Depending on your OS, you may already have Python (mac or linux). In order for your Go compiler to find the source files, you need to structure your go directory in a certain way which may just add onto the base knowledge needed to get started. With Python, you can add .py files anywhere on your computer and call that file using your python3 interpreter and it will run the code. Very straightforward. Golang is definitely a very easy to pickup low level language but it's still low level. You still have pointers which are one of the most common issues that people have when learning low level languages. They're not really complicated but understanding how to use them correctly will trip a lot of people up. To add on top of that, concurrency is a built-in model with Go and concurrency is not something you probably want to worry about at the moment. So my recommendation is to learn Python first. It will teach you the fundamentals and, most importantly, how to think like a programmer. There are also plenty of very good Python tutorials out there and it's a decently mature language. It's also a powerful language that can do all sorts of things from web development to machine learning. Low level languages definitely feel more natural once you understand how to think like a programmer anyways because you understand why things are the way they are and why people use other tools.
Thanks for the detailed explanation, now I know more. So, in short if I tame my JSONRPC to send POST to a speicified endpoint i.e "/v1/api/receiver" then I can probably retrieve my RPC data like this: ? [`router.POST`](https://router.POST)`("/v1/api/receiver", rpc_handler.Processrequest)` &amp;#x200B; is that correct ?
[https://github.com/quii/learn-go-with-tests](https://github.com/quii/learn-go-with-tests)
C# is a massive behemoth with a lot you need to learn to get into it. If you want a behemoth does everything and adds endless layers of abstractions there‚Äôs a lot of lanagues like that. Every single one with generics is incredibly complex, same with functional programming and their type systems. Go I was coding meaningfully with within a week. Being a small and simple language as valuable. I‚Äôd go grows beyond that it has grown beyond it‚Äôs own usefulness imho.
C# the language is very clean. There is definitely a lot to. Net, but that's diff. I would say there are fewer core packages in C# than in Go at this point
[removed]
[removed]
[removed]
If only the playground would at least support basic syntax highlighting. Something as simple as bold keywords would go a long way.
If you are new to programming, I'd recommend you to do a little course called CS50. It's Harvard Introduction to Computer Science. It teaches concepts that are language agnostic and more importantly it focuses a lot on problem solving, which is really what programming comes down to. You can do it for free. In this course you get to play with different concepts and languages (C, Python, JavaScript, SQL) that will help you choose a path later on. You can do this course and then go on and learn Golang, or any other language that you want. Highly recommended!
That db.Query line is not a valid SQL query. So can't tell what you are doing wrong.
Hm.. I created a gdpr export tool and some testing accounts had texts that were enormous when I remember correctly.
[removed]
Oh, sorry. Let me post the exact code: masterString := "placeholder" rows, err := h.db.Query("SELECT GROUP_CONCAT('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaatest') FROM table1 where table_id = '4'") for rows.Next() { err = rows.Scan(&amp;masterString) fmt.Println(masterString) if err != nil { log.Fatal(err) } This outputs: "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa Note the 'test' bit is missing at the end. Also interesting to note this is *exactly* 1024 characters. Maybe there is a 1 kilobyte (assuming chars are stored as bytes in go?) bottleneck somewhere in the above code?
I tried googling this a lot and I found no results, so the problem is clearly something I'm futzing up on my end.
You are needing list1, min, and max *because* you are looping outside of the function. I would simply move the loop and the min/max declaration inside the function. Whether you pass the list in is up to you - compared to the function passing method, passing the list will either require you to commit to a single concrete implementation (i.e. operating on []string, or []int, or []MyStruct, etc), which may be fine, and certainly is fine for 'I'm just learning' code; or to use either reflection or casting on an interface{} parameter to determine the comparison method to use.
It's a MySQL thing... https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_group_concat_max_len Default of group_concat_max_len is 1024, so need to raise it.
The problem is not in Go, or in the go-sql-driver. The truncation is happening before that, in MySQL: [https://stackoverflow.com/questions/2567000/mysql-and-group-concat-maximum-length](https://stackoverflow.com/questions/2567000/mysql-and-group-concat-maximum-length)
Those repos end up redirecting to [https://go.googlesource.com/net](https://go.googlesource.com/net) (except the last one, which is text); how does curl (or raw telnet if you're so inclined) feel about that server? It works for me, so it's probably something closer to you on the network, but there's a lot of possibilities. (I resolved the address via go get -v and reading the redirect info.)
So should I put 'go get -v go.googlesource.com/net'?
Thank you thank you thank you! Seriously thank you. I'll need to get access to our SQL database itself it looks like to raise the limit, but I now have a solution I can bring to my boss instead of 'lol I dunno it's busted yo'
That's exactly what I needed to know. You guys rule. I hope you have an amazing day tomorrow.
I think Go is a fairly good beginners language right now, *but* stay away from concurrency for at least the first three or four months. Experienced programmers enjoy the way good Go programming can turn an insanely impossibly difficult hard problem with the way it used to be done into a tractably-complex problem for intermediate programmers, which is great and all, but still not something a beginning programmer should dive straight into. By that I mean, don't do any yourself; don't "go" things and don't create your own channels. For the most part, if you consume libraries that use concurrency under the hood, you'll be fine. (Not 100%; if you get into net/http to build servers, just make sure you don't touch any global variables, that everything you manipulate in a handler was created in that handler. Don't touch any members of the object that implements the ServeHTTP method, either, as appropriate.)
If I'm not mistaken, previously %w only caused wrapping if the tail of the format string was exactly ": %w" which is kinda gross. Now %w can appear anywhere in the format string once. Some think it's still gross because a format string verb now causes a side effect unrelated to formatting.
I'm not saying you should change the import, I'm saying that you may be able to connect to [golang.org](https://golang.org) but not [go.googlesource.com](https://go.googlesource.com) for some reason. Unfortunately, I don't know what that reason is, and probably won't be able to guess from here, because there's just too many possibilities.
It's a playground not DisneyWorld!
No it's today. Everyone is tired. I just meant his stuff is good but if you don't use it, then you won't remember it.
gqlgens plugin system is still under development, we need to work out where the interfaces should be. We have a few ideas that will be forcing functions in what needs to be exposed, Feedback is always welcome. &amp;#x200B; It would be good to see what the output of \`graphqlc\` looks like. I've always found committed examples great for groking codegen projects.
It's to test your skills /s
I appreciate your enthusiasm for sarcasm, but to become a master you mustn't use /s. *I'm a human being, and this action was performed manually.*
Remote ok? Expected compensation?
tl;dr Look at: https://github.com/dvyukov/go-fuzz
Have you seen pprof? https://golang.org/pkg/runtime/pprof/ It also has a web interface.
&gt; Fuzzing seems less useful in Go than lower-level languages because you usually already have memory safety. You'll find bugs and crashes, but probably not exploits. Oh really? Then why are there so many panics in the Go standard library? [1] [1] https://github.com/dvyukov/go-fuzz#trophies
Those come under "crashes", right?
Great post TIL cobra
I haven‚Äôt looked at all of them, but I know crashes can turn into security holes that can be exploited. Just last week I was in a Meetup in Vancouver where /u/dgryski talked about fuzz testing, [go-fuzz](https://github.com/dvyukov/go-fuzz), and how naive some engineers can be when looking at things that look innocuous. One of my coworkers makes this mistake a lot, and it frustrates me so much, they often leave comments in the code saying _‚Äú[‚Ä¶] this error is ignored because it will never happen‚Äù_, or _‚Äú[‚Ä¶] lets panic here because there‚Äôs no better way to handle this error‚Äù_. I wanted to take them to this Meetup with me so they could learn from other people in the community how dangerous ignoring errors is, but they made excuses and didn‚Äôt go.
I haven‚Äôt looked at all of them, but I know crashes can turn into security holes that can be exploited. Just last week I was in a Meetup in Vancouver where /u/dgryski talked about fuzz testing, [go-fuzz](https://github.com/dvyukov/go-fuzz), and how naive some engineers can be when looking at things that look innocuous [1]. One of my coworkers makes this mistake a lot, and it frustrates me so much, they often leave comments in the code saying _‚Äú[‚Ä¶] this error is ignored because it will never happen‚Äù_, or _‚Äú[‚Ä¶] lets panic here because there‚Äôs no better way to handle this error‚Äù_. I wanted to take them to this Meetup with me so they could learn from other people in the community how dangerous ignoring errors is, but they made excuses and didn‚Äôt go. [1] https://www.meetup.com/golangvan/events/261046110/
Do you start building a house without at least a draft of the plans ? No ! Stop coding right now. Put aside go and any language. You need to understand what is a client, and what is a server. You cannot right any code if you have no idea what you're doing, and even least with a "lower" level language like go. And make it simple, do a sample project with rest only. Then a sample with jsonrpc only. Then only try to have both.
I never really think about it anymore since the better playground extension has syntax highlighting
Check this out: https://goplay.space/
I haven't heard of it. It seems pretty expensive with all the options available for free, but if cost isn't a big deal to you, they might be a cool duo to learn from. They certainly look like they put a lot of effort into their site and have dedicated their careers to training people in Go. Learning more than one web framework never hurt anyone (unless you were a Flash developer--sorry y'all!) so I wouldn't worry about Buffalo vs gin vs chi. I use standard library or gorilla mux depending on the project, but Go code is very good at being easy to understand, so you aren't going to throw away hard work learning one and then using another. It looks like you've done enough Go to develop opinions on web frameworks, which to me says that you will learn more from working on a project than a training site. Once I went through tour.golang.org I was able to start coding with https://gobyexample.com/ for looking up examples. After a little more time I was comfortable enough with the syntax that the godoc for any library was pretty much all I needed to use it. Remote can be a little tricky when you aren't senior in a language, but Go might be a place where that's less true since companies need to look harder for Go devs. Good luck!
The error you posted is not the output of the panic in your source, so I can't help. Also I'd print the exact params of Rel with the error, too. Without this, you test something else.
Syntax highlighting is juveline
Thanks. I'm not great in any of the frameworks above. But yes I will try the practical approach before buying the subscription since Money matters to me.
&gt; this error is ignored because it will never happen That sounds bad! You could just panic, and then that'll only be a problem if your assertion was wrong. &gt; lets panic here because there‚Äôs no better way to handle this error That sounds good, in theory. Panicking is not ignoring an error. It's the opposite. It is deciding that an error is so serious that you'd rather just have the program terminate than continue and potentially do something bad (like behave exploitably). It's the best way to deal with an error if you're not going to put in the time to reason about what happens to the program after the error occurs.
I disagree on the Blockchain part. Being myself an ethereum dev for more than a year. But this is true that the technology is still year young and needs to mature. We're working on it. Other than that, great post !
IIRC the go creators believe that a good language shouldn't need syntax highlighting, so in places like the playground they opt not to have it. I could be remembering wrong, though.
I don't think many will agree (esp. with the tone) but wow do I love no syntax highlighting. I swear I get less headaches.
Node will be path of least resistance for you already do front end. So you know just already and have to learn backend concepts and learn a backend framework (Express/koa). Go is better is some of the ways like concurrent, performance and you don't have to use packages for every small thing, go std library is great.
You will have to learn JavaScript, everybody does, but that is not so complicated once your are experienced so no need to start with a language with a toxic ecosystem. To learn Go (which ist the proper name of the language; golang.org is the website): Take the Tour of Go (and of course re-read your copy of Cormen &amp; Leiserson).
Thank you
I did not know the .proto files, very good post
 Thanks a lot, I‚Äôll definitely do this
Protoc is not a Go module program (it's written in C++), so Go modules won't help you. The [standard Go plugin for protoc is written in Go](https://github.com/golang/protobuf/blob/master/protoc-gen-go/main.go), but without protoc it is worthless.
While that's not module's main purpose, there are some usage patterns that work for Go based binaries ([see this RSC blessed pattern](https://github.com/golang/go/issues/25922#issuecomment-402918061)). In this specific case it won't work because protoc is not a Go based binary.
This Chrome extension does it well https://chrome.google.com/webstore/detail/better-go-playground/odfhkelcmblecfdnboahphiafolojmpl
The int value is the number of bytes read.
yeah but when I access it, nothing gets printed. Is there something extra I should do to extract the value?
I believe it follows the standard `io.Reader` interface: pass a non-empty slice `b` to `Read`, it returns an error or `p` where `0 &lt;= p &lt;= len(b)`
Yeah. I'm doing exactly what you described. I'm giving a \[\]byte of size 10 to Read. But still I'm not able to access the int.
 you can print the value of the integer that it returns like: ``` err, nbytes := conn.Read(buf) log.Printf("read %d bytes", nbytes) ``` the thing is, you need to make sure the buffer you're reading into has bytes allocated: ``` buf := make([]byte, 32768) err, nbytes := conn.Read(buf) log.Printf("read %d bytes", nbytes) log.Printf("read the following data: %s", string(buf)) ``` if you don't allocate a backing store for your buffer, you will not read anything. can you post some sample code?
You have to pass in a byte slice for Read to populate with data, (Ie you have to pass in a pre-initialized buffer). The returned int will be the number of bytes read into the buffer. I knocked up a simple example for you -&gt; https://play.golang.org/p/r6DW8XEPicx note you will not be able to run it in the playground as tcp connections are blocked ... hopefully you will get the gist though
Thank you, you guys have been great with providing help and useful information. It‚Äôs much appreciated
My eyesight pixel resolution is fading as I head toward becoming a senior; my eyesight color perception is seemingly good as ever. I‚Äôll take that extra sensory input thank you very much.
Would this be covered in the ‚ÄòMastering Ethereum‚Äô book?
Thank you very much, I really appreciate it
yeah, this is what I wanted. Thanks a lot. But when I implement it in a client and a server fashion, I give the same 32768 bytes buffer as suggested above. Then I'm just able to send 3 or 4 messages and the client automatically disconnects and I get an error. &amp;#x200B; [This is my gist](https://gist.github.com/6e94078e224465db23db16790dda3d1e)
`r.collection.CountDocuments(c, nil, nil)` should be fine; it's the explicitly recommended alternative to `db.collection.count` Under the hood `r.collection.CountDocuments()` runs via the aggregation pipeline (without a filter given it will just scan the primary index). `db.collection.count()` is what uses the metadata, but you're not actually calling `db.collection.count()` here. See https://docs.mongodb.com/manual/reference/method/db.collection.countDocuments/
[Collection.CountDocuments](https://godoc.org/go.mongodb.org/mongo-driver/mongo#Collection.CountDocuments) is the correct method, you just need to define a filter first. In your post, you are passing `nil` which means your query is empty, which is what the warning in the [official documentation](https://docs.mongodb.com/manual/reference/method/db.collection.count/) is telling you to avoid. If you add a filter instead of _nil_ _(the second parameter in your method call)_ then you‚Äôll be good to go.
You wrap the connection (io.Reader) in a scanner. Scan() already calls Read() internally. In other words: both handleConnection() and connCheckForShutdown() are essentially trying to "drain" the reader at the same time. The scanner's Err() method returns the last error it encountered: https://github.com/golang/go/blob/master/src/bufio/scan.go#L216. You should simply remove connCheckForShutdown(). After Scan() returns false and you break out of the loop, you can check for EOF and other errors: if err := scanner.Err(); err == io.EOF { // EOF. } else if err != nil { // Error. }
[golang/go](https://github.com/golang/go) repository has been mentioned **7 times** on Reddit over the last 7 days. The last 3 mentions: |Mention|Source| |---|---| | I&amp;#39;m not sure if &amp;quot;not open to feedback&amp;quot; is accurate It took 5 years to get Math.round into the standard library [ https://github.com/golang/go/issues/4594 ] because &amp;quot;it&amp;#39;s a one-liner&amp;quot; (if you want to do it wrong). The issue was essentially WONTFIX from 2012 to 2017|[/r/programming](https://reddit.com/r/programming/comments/bmr97z/the_pros_and_cons_of_programming_in_go/en0fcu2/ "/u/orbat at 2019-05-10 12:25") | | https://github.com/golang/go/wiki/SliceTricks|[/r/programming](https://reddit.com/r/programming/comments/bmr97z/the_pros_and_cons_of_programming_in_go/en0gdwh/ "/u/unpleasant_truthz at 2019-05-10 12:36") | |Related issue in golang/go by Rob Pike https://github.com/golang/go/issues/26074|[/r/golang](https://reddit.com/r/golang/comments/bmybl9/does_anyone_else_have_a_problem_with_go_binaries/en1jgng/ "/u/TrueFurby at 2019-05-10 18:28") | ^([Report an issue](https://np.reddit.com/message/compose/?to=gajus0&amp;subject=GitSpo%20Reddit%20mentions%20bot&amp;message=Hello%20Gajus,)|View all [mentions of golang/go](https://gitspo.com/mentions/golang/go))
so what should be an appropriate filter in order to count all the docs?
Comp range?
You've got two different read mechanisms going on, direct and stream and in different go routines. They are going to conflict with each other. I would look for a sockets tutorial as they tend to be basically the same for whatever language. Or find a go lib that wraps up some of the socket complexity. Or study another open source app that uses sockets to see what they do.
Hey, I have been writing a TCP proxy in Rust for a while now and had to rediscover all these things as well. What you really want is to Peak the connection. This will read 1 byte without popping it out of the stream. https://stackoverflow.com/questions/26196813/peek-into-conn-without-reading-in-go
[gophersizes](https://gophercises.com) was a good start for me Go is a pretty low level language, you can do a lot with it, but its rather easy to pick up most concepts. For someone with zero coding experience I would still recommend looking into Java or C#
Honestly it‚Äôs probably easier to jump into a scripting language like python where you get that quick feedback with a repl. Once he understands the basics like variables, functions, and the core types like string, int, float, list and dict in python and is comfortable with the command line and a text editor you could move into Go but by the very nature of being a statically typed compiled language it‚Äôs more complex than python.
&gt; *lets panic here because there‚Äôs no better way to handle this error* As was already noted, this can be the best way to deal with some errors. Of course it depends on the exact case, but I really don't think this is as egregious as just completely ignoring errors
I would recommend checking greatercommons.com . Tod is a great teacher with many years of experience at the college level. Check reviews of his intro to comp science course where he uses Go. Go is a great choice as a first language. Good luck!
The first lesson in almost every tutorial/teaching series for most languages is a "hello world" program. It's pretty much traditional at this point, but it also makes sense because almost any basic program is going to need a way to output the result so the programmer can see if their program is working as intended or not, so it's the first thing you learn to do. Not sure what you're thinking the first lesson should look like instead?
Ya, but I just don't know how to explain why print statement. Should teach from basic CS, how computer work, I/O, then only code?
But I can't find this CS courses
&gt; greatercommons.com https://greatercommons.com/learn/go-language https://greatercommons.com/learn/golang
In short: yes.
Ehrum. I mean,you want to start with data structures or something? What basic programs would you have them implement when learning - and you *absolutely must* have people writing programs from day 1, sitting people down to lectures on theory without actually writing code strikes me as a terrible approach? Without either print statements, GUIs, or I suppose file I/O (which is almost exactly like print statements except more indirect), how will they have any idea what their program actually did, if it worked beyond "well, it didn't *crash*"
yes
I like https://exercism.io/
What do you mean by access the int? Code would be great to see here :). Are you expecting the first result of Read() to be parsed from the data through the tcp pipe? It's the number of bytes read, so if someone sends your tcp connection a 64bitnnumber "3", the first value from Read() will be 8 (8 bytes in a 64bit number, not 3
I'm one of the founders of Gopher Guides. Most of the buffalo videos on the site are free as well, so if that is what you are interested in you won't need to pay for them. In addition to our premium channel we offer 1:1 office hours as well if you need any specialized training. I'd be happy to answer any other questions or hop on a video to chat if you want as well. Ping me at [cory@gopherguides.com](mailto:cory@gopherguides.com). We love feedback as well (good or bad), so don't hesitate to reach out with questions or comments.
Hey vektah! Thank you for your work on gqlgen and gqlparser! From my perspective, plugins residing the core repository, and more importantly, in the same binary is has the potential to be problematic. If those managing the core repository do not accept a new plugin, for whatever reason, a developer now has to manaintain their own fork indefinitely or forgo that plugin. Now suppose that the same developer wants to non-core plugins; this becomes more difficult (but not untenable) to maintain an up-to-date fork. With Go this model forces other developers to work in Go limiting the potential field of contributors to the eco system. Other issues include the increased ability for tight coupling and idiosyncrasies, e.g. * A [plugin](https://github.com/99designs/gqlgen/blob/master/plugin/plugin.go#L10-L12) can fullfil the [MutateConfig interface](https://github.com/99designs/gqlgen/blob/master/plugin/plugin.go#L14-L16) and/or the [GenerateCode interface](https://github.com/99designs/gqlgen/blob/master/plugin/plugin.go#L18-L20), but only by [looking](https://github.com/99designs/gqlgen/blob/master/plugin/modelgen/models.go#L65) [at](https://github.com/99designs/gqlgen/blob/master/plugin/resolvergen/resolver.go#L24) [the](https://github.com/99designs/gqlgen/blob/master/plugin/servergen/server.go#L26) [implementation](https://github.com/99designs/gqlgen/blob/master/plugin/stubgen/stubs.go#L31-L58) can I determine which interface(s) a plugin supports. * Because calls to MutateConfig have the potential to change the configuration, [call order](https://github.com/99designs/gqlgen/blob/master/api/generate.go#L28-L35) is important and the call order is [not](https://github.com/99designs/gqlgen/blob/master/api/generate.go#L15) [necessarily](https://github.com/99designs/gqlgen/blob/master/api/generate.go#L19-L22) [obvious](https://github.com/99designs/gqlgen/blob/master/api/generate.go#L24-L26). * Furthermore, some plugins [generate](https://github.com/99designs/gqlgen/blob/master/plugin/modelgen/models.go#L221-L226) code from calls to MutateConfig and some from [calls](https://github.com/99designs/gqlgen/blob/master/plugin/resolvergen/resolver.go#L37-L41) [to](https://github.com/99designs/gqlgen/blob/master/plugin/servergen/server.go#L33-L37) [GenerateCode](https://github.com/99designs/gqlgen/blob/master/plugin/stubgen/stubs.go#L43-L51). In the [spirit of protoc](https://developers.google.com/protocol-buffers/docs/reference/other), graphqlc [emits](https://github.com/samlitowitz/graphqlc/blob/master/pkg/graphqlc/generator/generator.go#L188) a [CodeGeneratorRequest](https://github.com/samlitowitz/graphqlc/blob/master/pkg/graphqlc/compiler/plugin.proto#L20-L32) via [stdin](https://github.com/samlitowitz/graphqlc/blob/master/pkg/graphqlc/generator/generator.go#L195) to the generator and receives a [CodeGeneratorResponse](https://github.com/samlitowitz/graphqlc/blob/master/pkg/graphqlc/compiler/plugin.proto#L35-L97) via [stdout](https://github.com/samlitowitz/graphqlc/blob/master/pkg/graphqlc/generator/generator.go#L203). This means that the ouput depends entirely upon the compiler/code generator being used. The [graphqlc-gen-echo](https://github.com/samlitowitz/graphqlc/tree/master/cmd/graphqlc-gen-echo) [generator](https://github.com/samlitowitz/graphqlc/tree/master/pkg/echo/generator) can be used as a very simple example. Please see the "[u]sage" section in the [README](https://github.com/samlitowitz/graphqlc/blob/master/README.md) for an example of how to use the graphqlc-gen-echo plugin. Plugins can exist outside of the core repository as long as they are using the same descriptor.proto and plugin.proto definitions. Because [descriptor.proto](https://github.com/samlitowitz/graphqlc/blob/master/pkg/graphqlc/descriptor.proto) and [plugin.proto](https://github.com/samlitowitz/graphqlc/blob/master/pkg/graphqlc/compiler/plugin.proto) can be compiled via protoc, graphqlc generators can be written in any [language](https://developers.google.com/protocol-buffers/docs/reference/overview) which has a protoc generator.
Ex https://play.golang.org/p/97afLuWFb0k
Your main thread waits for the go routines to get done. You go routines wait for the channel to be read from. The reason it works when you buffer the channel is because it does not block the go routines since it is not full. A regular channel blocks until the data is received. Put your loop before the wait on the wait group. You will have to have another go routine that will wait on the wait group and close the channel when the wait group is done. &amp;#x200B; import ( "fmt" "sync" ) func main() { urls := []string{ "https://qrng.anu.edu.au/API/jsonI.php?length=1&amp;type=uint8", "https://qrng.anu.edu.au/API/jsonI.php?length=1&amp;type=uint16", } var wg sync.WaitGroup c := make(chan []byte) wg.Add(len(urls)) go closeChannel(&amp;c, &amp;wg) for _, url := range urls { go getPage(url, c, &amp;wg) } for v := range c { fmt.Println(string(v)) } } func closeChannel(channel *chan []byte, waitGroup *sync.WaitGroup) { waitGroup.Wait() close(*channel) } func getPage(url string, confirm chan []byte, waitGroup *sync.WaitGroup) { confirm &lt;- []byte(url) waitGroup.Done() }
I'll get ripped on for this, but I'm self taught so my approach is different. c++ is what you should learn as a first language. it'll give you the knowledge on how to do almost anything, plus most frameworks are c++ anyways. learn c++ and enjoy being an expert. or continue with Roland, js etc and never be a true expert.
in my opinion the best language for beginners in computer science is [Racket lang](https://racket-lang.org/) ;-)
Mornin'. So here is a minor modification that makes it work: [https://play.golang.org/p/f3VdaBnHc\_C](https://play.golang.org/p/f3VdaBnHc_C) Here was the issues: Your channel can only take one item (if it is not buffered). So something has to read it before something else can go on it. You have to have the \`range\` running at the same time. However, you could not get to your range because you had a \`wg.Wait\` that needed to have \`wg.Done()\` get called for each \`wg.Add\`. So your \`wg.Wait\` was waiting for your \`Done\`'s, but you had none. Then you were closing your channel. If it is closed, you can't range over it. But you were not getting that far anyway. So a couple of things were causing you to get a deadlock (nothing can progress in the program). So, the additions in the link. We put a \`defer wg.Done()\` in the goroutine \`getPage\`. So when this thing finishes, it will call \`Done\`. We put the middle anonymous goroutine in the middle that will sit and wait for \`Wait\`, and afterwords, close your channel. Since it is in a goroutine, it is not blocking the rest of the program for getting down to the \`range\`. You can \`close\` the chan after the \`Wait\` because you are done with it and you know you are done with it because the only way \`Wait\` could be called is because we drained all the responses on your \`confirm chan\`. Hope that helps.
Awesome! Send me a resume and let's catch up.. matthew.clark@oscar-tech.com
You might try the book "Get Programming with Go" by Nathan Youngman (can be found on Amazon.com). People teach C (and even C++) to beginners, and those aren't exactly easy languages. Also, although you may think all "absolute beginners" are the same, they aren't. To give an analogy, you might be teaching someone how to juggle that has never juggled. One person will pick up the skill in a day or two, and the other takes a month or more. They were "absolute beginners", but they aren't the same. To make the point clear, a 3 year old is an absolute beginner, and a Ph.D. in theoretical physics could be an absolute beginner, but you'd expect the Ph.D. to grasp the concepts of programming more readily than a 3 year old. Since your brother has a math background, and you're there to help, I think it can be manageable although there's more intro material on other languages. Still, you have motivation to teach, and Golang isn't, say, Erlang or Rust, and as long as you stick to the basics (rather than the features Go is known for), I think it should be fine for teaching.
sent you an email from my email JavascriptEvangelist @ gmail.
Causing an unwanted crash often _is_ the exploit. It is a category of DOS attack.
Personally I just don't feel like python is a good starting point, though I know many people disagree. The two best things about it as a teaching language are the standard repl, which is a great tool for playing around while first learning the basics of variables and syntax, and the indent-as-blocks behavior, which forces the habit of sensible indentation that so many new programmers tend to ignore until they've written enough code to truly appreciate the importance of readability in code. Otherwise, python's whole be-different-unless-there's-a-damned-good-reason philosophy just doesn't seem like a good introduction to programming unless your whole programming career is going to *stay* python. I'd say the same thing about a lot of other languages that are as different from python as they are from everything else; haskell and lisp, as two examples. In Python's case, a handful of ubiquitous language features are so widely used and abused that someone learning python first will spend the rest of their live asking "why doesn't language X have this?!" Some of the most horrifying code I've ever seen was written by people using language A while wishing it was - and trying to make it - language B. C++ code riddled with gratuitous `pair&lt;&gt;` because they want tuples, for example.
a denial of service is still an exploit.
I never knew coverage-guided fuzzing was a thing. That's really cool!
Very cool project
Unfortunately not, since we make closed source applications.
That's fine, ended up finding a good example of it. Thanks for your help!
I've found Golang to be tough. The documentation makes lots of assumptions about the readers ability. e.g.If you are are working with Oauth2 it's assumed you know how to extract Claims from a JWT token with no sample code provided.
What you're describing is just the mental hurdle of learning your second language. The problem of "My old language that I already know has x, why doesn't this new one?" will happen no matter what.
The game is really fantastic! Well done. I've been wanting to do something like this myself, but haven't. Looking forward to reading the code.
Pretty cool! I wasn't able to install from tuxfamily.org, but it worked fine from github. You may want to check that and/or update the instructions. &gt; go get -u git.tuxfamily.org/harmonist/harmonist.git package git.tuxfamily.org/harmonist/harmonist.git: cannot download, git://git.tuxfamily.org/harmonist/harmonist uses insecure protocol
To be honest, what helped it click for me was a test to create 4 functions and have them change a var. Having to carry data and change it between functions gives you the idea away from objects or that things are too complicated to touch.
The git tuxfamily server seems down today, yeah. I've added to the readme the fact that the game can be get in two repos, thanks!
Good market rate. Depends on experience.
Depends - we‚Äôre ideally looking for someone around London or Dublin as we have client meetings to consider.
I second the recommendation on Python, but not for the reasons you listed. Python has a lot more beginner-friendly resources. The community is also larger. There's a large, active subreddit dedicated to just beginners learning Python (/r/learnpython).
https://www.dailycodingproblem.com
https://exercism.io
[removed]
Next time you have a hanging bug in a simple program, you send it a SIGABRT \[1\]. That makes it dump out the backtraces of the goroutines, and would have shown you where each one was hanging. &amp;#x200B; \[1\] kill -ABRT $(pidof PROGRAMNAME), or pkill ...
Different than what? Haskell and Lisp are not different for the sake of being different.
I was only referring to python with the "for the sake of being different," and I know that's not the literal design process that goes on, but from what I remember, there was a fair bit of "everyone does it this way isn't a good enough reason for us to do it this way" reasoning in the python language design discussions I remember reading years ago. Haskell and Lisp are just other examples of languages that are very different from the bulk of other widely-used languages.
Sure, I meant that the differences between Haskell and Lisp and the other languages you mentioned are not just syntactic.
Advent of Code
&gt; We studied six popular Go software [projects] including Docker, Kubernetes, and gRPC... ...The authors searched the GitHub commit histories of the applications to find commits fixing concurrency bugs (3,211). From these 171 were randomly selected for study. This is good information and a great project, please read this paper / blog post.
My opinion is that unless you're looking to go into the c/c++ world (embedded, games..) Go is a good language to get into. It tends to get dumped on in /r/programming, but the facts are it has a lot of third-party libs, fast/small (compared to Java) and the language is terse. I find I can get much more done in go than Java in the same line of code count. I personally do not find OO design and coding compelling. OO code is easy to do poorly, and tends to code bloat. Inheritance should be used sparingly and often is not. I would also suggest Rust, however it is still evolving as a language but would be in the same vein.
love it. how did you make the tiles, are these just utf8 symbols?
Absolutely, do you think that Real Time programming would be easier to get into with rust? From what I understand it is will be the optimal language to use since it will essentially have the "native connector" to web assembly. I saw C# had Blazor, which is why I considered it but is good to hear that there is a super strong language to learn like that. Rust would obviously open the door to hardcore systems programming; however, I feel like Go would just open the door period. I mention one project on my resume where I used it and recruiters call me left and right looking for Java translation to Golang. It's nice because you could just say "meh, we're just gonna rewrite these 5000 lines into 200 lines of Go. I don't even need to look at it". I do need to keep my eye on Rust though, but you think it is just a matter of opinion which language I should jump on first?
From a strictly resume oriented view, go will garner more interest than rust. Go also has a wider application to microservices using grpc for example. Go has a web assembly compiler as well. At some point if you stick with it long enough, it becomes less about languages and more: what's the right tool for the job, and what concepts can I apply to make this software successful.
thanks a lot guys!
I don't disagree, but I think that Rust experience might lend more "mobility" than Go experience, in that it is much easier to pick up Go given a decent understanding of Rust than vice-versa. Go, for all intents and purposes, implements a limited subset of Rust's features, and is more flexible and forgiving about how those features are used. Whether or not this is actually an argument for learning Rust over Go depends on what you value I think.
Part of your impression, I think, is that C# and other languages you are thinking a lot about are younger than Python. Python got a lot of its personality from Lisp. It isn't doing things for the sake of being different but rather moving slower so that it doesn't do things just to be like other languages. If you look at how features have been added, things like template strings, enums, etc were eventually added, but by going slower, it is now a very old language that hasn't layered bad APIs its forced to support that make it obsolete as a great choice now.
Every provider I looked at had an example for oauth2. Take Google: https://github.com/golang/oauth2/blob/master/google/example_test.go I do agree that Oauth, OIDC, and friends have a lot of depth to learn. Ity isn't easy, but I don't think the problem it's solving is inherently easy either. For what it is, I think Go was much easier than when I did the same in C#. I had my site running on Google's Oauth before implementing my own user management system, using just the docs there. For claims specifically I don't recall if I looked at the docs or directly at the returned JSON, but if you read the JWT specs, you already know what to look for, and if you don't, you haven't read the manual yet. Like I said, the spec isn't simple, so that might seem like a lot to ask, but once I read the spec and looked at an example, it seemed pretty straight forward, and I'm not sure it can be much more simple simply because there are so many concerns involved.
There is so much to learn in programming that the challenge isn't learning everything--that's impossible. The actual challenge is being able to study things without ever knowing everything and be okay with that. After you know this code somehow does something you'll at some point learn about packages. Then you'll understand that the fmt is telling you that the next bit is from another chunk of code. It's a lot of symbols right now, and tour.golang.org goes through it fairly well, but it might feel fast if you haven't seen other things. Let yourself advance through the tour, and then start at the beginning again, running all the examples. The symbols and words will start to mean something in how they relate to each other, and you'll get better at learning every year of your coding journey. I'm a 2007 marketing degree graduate, and I'm still getting better at learning, though I learn much much faster than I used to. The language you pick doesn't matter much. Each time you learn a language, it helps with every other language you learn, so you are never wasting time. At some point a project or job opportunity will lead you to spend more time on one language than another. That might last or not last. The most important thing is to start trying somewhere. :)
I could be wrong but I think these same courses are available on udemy for less than half the price (and likely a dollar cheaper than that if you purchase from an incognito window üòã)
How exactly does this work? I'm not seeing any output: &amp;#x200B; echo '\[{"id":1},{"id":2}\]' | jsl --filter='id==1'
I'm not too sure on this myself either, but I think this is not just related to go, but to any application that can be installed. Typically you would have the application operate within the working directory. Sometimes people give a flag with a path to a config file, or a log directory. Sometimes a logging directory is defined in a config file. This is how nginx does it I believe. Additionally you could create a systemd service or make a docker image as is popular with go applications. That said, when you compile/install your go application, it's not the full application. It's only the executable.
You may already be aware of it and just wanted to write your own version, but [jq](https://stedolan.github.io/jq/) has been around for a while and does what you‚Äôve described, FWIW.
I assume a single json object per line, (since that seems to be the norm in go). &amp;#x200B; I do think i need to support some sort of unpacking though. I'll put it on my list.
jq seems very powerful, and likely better in a number of ways. The dsl was a little complicated, and I wanted something that used vanilla js. It looks like both gron and jq are better tools, mostly a learning experience for me. Thanks for taking a look!
Typically you will build your application in one place, then deploy it to the production system separately (at larger scale, people frequently use CI/CD pipelines, and/or deploy via containers, but for pet projects, manually deploying is okay). If you need to access config files and/or log directories, you should make these paths configurable via command line arguments and/or environment variables (the latter is particularly useful for container deployments).
This simplest way to do this is take your incoming client connection, client, and then the connection to your destination, upstream, and relay the read/writes. func relay(client, upstream net.Conn) { go io.Copy(client, upstream) go io.Copy(upstream, client) } I would wrap io.Copy() personally to make sure I don‚Äôt leak anything. If there are any failures reading or writing from the two connections they will both terminate.
Looks like I spoke too soon, turns out you found a bug with very simple values. Just pushed a fix, once you've updated the following should do what you're expecting. &amp;#x200B; \`\`\`echo -e '{"id":1}\\n{"id":2}' | jsl --iter="[i.id](https://i.id)" --filter="i.id==1"\`\`\`
Looks like I spoke too soon, turns out you found a bug with very simple values. Just pushed a fix, once you've updated the following should do what you're expecting. &amp;#x200B; \`\`\`echo -e '{"id":1}\\n{"id":2}' | jsl --iter="[i.id](https://i.id)" --filter="i.id==1"\`\`\`
Looks like I spoke too soon, turns out you found a bug with very simple values. Just pushed a fix, once you've updated the following should do what you're expecting. &amp;#x200B; \`\`\`echo -e '{"id":1}\\n{"id":2}' | jsl --iter="[i.id](https://i.id)" --filter="i.id==1"\`\`\`
Looks like I spoke too soon, turns out you found a bug with very simple values. Just pushed a fix, once you've updated the following should do what you're expecting. &amp;#x200B; `echo -e '{"id":1}\n{"id":2}' | jsl --iter="`[`i.id`](https://i.id)`" --filter="i.id==1"`
Looks like I spoke too soon, turns out you found a bug with very simple values. Just pushed a fix, once you've updated the following should do what you're expecting. `echo -e '{"id":1}\n{"id":2}' | jsl --iter="`[`i.id`](https://i.id)`" --filter="i.id==1"`
Looks like I spoke too soon, turns out you found a bug with very simple values. Just pushed a fix, once you've updated the following should do what you're expecting. echo -e '{"id":1}\n{"id":2}' | jsl --iter="i.id" --filter="i.id==1"
I hear ya ‚Äî I hope my comment didn‚Äôt come off as condescending or dismissive because a.) I genuinely think your work is cool and worthwhile in its own right and b.) I am always rewriting something that already exists, and doing a worse job of it... in fact, the only project I‚Äôve ever created that has got _any_ traction (few hundred stars on github) I recently found out was basically formed and then rewritten by AWS folks who, honestly, did a _way_ better job of writing it. Way more elegant and much better in every way. So I‚Äôd be a huge hypocrite if I made a commentary on anyone else‚Äôs attempt to build anything.
I hear ya ‚Äî I hope my comment didn‚Äôt come off as condescending or dismissive because a.) I genuinely think your work is cool and worthwhile in its own right and b.) I am always rewriting something that already exists, and doing a worse job of it... in fact, the only project I‚Äôve ever created that has got _any_ traction (few hundred stars on github) I recently found out was basically formed and then rewritten by AWS folks who, honestly, did a _way_ better job of writing it. Way more elegant and much better in every way. So I‚Äôd be a huge hypocrite if I made a commentary on anyone else‚Äôs attempt to build anything.
It appears I spoke to soon, you actually found a bug where very simple values are not being output correctly. I've fixed it, and updated, once you've installed the latest the following should work: &amp;#x200B; echo -e '{"id":1}\\n{"id":2}' | jsl --iter="[i.id](https://i.id)" --filter="i.id==1"
I hear ya ‚Äî I hope my comment didn‚Äôt come off as condescending or dismissive because a.) I genuinely think your work is cool and worthwhile in its own right and b.) I am always rewriting something that already exists, and doing a worse job of it... in fact, the only project I‚Äôve ever created that has got _any_ traction (few hundred stars on github) I recently found out was basically formed and then rewritten by AWS folks who, honestly, did a _way_ better job of writing it. Way more elegant and much better in every way. So I‚Äôd be a huge hypocrite if I made a commentary on anyone else‚Äôs attempt to build anything.
It appears I spoke to soon, you actually found a bug where very simple values are not being output correctly. I've fixed it, and updated, once you've installed the latest the following should work:
I hear ya ‚Äî I hope my comment didn‚Äôt come off as condescending or dismissive because a.) I genuinely think your work is cool and worthwhile in its own right and b.) I am always rewriting something that already exists, and doing a worse job of it... in fact, the only project I‚Äôve ever created that has got _any_ traction (few hundred stars on github) I recently found out was basically formed and then rewritten by AWS folks who, honestly, did a _way_ better job of writing it. Way more elegant and much better in every way. So I‚Äôd be a huge hypocrite if I made a commentary on anyone else‚Äôs attempt to build anything.
I hear ya ‚Äî I hope my comment didn‚Äôt come off as condescending or dismissive because a.) I genuinely think your work is cool and worthwhile in its own right and b.) I am always rewriting something that already exists, and doing a worse job of it... in fact, the only project I‚Äôve ever created that has got _any_ traction (few hundred stars on github) I recently found out was basically formed and then rewritten by AWS folks who, honestly, did a _way_ better job of writing it. Way more elegant and much better in every way. So I‚Äôd be a huge hypocrite if I made a commentary on anyone else‚Äôs attempt to build anything.
This is probably worth reading, although I couldn't help feeling that it was pretty biased and with a little work could have been a lot more helpful. Like they just had a premise that go failed at making concurrent programing simpler because code had a non-zero number of bugs, so everything was tainted with that view. There were few comparisons and the couple that where there seemed problematic (like comparing number of threads to number of go routines). For instance while go feels so much usable for creating concurrent code, as you write more of it you do still feel the edges where a few tweaks could maybe provide significant benefits. Maybe reading the original paper will provide a lot more information.
This is probably worth reading, although I couldn't help feeling that it was pretty biased and with a little work could have been a lot more helpful. Like they just had a premise that go failed at making concurrent programing simpler because code had a non-zero number of bugs, so everything was tainted with that view. There were few comparisons and the couple that where there seemed problematic (like comparing number of threads to number of go routines). For instance while go feels so much usable for creating concurrent code, as you write more of it you do still feel the edges where a few tweaks could maybe provide significant benefits. Maybe reading the original paper will provide a lot more information.
This is probably worth reading, although I couldn't help feeling that it was pretty biased and with a little work could have been a lot more helpful. Like they just had a premise that go failed at making concurrent programing simpler because code had a non-zero number of bugs, so everything was tainted with that view. There were few comparisons and the couple that where there seemed problematic (like comparing number of threads to number of go routines). For instance while go feels so much usable for creating concurrent code, as you write more of it you do still feel the edges where a few tweaks could maybe provide significant benefits. Maybe reading the original paper will provide a lot more information.
This is probably worth reading, although I couldn't help feeling that it was pretty biased and with a little work could have been a lot more helpful. Like they just had a premise that go failed at making concurrent programing simpler because code had a non-zero number of bugs, so everything was tainted with that view. There were few comparisons and the couple that where there seemed problematic (like comparing number of threads to number of go routines). For instance while go feels so much usable for creating concurrent code, as you write more of it you do still feel the edges where a few tweaks could maybe provide significant benefits. Maybe reading the original paper will provide a lot more information.
This is probably worth reading, although I couldn't help feeling that it was pretty biased and with a little work could have been a lot more helpful. Like they just had a premise that go failed at making concurrent programing simpler because code had a non-zero number of bugs, so everything was tainted with that view. There were few comparisons and the couple that where there seemed problematic (like comparing number of threads to number of go routines). For instance while go feels so much usable for creating concurrent code, as you write more of it you do still feel the edges where a few tweaks could maybe provide significant benefits. Maybe reading the original paper will provide a lot more information.
Why would filenames be a problem for structured logging? Now, you really want structured logging to understand errors *in a structured way*, not just as the error string. The filename needs to be a separate field. But that's what "structured logging" means in the first place!
Why would filenames be a problem for structured logging? Now, you really want structured logging to understand errors *in a structured way*, not just as the error string. The filename needs to be a separate field. But that's what "structured logging" means in the first place!
Why would filenames be a problem for structured logging? Now, you really want structured logging to understand errors *in a structured way*, not just as the error string. The filename needs to be a separate field. But that's what "structured logging" means in the first place!
Why would filenames be a problem for structured logging? Now, you really want structured logging to understand errors *in a structured way*, not just as the error string. The filename needs to be a separate field. But that's what "structured logging" means in the first place!
Why would filenames be a problem for structured logging? Now, you really want structured logging to understand errors *in a structured way*, not just as the error string. The filename needs to be a separate field. But that's what "structured logging" means in the first place!
That's a very awkward thing when you could just put the protoc executable in your repo, for the same amount of hurt. (Please do not attempt at home.)
`protoc` is not written in Go.
This is probably worth reading, although I couldn't help feeling that it was pretty biased and with a little work could have been a lot more helpful. Like they just had a premise that go failed at making concurrent programing simpler because code had a non-zero number of bugs, so everything was tainted with that view. There were few comparisons and the couple that where there seemed problematic (like comparing number of threads to number of go routines). For instance while go feels so much usable for creating concurrent code, as you write more of it you do still feel the edges where a few tweaks could maybe provide significant benefits. Maybe reading the original paper will provide a lot more information.
If you aren't using CI/Other then you'd just build your binary and distribute it manually, depending on where you're distributing/your app you may want to compile statically as well.
If you aren't using CI/Other then you'd just build your binary and distribute it manually, depending on where you're distributing/your app you may want to compile statically as well.
In my experience, jq chokes on huge JSON documents. Does jsl?
In my experience, jq chokes on huge JSON documents. Does jsl?
In my experience, jq chokes on huge JSON documents. Does jsl?
In my experience, jq chokes on huge JSON documents. Does jsl?
This is excellent. (Referring to the original paper)
In my experience, jq chokes on huge JSON documents. Does jsl?
This is excellent. (Referring to the original paper)
In my experience, jq chokes on huge JSON documents. Does jsl?
Hi, It is a good practice to use docker to create consistent images for applications which aren't strictly cli commands only. For this purpose I use docker like described here: https://flaviocopes.com/golang-docker/ Logs you put to the stdout and docker will do the logging, depending on how it is configured. All you storage and certificates can be mounted via bind mount/volume. Overall using docker will benefit you greatly! Others also are able to customize the setup on the fly. Hope that helps
Hi, It is a good practice to use docker to create consistent images for applications which aren't strictly cli commands only. For this purpose I use docker like described here: https://flaviocopes.com/golang-docker/ Logs you put to the stdout and docker will do the logging, depending on how it is configured. All you storage and certificates can be mounted via bind mount/volume. Overall using docker will benefit you greatly! Others also are able to customize the setup on the fly. Hope that helps
Hi, It is a good practice to use docker to create consistent images for applications which aren't strictly cli commands only. For this purpose I use docker like described here: https://flaviocopes.com/golang-docker/ Logs you put to the stdout and docker will do the logging, depending on how it is configured. All you storage and certificates can be mounted via bind mount/volume. Overall using docker will benefit you greatly! Others also are able to customize the setup on the fly. Hope that helps
Hi, It is a good practice to use docker to create consistent images for applications which aren't strictly cli commands only. For this purpose I use docker like described here: https://flaviocopes.com/golang-docker/ Logs you put to the stdout and docker will do the logging, depending on how it is configured. All you storage and certificates can be mounted via bind mount/volume. Overall using docker will benefit you greatly! Others also are able to customize the setup on the fly. Hope that helps
Hi, It is a good practice to use docker to create consistent images for applications which aren't strictly cli commands only. For this purpose I use docker like described here: https://flaviocopes.com/golang-docker/ Logs you put to the stdout and docker will do the logging, depending on how it is configured. All you storage and certificates can be mounted via bind mount/volume. Overall using docker will benefit you greatly! Others also are able to customize the setup on the fly. Hope that helps
I was hoping to use Docker eventually so that's great thanks.
I was hoping to use Docker eventually so that's great thanks.
In my experience, jq chokes on huge JSON documents. Does jsl?
This is excellent. (Referring to the original paper)
This is excellent. (Referring to the original paper)
This is excellent. (Referring to the original paper)
In my experience, jq chokes on huge JSON documents. Does jsl?
This is probably worth reading, although I couldn't help feeling that it was pretty biased and with a little work could have been a lot more helpful. Like they just had a premise that go failed at making concurrent programing simpler because code had a non-zero number of bugs, so everything was tainted with that view. There were few comparisons and the couple that where there seemed problematic (like comparing number of threads to number of go routines). For instance while go feels so much usable for creating concurrent code, as you write more of it you do still feel the edges where a few tweaks could maybe provide significant benefits. Maybe reading the original paper will provide a lot more information.
I was hoping to use Docker eventually so that's great thanks.
I was hoping to use Docker eventually so that's great thanks.
I was hoping to use Docker eventually so that's great thanks.
I was hoping to use Docker eventually so that's great thanks.
I was hoping to use Docker eventually so that's great thanks.
I was hoping to use Docker eventually so that's great thanks.
I was hoping to use Docker eventually so that's great thanks.
Hi, I'm the author of graw. I'd be interested in hearing what your use case was and what you would have wanted from graw. Also I looked at your streaming code and have some advice based on my experience writing graw: It looks like your [streaming code](https://github.com/thecsw/mira/blob/b53a4d901ff53ec2d48908b18f118d26f28e0169/streaming.go#L42) fetches `M` elements from the listing every `N` seconds and then forwards to the user everything newer than a timestamp acquired from the last seen post. This has two problems: 1. You will miss posts in highly active listings like big subreddits or /r/popular. Getting 4 posts every 15 seconds certainly will miss posts, but it's not really about the numbers and more about that fact that you can't pick constants for which this will always work. 2. In low traffic listings you'll keep downloading the same posts over and over even though you don't need to. This may not matter that much, data is cheap sure, but it seems odd to spend that when it isn't necessary, especially when the cost may not be clear to the user.
Hi, I'm the author of graw. I'd be interested in hearing what your use case was and what you would have wanted from graw. Also I looked at your streaming code and have some advice based on my experience writing graw: It looks like your [streaming code](https://github.com/thecsw/mira/blob/b53a4d901ff53ec2d48908b18f118d26f28e0169/streaming.go#L42) fetches `M` elements from the listing every `N` seconds and then forwards to the user everything newer than a timestamp acquired from the last seen post. This has two problems: 1. You will miss posts in highly active listings like big subreddits or /r/popular. Getting 4 posts every 15 seconds certainly will miss posts, but it's not really about the numbers and more about that fact that you can't pick constants for which this will always work. 2. In low traffic listings you'll keep downloading the same posts over and over even though you don't need to. This may not matter that much, data is cheap sure, but it seems odd to spend that when it isn't necessary, especially when the cost may not be clear to the user.
Hi, I'm the author of graw. I'd be interested in hearing what your use case was and what you would have wanted from graw. Also I looked at your streaming code and have some advice based on my experience writing graw: It looks like your [streaming code](https://github.com/thecsw/mira/blob/b53a4d901ff53ec2d48908b18f118d26f28e0169/streaming.go#L42) fetches `M` elements from the listing every `N` seconds and then forwards to the user everything newer than a timestamp acquired from the last seen post. This has two problems: 1. You will miss posts in highly active listings like big subreddits or /r/popular. Getting 4 posts every 15 seconds certainly will miss posts, but it's not really about the numbers and more about that fact that you can't pick constants for which this will always work. 2. In low traffic listings you'll keep downloading the same posts over and over even though you don't need to. This may not matter that much, data is cheap sure, but it seems odd to spend that when it isn't necessary, especially when the cost may not be clear to the user.
Hi, I'm the author of graw. I'd be interested in hearing what your use case was and what you would have wanted from graw. Also I looked at your streaming code and have some advice based on my experience writing graw: It looks like your [streaming code](https://github.com/thecsw/mira/blob/b53a4d901ff53ec2d48908b18f118d26f28e0169/streaming.go#L42) fetches `M` elements from the listing every `N` seconds and then forwards to the user everything newer than a timestamp acquired from the last seen post. This has two problems: 1. You will miss posts in highly active listings like big subreddits or /r/popular. Getting 4 posts every 15 seconds certainly will miss posts, but it's not really about the numbers and more about that fact that you can't pick constants for which this will always work. 2. In low traffic listings you'll keep downloading the same posts over and over even though you don't need to. This may not matter that much, data is cheap sure, but it seems odd to spend that when it isn't necessary, especially when the cost may not be clear to the user.
There's also a Go binding to jq in github.com/ashb/jqrepl (written by a friend, and I've contributed some improvements). I've used it in a few work projects as a really nice way to let the user specify some kind of filter or transformation for structured data from the command line.
This is excellent. (Referring to the original paper)
In my experience, jq chokes on huge JSON documents. Does jsl?
I was thinking of eventually using docker so that's great thanks.
Awesome thanks for the info.
The map tiles are all monochromatic pixel-art 16x24 in size. I draw them with a little Tcl/Tk script; tiles can be found [there](https://download.tuxfamily.org/harmonist/tiles/) (a script then puts all of them base64-encoded in `images.go`). Drawing them was a fun experience, though I'm not an artist :-)
Docker really is your best option here. It‚Äôs really easy to wrap your head around as well if you‚Äôre used to a CLI.
 [https://www.codingame.com/](https://www.codingame.com/)
Tried web version, very neat experience! Good work!
A lot of what that article says go doesn‚Äôt have is what I like about go
Simplicity is very good.
The map tiles are all monochromatic pixel-art 16x24 in size drawn by using a little Tcl/Tk application. I'm not an artist, so it wasn't easy :-)
Sure. It shouldn't really matter what the backend is written in, if it's exposing some kind of api like http or a common RPC endpoint. Nothing specific to Go here.
The concept of inmutable steings is not new lol. Python does it as well
While Go does not have classical inheritance, I would compare struct embedding pretty closely to JavaScripts prototypical inheritance in feel and usage. I think to say it lacks inheritance isn‚Äôt exactly the case.
How did you do that? Using opencv?
Can we say its relatively new?
Well i am not sure but python is quite old I would say, compared to go. Also, I am sure other languages do it as well. Have no idea...
I had a quick look earlier. Looks great.
Assembly language is a very simple.
Docker is the best solution for this. Where do you want to host your app ? If you want to host in GCP or AWS, Appengine / Beanstalk are both excellent candidates if all you have is a single app. You can just print to stdout normally (no need to tweak anything in your \`log.\*\` ) but get the log messages viewed in the GCP/AWS logs.
So if I connect my backend with nginx then I have to connect front end directly to nginx and the chain will be completed
Thanx mate!!! can you suggest a good api for that purpose
OpenCV has been used only for accessing webcam. There is another reddit post where you can find more details about the process, maybe a blog post will follow along: [https://www.reddit.com/user/esimov/comments/bq1vxw/real\_time\_face\_detection\_with\_image\_triangulation/](https://www.reddit.com/user/esimov/comments/bq1vxw/real_time_face_detection_with_image_triangulation/).
I‚Äôve used Go Mobile with some success. https://github.com/golang/mobile
Well yes. Ruby added Frozen String literals in 2.3 Python has it from the beginning Java String class instances cannot be mutated &amp;#x200B; Also In C++, PHP, Perl etc. strings can be mutated. &amp;#x200B; So like yeah. I can edit that part.
Don't get me wrong, i just think this is not something revolutionary and new :)
Yeah I get that. I just thought, this was a feature that Go creators thought was important from the beginning unlike other languages where this was added later. But certainly its not a new thing.
Github?
Javascript strings are also immutable.
Nice. Will love to go through the code. Github?
Felt the same But that article didn‚Äôt mention that go also doesn‚Äôt have named parameters
We expose a JSON API for this. Then use gRPC for everything behind it.
ok
Yes, once. Since then, I know that if I compare to nil, I have to use pointers - esp. if interfaces are involved.
Isn't this something you can set up in plain HTML and have the form send a post request to some backend endpoint you set up? Given that you want to take care of the styling definition, I don't see why you'd need any sort of library for this.
thanks - this was exactly what I wanted and worked perfectly.
I'm building a mobile app that has a lot of forms involved (300+), every form is different than the other. (depending on the section the user is posting on). That is why I need an API for it. &amp;#x200B; The forms will be built by non-dev people, which means we need some sort of form builder as well, so it is easy for them to manipulate. (this part seems time consuming, if I was going to build it.) &amp;#x200B; I don't want to reinvent the wheel as I know there are too many platforms that do build/manipulate forms, but I was surprised by the pricing and lack of some important features I was looking for. &amp;#x200B; Those who offer cheap service, they don't provide such good way to access the form definition.
No. That‚Äôs called a sum type and Go does not support them. Here is an [article on some workarounds](https://making.pusher.com/alternatives-to-sum-types-in-go/).
Manually setting `os.Args` is indeed not the best idea, so I suggest something like the following: func main() { start(os.Args) } func start(args []string) { // ... } Your test code can then simply call `start()` with whatever arguments you need.
Well thanks you :)
# GITHUB?
Tests as in your _test.go tests? Use TestMain to parse flags and then Run to execute all tests. https://godoc.org/testing#hdr-Main
What? x86 has over a thousand instructions and some of them look like ‚ÄòPUNPCKHBW‚Äô
Is your backend not exposing sone kind of API already?
Yesterday I bought a course of Golang from udemy and now I am worried whether it is beneficial or not to use golang
so i just wanna know whether it will work with android apps and so far I think it will work according to the replies
The instructions are not the grammar
I see, so first, yes you can write API in Go. Swagger (https://github.com/go-swagger/go-swagger) or gRPC (https://grpc.io/docs/quickstart/go/) can help you build your API
wow -- ya, that is the clearest and most succinct way to put it. thank you!
Thank you for the information)
[removed]
[removed]
In addition to venju's point, even in dynamic languages or languages that have true sum types, that return type is a code smell. It's probably better to unconditionally return a slice, and for it to be a possibility that the slice has one value in it, than to vary the type like that. Again, this has nothing to do with Go, this is generally applicable advice.
Well you can... if you ignore the return type and use "interface {}" instead, and that's the issue, it's either simplistic compile time type checking or not compile type time checking at all.
&gt; that return type is a code smell. TIL Haskell language is a complete code smell all together.
or Gitlab? Gitea? Bitbucket?
Gitlab? Gitea? Bitbucket? or even a gist/play?
Sourcehut?
Wow, that looks fantastic actually.
Go is not fault tolerant as Erlang, one panic kills the whole app down.
Sounds like scaffolding. The only way to do this in golang currently is via code-gen. In order to have true scaffolding within a live app, the language has to support generics.
[https://github.com/esimov/pigo/tree/master/examples/delaunay](https://github.com/esimov/pigo/tree/master/examples/delaunay)
&gt;Constructors `structVal = structVal.Init() //You can also pass arguments into there` &gt;Operator Overloading Just make a Add or Compare function for your struct. The amount of code you write doesn't change too if you want to do simple operations. Equations on the other hand..... but I wouldn't expect Golang to be a programming language for mathematical computing &gt;Default Parameter Values Set a parameter to nil, and check inside the function if the parameter is nil. If it is, then give it a default value.
A function that returns two types is an abomination. I used to feel the same way about ‚Äúclever‚Äù or ‚Äúconvenience‚Äù features like these. Now I choose ultimate simplicity.
Don‚Äôt do this. Return a type that has the interface you need then invoke it.
can you give an example of what you do?
With the image being constantly obscured differently every frame, I'd worry about a security risk. I can at least image that the slight amount of detail being exposed in various parts of the face could be reconstructed, given that different details are given each frame.
Docker is great of course (and what we use usually, if the deployment is not serverless) but what do you mean by "can't find my logs, config and certs directory"? It is what you set it, you can deploy golang directly and a statically linked executable binary, there are no dependencies for the run itself. -&gt; you could it yourself, on a CI server or whatever build machine, copy it over and run it. end of story. it's the easiest thing to deploy (no JDK, no python, no deps..)
This is well explained in https://golang.org/doc/faq#nil_error.
That's not what they said at all ‚Äì the statement was about returning a list vs the element type in particular.
You mean like err and something else? :P
First of all: don't do it unless there is a semantic difference between a slice of one element and the element itself. Second of all: probably still don't do it and return a second return value flag or something. Third of all, having two return values and returning "nil, Val1" Vs "val2, nil" is essentially a labelled sum type.
Generally speaking, always return nil values explicitly and you won't run into this. Beyond that beware converting a typed pointer that could be nil to an interface.
I don't understand why the article describes shared library installation in this way. It seems to imply that using "install" is necessary for each shared library in order for it to be available to your application. But that isn't true. Only the source needs to exist on the GOPATH (I'm ignoring the fact that this doesn't touch on the newer module support), because building the application will also build the local GOPATH dependencies. "go get" also implies an install if that is how the deps were orgiginally fetched, vs a clone. What "install" does do is help them from being rebuilt again later, which could be nice if you have a complicated cgo dependency. Side note: that blog hosting site is really awkward on a mobile phone because if you don't have a login it gives you less than half of the screen as a reading view.
It makes perfect sense if you understand how concrete types, methods, and interfaces work. Consider: ``` type myError struct { s string } func (e *myError) Error() string { if e == nil { return "unknown error" } return e.s } func doFoo() error { // blah return myError(nil) } func main() { if err := doFoo(); err != nil { log.Fatal(err) } } ``` Why shouldn't the err != nil in main be true? That would literally be ignoring a valid error. A typed nil can have methods, therefore a typed nil can satisfy interfaces.
Yes, you are right, you dont have to install is necessary for each shared library in order for it to be available to your application. Only the source needs to exist on the GOPATH. But you need to run go get example.com/library-name in order to add it to your GOPATH.
Are you trying to say that something simple can also be complicated? While true, it's not a great example because what makes ASM _usable_ is the instruction sets, not the grammar. Assembly is simple but actually using it is complicated.
[https://github.com/esimov/pigo/tree/master/examples/delaunay](https://github.com/esimov/pigo/tree/master/examples/delaunay)
[playground](https://play.golang.org/p/cqylSNm89l-) for the curious
That is exactly my point. Simple grammar but complicated to use. I was making a direct reply to someone saying "Simplicity is very good." about GO. People in this thread don't seem to understand that simplicity can sometimes by bad. This is of course the go sub reddit so i might have had to high expectations about the people heres Assembly language knowledge.
I have a client ID I want to hide from the front end. I also want to trim down the JSON the browser receives, though I'm not sure if the bandwidth saved would be significant, will do some benchmarks
The value of argv[0] (or any of the args) is not enforced. The syscall for starting the process only cares about the program Path. It is convention to have the first item in the args be the valid program name. But it is also valid for it to be unset completely.
I meant the args\[0\] is the string associated with the initializer function that it's been registered with
&gt; The value of argv\[0\] (or any of the args) is not enforced. The syscall for starting the process only cares about the program Path The major part of my misunderstanding arose from the belief that it's important to have argv\[0\] same as that of the process (or program?) name. Thanks.
I'm kind of confused why this question was cross-posted to /r/golang.
I'm currently just deploying to AWS. That's really useful to know about logs and stdout, thanks.
Sorry I should have explained it better. I was setting the paths to the logs, config and certs directory based on being children of my root directory but of course when you use 'go install' it creates a binary to your $GOPATH/bin directory. Thanks for the advice.
:eyeroll;
No, that‚Äôs two value, each of a single type. I have zero problem with this, particularly in the way you‚Äôre describing.
Ah well that part might still be important to have it run an already registered function. Not sure.
It really depends on the usage model and how much extension you want to delegate to the plugin. This will dictate what the coupling boundary looks like. My default is to communicate with textual messages over a domain socket. Then plugins can be implemented in any language that supports your communication protocol (line oriented json messages). If you need high call rates and tight coupling, then bring in process.
I don't get it, why would I need all that!
You're right, I should've not done that. I just wanted more people to access the question, because I couldn't get much of help in /r/reactnative. Are you aware of any subreddit that this question makes sense for?
If you had vendored the dependencies, it'd still have compiled. :-) (At least it's not here).
Nope, sorry. Best of luck!
From https://blog.golang.org/godoc-documenting-go-code &gt; Notice this comment is a complete sentence that begins with the name of the element it describes. This important convention allows us to generate documentation in a variety of formats [...] Something to take into consideration when planning to share your work.
Fault tolerance is not about not exiting from panics, it's about dealing with errors in a robust way that doesn't cause the app the end up in a bad state. In my experience, the only way to consistently do that is to fail early and hard by default (so you can discover problems), and fail soft only when absolutely necessary (combined with logging/metrics). That being said, panics are not for error handling they are for truly unrecoverable issues. But there are cases where you are forced to treat them this way (recover, convert to error), for example if a library misuses panic.
Struct embedding is essentially just a syntax shortcut for: struct foo { bar bar } There's a bit more to that, as methods from `bar` can be promoted so `fooInstance.methondBar()` works; but again, that's just a syntax shortcut for `fooInstance.bar.methodBar()`. If it were inheritance, `methodBar()` would have access to `fooInstance`, but it doesn't. Personally I think struct embedding was a mistake. Too many confuse it with inheritance, it can sometimes be surprising, it makes the code harder to parse (annoying when writing tools), and I haven't seen cases where it solves problems that can't be solved otherwise.
You can recover from panics. If you're writing a long-running application you should probably do exactly that, so that a panic in one goroutine/connection isn't going to kill the entire app. It's just a few lines of code.
I think the title is misleading and the content too. It does not draw a difference between "share a library" and "shared library" (.so or .dll, dynamic linking). In fact the section headings use the term "shared library" showing that the author does not know the difference. Instead this article talks about publishing a library. He mentiones uploading it to GitHub but forgets the most important step: picking a license. If you do not pick a license your project is effectively proprietary.
Also about 50% screen is covered in menu+registration content, so you can only view the content in some tiny porthole.
Your comments on error handling make no sense. There is nothing stricter about Go error handling. Infact, Kotlin can just as easily destructure return values, can handle try, catch scenarios (not a Go feature if I remember) and has sealed classes, which go a lot of the way to providing compiler enforced branch exhaustion.
Sorry my eyes.. Repos?
NPM(node package manager) is used to manager node's packages but not node itself. what your gpm do is more like to NVM(node version manager).
RESTful API is a very cool thing! I also advise you to look at GraphQL, but after RESTful API.
https://github.com/yashishdua/gpm
You can access the webcam and get pixels natively in pure Go on Linux/RPi and Windows, see this https://github.com/gen2brain/cam2ip/tree/master/camera, for macOS you can use the OpenCV bindings. Like it is now, you have pure Go detection library that you compile to c-shared lib and access from Python via ctypes, a little confusing.
Thx, What problem does it solve?
Updating is an extra utility. GPM allows to create a boilerplate project, helps to build a project using vendor and modules. Check full package here: [https://github.com/yashishdua/gpm](https://github.com/yashishdua/gpm)
Everything in Go needs to be inside a package, just like everything in Java has to be part of a class. If you want to share your example function across multiple packages it has to reside in a separate non-internal package. If you just need it in your local package you can make it a non-exported function (lowercase) in your package (same directory) or create an internal package for it (only advised if you have lots of code that belongs together but is only needed in one place).
To use a function defined in a different file, but in the same directory, you don't need to import anything. Just call it without any qualifier, just the same as if it's in the same file where the call is.
&gt; A function that returns two types is an abomination. There is no such thing... Unless you speak of dynamic typing languages of course, where the return type may be arbitrary.
With introduction of Go modules, depending upon you are outsdie GOPATH or not, you need different go commands to setup. It's all taken care of! Soon, I will add commands to setup docker and heroku server as well. Supportive commands like Update are super helpful! There is no existing command to do that.
Yeah, digging around I'm starting to understand how my view of packages is off. Go has some learning curve, at least for me, but I'm loving it. Thank you for your explanation.
Love this one, nice job
Is there any need to set any other environment variables?
Firstly, panics of course NOT for error handling. Fault tolerance coming with supervision trees and process isolation on Erlang. And for your comment, fault tolerance is not about error handling. Error handling and recovery are different concepts and there are good pattern matching mechanisms for error handling in Erlang. Also check: https://stackoverflow.com/questions/3760881/how-is-erlang-fault-tolerant-or-help-in-that-regard
Graphql seems to me to be the logica successor to RESTful
Why would another implementation of Go implement a feature that is not part of the specification? Would any serious company switch to a community based project (that means leaving a lot of tools supported by Google) just to get some generics? Or maybe I'm understand this wrong...
That's true, but I've heard, that the driver for Golang isn't as good as the one for Nodejs, so would still used Nodejs instead of go for graphql.
Or empty interface...
Not that I want to get you down, but I don't see this being useful long term. Right now, yes, because we have both GOPATH and Go Modules. But GOPATH is being deprecated this August.
Amazzzing thoughts with lotz of hashtags. I am sure no one has thought of it before.
Apologies
That's a warning, not an error. Since the project has a go.mod, you're probably better off cloning it outside your GOPATH.
Very different concerns. Be careful with thinking it's a replacement
Just to point out, OpenJDK does not have special features at a language level, just an open source implementation
We can't do this because it's stupid to fragment a community just because you want a feature. Go use something else if Go doesn't have what you want
Agreed. It‚Äôs just there are lot of discussions around generics and noone has taken a stab at it . Though I am not a language implementer but it would be nice to see some implementation of generics in Golang .
All I am thinking is, since go is open source it would be nice to have some implementation of generics as proof of concepts, so that commiters of go can review it and may be include it in the specification .
As I understand it, GraphQL is great for writing backends for single page apps and JavaScript frameworks. Server-to-server type APIs are still better served by REST. Is that accurate?
export GO111MODULE=on
Not really? GraphQL is a good way to let internet strangers send your server pathological queries that grind your database into dust but for some reason no one talks about that.
Everything not strictly enforcing types and schema is "great" for Ui or frontend interfaces in general. Comparing a subset of GraphQL and RESTful will not give you an edge in a sub-million-install apps. Even then you get to a point where you could be better off using binary or RPC based implementations.
In addition to the other general answers, specifically for your own case you just need to move the internal file into a package folder and then do: ``` import "exampleproject/internal/exampleFunctions" ``` where your example go file is under that exampleFunctions package dir
Hey! Such a surprise seeing you. Thanks for replying! I am not sure if you are familiar with r/MemeInvestor_bot It is a meme investment bot on r/MemeEconomy and currently, it‚Äôs whole core codebase is written in Python with the halo of praw. After a year of running it, we hit several bottlenecks and limitations purely to the language structure, so we thought about moving it to Golang. graw was the first api wrapper that we looked into. Unfortunately, we didn‚Äôt really get the sense of how to work with it and we had a bit specific needs for our system (mod privileges, editing user‚Äôs flairs, subreddit moderation). The decision was to make our own wrapper that will satisfy our needs. About our submissions streaming. Yeah, that was a bit tricky to come around and I get where you are coming from. Every sub is different and it would be almost impossible to find that sweet spot with constants. By any chance you are aware of a better approach? Again, thanks for contacting! I love your work on graw (been using a bit later)!
REST is an excellent tool for when you do not know or care about what is implementing your API. RESTful APIs can service both service-to-service and service-to-UI pretty comfortably. If there were no UIs in the picture, gRPC would probably be more performant and have less coding overhead. If you know that your API is being consumed primarily/exclusively by a UI, GraphQL would probably get you a lot of niceties that REST/gRPC could not provide (only get what you ask for, shared UI/server types, etc.)
[removed]
Ah yeah that makes sense. I didn‚Äôt personally need any endpoints for moderation so I didn‚Äôt add them, but someone could add them to the reddit subpackage if they wanted; all they need to do is specify the endpoint and parameters. Maybe group them in a Moderation interface. For streaming events from listings, what I do in graw is keep a ‚Äútip‚Äù, which is the id of an element in the listing. Then I use it as a parameter in the request as ‚Äúafter‚Äù/‚Äúbefore‚Äù, so it will return posts only one one side of the tip in the stream. This will work as long as none of the tips get deleted or caught in a spam filter, because after that they are removed from the listing and requests will always come back blank. If every few blank results you pull the tip element specifically to check that it is still valid, you should be good. Just keep a list of chronological backup tips to fall back on when one gets broken.
Maybe openapi is a good idea. Checkout kin. This provides a standard API that you can either codegen from or just parse. The forms hitting the openapi gateway can then be validated using open api validation. Again just Google for "kin openapi"
That‚Äôs a fantastic idea. I will make sure to implement it!
If you use Go 1.12 you don't need to set any environment variables.
ahh, right. It's necessary to use \`dep\` before building in this case...
They were sending free CD's to anyone attending Mac's concert in LA o:
Since in ago tradition the first n values shouldn‚Äôt be inspected if err != nil, it is essentially a poorly tagged union that uses more space. Sum types are objectively better than this.
What is [socket.io](https://socket.io) ? &amp;#x200B; Do you mean sending packets on network? If yes, try using net package and use appropriate UDP or TCP methods and interfaces. &amp;#x200B; If you mean BSD sockets, well use the system libraries or syscall directly or via CGO interfaces.
I suspect that the link has more meaning than just a tutorial on a REST API in Go. Nice effort to build the site you have, and if you get exposure for your site through links here, then more power to that, because it looks really useful as a platform. However, as far as REST API tuitorials go, I feel the approach is a bit meh, even though the writing and layout is clear. In the community, I feel like by now, there are a million and one tutorials that are just the same. It's little more than copy/pasta in terms of value, compared to other tutorials on the subject. I also get that in a tutorial, it can't be too long, and staying focused on a core message is better than making a tutorial that covers multiple things and the messages get diluted. However, in terms of writing a REST API, there are so many better ways to structure a project, to decouple concerns, to build SOLID and to be easily testable. I don't want to be negative, because your site is good, but I feel like these tutorials are bordering on little to no value anymore. We've moved on so far from that.
Thanks.. CGO interface is best.Can i call the nodejs function using cgo?
How big of files are you working with? I've process multi-gigabit JSON files through jq, assuming their valid JSON, without fail.
Mine are multi-*gigabyte*. üòâI just remember the command seemed to parse the whole file even though I only wanted the first 10 array elements, for example.
I am not sure I understand, are you just showcasing a core library? Also, there are builtins `Hostname()`for Host w/o Port, and `Port()` which returns a zero value if no port is present.
"Can i call the nodejs function using cgo?" But...why?
Why does it need to be a question of OR? Why not just return an array regardless, and if the array is only a single index, thats effectively the same result? Alternatively, you can return an interface, depending on how you choose to implement the layer of abstraction ``` type Implementor interface { GetBar() interface{} } ``` ``` func (i *Implementor2) GetBar() interface{} { return []Bar } ``` ``` func (i *Implementor2) GetBar() interface{} { return Bar } ```
I'm guessing you are asking for a websockets implementation for Go. It that's the case take a look at http://www.gorillatoolkit.org/pkg/websocket.
We are tried to implement socket.io in golang but there is only websocket available in golang.. That's why üôÑ.. Socket.io is available but it is a third party package and currently there is no commit or update in that package.
Yes but Im trying to implement socket.io.
So you want to call a JS library from Go? I'm confused about what you are trying to do and why a library would exist for it.
In websocket it is difficult to implement namespace and rooms
I see. Makes sense. I worked on something similar for a webrtc project for a bit. It was barely functional though. I implemented rooms myself.
Is it a good way to go websocket or I should find another way
If you are building a web app. Yes I think so. It's widely supported in languages and platforms.
It really depends on what you mean by ‚Äúprocessing‚Äù. Generally speaking, you‚Äôre going to be IO bound, so goroutines are unlikely to solve the issue. But in the odd case where you‚Äôre actually CPU bound, you can make several workers that all read from the same goroutine that a ‚Äúreader‚Äù goroutine is ingesting from. Let each of those aggregate on their own pace, then once the final byte is read, close the ingesting channel and have the aggregator workers push their data into a aggregator. Eg, if you were just word counting, (which would be IO bound for sure, but let‚Äôs pretend it isn‚Äôt). You would have one goroutine reading each line and feeding into one channel. You would spawn N goroutines where N is the number of physical CPUs. (You also need to set GOMAXPROCS). Once the reader is done, close the ingest channel, and then have the workers write their aggregate data to a second channel. A worker, spawned by the closing of the channel, would then tally each of their results that it read on the channel.
&gt; Once the reader is done, close the ingest channel, and then have the workers write their aggregate data to a second channel. A worker, spawned by the closing of the channel, would then tally each of their results that it read on the channel. If I have a worker that reads a 10GB file into the channel, and then I spawn workers to read off that channel, wouldn't I have read the whole file into RAM? Or am I not understanding how the channel open/close works?
Sort of. If the channel has a small buffer then that will limit how much is actually in ram at once. So say the channel is for strings, and you read 1 line at a time. If your channel has a capacity of 10, then it will accept 10 lines before the file reader is blocked and no longer able to write to the channel until something, aka a worker, reads a line from it. So they pass thru ram but aren‚Äôt all read at once. You could, if you really wanted, make a channel with a massive capacity, but typically channels are pretty small and tuned to the application. In your case, I would be using a bigger bufio, and a channel that‚Äôs N *2 where N is the number of workers and physical cores. That way you‚Äôre reading a larger chunk, which is much faster than lots of smaller IO reads. And then there‚Äôs always something waiting for a worker.
What I'd do is have one worker that does the readString and writes to a channel. A bunch of workers will read from this channel and do the calculations. They in turn can write to another channel to another worker that updates the map. If you have multiple workers for map update you will need a lock on the map. If you want to limit the amount of work dispatched concurrently, I would use another channel as an object pool. The objects might contain a buffer that can be reused for the reads. When the map is updated, the objects are put back to the object pool to be reused. The poll is seeded with a fixed number of objects to achieve target performance. This also reduces memory allocation overhead since you reuse the objects. What remains is that your map might keep increasing in size as you add to it. Hopefully your processed data is much smaller.
This post is like a car crash. I need to keep moving, but it‚Äôs so bad I can‚Äôt help but stop.
&gt; What remains is that your map might keep increasing in size as you add to it. Hopefully your processed data is much smaller. It will for now, and the processed data is much larger than the map is ever allocated. I am doing some statistical analysis on the text (word/pattern frequency etc.) so I'm saving various counts in it right now. What's the usual Go-dev-approved system for map-like persistence? Every language seems to have its own commonly-used engines/libraries for these things.
Hey! Just wanted to say thank you! I just fixed the streaming option. I actually used the `before` parameter to sort the submissions listing remotely [Here is the new method](https://github.com/thecsw/mira/blob/master/streaming.go#L43)
How does Hippo compare to [go-micro](https://github.com/micro/go-micro) and [go-kit](https://github.com/go-kit/kit), the two classic microservice libraries? In other words: If I have to select a microservice library, when should I choose Hippo, and when should I pick go-micro or go-kit instead?
Sounds like you want map reduce doesn't it? Here's a guide: https://appliedgo.net/mapreduce/ Here's a ready to use library: https://github.com/chrislusf/glow
&gt; What's the usual Go-dev-approved system for map-like persistence? Simplest way is to save it to a file using Gob or JSON serialization. That is just a couple lines of code. There might be some better third party libraries I'm not aware of.
Yeah, this is pretty much the same pattern. Glow looks useful, thank you.
I guess what I'm saying is that distinguishing the *grammar* from the *instruction set* in your argument suggest that Assembly without the instruction set is useful. Which it is not. In order to make ASM useful, you need the instruction sets and then the language becomes extremely complicated. Conversely, Go is inherently useful without grammars or instructions that complicate the language. In other words, Go can do complicated things using simple instructions and remain simple. I agree with you fundamentally that just because something is simple doesn't mean that is good. However, I don't think that point was ever made in the same context. I don't think anyone would disagree with the statement that "simple is better than complicated" all else being equal, so I would agree with the sentiment that, in the context of Go, "simplicity is very good". It makes programs easier to read and follow, and encourages developers to not write stupid and confusing code just to fit everything in one line. In many ways, Go is better at PEP20 than Python is.
was going to say the same thing. try implement your own version of map reduce.
Thanks for the answers, it gave me more insights about how to think about packages in Go and what to look for. In this case, the actual error I made was more of a brain fart, which led to look for the problem in the wrong place. Here is the stackoverflow question I asked in more detail and a very on-point answer - [https://stackoverflow.com/questions/56209762/how-to-import-local-packages-when-using-go-modules/56209940#56209940](https://stackoverflow.com/questions/56209762/how-to-import-local-packages-when-using-go-modules/56209940#56209940) Maybe it will help someone else as well to understand the packaging better. TL;DR I imported the package, but forgot to use it in front of the function I wanted to call. It should have been "example.GetAllEmployees" instead of just "GetAllEmployees"
This talk but JGC is worth having a look at i think https://youtu.be/woCg2zaIVzQ
The instruction set is not complicated it is just large. Its just like the GO API. Assembly is a simple language and easy to learn. Its hard to make complex app just because you need to work with so small building parts. So its a simple language but hard to work with. The problem with GO's simplicity is ex lack of generics. When Java switched from non generics to generics there were so many exceptions that disappeared from production environments. I remembered when that happened. There were ClassCastExceptions that occurred in large codebases and when they introduced generics they disappeared. Having generics in collections is really not complicated. If you pay someone to be a programmer and they think that generics are complicated then you might reconsider if they really are a good programmer.
I might be misunderstanding your problem, but aren't you going to run into RAM issues regardless of whether you are concurrent or not, if you are going to read in the 10 gigs into one big buffer? Sounds like goroutines + channels will only amplify the problem. As an alternate approach, can't you batch read the file i.e. instead of `reader.ReadString` you would just use `Read` and read a finite number of bytes into memory and partially compute your results. Even without goroutines, this sounds much easier on the RAM. You could also use a divide and conquer approach - say for a file of size `N` bytes, two (scale the idea to your desired numbe) goroutines read `(0..N/2)` and `(N/2..N)`, `p` bytes at a time where `p` is a desirable constant. For storing the results, using a single `map[string]int` shared across goroutines would get you into performance issues with lock contention if you go that route. You could maybe pass the map across a shared channel and you would be fine. Alternatively, based on what exact computation you are doing, it might be feasible for each goroutine to store its results in it's own `map[string]int`, and the results would later be merged into a single result set, ideally in `O(m1 + m2 + ... mN)` time where `mX` is the size of the map for goroutine `X`.
While Glow is probably better to use in a production application, you don't learn a language by only stringing together other's libraries. I wouldn't write my own standard library functions in many cases, either, but it's helpful when learning to understand some of those fundamentals.
pffff. Ok, I stopped reading after 2 or 3 lines, because the font you use, is for me a no-go. If you want to target an audience.... I would use a normal font, which gives it a more professional look. (I think it's a pity, because you probably have something interesting to tell us.)
So use it as a reference to implement your our version.
A similar tasks has been picked up by a couple of people using the term ‚Äûlarge textfile processing using Java‚Äú by Paige Niedrighaus. This is more beginner level, but multiple cross-language implementations exist, you may find some tips and tricks. Not sure if a Go version exists.
It is an article about variadic functions. In my opinion Inanc Gumus wrote a better article about them and also uses a readable font. [Link to the the mentioned article](https://blog.learngoprogramming.com/golang-variadic-funcs-how-to-patterns-369408f19085)
[removed]
[removed]
That's what the first link is for. It's a build your own tutorial.
I was aware about different kind of Go libraries dealing with accessing the webcam, but I haven't found an unified and widely accessible solution, which should be platform independent. This is why I opted to transfer the Go binary as a shared library to Python OpenCV. Also I opted for this solution as a proof of concept of how Pigo can be integrated into other languages.
No src folder https://github.com/golang-standards/project-layout
Udemy courses are not being updated I think. 40-50USD for Todd's courses is a great price! This is investment in yourself and your career. After the Go course I'd recommend Go web programming course.
Others have answered about the MapReduce pattern, but I think you also expressed some confusion about channel synchronization, so I'll try and answer that. Channels have buffers. The size of the buffer is specified when you create a channel. When you omit the buffer size, it defaults to 0. When you send a value on a channel, there are two cases. Either there is a free spot on the buffer. In that case, the value gets queued on the buffer and you code moves on to the next line. If there isn't a free spot, sending blocks until someone receives from the channel and makes a free spot. As I already said, if you don't specify the buffer size, it defaults to 0. That means that there's no free spots on the buffer ever. Whenever you send a value on such a channel, it will block until there is a receiver ready to receive the value. This is also called a 'synchronous channel'. Sending and receiving always happen simultaneously on it.
I have the errors thing in the TODO :) What is the idiomatic way of handling a fatal error though (like ROM missing in this case)? Also where should the source files go in that case? /cmd/appname? It's weird because in practice a lot of "big" Go projects don't bother with that, e.g. lf: https://github.com/gokcehan/lf
Here: [https://github.com/faruqisan/kuy/blob/master/kuy.go#L41](https://github.com/faruqisan/kuy/blob/master/kuy.go#L41) `opt.WaitPeriod.String() == emptyTime` will never happen. The String representation of a zero durations is `0s` while your `emptyTime` contains the following string `"0001-01-01 00:00:00 +0000 UTC"`. Also `time.Duration` is a `int64` so you can do the following `opt.WaitPeriod == 0`. For locking you could use a `sync.RWMutex` so you can differentiate read locks and write locks. And am I understand it correctly that a user cannot leave a pool by disconnecting?
Start by spelling the language correctly, it is "Go". And why not implement generics yourself? Can't be that hard. The hardest decision will be on the syntax, but hey: Everybody is used to &lt; and &gt; so just do it. I have some spare time on Thursday to do a review.
Maybe you can avoid constantly re-registering ACME accounts (not so polite to Let's Encrypt) by changing your acme-dns-route53 binary to take a private key as an environment variable, rather than a file. This is a bit ambitious if you use RSA keys, but an ECDSA P-256 key is actually quite compact and fits easily with your other env variables.
log.Fatal for example. cmd/app only contains a main.go, which calls as few code as possible from either internal/app/... or pkg/app/... (one is internal code which other projects except this one can not import from (Go restriction), and pkg is public api). So your code would probably go in internal/app/...
What would you recommend instead of this?
"Go fvck yourself"
Yeah this font makes my eyes bleed
good!
I would personally like additional stuff like how people test their microservices. Often with these "simpe" tutorials a lot of the interesting stuff around the actual content is missing. A lot has been written about how to create \`hello world\` but things like integration test/deployment and gotchas would be interesting in my opinion.
there is a lot here but just curious: are the things you're testin io bound? can you post the source?
They‚Äôre X.509 certificates, not ‚ÄúSSL‚Äù (which isn‚Äôt even in use anymore and was superseded by TLS 20 years ago).
endtest spam, user is affiliated look at post history, also uses multiple accounts to push this crap.
Good, let's run it on google images
I hope it works üòÖ
Do you think it's worth using Gorm considering the generated queries? And the queries represent what you expect?
They are related to cryptography, and i unfortunately can't post the sources, as i don't have the approval to do so. If you want me to specify things, just tell me :)
Something like V language with implemented generics, wait for it next month. https://vlang.io
Yes, this is just to avoid re-zeroing the existing element. The element points to already allocated memory chunks. Simple `append` will zero the element, so references to the allocated memory chunks is lost. This means an additional memory allocations when initializing the zeroed element.
Sorry I was looking for like specific examples, I am trying to learn exactly what this article is teaching and if there was a better examples I was hoping to see them. I am very new to the RESTAPIs
This is just blogspam, don't click through the link.
Your aren't running anything in docker?
SQL is great, no ORM for me
That's a great article, very concise. I've yet to feel the need to use gorm or similar in a project since the built in library is fine but I definately see its uses for getting the boilerplate done. Personally, if the project grows, I'd opt to create a internal repository of common functions for each table. Keeps things tidy, testable, non-magic, and easier to debug.
Yeah, I think /u/lpave is asking what RESTful API tutorial in Go would you recommend rather than what should OP have written a tutorial about (on another subject) which is what you appear to have answered.
As mentioned in the article, the trouble is with complex cases. For the simple cases, if not using an ORM, you can use a project like gnorm (not gorm) to inspect database and automatically generated common code for you. When you need something more complex, write the SQL yourself.
At [Prisma](https://www.prisma.io), we're rethinking how ORMs should work. We believe that there can be tremendous value in providing a programmatic interface to a database, but we're not satisfied with the [current state of ORMs](https://www.reddit.com/r/golang/comments/b9h8xo/the_state_of_orms_in_2019/ek5we7k/). I also agree with the article that many ORMs can be a great help when starting out with a project, but often impose maintenance burden and lead to performance penalties on the long run (especially for new developers that don't have a strong SQL background and don't have a good understanding what the DB calls generated by their ORM actually look like). When using gorm, developers define their database tables as Go structs and let gorm handle the migration. Prisma takes a slightly different approach: You define your database schema (the "Prisma datamodel") using a generic modelling language to describe your schema. Based on this datamodel, Prisma generates a type-safe database client that you can use in your application. Note that if you're starting with an existing database, Prisma introspects your database schema and generates the datamodel from it (so the client is effectively generated from your database schema). I would love to hear everyone's thoughts on this approach! Feel free to check out some examples, e.g. how to build a [GraphQL](https://github.com/prisma/prisma-examples/tree/master/go/graphql) or a [REST](https://github.com/prisma/prisma-examples/tree/master/go/rest-gin) API with Prisma.
Not exactly ORM, but something that helps. https://github.com/gocraft/dbr
&gt; Start by spelling the language correctly, it is "Go". This attitude is part of the reason that people dislike the GO community.
I'm afraid you will have to write an adapter function thay can take care of populating a slice of your own struct type
Forgot to mention that I am running my go server in docker
localhost is only local to docker. You need to connect to the IP where elasticsearch is bound to. If that's running on the host hit the IP of the host itself
[removed]
[removed]
There is no reason for you to be rude . I am suggesting that implementation of generics will be easy . All am suggesting is we (community) should implement prototype or so proof of concept and present it to committers .
How do I find the ip of the es cluster then?
It already exists, it's called wget
Oh bug off. The colloquial terminology used is "SSL" and everyone knows exactly what you're talking about when you say it.
This might be helpful: https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach
https://up.docs.apex.sh/ can also handle this for you if you are creating serverless applications in Go.
Without writing something too long that would itself cover everything in a tutorial, a lot of where Go development has moved to is summed up in this from Dave Cheney a couple of weeks ago: https://dave.cheney.net/practical-go/presentations/qcon-china.html and also this from Mat Ryer: https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831 Between those two, tutorials can provide much more advice for readers on how to produce code that is production quality.
Might be helpful if you provided some code as an example.
Objectively better on the axis you choose? ü§∑‚Äç‚ôÇÔ∏è
SQL is an abstraction already. ORM in turn is an abstraction over an abstraction. If anything, at least consider doing a database-first orm, like sqlboiler: https://github.com/volatiletech/sqlboiler (I'm not affiliated with them in any way, I just remember the project from previous discussions).
Waooo, that is exactly what I was trying to avoid.
You don't need golang at all. Certbot completely off the server (my preference) with AWS credentials specifically for registering DNS certs takes 3 commands to setup and one in a cron to renew I quite like golang and it's single binary, but then I don't need golang, just the binary. Because I usually register locally I also avoid generating new ACME accounts apt-get install -yqq software-properties-common nginx-full python python-pip python3 python3-pip pip3 install certbot-dns-digitalocean &amp;&amp; pip install certbot-dns-digitalocean certbot certonly --dns-route53 --dns-route53-propagation-seconds 60 -d somedomain.ext -d *.somedomain.ext -m youremail@yourdomain.com --agree-tos apt-get install -yqq software-properties-common nginx-full python python-pip python3 python3-pip pip3 install certbot-dns-digitalocean &amp;&amp; pip install certbot-dns-digitalocean certbot certonly --dns-digitalocean --dns-digitalocean-credentials /etc/digitalocean-key --dns-digitalocean-propagation-seconds 60 -d somedomain.ext -d *.somedomain.ext -m youremail@yourdomain.com --agree-tos Technically if I were to do away with separation I wouldn't need these in a docker container, or I could `docker run` them with a different volume mount per logical property, customer, etc.
A couple weeks ago there was a post called "[Word Counter algorithm on Go with sync and concurrent variation](https://www.reddit.com/r/golang/comments/bbq069/word_counter_algorithm_on_go_with_sync_and/)" There were two examples: using a single-thread, and multiple thread version. I told them [a single CPU core could count bytes faster than any I/O device should be able to stream data](https://www.reddit.com/r/golang/comments/bbq069/word_counter_algorithm_on_go_with_sync_and/ekkv9gy?utm_source=share&amp;utm_medium=web2x) and went ahead and forked the code to demonstrate. My code focused more on [reducing the time between completing the I/O tasks and processing the data](https://github.com/pmorelli92/go-word-counter/pull/1) resulting in a 10x speedup from the concurrent code. I would have the script read data as fast as it can in an unbuffered way. If there is a lot of complex processing on the data submit it to a worker process in another thread (two threads). If there is only a little data, do the work in the same thread. [This code is fast enough for most cases](https://github.com/Xeoncross/go-word-counter/blob/master/main.go#L72-L103) If the file is hosted in memory (or any other way that a single CPU core could be exhausted trying to read it fast enough) then look into having 2+ threads reading from bytes X to Y and submitting the data to 1+ worker processes on the other side that do the actual calculations.
I know wget. But this img-dl will download all images from q specific url not download the webpage itself.
&gt; That means that there's no free spots on the buffer ever. Whenever you send a value on such a channel, it will block until there is a receiver ready to receive the value. This is also called a 'synchronous channel'. Sending and receiving always happen simultaneously on it. Here's where my misunderstanding is. I thought an unbuffered channel simply did not have a limit to how large the buffer would get, not that it would default to `1`.
You can add parameters to wget to just grab images. Just saying it's open source so you can look how they did it.
&gt; I am suggesting that implementation of generics will be easy . That's why I ask you to do it. &gt; All am suggesting is we (community) should implement prototype or so proof of concept and present it to committers . This assumes a false dichotomy between "community" and "committers".
If your json objects are one per line, (rather than nested), it should be pretty efficient. Especially if you're not trying to accumulate some large object as a result. I've definitely used it on multi-gigabyte files of calendar events without issue. &amp;#x200B; The go json library does make it easy to parse nested objects, but I haven't explored that just yet. &amp;#x200B; Since I'm reading one "line" at a time, if you have significantly large objects, it could choke on them. I'll make sure I come up with a way to reasonably parse large lists (on a single line). &amp;#x200B; One of the great things about go is that since I use channels internally there is back-pressure if the output is not being read; thus if you piped your output to something like \`head -n 10\` ; jsl wouldn't load the entire file (\[likely only a little more than what is needed for 10 lines of output\]).
Wow, i really like the idea of doing some of this in a repl, being able to tune your functions/filters/etc. Great project!
This is fine if you don‚Äôt need to sanitize input. If you need just a lot of ‚Äúselects‚Äù yeah I can agree 100% but if you need to validate, sanitize and work with input than the choice isn‚Äôt super clear. Thing is that if you have more than 1 dev in project chances are that someone will leave a massive hole in security of your system if you don‚Äôt have automatic systems to sanitize input.
What kind of "sanitization" are you talking about (just sql injection?)
&gt; SQL is an abstraction already. ORM in turn is an abstraction over an abstraction. This really isn't an objection. Just about everything is already an abstraction on an abstraction; eg. Go is an abstraction multiple layers deep
You make it sound like an ORM isn't just using SQL.
For very naive implementations perhaps, but then RESTful won't rescue you either.
At the end of the day, even if you think you're not using an ORM, you probably are. No matter who you are you're most likely putting _some_ level of abstraction between raw SQL queries and your business logic, even if it's just simple stuff like `getUser()` or `updateUser()` utility methods.
This sunny guy is poop tar
An insightful article that shows how to do Let's Encrypt step by step. For the impatient among us there are also ready-mades available, e.g. [mholt/certmagic](https://github.com/mholt/certmagic)
Especially with most ORM library docs being just plain awful (like GORM). For me, it's plain and efficient SQL, with a struct serializer to simplify some work.
thanks i'll check it out
...said Ormlet, prince of Databasemark.
Why do you test for pani? Panic shozld be an abortion case, not a testable point!
And this is related to Go in...?
Sql Injection, malware injection, format validations etc. If you have to wirte every one of this by hand you Linda arƒô burning time that cost a lot of money. It usually is not ‚Äúspeed critical‚Äù to handle user input with orm as people don‚Äôt type that fast. This is my point :) most of my experience points to correct database design and index building as more important in improving speed but if it is just a select that gets hold of some data I would most likely write it by hand.
Fair. That makes sense.
mate why are you posting code as a gif, just take a screenshot of the whole thing or copy paste it as text
Go tends to have fairly large packages, but many files per package. If you have an obvious division between data structures and algorithms, separating them into different packages sounds good. But if that comes at the cost of having to name one of them "types", I'd be very skeptical. If you have no better naming close at hand, I'd just stick them together. (The shorter answer is obviously "it depends"...)
It defaults to 0, but yeah, the point remains. Glad I helped :)
Perhaps it evolved what ORM means, but originally ORM stands for Object Relational Mapping, which is mapping a classes to a tables. If you're not doing that technically that's not ORM. Anyway, what I think what really is needed is a way to be able to use language type checker to also check SQL statements. I think JOOQ (in Java) and LINQ in C# is trying to do that, I don't know how they work since I didn't use them, but I believe they are approaching the problem the right way.
ORM or not, one of the most important things is to isolate your DB code into a separate package that exports abstract methods (\`GetUser()\`, \`UpdateUserEmail()\`, etc) vs scattering SQL/ORM code all throughout your business logic.
care to elaborate why it's awful?
&gt; but originally ORM stands for Object Relational Mapping, which is mapping a classes to a tables. Right, but realistically that's what most people do, even if they think they're not using an ORM. Cycling through rows and columns is tedious, the first thing (good) developers do is make a utility method that maps a query result to some usable domain object with getter methods or whatever your language's equivalent is. You may not be using some generic ORM library that does it all for you, but chances are at a minimum you're not interleaving raw SQL processing in your business logic.
But you need somewhere to run that. It can run on your local machine, sure. But with how cheap it is to run a Lambda function that only wakes up like once a day (read: effectively free), why not run it in a far more reliable environment like AWS?
That‚Äôs like saying ‚ÄúI will use assembler for machine learning since it‚Äôs the abstraction all software is written on‚Äù. Of course I object, SQL knowledge is somewhat portable, while a domain specific ORM is not. You can land jobs knowing only SQL. SQL as an abstraction does it‚Äôs job well, and simply put, all ORMs only generate SQL and exclusively facilitate programmers who either waste time writing CRUD boilerplate, or just don‚Äôt put the effort into database schema/migrations. The only measurable impact an ORM would have, is possibly introducing compile time safety for your queries. That‚Äôs pretty much theoretical from the API signatures I‚Äôve seen, which are basically ‚ÄúFrom(string)‚Äù and ‚ÄúWhere(string)‚Äù, where you‚Äôd just inject SQL fragments. Good good goodgoodgood. If you write your own ‚ÄúUpdate/Replace/Insert(table string, data interface{})‚Äù, which generates the relevant SQL from your struct (which already has database tagged fields), what particular thing do you still need from an ORM? The magic to create/alter your database schema, and properly index and construct your select queries? Which you have to typehint somehow? It‚Äôs exactly the reason why I suggested a database first ORM, if any at all.
Please refrain from using generic titles for posts which have nothing to do with upstream support for generics in Go.
He is probably testing the condition of panic occurs. Better to know program terminated on exception rather than continues in abnormal state.
How do you test for panic? If using standard testing library you probably have defer function with check for recover() right? If you are open to use testify/assert package then you can assert.Panic() in single line.
You have several options: 1 run ES as container on same docker network (most recommended) 2. Run your go container with --network=host 3. Find the machine IP and connect to IP instead of localhost.
I find that small packages is the exact problem and comes from other language mindsets. To me it makes more sense to organise around shared responsibility topics.
You're joking right? I'm sure this has to be a joke. A 56k modem is probably reliable enough for this. You're using a fetish for cloud-technologies, which hurts cloud legitimacy. Elastic infra is good for when you need it. Lamda's to get free automated certs you don't need. EC2 is as reliable, as is pretty much any internet connected machine with a 1990+ connection. Security, availability, access. All reasons what I do is not ideal. Reliability is not a concern for setting a DNS record &amp; issuing several lightweight http calls. Fuck you dont even control the reliability here regardless of who you use. Who put you up to this?
What is a large package to you? &amp;#x200B; To me, 5 or 6 exported methods, plus 8-10 unexported helper methods is like a medium sized package.
I've run into a types or registry package quite often. Many files per package sounds good, like a seperate file for every exported function, and a helpers file for all the unexporteds.
It‚Äôs probably your laptop/workstations IP address or the IP for your docker VM if running on a Mac or Windows.
&gt; Security This is precisely one of the reasons not to fulfill DNS-01 challenges locally. Why would I give my web server the ability to alter my DNS records? That could lead to my entire organization getting compromised - one quick change to MX records and we're done for. Of all of the DNS APIs supported by various ACME clients, only RFC2136 (nsupdate) actually supports restricting an API key to a specific RRSet (_acme-challenge). The rest, including Route53, give you full access to every RRSet. So the community has come up with hacks like [acme-dns](https://github.com/joohoi/acme-dns) or [DNS Alias Mode](https://github.com/Neilpang/acme.sh/wiki/DNS-alias-mode), which require extra infrastructure, *just* to avoid this massive violation of the principle of least privilege. The other reason to do ACME in a "serverless" way is when you have multiple servers who need to use those certificates. Whereas running a local ACME client would mean some complicated file sharing setup, doing this in Lambda+ACM+IAM allows you to sanely pull certificates to your servers on a schedule. This also works great when you're not using AWS for your general compute at all.
That gif is annoying and this thread has no context. Are you just sharing? Do you have a question? Need a review?
It's basically examples, there's almost no documentation around working with relations except for "making a relation"
3. Not using docker
why you decided its spam? its the article featured in U today media. Do not spoil please.
this is fodder for a galaxy brain meme of sharing code
A little late to the party but this is a simple program I wrote to hash files. Could simply drop in a replacement for the actual work function. https://github.com/abraithwaite/stella-artosis
(This is purely based on my experience with Go benchmark, I have no idea how they were implemented. Please correct me if I'm wrong) First, benchmark is running N (10, 100, 1000, 10000, and so on) until the difference between previous and current N is quite big. The definition of quite big may vary. Benchmark library does not know your functions. What they do is run the loop until and compare the start and end time until its big enough. Second, running parallel benchmark with 1 CPU will require context switching, and its have cost. There is more detail about this on https://golang.org/doc/faq#Concurrency
I‚Äôve started doing this and I think it‚Äôs a great pattern üëçüèº Which package owns the types that are returned? Generally in my apps the consuming package will own the type, and will have a bunch of non-DB business logic on it. To keep dependency unidirectional, I define a totally different ‚Äúresponse type‚Äù that belongs to the database package. the consuming package imports both the abstract method as well as the response type.
Panic is part of your public interface. If you are going to do it, it's a valid thing to test for. (I don't toe the "never panic" line. There are times it makes sense.)
[clean architecture](https://medium.com/@hatajoe/clean-architecture-in-go-4030f11ec1b1) is the way I tend to prefer. It helps a lot with circular dependencies and knowing where to put things.
I'm not sure what you mean. I sanitise inputs using this method, both for auto generated code and hand written. Is your concern that when you write the SQL by hand then someone will forget to sanitise an input, while if you use an ORM then that won't happen?
Sounds to me like you need to learn Go database/SQL library and maybe SQL. Your comments are just plain wrong. ORM SQL generation is awful.
I've tested gorm vs. a home grown development tool which creates GO structs directly from database tables. The speed difference is massive. ORM tools are dreadful. We did the same thing in C# completely ditching LINQ because of the same reason. If you know SQL, you cam improve the performance. When you rely on an ORM generating SQL, you have no idea what it is doing. Depending on the tool, you may be able to improve performance...maybe not. You're at the mercy of the ORM.
Yeah I'm currently using Gorm as requested by my boss. Having said that I applied a Clean/DDDish architecture so when the time comes I will swap it up with more barebones implementation. But I do appreciate what they provide.
agreed, they have a fair documentation but not ace.
Usually I'll have a separate package for global domain types (User, etc) which is imported by the DB package and consuming packages.
Very Java-esque , but a good read. I like the structure. Obviously it's way over the top for a small application, but for bigger crud like applications this is definitely a great structure.
For me its really is dependant on the project requirements and therefore the client requirements. Most of the projects I've done pretty much all require REST. Some then want some form of RPC, others also want graphQL. &amp;#x200B; Regarding data intensive app's. I'm currently building a golang based HFT engine that will most like use RPC to talk with different parts of the system as this app is processing a lot of data and very fast. :)
gRPC gives you: * A spec that is actually useful for generating clients and servers * A spec that can provide support for forwards and backwards compatible changes * A more structured metadata pattern * Better connection primitives (http2 by default, bidirectional streaming, concurrent requests over a single connection, long lived connections, client side balancing for when you need it) * Clients can discover how the service is meant to be communicated to (reflection service is awesomesauce, go look at grpccurl) * Generated rest exposure (see gloo or grpc-gateway) * Generated graphql exposure ([https://github.com/google/rejoiner](https://github.com/google/rejoiner)) * Performance improvements even for small payloads * Latency improvements * Size decrease * reduction in cpu consumption Imo start with gRPC and then expose it for external clients however you need to via automation but keep your internal bits gRPC
Damn that sounds awesome. HFT definitely seems like a good use case where you'd need to streamline response times in every way possible. Any more details you can provide on that project? Sounds super interesting.
[removed]
Depends on what you are doing. The questions you asked never concerned me. Sometimes I want a clean separation of a single feature from my main project; sometimes I just put everything in the same place until I have to refactor it.
Proper REST is a godawful mess and really difficult to follow, and you still have to self-document everything and keep the docs maintained, which is a PITA. Improper REST (what most people write, i.e. HTTP endpoints with whatever json feels right) is like python - fast to write and you can mash whatever you want into it and it'll more or less work, but is generally a total mess, no consistency, no way to discover the API, you mostly need to go read to code to know what it's doing. &amp;#x200B; gRPC forces you to define the API in structured documents. Then a generator creates the client and server stubs for you. \*and\* It'll create the stubs in whatever language you like. Someone wants to run python against your gRPC server? No problem. &amp;#x200B; REST is really only good for CRUD, but 100% of apps want to do more than CRUD. What they really want is to run a function on the server, and that's what RPC \*is\*. &amp;#x200B; gRPC \*seems\* like it's harder to set up, but it's really not once you've done it a couple times.
avoiding having to refactor is big motivation
There is a recent project that was posted here right up your alley: https://github.com/graph-gophers/graphql-go
A package should be organized around providing as much as possible of what your caller will need to handle a task or a set of closely related tasks. Consider the net/http package, for instance... It's not broken up among types, helpers, and utilities; it's not broken up between client and server. It's all together, because it's all one set of tasks.
Refactor is how you improve. You should let yourself just try things out.
this is awesome, thanks
nice, thank you. seems like a tame introduction
ORM is for people who can't understand SQL or how relational databases work under the hood.
Yes, I like the stubbing + struct creation for sure. I'm still trying to wrap my head around how the API discovery works, you and one other person mentioned that. And yeah by harder I mostly just meant in relative terms vs. using net/http to spin up a web server in 2 minutes.
Let me introduce you to Swagger...
wow. lots to dig into there
Let me introduce you to an accurate swagger spec Once i find one :|
Thanks for feedback, Honestly I didn't create unit test for WaitPeriod. Yes, lately I'm thinking about RWMutex .. will patch the code later. &amp;#x200B; Currently this library didn't have feature to leave the pool by disconnecting, this will become a feature in the future :+1
Good write-up, please consider using the line tool to draw arrows and use the text area tool to add text.
is this a remote position? what is heroku's interview process like?
Why not just put everything in a single flat file? Because then it becomes impossible to maintain and keep track of. Why not just put everything in individual files, struct by struct, function by function? Because then it becomes impossible to maintain and keep track of. Why not do something in the middle? Because then we don‚Äôt know where that is, and often end up where we started, plus tens to hundreds of hours of refactoring. The short answer is ‚ÄúIt all depends.‚Äù The long answer is ‚ÄúDo what feels right and makes sense. Collaborate. Ask people how they would like the package to be when they are forced to maintain it. Ask yourself what‚Äôs right for the customer, which is how can I ship this code as test-complete, bug-free, performant and sexy as possible.‚Äù It‚Äôs a different answer every time. When I write API client libraries, it‚Äôs completely different from web apps, which end up completely different from data engines, which end up completely different from utility scripts and automation. It. All. Depends.
Discovery is mostly - has a concrete definition that is separate from the code. I mean, there's also reflection, since grpc servers are self describing. But that's not what I was talking about.
Woah, how did this get there
Yes, the team is 80% distributed. Folks are partnered with an internal recruiter who walks you through the interview process, starting with a conversation with an engineering manager.
But how does it continue after a panic? Only if you recover from the panic! Don't recover, let it die!
That's really awesome! I'm definitely applying for the position in the morning üòÅ
Well, it's limited remote: &gt; Candidates may be local or remote, but must be in a US-friendly timezone.
Any chance some of it is public?
No.
US-friendly timezones? I guess central Europe doesn't fall under that?
iirc (I‚Äôm on my phone), must be able to work an 8-hour block between 6am and 6pm PST. Basically, needs to be able to have some synchronous communication with the team.
Is this more or less a Go question? Are ORMs in other languages more useful? I feel it really depends.
GORM is dreadful. ORMs do not need to be. Of course, if your code is properly abstracted you can switch between using SQL and ORM tools where appropriate. It need not be, nor should it be, an either/or choice.
If it's okay with the thread owner, I would like to ask for another side. What are the use cases where it would be better to use REST compared to gRPC?
What about security roles? Remote available?
After trying gRPC I will NEVER go back to REST. If I were writing any API (even for front end consumption) I would write it all in gRPC. I highly suggest trying a real world example in gRPC and REST. The moment you make a change or create client libraries in different languages is the moment you will realize how asinine and time wasting REST is. REST is the worst fucking game of telephone ever. "I'm going to write a server based on what I THINK the contract is (swagger doc), then you can write a client based on what YOU think the contract is". Two machines are communicating...they should have a clear contract with strong types, and autogenerated server and client code, so changes can be propagated as quickly as possible without a human trying to parse another document written by a human to understand how to write their code. But the real stupidity of REST lies in its "beautiful and simple layer of abstraction". Should data be in the HTTP header? The URL path parameter? A query parameter? Or maybe the body? What should the URL be for something that's not an obvious CRUD operation? Should it be a POST or a PUT? What if I want to stream data? Which of the generic 4 verbs should I be forced to use to define what has always been a damn function call with input and output? I know I sound salty, but it really does drive me insane.
Start in gRPC and add REST on top. This will generate the REST proxy and even will generate a swagger spec: https://grpc-ecosystem.github.io/grpc-gateway/docs/usage.html The proxy it generates is go code. In the same server app you can listen for gRPC on one port and REST/JSON on another port. There is probably a way to mux both servers onto the same port but I haven‚Äôt looked into it. It‚Äôs also worth looking at Envoy‚Äôs gRPC-JSON filter: https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/grpc
Any recommendations on articles to read or get up to speed for using grpc?
thanks :)
Huge shoutout to grpc gateway. It provides a RESTful interface for all your gRPC requests for clients that can‚Äôt utilize it directly. It‚Äôll even, if I‚Äôm remembering correctly, provide streaming via web sockets. It‚Äôs really an awesome feature that makes going forward with gRPC a much easier decision.
I recommend * [Alan Shreves](https://twitter.com/inconshreveable) Gophercon talk [grpc: From Tutorial to Production](https://www.youtube.com/watch?v=7FZ6ZyzGex0) * [Johan Brandhorts](https://twitter.com/JohanBrandhorst) [blog](https://jbrandhorst.com/) * [SRE your gRPC](https://www.youtube.com/watch?v=eoy9z0UlaII) by [Grainne Sheerin](https://twitter.com/sre_grain) and [Gabe Krabbe](https://twitter.com/krabbe) * This [article looks good](https://blog.lelonek.me/a-brief-introduction-to-grpc-in-go-e66e596fe244) by [Kamil Lelonek](https://twitter.com/KamilLelonek) * the [upstream quickstart](https://grpc.io/docs/quickstart/go/) * the [godoc](https://godoc.org/google.golang.org/grpc) * #grpc on the gophers slack because you can pester Johan and many others with questions (please don't pester him directly just ask in the channel) and if you want to dig into gRPC client side balancing there is this totally crappy post that I really should finish part 2 of one day https://kca.id.au/post/k8s_service/
This is excellent thank you! I know what I‚Äôll be reading at the airport this week.
Oooh you totally want to look at [gloo.io](gloo.io) as well. so much ZOMGness
Well if you want Airport reading you should get the SRE books on to your list as well. :P
These two articles are great at discussing the various high-level differences and tradeoffs between RPC and REST(ish) APIs: - https://www.smashingmagazine.com/2016/09/understanding-rest-and-rpc-for-http-apis/ - https://phil.tech/api/2017/04/18/you-might-not-need-graphql/ As far as RPC frameworks go, you might want to look into [Twirp](https://blog.twitch.tv/twirp-a-sweet-new-rpc-framework-for-go-5f2febbf35f). I'll confess I have only used JSON-RPC before (as an experiment).
&gt; iirc (I‚Äôm on my phone), must be able to work an 8-hour block between 6am and 6pm PST. *u…ê·¥âl…ê…π ásn…ê u·¥â  élp…ês s ûool*
For test scenarios I would assume there is recover as assert for not nil. Seems perfectly fine for testing to me. This is not production run but test.
I put everything into one package until it becomes obvious that parts of it need to be broken out. Packages are bigger than classes in other languages, and I have packages with nearly 100 exported methods that are still coherent and useful. Generally I separate code into packages by area of responsibility. Having said that, I've used a "models" package in my latest project that contains all the structs &amp; interfaces that the rest of the system relies on, so everything imports the models package, and models imports nothing. It seems to work OK, and it's nice having somewhere I can dump everything. If you have a "utilities" package then I'd suggest you're breaking things apart too much - things that need to share a function are often related and would benefit from being associated.
You might be interested in this: Principal/Lead Platform Security Engineer - Remote (Americas) https://www.heroku.com/careers/principallead-platform-security-engineer-17
oh man -- i'd love to work @ heroku.
But this is the main problem with ORMs - they treat the database as a persistence layer for code objects, rather than the place where the data lives. It creates really bad database performance. In old-school 3-tier architecture terms, each tier of the application needs different data structures. The UI needs structures with lots of descriptive information for the user, the business layer is more interested in capabilities (things like roles and permissions), and the database is more interested in relations between entities. If you think about it for 10 seconds, it's obvious that how the data needs to be structured for efficient storage is nothing like how it needs to be presented to the user. Trying to create a single object for each entity that serves all the purposes of the entire system results in massive code objects that take forever to load from the database, and the tendency to manipulate them in code. Manipulating data in code is stupid, because when you're done you have to load it back into the database. The data lives in the database. It's not just stored there, that's where it lives. If you're going to change the data, use SQL to tell the database what to change. Fetch only the minimum amount of data needed to make a decision, then throw it away and feed the decision back to SQL. Use SQL functions and views to get the database to do the heavy lifting of managing the data. For example; I have "display views" that match what the UI needs to have to function. Loading data into the UI is a matter of running a \`select \* from vw\_documents where user\_id = $1::uuid\` and passing the result to the UI. All the logic for "what documents can this user see?" and "what data does the UI need for each document?" is in the SQL for the view. Complex substructures are handled with array and json fields. I can make this nice and quick by tweaking the SQL to get the query efficient, or in the extreme cases, materialising the view. Anyway, /rant over. tldr; Creating a false correlation between code objects and database tables is a terrible thing to do.
id love to work with golang professionally. day job as android dev at the minute.
Use ‚Äògo build‚Äô instead of install
I‚Äôm based on the Australian east coast. Heroku is a dream employer. If I‚Äôm willing to work during those hours, would Heroku discount me because it‚Äôd be a ‚Äúnight shift‚Äù in Australia?
Yeah that‚Äôs what I mean, that kind of detail should be in fields, and error messages should be low cardinality ideally for analytics / indexing. Probably won‚Äôt happen now though it‚Äôs sort of a breaking change üòë
&gt;I've run into a types or registry package quite often. If you're building a package to define a wire protocol, sure. But have a look at the standard library. Even "container" is not a package on its own, it's just a prefix for other packages. It shouldn't be your first choice. There are many libraries with (IMHO) poor style, so "running into it" is easy. I think you are asking what the idiomatic way is, and looking at the standard library is better when possible.
That‚Äôs a tiny package. Minuscule even. I‚Äôd put the line for large at so many exported symbols that godoc index doesn‚Äôt fit on my screen.
I've worked at Heroku in the past. It's a great place to work. They really love Go there.
Having a us friendly time zone doesn‚Äôt really make sense. Western Europe can be considered us friendly but not for people that work in the west coast.
How can I go about applying?
I wouldn't put everything together in a "models" package. It's safer to have a package represent a single bit of responsibility. Its types and methods are only used for the responsibility the package carries. If you're putting everything in one basket, you risk using a method or type for different use cases, each with their own responsibility. You can't easily alter something without having to consider all the relying use cases that might break because of it. This is the main idea behind "clean architecture".
If you‚Äôre doing this ‚Äî and I like it! ‚Äî why not take the logical next step and implement those as stored procedures in the DB? With this done, you should be able to create DB access roles that only grant access to specific sets of relevant tasks, rather than attempting to _approximate_ granular access with combinations of SELECT, INSERT, etc.
Alright, I think I get the idea. I will have to write my own functions then
I'm not sure what you mean. If you have embedded structs in Go, the encoding/json package will already serialize the struct members into the same level as the encapsulating struct: https://play.golang.org/p/nkX0dSdvtHE
Aussie East coast go crew reporting in
Because a package can spanany files, I tend to not count it in terms of number of exported symbols. I just think about whether everything shares the same responsibility. I would be more inclined to split into files based on the number of functions and types.
* Log as close to the error as possible * Assume this pattern for all _your_ code * Assume nothing from dependencies If you‚Äôre dealing with ephemeral things like requests, it‚Äôs ok to use the context to stash the logger and pass it along, as long as you recognize you‚Äôre responsible for memory and concurrency safety.
I wouldn't put an individual function in each file. I tend to organise packages by domain, and then it's just a tree of sub-domains within that. Files might be very precise sub-domains, or simply named after the package. The standard library does it a similar way. For example, here's a snapshot of some parts of the encoding domain package: encoding/ base64/ base64.go csv/ reader.go writer.go gob/ debug.go decode.go encode.go error.go json/ decode.go encode.go fold.go tags.go The same sort of patterns are used there. Base64 is quite straightforward compared to the rest, so it has a single file (that's not a test), named after the package itself. CSV isn't super complex, but the concept of a Reader and Writer make sense to be split into separate files. This would equally work as one file though probably. JSON and Gob are much more complex, and have many more files, including sub-domains like debugging, error handling, or handling things like struct tags, etc. The key takeaway I have from this kind of structure is that it's all domain focused. How it may be split is subjective, but even with the different approaches here, it's not difficult to find something you want.
I've [commented elsewhere](https://www.reddit.com/r/golang/comments/br03d4/should_i_use_struct_oriented_file_structure_or/eob88vi/) here, but just to put one at the top-level; I'd organise packages by domain, similar to the standard library. Package sizes can very depending on complexity, and that's fine.
says "US remote". does this mean only US-only, or just that the HQ is based in the US?
Wow! Never seen rejoiner before - that looks fantastic. Will have to give it a try with Kotlin later today.
These are probably questions to ask the recruiter, as I don‚Äôt speak for Heroku and I‚Äôm in the engineering department!
How was the HackerRank portion of it?
I'm currently happy with my job. I just wanted to let yall know that you have the best goddamn socks.
I guess this wouldn't work for someone in Nigeria ?
What's your experience with browser compatibility? Last I checked, it didn't seem so good and there were multiple implementations. I'm quite afraid of unsupported libraries.
They‚Äôre my favorite Heroku swag too! I believe we‚Äôre on socks version 3; 2 is my favorite design so far.
in principle yes, but it is possible to mutate strings in-place using the unsafe package. so if someone really *really* wanted to write a version of ToLower with optimized allocations, they could. but the standard library is right to not do this.
What about people who are willing to move to the US? Is there a possibility?
You could work like the golang std log package. It defines public methods to use (Info, Warn, Error...) that you can call from anywhere (log.Info(..)). You can define your own log package wrapping around Zap that offers the required public methods. If Zap needs special config, you can do so in the main() routine with a log package global "Init(cfg)" method. At least that's how I've introduced zerolog to my services. Pro's: * Easy to introduce, as it's just like using the std logger * You can log in the function where it happens, without having to pass the logger as a function parameter everywhere (or pass it through context) Con's: * You can't inject loggers at specific parts in your code.
yeah, I get that, but man having all the complex types in one package sure does solve all those circular import problems ;)
The reason I like to put exported functions in their own files is that, those are the functions people are most likely to look up. So they come across store.Persist(), and they can directly see a "Persist" file in the "storage" directory, and go right to it.
The reason I made this post was because I took a look at a project and said, sigh, another refactor. Shoulda did right from the start.
I didn't even know there were different versions! I have the argyle ones, but now I'm google image-searching "heroku socks" and they all look great :-)
I‚Äôd be interested but stuck doing go now
That makes sense in a way, but it doesn't sound like it'd scale well in larger packages. If I'm going to really dig into some code I'll just use my IDE anyway so I'll be able to find the function no matter what the file name is. Of course, that's different on something like GitHub but it seems like you're swapping one problem for another there, along with fragmenting your domain.
That's every project, 6 month down the road. You never could did right from the start because you didn't have the experience of making and using it. The best part of Go's simplicity and type safety is how easy it is to refactor. Also, learn to write code that's easy to refactor.
You can add a monitoring system like Prometheus. [https://prometheus.io/docs/guides/go-application/](https://prometheus.io/docs/guides/go-application/)
It feels like a lot of extra work, but we are just making a new file then pasting a function in it. How I do react looks something like this, but maybe for backend it is unnecessary.
The [Go Swagger codegen](https://github.com/go-swagger/go-swagger) isn't the best - you can't differentiate a missing optional field from its 0ish value. That's a non-starter for me.
The toughest part of about gRPC is learning it because it's something other than REST, which has been hammered into us ever since we started web dev. &amp;#x200B; It'll take time to wrap your head around what RPC is and then what Google's implementation of it is. &amp;#x200B; When my buddy advocated for gRPC, my first thought was..... why learn another new technology when REST is good enough? He said just try it so I did. Now I'm a better dev for it and can use either depending on the situation.
[removed]
&gt; &gt; Security &gt; This is precisely one of the reasons not to fulfill DNS-01 challenges locally. I know, I said the same above. &gt; &gt; Security, availability, access. All reasons what I do is not ideal. You then go on to make an assumption. &gt; Why would I give my web server the ability to alter my DNS records? I don't know. I've not allowed a web-server to alter DNS records, nor advocated for it. I wonder where you got that from? Perhaps pre-DNS or old DNS based auth required this. &gt; Of all of the DNS APIs supported by various ACME clients, only RFC2136 (nsupdate) actually supports restricting an API key to a specific RRSet (_acme-challenge). The rest, including Route53, give you full access to every RRSet. Honestly I don't know what an RRSet is. I can absolutely restrict Route53 access for an IAM role, which is how I implement principle of least privilege. I've no idea what you do, but it sounds very involved. My setup is creation of an IAM with credentials for specific AWS services and resources. &gt; the community has come up with hacks like acme-dns or DNS Alias Mode, which require extra infrastructure, just to avoid this massive violation of the principle of least privilege. No clue what those are I'm afraid. I have not needed to invent anything. I merely picked a tool that allows me to DNS challenge using a range of providers. Installation and deployment of secrets are a separate thing, but this works for me. &gt; The other reason to do ACME in a "serverless" way is when you have multiple servers who need to use those certificates. ??? You don't need serverless to get that benefit. What it may get you is improved connectivity to your services if you use the same provider. &gt; Lambda+ACM+IAM allows you to sanely pull certificates to your servers on a schedule, without unnecessary credential exposure in the wrong places. I've not said not to use ACM, although I will admit I've not advocated for coupling to them as the only source of the services they provide. Most are capable of locating and setting up alternatives. &gt; This also works great when you're not using AWS for your general compute at all. I'd be interested in reading about that. We use cloudfoundry at work and maintain CredHub + ACM + LastPass. It's a fragmented mess. Personally and outside of work (what I've discussed here), I don't treat certs as secrets. I have a revoke button, they are stored encrypted and only transmitted, issued, received encrypted. If someone gets through a hole, hopefully I have enough visibility to reverse that process, but nonetheless I can invalidate &amp; replace the cert very swiftly.
There are a lot of examples of rest and grpc examples in github, but can anyone on this thread point me to great real-world, in-production, enterprise-level examples that are out there, a la [awesome-go](https://github.com/avelino/awesome-go)?
That's a problem with gRPC as well... v3 removed support for optional fields.
IMO: Neither. Structure packages about concerns, not individual types or whatever. e.g. I have a package for logging, for logical time stamps, for filesystem-abstraction, for authentication, for the persistence logic, for the RPC server‚Ä¶ each containing a mix of types and functions specific to that concern. If you look at [the stdlib](https://golang.org/pkg/), that's how it's organized too. There is one package concerned with http, containing a bunch of types and functions. There is one package concerned with json. There is one package concerned with TLS. There is no "types" package and there is also no "utilities" package.
I think you have a false dichotomy. The correct way to think about it is Hexagonal Architecture or Clean Code. Building something isn't the hard part, building something that is maintainable is the hard part. A more modular system is going to be more maintainable, so where you draw the "dotted lines" between modules is super important. &amp;#x200B; For example, let's say I'm writing a program that uses a central a "configuration" struct, and it needs to be initialized with a JSON file. My first impulse will be to write a method that takes in a filename, reads that file, decodes the JSON and returns a struct. Boom, done. It's literally about 3 lines of code. It looks fine. It works fine. &amp;#x200B; But in reality, I've drawn the line in the wrong place, and will have problems later: * The code is basically impossible to test (Maybe with some intrusive mocking, or rewrite to allow injecting an OS interface). * The code is inflexible (What if I want to read my config from the network? That literally has no bearing on the items in my config struct.) * Maybe you want to turn the code into a library, and you need a way to "set configuration" without creating a file. * Maybe someday you want to run this on an embedded system that literally doesn't have a filesystem. &amp;#x200B; Ideally, the config struct should never depend on external systems. The filesystem is bad, because it's stateful. Relying on JSON is much less of a problem, because it's a stateless function. &amp;#x200B; So a better solution is to have a "JsonToStruct" method that takes a string and returns a config struct. Move the code for "reading config file" into a different module. (Yes, even if it's literally one line of code!) For a quick hack you can put that code in main. But really it should be in it's own module with a routine that takes an OS interface, so that we can test all the corner cases. Because it takes a filename + OS file interface, and returns a string, it's easy to write tests: does it print the right error messages when the file is not found? when empty? when not readable? etc.
Considering how far they got in fixing some major issues (automatic client library generation!!!) it's interesting that they didn't address two major issues with REST: - Timeouts: connect, first message, between last message sent/received? (hung client or server) - Load balancer / Proxy built-in? gRPC also introduces a few issues that REST doesn't have with my biggest concerns being: - No native browser support (Javascript) - Need better structured error handling (or something like errors.Wrap())
This post indicates nothing about the salaries they're paying
I'm sorry but the technology world revolves on Pacific Time. If you want to work for the big companies and make the best money this is the way
If you are saying that file structure is not the most important aspect of maintainability, I agree with you. As a newbie I am just looking for ways of architecting an app different from the low hanging fruit I've come up so far.
Yes, there is. &amp;#x200B; Discord Gophers [https://discord.gg/0f1SbxBZjYq9jLBk](https://discord.gg/0f1SbxBZjYq9jLBk) &amp;#x200B; Also listed on the [https://golang.org/help/](https://golang.org/help/) page, among other resources you might find useful.
I am saying that file structure is important. I.e. trivial things (3 lines of code that read a file and decode JSON) may need to be broken up into different files for the sake of maintainability/testability. &gt; As a newbie I am just looking for ways of architecting an app Yes, instead of thinking "bottom up" (I have this code, where am I going to put it?), you have to think top down (what is the essence of this code? What should it do? What should it NOT do?) It's quite a bit of work to 'tease apart' all the different bits of work and try to organize them in piles. There is no single "correct" answer, everything is just a series of trade-offs. Test-ability is a very good one to steer by. But also drawing out your dependency graph. Should my "config struct" depend on the entire OS module, or can we think of a simple way to eliminate that? And on a higher level (see Hex arch), you want **"input/output modules"** (that do the minimum amount to talk to external systems, such as "lookup single customer"), **"business logic modules"** (that have the business rules, such as "customer must have an address") and some glue code to hold it all together. The business logic is trivial to test, because it should never depend on any external system. The glue logic is easy to test if you give it dummy interfaces for all the I/O modules it needs. The I/O logic can be hard to test, but it tends to be trivial and stay working once it works. (i.e. it shouldn't have any logic, shouldn't make any decisions. Just translate "getCustmer()" into a SELECT statement. But to ensure the biz code doesn't depend on the DB code, you need to make the Customer struct into it's own module that depends on nothing.
If you are willing to use Slack, there is a Gopher's Slack that has over 40k gophers atm. Link to invite: [https://invite.slack.golangbridge.org/](https://invite.slack.golangbridge.org/)
I see the Go Playground as a test for some simple function. To work with several files, I would open VIM (or IDE) and create a test polygon, eg \~/go/src/tst/dirpolygon. I think it's more practical.
For anyone having troubles with this issue, I've found that there are two libraries that can be used to make using neo4j and go more pleasurable. The first one is [structs](https://github.com/fatih/structs), and the second one is [mapstructure](https://github.com/mitchellh/mapstructure). &amp;#x200B; Structs is used to basically convert a struct to a map\[string\]interface{} and mapstructure is used to convert a map\[string\]interface{} to a struct. &amp;#x200B; Here is an example of both of them being used. type User struct { ID string `structs:"id,omitempty"` Created string `structs:"created,omitempty"` Updated string `structs:"updated,omitempty"` Email string `structs:"email,omitempty"` FirstName string `structs:"firstName,omitempty"` LastName string `structs:"lastName,omitempty"` Password string `structs:"password,omitempty"` } // Create user and return the created user func CreateUser(newUser User) (User, error) { session, err := graph.Driver.Session(neo4j.AccessModeWrite) if err != nil { return User{}, err } defer session.Close() cypher := `CREATE(user:User) SET user = $prop RETURN user` result, err := session.Run(cypher, map[string]interface{}{ "prop": structs.Map(newUser), }) if err != nil { return User{}, err } user := User{} for result.Next() { record := result.Record() if value, ok := record.Get("user"); ok { node := value.(neo4j.Node) props := node.Props() err := mapstructure.Decode(props, &amp;user) if err != nil { return User{}, err } } } if err = result.Err(); err != nil { return User{}, err } _, err = result.Summary() if err != nil { return User{}, err } return user, nil } // Get many users func GetAllUsers() []User { session, err := graph.Driver.Session(neo4j.AccessModeWrite) if err != nil { return nil } defer session.Close() cypher := `MATCH(users:User) RETURN users` result, err := session.Run(cypher, map[string]interface{}{}) if err != nil { return nil } var user []User for result.Next() { record := result.Record() if value, ok := record.Get("users"); ok { node := value.(neo4j.Node) props := node.Props() user := User{} err := mapstructure.Decode(props, &amp;user) if err != nil { return nil } users = append(users, user) } } if err = result.Err(); err != nil { return nil } _, err = result.Summary() if err != nil { return nil } return users }
Thanks!!
Thanks!!
You're welcome. :)
You're welcome :)
Thou shalt not covet thy neighbor's programming language
Sorry if it's obvious but what's a test polygon?
+1 to the Discord for Golang, much more relaxed atmosphere with super helpful people. And not just for Go üòä
See also the [expvar](https://golang.org/pkg/expvar/) package in the standard library. It lets you expose your vars, and other programs can come along and scrape the values. &amp;#x200B; Prometheus is the right tool for storing metrics in large scale systems. But if you are smaller, you can look at all the backends supported by [Grafana](https://grafana.com/). (Large or small, Grafana is the right tool to view metrics. In fact, it supports graphs that pull from many backends simultaneously.)
You don‚Äôt have to be sorry lol especially when you don‚Äôt mean it.
Heroku is a great place to work, and Hunter is great! You should join this team.
or ... ORM is for people with deadlines
How much Go is used internally at Heroku now? IIRC it used to be mostly Ruby.
Here's an example of a package that is too large... [https://godoc.org/github.com/olivere/elastic](https://godoc.org/github.com/olivere/elastic)
F\*ck, I just realized I used REST without stopping to think if it was the right decision... Usually it works well - but this time its \*another\* person writing the frontend, and I lost a lot of time explaining to him how to use the API...
This question has little to do with Go, and is probably better to post in /r/elasticsearch. It looks like you don't want to use \`NewMatchQuery\`, because it will always insert a \`query\`: [https://github.com/olivere/elastic/blob/release-branch.v7/search\_queries\_match.go#L146](https://github.com/olivere/elastic/blob/release-branch.v7/search_queries_match.go#L146) There is a fallback: [https://github.com/olivere/elastic/blob/release-branch.v7/search\_queries\_raw\_string.go#L22](https://github.com/olivere/elastic/blob/release-branch.v7/search_queries_raw_string.go#L22)
Definitely interesting, thanks!
We have Splunk, so that part is going to be used mostly for debugging the application, not per say for metrics at the moment. I'm in the process of making the logs have proper k-v pairs so that would be easier down the road to do that.
Go is now used *significantly* within Heroku, and more every day.
&gt; Timeouts: connect, first message, between last message sent/received? (hung client or server) Timeouts work well. you just set a context timeout on the message call. this gets more fun with streaming connections but you can get other stuff &gt; Load balancer / Proxy support for scaling Wat? decent LBs work fine with grpc. &gt; No native browser support (Javascript) Use a gateway so you can keep a decent spec internally because limiting to just what web clients can do instead of supporting both is painful &gt; Need better structured error handling (or something like errors.Wrap()) +1
SOAP (wsdl on) -&gt; REST (wsdl off) -&gt; gRPC (wsdl on) -&gt; ??? (wsdl off)...
Log the problems where they happen, put loggers in as members of your structs, and correctly use composition in your design such that you're passing the logging value to far fewer places than you probably expect. If you have an "environment" or "config" object for bits and pieces of your code base, you can compose these things together easily as you go, and the logger goes with them. It'll take a few swings at it to get it right, but the result is pretty powerful.
jq reads the whole toplevel object into a dict (equivalent to unpacking to a \`map\[string\\interface{}\` in Go). That makes it slow compared to anything which extracts only the needed fields. I got tired of jq's slowness and wrote a pre-filter in Go which extracts the fields I need\[1\]. Then if I need fancier filtering and manipulations I feed that much smaller data to jq. &amp;#x200B; \[1\] [https://github.com/nsd20463/gjq](https://github.com/nsd20463/gjq)
Why wouldn't they just be looking at the godoc which links them to exactly the file and line number?
\&gt; gRPC \*seems\* like it's harder to set up, but it's really not once you've done it a couple times. Just to clarify: are you talking about simpler, "monolithic" servers as well?
Timeouts only work on the TOTAL call time if I remember right. As you mentioned, this is hard with streams as there is no concept of "_drop clients who are slow to consume the stream_". &gt; decent LBs work fine with grpc. Which LB's are you talking about? I was looking for good transparent support for gRPC.
That's a bad approach (except for small projects) and I believe this blog post is misguided. The main reason is coupling - you want to avoid coupling between different "things" within the same layer. There is no reason to make them visible to each other. Simon Brown has some nice presentations about this for bigger applications, e.g.: https://youtu.be/5OjqD-ow8GE?t=725 But of course, as usual, "it depends".
While the other comments are very good, they're definitely overkill if you're just looking for one stat on a small API. You can easily create a simple concurrency-safe counter using [sync/atomic](https://gobyexample.com/atomic-counters).
yeah streams are the painful part of timeouts. but iirc you can reset the context for every message sent preventing it from timing out. On LBs: anything envoy based will handle grpc just fine. Traefik will also do it. newer versions of nginx are not garbage with handling it (still meh from their reload behaviour but hey) linkerd(|2) also does decent grpc iirc. Even haproxy is finally adding support for grpc iirc the gcp http loadbalancer does proper http2 and can support grpc. The elephant in the room though is aws. ALBs are problematic as they only support http2 on the front end. yay useful :( ELBs and NLBs can handle grpc but lose all loadbalancing functionality and just spread connections
I so name for myself projects in which I test a functional. If Vim is just a folder, and if Goland is a separate project.
That looks like the right approach. It's indeed nice to have the logger in a config struct. Thanks!
HFT in Go? This is some kind of personal/learning project?
Overhead of gRPC is not acceptable in real world HFT systems, Go also.
I recommend you zerolog
You probably want something like this: ``` client.Search().Query(NewMatchQuery("client", "android") ``` https://github.com/olivere/elastic/wiki/Search
Magic.
At least you get to ride kangaroos to work.
Starting with grpc is a good way to work as you define contracts all the clients can use without having to write a bunch of code. if for some reason you want to add in json support you can just use a separate server to convert the rrquests and [https://github.com/grpc-ecosystem/grpc-gateway](https://github.com/grpc-ecosystem/grpc-gateway)
I use slack usually for any programming related discussions. Member of gophers kubernetes and many more groups there. Never used discord but heard it is more like a gamer kind of platform. What is the difference or advantage of discord?
There's Go System's Programming from Mihalis Tsoukalos, a good overview with interesting/useful parts concerning IPC, signals, socket. I also suggest the talk from Korchagin about Go as scripting language in Linux
Is this even a thing? Serious question. I thought there was a reason most system level is done in C. Maybe Rust would work instead.
Go is not a good tool for writing low level software such as OS. Go with C (pun intended) ;)
[https://www.reddit.com/r/golang/comments/71j5go/can\_you\_write\_an\_os\_kernel\_in\_go/](https://www.reddit.com/r/golang/comments/71j5go/can_you_write_an_os_kernel_in_go/)
[removed]
I agree, but I tend to prefer log funcs to loggers (`func(string, ...interface{})`). They're easy to stub out in unit tests and they don't couple your struct's logging to any particular log implementation.
Something I've been concerned with is that the log entries are almost useless when you do deep logging because you lose the "why". It also goes against the single responsibility principle. Should these functions do two jobs, process data and send logs out on what it did. I like to have layers in my apps where logging happens where you know the "why" along with the "what". This removes having to transfer the logger all over the place. Why example: User requested to see an order. What example: Order was not found.
[removed]
You can checkout grpc-web or grpc-gateway to make it easier for front ends to consume the data.
Yes there should be the basic error and a why wrapper for the error. Zap also has a stacktrace so it's good to log deeply as soon as you have the why and the what. But passing the logger as a parameter (wether global or not) sucks indeed.
I'll always take a machine contract over a human contract any day üôÇ
It's not much of a thing, since Go really isn't suited for stuff like that (although there is Gopher OS, but it's nice more of a novelty) since it has a runtime. It's certainly possible, just not something you'd really want to do
https://github.com/google/gvisor They‚Äôve got performance issues but that‚Äôs because they are (were?) using ptrace. Still, it‚Äôs a full kernel. Last I looked, the even had a user space tcp implementation. In go :-).
Or, better yet, Rust.
As a temporary fix, set `$GO111MODULES=on` and put all your code in `$GOPATH` and it should more or less work. That's what I do to keep local godoc working.
Know any good guides on low-level stuff with Rust? Would be nice to get into Rust that way.
I just finished the official Rust book and it's really good. It can be a bit handholdy at times but I actually enjoy it as it's pretty thorough. It's free online. I would recommend starting there. Sorry I'm on my phone or I would link it. A quick Google search and it will come up.
I haven't had any trouble using VS Code with modules. I'm using Go 1.12.4 at the moment. I do think I had to let the Go tool run its tool updates, and it switched itself over to the new Go language server when it ran them. To my it runs better than it used to, but I have had hiccups with updates where I have needed to open the command palate and reinstall the tools via the Go command. I didn't change any settings, though, as the plugin seems to have fine settings for me, and 1.12+ supports Go modules without the env flag.
absolutely correct - I apologise! It was an attempt to give an example of the type of thing `retool` is used for written in haste (i.e. binary tools that aren't build dependencies but are required to build your application). I have however definitely used `retool` for `dep` (when that was more of a thing), and `go-bindata` via `//go:generate` tags, and it's worked well across a team to ensure we are using the same versions of these binary tools which can't and shouldn't be specified as dependencies in either `dep` or `go mod` config files.
You may not have seen this as this is a fairly recent update, but now that \`gopls\` is a thing we have, take a look at this documentation here: [https://github.com/Microsoft/vscode-go/wiki/Go-modules-support-in-Visual-Studio-Code](https://github.com/Microsoft/vscode-go/wiki/Go-modules-support-in-Visual-Studio-Code). Has worked fairly well for me in VSCode.
I would call Docker a success.
you only need to set those things if using an older version of the extension, so I avoided setting them and use the language server fine now
There‚Äôs a ‚ÄúWriting an operating system in Rust‚Äù series that seems to be very popular.
so https://github.com/moovweb/gvm?
Brilliant, thanks! I've seen a few articles reference "Go: Install/Update Tools" as if it's an action to be performed. I'm a VSCode noob; do you know where I can find that?
Phil Oppermann's blog: https://os.phil-opp.com/
Docker and kubernetes are the lowest level I know Go is can go. I wouldn't say those are super low level either since the guys at docker were originally going to use Python.
Link to "Writing an OS in Rust" [https://os.phil-opp.com/](https://os.phil-opp.com/)
Suuuuuprise
Discord has voice chat rooms, which is an advantage for gaming but not discussions
Docker and kubernetes are the lowest level I know Go goes. I wouldn't say those are super low level either since the guys at docker were originally going to use Python instead of Go. The guys at a google conference said that they used Golang for mainly large scale scripts and cloud. I didn't hear any of them say "writing drivers for android" or anything of the low level stuff. If I wanted to get even lower level, then I would just go to C++.