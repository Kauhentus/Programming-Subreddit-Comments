&gt; Using CPAN is easy. ...It is easy to automate, had a web client, and had a command line client. "had"?
Could you be more specific on point 2. I won't want to write which part myself? Any examples of something I could grab? Thanks!
Python especially seems overzealous, but I think a lot of that has to do with searching for packages., eg: [classifiers](https://pypi.python.org/pypi?%3Aaction=list_classifiers)
I agree. I was completely confused about how to properly version my releases so others could hook into particular versions. The most sensible solution to me was [gopkg.in](http://labix.org/gopkg.in). I feel like all `go get` would have to do is have an API for tags: github.com/&lt;name&gt;/&lt;package&gt;#v1.0.0, as well as a way to import those tags in the source as well -- possibly through a config file.
The benchmark was with Go 1.3 or 1.4 some time ago, it will be rerun with 1.5 said the author.
Sorry I'm not referring to limiting the total number of goroutines. Instead think of the number of goroutines that are required to service each user. Lets have a hypothetical application that has the following goroutines that are spun up each time the user connects: 1. Receive the data from the user 2. Send the data to the user 3. Send data to the backend 4. Monitor something for the user 5. Monitor something else for the user So in this hypothetical setup we have five goroutines per user. Thats 500k goroutines to serve 100k users. If we could combine goroutine 4 and 5 we could reduce our total goroutines by 100k.
yeah, and I've used the classifiers precisely 0 times to ever find anything. Usually a Google search for &lt;language name&gt; &lt;thing I want to do&gt; is more productive.
Really happy to see this. It is good authorization is in the plan. For me that is where this gets really interesting. Once it is in place it will be a great reference for application developers to build them around this. Even if they don't use it initially. It will make it easy for them to integrate them later. Problem now is we do not have such a reference and authorization is done as an after thought and rushed.
This is how I'm handling errors, but I admit I'm new at go lang.
If you're going to use RethinkDB it will be doing most of the work for you. Each go server can be stateless. You can round-robin DNS the servers, or have a front-end that redirects. (like www.example.com -&gt; chat-001.example.com) If you build the front-end such that it can auto-reconnect you won't need to do much for failure, just kick bad servers out of the pool. So you will have: * 1 or more frontend, traditional http servers servicing your normal application * a bunch of chat http servers which basically proxy requests to RethinkDB * a bunch of RethinkDB servers You could save money by rolling your own, but obviously that's a lot harder. Redis might be an alternative to RethinkDB worth investigating. (BLPOP and BRPOP with a bunch of lists)
The multiserver message processor. Grab one of the mentioned software programs and build on those.
Rust doesn't need to be mentioned in every Go context.
So, first, you can read the source. Go source code is _very_ easy to read. Especially if you're coming from C++ or a language like Python where the base source for the language is very strange-looking C, the vast bulk of Go is quite readable. You can look up what errors it produces. And this is where "returning errors" as the error-handling strategy comes in useful... exceptions can't hide, so it suffices to simply examine the target function, not the complete transitive closure of everything it calls, which isn't even necessarily possible if an interface value is used. In this case, I suspect you're likely to discover that the only way that can fail is for `cfg` to be of a type that will fail. If you are always passing in the same type (i.e., it's not user input), then what you do is: // cfg is always a constant type, by inspection MarshalIndent // therefore can't fail buf, _ := json.MarshalIndent(cfg, "", " ") And, voila, no more error clause you can't trigger. Don't skip the comment! (And don't be wrong.) Alternatively, if you can pass in types to this function, the test can pass in a bad type; any sort of `chan` is one option that should make that fail. This is an example of what I mean when I said in my other message that I've found this can sometimes simplify my code. Another thing I've now found a couple of times during coverage testing is one block of code I can cover, then a second block I couldn't, because it turns out the second block was behind an if clause that logically was already completely subsumed by the first. I'll stick by saying this isn't necessarily for everybody or every library, but I guess I would point out that it may at least be worth looking at coverage testing for everybody, because you do learn some surprising things sometimes. I have a bash alias that makes it easy to run the HTML coverage: htmlc () { t=$(tempfile) go test -coverprofile="$t" $@ &amp;&amp; go tool cover -html="$t" unlink $t } You can use that to test a module via `htmlc github.com/blah/whatever` or just running it bare tests the current dir by default. Adapt and adjust as needed, of course. (`htmlc` is "html coverage", name it something that makes sense to you, of course.) 
&gt; he only way to achieve this is by a community based central service [citation needed] I consider the npm/rubygems/pip/cpan solution inferior to the go solution. [godoc.org](http://godoc.org/) is far superior. &gt; 100% test coverage This is a naive requirement that doesn't work and is incompatible with other requirements, for example: &gt; tests must not rely on any prerequisites or infrastructure and any external reference must be mocked This is too restricted and rules out a lot of valid testing-strategies. For example, a lot of graphical software will spawn an XNest to do testing. It is nonsensical to require to implement a correct X-Server to do your own testing. Also, you can't mock out stuff anyway, because you require 100% Test coverage, so every non-mocked implementation (which needs to be used anyway) can't be tested and you can't get 100% Test coverage. &gt; doc.go for package introduction That is nonsensical, in my opinion. I pretty much never put up a doc.go, unless it's a pretty big package. &gt; version reflecting backwards compatibility (see below) I consider this [nonsensical](http://blog.merovius.de/2015/07/29/backwards-compatibility-in-go.html) too. There pretty much *is* no backwards compatibility in go, on an API level. Next to every change possibly breaks *something*. &gt; no hidden exported symbols (returned unexported types having exported methods) IMHO, any requirement that would exclude [stdlib packages](http://golang.org/pkg/encoding/binary/#pkg-variables) is useless too. &gt; subpackages are imported as gogi/[packagename]/[subpackage] and can only be imported from the same Gockage, i.e. it is not allowed to import subpackages from other Gockages Do I really need to tell you how nonsensical this is? Look at pretty much any larger project and you will find hundreds of "subpackages", that are usefull outside of this specific project. The etcd raft implementation and pretty much everything in camlistore comes to mind. &gt; all imported Gockages must be part of the file dependencies.gogi which is a json hash mapping the Gockage name to an array of the major version numbers of that dependency that can be used Urghx. I *really* and *enthusiastically* hate any design that requires metadata files. They are a PITA. We already record dependency information (with import paths) and versions aren't particularly well defined anyway. &gt; there is a file meta.gogi which is in json format The same. &gt; pure Go package: no cgo, no assembler Rules out far too many useful packages… &gt; no goroutine launching (i.e. no go statement) Makes this completley and utterly useless (it's a *feature* of go, that every library can just spawn goroutines and use concurrency without worrying what the main package does :) &gt; no init statement (i.e. no implicit initialization) … far too strong an assumption. &gt; All Gockages should be under the same license, the GPL2. So… I assume by now you have completely given up on the hope that this scheme is adopted by any significant part of the community? &gt; When viewing the Gogistry concept as a whole it shows that not only the Go packaging problem can be solved but also a very high degree of reliability stability and code quality could be achieved that is superior to what registries like Rubygems or npm offer. Not only do I consider this a step *back* for go packaging, I also think that the main *advantages* are better served by writing a travis script that checks coverage, go vet/fmt/lint/… and can be reused simply for different projects.
There is a lot of negativity in my post, I'm sorry for that. But I honestly think, that this hasn't been thought through and a lot of pieces of this proposal show, that there really hasn't been a lot of consideration for community needs. You don't have to change anything of this. But I am 100% certain, that this will not be widely adopted *at all*. Lincense restrictions and taking away power of go (in the form of forbidding concurrency and cgo/asm) will *definitely* be the death of this…
The address of a house is not the house.
&gt; So, first, you can read the source. Well, I did, that's why I said "no idea how to trigger". As far as I understand it, it won't fail. But I didn't checked every involved line of code, so maybe there is an error like "out of memory" or something like that. &gt; If you are always passing in the same type (i.e., it's not user input), then what you do is: Yes, indeed, it's always the same type I made (with values from user like integer, strings, etc.), but the user input shouldn't be able to trigger an error. So I should suppress the error with '_' to reach a 100% coverage of the testing module and may lose "out of memory" errors this way? Maybe "out of memory" isn't the best example, because it would panic anyway. I usually catch every error and didn't tried to reach 100% coverage so far. But I really like to do both, now. That's why I asked to find out how others handle it. Thanks for your tip. So far I haven't thought about your solution: // cfg is always a constant type, by inspection MarshalIndent therefore can't fail buf, _ := json.MarshalIndent(cfg, "", " ") In this special case it should work without side effects. Oh, and thanks for "gometalinter" in your previous comment. So far I started them all one by one, gometalinter is handy. :) And you reached a 100% test coverage with all of your [Go] projects? Almost all projects I saw are far below 100% coverage, many also FAIL testing and there are a lot even without a single test... Is it worth the effort (cost-benefit ratio) or is it more like a fad of perfectionists?
Well obviously you don't get that this is not a replacement for the current packages but a proposal for an additional format that can be used side by side with normal go packages. Obviously this package format is not for every possible go package but for the ones that have the mentioned restrictions. So graphical software spawning XNest is not the primary target and cgo based packages neither. Even if this restriction might be relaxed at some point (as you might have read if you read carefully) it allows some fine guarantees to be made. With simplicity comes power. There are still quiet big amount of really useful packages that could be build with this restrictions and they could be seemless by used side by side with normal go packages. Also it is no problem to build packages in a way that it leaves it to the importing package to run the go statement in front. I won't see camlistore and etcd as a library but more as a project. Gockages are libraries that can be used within projects. As for the use of subpackages: Sure it is not the way go packages are organized today but that also partly due to the fact that we have no reliable dependency management. It is perfectly possible to construct future gockages in a different way. Please note that a Gockage is not identical with a repository. So it is perfectly possible to have different Gockages nested or whatever inside the same repo but import and upload them as different global Gockages. Also the standard library has nothing to do with it. It won't change and won't go away and there is no need for it to be a Gockage. 
It should be no problem to turn the raft implementation into a global gockage to reuse it as a library (if etcd team wants to do it, they wont even have to change the paths since they can still use it as a go package like before / at the same time). If they won't? Well then it is not a gockage who cares? It is hardly an argument against a future system that nobody is using it yet. If there is an additional package system that has packages without go statement that does not remove anything from the power of the Go language since the old packages can still be used. Also you seem to ignore the fact that this is preliminary restriction that might go away later. I obviously contradict some current idioms since I construct new more restrictive idioms in order to enable better sharing of code. That does not mean that the old idioms should go away, but that some of them have their place outside the proposed system. It wish you would consider more of what **can** be done within this new idioms and what it gives instead of what can't. I think this is still a lot and should be explored how far you can get within this restrictions and what kind of reliability guarantee it could give. This proposal does not try to please everyone and instead keeps focussed. It is not for everything and the kitchen sink and that is a Good Thing (TM). If it would be picked up is not on me to decide, but thanks for the bad press. 
But, then we can't run on master :) ...I agree with @qudat though, git tags would make everything easier.
First, there's no virtue in using them where they aren't necessary. Second, keep them minimal. There's nothing wrong with one-method interfaces. If there's two methods "sort of" related, it can still be better to have two interfaces and a second one: type Composed interface { FirstInterface SecondInterface } One of the best ways to learn interfaces is to be sure to be testing your code as you go. What you'll find is that you may have something that looks like this: func DoSomething(f *os.File) error { ... // only Read()s from f ... } When you go to test that, you'll sigh in exasperation about how you need to create a file just so you can test this function. (Free bonus hint: If you do really need to do that, see `ioutil.TempDir` or `ioutil.TempFile`.) But if you _only_ call Read, you really want an `io.Reader` there, which can then be easily satisfied in your test with r := bytes.NewBuffer([]byte("Your Test Content Here")) In general, this is a really powerful use of interfaces: Where ever you take in a rich and complicated object like `*os.File`, but only use a small fraction of it, use an interface to declare that small fraction, and watch your test code grow in power even as it shrinks in size. Also, this is not a general thing about interfaces, but prefer `io.Reader` and `io.Writer` to strings where possible. It's a huge code smell to take a string in and immediately wrap a `byte.Buffer` around it to turn it back into a reader. It's a code smell, though arguably less smelly, to take in an io.Reader and immediately `io.ReadAll` on it.
I don't aim for 100% test coverage, but for a slightly different reason. I do think that 100% coverage of mathematical functions and such is correct. But overall it gives a false sense of security. Even if 100% of the lines are touched, it doesn't mean it's 100% right. I ran into an issue lately where a string was being parsed backwards but the tests didn't complain because they were all for parsing things that gave the same results regardless. In most cases, I skip error blocks that I can't find a programatic way to break; for example I will assume error blocks will work if the database crashes but I don't trigger/simulate a database crash to test them--that's a slippery slope where you now have to test your testing framework.
For me, Go's interfaces became really awesome when I started defining them at the receiver instead of the provider. Go does interfaces different from others in that **anything** that has the methods to satisfy the interface will. This makes it trivially easy to write decoupled code by programming to an interface you define based on what you actually want/need to interact with. My code was much easier to test after doing this, and with much looser coupling. As well, for CRUD code, I ended up taking the modelq package and modified it with my own template to generate my CRUD code. I went with reflection the first time around and was not a fan. Code generation using the actual database schema as the source of truth has been much cooler.
And it would be nice if the inhabitants could go outside the house and still be recognized. So one of the points is to decouple the gockage from its house so that it stay in contact with its friends even when relocating.
Feel free to add to the license discussion issue: https://github.com/gogistry/roadmap/issues/2
What are intrinsics?
&gt; It wish you would consider more of what can be done within this new idioms and what it gives instead of what can't I am trying to tell you reasons why I predict that this won't be widely adopted. I am not trying to convince anyone of my opinions or predictions, nor have a debate about whether or not I am right. Do with my comments, what you will. &gt; If it would be picked up is not on me to decide, but thanks for the bad press. You asked for comments about it and now you apparently are angry because they are neither positive nor convinced that this will get adopted. For the best of my knowledge I wasn't particularly insulting, so I would suggest, if you don't want comments, don't ask for them.
Not very different actually, its just that most networks such as my school's network block the SSH protocol. To bypass this I tunnel SSH through TLS with this program I created. After connecting successfully with SSH through this program I open up a SSH SOCKS5 tunnel on a port and use that to browse the web without any restrictions. Think of it like this. http://pastebin.com/raw.php?i=44J505Te Without the gTLS client/server in the middle my school's DPI (deep packet filtering) system sees I'm connecting via SSH and blocks the connection leaving me very sad. But my school cannot block TLS because of its ubiquitous use throughout the web. If you block TLS, you might as well just shut down any access to the internet. If you have any more questions don't hesitate to ask :)
Doing 100% is really hard. I've done it only once and it's for my structs package: https://github.com/fatih/structs However let me say that it is the most stable library I wrote. I'm so confident if I want to add a new feature or change the underlying implementation. It's an awesome feeling. However is it worth it? Don't know :)
Ban some things that are now caught by go vet checks or third-party tools, like ineffectual assignments (https://github.com/gordonklaus/ineffassign), dead code, etc. (Pike talked about making the compiler do ineffasign's analysis in an issue thread, but I'm not holding my breath for 1.x, because it would break a lot of code out there.) Clean the stdlib of some bits that differ from the direction Go ended up going, like "generic" containers using interface{} (e.g. container/list). Since they moved low-level syscall interfaces out of the stdlib, make syscall internal so there's no longer a split between old and new calls. You could do worse than defer, but I don't love how easily you can leak resources with it (e.g. forgetting to resp.Body.Close()). I can't say I'm taking something away here, but maybe you can 1) declare return values 'must-use', meaning must use or assign to _ (which gives you something like kisielk/errcheck for free), and 2) make methods requiring cleanup return a must-use cleanup function, so you have to defer m.Lock()() or unlocker := m.Lock() to satisfy the requirement. If you give up on any pretense of not adding things, 'cleanup m.Lock()' could be like 'defer m.Lock()()' but conveying intent a little better. (Credit to someone I can't find now from the Gophers slack for mentioning the 'defer m.Lock()()' trick, and for the Go team member who noted that it's painfully unreadable. :) )
nice!
I opened an issue in Go with your suggestion, I think it's entirely feasible: https://github.com/golang/go/issues/12504
It's extremely unlikely to succeed and not a real-world based proposal. Imagine that for every exacting rule you make you lose 1/2 of the people who might contribute. Then, since you have at least ten exacting rules, you must have already lost at least 1/1024 of the people who might have contributed. And the number of people dropping out for each silly rule you think of is definitely going to be much more than 1/2. 
Most of what I've read says that 100% coverage is useless. You want to worry more about writing tests that actually test your codes success and failures, rather than just covering everything. Most people will say something like 80%+ is great to strive for and that 60%+ is reasonable to expect in an environment that takes code quality seriously.
For my open source libraries I aim for almost 100% code coverage. If I'm calling a function from the standard library and just return any error it spits out then I don't check that behaviour because, quite frankly, it is inconceivable that the test wouldn't pass and is cumbersome to test. If, on the other hand, I do something other than just return the error then that should be tested. I work on a large [microservices golang codebase](https://speakerdeck.com/mattheath/building-a-bank-with-go-golang-uk-2015) at work and I write acceptance/integration tests that test high level things (e.g. being able to make a transaction, any webhooks that are registered are actually sent) and unit tests to test all the nitty gritty stuff (e.g. behaviour when another service is down). It is naïve to assume that test coverage perfectly correlates with test quality, some code paths in our code base have dozens of tests that test every single edge case - you could remove all but one of them and still retain the same coverage but massively reduce your ability to catch bugs.
That really doesn't make it bogus, though. If I'm designing a stack like this, I want realistic benchmarks. You can't just say "oh that python benchmark is no good because its using features that make it _really fast_". Umm, hello, _I_ will be using the features that make it really fast. The benchmark would be bogus if it puts an unfair limitation on the Go solution. Like, you could say that maybe they should have designed it so the Go solution _also_ uses the SSE HTTP parser. But I think we all know that the reason the Go solution is a bit slow is because of the GC overhead with lots of goroutines. Maybe 1.5 helps a bit? This isn't a competition and it isn't advertising. Its _information_. 
Here's my handler type: https://gist.github.com/Knorkebrot/3fa97a3151cd99ca5fd4
Agree, hashing and crypto performance would gain a crazy boost.
Absolutely. I was thinking of how the image processing libraries would benefit. The APIs are really good but the performance isn't quite there.
Can people please stop pushing atrocities like those commited in the Ruby, Javascript or PHP ecosystems as desirable models for the Go community to follow? Thank you. There aren't many things more painful than taking the shit that comes out of these communities and try to make it work together properly. Those tools might be convenient for the developer but they fuck the users of your software and everyone else who might have to maintain that crap while trying to keep their sanity. I don't even know why every language community is supposed to badly reinvent the package management wheel anyway. Why tie it to a specific language? A Go program can perfectly well depend on some other command written in C, Perl or any other language. System-level package management systems like dpkg/apt or rpm/yum already handle all that and the problems haunting rubygems et al. were fixed there a decade ago. What keeps you from doing versioned releases? You don't need language-level support for that.
It's based on the recent poll in this subreddit: https://www.reddit.com/r/golang/comments/3hfq8i/what_editors_ides_are_you_using_while_programming/? I basically summed up all upvotes (trying to separate 'I use this also' from 'I like your opinion') :) Here is google docs with calculations :) https://docs.google.com/spreadsheets/d/1KTpZylL7Tl7YS9DIaiGijlXa3DDINhZmzJuH3DbEd-E/edit#gid=0
Striving for 100% coverage really isn't the point. The point is to write tests to show you if your code breaks in the future. Covering all of your code is a good idea, but only if what you're covering it with is useful. Write tests that prove your specifications of your code. In every way imaginable. Cover your one block of code the 50 different ways it could work/act. Cover every corner case. Those are solid tests. Those are honest tests. If you can/want to, use go fuzz to find more test cases. Once you're doing that, working on getting to 100% test coverage using only *good* and *honest* tests is a worthwhile effort. I can cheat my tests, do a single run through of a function to cover the most common behavior. `go test` will touch all of the code in the block, and I can call that "test coverage". That's not an honest test though, I'm gaming the system. * 100% honest test coverage is a good idea. * 100% test coverage (maybe not 100% honest tests) is worse than 40% test coverage - at least you're not lying. * Don't freak out about not having 100% honest test coverage. Missing test coverage is not the end of the world. * It is possible to get 100% honest test coverage. It takes *a lot* of work.
Brilliant! I was just asking a coworker what environments were popular, this is great.
Spacemacs is emacs btw 
I'm not an expert in statistics, but I'm not sure these responses provide representational sample of all gophers. :) Results correlate with my observations, though.
Here is larger version, btw http://i.imgur.com/qrYk1sh.png
LiteIDE isn't on there? Huh, I know a lot of people that use LiteIDE. I use it. It's autocomplete is wonderful.
There were only two upvotes for LiteIDE in the original survey :(
vim-go is amazing, even without youcompleteme which I can never get working.
My issue with `database/sql` is that it takes way too much code to fetch a simple array of structs. Without some tricky reflection, you'll find yourself repeating the same large chunk of code over and over too... At least we have sqlx I guess. I would love to see some more Go ORMs too, but without generics that sort of library development is a lot more difficult than it is in other languages.
A way to avoid this fanout is an IMO acceptable tradeoff: Store the presence status of each client in the database, and have every client poll for it (batched - for all "friends") every 60-120 seconds or on-request. This is good enough for most cases and avoids the HUGE fanout caused by realtime updates.
+1 for using zeromq. Makes many things much easier. Plus it's an awesome piece of software.
At his scale, a single message broker may not do the job. And ZeroMQ is not a message broker (but may help in implementing the system)
Another way of doing it that may be useful if you have many small-ish packages in your GOPATH that are non-public and developed more or less independently - think a larger web app -, you can check in your whole GOPATH in one git repository and develop in different branches. From time to time you can create releases and merge everything back into master. This may or may not be a useful approach (I haven't tried it, at least not in Go), especially if you're an individual contributor it might be too much overhead. Otherwise it can provide you with a bit more stability by having explicit releases.
I've tried others, but now don't see any reason to use anything other than LiteIDE.
Ya pretty surprised not to see it there at all...it's so much better than the others that it's not even funny.
I did a video, "five minutes of go in emacs" a few years ago for people who kept asking me what ide to use: https://youtu.be/5wipWZKvNSo
Because that makes the log file depend on the starting mechanism and unconfigurable. I use wrapper scripts for third party software that can't log to a file usually, since that makes it independent of the init system used.
I've never heard of it. And the two guys sitting next to me never heard of it either.
For reasons beyond my grasp, liteide is quite underrated. I started with it and then tried most alternatives only to return to using liteide. It's fast, simple and it just works without any struggle with installation or configuration.
theme pool is a little limited there. But http://themebow.com/ takes care of that
I'm honestly happy with the built in Monokai.
I actually started to use it recently. Before I was a vim user for 5 years and then 2 years of emacs or so. Also I'm the guy who made Go autocompletion (github.com/nsf/gocode, not that I'm showing off, gocode is pretty crappy, but no one has made a replacement so far). So, why Atom? 1. Super easy to browse and install packages. Because editor is built on top of a browser, browsing packages is like browsing their github pages with markdown based READMEs and all that. Each package gets a nice settings page and stuff. Basically resembles browser experience with plugins a lot. 2. HTML is built-in. Features like markdown preview and fancy color selectors and minimap. I know sublime has some of it, but here it's written with web technologies. I am a hater of the html crap myself, but it's winning, can't do anything about it. Most GUI innovation and progress happens in html world now. And just imagine, you can use all those libraries and packages in your editor. 3. The editor itself is pretty slick. Yes, it's heavy and resource hungry and a bit laggy. But github teams is working on it, improves it. I wrote quite a bit of code with it, to me it works just fine. Haven't tried running it on netbook and such though. Anyways, but the editor itself is simple and you learn what's where rather quickly and then you get used to it. Overall, maybe it's a bit early to switch to Atom for good, plugins are young, there are not that many of them, but it seems that the potential is great. In my opinion it may become a next emacs. I mean emacs at some point was known as very resource hungy program and progress just catched up. Emacs is also known as an OS itself and here Atom being browser-based it's possible that it will becomes something similar. And thank god, no need to write elisp anymore. I'm not a big fan of JS and CoffeeScript, but it's better than lisp. Also Atom itself is based on a big app development platform github is building and we already can see other projects emerging. Like Visual Studio Code and others (http://electron.atom.io).
Look into NeoComplete, which needs vim compiled with lua. It is very smart token completion and likely saves me hundreds of keystrokes daily.
1. Javascript *is* a toy scripting language. It you don't know anything about programming languages, at least go read its history. The fact that its wide spread (or that you might be using it everyday) now doesn't change this fact about language itself. 2. There is no such thing called "full long SMID". Clearly you don't know what you're talking about. SIMD data types as supported by hardware is short, that's it. You probably saw that "long" word [here](https://hacks.mozilla.org/2014/10/introducing-simd-js/), which is talking about a class of problems, not hardware registers. There is already a draft for 128-bit SIMD in ECMASCript, it's already a matter of time. AVX brings 256-bit registers to the amd64 world (but that's not what they meant with "long" there), but there is no NEON equivalent of this on arm machines, so of course it won't be a part of SIMD.js. 3. That's SIMD, not SMID. 
Agreed! :-)
You missed a chance to call this go-tee. Goatee. Get it? Sheesh.
It's great, and with a bit of tweaking not that ugly as it seems. It's far superior to any other Go IDE at least IMHO, and I've tried them all several times. IntelliJ comes close but it's still very slow - still it shows great promise and it's always getting better. The problem with LiteIDE is that the sole maintainer has sort of disappeared in April, and the project will die unless someone else picks it up.
I'm sure they did it because the editor has a large front-end following, the exact type of people who will be proficient in JavaScript and CSS so are likely to be able to extend it easily.
It's much faster though, and has much better integration with build, testing and debugging tools.
I believe I was clear about needing multiple servers? And it is difficult to recommend a specific piece of software with a lot, _lot_ more details. I have to admit, whoever saw fit to downvote the only reply in this reddit post that _actually answers_, even if only partially, the question of how to implement this service, probably written by the only person in this discussion to have actually _implemented_ a similar service based on my reading of everybody else's post, should probably hope they are never in this situation themselves.
Does semantic Go completion work properly with NeoComplete, and is there any additional config required for it? 
and that plugin's name? [vim-go](https://github.com/fatih/vim-go) *glad we cleared that up!*
This is really cool! I suspect it might eventually make its way into ngrok =D Btw, nice work with the API, it's quite clean and elegant.
You made a go program to concatenate tech logo's together for readmes? That is an oddly niche use-case. edit: ... no, [THIS guy did that.](https://www.reddit.com/r/golang/comments/3jscnm/maingo_delicious_logo_service_for_building_tech/) OP you're a cool guy.
Not sure I follow what you are saying. This package is for intercepting and proxying http requests, geared towards helping the QA process and black box testing. Service A calls Service B, and you want to verify how Service A behaves if Service B gives back errors, the wrong response, wrong headers, takes too long, etc. 
A wrapper script for capturing panics is fine, too, I think. Those, like the init system approach, also include unrecoverable panics, which (as the name says) you can't recover from. When an unrecoverable panic happens, there might be no way to safely run arbitrary Go code, so they can't be logged using your favorite logging system but instead just get written out to fd2/stderr. And the most straightforward way to make writes to file descriptor 2 go where you want them to go is for the parent process to arrange it that way. If you insist on doing it inside your process, you could try it with dup2[0]. Still, I think it's way more sane to do it in the parent, so that it's obvious what's happening. [0] http://play.golang.org/p/9dfIMJ8UVM
At first glance it looks extremely similar to codegangsta's cli. I'll check it out
yes. If you're on a Mac it seems best to use MacVim (v7.4, and lua support)
IntelliJ is heavy and written in Java. 
Count me as 3, I just didn't know about the survey... I have a hunch (based on discussions in the project's mailing list and github issues) that for some reason this editor is more popular in Asia, i.e. China and India. 
Thanks for both the compliments! A few days back, the API wasn't quite as clean... There was nothing but a huge main func() and a few helpers. Split it into the lib and frontend during my daily commute. :)
I've made a very short summary of the discussion. Thanks to all participants: /u/balloonanimalfarm, /u/brunokim, /u/daniel_chatfield, /u/dericofilho, /u/dgryski, /u/dmikalova, /u/farslan, /u/jahayhurst, /u/jerf, /u/kurin
I think you're describing one of the main usages of sshmux &amp; sshmuxd. :) (A list of servers with only one user for each) For me, the motivation was that we have multiple clients that we need to distribute things to. We exposed a small sacrificial VM for sftp'ing for one of our clients, but that isn't a good solution in the long run. sshmuxd would allow for port 22 to provide access for all the clients, and myself for maintenance, without anyone knowing about each other.
You should take a look a the [experimental vendoring](https://docs.google.com/document/d/1Bz5-UB7g2uPBdOx-rw5t9MxJwkfpx90cqG9AFL0JAYo) available in Go 1.5. [Glide](https://github.com/Masterminds/glide) is a nice tool to easy get deps for vendoring.
Yeah, sounds like it. Can it be runtime reconfigured without interrupting ongoing connections? Seems like it'd be pretty easy to rig up with confd if so, and I could just have autogenerated configs that say "this user has this key" and then it sets it up to go only to that user's premade service name. (Probably "$USER-shell" or something). What does the invocation on the client side look like when you use this?
Dokku/docker gives almost no overhead. In average results without Dokku are the same, sometimes faster, sometimes slower, but in range of +/-5% of what Dokku performed. Running 10s test @ http://45.55.128.8:8080/ping 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 135.26ms 24.04ms 627.03ms 99.05% Req/Sec 366.63 71.27 500.00 72.31% 7203 requests in 10.05s, 844.10KB read Requests/sec: 716.62 Transfer/sec: 83.98KB Just to clarify, I had dokku/docker installed, but I stopped all the containers, ran go binary on the host system outside of the container and measured the speed.
Your reaction to being corrected on two small facts of your whole reply is highly unprofessional. 
On the OpenShift with scaling it looks like all the requests errored out non 2xx or 3xx. Could be a config issue. I did something similar and was able to push to about 6900 reqs/s on an acer c720 for a service that returns the time in a json packet along with a redis request counter. The biggest improvement was with redis pooling to match number of simultaneous incoming connections. The load tester was also written in golang to use goroutines instead of threads for higher concurency and throughput. Code is here: https://github.com/gituser1357/golang-practice/blob/master/httpLoadtester.go https://github.com/gituser1357/golang-practice/blob/master/timeService.go 
This looks really useful, good job. I like tools that provide a better UI on top of an existing tool by generating configs. I have been meaning to build something similar for `iptables`.
If anyone has any ideas on how to make the tests pass on different machines while keeping them sensible, I'd be thrilled to listen. 
I want to say the limit of these benchmarks is your own connection rather than the hardware limits of each container/service (I've certainly seen much better performance for similar routes out of the same containers on AWS and Digital Ocean). The test would be more valid if you used another container in the same region of each service to conduct the benchmarks.
If you look at the [Travis history](https://travis-ci.org/deiwin/picasso/builds/78929498) you can see, that I initially tried to just compare every pixel of the freshly created image to a pixel of a PNG I'd previously created and manually confirmed to be what I expected it to be. It works well on my own machine, but failed when Travis tried to run the tests. I then figured that if I add some leniency and expect the color values of each pixel to be *close* to eachother (`+-2`) then that will fix it. [It didn't](https://travis-ci.org/deiwin/picasso). Now I'm out of ideas.
Ty (and thanks for the PR) Re: Proxy. Not at present, I guess it could be possible but im not sure what the use-case is? 
With regular log in (using -A), it will present you a list of servers, unless the user is only permitted access to one server, in which case it will just connect you directly. I guess I should explain things a bit better in the readme.
In the case that inspired fakettp - Service A calls several of B's endpoints (we are testing changes to A). We want B's endpoints to actually work (set up data, etc). However, we changed one part of A that deals with one part of B, so fakettp allowed us to let all of B's calls happen "naturally" aside from the one we wanted to mock for QA purposes. This let our QA black box test Service A and its dependencies.
**Never** ignore errors.
Don't use `defer` in a for loop. Deferred functions do not get run until the calling function returns! You use `defer f.Close()` in a for loop within `main()`. That keeps *all* the files open adding many defer close calls to a list to all be run when main returns. Among other problems, depending on the size of the input and how resource limits are set you might run out of file descriptors.
Thanks. I have fixed these issues.
Because jumping on a proxy without using ssh -W requires agent forwarding. SSH proxies aren't a new thing, hence the super old bug report, that just never got followed up on. WinSCP also supports it, it's just the OpenSSH bundled sftp/scp clients that explicitly disable it, and due to the way ssh parses options (scp and sftp just call "SSH" with a bunch of parameters under the hood), you cannot enable it (an option can only be set once on the command line). There is no mention of why this is occurs other than "the code that disables it was always there". The workaround for this issue is to use "ssh -W"-style ProxyCommands.
Wow, thanks! That was exactly it. I was using 1.5 locally, but Travis defaulted to 1.4.1. Just had to tell Travis to use 1.5.
You didn't correct my post. You just repeated bits of it to me _as if_ you were correcting it. Including something from the _first sentence_. Yeah, that's annoying. After that sort of impoliteness you hardly have grounds to complain on being called on it.
Just my personal style would have been to define the function type as: `type predicate func(int) bool`
This can't be dressed enough!
Yeah, I think that's a better name. I have changed it.
Not sure why you have a delay. I just have the following: &gt; let g:neocomplete#enable_at_startup = 1 &gt; set completeopt-=preview The scratch preview was annoying. Can't remember what it did but that second line made it go away 
I'd be lying if I said I didn't spend half a day pondering on various punny alternatives for the name. For example, *vanGogh* would've been easy pickings. Finally settled on *Picasso* because he was a prominent cubist, which I think goes well with the whole layouting thing.
&gt; the queuing server This can be misunderstood as "you will have one queuing server". That's what I tripped over. &gt; The sort of software you're looking for is called a "message queue". [...] names [...] referenced a lot are: RabbitMQ, ZeroMQ, ActiveMQ. ZeroMQ is still not a message queue. It is important to make that distinction, IMO. and btw, it's about fucking reddit karma and comments. If you don't like it, don't do it. If you do it, don't complain. Extensively whining about one downvote is a very bad sign
Is it for Windows, Linux, both?
I thought there already were shared libs. -buildmode=shared
Access denied. 
Yes, that is exactly what it is.
Actually noone can answer this question exactly without background information. 'Chat' just describes a very versatile term. You can have a chat room with alot of ppl or you can have a chat between two people sending each other messages. So you should atleast provide the context what kind of chat is this.
As an alternative to intrinsics, I work on Python-embedded assembler that can generate 6a-compatible assembly sources, 6l-compatible syso objects, or produce normal ELF/Mach-O/MS-COFF object files (e.g. for cgo or gccgo). Try it here: https://github.com/Maratyszcza/PeachPy
-buildmode=shared will allow to compile (and then load) go shared libraries from a go-main program. but it didn't make the cut for 1.5 only -buildmode=c-shared, that allows to compile go-based shared libraries from a C-main program, did make the cut for 1.5.
This is great, exactly what I want. I previously used [glide](https://github.com/Masterminds/glide), however it didn't recursively download dependencies.
Just to give a notion of what "quite slow" means: When I started with go, I did this too (as a lot of people probably). I measured about a 100x slowdown using reflection. That is IMHO enough to make it very hard to justify even in programs, where speed is not the *prime* concern. Usually, writing a for loop by hand doesn't take *that* long.
This appears to be in the same space as CockroachDB, but neither project acknowledges the other. Can anyone in the know make any comment or comparison?
there are discussion on hackernews, see https://news.ycombinator.com/item?id=10180503
from hackernews thread https://news.ycombinator.com/item?id=10180503: The goal of TiDB is to create fault-tolerant distributed RDBMS. Especially for distributed transaction support. Let developers get benefits without changing any of their existing code. 
This is troubling: https://github.com/pingcap/tidb/issues/45
The original copyright notices were stripped and replaced with PingCap copyright notices. That's not cool.
Why don't you go with the desired project structure? For example, if your project is in github.com/user/project, you can import lib as "github.com/user/project/go/lib". If you expect lib to be used by other developers, I would just have an independent repository for it, else I don't see what is the problem.
It won't work on Windows without a POSIX environment, as it uses the environment variable $EDITOR and the /tmp directory. I'll see if I can change that.
agreed. But, the objective of the article is to give reader overview on how to write generic function in golang. And code I've written is for demonstration purpose only. I did not mean to encourage reader to write generic function everywhere. 
It's not cool, but It may simply be an honest accident resulting from some automated scripts or similar to apply pingcap copyright notices. As long as the original copyright holder ends up happy and the pingcap folks remain civil, responsive, and end up complying, it doesn't have to be a big issue. 
Congratulations to Go IntelliJ IDE team for modern responsive licensing. 
1) Generics 2) Default arguments 3) Overloading (function, method) 4) Macros (or alternative ways to hack the compiler/runtime)
What are you planning to use this for? Depending on your use case, there might be a nicer solution.
I'm just trying to simplify database crud, without using a ORM, so I just need to store some table related metadata (pk, fk, json, etc).
Delve is a fantastic tool. I hope it will get more traction / contributors. As for GDB, as soon as it will support Go apps better, it will definitely make its comeback to the plugin / whole debugging Go apps scene.
Does this thing do gofmt properly now? Thats whats kept me on vim-go recently. Constant auto-gofmt.
You said "coming up with more syntax to do the same things." This is exactly the problem with what's cool with the kids these days... http://z505.com/cgi-bin/qkcont/qkcont.cgi?p=Is-Ruby-457-Ways-To-Do-The-Same-Thing Just to be cool and hip, and modern, people create syntax duplications that do the same thing as before, only cooler than before (not). Agree with your post - it's not about your benefit, but everyone else's too.. And unfortunately Lisp suffers the same problem: you can write genius code in lisp (all sorts of DSL's) but who can read your lisp code? Same problem with C++ but not so much DSL's, rather the other "Features" of c++ that makes only geniuses able to understand the code. Genius might not be the right word, as geniuses prefer simplicity over complexity. Almost "too clever for their own good" or "shot themselves in the foot with complexity" Ruby outright admits as one of its philosophies that it wants to be complex mess inside, like a human body - it says this somewhere on their website. They think hiding all the mess in the compiler is okay, to end up with a supposedly elegant language (the biggest danger of ruby is it appears aesthetically pleasing to the eye, luring all sorts of programmers in like a beautiful woman, only to find out that this woman is a mess inside). Okay it's a bad joke, but you get my point. Whereas at least with C++ you can tell it is not elegant, and isn't like a beautiful woman luring you in - it's more like some kind of "it's based on C so it must be good, it's C++ so it must be the next generation of C, so I'll use it" problem.
C syntax has also been described as "inside out". Left to right is Wirthian: var x: integer; s: string; function something(i: integer): boolean; func something(i: int): bool; Inside out is like this: // void doesn't tell me anything! it doesn't say proc or func void something(int something); Void is the function result, so what's it doing on the left? Instead of void, they could have made C like this: proc something; func something(): bool; i.e. left to right If you look at this: int something; int another; The problem with this C inside out syntax is it keeps telling you, int, int, int, but what's important is not the int. Your eyes should be notified of the variable name, not the fact that it is int. Int just happens to be what type it is, but you're looking for variable names, IMO, and blurting out "int" first before the variable name, doesn't really help much. Obviously some people will have different tastes but it would be interesting to do a scientific research paper on how the human eyes work and empirical tests that prove one way better than another.. I never found "void" to be useful in C, why not just call it a "proc", what's the point of the Void information being blurted out in my code? 
https://github.com/go-lang-plugin-org/go-lang-idea-plugin/wiki/Documentation#formatting-the-source-code
You sound like you'd fit in with the Go community quite well. Enjoy!
So the answer is "no" then. It still doesn't provide the basic auto-gofmt functionality. Why didn't you just reply with the answer?
Sorry if off topic, but I just tried out IntelliJ for Go and I was wondering if there is integration with the oracle tool.
This would be more interesting with a screenshot.
I should just get off my duff and implement it myself. Are all developers here. 
I understand what you're saying, but how would you handle the configuration for the log file path then? Add `jq` as a dependency? (assuming the config file is in json format) Thank you for the `syscall.Dup2` example :)
yep)
Naming can be improved: * product.ProductSize -&gt; product.Size * product.Product -&gt; product.Info * inventory.Inventory -&gt; inventory.Item * inventory.InventoryComparator -&gt; inventory.ByName Also: var ( NA = Size{"NA", "Not applicable", 1} XS = Size{"XS", "Extra Small", 2} S = Size{"S", "Small", 3} M = Size{"M", "Medium", 4} L = Size{"L", "Large", 5} XL = Size{"XL", "Extra Large", 6} XXL = Size{"XXL", "2-Extra Large", 7} ) 
One of the authors here. Sorry for the mistake, we do this with a script. We have already fixed this issue and invited cznic to review the pr. We really appreciate cznic's awesome job. 
"Superior - Toolkit for the Go programming language" really doesn't say much about what it is. It sounds like it's a general toolkit with lots of utility functions, but it's "just" a function for printing with color. Consider giving it a more descriptive title and/or name. (e.g. "colorfmt").
Deeply agreed! While the package is nice and the code is clear and good as well, I think the name does not help too much to understand what it is for. Anyway, colorfmt is not a good name either IMHO since it is not about providing formatting utilities with color but just to add escape codes to various strings. By the way, do this package work in all OSs the same? it will undoubtedly work under Unix-like systems, but what about others?
a help() function doesn't make much sense in a library imo...
Isn't that movie about a kid that gets into Harvard? What's the context here?
Can you please tell me where did I go wrong?
 /flagcode ffjkf It seems just Go wasn't convincing enough for Hollywood.
this is stuff is way more (not that it is a good thing ) than Gorilla sessions. It actually has http handlers that deal with the authentication process , so it is not a cookie-based session management , it is a "fully featured" ( again not that I think it is something well done ) authentication "framework" with routes . The title of this submission is 100% misleading. &gt; Package gelada provides a tool for HTTP session authentication control (via cookie). 
looks prettier than the structure I described. Do you have another abstraction where a you can only access to datastore within models like func (u User) CreateUser() (User, error) { return u.Datastore.Create() } or does the endpoints/routes have direct access to datastore?
The first and third goroutine will hang waiting for the channel to be consumed, as the channel doesn't have a buffer.
Normally, goroutines are not garbage collected or cleaned up until they exit - it doesn't look and see "Hey, these two goroutines aren't ever going to do any useful work." However, a go program exits when its `main()` function exits, without waiting for any other goroutines to complete. Any remaining goroutines just simply stop abruptly, without calling any `defer`red functions. Edit: Play link, for formatting: https://play.golang.org/p/p7Hikt72VE
Thanks, may be I will add capacity 1 to that **chan**. But what happens to other goroutines? Does GC take care of it?
Does not read the ProxyCommand from .ssh/config. I am trying to make those changes to make it compatible with the ProxyCommand for jump hosts I am using. Let me know if anyone has pointers for this.
&gt; So you are saying that I dont have to worry about those loose goroutines hanging around? During the course of your program, yes. As Fwippy said, they're not garbage collected until they exit, so they could last the lifetime of the program. That said, once `main` exits Go's runtime cleans everything up, _everything_ exits, and the memory is given back to the OS.
Thanks and yes, the lifetime of those goroutines will be that of the program itself. I wish there was either a GC or auto runtime monitoring for goroutines!!
It should probably be a [godoc example](https://golang.org/pkg/testing/#hdr-Examples) in a `*_test.go` file.
&gt; it will undoubtedly work under Unix-like systems Not really. This package appears to use ANSI colour codes. Unix-like systems support many terminal types not all of which support ANSI colour codes. Unix-like systems have a way for dealing with whatever codes the current terminal supports and this way is **not** to hard code specific codes.
Forgot to mention. Go has been the best language as an introductory programming language. I started coding in C++, which I had hard time to have fun with. Go got me into coding, and now I want to learn C++ again because I can learn better from what I have learned with Go.
It's what Lisp does :)
It looks like you're trying to fake generics. In general though, you're trying to cast an anonymous struct with the signature `Id int, Data interface` to a named struct with the signature `Id int, Data []string`. I'm not sure why you'd expect that to work.
That sounds like it would be a way too magic feature...! Rather, to make things easy to predict and nice to work with, goroutines do exactly what you tell them to. Try to imagine how hairy debugging would get if goroutines suddenly disappeared when you didn't expect them to! The Go runtime does provide *some* monitoring, in the sense that it will error out if you accidentally block all your goroutines in a giant deadlock. Terminating main() doesn't actually have much to do with the runtime. The operating system considers your application done when main/_main terminates, and anything left behind will be cleaned up by the kernel. The Go runtime could, and might clean things up here, but the default behaviour of any application terminating main is to be killed by a kernel that has seen too much and has nothing to lose...
You used reflection to poorly implement a generic function.
Because you're casting from interface{} to interface{}. 
From what I'm working on right now... // InitStore initializes the default sessions.CookieStore with the given options. // keyPairs should be alternating authentication and encryption keys. E.g., // InitStore(opts, auth1, enc1, auth2, enc2 ...) // Repeated calls have no effect; it will only run once. func InitStore(opts *sessions.Options, keyPairs ...[]byte) { once.Do(func() { ... }) } Simple, sweet and to the point. 
It works because they're all pointers to type `T` In your other example you have two fundamentally different types: type foo struct { A int; B []string } bar := foo{ A: 21, B: []string{"Hello, world!"}, } and baz := struct { A int B interface{} } { A: 21, B: []string{"Hello, world!"}, } 
Yes. You may be interested in [my blog post about how to use quit channels](http://blog.carlsensei.com/post/72359081647).
No. Go is neither covariant nor contravariant. Types are either equal or they aren't. You have to either take the structs apart and deal with the pieces, or use reflection. Type assertions are only "assertions", not "coercions" of any kind.
Consider using a [sync.WaitGroup](http://golang.org/pkg/sync/#WaitGroup) for this. In general, Go and every other runtime I know will exit when a distinguished thread (or local equivalent, like a goroutine) exits, because as the complexity of the program grows, probability approaches 1 that some thread will fail to exit at the correct time, resulting in the entire program essentially hanging at shut down. Heck, even when things like Windows work like that but allow threads to tell the OS "No, wait, don't shut me down yet" you get programs hanging, just off that small number of threads that explicitly claims that feature. And for the question of whether it is hung, it is in the general case an instance of the halting problem. In some specific cases the GC/runtime could figure it out (you have a receive-only channel ref, no sendable channel refs exist any longer) but implementing such things is, in a weird way, sort of a bad idea... optimizations like that which only trigger _sometimes_ are sort of worse than ones that never trigger; you depend on them until suddenly, one day, in your huge network program they stop firing, and the first notification you get about that is the 3am pager alert that your site is down. Given Go's core target audience, that's not a made-up story... that's life!
&gt; the code is clear and good as well Honestly the code could be cleaned up a lot; it's just a ton of nested switches. OP, you should spend some time reading the fmt package in the standard library.
Thanks! I am really enjoying working with markdown, except when I miss latex to write math equations.
[removed]
Closed issues [here](https://github.com/golang/go/issues?q=milestone%3AGo1.5.1).
Saw you post this in #go-nuts freenode the other day. Good work.
This is awesome thanks. I got a question though. In the last example the author stated passing variables over context in a request scope is not adviced. Why is that? It is a more functional approach also allows a better abstraction between requests as I can see. 
File size of my binaries went up again ... -[ºل͟º]-.
Yes, this is the approach we use. One way you can use the segment library is through bufio.Scanner and its related bufio.SplitFunc. The SplitFunc abstraction gives some []byte and an EOF flag to work with at one time. In our case, within Ragel, if we're not at EOF, we can't allow matches that go to the end of the buffer, because there might have been a longer match possible. There are some practical limitations of course regarding how large a buffer you use, and how slow the Reader can be. But in practice it seems to work well.
I really like the visualizations! Very nice.
Congratulations to Go team.
This is fantastic - bravo! I strongly believe the Go community is a great example of a feedback loop, in that beginners (or people like me who just ask silly questions occasionally) can go to the go-nuts mailing list, IRC, or any of the other accessible channels and get help immediately. By getting such great help so quickly, the beginner is more likely to help others down the line. This is great work, and I look forward to seeing how it will inspire people just starting to look at Go. Thank you for this contribution!
If you're talking about [this bug](https://go-review.googlesource.com/#/c/14227/), then it looks like it.
Which they did. Kudos to them.
This seems to be mostly a Go thing. I wish the OSX package installer would actually take care of this for you, and I can think of no reason why it couldn't. Speaking of the package installer, I wish golang.org/x/tools/cmd/... was installed with this package installer too. On the other hand, I can see where it would be tricky to handle the $GOPATH/pkg bits automatically, especially considering there could be a multi user environment in play, so I don't think it's reasonable to expect a 100% automated upgrade path.
You can checkout the source of github.com/daneharrigan/hipchat and make it accept host also (right now its hard coded), and point it to your hosted server.
I'm installing via the OSX installer pkg. The installation instructions say: &gt; If you are upgrading from an older version of Go you must first remove the existing version. [1] So I follow the uninstallation instructions and remove /usr/local/go and /etc/paths.d/go before running the pkg file. Seems odd. I'd expect the installer to overwrite the existing ones. [1] https://golang.org/doc/install#install
&gt; The OSX installer pkg removes the old files for you (and pops up a modal to inform you of this) Oh cool! I never event attempted the install / upgrade without first removing the old version, since that's what the instructions tell you to do. Thanks for the tip!
Try using brew instead. It will save your sanity.
What do you mean? This is generally how software development works. 
No, you release service packs if your release is faulty. You don't abandon old version to release new version 
You might want to redo those charts in log-log format. It makes the graphs in the smaller regions spread out enough to be distinguishable from each other, usually. Then you probably wouldn't need a separate graph for the 4-8 core case, either, you'd just start dropping data points for 1 core on the right.
edit: when I say caching I mean an external cache, e.g. redis. I agree. Network latency is almost required in almost any scenario, and tbh, I think the author is looking at caching incorrectly. For instance, why not have an update (e.g., new employee) dump into the cache on its way to the database? Then your cache is guaranteed to have the latest data and requests can hit the cache for data first. Also, as far as I'm aware, if you don't have a complex database/cache scheme it's best to only place in the cache objects with a determined expiration _or_ objects that will never expire -- not random expiration. For instance, a web app's sessions could be cached because they're guaranteed to expire in N seconds (or never) _unless_ the cache receives an event that says, "Hey, drop this specific entry".
There's nothing wrong with using switches; they're very fast and it beats a bunch of if/else. The way OP is using switches isn't that great, though. Look at the content of each statement, it's literally almost the same thing each time. `x = x + something`. This code screams, "there's an easier way to do this." And there is. For example, you could use a switch to determine which decoration to apply, and then use a switch to determine which color to apply. This would also reduce the number of constants to 12, which is another improvement. Also, doing `string += string` is a bad idea because it allocates new memory each time and is very slow. Also the API is a bit clunky. There are already a lot of good printing/formatting functions in `fmt`, why switch to this, which doesn't correspond to that standard or even format strings? Something like `hex.Dumper` would be much nicer; return an `io.WriteCloser` that applies color formatting on the fly.
Thanks, this is helpful. I built most of the features backwards, like the lexer first, then the scanner, etc. So I have tests for all of them already. I feel like they're more elegantly combined into a single package as unexported functions. But, I end up testing the lexer 4x, the scanner 3x, the parser 2x and the preprocessor 1x, since each level also tests all the way down the chain. But, when I add new features, they typically enter into the lexer and parser, so it could be hard to develop without trying to test them individually as well. Is this type of testing redundancy typical or is there a better way to test these items in isolation?
I do use Homebrew, I just never thought of using it for Go! I had issues installing MySQL and Homebrew saved me from hell!
Ah ok. Yeah you could do that but I guess my point was to avoid extra network operations. I have a real world example of building a pivot table from some set of data and I need it to happen in less than 10ms if possible. The crosstab operation is expensive and I don't really want to make more than one db query because that takes way too much time. Keeping the data I want to use to construct the columns in memory is the best way I could find to get that time as low as possible, Since at that speed the network latency accounts for a major chunk of the overall execution time.
Thanks!
I use Homebrew. To be honest, I'm kinda getting tired of the mess it leaves around. Plus, I'd rather use compiled and signed binaries than compile everything myself. I'm honestly probably going to do Nix when I reimage soon here, or use Docker containers for everything. I like that brew tests installing all packages on the same system to make sure they're all compatible. I like that Nix tries installing each package on a clean system to verify no missing dependencies. I wish they both did both. But, I really am starting to think that Docker (for as many applications as I can) is the best way to go.
Personally? Insufficiently.
I just posted the link. :)
I tend not to sweat this kind of problem. Rather than thinking about what code paths are being tested, I tend to think of it as "if a test fails, what does it tell me?" If a test fails at stage 3 but not stage 2, well... where to start looking is obvious. Also you'll naturally tend to focus on what really needs testing; it can easily be the case that while the stage 3 test is testing stages 2 and 1 that it is _very_ incompletely testing stage 1 even so. This isn't necessarily the best case because in a compiler you'll probably end up with pretty complete tests, but in other cases where I'm layering tests together, if the lower levels are well tested it lets me not try to puzzle out how to test layers 2 and 1 at the same time, from layer 2. I consider this a good thing overall.
If you like things to break and get upgraded constantly for no good reason.
This looks great, I'll be kicking the tires this weekend for sure
OK, sounds good. That's the track I'm on then and the testing certainly feels comprehensive. Thanks.
Does it support 4K?
This looks like a lot of work without enough justification. What's the use case here?
Very nice. It should also mention the IsZero method. It took me some time to find out how to check if a time was set or not.
Thanks a lot for posting this here Damian!
Great idea! 
I would really like to migrate our clusterfuck of a perl product at work to Go. 
way too many down-votes for /u/dragonfax and up-votes to this. There's nothing vague about the question as the "properly" reference is clearly to https://golang.org/cmd/gofmt/ which the community at large uses. The intellij plugin does not use this and likely never will. The last time I checked, the formatting provided by intellij does not match gofmt either. I don't use intellij for go development, but I do use intellij for a number of other things and having a save-hook doesn't really match the experience intellij provides. Files are saved automatically which would mean you may randomly see formatting occurring when you are doing nothing. The default key binding `ctrl+s` maps to `save all open files`, not just your current file being viewed, and pressing it is more of a sanity check than anything else. One could create a custom macro that calls `go-fmt then save-all` but pressing this would be a bit superfluous. The default shortcut for formatting code is `ctrl+alt+L`. One can set this up to format the file being viewed, understanding files are being automatically saved in the background, but this doesn't have the same guarantees that the code you are committing is properly formatted since other editors wouldn't have dirty buffer saved anyway. This is likely why the docs for the plugin suggest a git hook, which really isn't such a bad idea as you can toss in lint and vet checks as well.
Cool reply!!! Thanks a lot mate! Additionally, I never heard of package hex so with your reply I learnt something new (I'm going over it right now).
From 100ms to 10ms, that's impressive. I know that Python is slow, but didn't think it's that slow. How about your productivity in golang? Is it comparable with Python?
&gt; How about your productivity in golang? Is it comparable with Python? Depends on what you were doing with Python at first place. 
If your employer is still using Perl at this point, then they are probably going to keep sticking with it. My suggestion would be to find some small, independent software component and rewrite that in Go. That might open them up to the possibility of updating the whole suite.
[time.go](https://github.com/golang/go/blob/5f859ba83d4c47b6a6a75559041207387acab7ba/src/time/format.go#L43) these constants really help when you are dealing with custom layout for formatting
Oh wow, yea, I didn't expect that level of "portability". Very interesting.
Booking.com?
That is not true at all... Literally none of that happens in any common scripting language out there at request time... Edit: to expand. No sane system out there waits until a request comes to spin up an interpreter. And very few will completely re-parse the whole source on each request, caching systems are built into most major languages. Edit 2: y'all motherfuckers need to learn how fastcgi works...
No, in PHP it launches a listener ahead of a request and it waits for a request. And it uses cached opcodes if available instead of re interpreting the source on each request
Maybe if you don't interface through apache.
If you are using simple CGI then what you say is true. If you use fastcgi or newer (which the overwhelming majority do) then listeners are already created when the request comes in.
Writing native golang tests is a joy compared to anything else I have worked with. I had a similar experience porting python tests to golang.
Same with nginx. Not sure what the parent comment is talking about.
brew update brew switch go 1.4.2 (if you have installed go1.5) brew upgrade go
Their parallelization example ends with: "Each ChunkScoreResult contains an “order” attribute which allows us to re-order things once we’re done." A better way to achieve the same thing is something like this (edit: with some fixes): results := make([]*Result, len(chunks)) wg := sync.WaitGroup{} for i, chunk := range chunks { i := i chunk := chunk // see comments below about capturing wg.Add(1) go func(){ results[i] = Score(chunk) wg.Done() }() } wg.Wait() This means the scoring function can be agnostic to the parallelism and you don't need to reorder the results at the end. (You can do the equivalent to a waitgroup by filling up a channel but the waitgroup more explicitly serves the desired purpose.)
This makes me unreasonably excited.
Just as a heads up for those coming after us, there are a couple issues in this code: closing over "i" and "chunk" in a goroutine and not calling wg.Add(len(chunks)) before the loop. I agree with the concept though--write code simply at first, wrap it with parallelism if you need, and only resort to more fancy parallelism when profiling directs you that way. 
Let me start by saying I'm not clear on what problem it is you are trying to solve. I've not heard of Circus before, but much of its intro material talks about managing sockets, and that made me think of https://www.badgerodon.com/socketmaster. Is there a reason you don't want to use something like SupervisorD? Or heck, Circus? It does not look like Circus must be used with solely Python as the docs show it managing Redis. Because concurrency with Python is the way it is (gunicorn, twisted, gevent,...), you often need to spawn and monitor multiple processes and workers. Go's concurrency is different. You are just going to spawn goroutines; it is not common to explicitly spawn new processes in my experience (I don't believe I've seen a Go process fork, which is what happens in programs like gunicorn). You will have the one Go process. If you need to manage multiple Go processes (ie, different binaries doing different things), then there is no advantage to having a Go arbiter managing them all over any other solution like Supervisord or Circus. If you are wanting to leverage Circus' pub-sub, you may be able to just use ZeroMQ bindings and let Circus do what it already does. I guess what I am getting at is that there are existing tools for managing cpu/mem monitoring and process restarting. What advantage are you wanting to gain by having yet another one written in Go (beyond that it is likely fun to write and perhaps easier to maintain than solutions in other languages)? 
Probably the dude that I got into an argument with. He seems to downvote everything in this thread that isn't his opinion.
I am creating a modular framework to be used in some of my apps. And I needed to execute spefific methods defined in the apps. I also didnt need the panics as mentioned in README since they were useless and not helpul.
Fixing the code you mentioned Epolevne wg.Add(len(chunks)) for i, chunk := range chunks { go func(index int, c ChunkScoreResult){ results[index] = Score(c) wg.Done() }(i, chunk) } 
I have the feeling you've been left using scripting tech from somewhere around 2006, and never discovered how people have sped things up since then.
Slight elaboration that I'm rather fond of: s/JSON/gzipped JSON/g Con: More complexity, albeit complexity that's relatively plug-and-play to add in. Pro: If you ever in the future need a binary blob for "efficiency reasons", you can just hex-encode[1] it in a JSON string. gzipped hexadecimal is close enough in size to the original bytes for most purposes (15-20% worst-case overhead for random payloads). And the mere fact that this is an option lets you decisively shut down anybody trying to add complications to your protocol. [1] gzipped base64 is even better (2% overhead), but only if the input bytes are relatively uncompressible (because base64 encoding breaks up any nice byte-aligned redundancies and makes them look distinct in up to three different ways). The hex vs base64 choice is immaterial, the point is that gzipping your JSON tends to be a good idea.
&gt;closing over "i" and "chunk" in a goroutine Can you expand on that? I've noticed govet complain about that but didn't really understand why. I thought this was the point of a closure?
I like the term "anti-abstraction language" since it describes Go pretty well. But I think that is not necessarily a compliment for Go. Abstractions can be horrible like some big Java frameworks, but abstractions are very useful and help to save development time and to avoid error. And abstractions are useful to separate concerns, e. g. separate technical from business logic. If you look at Go code it is often a mixture of low-level technical stuff and the actual logic. Take a look at this tiny Scala method to calculate a special discount for all order positions above $ 20.00: def specialDiscount(order: Order) = order.positions.filter(position =&gt; position.price &gt; 20.00).sum * 0.05 A Go fan once told me that code like this would be overly abstract and hard to understand. But what is the alternative? It would be a bunch of for loops and auxiliary lists. And in this mess of code it would be hard to find the actual logic and it would be easy to make mistakes. Abstractions are a good thing. It is just a question of the right level (and Go's level of abstraction is a bit too low, for my taste).
I kind of disagree with Go being anti-abstraction. Have programmers forgotton that you can reduce code duplication by function composition - the classic way? Or Closures? Methods? Interfaces? In my projects I've only ever felt the lack of generics when it comes to handling of model data (models as in MVC, but not necessarily limited to an MVC approach). The often named cases in that one needs the same function for and int and a float is so incredibly rare in a typical business application that I don't understand why it even is a thing. But handling data that you write to/read from databases, APIs etc. is the only part where I actually wouldn't know how to strictly enforce DRY.
I've switched working in python to working in go for internal components, and I'm way more productive in golang. The static compilation catches so many mistakes that would require a test run in python. 
Shouldn't the discount be a negative number?
The bowler hat, umbrella and union jack waistcoat give the gopher a distinctly English feel to it. Which is sad, because England is not the UK.
The discount itself is positive, but will eventually subtracted from the bill. Anyway, this is not *that* relevant for the topic here ;-)
Yup. You can even mix the two without additional bits for type specification, because a gzip stream's header and the legal start characters of a JSON stream of any kind (even bare strings or numbers) completely do not overlap. That's a dangerous shortcut in general, but safe here. So a protocol that was previously JSON-only can even be later upgraded to a gziped-JSON protocol with a minimum of negotiation.
I haven't updated it because it's mature. It's in use by me quite extensively and if you hit the [godoc reverse lookup](http://godoc.org/github.com/thejerf/suture?importers) others are using it too. The system I was going to think of as the benchmark is still in alpha (big system), but it's used in enough other places.
Well, partially. You still get two parsing passes because the first time through, RawMessage still validates the JSON, and the second unmarshal will as well. Point being, if you've got a situation where 99% of a multi-megabyte message is behind RawMessage, or you've got multiple layers of recursive RawMessage with a big message, you can hit some performance problems. If you know for sure that it's something small, though, it's pretty good.
Yeah, the imagery is very city-of-london-esque. My colleagues and I don't find it very appealing in a broader sense, and find (rightly or wrongly) that it reinforces the widespread opinion that the south-east seems to conflate itself as "the UK". I'd imagine it appeals to those outside of the UK and folk in the south east, but elsewhere, I reckon it probably grates.
thanks for posting, look forward to watching all of them!
You can use go to send a post/get request to your phantomJS app. 
And multi-megabyte JSON is going to be really slow anyway; at that point, JSON is just the wrong tool. Regardless of that, what the example code does is unmarshal-&gt;marshal-&gt;unmarshal, and there's no way for that to be less wasteful than json.RawMessage.
The biggest hurdle I had from python -&gt; go was the package organization. Golang has a different way of importing packages as well as using components within a package. 
I fixed the original post in the way recommended in the Go docs (with "i := i").
Why not use systemd?
For all the flak it gets for having everything and kitchen sink, it is a pretty good tool to supervise/limit daemons
&gt; Forgive the noob question, but what does that get you? It especially helps if you think of it as a cross-language API. Almost every language has an API for dealing with JSON now. But in general, the APIs have no support for parsing a JSON stream until "one thing" has been parsed, then passing the steam back to you somehow at the next point. (Those that can must also therefore refuse to parse bare numbers; there is no byte that you can read that is part of the number but also unambiguously indicates it has ended, the way arrays, objects, and strings have.) So you can't in general just start sending concatenated blobs of JSON down a pipe. Adding a length means that, one way or another, you can explain the situation to your local JSON library. Usually by pre-sucking the values into a buffer, but one could imagine wrapping an `io.Reader`-compatible wrapper around an `io.Reader` in Go that knows how to "window" the underlying reader correctly. The general read loop, minus the obvious error handling (so it's clear): size := make([]byte, 4) ioutil.ReadFull(reader, size) bufSize := binary.BigEndian.Uint32(size) buf := make([]byte, bufSize) ioutil.ReadAll(buf) // decode the JSON Of course there's error handling on virtually every step there. Incidentally, this is where io.ReadFull really shines. It is in fact an error in this code to call `reader.Read([]byte)` and assume that you got all the 4 bytes you needed out of it. It is perfectly legal to end up needing to call the Reader repeatedly even to get the first four bytes. Worst of all, the assumption _mostly_ works. `ioutil.ReadFull` is much easier to use; at the end of that call, _either_ you have an error _xor_ you've filled the whole buffer, and you don't have to worry about TCP's nasty little in-between states. 
It would be nice if things that I'd actually want to start on first request (test mysql/es/influxdb DB instance) would support that...
Can you publish some example code actually motivating this project? I'm guessing there is a more straightforward way to accomplish what you're doing.
Let me start by saying thanks for the detailed and informative response. &gt;(beyond that it is likely fun to write and perhaps easier to maintain than solutions in other languages)? Pretty much hitting the nail on the head. I have an existing project that uses digitalocean's api to spin up a vps, install my 'agent' which is a twisted service, that uses circus to spawn and monitor preconfigured applications on demand. (game servers, etc) I've delved into learning Go and think it would be a perfect fit, small binary, likely using less resources.
Thanks for the link. At least the readme on the repo is up to date, was updated 4 hours ago.
Amazing, thanks! I just came here to post your closing Keynote about community, I really liked it. [Damian Gryski - The Go Community](https://www.youtube.com/watch?v=IiSyFc10Jj0)
Thanks!
The Orange Order in Northern Ireland and Scotland often wear it.
If anyone else wants to binge watch the whole conference (about 9.5 hours), here are the videos in order of [the schedule](http://golanguk.com/schedule/). * [Crossing the Language Chasm](https://www.youtube.com/watch?v=JPVRnEZ4v_w) * [Stupid Gopher Tricks](https://www.youtube.com/watch?v=UECh7X07m6E) and [Building APIs](https://www.youtube.com/watch?v=tIm8UkSf6RA) * [Complex Concurrency Patterns in Go](https://www.youtube.com/watch?v=2HOO5gIgyMg) and [Building a Bank with Go](https://www.youtube.com/watch?v=cFJkLfujOts) * [Program Analysis](https://www.youtube.com/watch?v=oorX84tBMqo) and [CockroachDB: Make Data Easy](https://www.youtube.com/watch?v=33oqpLmQ3LE) * [Go kit: a toolkit for microservices](https://www.youtube.com/watch?v=aL6sd4d4hxk) and [Understanding memory allocation in Go](https://www.youtube.com/watch?v=zjoieOpy5hE) * [Dependency Management](https://www.youtube.com/watch?v=CdhucJShJU8) and [Whispered Secrets](https://www.youtube.com/watch?v=ViBRx-F4Z2U) * [The Go Community](https://www.youtube.com/watch?v=IiSyFc10Jj0)
Cheers, friend.
I think this article spells out something that some Go users have been saying for some time. I know I say it all the time. Most of the complaints come from people that haven't really used Go beyond just trying it out. And many seem to aim directly for the things it doesn't do when they try it out and complain about it. But when you actually get down to solving real wold problems you'll find that you don't do the majority of the stuff that you thought you did/would. And you also find out why Gophers tend to say they like it because they can get shit done. I wish more people would understand this instead of dismissing Go developers as Google fanboys. It doesn't mean that they have to like Go or use it. Just quit swearing that the do don't know what they're talking about.
Part of the complexity introduced by generics is already present in the language due to its builtin generics. A common thing people run into is that they have a []concreteType and they want []interfaceFulfilled. You have to loop through the concrete type and create a new slice to cast. So even though Go's authors wanted to avoid all this type system complexity the end result is the programmer runs into questions of invariance vs covariance regardless.
Also remember that you can easily watch talks at 1.25x or 1.5x and still totally understand the speaker.
Understandability has a lot to do with what you are comfortable with. In one case you have to simulate the state, in the other case you have to simulate the cascade and callbacks. I suspect that the "best code" for figuring out discounts would be in logical languages, not in functional nor imperative.
The reason conference organizers put Peter on the program is because their audience wants to see him. (Do you feel the same way about me, I wonder? (Rhetorical question.)) In any case, there are much more tactful and less hurtful ways of making your point. Hostile attitudes like yours are harmful for everyone.
Thanks, I'll be looking into suture later tonight.
&gt; But I think that is not necessarily a compliment for Go. I don't think it's meant to be, but I think it's accurate, and helps describe the language in better terms than it being a 'systems language' or a 'concurrency language'. It tells you something about when you'd want to pick it for a project.
Sometimes to overcome barriers to diversity one needs to be blunt. There's no evidence that this statement --"The reason conference organizers put Peter on the program is because their audience wants to see him" -- is true. Can you show me one conference that says, "we get the speakers you want to see"? No, I didn't think so. Furthermore, his conference talk was essentially the same at all three conferences he appeared at. It stifles diversity. It's in the interest of everyone if certain people--(Veronia Lopez, William Kenneyd, Peter Bourgon, Frances Campoy)--- don't dominate the speaker circuit unless they are giving a substantially new talk. Regarding your appearances, you seem to be an official representative/cheerleader for the go community, so I guess we have to put up with seeing/hearing you all the time. 
Maybe you could describe it as being very abstraction-conservative. Anti-abstraction is the attitude that 'you don't need map and filter if you have a for loop'. And of course, anti-abstraction doesn't mean to say abstraction-free, because otherwise you'd be using assembly. In Go's case it's not simply because the authors didn't like abstractions, but it was because they felt the necessary abstraction (generics) came at too high a cost. I think it's quite a fair way of describing the language: the opinion that the cost of abstraction is higher than the alternative, therefore anti-abstraction.
Let me make one other point. I heard Peter Bourgon for the first time on the Changelog and I thought he was extremely interesting and intelligent and an obviously very capable engineer. It's just that by speaking so often and saying the same thing, he's (as are several other people) depriving the community of opportunities to hear about what other people are doing. By the way Enneff, I don't think you should be giving lessons about how not to be hurtful or hostile. If I remember correctly, you publicly accused someone (on Twitter) of being curt with you because they wrote a brief "thanks" (rather than "thank you"???) in response to a comment you made.
This is my current git pre-commit hook for my local go project: set -e go test ./... go install -v $(go list ./... | grep cmd/) ./gml $(find -name lintclean -printf "%h ") The first obviously does all tests it can find. The second uses the standard "commands go under a directory named `cmd`", finds all of them, and "install"s them, which is pretty fast because it only builds what it needs to. This verifies that I don't blow up any of the several commands in this project, which is easy to do since these often don't get tested. The last one means that if you drop a file called "lintclean" in the directory, the checker will assert that it _stays_ clean in future commits. I don't necessarily need any of the linters screaming at me during early dev in a module, but once I clean something up and "seal" it, I want no regressions. (Otherwise modules have a way of just decaying...) The referenced `gml` is also a bash script: gometalinter \ --exclude="composite literal uses unkeyed field" \ -D gocyclo \ $* which is a place I've been using to tune gometalinter as I went. (I pulled it out so I can also invoke it manually, otherwise I'd just inline it.) [Justification for the settings deleted. You do your thing and I'll do mine. :) ] If this project gets big enough I may have to cut this down, but for now, worst-case is 5.3 seconds, best (and normal) is 1.7 seconds. This is quite worth it.
&gt; By the way Enneff, I don't think you should be giving lessons about how not to be hurtful or hostile. If I remember correctly, you publicly accused someone (on Twitter) of being curt with you because they wrote a brief "thanks" (rather than "thank you"???) in response to a comment you made. That tweet was a commentary the subtlety of written communication. I didn't think it was the fault of the author. Sometimes a curt "Thanks" can appear passive aggressive. That doesn't mean that it is, or that you should be offended by it. My comment was in part me realizing how easy it is to appear rude online, even with something totally innocuous. (In fact, your misunderstanding me strengthens my point.) BTW, when someone says "you're being rude" replying with "yeah well YOU'RE rude too!" relinquishes any high ground you might have had.
&gt; "The reason conference organizers put Peter on the program is because their audience wants to see him" The way conference programming works is this: - Organizers put out a call for proposals. They may also invite specific speakers that they think may draw an audience. - When the proposals are collected, the organizers review them all and pick the N talks that they think will result in the best conference for their attendees. &gt; Can you show me one conference that says, "we get the speakers you want to see"? I thought this should be self-evident. Most conferences are in business. They need to provide a good experience so that they can grow and get more paying attendees next year. If you doubt this, email any conference organizer and ask them why they choose the talks that they do. Your blunt criticism directed at the speakers themselves doesn't really help to improve the situation. It just makes people feel bad. (I certainly do; it's a beautiful Saturday morning and I'm having this conversation with you.) If you want conference organizers to broaden the diversity of speakers, tell them so. (Although if you're not actually a paying attendee then your opinion might not matter so much to them. That conference videos are released for free online is a pleasant side effect, but ultimately such videos are just advertising for the conference itself.) Meanwhile, don't begrudge people who have something to say from saying it. If the audiences really don't want to hear it, they'll tell the conference organizers and those speakers won't be asked to speak again.
At first glance this looks like a well-written little package. However, I think it's a recipe for disaster. Why would you ever want to cover up a panic? And won't go not compile code with an undefined method or a method with too many/few arguments...? I'm confused.
Great talk. I like the contrast between cultural mosaic and melting pot.
Because there's a difference between a slice *index* and slice *bounds*. Note that s[1] will give you an "index out of range" panic because s[1] indexes into the array, but s[1:] doesn't panic because 1 is a valid *boundary* of s. It's the same as s[1:1] which is, incidentally, both valid and an empty slice. Something like s[2:] will give you a "slice bounds out of range" panic, because 2 is beyond the boundary of s.
The indexes in slices are the points before, after and between the entries. So 0 is the start of the slice, and 1 the end. Thus the slice index is valid in and of itself, though that expression will always return an empty slice.
Why are you using `float64` instead of `int` for storing the guesses? Also, you should probably just call `rand.Seed(time.Now().Unix())` once at the start of the program.
Annotated a bit here: http://play.golang.org/p/eTwkCArUvF Note that block comments like that aren't really "the Go way" - I merely wanted them to be visually distinct from your comments. I iterated on it a bit while attempting to stick with the overall flow that you had created. Below is the progression if such a thing would be useful in learning: With the suggested clean-ups: http://play.golang.org/p/6JtARfM2_5 A bit more idiomatic: http://play.golang.org/p/J2TWA11Z4n And finally, a decent bit more idiomatic (and annotated) while still sticking to the general form of the original: http://play.golang.org/p/pxYw4vlKsa Disclaimer: I'm tired and only wrote these up in the playground, which is less than ideal for testing programs expecting input from a user. I hope they are educational but cannot guarantee that they are fully correct. All versions do at least compile.
It's concise through abstraction, since the details like looping and applying conditions are abstracted. But I don't find it overly abstract, too.
Enneff, at the time that you made that tweet, most of the conversation in your Twitter thread seemed to be about how everyone agreed with you that his "thanks" was inappropriate or rude, and not about the subtlety of written communication, and IIRC you didn't step into clarify that you weren't upset with the author (please correct me if I'm wrong), in fact it seemed you were at least indifferent or quite content that people were agreeing that he was rude, so (unless my memory is totally off--I haven't gone back to look at that thread), I'm skeptical of your claim now that you weren't in anyway upset with the author. But back to the main point, my criticism of Peter Bourgon and others like him is that they don't show self restraint in the number of speaking engagements they accept, and it's perfectly acceptable for me to post that message on a public message board. Furthermore, I never said anything else negative about them, only exaggerated the number of times they've spoken (a gazillion instead of three or four), so what exactly did I do wrong? And why would I message the conference organizers if I'm asking these speakers to show self-restraint in the number of engagements they seek out and/or accept? Other people posted negative feedback about some of the speakers at Gophercon (in fact the speakers from Google who openly admitted they weren't prepared to speak) on public message boards. By instructing me to message the conference organizers directly, you're basically saying that my feedback shouldn't be heard by the community. It's not up to you to decide who's feedback should get heard or what's inappropriate and if I don't break the rules of the Reddit board then maybe there's no reason for you to intervene here. In fact, I think your time would be better spent making sure that the person you linked to on Twitter for his "thanks" wasn't made to feel bad for being a public example. 
A little OT, but you forgot lizard and spock :D
Thank you very much, I'm glad to know that for my first time doing anything in go and first time coding anything in a long while that it wasn't too incredibly wrong - the cleanups do definitely make sense. The more idiomatic versions I will need review closely and make sure I understand. 
Here's an illustration of what everyone else is saying: http://play.golang.org/p/5L_1yLTIrn Basically, bounds don't indicate the elements themselves, but instead the points before/after them. The point immediately after the last element is a perfectly valid bound.
Thank you! I was trying to find some doc!
Here one of the organisers, from the CFP of the conference the process was: &gt; Using an anonymized list of all papers (contains talk title, abstract, and 'why you should choose this talk'), the organisers rate each talk from 1-5 to create a shortlist of around 40 abstracts. &gt; Abstracts are then discussed and put in order of must have talks, with the top 20-30 papers being the focus. &gt; Submissions are then deanonymized and final selections are made based on the speaker's location/cost of travel and level of the talk. Making the schedule was the hardest part of the conference, we left out some good talks and tried to balance the level of the talks and the type of speakers. I personally push up the talk by Peter Bourgon, because I know that the quality of the talk would be good and I know Microservices is quite trendy at this moment in London, so for people that want it to go to the conference and has to convince the boss would be easy sell. Is good you comment about Dean's talk (really good talk in my opinion) because was at the same time that Peter, so people during the conference had the opportunity to see Dean or Peter. Any feedback for the next year would be appreciated 
Is there a good reason why the slice bounds and the index bounds are different? Why not just make it `s[startingIndex:endIndex-1]`? In which case, `s[1:]` would panic because 1 is out of bounds. Seems like the intuitive way to do it, no?
If `[]int{0}[1:]` is out of bounds, so is `[]int{}[0:]`, and equivalently, `[]int{}[:]`. I don't expect to panic when I say "give me all of this empty slice" - I expect to get an empty one. More generally, I think that an empty slice is a valid thing to expect to get in a lot of cases. I find that the current functionality does what I expect almost all of the time. On a related note, I really like that `s[:len(s)-1]` gives me a slice with all but the last element. (I think this is probably on account of my brain making fencepost errors).
It's a bad habit to seed rand more than once. It gives you no benefit, and it actually introduces a security vulnerability if you ever end up in a position where that matters. The vulnerability is that when you control when the random number generator is seeded (ie. current timestamp of the request), then you can easily guess what the next random value will be (given a known seed, the sequence of random numbers is deterministic). And of course for anything security-sensitive, crypto/rand should be used instead but that's even further out of scope here. Obviously not an issue with a toy game, but still a bad habit. :) On the other hand, if you're writing tests, then being able to seed the engine on demand is really valuable for deterministic results. Better yet, replace the random number generator with a deterministic one you mocked yourself.
[removed]
We could make it panic on all of those cases, but we wouldn't say "give me all of this empty slice" anymore. Instead we'd say, "give me all of the elements between 0 and len(s)". Which *should* panic because there are no elements. That could also preserve `s[:len(s)-1]`. But, I suppose I'll just have to learn to think about it the way it's implemented. Fine. :|
Start with [Golang Book](http://www.golang-book.com) and after [Effective Go](https://golang.org/doc/effective_go.html)
The plugin should take care of all the imports (minus automatically removing them when unused right now) so I'm not sure about the need for goimports but this is still another valid option. 
I really liked https://gobyexample.com/ when I was first learning go.
+1 - This in combination with the official docs is ace.
I blogged about how i learned go: http://andygrunwald.com/blog/2015/06/20/resources-to-learn-golang/ Maybe helpful
Thanks for pointing that out! I edited the article to include your notes.
A lovely bunch :(
&gt; [Rust] has it all: proper type inference, generics, automatically derived traits, syntactic macros, all manner of fancy compile-time checking. The author suggests Rust has (or had) automatic derived traits. Does it really have (or had) this feature? That I know of, Go is the only mainstream language with this feature, for interfaces.
Rude. While the code certainly isn't the cleanest, the author's pretty clear that the example is a stripped down version of actual code; which probably makes more sense in context. If you want to critique the code example, that's fine. But don't be a friggin jerk about it.
I don't know if the `Options` struct is the better way... In my opinion, is better "GetManyByName"... `Options` struct would be nice, for example, to indicate if you want sort the search. 
&gt; Is Go a good fit for this? Yes, go has been already successfully used for all of the named things. :) &gt; and where does it lack ? Currently GUI apps. Hopefully that will change over the next year or so, there are two very promising contenders. &gt; ( other than the mobile apps ) Go is actually one of the best languages for developing mobile apps, after the native ones (java/obj c. respectively for android/ios). :)
Nice, but the use of gorilla.Context will lock the context map for each request, I don't think it will scale well :(
I had seen that site, actually. I need to check it out further.
Will definitely check it out!
Resources upon resources! Thank you!
I'll check it out once I make it out of gobyexample.
If you are interested in web development, write a website or app with minimal third-party module usage. I mainly use Gorilla's mux and websocket modules in addition to github.com/lib/pq for my postgreSQL driver. Start with serving just a string, then a static page, and then start adding routes and experimenting with controller functions. I recommend [this book on building web services.](http://astaxie.gitbooks.io/build-web-application-with-golang/content/en/index.html) You'll want to use html/template if you want to serve web pages. An example of a static template composed of other templates would be: {{define "index-loggedout"}} &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; {{template "header"}} &lt;/head&gt; &lt;body&gt; {{template "nav-loggedout"}} {{template "news"}} &lt;/body&gt; &lt;/html&gt; {{end}} Making your own user authentication module is a good next step. It will get you comfortable with the different http methods (ie: GET, POST) and database interaction. A minimal *user.go* I developed has the following functions: * hashPassword(password) hashedPassword string * addUser(name, password, email) success bool * userExists(user) exists bool * newSession(user) authKey string * sessionIsValid(authKey) valid bool * deleteSession(authKey) err error * getNameByKey(authKey) userName string powering the following endpoints: * / (GET) -&gt; logged out page || logged in page * /login (POST) -&gt; error string || set auth cookie * /register (POST) -&gt; error string || set auth cookie * /logout (GET) -&gt; delete auth key from session table Where jQuery handles ajax form posting, displaying error messages (eg: incorrect login, user already exists, password too short, ...), and refreshing the page upon authentication. A real web service will need additional functions like account recovery, email verification, and editing account info, but these are the essentials. Once you have your user authentication infrastructure set up, you are ready to build out your application. PS: Make sure you adhere to security standards when handling user info. Most importantly: you may only transmit passwords or auth keys over SSL (https), and you may only store securely hashed passwords generated by libraries like pbkdf2. You can set up an http -&gt; https redirection server with 3 lines of code right before you start your secure server. go http.ListenAndServe(":8080", func (w http.ResponseWriter, r *http.request) { http.Redirect(w, r, "https://your-website.com", http.StatusMovedPermanently) })
http://golang.org/doc/ walks you through quite a lot, just keep reading in order and write little programs as you go along.
Very nice! Just to complete, a few days ago I wrote a simply crud using MySQL driver to teach in an easier way. [Github - Go MySQL Crud](https://github.com/gustavokuklinski/go-mysql-crud/)
Go was built as a language for large high-performance systems, particularly servers that handle tens of thousands of simultaneous requests. Hence the centrality of concurrent I/O to the whole design. Consider where it's coming from. Google production is historically a C++ and Java shop packed full of multi-layer services tied together with [protobuf](https://developers.google.com/protocol-buffers/?hl=en)-based RPC. Handling stupidly huge numbers of requests per second is kind of what every Google service is about, and that's what Go is built for. Go is safer than C++ and faster than Java. It's less verbose than either, and it compiles incredibly quickly — something that matters in a large organization with thousands of source files. And Go's toolchain encourages a range of software engineering practices that matter primarily in large organizations. Just to pick a trivial example: Having all the pigheaded coding-style arguments settled once and or all (by `go fmt` reformatting everyone's code to look the same dumb way) *actually matters* when you care about the human time of thousands of coders who are passing code-reviews around among multiple time-zones, where a quibble about indentation might cost someone a day's time before they can get their change in. The fact that Go is supplanting Python for system automation tasks says more about the problems of Python than the design of Go. I've been using Python for ~14 years and it's still my primary language ... and getting good performance out of it has never been straightforward, especially once concurrency is in the mix. And as sysadmins scale systems from three servers in a closet to three thousand servers in the cloud, concurrent performance starts to matter a hell of a lot.
I [like this golang talk](https://vimeo.com/53221560) by /u/enneff that walks you through building a chat program. The chat program goes from a command line interface, to using websockets, to having AI that simulates users. The talk shows the power of golang's type system.
Remember to be careful with it though. Since it is inherently racy, you can take the number of items in the channel, then try to send/receive from it according to the value you got. But that value may well change between those two operations, making the len() useless, since you must take into account that the channel is full or empty at the send/receive operation (Using select) if you don't want to write if it's full or something like that.
From [line 148 of builtin.go](http://golang.org/src/builtin/builtin.go?s=5727:5747#L148): 148 // The len built-in function returns the length of v, according to its type: 149 // Array: the number of elements in v. 150 // Pointer to array: the number of elements in *v (even if v is nil). 151 // Slice, or map: the number of elements in v; if v is nil, len(v) is zero. 152 // String: the number of bytes in v. 153 // Channel: the number of elements queued (unread) in the channel buffer; 154 // if v is nil, len(v) is zero.
Yeah, I am really interested in the idea of concurrency through communication. It is, by far, my favorite part of Golang.
Using select is generally the best way to deal with any complex channel flow.
Well sure, using select is slower than not using select. But not much. If you're truly worried about the overhead of select becoming an issue, then the right answer is going to be more complicated. What I meant is that it doesn't usually make much sense to worry about exactly how many items are in a channel. Consumers just consume, and producers just produce. It usually works just fine, and usually better than over thinking the problem, i.e. trying to be clever based on len(). And because that is generally true, many Go programmers are surprised to learn that len() world on channels.
It can be useful for monitoring, or other cases where using a slightly stale value is acceptable (like the load-balancing case /u/Fwippy mentioned).
I am sure the go mobile is just used as an alternative to game dev and for making libraries for those platforms. It can't replace Java for android or swift/obj-c for iOS with regards to normal apps.
Not much to do with op question but is that code racy? (assuming ch2 len is modified in other goroutines) ch1 &lt;- len(ch2) 
Kingshard support join in unshard table, but don't support join in sharding.
I found a use case in throttling requests that are handled concurrently. When you spawn new goroutine that handles some request you increase number of handled request at the time. If you have buffered channel "make(chan struct{}, maxRequestAtTime)" that signals done from the request goroutine you can use len() against the channel to "empty" it from signals that don't need throttling.
yes, as the whole operation is not atomic.
Also, I believe go has quite a lot of new things to learn for the named set of languages. Or rather "quite a lot of old things to unlearn". The language might be boring as a language, but it is quite challenging to learn as a philosophy (in fact, quite a few people posting here on the reddit *don't* get that part very well).
Shouldn't you close the pool channel at some point to let the workers exit?
&gt; GOPATH is weird. Once you get the hang of it, it’s fine, but early in my Go programming days it caused plenty of confusion. It feels like a bolt-on, and I’ve learned to use a separate GOPATH for every project. It doesn’t feel right, an often I wonder how it made it into the Go system. Why would you do this? This is pretty much exactly how you are not supposed to do it. Read http://golang.org/cmd/go/#hdr-GOPATH_environment_variable And then you should vendor your projects dependencies with something like godep, if you need it.
https://github.com/golang/go/issues/12488
I may be oversimplifying, but doesn't this provide the same guarantees as an buffered channel with a large-enough-to-cause-memory-problems buffer? No queue can provide the "you can always send" guarantee, surely? If the producer outpaces the consumer, you'll accumulate in the queue until either you hit a preconfigured limit (the case with the buffered channel) or you hit system resource limits. There's also the question of the utillity of a queue which doesn't keep up. Why queue more items in that case? At some point you need to drop stuff on the floor, which is exactly what a buffered channel with the 'default' case does.
This is the sort of instruction I have been looking for. "Composition" is such an integral component to designing go applications, it's surprising how difficult it is to find anything beyond the basics. One big question I have about the interplay between structs and interfaces is simply: what happens when an interface needs to access a struct property? Should I just pass the struct into the interface function parameter? Is it code smell?
Not sure I understand your question 100%. If your code needs to access a field, you must perform a type assertion and pull the concrete type value out of the interface value and work with the concrete type value directly.
So I should never try to access a struct field from within an interface? Like if I embed an interface within a struct.
&gt; There's also the question of the utillity of a queue which doesn't keep up. The use case for this is bursty traffic. The system does keep up generally, but the queue absorbs the bursts when they do happen.
The primary reason for garbage collection is not to make freeing memory easy and avoid leaks, but to ensure that data lives at least as long as it has to. Freeing memory is easy, but when it's not clear who is the owner of some object, you might free too early, or free twice, both of which result in undefined behavior in C and C++. RAII smart pointers can prevent leaks, but they don't ensure the validity of references to the owned data (references into vectors are invalidated when the vector's array is reallocated and elements are copied, for example). Edit for the downvoters: From the [Go FAQ]( http://golang.org/doc/faq#garbage_collection): &gt; Another point is that a large part of the difficulty of concurrent and multi-threaded programming is memory management; as objects get passed among threads it becomes cumbersome to **guarantee they become freed safely**. Emphasis mine. It's also listed and explained in the .NET CLR's [Book of the Runtime](https://github.com/dotnet/coreclr/blob/master/Documentation/botr/intro-to-clr.md#the-clr-garbage-collector-gc): &gt; 2.Garbage collection eliminates a whole class of common user mistakes. It is frightfully easy to make mistakes concerning the lifetime of a particular object, either deleting it too soon (leading to memory corruption), or too late (unreachable memory leaks). Since a typical program uses literally MILLIONS of objects, the probability for error is quite high. In addition, tracking down lifetime bugs is very difficult, especially if the object is referenced by many other objects. Making this class of mistakes impossible avoids a lot of grief.
I used it in a rate limiter just now from reading this post... https://github.com/jasonmoo/cloudwatchlogger/blob/master/rate_limiter.go
@sindbis linked to the blog, not the blog post. When the blog is next updated, your link won't make sense. If any future internet people need it, here it is: http://www.goinggo.net/2015/09/composition-with-go.html
Have to agree completely. Node.js just sucks. I can't help but feel the Node.js developers had the thought "hey async is awesomesauce! Everything should be async! Waiting for io is for dorks!"
Totally didn't catch that! Thanks!
Fair point.
I can't really give you an unbiased opinion, as I loathe Node.js and its event driven madness. But I can tell you that Go's use of CPU cores is leaps &amp; bounds better, seeing as Node isn't multicore. Not to mention Go will be quicker than Node in many other ways, too. The thing you really have to ask yourself, is this worth the cost of a rewrite + learning a new language &amp; its idioms? My experience is that it was definitely worth it, but those three months of not adding value to my business was *hard* - but now that I'm on the other side of it I'm very very happy I made the change. However, I like Go's clean syntax &amp; idioms so YMMV. Maybe you should just implement [clustering](https://nodejs.org/api/cluster.html) into your project?
OP wants concurrency, I think that out of the box Go offers better concurrency support than the languages mentioned. Node doesn't support CPU core concurrency without clustering.
If I read this correctly, you want concurrency, but you currently store the game state in memory that is only available to the process itself? &gt; in-memory databases will not remedy my particular issue because I use object references within the buffer data Go will not solve your issue. I would recommend you to consider refactoring your code in a way that an (in-memory) DB can be of service here. 
Just yesterday there was an article by someone who switched from node.js to go: http://www.philipotoole.com/400-days-of-go/ I tried to look carefully at both node.js and Go before making the choice for my current project and went with Go. It has been working well so far. One think where node.js seems to be superior is parsing JSON, as Go uses a lot of reflection to achieve that. But as you point out, Go is much better at concurrency. Have you thought about moving the state/cache to some other database, like redis?
&gt; One think where node.js seems to be superior is parsing JSON... When you want performance, you probably shouldn't be using JSON in the first place. i.e. Cap'n Proto or FlatBuffers would be probably more appropriate.
&gt; I'm not clear on the why/how... but it sounds like a bad idea. Yeah, [just created a question](https://github.com/nodejs/node/issues/2874) about that. Thanks for your concern! However, I am starting to lean closer and closer to Go :) I'm getting a bit frustrated with nodejs` single core bound / clustering thingabob. 
This is probably not the part of the code that is causing the problem. Actual problem is somewhere inside handler because "/usr/local/go/src/net/http/server.go:1287 +0xb5" will execute only if there was panic wile handling request. Check code that is depending on wrapper functionality. Possibly something to do with writing to response writer.
Reading the thread here, you already seem to have decided to rewrite the thing in Go, but as some people already suggested, I'm not sure that would solve all your problems. It seems like not knowing the limitations of the platform and not designing for such scale is what got you. With a redesign this could probably be done in Node too. I personally wouldn't do it, but that's just my preference. You mentioning 5000 separate games seems like you could even easily do this with just running multiple Node.js instances on the same server, each fixed to a different core, and running a reverse proxy in front of it and some sort of tagging so the same client of a game always ends up on the same instance. But in the end, your application is not designed to scale. There are many ways to do that, and if your game does not need some global state shared between different games, it might be pretty easy. Now some people propose using things like Redis - which can partially solve things for you, but be sure you know what you're getting into - Redis and other nosql/in-mem db's also have (serious) pitfalls. Redis for example will become tricky once you would have to go beyond one server, and on top of that, if for some reason your Redis server is restarted - you lose all data. Another thing to mention is, if that's going to be your first application in Go, it will end up not being the best Go code ever written. You'll not be familiar with the language, it's best practices, it's do and dont's - and you'll make a lot of mistakes initially, which might end up in your core design and bite you in the ass afterwards - but you sure would learn a lot :)
In C++ you could access that other memory directly but you really shouldn't. It's chock full of hazards. There are reasons RPC boundaries exist. A single in memory DB is the way to go; redis, mongo, etc. It handles the isolation for you so you don't have to worry about those hazards.
Honestly, you will make dumb decisions. We all do, and that's how we learn to write better code. The fact you are trying, seeking advice, and considering others opinions means you are on the right track and going to do great.
i don't get why so many people is confused with the GOPATH i find it way way easier to work that virtualenv and much much simplier.
Don't use the Erlang VM for anything with a heavy compute load. If you game has trivial logic and is mostly routing communication, it's fine, but if you start in with serious AI, it'll rapidly become too slow.
sounds like a good use case unfortunately one of the things node does every time you call an array func like `map` is wrap the source array in an object {}, so its definitely slower than using a typed language. 40k lines of node is probably 60k lines of go... but porting goes pretty fast once u get the datatypes done. the syntax is way more terse... one guy made [iGo](https://github.com/DAddYE/igo) that has a coffeescript like syntax. you can try it but last it was updated to go 1.3, so i cant recommend it idk if it still works.. one thing you can do is profile the cpu usage of your node app... i like this quote the pareto principle, 80% of the bugs are gonna be in 20% of the code, (or... 80% of the bottlenecks are in 20% of the code)... i find its true and i find that its even better, sometimes 95% of the bottlenecks are in only 10 lines of code. or set a task for each core, one for managing users, one for maps, one for chat, one for http, and 3-4 to the rooms (especially pathing i guess)... should help and not be that hard. and last you could try compiling your game to ASMjs... it replaces all the V8 builtins with tighter ASM JS implementations (ie no {} objects)... its possible you can get 2-300% gains from that.
&gt; Go allows you to integrate with greater ease specialized languages for significant parts of your larger projects that have special needs genuinely curious ... would like to see some examples
&gt; The very fact that it is easy means it isn't that great to "keep my wits sharp". They shouldn't have to rely on the language being difficult for this. If someone wants to keep their wits sharp, they should solve complex problems with a language and not fight the language/tools themselves.
You have 5000 games, that's 5000 logical pieces you could break the work into. Obviously you don't want 5000 copies of node running on one machine, but you should be able to chunk the data up so that, say, you have 5 processes each with 1000 games, and each should take about 20% of the memory. The hard part of concurrency/parallelism is identifying the ways you can break up the work, and then cleanly separating it.
awesome. Already using it. Thanks for sharing.
http://play.golang.org/p/XeDIPXXGgy These are the simple changes I added out this morning to make it easier to add commands.
Wow. I need to read this a couple of times but will file it away for later. Having an example of practical profiling or assembly-peeping keeps Go in a very credible position for projects that might eventually worry about such things. (I have some gaming/search-tree/simulation ideas in mind.) Bookmarked and thank you.
&gt; And having all my memory multiplied across processes just screams horror and I couldn't live with myself. Why though? Does your server have enough ram to handle n node processes running? If so, it's not a big deal. Sure it might make you feel dirty deep down but if you're not memory bound starting up extra processes is a lot easier than a complete rewrite.
Don't [websockets](https://en.wikipedia.org/wiki/WebSockets) do this? I believe they are over TCP and use standard http ports...
Would this need to be a actual web application or can i have it as a .exe?
I guess the declaring types inside/outside of functions makes sense... I've never really thought about it before. `type ...` is figured out a compile time, and so the only difference between func foo() { type bar string } and type bar string func foo() {} Is the scope of each type. It'd make no sense—and I'm not even sure how they'd implement it—to be able to declare a new named type every time a function or method is called.
Not sure why you are characterizing this as a reverse TCP connection. The normal use case is that a client opens a connection to the server. The connection is two way - they can both talk to each other on the connection. Do you mean that the server should be able to open a connection to the client? Here is a code example. https://systembash.com/a-simple-go-tcp-server-and-tcp-client/
&gt; Either Go is really easy to learn, or Go keeps your wits sharp. Writing a real-time physics engine has challenges regardless if you use a language like Go or C++. My argument is that actions like making a real-time physics engine is what keeps you sharp not learning the tool itself.
It' s the same type of lock that's used in ServeMux. Why wouldn't it scale well in gorilla if it obviously scales well in ServeMux? https://github.com/gorilla/context/blob/master/context.go#L14 https://github.com/golang/go/blob/master/src/net/http/server.go#L1590 
I think the point is just that it would be nice if the compiler would enforce this for you instead of having to DIY. Generally speaking, I think the opinion of the Go team is that it's better to just use convention instead of compile-time contracts (see `interface{}`) in order to avoid over-engineering, but it would be nice if there were a few more options in this regard.
Normal sockets work just fine; websockets only really exists so that you have a defined way to get a TCP socket going on a port that is *also* doing HTTP. If you aren't running an HTTP server - or don't really have any issue with clients having limited outbound traffic, which is often the case, and can therefore use an arbitrary port - just use native sockets.
Maybe you can use 'go generate' https://blog.golang.org/generate 
If you're interested in something a bit more advanced, I've [got a slackbot I've been working on](https://github.com/mhoc/jarvis) in Go for some time now. There aren't that many commands yet but the fundamental framework around what commands there are is pretty cool IMO. One thing I learned: **Do not use golang.org/x/net/websocket**. It has bugs which make it completely non-compliant with the official websocket standard. I ran into several weird problems, like the websocket spontaneously disconnecting without telling me. Gorilla's is better.
What makes Gorilla's websocket library so much better than net/websocket? I rewrote the [nlopes/slack](https://github.com/nlopes/slack) library's websocket handling with net/websocket and I didn't think it was too bad.
[Among and beyond the many complaints from the Gorilla devs](https://github.com/gorilla/websocket), /x/net/websocket... * Does not pass the [Autobahn Websocket Test Suite](http://autobahn.ws/testsuite/). Essentially, that means in some way it is not RFC-6455 compliant. * [Cannot receive fragmented messages](https://code.google.com/p/go/issues/detail?id=7632) even though Chrome is universally known to fragment large websocket messages. * And on the hilariously ironic flipside: [Cannot receive messages that are of some significantly large size](https://github.com/golang/go/issues/2134). Ignored since... 2011. I like this comment from the owner of that issue: "we're still discussing what the right websocket api is." August 8th, 2011. * [Does not send 'close' messages](https://github.com/golang/go/issues/4588). Golang devs have been silent on this one for three years. * [Does not send and receive pings and pongs](https://github.com/golang/go/issues/5958). Ignored since 2013. * [Cannot close with a custom error code and handler](https://github.com/golang/go/issues/4588). 2012. Essentially, the developers of go no longer work on that project. The entire codebase of /x/net/websocket should be deprecated. If anyone tries to download it, the go compiler should print a warning in bold red text saying "Do Not Use This". 
I think this is it. I haven't located the exact problem yet, but there is some very suspect error handling in the handler where it is trying to read cookie data that wouldn't exist in this case. Thanks!
It looks nice. I recommend using slugs instead of note ID in the URL for better search engine optimization.
Also, memory for executable code, such as node and its shared libraries, should be shared across all instances of the process.
would you mind clarifying what you mean by "you need to know the on-disk serialized format of trees"? The api is quite minimal but the current focus is only on reading and writing dangling objects. Should probably list that in caveats.
I actually didn't know that! Cheers!
We used it for some cross platform automation for a customer. Essentially we needed automate SSH/HTTP commands into other servers, extract a lot of data and do some additional behaviour. So where we'd normally use a series of bash scripts and hope the servers provided had all the dependencies, we used Go to deploy to both Windows and Linux servers and used some external packages for SSH functionality. It then provided a web ui for all staff to use and to clean up was just delete a directory. Saved us from managing dependencies and version differences, UI was better because of web interface, deployments was just stop old binary and start new, deployed on both Windows / Linux.
Awesome, though one thing I'd like to know is how using *anonymous structs* would impact performance. e.g. dummy := struct{ Name string }{ "John Doe" } vs type user struct { Name string } dummy := user{"John Doe"} 
Hey! This is a very good idea and I might do the same in the future! In the meantime, I modified some code and made a pull-request! https://github.com/kiwih/heyfyi/pull/3 I see you have parameters hardcoded in the source, and a better way to do that is to have parameters as environment variables: http://12factor.net/config So basically what I did is: + Add a .gitignore file ignoring _ENV.sh + Add an ENV_SAMPLE.sh file + Add code to read environment variables So now you can have a file named DEV_ENV.sh in your source tree on your development machine with all your parameters, and customize it without worrying of configuration getting shared in the commits. There are some great horror stories of people publishing ssh keys and/or API keys in the form of publicly readable git commits on github. When you're starting development, make sure you run: `source DEV_ENV.sh` to load all the environment variable from the `DEV_ENV.sh` file :) Example (from the pull request): /* On platforms like heroky/dokku this should be PORT, not HTTP_PORT. */ HTTP_PORT = os.Getenv("HTTP_PORT") if len(HTTP_PORT) == 0 { log.Println("$HTTP_PORT was not set, defaulting to 3000") HTTP_PORT = "3000" }
you can actually do that: HTTP_PORT=8080 yourcommandhere
I'm a relative Go noob, especially when it comes to webdev. Is it usual to put the main() function in a subdirectory? I was trying to find it as a starting point, but you don't have a main.go in the root of the project and after a bit of looking around I found it in /run. Seems a bit strange to me.
Google already has it on the list of approved languages. Google is pretty serious about Go, and what slips through seems to show to me that they actually want to rewrite a lot of systems step by step. Don't know if they want to get rid of all the C++ code, but I can imagine it...
I agree with this - I use managed Azure with my company, and that passes in stuff from environment variables. At the moment, the arguments (such as the server address) come from a flag (or it should have done, the fact that it hadn't was a bug). Just looking at your change, I spotted this though: if len(COOKIE_STORE_SALT) == 0 { log.Fatal("$COOKIE_STORE_SALT was not set, cannot go on. Exiting.") } else { store = sessions.NewCookieStore([]byte("9s7YD807h*&amp;DHhihSD123434SASDD__834HUSJNCxczc123!@#sd85")) } That doesn't actually use the env variable! I'll accept then modify it to. EDIT: Done this, and moved the environment variable loading into the run package.
Yes, but: 1. That functionality is actually provided by the shell, not go (this is fine, just pointing this out). 2. If doing this, altering the configuration may require an edit of the Procfile (and a totally unneeded commit). Configuration is not code.
It's something we started doing at our company. There are three main reasons, at least for me - a) You can use the loader package to hold non-go things, i.e. templates, static files, etc. This is just an organisation thing, and mostly personal preference. b) Your loader can pass in the arguments and it's easy to change how this is done (see the latest commit - the run package loads the environment variables instead of the heyfyi package) c) We like to use GoDoc on all of our code! You can't (to the best of my knowledge) use GoDoc on a 'package main'. So, by having a different package main, then we can use GoDoc on them. 
You are right, I misunderstood the API. my point still stands, basically: You pass back an io.Writer, to which I need to serialize a tree in a certain format and your library then parses it again and transforms it into the on-disk format. This is brittle. As a user of your library I now have to take extra care, that my serialization is safe and correct. If I take user-data (which is pretty likely) this is very hard. Why not define, e.g. type Tree []TreeEntry type TreeEntry struct { Mode int OID [20]byte Name string } or something similar, so that I can create and pass a `Tree` in and I get compiler-checked and faster writes? The API just seems bottom-up instead of top-down: Instead of thinking about how the library should be *used* and then write an implementation of that usage, you instead seems to have thought about how you would *implement* it and then wrote an API for this. This is basically the lowest layer of a git library -- a layer so low, I wouldn't even export it to the user. As an aside: You updated your README to say, that you only handle "dangling objects". I think you mean "loose objects", which is the normal nomenclature of git. "dangling objects" are usually "unreachable objects", e.g. when you go into detached HEAD state, commit and then checkout a branch, the commit you created is dangling, because there is no branch that can reach it. 
Check out pgweb. Its the most beutiful code I've ever seen both in frontend and backend. Not saying it's the best approach but you can and imo you should put main.go in the most upper level. It makes everything easier for the new lookers
&gt; pgweb It does seem quite clean! For Azure, we have to make the most upper level package main, but I find when developing non-Azure projects I swap back to this layout (I just find it cleaner for some reason!) It does seem that more people do it the other way around though, so I will bear that in mind.
Nice! :) Aside from the technical point, your background is inspiring. Getting to learn to code, and to do it good, without any professional working experience deserves praise. Yes, code will get you out of abysmal poverty, good luck with finding a full time job, you definitely have the chops. You might want to look into remote work, full time or contracting, there are a lot of startups looking for good Golang devs, take a look at angel.co, golangprojects, weworkremotely or similar sites. You may not have a juicy CV, but you have a great github repo. Cheers!
[Basecamp uses Go](https://signalvnoise.com/posts/3897-go-at-basecamp). Wether or not Basecamp counts as "enterprise" might depend on your definition.
Examples of what? Go gives you a decent but not overcomplicated type system and good support for concurrent and parallel execution of code. Some people like the VPRI folks are trying to integrate languages on a lower level (roughly a BCPL level) but that puts greater burden of proof on the higher levels that you won't screw up at runtime, and concurrency and parallelism in shared memory on current architectures are not even considered (they appear to be trying to avoid it, which is not practical until future computers drop the multi-core approach). On the other hand, you could complicate the language further (like Haskell does, for example) but there appear to be diminishing returns with those efforts.
If you wanted to make it completely self-contained you could use [ql](https://github.com/cznic/ql), however I've just tried to do a quick replacement and it's throwing errors --- to do with the sql-dialect and the gorm &lt;-&gt; db mapping and not your code. It may be more effort than it's worth. Especially if the plan is to use it for production. I should say, I'm going to find it useful to have this sample to work from for a small pet project I'm working on at the moment!
MediaMath has many services running in produciton. One example - https://github.com/MediaMath/grim
I seemed to have overlooked this entire paragraph somehow &gt; The API just seems bottom-up instead of top-down: Instead of thinking about how the library should be used and then write an implementation of that usage, you instead seems to have thought about how you would implement it and then wrote an API for this. This is basically the lowest layer of a git library -- a layer so low, I wouldn't even export it to the user. This actually isn't true at all. Right now, I have a broken program that use to work that is going to depend on this. In that (unpublished) program, I have the general feel for what I want to type to make stuff happen. In fact, this is how I always start most *anything*. Type what I wish worked, then make it work. Regardless, I wanted the implementation to be robust for unaccounted cases. So when I started asking myself, "what *is* a blob", one of the first conclusions I drew is that is nothing more than compress/zlib.NewReader prefixed with a header. That's why if you look at git.Reader, it has a Reset method very similar to zlib for efficient reuse of multiple reads and requiring very little legwork for what I consider a win for a very basic type. I haven't completely decided the approach to take, but likely there will simply be a git/gitutil package, similar to io/ioutil, and most users will likely want to import that. The package isn't quite there yet though.
Neat. Smells more like distributed programming than a synchronous channel can provide. Could help one prepare to move goroutines between address spaces or on to a networked grid (netchannels?)
I see you post a lot here. Keep up the good work man. The language needs more ambassadors like you.
That's a great point. I guess I misinterpreted OP's post to mean some kind of webserver (with clients as browsers). I blame too many postings on about webapps. Using native socket's in go is also easy! There are some examples in [the net package](http://golang.org/pkg/net/).
Please correct me if I am wrong, but it look like it is not distributed yet. From the roadmap : https://github.com/pingcap/tidb/blob/master/ROADMAP.md Distributed KV and distributed Transactions have no checkmark! So in it's current state, how does that differ from using sqlite?
I'm not sure why you're trying to do this, but this potentially inefficient implementation should work: +/u/CompileBot go --include-errors package main import ( "bytes" "fmt" "io/ioutil" "net/http" ) func checkIP() (string, error) { rsp, err := http.Get("http://checkip.amazonaws.com") if err != nil { return "", err } defer rsp.Body.Close() buf, err := ioutil.ReadAll(rsp.Body) if err != nil { return "", err } return string(bytes.TrimSpace(buf)), nil } func main() { ip, err := checkIP() if err != nil { panic(err) } fmt.Printf("CheckIP reports %q", ip) }
It doesn't work in whatever sandbox CompileBot runs in, though.
We're at the initial stages of adoption - I currently hack at a large national mapping agency and have argued the case for go. I'm looking to use it for microservice and some command line tooling. I'm especially interested in the c integration with gdal and proj4 (eg https://gist.github.com/schoenobates/f6ca293eadfe2b7b4157)
Solid documentation, tests pass. Heck, the existence of tests is a good sign. It shows you put a lot of effort into this. Nicely done. I'll be trying this out. Thanks for sharing!
How is it inefficient? As far as i know this is the only way to get the systems external IP... I need it in another function for calling at anytime, like so; Server tells client to tell its IP -&gt; Client tells IP to server -&gt; Server tells Client to change IP, then asks for the new IP There isn't a set time i want it to check the IP, just whenever i send to command to do so. I am new so i may not know, is there a way do do this simpler?
It wouldn't, Its setup to block out-going connections for security.
Running it as a standalone application an windows exe.
At Malwarebytes, we use Go for many different projects and systems. A lot of Go source code powers our Malware Labs, Telemetry Data received at Millions of requests per minute, some of our Big Data systems. You can check some articles I've posted recently: http://marcio.io
Huh, didn't know that Go had ability's to add quotes to strings and stuff like that.. https://golang.org/pkg/fmt/
I'd not heard of this. What's the performance like for it?
[removed]
I get a funny feeling when I see an attempt in Go to create object inheritance as you do with controllers. I don't think it's the right way to do things. Instead, I would try to attach reusable thread safe resources to a struct that implements the ServeHTTP method. Additionally, you've wrapped a lot of libraries that do the real heavy lifting like gorilla's context. Although I use that library for more than one project, I would suggest not having to lock shared memory and just creating a new context. As a matter of fact, it seems like you are giving the illusion of a non locking context, but are using gorilla underneath. Overall, good job in creating a framework. A good deal of work went into this and that's commendable. Personally, I would only use frameworks that lean on the standard library and not on other frameworks as it serves merely to abstract from an already simple to use concept. Lately, I find myself only using some parts of the gorilla framework when I need secure cookies. If you could include some different types of authentication built in, I would consider using it for rapid prototyping.
Thanks for the feedback. I wan's so sure that declaring Routes inside the Controller was the best way. So, `[]string` was like an insurance policy, just incase I will have to pull routing out of the conrollers. that way it will be easy to serailalize or deserialize routes from `json`, `yaml` etc. And, you should check the second `utron` premise on the README, `[]struct{method, path, action string}` has nothing to do with routing( unless of course you are addicted to annonymous soups). There is already a great share of annonymous stuffs in `utron` so I was trying to make stuffs that matter, matter. And thanks again for taking the liberty to dig the source code.
Thanks for the compliment, you are welcome.
Thanks for the feedback, to avoid a longer technical discusion I only want to tell you that `utron` does not rely on `gorilla.Conext`. My bad that I added a helper method on `Context` struct `Context.GetData` to help retriving data stored in the context by `gorilla.Context`. This is the only place `gorilla.Context` is refered. Now, to clear the stuffs out this is how `Context.GetData` is defined. // GetData retrievess any data strored in the request using // gorilla.Context package func (c *Context) GetData(key interface{}) interface{} { return context.Get(c.Request(), key) } The reason I added the helper is because `utron` supports middlewares, and middlewares are famous for passing data around.
I've got no idea. I can't even find any reports stats online either. I've not really looked into performance (I don't use go professionally so it doesn't matter to me at the moment). 
OK you mean you're going through a proxy/nat. I guess your original plan is on the right track then...
Every second db supports JSON like storage now days. Off the top of my head, mongo, postgresql, rethink and couchdb may be worth looking into.
Fair enough. :)
Very well done! I'm a beginner at Go but even I can see that you put a lot of effort into the code being nice and clean. Where did you pick up on this stuff? :-) I'm going to check it out maybe I'll learn a thing or two or three from you. Thanks for sharing!
Ouch, that came off a little snarky. I think the question has led to useful answers. I expect follow up questions that can lead to better understanding.
Please explain. I'd like to know why.
I think that MongoDB is a perfect fit for your needs, as it can do exactly that with BSON, but the IO is easy. I created a simple crud example doing exactly this. [MongoDB simple CRUD example in Go](https://github.com/andyrees/MgoCRUDExample)
You might also look at https://github.com/gorilla/websocket
If you want to find examples from the net use mongo. Postgres json is also good, faster than mongo for some important cases but since it's new you won't find lots of examples and things like update are missing in postgresql. You'll have to wait for the new version to come up. Also postgres json queries look so bad :(
It was based on Revel. We added a "filter" that would add a configurable random delay, return an empty reply or simply let the connection hang, either before or after the request had been processed. As I said, very basic compared to this. Here is the "filter": https://gist.github.com/klauspost/d6e28edc72063d4d2a4f 
There is also [Centrifugo](https://github.com/centrifugal/centrifugo) which is not exactly what you are asking for but it covers many of keywords in this topic - i.e. server to build real-time applications supporting Websocket or SockJS-fallback connections. It's standalone and application must communicate with Centrifugo via provided API to deliver messages to clients.
A couple of observations, without compiling and testing the code: * You split the code up into lots and lots of files. It's a 400 line project, it's fine to do that in a single file :) In go, you usually don't split up your source quite as much, people will be thankful if they can find a function in the same file it's used :) * You use a sync.RWMutex, but only [Un]Lock() it. * You mix channels and Locks a lot. It seems a lot more complicated, than it needs to be, imho. A better architecture (that also solves your concurrent connection problem) would be, to spawn a fixed number of workers, that all read from a common queue-channel and write all found links to an output channel. A separate goroutine owns the map and reads from the output channel, looks them up (lock free, as it owns the map) in the visited map and if it hasn't been visited, writes it to the queue channel. This should make your code much simpler and make it easier to argue about. * nit: `fmt.Println("AbsoluteURL: " + absoluteUrl)` has the same output as `fmt.Println("AbsoluteURL:", absoluteURL)`. You should prefer the latter. * You possibly have a race with wg. Imagine the following: Crawl passes a url into queue and returns. Crawl thus calls wg.Done(). Before the goroutine of main runs again and calls wg.Add(1), the separate goroutine runs and wg.Wait() returns (as all crawlers called done). It closes queue prematurely. I am not sure about this being possible or the case, but if you get inconsistent results, this points to a race condition anyway. Have you tried running with the race detector enabled?
&gt; You split the code up into lots and lots of files. Coming from Java splitting up the code into pieces allows it to have smaller code pieces doing one thing, having a faster view about everything. I don't see that as a problem but as a solution instead of a 400 line file, more than 50 SLOC in one file drives me crazy :). &gt; You use a sync.RWMutex, but only [Un]Lock() it. What else should I do with it but lock() and unlock()? &gt; spawn a fixed number of workers Interesting, the whole paragraph seems much more goish and cleaner than my code and would solve some, maybe all issues. I have no idea how to build a worker but I will google a bit around to inform me. &gt; You possibly have a race, have you tried running with the race detector enabled? Will do, thanks for the tip.
I did something similar as my first project, a google search crawler It's not far better, but maybe you can find something usefull in it. https://github.com/captainju/goGoogleSearch/blob/master/Search.go
Me neither. How are you running it? If I try with `go run -race *.go` I get the output: ================== WARNING: DATA RACE Read by goroutine 16: main.main.func3() /tmp/Crawler/src/crawler/main.go:101 +0x67 Previous write by main goroutine: main.main() /tmp/Crawler/src/crawler/main.go:96 +0x65e Goroutine 16 (running) created at: main.main() /tmp/Crawler/src/crawler/main.go:103 +0x71d Not sure what's the problem yet, though.
Ah, I see the problem. You use uri in a separate goroutine.
[Patch](http://p.nnev.de/7129)
As you might already know the "REST for Websockets" meteor is using to communicate with the client is called [DDP](https://www.meteor.com/ddp). There is at leas on [implementation in go](https://github.com/meteorhacks/goddp), unfortunately long abandoned :( Every communication between server and client is either a static file or DDP. So a go server with DDP could be used as a drop-in replacement in many cases.
If your environment is set up right, this is never needed.
how to set up right? 
I was just thinking about building a tool to do exactly this. Glad someone beat me to it.
&gt; Obligatory: http://www.catb.org/esr/structure-packing/ Yes.
Wouldn't the worker pool architecture solve this issue?
I've literally never needed to run this command before. Why would you want your GOPATH to be your wd? I'd prefer to have my pad be the dir with my go files in it...
Hi there, I actually implemented something like this and have been using it for a smaller application (i.e. 2-3 concurrent users) since a few weeks. Websockets: I use gorilla/websocket as server library and initially used socket.io as a layer on websockets for automatic reconnection. It is however not to hard to implement your custom re-connection and back-off algorithm in javascript. [Echo](https://github.com/labstack/echo) is also a nice little library that provides socket handlers in go. Client Side Handling: React with [Cerebral](http://christianalfoni.com/cerebral/) is absolutely awesome to manage the client side. Cerebral is similar to Redux but adds some opinionated concepts to make your life as developer way easier (including a reactive-router). All data is managed in one big store (similar to Om) and actions are combined using signals. This makes the data-flow of the application very clear and it is super easy to record your actions and playback – or revert it if necesarry. Handling of asynchronous pathways is also included and you can easily create an optimistic update on the client and revert it later if the server cannot handle the change. RethinkDb: Using golang channels it is very easy to send updates from a RethinkDb changefeed via the websocket connection to the client and trigger a specific signal. In addition I store all signals as audit trail in a separate table. Hope this is of some use for you.
If you want a single-project workspace (gopher consensus to the contrary), [gb is going to be a much better option](https://getgb.io/)
Is it only me who doesn't like this way to develop go programs? All of your go packages are in one folder? 
why? 
for my go programs spread over in many folders in my computer. You not?
Does this tool find out about how to rearrange the struct variables or do you have to figure that out yourself?
It must be something else. I don't always dev in my GOPATH, and when I don't, I still have no need for this. 
You've already got an open thread on the subject, please be patient. Edit: Did you delete that?
can someone eli5 how the arrangement can mess up sizes? Does this happen when there are many fractions of an adress? 32bit 32bit 64bit will use 128bit, while 32 bit 64 bit 32bit will use 192bit?
I see the solution you are trying to implement, and I understand the question you are trying to get answered so you can continue with the solution you already have in mind. What is the problem this solution is supposed to solve? 
* Yes, that's a problem I don't know how to fix yet * I don't know what you mean with the "wait to write", I don't see anything like that at lione 52? Small code update pushed to git.
[removed]
It is unclear to me what you mean by "proposal". I assume you mean that you want this in the core Go library. My suspicion is that the odds of that are very, very low. However, there has been motion in the `testing` package lately to allow more overriding. Rather than advocating for a very specific set of functionality to go into core, you might be able to get the testing package extended to allow you to plug in more of that stuff. It also breaks up a rather monolithic proposal into a series of smaller proposals that may individually have a greater chance of success ("we'd like to be able to use an `M` object in a way that lets us construct tests." "We'd like greater control over the structure of the output with these tests." "We'd like to be able to hook the run command line parameter." "Wed' like to see these concrete parameters become interfaces." etc.). You could then provide an external module that provides what you want, and probably other useful things too.
couchdb is a native-JSON document database and I think fits the bill exactly =) http://couchdb.apache.org/ 
I don't know whether gc applies this kind of aggressive optimization but considering that this may break programs using reflect.StructField.Offset, or reflect.Value.Field(i int), it would need to also maintain a set of old/new offsets conversion tables for each type... sounds wasteful.
&gt; It is unclear to me what you mean by "proposal". It is a proposal in accordance with the go [proposal process](https://github.com/golang/proposal). You can see the issue with initial discussion [here](https://github.com/golang/go/issues/12166). So far, the voices have not been overly critical.
Ah, thank you. My feedback then is that I'd still suggest considering how much of that could be rewritten to be generic hooks that you might provide an implementation for, rather than baking that literal functionality into the go tool but locking out anything else that someone might come up with.
Most people seem to just use a single GOPATH.
Presumably in a similiar way as they do in C http://www.catb.org/esr/structure-packing/ Not sure if C compilers are allowed to rearrange in-memory locations of the struct fields.
I keep everything in a single GOPATH directory. If I want to isolate a project, I might make it its own GOPATH, but then I would just create an 'activate' script that I could source to set my GOPATH correctly. This is pretty rare, however.
What's a framewark? :-D
Thanks for the interest terrason - ~1 year old - 10 people - Yes, several. A couple profiles - https://github.com/netik, https://github.com/ryanking - No intern program at this stage - We're pretty heads down throughout the day. Headphones in. Meals provided by company. But, we're a pretty close team and hang out after / outside of work. 
Running your snippet locally produces 144 bytes. I think 104 bytes is a playground anomaly.
Yeah the connection blocking issue may be related to port. I would always try to use standard http ports (80, 443) whenever possible.
Thanks, that is a good resource to take a peek at to see how they handled various things.
Can't say I have ever needed this approach yet. Even if I needed something like this for a polyglot project in a different location, I think I can just symlink the Go bit, or full project root, into my GOPATH, and then still be able to build it from any location. Beyond that I would start looking at gb 
I'm using your tools mostly through gometalinter, thanks alot for them, they come in really handy!
Good questions. - I'm sure we can accommodate private office if important. - We really value work/life balance. Less hours with higher-focused work &gt; more hours of poorly focused work - We'll be hiring someone dedicated to on-call work and administration. Right now, we're focused on high-performance, stable development. 
The command might be useful if you rely on any go tools and syntastic when working on gb project
Wasn't there a web visualizer of struct packing somewhere? I liked that, but lost it. EDIT: found it: http://golang-sizeof.tips/
PGX has pretty good support for this as well: https://github.com/jackc/pgx/blob/master/examples/chat/main.go
Didn't bump into this library yet. Will try it out, but looks nice at first sight!
&gt; Is this architecture-dependent? Yes. You can expect different results on 32-bit and 64-bit systems.
I've always thought that the on call should be the developers cause they are often most empowered to fix the root causes of problems, and being on call motivates them to do so, so they get called less.
"Go 1.6 will make its garbage collector slower" is an unlikely headline. The article seems to be [copy and paste of the original document](https://docs.google.com/document/d/1kBx98ulj5V5M9Zdeamy7v6ofZXX3yPziAf0V27A64Mo/preview?pli=10#heading=h.trxfu6r1nxt). 
I agree. However, being on-call can also be overwhelming and specialization around that is sometimes beneficial. It's never good for problems to exist, so I think our team has plenty of incentive to make sure the root causes of problems are fixed.
Go is great for general use. I write all kinds of apps with it. It sounds to me like you're wanting to write an application that uses a an existing library?
Believe it or not, this is the SECOND time someone has used this screencast in a tv show or movie. Crazy.
`go help buildmode` explains some ways external programs can call go code.
&gt; Would you be able to inject one processes into another native processes? That question is not well-formed. What do you mean by "inject"? Processes exist as a hierarchy (at least in unix-like-ish OSes), one process can never be "part of" another process. If you mean "started by", there's [os/exec](http://godoc.org/os/exec). If you mean, you want to use the code of one program in another program, that's either cgo or what /u/nliadm said. But without some better phrasing of your question, it won't be possible to answer it properly. PS: It's "go", not "golang", lest "GoLANG" :)
There is no way I will like it. As I just said, it is against humanity. pkg and a/b/pkg are both valid, neither is not recommended.
&gt; In discussions about Go, the lack of generics usually comes up. In tedious discussions about Go on net forums, some tiresome individuals drone on and on about generics, then they tell you to use Rust instead. They're called "bores". 
By 2.0, Go's GC will violate spacetime laws.
Never. Not even non-newbies _suffer_ from not having generics.
Yes, it is a frustrating limitation, especially since it hits end-users without knowing why. I have fixed them in rclone, and I have restic on the TODO-list.
suppose you want to write a pop() function that pops the last element of a slice... func pop(arr *T) { l := len(*arr)-1; val := (*arr)[l]; *arr = (*arr)[:l]; return val } even though the same code can be used, theres no generics, so now you have to write 10 functions, or a switch statement to handle each type (20 lines?): * `popInt` * `popInt8` * `popInt16` * `popInt64` * `popFloat` * `popFloat64` * `popString` * `popRune` * `popByte` * `popChar` ...etc
&gt; * Ability to operate in a startup environment and execute in the presence of *ambiguity and change* Can you elaborate on what this means to your company? What thing(s) are acceptably ambiguous? What thing(s) change (and how often)? How do these factors contribute to your company's success? Early in my career, I worked for a software startup that was created on a whim by a self-funded non-engineer with no business plan. As you might imagine from that description, we had no roadmap, no requirements, no specifications, and no release goals. That level of ambiguity and change ultimately led the company to financial failure. I do not cite this example to suggest Bolt is similar, but to illustrate how much more there is for Bolt to say about its culture/environment. I look forward to hearing more as I have an interest in a large portion of Bolt's problem domain and I might be interested in applying. 
The Spice must flow.
... No shit. It will hopefully be improved every single version. Just like any other programming languages runtime. 
We had a few PHP script run by cron jobs to blast emails. Took me practically no time to convert those to Golang binaries and they run so much faster obviously
It sounds like you want Python man. It is amazing for writing scripts.
My apps tend to be longer running, with high concurrency. Both client side and server side, these sorts of things are natural strengths for the language. But keep in mind, it's another tool in a toolbox. If you can do something more efficiently in a shell script, you should do it in a shell script. A large portion of the code I write is prototyping in bash, and most of those prototypes end up being good enough to stick with.
Yeah I didn't like it either but now I just create a new project in Eclipse and it gets its own folder in Go/nameofproject so I'm fine with it.
With this mindset all you will be getting done is truly only shit.
I don't know what your use-case was but GNU tail can tail multiple files, I do that a lot for the same case as yours (an application writes multiple log files in a directory and I want to tail them all sometimes).
IMO, readability or other reasons for a specific field order should always take precedence over (pre-mature?) optimization of struct space. Only if you have an issue and profiling shows you where (e.g. you allocate a lot of one type of struct) should you worry about trying to save a byte or three by re-ordering.
I usually do something a bit simpler, that I believe will give you what you want. Below is some code you can put in src/etest/etest.go and src/etest/dates/dates.go and try out. [couldn't figure out how to format code here, so I put it in the playground, but you need to split into two files/pkgs] http://play.golang.org/p/RlVqqgR3ex 
While it's true that Python will pretty much always result in smaller file sizes, deployment in Go is a hundred times easier due to the static binary. If you start using anything outside the Python stdlib, deployment can become extremely painful. Matching the right version of the interpreter, making sure you have all of the dependencies, getting into virtualenv if a dependency you need conflicts with the version required by another script/system package. To be honest, with how cheap storage is nowadays I don't see why a 4Mb binary is an issue. I think a big part of the reason the binaries are so large is due to embedding the runtime environment. That's important because it means the minimum binary size is rather large, but they don't tend to grow too much as the project gets larger. 
This is unrealistic, at least for me. My go packages are often parts of other projects including non-go code.
Also the Golang driver for MongoDB (mgo) is great.
I never said it was a problem. But it takes ~10x longer to do such basic things in Go than in Python from my experience. And what deployment issues? I don't write scripts for other people, only for me.
You always hear this answer, but… I have never seen a program that needs 10 different pop functions? If you need it, you only ever need it for one single type, *maybe* two. And even *if* you need it (you don't): You have to add 10 two-line functions. So what? That will hardly even come up on your radar even in time or in code.
&gt; In my opinion, anyone that says otherwise hasn't worked on a large code base that has many responsibilities and is frequently updated (like UI or evolving business logic) You mean, like the People working at Google with a 76TB repository and tens of thousands of commits a day? I am sorry, but saying stuff like this is just… ridiculous.
I think this is entirely the problem, even though you phrased it not very good :)
I kind of do. Generics have their place, and maybe in the future that will be in Go or a fork of Go, but until then why waste your time trying to bend Go into something it's not? When all you have is a hammer... blah blah blah.
However, they don't use Go exclusively. I maintain that is it is true that some problems are easier to model in an object oriented language with generics, some are easier to model in a functional language and some are easier and perfectly valid to model in Go. That being said I believe /u/drunk_puppies could achieve the some of the same things he does with generics in C# by using interfaces in Go. Source: I've been programming .Net since version 1.0 (pre-generics) and I've been writing and loving Go code for about a year now.
Not really useful, since it really debated argument: generics. I love GoLang for various reasons and understand its pragmatical philosphy: anyway I want generics for it. Not `interface{}` or code generation, but real generics.
* Here are few I can share: https://gist.github.com/egonelbre/ac1eab514607d7a453b1 * quick line count https://github.com/loov/qloc. * I've also used Go as a bootstrap language for projects (i.e. something that needed multiple communicating pieces in Delphi). * Used it to convert from html -&gt; dita. * had few utilities to diff/compare crash logs between different computers to find offending drivers/programs. * I often use Go as one of the prototyping language to clarify the algorithm and understanding of the code. I.e. it has a nice property -- if code looks nice in it, it's easy to understand. * used it as a code-generator for other languages.
I have several little utilities that help me work faster throughout the day. - A tool that uses github code search and assembles a document from comment fragments spread across multiple repositories. - A wrapper for the `nsupdate` utility that can be used to update DNS records on servers that support DDNS, such as Active Directory. - A service that scans our IPAM system at work, finds all the switches, and tells me where a server is based on its MAC address(s). - A command-line utility for fetching secrets from a number of backends, such as the OS keychain, or a read-only file, or a prompt, or our password vault service, etc. - A service that assembles a grafana dashboard of a hypervisor and its guests when you give it either the hypervisor or a single guest name - Command-line utility to pull data from Dell's hardware inventory service (xserv.dell.com) and get warranty information for a server - Command-line utility to get information from a Dell server's iDRAC and format it in JSON. There are a few more tools that I have written and use personally. Basically when I feel like a shell script just won't cut it, I reach for Go. That said, I write a *lot* of shell scripts :)
I made a web portal that has all my network management web services in frames for convenience. The menu has links to Cacti, intermapper, nagios, unifi, prtg, hostbill, etc and open an iframe. I can change the menu with a webform that writes a csv file. Its great since all my networks have different web services and now i don't have to worry about bookmarks or remembering the addresses for anything, everything is on a portal for the respective location.
Most of my actual projects in Go are bioinformatics-related. There are a lot of situations where we have a perl or python script (or even bash) that performs an important task in our pipeline, but is slow (or terribly sequential). They don't *need* to be ported to Go, but every bit I port reduces the demand for our cluster and improves job turnaround time. 
Okay, that's a different thing. You don't talk about processes, but about code (running code in a foreign process). And yes, with the mechanism hinted at by /u/nliadm this is possible (basically, all you need for that is dynamically loadable code. As of go 1.5, the gc toolchain can create that).
*It is by will alone that I set my code in motion. It is by Go that the code acquires concurrency, The memory acquires garbage, The garbage is collected, Its speed serves as a warning. It is by will alone that I set my code in motion.* 
Linking an article about not using C++ template metaprogramming is extremely disingenuous to this discussion. That isn't analogous to Java/C# generics, which is what most people think and are referring to.
In Unix you'd store the PID of your process in a file in a known location. Then when your process starts, check that the file doesn't exist, or if it does exist check that the PID in the file isn't running anymore, and then overwrite the file with your new PID. I don't know if that information is of any use to you in Windows.
But your version is longer than mine, and you effectively ignore the error you get if the JSON decode fails, so it's actually less safe, too. In fact, you're effectively ignoring all of your errors—never a good idea. Why do you want to avoid json.Decode? It's functionally no different than typing SerializeObject, right? More generally, Go doesn't support the kind of generic programming you're trying to do here. You can't just unmarshal JSON data into an arbitrary "object" and then type-assert it to something concrete. Rather, you have to take the concrete object, and populate it via a JSON unmarshaler. And in general, and especially when you're this new with the language, any use of the empty interface `interface{}` in your function parameters or return values is pretty much guaranteed to be a sign you're doing something the wrong way. Other nits: - Go names never use underscores - Why are you using a LimitReader with that magic number? - It's not SerializeObject, rather DeserializeObject
&gt; This becomes almost unbearable when you start dealing with websockets, as many websocket APIs just have a "type" field then the structure of the rest of the message changes based on what type it is. There are many 3rd party packages which allow you to work with JSON in other ways. In this case though you can just use the standard package: (https://play.golang.org/p/cXa3UXBsm3) package main import ( "encoding/json" "fmt" "strings" ) type Message struct { Type string Data []byte } func (m *Message) UnmarshalJSON(data []byte) error { var tmp struct{ Type string } json.Unmarshal(data, &amp;tmp) m.Type = tmp.Type m.Data = data return nil } func main() { raw := `{ "type": "whatever", "arbitrary": [1,2,3,4,5] }` var msg Message json.NewDecoder(strings.NewReader(raw)).Decode(&amp;msg) fmt.Println(msg) }
Here's an example of using go &amp; bash together: https://github.com/progrium/go-basher
There is no issue surrounding the fact that you _can_. The point is that the type system Go's designers have chosen, in this very particular use case, becomes either useless or cumbersome depending on the way you implement it. In your example; cumbersome. I don't want Go's type system to change, though. Its simplicity makes understanding new code much simpler than Java or even Python. It gives you enough structure to not shoot yourself in the foot, but not so much that your entire app _becomes_ structure. A language does not need to be all things to all people. What go does, it does well. What it does not do well is this. 
I've just used a secondary Go program for fuzzy string matching in a larger Python web server that needs to find matches to user input. I had written in Python before, but in Go it is ~8x faster (which brings the web response time down by eight whole seconds...). Very useful!
If you need more places to ask questions. Try #go-nuts on freenode irc. Lots of helpful and knowledgable folks on there :)
If you had an open pull request, I could do it from my phone right now.
Good point. I was trying to differentiate between a script that processes a request or evaluates a file and a more nuanced application like a game or a web experience. Also, I always thought go was supposed to replace all of google's c code - which would have been used for the former and not the latter. 
Ever written a program that needs 5 different kinds of slices? Recall that Go doesn't have a 'set' type. I use sets all the time. We end up just using maps, and open-code all the set-related logic. Repeat this pattern a dozen times in a large program and I you might start to appreciate generics.
Yeah, we mostly use C++
Some of these are personal style, but most are idiomatic: - Consider renaming resm.go to main.go, then you won't have to tell people where your main function is. - Message type is declared in resm.go but not used there. It's also exported but none of its members are. Declare it where it's used and comment "ch" to tell readers what it's for or name it something more descriptive. - There's no need for comments like "Init arr" or "initialize resources." Instead, add a lot more comments to resources.go. Assume your reader understands what the Go language does, and focus on *why* you're doing things instead of *what* you're doing. Every function should have a comment directly above it that describes it and starts with the name of the function. Don't be afraid of multi-line comments. - The error message "Failed" could be more precise. Consider defining all possible errors at the top of the file, and "return errFailedToAllocate" or something similar. Typing the same error string "Failed" from multiple functions sets yourself up for a making a typo and not noticing. - Why is your resources variable named arr? Maybe just name it resources. Then it's easier to read. - Prefer more small functions over fewer big functions. In main, each of those routes could be a function. Can you break up any of the functions in resources into smaller functions? - Put comments for members of the Resources type inside the type instead of above it. - Add comments at the top of files to tell readers what the file does. - A function shouldn't modify the value of its arguments (when they're not pointers). In tryDeallocate, prefer "internalID := id-1" or "Resource{id-1,...}" over mutating id and then using it directly. - Functions that are exported should start with capital letters. The ones in resources.go should be made more consistent. - Structure elements that start with capital letters are exported. Should all members of Resources be exported? - Prefer "func (r *Resources)" over "func (a *Resources)" - Don't write your own JSON generating code. You already used the standard ones in config.go, so also use them in resources.go. 
Anyone know how this differs from CockroachDB?
If you want to iterate over all values of an enum, use iota and add a FirstEnum and LastEnum (use appropriate names). Then just: for i := FirstEnum + 1; i &lt; LastEnum; i++ { // use EnumType(i) } You could also add a Values() method to your EnumType that returns a slice of all the enums. Then range over that. That would be pretty much exactly what your Java example is doing.
pid files are full of race conditions. You should just use flock, which is easier to use and actually works correctly. There are similar things in windows land I think.
Have you checked the sha1 digest? I just downloaded it to check (albeit, on OS X), and I got 0a439f49b546b82f85adf84a79bbf40de2b3d5ba. That's what it reports on the download page, so maybe their download page has been compromised and is reporting the sha1 of a compromised installer. Or, perhaps more likely, some security certificate expired. Or maybe there's some kind of exponential expansion problem in a compressed file (hence "Bomb"). Anyway, the release is 10 days old, so you would think someone would have fixed it by now if there was something inherently wrong with the installer.
Mostly code in php, Had a requirement earlier to compare two folders (which contains many***** files) (compare all files in those and report the files,folders added/removed/modified) did that in golang... (The best thing i like about golang is that the language is small and simple, which means that we can actually focus on the real problem). Now trying to convince our PM to rewrite our *big services* in golang
The reason I use types and a a struct that does not export the value is precisely to give up this type of syntax: by having an opaque struct, you cannot use directly the integer constants and are bound to work with types instead (not reflection types, but compiler types here). Even with the auto-generated function that enumerates values (DayEnumValues()) I would still expect a type switch to be used within the ranged for. I know it's a stretch and an abuse of Go types, but my point is that it's a viable approach :)
Hej, What I mean by 'iota is not supported' is that iota basicly allows your enum to fit a given environment. So you can simply create a bit flag 'enum'. Which is really nice in alot of cases. What I mean by archived wrong is that I think the type should stay a numeric one and then maybe map the code to the data with a switch case. As far as I can see you want to archive that data is close to the enum name.
Ofcourse there are always overlapping domains. I can only talk for me as person I use golang for mostly all network development. Go has alot predecided decisions, but all of them make it really good for network development. 9/10 times I would choose go for a network project because It's really nice to work with it. However Rust gives you alot of freedom. While the syntax may look abit weird you are still kinda free in your decisions. And most concepts in rust are really good in performance terms. While I use rust rarely mostly if I do some uni stuff or code some application which basicly is more functional on It's own and doesnt aim for serve/recieve any data. I think rust could contribute a significant change to the whole game development section. So I think Rust and Go will be able to keep important domains for theirself.
&gt; If you’re a Java developer you might recognize this as a safe approach (...) It's not safe, sync.RWMutex has not concept of lock upgrading, this is a race: if instance == nil { mutex.RUnlock() mutex.Lock()
&gt; Repeat this pattern a dozen times in a large program and I you might start to appreciate generics. I *am* appreciating generics. I just can also live without them. They are not very important. And I think your set example is a perfect example for that, actually. It is next to zero additional work to just use a `map[T]bool`. And don't forget, that the large the program, the less the maybe 10 additional lines of code will really factor into it's complexity.
No, it's not. You need the rest too: if instance == nil { mutex.RUnlock() mutex.Lock() defer mutex.Unlock() if instance == nil { The second check makes this safe. If instance was set between `RUnlock` and `Lock`, the code will simply return the new value (as intended). Completely safe.
To add to this, some filesystems provide non-standard syscalls for copying files efficiently. Some filesystems can support reflink-style copying (sharing data blocks between files until they differ) for example. It's up to the application to make use of those features if they choose, and doing so in the standard lib would be too cumbersome or make too many assumptions to be generally useful.
Thank you very much. I did JSON generation this way, because I thought that converting my array to map and then to JSON would be inefficient. I'll fix everything else you've mentioned. 
TiDB and CockroachDB may have the same goal for building a distributed SQL database. :-) 
The code did not upgrade the lock
Right, sorry, I've horribly misunderstood the code.
Map is fine, unless you actually want set operations - union, intersection, etc. You have maybe 100 LoC per set type, and fixing bugs means touching them all. The only word for it is CLUMSY.
Umm, nope. Tons of templates and generic code in Google. Tons.
Doesn't handle metadata (e.g. how do I copy windows acls in Go?)
The idea behind generated code is, that you can `go get` it then and that you don't need third-party tools to build. It's a good idea, I think.
There are legitimate reasons to worry about this even beyond merely "not starting two instances accidentally"; if you're running a typical Windows program and you double-click on a type of file that program handles, in Windows you generally expect the already-open instance to open the file, not for a new instance to pop up.
OP wants to prevent two processes from running at once. sync.Mutex only works within a single process.
&gt; For example, if you're copying a folder, and the destination has a file with the same name and path, do you overwrite or skip? Default is skip until overruled with code flag by the developer?
CockroachDB never was "only a key value store". From the beginning, was announced as newSQL database. Furthermore, I think that TiDB is inspired in cockroachDB.
Nice. Few suggestions: 1) consider sanitizing (especially url-encoding) [the user's input](https://github.com/kenhkelly/GoWeather/blob/1bbce3f7b0dfa975b8e90503d4e57427c3bcbb95/goweather.go#L20) with [url.QueryEscape](http://golang.org/pkg/net/url/#QueryEscape), for instance 2) you don't need a [new variable](https://github.com/kenhkelly/GoWeather/blob/1bbce3f7b0dfa975b8e90503d4e57427c3bcbb95/goweather.go#L47) called `errr`; it's common to reuse error variables 3) on that same line, you can can unmarshal in one line without needing ioutil: `json.NewDecoder(resp.Body).Decode(&amp;f)` - avoids the extra buffering. Nifty little app though, nicely formatted output.
Thanks for the input! I took implemented your suggestions. Glad you liked it
What message is printing where? The "New\n" you're sending to the server? The message printed at the bottom? If the message at the bottom is printing, and it's "hello" or "Die", you probably have some whitespace around the string that you should strip. If message is blank or something, you're probably getting an error from the server or reader that you're ignoring because you're dropping the errors instead of checking them.
My guess: eurocentrism.
Because it's easier to implement. Having multibyte separators means doing lookahead reads. For such advanced cases there is a Scanner type right there in the same package: http://golang.org/pkg/bufio/#Scanner
Your critics are weak and could as well apply to any program/templating written in Go. I have explained - both here and in the article, for those who cared reading - what it gets you. Thanks for your feedback; no, actually not, thanks for nothing. :)
Yeah, in my templating I ignore any enum that is not a simple list enumeration, including bit flags and any other you can come up with combinations of iota. I get what you mean, but this go-genums tool is really an experiment at using types for enums.
you can use context-sensitive code folding in your editor if you really hate looking at the error checking all the time
change the name for something else than main
Ehem, no. It's Americacentrism if at all as English can get away with ASCII only, but as soon as you start with languages like German, you have characters outside of ASCII. Remember, Go is all about Unicode so everything outside of ASCII is a multi-byte character.
As to “why:” The `bufio` package only allows you to put back a single character, which makes putting back entire runes impossible. This restriction comes from C's `stdio` and is pretty sensible because allowing arbitrary pushback involves extra overhead in every single IO operation or other complications, such as resizing the IO buffers occassionally, all of which are detrimental to performance.
This only works if you read in a `rune` as the last operation for some reason. Valid point though.
Because searching for multiple bytes is difficult. The `bufio.Reader` reads data into a fixed-size buffer that is periodically refilled. Suppose I was looking for the string `ab` inside of `xyzabc`. The code would do a `bytes.Index` and find it at `3`. But if the buffer size were `4` you'd have `xyza` inside the buffer so it wouldn't find it the first time, read the next chunk as `bc` and also not find it in there. Certainly you could write code to work around that, but I think `bufio.Reader` is generally considered a low-level API. https://github.com/golang/go/issues/2164 https://github.com/golang/go/issues/511 I'm not sure if there's a helper to do this, but here's how you can write it yourself: (https://play.golang.org/p/vgpRbPSmVt) func readString(rdr io.RuneReader, delim rune) (string, error) { var buf bytes.Buffer for { r, _, err := rdr.ReadRune() // probably need to do something special for io.EOF and the // the trailing bytes if err != nil { return "", err } buf.WriteRune(r) if r == delim { break } } return buf.String(), nil } 
It's always a good idea to look for [existing reddit posts](https://www.reddit.com/r/golang/comments/3k05jv/write_daemonizable_service_in_go_doesnt_use_flags/) before posting.
Yes, the reference implementation of Go is not written against the libc, but the `bufio` API has a similar design to the `stdio` API and this was one of the things they took over. Remember that Go has been designed by a team that also designed parts of UNIX and almost all of Plan 9, so it's no wonder that they did things the same way as back then.
If you send a 302 (http.StatusFound) code it should redirect automatically.
The benefit of a library not using flags is that the application is free to decide where configuration data comes from without fighting with the library.
Late to the party, but here's my 2 cents: Utility scripts. I also use go for several "full" services but thats not your question. I previously used python/bash(also on windows using git-bash) for all scripts related to deployment, building resource bundles, etc used for my cross-platform c++ application. But imo it is just a lot simpler and cleaner to use go for that. There are multiple reasons. Perhaps the most important is the "everything is unicode in go" vs "dealing with unicode is hard/annoying/sucks in python/bash". If you are dealing with unicode then go &gt; python/bash every time. Also the ease of http(io)+json/xml. This admittedly is also easy in python but you typically end up with external dependencies in a virtualenv or something, while with go all you need is the runtime installed since the standard library has everything you need for that. And if you don't want to install the runtime you can save an (admittedly large) static binary in your repo per os and just run the binary after checking out the project. I guess i'm biased since i use the concurrency features of go quite a lot in other projects and have become comfortable with this simple but powerful language. Thus i probably ignore the overhead of using go over python/bash for simple scripts etc. 
mm, you could fake a shell with a simple REPL, and you'll want to handle ssh negotiation. Set a weak user/pass combo like root:root, so they at least have to try. so, core functionality: Negotiate SSH, imitate error and success conditions based on input, don't mess up and drop them an actual shell, log attacker info like IP, log interaction once in your REPL.
That solved my problem, thank you! I used 200. I forgot there were status codes for redirection. Thank you very much :)
[That fixed it](https://www.reddit.com/r/golang/comments/3loqtq/how_to_redirect_a_user_after_login/cv83268) Thanks :)
Come back in a year when it's relevant.
Upvoted for cli weather app. :) My first ever (nearly) completed go-program ([woozy](https://github.com/gummiboll/woozy/)) was something similar but read its data from yr.no. I think you gave me some inspiration to continue with that project, thanks :)
Looks handy; installed. I might consider passing the input through `gofmt` before uploading, though you'd need to handle the case where it fails from malformed input.
Maybe it would be interesting what they would do when they get shell access. Fake the shell too and see what commands they try to execute, perhaps this can help in identifying whether they want to install software (and which), if they need information (which information?) and so on...sounds like a good one! Btw changing port only reduces the amount of bots, but doesn't improve security. If you're still using passwords I suggest you take a look at RSA key logins!
Awesome! I didn't know that API existed. Last week I built something similar, but using data from a Dutch agency. It polls every 10 minutes data from their site and saves it to a SQLite database. Then using d3.js I create graphs of that, take a look: http://pi.tacodewolff.nl:8080/knmi it's still pretty basic but maybe a nice idea for you too?
1. Go is easy to write, read and manage. 2. Primitives for concurrency baked into it. 3. Go community is big and constantly evolving.
You may take this and expand: https://www.reddit.com/r/golang/comments/2p1cms/high_interaction_ssh_honeypot/
You might try asking the question without first claiming that "It's just so retarded". You could say "stupid" instead if you really need to express an opinion, or perhaps you could ask a question and assume the authors made it that way based on experience or some design principle.
Watch [Lexical Scanning in Go](https://www.youtube.com/watch?v=HxaD_trXwRE), by Rob Pike
Thanks for letting us know that it's retarded. I'll be sure to pass the message along to Rob Pike and Ken Thompson et. al. 
Already saw a blog post of someone doing that, in general they try to download some files and execute it in there.
But why is it bad practice? I mean, people might say "Water is bad for you". You still need to know why else you might believe anything.
It is pleasant to write, it is pleasant to build/deploy (one binary), it is statically typed (I'm looking at you JS/python), it is quite multi-platform.
Then by all means, stick with go. Just try not to sweat small details like this. It's OK to think go's way of doing something is wrong. I have my own small gripes about the language too, but I'm most effective with go when I ignore them and try doing things "the go way". More often than not, the thing I thought was so awful, isn't all that bad. Sometimes it turns out to be even better than what I wanted go to let me do in the first place. **cough** error handling **cough**
And as for why go prefers absolute import paths, check out https://groups.google.com/forum/m/#!topic/golang-nuts/1XqcS8DuaNc/discussion It was discussed at length there Edit: and also https://codereview.appspot.com/5787055
The [ssh package](https://godoc.org/golang.org/x/crypto/ssh) from the /x/ repository is pretty good. Aside from logging username/password attempts, other things you can do: * For some fraction of attempts, accept the password and present a fake shell prompt which just logs the commands they try to run. * Publish the attackers' IP addresses to use as a blacklist. [These folks](https://www.openbl.org/) are already doing something similar. * Closely imitate the banners and login message of a particular expected-vulnerable system, like some oldish Linux distribution, or an older version of OpenWRT or something.
That is a horrible example because its VERY non-generic. I have never in my life wanted that, yet I have wanted lots of generic things. As for optimization, think of it this way. Suppose the simplest possible code is 50% as fast as the fastest possible implementation, and you have 5 cut-and-paste copies of it (because that's Go for you). Optimizing increases code complexity, let's say exponentially. How much impact do you get from optimizing (and complexifying) each of your 5? Not too much, so you won't. But if you know that optimizations cover every case, then your payoff is much better. Then let's talk about tests, time to run tests, etc. So I assert that half of the con arguments in the doc should half their reciprocal arguments as pro. Generic algorithms can be more efficient (because there is more incentive to make them so). They can be as easy to comprehend. They can be more centralized and less frequently read by humans. 
OMG! You solved my problem! It's only when you are working inside the GOPATH that you can't use relative paths. Outside your gopath they work perfectly! Thanks!
Not every Go written thing has to start with goActualName
[Gisp](https://github.com/jcla1/gisp) is a Lisp written in Go using this video's techniques.
You could use the JVM if performance is a concern.
Bending a language's design for how is modules work for one particular interpretation of one particular design pattern would be, what's the word, "retarded". MVC merely mandates that you have classes that are clearly either M, V, or C. It does not require that you organize them in any particular way. That is a requirement you are bringing to the party, not MVC. Personally I've never seen the point of that organization. I've always preferred to organize them by logical units of functionality, not by a rather arbitrary structural distinction.
Hey look at my project, 1 folder with 100 files. xD Anyway. Relative paths do work. You just need to place your project outside the GOPATH/src , I didn't know this. Is that obvious? I might have followed the wrong tutorials.
Sigh... I hope you realize that you're doing exactly the opposite of every piece of advice in this thread. I'm asking you one last time to forsake this madness. By abandoning GOPATH, you're officially fighting the language. It's not that the community doesn't still want to help you, but we simply won't know how. You're going down a road that most of us have never traveled. If you do this, you're on your own. Good luck.
Nothing. Following the candidates a year and a half before the election is what's irrelevant.
Because web scale! /s I was interested until I noticed that it requires mongo. Not interested in adding mongo to my setup.
https://www.adayinthelifeof.nl/2012/03/12/why-putting-ssh-on-another-port-than-22-is-bad-idea/
I took a look at the ipinfo.io site, and it doesn't even detect mine. How accurate is it?
Looks pretty cool. What OSes do the icons work on? That's kind of something I had in mind.
Ha ha, sneaky, using goto! :) However, from the [Tour](https://tour.golang.org/flowcontrol/1): &gt;Go has only one looping construct, the for loop.
Just a small remark: Your page looks very bad on mobile. The code-examples are very thin (I think you set their max-width to something like 50% or so…) and can't even be scrolled :(
They are unicode icons so they should work in all modern os:es (someone please correct me if I'm wrong)
Well, yeah... that's why everything is MVC in web unless you're making a tiny API. It's not about MVC though, it's more about your code being spread out in a structured way. Having everything in 1 folder reminds me of the 90s.
Thanks! It's so players can't Google the question in a new tab. :)
After finding out how it works, i can say: Go designed it perfectly. Only... It's like almost all go-devs don't know how it works. They all seem to jump to the retarded sentence "It's bad practice". And it's not. Ofcourse it's not. But hey. Almost everyone said "angular is awesome". = Majority of devs are shitty devs. So how it works: In GOPATH/src, use absolute paths Projects outside GOPATH/src, use absolute or relative paths based on your needs.
This is the approach we took initially. But after the amount of different queries got bigger and bigger we started to lose oversight of all the queries more and more. This way our overview of all the different queries is better, and we don't mind the runtime dependency since we'll deploy the SQL files together with our binary anyway. (Including syntax highlight for our SQL files :)) It works for us, but your mileage may vary.
See also: [Docker and Go: why did we decide to write Docker in Go?](http://www.slideshare.net/jpetazzo/docker-and-go-why-did-we-decide-to-write-docker-in-go)
Yeah, probably you are right. My logic was to save memory, not cpu.I thought that if I make array -&gt; map -&gt; json I will have the same data 3x times in memory, but if I do array -&gt; json I will have only two. But now I think that it could be wrong.
Although the standard library uses reflection, some of the other third-party packages don't. It simply depends on what you use.
I find the question a bit ambiguous, though (the formulation on the tour notwithstanding). I would count `for {}`, `for stmt; expr; stmt {}` and `for k, v := range val` as three different constructs. go only has one *keyword* for loops, but more than one *construct*. [edit] technically I would even differentiate between `for k := range val` (maps/slices/arrays), `for v := range val` (channels) and `for k, v := range val` (maps/slices/arrays again)
If you don't follow the convention your project will not be go-gettable. It's bad practice because it doesn't play well with others. If you use goimports this is largely a non-issue. It will manage your imports so you rarely ever type it out. (And an editor like atom+go-plus or vim comes with all these bits included) Renaming a project is rare. But it's also not difficult as you can easily use a find and replace. In other words the design decision may seem strange, but in practice it has little impact on productivity. In fact its simplicity led to things like godoc.org.
Updated the article to reflect that a user needs to have that limit imposed by the system's security limits before calling ulimit - also added a link to the upstart stanza documentation on setting file limits as well. As for the tcp_tw_recycle - This will obviously vary by network. I have no devices or services going through any NATs so this works. Thanks for the input!
because you wrote "solving my need" - you could use imagemagick for this :) convert x.jpg y.png It produces better results atm.
Fixed! I just switched from Octopress/Bootstrap to Hugo/PureCSS and had forgot to mark the responsive sections properly. It should look much better now on mobile/tablets.
You should be using defer in your error handling example. This keeps you from having to use a goto (which you should absolutely not do). You can simply return on errors. Defer is intended for exactly this situation -- set resource cleanup logic after allocation, then forget it. 
As pointed out in the second answer, you are hanging trying to write errCh. You can use a buffered channel as suggested, or you can use a non-blocking channel write (write errC in a select statement with a default clause)
You're very welcome, good job on the article.
I use vim, but looks like Atom runs golint to verify syntax. I've already installed golint, will try to code without it complaining, thanks.
&gt; On which basis? Are they easier to comprehend than a concrete implementation counter-part? I didn't say easier to comprehend, I said "as easy".
You can do reads the same way where needed. Works a treat
Decorator pattern in Go is: One, create an interface `interfaceX`. To create an "`interfaceX` decorator", you would: type DecoratedX struct { internal interfaceX // whatever else you may need } // override interfaceX methods at will Middleware is a specific case. Decorator is the general case; middleware is a decorator on `http.Handler`. Since it's so simple, you don't see much discussion about it here. It occasionally also comes up in the context of decorating `io.Writer` or `io.Reader`. For some simple cases, see the several functions in [iotest](http://golang.org/pkg/testing/iotest/) that take in one or the other and return a modified version. (Consider also clicking through to the [source code](http://golang.org/src/testing/iotest/reader.go?s=381:422#L5) to see it in action.)
Thanks for the tips! Might look into it, though as it's running for me now I'm not so inclined to change;) but it would help adoption I guess. 
I found this to be pretty helpful to get started building web apps in Go: http://nicolasmerouze.com/build-web-framework-golang/ It's not anything extraordinarily great, but here's a small-ish web app I threw together a little while ago: https://github.com/bieber/mixer I think I use much more granular packages than a lot of people would suggest for Go projects, but I'm pretty happy with the way it works out, so eh :p
I don't understand how people transmit contexts across API boundaries. For example, if server A gets a request and decides the deadline should be one second, and the request depends on results from server B, how do you pass the constraint on to server B? Do you attempt to transmit cancellations across different servers? It seems like context is only usable for request scoped stuff, ie on one server, but it would be most useful across network boundaries.
You could solve that runtime dependency by injecting those files into your project automagically though, using something like https://github.com/tv42/becky
You are right. The documentation says context is for request-scoped values across API boundaries, but seems limited within the same process. I think it's a hard problem, once being tried with something netchan, or etcd. If you need to communicate across servers, I would just use protobuf or gob packages. 
I was aware of it on reads, but on writes I didn't notice it. The docs all talk about how to do a non-blocking read. Maybe I just missed the part about writes, but maybe it's not discussed enough. 
I'd actually look at GRPC. Although it's still in Beta right now. It has management of the context, and cancellation across multiple servers: http://www.grpc.io/docs/guides/concepts.html#rpc-termination
Awesome package, except the code doesn't build! It's failing in TravisCL too. EDIT: oh I see, azul3d is not available at that URL. I get the same error as https://github.com/shurcooL/Go-Package-Store/issues/35
If you want people to use your repos, it would be more effective to provide a detailed TL:DR list of what use cases warrant it. "More features" and "" are not detailed enough to make me interested.
Packages aren't first-class though. An empty struct with methods off it is basically a first-class package though.
Naw, it's really just "a thing that can implement an interface". It can't carry constants, variables, or have an `init` function. It also can't be especially used to provide polymorphism above anything the interface already provides.
Ah yes I forgot about all the mutable things that can be exported. But outside of that, it's basically a first-class package. If Go had a little bit of parametric polymorphism in it, you could probably do some really cool things with empty structs + structurally-typed interfaces.
On a related note, occasionally I define: `type noop struct{}` and use it for stubbing out interfaces, mainly during development. It's sometimes useful to have a dedicated "don't do anything" type that implements every interface you might happen to need (after a bit of quick stubbing).
Thank you, I'll look into rewording it.
The game itself doesn't prevent a perfect score, although it seems like it's hard to get. We've only had a couple of users score 100 so far. :)
Thanks a lot, didn't know that. Will defiantly use it next time. 
The real answer is because other things in the same space are written in go. Nothing brighter or dimmer. Go has critical mass in this space.
&gt; var JSON = jsonCodec{} `var JSON jsonCodec`
You probably already have the azul3d package, so `go get` isn't trying to fetch it.
I commonly use this kind of thing for storage drivers and database abstraction. Its also useful for test mocking also.
I'm new to Go - can someone explain to me why this is helpful?
Empty structs are more useful in imitating sets with maps, imo.
luckily `gofmt` fixes this atrocity
is that Celsius or Kelvin ?
It's a global variable, not a local one, so `:=` won't work.
I instinctively clicked the format button when something looked off and it took me to read the comments to figure out that was the catch. gomft truly is the best thing since paper tape.
Is there really a temperature unit in the imperial system?
I come across these just the other day: https://github.com/joshrendek/ssh-passwd-honeypot and this feeds into http://sshpot.com/
I stuck with what the API service I'm using calls it. It's listed here. https://en.wikipedia.org/wiki/Category:Imperial_units
Cool as well, ... ! Thanks
This intro is definitely cool as well! Believe it or not I was not aware either :( of the package text/scanner :( Shame on me! Thanks a lot for the links
Goodness! I swear I search in reddit for other related threads and I found none! Thanks a lot really!!
The deadline only matters to the A process. The B process gets called normally with no deadline passed. It either finishes with A's deadline or not and A handles that and B handles the cancelled request. Trying to pass deadlines would lead to overly tight coupling and would make the app more complicated and fragile. [edit: grammer]
Pretty hilarious example. For those who aren't aware, officially speaking, statements in golang are terminated by semicolons, but they are added by a preprocessor in the compiler. I'm surprised this doesn't throw an error. 
I don't understand why people want these fullblown IDEs for go... Just use sublime with go-sublime or vim with vim-go
The problem with that approach is, that you then have to call into C for *every OS interaction*. Calls into C are a common source of grieve, because they have non-trivial overhead (you can't use a go stack for C calls, you can't reschedule them, you probably can't pass go-allocated memory to C safely…) -- and also for other reasons irrelevant here. It's different for C -- there is no overhead there. I like the go way better :)
Can you convince them that this is not the Go way, and `gofmt` exists for very good reasons?
are you saying that for i:=0; i&lt;10; i++ { ... is actually 3 statements? 
Ah OK. It's interesting to me that the Go community hasn't solved this issue more broadly.. Like in Node with npm, I can just edit the `package.json` (if I haven't already specified to use the latest package version) and then `npm install` and all good.. 
It kinda is. The first and last parts could easily be statements on their own. The only post that requires hand waving is the conditional.
I'll be the first to comment. Great work! I wish I understood how to use these kinds of tools. :)
&gt; I suppose that this is a great benefit in that it will serve to help prevent GPL and LGPL code from infecting the bulk of the corpus of Go software. Stopped reading there. Downvoted corporate propaganda.
It's a good thing that GPL doesn't let you (and your employer) take others' work for granted.
I didn't understand nothing in documentation, but mail list and the Stackoverflow work.
Curious if you've benchmarked it against HAProxy. Looks very promising especially considering the config options 
I really like http://godoc.org/. I prefer it over every other documentation I have ever seen. Simply because static analysis makes it possible to follow identifiers directly and the organisation of the page is good (though not always perfect), i.e. I can look at a package, find the type or function that appears to do what I need and then, simply by following links, how I can create all the arguments and preconditions to use it. It's *so* much easier than anything I've seen so far. Bad documentation is a problem, but I find with the go way that even bad documentation is still enough, often, to get going fast. Also note, that you *can* make good documentation with godoc. You can create an overview description, you can create examples, you can do everything you need. I *much* prefer the go way. It is the best solution I have seen so far both to the distribution problem of packages and the documentation problem…
How does this compare to Vulcand?
we all do ;)
I've read your entire post and I still don't understand what your question is. Hell, there isn't even a single question mark! You seem to have troubles with choosing a front-end but I just can't see how this is Go-related. If you add an actual *question* to your post, people could try and answer that. Otherwise, people will just click "expand", see a wall of text without a single "?", maybe push an upvote button (meaning, "I ain't reading all that but here's some to you for the effort"), and go on with their day.
ok here goes .. i think i nearly have a working program but i am sure it is way inefficient .. would love to know how you would do it. Simply, i have a file which is binary .. but inside it there is a token "EOF\n". I know this exists somewhere inside it. What i need to do is split the file into two -- one file with all the contents up to EOF\n, and another with all the contents after it. Thanks!! 
Not sure if the way I do it is similar to your package on the backend, but it seems to work for me if you're looking for a programmatic way to mass update packages. Definitely going to check yours out, though! #!/bin/bash GITHUB=$HOME/go/src/github.com GOLANG=$HOME/go/src/golang.org find $GITHUB -type d -name .git \ | xargs -n 1 dirname \ | sort \ | while read line; do echo $line &amp;&amp; cd $line &amp;&amp; git pull; done find $GOLANG -type d -name .git \ | xargs -n 1 dirname \ | sort \ | while read line; do echo $line &amp;&amp; cd $line &amp;&amp; git pull; done
https://github.com/boltdb/bolt might be worth looking into. 
Thank you! I have to admit, I tried with wrong google query. I found old thread about this subject: https://www.reddit.com/r/golang/comments/2f730k/can_anyone_recommend_a_simple_embeddable_database/ also here is nice list of go stuff: https://github.com/avelino/awesome-go
I really like this, since I have been trying to implement something similar. The approach I took was to generate a config file for haproxy from zookeeper nodes. It is working fairly well. I tried to plug this in and at first sight, it looks promising. It would solve my problems of dynamic backends. However, I ran it with 3 backends configured, but only 1 running, and it triggered the circuit breaker taking the whole frontend down with it. To be really useful (in stead of just useful) it should only trigger a circuit breaker on the servers that are down, but keep balancing to the servers that are up. Also, having some way to have a health check would be really nice, triggering the circuit breaker if the health is not within configured parameters. I do realize these are probably issues that oxy would have to solve but just wanted to get them out there. Great job, I hope I will be able to use and improve/extend! Thor
I like that bolt has buckets, but I can't find a nice example for simply writing and reading stuff. E.g. Can you just make one tx for reading, one for writing, and keep using that for the lifetime of the program, committing after every write? Does the read tx see a snapshot? Does it only see changes after commit? 
I was thinking about this as well. I came to the conclusion that this was intended to directly address data, and I didn't feel that an array index was a reliable method to directly address data.
&gt; Question 1 : for better working space I created /Developer/goprojects . Do I have to set my path stuff for only this directory even I have multiple projects in that folder ? Set GOPATH=/Developer/goprojects and PATH=${PATH}:${GOPATH}/bin &gt; Question 3: How do you manage your workspace for golang projects ? I have one GOPATH ("/Developer/goprojects" in your case). What is your question exactly? You have your source repositories under "src" (e.g. "${GOPATH}/src/github.com/&lt;user&gt;/&lt;project&gt;/**"). There is nothing more to manage!? 
If you remember what was discussed [here just 1 day ago](https://www.reddit.com/r/golang/comments/3lu2s4/cool_golang_trick_nil_structs_can_just_be_a/), it helps this make more sense. Because a nil object of a concrete type is valid, and that's not merely some accident but actually _useful_, there _has_ to be a difference between an interface with nothing in it, and an interface with a nil value of a specific type in it. Mind you, I still consider this a gotcha. To be a gotcha, it is sufficient that it demonstrably trips people up with some frequency, regardless of the reason; it meets that standard. I'm offering this as a way to help make sense of it in your head so it trips you up less, not as an argument against it being a gotcha.
Y'all might be interested in googling around the phrase "json query", with or without go/golang added. I don't know that you'll necessarily find an off-the-shelf solution for your exact problem, but you might get some ideas, or code you can, ah, "borrow".
I'd point out I've had better luck searching on godoc.org than I have on Google. A couple of times now I've done my due diligence on Google, found out nothing seems to exist for some problem (or only very incomplete solutions), and only after finishing it discovering on godoc.org that a better solution existed. godoc.org is really the answer to the question right now. It's still not "CPAN", but, well, CPAN doesn't always live up to its own reputation, either. Get away from the "main" packages and you're just as much in the weeds as in any other language.
I am confused by your "borrow" in quotes, what is that trying to communicate?
I understand how Reddit title linking works and am genuinely not confused by it, but when I read this title/link and saw "linkedin.com" as the host, I thought (to myself) how much more credible the claim would be if it was actually LinkedIn (engineering team) making it, rather than a user from a LinkedIn account. 
&gt; mind explaining at a high level how this implementation Yes, :) Just set the terminal into raw mode, so we can read characters from stdin one by one, and writing ANSI Escape codes to stdout to control how it display.
Yes, of course. Implement tab completion is not hard, just need some time.
"Ruby is clearly done. Javascript is misguided and python is held up on stilts by the data scientists." I totally agree with this. I've developed backend apps in both nodejs and PHP/HHVM. I've run against the wall with latency and threading issues. With NodeJS you have to run multiple instances to take advantages of multiple cores. With PHP at 5.6 it's awful performance. 7 solves this but still latency is a question. With HHVM it's great performance, latency is great. But still in it's infancy and lots of extensions for php are missing! It's not ready for prime-time still. Go? Solved both problems of latency and concurrency and not only where going from PHP to HHVM solved the problem of having lots of servers, I benefited from having fewer servers still. Not only this, but I also ported a cron/message queue infrastructure originally from php (which crashed due to long running scripts) to python (which crashed due to pool/threading) to Go. In Go, not only was concurrency simple, but the application ran flawlessly. My backend system was 100% stable with Go and much faster than PHP and Python. In short. I now have 2 codebases. Over time, I am moving from PHP to Go and my headaches are getting less and less. I seem to enjoy writing in Golang much better than python, php or even javascript ha! One thing I really wish for. Is something like a Meteor clone. I use GIN, but it's not quite ready I feel. I come from PHP, so having a framework like Codeigniter means I can just really be productive like 10x. But also having react for Single Page Application and being a first class citizen. That would totally rock and I would switch in a heart beat!
"Lift". "Appropriate". "Abscond with". "Steal". Seriously, though, honor the LICENCE, but most of them are pretty generous in the Go community.
So, does it use the terminfo database? Because I found that unbearable because the format is just so… meh. But without it, you might have problems with some terminals.
Nice! I've used [liner](https://github.com/peterh/liner) in the past and it works just fine for me though.
Check https://github.com/pingcap/tidb They took cznic/ql and use it as a SQL layer over other KV stores (boltdb and leveldb amongst others). See https://github.com/pingcap/tidb/blob/master/docs/USAGE.md for specifics.
Thanks for the link. I like seeing these kinds of tools because they've saved me a lot of time in the past. Why would one use this over [spark](https://github.com/rif/spark)? (Also, I wrote [Caddy](https://caddyserver.com) for a similar purpose; was tired of configuring nginx or Apache all the time for quick little site experiments.)
I read a remark somewhere that this should be possible, and then I was like, what really? and indeed... for long clauses it can be a "nice" solution :P
&gt; So you are saying I stole a rather simple 17 line function. No. I'm saying there's been a lot of work in this area already and you may be interested in leveraging some of it, much of which is generously licensed. Was it 3AM last night? 
As people have mentioned there is a convention to use doc.go to put the level of documentation that is typically found in CPAN modules via POD. Go's documentation standard has somethings I'm hoping Perl will steal, especially the examples. You can a file called *_example.go with comments showing what the output should be, that not only becomes a test; but is also a runnable example in godoc.org. (Look here for a better explanation http://blog.golang.org/examples) Really nice stuff. But as people have mentioned to get that level of documentation there needs to be a culture around it. Perl has created that culture by providing all the tooling that comes with it. When you upload a module to CPAN you get all sorts of things like coverage reports; on a variety of platforms, as well as remarks on the quality of documentation, all without much effort on the Authors part. To this end, the San Diego Gophers has put a proposal to enhance godoc.org to provide an way to rank and categorize packages (based on various tools (go vet, go lint, etc) something akin to [goreportcard](http://goreportcard.com/report/)). The idea is to make it easier to find great packages, and to encourage package authors to put the extra effort to make their package even better; by quickly providing way in which they can improve their package. Basic low hanging fruit. A lot of this is already provided by the basic tool go provides. We are just make it more visible. The proposal was just submitted for review; and hopefully we can open it up to the community, soon, to get feedback. I like the fact that it's really easy to share a package in go. The decentralized aspects of it are wonderful, and do avoid many of the pit falls of having a central repo. Going this route allows enterprises to setup an internal godoc.org site point to their internal repos easily; getting the same benefits as the public godoc.org site. This can only help adoption of Go in enterprises. And increases the number of possible contributor to image the site better. Doing this for CPAN is a pain. And though my current company has managed to do it; it was still a pain. NPM is a nightmare in this regard. 
* `gofmt` * [`golint`](https://github.com/golang/lint) * [`errcheck`](https://github.com/kisielk/errcheck) * [Style.](https://github.com/golang/go/wiki/CodeReviewComments) Apart from that, the code seems fine, although I've never worked with Mongo, so I can't reason about that.
I don't know about the others (I've not programmed them in recent history), but I don't see Ruby going anywhere anytime soon because of Ruby on Rails. It's big, it's complex, but it gets the job done in a way that basically no other framework does right now, and may never do because a large part of what allows that is the Ruby language itself. IMO it just sounds like hyperbole.
Please note, I also release my code under BSD or z-lib license. I'm fine using GPL code in other contexts. People license works in different ways for good reason.
&gt; It's really funny talking to people who chase the waves of technology and find out that they don't know that 100% of all containerization technology today is written in Go No, it is written in C (Linux kernel)... Go is basically used as API translator As sad as it is, Java and Javascript is not going anywhere for at least next few years.
Package centralisation is bad, sure, but one of best points of CPAN is that I can click on say [here](http://www.cpantesters.org/distro/S/Search-Elasticsearch.html#Search-Elasticsearch-1.99) and get a report of all the tests given version of lib has passed, **and** get a same for all of its [deps](http://deps.cpantesters.org/?module=Search%3A%3AElasticsearch;perl=latest)
This is fantastic. Maybe a color palette switcher for the code? Fine work.
The code uses bolt now :) 
These questions are not what OP asked for.
Personally I don't like how heavyweight React/Angular/etc are... I feel like I have a similar situation to you and I've liked working with http://vuejs.org the most so far.
@captncraig @MoneyWorthingTon @jasonok6 Well noted your remarks. Will certainly implement a palette switcher for the code. var _ Jedi = (*Knight)(nil) was the 1st shot, was changed to give to read a more 'decomposed' form of 'type checking', is Leo a Jedi? by the way I meant Luke.... Will maybe add the suggested one as a comment. Thanks for your useful comments.
My apologies if my lack of punctuation and improper phrasing did not make my asks very clear - I rushed to create the post, but, I was simply trying to provide context to my situation rather than just plainly ask "What frontend should I choose?" I now see how this can be taken as just a "wall of text" and how it may or may not be considered relevant in this subreddit - I will keep this in mind for future posts. Though you're correct in stating that my decision for a frontend is not directly related to Go, it is a common situation that others are facing. Folks are looking to the language to facilitate the creation of more modular, concurrent, decoupled architectures, specifically, for the use of HTTP servers, and the lack of any formal direction from a frontend perspective still very much varies depending on who you ask. So with that said, given the perceived nature that the native template package does not seem to be as widely adopted amongst Golang developers compared to other non-Go options (Angular, ReactJS etc.), what frontend technologies &amp; approaches are you integrating into your stack if it is not Go templating? If I've misinterpreted the stance on Go templating being used for substantially sized webapps, would you recommend they be a viable option to choose long-term?
i gave u 3 hours and still not done?? can you estimate the card again? this needs to go out asap because of sponsor deal. and would need to know how you gave underestimation to put the whole project in jeopardy.
Interesting, I had never heard of Vue.js. What do you find easier about Vue compared to React/Angular etc.? Does it have a similar learning curve compared to React/Angular?
... and then you have all those crappy PHP bugs/errors which would be avoidable during compile time in Go. ... then you dig hours in code to search for a bug ... after finding a usage of double equal instead of triple equal.
Well that is basically it. :D
I made [GoWeather](https://www.reddit.com/r/golang/comments/3ly1wf/goweather_20_my_app_to_learn_go/) to help me learn Go. I thought it was pretty successful, so I wanted to make another CLI app to try a few other things and to further cement what I've learned so far. Hope you like it and thanks for checking it out
Yes. It is production ready?
That's all fine and well, but I don't think Go will face its strongest competition from Python or Ruby. NodeJS will always have the benefit of using the same language for front and backend, if that matters. I think Go will face strong competition from languages such as Elixir which make concurrency and scaling incredibly easy. The Erlang VM provides a ton of stability and has decades of engineering behind it; the battle I am most interested in watching is the Elixir/Erlang vs Go battle.
why is installing go with homebrew out of date? i just did it a few days ago and i got 1.5.1, could you elaborate on why its better to do it by hand?
Mind sharing your experiences with bitcoin and go? Have you worked on btcd?
You may be interested in JSON Pointer (RFC 6910): https://tools.ietf.org/html/rfc6901 And a tested Go implementation: https://github.com/xeipuuv/gojsonpointer
No, I have no experience with the actual bitcoin protocol (though it interests me from afar). I built https://cryptowat.ch in Go - it's a real-time data stream and charting service for Bitcoin (and other cryptocurrency) markets. I started on it as a project for learning Go, and just kept working on it because it grew and is very fun to hack on.
Your random ID's are not long enough, lets take a look at the average recursion depth of your CreateToken function. For those who haven't looked at the code, it generates an ID by randomly selecting 4 characters from a set that has 36 elements. If it chooses an ID that has already been picked, it calls it's self. Using Rob Pike's Ivy program and some simple Unix tools, we can calculate the average number of times CreateToken is called as a function of the number of ID's in the database with the following command: $ paste &lt;(ivy -e '100 * iota 100' | tr " " "\n")\ &lt;(ivy -e '** ((100 * iota 100)**2)/(2*36**4)' | tr " " "\n")\ | column This gives the output: 100 1.00298130618 3500 38.3466379788 6900 1429567.30583 200 1.01197865993 3600 47.3716851904 7000 2162266.27008 300 1.02715396622 3700 58.8702734104 7100 3290026.66044 400 1.04878246525 3800 73.5968028405 7200 5035879.59715 500 1.07726106889 3900 92.5566273447 7300 7754198.88702 600 1.11312052244 4000 117.095922124 7400 12011139.5063 700 1.15704191433 4100 149.025881072 7500 18716177.8599 800 1.20987825379 4200 190.795137588 7600 29338357.294 900 1.27268207439 4300 245.730228278 7700 46263671.9876 1000 1.34674031394 4400 318.37249647 7800 73388850.3072 1100 1.43361808659 4500 414.952302648 7900 117113172.407 1200 1.53521342452 4600 544.059617854 8000 188003997.616 1300 1.65382565467 4700 717.59678215 8100 303608621.304 1400 1.7922408298 4800 952.138552378 8200 493226943.3 1500 1.95383860576 4900 1270.88277967 8300 806055902.862 1600 2.14272621686 5000 1706.46158919 8400 1325162721.33 1700 2.36390684052 5100 2305.01213682 8500 2191588105.15 1800 2.62349178503 5200 3132.09980851 8600 3646148364.2 1900 2.92896874315 5300 4281.37872558 8700 6102326147.29 2000 3.28954205319 5400 5887.31641431 8800 10274061749.3 2100 3.71656579528 5500 8143.9816376 8900 17401015946.7 2200 4.22409703082 5600 11332.9212548 9000 29647816612.8 2300 4.82960511756 5700 15864.7281161 9100 50815535137.8 2400 5.55488455448 5800 22341.3325726 9200 87616513726.3 2500 6.42723425879 5900 31649.8160711 9300 151971136329 2600 7.48098696883 6000 45104.4077609 9400 265168499014 2700 8.75950055356 6100 64662.4947509 9500 465445061843 2800 10.3177610975 6200 93254.8879947 9600 821865217563 2900 12.225799477 6300 135293.343827 9700 1.45988434695e+12 3000 14.5731939955 6400 197454.453605 9800 2.60868703859e+12 3100 17.4750288418 6500 289896.594783 9900 4.689334208e+12 3200 21.0798120061 6600 428158.895598 10000 8.47980896916e+12 3300 25.5800413914 6700 636139.709532 3400 31.2263648374 6800 950792.436246 The numbers on the left represent the number of ID's in the database, and the number on the right estimates the number of times CreateToken must be called before finding a free ID. As you can see, after just a few thousand ID's present, the performance of this function drops of a VERY steep cliff (O(e^(n^2)) to be precise). I would recommend using 256bit numbers encoded as base64 without padding, if you do this, you do not need to check for collisions as they are so unlikely. You can read about the problem in more detail [here](https://en.wikipedia.org/wiki/Birthday_problem). 
have you tried utron? https://github.com/gernest/utron
I will definitely check that out.
Thanks for the in depth analysis! I was somewhat aware of this problem when I was writing this and was trying to find a balancing point between a short human readable id and a practical number of possible IDs. I would like to be able to actually print these access tokens on paper from network enabled receipt printers and people would then need to go type them into a form or url to use them. So this makes it's it difficult to use a lot of characters or complex characters or even case sensitive characters. I had considered QR codes but my research leads me to believe very few people actually use them. Tokens are deleted after they're used so that helps slightly but not drastically. Are there any solutions you know of for unique but short or easily type-able IDs?
Hmm, if you use 64bit ID's, and stay below 1 billion ID's AND keep the collision check, you should be alright: 1000000000 1.02747573785 2000000000 1.11451598584 3000000000 1.27627475734 4000000000 1.54292639389 5000000000 1.96919800895 6000000000 2.65324111581 7000000000 3.77404609723 8000000000 5.6673604258 9000000000 8.98457662822 10000000000 15.0368736999 You can generate them like this: package main import ( "crypto/rand" "encoding/base64" "fmt" ) func main() { buf := make([]byte, 8) rand.Read(buf) id := base64.RawURLEncoding.EncodeToString(buf) fmt.Println(id) } They turn out fairly short: $ go run rand.go 4bxJfKQ8iuQ There are also interesting schemes, that basically encode numbers in a very large base where each symbol is a word, for example: https://giant.gfycat.com/WatchfulAlarmedHorseshoecrab.gif. The main advantage of this is it is easy to read aloud and easy to type on a mobile phone, where special chars and numbers are more difficult to type. You could encode a 64 bit random number in just 4 words: $ ivy &lt;(echo "ceil 64/(2 log $(wc -l &lt; /usr/share/dict/words))") 4 EDIT: I made a little program which generates ID's using the word technique, it works fairly well. The source code is [here](https://play.golang.org/p/tWEt9iT6EC). You can use it like this: $ LC_ALL=C egrep '^[a-zA-Z]+$' /usr/share/dict/british-english-small | wordFriendly Using this dictionary, you can safely generate quite a few ID's $ ivy -e "sqrt $(LC_ALL=C egrep '^[a-zA-Z]+$' /usr/share/dict/british-english-small | wc -l) ** 4" 1619177121 The ID's it generates with the british-english-small dictionary are quite nice: $ LC_ALL=C egrep '^[a-zA-Z]+$' /usr/share/dict/british-english-small | wordFriendly -n 10 | column PawnedCumsIdentifierBiding PouredEmitFurthestPrawns SluicingCorneringEnteringPumas TingGenuinelyAcclaimsGrades FaithfullyDenialEnrolFingernails TrinketsToffeePridesAssessor SmotherTransportableOctalLatched InterludesChargingWakeningPreviewed FrownsMeasuredCapacitanceIntensifying EvaporatingRawestBuildsFlounce Usage: Usage of wordFriendly [wordlist] -cpuprofile string write cpu profile to file -digits int number of digits in each ID (default 4) -n int number of ID's to generate (default 1) 
You can use type assertions, in the form: interface.(type) This can be used to perform a type conversion, and also returns an optional boolean as a second parameter, indicating if the conversion was legal/successful. Here is a simplified example based on your playground code: http://play.golang.org/p/B9q-yvzb5- Reference: https://golang.org/ref/spec#Type_assertions You can also switch on types: https://golang.org/ref/spec#Type_switches
But I can't map[string]type can I?
What is sad about java? 
If you've got 1.5.1 from Homebrew, it's up to date. I remember back when 1.4 released, Homebrew was still installing 1.3 iirc. And I want to say a bit before 1.5 hit (a couple of months?) it was still running 1.3. My experience has been that it's out of date - possibly not the case. That aside, I install it by hand because it's as simple as: curl https://storage.googleapis.com/golang/go1.5.1.darwin-amd64.tar.gz|tar xf -C /usr/local And then creating the required directories, and setting env variables - stuff that comes from my dotfiles. Clicking through a pkg install requires me to do stuff, Homebrew requires Homebrew (which I recently moved away from), and I'd rather just automate it independent of everything else.
Yes, but I think vi mode is not the best practice in readline. So it may not coming so soon as other features.
http://play.golang.org/p/hepXxzxrdK I've cleaned up your code a bit by making TestType function take an interface{} and replacing your init function with a compound map literal. Also there's no reason to have if something { return true } return false when you can just do return something
This is the most violent title I've seen on Reddit today.
```@username``` doesn't work on Reddit, so you'll want to reply to them individually.
&gt; "Ruby is clearly done. Javascript is misguided and python is held up on stilts by the data scientists." &gt; &gt; &gt; &gt; I totally agree with this. I've developed backend apps in both nodejs and PHP/HHVM. I've run against the wall with latency and threading issues. I totally disagree with this. Unhip doesn't mean unused. Ruby is a language that'll stick around because it has all the advantages of perl. Between Rails and Jekyll it remains useful for writing webpages and webapps big and small. It doesn't seem to see much use in desktop apps, but it makes for an excellent scripting and glue language. More portable and nicer than BASH. Javascript is the language that I *wish* the author was right about. I think it's more than misguided; it's genuinely awful. But it is *the* client-side scripting language of the web, and that will never change. Standards boards and browser adoption move slowly. Python is HUGE. In addition to literally dozens of web frameworks and static site generators, there is a lot of very neat and very useful desktop Python software still being maintained and written. Yes, it's used for science and mathematics, but also tons of applications and games. It also sees heavy use in academia not only as a language for science and mathematics but also taught to freshmen in intro programming classes. That alone will keep it popular well into the next decade. And, like Ruby, it's *also* used as a scripting and glue language. It's a language that does it all and does it all well. I like Go, I really do, and while it might someday see more use than Ruby, Javascript and Python are at this point pretty established. Of course this is all assuming that Haskell fails to take over the world. Fingers crossed!
This. The instant I read that I went "um no, you are just flat out wrong". Take a look at Netflix. They have been using containers for years. How? Native Linux technologies like cgroups. Not a lick of Go in sight. I love golang and use it extensively. But please, do your research before you go out and act like you know everything. 
Ya I'd love to see Go more popular, as popular as possible, but really dislike this snake oil seller/bible thumper style and hope it doesn't get traction among the user community.
I agree that there is not much talk of movement from scala to go. But just because go is not appealing to scala devs doesn't mean that go is not taking off. I don't know that it will 'dominate' per se, especially with things like rust getting more mature, but it is definitely going to make a dent. The article makes several valid points. While there are some errors and half truths in there as well, it does not detract from the fact that go is becoming more and more popular every day in lots of areas. 
&gt; &gt;It's really funny talking to people who chase the waves of technology and find out that they don't know that 100% of all containerization technology today is written in Go &gt; No, it is written in C (Linux kernel)... Go is basically used as API translator True enough. But even forgetting that for a second and focusing on the userland parts, BSD Jails and Solaris Zones predate the birth of Go the language by a good many years, nevermind Docker. Containerization has recently seen a big surge in popularity, and Docker is written in Go, and Docker is pretty damn cool... but that one part of the article is pretty cringeworthy, especially since he says it so loudly and unequivocally.
At first I was like &gt; Killing a child o_O Then I lol'd.
Awkward comes from something new, unfamiliar territory. That's where I learn the most!
Well, generally, keep going with the same idea. Try to create interfaces that simply directly say what you actually want, which may involve returning other interface values. That said, there is a certain limit to this technique where eventually you will really start to miss generic types. Reflection can get around it but it's tedious and often slow. Still, people tend to underestimate the distance to that limit before they really start trying. You can also cheat a bit if the parameters can be JSON or XML that the encoding package can handle; those use reflection, but at least you don't have to expend the effort to write it yourself, it's all just library code. Also have a look at how the marshaling works with interfaces (see the encoding package itself for a couple of definitions) as it may provide some other useful techniques.
Can you explain more about how you built it? Is it API based? D3.js? React? EDIT: Looked at it through Chrome inspector and am glad that I was right! I'm still curious about how you built it though, cryptowat.ch is basically what I'd like to be able to build one day! EDIT2: I noticed your top level components have props in it somehow. Are you using an implementation of flux?
Actually the standard library does something similar: https://golang.org/pkg/encoding/gob https://golang.org/src/encoding/gob/type.go?s=25464:25496#L810
fantastic! thanks so much for the pointers i forgot to mention that the file i am reading is oversize ... many GB .. so a single pass without slurping everyghing in is desirable. So, with that in mind, I've created a version that reads one char at a time .. i'm assuming the file system is buffering so i don't need to go to any fancy reading large buffers and managing all that shenanigans. Anyway, the below seems to work ... let me know anything that is blatantly bad: package main import ( "bufio" ; "fmt" ; "os" ) const token = "EOF\n" var bytes_matched = int(0) var found_token = false var bytes_read = int(0) const debug = true func main() { reader := bufio.NewReader(os.Stdin) outf,err := os.Create( "part1.bin" ) ; che(err) writer := bufio.NewWriter(outf) second_file := false for { b,err := reader.ReadByte() if err != nil {; break } // reached EOF bytes_read++ err = writer.WriteByte(b) ; che(err) if !second_file { if !found_token { running_match(b) if found_token { writer.Flush() outf.Close() outf,err = os.Create( "part2.bin" ) ; che(err) writer = bufio.NewWriter(outf) second_file = true } } } } writer.Flush() outf.Close() } func running_match(b byte) { // bytes_matched and found_token are global variables // updated by this func // check the current byte matches // the 1+last matched pos in the token // so if b==E, we will add 1 to the "bytes_matched" // if the next b==O, then bytes_matched will be increased to 2 // if the next b!=F, bytes_matched will be reset to zero // this func should never be called once we have a full match if bytes_matched &gt;= 4 { if debug {; fmt.Println("should never be called !!") } found_token = true return } if b == token[bytes_matched] { bytes_matched++ if bytes_matched == 4 {; found_token = true } }else{ bytes_matched = 0 //reset } // debug if debug &amp;&amp; bytes_matched &gt; 0 {; fmt.Println(bytes_read,bytes_matched) } } // func to save me having to type func che(e error) { if e!= nil {; panic(e) } } edit: changed the misleading name of a variable
Google trends allows you to specify that you are referring to "Go", the programming language and not the word go. https://www.google.com/trends/explore#q=Go%2C%20%2Fm%2F09gbxjr%2C%20%2Fm%2F0h989&amp;cmpt=q&amp;tz=Etc%2FGMT%2B3 PS: check out the trend graph for java, it filled me with joy: https://www.google.com/trends/explore#q=%2Fm%2F09gbxjr%2C%20%2Fm%2F07sbkfb%2C%20%2Fm%2F0jgqg&amp;cmpt=q&amp;tz=Etc%2FGMT%2B3
Wow, thank you, this is exactly the sort of information I was looking for.
https://godoc.org/golang.org/x/crypto/ssh/terminal#MakeRaw Seems the only way is set the terminal into raw mode. During in raw mode, any character even ^c will be catched up.
*Way* lower learning curve IMO. The Vuejs faq does a pretty good job explaining the differences and pros/cons between the other, more well-known frameworks: http://vuejs.org/guide/faq.html
Is proto3 included in gRPC?
Here's the [desktop version](https://groups.google.com/forum/#!topic/golang-announce/iSIyW4lM4hY). It appears to be minor issues and hardening for `net/http` when a Go application is proxying HTTP requests. It's a bit late so might not be thinking clearly but I'm pretty sure this is for Go applications functioning as a reverse proxy, not as a client.
it's basically just a text editor, albeit a really good one, with support for running external commands. Best example of this would probably be Acme.
Replace the @ with /u/ and they will be notified of the comment.
We've switched over from godep to [glide](https://github.com/Masterminds/glide).
I don't know off the top of my head, but that's a silly statement to make. Of course Go CAN do it. It's just a story of whether or not someone's written the code yet.
and with glide? 
I am very confuse now, I am using Go 1.5 and what should I use for build tool?
I think this is good. You're using a `bufio.Reader` and `bufio.Writer` so it will be buffered (which means reading a single byte should be fast). You could probably run `gofmt` over your code to clean up the styling. This is probably ok as a simple script, if you wanted to re-use it I'd avoid the global variables, put them in a struct and use methods - then always return errors instead of panicking (if I'm going to panic I'd prefer to do it further upstream) It feels a little noisy at first, but you get used to it (Go tends to be vertically verbose - more lines, but they're generally pretty short) This is a good illustration of how programs can evolve in go. You might start with the really simple, in-memory version (`ioutil.ReadFile` and `bytes.Split`), then the streaming version using regexp, and now a specialized version... each more efficient than the previous. (but also solving a more specific problem)
Actually I am just trying to learn GO and it's ecosystem. I am doing webapp with it. And I am trying to prefer "the go way" to do things. But I would like to have installation of software simple at least for start. Eventually I would like to have database changeable. eg. use embeddable or some external like postgresql
glide is a better choice imo.
I love gb. No surprises, no craziness, just works.
Someone out there on the Great Githubs must have this already written, but there must be somebody who has wrappers for io.Reader &amp; io.Writer that take a connection and automatically refresh the deadline based on various criteria. (I would say that there's a temptation to make it so that when one byte is sent you reset the deadline, but you really want to enforce a minimum _bandwidth_ as well. It's almost always better to just fail a transfer than let it carry on at an average 56 bytes per second for minutes at a time. Might want to use that as an evaluation technique.)
10k entries in 28 minutes with elastic search seems wrong, es should be able to handle that in a breeze with the bulkapi. could it be that your ES instance is under spec? 
Looks handy, thanks!
I just switched from glide to godep! I'll come back to it when go 1.6 is out.
Both are great tools, but I'd like to see how they evolve when Go's vendor mechanics are the default in 1.6. Personally, I use GO15VENDOREXPERIMENT for building and just wrote a simple program (https://github.com/pressly/gv) to copy packages from $GOPATH to `./vendor/` and use a Makefile to build/update packages. I also use glock (https://github.com/robfig/glock) to sync package versions to my $GOPATH. However, I think glock or any package management tool needs a major haircut to be directly designed for the new vendoring. the Makefile I use for all my projects....: https://gist.github.com/pkieltyka/f5c493fb2f63ef7bc76b btw, it requires Go 1.5 for its vendoring support. And also make sure to commit vendor/ in your VCS as well and use `make dist` when building binaries for distribution. 
Another build tool is not a necessity for GO15VENDOREXPERIMENT.
Go's new built in vendoring (as of 1.5). Go 1.6 will have it on by default.
I think i'm going to incorporate https://github.com/hashicorp/yamux so that I have multiplexing and then use the ConnectionWriteTimeout property of yamux.Session. 
I don't really think GopherJS is what I am going for, more of a pure Go implementation, getting the Go syntax vs. JavaScript isn't the goal, the goal is replace the layer with go. 
I think the original Ruby code was inserting the records one at a time, not in bulk.
&gt; Step 8: Remove the logging statements Using a preprocessor helps here, so you don't have to repeatedly uncomment/recomment debug lines when switching between debug/release builds. *[sigh]Though it throws off line numbers, and "go fmt" refuses to update files that aren't pure Go. And it means conditional imports as well, since Go will complain about any that are unused in the release build.[/sigh]*
I code in it everyday. Still sucks.
This is great! Easy to read with lots of comments. I forked it and made one (mostly cosmetic) change. Within `Scheduler` you have all of your fields with `mu *sync.Mutex` at the top. I've seen Andrew and Brad organize their fields with the mutex only being above the fields it owns. I'm not 100% sure my commit is correct so I didn't initiate a pull request but you can take a look to see what I mean: https://github.com/jbydeley/go-scheduler/commit/eade93c189802d87b3ce9c0c7666d2d51beeaee1 And the video where Andrew and Brad talk about it here: https://youtu.be/1rZ-JorHJEY?t=1375
Obviously i have seen this. But it does nothing but tell me its possible to do in Go. I need for information, examples to learn from. 
I think this was posted a couple days ago on here, but Rob Pike doesn't hold `ScanF` in high opinion either: https://github.com/golang/go/issues/12275#issuecomment-133796990
Thanks for the kind words!
Looking at various tools I can see that some (gvt, glide) assume dependencies to be directly in vendor sub-folder, and some other (gb, gocode) assume that dependencies live in vendor/src sub-folder. I need gocode to work for autocomplete. How does one reconcile these differences?
I'd recommend still leaving the use case in the README.md, not in the godoc. I like putting the docs in the godoc entirely rather than half in the README, but you should leave the sales job in. And, no offense, but [scheduler is a really bad name](http://godoc.org/?q=scheduler). (Yes, a lot of those are subpackages but a lot of those are top-level packages too.)
Thanks for the feedback, I'll keep the sales pitch in mind for future packages and update this one when I got the time :) And no offense taken, it's just the best name I could come up with. Would be awesome if you could suggest a better name?
I apologize for my earlier words. I have looked at your example and tested it but it gives me the following error; &gt; M:\Computer\Programming\Go\HTTP POST.go:13: url.Values undefined (type string has no field or method Values) From what i can tell, with my limited knowledge of Go, it should be working... But its not. I am able to understand how it should do the job though, so thank you.
I'd recommend turning this inside-out a bit. Instead of using type `interface{}`, why not have instead require an interface like: type Serializable interface { encoding.TextMarshaller encoding.TextUnmarshaller } The developers know the most about what their datatypes are and what they need, and have the best access to the types in order to write clean marshalling code. If something like `encoding.json`works for them, implementation is easy for them. If it doesn't; you have even less hope of marshalling the data than they do.
Scary
I'll give that a go and see what happens there.
But it doesn't have the manpower of Google. I would love to test Crystal but the development seems slow so I doubt 1.0 will be seen before 2017.
monday := "friday"
Stack Overflow doesn't have discussions and Google+ is nonexistent.
Try the gophers slack: http://blog.gopheracademy.com/gophers-slack-community/
I hope not, "batteries included" is one of go's nicer features.
&gt; Google+ is nonexistent. Well. You asked for forums. Google+ has such forums that are relatively active.
&gt; Would be awesome if you could suggest a better name? I dunno, I'm not very good at this sort of thing, but "tapir" is sort of interesting. You've got the API in the middle, it sounds like "taper" which is sort of what you do, and you get a nice logo possibility out of it. (Behold the power of `grep $THING /usr/share/dict/words`.)
&gt; Well. You asked for forums And Google+ is none, neither is facebook.
No forum as far as I can see.
Nice example. The fact that you can replace the time per-value is the most important takeaway, I think... But, yeah, don't use "this" as a receiver name. 
&gt; (As successful as UNIX has been, if it had somehow not been invented, and someone just today came up with the idea of making a big ol' collection of tiny programs that emitted textual streams at each other that you could pipe together and then building huge swathes of infrastructure on this primitive, they'd be laughed out of the building.) Eh. The preceding idea was to do that with binary records, often fixed-length, and with programming languages that make bad Perl examples look readable. Today, folks might use semi-human-readable but formally-defined formats like XML or JSON; or binary formats that can be unambiguously parsed into human-readable form for debugging, such as protobuf. But I doubt anyone wants to go back to the days of virtual card punches.
Given how many Go projects and libraries either provide services over HTTP, or consume HTTP services, HTTP2 support in stdlib makes sense. If you're not using HTTP2 yet, you probably soon will be.
Well, yeah. Except for the human-readability part. Classic Unix has its atrocities in that regard though. The mail system, particularly sendmail.cf and procmail, kind of stand out ... The other thing that jumps out at me as crappy about plain-text systems is that they always end up involving *encoding* for stuff that doesn't fit into their ideas of "text". Quoted-printable, anyone? (Oh look, again it's the mail system at fault.)
I suggest you hire a contractor.
Also 1.5 generated binaries execution speed is slower unfortunatelly for tasks I do. 12s vs 15s for large logs reading.
The problem is that I don't think there is c api to call go code from c right? And also no shared library or dynamic loading in arm either so it seems to be a lot of work.
In reply to both approaches, the classic comic on exactly this subject: https://xkcd.com/936/
Thanks to both of you. I know there are different ways to generate a password. The project I was working on is mostly for educational purposes. As I mention im both the description above and the README.md - I am aware that the generator logic is somehow flawed, but I still need to know where my other bad decisions are :) @Iwe - I'll take a look a this project - thanks @drewindo - xkcd is alread in my news feed ;)
At the least if keeping the gopass-cmd out of the root of the repo, make sure there's a note in your Readme that designates what the user should install: go get github.com/makpoc/gopass/ui/gopass-cmd
That's awesome :) I'll work with the CLI output to make it simpler and more understandable. I don't see a point in setting default value for domain, because it's useless in most cases (that I can think of at least). For the short/full flags - I might move to using [codegangsta's cli](https://github.com/codegangsta/cli) package. For the webui - I'll make sure to add a start message. It does not read the masterfile because if at some point it's hosted somerwhere it would not make sence for everyone to use the same secret. The web UI has no state, nothing is stored and/or loaded from the system - the password is generated purely based on the provided parameters. What about the templates. To me it feels strange to have a separate variable for each page. The templating system is unnatural or (the better explanation) I don't understand how to use it. Right now I generate a template, containing everything except the actual content of the page (headers, navbar, ...) and then I add the concrete content and store the resulting page in a variable, which is known by the handlers. I don't like it :)
&gt;But it doesn't have the manpower of Google. I don't think that's a big factor. Many languages not backed by google have become successful and languages backed by google don't always succeed (see dart for example). 
Again... as you end up pointing out... the "human readability" aspect ends up oversold. Besides, general principle of programming, forcing an abstraction on top of something that can't actually conform to that abstraction produces very sad results. You seem to be looking at a rabbit with me... or, perhaps with just a bit of a perspective change on the same set of facts, you'll find [you also see a duck](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Kaninchen_und_Ente.png/1024px-Kaninchen_und_Ente.png), without any of the facts changing.... Ignore the sales pitch for plain-text human-readable protocols... we've been living with them for decades now, we have the experience to simply look at them. They aren't useless, but they've got some really, really, _really_ bad issues that are basically unfixable. (And remember "plain-text" in the UNIX world really means _text_... even "HTTP" is more structure than UNIX has and is really no longer "plain text".) Look at them for what they are, both good and bad, not what they're "supposed" to be.
It's nice that you keep coming to this subreddit to complain about Go.
Thanks :) Easy to use in theory, but I suppose hard to set up in a way that it efficient, cheap, with few false positives and where the warnings actually lead to action. Not my expertise, I just wanted to fill the gaping hole of QI detection tools...
Any suggestions welcome! Env var and Flag sources are on the todo list. A dynamodb source is on its way.
Is there something that was a problem? I'm happy to look at that before go 1.6 comes out.
I wrote up a quick into to the new vendor system at http://engineeredweb.com/blog/2015/go-1.5-vendor-handling/. The setup is useful but the details don't appear to be widely known, yet. Hope it helps.
should read "The Go Programming Language". not "Google Go"
Many Go users feel it's not even close to Java in all the right ways. Ecosystem, maturity and more professionals using it improves everyday.
That's exactly it. I just went from being an ops engineer working with several stacks including java and go to just go and I'm actually happier with every passing day.
I'd guess that's why the title says "can" and not "does". Its a forward looking piece. Personally though I'd rather not see these pieces popping up because it starts wars that don't help the platform. It looks like a hype cycle is brewing where Go had been growing on successful usage.
That's actually where I started and didn't find anything at the time for Go. I thought about formalizing it on JSON query and maybe I'll give it a shot if no one else has done anything.
Ah, sorry I didn't put it together that it was you in both places. Once gocode is willing to put the change in I'm happy to help. gocode supporting the vendor directory well will be a benefit for everyone. Not just glide users.
There's Scala. I know its pretty hot right now. Edit: why is this being downvoted? No value judgement, scala is a primarily functional programming language; probably the most popular one out there?
So there is an interface 'Source' if you wish to implement such things, I'd be very willing to accept pull requests :).
&gt; Say what. Well, I meant the Go runtime keeps track of if anything references them. I'm not super familiar with that bit of the runtime, so if it isn't reference counting, I'm happy to update to say so. &gt; Once you *convert* an `unsafe.Pointer` to a `uintptr` and said `unsafe.Pointer` goes out of scope, you risk a dangling pointer. I'm not entirely sure that is the only case it can change, but I agree 'convert' is perhaps a better work than 'cast' in this instance.
Thanks. And that above is the reason I am reluctant to move to new vendoring. So far, all my packages are in the same global GOPATH location. Has worked well so far while maintaining 5 separate projects simultaneously between 3 developers. I used to work on nodejs projects and liked vendoring there, especially when they made npm look for the module up tree to avoid pulling a duplicate down the branch.
&gt; (the part where it adds special characters), but when I have more time I'll most probably redo it. You can write a simple PRNG for that, [like this](https://github.com/opennota/rand/blob/master/rand.go).
Thanks, I'll definitely look into it!
&gt; implement see github.com/spf13/viper for their remote config sources, which support consul &amp; etcd as sources for a good starting point 
I didn't realize there was a competition. I'm just gonna reach into my bag and pull out the tool I want to use for the job. I don't need proof that my tool is better than other tools. I know it's the right tool for me. 
If you have a good development ide like eclipse, intellij or visual studio etc you hardly type out any words at all so I the language it self does not contribute so much in coding speed . The tooling and libraries available for java is light-years ahead of go 
From the little I know of it I agree, my knowledge is also based on trying Scala out like 5-10 years ago (not sure). To me it seems like the ML languages might be the best bet right now for a chance of getting FP to a wider audience. In theory I like Haskell more but even very smart friends of mine disliked it when being forced to use it in university and it's so divergent with all the concepts constantly being fed into the mix that I think it's has too high threshold for ever getting really popular. I don't want a hot language, I want a FP language that more or less every professional programmer at least is somewhat familiar with that has a clear enough way of doing things. Having said all this about FP, I think Go really hits one of the sweet spots in the imperative space. I've really thought "this is what java aims for but better suited to what we do today" several times for different reasons.
The videos are up now: https://www.youtube.com/watch?v=UECh7X07m6E
What a novel and unaddressed observation.
I can't agree more with you on Go if I need something done quick Go I'd my goto tool. As far as Haskell. I think the issue with learning it, is that it's used to teach/experiment with category theory and lambda calculous. While these are really good to know they are not necessarily practical for everyone. Too many books on ML languages focus too much on theory and less on practicality. When in fact Haskell and others can be very practical. To address your last point, you actually do have an FP language most programmers are familiar with. JavaScript! They even have some of the more complex features like monads already implemented (e.g. ajax, promises, and to a degree jquery)
I think I at least want pure functions and functional composition as core language features and in wide spread use in my fantasy popular FP language. Edit: and static typing! Edit again: and single variable assignment, it's hard comparing to js:) The JavaScript world seems to be slowly moving in the right direction though. It's only quite recently the first really nice persistent data structure library with enough stuff in it to seemingly cover most grounds popped up on my radar (the one from facebook). I've tried a bunch of the earlier ones but they lacked to many things that they didn't really in the end make things tidier. The engineers of Facebook seems to be generally helping out a lot in pushing these things further, regardless of the fact that facebook.com apparently will disable my fb account one week from because I'm not using my legal name. To my surprise I found out that their CLA is actually possible to sign by e-mail only which at least means their engineering side of things are saner than the rest of it :)
&gt; I thought the Go team was trying to reduce its size and split packages out into separate repositories. They can't remove anything from the standard library without breaking the compatibility promise.
&gt; I think there comes a time when you just have to plug your nose, look at whats out there, and then do your best to refine and make the best least bad thing instead of waiting for a perfect solution to come along. The problem is that once you implement something you can't un-do that. Go is meant for enterprise usage, and so backwards compatibility is a HUGE thing. so anything they put in the language will be sticking around for a LONG time, and if it's done wrong they will need to deal with any issues caused for a LONG time. If it causes the compiler to be slower, or binaries larger, or even just adding complexity to the compiler/runtime it is something that can't be undone and the effects of it will be felt for many years. It's kind of nice to see a language out there to put their foot down and say no to something.
&gt; It's kind of nice to see a language out there to put their foot down and say no to something. 100% agree. Some say it's a weakness; I see it as a strength.
There are ways to do it without being bound to the first implementation. Rust did and is doing this really well. They tried everything and constantly tweaked while in the alpha and beta stages. Now that they are stable, they have introduced the idea of unstable features and libraries that can change at the drop of a hat. This contract allows features to get widely tested before final adoption or removal. I think just about any language could benefit from a similar sorry if evolution path.
Rust did a neat trick here. You have to opt in to using unstable features and apis. You can't simply stumble into them. So the chance of mistakenly doing stuff with unstable code is effectively eliminated.
I also enjoy it when functions are first class, and writing functional javascript feels great. Except I hate the closing braces that makes it look "scheme-like".
You need to you PhantomJS Webdriver protocol which is used for example by Selenium.
Rob Pike told me that it's “probably safe” to convert an `unsafe.Pointer` to a `uintptr` (and back) with respect to garbage collection if you do so in one statement. I'm not sure if I can take this as authoritative though. 
Hi, today I decided to share with you a little notice about the project I've just finished. go-url-fuzzer is a CLI application written entirely in Go language, inspired by the Indir url scanner (source link on github). The application let you search for hidden files and directories on the webserver by comparing a defined set of common URL patterns. I hope you will enjoy the project and encourage me to participate in future ones. Any positive or negative feedback about the application is appreciate. Have a nice weekend.
You beat me at posting this.
&gt; I rather copy and paste code than fall back on less safe methods. Exactly my point. With the expressive, powerful template system in C++, you could write generic code once, and get optimized output. No compromise between generic code, and safety, or as they say in the C++ world, "zero-cost abstraction." 
Think of it this way - Go is a language that has been optimised for reading, meaning its simple to look at a piece of Go code, figure out what's happening and make changes. This is in contrast to more verbose languages that are easy to write with the help of an IDE, but have to be parsed by other programmers in their head before they can understand it. Java has been around for 2 decades, so I'm no surprised that it has a better ecosystem of libraries. But if a person had made a similar prediction about Java in 2000 - *The tooling and libraries available for C++ is light-years ahead of Java, and hence Java won't succeed*, that person would have been wrong. At the rate at which Go is developing, I reckon you'll see the situation around libraries improve a lot in the coming years.
[Your dieharder test](https://github.com/EricLagergren/go-prng/blob/master/xorshift/xorshift_test.go) probably doesn't test what you think it tests. #===============# rng_name | mt19937 | #===============# To properly test your PRNGs specify `-g 200` on the dieharder command line and feed it raw binary 32-bit integers, as described on the dieharder man page under "BEST PRACTICE." [Example](https://github.com/opennota/rand/blob/master/rand_dieharder_test.go)
First of all I am glad you finally admit that languages can become successful without the backing of a large company. I know that must have been really painful for you to backtrack 180 degrees. Secondly crystal's community is growing very fast. They are releasing every two months.
I believe you are confused about what bleve is. Bleve it's not a distributed full text search server solution like eg elasticsearch. Bleve is the full text search *library* that such solutions use. The equivalent of Lucene in Go. If you want to embed bleve into your distributed app is up to you to implement replication, etc.
This is really nice work. I do wish you'd had more technical challenges to discuss in the blog article, but otherwise an interesting read. I've considered writing my own load balancing proxy and abandoning NGiNX but something always stops me. How's the performance compared to HAProxy and did you take a look at oxy?
Do you have to explicitly opt in before using a library that uses the unstable api/features?
[Previously discussed here](https://www.reddit.com/r/golang/comments/3lb1ym/proposal_enhanced_tabledriven_test_support/).
Then use an email client...
Looks pretty easy to use and useful. Thanks!
GC pause times improved, the raw program performance significantly worsened in many cases: I see 12s (1.4) vs 15s (1.5) log processing time.
..or you could use one of already existing libmagic bindings.
Github.com/justyntemme/gomonitor uses go to serve web pages that display the ouput of hard coded commands like top. Shameless self promo
... maybe avoiding the external dependency is less important to you than for the OP.
Pop that into a file called `tmp.go`, and run it with `go run -race tmp.go`.
Hey, this is cool. Is it required to read the whole file into memory to do the matching? How much of the file is required for these to match?
Given that the name has experiment right in the name I asked about just this. What I was told it that it will be on by default in 1.6 with the ability to turn off. In 1.7 there will be no off switch. That's the plan. Then they said, but it's an experiment so something might change. Though, that gets more and more unlikely.
I built a standalone search system for logs using bleve. Each bleve index is considered a "shard". Using multiple bleve "shards" allows the system to maximise disk IO, via parallel indexing operations. It also makes it easy to delete data older than a certain date -- just delete the shard containing the old data. You can check it out at: https://github.com/ekanite/ekanite
And no such thing as rvm exists (or, to the point, needs to exist) that I've seen. 
But his library is also an external dependency.
I wrote this[1] for my own use. It works well in some situations but not in all. It is mainly useful when used internally in a package. The main con is that it hides information that is useful for code coverage. i.e are you testing the error paths or not. I have another package that I use occasionally to work around this [2], but often times I end up unwrapping the portions I need to test. [1] https://github.com/surullabs/fault [2] https://github.com/surullabs/testfault 
It checks the files headers, the highest number of bytes it needs is 261 right now. 
Well seen... quotas may be... Thanks for the alert.
Alan Donovan told me something very similar, yes.
I was going to ask what the point was, since there have been very few breaking changes since Go 1, but it's been around since before Go 1. I guess someone still finds it useful.
&gt; No longer was I struggling to understand syntax as I did with PHP or Perl Really? If one can't understand syntax of PHP, Perl or Python (I dev in all 3). Then wow. Btw, I've dropped Perl + Python for Go.
That makes sense. I didn't think of that. I'm on Arch; they keep their [Go packages](https://www.archlinux.org/packages/community/x86_64/go/) up to date pretty well.
At least the unnerving static typing provides more safety.
Aside from the general stability, it's a compiled language, so the concepts from RVM don't really translate very well...
I will try to set up a syntax highlighting compatible with color blind requirements in the next update (early next week).
That is a very unhelpful comment. Please explain at least what you think is wrong or bad.
Cool. I am playing with a lib that takes an arbitrary hash function generator function and satisfies the `math/rand.Source` interface for ease of use and standardized outputs. https://github.com/jasonmoo/rnd I like your use of the diehard test, but am curious if you could use `go generate` to build diehard as part of the test suite. It appears to be missing.
I disagree with your response to the blog post (I enjoyed the tutorial) but I thank you for the link.
I guess it wasn't so much that I didn't understand it (then again, this was 10 years ago when I really was first starting programming), but rather that it did not read nearly as simply as Ruby. And after writing Ruby code (and learning other programming and scripting langs all this time) Go seemed just as easy to me.
Build? Like `wget &amp;&amp; untar &amp;&amp; configure &amp;&amp; make`? Interesting idea.
Dude rage quit? I thought he wanted a simpler life and left the industry. Honestly, I don't blame him. I'm curious about what you think about the content of the post? Is he off in left field with the criticisms? From what I know of his work he is a very talented engineer.
Looks good. Has some things I'm looking for like graceful shutdown and HTTP2. Is it a replacement for net/http or can I plug in my own MVC or Gin MVC to it? Or should I extend it? What's your thoughts? If anything, thanks for doing this. I'm writing my own MVC. Seems like lots to dig into!
I'm going to guess your intent is readability. Why not simply use YAML?
I don't know, to me Ruby/Rails and Go really solve different problems. Rails is really nice if you're writing a web app that isn't (or isn't just) an API or of you're doing anything where an ORM is really helpful (and I really like how they handle methods on objects). Go to me is a very good dear-God-don't-make-me-use-C / glue code / API where you don't need an ORM / anything where I want to do a lot of concurrency stuff language. In my limited experience anyway.
The 90s called, they want their user experience back.
You can read rsc's comment in this thread. https://news.ycombinator.com/item?id=8815778 ( I don't know how to link directly) And that was before Go 1.5, where entire toolchain is written in Go.
That was really informative. Thanks!
I thought this was great. I'm not sure though why you started with tests. I would have gone with the very basics first as the Go in 5 Minutes name sort of implies. But you've got lots of content to choose from going forward. I'll be watching these :)
Thanks. Yea, honestly I've been struggling with whether this should be a screencast for Gophers who already have some experience or for earlier Gophers who are just getting started. So right now I'm just doing a variety of topics and not expecting one screencast to follow the preceding one (which I guess is convenient because I want these to be self-contained anyway). Would you benefit from a "basics" episode?
I think starting with tests is a great idea! There are a lot of resources out there that explains the very basics, but not that many that covers actually best practices. I don't think I would subscribe if this was 5 minutes explaining the basics. Either way, I am subscribed!
No, the length is fine, but put up the main points (and not the complete text). When you are talking, I am trying to read the text at the same time, so I can anchor what you are saying. If instead of *all* the text, write the main points, then I can use that to anchor what you are saying.
got it. thanks!
Yeah. Being a weekly show, you'll have lots of opportunity test what works. I would try to make them approachable to broad levels of skill to appeal to a greater audience. You can also do something like a couple of minutes of basics and close out with more advanced stuff. Again you have lots of content to work with. I'd love to see you do something with design patterns for Go.
Great article and amazing job done on the [GopherJS](https://github.com/gopherjs/gopherjs) project. Thanks for posting this.
Sweet! You just got yourself a subscriber! :D
it would be cool to have a forum that is powered by golang-forum-software :D
A [time.Time](http://godoc.org/time#Time) always has time zone information attached precisely so that you don't have to worry about that :)
Are you just demonstrating a pattern here? It looks like you're not demonstrating dependency injection as much as you're demonstrating encapsulation of the implementation (you're exposing the interface and providing a method that returns a private implementation). The stranger thing is you're using a singleton, which is widely regarded as an antipattern and thus obscures your tutorial. You could more simply demonstrate it with a `func New() interfaces.BookService`, and even more simply: don't create an `interfaces` package. As it stands, dependency injection in Go is dead simple using the curly-brace syntax `MyThing{Dep:NewMyDep()}`, but as I said earlier, you're really demonstrating package-level encapsulation.
First of all great job and a very interesting article! As you mentioned in the go version using 32 bit integers made it faster. I tryed the same in the C version using `int32_t` from stdint.h, wich made the C version a little bit faster on my computer: 6.1s (gcc 4.7) and 4.7s (clang 3.5).
so does it do generics? how do i write a func with params? i dont know lisp. ex: `func printIdx(arr []int, idx int) { fmt.Println(arr[idx]); }`
This may be what you are referring to. I'm not sure of it's current status in the language, but will post back here if I become aware of it. https://docs.google.com/document/d/1e8kOo3r51b2BWtTs_1uADIA5djfXhPT36s6eHVRIvaU/edit?pli=1
first of all thanks for the feedback! what do you mean fix the README.md? i'll write it to an array thats a good idea, just that I want instant results, i don't want the user to wait too long for results. what do you mean bin? go get installs to $GOPATH/bin automatically no?
what would it take for you to feel safe? I agree with you. Basically, it makes me think that people behind are not really aware of the real conflict. 
Great job and well written article!
Liteide was on the good path, and I am sorry to see it is almost abandoned. I am using Adobe Brackets , which you can customize for golang pretty well.
To be candid with you, I like that more, too. To be agreeable with a wider audience and *in the unlikely event that push comes to shove*, there is the full, verbose document to fall back on. It doesn't solve everything, true, but it's there for those who would like it. We're aware of the negative implications of a CoC. This CoC is not used like a hammer or a barbed wire fence. It's more like the rug everyone is standing on. It's there because people expect it, but you only need to notice it if it becomes relevant to you. At least, that's my personal hope for the Go community at large.
Probably at least until there is a canonical GUI library. So… a while, probably.
I'd love more of these posts about the more interesting features of Go! GopherJS Channels are something that i've only begun to benchmark, and i think more awareness of their costs and/or benefits in GopherJS would make for some good blog posts. Even if it's a costly operation, knowing why it is costly and what improvements are being discussed for the shortcomings would make for good reading! Best of luck with GopherJS, i really enjoy the project!
Any Jetbrains brand with: https://github.com/go-lang-plugin-org/go-lang-idea-plugin
I have seen the opposite in both. At HotelTonight, we wrote an API that serves millions of requests per day in Ruby without breaking a sweat. On the other hand, there are plenty of great ORMs for Go. Again, check out the awesome-go list. It really does take building out a few projects in Go to figure out how powerful and awesome it really is.
Otto - A JavaScript interpreter in Go It's okay, nobody likes unambiguous names, anyway.
LIMIT 1 UNION SELECT mail,password,1,1,1 FROM users or $iId = mysql_real_escape_string("1 OR 1=1"); $sSql = "SELECT * FROM table WHERE id = $iId";
you can use mutex locks around an increment function instead of using channels. Are you using the count somewhere else?
Are you asking for a UI package to build native UIs with Go? Or a Go IDE? In which case I totally recommend you to check https://github.com/go-lang-plugin-org/go-lang-idea-plugin
It means that you can't hide from a psychopath who has an opposing view to yours, making these viewpoints less likely to be posted, although they are absolutely wanted and needed. Also, there are people who simply don't want their names plastered on the internet. Example: Lennart getting death threats RE: systemd, Ian of the Debian Technical Committee being denounced for his opinions and eventually resigning. Sometimes you want to have an opinion, and not have it haunt you because people are idiots.
Thanks, I'll take a look.
&gt; GoBridge is dedicated to building bridges that educate underrepresented communities to teach technical skills and foster diversity in Go. This sounds like a highly political group to run a supposedly universal forum.
Like Go meets Scratch?
I've always seen the need for an IDE as a failure of the language. For example, you kind of need an IDE to work with Java. A lot of projects rely on IDE features to get things done. From a Ruby and Python point of view an IDE just gets in the way. I think Go also fits into this category. A good editor (take your pick) is all you need IMHO. Have you tried writing Go without an IDE? There is no single answer to the IDE-vs-Editor debate and one size does not fit all.
Actually, some people use gists as packages in the real world code. See Go-Package-Store for example, where packages are named gist7480523, gist7802150 and so on. It's absolutely unreadable and scary. https://github.com/shurcooL/Go-Package-Store/blob/master/main.go
I don't use a IDE myself, What i am talking about is a simple Drag and Drop interface for Go UI. So that you don't have to write all the code for a simple form, instead its generated for you then you can focus on the code that makes the program work.
You mean something like Rails scaffolding?
&gt; Add a top-level handler that recovers from otherwise-unexpected panics Right now we are manually checking on every `err` in our application code, what if a third-party library panics? Is there some global handler we can instantiate for anything that would otherwise panic? Thanks for the input, much appreciated!
By the end of the examples, is there any reason why Option 3 couldn't be to simply yank out and name the anonymous defer function, then cleanly reuse the *Resource variable and call a short and sweet named defer?
SELECT * FROM table WHERE id &gt; $number quoting the number changes the meaning. As you give one off fixes for my example, I will modify the example to show you where you are solving a hard problem the wrong way. In this example the 1-off solution is to simply cast the int. The right way is parameterized sql as it fixes the problem across the board. 
&gt;Question 1 : for better working space I created /Developer/goprojects . Do I have to set my path stuff for only this directory even I have multiple projects in that folder ? I would suggest to have one GOROOT and one GOPATH. All your projects and other 3rd party packages will be stored under one path pointed to by GOPATH and the Go compiler is in GOROOT. Benefits: * Never need to change Env params and path settings again after initial setup * No hassle if you install a new Go distribution, because GOROOT and GOPATH are seperated Do NOT install Go distribution and your projects into one directory! Although its possible im quite sure you will run into problems farther down the road. Some coders have a seperate GOPATH for each project - and im sure they have some good reason for that - but most part of the go community suggest only one GOPATH. 
cool!
I think you're on the right track. I feel like he's talking about an "interface builder" feature found in those IDEs.
It does fee like an overkill. I am learning go as I go.
Yeah I'm all for terse "codes of conduct" along the lines of the above or Wheaton's Law, but lawyers, am I right? Perhaps it'd be a nice touch to include some version along these lines, clearly stated as the Zeroth Rule? I guess I get where some people are coming from, but when a given CoC begins to be used as a cudgel it's my experience that the community dies out anyway.
After you convert to int32 it looks like you run the test through GopherJS twice instead of doing the first through the Go compiler.
You mean a Web UI or a native, desktop UI? Sorry but the question / scope is confusing. 
Sadly we can't use URL shorteners here. http://github.com/xlab/gitio can help me get links like http://git.io/xlab_ping.git that resolve with 302 into https://gist.github.com/xlab/df49fae54b7c6ec03f71.git but the latter can be subject for go get and the former can't. I'm not sure if this is a bug or not. So, using "0eb7e53fa687acbf05ea.git" or "df49fae54b7c6ec03f71.git" will drive your gopher colleagues nuts.
Hello. I found the same example looking for gists being used in packages, but if you look carefully, that packages is not using gist at all. Is just the author that, automatically or manually, commit some gists in the code. 
The readability issue is there, and I am ok with that. This is not meant to replace traditional packaging or projects in github. I think is totally broken for that use case. One problem readability. In the [initial example](https://gist.github.com/guillermo/0eb7e53fa687acbf05ea) the code is really small. Is something that I was always tire of writing again and again, but too small to even create a proper package. Summary: This is just a technique and you should have the criteria to know when to use it and when not to. 
thanks. thats what i meant. when its compiled to go does it still use interfaces or is some % of the variables converted to builtin types? cool project also. gl!
The sins of the parent (language) shall be visited upon the progeny (languages)
He does talk about "simple Drag &amp; Drop system", of course he means the Lazarus/Scene Builder thing.
I think it might be a while until we see that given the UIs in Go are nowhere near maturity (at least from what I know, I might be wrong). 
They seem to talk about pretty vague things all the time and I can't see how this would be useful. Can someone enlighten? So I understand this tool compiles code for any environment with `otto compile`, but this is already just `go install` but I suppose it makes more sense for other languages. Then `otto dev`, this executes the binary...? `otto infra` is said to "create a base infrastructure according to industry best practices", what is a base infrastructure? Connecting to sockets??? Opening DB connections? Very vague sentence. `otto build`, we just compiled it, what else do we need to build? `otto deploy`, this pushes the binary to your production server, but how does it do that? Do I need to configure SFTP details, or does it use Git? Or what software does my server need to receive new deployments? I like the sound of deploying my code from my development computer to my server easily, but they seem to require a whole lot of features I don't comprehend...
Good
Are you saying something like this? http://play.golang.org/p/OeXUeo6-MU
1. It'll become very handy if your environment looks [like this](https://ottoproject.io/#microservices), distributed across several servers. 2. Otto belongs here because it's mostly written in Go.
Thanks for the suggestion. I've updated the blog with this Option 3, and linked to this discussion.
If you have any specific feedback that will help make the forum better, please feel free to share it.
&gt; highly political You keep using that word, I do not think it means what you think it means.
I was wondering why more web IDE's weren't using server side auto complete etc. I'll have to check this out.
"Not about myself."
The CoC is not going to stop anyone from advocating for minority views. What it'll do is stop *other* people from insulting or attacking that person for his or her opinion. The CoC actually helps the minority opinion. The majority opinion is the one few people are going to attack in the first place.
But speed limits make *me* feel unsafe. Also the definition of "reckless driving" is fluid and evolving, so until this gross injustice is adequately addressed I'm going to cry like a little baby.
The CoC only protects you against _public_ replies (which can be moderated easily—especially with a small community, see Hacker News), it's the lack of privacy which opens up the real can of worms.
FWIW, I totally agree with not requiring real names. It's a mistake that is well-intended, but almost always turns out to be a bad idea. See Google+ et. al. I posted as such on the gobridge forum: https://forum.golangbridge.org/t/real-name-req-is-a-mistake/660
the blog post explicitly says that GoBridge wants this forum to replace the go-nuts list "we expect the golang-nuts mailing list to decrease in effectiveness and usability" call me crazy but that does not look very diverse
Good point. That's fair enough, and I'm certainly open to a diverse set of communities (that's absolutely what makes us great). However, as /u/hoptar said, this post is trying to replace something with something else that doesn't really add much to it. I would instead prefer new communities surrounding a more diverse set of mediums. For example, how about a community of people doing stuff on livecoding.tv, or youtube channels dedicated to teaching how to build ground up apps in go. The go-nuts mailing list is an established medium that, in my own opinion, simply doesn't need replacing. Especially not with something that just doesn't seem to add much.
Great post! I personally have other issues with the forum that prevent me from using it (dividing the community and information, no official support from users who matter (rsc, Rob Pike, etc.), the automatic closing of topics after three months which prevents follow-ups which are needed when posts reach the top of Google search results three years down the road, the possibility of the forum disappearing at any moment, how it only shows the time of the last post to make it look more active than it is (literally _no way_ to check the initial post date), you're unable to add more than two links to any post), but I do wish it the best. If it gets more people involved, it'll help the community regardless.
I'm not quite following what your issue is. You want to broadcast messages from a single instance, in a non-distributed way? Do you care about persistence? Do you care about having to add a second instance for HA?
I'm not sure that we need yet another Go discussion community so I'm afraid I don't have any.
You're incorrect about the meaning of git - [RTFD](http://www.thefreedictionary.com/git). It means bastard, and the meaning gradually evolved to "fool", which is why Linus named it so. Nevertheless, we should make sure that no one who's born out of wedlock feels "unsafe" or "unwelcome". You're *also* incorrect about retard being used as a slur. It was no different from the popular book series "X for dummies". The maintainer wanted to convey that it was simple to setup and use (which it was). I think you also missed the point about using my real name. I have no issues using it in any other context, except when speaking with code-of-conduct peddlers. I've found that such people are remarkably motivated when it comes to destroying the lives of people who disagree with them, so I'd rather not take the chance. I will continue to participate in forums that require real names, such as golang bridge but if this topic comes up there I won't risk saying a word. 
If you want to add HA in the future, you need to think about how you will do it now. It's going to be hard to scale and replicate a system designed to work as a single instance. 
Give atom editor a try - with its multiple custom packages for golang it is super! For ref - http://marcio.io/2015/07/supercharging-atom-editor-for-go-development/
Just :GoRun right away.
This is how I program when I do java haha I feel its not very Golang-ey though... but I'll wait to see if any other gophers chime in :P Personally I like it.
https://golang.org/pkg/encoding/json/#RawMessage ? Use it to decode your embedded object later, with the right type. 
I think concern is always healthy, but rhetorical escalation in this case is unwarranted. Personally, I hope you join the forum and, if you see the ToS being used as a cudgel, you contact one of the administrators directly.
Normally I'd say it was unwarranted too, but some of the stuff I've seen on github this year has made me think otherwise. I've seen the same attitudes seep into parts of the Go community as well, but I hope I'm wrong about that. I did join the forum, because I think its going to be really great. :) But when the ToS is used as a cudgel, I hope someone else will point it out. Since the target of the cudgel can easily be changed, I won't risk it myself, even in private. Thanks for the encouragement.
if you just want to see the changes, just do "go run", "go build" is for building to a binary, "go install" is for puting the binary in your bin folder, neither are required to run a go application with "go run".
This works after saving manually ":w" otherwise it just runs what is unsaved. Any chance of incorporating save? This has still drastically improved the amount of time it took -- thank you!
If a third-party library panics then you're either using it incorrectly, or you shouldn't be using it.
I'd lean away from saving-and-running in one command, but if you want to create a mapping to do both, you can just throw something like this in your vimrc: `nnoremap &lt;leader&gt;r :w&lt;CR&gt;:GoRun&lt;CR&gt;` (Better practice might be to call the function directly)
Ok, what do you suggest for testing purposes? Overwriting the Config would be possible, but not very elegant... It would result in something like: 1. "dev"-config loaded via init() 1. set "ENV" to "test" 1. config.Config = config.LoadConfigByEnv Better ideas?