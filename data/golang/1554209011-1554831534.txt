You shouldn't use db.Query for something that doesn't returns rows. Use db.Exec instead. The error message could be more helpful. The 'H' is the postgres server message protocol for a COPY command (which doesn't return anything). Bear in mind that you will need to read from os.Stdin to get your results. Alternatively, fixing the db.Query should allow you to write directly to file (you may find an absolute path helpful).
For a completely different take, I'm wondering if go is the right tool, considering that psql is quite capable of doing output to CSV. You also should be careful to catch corner cases like embedded commas and newlines. 
Thanks for the answer. I tried using both of them (db.Exec and db.Query), neither worked to create anything. 
Thanks. Yep, I was wondering if perhaps you had a non-retina display with a DPI of closer to 110, but that wasn’t the case.
I agree, that's why ideally I would like to somehow implement psql capabilities together go. The reason why I'm trying use go here is because the complexity of the script will increase in the future. And go is way more maintainable than bash.
I know others have raised this point, but the author has missed the mark on the dependency management section: &gt; I like vendoring, however, because there’s no concept of versioning a library (you just get the HEAD of master at any period of time) it makes it really hard for library writers to make breaking changes and to pivot. If you use vendoring, you're using it to pin a particular version. Tools like Glide, and Dep existed for quite some time, allowing you to specify a version of a dependency that you want to use - and they both provided a lockfile to always use that same reference in the future too. Library authors can break things as much as they like, because people do use these tools. They just need to make sure they tag their repo. Now, as others have mentioned, there's Go Modules too, replacing legacy solutions like Dep. Again, this supports versioning. There are some good general points and criticisms of the language here though overall.
Here is my O(1) sort: func O1Sort(a []int) []int { return a } It is _the_ fastest sorting algorithm and it is _stable_ !! (One drawback worth mentioning: It does not properly sort _all_ inputs. But they are still stable!).
AFAIK they're both valid but under extremes (high/low concurrency) one can sometimes be found better than the other. Personally I lean on channels more than mutexes because I find them clearer. There's probably a lot of technical reasons for using one more than the other that I do not understand yet, but just thought I'd give you my 2 cents.
I happen to be working on a package/tool to do something similar, backup arbitrary tables to S3 as CSV, JSON or YAML. It's still a work in progress, but the Postgres to CSV bits are basically done. [https://github.com/gavincabbage/chiv](https://github.com/gavincabbage/chiv) Feel free to use whatever bits of code might be useful to you. Planning to make the formatters pluggable, and perhaps the destinations as well, in which case a plain old file destination is the obvious next choice after S3... so the tool might be just what you need. It's a personal project outside of work, so working on it in my free time, but hoping to be done in a week or two.
Imagine if we could combine the two algorithms! It would be *both* fast *and* correct 😄
Why `time.Second`, why not a few milli seconds?
Do you mean accessed or mutated? I didn't think there was a problem with multiple threads accessing items from a channel. The issue here is the `close()` I believe.
Are you referring to `rpc.RegisterName`? Because as I understand it that still uses dot notation https://golang.org/pkg/net/rpc/#RegisterName
MODERN xD as if the language had any relevant history xDdD
Issue is with `c = nil` and `close(c)` statements. One is reading c and another is writing c. 
Thank for the suggestion! 
You can't COPY here. You'll want to run a select and enumerate over the rows. 
Depends what you're trying to achieve. Using both together is also very common.
There is no issue with `c = nil` because it's a local variable. The issue is the read in one and the `close(c)` in the other.
Local variable or not doesn't matter... two goroutines are accessing a variable (with help of closures) which is not atomic and without locks. 
it will be out officially in 1.13. It's still a trial, so its anybody's guess
From how easy it is to use, it's worth it even just for satisfying a passing curiosity.
I wrote a private wrapper for urfave/cli that makes it more declarative. Still have some rough edges to sort out before I open source it.
`c = nil` only mutates the local variable's pointer to no longer reference the channel. It does nothing to the channel itself. It's a safe concurrent operation. The unsafe operations are reading from [closed] channels, closing [closed] channels, and sending on [closed] channels. Those require locks.
Thanks for posting and sharing your experience with Go /u/monumentshorts. I enjoyed reading it and could relate to many of your points. When you say static methods on a package, I think you're referring to public functions that don't belong to a struct right? If that is the case, I agree with you that it's tempting to create global variables inside packages that are used by these functions to handle state. And I agree that it is a bad practice on majority of the cases. I've caught many libraries (including my own) doing something along the lines of : package myLib ... var log = logrus.New() func setPackageLogger(newLog logrus.Logger) { newLog } Bad example, I know. But similar things happen. However I must say that global state is discouraged in Go: https://dave.cheney.net/2017/06/11/go-without-package-scoped-variables
About Duck typing and refactoring. That's indeed a downside of interfaces. I haven't tested but I read that Goland IDE from Jetbrains is pretty smart with refactoring interfaces. Something to keep in mind.
Been a while but used viper before. I believe it’s the same author. Maybe cobra is more full featured. 
Viper is for configuration. Cobra and viper are designed to work together. Use cobra to define the CLI, hook up the arguments to viper, then access all your configuration (cli, env, config file, defaults) through one consistent viper based mechanism. 
Thanks for your feedback. I do cover zero values for the primitive types in the in-depth section. The TL;DR is really just a quick glance reference for those familiar with the language that need a quick refresher. There seems to be a lot of feedback regarding the TL;DR not being clear enough so I'll look into changing it or removing it altogether.
Golang? Are you kidding? It's even in [the FAQ](https://golang.org/doc/faq#go_or_golang). I mean, okay, to bash a random obscure blog post for overusing "golang" may be called a nitpicking, but this is a freaking _book_ FFS! 
If just only unmarshal json data to struct object,I will chosen xpath method to extract specified data, that don't depend on defined object struct, this can solved unknown field.
Personally, I much prefer [`kingpin`](https://github.com/alecthomas/kingpin) as it doesn't rely on global variables. Unless you have specific requirements that only `cobra` supports, I would not use it for this reason.
1.0 just means that everything that works now will work on 1.1. It doesn't mean that v1.0 doesn't have bugs. So the API may be stable enough to be released with a bug which will be fixed in a patch version, it's ok and it doesn't break semver at all. The all point of semantic versioning is for you to convey to your users that any \*working\* API in current version will work in any other version with the same major. And anyway they released v1.0 on 20.3 and the issue was opened on 21.3 (if this is the one: [https://github.com/fyne-io/fyne/issues/161](https://github.com/fyne-io/fyne/issues/161)). So... 
Fair enough--if the fix came a day later, I might have been wrong about the severity of the state of the api in regards to Windows.
I tried to use cobra but just couldn't find enough compelling reasons and features compared to `urfave/cli.v2`. Did you try it at all and what were your takeaways if so?
Because it's a joke anyway? More seriously, it's because if it's too fast it doesn't work anymore. You need enough of a buffer at the beginning that you can get all of your goroutines launched before any of them complete, and if you're running on Windows with default timer resolution you need them to be multiples of at least 16ms.
&gt; (Note that you cannot cd into the directory for package bytes and run go test. The source code for Go and its stdlib are tested and built differently). You actually can :) In fact, you don't even have to cd, you can just `go test bytes` and it works fine. You can even change code in the stdlib and run `go test bytes` and it will rebuild the specific package. Or run `go build` in a package using `bytes` and the package will get automatically rebuild. It's actually quite awesome and useful for quick experiments sometimes :)
Your point is valid but there is no need to be nasty.
starred, loving the custom gopher btw!
I've used cobra with viper, but the one thing that seems unnecessarily difficult is the simple act of storing the config at a default location, as a file, if one doesn't exist. There are methods that are supposed to do it, but either I'm using them wrong, or they don't work. For example, if the config file doesn't exist, there are methods that can be used to create it. These methods require the file extension, despite the fact that when you read a config in, you must specify a file name without extension. It seems quite asymmetric. Surely, if viper knows the name and the extension and the config search path, it can use all that information to provide a method to store the config if one doesn't exist? There's already an issue related to this by the way. I haven't checked out kingpin, but I will. My other go-to is [urfave's cli](https://github.com/urfave/cli), but I really do like cobra's ability to generate clis. The price you pay is binary size. A cli generated with cobra is about 10MB in size. A cli using urfave's package is less than half that.
This is the answer perhaps - https://www.reddit.com/r/golang/comments/b8513o/why_are_my_go_executable_files_so_large/?utm_source=share&amp;utm_medium=ios_app
The following lines worked for me on Postgres 11.2, Go 1.12.1 on darwin/amd64. &gt;`sqlCopyStatement := fmt.Sprintf("copy users to '/tmp/users.csv' with csv header")` &gt; &gt;`res, err := db.Exec(sqlCopyStatement)` &amp;#x200B; &amp;#x200B;
I ran into this issue when experimenting with a CLI using cobra. In python's `argparse` you can define a group of mutually exclusive options, ie `-foo | -bar | -honk`. I couldn't find support, is there a way to do that besides coding the logic myself in the arg validation part?
See: [https://www.reddit.com/r/golang/comments/b8513o/why\_are\_my\_go\_executable\_files\_so\_large/](https://www.reddit.com/r/golang/comments/b8513o/why_are_my_go_executable_files_so_large/)
Indeed. My rule of thumb is that shell script should stay below 30 lines. Shell scripts do easy things easily, but hard things get out of hand pretty quickly.
\&gt; If generics, data transformation, and basic immutability were solved, I’d probably use go for everything. Me too. I think Go as an experiment has succeeded, but it's time to take it a step further and fix the parts it got wrong.
There are some concerns specific to C++, in that if you can get a buffer overflow going you might be able to read out the binary directly out of RAM, and the debug symbols will then hand them everything they need on a silver platter to exploit the binary. In Go, it's going to be harder to get there, because it's memory safe. However, I say "harder" and not "impossible" because it isn't. If you write yourself an arbitrary-directory-traversal vulnerability, and this is something a lot of people do (\`fileToLoad = myFileStorePath + form.Get("file\_request")\` is so easy, and You Lose^(TM)), then you can serve yourself up \`/proc/self/exe\` and get the executable a lot of the time. You may not have all the memory-unsafe concerns but there's still reasons to be concerned that an attacker may be able to get the binary, which will have a lot of good stuff for them. It still wouldn't be a bad policy to not include debugging symbols in the binary. I know we have a policy where production Go binaries have to be built in an environment that we verify won't leak any private information, because by default paths may have things like \`/home/jerf\` in them all over the place.
That compilation has "Mastering Go" as second best seller. I haven't read the book but looking at the code, well, it is the worst code in any language I have ever seen!
Will take a look at it, thanks for the suggestion. 
&gt; My co-workers and I are busy preparing the latest release of CockroachDB, `version 19.1`. CockroachDB To the best of my knowledge the current stable is version is `2.1.6`, can you explain the sudden jump or what `19.1` is all about? 
Where do you need to use global vars with Cobra? You just pass around the root Command struct, no? And as for the companion library, Viper, there is a default instance hidden as a global var, but you don't have to use it and can just get a `New()` separate instance.
Conversions are cheap and specific enough that I can't imagine needing a library to do this. Interfaces to strings seems especially gross.
This is very, very good.
Great news! Can't wait to give it a listen
I’ve missed it so much, thanks for letting us know!
My guess is that they're switching to https://calver.org/ like ubuntu, intellij and many others have done
I don't care what comes as long it's not generics.
[removed]
Ooooh that line up is amazing. 
You are such a &lt;T&gt; /s
Omg finally!!
I like this. Ask my colleagues, that's rare (which I would argue is due to an overwhelming BS to gold ratio)
I feel like selecting and explicitly looping through the rows to build a csv file can lead me to a lot of nasty edge cases with escape characters, etc. Feel a bit safer copying an entire table by using psql inbuilt commands. 
Hey, I put together a video explaining some of the internal mechanisms used: https://youtu.be/NM7X4PIUQB0. I don't have any benchmarks since performance depends entirely on how you use the service.
Which one is that? Do you have any link?
I think the key bit was the /tmp/ folder. It might be more lax with permissions thus allowing the db server to write files in it. Technically I could copy all tables to the tmp dir and then carry them over to a desired folder. However, that feels like a very roundabout way of doing things. Note: I don't have access right now, but will try to chdck it again tomorrow
[removed]
Maybe I'm having a dumb day, but I don't understand what I'm looking at here. It lists as "upcoming" at 2:00 CDT. I guess that means 2pm Central Daylight Time which was 90 minutes ago? I'm invited to "join the discussion" on Slack, but that Slack workspace is by invitation only with no way to contact the administrators. Topic sounds interesting, but maybe this isn't public? 
I for one appreciate this effort of making crypto code less cryptic very much. This is great.
They recorded an episode with a live stream audience but it needs to be edited before they post the final version. 
Ah, looks like they've pulled the linked page down now. Wish I'd seen this earlier, I guess.
Thank you
Hey, I missed you...
!RemindMe 24 hours
I will be messaging you on [**2019-04-03 21:14:19 UTC**](http://www.wolframalpha.com/input/?i=2019-04-03 21:14:19 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/golang/comments/b8llas/go_time_is_back_todays_topic_go_2_and_the_future/ejz6tp5/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/golang/comments/b8llas/go_time_is_back_todays_topic_go_2_and_the_future/ejz6tp5/]%0A%0ARemindMe! 24 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Any way to listen to it somewhere else? 
Awesome. I've subbed and I'll be watching that tomorrow. :D
No scheduled shows. Check back soon.
Inspired by some of your previous writings I wrote https://github.com/xeoncross/got because I wanted template inheritance without a loss of performance or new template language. Adding locale support at the template level seems like an interesting addition to consider (along with A/B testing).
Is there a video accompanying this?
I feel like the point about "No covariance" in the Bad Things section is actually incorrect. For instance, I've used this exact style of doing things many times over in several different packages. For example, see [the cloudlcoud/go-id3](https://github.com/cloudcloud/go-id3) package. There is a generic [Frame](https://github.com/cloudcloud/go-id3/blob/master/frames/frame.go) that a series of specific frame types make use of. There is also then an IFrame (bad naming, I know) that defines required behavior. There are many examples through this project where IFrame is used in function signatures but instances of various frame structs are instead passed. Is this not an instance of covariance?
Same question, the content looks interesting but I have a feeling I'm missing some parts.
Quoting directly from the official modules blog post I linked above. &gt; We are aiming to have the Google-run module mirror ready to be used by default in the go command starting in Go 1.13. Is this not the kind of centralized, 1st party solution you are looking for?
Seems like its internal to Go, I am not sure it can be used in user's land. Have you use it before? Do you have an example to use it?
I'm curious - rather than using one big "all" template to contain everything, why don't you define locale template "packages" and then specify the locale to use? example: folder structure: * templates * locale-en * index.gohtml * error.gothtml * locale-de * index.gohtml * error.gohtml * locale-cn * index.gohtml * error.gohtml * common * layout.gohtml and then templates := make(map[string]template.Template) templates["en"] := templates.New("en") templates["en"].ParseGlob("templates/locale-en/*.gohtml") templates["en"].ParseGlob("templates/common/*gohtml") //same for the other locales - load the specific and the common templates["de"] := templates.New("de") templates["de"].ParseGlob("templates/locale-de/*.gohtml") //and so on... or then use the locale template that your user needs based on their locale setting templates[user.locale].ExecuteTemplate(rw, "index.gohtml",data) On the same note, what's the use case for the dynamically-specified template?
Ah, so *that*'s what are Generics. Holy shit, that would be so much beneficial to concurrency. I hate having to write ten time the same shit for every type of variable I have. Ugh.
Just wait. The livestream was rough with audio issues and whatnot that will all magically be fixed in a day or two when they post it. 
I think the error message is pretty clear, you need `gcc` [1] inside the system PATH [2][3]. [1] https://gcc.gnu.org/install/binaries.html [2] https://stackoverflow.com/a/9546345 [3] https://docs.telerik.com/teststudio/features/test-runners/add-path-environment-variables
!RemindMe 48 hours
thats why i have mingw installed, and it still doesn't work. I added it to path and everything. It doesn't work and shows the same error. Ill probably just have to use my linux laptop, seeing as windows isn't useful for anything beyond gaming
Not yet. However, dotGo is usually pretty quick about releasing videos. Expect them in a few weeks.
Yes, you are right. I've added standalone functions so it can be used both ways. The original intention was I wanted to be able to chain them. However, I recognise that's just one usage pattern. When I talk about performance I'm comparing it to other libraries that use reflect. It's true that a callback with have a small overhead, but nothing like iterating through reflect. Thank you for your feedback and I hope it is useful to you one day :)
Not sure how much help I can be without seeing your path variable and stuff, so I'll just show you mine: https://imgur.com/a/ADiak2K and the files I have in my mingw64/bin directory: https://pastebin.com/QiEHp7Fj
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/KnxIIFT.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20ejzmjc7) 
The “bad” section isn’t very compelling. It’s a list of how you could use Go to write bad code… if you’re a bad developer who ignores normal best practices. Well, guess what, people can write bad code in any language. If it has loops, you can simulate a goto and just make old fashioned spaghetti code like it was 1968. No language can prevent that. But with modern languages you wouldn’t bother to do that because it’s easier to just do the right thing. Same with Go. You could “mess with privates” inside a package, but why would you do that? If you’re writing C++, you can declare random friend classes, but you wouldn’t do that for no reason. There is a fair point to be made about how simple functional-style map and anonymous lambdas are and how the author misses them in Go, but overall, the complaints are just begging for pointless language restrictions because that’s what other languages do. 
Well I think the issue is thinking windows was useful for programming. I got it to work on my Linux laptop in 15 minutes, including installing golang and googling the repositories I needed again because I can't memorize that much. 
There should be an award for comment porn as excellent as this example. Clear descriptions of the "why" are just fantastic. Great work.
No, it’s not. Variance is about how containers and their hierarchies relate. For example is a list of a superclass the superclass if a list of a subclass. For go, the main problem is lists aren’t not type converted. Try it 
That's what part of comment was about though, the links I provided have a working example of this. An interface is used in conjunction with a base struct type to and no type coercion is needed to use different struct types where the interface is expected.
The issue isn’t about interface usage, it’s about arrays. Here is a stack overflow question describing the array variance issue https://stackoverflow.com/questions/44602741/why-cant-i-substitute-a-slice-of-one-type-for-another-in-go
I had no issues setting up go-gl/glfw on windows. Just follow this [https://github.com/golang/go/wiki/WindowsBuild#the-manual-way](https://github.com/golang/go/wiki/WindowsBuild#the-manual-way) 
[removed]
Awesome! I waited for a year to hear it again 
[removed]
Great, love their show and can’t wait to hear it again!
I used a similar technique to convert Go [present](https://godoc.org/golang.org/x/tools/cmd/present) talks to PDF. https://github.com/mmcloughlin/podium
Yes!!!!
I would love to see a benchmark against some other template solutions.
Would love to know the time frame of Go 2
Awesome. I have been listening to old podcasts - you guys are good..
Great news!
 &gt; &gt; &gt; I also have to ship the html templates and the images that come with the application. Search for how to package bindata with your binary. You can build the assets into that single binary and ship it. &gt; Moreover, the program has a "exit"-button that will shut down the server but I noticed that most test users will simply (out of habit) close the tab and believe the program closed. I would like to hide all this 'complexity' from the user. You can have your front end page send heart beats if it's stateless http. Or you can know when the websocket client disconnects for longer than X amount. Then you can shut down 
After seeing [a critique](https://gist.github.com/tj/638adb053f802e6c19686bd2fee443b7) of the Go Error Values proposal, I've decided to see if it really would be hard to implement a nester-error-to-JSON encoding. It wasn't, and it looked kind of cool, so I decided to share.
It's a bit frustrating that it has so many dependencies. Really put me off using it.
Missed it somehow. This is exactly what I meant. So, +1 reason to be happy.
!remin2 20 days
!remindme 20 days
I will be messaging you on [**2019-04-23 08:49:16 UTC**](http://www.wolframalpha.com/input/?i=2019-04-23 08:49:16 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/golang/comments/b8llz1/optimizing_go_code_without_a_blindfold_dotgo_2019/ek0dvll/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/golang/comments/b8llz1/optimizing_go_code_without_a_blindfold_dotgo_2019/ek0dvll/]%0A%0ARemindMe! 20 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ek0dx35) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Wait, you *want* array covariance?!? 
Totally. The article is surprisingly dense with misinformation, misconceptions, and bad assumptions. Here's one sentence from the "Sometimes inheritance can be good" section: &gt; ...Because of this you can see that people circumvent this limitation by either creating mutable function variables on classes (so they can “override” methods) or they copy and paste entire swaths of code with needless duplication because they can’t find a way to abstract the commonalities. What does this even mean when it comes to Go? Does Go have classes? This is practically gibberish. I swear, I wasn't trying to be mean in my previous comments. The article is full of nonsense like this and there isn't a good place to start a discussion -- that isn't my fault. But yes, I agree that another big problem with it is that it implies that Go encourages bad practices. 
nice!
Also Gitea (https://gitea.io), a faster-moving fork of Gogs that takes community contributions.
Yes. Buffalo. 
!remindme 20 days
!RemindMe 48 hours
No scheduled show！
&gt; ook at this function and my mind just boggles... what are you left with when this exits? It sure looks like you are setting sc1's Remaining fields based on sc2's other field values, which means no necessary relationship exists between those same field values in sc1 and sc1's remaining fields? &gt; &gt; Example: if sc1 had OrderedQuantity 50 and InvoicedQuantity 10 and RemainingQuantity 40, on entry into the function, and sc2 had RemainingQuantity 0, OrderedQuantity 100, Invoic It is an update function. sc2 is the one coming in from node. sc1 is the one already in the blockchain 
I just can't stop the `foo = append(foo, bar)` even though it's clear that this seemingly contrived example is low-hanging fruit. Should I bother refactoring the above said low-hanging fruit?
dev dependency section plz
I already came from a PHP+Laravel background. After a few false starts with frameworks, I discovered that the standard libraries plus a handful of small helper libraries (e.g., chi for routing) were a much better paradigm to work with. I'm curious, what are you trying to achieve?
Use gitea. Like... seriously. 
I can confirm that gitea is the superior fork here.
I think the project is misnamed. It's not "casting", it's "converting". It's useful only when, well, when the library documentation says it is. When you're dealing with some external sloppy-typed value and you need to deal with it. I wouldn't make a new system require this, but if you've got existing stuff you've got to work with, it can be nice to not have to do all this yourself.
I assume not needing to do all the bootstrapping that using various libraries.
Sorry if this is stupid but do any of these support themes? I’d love a self hosted git server that didn’t have a GitHub-inspired UI. 
Gogs takes community contributions.
Maybe it does now. Gitea only exists because the only Gogs author seemed to go AWOL, so it was hard to get things fixed. People were queueing up to submit changes, none of which ever got included. So it got forked to Gitea, with a team of developers, and many more community contributions.
Gitea has a blog post discussing the reasoning. https://blog.gitea.io/2016/12/welcome-to-gitea/
You could just use Gitlab.
Sorry, but I cannot sew how this is related. The question is not how to add scrolling to some TUI widget, or I misunderstand something badly.
Gitea does have two themes at the moment, and there is a slightly hacky way to add your own until user supplied themes are officially supported.
Gitea includes a dark mode theme (`arc-green`), but you can add custom themes (and templates) easily. https://docs.gitea.io/en-us/config-cheat-sheet/#ui-ui
I like this. Would you be open to patches adding godocs on the exported functions? Would you be open to patches with breaking changes for naming conventions? One common Go naming convention is that acronyms should all be upper case, thus Html5 should be HTML5. 
What about an sqlite browser? What about a log viewer? &amp;#x200B; Of course you don't actually read all lines.
If I remember correctly Gitea only exists because one of the Gogs members was fed up the with low quality and subsequently removed the people responsible for it from the organisation
Very stoked to hear it's back! Can't wait!
Godocs for the exported functions are a great idea and it's something I was planning to add soon. The naming is a bit tricky. So far, all tags are lowercase with a capital first letter, e.g. Html. I chose this rule as 1) you don't need to know if a tag is an acronym (e.g. ul, ol) or some other abbreviation (e.g. div) to infer the spelling of unseen tags and 2) it allows to separate the tag Html from the type HTML. I guess you refer in particular to the DoctypeHtml5 function, which is not a tag and, therefore, should be called DoctypeHTML5 - I don't really have a preference in this case and am open to changing it. Hope that makes the reason behind the naming a bit clearer?
So why use this instead of https://github.com/Sirupsen/logrus which also supports console logs, files, and/or JSON packets (for external log collectors)?
use https://play.jsgo.io instead of the playground, like so: https://play.jsgo.io/4a6321cef7b75f47d9fc4287499af7f2293461c2
Not JSON specific, but I'd love to see a "temporary" / "permanent" marker for each error as well. Was this something that was retried? Should it have been? 
Makes sense. Thanks for the response.
In my last project we took a very similar approach to making markup (this was in Kotlin though). &amp;#x200B; The ability to type-check and safely refactor bits of our markup into components just by hitting the relevant shortcuts in our IDE was extremely good. It meant we made more general purpose components (like InputWithLabel) which had a knock-on effect in our CSS being more general purpose and re-usable too. &amp;#x200B; Assuming this works a similar way then this is a great addition to the ecosystem. 
`fmt.Sprintf(messageTemplate, mySlice...)` https://gobyexample.com/variadic-functions
AWESOME - wasn't aware you could pass a slice to variadic functions. Exactly what I need. Thank you.
So much for the Go fanatics who keep saying all you need is stdlib to make a web app, yet any Go web app out there which solves a real world problem (no, your hello world app that only uses stdlib is not one of them), does not follow such pattern. The downside of lacking a de facto web framework in Go? I'm looking at the source code at https://github.com/gogs/gogs and I do not know where to begin to make sense of the application. Every developer ends up making up their own standard, making the barrier of getting open source contributors help higher.
Another account that spams "{repo_name}: {repo_description}" to a bunch of subreddits, created the same day it was pointed out the last time?
[`net.Error`](https://golang.org/pkg/net/#Error) has a `Temporary() bool` method. You could use a similar convention with your errors.
You might want to take a look at how I did isometric rendering of blocks in my `gfx` package: https://github.com/peterhellberg/gfx#blocks (Specifically the spaceToIso and blockCorner functions)
I would update the licence inline with your actual info or delete it for outer licence file
This is one of my favourite features. I found a great use case where I could create dynamic SQL queries and have all the variables together in a slice and then use this :)
Not so sure about the "newtype" stuff (very much relies on knowing the Java keyword or something?). UsesName("harry") UnboxesName("harry") are both valid. type Surname string UnboxesName(Surname("harry")) is not.
How much go experience do you have? We use gitea for some time and when I see started go I was lost too, but now I can appreciate the structure of go projects, even if they aren't following a standard. Each folder is a package and each file is a part of the package containing what it is named, so that at least is the recommendation of efficient go. Beyond that... Yea everything beyond is free for the devs. But I am not aware of any open source project where I were easily jump in, like python projects. My 2cents
How dare you use my love of Arrested Development to farm karma from spam. 
It's probably not worth it, unless you know the speed or memory usage of your service is not where it needs to be and then also that profiling tell you this is a significant source of those issues.
Unfortunately urfave/cli seems to be abandoned. I'd really like to find out how to reboot it though, it's a great library.
[removed]
Newtype is the Haskell terminology 
Looks like a [bunny](https://twitter.com/bunnywithsign?lang=en) to be honest.
Sire, if I may, [https://github.com/muhammadmuzzammil1998/catsay/issues/3](https://github.com/muhammadmuzzammil1998/catsay/issues/3) 😊
you can olso check an api gateway that runs over kubernetes service discovery https://github.com/osstotalsoft/bifrost 
I was thinking of writing this one last week. Thanks
sadly you seem to be right - I have put in two PRs I think valuable with radio silence for the past 2-3 months: https://github.com/urfave/cli/pull/803 https://github.com/urfave/cli/pull/802 :(
which is that terminal? 
It's executed in Ubuntu but that pic is generated by [Carbon](https://carbon.now.sh).
awesome, that is new for me
Cowsay has many selectable characters, and you can write your own. Just FTR, not diminishing anyone's work here.
Yeah I know but I wanted to try and make a simple clone of it in Go 😊
😊
But... but.... this is an [owl](https://previews.123rf.com/images/isselee/isselee1207/isselee120700288/14275270-eurasian-eagle-owl-bubo-bubo-15-years-old-against-white-background.jpg)...
Will be useful for Twitter, thanks
You're still going to need to get off my lawn ;)
🤣🤣🤣
😂😂😂
Wait a minute... are you Matt Holt? like the creator of caddy server? &amp;#x200B; If you are, DUDE! I FOLLOW YOU ON GITHUB! YOU ARE AWESOME! AND YOU JUST MADE MY DAY! 😊😊😊
 ________________ / Already done, \ | just had to | | get back to my | \ computer. / ---------------- (\__/)|| _ (•ㅅ•)|| \/o \っ
Thanks man! Love your projects btw. ``` ____________ &lt; THANK YOU! &gt; ------------ (\__/)|| _ (•ㅅ•)|| \/o \っ ```
Hello /u/surimaque you can check “Go Developer Network” [1][2]. Unfortunately, the communities from Medellín and Bogotá haven’t joined yet, but I know there are people in these corresponding groups who are either thinking about it or already in talks with people from other groups to make the Go Meetups in Colombia more visible. [1] https://blog.golang.org/go-developer-network [2] https://meetup.com/pro/go
Recommend linking to a [detailed walk through](http://mindbowser.com/golang-go-database-sql/) as new devs may forget some things the same way there are [multiple steps that can be missed with http.Client](https://github.com/bradfitz/exp-httpclient/blob/master/problems.md).
!remindme 48 hours
Wake up grateful everyday for not having to deal with the mess that is `strftime` in Go.
Function chaining and panicking are both things to avoid for this sort of behavior. So, if error handling was introduced, this would be really close to something I'd use. I also suggest being able to set a prefix on the environment variables, and overriding the non-prefix portions with struct tags.
I went back and forth on keeping the panics or not. I kept them because I couldn’t see a reason to continue on error. If the config file was not able to be opened, the program shouldn’t continue. Why would one load an optional config file? The other panic is for unhandled types. Self explanatory. In this case, panics make since as they are programmer error, not runtime.
The reason is that I don't want your library to explode my application. I should be able to log and/or whatever and then do as I wish.
Thanks for the feedback! I’ll consider it for v2. In the meantime, you can still defer/recover. I hope you at least give it a shot!
fair enough. I can't delve it complete details but I am able to read the CSV using something like &lt;lines, err := csv.NewReader(f).ReadAll()&gt; Then later, I parse each line and these lines fill in a struct field by field like following. &lt;data := CsvLine{ f1: line\[13\], f2: line\[14\], f3: line\[15\], f4: line\[16\], }&gt; and so on across the range of lines. &amp;#x200B; Now let's say I want to simply create a proto3 type protobuf that includes f1 and f4 (any 2 fields) and further process it. That is where I seem to have the issue.
I've done something similar to this in the past and it's a good solution. You can take this logic a step further by walking a directory tree from a given root and ParseGlob() each directory into it's own map[string]template.Template. Then you can add languages (directories) without modifying code. 
Quite good, but there's a room to grow. When I did "Big Data" processing I came to several ideas, where the most important one was: 1. Avoid any kind of regular allocation whenever possible. Also, practice shows 2. Spawning goroutines regularly is not a good idea in such kind of tasks. I always recommend to replace it with worker pool and its queue. So I did [my version](https://github.com/sirkon/mineislarger) and it is almost 2 times faster than yours on my machine (2.12 vs 4.11). 
As an anecdotal aside, in a number of Go projects (audio processing, encryption, web apis, etc..) I've yet to find a reason to `panic()`. The stdlib very scarce on this construct as well...
For a file that large my instinct is to mmap() it and deal with it as an array of bytes. A naive switch from using bufio.Scanner(os.File) to a bufio.Scanner(bytes.Buffer(syscall.Mmap(os.File()))), is 0.2 seconds faster on my machine than the rev9 code. Since the code calls Scanner.Text() a lot, switching that to Scanner.Bytes() is the next place to gain speed and avoid garbage.
Perhaps you'd be interested in contributing to https://github.com/purpleidea/mgmt/ ? You can call it directly as a lib from golang too, although more focus is placed on using the special DSL. Good luck either way!
[removed]
pika?
Way heavier, and not written in Go. It's a different product all together.
This is almost exactly what we've been moving towards at my work. Panicking is totally appropriate for service misconfiguration, and a struct is simple to inject via wire where needed. Great stuff!
Awesome! If you end up using this, any feedback would be appreciated. 
Awesome! If you end up using this, any feedback would be appreciated.
Very cool. You could try switching from Mongo to Badger or Bolt so you'd have an embedded option. I've used Echo/Viper/Badger before and it makes for a nice stack. 
[removed]
Thanks! I will look into that. That would be very cool. 
Looks nice. Note you have a small typo in config.go Line 176: case reflect.Int16: val, \_ := strconv.ParseInt(s, 10, **26**) The 26 is probably intended to be 16. 
Another thing that you could do is abstract the database code as an interface and implement mongo yourself. That way, someone could just implement Bolt or anything else by themselves and need not have to worry about any changes.
This was the first I've seen Echo in use. I like the simplicity of both that and the Mongo.
Also - https://github.com/caarlos0/env
what is so exited about it - it remind me Apache Druid, however Druid has a huge benefit - it allows several measurements in one query Also, I wondered what us a benefit of using GPU? To my knowledge it works when we need to crunch the number in GPU memory - here we will spend more time looking for data on disk and then bringing to GPU memory... please correct me where I'm wrong
I start using gogs, then I had a bug and found out about gitea, which is fast with fixing thing and renew itself. So I stick to that.
if you even had a sql manager to build, you will never ever read millions of rows. (Hint: pagination) And the same with a log viewer. you will first define a filter, and look at the log lines that are of interest. You never let a human filter the data by looking at it. Humans are way to slow ;-) &amp;#x200B;
beter learn the basics of Go first, before getting in a lazy mood :-) Then try some frameworks, if you really want to walk that path, and do some experimenting with them. Perhaps then, you are wise enough to decide what is good for you. Frameworks : convenience over speed 
Please add this to [https://staticcheck.io/](https://staticcheck.io/)
!remindme 20 days 
Yeah, perhaps channel is just good enough for gophers， but still pretty work, ths
original blog author here; impressive! thanks for sharing it. I saw it running like this: `revision: mineislarger, runtime: 2.142013314s`
[removed]
it is a third time on reddit. Srsly?
Thank you! As far as I understand though packaging bindata requires a third party package, right? Also thank you for the heart beat info, didn't know about that...
thanks for your concern . &lt;3
A lot of 3rd party options for embedding static assets into the binary: https://tech.townsourced.com/post/embedding-static-files-in-go/
probably because they're seeking feedback and hoping it will catch on, but none of their posts so far have generated any interest here. I would think they'd have more success on /r/devops though.
Not a single unit test?
😂😂😂
Oooo!!! on it!
Yeah... I don't know how to make them yet
Rust or GTFO. ;)
\&gt; For example, in a JSON response, I want to omit the user "password" field in all responses and maybe omit the field "balance" if the user is not an admin. For me, I would rather just make a new type which is "safe" for serialisation. In the old fashioned world you'd call it a viewmodel, so in this case \`UserViewModel\` or \`AccountViewModel\`. &amp;#x200B; Just feels simpler to me to convey this sort of thing with types, but that's just my experience.
Are you accepting contributions?
I absolutely do! I am looking forward to learning from others and I'm glad you like my idea!
[removed]
We built one also in GO. We are also working on an Enterprise version. https://encrypt.kadima.io
OK.. that more to work with. &amp;#x200B; I would assume in your code that reads each line, you have some sort of logic that determines what field(s) the line contains, then you fill in the struct. So if the CSV is 4 lines, and your struct is 8 fields.. you somehow figure out if line 1 is one of the 8 fields (or more maybe), and then set the value of the CSV line to the property of the struct, and so forth. In my experience CSVs are usually structured like a DB table.. e.g. each line is a row in a DB, so you just need to know what each column in the CSV matches to what property in the protobuf struct. Then you fill it in, and rinse/repeat. &amp;#x200B;
I've also tried with the syscall lib but since it was deprecated I tested this also. 
ya, So I have already read that table. Let's say f1 and f4 are the fields that I want to codify for protobuf. They are both of string types. How do I go about it? It is indeed part of DB table. 
If I understand what this does correctly, like /u/quiI said, especially if you use an API first design where you specify the request/response payloads using json or yaml, you would typically have different yet very similar types defined. For example, a POST would NOT have an ID property.. that would be generated, so your payload may have name/address/etc, but no ID. But your GET would return the ID property as well as the rest of the POSTed data. A PUT would either use the ID property in the body, or, more likely, would use the /endpoint/&lt;ID&gt; url syntax and exclude the ID field in the payload, thus reusing the POST payload/schema. The PATCH would possibly ALSO reuse the POST because you wouldnt want to allow the ID field to be modified. But, there are some cases where OTHER data is created.. e.g. you POST a /users with a username/password/email (required fields), and it adds a timestamp, created/modified property, and other info that the GET would return. Now the PUT could possibly modify some of those values as well, so the POST and PUT payloads might be different. In these cases, defining them individually, rather than one super structure that may or may not have values is ideal from an API first standpoint. 
Ugh, it uses the Vim8 specific channel based API, so, won't work in NeoVim, or previous Vim versions. Few plugins rely solely on this API.
What is the issue you are having? If you are filling in the protobuf struct with the data from each line, then what do you do? Are you sending the struct via grpc to another service? Are you storing it in the DB? I am not sure what you are asking?
This seems more convoluted than simply implementing MarshalJSON. https://golang.org/pkg/encoding/json/#Marshaler
I use structomap mostly for GET responses. &amp;#x200B; Suppose I have a User struct with this fields: id, email, name, encryptedPassword, surname, address, billingProfile &amp;#x200B; For example, the endpoint /api/v1/users/:userId can return basic infos about a user if the caller has a role user, for example (id, email, name, surname) &amp;#x200B; But if I am an admin, and I call /api/v1/admin/users/:userId endpoint, I would like to see additional informations, like (id, email, name, surname, billingProfile, address and so on) And in both responses I've omitted to return the encryptedPassword field. &amp;#x200B; I like the idea to have different "serializers" basing on endpoint or user role, without change the original model
mmm, don't think so, I tried to use the Marshaler but I was supposed to create 4-5 marshalers for each model, just to avoid to return some fields in the response. But of course this is only my opinion :-)
You are probably not running your program as root.
What's that `:` after the hostname? Try removing it. Another silly question: does the command `mount -t cifs -o rw,domain=.,username=mansas,password=pass,vers=3.0 //192.168.0.1:/shared /mnt/samba` work under the same user yout Go program runs? 
A problem is that the stack of errors is "unstructured" anyway. I cannot know for sure that the depth of an error I might be looking at would not change through a trivial modification of the code to add an extra layer of context information. I don't believe that arbitrarily nested structures resolve that challenge either. That said, the standardization on an Unwrap() interface allows you to traverse down the list of errors and do things like check if each of them provides a "Fields()" interface (with some resolution to use the highest field for any that are duplicated). In the given example, that could allow you to extract something like a zap.String("sourcefile", "foo"), zap.String("destinationfile", "bar"), which I believe was the sort of thing suggested. In some of my code, I am moving to using xerrors.As() to get a user facing error with the fields that we need to decide on a particular return code &amp; error message etc. The new standard doesn't force that, but it provides options for it, which I think is also the case here. Go has no standardization on structured logging, as much as I wish it did, so the criticism that xerrors does not solve that seems to just be part of a larger user experience issue about improving support and standardizing it as an option.
I want to prepare a protobuf for the csv (table that is readin) already. I \*think\* the protobuf .proto file should look like following. message Row { string field1 = 1; string field1 = 2; } message Table { repeated Row rows = 1; } Now issue is, how do I use the read values in the struct (from csv) to form protobuf. 
This is the winning answer for me. I feel like a lot of these issues can be solved by utilizing the type system in a smart way. We utilize this approach quite a bit in-house
https://play.golang.org/p/5yFL4VSapVY Much less runtime interface hopping and reflection necessary.
I agree. I want something that has the least chance of misconfiguration, rather than the easiest. A new type ensures that I'm returning exactly what I want, explicitly, avoiding scenarios where a new internal/private field is added and accidentally exposed publicly.
This looks super nice. Thanks for sharing.
Nice work. I wonder if you could make a `FromFlags()` version too, so you could load/override from file/env/flags too.
This is indicative of some design issue. Somewhere that should not be dropping the index, or should be providing the index in addition to the pointer, is not doing so. You should really fix that instead. This is not a safe road to walk down.
No, to do it efficiently you need pointer arithmetic. The approach you took is absolutely correct. 
This is the sort of thing you should use xerrors.As for - create an interface for that, wrap any errors you want with a structure that supports that method, use xerrors.As to a pointer to a variable of the type of the interface, see if there is something assignable to it in the error list, use as appropriate. This is not something that needs to be applied to an ever growing error type interface.
I felt like this would be the answer. I'm trying to create a generic graph searching algorithm, and one of the tests is a 2D maze solver. Initially the nodes were just coordinates, but passing the coordinates around via interfaces was creating hundreds of thousands of allocations per operation. I figured "hey, I can just pass a pointer to each cell in the maze instead", and then the interfaces won't require any allocations. And it worked. It was almost twice as fast, and it went from allocating almost 7 megabytes of garbage per operation to no allocations at all. But anyway, yeah, I guess the cleaner solution would be to have each cell contain its own coordinates, but that just seems like a waste of memory.
Great! I will fork and help out any way I can. FWIW I am looking for a quick and easy way to set up Vue SPAs with a decent programmable backend using REST and websockets where appropriate (streaming data, mostly). It looks like your project will do a bunch of the grunt work out of the box. &amp;#x200B; Not sure why people are downvoting you. It takes quite a bit of chutzpah to make a nontrivial project, make a nice website for it, and then put yourself at the mercy of fellow gophers in this subreddit. Kudos to you for sticking with it.
And support for the cowsay theme files :)
Side point: you shouldn't store encrypted passwords of your users, you should hash and salt the password.
I don't grok this at all. What did he discover? Who is he posting as?
One thing that I like is the option to automatically generate JSON property names from the field name, with common behavior (camel case, snake case, etc.). I wish there were options in the standard marshaler to do that, instead of having to name every single field. 
My objection to this approach is that it requires a copy in/out mechanism for every type you're serializing. If you're not using code generation, then it's two separate places that you have to make sure you apply each and every model change to. It's a lot easier to make subtle mistakes with this amount of copy and paste involved.
This is awesome! Thank you very much for your kind words :) I truly appreciate your help on unit tests. I've never really had time to make any, nor did I think i needed them. But, since my project has grown bigger and bigger, I'm starting to realize why that wouldn't be such a bad thing... This is probably my first open source project that got this much attention so I'm pretty excited about collaborating :) Also, could you give me your GitHub username please?
OK.. I see what you are saying. I would assume that with a little code like if(admin){set props admins can see} would do the trick, but could also see if structomap supports some dynamic way such that at runtime if you add new use types with control over what properties they can see, then maybe something like this is better as you wont be writing code for unknown roles in this case.
It's worth noting that rather than adding some ugly code to let you choose to use sendfile that users would have to be aware of, Go instead made it so you [transparently get the sendfile behavior](https://github.com/golang/go/blob/412f659280607b06de9b25569cf668ea8f23dd57/src/net/sendfile_unix_alt.go#L22) when your io.Reader is an os.File.
You need a public non-auth method to expand the shortened url, otherwise you've basically just created an abuse vector/gift to bad guys.
Generally it's personal preference / how the team likes to structure their code. If your services are meant to be used together it makes sense to use a single repository - or even a single binary. That may even make development a lot easier. Say you need to make pretty invasive changes in three of your services that all rely on each other - having a single repo where you can work on those changes at once and send them all in with one PR is a lot easier (though that's more of a problem with the various popular git services not handling monotrees well). If your services \_can\_ be used together but it's optional and doesn't impede with each others functionality if they're not used together separate repos may be better. Personally I'm a fan of keeping related libs and executables in one repo, but I don't like the \`one binary\` thing many projects do not one bit - especially if they're client and server in one application, like \`vault\` for example. Yeah, we have mostly big hard drives - but that doesn't mean we need to waste space. 
Not really common practice, no. Remember that microservices don’t solve any technical issues, but instead introduce new ones. They solve management and organizational issues. One of the biggest is merge blocking, whereby you can’t work on a problem without breaking a change that someone else is working on. If you have your own repo for one service you can easily add those changes as long as it doesn’t break backwards compatibility in its API. A single big repo would most likely break that and add strange interdependencies, effectively turning it into a broken up monolith. 
Quite helpful, thank you!
Amen. I want to upvoat this more!
&gt;I'm trying to create a generic graph searching algorithm Yeah... Go's not a great choice for that right now. You'd either want a static type for the coordinates and given up on genericness, or pay the interface price, or find some other way to rekajigger things around. A static type for the coordinates would definitely be the current "Go" answer. If you're just screwing around in Go, I'd say that it's pretty common for this sort of thing to happen in toy problems, but it's still a great language for real problems. If this is the core of some system you are building and performance is paramount, you'd want to do it in a different language.
Yes
/:code does not require any authentication
Do you have a GitHub repo for it?
Lol yeah, never thought about using anything else. This package just seems overengineered.
They solve a lot more problems.
Let me ask my tech team for it. 
First time I used Echo. I like it. At work we use Gorilla Mux and I wanted to see how this compares. Also liking Mongo Driver though I have to look into the code half the time to figure out how to use it.
I broke out the store as an interface and implemented the Mongo store and started stubbing out Badger. Thanks for the feedback. I think it is much cleaner this way.
I think they _kind of_ explain the naming here [1] but I agree it’s not very clear [2]. [1] https://github.com/kubernetes/kops/issues/444 [2] https://github.com/kubernetes/kops/blob/master/docs/development/hack.md
It clearly is an error in the SFTP credentials. Have you tried creating the directory yourself via SFTP to see if it works? Don’t use SSH yet, first confirm if it works via SFTP, and then continue from there. It is also possible that GoLand is not able to create directories recursively.
Can't disagree more on this one. If you have CI built into your repo, it makes sense that your repo only builds one thing. otherwise it makes it difficult to version and release these things independently. If you're not building and releasing them independently, then you don't have microservices.
This seems self contradictory. If you release to things independently, they must be built independently, so there's no reason they shouldn't be separate binaries.
DM'd
You could easily start with a monorepo and use interfaces to keep things separated. You can always break things into smaller services. On the other hand maintaining multiple services is a huge overhead. You'll usually have multiple teams when the benefits of micro services make sense. A monolithic architecture with clean abstractions doesn't have to be a bad thing. Please don't waste your time on cool stuff, just focus on the business value.
I think this might be a controversial opinion but I'd go so far as to say that using a monorepo for microservices is an anti-pattern. To see the organisational and architectural advantages of microservices, they should be independent of one another, communicating only via their published interfaces and responsible for separate sub-domains (in the business modelling sense). If you are using a monorepo to make it simpler to have a great deal of shared code between your services then you're encouraging the exact opposite of this approach. If you feel a monorepo would help then perhaps you need to think again about your service boundaries or consider whether a monolithic approach is more appropriate for you at the moment. 
It's all stemming from kubernetes/kubernetes which keeps all of it's various scripts in a \`hack/\` directory. So lots of Go projects and devs working in the ecosystem follow similar conventions.
I like it. So essentially you might use this for your own site with domain in the URL, and then shorten things behind it. Not entirely sure when this would be useful, but cool setup.
It was a nice exercise for me and demo of Echo/Mongo/Go. I have used a custom url shortener for several projects where they wanted to own the data and not depend / pay for a commercial license of [bit.ly](https://bit.ly). 
&gt; SFTP I tried via SFTP and got Permission denied. But I created my directory via Putty and in Goland I have put the Deployment path to /home/go/src and Root path to /home/go in the configurations (Tools -&gt; Deployment -Configuration&gt; 
I would typically put the logic of the commands into a library module and have the CLI and REST interfaces call that library.
[removed]
I haven't done much with Gorilla, but I keep almost using it. I'm moving a personal project from standard library to gorilla mux tonight or tomorrow due to a refactor where I realized I'll save a ton of time if I just let gorilla handle my varying hostnames, subrouters, and http method checking instead of what I have now. For my data store, I've been pretty happy with Badgerdb. When I wrote Go at work, it was all SQL Server, but a combination of Badger and Bleve (for search, index, etc) has been a pleasure to work with. Badger isn't terribly more featureful than Bolt, but I like the fantastic write performance of Badger.
[removed]
[removed]
You went from passing `interface{}`, to `*node` but skipped over `coordinates` entirely. type coordinates [2]int32 func (c coordinates) X() int32 { return c[0] } func (c coordinates) Y() int32 { return c[1] } Try passing that around instead.
[removed]
This helped to solve the problem: https://stackoverflow.com/a/53827725/9591909
/u/karmiccloud isn't arguing that they should be built into separate binaries but that they should be kept in their own repositories instead of in a single repository. I agree with him. If you're using CI it becomes harder to only build and version particular parts of the repo. For instance if you update repo/service1 but made no changes to repo/service2, it's harder to independently build and version repo/service1. It's not impossible, but harder. Having them in their own repos makes this much easier.
We're just starting on Go-based services coming from a (mostly) Python monolithic system. The question of using a monorepo is pretty orthogonal, I think, and we're currently planning to continue using our monorepo. Our current plan is that each service will have its own go.mod file. A combination of modules and packages will ensure that the code remains separate between services unless there's some really good reason to opt the code into being shared. By having everything in one repo, it's possible to have one commit that upgrades a dependency that multiple services rely on, as one example. We can grep to find all of the code that uses a given service endpoint. We can bisect to get the state of all services as of a given time. I do think there are plusses to multiple repositories, too. (git bisect is faster, for one). I don't personally have strong feelings one way or the other, as long as service boundaries don't become mushy.
Respectfully, I disagree. If you're organising your code to enable it to be heavily shared between the services and therefore tightly coupling them together then it points to issues with your design. No?
In my opinion, you're doing this to filter JSON, not Go maps. General-purpose transformations on Go maps inside a Go app is something that possibly has some use — it's a common thing to do (e.g. rewrite AST expressions) — but without generics it's always going to be painful to do anything type-safe. Code generation is really the only option here. For that reason, applying transformation rules on the JSON representation makes more sense. There are tools for this — `jq`, [JSONPath](https://goessner.net/articles/JsonPath/) (used by Kubernetes), and so on. Think of this as building a new object by declaratively "picking" data from some source data. You may want to look into GraphQL. It solves the problems of querying JSON in a much better way. 
A mono repo with a dozen services and custom libraries that those services depend and might be interdependent on each other on would be super confusing from a tagging/branching/hotfixing perspective. 
It can be convenient when developing to have all of it under one entry point. I had a project where all services where one binary. If os.Args\[0\] matched the service binary's expected name it just to becomes that service and hides all other entry points. When running with go run or the the generic service otherwise or or more services could be selected to run via flags. We still tested and released the services individual go packages/binaries to production though but in reality it was just the same binary compiled at different times. 
Sure, but that configuration is complicated and can be a hassle if you ever need to make project structure changes. Or what if you deprecate one of your microservices but not all of them? It's not that the tooling can't be built to do that, but a lot of it is built and designed with repo=thingy_you_release in mind. It's just easier to separate the repositories at that point.
I agree. Lots of groups use monorepos just because it was a simple solution for solving Go’s early module/dependency issues. It wasn’t at all an artifact of how the system was designed and deployed. It might be intuitive they relate but in practice it doesn’t have to by any means. 
Hear this guy/gal, right now I'm suffering the consequences of having too many microservices
I know it’s a religious issue, but I strongly degree with most of this. &gt; Remember that microservices don’t solve any technical issues, but instead introduce new ones Oh come on. Obviously there are pros and cons but there are obviously some architectural advantages to micro services. &gt; One of the biggest is merge blocking, whereby you can’t work on a problem without breaking a change that someone else is working on. This is a *feature* not a bug. I’m don’t want to preach heavily since every org has different needs, but I would like to push back strongly as someone who works in a mono repo in a SOA. 
A mono repo is a way to organize code. It doesn’t dictate your architecture. Your architecture dictates your architecture. 
It's fairly common for Go projects to use a monorepo design. One reason being that CLIs are very common in Go. It's very easy to build an app that can do many similar things with one binary. One thing I wanted to call out is that you should design your projects around common models. If you have the same few core models and many operations on top of them, a monorepo makes a lot of sense from a code reuse / versioning standpoint. If you find that you have a lot of disperse models, then you will probably run into problems.
&gt; if you ever need to make project structure changes Not necessarily. Since services live in independent subdirectories, they can be moved at will. Shouldn't be many, if any, cross-refs to fix after a move. That being said tools like `sed` and `grep` make the cleanup straightforward. &gt; Or what if you deprecate one of your microservices but not all of them? They're independent. Doesn't matter. &gt; It's not that the tooling can't be built to do that, but a lot of it is built and designed with... Dunno what you're getting at here. The tooling's already built, already supports many deployments from a single repo. The problem was solved long ago. No need for separate repos, hasn't been for some time.
Obviously there is no correct, bulletproof way of doing things. There are only better ways and worse ways. You should do whatever works well for you and for your team and adapt to frustrations or issues that come up during development. As someone who has worked a good amount using microservices but also with monolith projects, I think the ideal solution is somewhere in between. For a recent project I am working on in go I am using “microlibraries”, if you will. Instead of having each service have a separate HTTP API, I am providing a go API that my main app can then import using go modules. So at the end there will be one binary but a number of different modules/repos. If you are going to be using go anyway then it is unnecessary overhead to have to deploy and manage separate services and make separate HTTP calls to talk to each service. It’s negligible in the scheme of things, but it introduces extra complexity. It’s simple to deploy a single binary. Curiously this article was being shared around today and I think it’s somewhat relevant. https://blog.bradfieldcs.com/you-are-not-google-84912cf44afb I realize my approach may be somewhat controversial and there *are* benefits of using microservices too. For example if one service has a panic it won’t cause your entire app to crash (although most http servers would recover from panics anyway), and you can disable or update individual services without having to touch your core codebase, but I am not sure it’s worth it in most cases.
I may be missing something, but services in a monorepo can still be independent of one another and to communicate only through their API. We have a couple of services in the same repo which are develop fully independently. Why is the general thought is that they share code?
That's not a micro-service, that's a monolith neatly divided into 3 areas of distinct domain logic. In fact I just checked the go-kit repo and the first thing it says is "Go kit is a programming toolkit for building microservices **(or elegant monoliths)** in Go." A micro-service would be 3 binaries that each do their own thing. The benefit of micro-services is moving your unique logic into its own app so that code updates require minimal deployments and reduce the scope for bug fixing. However this results in the common micro-service anti-pattern; If your micro-services share a large portion of their code, then every time you change that shared code you have to deploy every micro-service. Suddenly, what would be a quick fix and couple of tests in the monolith is 3 deployments and triple the tests. So to answer your question, no - In my experience - ~~well written~~ elegant monoliths are not common practice.
Typically in a monorepo setting everything is released all at once. You push v1.1, then everything becomes v1.1. It makes it easy to maintain compatibility. Generally I agree with you, but that scenario is harder to achieve when projects are separate repos.
[removed]
Same story here but with a ruby monolith. Already a year or so with services in a monorepo which are developed and deployed independently. It has it pros and cons, but I honestly think I can count more pros... 
[https://github.com/securego/gosec](https://github.com/securego/gosec) is a good tool to do static security analysis. If you need the list maybe you can look at the code
[removed]
About the anti pattern, you don’t have to share code between services, monorepo doesn’t mean monolith. What am I missing?
Oh yeah, the classic ‘let’s move our monolith into a couple of services’ sprint which lasts two years. 
There's a whole package of them in the stdlib called \`unsafe\`. Most of the functions in there can be used to subvert the type system. The cgo can also do all sorts of under-the-hood damage. Then again there are legitimate and important uses of both of these.
Good point. That's also the way we have our project laid out. The cobra cmds are limited to input validation and calling functions in our sdk library. At this point, it seems like I'll need to duplicate the Cobra command flags in a new library we use for REST. :( Maybe I can do something crafty like reflection on the cobra flags for each command. Hoping someone has gone down this path and has silver bullet advice.
*OwO, what's this? * It's your **8th Cakeday** ecnahc515! ^(hug)
Fixed, thank you!
&gt;configuration is complicated Citation needed? &gt;can be a hassle if you ever need to make project structure changes Everything is a hassle if you make project structure changes. Doesn't matter if it's mono repo or multi repo. &gt;Or what if you deprecate one of your microservices but not all of them? I don't see how this is challenging at all. It seems easier in a mono repo to me, if anything.
I’m sure others will have even better solutions, but I would read in 1-2GB chunks and sort them, save them as an efficient file, then clear the memory. Then it’s simply a matter of doing a merge sort on the resultant files to stream to a sorted file. Basically open them all and take the greatest one of the files, consume, and move to the next. 
There isn't really enough information here for people to make intelligent suggestions. &amp;#x200B; What do you mean "data array"? Do you mean the golang structure in virtual memory, or a database, or a pre-existing file? Do you mean sorting each record in itself, or sorting the whole 75GB? Is your virtual memory paged to SSD or to spinning rust (very different locality behaviors there)? &amp;#x200B; To manually handle chunks that fit in RAM you will probably want something like merge sort on a known chunk size, but a lot depends on the details.
See "tape drive merge sort" (not that you should use tapes!) &amp;#x200B; [https://en.wikipedia.org/wiki/Merge\_sort#Use\_with\_tape\_drives](https://en.wikipedia.org/wiki/Merge_sort#Use_with_tape_drives)
I wrote Gnorm ([https://gnorm.org](https://gnorm.org) and [https://github.com/gnormal/gnorm](https://github.com/gnormal/gnorm)) because I was fed up with the state of ORMs in Go. Actually, fed up with ORMs in every static language. They're just a bad fit. Gnorm approaches the problem from the other end. Instead of writing structs that generate your database tables, write database tables that generate your structs. To use Gnorm, create your database schema with the tools that were built specifically for that. Then, once your database looks how you want, run gnorm. Gnorm reads your database schema and by using templates, generates code for that specific schema. You can see an example of templates for generating code to access postgres and the code they generate here: [https://github.com/gnormal/postgres-go](https://github.com/gnormal/postgres-go) The great thing about doing it this way is that it actually leverages the benefits of static typing, rather than having to try to work around them. With most Go ORMs, if you want to do a select, you specify the select in plaintext (hello typos?) and you pass it a variable, without any type checking that the variable is a valid type for that column. With the code I generate in postgres-go (which is basically what we use at Mattel), you can't do that. Selects look like this: `users.Query(ctx, db, users.IDCol.Equals(someUUID))` ... see any strings there? Nope. Any empty interfaces? Nope. users.IDCol is generated for you, with a method called Equals (and others) that only take a UUID parameter, because the `id` column on the `users` table is a UUID. So... yeah, please check out Gnorm. ORMs are bad in statically typed languages (they're not great in dynamic languages either, but they're less bad, I think).
It would seem a package whose functions accept structures which can be populated by either REST endpoints/options or cobra commands/flags would be the way to go. These should be two different binaries, since their are different considerations for a short lived CLI and a long running server. Th In my opinion any “silver bullet” to somehow REST-ify an existing (idiomatic) cobra app is going to add unnecessary abstraction and dependencies to what should be a relatively straightforward task to which Go is well suited. Remember that code is more often read than written- trying to save time with some silver bullet here is just going to be a headache for the next dev to work in the codebase. Two shallow binaries calling logic in a common package without undue magic is the way to go here. 
&gt;This is a *feature* not a bug. Couldn't agree more. It helps to audit and keep larger teams in communication with each other which might not otherwise. It also helps prevents backlogging of changes that need to occur on legacy/deprecated routes, but never actually get finished since everyone is busy working on newer stuff. &amp;#x200B;
This is expected behaviour to me. If the kernel has a more efficient method to copy the file, I would want the API to chose that method. Otherwise my code would be littered with the same test. I am curious what your ideal API would instead look like
That is very terrible advice. But, thanks for sharing. 
I agree with a lot of the foundation set for the arguments in your post, and the ones in the article. I'm just curious though, how are you dealing with scaling if it becomes an issue?
You can use something like a sessionless cookie that stores a JWT with the user id as the sub. Then verify it on the backend whenever it needs to be validated.
ORM requires a very framework oriented development style, which Go is not particularly geared toward lacking both generics and dynamic class loader. It doesn't fit particularly well with Go's focus on simplicity and performance, either. And of course, because Go is fairly young, it is used more with more modern, NoSQL type databases, so traditional ORM isn't so applicable. Personally I avoid ORM like the plague. It tries very hard to abstract away the database and allow development of a database-backed application with a very code-focused mindset, as if the details of the database were trivial. But those abstractions eventually leak, and the database details are most certainly not trivial. An ORM could have value for a throwaway or prototype, but in that case, why not just use something like Mongo and eliminate the ORM entirely? I just don't see ORM having much to offer in today's software world.
When do you feel microservices should be considered? I switched a passion project over from laravel to Go partially because of microservices as i had been hearing about all the benefits. I am now totally in love with Go for other reasons but i feel like microservices sound like a lot of overhead 
I think you need to check the permissions on the directory on the server. It would seem that the user you are connecting as doesn't have write access.
I used this at work but it became bad for cost to benefit when it came to more advanced queries. We used a lot of joins and seldom was it just to get a row from a table. 
Can't disagree more on this one. Ive gone the 1 repo per service route, but ultimately moved back to the monorepo. It was so much easier managing dependencies between services in a monorepo vs multirepo. And it's quite trivial writing a robust deployment pipeline still.
I stick to `database/sql` and `sqlx`. I have `database/sql` code that has been working for years and has never needed to be changed due to a bug. Also, when business changes need to be made, I find it much easier to reason with `database/sql`. Sure, it's boring code but it's easier to maintain.
The old ways are sometimes the best ways. 
I the graph nodes don't necessarily represent points in euclidean space. They might be the configuration of a chess board or a route in the travelling salesman problem. In fact, I've come to realize that using coordinates was a mistake. The graph nodes aren't representing a position in the maze, they're representing a route through the maze. They only happen to be the same thing in A\* because each point in the maze forms a linked list that leads back to the starting point.
It is a lot of overhead. I work with microserviced in a small team and I'd say 50% of my time is spent on infrastructure instead of buisness value
One way to look at it is "is this making enough money for a dedicated ops/devops group/person?"
Not sure why you’re being downvoted. ORMs are the very definition of bloated abstraction. That doesn’t mean they aren’t useful, but they take away control, only to give it back through the use of janky interfaces that force you to design your logic around them.
Reasons you might use a monorepo with microservices: -You have a set of shared common libraries written by your team that the services depend on, and want updating them to be easier. Updating common dependencies across multiple repos can be painful. -You want the configuration for your entire system at a given point in time to be easily traceable,(it’s just the commit sha) -You want to be able to easily change your internal API contracts between services, Reasons you might want to split: -There are 0 common dependencies between services, they don’t talk to each other at all, and need separate deployment pipelines -You want a service to be tested/deployed only when an actual change is made inside the service, and don’t have capacity to invest in a smart deployment pipeline. If you have a monorepo, and only have a single CI/CD pipeline, then it can easily become a bottle neck for your teams as every service is being deployed as every change is brought in. Monorepos are common in large organisations because they can invest in the tooling and infrastructure for their deployment process that solves those issues, and they make it easier to make holistic changes when necessary. 
&gt; ORMs are bad in statically typed languages (they're not great in dynamic languages either, but they're less bad, I think). Agree with the first part, less agree on the second part.
Why do you need code, when it can be done using sort, split, &gt; and | from command line.
Sorry for the missing detail. It’s a string array; it can be byte array if that’s fast? Billions of records each are about 100 bytes. No database. 
Rather than external commands i wanted it to be done within go itself
[removed]
75GB is not much for database have you thought about Judy investing it into some db and let sort done there?
I looked at this approach, but the problem is that read and write operations actually require different data. For example: let's say you have a user table, which has a ton of fields (billing info, session info, personal data) including the user's name. You have a documents table which has more info, like the id, name, owner (user id) and time\_last\_accessed. The document's user interface needs to see who the owner is, but it needs the owner's name because displaying the owner id means nothing to the user. So you either have to run two queries to get the data the UI needs, or you create a read-only view with the right data in it, or some custom SQL from the server to fetch the right data. Fetching the whole user record when its not needed is a complete waste of resources, and could possibly end up being a security flaw if the system uses something like GraphQL that allows the client to determine which fields it needs. But obviously, when updating the time\_last\_accessed field in the document, you don't need the user's name. In fact, all you need is the document ID and the new timestamp. An ORM just isn't going to spot this stuff and allow for it easily.
I think it's the modern lack of SQL knowledge. Not having an ORM means you have to learn SQL, and dude, that shit is \*old\*. Though I do notice it's coming back into fashion ;)
Check out Peter Bourgon's blog posts about X years with Go. He outlines a project structure there that should allow you to define multiple services in a repo. We use that and are happy. If you have a very generic piece of code you can pull it to its own repo as a library.
As a side note, I really recommend looking at Bazel (https://bazel.build) for building stuff in a monorepo, especially if you also use other languages or build Docker images. Bazel makes building/testing all targets extremely fast. Setting up dependencies can be more work, but it's totally worth it. 
I think you're misunderstanding what I'm saying. Of course you would have _some_ code re-use and _some_ common libraries but if you have so much shared code that in a multi repo set up you'd be "having to pay whack a mole" to update common dependencies then it suggests that you've created a situation where you do have tight coupling between services. In the system I work on at the moment we have a small number of shared libraries, used to handle things like logging and reducing server or config boilerplate but we try to prevent creating situations where services need to be running the same version of those libraries to play nicely together and we keep the dependency graph of our shared libraries very flat. We also have a very small set of required behaviours for services, which keeps the cost of introducing a new service stacks very low. The result is that we have services from three teams in two countries written in four languages all ticking along nicely. 
I mean, as a Devops person, consider not using them until you need them. That usually happens when you start dedicating people to smaller subsets of the application, exclusively. So much overhead for so little. I mean, we're talking Heroku vs Kubernetes here.
I've spent a bunch of time with \`database/sql\`, \`sqlx\`, \`gorm\`, and \`pop\`. I think that each has its own use cases/pros, but I generally default back to "Why am I doing all this extra *stuff."* The tool that I found generally most frustrating was Gorm, as I just generally felt like it was a much less intuitive version of Pop. But even with Pop, for the work I was doing I found it mostly easier to just write my own queries anyway. I think sqlx is probably the best intersection of "I want to write my own SQL" with "I don't want to marshal all my fields into structs," which is almost universally what I want.
Seconded. You'll be creating more problems than you solve and spend ost of your time doing DevOps
Microservices only become beneficial when you have multiple teams working on clearly defined parts of the system. They allow for teams to independently develop and deploy but it requires alot of planning for it to work efficiently.
Thank you very much, you have been very helpful!
It was the problem 
Install clickhouse Import your data/csv Do with your data anything you wish in seconds Export into csv ordered by any key 
Hooray!
&gt; https://github.com/gnormal/postgres-go Shame it doesn't support views - would be a simple, appropriate way around the missing join support. 
That's a lot of words for `apt install go`
I whole-heartedly endorse the API first approach - I've been using swagger + go-swagger for generating my request/response 'models' and it's been a very nice experience. The built in formatting/validation of the go-swagger models has saved me lots of boilerplate too ([https://github.com/go-openapi/strfmt](https://github.com/go-openapi/strfmt)) &amp;#x200B;
I'm currently sitting in front of the book "Building Microservices" from Sam Newman so let's ask a real expert. Chapter 1, Key Benefits: \- Technology Heterogeneity \- Resilience \- Scaling \- Ease of Deployment &amp;#x200B; Lets discuss these four topics. Your service is written in go all the way down. Therefore we don't benefit from being able to write part of the service in Go and some other part in Ruby. Resilience could indeed be well supported by a microservice architecture. While your payment service is offline a shipping service might still ship things. Do you really have a problem that lets you divide responsibilities that enable you to have part of the system being resilient about failures in the rest of the system? If that's the case you might want to use microservices. If your render service has a lot more traffic than your heavily cached api service it might be a good thing to have two services and individually scale them. In the paragraph "Ease of Deployment" Sam Newman is talking about millions of lines of code which take a long time to build, test and deploy. Go can build 20k LOC in a second. If you are way above 20k LOC you might want to split things up into smaller services. If you don't I'd question if you really benefit from having multiple services. &amp;#x200B; From my experience: Having microservices means you'll have a API specification of all the services somewhere in a dedicated repository. Let's assume we're using grpc. You'll have your protos in that repo and generate the server and client stubs. Then you'll have to add the generated code into all the other services as a dependency. Whenever a spec updates you'd have to update all the dependent repositories. If you want to deploy breaking changes you'd have to carefully orchestrate the deprecation and update process. Therefore you really want to carefully design your API so that you don't have to make breaking changes that often. Are you really that good at API design and can you anticipate changes of the business in the future? Don't be naive and get yourself trapped in a bad spot. Refactoring a monolith with clean abstractions doesn't have to be a painful event. You can always replace a IUserRepository implemented "locally" with a MicroServiceUserRepository which makes a network call inside. The consumer of the IUserRepository will never know about these details. &amp;#x200B; That being said, I'm really not against microservices at all. I'm against you wasting your and your colleagues time working with tools that someone promoted on Medium and you though these tools were cool. You better focus on things that bring in business value. You should always evaluate if a tool really brings in value. Sounds easy but isn't. It's usually the easy and boring looking things that are the hardest to achieve.
What do you mean by using interfaces to keep things separated? And btw, can't you have monolith node API and have maybe one or two services that does a specific task only?
SQL isn't exactly difficult to learn, and just because it's been around a while is not a reason to -not- learn it. &amp;#x200B; If you use databases, that use SQL as it's query language, I suggest you learn it. &amp;#x200B; If you don't, well, then there's no need.
we are working with grpc micro services. Only one repo and services seperated by dirs. Multiple repos is hard to work. IDEs tree views will be complex and jr. developers will whimpers for that.
Don't talk to concrete implementations but rather interfaces.
Opinionated ops person here. If you mean infrastructure like deployment, cloud resources, etc, you need a more involved ops team — and one that is actively listening and helping you, not merely telling you go to look at docs for some new tool and telling you it will solve your problems. IMO if you have to wait on an ops team to deliver deliver YOUR business value to customers, they’re not doing their jobs. Further, they should be helping you with infrastructure patterns, not individual infrastructure projects. Otherwise you’re going to have to wait on them again and again.
Instead of putting words in my mouth perhaps you might want to use something besides ' I mean' 
&gt;my version I think you should update your blog to reflect his ideas. 
Maybe because he doesn't seem to understand that the tide turned back to relational databases away from NoSql DBs like Mongo and exactly what "modern" is.
Even anonymous struct is possible: https://play.golang.org/p/deB7w4eG3Dp
I've taken a very similar path as you! This is my windy story: I started with raw queries via database/sql &amp; sqlx. I wasn't happy that you had to pass around these custom types (e.g. sql.NullString) to represent nullable fields so I migrated to https://github.com/jackc/pgx, which lets you use pointers (e.g. *string) instead. I launch my application and was quite happy with raw SQL and pgx for awhile. However, I found myself not adding features because I was worried about breaking the raw SQL strings. What I really needed was type safety as my database changed. I was looking around for an ORM to handle this and I stumbled upon https://github.com/xo/xo which took a different approach. Instead of building a general purpose ORM, why not build a custom ORM around your application's database schema? I absolutely loved this idea, but found the existing XO implementation too limited. I wanted to make some different decisions and take it farther. I followed XO's introspection and built my own templates. This served me well for the most part and I'd probably still be doing it this way had I not learned about what https://prisma.io is up to. Prisma is taking this introspection approach to the next level. They generate Go code that looks hand-written but is capable of doing complex SQL queries like JOINs and nested SELECTs. Right now, Prisma requires a standalone server component to proxy the database, but in the next couple months they'll be releasing Prisma 2 which is just going to be a library you can stick on your own server. After learning about this, I actually reached out to the Prisma team to see where I could help. And they said yes! I'm working on all things Go for Prisma 2 right now. This API will change in the coming weeks, but you will be able to do things like this: ```go // get all comments from posts with a title that contains // "Go" written by "Alice Kipper". comments, err := prisma.Authors. FindByFirstNameAndLastName(db, "Alice", "Kipper"). FindPosts(posts.New().TitleContains("Go")). FindComments() ``` If you have any questions or would like to see a demo, please let me know! 
I also use `sqlx` but added some helpers to generate simples queries like insert or update from a map and build a where.
Cool, except they are not the same. The original example returns immediately on error, but the errorWriter keeps the execution chugging along, possibly causing more errors and/or side effects. I do like the general idea of using monads for errors, but sadly it doesn’t in this case. 
Some time ago I remember reading a tutorial that stated something like "Once you understand the pattern of monads you will start to see them everywhere". That was years ago and I still don't think I know what a monad "is". Today, if I see a pattern that can be encapsulated as a monad (usually some sequence of computations that track or perform some side effect like aborting on error) and the usage of the pattern doesn't violate the monad laws then its a monad. That is the best my poor brain can do.
I felt like the whole point of the post was "Nothing is cool about it. It'd be nicer if language actually supported the things we want to use" &amp;#x200B; I get very excited when I see a made up generics syntax and very disappointed once I realize it is made up (
Good point, they're excellent for ad-hoc serialisation
What were your motivations?
Sorry to bother you further, I'm a new gopher. Can you demonstrate your point? "Talk to interfaces" = write abstractions for business logic? 
You can use anonymous struct: https://play.golang.org/p/deB7w4eG3Dp 
Afaik, you still need to vendor it, although there is a “cache”.
(Sentinel) errors declared as variables and not const can lead to cross package variable abuse.
Good job
Vendoring is always a good idea especially if you have CI. 
It's either make a custom container type when sometimes needing to minimize error handling, or pattern match when often needing to describe behavior at the site of returned errors. I picked my poison years ago. I still like FP for certain use cases, though.
I truly believe that's the best way to think about it anyway. And I say that as someone who has [invested a lot of effort](https://blog.merovius.de/2018/01/08/monads-are-just-monoids.html) into understanding the "what actually *is* a Monad" part :)
You can try sqlite with go. Then a simple select should do it.
Wrong Reddit 
You could use a thin wrapper of platform specific generated code with zero (maybe?) runtime overhead.
Unfortunately, your post doesn't provide any information that could help the community to help you. Can you share more specifics about your system, your setup, your means, and *most importantly* what have *you* tried so far?
In general I think the standard library might be more pleasant to use if more functions and interface method specs took the form `func something(err *error)` instead of `func something() error` and started with an error guard that immediately returned `if *err != nil` and assigned `*err` if they themselves caused an error. There are often cases where I have rather long sequences of error producing calls that all need to be handled using the same strategy anyway. Rob solved this with some simple wrapping (which could easily implement the Writer interface), and I guess betting on the function you call to respect the idiom and immediately return if err is pointing at an error isn't optimal.
I think there is a whole chapter in TAoCP so just look it up in the shelf behind you.
Yeah, I need to fix joins. As someone else said, view support would probably be easy to add. Also I think there is a way to construct a join on the fly the way I do with queries, I just haven't put the time in yet to do it. Seems like a good next thing to work on. 
I'll add view support, that's a good point. I think it shouldn't be hard at all. 
Do you have hundreds of people working on your project? Do you have a large, dedicated ops team that can setup and maintain the infrastructure required to be nimble in a microservices environment? Are you able to build a well-designed monolithic application, with strict and proper seperation of concerns, including not sharing the same database, whose design still accounts for race conditions, data inconsistencies, and the general increase in the number of states your system can be in that arise from working outside of ACID compliant transactions? If you answered yes to ALL of these questions, microservices MIGHT be a good decision.
Is that true? I love writing SQL queries...
&gt; And in languages with better support for monads we can more easily express computations using them. This is what the same piece of code looks like in Haskell: &gt; &gt; do write fd p0 write fd p1 write fd p2 &gt; Yes, this code performs the exact same error handling as our examples above. [..] That's exactly why you'll never see it in Go. A lack of magic isn't a shortcoming of Go, it's its value proposition. 
Bullshit.
I'd certainly be interesting in hearing how you did this. Is there a public repo, or would you mind giving a little more insight?
That's exactly what I'm talking about though - people using ORM as an excuse not to understand the database. The ORM does its best but it will not outperform schema and queries written by someone who cares and understands what they're doing. Even if you do use an ORM, you need to learn SQL, you need to learn database architecture, you need to know all the things ORM is trying to do for you because it won't always do it the best way. Without tuning you'll sacrifice performance and waste database resources - ask a DBA, they see it plenty and most hate ORMs for exactly that reason. I don't understand why a back-end or full-stack developer wouldn't learn SQL if they're using a RDBMS. It's not that complicated. It's only slightly more complicated than the average ORM. And it's critical knowledge to the task. Instead of learning the mediocre abstraction just learn the actual thing.
That’s not what i want. It will be slow with that. 
How do they handle with large data with little memory?
I understand that it's often an inferior option, which is why I mostly suggest it for prototypes and throwaways. I'm saying that a language like Go that's been around less than a decade is going to see more NoSQL use vs RDMS use than a language that predates the NoSQL craze.
I’d like to do it without db since i want to learn best approach algorithm-wise. 
Hi, I've implemented the changes, currently in a v2 branch. Would you mind having a look at it to see if it's done decently? Would be a great help :) [https://github.com/leononame/logger/tree/v2](https://github.com/leononame/logger/tree/v2)
His original writes an item, checks for an error, returns if error, else writes next item, returns if error, etc. His replacement creates a place to save an error, writes an item if no saved error, saves any error, writes an item if no saved error, saves any error, etc. Since they both just call (write, error) repeatedly, they have the same effect, but with different syntax, no? Sure, if the ... was anything other than repeated calls to the same function and repetitious error handling, it could cause an issue, but presumably you'd want to check for saved errors before branching or calling anything with side effects. *rereading your comment before posting, it's obvious you're perfectly aware of how haskell's monads operate, but I've never been one to start into a good rant and then let it go to waste. you can happily stop reading here, unless you'd like to poke holes in my simplification, at which point, do carry on* In haskell, the bind operator `&gt;&gt;=` is overloaded by the return type of the functions being bound together. When specialized to a function returning the `Either` class, which return `Left value` or `Right value`, it will call the next function if it has a `Right value`, but won't if it has a `Left value`, instead just returning the value without calling on. [This is the implementation for either's bind instance:](http://hackage.haskell.org/package/base-)4.12.0.0/docs/src/Data.Either.html#line-155 instance Monad (Either e) where Left l &gt;&gt;= _ = Left l Right r &gt;&gt;= k = k r 
Or is it: monads reinvented sequential state?
It's like if you made up the word "concatenatable". Hey, strings are concatenatable but if you squint a lot of other things are too! In fact, we can describe mathematically what it takes for something to be concatenatable… Which, okay, great. But having a word for the concept of concatenatable or monad or whatever doesn't really help you in any practical way by itself. Haskell just so happens to be written with lazy evaluation at its core, so you _need_ to have a generic concept of monads because otherwise there would be no way to deal with stateful functions, but it doesn't really have an application for other languages unless you go out of your way to make it apply. Rust and Swift both successfully stole Haskell's good features without requiring anyone to understand that the Option/Maybe type is a "monad" because they aren't lazily evaluated, so you only need to use Options where it makes sense, and not pervasively. Anyway, I think Haskell is over now. It was good for the industry because it spread the idea of Option/Maybe types, but the syntax and import systems are hot flaming garbage, and laziness/immutability are hell for understanding performance, so it's not actually a good choice for serious production programming by itself.
Running a separate process to support an ORM-ish thing sounds like a huge step in the wrong direction. But glad it sounds like they're making a library version. Is it open source? I don't see any repo links on their website.
The Go authors are planning to make a package registry to prevent the disappearing packaging problem, but as of today, modules only solve the problem that if a package disappears you can be sure that when someone says "I have a backup" the backup is correct because it has the same hash as before it disappeared. You can try the [Project Athens](https://github.com/gomods/athens) beta if you don't want to wait for an "official" solution to the disappearing package problem, or just use `go mod vendor` and check in the sub-repos.
There are several "YeSQL"-style non-ORM SQL managers: - https://github.com/smotes/purse - https://github.com/gchaincl/dotsql - https://github.com/nleof/goyesql I'd love to hear reflections from anyone who has used them. ISTM that a YeSQL-clone+SQLX is the way to Go, but I don't have experience with it.
[removed]
If I change it so that it uses a map of strings, which is what the author of that library does in their tests `var responseData map[string]interface{}` `err :=` [`client.Run`](https://client.Run)`(ctx, req, &amp;responseData)` And you then output responseData, I definitely can see what comes back: `map[jurisdiction:map[id:ocd-jurisdiction/country:us/state:id/government]]` See also [https://github.com/machinebox/graphql/issues/26](https://github.com/machinebox/graphql/issues/26) Basically the response it gets back just isn't mapping into your structs, not that you aren't getting anything back. &amp;#x200B; &amp;#x200B;
That definitely solved my problem. Thank you!
I wish we had a dev ops team :). Our dev ops guys is fresh out of school and learning as he goes. He's doing great but of course, but learning by seeing what works takes time! By infrastructure, I do mean the dev ops side, but a lot of it is also code that doesn't produce any buisness value. 
I like making things elegant and abstract, but I do think there's a lot of merit in being naive and flat-footed as well. As the author of code, I don't feel very clever when I have to write \`if err != nil\` 3 times in a function body, but I think it probably makes it quite a lot easier for the reader. There is a tension between mathematical simplicity and good engineering practice, and Go aims for the latter. Of course, you could argue that you could remove the rails that prevent gratuitous abstraction and then programmers could choose to repeat \`if err != nil\` when appropriate, but I absolutely distrust programmers in general (and often even myself in particular) to reliably make the right decision. "Where to put the rails?" is not an easy question to answer, but my experience with Go suggests that the current configuration isn't bad compared to other languages.
&gt;Haskell just so happens to be written with lazy evaluation at its core, so you &gt; &gt;need &gt; &gt; to have a generic concept of monads because otherwise there would be no way to deal with stateful functions &amp;#x200B; Small correction: I think "functional purity", not "lazy evaluation", is the property that drives Haskell to depend on monads.
I think you misunderstood the code. The errorWriter doesn't execute any more than the original.
You can handle authentication for static resources the same way you handle it for the rest of your application. Just use the authentication middleware you're already using to wrap the call to `http.FileServer`or `http.ServeFile` when you set up the route(s).
cf. [goup](https://github.com/lpar/goup).
We're using [dbr](https://github.com/gocraft/dbr). It's not exactly ORM, definitely not a dynamic one, but it's kind of nice to work with, allowing for easy drop down to raw sql where needed.
What log library, which log format json, plain ... , do you see other logs in elastic. Are you sure elastic is not showing them? Maybe your dashboards are not working...
Hi, There are already really good suggestions in the thread. &amp;#x200B; Here´s a couple of slightly different suggestions which may or may not fly: &amp;#x200B; **Radix sort if you have a large drive** Let´s assume you know the range of the keys and each is unique and you have range x 100 bytes of hard drive space, then you can read each record and write it out in the correct position, and then it´s sorted. &amp;#x200B; **Breaking the rules by using go to call an external Linux command to get an optimized version of merge sort:** [http://kmkeen.com/gz-sort/](http://kmkeen.com/gz-sort/) (needs 4GB ram) (Others in this thread has mentioned merge sort, which is a good idea) &amp;#x200B; **Breaking the rules of your questions using the power of the cloud (you only need to rent one for a few minutes I think):** &amp;#x200B; **With a 32 GB machine instance:** If you have memory for the index and key (let´s say your index is 32 bits and key 32 bits you could probably use just 12 Gb of RAM + some for processing. Then you could seek wich on an SSD is quite fast and write copy records in the correct order. &amp;#x200B; **If you have a get a large memory instance** 1. read 2. sort 3. save &amp;#x200B; &amp;#x200B; &amp;#x200B;
[removed]
[removed]
I updated the repo with a Mongo and Badger store. I also fixed the makefile to build both environments.
Monads? That's the least of it! The scoundrel also reinvented the for loop, functions, if statements, executable files, reading from disk and networking. There are whole reimplementations of http in there! Listening on sockets? ripped off wholesale! Goroutines? cribbed homework from CSP!
Just a few suggestions. The functions provided by the package have a bit cumbersome names: `masker.Mask` doesn't really tell me much, other than having the same name twice. Maybe make it more general to mask anything that fits a property name, and then provide a shorthand for passwords. Maybe like `masker.Password(pswd)`. Then maybe `mask` would be a better package name too: `mask.PasswordWith(prop, "#*!?")` and `mask.Token(prop)` could be some shorthands for instance.
! Remindhim 24 hours
Yes, IP whitelisting is usually one of the things that you can do. You can also add DNS Response Rate Limiting, or iptables rules if you prefer. Take a look at these articles [1][2][3] you may find additional ideas. [1] https://www.us-cert.gov/ncas/alerts/TA13-088A [2] https://www.cloudflare.com/learning/ddos/dns-amplification-ddos-attack/ [3] https://www.fortinet.com/blog/threat-research/10-simple-ways-to-mitigate-dns-based-ddos-attacks.html
Monad is an interface, not a "thing". It so happens that "a normal imperative function that has local values that can be repeatedly rewritten to" can be represented by the monad interface, but it's not what they "do" in exactly the same way that "io.Reader" does not "write a set of bytes to a network socket". Yes, io.Reader can be wrapped around that functionality, but it isn't what io.Reader \_does\_.
thanks, brother sir
&gt; Which, okay, great. But having a word for the concept of concatenatable or monad or whatever doesn't really help you in any practical way by itself. Excuse me? Scala is impure, but monads are *very* useful in Scala too.
I personally like the way error handling is done in Go. It prompts me to think after every operation, if this goes wrong, how do I want to handle it? 
Absolutely right. It just an accident that lazy evalutation by making evaluation order unpredictable kind of forced the Haskell folks to *not* end up relying on a side-effecting crutch (like a moral equivalent of unsafePerformIO), so they were forced into inventing Monad which 'abuses' data-dependencies to force an imperative-like evalutation order (in IO, at least).
Is the map not magic, then?
&gt; Haskell just so happens to be written with lazy evaluation at its core, so you need to have a generic concept of monads because otherwise there would be no way to deal with stateful functions That really isn't true. Haskell was created *before* monads were proposed in the context of FP. They were adopted fairly quickly after they were proposed because they're a better interface than the alternatives. &gt; Rust and Swift both successfully stole Haskell's good features without requiring anyone to understand that the Option/Maybe type is a "monad" because they aren't lazily evaluated, so you only need to use Options where it makes sense, and not pervasively. Rust, much like Scala, doesn't have the `Monad` type in the standard library. However, Rust's Option is still a monad, because it has `and_then` (which is just `&gt;&gt;=`) and `Some(x)`. It's just that the documentation doesn't call any special attention to the monadic nature of the type, because the language doesn't (and can't) represent Monad as an explicit abstraction. It's just that when you're learning Rust, you'll eventually say "I guess I need to use this `and_then` function", whereas in Haskell, people point you to `&gt;&gt;=` and say "here's how to use it for Maybe, IO, State, Reader, and a bunch of other stuff". And you use Option in Rust and Maybe in Haskell to about the same level of pervasiveness.
[removed]
I like the way that Swift handles this with optionals and optional chaining. 
The linux sort command does efficient sorting. Also allows merging pre-sorted files easily. Use that!
It doesn't, not even in IO. Monad IO was chosen specifically because you can get around the imperative evaluation order, and build all kinds of parallel and concurrent systems. Before Monad IO, Haskell's `main` had type `[String]-&gt;[String]`, which achieved what you're describing with stdin and stdout. 
I'm intrigued by the construction of your API (currently learning to build web apps in Go) but I'm truly confused as to what Backlpulse actually is/does. Any chance that you can add a list of features, and perhaps explain a use case?
&gt; However, Rust's Option is still a monad Yes, but that's trivial because the monadic laws are pervasive. Go still has "concatenable" types because to be concatenable you just need to fulfill the laws of concatenation. But it's not a concept that the language explicitly calls out or represents, it's just a concept that I coined to make an example. &gt; It's just that the documentation doesn't call any special attention to the monadic nature of the type, because the language doesn't (and can't) represent Monad as an explicit abstraction. Exactly! 
&gt; The errorWriter doesn't execute any more than the original. That's true in the golden-path with zero errors. However, say there's an error in the first write. The original: 1. calls write 2. tests a branch 3. returns Whereas the errWriter version: 1. calls write 2. tests a branch 3. assigns a value 4. calls write 5. tests a branch 6. returns 7. calls write 8. tests a branch 9. returns 10. tests a branch 11. returns Granted, as long as write is returning immediately &amp; creating no side-effects, and as long as we're talking about a reasonably small number of write attempts, they'll probably be equivalent. In some programs, the early out of an actual return yields performance benefits.
Hello, let me start by saying that I'm also new and I'm more or less just lurking this sub for great minds and know-how, in general, I had the same issue until I started following proposed [Go project structure](https://github.com/golang-standards/project-layout). 
[removed]
[removed]
try to use absolute path for all non standard library packages
`errWriter` doesn't do early exit, but the Either monad is the same as the original.
Not more useful code, but an error check is done at every call and you could interleave more code. 
Backpulse is a Headless CMS, which means it can store your content like contact informations (email, name, address...), videos, photos, blog articles, or files... Though it can't display it with html but only in json (with the api). So you have to build your own front-end (with React / Vue.js / Angular, or even plain HTML). I think this is great if you want to build your own website with your own design without having to rebuild all the interface that's behind (database, secure authentication, file storing, etc.). Let's say you want to build a blog: you create a Backpulse site called "myblog". You write your articles with Backpulse's interface and on your front-end you retrieve them with the API (or with [backpulse/wrapper](https://github.com/backpulse/wrapper)) and display them with html. I already built some modules/extensions that can be added to sites: \- Articles (for blogging) \- Galleries (for photography) \- Projects (for portfolio) \- Music (for songs/podcasts) \- Videos (for youtubers?) You also have a storage space for each of your sites to store binary/text/images files. (500 Mb per site, but I might increase it), and you can collaborate with people on the same site. The documentation for the public API can be found [here](https://docs.backpulse.io/) though it really isn't finished because I've added a lot of modules since. So I recommend using the wrapper which is more up-to-date. I hope it's a bit clearer :)
I have been asked to knock up a few web apps, with a quick turnaround. I get what might be best practice for a good, solid foundation, but I need the scaffolding done already if I am to fulfil what is asked of me.
What is the content of your go.mod file? As already mentioned you should import using the fully qualified path. The go.mod file should tell you the root of the project.
go monads? &amp;#x200B; gonads!?!?
Fair enough. If you need any help, just ask!
the f# blog post on [railway oriented programming](https://fsharpforfunandprofit.com/posts/recipe-part2/) is a nice way to think about this particular case
Thank you!
You need the fully qualified path. Don’t use a `src` dir for your code, this is an anti-pattern. Also when importing a package you can only use public functions: so `routes.auth()` needs to be `routes.Auth()`
True, I should have been more clear that I was responding to the "more errors and/or side effects" bit. It definitely will include more function calls, though I probably wouldn't worry about that until it was shown to be causing performance problems.
&gt;&gt; However, Rust's Option is still a monad &gt; Yes, but that's trivial because the monadic laws are pervasive. It's really not. `and_then` is literally `&gt;&gt;=` by a different name, just like how in Scala `.flatMap` is `&gt;&gt;=` by a different name. Contrast that to Promises in Javascript. Promises have `.then`, which is what you get if you put `map`, `&gt;&gt;=`, and Scala.concurrent.Future's `recoverWith` and `recover` in a blender. Promise could fairly trivially be monadic, but as implemented it isn't quite monadic. 
Are you trying to mitigate on the sending or receiving end of the attack?
Receiving 
You could set the truncation bit on the response and block/rate limit any IP's that don't upgrade to TCP.
Awesome I love it! Our binaries have been growing in size and I haven't put in the time to check it out. This saves me time thank you!
The ‘src/routes/auth.Go’ is a member of the package route (the file start by ‘package routes’ ?) If your IDE remove the import line it’s because he can’t resolve the dependency 
When you are in a module context you need to prepend the module path to your imports: `module/path/src/routes`. And you package is not internal, only packages that contain literally `internal` anywhere in their path are internal.
Any idea what would be needed to make this work with something like docker/moby (or anything that has a more complex build process). From the readme it looks like this needs to compile the binary. Can I point it to one I compiled myself?
agree totally. I've been telling Rails devs they need to learn some SQL for years ;)
first time I've heard of YesSQL. Does it parse the SQL? If so, does it grok the more complex constructions like recursive queries? What's the advantage of doing this rather than compiling all the queries into functions/sprocs on the RDMS and calling them there? &amp;#x200B;
That's all your brain needs to do! You understand it. A monad is an interface involving some type signatures and laws. If you want to feel like you "get" them more, the only thing to do is write some Haskell and work with them to solve real problems. Then you'll see opportunity to abstract over monads, writing code that is generic in the type of Monad you're working with.
I agree it's ugly but that append isn't removing anything, it just happens to use append() to concatenate the head/tail together again to form a single slice.
It’s because it’s not actually removing it from the slice. A slice is much like a C array, just a sequence of values. You can’t just say “I want item X gone”. Instead, you have to shuffle up everything at X+1 by one index. Hence append is taking the array from 0-X, and appending x+1 thru the end to the original. It would be nice if there was a convenience method for that, but for some reason, the go developers decided to include only the bare minimum ways of working with slices. 
I'm waiting for 1.13 when module mode will be the default for all development!
`v` and `v1` are [two separated objects](https://godbolt.org/z/s8nkN4) (assembly line 32 and line 43).
Thank you, this is exactly what I have been looking for a couple of weeks ago.
Could use Kafka for that. 
This thread is filled with gold knowledge and advices! 
&gt; if this goes wrong, how do I want to handle it? What is your usual answer?
I'm glad Go team is working on user requested features. Good job. 
hopefully they will not be deliberately breaking vendor support by then. Then again the mvs crap really should be a breaking change.
https://github.com/gocraft/work
It really depends on what I'm doing. Many times it's just writing a log entry and not proceeding. Many times it's writing a log entry and proceeding. Many times it's exponential backoff. Many times it's some other course of action. It really depends. &amp;#x200B; The point is that when I'm working with Go, I'm essentially prompted to think how I should handle something going wrong whereas in some other languages, I must remember to handle things when they go wrong. 
A slice is \*not\* like a C array. Go arrays are like C arrays, but slices and arrays are very different in Go. A C array refers directly to locations in memory, and there are all sorts of tricks you can do with index arithmetic because of it. A Go array similarly refers to locations in memory, but the array is immutable -a \[1\]int is a different type from a \[2\]int, and both are different from a \[\]int, which is a slice. Slices are effectively sets of pointers to elements of an array. Every slice has an underlying array, and multiple slices can point to the same array. Slices look like C arrays, but you can get really badly caught out if you don't grok the differences.
You’ve only made a very academic, and very useless distinction. In practice, you can treat an slice as an array because that’s what they are. An array is static length but a slice can be dynamic, but that doesn’t change anything, since a C array is dynamic length as well. 
If order is not important, copy the last element into the location that you want to remove, then remove the last element 1 2 3 4 // remove 2 1 4 3 4 // slice = slice[:len(slice)-1] 1 4 3
Oh this looks like it'll fit!
If you use a slice like a Java List (that is to say ordered) then the solution I found will deliver the result you expect; but yours is an interesting alternative which might be appropriate in some circumstances.
I would say one of the first one was to integrate it into my dotfiles configuration here: https://github.com/cabaalexander/dotfiles/blob/master/config/install/go.sh And I as a new commer to golang I tried to install,`go` on archlinux and it installed not all the go sdk, I found a installer and read the documentation and decide to make my own no prompt automatic installer. (If there is another better way I'm open to suggestions) 😀 And if someone is at my position there you have an installer. 😅
I actually completely agree with this. I avoid using OO-style code when programming in C++, and tend to use namespaces instead of classes. I sort of see it as C with an insanely rich STL (which is one of the things it is).
I think the reason that this is not a builtin is because it makes decisions in regards to memory allocations and the sematics of your data structure that may or may not be acceptable to the user. The [Slice Tricks wiki page](https://github.com/golang/go/wiki/SliceTricks) has a nice run down of the differences of the different approaches to this problem. For example, the implementation you provided creates a new array that backs the new slice, whereas the following mutates the backing array (which has a different set of implications for your application): ``` a = a[:i+copy(a[i:], a[i+1:])] ``` When choosing a method you need to consider memory allocations, mutability and undesired object references... or wait until it becomes a problem and then fix it, like everybody else!
Thanks a lot! I've decided to finish the program \*and then\* rewrite it in Go, just as an exercise. Maybe I'll do it in Rust too, who knows. I feel like I need to expand my knowledge of programming languages anyway, might as well learn some great procedural ones.
😮 On my Google search I did not see it :'/
https://golang.org/doc/devel/release.html#go1.12.minor Actual link that doesn't make you login to Google.
I use jwt token for user to log in and use this web app. Users will upload their files which I don't want anyone but themselves to access those static files (images, pdf , etc ). &amp;#x200B; all those static files will uploaded to a folder in the same place where the go http server code are at. &amp;#x200B; like all those images can be accessed at : localhost:4200/temp-images/upload123.png. this upload123.png might only belong to user A. But if I still use jwt token, user B who logged in this web app, can type this link in browser to access this image. And I don't want these files pdf and images got stolen by whoever logged in this web app, How can I add access control for static resources in this case ?
Partially. There's no support for the offset argument, which would have been wonderful to have as part of io.ReaderAt. Instead if you need efficient ranged reads from a file to a tcp connection you need to either patch the go runtime or use dubious combinations of unsafe.pointer and go:linkname. Otherwise, your file descriptor doesn't get recognized by the runtime polling.
How does this compare to ponzu [github](https://github.com/ponzu-cms/ponzu)?
I said it might be a controversial view but you've clearly chosen to take it personally and get all hot under the collar. Perhaps for the sake of civility it's better that we just agree to disagree rather than resorting to insults, hmm?
SQS already has durability built in. Unacked messages resurface after the configured timeout. I used the aws sdk to read from the queue and process jobs. If the job can't complete due to a temporary failure it will reappear later. No need for a framework to manage this. 
What are the reasons that they have a 1.12 and a 1.11 release?
https://golang.org/doc/devel/release.html#policy
The bit about slices being references to arrays is not useless. IME without understanding that you will treat slices like they are arrays and write subtly buggy code.
You say that but I don’t see how you could. You use the same exactly code between the two and the compiler will often swap out an array with a slice anyways especially if you’re passing the slice/array around. 
There are still some hurdles: [https://github.com/golang/go/issues/30831](https://github.com/golang/go/issues/30831)
I'm sorry, where does the compiler does it swap out an array with a slice? I certainly hope it does nothing of the sort. Arrays are passed by value. Every element is copied. Slices are also passed by value, but the value is a 3-element struct { pointer, len, cap }. The elements of the slice are not copied. Forget this and eventually, down a chain of slices (and append()s) you'll wind up writing to a slice's element and changing other slices which you didn't intend to change. For example, stdlib bytes.Split used to (until go 1.N, N pretty recent) return slices of the input slice with capacities set to the full input slice's capacity. If you passed these returned slices around your code and somewhere far away did append() to one of them you'd get a surprise when the subsequent returned slices' contents changed too. Sometimes. Of the append wasn't sufficiently large to exceed the capacity. No array would behave like that.
Yes that’s very true, as append efficiently doesn’t make a full copy. But that doesn’t change what I said in the original comment. You still treat it the same way you treat a C array in that you cannot remove individual objects like you see in other languages. It’s still just a sequence. 
Not that I care that much, but didn't reddit's dupe link detection alert you when posting this? &amp;#x200B; [https://www.reddit.com/r/golang/comments/b8jaeu/goweight\_a\_tool\_to\_analyze\_and\_troubleshoot\_a\_go/](https://www.reddit.com/r/golang/comments/b8jaeu/goweight_a_tool_to_analyze_and_troubleshoot_a_go/)
Thanks for the write up. 
For the curious that do not have time to read the article, you can jump to [https://blog.owulveryck.info/2019/04/03/from-a-project-to-a-product-the-state-of-onnx-go.html#one-more-thing](https://blog.owulveryck.info/2019/04/03/from-a-project-to-a-product-the-state-of-onnx-go.html#one-more-thing) 
Couple comments, don’t want these to come negative, I appreciate the share. Don’t really know if you want feedback or just want people to be able to use, but here are my comments either way. - If you share without a license, it’s unusable to me. You have copyright since you wrote it, and no license so my builds processes will reject including this on license scan. - The fanout is a blocking channel write, suggest wrapping the loop that fans out in a goroutine with a timeout or something so if the consumer can’t keep up, you aren’t blocked. Also, this blocking channel will block the select statement since it is in the case execution, when this hits, if the channel read doesn’t happen you are deadlocked. - Strongly suggest adding benchmark tests for this where it times message in to messages out. A producer will always be able to write faster than the fan out. So the latency introduced by the fan out process should be documented, run and optimized if needed. - Almost everything I do in this space requires a message protocol so I can handle errors or message states, etc. I don’t know your cases, but the broker typically has to manage what happens if I can’t deliver or if the receiver is gone. Many times we have a second channel from client back to fanout service for message ack/error. This may be overkill for what you are using this for, but - Last bit, since you are passing in the channel to register a client, the owner of that is the client. If the client closes the channel, the whole thing will crap the bed because you will be trying to write to closed channel. Suggest making the add channel without an argument and return a channel that the client listens to. Then you manage the channels and you won’t break clients by closing channels since they can still read from closed chan without issue. This will make your shutdown process a bit more cumbersome but IMHO it will be a more robust pattern. Sorry for typos and cursory review, I’m on my phone so that suck.
My builds, I will build in docker and then push the docker image from the build to my registry. This way I have the dockerfile with the vendor artifacts or in the case of go mod I have the cache. Our other use case for vendor is getting around proxy/firewall issue for the various environments. In these cases we will build vendor and actually check them in with the code.
There is a diff between authention and authorization. JWT authenticates, but then your authorization service serves as the gatekeeper to determine who has access to what resources. A simple was may be to use directory structure that includes the user API/temp-images can point to a different directory based on the user. So I’m file system have /temp/images/common/all-access.png /temp/images/usera/usera-access.png /temp/images/userb/userb-access.png So then a user accessing the api can get at their stuff and the common stuff but not the other users stuff. This is super crude and rudimentary, just an explanation. If you actually care about authorization, manage it with a middleware service that can handle more complex cases. 
we do this too, currently it works, but you can get things confused easily.
Good job.
Because it's not the right data structure to use, and there is more than one way to remove an item from a list depending on what properties you want to preserve. The way you demonstrate is also the least efficient. 
tl;dr: &gt; Pointers to distinct zero-size variables may or may not be equal
I really enjoyed reading this write-up mostly because of the author's writing style. No bloated paragraphs, rambling introductions, etc. Very meaty content digestible in concise sentences.
Interesting read. Especially like the approach of chain handling. One time I had to do something similar I opted for wrappers instead (get interface, return interface), which are much less intuitive to use. One thing I'm wondering about, why not use string pointers? Wouldn't that match Java closer?
Nice :-) Here you are : https://twitter.com/golangch/status/1114442472770420736 
It would match Java better but it's more akward to operate on string pointers.
thanks
I wonder, why he hasn't even looked at the builtin coverage functionality in Go. Even if it wouldn't be adequate, it would be helpful to know why.
I’d say: great feedback! Especially from the phone.
That's a large root dir.
This is great. I'm currently using a "selfmade" solution to keep objects in the pool. Will there be an option to set maximum pool size in sync.Pool?
How was the performance? Did you benchmark it?
When I started Backpulse I didn't know API Based / Headless CMS where even a thing so I didn't try to make something better than what already existed. I've never used Ponzu, have you?
I do use builtin coverage. It's just it's nice to be able to track code coverage over time, which is what codecov.io provides. The way it works is that on every checkin the CI job runs all the tests with code coverage enabled and uploads the results to codecov. Codecov can then plot coverage over time. My gripe is with inaccurate accounting of empty lines (like comments or struct definitions) by codecov. Go's tool to visualize this count them properly. I don't know if it's codecov or maybe I'm not sending the data properly.
There's a lot going on here so let's discuss. Callback Pattern: If your moin gorouting blocks there must be a second goroutine which accepts incoming messages and invokes the anonymous function. As the "go" keyword istn't visible in this scope a user might easily get into a race condition if he accesses resources outside the anonymous callback function, e.g. a RW map. Also the program flow isn't clear. Go programs are usually (my opinion) written synchronously. Synchronous code is very easy to reason about. With callbacks this isn't the case. Aside from that golang escape analysis will allocate anonymous functions on the heap. So if you're writing a high performance program this might not be the desired outcome. &amp;#x200B; Reader Pattern: One single goroutine. Synchronous code. Top down program flow. Easy to read, easy to reason about (my opinion). Easy introduction of race conditions is prevented. Conclusion: I'd always use the reader pattern.
thanks, I do try
well, it wasn't academic or useless the first time I passed a slice by value and wondered why the original changed too.
Yeah, I should have mentioned that in the article. In Java, you can have circular imports between packages. In Go you can't. As a result, it's impossible to recreate Java's package structure in Go and I went with a flat package. If I had the option to design this code from scratch, I would split it into sub-packages. The business realities meant that it has to follow Java as closely as possible. 
Didn't get to benchmarking. But I don't expect much difference. At the core, the client sends http requests with JSON payload to the server and parses JSON responses. So most of the time is spent in JSON encoding / decoding. There are JSON libraries for Go that are faster than the one in the standard library, so I'm sure I could improve the performance, but I didn't get to that point.
Oh wow, thanks for the detailed thoughts. It sounds like the Reader Pattern is much better and fits the language itself. I keep avoiding to apply something I learned from the other language to Golang (like MVC and now it's the callback-stuff), I think I will stick with the Reader Pattern, thanks.
Please be aware this is just my opinion. Don't trust a single person on the internet.
yep, sure, I understand.
In the second example you can make c a channel to make it even more idiomatic. Great question btw.
Great suggestion, thanks!
https://github.com/golang/go/issues?q=milestone%3AGo1.12.2 actual link to the actual changes ;)
Wait, Haskell’s biggest contribution in your eyes is that it popularized Option?
What version of Java was the original code base? It seems to be &lt; jdk 9 as the module system addresses the authors concerns of over exposed classes. 
The version I was porting dated from around a year ago and it was indeed jdk 8. The latest version works on both. I can't really speak to thinking behind Java code but I imagine that they'll want to maintain compatibility with jdk 8 for some time in the future as this is a library used by other people. Switching exclusively to latest jdk is probably not an option.
What would you suggest then?
This guy is amazing. I have been using SumatraPDF for about 10 years by now.
Just never "SELECT \*", right ?
Nice article. I'm going to rewrite some solutions to golang shortly too :) For overloading replacement and for functions with many arguments you can try to use this interesting solution https://github.com/serajam/sbucket/blob/master/pkg/server/gob.go#L110 Just define required parameters A and Optional B and C, for example 
I am not sure they will survive GC. The pull request referenced smooths out the deallocation across two GC cycles, which means that objects are more likely to survive the GC as long as they are checked in and checked out at a steady rate.
\&gt; Codecov is barely adequate. For Go, they count non-code lines (comments etc.) as not executed. It's impossible to get 100% code coverage as reported by the tool. &amp;#x200B; Can you elaborate on this?
You should take this a few steps further.
He did a bit [here](https://old.reddit.com/r/golang/comments/ba0lsm/lessons_learned_porting_50k_loc_from_java_to_go/ek8l0lg/). I haven't witnessed codecov counting comments as coverage though.
Hey u/kjk, good article. Can you elaborate more on why you "dropped interfaces and instead exposed concrete structs in the API"? For instance, why would you think "hiding those internals from myself is counter-productive" instead of perhaps a sign that the design needed improvement? Because when this happens: &gt; Java programmers noticed that issue and sometimes use an interface as a hack to fix over-exposed classes. By returning an interface instead of a a concrete class, you can hide some of the public APIs available to direct users of the class. I take it as a design smell. You would seem to agree - you used the word "hack" in there. Are you saying these Java programmers are exposing interfaces but secretly doing type-casting underneath?
It was 50k loc in Java. So what about the Go port? 
mmm.. It is more like anti leech file gate with user authentication, since I already buried userID in jwt token. But when I use http.FileServer, it serves the whole directory without any filters. I don't know how to add conditions to a http.FileServer to make it response accordingly. I haven't found any examples of wrapping a middleware like that around the http.fileserver. I wonder whether this is why people choose golang just for middleware microservices instead of nginx or any other more comprehensive web server.
`module github/mlpanel` `go 1.12` &amp;#x200B; This is my go.mod
Thanks a lot for the response, I greatly appreciate the comment. I wrote this on a whim just to solve the issue I had writing a web server. As a somewhat novice this is all gold to me and I’m sure as hell going to be coming back and reading this a few a times. Cheers. 
Thanks, I got the error. I did not know that the public functions were written in capital letters and privately owned. This is really bizarre to me that only coexisted with javascript until then.
Meu problema foi resolvido. A questão era que eu estava utilizando uma função privada.
Meu problema foi resolvido. A questão era que eu estava utilizando uma função privada.
Meu problema foi resolvido. A questão era que eu estava utilizando uma função privada.
Meu problema foi resolvido. A questão era que eu estava utilizando uma função privada.
Yes. Purity is only good in small doses. Laziness is just bad. ML syntax is not good. Strong type systems were already popular. Type inference got a boost from Haskell but was also already a thing, and Haskell’s version is too powerful, which makes it less useful. Monads are a solution in search of a problem. Option types (not monads as a whole) weren’t commonly known before Haskell, and now are considered must haves for new languages. 
Why on Earth would you want that? sync.Pool is basically a freelist, which is emptied on GC. So you can have a lot of objects in it if you put it there, but don't reuse. And that possibly induces a GC anyway...
43557 according to tokei, of which 16493 are tests. For the Java/JVM client it's 50945 total of which 18004 are tests.
Great write up, fun read. Why did you choose to pass your FooArgs additional parameter struct by reference rather than by value? I’ve been trying to keep more allocations on the stack and I wondered if you had a motivation for this 
I don't want to shit up a thread in this Go subreddit, but here I go: &amp;#x200B; If all you get out of Haskell is a consistent semantics for "None" in place of null, then that's fine I guess, but you are making very strong and irrational assertions, bordering on FUD, and declaring them fact. I don't think you know what you're talking about, honestly. &amp;#x200B; &amp;#x200B; &amp;#x200B;
I'm doing CPU intensive work so there's no need to have more workers than CPU's. Any other ideas what to use from the std library to have a fixed size worker pool which won't get gc'd?
You can do this just with heroku which you can configure to watch for pushes to master on GitHub. It'll build and if successful restart the herokuapp with the new code
Thanks!
I’m not talking about performance. I’m talking about side effects. You generally should bail out as soon as an error happens and not just continue blindly executing code. 
[go hiding example](https://golang.org/pkg/net/http/#example_FileServer_dotFileHiding) This is in the doc and wraps the file handler with logic to hide hidden files. You couple probably do the same thing. Also yes, using package middleware in ms it probably easier or look at a MicroService package like go micro that supports middleware. He even has an authorization example.
Is that Notion screenshot the full timeline? This took you about 10 months? How many hours a week would you say that included?
I especially liked this "meaty" piece of content: "Both Java and Go have interfaces but they are different things, like apples and salami." 😆
Depends what tours doing. Scanners are setup to read line by line. A reader just adds buffering to an io.Reader. A reader can accomplish the same things. 
I love your writing style, OP. I really enjoyed how direct it was, I could learn a thing or two from you! I have a few draft posts myself, and may refactor them in a similar way. I may have missed this - as I'm reading on my phone whilst on a train - but I was wondering how you approached the architecture/design of the port, and whether you noticed any idiomatic issues? I only ask as my most recent place of employment had began using Go after a period of Java; and for all intents and purposes, the Go services were almost identical - I actually referred to them as "*Gova*". For a port I could understand if it was very similar, my main issue with the "*Gova*" example is that these weren't ports, but brand new services. They seemed to miss some of the simplicity and elegance of Go.
I love you both
I'm not entirely sure on CI and the other service parts of your question but I have developed a gomobile package that runs effectively as a gRPC daemon for an android application. The gomobile cli creates an aar java package file (I think that's the extension) then call it from java to start it as a service. It actually works pretty damn good but I don't need to update the underlying go code THAT often so it may not be the best for your type of work. 
I would add that the approach is only as good as the situation you're implementing it for. If you have a situation with 100 writes and code that changes very little then writing it out long hand might be annoying but it may yield better performance. If the code changes a lot, the performance hit might be worth it. There is no one best solution.
You may want to check the GoCoEdit app. It's a Go editor for developing *on* a mobile device. If you want to develop *for* mobile devices, it's another story.
Spammer created a new account. Spam list now also renamed. Reporting you as always, though.
it was 600 hours of 11 months, so around 56 hours per month. That wasn't full-time effort.
Not sure if that's codified somewhere or not but in Go the only case for using interfaces that I consider good style is when they are absolutely necessary i.e. you have multiple implementations of an interface. I dropped all uses of interface when that wasn't the case. 
Thanks, but I want the application to run somewhere in the cloud.
Thanks! I'm already using [Working Copy](https://workingcopyapp.com/). How would GoCoEdit improve the experience (I'm only interested in writing code on the mobile device, not executing it)?
Here's an example: https://codecov.io/gh/ravendb/ravendb-go-client/src/master/create_subscription_command.go there are 3 lines of actual code that are not covered from 53 total lines but codecov shows coverage of 66.7% 
That's how most people do it. Most of the time, but not always, those are equivalent. This happens so rarely that the impact on speed would be immaterial either way. I'm not convinced passing by value would be a clear win. You save on GC, you loose on more copying of the data.
Keeping the port as close to Java as possible was a business goal, so I didn't have much opportunity to redo things to be more idiomatic Go. Both Java and Go client will be evolving in the future so the less divergence, the easier it'll be to port future Java changes. But yeah, if that was done from scratch, some things would be done differently.
Reported your comment too. What did this weekly every single week embodies, is 8 hours of manual research and reading, significantly contributing to finding valuable information for all Gophers out there. Your comment embodies the picture of a continuously job-seeking individual that complains about the government not helping to get rich and eating fries and watching Reddit posts and soap series the whole day
Blimey! Slices are weird. I just exploded your example out to understand what's going on: a := []int { 1, 2, 3, 4, 5 } i := 2 a = a[:] // [ 1 2 3 4 5 ] fmt.Println(a) dest := a[i:] fmt.Println(dest) // a[2:], [ 3 4 5 ] source := a[i+1:] fmt.Println(source) // a[3:], [ 4 5 ] x := copy(dest, source) fmt.Println(dest) // [ 4 5 5 ], fills from start fmt.Println(x) // 2, amount copied a = a[:] // [ 1 2 4 5 5 ], a has been modified fmt.Println(a) a = a[:i+x] // [:4], [ 1 2 4 5 ], original a without value 3 fmt.Println(a)
&gt; I don't know if it's codecov or maybe I'm not sending the data properly. Sounds like a business opportunity to me, or at least the opportunity for someone to build an open source tool that tracks history and trends but also tracks coverage properly.
&gt; I also want to do all of the development on a mobile device. Why?
You can’t type cast interfaces underneath. That is basically begging for runtime error. If you’re type casting interfaces, then something is horribly wrong in what has been exposed. 
That's a low-priority project. Often I have chunks of time when I am not in front of the desktop computer. I want to use those chunks of time for working on this project. If you use those chunks productively, the gained time adds up. I want to have a replacement of an IDE in my pocket in order to use those chunks of time.
The only one I'm aware of is the [JetBrains plugin](https://plugins.jetbrains.com/plugin/10581-go-template).
&gt;blog.kowalczyk.info/articl... Fair enough.
I'm liking [json-iterator](https://godoc.org/github.com/json-iterator/go). More or less a drop in replacement for encoding/json, and something like 5x faster.
I’d love to hear more. 
A freelist. For concurrency, use a per-gothread freelist.
A few other things I noticed when porting Java code ([https://github.com/flanglet/kanzi](https://github.com/flanglet/kanzi-go)) to Go ([https://github.com/flanglet/kanzi-go](https://github.com/flanglet/kanzi-go)). Java byte is signed and Go's is not. Be careful when porting Java code. Go requires unsigned shift values (in Java xxx &gt;&gt; -3 is fine) and the shift behavior is slightly different (when the shift value is 64 or more). BTW, Go1.13 will get rid of the unsigned shift value requirement. Also, Java has signed and unsigned shifts: &gt;&gt; and &gt;&gt;&gt;. Go has more types (unsigned) and is more strict in casts. Be careful to select unique constant names per package in Go (say, when porting static const from Java classes) to avoid name collisions in different Go files in the same package. For my case, the size of the Go and Java code is very similar. Some benchmarks are available in the github pages.
Good advice for how to tackle big ports or rewrites: &gt; Without testing and validating after every little step I'm sure I would be defeated by complexity. &gt; &gt; At the core the client talks to the server via HTTP protocol. I captured the traffic, looked at it and wrote the simplest Go code to talk the server. &gt; &gt; My first milestone was to port enough code to be able to port the simplest Java test. This is a common strategy: port the tests first, starting with the smallest possible unit of functionality. Get that to pass. Add more tests, implementing only as much code as you need to make those pass, and repeat. I guess this is basically test-driven development, but fortunately you're starting with a clear specification: the existing program. Also, check out the boilerplate short-circuiting logic he had to put into every function to achieve "Fluent function chaining". This is closely related to the recent post on this subreddit about monads vs. ErrWriter. It really feels like Go is missing a valuable abstraction here.
 &gt;Keeping the port as close to Java as possible was a business goal, so I didn't have much opportunity to redo things to be more idiomatic Go. That makes perfect sense, and is a perfectly valid reason. It's quite the contrast to the situation I was in, where there was a real opportunity for following idioms and writing concise and explanatory Go. Either way, great work and a great write up! 👍
Do you know what the motivations were of the company to port this piece of software to Go?
Are you disagreeing or agreeing? I honestly can't tell.
It's a database driver. They wanted Go users to be able access RavenDB too.
You'd have a point but nothing is blindly executing code
This is dream project. Were you contracted to do this or did you volunteer?
I was the one who submitted the PR earlier for the license change. If you look at my fork the develop branch has my stab at how I would do the full implementation. I left the feature branches so you can separate the client return stuff from the concurrency stuff. Also you way want to take a look at the tests, I added some cases to give it 100% coverage and test out the close. I didn’t submit a PR for these changes since it looks like you are trying it out. Let me know if you want me to later. Have fun.
&gt; In Go string is a value type. It can't be null, only empty. I suspect this is the reason why the entire AWS SDK takes arguments as *string
Cobra supports slices. Cobra implements it’s own wrapper around the std flag library. 
For scanning lines they're fairly similar, just use the one you like best if you can't decide. The scanner doesn't have to copy the line, because it's invalidated when you next call Scan. OTOH if you get a partial read it has to rescan the whole line due to how the scan function works. The reader has the advantage of being an io.Reader. ReadString and ReadBytes always copy the line though, ReadSlice and ReadLine don't. The pretty much sums up the entire difference when scanning for lines, the Scanner can of course scan for other things as well though. 
Elaborating, but I guess I wasn't clear enough :) Initially, Haskell was forced into inventing a List transform based IO to force an imperative-like evaluation order. It continually listened to stdin, and outputted to stdout as soon as a new value in the list was ready. They would write programs in an imperative language to wrap around the Haskell program to direct user interaction. Note that Monad State already existed then, so writing imperative-looking programs was already possible. Then, some decade later, the IO Monad was invented, along with an IO-aware runtime. You use the IO Monad to describe an IO graph, which doesn't have to describe imperative programs at all. That's explicitly the advantage over the previous technique. Fork-based multi-threading with shared variables or channels or STM, automatic parallelism, actor systems, FRP, data parallelism... pretty much any system that's been thought up has been put into GHC by now. And it's possible because IO Monad doesn't rely on data-dependencies to force an order.
You might like https://willnorris.com/2014/05/go-rest-apis-and-pointers
Same. SumatraPDF is simply that great.
I'd just build some middleware that checks that the URL is appropriate for the username in the JWT. e.g. make sure that the URL is /temp/images/userX/* if the logged in user is userX before passing it to http.FileServer, otherwise respond with HTTP 403.
Their job offer popped on https://twitter.com/golangprojects which is twitter account aggregating Go job offers. I sent them an e-mail pitching myself, we negotiated the scope and price, we had a Skype chat and I got the job. A great company to work with.
There’s a typo in the string vs string section, you wrote “an reference”
So this may have been a case of "preemptive abstractions". Fair enough.
Correct, and that is what I meant.
If you were to redesign the package structure, how would you go about it? I'm writing a go implementation of an algorithm written in pseudocode that is written with cyclic dpendencies in mind, and i have no idea what's the idiomatic way of restructuring it. Currently i have all inter-dependent code in a single package, but that results in big packages, and private methods being exposed between go files, although this doesn't really bother functionality it feels weird coming from other imperative languages. Anyways i'd like to see how you would encounter this in your case. Thanks on advance.
They do take a little bit of getting used to! They are great abstraction when you realise they are not arrays! I would add one more Println to your example: https://play.golang.org/p/Pb7BcvA-a8G It's important to remember that slices are a 'view' of an array (and an array is a contiguous block of memory). So after the 'remove' you'll end up with two references to the last element. But to honest I rarely find myself worried about memory leaks in Go... it depends how long your slices/arrays are going live, I suppose.
I don't think I can give generic advice about structuring code. I believe it depends mostly on the code you're writing. I will say that I don't try to force it. If it's hard, if I can't figure out how to split code into packages, then I don't do it. There's nothing wrong in having everything in one package. Maybe I'm missing something today in which case a better way might come to me in a week or a month and then I'll implement it. Or I'll never come up with better way which is fine if I have working code that does what I want it to do. "The best way" to structure the code is often in the eye of beholder and often given too much emphasis. If you want tactical advice: get someone you trust and respect to give you code review. If you feel they give you good, concrete feedback implement that and do more of that. 
Looks like a slice of maps? Iterate over the slice and then grab the current map and grab the key and value and store it in a custom stuct. 
Thank you for the effort you put into this answer and the other comments below. This really helped me.
Not in the language itself, nor in the stdlib. But some 3rd party libraries implement it with either an interface reflection api or with codegen
Is that the actual contents of a particular field? Doesn't seem to be anything easily marshaled into a data structure without custom parsing it. The CustomFields type is a map of string to string, which means the value of each field will be some custom format string type. 
Yeah, what I pasted is the contents of "data" which in my code is the result of the specific custom field "customfield_12345". Should I be doing that differently? It just returns data as a single, unstructured string. 
But it's unstructured (if that's the right term) data, that's just a single string that I get back as "data". How would I conversations it back into a slice?
Oh now I get what you mean. In fact, the 66,7% is correct, because there are not 53, but 18 "coverable" lines (all the colored lines). You can't really cover types and var declarations etc.
thanks, fixed
A couple of variations on this you might consider: c.Loop(func(msg string) { fmt.Printf("received: %s\n", msg) }) This keeps execution in one goroutine like in your Reader example but you get the benefits of being able to pass callbacks. If you want error handling, you might add this to the signature for the callback, and possibly the return for Loop. If channels make sense for your situation, this is pretty straightforward as well: ch := make(chan string, 0) go c.Loop(ch) for msg := range ch { fmt.Printf("received: %s\n", msg) }
It sounds like what you want is an interface. How this typically works is you write an interface that the client can use then write an implementation that conforms to it. This creates a bit of extra work for you but it makes it so you can change out your implementation later if say you want to call a completely different api. All the client ends up knowing about is that there is some function that returns some value and accepts certain parameters. Hope that helps.
To address this question: Arrays/slices are good at random reads/writes but insertion and removal are not not ideal operatons for them. If you mostly do instersts or deletes a liked list serves you better. 
[removed]
It’s like if Hemingway was a programmer. 
[removed]
[removed]
Why would you add a channel to something that just reads a message off of a socket? There's nothing idiomatic about that.
Succinct and interesting. Nice write up.
gotchu fam
You can try doing type assertion to convert it to a slice of maps, but you might have a hard time doing so as the function is returning you a string value instead of interface.. [https://github.com/andygrunwald/go-jira/blob/master/issue.go#L913](https://github.com/andygrunwald/go-jira/blob/master/issue.go#L913) &amp;#x200B; Alternatively, the function also returns the response, you could try reading the body of the http response to see if it works. then, use the json package to unmarshal it (if it's json data).
Dave would like a word with you.
Philosophically Go is sort of against this, and lack of generics/contracts makes it kind of awkward and slow anyways. Also see: https://github.com/robpike/filter where one of the main Go authors wrote a library like that discarded it and said about it: "Instead, I just use "for" loops. You shouldn't use it either." But man, I would kill for some list comprehensions, performant or not...
Donate?
Look into opensnitch
You don’t want to redirect to the long in this case, you just need a to respond with the long as either a text doc or json
I like to use interfaces when I need to test behaviour in a package with another package injected into it. Fx. a logging interface. Similarly, I recently implemented an interface and used it as an input so that I could inject a mock client into a function during testing. How do you get around such use cases without interfaces?
Thanks I had that idea but couldn't figure it out either.... here's what I tried, do I need to do something special with the body? func getdata(issue_id string) { issue, _, _ := jiraClient.Issue.Get(issue_id, nil) _, resp, _ := jiraClient.Issue.GetCustomFields(issue_id) defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { panic(err.Error()) } var result map[string]interface{} json.Unmarshal([]byte(body), &amp;result) fmt.Println(result) } [https://www.sohamkamani.com/blog/2017/10/18/parsing-json-in-golang/](https://www.sohamkamani.com/blog/2017/10/18/parsing-json-in-golang/) is an example I found below but I'm not sure what key is returned in the body to replace "birds" birds := result["birds"].(map[string]interface{}) for key, value := range birds { fmt.Println(key, value.(string)) }
Who set that field data to that value in the first place? I can't imagine Jira created that format. 
Maybe any Cloud IDE or even [Cloud9](https://c9.io/login)
This function is creating a map of the data, [https://github.com/andygrunwald/go-jira/blob/master/issue.go#L884](https://github.com/andygrunwald/go-jira/blob/master/issue.go#L884) and [https://github.com/andygrunwald/go-jira/blob/master/issue.go#L525](https://github.com/andygrunwald/go-jira/blob/master/issue.go#L525) I think I might be better off interacting with the response body like another commenter suggested, though that's still going to be difficult.
I hate to be that guy, but Google will bring you right to the answer to this question on Stack Overflow and other places. Try it next time, so this thread doesn’t become a dumpster fire like /r/python
I don't understand. Why is Go so against filter, reduce and other generics? Wouldn't it making worth with data, specifically JSON, easier?
Project is open source: [go-gecko](https://github.com/superoo7/go-gecko)
logo 10/10
thanks, got it from [free-gophers-pack](https://github.com/MariaLetta/free-gophers-pack) and edit a bit with affinity
It's how Go is designed. Filter/map/reduce functions work using interface{} which have an overhead of reflection. For efficient code, you need to use types, at which point, it is cleaner to just use a for loop. Or you can also use codegen to generate the functions. But that might be an overkill depending on the size of your project. Also see https://groups.google.com/forum/#!topic/golang-nuts/RKymTuSCHS0
/links/:code provides the details in as JSON
I personally use those chunks of time to write down ideas that I won't think about while coding or think about the project from a different point of view or approach.
I would argue returning a channel would be wrong here because the caller wouldn't be able to control the concurrency. See Bryan Mills's talk "Rethinking Classical Concurrency Patterns" from last year's Gophercon for a fuller rationale.
Nice :) You\`d better rename your helper package or divide it into two separate packages, because \`helpers\` is not a golang style (section "Bad package names" [Link to post](https://blog.golang.org/package-names))
Thanks for the advice, take note of that.
That seems like a bug in the library. It only special cases looking for a map as the value of the field and extracts from it. But anything else it's just going to stringify which is kind of useless. Seems your custom field is a slice and the Jira lib is stringifying it. So either you need to report that and get it fixed or manually parse the response body. 
There is a rewrite of the escape analysis code coming; not sure if it solves these issues. You might be interested in this document from 2015 listing the known flaws. Not sure which ones have been fixed though: https://docs.google.com/document/d/1CxgUBPlx9iJzkz9JWkb6tIpTe5q32QDmz8l0BouG0Cw/edit#
There was a post around here just a few of hours ago that said something about the use of reflection in fmt.Printf causing the heap to be used
It's likely: [https://stackoverflow.com/questions/44697906/why-a-constant-escapes-to-heap-in-golang/44699604#44699604](https://stackoverflow.com/questions/44697906/why-a-constant-escapes-to-heap-in-golang/44699604#44699604) &amp;#x200B; Consider: [https://play.golang.org/p/wgCWwafPQDM](https://play.golang.org/p/wgCWwafPQDM) &amp;#x200B;
I wouldn't say that the designers of Go are philosophically opposed to the idea of map/filter/reduce, but that they recognize that the language (pre-generics) doesn't support those patterns well, so the patterns aren't worth using.
[removed]
In a follow-up article. Already mentioned Denis' implementation in Appendix B.
Now with much improved meiosis.
It’s this exactly. Print will cause it to change things to the heap. It was about allocating two objects and them being the same memory address. 
s1 := []int{1,2,3,4,5} func removeSliceElem( s1 []int, pos int) []int { a := s1[:pos] b := s1[pos + 1: len (s1)] newSlice := append(a, b) return newSlice }
Title of this post: 1/10 Please add at least a short description.
&gt; The const strings, variables i, j should be on stack-allocated, easily judged by a manually check. `s` is not a "const string". It's a normal, mutable value. A non pointer one. So is `i`, `j`and `k`. Any non-pointer value that's converted to an interface allocates on heap as a matter of principle. And fmt.Prinln signature is `Println(args ...interface{})`. The conversion can be optimized away in some cases, but most of them are within a function. Across function calls it's much harder. It's impossible to be optimized away always as that equals solving the halting problem.
One thing I'd like to see covered is how to handle pattern matching involving text strings, rather than just patterns involving individual character sequences. The use case I have in mind is extracting HTML elements using regexp. *I am aware that this is not advisable, but I want to do it anyway.* An example would be extracting an entire HTML table - there's no straightforward way to do this with golang regexp. The HTML tokenizer and parser make this *much* more complex than a simple regexp that matches &lt;table&gt;.*?&lt;/table&gt;. And unfortunately, that example regexp doesn't reliably extract a single table. 
GoCoEdit is an editor with go syntax highlighting. I used it a few years ago, so I don't know how it evolved. I just experimented with development on mobile and gave up. It can't beat the development on desktop computer. But I only have a small screen iPad. GoCoEdit has an efficient way to access all the special symbols we need when programming like [] and {}. At the time we only had the simple screen keyboard. 
&gt; It’s convenient to use `raw strings` when writing regular expressions For inexperienced programmers, the meaning of this sentence will be unclear. Otherwise, I find the tutorial very good and helpful. 
In the escape character section, shouldn't octal values have a 0 after the \ ?
Thanks! I'll certainly fix that.
The \\-followed-by-three-digits notation is specific for Go. It's called a rune literal. [https://golang.org/ref/spec#Rune\_literals](https://golang.org/ref/spec#Rune_literals)
[removed]
Yeah because trying to extract data from HTML with regexes doesn’t work reliably. That’s why it’s “much more complex” with the HTML tokenizer/parser. You basically just said: “I want to do this complex task with this simple tool but can’t because the simple tool can’t do complex tasks.” And you want to add info on how to do a thing with a tool that is nearly universally stated to be unsuited for the task to a document for people just learning. 
&gt;Any non-pointer value that's converted to an interface allocates on heap as a matter of principle. Future versions of Go might be able to put the non-pointer values on the stack and pass a stack pointer (instead of a heap pointer) to `fmt.Println(i)`. &amp;#x200B;
I think that's already the case sometimes. It's what I meant by "The conversion can be optimized away in some cases, but most of them are within a function.", but I formulated it quite wrongly. Thanks for the correction.
`fmt.Println()` is a “Variadic Function” so all args will escape to the heap. Avoid variadic functions and passing pointers; then everything will stay on the stack.
Thank you. I learned something. 
thanks 
The closest is example https://golang.org/pkg/testing/#Examples
So did I. :)
There are project like [free-gophers-pack][] that provide free to use pictures and drawings of Gophers. On the other side a Gopher it not that hard to be drawn and can actually be created with small effort as vector/pixel graphic in Illustrator/Inkscape/GIMP/Photoshop. [free-gophers-pack]: https://github.com/MariaLetta/free-gophers-pack
The cast majority of the time writing the response is the last thing I'll do in the Handler, so checking the error is pointless since there's nothing to do if the write failed anyway. The exception would be if the Handler was going to do something after writing, in which case I might check it. The tricky thing to remember is that even if the server thinks an error occurred, the client might have gotten the data just fine. Like so: * Server sends response to client. * Client receives response. * Client sends ACK to server so server knows it got the response. * The ACK is lost. * The client thinks it's done and closes the connection. In the case the server would _probably_ return a write error, but the client would have gotten the write. Tldr: it's usually not worth the effort.
Remove the &amp;.
Do &amp; *after* the type assertion to Node.
Ashley Macnamara. 
Nice logo would like to have logo for my library Would also like to share my first go library https://github.com/onkarvhanumante/Excel2JsonTree
You mean like this? &amp;(funcImpl.funcBody.Back().Value.(Node)) That doesn't compile
Yep, `*interface{}` is a pointer type, not interface type. Working example: https://play.golang.org/p/SLRiIcsqcOJ 
Great talk. It's probably also of interest for OP.
You should maybe consider doing it with [nftables](https://wiki.nftables.org/wiki-nftables/index.php/Main_differences_with_iptables), which is supposed to [replace iptables](https://wiki.nftables.org/wiki-nftables/index.php/Moving_from_iptables_to_nftables) in the long run and has a [library made by Google](https://github.com/google/nftables).
A demo of it working can be found here: [https://gitlab.com/ollybritton/gofuck](https://gitlab.com/ollybritton/gofuck) I'm not entirely sure how Go projects are generally laid out or structured, so there is probably a lot wrong with the formatting and style of the code in general. I would greatly appreciate any criticisms or feedback. 
I would still log the error, even if you can't throw a 500 or anything at that point.
https://golangweekly.com/
https://gopherize.me
http://book.mixu.net/distsys/single-page.html
If you can do anything withe the error, then check it. Otherwise, it's unnecessary. Sometimes logging the error is all you can do, but that may be useful: you see the client closed the connection prematurely, for example. If it's not useful, then don't even log it.
You may need to put the Node valley into a variable, first. Then take the address of the variable to get your *Node.
It's more the use of interface{} and reflection. The last time I was optimizing an inner loop I was able to make variadic functions whose arguments don't escape and call them with slices directly or indirectly that won't escape. It's mostly about whether the function you're calling let's it's arguments escape, so you may have to jump through some hoops.
https://columbia.github.io/ds2-class/
Couple of things: I would avoid having a folder called src, it's an unusual pattern in go. The http client has no timeout set, I would also recommend this be intialised outside of the package and allow the implementor to pass it in, I normally use a NewClient func that returns a client struct, then create request methods from this. Would you like a pull request?
Excuse my ignorance, but aren’t comments supposed to be just that, comments? Why would you want to have a special meaning in the comments to implement something like this? Just use the testing package [1] and create explicit unit-tests and benchmark to verify backward compatibility in your code. I’ve read many times in the Go issue tracker that some _—if not all—_ the core developers of the language are opposed to add annotations to the code in order to modify the compiler to do special tasks, either to hide warnings by “go vet” [2], to modify binary building [3], or to inline code [4]. They are even hesitant to add simple things like “list support” in the comments to translate Markdown into HTML via “go doc” [5]. Go supports build tags [6][7] using comment syntax, but I don’t think they will expand that to add inline testing like “doctest” does, at least not in the near future. [1] https://golang.org/pkg/testing/ [2] https://github.com/golang/go/issues/17058 [3] https://github.com/golang/go/issues/7007#issuecomment-66089610 [4] https://github.com/golang/go/issues/21536 [5] https://github.com/golang/go/issues/7873 [6] https://golang.org/pkg/go/build/#hdr-Build_Constraints [7] https://dave.cheney.net/2018/01/08/gos-hidden-pragmas
Try on the command prompt “which git”. If you get a response about the command not being found (which hopefully you will), do install fit via the package manager, eg “sudo apt-get install git”. Then try your go command again. If those steps don’t go as planned, I’m not sure.
well do you have git installed like the link says?
 Yes, forgot to install git :~
!remindme 20 days
was just curious, not really complaining about the absence of a doctest like framework. and thanks for all those threads and a detailed answer.
UIUC CS 425
There are a few I subscribed to. Some stop sending, or there is a long time gap between newsletters. Just do it if you want to do it. There is always something to learn and share. 
I wouldn't recommend this, it will 100% become just noise.
Do you have more of such links? E.g. a collection of interesting papers to read if someone didn't study CS but is interested in reading?
&gt; Excuse my ignorance, but aren’t comments supposed to be just that, comments? First, doctests in Python go in doc-strings not comments. Go uses the comment above a function to generate documentation, but it is still a comment in the source vs a string in python. If you just look at the documentation generation aspect, then doc-tests are useful in providing in-line documentation much like example files in Go. They are a bit more useful in Python due to the lack of type signatures on functions, the examples right there help show the expected types. In Python they not only help document their functions but also have advantages due to the test locality to the functions. It means you don't need the extra test files which is nice as it is pretty common to have a standalone (single file) scripts. I've also found having the tests right there with the code is handy when refactoring/reworking. I don't think they would fit in as well in Go and really don't make sense. Being compiled means you are never distributing the code itself as an executable. Also Go doesn't have the same formalized doc-strings like python has and putting doc-tests in the comments wouldn't work as well IMO. 
Try using a status code in the 300's as those are the redirect ones
Thank you, this actually works!
Oh, wait. The answer is you have to set \`CC\`. &amp;#x200B; \`\`\` CC=clang go test -msan \`\`\`
The gopher in the logo looks high. I mean it is basically floating.
This is not what I am searching for. All newsletters are a result of some opinionated filter. Someone decides for you what is worth reading and what is not. Maybe some find it convenient, but this is not what I am searching for. I am looking for an aggregate of all blogs that want to participate in the community stream (aka planet).
You need parametric polymorphism (and nothing more!) to get those. Sadly, basic parametric polymorphism (i.e. quantified a function over `forall a`) is never gonna come to go afaict despite it being a solved and mature design space. But the Go authors seem pretty loathe to learn from work outside their bubble. 
[Designing Data-Intensive Applications](https://smile.amazon.com/gp/product/1449373321/ref=ppx_yo_dt_b_asin_title_o02_s00?ie=UTF8&amp;psc=1) seems to be the industry standard, although it's not Go specific. 
o.m.g.
This is not true when working with immutable lists :)
I'm not sure if this is exactly what the go creators say about it, but from what I've heard others say, the feeling is that even aside from the generics support issues, constructs like map filter reduce etc can obscure the performance characteristics of your code. For loops might be verbose, but it's obvious what they're doing, goes the line of thinking, and it's easy to reason about the performance. Obviously when you're just parsing a dozen things out of json object, that argument can feel a little annoying, but this is part of the price we pay for using a systems language to write applications :)
Are there any recommendations as to how to implement or use the concepts learnt through golang
Great thanks!!
I think a good introduction was done by Denise Yu last year at the DevOpsDays ([https://www.youtube.com/watch?v=uTJvMRR40Ag](https://www.youtube.com/watch?v=uTJvMRR40Ag)) Enjoy! 
This looks terrible.
Yeah, this. I often feel like some developers conflate “dense code” and “fast code”. Explicit loop or not, the machine still needs to iterate over the data. Or, to put it a different way: what optimizations could be applied by the compiler to a filter construct that could not also be applied by the compiler to an explicit loop?
[removed]
nice.. congrats, that's the way to learn.
It would be helpful if you could explain a bit more about why you need a pointer. If your intent is for all instances of the same Node retrieved in this way to reflect all changes made to one another, then you need to change your list.List to store a *Node to begin with. If you pull the Node into a variable and take it's address, you will only have the address of the new variable not the value in the List.
I do love those: https://www.mauricioaniche.com/publications, but I'll keep pasting more here and let the community also contribute. :)
I don't think it's a bug, just a lack of extendability in this function... I moved on to using the "Unkown" field of [https://godoc.org/github.com/andygrunwald/go-jira#IssueFields](https://godoc.org/github.com/andygrunwald/go-jira#IssueFields) which seems to be promising so far. func getsomedata(issue_id string) { issue, _, _ := jiraClient.Issue.Get(issue_id, nil) // This returns as a slice of interfaces []interfaces{} data := issue.Fields.Unknowns["customfield_12345"] //I can also do type assertion to get my desired field data2 := data.([]interface{})[0].(map[string]interface{}) } So far so good, progress! Now I'm having difficulty finding how to range/iterate over all indexes rather than specifying one. Any guidance?
Yeah, the generated one doesn't look hard to write... the first time. We've been liking wire so far at my workplace. It's been mostly useful as a way to add a new dependency and not have to track down all the places that need to change. Add a new argument to a constructor, rerun wire and it'll tell you exactly what's missing. Fixing it is just adding one or two statements to the wire call, rather than finding all of the appropriate call sites and adding the new parameters. (Not hard to do with Goland, but still more work than doing nothing.) If you already use generate for stringer etc., wire is cheap and easy to try and saves a bit of work.
[removed]
Catch it and log it. Knowledge is understanding. 👍🏻
💯 Should be the top answer.
I updated the repo with a web admin client. 
&gt;I don't think it's a bug, just a lack of extendability in this function... I guess that is a matter of opinion. Seems to me if one is going to implement custom unmarshaling, that it is unexpected behaviour for it to only handle one case and then let anything else just convert to a string representation. A user would have to understand the implementation of the library to figure out why the custom field value is returning that un-usable format. 
I guess that's fair, I'm still fairly new to go so I'm hesitant to blame the library since I barely know what I'm doing. 
thanks! just bought it
Sure, I'm still a lil bit lost out there lol
[removed]
Here is what I have come up with so far: instr := uint32(0xaabbccdd) aa := instr&gt;&gt;24 bb := instr&gt;&gt;16&amp;0xff cc := instr&gt;&gt;8&amp;0xff dd := instr&amp;0xff fmt.Println("aa", 0xaa, "bb", 0xbb, "cc", 0xcc, "dd", 0xdd) fmt.Println("aa", aa, "bb", bb, "cc", cc, "dd", dd) is there something better I could be doing? faster?
I always start by going to the tests. If they are not unitary I get disappointed; but keep going, if they are not BDD, that makes me feel bad; if they are not well written making sure there is a very nice triple A (Arrange, Act and Assert), well it turns things hard for me; of there is no test at all, readme guides me, if it is limited, then I start digging into the modules. At the last point I'm already quite disappointed and angry. Hehehehe... I come from a nice Java, Rails and Python background, so things like tests does matter a lot for me. I'd recommend Pivotal's code, webinar and etc.
Sam Newman's [Building Microservices](https://www.bookdepository.com/Building-Microservices-Sam-Newman/9781491950357?redirected=true&amp;utm_medium=Google&amp;utm_campaign=Base1&amp;utm_source=MY&amp;utm_content=Building-Microservices). It's not Go specific but it touches on basically everything you need to know about MSA, some in depth, others not so much but at least you'll know what to look for. Good luck!
Hey Nate! &amp;#x200B; Your feedback has been noted and I completely agree that it's not an ideal workflow for Go right now, since you'll either need to use weird build flags (e.g. cgo) or a separate local process. &amp;#x200B; The core logic is quite involved so ideally we don't need to write generators for every language, but that's not off the table. We're currently experimenting with compiling the core to Web Assembly so we still get the single binary goodness without crazy build flags. &amp;#x200B; If you have any ideas or opinions on how you would approach this, I'd love to hear them! &amp;#x200B; P.S. I recently watched your youtube video on Mage. Keep up the great work!
You could start out with a [4]uint and give access to the struct members by abstracting it with methods: https://play.golang.org/p/KkBGMAN3fdq You will probably want to make a way to also set fields, too. That might be a bit difficult with the way this one uses values and copies array data. You could also start out with a uint32 instead of a [4]uint and then use methods to get (and ideally to also set) the fields. If you do that, you will probably use bit shifting similar to the way you were doing it above. Hopefully that at least gives you some ideas
Thanks a lot!!
This was a good intro video thanks!!
Please do!! Thanks a lot :)
Got some good resources in this thread - thanks for asking, OP. One thing I find confusing is how distributed apps can have data locality. Different data for different users, placed on different nodes. Or things like Elasticsearch... How do they know which "node" has the data it's looking for? I guess that's what indexing is for. Or maybe it just queries all of them.. I have a lot to read about
Maybe you can add some other STUN servers other than a single Google one (or it make a CLI flag, so users can choose who to expose their connection metadata to).
So like `scp`, but without encryption, requires a manual two-way handshake involving copying and pasting long strings, and requires a [third-party server](https://github.com/Antonito/gfile/blob/b9af48c7fc431b678aacd39f205f3be3a2d21bb0/internal/session/session.go#L47), despite being described as a way to `share a file directly between two computers, without the need of a third party`? Maybe neat as an toy experiment with the WebRTC protocol but for practical use cases I'll stick to `scp`.
I think you misinterpreted the goal of the project. It's never been meant to replace \`scp\`. When two people want to casually exchange a file, it's not always practical to set-up a \`ssh\` service. I'd rather execute a single binary and copy-paste two strings with it that set-up a whole ssh server just to do a one-time transfer. I mean *no third party* as in *data does not transit through a third party server*. The code you linked relates to a [STUN server](https://tools.ietf.org/html/rfc5389). Furthermore, data is actually encrypted (under the hood, WebRTC sends data over [DTLS](https://tools.ietf.org/html/rfc6347)). &amp;#x200B; Nevertheless, as you say, the project is still an experiment and there are a lot of improvements to do on it.
If one ES node cannot answer your request it will relay that request to another node so the consumer doesn't have to know this.
Thank you for the feedback! I like the idea of adding a CLI flag for it. I can probably still defaults to Google's STUN server if no other server is specified through command line though.
&gt; I come from a nice Java, Rails and Python background, so things like tests does matter a lot for me. And since Go makes unit testing ridiculously easy, tests should matter a lot to any serious Gopher, too.
For a library, godoc shows the surface. A decent API makes it obvious which types and/functions are primary. Start with those and follow the branches out. Sometimes there are mostly shrubs like the strings package. Sometimes there are happy little trees with "run funcs" like net/http (http.Server). For an application, start with the main func. Hopefully, the main func has no or minimal logic that needs to be tested beyond building and running the app. Walk through the main function and traverse the tree of logic as you see fit. The tested code should be in the branches. Whether for libs or apps, read the readme and any other available docs. Even docker files can hint/clarify what's going on.
Unit tests are for computational logic like string parsing. Functional/behavior tests are for APIs. I am disappointed by neither when they are applied consciously. Either if those types of tests may be "integrated" with other systems, but preferably they use mocks. Integration tests are for systemic interactions. Again, no disappointment when used with a clear mind.
What's the difference between a text string and a character sequence?
[Max &amp; Ben Try Distributed Systems](https://www.youtube.com/playlist?list=PLjvJiJ23Dh0QuPcYWg9MQP6v3OG5_E9M2)
What was the reason for moving away from ORM?
**Brendan's** [https://github.com/brendandburns/designing-distributed-systems-labs](https://github.com/brendandburns/designing-distributed-systems-labs) 
Yes, I noticed that, a awesome project.
AWS lambda is fun, and I wonder if I can make a host as "lambda server" and deploy a function just like deploy a AWS lambda, then I built https://github.com/metrue/fx 
If you dereference after the assertion you get a `**Node`. Is that what you want?
Yeah, I would also wanna know why because there is a fantastic package called sqlx and it's a low level SQL client that helps manage ORM.
How does it require a 3rd party server? No data is exchanged with a STUN server, that is just to allow NAT hole punching. You can disable it and only use host candidates. You need to do basic research before spreading FUD. WebRTC uses DTLS, again do some basic research. How would you do SCP if you had two hosts behind a NAT? A 3rd party server probably, even if you rent it from AWS/Digital Ocean/.... it isn't your server. 
I'm currently reading building microservices with Go, by Nic Jackson, and am quite liking it. 
I think Google's blog post explains the need fairly well: https://blog.golang.org/wire
Okay, I have some free time so will push something later today.
Usually, there is some cost for learning ORM, and since ORM hide some detail of SQL, it's difficult to debug sometimes, and the project is for learning purposes, I want to expose more details, that's my reason. But it feels free to use ORM, if you are familiar with it. And ORM did some good works too, like avoid SQL injection, optimization, etc. So it depends. 🙂 &amp;#x200B;
Have you checked that the value is 10000 ? I expect that it is not. The program may not crash, but the result may be wrong. 
don't buy this illusion, writes on slices are not concurrency-safe. if you were to write at any point in time, with each goroutine accessing different parts of the slice (and not resizing it) then it is concurrency-safe. (but even here I believe we must be specific about what we really do)
The runtime reserves the right to do thread unsafe things during a map read. It not crashing now doesn't mean it won't crash later. Increment definitely isn't an atomic operation. When I ran it, I got 89536 instead of the 100001 it should have been.
Thanks for your reply, I'm aware of it. I'm just curious why it does not crash the program like the first case
Thanks for the explanation
The reason is most probably because in the first code, concurrent go routine insert an element in the map. This requires allocation and setting the value through pointers. What happens is that the pointer values get mix up and one go routine tries to write or read in the wrong place in memory. This cause a panic and fatal termination of the program. In the second code, only the values are mixed up. The map element is preallocated. So there is no allocation and pointer fiddling by the go routines. They only read pointers value that never change while they run. They all read and write in the same location. There is no opportunity for them to read or write where they shouldn't and cause a panic. The problem you get is that go routines overwrite the computation results of other, and the final value will be smaller than 100000 if this overriding occurs. 
&gt; Surprisingly, the program finishes successfully. Not really. $ cat main.go package main import ( "fmt" "sync" ) func main() { numbers := make(map[string][]int) numbers["foo"] = []int{1, 2, 3} var wg sync.WaitGroup wg.Add(100000) for i := 0; i &lt; 100000; i++ { go func() { numbers["foo"][0] += 1 wg.Done() }() } wg.Wait() fmt.Println(numbers) } $ go run -race main.go ================== WARNING: DATA RACE Read at 0x00c00001c5e0 by goroutine 7: main.main.func1() /home/jnml/src/tmp/main.go:16 +0x8d Previous write at 0x00c00001c5e0 by goroutine 6: main.main.func1() /home/jnml/src/tmp/main.go:16 +0xa3 Goroutine 7 (running) created at: main.main() /home/jnml/src/tmp/main.go:15 +0x17d Goroutine 6 (running) created at: main.main() /home/jnml/src/tmp/main.go:15 +0x17d ================== map[foo:[91674 2 3]] Found 1 data race(s) exit status 66 $
Very interesting. I had no idea we could chain functions in code. I also had a mid size project which I recently ported from single package to multiple sub directory. What helped me is that my main file is in 1st level all others are in 2nd level subdirs. So just think of it as if they are still in the same package but one level below. Must admit that doing this took roughly 1 day and all the time carefully checking that I didn't get the circular dependency error.
Might be useful: https://www.distributed-systems.net/index.php/books/distributed-systems-3rd-edition-2017/ 
Last update 5 months ago.
Agreed. They should be based on purpose.
GO treating it as first class citizen makes me feel so happy. Hehe...
You have to protect any concurrent map access by using a sync.Mutex. e.g. &amp;#x200B; `import "sync"` `type SyncMap {` `mut sync.Mutex` `m map[string]int` `}` `func (s *SyncMap) Set(s string, n int) {` `s.mut.Lock()` `defer s.mut.Unlock()` `s.m[s] = n` `}` `func (s *SyncMap) Get(s string) int {` `s.mut.Lock()` `defer s.mut.Unlock()` `return s.m[s]` `}`
My best tech read from last year, highly recommended
I switched recently from logrus to zap ! I suggest you take a look ;)
I would think that performance/optimization is a reason \*\*not\*\* to use ORM. 
Especially if you know how to use SQL. 
&gt;https://github.com/robpike/filter Well said. 
Is this like elasticsearch?
Does anyone know any articles which compare Bleve and other search engines?
Does the server not know the structure of the data sent to it?
It does.
Generated code does seem much better than runtime injection.
Oh cool - thanks!
My problem with Bleve (and many other text-search engines) is that they only offer ordering/sorting on a single axis. With sphinx I can do complex ranking on more than just a boolean (exists|empty) field. Consider the following order clause that places 5x more value on a documents title than the text (combined with BM25F ranking). ranker=expr('1000*bm25f(2.0,0.75,{title=5,text=1}) I'd love to see elasticsearch, bleve, [sonic](https://github.com/valeriansaliou/sonic) and many others upgrade to more useful/complex sorting options.
I'd suggest that MVC patterns and the package organization doc you linked to aren't mutually exclusive. You can still create models, orchestrated by a controller, and rendered into a view, without having packages called `models`/`views`/`controllers`.
I'm prolly wrong but I think it has something to do with Jon.rawMessage but I guess cause I don't know your context it's hard to say. Like I guess you can store the response body? Technically that's the raw data but not really usable. You could I guess go through the long process of unmarshal to []bytes and then try to reform it and compare? Not really sure why you wanna do that? 
Just to highlight this: you must use -race if you are writing concurrent code and you are still learning. Go omits these checks by default because they are slow but you should use them when learning about concurrency. 
`var x []MyStruct if err := json.Unmarshal(myData, &amp;x); err != nil { // handle }`
Tables in 2019.... Okay...
Ugh. No slide for the bottom line.
It only updates go :/ doesn't it ?
hackernews discussion: https://news.ycombinator.com/item?id=19601798
How does it compare to [Python's magic wormhole](https://github.com/warner/magic-wormhole)?
What a low quality shit-post.
Out of curiosity, and aside from the fact that you didn’t use `go fmt -s` against your code, why do you add the extra curly braces in all functions? func glue_parts(fname string, last_part int) { //{{{ } //}}} Also, why did you make your code dependent on a 3rd-party package called github.com/spf13/pflag rather than using the one provided by the standard library https://golang.org/pkg/flag/ I don’t see you using any special feature from the 3rd-party package, so I wonder why are you adding an unnecessary extra dependency to your project?
https://eagain.net/articles/go-dynamic-json/
SQLite’s full-text search also supports such ranking, IIRC.
Well, yes. There were plenty of solutions for updating other things.
awesome!
The extra brackets are a company thing Vin providers different fold methods syntax folding is the standard one as every editor I prefer using marker folding so I can put folds wherever I want. About pflag, standard flag does not support flag folding and Unix style flags so I always use pflags to support that sort of flags which most people using Linux like myself loves and used to use
The way I'm reading the thread, you're the one taking it personal. I'm not seeing you address any of the points I raise, still don't know what you're getting at, hence why I used the phrase "hand-waviness". Its fine if you don't want to address my points, why bother posting in this case?
ULID provides a type for monotonic entropy and it's non-time-based portion should be sufficient to prevent timing attacks. I wrapped it recently to ensure it's usage would make use of both monotonic entropy, and a reader pool. Further, the wrapper eases usage with databases. It's not really "ready", but should work well. Feel free to contribute or simply use as a reference. [https://github.com/codemodus/uidgen](https://github.com/codemodus/uidgen)
&gt; ULID has millisecond resolution, but that could (very remotely) be used for some variation of a Timing attack. How is this more of a problem than using sandflake or ksuid which also use timestamps? 80 bits of randomness vs 96 bits, vs 24 bits. I would be much more concerned about sandflake due to the lack of fully random space to protect against the timing attack compared to the others.
You are right that sandflake also provides millisecond resolution and should be included. I'm also concerned about the small address space should two machines generate the same worker id. However, KSUID only provides _second-resolution_ which is much less likely (1000x) to provide any information about calculation times. It seems to be the strongest here (but is also 32 bits larger).
[This only works for a single host](https://github.com/codemodus/uidgen/blob/master/uidgen.go#L105) which kind of defeats the point of adding all those extra bits for distributed ID calculations. Maybe I'm missing something, but you don't need a special sync pool for a monotonic clock: https://gist.github.com/Xeoncross/ed34985b3d9d00a87a352f5e7acd61bd
What's your use case or specific needs? That might help narrow down the best solution for you. &amp;#x200B; I use a Twitter style snowflake for cases where I need a unique ID but the things I've done may not be at the same scale as what you're doing. (Granted, Twitter Snowflakes worked for Twitter's scale). I like that the snowflakes are only 64 bits and can be Base58 encoded down to pretty small number of characters. For some purposes that's pretty nice to have. &amp;#x200B; But I suspect it would face the same potential issues as you've described above by having both millisecond timestamp and a machine ID. Depending on your use case though those may both be a legitimate concern or not really something to worry about. &amp;#x200B; I wrote a snowfake library for Go ([https://github.com/bwmarrin/snowflake](https://github.com/bwmarrin/snowflake)) which may be useful, again, depending on your goals :)
 [https://github.com/gofrs/uuid](https://github.com/gofrs/uuid) Supports all 5 variants from RFC-4122. Compatible with the UUID/GUID type in most databases and other systems (Java, .NET, etc)
Wow thanks a lot! My implementation of the concurrent writes was not as complete as yours (didn't implement timeout) but it is good to see I was somewhat on the right track. This stuff is invaluable to me as a learning tool.
I personally have a half-dozen different use-cases. I posted about this to get feedback (like yours) on this topic to provide more information for making choices. In one sense, Twitter ID generation is at a very small scale; they only have +10 nodes generating ID's. This would obviously never work for larger networks like couchDB (is it still around?) and IPFS. Then again, it's also only half the size.
I think most developers would agree, a UUID's main redeeming quality is _legacy support_ with existing systems. New projects can move on.
Can you post an example?
https://github.com/golang/go/wiki/Blogs https://www.ardanlabs.com/blog/ https://golangweekly.com/issues https://blog.gopheracademy.com https://golangnews.com https://forum.golangbridge.org https://www.reddit.com/r/golang/ https://github.com/golang/go/wiki/ResearchPapers https://jgoodall.me/2015/11/17/golang-resources.html https://github.com/astaxie https://github.com/thewhitetulip/web-dev-golang-anti-textbook/blob/master/README.md
Using UUID doesn't really help to address any of the issues with UUID.
it sounds like the OP isn't interested in uuids but in non-standard similar "upgraded" versions with similar entropy but also timestamp embedding. Personally, I prefer either uuid or an incrementing int and want my dates to be separate, and I'm using the library you list here
Ah, okay :) Wasn't sure if you were looking to find a solution for a specific use case or not. Twitter format by default supports 1024 nodes, for what it's worth, and a single machine could easily be multiple nodes. With those defaults you could generate over 4 million ID's per millisecond. Also, with my library you can adjust the bits used for each component should you need more/less nodes or sequence numbers, etc. There's definitely limits, pros, and cons to each approach. I think I'd look at them as tools and try to find the right tool for each use case over trying to find one tool that works in all cases. I'd also aim for simplicity where possible :)
You can use `matchinfo` to give weightings to columns. https://www.sqlite.org/fts3.html#matchinfo
&gt;I would avoid having a folder called src, it's an unusual pattern in go. Can you explain further? I very recently started Todd McLeod's Golang course on Udemy, and he explained that a standard Golang project architecture looks like this: root |--/bin |--/pkg |--/src |--/main.go
[removed]
Keeping identifying information (like dates) out of the ID is certainly a valid requirement (Hello SSN). However, in those cases 100% random bits of X length provide much more security than any of the UUID specs. Even "purely random" UUID v4 wastes bits for upgrade [constants that were never used](https://tools.ietf.org/html/rfc4122#section-4.1).
I probably reasoned through it too quickly; I'll review that portion of the code again soon. The impetus for the pool is the rand.Rand type as noted here: https://github.com/oklog/ulid#usage Maybe I was wrong to structure it the way I did, but it seemed right at the time.
Great, now we just need scaleable, multi-node clustering with multi-core threading for SQLite along with in-memory indexes.
Conclusion was rather boring. To show how each has a different model for concurrency that might be better for some types of work and that even though each has 1 favored model for concurrency you can implement other models using the existing primitives in each. She references the examples in the talk where they implement each ones concurrency in the other. They do mention how implementing Go's CSP in Elixir is more awkward than the reverse. IMO this is because CSP is a lower level concurrency primitive than Agents so implementing Agents in CSP is thus fairly straightforward. IMO once Go has generics an Agent library will pop up pretty quick that encapsulates that pattern.
I believe it's something that the course will get to, but this explains the Go project structure pretty well, including what /src is in Go, and why it's not used in the actual project. https://github.com/golang-standards/project-layout/blob/master/README.md
Thanks very much for the link, I hadn't seen that golang-standards repository before. That's a great resource.
1. Based on the name and example design, this is a Go-clone of Metalsmith. That's not a bad thing! But own it in the README. 2. &gt; In contrast to other generators, Goldsmith does not force any design paradigms or file organizational schemes on the user, making it possible to create anything from blogs to image galleries using the same tool. That's just ignorant. I have made an image gallery, a blog, and a hierarchal information site in Hugo. There's nothing about Hugo that forces you into a particular paradigm.
[removed]
I am familiar with Metalsmith, and I pay homage to it in the name of the tool, but aside from both projects using the "builder" pattern to create a pipeline for processing files, there are many architectural and design differences. I do not see it being more of a clone of Metalsmith any more than Hugo is a clone of Pelican or Jakyll. &amp;#x200B; I have used Hugo in the past, and I have ran into many issues building the site I wanted. I'm glad it works for you, but it was not flexible enough for my needs : )
[removed]
&gt; You have to protect any concurrent map access by using a sync.Mutex. Concurrent reads are perfectly fine.
[removed]
[removed]
[removed]
wormhole is, as you say, in Python. It means you need to have Python installed whenever you want to use wormhole. If it's not a problem on Linux/MacOS, but it may be a bit of trouble for an inexperienced Windows user. I like the fact that Go allows us to statically compile an executable, that you can then drops on a computer and run without any dependencies. Another point is that it's easy to embed into other project (ex: one of my main next goal is to embed gfile in a webpage, via WebAssembly) &amp;#x200B; Also, I'm not using PAKE, and a relay is not needed when a client is behind a NAT. gfile is able to do NAT hole punching thanks to STUN. :)
You mean like https://github.com/rqlite/rqlite ?
Scoring leaves a lot to be desired in Bleve, but we do support boosting of fields for exactly this type of use case. Sorting of results is also quite powerful now, so it would be helpful to understand how else you'd like to sort.
It is a library, not a server/cluster, so a better comparison is the Lucene project which Elasticsearch uses to operate with indexes on the local node.
SQLite is eminently comparable to Bleve, the embedded search engine this is based on.
Even basic support for multiple axes would be great. In other words, results ordered by score, where score = `field1 * weight + field2 * weight + ...`
Nice. Anyone want to spin-up a rqlite cluster to see if matchinfo can handle distributed results in the correct order?
You don't need generics to re-implement Erlang/Elixir-style actors, because the messages between processes are untyped. It's [not that hard to replicate the basics](https://github.com/thejerf/reign), which we did to port something out of Erlang. That includes cross-node communication, too.
Then what is bleve? I thought that was the lucene equivalent.
You've said "multiple axes" a couple of times, but I'm not entirely clear what you're referring to. Do you mean something other than weighting fields independently?
Sorry if I wasn't clear. Bleve is a library, and it is the Lucene equivalent in this comparison.
Awesome work guys, you've just inspired me to start refactoring my own service!
I mean weighting fields together, yet with independent weights. Generally results are only sorted on one field at a time. For example, in SQL you would write `...ORDER BY field1 DESC, [then] field2 DESC`. It's not possible to order by both together with each field having independent weight that can contribute to the overall rank.
Go project one: write an aggregator. 😀
Not using Python for a CLI is definitely a huge plus. I hate having to maintain little virtualenvs.
that is awesome
Oh hey, that's me. Give a shout if you have any questions!
A textual transcript of this would be really nice. The slides are very light on text (as they should be). Cool stuff!
I like this. I have been trying to use the colly library to do something similar for saving image boards to read on road trips.
You can also submit your project for code review on the official Go lang slack channel called “#reviews” if I recall...
So there's a manga downloader, a tool to automatically un-censor hentai, another tool to automatically colour manga pages, and there's even one to double the size of drawings without losing quality. Do we miss anything at this point?
(Direct download link)[https://golang.org/dl/] Minor release. Notes: Fixes an issue where using the prebuilt binary releases on older versions of GNU/Linux (led to failures)[https://github.com/golang/go/issues/31293] when linking programs that used cgo. Only Linux users who hit this issue need to update.
True. I was thinking more of culture where Go devs seem to like their typing and would take better to an actor system that allowed for that.
Fantastically communicated. Thanks, /u/jean_deklerk!
&gt; If it's provable that he's violated the copyrights of others, or is intentionally misrepresenting others, how does his account still exist? No ones bothered to file a DMCA.
How can timing attacks be used against ULID? Can you give an example? [serious]
Normal breast in the hentai
Thank goodness I am not the only one who thinks Hugo is too complicated to use.
Doesn't this justify a major version bump? It seems that the API that the module provides is being changed in a backward-incompatible manner.
Things may have improved since I've last used it, but I couldn't even have my images in the same directory as markdown documents, because that was not the Hugo way. Also, seemingly basic things like [trying to figure out how to get a menu button to light up](https://discourse.gohugo.io/t/confusion-regarding-proper-use-of-menus/1647/10) were incredibly complicated. Don't get me wrong, I think Hugo is a great out-of-box solution if your design ideas align well with it. If that is not the case, it is a bit of a battle.
That's a astute question! I originally had this in the talk, but ended up trimming it out.. maybe erroneously heh. &amp;#x200B; The answer is that you're right! It is super weird to be removing parts of the API surface of a module and only call it a minor. However: &amp;#x200B; \- The entire process doesn't work if you do that because performing a major version bump provides a "new" module. That is, major versions beyond v1 have entirely separate import paths and module import statements. So, instead of fixing users under-the-hood, you're asking them to change all their import paths and their module require statements. And because MVS only performs the max(...) within a major you don't even fix the problem in the old major version, so existing users still end up broken. \- In practice, no user will care. \`go get\` / \`go build\` / \`go test\` etc will notice the change, add the new require statement to your go.mod, and continue along happily without user intervention. So, given the last point, the way I see it is that this is a time to be pragmatic: the process of splitting out modules without hurting your users requires kind of briefly squinting your eyes at the rules of semver.
That's a good idea! I'll send a note to the organizers.
Degenerate.
No, I'm gonna leave it to piss those who takes jokes hard as a dick.
Gotta automate them all together
You’re missing the intermediate certificate in the client file. The client file should include your cert and the intermediate.
Most likely you're using self-signed certificate which is not signed by known certificate authorithy, hence "unknown certificate authority" error. This topic is too large to explain here. Start with https://en.wikipedia.org/wiki/Self-signed_certificate and google "self-signed certificate" and "tls: unknown certificate authority". That'll surface lots of reading material.
It's not so much a timing attack in the cryptographic sense, but just that you're leaking when it was generated. That could be bad, depending on you use case.
I am using the LetEncrypt cert files. Thinking that was what was needed alone. All I can find online are things that use the acme clients to manage certs.
- [You don't need setters/getters](https://golang.org/doc/effective_go.html#Getters) in https://github.com/Girbons/comics-downloader/blob/master/pkg/core/core.go#L47-L80 - Also in core.go, you don't return errors, but just `log.Fatal`, you should propagate errors up generally, and handle them appropriately. Probably just exiting, but still, it's good to avoid `log.Fatal`ing in the middle of your code. `defer`'ed functions do not run when you do this, which causes potential resource leaks (eg: if you create a tempdir, then defer the deletion of the directory). - https://github.com/Girbons/comics-downloader/blob/master/pkg/sites/sites.go#L13 should probably return a `*Comic`, not take one.
thanks moving it up in the queue
(this is me posting in the wrong account 😓)
Maybe they expired. Let's Encrypt certificate are only valid for 90 days. It really is built for auto-renewals and managing certificates for you.
Thanks
I see. Thanks
Yeah, they will cost more sometime
thanks for the suggestion!
Someone write the pipeline [https://airflow.apache.org/](https://airflow.apache.org/)
Seems like an oddly specific use case. I can’t imagine how this would be useful.
I ran into an odd (maybe expected) problem: [https://gophers.slack.com/archives/C9BMAAFFB/p1554787546287500](https://gophers.slack.com/archives/C9BMAAFFB/p1554787546287500)
Unmarshal into a \`map\[string\]struct{ ... }\` type. Use [https://mholt.github.io/json-to-go/](https://mholt.github.io/json-to-go/) for the struct type.
Unmarshal the whole blob into that type or just the commentsById sub-object? I'm still not sure how this is supposed to work. Also, thanks for the assistance.
As long as you write one filter and map function per type, then yes.
Hi! Could be that you just have to change cert.pem to fullchain.pem. See this [stackover](https://stackoverflow.com/questions/37321760/how-to-set-up-lets-encrypt-for-a-go-server-application) question, if you created the certificate with certbot you can just do: http.ListenAndServeTLS(":443", "/etc/letsencrypt/live/www.yourdomain.com/fullchain.pem", "/etc/letsencrypt/live/www.yourdomain.com/privkey.pem", nil) However, what I find a nicer solution is to use nginx to handle my SSL. If you have a server, you can just run your Go API on your server without TLS on some port which is not exposed to the world(e.g. localhost:8080). Now use Nginx as a [reverse proxy](https://flaviocopes.com/go-nginx-reverse-proxy/) where it reroutes traffic to your Go API service which runs on your server at some non exposed port. This means that in your server the traffic is not encrypted, but outside of your server it is. Certbot can [automatically install](https://www.digitalocean.com/community/tutorials/how-to-secure-nginx-with-let-s-encrypt-on-ubuntu-16-04) and renew certificates for Nginx, so you don't even have to manually specify which pem and privkey files need to be used. If you're not sure about the correctness of you pem files you can [decode](https://www.sslshopper.com/certificate-decoder.html) them btw, to see what information is stored in them.
Data as a map of string -&gt; struct. The string is the random key and the struct is the sub object
In the end I wrote a little NodeJS Typescript stateless server (with a cache though) Docker image that loads javascript and spit out HTML. It's at https://github.com/qdm12/htmlspitter The idea is to simply spawn more containers if you need to scale up.
Can you remind me the tool for coloring please? I know the others but can't remember about this one
Maybe something that redraw from bad quality scan?
commendsById as a map of string -&gt; struct?
Add some print times at various places in the code. My guess tho is it’s how you are handling adding words. Append will, upon the slice being over capacity, allocate a new array, copy all the existing elements, then add the one new one. So it’ll be doing that on append if each new word. That’s not really efficient. There may be other ones but that’s the one that stands out to me.
Would you please point me to these tools please? I am really intrigued.
It's easy to achieve that manually, I have a pattern I use with DI where I only have constructors in one place, and the compiler tells me if I'm missing anything. On mobile now, but I wrote a post about it a while back. I'll link it later.
I thought of this and used a version without the append, see the edit up top.
Have you tried just doing a println instead of invoking the printf formatter, just like in your Perl script?
Using fmt.Print*f* is overkill if you do not do any formating. Also buffer your output to stdout. And if you wanna go fast: work with []bytes instead of converting to and from string.
From [the issue](https://github.com/golang/go/issues/31293): jasdel: With Go 1.12.3 and 1.11.8 I'm still running into this issue with a slightly different error. jayconrod: "Yep, this still seems to be happening. Same error with the original repro instructions."
I tried this and it sped things up a LOT: ofile, err := os.Open(os.Args[2]) if err != nil { panic(err) } defer ofile.Close() for _, a := range words { for _, b := range words { fmt.Fprintf(ofile, "%s%s\n%s %s\n", a, b, a, b) } } Before: real 0m2.714s user 0m2.039s sys 0m0.744s After: real 0m0.207s user 0m0.178s sys 0m0.093s For benchmarking, your perl code on my laptop: $ &lt;pass.txt time perl double.pl &gt;/dev/null 0.24 real 0.23 user 0.00 sys Looks like it may just be stdout that's the culprit.
This is a great intro, been messing around with wire myself and impressed so far. With less boilerplate code I find myself breaking things up more.
Thanks for the review! I'm going to make that changes as soon as possible
I didn’t know that, thanks!
Doing a test of this approach I've hit another problem. I'm loading the list into a \[\]\[\]byte and ranging over it. \`\`\` w := bufio.NewWriter(os.Stdout) for \_, a := range words { w.Write(append(a, 0x0a)) } \`\`\` When I get to a specific entry in the list, it skips a character and adds a newline. I've checked the bytes making up the entries in the words \[\]\[\]byte and they are OK. The output then gets littered with random new lines, as though when it's flushing, the underlying writer is adding a newline of it's own?
bufio speeds things up a lot, but IMO only because there's something fishy going on in the runtime. I'm seeing 84% of cpu time being used in runtime.pthread_cond_signal: flat flat% sum% cum cum% 260ms 83.87% 83.87% 260ms 83.87% runtime.pthread_cond_signal /usr/local/Cellar/go/HEAD-7b62e98/libexec/src/runtime/sys_darwin.go:371 20ms 6.45% 90.32% 20ms 6.45% runtime.(*mspan).refillAllocCache /usr/local/Cellar/go/HEAD-7b62e98/libexec/src/runtime/mbitmap.go:180 10ms 3.23% 93.55% 10ms 3.23% fmt.(*pp).doPrintf /usr/local/Cellar/go/HEAD-7b62e98/libexec/src/fmt/print.go:966
In Go, Stdin, Stdout and Stderr are not buffered. Which means, fmt.Println does a syscall every time. Use bufio to wrap Stdout will likely improve the result greatly.
If you have any control over the JSON, \`commentsByID\` should be an array, with each item within the array being an object containing the 6 fields (\`id\`, \`rowId\`, \`userId\`, \`text\`, \`createdTime\`, \`lastUpdatedTime\`). Apart from being a rather bad JSON object, you can't know the name of the comment objects without prior knowledge or looking inside for the \`id\`.
My comment [https://www.reddit.com/r/golang/comments/bb4sgb/go\_vs\_perl\_simple\_task\_speed\_comparison/ekghltt?utm\_source=share&amp;utm\_medium=web2x](https://www.reddit.com/r/golang/comments/bb4sgb/go_vs_perl_simple_task_speed_comparison/ekghltt?utm_source=share&amp;utm_medium=web2x) has an attempt to use buffered IO with stdout, but I'm having more issues :/
Thanks. I didn't know we can unmarshal an entire array too. Do you know if it's possible to do the same thing using gob package?
I've never actually used the gob package so no
Maybe something like this: type Document struct { Msg string `json:"msg"` Data struct { CommentsByID map[string]Comment `json:"commentsById"` } `json:"data"` } type Comment struct { ID string `json:"id"` RowID string `json:"rowId"` UserID string `json:"userId"` Text string `json:"text"` CreatedTime time.Time `json:"createdTime"` LastUpdatedTime interface{} `json:"lastUpdatedTime"` }
You're not flushing, also you can keep it simpler, with strings not [][]byte, see below. Your *only* major difference was buffering, not anything else. (it gets more obvious once you add **$|=1;** as your second line, under the shebang, in your Perl code). w := bufio.NewWriter(os.Stdout) for _, a := range words { for _, b := range words { w.WriteString(a + b + "\n" + a + " " + b + "\n") } } if err := w.Flush(); err != nil { panic(err) }
the problem here is that the scanner reuses the buffer, and you're not making a copy of it. From the docs, &gt; The underlying array may point to data that will be overwritten by a subsequent call to Scan. so you need to copy it (cheapest way to copy it? call `.String` :-) )
I'm still building this but the map[string] interface {} is what you are looking for. They use it right in the go blog. https://blog.golang.org/json-and-go This I'm trying to put it into types each field. Some think it's pointless cause you have to save it to a database but I like the idea of slice of type per field. https://play.golang.org/p/4YvUFmYjemO
&gt; Login or register to see the full job description! Fuck off!
This was actually not worth watching.
&gt;Go doesn't provide automatic support for getters and setters. *There's nothing wrong with providing getters and setters yourself, and it's often appropriate to do so*, but it's neither idiomatic nor necessary to *put Get into the getter's name*. If you have a field called owner (lower case, unexported), the getter method should be called Owner (upper case, exported), not GetOwner. The use of upper-case names for export provides the hook to discriminate the field from the method. *A setter function, if needed, will likely be called SetOwner*. Both names read well in practice:
This is exactly what I was looking for. Thanks greatly.
It's not expired generated it like 2 days ago. The answer was given by /u/wimh4l [here](https://www.reddit.com/r/golang/comments/bb1ngm/questions_on_using_letsencrypt_certs/ekgal9q/)
This is awesome. Someone should write a comic reader in a golang native gui library and just use your pkg code to load up comics. Automatically store them as cbz in a simple directory system.
&gt;github.com/Girbon... `a tool to automatically un-censor hentai` will it be possible to use the same approach to implement a photo application that automatically removes filter or makeup from a photo?
Yep, this is the right approach. CommentById just needs to be read as a map\[string\]struct. Probably LastUpdatedTime can be changed to time.Time as well if its also a timestamp. &amp;#x200B; If a separate struct for Comment is not desired, it can also be written as bellow type Document struct { Msg string `json:"msg"` Data struct { CommentsByID map[string]struct { ID string `json:"id"` RowID string `json:"rowId"` UserID string `json:"userId"` Text string `json:"text"` CreatedTime time.Time `json:"createdTime"` LastUpdatedTime time.Time `json:"lastUpdatedTime"` } `json:"commentsById"` } `json:"data"` }
That escalated quickly.
I kind of scrubbed through it quickly, but missed the point of that talk? Was it a political, social statement, a tutorial, or what?
You need to do $¦++ at the top of the Perl program to disable buffering. I'm surprised nobody has mentioned it.
Sqlx is not an ORM, its just a bunch of very useful helper functions around raw sql
I wonder if it would be worthwhile to make a comic book _reader_ in golang as well. Could be a good experiment with the Fyne gui library.
&gt; I suspect theres something really slow inside the fmt package thats making go really slow when writing There is. `fmt` functions take `interface{}` and use reflection a lot.
Thanks for the talk!!
I vendor my dependencies and keep my checkout outside of go path when working with go modules, this path has proved fairly painless so far.
of course; but the problem is that I can't find a REPL to support our go.mod files. Instead, they want to import stuff from GOPATH and the migration seems painful. I would love to find a REPL with support for vgo. Or painless migration back to dep/GOPATH.
I guess it was a demo of creating an application in Go to create 3D model files to be printed. Existing solutions we're had because they were written in*gasp* JavaScript.
Lost me at “installing a vagina”. Not that I’m not interested or not ok with that, but it’s so far off topic and forced, it’s cringy. Forcing an unrelated subject in to a tech talk just because you have a mic.
Anyone with a reply? I’m curious
https://github.com/campoy/whispering-gophers
Perhaps it's oddly specific because most engines don't support it. Almost all applications have to create a composite field... because that's the only choice. To explain, imagine these very reddit comments. They have a "score" made up of date + votes. Since we can't sort by `dates * weight + votes * weight` they have to create a composite key "score" which can be used. Now, pre-calculating this is *small* value is easy and faster anyway, but imagine a larger text/byte blob. In the example I gave originally you might want to give more value to results with a keyword in the document title, but still include results with the keyword in the document body. Now, you could duplicate both into a new `title_body` attribute, but even then you can't add 5x the weight to the title for sorting.
I just klicked on the video, scrolled trough a little bit and instantly closed it. I'm convinced this talk single purpose was to shock the audience and get some audience, nothing more.
Are you interested in plaintext streams, binary streams, JSON, XML, REST, RPC? All of these send and receive messages. To be fair, regardless of your answer, I’m going to suggest a combination of JSON and ProtoBuf/gRPC.
I'm sorry that I don't have time to provide an in-depth response here, but I do have a project that is available in githuib that you can look at for help: [https://github.com/adamcrossland/rolld](https://github.com/adamcrossland/rolld) It is a server application that receives WebSocket connections from n different clients -- an HTML/JS client is included -- processing inputs and sending back responses. It uses goroutines and channels to manage many separate sessions, a session being a group of connections that are participating in shared messaging. You can see it in action at [https://rolld.net](https://rolld.net) It is meant to be a tool for folks playing D&amp;D or similar RPGs remotely. It rolls dice and allows every to see the results of the roll. Kinda dumb, but it suited a need that I had.
oooh .. that's bad.
This is great, and works well. Another comment mentioned not converting to and from strings, so is there anything about why calling the .Text() ends up being cheaper?
By directly assigning to the struct fields. These are all simple assignments, no need for setters. This isn’t Java.
Not much "distributed" about relying on a central server.
well, it's probably a tiny bit slower (I couldn't measure a difference in speed, but it might be); but reading and writing the code is slower: instead of a := scanner.Text() you'd have to do abuf := scanner.Bytes() a := make([]byte, len(abuf)) copy(a, abuf) or a := append([]byte(nil), scanner.Bytes()...) and while the first one is obvious, the other two need you to stop and think about it. Which is fine if it makes a big difference to performance, but it doesn't...
I am sorry but I guess I didn't make my query clear to understand. I edited my post a bit, can you read it again?
Hi, [Here](https://play.golang.com/p/nzZbq55ue_M) you can find a sample on how you should approach this. I put also some comments to make that understandable.
Hey thanks for taking the time to write the whole code but it didn't work correctly. The program just finished executing without doing anything.
Ah, my bad. I probably misread it in my just-barely-awake haze. Now I’m out of time this morning.. I hope someone comes along and offers a hand.
Sorry, I missed the \`wg.Add(1)\` calls. You can find the fix in [here](https://play.golang.com/p/hSuAhjwutpb).
I mean, probably. Nvidia can transform a sketch into a photorealistic scenery, it's not so fast-fetched at this point.
It worked. Thank you very much. If it's not much trouble, can you tell me where to learn the concepts you used to fix my code. I have tried searching but I get lost in so many things such as channels, mutex, sync etc. that all focus on concurrency/multi-threading.
It's fine. I got the correct answer from u/zetttaa .
Text is cheaper if you can reuse the byte slice. In your case, you need the whole thing to get into memory, so you can’t reuse it.
Thats a great idea. The problem is that I’m really bad at designing UI lol
Exactly, in my case there is no need to use setters at all.
First of all, I would recommend to you to take [go tour](https://tour.golang.org/welcome/1) for a spin, and for your specific need, [this particular section.](https://tour.golang.org/concurrency/1) As I can see, [this](https://medium.com/rungo/anatomy-of-channels-in-go-concurrency-in-go-1ec336086adb) covers most of the things that you should scrape in order to get a better understanding on how goroutines/channels/waitGroups can/should be used. Another place (also where I am going every time when I need some clarifications), is the [Golang Official docs](https://golang.org/doc/). This contains truly comprehensive content and really pragmatic examples. But I recommend using this only later after you got some knowledge and you are pretty comfortable writing go.
Can I ask why you linked to something that redirects to a Github repo, rather than the Github repo?
Sorry, I thought it would be interesting to use a link created by the web application itself. Should I just link the GitHub repo directly?
If you want feedback on the code, I would say yes.
Cool, thanks for the advice :) Will re-post since I can't seem to edit it
Lolz
With buffered IO and concat'ing the string, I got the time to be equal. Here is the revision , and then the results and how I used `go tool pprof` to figure out where the lag was. &amp;#x200B; [https://gist.github.com/tonymet/6dec6bd8acb816f946b823af1f780035](https://gist.github.com/tonymet/6dec6bd8acb816f946b823af1f780035) func main() { bufStdOut := bufio.NewWriterSize(os.Stdout, 1000) defer bufStdOut.Flush() file, err := os.Open(os.Args[1]) if err != nil { panic(err) } defer file.Close() words := make([]string, 0, 1000) scanner := bufio.NewScanner(file) for scanner.Scan() { words = append(words, scanner.Text()) } for _, a := range words { for _, b := range words { bufStdOut.WriteString(a + b + "\n" + a + " " + b + "\n") } } } &amp;#x200B; **Results** ➜ time perl hasher.pl 10-million-password-list-top-1000.txt &gt;/dev/null perl hasher.pl 10-million-password-list-top-1000.txt &gt; /dev/null 0.26s user 0.01s system 98% cpu 0.270 total ➜ time go run hasher.go 10-million-password-list-top-1000.txt &gt; /dev/null go run hasher.go 10-million-password-list-top-1000.txt &gt; /dev/null 0.26s user 0.12s system 134% cpu 0.282 total &amp;#x200B; **PProf** Used [https://github.com/pkg/profile](https://github.com/pkg/profile) for easy `main()` profileing go tool pprof -text ./hasher $p|head -n 9 File: hasher Type: cpu Time: Apr 9, 2019 at 9:15am (PDT) Duration: 515.49ms, Total samples = 310ms (60.14%) Showing nodes accounting for 310ms, 100% of 310ms total flat flat% sum% cum cum% 280ms 90.32% 90.32% 280ms 90.32% syscall.Syscall 10ms 3.23% 93.55% 10ms 3.23% runtime.acquirem (inline) 10ms 3.23% 96.77% 30ms 9.68% runtime.convT2Estring
With a build binary the results in go are much better only **90ms vs 270ms** time ./hasher 10-million-password-list-top-1000.txt &gt; /dev/null ./hasher 10-million-password-list-top-1000.txt &gt; /dev/null 0.09s user 0.02s system 98% cpu 0.112 total
Are you connecting directly to the go server or are there one or more proxies in the middle? This could be limit anywhere in the chain.
I was just chatting to folks on the Gophers slack the other day about how Hugo seems to have jumped the shark. It used to be great, but it keeps getting more and more complicated. Every month or two I have to add some more junk to my config, yet things which ought to be trivial (like producing an Atom feed) are still painful.
[removed]
Downloaded the samples to give it a try, and the build is failing: # github.com/FooSoft/goldsmith-components/plugins/markdown ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:27:15: undefined: blackfriday.HTML_USE_XHTML ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:28:3: undefined: blackfriday.HTML_USE_SMARTYPANTS ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:29:3: undefined: blackfriday.HTML_SMARTYPANTS_FRACTIONS ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:30:3: undefined: blackfriday.HTML_SMARTYPANTS_DASHES ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:31:3: undefined: blackfriday.HTML_SMARTYPANTS_LATEX_DASHES ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:33:19: undefined: blackfriday.EXTENSION_NO_INTRA_EMPHASIS ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:34:3: undefined: blackfriday.EXTENSION_TABLES ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:35:3: undefined: blackfriday.EXTENSION_FENCED_CODE ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:36:3: undefined: blackfriday.EXTENSION_AUTOLINK ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:37:3: undefined: blackfriday.EXTENSION_STRIKETHROUGH ../../../go/pkg/mod/github.com/!foo!soft/goldsmith-components@v0.0.0-20190407224219-de02c75c0333/plugins/markdown/markdown.go:37:3: too many errors Also, might I suggest switching to [CommonMark](https://gitlab.com/golang-commonmark/markdown)?
Just one `/^var ` per file? That's too opinionated. Splitting methods far from types is the opposite of readable.
Ah right! That would be it.
Looks neat! Haven't check the code but I think it's really nice!
Is this maybe a vendoring problem? The build definitely works on my machine (tm) after getting latest, and it seems like it should work for everyone. &amp;#x200B; The first error in that list is me referencing a constant in blackfriday: [https://github.com/FooSoft/goldsmith-components/blob/master/plugins/markdown/markdown.go#L27](https://github.com/FooSoft/goldsmith-components/blob/master/plugins/markdown/markdown.go#L27) As you see, the constant is indeed inside of blackfriday, here: [https://github.com/russross/blackfriday/blob/master/html.go#L39](https://github.com/russross/blackfriday/blob/master/html.go#L39) &amp;#x200B; I'm definitely open to switching to CommonMark, it's just when I wrote the plugin, blackfriday seemed to be the most popular markdown processor out there. Is CommonMark just objectively better?