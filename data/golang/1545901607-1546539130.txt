How about grpc-web-gateway?
I haven't ever run into a library need in Go that wasn't met. I write the most C#, but even a project working with Active Directory wound up great in Go once I realized I would be using raw LDAP queries either way anyway since I needed to use a lot of custom fields.
because its not OOP in the same way structs and void pointers didn't make C object oriented... not that I cared.
well, when the community isn't one nutcase posting a link with no explanation and is able to form a coherent sentence, I'll listen. But thanks for your advice, it makes you look like a brown-noser infront of the "community"
In the websocket upgrade handler you use a cookie to identify the user, and go from there The cookie is usually the session cookie that identifies the users login session that contains any information you need
That's how I'm doing it. The thing is, I also save conversatins to database (converstation id and participants). After user sends a message, should I select user ids from database and loop through them or how else would you do it?
Have you tried running the application with the default config? After several errors and fixes of the config, it starts without errors, but stops immediately.
nope
awk and grep have decades of optimizations. You'll have a hard time writing something from scratch that can compete with them. And then there's full text search engines which is magnitudes faster than awk and grep for large amounts of text but it comes with some constraints. Take a look at https://blevesearch.com
&gt; Just push code into master branch through pull requests. Even though you were the only contributor, It makes your project look more professional. ü§î
It works perfectly fine for me
That's my point of view, I meant to do a pull request other people can give their opinion about your code
When was the last time you opened it?
[It isn't go](https://i.imgur.com/VdRf7Ci.jpg)
Lol I completely missed that. In my mind, I was sure it was not go but I completely missed that. Thanks!
 That‚Äôs php
https://i.imgur.com/yto6HZ9.jpg right after you asked
Good libs tend to be a lot more valuable than frameworks over time in my opinion. Frameworks tend to become legacy after a few months and often require a complete rewrite of the application Frameworks just feel like a huge bet. Like some others have mentioned, you don¬¥t need a framework for something simple, and it makes sense in my mind to not start off with a structure scaled for a hundred services when you just write one. When you write your 100-services, morph the code into GraphQL ... maybe the framework won¬¥t fit anyway. Here is some good code that has been maintained since the 1970s: [http://git.savannah.gnu.org/cgit/emacs.git/tree/src](http://git.savannah.gnu.org/cgit/emacs.git/tree/src) &amp;#x200B;
It's just me then, thanks.
I suppose you forgot to post the link.
Docker has an API, you might as well use it instead of grepping stdout.
I'd question that too, but only on the argument that it makes you look more professional. I find value in pushing to master via pull requests, even if I'm the repository owner, because I can document changes as I go through GitHub's pull requests. It's a recent change I made to my process because by just asking myself to use pull requests I feel more compelled to write about my changes. As an added bonus, it gives me an opportunity to review my changes as if I weren't the writer. I sometimes notice problems with my code that I can then fix before merging.
Indeed. Anyone who thinks I am "unprofessional" from looking at my commit history I probably want to avoid working with anyway
Is it possible that you are travelling to a country that is affected by US export restrictions (e.g. Iran)? Unfortunately Go pages aren't reachable from these :(
If it involves payments you want type safety. Golang has it, JS doesnt
No I'm not traveling. I'm still in the same location I was when I visited it few weeks ago. If there are any restrictions I guess they were put in place recently.
.NET is experiencing a sort of renaissance with the new .NET Core. It's a first class citizen in the world of Linux development platforms now.
I don't know about making you look more professional, but I do think that it makes it easier for others to contribute to your project if anyone wants to and it gives you one more step of "Is this REALLY what I want to do?" which I like.
If only there would be a way to check if hosts are down for everyone or just you... 
I agree. Most languages are multi paradigm and I never like to say I have to do things a certain way just because of the language. I‚Äôm not sure when inheritance became a ‚Äòbad practice‚Äô as it is always the right choice when you absolutely need it. I think that‚Äôs a misunderstanding of ‚Äòfavoring‚Äô composition over inheritance. All that means is while we try to lean toward composition, when a situation calls for inheritance we use it but not until that time. We don‚Äôt just go writing a bunch of classes that use inheritance just because. Don‚Äôt worry about the people that take hard stances and don‚Äôt allow for things to be flexible the way the creators intended. Those people will argue with you until they are blue in the face that it is the way they insist and allow no wiggle room. Happy coding!
Nice article. My biggest takeaway was discovering [TiDB](https://github.com/pingcap/tidb): a distributed SQL database server that's written in Go and is compatible with MySQL.
As I said, if you stick to widely used tech like Elastic and MySQL you won't find Go's libraries limiting at all. In terms of server cost, while Go does indeed tend to be less resource heavy than the JVM, code quality matters a lot more than the language itself does. Frameworks, I've personally used Gin and think it follows the Go language philosophy quite well. Especially since its API is very much like stdlib you'll find that porting to something else in the future (should that be needed) would be rather simple. 
if you go with JS then use typescript, but i would recommend using golang for the server, super minimal, and the docker container, if you use them will be super small.
When you use `dep`, it scans your project‚Äôs go files for imports and instead of downloading them to your `$GOPATH` like `go get` would, it stores them in this special `vendor/` folder. Starting with go 1.5, `go build` will check for the existence of a `vendor/` folder and use this to resolve imports. `dep` is just a tool for managing your dependencies on other go packages. I won‚Äôt go into detail on why such a tool is useful, but you can read more about it by Googling. 
Thanks for the reply, but how do I import whatever files inside the vendor folder? Like I need to import gqlgen/cmd; how would I accomplish this?
https://golang.github.io/dep/docs/daily-dep.html 
[Read the dep documentation](https://golang.github.io/dep/docs/daily-dep.html#using-dep-ensure) 
It happened for me to require a structure of files and directories as a project skeleton. I created this tool to make it easier. It works like git stash - but in a generic way and not necessarily inside a repository. There were many ideas that never got implemented (maybe because I did not need them!), but I thought somebody
The same way as you would without using dep. Really. Just forget you're using dep while writing the code. Just remember to dep ensure before checking in or making a production build.
If you do payments right, the critical info should never hit the backend. Store only the customer's payment provider token, let the payment provider handle the rest.
There is no need to use any web framework. You can use needed libraries and setup your code as needed. I have done similarly by writing boiler place code which helps with all kind of go apps without any framework. Do check this: https://github.com/MiteshSharma/go-project
Or a good decimal package, unit and/or functional tests... But yes, Golang is a good choice.
Very cool idea. Would be useful in a corporate environment. I think the only thing missing would be some sort of godoc integration, especially for private / behind firewall repos that are common in such an environment. 
The following code I‚Äôve written in the screenshot isn‚Äôt working. 
Go for go
Procedural is more accurate
[https://imgur.com/a/dpXYlHc](https://imgur.com/a/dpXYlHc) &amp;#x200B; Heres the result
By most people's definition of framework, Go's standard library provides a framework for building web applications. You don't necessarily need to use it, but you'd probably be crazy not to leverage it in some way.
It sounds better if rephrased as ‚ÄúEven though you‚Äôre the only contributor, make sure your changes go through code review just like anyone else‚Äôs contributions.‚Äù
https://downforeveryoneorjustme.com/godoc.org
Well thanks for this
Fascinating. How does Photo Prism compare to Perkeep or Upspin? Narrower focus, of course. 
that's a good point, and there are whole schools of requirements-gathering people out there who specialise in gathering requirements so that engineers can do their thing perfectly first time. There's only two problems with that approach: 1. It doesn't work. What people say they want is different from what they actually want. To find out what people actually want, you have to give them a prototype of the thing and see how they use it. 2. It's not cost-effective. It's all based on "engineering is expensive, so it's cheaper to do more design and less engineering". That's no longer true (despite the six-figure salaries). It is actually cheaper, in all the ways, to write one version as a discovery prototype, and then write it again properly with decent information. As Fred Brooks said decades ago: "you're going to throw away the first version anyway, you might as well plan to do it". The whole of the Agile software movement has been against this idea that there is a Design Phase where the system is perfectly designed, and then an Implementation Phase where it is perfectly engineered. That is know as the Waterfall Model, and it has been proven over and over again to not work. Agile does work, and a big part of Agile is iterative development, where the team builds simplified prototypes of the thing, and then rewrite or extend them as needed. Discovery (of both the customer requirements and the problem domain) is *part of the development process*, and trying to not make that true is a painful road to project failure.
Go's dynamic linking supports this; not sure how this pans out for wasm targets. Also not sure how effectively browser caching would support this. For example, the same program might run equally well with Go 1.6 and Go 1.7 runtimes, but if Go 1.7 is cached and the site wants to ship with Go 1.6, the browser probably has no way to know that the 1.7 version is okay. This could even apply to the exact same version of the runtime compiled with ever-so-slightly different options (or for all I know, even compiling with the same options might produce a binary artifact that is not bit-for-bit identical).
Hello /u/prf_q - Thank you for your comment. Actually, "thumbai" is a flower name (https://en.wikipedia.org/wiki/Leucas_aspera) from my hometown. I have described the project name and reference to Wikipedia on about page https://thumbai.app/about
Hello /u/zelenin - Yes, I have tested it on macOS and Linux environment. Could you please provide an inputs (step you have followed, etc)? or you could guide me for updating/improving documentation. Actually, following https://thumbai.app/docs/get-started reference, I believe user get THUMBAI up and running. With your inputs I could fix or improve THUMBAI for final v1.0.0 release. Looking forward to your response. Cheers, Jeeva
I live in bay area. Just go with python. People only use `go` for gluing existing python. The interviewer probably know more about python than `go`. For me, i am better at `go` than in `python` but that makes you "not a good fit". There's a saying, how do you know someone is a `go` developer? they will tell you. 
Hello /u/jediorange - Thank you for your appreciation. I got the basic gist of your thought. Could you please explain bit more from your thoughts, I could implement it before the v1.0.0 release? Cheers, Jeeva
Well, the problem I have at work is that our private code can‚Äôt be accessed from godoc.org. Ideally we could view the code documentation from a central website (just like godoc.org). Since this is already getting the code and caching it, it seems like the godoc content could be rendered as part of the web page. 
First, screenshots of text are annoying. Just post text if it's small or a pastebin if it's larger or formatted. Second, it looks like the initial gqlgen/cmd package hasn't been cloned to your GOPATH (or module cache) yet. Because you are probably operating from within your GOPATH location, go 1.11 is looking there for the dependency. Try running go get github.com/99designs/gqlgen/cmd 
Hey I got it working couple minutes ago! Thanks so much for the help! And i won‚Äôt post screenshots next time, thanks!
I'm not 100% sure but it is one of my favourite things about Go ... Especially coming from node.js where u can't print hello world without 15 imports ( not bashing node just not my cup of tea)
&gt;Even though you‚Äôre the only contributor, make your changes go through a code review process just like anyone else‚Äôs contributions. Completely agree, I just made the change, thank you so much for feedback and advice
I don't think it's that so much as it is a combination of Go's relative immaturity and the lack of a good package/module manager. The Go ecosystem is still very young, and there are a lot of competing solutions for any given problem. None of them solve everyone's solutions perfectly, so it's natural that people would build and publish their own itch-scratching solutions. This is further exacerbated by the "a little copying is better than a little dependency" ethos. Go fundamentally encourages you to "roll your own" with the pieces you need rather than taking a dependency on other projects. This naturally leads to a a lot of homegrown solutions. Finally, the lack of a standard package or versioning manager means that taking dependency on external projects is somewhat perilous. You more or less are expected to vendor static snapshots of your dependencies and ship them in your source tree. Simply declaring a Github import doesn't make any guarantees about what version of the code you're getting, and it could well be that your project which builds fine today is broken tomorrow because of an upstream change. There are tools like dep which do attempt to address this, but they're hardly standard in the ecosystem yet. As a consequence of the lack of good package management, transitive dependencies basically just don't happen. This can be a good thing - look at the mess that is any node_modules directory sometime - but it also means that it's more difficult to build up a project on top of other projects, layer after layer. The alternative is naturally grow-your-own.
Awesome! Good luck! 
Every 3rd party package you use is another dependency that has to be tracked and managed. Go is a little bit more biased towards doing things yourself and avoiding yet another dependency (IMO anyway).
Third party dependancies often become a huge headache in the software application lifecycle. It may appear to save you time up front, but done properly you need to first audit the code or ensure someone you trust has done so, determine if the third party dependency has an active developer and user community, join and monitor that community for security issues and changes that may break your application, and eventually convince your organization to support the external dependencies development in some way. &amp;#x200B; A solid standard library is a big deal.
In case you didn't know, you can lookup all go documentation in your terminal, eg. - `go doc strings` - `go doc fmt.Printf` - `go doc github.com/gorilla/mux` I'm pretty sure it doesn't do a lookup for packages you already have in your GOPATH.
Yeah, but headache which is usually worth the price. But I suppose Go's lack of reliable dependency manager makes that price extra high. I think I kinda get it now.
Depends. If you are looking at very well established dependencies that do something extremely complicated, then yes. A database or cryptography library for example. If you took a random sample of open source go libraries on github, the overwhelming majority are hobby projects that should go nowhere near your production code unless your going to take it under your wing, in which case you should just implement it yourself in an idiomatic way.
Seems like modules invalidate (or will invalidate?) much of your post, no?
I certainly hope so!
Can you give an example? This isn't ringing any bells with me. In particular, if you ask about session libraries, you'll probably get directed toward the sessions module in the [github.com/gorilla](https://github.com/gorilla) project. If you want markdown, you'll get sent to [github.com/russross/blackfriday](https://github.com/russross/blackfriday). If you want a \`min(int, int) int\` function, then you'll probably be told to write your own \`func min(a, b int) int { if a &lt; b { return a }; return b }\` instead of taking on a dependency as you would in Node.
Modules seems to fix the dependency management problem, or at least put Go well ahead of most other programming languages.
I think you show that more pronounced skepticism I was referring to in my original post. Nice to have you on board! I think I get where you're coming from, however, I must note that I think that the problem you're referring to is partly caused by lack of widely adopted dependency management tool so it's not really an argument against dependencies, it's more of an argument for proper tools to make that option available. Because there is no other way to ensure, that reliable, well known in community and widely contributed open source packages would come to life. If you want something to become better and perfected you have to open up to the collective brain power of it's users. Look what happened to PHP after composer? It was laughable and rather hacked in / baked language with very messy practices risen to one of the best languages for rapid development of web applications. Symfomy, straight Java Spring port. Laravel which is liked even by people who do not like php (Rails like web framework). ORM's like Doctrine (Entity Framework / Hibernate like). I can go on and on about time tested proven open source solutions which made entire ecosystem of much high quality as a result. Don't you think Go would benefit from a high quality dependency manager too? If no, what think makes Go a different language, perhaps there is something important that would be lost? From where I'm standing I can't see it.
It's not a question regarding specific technical implementation I need help with. I'm reasonably fine on that front, although I have trouble with code duplication which it seems Go community is rather fine with, which was a surprise, given that developers in general aren't people who like to repeat themselves over and over. In turn I found out about the state of dependency management or lack there of and some hints on where the entire ecosystem is heading, which was interesting. Although I appreciate your attempt to help, here have a point!
Regarding dependency management, check out Go modules. I've found that they dramatically advance Go's dependency management story to the cutting edge. Regarding duplication, most programmers falsely believe that dependencies are free; Go's philosophy correctly realize that the cost of dependencies is nonzero, so for small units of code reuse, "copy" is cheaper than "depend". Hopefully this provides the clarity you're looking for. :)
Opinion: it has nothing to do with the "package manager". Exhibit 1: Dependencies are adopted when imported, like a puppy. Each one (if you are doing engineering) must be taken care of. Exhibit 2: Go doesn't depend on libc (well, except for networking on some systems). Not only is the executable make system calls directly, it also tends to not shell out for functions. This is a runtime issue, but the mindset is similar. Exhibit 3: Go doesn't really support map/reduce. If you need to loop, use "for". This tends to result in slightly more words on the page, but arguably more maintainable as the maintainer adds in additional conditions and sanity checking. Do look for existing packages/modules when looking for an HL7 parser. Don't look for an external package for looping over an array. Let me turn your question around on you: why do many JS projects have literally thousands of dependencies? Can anyone from engineering actually read and validate those or is there a mindset that auditing dependencies don't matter? I'm all for external packages, but each external project needs to be reviewed, just like internal code. So if I'm faced with 10 lines of code I write vs 100 lines someone else writes, I'll choose the 10 lines I write. 
Just about to query the search engine about it. I'm not expecting something like npm or gem given all the monoreppish like Go workspaces. However providing some sort of dependency control tools for end user would be nice even given what you say is true, which it is. I just think that in many instances the cost and risk can be mitigated to a reasonable price for a trade off. Just coming from languages which usually had well establish dependency managers is not as easy to get one's mindset on that path. Although I would be thrilled to see Go do it in it's own way.
&gt; Exhibit 1: Dependencies are adopted when imported, like a puppy. Each one (if you are doing engineering) must be taken care of. It's never a problem of adopting dependencies. It's a problem of controlling them. That stands true no matter the language. While I see the general philosophy of Go seems to be a powerful force here, I think that this common problem which seems to be widespread no matter the language plays huge part. &gt; Exhibit 2: Go doesn't depend on libc (well, except for networking on some systems). Not only is the executable make system calls directly, it also tends to not shell out for functions. This is a runtime issue, but the mindset is similar. You'll have to pardon me. I'm quite lost on what you've tried to suggest here. I suppose what you've tried to say is that Go as a language is very well isolated from it's surrounding environment, like OS it's running in? I'm not sure how's that related to dependencies, we are talking about Go code. &gt; Exhibit 3: Go doesn't really support map/reduce. If you need to loop, use "for". This tends to result in slightly more words on the page, but arguably more maintainable as the maintainer adds in additional conditions and sanity checking. Not following. How is this related with dependency management?
I‚Äôm fine with single binaries, and Go is a great language for that. Installing a new version of Gitea is ridiculously simple. Not sure I follow the whole ‚ÄúUse Go everywhere‚Äù philosophy though. Had this been a desktop app, like Lightroom or Aperture, I could understand the ‚Äúneed‚Äù for an embedded database, hiding the implementation details from the end user. This however is not a desktop application. It is meant to be running on a server somewhere, which already implies some level of expertise for setting it up. By embedding a database you‚Äôre probably creating more problems than you‚Äôre solving. You‚Äôve already settled on the web as a target platform, and just using a prebuilt/preinstalled MySQL/MariaDB database would give administrators much better tools for performance tuning, debugging etc. Debugging embedded database errors is not much fun. I should know, I spent ~6 months hunting down a bug in an embedded Berkeley DB. 
This: http://www.gopl.io/
That will be something I'll be experimenting in my sandbox. Less than month into Go and it continues to bring actual enjoyment while learning!
I think they want to make it multi-user at some point.
The problem with dependencies is not tooling (although Go modules certainly helps) but the due diligence required to avoid things like the Node.js community's left-pad or event-stream fiascos. That could be crowdsourced but certainly not automated. Now, the Node community may be exceptionally dependency-happy, even for trivial functionality like left-pad, but the same issues apply to any language. When you consider the fact Go is used for a lot of mission-critical software, often with big security concerns like Docker or Kubernetes, conservatism is warranted.
All the major databases are multiuser, though I don‚Äôt see why they would make it multiuser at the database level. Most projects do user management themselves, and stick a user Id relation onto tables,
Most likely, yes. You could also test this out and see for yourself :)
http://left-pad.io I always looked to such npm packages as running joke. Do people seriously use them in prod? What?
Either you have a very odd definition of ‚Äúopen source‚Äù, to the extent what you‚Äôre claiming is nonsensical or you‚Äôre not explaining your actual issue well enough that you‚Äôre likely to get serious responses.
Got plenty of serious responses. Code which is distributed via MIT/GNU licenses.
Name one package Go developers commonly use that‚Äôs licensed in a way that conflicts with your definition of open source.
I'm not really making statements here specifically about Go's dependency manager and/or lack there of. Just third party dependancies as it applies to all software which leads me to appreciate just how robust Go's standard library is. When it comes to dependency managers and analogous system package managers, how do you account for the [original developer abandoning their project out of disinterest and handing off the keys to another developer with malicious intent](https://www.zdnet.com/article/hacker-backdoors-popular-javascript-library-to-steal-bitcoin-funds/)? We cannot escape dependencies, but one has to consider the myriad of nasty ways they can undermine the quality of your software at any random point in time. Many of those are wetware and trust issues with no technical straight forward solution. Developers who don't pay attention to this end up with gnarly dependency trees with an unknown number of unseen liabilities. I totally believe dependency management should be automated, but for the purposes of accuracy and repeatability, not because the complexity of it is beyond what can be done manually. Web development is an endlessly proliferating problem domain piled a mile high with frameworks with flashy names and constantly shifting foundations. It feels unnecessarily complex in a way that strongly hints, *to me*, at clumsy and misapplied applied abstraction. Don't get me wrong, I appreciate the result and use it everyday but I don't devote much time to staying current with the latest and greatest so weight my opinion accordingly.
I suppose BSD licenses also counts: "BSD licenses are a family of permissive free software licenses, imposing minimal restrictions on the use and distribution of covered software." Don't keep all the legal naming in my head. Yeah sure, https://github.com/gorilla/mux
Go is dynamically linked to the system libraries on Windows, macOS, and Solaris. The FreeBSD syscall API/ABI is pretty stable. 
FreeBSD: will require recompiling, but that's true for a lot of non-Go software on FreeBSD, too. OS X: https://go-review.googlesource.com/c/sys/+/154179 Solaris: requires the libc Windows: Windows is famous for being super backwards compatible, to its own detriment.
The question here was about the lack of a dependency manager. the OP was unaware of modules which should solve 99-100% of his doubts i suppose. The dependencies on the other hand are IMO really bad in languages which are not good from early on (only those which were created after people should have learned that) Why use a dependency for sth i could easily create myself or even don‚Äòt to bc my std library is that powerfull
This Guide is more on how to setup a project of any type on Github. I was expecting some more go specific things in here like. How to structure your project, how to use go module system etc. I'm still a go beginner, but as far I know no good examples yet on go modules and how to use. I was using it for tools for example but got feedback I shouldn't use it for that. Would be great to include some more go module specifics as only the linked makefile doesn't explain that.
Thanks for the details. Yes, its possible. I will add godoc feature. Once its ready, I will ping you. I have create a issue here to track this https://github.com/thumbai/thumbai/issues/3
Hey @marcofranssem that was my initial idea but I thought the post would be so long. I do it since I think it could be a great article to discuss about Thanks so much for your advice
&gt; When it comes to dependency managers and analogous system package managers, how do you account for the original developer abandoning their project out of disinterest and handing off the keys to another developer with malicious intent? Bad things happen. I mean obviously there is risk. But to be on the brink of paranoia about it seems counter productive. People get to car accidents and die horribly, should that be a reason not to use a car? That's obvious, statistically provable risk you take for measurable benefit. Question is what's the sane amount of risk to take for that benefit. &gt; We cannot escape dependencies, but one has to consider the myriad of nasty ways they can undermine the quality of your software at any random point in time. I agree. However, you must also take into account that people use dependencies between their own home projects. I mean in company I work, we use bunch of home-grown libraries between our projects and services. &gt; Developers who don't pay attention to this end up with gnarly dependency trees with an unknown number of unseen liabilities. Yes. Absolutely correct. &gt; I totally believe dependency management should be automated, but for the purposes of accuracy and repeatability, not because the complexity of it is beyond what can be done manually. What are your thoughts on semantic versioning and Go modules? &gt; Web development is an endlessly proliferating problem domain piled a mile high with frameworks with flashy names and constantly shifting foundations. I don't think that those shifting foundations are due to mischievous developers as much as it's due to the nature of the environment. It's directly in the face of end-user and that being reality, that places developers directly at odds with business (marketing, ux etc). And that's simply very dynamic and a constant race, like out right battle, which a lot of developers name as 'fatigue'. Although, have to admit, a lot of new blood starts from there there with small businesses etc, and given that software developers are plagues due to constant inexperience (number of professionals doubles each 5 years I think?) you'll have some really messy weird s*** and lazy work / lack of responsibility.
Attempting to apply the stuff you've learned in the PHP/Java/C# world (since those are languages you referenced directly or indirectly) will probably not work out great in Go world. The language is intentionally simple, with an aggressive leaning towards simple solutions wherever possible. 99% of open source software are overengineered solutions to simple problems, marketed in other languages as "So you don't have to." But what other languages have proven time and time again is that "So you don't have to" eventually becomes "you definitely have to, but since you're already in this far you also have to back out of whatever you're currently doing." In the same way that Go and its community generally frown upon "traditional" patterns like Full-DI and classical OO principles, it also frowns upon using libraries that aren't too far a stretch from something you could write relatively quickly yourself. The libraries you referenced from other languages are also maintained either by companies or hundreds/thousands of developers. The libraries you referenced are not the rule, they're the exception, as the person you're responding to has already pointed out. If you go through PHP/Java/C# projects on github, you'll find the same amount of unfinished/undocumented/unmaintained code as any other language. So, generally speaking, there are tools in Go that are similar in magnitude and quality to EF or Spring - things like Gorilla Mux, Bcrypt, etc. But again, the community leans towards less dependencies because of the lessons learned from other languages. You don't have to agree, and you definitely are more than welcome to use all the dependencies you want, but that is generally not the point of the language or its community, so I wouldn't expect much in terms of support if you're just trying to work with Go the same way you'd work with Node.
&gt; I always looked to such npm packages as running joke. Do people seriously use them in prod? What? That's the problem with Node and overusing dependencies though - you as the developer of your project may not have included left pad directly, but (as was proven by the unpublishing of left pad) pretty much all of the things you depend on do, so if a transitive dependency is unpublished you're still screwed. &amp;#x200B;
&gt; Attempting to apply the stuff you've learned in the PHP/Java/C# world (since those are languages you referenced directly or indirectly) will probably not work out great in the Go world. The language is intentionally simple, with an aggressive leaning towards simple solutions wherever possible. One of the reasons I picked Go rather than yet another OOP language. It introduces new concepts and forces to shift mindset. But when you start it's not that easy to see towards what exactly you should shift it. Thanks for your detailed response!
So ... Go developers use a variety of open source packages, in fact almost all the packages they use - including the Go stdlib - are open source. So Go developers are not even slightly skeptical about using open source packages. Which makes your question either ridiculous or trivially answered by ‚ÄúUh, they‚Äôre not‚Äù. I think you meant to ask about third party packages, but I‚Äôm not sure why you dragged licensing in to your question.
&gt; what you write your own sessions each time? I just love how you assume everyone here is writing web applications. 
Huge sections of the programming community would argue that traditional inheritance (as opposed to compositional inheritance) is a/the cornerstone of Object Oriented Programming.
I don't. I'm well aware for what Go is used. But since I mainly work on the web that's a quick example which tops in one's head given the one's own context. You accusing me of something you are doing yourself pretending to be a mind reader in attempt to make a jab at me for no other reason but to make me feel bad about something. 
Given the fact that majority of the answers where in agreement with my assumption it makes me skeptical of your conclusions.
&gt; You accusing me of something you are doing yourself pretending to be a mind reader in attempt to make a jab at me for no other reason but to make me feel bad about something. It appears I was right about you. You are not here to talk about technology, but to pick up a fight. Go with God. 
&gt; It will have stuff like payments, image storing, authentication, community with comments and threads and will need to connect to frameworks like Elastic search. Pretty much every language can do this, most of which will wrap external APIs or just hit a database that you own. Go and Node would both be fine. There may be fewer formal libraries that wrap those APIs for Go than for Node, but they wouldn't be hard to write yourself (and by hard I mostly mean time consuming). &gt; If so is any framework like gin and echo be good to use. Keep in mind to minimise server costs and be a little future-proof. You could use Gin, Echo, or just Gorilla mux + standard library. Either is fine. If you're a fan of Express, you could also look into GoBuffalo. In terms of server costs, as Go is much more performant than Node, it would also be cheaper to run and maintain. It would allow you to do more with less. &amp;#x200B;
Frankly, now I think I've never gave enough attention to the dependencies of my dependency. I think I'll be more careful now. Thanks for bringing that fact to my field of attention. Now as I think, srsly, damn.
Yeah - this is the real unseen villain of 3rd party dependencies. It's exactly why Go has a "use less dependencies" mantra - dependencies are things that are inherently out of your control, and the more of them you have, the more risk you're introducing.
Both Go and JS are fine. I'd say Go is more future-proof, since it has better performance (as you get more traffic, that may be a problem later on). On the other hand, JS has more libraries and it is much easier to find Node programmers than Go programmers. Instead of using vanilla JS, you can also use TypeScript to add some type safety. Both are great technologies.
Before you pretend to be a mind reader for a third time I suggest you could read my exchanges with other participants before you make character-concerning conclusions. I mean really, it's simple, just don't be rude, and people won't be somewhat rude back.
It's all about the risk model. When someone's life or lively-hood is on the line, one makes different value judgements about risk than in other cases. Go tends to be used by serious people doing serious work where mistakes can be very expensive. I also come from the (privileged?) perspective of having cleaned up a large amount of technical debt. A simple decision an inexperienced developer made years ago can quickly become an enormous amount of billable hours. Sometimes you take on technical debt to get achieve a minimum viable product before you run out of money thereby missing your window to ship but that debt will come due. Other times, the technical debt was just a bad choice.
`godoc -http=:6060` opens a local godoc server you can browse, just like https://godoc.org/ hope it helps
Yeah, I'm aware of it now. I suppose my introductions to OOP was a bit different. Avoid inheritance. Prefer composition as general guideline. Composition usually through DI though, which you mentioned, if I recall correctly isn't preferred by Gophers. What you think of Go Clouds Wire though? Seems like it's "official" DI container. I say, I still writing Go by creating files with Structs, using receiver methods. And when creating new instances as sort of services. Am I on the wrong path?
From my point of view, discipline is the thing that gets overlooked a lot of times when talking about frameworks. Frameworks tend to enforce specific patterns and code style which are quite useful for large projects.
It's definitely hard won knowledge that rarely if ever finds its way into curriculum. 
That library appears to be very young and still in heavy flux. I honestly have no idea if it'll get picked up and used heavily, but I'd guess not, or at least not for a long time. You can totally do all of the things you described and be fine. There's nothing inherently wrong what you described, I would just caution against doing things because you feel like you're supposed to - as the things you're supposed to do in Java or C# don't normally appear in Go (again like full DI for everything). Here are two examples of a User type/service. Either is fine, the former just provides the ability to have multiple user services if you need. Both require a DB pointer to be provided externally, so you could argue they're both IOC/DI, the latter is just less "object oriented" than the former. [OO-ish](https://pastebin.com/erDUrkib) [Not OO-ish](https://pastebin.com/jC9Pz5ug)
Yeah - Go to me has always had a programming style where everything felt very deliberate. You generally have good answers for why you did things, or in the case of external dependencies, why you didn't do them. Node specifically seems to have a "Install stuff first, ask questions later" type mentality, which made me deeply appreciate Go's opposite viewpoint.
Thanks! :D Well, I've leaned towards such approach, because it was easy for me to organize code like that and get started to familiarize myself with Go language spec by building simple CLI application / exercise (file parser / commission calculator). But while I feel right at home separating reusable code into 'domain' objects as such, I've never liked classes. As they seem sort of bloated to me. Not sure if that's the right word precisely. I hope you get what I mean. Like in ES6 javascript, there are classes but I don't understand the point of them other than offering inheritance which I don't use. However write them anyway so others would not be mad at me who share same codebase. But while javascript is messy (I still like it, however, would not trust it to write any more serious backend), I can only describe Go as .. elegant. Which feels awesome. Thanks for all your comments. Much appreciated. I'll try to keep my mind open, and as I've mentioned, be more vigilant towards dependencies. 
exec.Command expects the arguments to be separated from the command as slice elements, not concatenated as one big string. Try it out. 
[removed]
The exec packages executes binaries. It is not a shell. You can't have shell pipelines in there. You need to set-up I/O redirection yourself. 
You won‚Äôt be able to use the same compiled binary, no. However, cross compiling for multiple platforms is super easy and convenient. You should be easily able to write go cross platform code and target FreeBSD when compiling. I‚Äôve written go programs and they‚Äôve just worked when crossed compiled it for Linux, FreeBSD, MacOS/Darwin, and Windows.
No, you can't *test* that something won't change, you can only test whether something *has changed*. Absence of evidence is not evidence of absence. You can only rely on manufacturer's specification that tells you exactly what is stable and what is not stable. 
As others have mentioned, the cmd expects an executable as the first argument and the rest of the args to follow. It is not a shell so you cannot do pipes and redirect. You can however wrap it in a bash call: cmd := exec.Command("/bin/bash", "-c", processedFilesFolder + " -type f | xargs sha256sum &gt; " + processedFilesFolder + "hash.txt")
Oh, I didn‚Äôt notice it... Thank you, I‚Äôll repost this post with a link!
My background is primarily as a nodejs developer. My feeling is that the js community and especially the typescript community attach themselves to frameworks built on frameworks written with experimental language features on top of another framework, and it's complete madness. Coding in go has been a relief. Because you know what the code is doing, and it fits your use case. Not every use case that you don't event know about. Sometimes something isn't simple and looking for a good community driven project is ideal to use a dependency. In general though I think the go approach is spot on. I wouldn't touch a typescript project with a ten foot pole and its dependencies if I could. 
Have you read the [mongodb engineering blog](https://engineering.mongodb.com/post/considering-the-community-effects-of-introducing-an-official-golang-mongodb-driver)? They mention that the Go driver will follow the common specifications mongodb publishes for all their drivers. You should checkout, the [driver specs](https://docs.mongodb.com/ecosystem/drivers/specs/).
technically true, but its the std ECMAScript server impl with its std lib. One could argue that the Go language and the go stdlib are two different things. /i/ wouldn't, but one could.
I actually did see that blog post. I guess I'm not sure what it means *in practice.* Connecting to the DB with a client using mongo-go-driver and firing queries in a dev environment is fine, but I would like to know the mechanics of what's happening, specifically around connection pooling. Is the client implicitly managing a pool of connections/sessions? In the example I posted, using mgo, there is the concept of session copying: `sessionCopy := mongoSession.Copy()` Each goroutine copies a session and then closes it, so that the work can be done concurrently and there will be no bottleneck. I'm finding it hard to understand how to use such a technique using the official driver. Perhaps it's not necessary because they handle it for us? In that case, though, I would expect to be able to configure various parameters around the pooling in a "relatively simple" (haha) way.
TiDB, AFAICT, isn't embedded.
I really like [sqlx](https://github.com/jmoiron/sqlx). It has lots of nice quality of life features.
Vague blanket statement. It would have been nice for the original question to have offered some specific examples instead of requiring a stream of comment branches to ferret out the intention. I'm still not even clear if it's about licenses, package management, or just a claim of a fear of open source. Strange post. 
&gt; I always looked to such npm packages as running joke. Do people seriously use them in prod? Yes, which is why it was such a big deal. &gt; In a way you suggest that Go took a path in it's design that of lowest denominator. If there is something someone might misuse in terrible way, when it should be extra difficult for everyone to use. No, the vulnerability is the same in most language, it's just Go and Rust developers are more conservative, Node developers more promiscuous, and Python somewhere in the middle. &gt; Do I get your point or I misrepresent something due to a mistake? I would guess it is picked for mission-critical, as you put it, because it is conservative. It's an emergent property of the community. I don't think the language itself has that much influence, apart from the fact a certain kind of programmer prefers simplicity over the baroque complexity of a C++ or Java. &gt; But I suppose when it's already have a strong audience and it's own distinct feature set for which it is picked, why it would want to change that. Because versioning and management of dependencies is a real problem and the pre-modules situation with proliferation was sub-optimal.
If you read the article they did embed it. It isn‚Äôt normally though. 
I also use sqlx and quite like it. It is much cleaner than [go-sql-driver](https://github.com/go-sql-driver) . It is concise but not at the expense of forcing on you the bells and whistles of an ORM. 
gorm. https://gorm.io
How is gorm performance compared with other options? Are there any benchmarks? 
You're right. I got sidetracked looking at TiDB that when I went back to the article, I must have skipped right past that. 
Going back to the article, the first paragraph says this: &gt; That‚Äôs why we started working on an easy-to-use application that can be hosted at home or on a private server. I'd say that's why it's embedded by default. It should be pretty easy to make it configurable to use the embedded DB or an external connection.
I think it's gonna come up as slow as any ORM might, but you can just use raw SQL and mainly use it for the driver and schema stuff. As with most tool choices, though, YMMV depending on what you're using it for.
What about package management in production, can modules be used? Is it safe for production
What about package management in production, can modules be used? Is it safe for production
Thanks, What about package management in production, can modules be used? Is it safe for production
What about package management in production, can modules be used? Is it safe for production
What about package management in production, can modules be used? Is it safe for production
Just wan't to gartulate(spend) GoBridge..
Performant enough to do [this](https://www.youtube.com/watch?v=nk87zsxpF1A). In reality most of the heavy lifting in both TF and Gorgonia is handled by CUDA. I'm currently working on making Gorgonia work on TPUs too. I'll be honest: the CUDA API of Gorgonia is a bit clunky. But Gorgonia was built for extensibility hence the slight clunkiness. We appreciate any contribution to help make things better
It is terrible Use gorm for some of its feature (logging is awesome), not for performance And never do large joins (or preloads) with gorm, generated requests are awful Benchmarks can be find in some other orm, check sqlboiler
where do your dns setup pointing? might be affected by that.
If you're the only maintainer it's highly unlikely anyone will comment. And how long do you leave the PR open? Even at my job opening a pull request without specifying reviewers is unlikely to get any attention. That said, I can see some benefit in doing a formal review of your own code in this way before merging into master.
sqlx and go-sql-driver are orthogonal to each other, so even if one was cleaner than the other, it would be irrelevant. We use both at work.
But, what's about automated checks? I mean by making use of PR you can check that the CI works fine before modifying your master branch. Same with other integration tools such as test coverage, or linters
What exactly you are looking for? Are you using one-time payment or subscription? Stripe document is good as per my understanding. I have used subscription flow, in which created a product on stripe dashboard with a plan. Once a user gives credit card details, our client makes a request directly to stipe and get token for the card so we don't need to worry about PCI compliance. Send this token to our server with user email. Create a customer on stripe using their API with email as a unique identity. Next, send payment request with customer id and generated token with a plan details and you are done. Don't forget to set webhook URL so your server can get callbacks when next payment is done.
Can you compile for windows from Linux, or do you need some static and need to compile on the target host with Go? 
You don't need PRs for this, just configure your build server / service to automatically run checks for all branches.
You may want to check my thread "why gophers are so skeptical of open source packages". There isn't anything like npm currently. And it seems there wont be. There is official vgo proposal going which should go live in 1.11. But it wont be the same as npm. 
Yeah I got you but have a look at the below scenario if you work on master branch locally and "unfortunately" you introduce a linter issue in your code, then you push the change into the remote repository and your master branch will be corrupted... The only way you could fix this is by creating pre-hooks on your local .git/hooks but you can not guarantee that all the developers have git hooks configured locally. 
Have you tried [gosqljson](https://github.com/elgs/gosqljson)?
Sure. But the original comment I was responding to simply stated the reason as "other people can comment on your code."
Ok! Maybe I should explain better in the article why is good idea work with PR. Thanks a million for feedback and sharing your point of view!
I haven‚Äôt used any yet, but I‚Äôd suggest checking out https://crawshaw.io/blog/one-process-programming-notes and the [`crawshaw.io/sqlite`](https://godoc.org/crawshaw.io/sqlite) package it mentions. It‚Äôs the one I‚Äôd try first.
If you write raw SQL queries, do you still get the normal go performance, with the added bonus of the other things that gorm provides, like migrations and so on?
Both Gorm and SQLx that have been suggested in this thread are not actual SQL drivers, right? Or am I missing something? They both rely on other drivers.
Well, strictly speaking Gorm is a ORM, and Sqlx defines itself as 'general purpose extensions to golang's database/sql '. But what i meant by 'driver' was whatever you choose to make queries on your MySql database. &amp;#x200B;
I agree with most of your reasoning :)
Sessions are managed implicitly by default, [https://github.com/mongodb/mongo-go-driver/blob/master/mongo/sessions\_test.go#L561](https://github.com/mongodb/mongo-go-driver/blob/master/mongo/sessions_test.go#L561) 
Yes, you can compile directly. Check out the GOOS and GOARCH parameters.
Thanks a lot
you even don't need to store the token, when using smth like jwt as an example, just set expiration time.
Thank you for the answer! Happy holidays!
I trust go ecosystem more than 10 years of npm. So i am opiniated. 
As always, [if there's a question mark in the title, the answer is "no"]( https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines):) A framework inevitably makes assumptions about your system. Great when you start out because you have a ton of work done for you. Terrible when your system matures because you have to do a ton of work to modify the framework's assumptions. And you will, eventually, discover that your system no longer matches the assumptions of the framework. Libraries of commonly-used routines are great because they can be swapped in and out and don't depend on each other. If you don't like how Gorilla Sessions handles things, or your system needs something else that it can't provide, then you can rewrite the code that depends on it pretty simply. Frameworks, by definition, are not so easy to change. And yes, writing your own session handling routines does seem like a pain at the start, especially if there are libraries out there that do it for you. But knowing exactly how it all works is a great advantage, and being able to change it whenever you need to is another.
I usually check this page: https://github.com/golang/go/wiki/SQLDrivers Based on that info, it seems like https://github.com/go-sql-driver/mysql/ is the most used MySQL driver.
to be honest, I'm not sure a good package management system actually "solves" this problem. I mean, yes, you can ensure repeatable builds, and I'm not knocking that as a benefit. But because of security updates, sooner or later you're going to have to upgrade versions and deal with any build breakages because of it. The very act of including a dependency means that your code can be broken by someone else's actions, regardless of package manager. 
I predict we're going to see a lot more "malicious package attacks" in the JS/Python/Ruby/etc world in the next few years. As the original maintainers get bored with being taken for granted by idiots and move on, and the bad guys realise that by taking over the maintenance of a single package they can inject code into thousands of websites/applications, we're going to see more emphasis on the security aspects (or total lack of it) in the npm ecosystem (and others). The golden years of being able to trust any npm package to not send your user's login details to a url in Russia are going to be over soon. I'm not saying this is why Gophers tend to avoid dependencies, but I agree that we do view dependencies with much more suspicion than the JS community (in particular). Dependencies are bad, because they save you time now at the cost of a lot more time later. Better to write your own code if you can.
I like and use sqlboiler the most. 
I am not using modules in production yet, but as far as I know, they are safe for production. I never had a problem with just `go get`. If you are very concerned about your dependency, you can vendor them. Although this is not something you should do very often.
multi-dimensional array doesn't seem to be supported out-of-the-box yet: https://godoc.org/github.com/lib/pq#Array. Maybe try playing around with GenericArray to see if you can scan it yourself instead: https://github.com/lib/pq/blob/master/array.go#L310 Alternatively, use go-pg which seems to support multi-dimensional array.
I'm having some difficulties on some stuff. If someone wants to help me (knowledge of C needed) you're welcome :)
Yes, that‚Äôs what I mean by [cross compiling](https://en.m.wikipedia.org/wiki/Cross_compiler), and no, you do not need any static libraries or DLLs when cross compiling*. * An exception for when you would need to install or provide platform specific dependencies (i.e. header files) is during cross compilation is if you‚Äôre using `cgo` and need to link against C libraries. But this is easy to do for targeting Windows from a Mac or Linux with mingw-w64. 
Desktop link: https://en.wikipedia.org/wiki/Cross_compiler *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^227651
Nice! I started my Tour of Go some weeks ago, absolutely loving it. Planning to read The Go Programming Language (aka The Bible) myself aswell!
my two cents &amp;#x200B; stop reading books, just dive right in and learn by doing &amp;#x200B; for real, reading books is really old school and the learning curve is very low
Agreed. There is some magic that comes with using books to learn but alot of the material gets dated when you look at how the Golang community is structuring their code. For example, Go Modules
Oh, I‚Äôve already dived as soon as I finished the tour. Ive been building a micro service for an app I intend on building. While I agree the best way to learn is by getting stuck in, I think reading books is an invaluable tool. I‚Äôve already come across a ton of information and techniques I may not have discovered if I only went straight in to developing. 
Personally, the project that got me learning the most was building a blockchain in Go. Really teaches you a lot about a whole range of different topics in Go (networking, I/O, ‚Äúpseudo-OOP‚Äù, RPC, APIs, TLS/SSL, etc...).
Yes, you need to import each package you need explicitly. This avoids pulling in more than you actually need.
Totally agree. Reading educational books about programming is a *major* time waste. It's still a thing because of the old habits, I guess. But nowadays, I'd never recommend to anyone to start learning from a book.
I purchased *The Go Programming Language* book and read it all. I then started working on my project to completion. That book really solidified my understanding. It is a handy reference along with the official docs.
Agree, it is extremely important to code something, substantially larger that ‚Äúhello world‚Äù or any other basic example. Some of the topics are not even covered in books, and the only way to understand it is through experience. Nevertheless, books provide solid knowledge on basics, like any other documentation. Instead of reading Stackoveflow, one can easily answer, after going through docs once.
Very true. But books provide solid understanding/knowledge of the basics.
It depends a lot on your personnality. Some people learn by diving deeply into the language, and books/documentation are great for this. Some need a lot of practice, and starting a project is great for this. I'm in the second group, as you are, but I know great programmer who feel uncomfortable until they totally master a PL.
Not everybody learns the same way. It's a depth-first vs breadth-first thing. Both work, but on different kinds of people.
Couldn‚Äôt disagree more. Books are a fantastic way to see the available features of a language so when you do start a project you have a tool chest instead of fumbling in the dark. 
Isn‚Äôt that the job of a reference?
A good read of a book will give you the breadth of knowledge to know how to reference something. Memorizing the initial books isn‚Äôt the goal, it‚Äôs exposure. After that you know what the terms and names of things are to reference down the line. Obviously, everyone is different. I was just pointing out lots of people like to start with books. I‚Äôll read 1-3 books on a tech before trying it out so I understand the limitations and features worth exploiting. 
The performance hit comes from using reflection to map your results back to golang struct. But most people probably won't notice. I'd say write it and optimize when it matters.
While I agree you don't *need* books, or that they are not the *best* way to learn a language, I find they provide a great resource for the times that you find yourself tired of staring at a screen. Also, I personally find them useful when I'm in a room with family or friends and everyone is hanging out. It avoids the stigma of being on a device and disconnected.
I had to zoom in just to make sure it wasn't written by Dennis Ritchie. Would you recommend it to someone with zero experience with Go? 
There is no point to a reference if you don't understand it. It's the reason why exams in college that I had were all open everything except for internet, you can have all the references you want, but unless you actually understand the materials, it mostly likely will be a waste of time.
Yes.
12 % downvoters are Java developers.
But wouldn't that be true even if you didn't use an orm? I mean, don't you want to convert it to a struct anyway? I'm new to Go so I don't know. 
Apparently there are faster solutions, I'm fairly new to Go myself, gorm is what I'm using for a small micro service for file upload (there aren't many relations).
Well, one or the co-authors is Brian Kernighan :-)
Recent Go versions do not depend on libc. You can even put Go programs into scratch container and they will work.
Go doesn't have sub packages. 
I love programming in Go, enjoy the books and hope you find some great programs to write!
Thanks friend! 
Good luck! 
I think it depend upon the quality of the book, there are lots of terrible terrible programming books, filled with outright wrong information. Then there are things like "The C Programming Language", "Ppogramming Pearls", Code Compete, The Pragmatic Programmer, which are each excellent in their own right. I would never say "no books", nor "always books", since people vary. But having a _real_ project is always going to be useful.
I started learning go less than a week ago. Yesterday I made my first useful script and it was a good experience. Also I've started the book you mention and it's great for it dives you in the language using useful things. I don't want to resolve a mathematical problem while learning a new programming language, I need to learn through close to real life examples to keep myself hooked.
Try to install Windows subsystem for Linux (WSL) . It creates a Linux environment without virtualization and it works very well, but only on windows 10. You can install Ubuntu, Debian and Suse. I use this on windows. I make a symlink in my Linux home to a location in my windows 10 users‚Äô home directory (/mint/c/users/me/code). This lets me use the window shell and programs to edit code and the Linux environment and tools (Go, make, etc..) to compile and run. 
Is this command line only? Or can you install gui apps? 
With vscode the experience for me is pretty much the same as on macos. Instead of windows shell I use cmder. It provides good shell experience and comes with git for windows which includes a bunch of useful Unix utilities. I also hooked it up into vscode to get a Unix like terminal inside vscode. With that setup everything is smooth and just works. Only problem is cgo (installing mingw or something is a pain) but you should avoid using it anyway, windows or not. You could use bash for windows but general recommendation is to avoid mixing Windows and Linux environments.
rand is still a package inside math(which itself is a package)though, right? And source code files within rand have package name of rand. I'm not sure what you mean by your last sentence. Would be helpful if you could explain that
Actually idk what happened but it stopped working. The imports aren‚Äôt looking at the vendor folder and not properly importing the modules. I checked whether my gopath is set correctly, and it is. I‚Äôve spent the last four hours on this. Can you please guide me through? I‚Äôm more than willing to elaborate on any bit of information. Thanks!
Great comment
I'm not sure I understand what you're asking. ISTM that the code you are writing works? FWIW, you can create new types with reflect using [StructOf](https://godoc.org/reflect#StructOf), PointerTo, SliceOf, ArrayOf‚Ä¶ etc. Types created with reflect, however, can't have methods (except some edge-cases using embedding). [There is a github issue for that](https://github.com/golang/go/issues/16522). Hope that helps :)
Agreed - good books cover the nuances of languages that you don't even know you need to learn. Learn the basics by doing and the nuances by reading experts.
&gt; rand is still a package inside math(which itself is a package)though, right? No, that's the point :) It's not *inside* math. There is a directory-structure, but it's conceptually orthogonal to the package structure. The directories are nested - the *packages*, however, are not. If it helps, there are build systems for Go that don't map folders to packages (e.g. in bazel you can have multiple packages in the same folder).
Thanks for your response. My code is not working actually. The result is a zero-value of the type given to the function. I also tried StructOf but there was no luck. It seems that GORM is not filling the properties and still returns a zero value of the same type. TBH i wanted to ask this in github‚Äòs project, but ISTM that the issues aren‚Äòt getting answered a while...
VirtualBox? Setting up a Linux VM doesn't take long, and is almost as usable as a proper Linux machine.
I always check some metrics, normaly when looking at Github I check this: - How much Issues the project have, see open and closed, checking how much time to get feedback from the maintainers, also see how the maintainers speak with the people who open the issue, etc. - When was the last commit, it's important that the package have a constant commit historic and contributions - How much stars the project have, if a project have a low number of stars probably anyone are using it - Number of forks, if the project have a lot of forks probably many people are working on it or are make some customizations - Check the project documentation, if someone spend time writing one probably the project has some value - Check if there is someone writing about, see blogs, reddit, HN, etc. If someone spend time writing about the project, probably it is good.
cli only
I would typically agree, but *The Go Programming Language* book has changed my mind on that. It's actually very informative. I recommend it to anyone wanting to learn Go.
Which book do you like best?
Thanks! I've done most of these, was hoping there was some kind of unified source for 'Enterprise readiness'. Guess I'll stick to the same thing. 
The other posters are 100% correct. Organization of packages in the directory structure creates no connection between them. For completeness, I will mention the one exception, which is internal packages. Starting with go 1.5, you can create a package that can be imported only by its "parent" and "sibling" packages.
I've legacy apps that runs since 20 years (in Python), i'm happy that they didn't depends of unmaintained dependencies (i'm less happy with Py3). For the next 20 years i choose Go specially to don't have dependencies (and upgrade) concerns. The minimum dependencies i need can be vendored and are easy to read and maintain or replaced by myself if needed (mux, sqlx...)
I‚Äôve only had a read through ‚ÄòGo in practice‚Äô so far and it‚Äôs been great at exposing me to best practices and techniques for common use cases whilst also explaining features as it goes. It provides a basic foundation to begin with but in my opinion the tour does a better job. I then decided to buy ‚ÄòThe Go programming language‚Äô to have as a reference and a more in depth guide. The last choice ‚ÄòMastering Go‚Äô probably isn‚Äôt necessary for most. I just bought it as it seems to be the most technically detailed and also provides information on Go and the unix operating system and implementation details on data structures other than the built in types. 
The brace matching style that Go adopted and formats to is known as [K&amp;R Style](https://encyclopedia2.thefreedictionary.com/K+and+R+style) which is Kernighan and Ritchie. I geeked out a little when I found out Kernighan was a co-author. 
Check out a package we made at a previous gig. https://github.com/gocraft/dbr It does what you want to do in the same way you're describing. If you don't want to use dbr itself feel free to lift the related reflection stuff.
Even with the normal build you can put packages x and x_test in the same folder (which is occasionally useful for resolving circular deps while testing).
I would. I read it when I had basically no knowledge of go. Go is a very, very simple language. The learning curve is almost non existent if you already know some statically typed language. The book introduces the syntax and doesn't expect you to have any knowledge of it beforehand.
Thank you! Checking the tests is a great idea.
You can install GUI (gtk/qt) apps in WSL using apt or yum but they‚Äôll need an Xserver running. You can use mobiterm for that (there‚Äôs lots of x server options in windows). You can set your display variable in your shell to point to it and then run graphics application. 
&gt; This avoids pulling in more than you actually need This, plus it makes it easier for other people to understand your code. "Where is that `rand.Intn()` coming from? Oh, here it is: `import "math/rand"`." And furthermore, if "sub-" packages were imported implicitly, what if you import both `math` and `crypto` that both come with a `rand` package? The compiler would not know which `rand` package to choose when compiling `rand.Int()` if the `rand` package is not imported explicitly.
All of this, plus the versioning. Did the version number already arrive at 1.0? Do the authors use semantic versioning? (All below 1.x is experimental/incomplete.) How often do they release new versions? Do they mention whether they regard their project as stable/tested/production-proven (references please) or rather as experimental? None of these aspects are direct hints on quality or stability, but they add to the whole picture.
Welcome to Go... you're gonna love it!
It's a small project but I tried to follow best practice in Go. I hope to get feedback on non idiomatic code that can be improved.
Go itself doesn't care if it's inside or not. They're completely separate packages that happen to be in this directory hierarchy. But we as developers do care about that and give it a meaning by putting specific packages "inside" other packages. Like, there're two `rand` packages - `math/rand` and `crypto/rand` . Although both of them have no relation to `math` and `crypto` from a language point of view, for developers they're definitely related and you can read important differences between the two in their respective docs and why they're located "inside" specific package. &amp;#x200B; Go tooling doesn't care about what is inside what to a point that you can even import package without pulling source code for packages "inside" it. For example, popular tool `dep` allows you to vendor external dependencies by downloading source code into `vendor` directory inside your project. If you tell it to add package `A`, it will not add package `A/B` if `A` doesn't directly depend on it.
Well we can forget the Go module system here because the gqlgen docs say it doesn't support modules yet. So let's just assume you have your project set up on your $GOPATH. It's ok if you don't have it set, because it defaults to being `$HOME/go` If you used `dep init` then your vendor folder at the root of the project will have the dependency (which your screenshot confirms). If you want to check in your complete project with the vendor folder, we could confirm your project structure? Where have you put your project and what have you set your GOPATH to? 
I'll look into that, thank you. 
My two cents Maybe it's just me, but I found that I'm able to trick myself psychologically with books. It somehow helps me commit to reading through the material and understanding it. Carrying the book around with me wherever I go, to work, back home, going out shopping with the wife when she goes to stores I really dislike - it's a constant reminder of a goal I've set for myself to learn this material. Of course it's important to learn through practice and yes you can google to fill in the gaps, but it's a nice feeling to go into a project with the intuition of what features the language provides you. They are not mutually exclusive learning techniques and both work really well. 
GUI apps are not supported by Microsoft and they never intended for them to work. It's pure luck that Xserver is working. Checking it out just for fun is fine but I wouldn't depend on it, as there could be all kinds of problems. WSL is great but still a long way from being stable and feature complete even for CLI applications.
My gopath: /users/[username]/documents/go My project: /users/[username]/documents/go/src/github.com/[mygit]/pet-store-api I followed many dep tutorials and somehow their imports know to use the vendor folder whereas in my project, they seem to be confused with the other GitHub folder I have.
Programming in a while is very much the same as programming outside a while but you have to keep in mind that your code will be executed again if the condition is not reached. 
Assuming your paths are correct (and the Users title case is really correct) the vendor folder should automatically be consulted by the Go tool in addition to the GOROOT and GOPATH. But we are not seeing it check that location. I don't really have an explanation for that. If you ran the dep tool and it vendored your dependencies properly, the Go tool should check that location
My problem with versioning is that people have different ideas of what is considered 'stable'. It also says nothing about the quality of the code (i know not all production code out there is great). I guess if it's on a high enough version number combined with number of maintainers and other factors it could be a good sign. 
So what do I do now? Because I‚Äôm really lost, I‚Äôve done everything right yet it‚Äôs still not working.
&gt;The point of the article is that you can just use the standard library without any additions. That's seems like the opposite of the point of the article. The point of the article was that for lots of common tasks, you have to use some packages if you don't want to waste your time writing a lot of boilerplate.
Unfortunately when you report details that all sound correct, and the output is still incorrect, there is little left to suggest, short of someone sitting down with your environment and trying to suss out which detail you have actually overlooked. You could try posting back your `go env` and `tree` output in a pastebin for a sanity check? 
Could you suggest some project for getting into Go? I was hoping for something along the distributed systems/ operating systems side. But anything works.
While I agree that everything you need is online, books can make things a lot easier by organizing it and presenting it nicely. Particularly things you can't get from Effective Go and the other core docs like project layout, coding patterns and such. Things that can be picked up by reading blog posts and watching talks but which could easily be better presented in a book.
[removed]
Unfortunately Go in Practice contains various errors when it comes to chan synchronization. It's a shame really.
How do you know the future? You don't. You extrapolate based on your knowledge and the behavior of the system you are interested in.
The Go Programming Language is a great book and helped me get a grasp on the language that the online tutorials and such didn't. Not as concise as The C Programming language but by far the best book on the topic I've found. 
Without getting into the details of your specific problem I put together this example for you. [https://play.golang.org/p/tGBERT8nKSO](https://play.golang.org/p/tGBERT8nKSO) &amp;#x200B; It demonstrates how to determine underlying value type of an interface{}, how to use that value type to create a pointer to a new instance of that type, how to use that new instance, and how to convert it back into the known type. &amp;#x200B; Good luck!
Documentation improved and template files added.
This may be annoying, but it's actually a feature of Go. &amp;#x200B; Many other languages are 'fuzzy' about imports. For example, in Ruby, I can have my main file import library A and B. A might import C, and B might \*accidentally\* start using C without declaring it. This is great for hacking together a prototype, but a nightmare when trying to figure out what C is and where it came from while reading B. It can also cause problems if the main routine says "import lib/\*" and the filesystem determines if A or B is imported first -- the program will literally fail on some filesystems. (!) &amp;#x200B; In Go, everything is super explicit (in both library imports and error handling). This feels pedantic at first, but allows you to move faster down the road because you can debug things so much easier. (i.e. there will never be ambiguity which "rand()" you are calling.)
Dang, I wish this tutorial was built for the gqlgen library; Nonetheless, great job!
You are not the first person to ask. There are some good pointers over here at StackOverflow [https://stackoverflow.com/questions/42291569/pst-to-utc-parsing-of-time-in-golang](https://stackoverflow.com/questions/42291569/pst-to-utc-parsing-of-time-in-golang)
I don't have date-time, I have date
The tree from the $GOPATH is really massive so I didn't list it here, but here is the go env. [https://pastebin.com/C18vsfNn](https://pastebin.com/C18vsfNn)
If the function will error, it should also return an `error` and that's what you should be checking the value of, a `nil` value is success.
Generally, rather than screwing around with reflection, I equip my classes with a method that does what I want, and I declare an interface that has that method that I can use for argument types. I have a _lot_ of type ObjMetadata interface { Name() string New() ObjMetadata } in my code. This allows me to get names out for things like your GetRepository call, and code that wants to manipulate the types in question but not know the concrete type can just deal with the interface. Grow the interface as necessary for those generic operations. You can see an example of this pattern [here](https://github.com/thejerf/sijsop/blob/master/sijsop.go#L163). Sometimes a bit of API work can even make useful methods not lose the type, such as with the [Unmarshal method](https://godoc.org/github.com/thejerf/sijsop#Reader.Unmarshal) I implemented.
I think this is an interesting question, because you're not asking about *invoking* panics, you're asking how far should one go to *prevent* panics. This is my general rule of thumb on that: **If the value is optional,** ***always do the nil check*****. If the value is required but dependent upon user input, do the nil check. If the value is required and entirely independent of user input, let it panic.** My reasoning here is that panics should alert the programmer to bugs, but should never result from any possible variation of user input. This is difficult to master but tests can help a lot.
Here is an example: [https://play.golang.org/p/kJnw1o8te0u](https://play.golang.org/p/kJnw1o8te0u) Note that in the Go playground it will say the local time is UTC. But the first example assumes the date is alredy UTC. The second one assumes it is in the local time. Is that what you are after?
The part I don't understand from your question is, if your input is only a date, how do you expect to end up with a time of 11:45:26? Where does that time value come from? Are you expecting the given date to be combined with the current UTC time?
doesn't `const patt = "2006-01-02"` exists in the "time" library as constant?
Hello, gophers, &amp;#x200B; I built a command line tool for twitter last month. It is a little out of necessity. Since I mainly work with the command line, I wanted to have a small program to quickly check my timeline and send tweets. Since I like to use Golang, I thought I'd build it myself! &amp;#x200B; I am very happy about feedback. Some features are still missing, but will be added later.
`time.Now().Location()` -- I don't want my location, I want UTC
No, it returns the location used in \`[time.Now](https://time.Now)()\` which is local time. But like I had said, if you are looking at this on the Go playground site, it will always be UTC
No. [https://golang.org/pkg/time/#pkg-constants](https://golang.org/pkg/time/#pkg-constants)
how about my question?
&gt; No, it returns the location used in time.Now() which is local time. then what does it have to do with my question?
&gt; If the value is required and entirely independent of user input, let it panic. I think this is a reasonable good rule-of-thumb in general; for example a HTTP middleware: func Middleware(opts Options) func(http.Handler) http.Handler { if opts.Required == nil { panic("middleware/foo: Required is nil") } return func(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { // [..] next.ServeHTTP(w, r) }) } } In this case the programmer forgot to set a struct field correctly, and I think panicking for that is appropriate. It's independent of the user input, it will *always* happen on every program run, and using error returns would just make things convoluted. Another condition that I typically use is that a panic should be reliable and fast. That is, not dependent on some (potentially obscure) state. This way a programmer will never be surprised by a panic, and it's used reliably to tell the programmer that they made a mistake in calling a function. So this would probably *not* be a good idea: func foo(somesuch *string) { if somesuch == nil &amp;&amp; !someOtherCondition { panic(...) } } func foo(asd bool) { if !asd { x := foo() if x == "" { panic(..) } } } I find it useful to use panics like this in cases where I don't need an error return but still want to do some helpful validation on the parameters to guard against mistakes (and give more helpful errors, rather than some random nil-reference, or give the wrong output).
Any errata available anywhere?
I've wrote and compiled a good amount of Go code for both Linux and Windows. Honestly, there's not much difference. Visual studio setup is basically the same from what I can tell. Start writing some Go and VSCode will ask to install some plugins. Install them and your off. I have the Linux sub-system installed in Win10, and I do use it a lot when I'm ssh'd into servers. But, for compiling windows apps, I use the good old piece-of-crap command line. Works fine for both compiling and using git. Granted my go commands are usually `go run` and `go build` without additional flags.
Who would buy a book to learn programming in 2019?
If you're going to presume that the input date is in UTC, this will work: https://play.golang.org/p/CC_IjJTQlBA Otherwise, you'll need to replace the location in the parse with whatever timezone the original data comes from, then convert to UTC via `time.In()`.
If not an errata, would you be able to point out where the mistakes are made? This would be a great help.
This üëå
I don't know, but that's a cool idea.
'just pick a program and make it' is almost always correct. What can you give an example where you didnt know enough about what to google? Just a plane english question and "golang" generally works.
[removed]
I'd help you if you need it. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
I think it also depends on the documentation and update frequency. For an extreme example, a web js book is just shooting yourself in the foot. Learning where to find recent info is way more useful than a thorough run down from a single point in time while there are wealths of well organized up to date documentation. Obviously go is not that, just commenting on the spectrum of programming in general. To another extent experience compared to content is also an obvious factor. All that said I would probably read a go book mainly for bridging the oo vs functional programming concepts. Being a dabbler who‚Äôs looking to work go into some projects I might be picking up a book myself and will probably buy one of these (taking suggestions, haha).
Where are you located?
What reference materials did you use to tackle such a project, if I may ask?
Anything that gives an alternative from the grip python has on NLP gets a big thumbs-up from me.
Started off with just reading a few medium posts on blockchain, looked at a few existing implementations and went from there (Go-Ethereum is pretty well documented and well written).
there is a TON of nuance that your average web-site will not go into but a book will. books remain a crucial component of really getting to know a language.
Should've went the whole way and called the library "goatee"
One thing is an early planning for maintaining . code, like right amount of right logging , plan for adequate and relevant unit and integration test 
&gt; I feel stuck between the two camps of 'reading books' where things quickly get over my head and 'just pick a program and make it' and running into my skill limit quickly I'd highly recommend doing the exercises on exercism.io. They start out very simple so you can build comfort and understanding gradually, and they have excellent mentors happy to assist you.
What‚Äôs your background? I don‚Äôt think that Go is beginner-friendly. Try C for 2 weeks to learn the fundamentals, then come back to Go. C (not C++) is fairly simple because it lacks many of the features of modern languages. Yet it‚Äôs low level enough to teach you about pointers, allocations and structs- all of which are in Go.
Consistent formatting, striking the right balance between abstraction and concrete implementation, how to break up functions into readable chucks. Basically communication to the next programmer who has to read your code. It's why programming is an art as much as a science IMO.
They write good documentation and commit messages.
If you're looking for collections of mostly simple straightforward puzzles, https://adventofcode.com/ may be for you. This year was pretty hard, last year was a lot easier (for me) and I did at least half of them in Go. I think there's at least five years worth of puzzles. Have fun!
Solutioning a problem and creating a doc with the plan and good ways of solving that problem, challenges that are pending and share this doc with the teams and take input and then start to code.
Yeah, but I feel like documentation happens less than what would be good even in professional setting
That's not what the word "receiver" means. A method only has one receiver.
Everyone is describing all the planning that goes in, but Go was designed to allow the developer to start writing right away and not get cornered in by earlier decisions. For me, good code is well documented and functions and structs have a single purpose/use that they do well. 
I recommend joining the gopher slack. It is very friendly, with a ton of channels including a newbie one. [https://invite.slack.golangbridge.org/](https://invite.slack.golangbridge.org/) It is a great place to ask questions and talk to people in real time.
A company preference. There is a lot of devops code out there in both, but I see it trending more towards go in the last two companies I have been in and most of the community developed general devops tooling in the last 3-4 years. One big advantage I see for Go is it is easier to maintain, which is where the majority of time is spent in projects.
Yes. The Go Study Group meets every Thursday at 10am Pacific time online. https://gophersource.com/study-group/
Can you give a short example of something you did in bash and are struggling with how to approach it in go? It might be easier to discuss starting with something concrete.
This looks like a very promising project, keep up the great work!
Are you planning to handle streaming tweets? If so, how do you plan to implement it seeing as the API now seems to be locked behind a paywall?
Do you have any sources on that? To me that sounds not like a good thing to do. No matter what language.
My two cents would be thinking about how to test whatever they‚Äôre building. Whether they work in a TDD fashion or not, writing a testable app is very important!
[removed]
Debug. 
1) A shitload of tests covering as much of the code as possible 2) Constant refactoring of existing code to break it into smaller and smaller chunks that are arranged in good patterns and testable separately
Definitely agree with these specifics, but more abstractly: empathy. Don't optimize for entire rewrites, optimize for maintenance. The next person that comes along almost never wants to rewrite a project until they crack it open and feel lost. Future engineers will almost always try to preserve intuitive structures, but without any sane touchstones the rewrite thought grows. This applies to file structures/names, balanced abstractions, code commented through small function names, and to the point documentation. An engineer looking at code probably wants to know one of two things: how do I use this, or how do I fix this? I try to follow these because 6 months later I will have no idea what I wrote or why and it's likely the "next engineer" is me.
It's wise to read a book without investing too deeply for the first run. This way you learn what could be done, some language idioms, ins and outs, and will know what are you searching for when stuck on an actual project
Functions having one job and doing it well :) It's strangely true about planning, though. As a newbie I charged in and wrote code, and then rewrote it when it didn't work right. As I learned, I planned more, and wrote up enormous class diagrams on a whiteboard before hitting the keyboard. It didn't seem to reduce the amount of rewrites, just increased the amount of code I had to rewrite. Now, after ~40 ish years coding, and 25 years in the industry, I charge in and start writing code. I know that I'll discover about the problem domain as I go, and try to not over-plan and over-optimise too early. I write code that's easy to understand, and easy to alter (well, I hope I do, that's the goal anyway). The best advice I ever got during my career, and something I still struggle with, is to write the simplest code required to solve just the problem in front of me. Don't overthink it, don't over-optimise, just solve that single problem as simply as possible. 
I thought you were coming hear to learn. I see you were actually only coming here to validate your own opinions that you started with. 
Understandable comments, use of design patterns, well formatted code (go PYTHON!!) &amp; concise/simple solutions to (sometimes complex) problems. Bonus: testability. Moan all you want; testing will not help solve realtime distributed communication in an elegant &amp; graceful manner, working alongside 10 other devs.
But I came to actually different conclusions than I've started with. Did you bother to read the edited section?
Two things: 1. Have you benchmarked the performance of [this huge select group](https://github.com/ugjka/messenger/blob/6ab8ea226327bcc203e589c0c45e9c405a8a8f3a/messenger.go#L56)? It seems unnecessarily big currently. 2. Can the [`setup`](https://github.com/ugjka/messenger/blob/6ab8ea226327bcc203e589c0c45e9c405a8a8f3a/messenger.go#L34) function can be simpler? Like: &amp;#8203; func setup(....) *Messenger { return &amp;Message{ buffer: int(buffer), drop: drop, ....... kill: make(chan struct{}), blocked: nil, chanlens: nil, } }
Most comments here are just personal opinions.
Conceptual integrity: https://www.google.com/url?sa=t&amp;source=web&amp;rct=j&amp;url=http://wiki.c2.com/%3FConceptualIntegrity&amp;ved=2ahUKEwjqieWv9cTfAhUSLHwKHTY-C_0QFjACegQIARAB&amp;usg=AOvVaw2Z3gpKT4MJql72Sdw1smvR
Streams will definitely be added. Just for the sake of tracking your timeline in real time. With a developer account you can use Twitter Api quite well without reaching the rate limits too fast. Enterprise features will probably follow later on..
1) Performance is not my priority, you could probably write more performant code with an RW mutexes, i wanted to do this purely with channels and have no data races 2) it is a matter of taste, since this is hidden from the API i don't get what difference it makes
They write the solution that's the best fit for the problem, not the one they think is most impressive. I teach and train a lot of juniors, and too many think writing code that's complex, difficult to understand, or relies on a lot of trendy dependencies are signs of their brilliance.
Train others around them. Listen and learn from others around them. Favour communicating to find the actual problems rather than over engineering the wrong solution In my opinion the ones talking about lots of documentation and design are way off the mark. That's back to the 90s with UML diagrams solving the wrong peoblems
thanks a lot for the help :) somehow didn't notice that when I read the docs
Code comments are code smell. It's an attempt to explain what you failed to convey with code.
&gt; is to write the simplest code required to solve just the problem in front of me. Don't overthink it, don't over-optimise, just solve that single problem as simply as possible. This is fantastic advice, I think, but strangely hard to do‚Ä¶ 
Can confirm. I'm that dev that doesn't leave comments. My team doesn't seem to mind, as long as I keep things concise and readable.
I think it fallows Drafus model. [https://www.youtube.com/watch?v=lvs7VEsQzKY](https://www.youtube.com/watch?v=lvs7VEsQzKY) very good talk. Mainly about effective teams, but goes out of its way to explain how juniors differ from experts and their though process / work patterns. Although, not all professionals necessarily improve over time. It's possible to be a junior level developer and iterate same year for 5 years. A lot of freelancers are like that due to rather monotonic environment and dealing with small / medium scale 3rd party initiated projects. That includes web developer agencies and similar too.
Exhaustive error handling.
What about package management in production, can modules be used? Is it safe for production
Sorry, I don't understand what you're saying. Can you explain?
Measure.
Disagree. Clearly written code may be an excellent way if communicating *what* is happening, but often fails to communicate *why*. Commenting to expose the author's intention is often both useful and necessary.
I can't replicate this, the supplied code works fine for me.
I strongly recommend exercism.io, it's like a tutorial/guide but you have challenges and have to submit your answers which their program checks that you've done it properly. On top of that once you submit your answer a mentor will review it and give you suggestions and tips. I love it
Thanks, even if I don't really have any other idea of things to do, except more rules, like IP, phone number etc. &amp;#x200B; For phone number though, the thing's harsh, as there's an infinite amount of different formats.
Your err checking is far (one statement more) after the statement which may introduce the error. Place the err check after the statement which returns the err, and see if that helps.
I've seen all kinds of code in a professional environment, some of it really terrible. It's one of the reasons why successful tech companies have very rigorous coding and design interviews; just because someone has 10 years of experience in a given language doesn't mean they will code in a clean and efficient manner. And just because someone has only 1 year, doesn't mean they will perform worse then someone with 10 years.
I also tried replicating. Downloaded the file 10000 times, and 40 times concurrently, with the executable built with race detection. Nothing. So my only feedback would be better error handling. There are two errors you are not checking. ``` err := http.ListenAndServe(":3000", nil) if err != nil { fmt.Println(err) } ``` And ``` err = metainf.Write(w) if err != nil { fmt.Println(err) } ``` And the order of error checking is wrong here, check the error before using the value (as it might be nil) ``` metainf, err := metainfo.LoadFromFile("ubuntu-16.04.5-desktop-amd64.iso.torrent") if err != nil { fmt.Println(err) } metainf.Comment = "metainf has now been changed" ``` If you make these changes and keep getting issues without errors, try disabling your firewall. It is a wild guess, but I got nothing else.
Don't call him Shirley
They take any or more responsibility 
This is complete nonsense that I have no idea why you would invent. Code comments serve to explain the portions of the stack which cannot be explained in code. // Inject dependency early so later handlers can access it SomeFunc(AParameter) Explain that in code please.
If you want to get the system's local time zone use `time.Local`, not a hack like `time.Now().Location()`.
I think it depends if you use comments for the what or the why. If you're describing what is happening it might not be the best use of comments since they'll have to stay in sync with the code but in a lot of cases the why might be worth documenting inline. For example if you are integrating with some third party HTTP API and it uses statuses weirdly you might just pop a comment in to clarify that it's not a mistake that you treat a 500 as a 404 or whatever. 
A method has at most one pointer receiver, **always**. You want to know about parameters/arguments. Well, at first, a method with 10 named, different arguments is probably doing too much and should be split. To answer your question: I don't. Usually I try to avoid optional arguments (i.e. ones which could be nil), so nil should not be passed. If it happens, it's a programming error and all bets are off, so a panic is absolutely okay. Handling nil pointers as errors would also poison your method's (or function's) API. Consider this example: [Int slice](https://play.golang.org/p/yhpZXyl4gVV) \- If you'd check for nil values (the nil slice could be argued to be equal to an empty slice), what would you do? Adding an error return value to every function, losing the composability? Trying to invent default values, like the identity function for Map and a constant 'true' function for Filter? This would hide bugs (where nil is errorneously passed) and what if there is no 'sane' default value, like for ReduceLeft? Your program should handle extraordinary circumstances not controllable by the program itself, e.g. failing to write to standard output, broken TCP connections, crazy user input, etc. - programming errors should be exposed instead. Interestingly, this puts me in the [Offensive Programming](https://en.wikipedia.org/wiki/Offensive_programming) camp (despite the name, this is **not** the opposite of defensive programming).
I believe it is more idiomatic to set variables within the struct declaration rather then after. One of the reasons I can think of would be that if the struct changes, if variables are set within the declaration, a compile error or warning telling you what is missing and/or if there are too many variables. Setting them after declaration will do this less often.
&gt;gqlgen I¬¥m sort of happy it doesn¬¥t because gqlgen had a lot going on with the install and configuration when I tried to use it a few weeks ago, although it does have good docs and rich features they hopefully manage to simplify things eventually.
I would say that the one word that sums up good software development is *discipline*, and not all professional software developers have it.
It's a commonly accepted notion. Mentioned in numerous refactoring books. Issue that people don't even try to write clean code because they assume the comments will make code clear enough. And your example of injecting something prematurely so that later on something can access it rather than on need is not a good pattern. Although I recognize it can be necessary evil, the necessary evil you have to introduce to your code is due to the fact that someone made a lot of mistakes earlier already.
And good variable and function naming. 
I'm not even sure what you mean by "why". Seems like coupling here, if you need to tie specific module to some specific business need. Code which is led by excuses in form of code comments doesn't make code of better quality. It's still code which probably is begging for refactoring, now also with additional cognitive load of comments in the view to distract from that fact. Also, another huge problem, you are prematurely convinced that you did the best you can and therefor won't even try to make it better. Because "I explained it in the comments". Sorry, not good enough.
A lot of the stuff in here is really good. I think the thing I notice most is the novice and intermediate try to write perfect code, super efficient, super super reusable. The professional understands they‚Äôre paid to make the needle move. They aren‚Äôt paid for perfection. They‚Äôre stakeholders in their own product, so make it testable and extendable, but make sure you don‚Äôt hold up the project or sprint. I‚Äôm not saying just go in with guns blazing, but ‚Äúgood enough‚Äù is most definitely an acceptable phrase. Just find out what good enough is. Also, priorities. Always know which tasks are most important. Last but not least, learn what your team uses. Don‚Äôt be on docker and barely know how to work it. Be able to contribute if you can. Invest in yourself and learn it. 
Proper formatting and segmenting code into logical blocks. I've had quite some juniors where every function, no matter how many parts it had, was a single continuous block of code. Write comprehensive but in depth comments, that walk the reader through the reasoning and logic of more complex code paths. Proper naming. Rather use a longer and descriptive name than a shorter one. Example: propj and props. Respectively they join and spit a hash of properties. Instead they should be named properties_join and properties_split. Generally someone who starts reading the code base should understand what the function does without having to look up the documentation. Commit often and commit early. Also push multiple times a day to have your progress backed up - you'll never know when the pc you work on goes to shambles. Use chunk commits if you have multiple different changes in a file and don't commit them all at once. That's going to make bisecting and trailing changes harder. Add todos to the code where stuff needs to be updated or replaced with something more performant. Mark portions that work around bugs explicitly with eg BUG and the ticket number, if it exists. That makes it easy to find the code to remove the workaround once a fix is available. 
I'd like to see more junior devs try and aggressively solve problems more without giving up or asking for help. In peace time coding you should spend at least 30 minutes working on a problem before you ask someone. In wartime that gets decreased to 20 minutes. This is not because helping people is a waste of time but it builds the research muscle you need to explore code and find solutions.
&gt; And your example of injecting something prematurely so that later on something can access it rather than on need is a bad pattern Except it isn't at all. In this particular case it's the order of middleware in an HTTP handler. Where order matters of course. Shy of writing all your code in Coq first, you can't escape this sort of requirement. Pretending like your code is 'self documenting' is delusion, and I will not hire anyone who believes they don't need to explain their mindset as well as their approach in comments.
You might as well not use that third party HTTP API. Although I do get your point. On rare occasions comments are necessary evil. But the reviewer should be especially vigilant towards those.
Dependency injection is a bad pattern?
Send Content-Length header? 
If that's commonly accepted pattern within the language done in commonly accepted way, when explaining it is excessive practice. Or it may also indicate that you're creating "God module" if your piece of code is so huge that it's difficult to track the injected dependencies inside. 
\- Write design docs and specs \- Review a lot of documents and code \- Have a lot of their code and docs reviewed \- Work a lot more with others than in isolation 
Refer to programming as an art instead of a science. People who really understand this have been doing it for long enough to know that easily half the job is \*dead body discovery\*, and the art of dressing up those bodies to look as if they belong among the living.
\&gt; Pretending like your code is 'self documenting' is delusion Well to bad you haven't encountered it. Although given that it's common by Gophers to use abbreviations I'm not surprised. That's I guess one of the more nasty practices more common in Go ecosystem I've encountered. Always use full words which have semantic meaning even out of context. As a rule of thumb if what your function does does not fit in it's name, when that function does too much. There are ofc occassions where you would comment / document certain interface methods, but generally that's not needed too as long as you keep your interfaces lean. We do that in our company (around 30 developers) and I would argue that we have less readability understanding intent issues than some other companies which relies on code comments. That's the impression I get when I talk with other people in the industry. 
I'm getting DNS\_PROBE\_FINISHED\_NXDOMAIN for both the link and the main [golangbridge.org](https://golangbridge.org) domain.
They don't get hung up on micro-optimizations that don't matter, and optimize their time on getting a working solution, according to the goal of the product/service they are building, not according to what is most elegant or whatever other fictitious criteria may be floating around. They know that bugs are nearly avoidable and that's OK. They don't let *perfection* be the enemy of *good enough*. This last one seems a little silly but I've noticed it (in my short 6 years in this industry): experienced coders recognize that a development environment is largely a personal choice, so they won't give you a simple answer when asked questions like "what IDE should I use?" (It's a little scary how many people believe that there is actually **an** answer.) &amp;#x200B; &amp;#x200B;
Please show me *any* code that not only encodes the actions to be carried out, but the philosophy behind those actions. I am sure some exists somewhere, but I have yet to see any that was sufficient.
You should not invent your own philosophy of actions if you intend your code to be easy to read for other developers. Stick to conventions. Because now what you insist is on reinventing the wheel and through comments expecting other developers to conform to your reinvention. Sorry, that's not acceptable practice. As for "why" question, you should not write code which is tied to specific side effects. Why question is generally irrelevant as far as code is concerned, if it is, when you're producing coupled code, which is a problem on it's own. You explain the "whys" in readme.md
&gt; As for "why" question, you should not write code which is tied to specific side effects. Why question is generally irrelevant as far as code is concerned These are just 'correct sounding' excuses, rather than any sort of concrete reason. We're not even talking about side effects here. Here is some Perl 6 code I wrote for AOC: @a.categorize({.b ..^ .b+.c}).pairs.race.map: {.key =&gt; set(|.value¬ª.id)}; No side effects there, and an explicit description of what is to be done. Can you actually tell me what this is doing at a *slightly* high level purely from reading that code?
Why should I need to infer something from purely reading the code, when function name would tell me without me needing to read it in detail. Yes it's written in messy way. Instead of writing code comments and leaving messy code you should fix the damn code. For example: ``` flatten(routes) { return routes.reduce((accumulator, route) =&gt; { return { ...accumulator, [route.id]: route, ...(route.subRoutes ? this.flatten(route.subRoutes) : []), }; }, {}); } ``` I don't need to infer anything. It's right there in the name and the argument it accepts. And if you need to dig into implementation details fix a bug there, comments about "whys" won't help you either. 
Good point! :)
&gt; Why should I need to infer something from purely reading the code, when function name would tell me without me needing to read it in detail. &gt; &gt; Just *moments* ago you were telling me that if you needed to use something like the function name, then I was writing 'coupled code' which is bad. &gt; Yes it's written in messy way. Instead of writing code comments and leaving messy code you should fix the damn code. Nothing is wrong with the code I showed you. It even parallelises. You try to give an example which doesn't suffer this problem, but nobody ever denied that some code can be very readable. The point is you couldn't even give me the slightest indication of what my code is doing at a higher level. I believe I have succinctly proven my case.
don't practice hacker rank ? 
&gt; The point is you couldn't even give me the slightest indication of what my code is doing at a higher level. &gt; I believe I have succinctly proven my case. Lower level modules should make NO assumptions where are they gonna be used. You have proven that you like to couple your code.
You cannot know what _will_ happen, but you can take a look at what _did_ happen in the past. From that you make assumptions on how stable the repo is.
Yeah you're just flailing here. The code I showed you is functional and un-coupled. If you're not going to concede the point or offer a counter-argument, please don't bother replying.
Yes, this! That's why my functions have names like algorithm_c_from_parks_buttworth_morgan_efficient_computation_of_nearest_neigbourhs_in_random_graphs_proc_ieee_2011_3_v4_p45_but_using_a_skiplist_as_benchmarks_showed_this_is_10percent_faster_for_our_type_of_input_as_our_data_has_vanishing_homological_degeneration.
com¬∑ment /Ààk√§ment/ - noun - a verbal or written remark expressing an opinion or reaction. ...yes?
You suggested that you comment on where the lower module is being used in higher modules to provide. Which is deliberate violation of SOLID. What other counter argument you need? What suffice as counter argument on your book when?
The first TL that I worked with pointed me to the book, The Unwritten Laws of Engineering: https://www.amazon.com/dp/0791801624/ref=cm_sw_r_cp_apa_i_sg6jCbJA8Q7GC It's a brisk read and sums up what I have found to be true. (Most of what makes for a successful engineer are not technical.)
You write functions which do 54171321 things? When naming is the least of your problems. Like some people just come to prove me wrong throw examples why my assessment is accurate.
Professionals as you describe them have a larger network of other professionals they know, both in meat-space and online, and talk shop with. 
I have to admit I'm a little stumped by the anti-documentation vibe in this thread. I'm having trouble wrapping my head around it. i agree with you that self-documenting code is a delusion. Granted, well-written code using clear variable and function names make a HUGE difference, but I remain unconvinced that they are the sole solution.
&gt;Just &gt; &gt;moments &gt; &gt; ago you were telling me that if you needed to use something like the function name, then I was writing 'coupled code' which is bad. Quote me please. Otherwise please don't make things up. I've said this about comments, not about extracting functionality into functions which what commented code often lacks and smells of. Proper separation of concerns. Functions which do too much etc.
I'm honestly trying to understand your viewpoint better. Do you have any examples of code written this way that we could see? I don't think I've seen any self-documenting code except for relatively simple programs or scripts. As you say, perhaps this is due to a flaw in the code design and laziness on the part of the programmer. This may be a case where examples help prove your point.
&gt; You suggested that you comment on where the lower module is being used in higher modules to provide context No, what I said was that *comments exist to fill the gap code cannot*. &gt; Which is deliberate violation of SOLID You edited your previous post, and added a few points there, so i'll quote them here too: &gt; Should I point you to SOLID? Basic programming principles, are you gonna try to debate that too? &gt; Comments always reveal something innately problematic. And most of the time these are problems which were deliberately put by the developer What's funny is that I was educated before SOLID became a thing and it has very little to say on the subject of comments. Almost all, or perhaps all languages cannot fully encompass both the *purpose* and the *mechanism* of code. The example I gave you above embodies this well. I deliberately stripped it of useful variable names, because these form part of the *purpose* portion. The machine cares not what they are, but they are vital for the human to quickly and completely understand. You say as much yourself here: &gt; Yes it's painful to be thinking of names for 15 minutes. But why are you thinking of names if the code itself is self documenting and is not closely coupled? Because they form a part of encoding the *purpose* of the code. The code I shared above builds a trivial *spatial index* for one of the challenges and this is not immediately apparent by seeing it. Yes perhaps for some people moving it to a function called `build-spatial-index` would be enough of a solution, but this still fails to encompass the ultimate purpose. **Why** am I building a spatial index? **What** drove this decision? This is completely unrelated to close coupling, and entirely related to comprehension, onboarding, and resilience. For a pertinent example, this came up on HN recently: https://news.ycombinator.com/item?id=18772873 Look at the sheer volume and quality of comments and the purpose for them being there.
Making sure you fully understand what is being asked of you to do. Quite often requirements are not well defined and it's up to you to keep plugging away until it's clear what is required. Even if you have to go back a stage to fully understand something and spec it out. If you don't understand then don't stay silent and waste time coding nonsense.
Here are some things I can think of: &amp;#x200B; Beginners solve technical problems, senior devs solve business problems. Beginners solve problems, senior devs help others solve problems. Beginners learn how to improve the quality of their work. Senior folks improve the quality of work of teams or entire organizations. Beginners spend their time thinking about minutiae of a specific problems (use a map or an array here). Professionals spend time thinking about larger scope things (e.g., change the underlying implementation of the map to get 2x speedup across the board). &amp;#x200B;
It's an intrinsic bias. To the person who wrote the code, of course it's trivial and obvious how it works. Of course it is self documenting, because either the author knew what it was doing already, or works in a team with people doing similar tasks. It's very common for someone to come back to their code 5 years later and be utterly stumped as to what the hell they were even doing. This happens with good and bad code alike. I linked this further down the thread, and it bears re-linking here: https://news.ycombinator.com/item?id=18772873
Testable code. Comments that are actually useful. Keep in mind that most code out there is utter crap.
They don't write a custom solution if a suitable one already exists. They know that "consistent" is often better than "correct".
Error for me aswell. How do we join?
All of these things so far listed are kind of true ideally, but in my experience the real difference. Professionals ship code, novices spend all day figuring out the best way to write it.
Your error handling is all wrong. In addition to the comment from /u/mfontani about where the error check should be, you also shouldn't write metainfo if there's an error and should be sending back a different status code: func foo(w http.ResponseWriter, r *http.Request) { metainf, err := metainfo.LoadFromFile("ubuntu-16.04-desktop-amd64.iso.torrent") if err != nil { fmt.Println(err) w.WriteHeader(200) return } w.Header().Set("Content-Type", "application/x-bittorrent") w.Header().Set("Content-Disposition", "attachment; filename=test.torrent") w.WriteHeader(200) metainf.Comment = "metainf has now been changed" metainf.Write(w) }
I made a tiny utility that will let you run a shell command in all your git repos. I mainly use this to do a `git fetch` every now and then using a cronjob. It even has an option to run in all directories in case you wanna do that. So it essentially lets you run a shell command in multiple directores in parallel.
Nice! I would recommend trying to implement `image.Image` for your `Identicon` struct directly, it's not a complicated interface and would prevent some superfluous drawing at runtime.
This is terrible advice. First, learn any language you want. Second, two weeks of C won't make you any better at anything, it'll just make you bad at C. Third, you can learn about pointers, allocation, and structs in Go just fine.
I see this a lot in senior and up too. Overdesigning and trying the newest of the new because their challenge is the code, not the product. 
If you had fun doing it then that's awesome, but do checkout [mr](https://myrepos.branchable.com/)
I cannot share non open source code and now I would need to go through github and search each project. However I can provide examples: float a, b, c; a=9.81; b=5; c= .5*a*(b^2); To this self-documenting code, which shows what is being done: ``` const float gravitationalForce = 9.81; float timeInSeconds = 5; float displacement = (1 / 2) * gravitationalForce * (timeInSeconds ^ 2) ``` And then to this documented code, which better explains why it is being done: ``` /* compute displacement with Newton's equation x = v‚Çít + ¬Ωat¬≤ */ const float gravitationalForce = 9.81; float timeInSeconds = 5; float displacement = (1 / 2) * gravitationalForce * (timeInSeconds ^ 2) ``` And the final version of code as documentation with zero comments needed: ``` float computeDisplacement(float timeInSeconds) { const float gravitationalForce = 9.81; float displacement = (1 / 2) * gravitationalForce * (timeInSeconds ^ 2) return displacement; } ``` Here's an example of a poor commenting style: ``` const float a = 9.81; //gravitational force float b = 5; //time in seconds float c = (1/2)*a*(b^2) //multiply the time and gravity together to get displacement. ``` That's not my post exactly.
That's a great example. Thanks!
What's the point of negating my statements if you aren't providing any justification? My first language was Javascript. I didn't realize the value of learning C until I was 5 years into programming. If we were talking about a high-level dynamic language, I'd say there's no need to learn C. But Go is somewhat of special case. It allows you to use inferred types that resembles the dynamic typing of Python and JS, yet it also allows (and sometimes requires) the use of pointers and explicit allocations. I could see a newbie coming in and thinking that it's easy at first, then stumbling pretty hard with those areas. C is simpler than Go (and many folks who haven't tried it think it's some crazy amalgamation of pointer arithmetic, but that's not the language- that's how some programmers use it). I didn't say you had to become good at C. I just said you should "try" it.
&gt; No, what I said was that comments exist to fill the gap code cannot. Can't really imagine the case. I suppose low level languages cannot be expressed semantically. Otherwise you should not write your code (a language used to program (= give instructions to) computers) as code (to represent a message in code so that it can only be understood by the person who is meant to receive it). Otherwise what you gonna write in your comments? Given that you should not make assumptions where that piece of module will be used. So it stays within it's own context? Usually arguments it accepts and result it outputs. That's fullfilled by doc blocks for dynamic languages and by Type system in typed languages. And the entire process of what exactly is being done is already being documented by meaningful function names and variables names. &gt; I deliberately stripped it of useful variable names, because these form part of the purpose portion. The machine cares not what they are, but they are vital for the human to quickly and completely understand. We write code as much for computers as we write code to other developers. Code itself is communication with other people. Not comments although some people use them to try to explain something. You're code should already speak for itself, by itself. And if that's really really not enough, you can add comments, but in my experience those cases are really rare. Usually you need to refactor the code. &gt; Why am I building a spatial index? What drove this decision? If I need to start caring on precisely why certain decision was made, it indicates problem with the code or it's really complex programming problem. Usually it's the first one. For another developer it's enough to understand that one needs to `build-spatial-index` because some other module requires it, and proper IDE will tell you that right away. Program to API, not to internals.
You don't really need to call `w.WriteHeader(200)`, [it will be implicit from the first real `Write` call](https://godoc.org/net/http#ResponseWriter). And for the first `w.WriteHeader(200)` call, you really should use `StatusInternalServerError` or some other 5xx error instead of `200`. And `metainf.Write(w)` [might return error as well](https://godoc.org/github.com/anacrolix/torrent/metainfo#MetaInfo.Write).
For me its just a difference in knowledge. If you have no knowledge and try to solve a problem then you likely use an existing solution that does not fit for your problem. Worse, sometimes you solve non-existent problems. I experienced this while writing Java and had the goal to make my code more *decoupled*. The solution I found was Dependency Injection - and all of its *implementations* (google guice, spring DI, etc.). I started to use too many features I did not understand and achieved **nothing**. I could not test my code and to date believe that my coupling got worse from that decision. Classes had dependency passed via their constructors but also via private fields. Now, with more experience I do not make these mistakes anymore (I make different ones). I never optimize code upfront. I try to use static code analysis where possible with most restricted settings. Code is formatted by a tool before committing. I ask more questions to get an understanding of the problem.
[removed]
[removed]
Hope it helps. :) Try writing all your code like that atleast for single project. And you'll find out that after a few months passed it will a lot easier to return to what you previously wrote. You don't need to let go of the comments if you don't want to. I bet you'll notice that you have to rely on them to guide you less and less.
[removed]
Ya my bad. Thanks for the clarification 
Your env looks normal. For the tree output, I just meant your project root. 
I figured out the solution. My vscode terminal wasn‚Äôt in the correct directory, so I had to cd into the $gopath
Use version control for every project. Keep the code as clean and as simple as possible. Great code is self documenting. This is supported by good variable and method names, keeping methods short, and breaking down the functionality into logical chunks. Unfortunately you generally have to learn this the hard way, usually buy having to revisit your own code months after writing. At this point it may as well have been written by a stranger. You have to remember, especially in a professional environment, the code will be to be maintained. 
&gt; You write functions which do 54171321 things? No. My functions do one thing. I tried to explain why a name alone cannot (and should not) carry all the weight of documentation to illustrate why comments are not a code smell but necessary. No need for an enlarged argument here: Your opinion on comments is common in the clean code camp and a lot of people take pride in writing "selfdocumenting" clean code. It is just that the OP asked about what _professionals_ do different and good comments do distinguish professionals from the rest. 
 find &lt;root&gt; -type d -name ".git" -execdir sh -c "pwd; git fetch" \; This recursively finds all the git dirs under the root and runs a command in that dir. Although it does run them sequentially unless you background the command with `&amp;`. I noticed in the gloc utility that you aren't using a bounded number of goroutines to run the command. What if I run it against 100+ repos? It is going to launch 100+ commands at the same time. Is your utility very bespoke to your own local problem of operating on a limited number of git repos directly under the root? 
That's a great idea, thank you! Already working on it :)
Oh. You never tried this from your shell? The settings of your editor could have been completely different this whole time. I have no idea how vscode terminals work. Glad you figured it out.
I can relate, C was my first programming language, I didn't just learn it, right after I got used to the basics I started programming and working on personal projects in C, 2 months later, I was contributing to other C projects. After almost a year of C, I was able to easily understand other languages and study them with ease, but I didn't like any other language out there back then, Until I heard of Go and slowly started moving to it. Learning C as a first language helps **ALOT**, not only it'll make you a better programmer but you might find it easier to work with low-level code bases, and if you're interested, you'll be tinkering with compilers, libcs, kernels, and so on.
https://golang.org/pkg/strings/#Index
Testing!
`var prefix string prefixIndex := strings.Index(foo, substr) if prefixIndex &gt;= 0 { // found it prefix = foo[:prefixIndex] } `
Use Index instead of IndexByte, like this: [https://play.golang.org/p/uLNhuQ51J0Y](https://play.golang.org/p/uLNhuQ51J0Y)
Bah, I meant to to make that first WriteHeader call a 500.
Cool! Recommendation: If you swap the argument order so that the first arg is the dir, then you can change the "rest of the args" to be the command, so it doesn't need to be quoted. e.g. `gloc "./path/to/dir" git fetch --something -blah foo bar baz` Removing a layer of quoting makes it easier to deal with any escaping you might want to do for the command itself.
&gt; substring is indeed present before I don't think that's necessary - just check for a `-1` returned from `.Index()`.
Interesting how entire enterprises who lead successful IT departments for decades are not professionals.
The only problem I see to the solution given in the SO post is there is no way to traverse up through the file tree. I think you should add a pointer to the "parent" of a given file to allow this. 
why not just something like ``` fsobj { name: string isFolder: boolean ... } ``` and just store it in an ordered list? 
Well, that's exactly how you check that the substring is present. What I meant is don't do this blindly because it'll panic: func main() { longStr := `something something something something something1 something1 something1 something1 &lt;&lt;special_tag&gt;&gt; something2 something2 something2 something2 something2 something2 something2 something2 something2 something2 something2 something2` fmt.Println(longStr[:strings.Index(longStr, "not there")]) } Instead, check first: func main() { longStr := `something something something something something1 something1 something1 something1 &lt;&lt;special_tag&gt;&gt; something2 something2 something2 something2 something2 something2 something2 something2 something2 something2 something2 something2` i := strings.Index(longStr, "&lt;&lt;special_tag&gt;&gt;") if i &gt; 0 { fmt.Println(longStr[:i]) } }
I'm new to Go, so I'm not completely sure what this does for me. If I start with this project template I'm set up for making a library that i can share?
Probably just a holiday oversight and will magically appear again after the new year.
Hmm, that's interesting. Also, I think I should limit the number of coroutines.
You could either use the semaphore pattern or the pattern of prelaunching a fixed number of workers. 
I have changed it to run only a limited amount of workers. Also a added a flag to override if needed. Thanks for the suggestion.
Oh yeah, thank you.
Even if it was trademarked, you could use it in a factual sense (e.g. describing interoperability) anyway. If you're thinking about using the word in a way that might confuse with or suggest endorsement by the Golang project, that's surely a bad idea.
The name of the language is Go, not Golang, which is merely the domain name. As for trademarks, you can simply look that up: http://tess2.uspto.gov/bin/gate.exe?f=tess&amp;state=4805:rdukex.1.1
Ah yes, of course!
Sorry, I'm checking if there is a new invite URL or if someone can fix the domain name. In the mean time, if anyone wants to post or PM me their email happy to send an invitation manually.
I just pinged them on Twitter to let them know.
you can type assert from an interface back to its original type (or any other compatible type/interface) type FileOrFolder interface{} type Folder struct{} var f = Folder{} var fileOrFolder = FileOrFolder(f) folder, ok := fileOrFolder.(Folder) &amp;#x200B;
Neat project. Maybe flesh out the readme a bit, put some example usage and more information about the project and what its use cases are. 
awesome
[Yes](https://github.com/ttacon/chalk)
Google has a phone formatting and validating library. They needed it for Andorid.. However the library is ported to multiple languages and AFAIR go is one of them.
Why do you want to use golang?
[removed]
 Well, it's possible but it's easier to use other languages mainly because there are frameworks already in place. It's like trying yo hammer down a nail using a bat. The bat will do the job but there are better tools out there.
[removed]
There is a book called **Go Machine Learning Projects** by u/chewxy which was released 2 months ago.
If it's a real project you probably need to define types for everything you want to unserialize. "It's too long" is not really a valid excuse. That being said, you can maybe use the [jsonparser](github.com/buger/jsonparser) package to unserialize only what you are interested in from the payload. 
Hi Mike This looks good. Just posted an issue. I was working on gtk bindings myself, but is far from complete. I would like to abandon my efforts on the bindings and start building the application on top of gobbi. I would like to know what are your plans with the library. Did you create this library because you plan on creating an application based on the bindings yourself? Do you plan to maintain this actively? :) Thank you for your efforts.
Use this page: https://mholt.github.io/json-to-go/ to generate structs from your json.
Is this what you are thinking about? [https://mholt.github.io/json-to-go/](https://mholt.github.io/json-to-go/)
I think so, I'm not sure. I've always done this by hand. :D
Me too... I parse a lot a JSON structures from AWS and Google and I've always done it by hand. So far, I haven't run into any issues and it's all been straight forward even for nested JSON objects and arrays. I thought I remember reading that some people have run into complex scenarios that is difficult (or impossible?) to create a struct and are forced to resort to a map and type assertions. But, I haven't run into that scenario yet.
My current head-ache is parsing json in which every property can be one of: a string consisting of a URL, an object (which has the same structure as the current object we're unmarshalling or 90% of it), or an array of values that can be either a string, or an object conforming to the forementioned rules. :D It's a pretty bad API design (IMHO) but whatever, I'm getting there. I only had to implement my own forked json.Marshaller and Unmarshaller. For who's wondering, the API is the [ActivityPub](https://www.w3.org/TR/activitypub) specification that poweres Mastodon/Pixelfed/Peertube and the rest of the "fediverse".
What made you decide to implement your own json.Marshaller/Unmarshaller vs using the default, declaring your string/object values as interface{} and then type asserting? Did rolling your own json.Marsaller gain you anything? I don't know which way I would implement this if I ran into this scenario.
&gt; declaring your string/object values as interface{} and then type asserting That's mostly what I'm doing - but I'm not usinng plain interface{}. I needed the custom marshaller because there was some additional functionality I needed. Theoretically the output is not plain json but something called JSON-LD, which is a way of representing ontologies using json. This requires some additional behaviour at marshalling/unmarshalling time. Ie, Some properties I want to output as just the string URL I mentioned before, even though they are full objects. Another reason is that a JSON-LD output needs to have one (well, they can be more, but I digress) custom property which does not really exist in the struct. This is called the "@context" and it's used to identify the particular ontology the json object is ascribed to. However over time I feel more and more like implementing my own marshaller/unmarshaller has become a very ugly solution. I might have to revert to using one of the existing json-ld packages. :(
Thanks for you explanation. Makes sense.
If you don't know already, learn how machine learning works, then you can implement a machine learning algorithm with almost any language.
[removed]
Are you by chance working go-fed? Also hello fellow fediverse ambassador o/ 
Yes, internet and documentations
The entire machine learning ecosystem is sticking in Python....
The Go driver has been implemented as a university project and is available at: [https://github.com/ixy-languages/ixy.go](https://github.com/ixy-languages/ixy.go)
All done, this was really helpful! As a bonus \`Identicon\` now also implements \`draw.Image\` :)
I really don't have the time to reply to your post as you're literally repeating the same thing again despite me illustrating why the thinking is not sound. That said, I did click your link, and guess what i found within, advice not to do: &gt; Documenting Variables Never put a comment on a variable declaration. Facts about how the variable is used, its bounds, its legal values, its implied/displayed number of decimal points, its units of measure, its display format, its data entry rules (e.g. total fill, must enter), when its value can be trusted etc. should be gleaned from the procedural code. If your boss forces you to write comments, lard method bodies with them, but never comment a variable declaration, not even a temporary! So haven't you been telling me to do a thing that your own link calls **'how to write unmaintainable code'** ?
I can't find it on Google, if you know where the Perl5 slang project using grammar engine is please let me know, thanks.
There's a book on machine learning in Go at PacktHub. 
Most machine learning tools are written in C or C++, with Python "just" working as a glueing language. Depending on the case, Go has amazing libraries (e.g. a OpenCV 3 wrapper gocv.io and the general purpose golearn library). Regarding OP's question: There‚Äôs the book Machine Learning with Go by Daniel Whitenack which a colleague of mine was quite fond of. :)
At least tell us your github username / project names.
1. project [gitbatch](https://github.com/isacikgoz/gitbatch) 2. project [tldr++](https://github.com/isacikgoz/tldr) 
thank you! I forgot to add them, now added.
If the JSON is huge then encoding/json has a steaming API. Otherwise what are you doing, define your types like an adult.
No unit tests, no benchmarks? How did you conclude its "almost as fast" as the C implementation? I really want to see some form of comparison that I can replicate. Would be awesome.
If you want to escape the mess that is Python libraries I would use a language that was made for this purpose, namely Julia. F# is also a very viable choice. Use the right tool for each job. 
Hmm. What the holy fuck. &amp;#x200B; These WASM projects are really amazing: [https://github.com/golang/go/wiki/WebAssembly](https://github.com/golang/go/wiki/WebAssembly) &amp;#x200B; Then you can do things like: GOOS=js GOARCH=wasm go build -o bumpy.wasm ./main.go And you can build a binary that runs directly in firefox AND chrome: [https://stdiopt.github.io/gowasm-experiments/bumpy/](https://stdiopt.github.io/gowasm-experiments/bumpy/)
Doc blocks are not code comments.
&gt; Doc blocks are not code comments Yep I'm glad to give up here lol.
A doubly linked with parent and child refs. Can be made in any language. Node: - id (unique id or pointer) - nextId - prevId - parentId - childId - isFolder - name
I have... concerns... about the quality of the material published by Packt. Do a search for "Packt quality". I was *very* disappointed with one of their book bundles on Humble Bundle awhile back.
If you are not familiar with basic terminology and can't differentiate between different things which has different functional purpose, when don't pretend to be a an expert in the field.
Hey guys, in regards to the subject, have you tried tensor flow with go? I got great experience with python and I was planning to prepare a workshop with tensorflow, but I am not sure if make use of both golang and python implementations... 
I agree, they tend to be not on par with O'Reilly or No Starch Press. But they tend to release new material much faster than other publishers. 
Hi, nope not working on go-fed. Working on [activitypub.go](https://github.com/mariusor/activitypub.go). A much smaller - both in ambition and in features - package than go-fed. I don't consider it featureful enough for usage in production environments even though I'm using it as the base for an activitypub link aggregator, called [littr.me](https://github.com/mariusor/littr.me).
I should probably clarify that the select group basically mimics a mutex. Do it any other way and you'll probable have data races without mutexes. And I wanted a pure channel implementation. This is more of a proof of concept than something you would use in production.
Both projects look really useful. 
Fish shell. I see you are a man of culture as well.
Just some thoughts. 1. Follow-through. 2. Think about how other people will use the code on a daily basis not just a tested happy path. 3. Meaning log and error message for operational troubleshooting. 4. Ask lots of question is you don‚Äôt understand. 
here's the "real url": https://gophersinvite.herokuapp.com/
Thanks for the kind words rkanchan. I believe that I have addressed the issue that you raised. As for my plans for the library, I'm not entirely sure. It's a little bit chicken and egg. The more it's used the more incentive there is to maintain it. To find out what problems might be encountered when using it for a non-trivial application I've started to put together a gtk application for inspecting docker images. Something somewhat analogous to https://github.com/wagoodman/dive. Even though it doesn't do very much yet, it's already uncovered a couple of issues that I've had to fix in gobbi. What worries me a little is that some of the APIs that are not yet supported might be be tricky to implement. For example subclassing and virtual functions will be a big challenge, but many applications can be built without requiring that. Mike
I'm not sure why you are so agitated. It is funny that I think the "self documenting" code in the comment you linked actually _requires_ a real comment. Newtons formulas are wrong but _very_ good approximations in a lot of cases. Why they are good enough approximations needs a comment. I do not understand how you could interpret my example as an "explain[ation] [...] why developer wrote bad code". You are simply wrong but obviously incapable to admit it.
No.
Yeah, nice projects!
It's truly terrific: [https://github.com/arthurkushman/pgo/blob/master/core.go#L15](https://github.com/arthurkushman/pgo/blob/master/core.go#L15)
There is also https://quicktype.io/ that given the JSON, can generate the structures. 
I'm not agitated but I'm tired people providing examples which support what I'm claiming when pretending they provided a sound argument. 
You are welcome! :-)
No tests?! Classic university project :D 
but why not zero?
&gt; But like I had said, if you are looking at this on the Go playground site, it will always be UTC I'm speachless &amp;#x200B; I UTC alwayls
why not \`[time.Now](https://time.Now)().UTC().Location()\`?
Sweet, thanks!
github.com/mattes/migrate? seems simple enough. It didn‚Äôt exist when we need one, so we created our own.
[flyway](https://flywaydb.org/) 
tnx /u/tenf0ld for the answer. actually, yours and /u/jerf's answer made it possible for me to find what exactly I wanted. So here was it: type Repository struct { d *gorm.DB m interface{} } type iRepository interface { FindAll() []interface{} FindOneById(id uint) interface{} } func GetRepository(model interface{}) Repository { return Repository{ m: model, } } func (r Repository) FindAll() interface{} { val := db.Find(getInterfaces(r.m, -1)).Value return val } func (r Repository) FindOneById(id uint) interface{} { val := db.First(getInterface(r.m), id).Value return val } func getInterface(i interface{}) interface{} { return reflect.New(reflect.TypeOf(i)).Interface() } func getInterfaces(i interface{}, size int) interface{} { if size &gt;= 0 { return reflect.New(reflect.ArrayOf(size, reflect.TypeOf(i))).Interface() } else { return reflect.New(reflect.SliceOf(reflect.TypeOf(i))).Interface() } } this approach allowed me to simply: u := repository.GetRepository(models.UserModel{}).FindOneById(2).(*models.UserModel) us := repository.GetRepository(models.UserModel{}).FindAll().(*[]models.UserModel) fmt.Println(u.Username) for _, i := range *us { fmt.Println(i.Username, i.Role) } &amp;#x200B; tnx guys
[removed]
I have used flyway for the last couple of months I like it. I have already used [Liquibase](https://www.liquibase.org/) but I strongly prefer flyway now.
More "terrific" php goodness: https://github.com/arthurkushman/pgo/blob/master/pdate.go#L25 (don't pass non-ints by mistake!) https://github.com/arthurkushman/pgo/blob/master/pfiles.go#L23 https://github.com/arthurkushman/pgo/blob/master/pfiles.go#L28 (better get those arg counts and types correct or panic) https://github.com/arthurkushman/pgo/blob/master/pstr.go#L16
I'm tired. [https://www.youtube.com/watch?v=ZsHMHukIlJY&amp;t=3s](https://www.youtube.com/watch?v=ZsHMHukIlJY&amp;t=3s) &gt;You are simply wrong but obviously incapable to admit it. Watch the link if you doubt my competence, perhaps someone well regarded and known in the industry will suffice with slides and solid argumentation. It's well known IT consultant, Keviln Henney. The talk is about 7 awful programmer habbits programmers have. Related mainly with code readability. Has specific point about code comments too. I'm agitated because all I do is encounter such attitude such as yours. Unwillingness to accept the fact that one's code could be better. And that you have to fight through such walls of ignorance to punch through that it's exhausting. &gt;A delicate matter, requiring taste and judgement. I tend to err on the side of eliminating comments, for several reasons. First, if the code is clear, and uses good type names and variable names, it should explain itself. Second, comments aren't checked by the compiler, so there is no guarantee they're right, especially after the code is modified. A misleading comment can be very confusing. Third, the issue of typography: comments clutter code. * Rob Pyke, inventor of Golang.
I own it and it‚Äôs shit.
There are at least a few very notable exceptions, but most of their stuff seems pretty bad.
Also Dan Whitenack's book
I have used [goose](https://bitbucket.org/liamstask/goose/) for over 2 years in a production environment. It is not great, but gets the job done. Unfortunately, it is no longer maintained. There are forks available, like [this](https://github.com/pressly/goose), but they are slightly different than the original. [migrate](https://github.com/golang-migrate/migrate) is on my list of alternatives to try out in the future. I took a look at flyway, as others suggested, but I was not happy about it being written in Java, and that the creators withheld useful features from the community version in favor of making money on the commercial versions. I would prefer to use a completely free tool written in Go.
Golang compiles to a single file static binary, so doesn't need package management in production...
I'm not a fan of prophylactic coding that prevents other coders from doing bad things. I'm a HUGE fan of validating all input to the program. Step 1 should always be validation, so that steps 2-n don't need to redo validation at every step.
Terrific answer.
As a hack maybe, but as an example that's not very useful - what do you do if you need a location that's not UTC? May also require additional allocs - would have to test.
&gt; what do you do if you need a location that's not UTC? you idiot? You don't have to worry about what I do about that 
Related recent thread: https://www.reddit.com/r/golang/comments/a6yo8k/do_you_use_database_in_your_go_project/
Wow, you're a real charmer. Don't expect any help here in the future if this is how you behave.
I love the "Credits" section in the README of your projects. I'm often curious what libraries projects use to achieve what they do, so I end up digging through the godoc import graph, but this is much more convenient. :) Anyways great work, thank you for contributing to the community!
https://github.com/ixy-languages/ixy-languages#performance
Just bought this book at your recommendation! Excited to read it. 
Currently using `go-graphql` to build the backend for a side project right now. Really like the api. Plus, resolutions and mutations are incredibly fast, thanks to Go. 
* https://github.com/ixy-languages/benchmark-scripts * https://github.com/emmericp/ixy#compiling-ixy-and-running-the-examples
man, I just posted a link for a book mentioned above... please give your feedback once you read it. it will be even more valuable.
its build into the standard library and super easy to customize and pretty lightweight in comparison to some other routers
Will be sure to do so! Thanks again for posting the link. 
Hmmmm [https://github.com/arthurkushman/pgo/blob/master/CONTRIBUTING.md](https://github.com/arthurkushman/pgo/blob/master/CONTRIBUTING.md) &gt;Your code MUST follow Go recommendations and go fmt &amp;#x200B;
Builds added: https://github.com/dc0d/fstash/releases
well the type should be map[string]struct{Point struct{x float64;y float64};Unit struct{Id_ int64};Alt int64} i believe
That's a nice thing to know, esp. knowing how hard accurate phone validation is (as for e-mail, as the dumb regex I used shows).
Can you elaborate on how it is super easy to customize?
[https://golanglibs.com/category/pdf?sort=top](https://golanglibs.com/category/pdf?sort=top)
The `wk` stands for WebKit. As of yet, nobody has written a usable browser rendering engine in pure Go. It's worth also thinking about that you'd be running a browser engine within a browser engine. Better to think of a different approach.
Well, - you can create submodules easily mounting muxes inside of each other. - You can have wrappers for verbs like GET POST etc really easily - You can set up a wrapper to have url parameters in around 20-30 lines of code at worst etc. etc.
Thanks for clearing that up. Currently I can't tell exactly what's the reasoning that the requirement is HTML -&gt; PDF. So I'm not sure I can just give up on HTML part as of yet. But that's what I'm going to figure out first thing next morning on the job. 
&gt;You can have wrappers for verbs like GET POST etc really easily Can you provide me with some code or article that shows how to do this? &gt;You can set up a wrapper to have url parameters in around 20-30 lines of code at worst And this Thank you
Comment of the year
Either remove the quote marks from around the value of `age` in your JSON, so it becomes `{"name":"John","age":35}`; or change the type of `Age` in your struct to `string`.
Wait so there's no way of asking the decoder to change the type of specific fields ? &amp;#x200B; If not, what are the alternatives to the \`Decoder\` type ? (I did some research and I can't seem to find a way with the regular Unmarshal function)
Checkout the Json.Number type 
I will be using this for a subscription-based web app. Your flow definitely clarifies this process. The step by step helps paint the picture for me. Now, I just need to experiment around with it in action. Thanks for the time.
The documentation [is here](https://golang.org/pkg/net/http/).
I don't really understand the challenge? Make a struct called whatever you want that has a point and a unit struct within it. Unmarshall it and you will not lose any information since the key is duplicated. 
I've had good luck with https://github.com/golang-migrate/migrate. You write the up and down migrations in separate files using raw sql.
You can do it with a field tag on the struct. Example: type person struct { Age int `json:"age,string"` }
You can do it with a field tag on the struct. Example: type person struct { Age int `json:"age,string"` }
Regardless of whether its servemux or anything else, adding any library to a project should always be approached with a "what value does this give me?" rather than "I may as well use this" . There are a bunch of reasons for this but two really obvious ones are 1) your new dependency needs to be versioned, this can cause problems in itself(especially in a world where you don't commit vendor) and 2 its another point of failure. If I use the gin router for some obscure use case, can I guarantee it will behave as well as the standard library? Always keep things as simple as you can and your colleagues will be very happy. For what it's worth , we use gin, standard lib and guerilla mux in production across different Microservices and in our retros we have agreed we will use the standard lib in future just to make context switching that little bit faster for devs. Standards are king. 
Here is a simplified example. package main import ( "encoding/json" "fmt" "os" ) var jsonData = `{"123":{"Point":{"X":1.1,"Y":2.2}},` + `"456":{"Point":{"X":3.3,"Y":4.4}},` + `"789":{"Point":{"X":5.5,"Y":6.6}}}` var structData = map[string]struct { Point struct { X float64 Y float64 } }{} func main() { err := json.Unmarshal([]byte(jsonData), &amp;structData) if err != nil { fmt.Println(err) os.Exit(1) } for id := range structData { fmt.Printf("ID: %s X/Y: %f/%f\n", id, structData[id].Point.X, structData[id].Point.Y) } } Output: ID: 123 X/Y: 1.100000/2.200000 ID: 456 X/Y: 3.300000/4.400000 ID: 789 X/Y: 5.500000/6.600000
Apart from javascript where you would just leave it as an object, most other languages would convert it to a class (a POJO) in the Java world. Structs are no different for this use case. They are also really useful for testing and can help your colleague developers see what your expectations were from the payload. I know it's annoying(it annoys me too) but I highly reccomend defining and unmarshalling to Structs. 
It seems like the JSON decoder parse any quoted value as string, so the Age field content needs to be unquoted. [Example](https://play.golang.org/p/ScDQ8zs3OSP) ``` package main import ( "fmt" "encoding/json" ) var json1 = `{ "name": "John", "age": "35" }` var json2 = `{ "name": "John", "age": 35 }` type User struct { Name string Age interface{} } type IntUser struct { Name string Age int } func main() { var result User // First case: quoted err := json.Unmarshal([]byte(json1), &amp;result) if err != nil { fmt.Println(err) } fmt.Printf("Age type: %T\n", result.Age) // Second case: unquoted err = json.Unmarshal([]byte(json2), &amp;result) if err != nil { fmt.Println(err) } fmt.Printf("Age type: %T\n", result.Age) // As int var intResult IntUser err = json.Unmarshal([]byte(json2), &amp;intResult) if err != nil { fmt.Println(err) } fmt.Printf("Age type: %T\n", intResult.Age) } ``` Additionally you dont need to put double braces on JSON
[removed]
Ah, it's super cool that they were able to phase away the C bits. Apparently that's a very recent change, the commit was pushed 7 days ago. It still sort of miffs me that Go lacks a `volatile` equivalent, even something as blunt as a compiler directive, but it looks like in this case the atomic package does the trick, thankfully.
As someone who has used php since 2002 and go since 2015, panic != die... If you're working on a web app in go, panic is the last thing you want a route doing. :/
For performance \`go-graphql\` is actually the slowest implementation if you want to believe [https://github.com/appleboy/golang-graphql-benchmark](https://github.com/appleboy/golang-graphql-benchmark). I also think that code generation solutions is prettier than using runtime reflection, empty interface and type assertions. I assume that you're referencing \`playlyfe/go-graphql\`, but it also looks like it is a heavy underdog star wise to \`99designs/gqlgen\`, not because that should matter - but the project doesn't look actively maintained in contrary to \`99designs/gqlgen\` that is used in production at a semi-big company.
Been wondering this myself. I just want something dead simple which is contained within the binary without requiring a myriad of imports. Closest I've found so far is BurntSushi/Migration, but it's old and not being developed/maintained. Seems like something that would have a single mature library which everyone used, given how popular Go is as a backend...
Congrats
How do you live with DB migrations not being handled by the application itself? To me, thats the only thing that makes sense...
Thank you for being so helpful. I literally couldn't have found the official documentation of without you. I am blessed to be part of this friendly community full of helpful people just like you.
That's interesting. How did you convince your team to use the standard library which does not offer getting key params from the path? (/foo/:key) &gt;Always keep things as simple as you can and your colleagues will be very happy. I am all for simplicity but sometimes you have to write those extra lines of boilerplate code and how do you keep your colleagues happy with that?
&gt;You can have wrappers for verbs like GET POST etc really easily I do not understand what do you mean by wrappers for verbs. If this is as easily as you claim it to be, can you showcase it to me or at least tell me what do you mean or how to construct it?
Oh very interesting... I didn't know about those benchmarks. It does make sense that runtime reflection would be slower... I just might switch over to gqlgen now that I see that üòÅ I have used node with graphql in production and gqlgen looks remarkably similar to that. Developing with graphql-go has been a good experience though. 
I‚Äôm currently in the process of adding CRUD operations to the mocks. 
Nice. Compare to Mountebank (mbtest.org)
Yep. I never really used/knew about Mountebank, but I‚Äôve heard there‚Äôs a lot of configuration to get it working. I like to keep things simple. Just updated master with the ability to Add, Update, Delete mocks. 
Every single section of this article has something that makes me weep at the blatant and unnecessary cycle waste. Perhaps that's just the price of high level features, maybe I'm growing prematurely old. But without language level support, this DIY stuff feels both extravagant and fragile. As a further point, consider all the things that must be gotten _consistently right in a quadratically growing surface area_, needing to call nextState from all the other functions, reinventing slice access, etc. I can't shake the thought that no human should maintain something like that, it begs for `go generate` or other code expansion. If you're doing all this by hand anyways, how is that any less work than doing mutexes by hand? Or any more reliable if you have to remember to abstract your slices, which you might have several in a struct? The benefits are nice, but come at a high price of misery, I think.
[removed]
When designing a website from scratch, the restrictions the default muxer places on you aren't that serious. I just specify an API simple enough to fit that structure. I only need to get crazier if I'm matching some existing design. There's a lot of flex room in HTTP APIs. Most people don't seem to see it the way I do, but it's just a steam of bytes in the end. Where in the request a bit of data is stuffed is less important than clean code. Or, alternatively, dragging in a huge pile of code so you can parse ints in the path as an id is really silly. A lot of the "advanced" features those muxers support are better unused. (Bonus mobile phone typo of the day: "Most people don't seem to see \[HTTP\] the way I do, but it's just a stream of bees in the end.")
```package main import ( "fmt" "log" "net/http" "os" "os/exec" "time" "github.com/satori/go.uuid" "github.com/spf13/viper" ) func Execute() error { log.Println("Listening on :8000") return http.ListenAndServe(":8000", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { if r.Method != http.MethodGet { http.Error(w, "Nope", http.StatusMethodNotAllowed) return } t := time.Now() url := r.URL.Query().Get("url") if url == "" { http.Error(w, "Nope", http.StatusUnprocessableEntity) return } originalURL := url url = ParseURL(url) # Can be removed, but our implementation provides automatic authentication mechanisms. pdf := fmt.Sprintf("%s/%s.pdf", viper.GetString("WORKDIR"), uuid.Must(uuid.NewV4()).String()) defer os.Remove(pdf) c := exec.Command( CHROMIUM_PATH, "--headless", "--no-sandbox", fmt.Sprintf("--print-to-pdf=%s", pdf), "--virtual-time-budget=5000", url, ) // c.Stdout = os.Stdout // c.Stderr = os.Stderr if err := c.Run(); err != nil { http.Error(w, err.Error(), 500) return } duration := time.Now().Sub(t) w.Header().Set("X-Duration", duration.String()) log.Printf("Generated PDF for %s in %s\n", originalURL, duration.String()) http.ServeFile(w, r, pdf) }), ) } ```
You should make a post on here once you've read the first 2 chapters or something!
Everyone else's advice is correct: define your structs. You'll spend more code validating your interface{}s than you will defining the structs. That said, I will tell you how to handle your nested arrays, since it's a general go thing. You can't do anything with something of type \`interface{}\` until you cast it to something you can do something with, ether a interface type that has some methods, or it's actual, non-interface type. So this case you want to cast to its value, which is \`\[\]interface{}\` (you can discover this by fmt.Printf("%T", x)). [https://play.golang.org/p/5aCXj3ZoeKa](https://play.golang.org/p/5aCXj3ZoeKa) &amp;#x200B;
Wait, WHAT. How did I not know this.
I think OP is used to using tags like 'json:"keyName"' to match up struct names to json keys
Ask this on stackoverflow
I used Mountebank back a fair bit for about four years now. I like to record and playback which isn‚Äôt so much config
This is not immutability. This is encapsulation. To even touch immutability, the setter should at least return new objects instead of changing data in place and returning reference to the same object. Immutability is not about not letting users of a package change some variable. That can be achieved by not exporting a variable. It's about not letting ANYTHING change a variable and usually it's the compiler that ensures that which also enables compilers and other tools to enable a lot of other features and optimizations for example copy-on-write. &amp;#x200B; &amp;#x200B;
I didn't. You have just found your reason to use a library. 
Yep but he has that info in the struct so he still can 
Great works ! How many days did it take to write each project ? 
thank you! tldr took less than a week. gitbatch on the other hand, it took roughly 3 weeks to build a testable product.
Hi I woke up and read your message and it really inspired me to write a new thing in my book addressing your question https://github.com/quii/learn-go-with-tests/blob/master/os-exec.md I hope this helps! 
You can manually implement [UnmarshalJSON](https://golang.org/pkg/encoding/json/#RawMessage.UnmarshalJSON) on a custom type and make it more... flexible in how it reads the input data. I've implemented an example here: https://play.golang.org/p/3dCwKiSkWpk The custom FlexibleJsonInt type is decoded as follows: - If the input data is empty, error - If the input data starts with a quote, it'll be first unmarshalled as a string and then parsed to extract the int - Else, the input data is decoded as a regular int Output: { "field": "" } =&gt; Error: strconv.ParseInt: parsing "": invalid syntax { "field": "-1337" } =&gt; {Field:-1337} { "field": -1337 } =&gt; {Field:-1337} { "field": "0" } =&gt; {Field:0} { "field": 0 } =&gt; {Field:0} { "field": "1337" } =&gt; {Field:1337} { "field": 1337 } =&gt; {Field:1337} 
This is nice but it forces the decoder to expect a quoted value. Passing unquoted integers will no longer work.
beautiful! I took a very similar approach. &amp;#x200B;
Don't know about google maps but youtube is a python script
The ``json:",string"`` tag is intended for this purpose. https://play.golang.org/p/KtyGsGN-7Ym (Sorry for the lack of error checking and good style, it's hard to code on mobile)
Atleast parts of it have been migrated to go.
I find your excess of faith... amusing ;) We routinely assume that a not-insignificant percentage of our users are malicious. We routinely assume that a not-insignificant percentage of the entire internet is malicious. Stand up a new server and you'll immediately get login attempts using default Wordpress credentials, and we consider this to be normal. Yet, somehow, the developer community is entirely benign and above suspicion. Does this seem realistic? After all, those login attempts were written by a developer somewhere. There are thousands, or hundreds of thousands, of skilled developers actively attempting to develop malicious software out there. They ask StackOverflow questions, they star github projects, they're members of the same community that we are. There's nothing stopping them from writing or maintaining packages. And there's no security on any of the package managers to stop malicious code. To be fair, I don't believe the original authors of most packages are malicious. However, increasingly, the burden of maintaining a popular open-source package is getting very hard. There have been a few high-profile people dropping support for their own packages because it takes too much time and effort to deal with the user base. And increasingly that user base is getting less polite and more entitled. We will see more and more popular packages get orphaned or handed over to others to support. Not all orphaned packages will get picked up by bad people, but a few will. Obviously, there's a huge opportunity for bad people here. Most developers don't audit the code on new releases, and malicious code injected into a package will get deployed to production without being spotted. Take over one package and you can inject malicious code into thousands of programs/sites. I don't believe this is a major threat occurring right now. But it will happen, probably soon, and there's no defence against it except to be very, very careful about your dependencies, and the dependencies of your dependencies. The more dependencies you have, the greater the risk that one of those packages will go dark. 
For me, just execute sql one by one before system start. &amp;#x200B; My code separated into several modules, each module deals simple business, so sql is simple too.There are limitations: * create table should always followed by \[if not exists\] * any script should be able to be executed multiple times * some sql would be ugly (eg: postgresql create type does not support check exists, so i have to add magic) Anyway, just simple stupid but works.
&gt;Google Maps Go and YouTube Go Google Maps Go and YouTube Go are Android apps, not website.
Ah. Yes. Though Go no doubt still used in server side APIs.
He did use "withers" which do exactly what you said. Setters are only package local.
I use sql-migrate and have the application run migrations in the startup code. This won't work when I scale horizontally, so I'll likely move over to Flyway at that point.
Alright, I see. Well that's my problem. I love simplicity but I cannot find a good reason to convince developers to use ServeMux.
Adding `,string` indeed allows the usage of quoted/stringifed integers But it prevents from using unquoted ints 
Thanks for the reply. I do the same on my own projects. Unfortunately I have a very difficult time "selling" ServeMux to a team of developers.
Janteloven.
Google is migrating most of backends of their platforms to Go. Especially Google search and YouTube backend if I'm not mistaken.
I got answered in [https://gophers.slack.com](https://gophers.slack.com) The answer I got were: &amp;#x200B; &gt;if it's a TCP proxy, it will only work with unencrypted connections. &gt; &gt;Which might pose a challenge, since encryption continues to increase. &gt; &gt;For the request buffer, the only way to grow it would be to detect that you filled it, create a new slice, copy the data from the old slice to the new slice, and then read the rest of the data. &amp;#x200B;
Just a typo. Thanks!
Maybe I'm stupid, but I don't get this part... 1 &lt;&lt; 1 (shift 1 bit so 21 = 2) = 2 = 21 1 &lt;&lt; 2 (shift 2 bit so 22 = 4)= 4 = 22 1 &lt;&lt; 3 = 8 = 23 2 = 21 4 = 22 8 = 23 What?
Maybe I'm stupid, but I don't get this part... 1 &lt;&lt; 1 (shift 1 bit so 2^1 = 2) = 2 = 21 1 &lt;&lt; 2 (shift 2 bit so 2^2 = 4)= 4 = 22 1 &lt;&lt; 3 = 8 = 23 2 = 21 4 = 22 8 = 23 What?
They're misery likely Java-based as they're on Android.
Bad rendering on mobile or they forgot a ^. Should be: 2 = 2^1 4 = 2^2 8 = 2^3
I guess the author forgot it then, since it's the same on my desktop. But then it's kinda redundant, the author is saying: 2\^2 = 4 = 4 = 2\^2
He might mean 2 = 2^(1) 4 = 2^(2) 8 = 2^(3)
Most large scale back end systems at Google are written in C++ -- for performance reasons. This will likely remain so for the foreseeable future. There is no organized "migration" of systems to Go happening at Google, especially just for the sake of rewriting code in Go. Choosing Go at Google is definitely a good option -- it is well supported and even encouraged whenever its benefits outweigh it's costs (I.e. performance is not critical, and the language/libraries suit the problem). So, many new systems at Google are written in Go, as are many "tools" and other programs where languages like Java, Python, even Bash would have been chosen in the past. It is, for example, a frequently chosen favorite for SRE/DevOps solutions, where simplicity is most often much more important than performance. It is also a great choice for key pieces of infrastructure where performance is not crucially important (and a *lot* of things fall into this category). That said, there is still plenty of Python being written at Google still -- because scripting and a REPL still have their place. Java also has it's strengths.
C++, too (where appropriate).
Immutability is a two sided sword, quite close to the problems you get when using a singleton. You might think ‚Äûthis never needs to be changed‚Äú, but you are probably wrong in the same way as when thinking ‚Äûthere will only be one instance of this‚Äú. I guess that‚Äôs one of the reason why go does not have this feature. The other one is that immutability is mostly an illusion. You use RAM not ROM, so when going down to the bottom of things nothing really prevents you from modifying things besides the compiler (and proper memory semantics). Have a look at c++‚Äòs const_cast as an example. So we‚Äòre talking about a concept that can be worked around and has a tendency of being used unnecessarily or in a wrong way. I mean - ever tried to use the ‚Äûconst‚Äú keyword correctly in c++? Have fun. Takes a while. So long story short - there is a reason why this feature has not been added to go. And I‚Äòm pretty sure it has been discussed by the creators of go. I would rather deal with ‚Äûlet‚Äôs make sure modifying this value does not break anything‚Äú at the moment of writing then ‚Äûlet‚Äôs just mark this as immutable and hope nobody ever changes this‚Äú.
@all Yes that was formatting issue and seems like its corrected now.
I'm in the same boat as you. I haven't had a single project where I could use the default ServeMux. If it at least had parameters and the ability to specify the route method I'm sure that a lot more people would use it. Those are the two most basic things I believe any router should have.
[Maybe this is interesting as well](https://blog.merovius.de/2018/02/25/persistent_datastructures_with_go.html).
https://www.net.in.tum.de/fileadmin/bibtex/publications/theses/2018-ixy-go.pdf
I'm not sure that answer is correct. &amp;#x200B; If you want to forward a TCP connection, you can do just as you've written, just do it forever in a for loop. Or to be more precise, implement what io.Copy does for writing upstream (backendConn) and copying the response to downstream (frontendConn) - each in a separate goroutine. &amp;#x200B; Here encryption is above this layer, so no problem (just your logged stream is gibberish).
The language is called "Go"; and [its authors even put an entry about it into the FAQ](https://tip.golang.org/doc/faq#go_or_golang). The word "golang" is merely 1) the domain name for the main WWW site dedicated to Go; 2) a special keyword to which a popular Internet search engine gives special meaning. Hence I think this word is not trademarked (and cannot, sensibly, be). 
We do it using headless chrome. In short: cmd := exec.CommandContext( cmdc, "chromium-browser", "--no-sandbox", "--disable-gpu", "--virtual-time-budget=2000", "--timeout=6000", "--headless", fmt.Sprintf("--print-to-pdf=%s", fname), fmt.Sprintf( "http://localhost:8080/%s",url ), )
We don't have a Go agent yet, but I'm a developer for the commercial [DocRaptor)[https://docraptor.com] HTML-to-PDF API. It's a pretty simple API and has a more advanced PDF engine than the OS tools.
and when you need to add/remove/change tables along the way?
He doesn't know the key name ahead of time
Unmarshall it into a struct then add it to a map using the ID as the key 
The simplest solution is a go func() { io.Copy(io.MultiWriter(backendConn, os.Stdout), frontendConn) }() go func() { io.Copy(io.MultiWrite(frontendConn, os.Stdout), backendConn) }() 
The issue is that you are trying to read the entire request before transmitting it to the server. This is going to be difficult because there's no way to determine ahead of time how large a "TCP request" will be, simply because there's no such thing as a TCP request. TCP provides a bidirectional data stream where both sides of the connection can send bytes at any time. With specific applications like HTTP, you can look at the contents of the request to determine when it is completed, but that's a bit tedious to implement (and at that point, you have an HTTP reverse proxy, not a TCP reverse proxy). So you're going to need to forward the request bytes to the server and the response bytes to the client at the same time, continuously. If you want to log the request and response, then you can print those out after the connection is closed.
Here is adapted version. But again, it isn't exactly what you want since you're not going to be able to read the HTTPS data. If you want to log HTTPS request/response, you're going to need to perform SSL termination at the proxy -- this basically means that your client sends HTTPS requests to your proxy, the proxy treats it as an HTTPS request (not merely a TCP connection), decodes the request, and makes an HTTP or HTTPS request to a backend server, then returns the response to the client. func forward(frontendConn net.Conn, remoteAddr string) { defer frontendConn.Close() err := frontendConn.SetDeadline(time.Now().Add(5 * time.Second)) if err != nil { log.Fatalf("Unable to set frontendConn deadline %v", err) } backendConn, err := net.Dial("tcp", remoteAddr) if err != nil { msg := "Dial failed for address" + remoteAddr log.Fatalf("%+v %+v", msg, err) } defer backendConn.Close() err = backendConn.SetDeadline(time.Now().Add(5 * time.Second)) if err != nil { log.Fatalf("Unable to set backendConn deadline %v", err) } log.Print("frontendConnected") requestBuf := new(bytes.Buffer) responseBuf := new(bytes.Buffer) ch := make(chan bool) // forward data from client to server go func() { tee := io.TeeReader(frontendConn, requestBuf) io.Copy(backendConn, tee) ch &lt;- true }() // forward data from server to client go func() { tee := io.TeeReader(backendConn, responseBuf) io.Copy(frontendConn, tee) ch &lt;- true }() &lt;- ch &lt;- ch requestBytes, _ := ioutil.ReadAll(requestBuf) responseBytes, _ := ioutil.ReadAll(responseBuf) log.Println("we sent request::", string(requestBytes)) log.Println("we got response::", string(responseBytes)) }
This is invalid JSON: \`{{"name":"John","age":"35"}}\` Curly brackets are for objects. An object contains zero or more name/value pairs, it cannot directly contain another object unless it's embedded as a value, in a name/value pair. For example, this is valid: \`{"person1":{"name":"John","age":"35"}}\` But the API you're using should really return this: \`\[{"name":"John","age":"35"}\]\` Square brackets are for arrays, and array members are comma separated. RFC7159 specifies JSON. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Well sure, but I think it's the simplest answer to OP's question, and most of the time you are dealing with a single client app that will send it in the same way consistently. Don't make it more complex until it's necessary to do so 
https://github.com/thecodingmachine/gotenberg/ is pretty cool. Essentially headless chrome. Runs as a docker image and has a go based client library.
I'm pretty sure it's because OP is printing r.Body, which is a reader of some kind, not the JSON itself.
For the right shift you say: &gt; Shift n of bits to the right and append 1 at the end. It should be append 0 to the (left) end. Otherwise, 4&gt;&gt;1 would be binary(1010), not binary(10)
You create confusion in learner when you write 2^1 =2 and shift only one bit. Please if possible for you try to elaborate on this concept. Thankyou
Why won't this work when you scale? One instance will do the migrations and the others will noop when the version matches. As long as you aren't adding and removing in the same migration you should be OK.
The receivers are struct not pointer so it is a copy
It sounds like you have not used a language with immutable data structures built in. They can enable very elegant and reliable designs when fully integrated into the language and standard library.
Bitch, Intel and AMD‚Äôs billion dollars broke x86_64 don‚Äôt expect dumbass Internet coders to release Coq verified algorithms. Take what you can, give credit, workaround and writecha own.
Good advice. I typically introduce this as one of the first variadic options: [https://github.com/tmc/figma/blob/master/options.go#L15](https://github.com/tmc/figma/blob/master/options.go#L15) ( WithHTTPClient(client \*http.Client) )
I think another one that's especially important with libraries that make requests on your behalf is context. Passing context to a function (and using it in said function) ensures that when you cancel the operation/context, you're not left with orphaned goroutines. This can be most useful in a Web server, where users can easily cancel their requests. Instead of the server continuing to do work in the background to serve the (now cancelled) request, it can cancel any long running operations and free up those resources. 
True, I‚Äòm coming from a c/c++ and thus very low level background. And in c/c++ immutability can become a mess quite quickly and you can always cheat around it - because of the language‚Äòs memory semantics. From an API perspective I can agree that it makes sense to build (im)mutability into the contract but still you need to do so with care as especially in c++ refactoring const correctness in a large codebase can easily break your neck. Also I have rarely seen cases where it gave you actual benefits besides ‚Äûtrust me, I won‚Äôt change this‚Äú which can also be achieved with copies (yes, even though they are more expensive in some cases). So - In the sense of readability and maintainability I still think that immutability does often do more harm then give benefit.
The situation I'm thinking of is: Node 1 starts executing a really long migration but hasn't written to the migrations table yet Node 2 starts executing the same migration, meanwhile node 1 finishes. Node 2 now fails to run the same migration, causing the app to fail to start. You might actually be right in that sql-migrate handles this case already (possibly by locking the migrations table in some sort of manner before writing). I just remembered that Flyway explicitly mentioned support for distributed transactions in the docs.
True, I‚Äòm coming from a c/c++ and thus very low level background. And in c/c++ immutability can become a mess quite quickly and you can always cheat around it - because of the language‚Äòs memory semantics. From an API perspective I can agree that it makes sense to build (im)mutability into the contract but still you need to do so with care as especially in c++ refactoring const correctness in a large codebase can easily break your neck. Also I have rarely seen cases where it gave you actual benefits besides ‚Äûtrust me, I won‚Äôt change this‚Äú which can also be achieved with copies (yes, even though they are more expensive in some cases). So - In the sense of readability and maintainability I still think that immutability does often do more harm then give benefit. [moved]
I used to like variadic functional arguments for options. It seems very nice from using the library. However it makes inspecting and maintaining a library much less straight forward. Following the logic of the \`With\` functions is a pain and they are often stuffed into a \`options.go\` file like you linked above making me go back and forth between files to find the operation of a &amp;#x200B; So it provides a bit of "clean" API to the user by making the implementation full of confusing boiler plate. &amp;#x200B; A config struct is much more straightforward imho, provides clean code in the library and for the users. I am not the only one who feels this way: [https://twitter.com/rakyll/status/1000128803153170432](https://twitter.com/rakyll/status/1000128803153170432)
Big time!!!
This is the most elegant IMO. Other projects like Logrus and GRPC do similar. 
While I generally agree with all points, this part (from "Return structs not interfaces") does not seem right to me: &gt;When returning an interface you are basically declaring an exact set of available methods. If someone were to write their own mock implementation of that interface (for example for the purpose of testing) you are going to break their code by adding more methods to it. That means that while adding methods to library structs is safe, adding methods to interfaces is not. Even if a constructor returns an interface instead of a struct, I can still create my own interface, a subset of the libraries interface, which I then use and mock. See [https://play.golang.org/p/KOm3VFJx6s3](https://play.golang.org/p/KOm3VFJx6s3) Of course, I still return structs if I can, but I am sometimes hesitant to do so when their zero values, despite my best efforts, are not useful.
&gt; Some time ago my friends and I came up with an idea of merging our IRC bots and **rewriting them in Go**. ok. &gt;In order to avoid rewriting most of the already existing functionality we attempted to find existing libraries... huh? He **just** said ‚Äúmerging our IRC bots and **rewriting** them in Go‚Äù. &gt;...existing libraries supporting the APIs used in the bot. huh? wtf does this even mean. Is this super genius thinking they are going to find the same API for a completely different language? This smells like a fantasy-land requirement that some jackass CIO brainstormed while reading CIO magazine sitting in business-class aggravating his haemorrhoids travelling to a IoT convention with guest speaker Elizabeth Holmes. wait... my mistake. This explains it all -- the blog was written by an individual with superior software development experience: &gt;a computer science student and developer. 
I think most programmers, myself included of course, make these mistakes, especially when learning a new language and its standard library. The advice in this blog is right on target, and I was hoping for more salient bits of wisdom.
The points in the blog were reasonable and well made. Would you like to argue with what they wrote instead of discrediting them based on the fact they are still a student? I bet you could find 15 year olds who are better coders than either of us. 
I think the guy just used the wrong terms, you're being unnecessarily rude
"Stop writing open-source code that doesn't solve my problem." You might have good advice in there, but your framing is very bad.
&gt;I bet you could find 15 year olds who are better coders than either of us. I bet this blogger isn't 15, and isn't in this "better coder" category to which you refer. Regardless, the blogger **is** telling the public to stop writing broken go libraries. Yet none of the issues he raised makes any of those libraries *broken*. For example, using globals doesn't make a library broken. As always, it depends on the job the library was **designed** for. But alas, those sans experience bitch the loudest about things that don't make their ill thought "code rewrite" endeavours easy peasy lemon squeezy have to blame someone, some free libraries, that their idea, really just an embarrassingly weak one, wasn't worth even the white board ink. And yes, by his blog title, he is blaming other peoples libraries.
Ah, I missed that. That makes more sense but I think it's still misleading. Isn't a major point of immutability about being able to always pass by reference, being able to have extremely cheap equality checks by just checking references among other things? This approach does not give us any major benefits of immutability really. I think I'd still call it encapsulation.
maybe i just used the wrong terms too.
A big problem I've run across (in node as well as Go) is people not taking advantage of streaming chunks of data for processing. Many libraries that deal with potentially large payloads require the whole content to be loaded into a `[]byte` slice rather than asking for a `io.Reader` and working in chunks.
Well he is clearly frustrated with the quality of the libraries he has come across. And he points out the issues he came across. And it's good to keep in mind when writing libraries. I don't see that op has done anything wrong. 
These, and more, are listed in bullet point form [here](https://medium.com/@cep21/aspects-of-a-good-go-library-7082beabb403)
&gt; Of course, I still return structs if I can, but I am sometimes hesitant to do so when their zero values, despite my best efforts, are not useful. In these cases, why not return a struct pointer? For example, https://godoc.org/net#ResolveIPAddr returns nil pointer if there is an error.
Sure! I made this script for just such an occasion. I wanted to make a web API in Go for checking this, but I thought I would start with just a binary that you could call and give it an argument of one or more names to check (my shell example doesn't, it just runs test cases, but it'd be an easy change to make it do that exact behavior). [Link to Gist](https://gist.github.com/andrewimeson/0643bb0f0e91d830d0d58d128b8b15bd) And inline for convenience #!/usr/bin/env bash # Quick script to test if names are blocked using CleanBrowsing.org's Family # Filter DNS servers DNS_SERVER='185.228.168.168' BLOCKED_AUTH="cleanbrowsing.rpz.noc.org." domain_is_blocked() { for name in "$@"; do result=$(dig "$name" @${DNS_SERVER}) if echo "$result" | grep -q 'status: NXDOMAIN'; then if echo "$result" | grep -A1 ';; AUTHORITY' | awk '{ print $5 }' | grep "$BLOCKED_AUTH"; then echo "Blocked: $name" else echo "Real NXDOMAINi: $name" return 1 fi else echo "Not blocked: $name" return 2 fi done } # Functional tests test_domain_is_blocked() { if [ $# -ne 2 ]; then echo "Expecting two arguments for test" &gt;&amp;2 return 2 fi if domain_is_blocked "$1" &gt;/dev/null [[ $? == "$2" ]] then echo 0 else echo 1 return 1 fi } # Run some test cases test_domain_is_blocked "reddit.com" "0" test_domain_is_blocked "google.com" "2" test_domain_is_blocked "sdfafdadsfjk.example.com" "1"
The complexity between that and this makes them hard to compare.
So, uh, anyone have best practice Context links they could post here for me?
&gt;Every single one of those libraries had some fundamental problems that made it unusable in any real world applications. we'll just leave his quote here. &gt;first three libraries that I found and which I am not going to name here to avoid shaming their authors this one is nice also.
I see nothing wrong with those statements, and it's kind of him to spare specific authors. What's bugging you? 
This is gold.
Ah for locking sql-migrate doesnt handle it currently. I use Postgres, so I do a session advisory lock, run migrations and then release the lock.
I'm also using PostgreSQL - will have to look into this
Truth, enterprise is in its own class of complexity. Still, they had one job.
https://blog.golang.org/context
Here is one: https://blog.golang.org/context
https://youtu.be/LSzR0VEraWw
Is Dave Cheney, who has a vision for the future of go, stating that the current approach is wrong, and imagining how the go team can do better for us in future, or is he literally saying that we should not use it today as it is being used in all the go libraries right now?
https://medium.com/@cep21/how-to-correctly-use-context-context-in-go-1-7-8f2c0fafdf39
I think the idea is that the libraries were labelled as "fundamentally broken" and that even being *mentioned* in the article would be "shame worthy," yet all the perceived transgressions were pretty minor. It comes off as super hyperbolic and unnecessary. Outside that, I personally felt as though the adjustments put forth were absolutely both reasonable and desired... outside of the "return structs, not interfaces" point.
It's basically so promenent it should just be considered at a higher level in the language design. Like channels or goroutines. I have no idea how that would work but I don't like it as it seems like it will have some form of stack traversal like exceptions.
If you produce any code or toolkit for let's say a project, public/private aside, can't wait for you to see nothing wrong when years later a junior hire condemns your work as unusable in the real world -- even though, you know, it *has* been usable in the real world.
It gets passed around to everything, so DI would be the most common way to handle it. Scala would maybe use an implicit?
See https://mholt.github.io/json-to-go/
I have very mixed feelings on this. On the one hand, yes cancellation seems like a fundamental concurrency concern and passing contexts all the way through the call stack is awkward and seem hackish. &amp;#x200B; On the other hand, any alternative would involve language/runtime level magic, which could potentially also be abused in many different ways (unless the designers are very careful). One of the aspects of Go I value the most is the relative lack of magic, and the fact they've managed to keep it that way for 10+ years.
YES IT IS. 
I‚Äôm a former fan of variadic functional arguments as well. It‚Äôs funny that I used them to make my libraries easier for others to use, but I found myself spending more time answering questions about options than anything else. Now I just create a config struct and it‚Äôs simpler for all involved. 
I use context primarily for cancellation, and secondsry (and rarely) for value (logging, tracing).
‚ÄúStop cluttering up GitHub with libraries I don‚Äôt like.
No. The "go" apps are just web-page views, aka progressive web apps
Looks like you did it with fountain codes, cool!
His post is mostly about the lack of acknowledgment of context cancellation, but without much background experience or explanation of why that means that context shouldn't be both cancellation and a bag of values. I think he has a point, but it's not a very compelling experience report and it also isn't a great analysis of ways to fix the situation either.
I never understood the arguments against goroutine local storage. Real OS threads have Thread Local Storage. With GLS implemented as a hash available to each Goroutine, the Context could simply be attached to that and be available to anyone who cares about it. Go is not like Rust, which staunchly opposes global, mutable state. If this is an antipattern at a Goroutine level, I think Go should do more to enforce correctness in shared access of global variables at compile time. If global state is acceptable for certain, specialized use cases, I feel like that is a great example of when it should be used.
Here is some context from a previous Reddit discussion: https://www.reddit.com/r/golang/comments/6s5a7q/context_should_go_away_for_go_2/?utm_source=reddit-android 
Thanks
Don't judge it this early as things might be changed when generics come in and play.
Nice projects. I think I'm gonna use Gitbatch cause' I'm tired of writing all the commands and I'm not super fond of those mega-heavy visual git managers... &amp;#x200B; It's funny because I came across both your projects a few days ago even before I saw your reddit post haha. &amp;#x200B; Btw, I'd be curious to know how you made the GUI for Gitbatch. Did you code everything yourself or did you find a library that does this sort of interface for terminals ? Do you know a resource where I could learn ? Thanks. (tbh I really can't bother looking inside your source code haha :D)
Context is pretty awesome. The majority of blog articles that are against Go or some aspect of the language / std library are basically uninformed.
I haven't tried it i must admit, i'm sure that the API is very nice to use. I tried one of the other similar runtime dependent libraries though. I just cannot help going through the code, because the libraries in Go is always so small that i can have a pretty easy glance at the general implementation. And i have decided on a few rules: * Has to be actively maintained * No reflection * No excessive use of type assertions and empty interfaces(despite it being close to constant time now) * Needs to have some amount of backing(usually just looking at github stars, and if any known companies use it in production) My main gripe with these things is that i simply don't understand why you would chose to solve a program in Go if you need to use these kinds of things, if your problem is so large and requires such a generic solution just chose something interpreted and ducktyped like Python, PHP or Node where it is extremely common to switch on a object w/o any serious overhead. The thing about code-generation is that it lends it self to be checked by the compiler, you can run unit tests that make sense, performance is obviously better. But i am also afraid that Go is going to run into the same problems that Java had when it solved everything with code-generation. I think it especially has some problems because it completely leaks auto-completions and intellisense when you're just coding a generic template so it is harder to debug and test when writing the implementation it self, the code that we generate can become neglected as well of course it is hard to reason about what code is actually running in the application and what is redundant etc. It is just about hitting the sweet spot with code-generation vs custom code vs reflection vs smt else, especially if it is a small developer team that cannot sit and custom code everything. &amp;#x200B;
To append sql after the existing scripts.(eg: alter table if exists tb\_name add column if not exists column\_name, drop column xxx if exists...) &amp;#x200B; Or, add flags to skip executing sql, then do that manually. &amp;#x200B; Many cons and limitations, so i have to pay attention to my sql. I can do that since my module is simple, usually 1 \~ 5 tables. 
If you're creating an service, a pretty standard approach is this: ``` cmd/ myapp/ main.go internal/ - unimportable packages [..] /models /somemodel.go /somemodel_test.go /service service.go service_test.go Makefile packages/ [...] - exportable packages vendor/ [...] ``` If you're creating an SDK package, generally bias to keeping everything as flat as possible, to not force people to import a bunch of packages to use the basic functionality. The AWS SDK is a pretty good example of how to lay out an SDK.
Generally I‚Äôm opposed to global state and I‚Äôm confident there‚Äôs a better solution, but I‚Äôm open to suggestion.
Just to provide a reference to the standard - https://github.com/golang-standards/project-layout
Thanks! Forgot about this.
this sentence makes no sense.
I think drawing inspiration from [trio](https://github.com/python-trio/trio) would be very beneficial.
A bit of a sensationalist headline, but good advice to start the new year! I'll add my 2c: write tests! And Examples!
thank you! I used [gocui](https://github.com/jroimartin/gocui) to render UI. You can check my repo or gocui‚Äôs examples to learn.
I activly use content in my GUI application for tracing and termination long-running processes (run external application in background): https://github.com/d2r2/go-rsync
Stack Over Flow
[JSONiter comes to mind](https://jsoniter.com)
I meant the client of the library instantiating an empty struct, like so: import sucks "github.com/GodsBoss/totallyAwesomeGoLibraryWithALongName" var xyz = &amp;sucks.UnusableZeroValue{} // We want to use xyz here, but it's useless! If a struct's zero value is not useful, I usually hide it (i.e. make it internal to the package), so it is not accidentally used.
[Go-kit](https://github.com/go-kit/kit) has a lot of good examples of microservices.
http.HandleFunc operates on the default mux where you use nil as mux in the listenandserve where mux.HandleFunc operates on the given mux
Created a project with basic layout following domain driven design. Do have a look: https://github.com/MiteshSharma/go-project Mainly we have 3 main packages: api for all api related code, app for all business logic, repository for all DB related code.
Is there hug difference between the two or just way of organizing code?
I think the [upspin](https://github.com/upspin/upspin) project is a perfect example of how to structure your code. Snippet of the structure: cmd/ &lt;- executables go here keyserver/main.go storageserver/main.go upspin/main.go key/ &lt;- domain logic and different implementatons regarding keys go here inprocess/ keygen/ server/ store/ &lt;- domain logic and differen implemenations regarding storage go here inprocess/ remote/ upspin/ &lt;- domain types (models) and interfaces go here upspin.go &lt;- contains: User struct, KeyServer interface, StoreServer interface Basically what they did: * Create a directory named like the project itself to hold your types (upspin.User, upspin.KeyServer, upspin.StoreServer) * Create a directories for necessary domain logic implementations (user/, key/, store/) * Create a cmd directory with sub-directories holding your executables: (cmd/keyserver/main.go, cmd/storeserver/main.go)
Which version are you using: community, pro, or Enterprise? If community, how are you dealing with inability to rollback? 
The fact that flyway ran in Java didn't bother me, we have been using a docker container to execute migrations. Your second point has been a bigger issue for me, I'm not a big fan of these freemium tools.
if you're doing simple 2-3 endpoints http.HandleFunc will be fine but you can't really add much there but using custom muxes you can do things like sub routing 
Thanks for the answer. I had a look at the repo you sent, and I noticed there are multiple files named \`main.go\` in the \`cmd\` folder. How does the compiler know which one is the entry point ? Same question for the tests : how does the compiler know which test file to run first ? &amp;#x200B; As for the way the tests retrieves all the app's main elements (types, functions, &amp; everything that it needs to tests), I'm guessing those elements are under a package name different than \`main\`, so the tests simply do an \`import\` of those elements, right ? (Apart from those \`main.go\` files I described, I didn't see any other part of the program belonging to the main package)
Thanks. I'll have a look.
[removed]
Community. Rollback hasn‚Äôt been a problem for us. If there‚Äôs an issue, write a new correction script and roll forward. Or, take a DB backup first and restore from backup. On a previous project, we used to write rollback scripts for every DB migration, but eventually came to the realization that the rollback scripts were just as complicated (and error-prone) as the upgrade scripts themselves. In a large project with lots of tables and lots of data, there can be a lot of corner cases to trip you up. You do the migration, fire up the app, and then realize it didn‚Äôt handle some corner case properly, so you need to rollback. Buuut, then you realize that the same person that wrote the upgrade script also write the rollback script. And if they didn‚Äôt consider this edge case in the upgrade script, they sure as heck didn‚Äôt consider it in the rollback script either. So, we stopped writing rollback scripts for every migration. If a simple problem occurred, we‚Äôd write a correction script and roll forward. If a complex problem occurred, we‚Äôd restore from backup ( or use a DB feature like Oracle SnapBack / flashback). Also note that sometimes, the original migration script is not a ‚Äòmutate-in-place‚Äô script, but rather a ‚Äòmake a copy‚Äô script. E.g. drop constraints on the table, rename the table to something temporary, create new table with new structure, populate new table with data from old table, reenable constraints. Thus, we have the original data in the event of an issue.
I am not really sure how this would be used. Some things I noticed: I assume the application should just exit when it has gracefully shut down. However, I don't really see a method of calling the shutdown code without sending a signal, for normal termination. In your example, you listen for the graceful shutdown in a goroutine. I assume this has the code to close db connections, etc. Without more glue code this cannot send information to the main routine to do stuff without races. Shutdown code is really tricky. There are arguments for designing your application for being killed without notification - and handle all the situations that can occur from that, or do elaborate shutdown mechanics. I you are interested, I have also written a [shutdown package](https://github.com/klauspost/shutdown2) that facilitates the elaborate shutdown. It is something that I mostly use myself for stuff at work. It allows functions to get notifications about shutdown and allows splitting your shutdown into stages, so shutdown is still concurrent, but allows for certain things to happen before others. I haven't found any major design flaws, but even with this, handling shutdown is really hard.
You're totally correct. The only file that belongs to the main package(s) is the main.go file. To answer your questions how the compiler "knows" which one is the entry point: It doesn't. But you know. Depending on which one you run, this will be the entry point. You can just \`cd\` into the directory and run the main package from there. For example: cd cmd/keyserver/ cd cmd/storeserver/ cd cmd/upspin/ # here you can either go run main.go go build The compiler will then start with the file you gave it and traverse the compilation from there. Regarding the tests, I'm not exactly sure if I understand your question correctly. Tests usually do not require an order of execution as they are self contained. To test everything you can run this command from your project root: \`go test ./...\`.
Thanks for the review, it was interesting to look at the same problem from the other side. I know my package is really a *basic* one, it was pulled from a real project. It just does what it does, nothing more. The only purpose of it to inform an application to do all the shutdown stuff, when a SIGINT was caught. To use it an application should implement all the shutdown logic itself (this is **not** handled by my package, maybe it is not a good idea). Btw, looking through your shutdown package made me think if I have ever properly implemented shutdown logic in my services. 
Thank you for the answer. I'm gonna try to re-organise my project :)
By the way, is there an "official" way of organising a project in Go ? Or does it completely depend on the developer's habits and the type of project ?
This is all you need: [https://www.amazon.com/Web-Programming-Sau-Sheong-Chang/dp/1617292567/ref=pd\_lpo\_sbs\_14\_t\_1?\_encoding=UTF8&amp;psc=1&amp;refRID=T642KX18TQTX52WMP08Z](https://www.amazon.com/Web-Programming-Sau-Sheong-Chang/dp/1617292567/ref=pd_lpo_sbs_14_t_1?_encoding=UTF8&amp;psc=1&amp;refRID=T642KX18TQTX52WMP08Z) &amp;#x200B; Great book.
Each service usually requires its own kind of shutdown handling. It is very easy to make races or hang the process. Therefore it is perfectly reasonable to design for your service to simply die and handle partial results, resuming, etc. After all this is not different than what would happen on powerout, an unhandled panic, etc. One thing I prefer is to have the shutdown code close to where I create the resources. That makes it easier to track and allows easily plug/unplug stuff. In general, if I want to create code that is independent of the shutdown methology I use a `chan chan struct{}` as a shutdown notifier (note how the Notifier is an alias for that). This allows it to receive a notification on shutdown AND send a message when shutdown is complete by closing the received channel. The last part is an improvement over contexts that cannot signal that shutdown of a module has completed. It does however require the caller to actually *listen* to the channel and signal that it has completed.
I don't think there is an "official" way. It mostly depends on your use case. If you just have a simple command line tool, you're probably fine by having a flat file structure and only a single main package. If you (plan to) have a bigger project you can use a file structure like upspin.
i agree. i also feel like cancellation IS contextual -- that is: i feel like a notion of "should this function even continue" should be part of that bag of information. 
https://medium.com/@egonelbre/thoughts-on-code-organization-c668e7cc4b96
I wrote a go program modeled after your script. The tricky part for me was that the data you are looking at (for the $AUTH\_BLOCKED) check is the SOA record, and that isn't available in Go's stdlib net package. I ended up using [github.com/miekg/dns](https://github.com/miekg/dns) which lets me make and inspect DNS queries with more flexibility. The "go way" of indicating an error or not is to use an error return value, so the domainBlocked func returns an error if either the domain is blocked or not found. If everything is ok, a nil error value is returned. &amp;#x200B; [https://play.golang.org/p/RnBs0CTvT-u](https://play.golang.org/p/RnBs0CTvT-u) &amp;#x200B; `package main` `import (` `"errors"` `"fmt"` `"os"` `"strings"` `"github.com/miekg/dns"` `)` `const (` `dnsServer = "185.228.168.168:53"` `blockedAuth = "cleanbrowsing.rpz.noc.org."` `)` `// domainBlocked checks if the domain is blocked or not found` `func domainBlocked(domain string) error {` `m := new(dns.Msg)` `// needs to be fully qualified, so append "."` `m.SetQuestion(domain+".", dns.TypeSOA)` `// m.AuthenticatedData = true` `ret, err := dns.Exchange(m, dnsServer)` `if err != nil {` `return err` `}` `// I've only seen one NS record in responses, but since a slice` `// loop over all` `for _, ns := range ret.Ns {` `// grep "$BLOCKED_AUTH";` `if strings.Contains(ns.String(), blockedAuth) {` `return errors.New("blocked")` `}` `// RcodeNameError is NXDOMAIN` `if ret.Rcode == dns.RcodeNameError {` `return errors.New("not found")` `}` `}` `return nil` `}` `func main() {` `for _, domain := range os.Args[1:] {` `err := domainBlocked(domain)` `if err != nil {` `fmt.Printf("%s error %s\n", domain, err)` `} else {` `fmt.Printf("%s ok\n", domain)` `}` `}` `}` Here is an example running it with your 3 test domains: `checkblocked` [`reddit.com`](https://reddit.com) [`google.com`](https://google.com) [`sdfafdadsfjk.example.com`](https://sdfafdadsfjk.example.com) [`reddit.com`](https://reddit.com) `error blocked` [`google.com`](https://google.com) `ok` [`sdfafdadsfjk.example.com`](https://sdfafdadsfjk.example.com) `error not found` &amp;#x200B; &amp;#x200B; &amp;#x200B;
Ok this time last question haha. So I've just re organised my my project. I created a `cmd` folder where I have my main package, a folder named after my project containing all my structs/methods (under a package named after my project), and a `test` folder containing my tests under the package... `test`. The problem is that before calling all my test functions, I have to initialise the app, so in other words I need to call what's inside my `main` package. How do I do that since I can't do `import "cmd/main"` ? I have an `Initialize` method where give set all the parameters for the app to run.
[GRPC](https://grpc.io/) with [grpc-gateway](https://github.com/grpc-ecosystem/grpc-gateway) .
How does it help in documenting APIs?
This is a little bit hard to follow for me, but I'll try my best. (Maybe you can provide a github link with your current code so far). I think, what you're trying to approach is having a test package/directory with all your tests. This follows the same logic like models, helpers, utils, which should be avoided. You should place your tests right next to the thing you're testing, e.g.: api/ handlers.go handlers_test.go Containing: // handlers.go package api func (s *Server) IndexHandler(w http.ResponseWriter, r *http.Request) { // ... } And: package api func TestIndexHandler(t *testing.T) { srv := NewServer() // init server // ... init http recorder srv.IndexHandler(rec, req) // ... check for errors } Check out this tutorial on how to test your http handlers: [https://www.youtube.com/watch?v=hVFEV-ieeew](https://www.youtube.com/watch?v=hVFEV-ieeew)
I use https://github.com/swaggo/swag It is pretty easy to set up while not being so bloated like other tools.
It is actually quite common to be able to accomplish the same thing in multiple ways. In Go, we tend to suggest that you use the simplest and most readable way that still gets the job done. In this case, you can create your own ServeMux or you can use one that is created for you, http.DefaultServeMux. The latter is what the top level functions in the http package implicitly use. This is also the one that will have helper handlers from packages like debug/pprof automatically attached, so it's most appropriate for top level routing set up by main. If you are making a package and writing tests, making your own mux probably makes more sense as it's more self contained.
Thanks. I'll have a look
Maybe I'm missing something: lines *29* and *39* feel *wrong*. You don't want to use a buffered channel. Instead of line *39* just close the channel. Closing a channel unblocks all receivers of that channel.
&gt; To append sql after the existing scripts.(eg: alter table if exists tb_name add column if not exists column_name, drop column xxx if exists...) &gt; &gt; ‚Äã and what I a) remove column b) change its type c) change its type partially?
Seems it doesn't
thanks for pointing this out. Do you add all comments in your API code and generate documentation using these comments? Assuming i use it for my project, i should force the team to add these comments on each API, right? 
Thanks. Yes, I think you‚Äôre right, since I don‚Äôt pass any actual data to the resulting channel. 
What's the value of porting REST APIs TO gRPC? If you want other applications to use your API then just use your API. If you want the feature set of gRPC then why bottleneck it by using a bunch of RPCs built to be RESTful. 
[removed]
There's a swagger docs generator. You define a protobuf service and comment it appropriately. It will generate swagger docs for the generated http endpoints
Grpc gateway has a swagger docs generator
Grpc has a lot more features but some Enterprise systems don't support http2 for things like authentication, security and proxying. To that point, allowing a restricted set of rest services can be valuable especially when they're generated.
We use schema-first API design, it looks easier then using special comments handled by swagger schema generation tools
On the contrary, reading this would be beneficial: [http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/)
Like which languages?
1. Do you make sure no changes go through without being updated in your API design document? 2. What if someone changes the code and missed to do changes in API document, was thinking if we keep both code and document together, it might be easy. can you give some points from your experience, what kind of problems you faced, why you chose schema-first API design, how hard it is to maintain?
Clojure is the one I have the most experience with.
See [https://app.quicktype.io/](https://app.quicktype.io/)
\+1 I like it because its light weight. The issue for me is the end binary is very large (40MB) for a barebone endpoint setup. But its a small complaint. &amp;#x200B;
Yes, I document all the endpoints. I wouldn't say force your team; if they don't document it then it won't show up on the UI page, simple as that.
We chose schema-first API design because we didn‚Äôt want our APIs to depend on language concepts, since our team develops services written in different languages (mainly in PHP, Golang, and NodeJS). I have rewritten some legacy services in Go for better performance keeping exactly the same API and the same swagger-schema. Maintaining this API design is not really hard for our team, because we always keep our APIs backward-compatible. And every non-breaking change is been discussed, then been documented in the schema, and, finally, changes to the code are made. 
A great/complete stdlib for Go is part of the reason we need so few packages. Packages in Go are usually just nicer/easier ways of doing what the stdlib already does. Packages in Node are almost required to do anything. Nodes NPM package chaos isn't even usable on lower end systems. I had 19 packages that imported 900+ other packages resulting in 1GB+ RAM usage on builds maxing out small a small VPS.
Not a book but an excellent online course: https://www.udemy.com/go-programming-language The course contains plenty of video lectures and hands-on exercises with solution walkthroughs and mountains of sample code. Todd is an excellent teacher, and I enjoy like his overall style. I'm accessing the course for free through my company's portal, but I just saw the price now when looking up the link, and at ten quid on sale, it's an absolute bargain in my opinion. 
But that's the statu quo, really. 'Functions taking a context or not' is basically the 'functions being async/returning a Promise/etc. or not' of modern Go. A truly 'colorless' Go would just have implicit contexts everywhere, just like it avoids colored I/O-ful functions with an implicit scheduler managing every stack.
OP didn't say their API was REST, did they?
If the schema is grpc/protobuf, I'd consider the schema to be the design document. Code is generated from the schema (assuming you use supported languages). So it shouldn't be possible for the design doc and the code to ever diverge. If you prefer something prettier than protobuf, there is a tool that'll generate html. Think it's called protoc-gen-doc.
Sure. Show us the code. Why do yo use a sync.Map? For preventing multiple requests starting the shell at the same time, you can use a simple sync.Mutex. For preventing that and also serving the result to all concurrent requests, golang.org/x/sync/singleflight is the best. To cache all this, use groupcache. The possibilities are endless till we know more about the probkem space.
1) define your API endpoints, as well as any documenttion using the google-api annotation standard inside a proto file: [https://github.com/googleapis/googleapis/blob/master/google/api/http.proto](https://github.com/googleapis/googleapis/blob/master/google/api/http.proto) as noted in the 7th step of the README here: [https://github.com/grpc-ecosystem/grpc-gateway](https://github.com/grpc-ecosystem/grpc-gateway) &amp;#x200B; 2) If you plan to use GRPC, you can use grpc-gateway now to both generate GRPC and REST endpoints in one command, as well as an agnostic definition of your payloads that can retain backwards compatibility with some simple steps - [https://developers.google.com/protocol-buffers/docs/overview](https://developers.google.com/protocol-buffers/docs/overview). You implement a GRPC service satisfying your protobuf definition, then the restful service will communicate with GRPC to handle requests. This can be set to internal only, meaning that if all you care about is serving REST, you can do so and leverage GRPC for internal communication only. While this step may seem like an excess, note that with GRPC you can utilize bidirectional streaming [https://rakyll.org/grpc-streaming/](https://rakyll.org/grpc-streaming/) , load balancing options [https://grpc.io/blog/loadbalancing](https://grpc.io/blog/loadbalancing), among plenty of other perks that you may want to consider or be prepared sooner rather than later. &amp;#x200B; 3) If you do not plan to use GRPC, you can simply ignore the GRPC generated code in the proto files and manually define your REST service via another system. You can still use the generated payloads to communicate between services, and have the preparation if you adapt to GRPC in the future, you just need to implement the services. To others, you can simply present the swagger-generated file from your proto definitions (here's a bit of everything inside proto to generate swagger) [https://github.com/grpc-ecosystem/grpc-gateway/blob/master/examples/proto/examplepb/a\_bit\_of\_everything.proto](https://github.com/grpc-ecosystem/grpc-gateway/blob/master/examples/proto/examplepb/a_bit_of_everything.proto) and when they ask for a data dictionary, you can refer to your proto file later. &amp;#x200B; 4) Use swagger to generate client side code (typically typescript/javasript), as well as postman definitions. Since this step is independent to anything specifically grpc/grpc-gateway, I felt it needed to be it's own &amp;#x200B; &amp;#x200B; &amp;#x200B;
They asked about Swagger.
Using go-swagger for REST apis and we auto generate swagger docs for RPC APIs. I wrote a small guide on using go-swagger within your project -&gt; [LINK](https://www.ribice.ba/swagger-golang/).
I think there is some point where the config struct is too unwieldy and fully configuring one takes alot of lines. One example would be tls.Config{}, lot of interdependent values etc. The worst way of providing arguments is DSNs in database/sql. Requires globals and init() functions... configuring tls connections becomes way too complicated etc etc. 
Any particular reason for using OpenSSL instead of the standard library AES GCM?
https://www.usegolang.com/
How much does that shrink down with ldflags and upx? 
You should probably trust other people on your project to not arbitrarily poke at immutable values.
Mine are always about 11mb, it might not be swaggo whivh causes the issue.
Yes, that's what I do. I also have one step in my ci whivh checks if the swagger.json was generated, but I just try to remember updating the comments whenever I change something about the API. Also have this on my checklist when reviewing prs.
fmt.Sprintf on urls gives me the heebie jeebies, I prefer something like path.Add or working with url.URL
I work at a company called omnio, with documentation hosted at [https://api.omnio.io/](https://api.omnio.io/) &amp;#x200B; I hand write that documentation with the openapi specification and use ReDoc to generate the documentation. Our new version of the API is switching from a regular webapi to graphql though, and in graphql using \`99designs/gqlgen\`, you develop the schema and then you generate the code. You get a playground for free as well, where api users can play with your API in a interactive fashion, i honestly think interactive documentation is just the best.
Golang for Data Science
The nodejs core library isn't terrible though. I think it's more a reflection of the mentality and of the average level of skill of the js community. 
Trio's lessons aren't very much tied to the async/await model.
No aware of this option, what is it? and how do I pass it when doing a gobuild?
Here is the [code](https://gist.github.com/keith6014/db470f8e5ab3b6ef211218fecee3e48e) You can do a simple `go run -race main.go` and in another shell you can issue curl commands to it. I put some comments in the code. I use a map because I want to keep each command as a key. I plan to run many commands (10+) in the background. singleflight and groupcache both look interesting. Thanks for mentining those, i will need to play with. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
I usually use *no* Router over any 3rd party router - I don't use `ServeMux`, I pass an `http.Hander` directly to `Serve`. But FWIW, the simple prefix-matching of `ServeMux` is probably the only routing that is general enough to be useful. Just don't put every single endpoint into a single `ServeMux`, but nest them, with one path-component per Handler.
&gt; How did you convince your team to use the standard library which does not offer getting key params from the path? (/foo/:key) Use `http.Handle("/foo/", fooHandler)` and then do `key := strings.TrimPrefix(req.URL.Path, "/foo/")` in `fooHandler.ServeHTTP`. i.e. there is no actual need for "key params", they are just path components, treat them as such. I described the approach in more detail [in this blog post](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html).
I make the APIs with protobufs, which generates the swagger docs, gRPC API handlers, and a JSON interface. I wouldn't think of doing it any other way currently, personally.
If I remember correctly tensorflow does have golang APIs
got it, thanks. Steps for writing API with document: 1. Make sure comments are added, give comments to add to the team or add urself if you adding 2. Generate swagger json during CI process 
Yeah it‚Äôs mentioned on GoDocs 
Excellent timing. I was just researching this. 
You can still use Ruby/rake if you are already comfortable with it, no rails required.
[standalone_migrations](https://github.com/thuss/standalone-migrations) üëå
I built my own, essentially porting [Flyway](https://flywaydb.org) into go. Sadly it's closed source, but flyway isn't and it's a pretty simple programming problem to solve anyway. Keep track of the state using a version table, and have some sort of distributed mutex lock. I was not impressed with any of the libs I researched and I had a rare persistence layer to target anyway, but go is good for this kind of thing.
It worked this way, thank you so much :)
Thanks, this looks interesting. swagger-go has more stars on github which suggest it is stable and used by lot of users. Will surly check this out. How is your experience with this library, any specific point to take care of while using it?
This is awesome. Also nice to see FB using Go. Thought they were more of a C++ shop for projects like this (folly and all)
in pure golang implementation need to load whole data in memory for en/decrypting 
It makes sense. There's surprisingly very few libraries available with a modern encryption scheme that also supports file encryption^1 . OpenSSL (and probably LibreSSL/BoringSSL) fills that gap. The only other library I've seen the ability to do file encryption is [Monocypher](https://monocypher.org/manual/advanced/aead_incr). ^1 When I say file encryption I mean streaming-based encryption which seems mostly useful for encrypting data that cannot fit in memory.
https://blog.filippo.io/shrink-your-go-binaries-with-this-one-weird-trick/
First time seeing a project with gqlgen and SQLBoiler and it's pretty alien to *me.* I'm curious what your experience was like using that combination?(pain-points, productivity etc.) I'm not that familiar with gqlgen or SQLBoiler so can't give feedback for structure etc. here a few general ones: * Keep the client and server code separate. Source tree will look a lot cleaner! * Stick to one dependency manger I see both dep and glide. (Also consider giving go modules a try) * Packages like "common" or "utils" are considered unidiomatic they will slowly become a kitchen sink. P.S. The end result is great. 
This ReDoc looks interesting.
awesome! &amp;#x200B; It's good to see more tile related projects. &amp;#x200B; I was searching for tile effect libraries the other day and all I could find was the python lifxlan tile effects [https://github.com/mclarkk/lifxlan/blob/master/examples/tilechain\_falling\_rainbow.py](https://github.com/mclarkk/lifxlan/blob/master/examples/tilechain_falling_rainbow.py) and my own photons library [https://delfick.github.io/photons-core/tile\_animations.html](https://delfick.github.io/photons-core/tile_animations.html)
&gt; I'm curious what your experience was like using that combination?(pain-points, productivity etc.) I like both gqlgen and SQLBoiler. They're fast, they just work, they give you static types to use in contrast to `interface{}`, and in the case of SQLBoiler it seems to provide a zero-cost abstraction. Some pain points and nits: - Not sure if I'm just doing something wrong, but gqlgen seems to want the source structs it works with to be in the same package as the code it generates. That is resulting in the generated output of both gqlgen and SQLBoiler being dumped to the same directory (`models/`), which is a lot of generated code. There's one or two files that I also maintain by hand in that package that are lost in all of that. - Working with generated code makes it hard for someone to see at a glance what's going on with the repo, because the history is messy. - gqlgen generates code that requires client code to use pointers for optional types and non-pointer structs for required types, and I'm not sure that's the right approach, but it hasn't cause any difficulties yet. &gt; Stick to one dependency manger I see both dep and glide. (Also consider giving go modules a try) This project is an archeological dig. It started out with https://github.com/olebedev/go-starter-kit and has gone through several major changes in libraries before settling on the current set, which I think will do the trick for a while. I hope to switch to the new go modules before too long.
I would go for a slighty different format where the loop over the items is separated (in case you need to change other fields too) and then use the simple one. It's far more readable, it's simple and therefore easy to maintain. Better is to pass an item to the adjustprice method (instead of a Num1), so it won't have to loop after all. (Which will be the fastest solution) func (o *Order) AdjustPrice(pos, price int) { o.LineItem[pos].Price = price } order.AdjustPrice(0,25) // then you can do this or making it even more simple like this: func (it *Item) AdjustItem(price int) { it.Price = price } order.LineItem[0].AdjustItem(55) // then you can do this BTW, my compliments for setting it up like this with having it working in the playground. That is super convenient.
thanks for mentioning this. I never knew this existed. (like a late x-mas present hahaha)
I understand what you are saying, but isn't this the whole point of having stuff out there in the open. If it doesn't fit your needs, then fix it? (or choose another piece of software that does forfill your needs?) What if the library you picked was just doing fine, untill you spotted it. So you want it to behave slightly different. Use Nike's motto: just do it! ;-)
I've used it with a couple of small apps that in production with no issues.
Can it be used in VSCode? ü§î
&gt; The license granted hereunder will terminate, automatically and without notice, if you (or any of your subsidiaries, corporate affiliates or agents) initiate directly or indirectly, or take a direct financial interest in, any Patent Assertion: (i) against Facebook or any of its subsidiaries or corporate affiliates, (ii) against any party if such Patent Assertion arises in whole or in part from any software, technology, product or service of Facebook or any of its subsidiaries or corporate affiliates, or (iii) against any party relating to the Software. Brutal.
Mostly Python for things like this that aren't directly in the path of serving pages to people, though usage of Go has been steadily increasing. 
There is, see here: https://github.com/golang-standards/project-layout
What OS and Go version do you use? If you are running Windows this is probably expected. Windows has a low resolution timer (it can be changed to have higher resolution, but only on a whole-system level which leads to problems with other programs). Running your code on a Linux (amd64, Go 1.11.2) gives me: 196ns 43.214¬µs 45.211¬µs 46.55¬µs 49.147¬µs 10.164316ms 20.365658ms 30.522777ms 40.610311ms 50.776836ms Which seems ok.
Didn't react have a similar license?
There is a migration package for go
`time.After` has shown up on my profiler before when called really often. It has the overhead of needing to allocate a new channel every time and start the async resource. I switched to `NewTimer` (like the docs suggest) for cases where it is constantly reused. 
on macOS (Mojave), go1.11.2. &amp;#x200B; good to know it much less on linux, I should have probably tried it on a server before posting. &amp;#x200B;
Yes, and it got deleted due to the outcry and developers moving away from React.
Just for disclosures sake ^ works at lifx. Also so do I (for the next two weeks). 
Y'all gophers should [support Dominik on Patreon](https://www.patreon.com/dominikh/overview). His stuff probably saves you way more than a couple of dollars' worth of time.
Awesome
Nice one... I never wrote a lot of Ruby and all my experiences just ended with rails. will keep this in mind when next I have to do some Ruby shenanigans :)
Sometimes I just don't get this crap. The paragraph above: &gt; Facebook, Inc. ("Facebook") hereby grants to each recipient of the Software ("you") a perpetual, worldwide, royalty-free, non-exclusive, **irrevocable** (subject to the termination provision below) license under any Necessary Claims, to make, have made, use, sell, offer to sell, import, and otherwise transfer the Software. For avoidance of doubt, no license is granted under Facebook‚Äôs rights in any patent claims that are infringed by (i) modifications to the Software made by you or any third party or (ii) the Software in combination with any software or other technology. Emphasis mine. Also following convention, the license is clearly [BSD] (https://github.com/facebookincubator/dhcplb/blob/master/LICENSE). I don't know what this [PATENTS](https://github.com/facebookincubator/dhcplb/blob/master/PATENTS) file is, but it is not a pattern I am aware of. My internet-post-only-law-degree would think this is dual licensed, and would not stand up to a challenge. Of course anyone who has the money to challenge FB on something so trivial would just re-invent the wheel.
An api for making JS programs? Why should I want to use a typed and compiled language like golang for get performance of a javascript application?
There are bindings for GTK+ and QT and other GUI libraries probably as well. Please don't recommend electron bridge.
Ye, I also find it weird that it was in the patents file. It feels like it would collide with any other license in the project. Maybe they just copied some project template and didn't bother to remove it?
like \`alter table if exists table\_name drop column if exists column\_name ;\` &amp;#x200B; The key point of this solution is, sql can be executed multiple times without pain, so i do not need to check executing logs or effects.Not all sql works, some may need to do tricks.Or, just give it up. &amp;#x200B; I did this in quick prototyping, deploy to test environment. &amp;#x200B;
&gt; I mean - ever tried to use the ‚Äûconst‚Äú keyword correctly in c++? Have fun. Takes a while. So long story short - there is a reason why this feature has not been added to go It's incredibly ironic that you're using C++ as an example because C++'s const is a poster child of immutability-except-not-really. I would learn how immutability actually works before writing a rant about it on the Internet.
Yep I saw this repo. Something is not very clear to me. Is this structure used for ONE project or for multiple projects ? The README says that the `cmd` folder is for the "main application**S**" (so the entry points used by the compiler for each project to compile). It also says other things, like, for example, the `pkg` folder is used to share all the public packages that can be reused by other projects. So it really seems like this way of doing things forces us to "divide" our programs and place all the different bits in some folders next to other folders of other, different projects. Is that right ? If it is, then I don't see the benefits of it. It would mean that when we work on one of the projects in the IDE, the IDE actually displays ALL the projects in the tree view. What about Git ? One repo would contain multiple projects... Also, what if we want to work on some smaller projects that don't require a complex structure ? I come from a Javascript/PHP background and, especially because I do some Symfony a lot, this way of doing things seems quite *exotic*... Btw if I'm correct the README says this is not an official way and developers can really do it the way they want.
It's neat to see LIFX still chugging along. I wasn't hired to (I'm a web developer) but as happens in startups sometimes I ended writing the LIFX wire protocol, firmware HAL, scheduling and interpolation code as well as the early cloud pub/sub and other odds and ends. No idea if any of my code is still used and can only apologise if all curse my name daily but we needed to ship something.
&gt; `[` and `]` require very little effort to type ... There are probably more non-English keyboards than English keyboards out there.
They don't specify how much is written in Go. They also say Go is the language of the internet? See it's stuff like this that makes it seem like it's this magically great web language but I believe it tends to be used more for dev ops or security. Sure there are big companies with big pockets, who can do a rewrite but I just don't think that's the norm. So young people reading this are going to get confused.
You're right, I didn't think too much about minor syntactic details like that in the beginning. The choice of square brackets was somewhat arbitrary and it stuck.
Funny, I've never seen Go development come up on r/Reddit...
Hey /u/ajaymt, its great to see golsp come so far! Inspires me to build my own lisp (maybe someday... Or perhaps a C compiler). Is pattern matching still O(n)? It would be a great improvement to get it to O(logN) or even constant time!
Can‚Äôt wait until this supports MUC!
I understand your point, but this isn't exactly a philosophical moment. I presume the poster wanted to know if the Go program would work with FreeBSD version X.Y.Z. I didn't tented to imply that, if true, it would work for FreeBSD version X+n. A quote I saw somewhere, sometime ago: *One's own experience is worth the opinion of a thousand experts.*
They have a pretty great dependency injection project I've been using for a while
Just to pull out one thing from the article: &gt; Also, lack of object-oriented paradigms such as polymorphism etc. makes you look at the computer screen meaningless. &gt; polymorphism is the provision of a single interface to entities of different types https://en.wikipedia.org/wiki/Polymorphism_(computer_science) Go has polymorphism. It has interfaces that are satisfiable by any type that implements them.
I didn't know about tldr++ until reading this post, it's a nifty little tool! Glad that your experience with Go is treating you well. As for your background in Java and experience with Go syntax, although I've only worked with Java in school, one learning curve that I had was remembering all of the OOP jargon. I like simplifications such as public or private methods and variables characterized by case rather than keywords.
Thanks for the feedback!
[removed]
you're talking about inject? I have more runtime error than I thought I would, so I decided not to use it.
&gt;`key := strings.TrimPrefix(req.URL.Path, "/foo/")` Doesn't that make maintenance more difficult though? Now the handler needs knowledge of "/foo/" which is duplicated in two places.
I noticed lots of people are talking about building a C compiler. I don't really understand, what you mean is build a "copy" of the current C compiler or create your own programming language ? &amp;#x200B; Sorry if the question sounds stupid, I'm relatively new to the world of compilers...
What is the advantage of nesting? &gt; with one path-component per Handler. Can you elaborate on this?
I'm french and I use an AZERTY keyboard and I'm so used to pressing Alt+Shift+( to write \[ that it doesn't really bother me. But I have to say it most be so much easier with a QWERTY keyboard...
This is my first read into a business related to betting that is utilizing Go. The momentum of stories of organizations using across across different kinds of businesses seems to be picking up quite a bit; it's refreshing to see for sure.
Basically build a program which can compile valid C code into an executable. So in theory it would work as a replacement to GCC and clang. It's no easy job to do this however, it would be better to start off with a more "toy" programming language, perhaps a small subset of C. The ultimate end goal is to learn more about programming language and compiler theory, that's a whole subfield of CS and it's very interesting!
Hi /u/ajaymt I'm new to Go and new to the world of compilers. I'd be interested in creating my own programming language because I bet I'd learn *a lot*. Do you have an idea what I could read, what I have to learn, etc ? I know the really basic concepts like parsers, ASTs, ...
This is cool! I recently took a compilers course and wrote a programming language as well. During that same semester, I learned Go and fell in love, so I think this is awesome!
Not OP, but this is a good introductory book: https://www3.nd.edu/~dthain/compilerbook/
There are differences between the QWERTY keyboards. It's **Alt Gr + 8** on the Finnish keyboard layout.
I've read your blog post many times prior making this thread. I am very thankful for its existence. In fact I think it's one of the very few articles on the internet that shows some non trivial usage of the standard library routing. Not only there's very little material on the subject but it's also hard to search for. Also judging from this thread, it seems that people are not willing to share/showcase good usage of the standard library routing.
&gt; My verdict on Go is that it is far more practical when it comes to create ‚Äúsomething‚Äù. I mean, you have an idea, you want to see quick results without concerning code-style or any architectural things, Go gives you the opportunity to do your job swiftly. Not much boilerplates. Once you create the ‚Äúthing‚Äù, you see that the program is actually fast, reliable and easy to distribute. You don‚Äôt need much effort to turn it into an actual product. Mirrors my experience with Go as well.
Online parser that works excellent for me: [https://mholt.github.io/json-to-go/](https://mholt.github.io/json-to-go/)
There is a [golsp command](https://godoc.org/golang.org/x/tools/cmd/golsp) in the golang tools repo and I suspect that's what people will find when they search for "golsp". Maybe change the name?
Hey :) Pattern matching is still O(n), largely unchanged from my initial implementation. O(logN) certainly sounds possible with some reworking, but constant time seems really hard -- I would have to build some sort of hash function that operates on patterns and argument lists. A C compiler sounds really cool -- it's not easy, but I'm sure *you* can do it ;)
Hey, thanks for the response! I didn't really follow a specific guide, I just kind of mucked around until I had something that worked, so take my recommendations with a grain of salt. Regardless, aside from the great book that /u/knotdjb linked, I've heard [Build Your Own Lisp](http://www.buildyourownlisp.com/) is a great, free resource. Also, Thorsten Ball's [books](https://thorstenball.com/#books) are supposed to be great if you don't mind paying.
Thanks!
You're right, and I should, but refactoring this name out is going to be a nightmare. Perhaps I will eventually.
Thorsten Ball's books are good. I had fun [with my version](https://github.com/skx/monkey/) of monkey, and later went on to [implement BASIC](https://github.com/skx/gobasic/).
I have to agree with you. I have nothing against good programming books, but I like to just learn the basics and then start building something real. This is what I did with Go (only watched a quick tutorial) and directly started building an API.
Okay I see. So technically it's different from GCC and clang because those compilers are built directly with an assembly language, whereas your compiler is built from GCC or clang. Right ?
As someone that tried to extend C with some handy things like type interference, generics for functions and some new operators: please know what you are getting yourself in to. C seems like a simple language, but in a lot of things this is not the case. How you write C is only one of the many ways to write it. Starting from a predefined syntax tree helps, but it is still a PitA
What type of errors? It only runs during startup. I've used it both at work at in my own projects in production environments for a long time. One of the projects averages around a million calls per month or so.
&gt; They also say Go is the language of the internet? Nope. What's written is exactly: "Golang is a language for the internet."
This book is great, and there‚Äôs a sequel for how to build a bytecode interpreter: https://interpreterbook.com/
GCC is written in assembly, C, and C++. However a compiler for a language doesn‚Äôt necessarily need to be written in that language. You could write a C compiler in Python. I don‚Äôt know why you would but you could. 
The article says that they're moving from .net. Not surprising that Go offers advantages by comparison. You know that they're going to need something cross platform and quick, both to develop and to run.
Call it GolspGo
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/lifx] [Conway's Game of Life on LIFX Tile](https://www.reddit.com/r/lifx/comments/abxbmj/conways_game_of_life_on_lifx_tile/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
You can use raw sockets to send IPv4 packets to local socket endpoints. gopacket makes it easy to encode the packet data. Here's a simple example: buf := gopacket.NewSerializeBuffer() serializeOpts := gopacket.SerializeOptions{ FixLengths: true, ComputeChecksums: true, } ipLayer := &amp;layers.IPv4{ SrcIP: net.ParseIP("127.0.0.11"), DstIP: net.ParseIP("127.0.0.1"), Protocol: layers.IPProtocolUDP, Version: 4, TTL: 255, } udpLayer := &amp;layers.UDP{ SrcPort: 5678, DstPort: 1234, } udpLayer.SetNetworkLayerForChecksum(ipLayer) err := gopacket.SerializeLayers(buf, serializeOpts, ipLayer, udpLayer, gopacket.Payload("hello world\n")) if err != nil { panic(err) } bytes := buf.Bytes() fd, _ := syscall.Socket(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_RAW) addr := syscall.SockaddrInet4{ Port: 1234, Addr: [4]byte{127, 0, 0, 1}, } if err := syscall.Sendto(fd, bytes, 0, &amp;addr); err != nil { panic(err) } If you start netcat: $ netcat -ul 1234 And then run the code separately: $ sudo go run test.go Then you'll see "hello world" in netcat output.
I was very close to writing such a service myself. Useful.
I wouldn't worry about the mutex performance -- acquiring the lock is a tiny operation compared to performing the GRPC call. It seems like avoiding it would require initializing the internalGrpcConn before GRPC Serve call, and tearing it down and re-initializing on isLastRequestFailedToInternalGrpcService.
Haskell
How would you extract multiple parameters from the url? It feels like this would be pretty messy/inefficient.
thx. The service is really trivial, just connects together `mmcdole/gofeed` and `ChimeraCoder/anaconda`.
That's not overhead but more due to schedulers, both Go and OS. You can't expect any kind of precision from non-realtime OS and Go scheduler. Especially when OS aggressively tries to save power. A couple of ms over deadline for me looks completely normal, that's about the resolution I would expect. Regardless of the results shown here, even on Linux you might be preempted by the kernel for multiple ms and you can't do anything about it. &amp;#x200B; You can open issue, maybe there's a particular problem with macOS, but, in general, you should expect this kind of result.
We use envoyproxy ([https://www.envoyproxy.io](https://www.envoyproxy.io)) as a sidecar utility and even wrote a small docker utility to simplify usage for local development (https://github.com/dkfbasel/kolumbus). Works amazing and gives us lots of added benefits in terms of monitoring, dns resolving, circuit breaking, etc. 
Side note: API stands for *application programming interface* which is totally independent from REST (or HTTP for that matter). OpenAPI (formerly known as Swagger) is only for REST APIs. So, when you are talking about Go APIs, there might be confusions about what you mean because every Go library no matter if it's related to REST or not has an API.
&gt;I believe it tends to be used more for dev ops or security It is used for this but Go today is the language of microservices. It's a great language for backend. Big and small companies increasingly porting stuff from various other languages on Go. It is a great language for the internet but not magically. It's not the business side of things that chose Go, it's engineers that saw a great value in it. Which is why this article is kinda weird for me.
Define a constant.
The most I've ever extracted from the path is 2 parameters, and that's easily done with `strings.Split`. Anything sent as query parameters can be obtained using `r.URL.Query()`.
For more complex migrations that touch different sources, I wrote a migrator that works much the same way and lets you run arbitrary go scripts. We use this to communicate to third parties while updating our database. [https://github.com/cbelsole/yam](https://github.com/cbelsole/yam)
When `http.Get` returns an error, the response is `nil`. You then try to get status code from it, that's where you get a panic. If you get an error, handle it and return from the `getPage`.
The advice here is actually not Go specific. It's actually very - maybe not exactly the right word - basic, the first one describes why dependency injection is a really good idea. The others could probably be related back to other SOLID principles. I myself had to learn and re-learn these principles again and again and they are still not as ingrained as they should be. And I have the feeling that it's not taught enough or at all to people learning software development, neither in schools of any kind nor in the community. It's a shame actually.
[removed]
Hmm, I ran `staticcheck ./my-app.go` and it didn't return anything. This means it didn't spot any problems, right? Or do I have to tell it what to check?
It's 2019 - changing the name of a first class thing in a 3GL should be the work of minutes :(
[removed]
 msg := []byte{104, 105, 10} fmt.Fprint(os.Stdout, msg) Produces: [104 105 10] If you want to use `fmt.Fprintf` you need to format string: fmt.Fprintf(os.Stdout, "%s", msg) Which produces: hi And is basically the same as casting it to a string. You should use `conn.Write(msg)` to write raw bytes to the connection, fmt is needlessly converting it to a string and then back to a byte slice to write it to the underlying conn. Though you likely want to wrap the conn in a buffered writer if you are writing multiple things to it. fmt is used for creating and formatting strings, you don't need to and should not use it if you are just passing byte slices around.
The parser is doing a lot of allocations, whereas it could use better referencing. As an example, replace `type Keyword int` with `type Keyword byte`. `parseSelection` 1.87GB -&gt; 1.29GB. _However, for some explicable reason removing `Description string` makes it allocate more._ The allocations are coming from: 1. token.Token and its string fields. Rather than parse out the strings, remember the start position and/or length and refer to the original string. 2. Then you have selection set, which is a list of interfaces. Interfaces always require a pointer to some other memory location. So rather than have `Selection` as an interface make it a large struct with all of the fields from `Field`, `FragmentSpread` and `InlineFragment`. This should get rid of a lot of pointers. Due to being able to keep `SelectionSet` in a single array. 3. `document.Field` has a bunch of optional arguments, rather than store them all keep a pointer. You can try using something like: type Field struct { Name string *FieldOptional } type FieldOptional struct { Alias string Arguments Arguments Directives Directives SelectionSet SelectionSet } Although this might give even better gains: type Field struct { Name string SelectionSet SelectionSet *FieldOptional } type FieldOptional struct { Alias string Arguments Arguments Directives Directives } So my guess is: 1. tokens (and strings), 2. interfaces and 3. slices.
_Note: based on a quick review and testing, so take the suggestions with a grain of salt._
Got the idea. Thank you. I used \`fmt.Fprint\` in a project to write files. I think I should review it.
I love vs code. I‚Äôm sure a lot of editors have similar features but the way vs code works with go tools is perfect. Makes coding with go a lot of fun!
Please read [Meta-analysis: Golang web framework/toolkit?](https://medium.com/@mrramazani/meta-analysis-golang-web-framework-toolkit-f65a632358e1) to have a clear decision yourself. &amp;#x200B; &amp;#x200B;
Acme. 
[Crafting interpreters](http://craftinginterpreters.com/contents.html) is pretty good.
I have been using VS Code for more than 2 years now, and it‚Äôs getting rich with features on each iteration.. there are extensions available for all our needs.. If you are looking for an editor for Go programming, then VS Code for the win!!
I love vim. It's like a language for the hands. I use it for programming in any language.
Having used both Atom and VSCode I can tell you you won't find any notable difference in editor or addons, and even through both are owned by Microsoft (which Im not a big fan of), you are more "distant" from them using Atom. Dont know about GoLand though 
And when combined with plugins like [ale](https://github.com/w0rp/ale) it maintains a lot of the benefits of IDEs while keeping all the benefits of vims modal editing. The only downside is it takes longer to learn and longer to find/set it up the way you like it. But well worth it when you do.
Oh! The old _‚ÄúVim vs. Emacs‚Äù_ discussion‚Ä¶ I think with the popularization of [Language Server Protocol ‚Äî LSP](https://langserver.org/) the need to find a particular IDE or code editor to write in a specific programming language is disappearing. Nowadays, programmers find an editor that they love using and then install a bunch of plugins to leverage the power of LSP. Keeping this in mind, you‚Äôll see that all the answers you‚Äôll get in this thread follow the following pattern: ‚ÄúEditor X + Plugin Y‚Äù. Here are some examples: * VIm + [vim-go](https://github.com/fatih/vim-go) * Emacs + [GoLangMode](https://www.emacswiki.org/emacs/GoLangMode) * JetBrains + [GoLand](https://www.jetbrains.com/go/) * SublimeText + [LSP](https://github.com/tomv564/LSP) + [go-langserver](https://github.com/sourcegraph/go-langserver) * VSCode + [ms-vscode.Go](https://marketplace.visualstudio.com/items?itemName=ms-vscode.Go) * Atom + [go-plus](https://atom.io/packages/go-plus) * LiteIDE + [GoTools](http://liteide.org/en/) * etc‚Ä¶ The list goes on and on, and there are so many that there‚Äôs no way I can list them here without spending an entire day researching. Everyone will give you their own opinion of why their editor is better than others, but once again, the question is mostly _‚ÄúDo I like this editor + LSP?‚Äù_ than _‚ÄúIs this editor the best for Go?‚Äù_. That‚Äôs why so many people are switching to VSCode, Microsoft is the one coordinating the LSP specification, so even though the editor is just ‚Äúmeh!‚Äù the plugin ecosystem is thriving with the LSP integrations. I‚Äôve been a happy SublimeText user for 6+ years, but I have to accept that the tools that I use to build projects in Go are the same tools that VSCode plugins use _(go-langserver for LSP, gocode for autocomplete, go-fmt for formatting, etc‚Ä¶)_, so I could switch between all these editors without noticing the difference. I love SublimeText and stick with it no matter what language I‚Äôm using for my projects, and these are the same reasons VIm users stick to VIm, Emacs users stick to Emacs, and so on, they love the editor and find ways to make it better no matter what they are doing with it.
VSCode. Works perfect with Go. As if it was intended for it - it is that good Go support. I also work in other languages, so the I prefer an editor like VSCode that can handle whatever I throw at it (C#, C/C++, TypeScript) in a familiar environment rather than use specialized editors such as GoLand. I also work cross-platform, so VSCode being the same exact experience on both Linux and Windows is also a plus in my book. Oh, and since MS bought Github, technically, Atom is also a MS project. :)
Even if it's just a toy, that's a huge accomplishment. Congrats!
Fair enough, if they're that similar I'll stick with Atom. Do you use Atom still?
Good point haha, forgot about that! Wonder if they ever announced their plans for Atom, going to have a quick Google.
&gt; The only downside is it takes longer to learn and longer to find/set it up the way you like it And here is where I get lost every time. I love Vim but just don't have the patience to faff with so many plugins, when an IDE is one click and done.
I'd love to have some more insight on Lifx as a company. How many employees? What's the main focus or project priorities?
Have you ever seen processor that runs on top of java? 
Switching from Atom to VSCode a couple of years ago fixed nearly all the paper cuts I had with Atom. Unfortunately it's so long ago I can't remember what they were. VSCode's vim plugin is also quite good, which sealed it for me.
I use [nvi](https://en.wikipedia.org/wiki/Nvi) which comes with [OpenBSD](https://www.openbsd.org/).
[removed]
[removed]
I've been using it for months, great pipeline framework.
LiteIDE
Used Jetbrains' PyCharm at my last job, now using GoLand and am very happy. GoLand does a great job at navigating interfaces vs. their various implementations, makes large projects more digestable. And the vim plugin for GoLand satisfies 99% of my modal editing needs. The IDE makes it very easy to map commands to vim vs. IDE actions.
I use it with gometalinter. After installing (go get) staticcheck, edit the settings in vscode: "go.lintTool": "gometalinter", "go.lintFlags": ["--deadline=10s", "--enable=staticcheck", "--disable=megacheck"] This enables staticcheck (which is not enabled by default by gometalinter), and disables megacheck (which is obsoleted and replaced by staticcheck)
True, but once you set it, vim works great for many years to come with any language, while other editors come and go.
I used vim for over a decade, but now I use vscode with the vim bindings. It gets me most of the way there.
Odd that the author is blogging at work about waiting to get home to code.
Emacs. I've been learning Go, and the `go-mode` package as been fantastic in making sure my code works, especially when I define types.
I‚Äôd run each command in a goroutine and for loop of its own. Lock free, zero communication overhead, zero shared state. üëçüèª
Seems OP is assuming his program is the only thing running on his system.
Agreed. Thanks for clarifying. 
https://github.com/ShivamSarodia/ShivyC
Great job! Do you have a blog post or something detailing your development process? I'm pretty sure that would be interesting. 
You will need to use or build a session implementation. Here‚Äôs a common one (with example in README): https://github.com/gorilla/sessions/blob/master/README.md https://godoc.org/github.com/gorilla/sessions#Session.AddFlash 
You should look up the definition of mature. It‚Äôs not a measure of time. 
Thank you. üëç
So basically this? * Read the cookie from Request. * Add your \`&lt;FlashKey&gt;:&lt;FlashValue&gt;\` to the cookie. * Send new cookie in Response via Set-Cookie header. * In the handler that uses the flash, read \*flash\* from request cookie, render it in the response. * Remove or overwrite \`&lt;FlashKey&gt;:&lt;FlashValue&gt;\` in cookie and apply with Set-Cookie header in response.
goland is perfect for golang in business project for quick refactor and quick edit / error check.
I think it was it, thanks!
Your directory structure should probably look more like this: ./app-repo |_ resources/static/index.html This is pretty subjective, admittedly. But a top level `resources` directory is pretty standard these days. You should also probably move your path handlers into a routes.go that returns handlers, and then implement them all in one place, like so: http.HandleFunc("/foo/", handleFoo()) http.HandleFunc("/bar/", handleBar()) I think [this](https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831) is the best pattern I've ever seen for go web apps. I've used it for a few projects and it's very extensible and easy to test.
Thanks for the feedback, those tips sound great and that link is very helpful! I'll update the Pointers section of the post when I get a chance.
Great work !! :D 
complicating much? Store it in the session and check if there are any flashes in session each time you render page.
Hey, thanks for taking the time and looking into this. Thanks for the \*pointer (hehe) to the Selection interface. I think this is the main reason for the issue. I did a quick test to verify this: type foolish interface { fool() } type foo struct { } func (f foo) fool() {} type bar struct { fools []foolish } type baz struct { bats []foo } func getFoo() (f foo) { return f } func getFoolish() (f foolish) { f = getFoo() return } func Foo() { var bar bar for i := 0; i &lt; 100; i++ { f := getFoolish() bar.fools = append(bar.fools, f) } } func Baz() { var baz baz for i := 0; i &lt; 100; i++ { f := getFoo() baz.bats = append(baz.bats, f) } } Here are the Benchmark results: BenchmarkFoo/interfaces-4 1000000 1768 ns/op 4080 B/op 8 allocs/op BenchmarkFoo/no-interface-4 3000000 440 ns/op 0 B/op 0 allocs/op So it looks like having interface types inside slices is a really bad idea. I'll refactor this. Thanks for the help! =)
...and remove them after fetch, so they don't leak into next request. 
Maybe I'm missing something, but let's say I have this route `community/{group}/users/{username}` where `group` and `username` are parameters. How would you make Go route to that path without basically having to build your own router?
GoLand is great, but the price tag is just atrocious. 200 EUR annually is too much for this IDE. It would be a good price for a lifetime license (a single major version), but not for a subscription.
1. try pgpool 2 ( or some others postgres sql middleware ) first to speed up postgres. 2. try [github.com/jackc/pgx](https://github.com/jackc/pgx) driver , to refactor the pg DB access. :) 
&gt; The database connection is being imported as a global object I am going to assume this means you have something like `func (db * DB) GetUser() (*User,error)` (and not the function defined on package level). And then the services reference the db via some global like `var TheDB = NewDB()`? My first suggestion would be to do dependency injection (you don't need a framework for this). So in the refactor, create an interface like ``` type UserDB interface { GetUser() (*User,error) } ``` The smaller interface here allows for easier mocking (I found [gomock](https://github.com/golang/mock) useful) and possibly replacing the DB with a different implementation. Then rename `TheDB` global reference and see what breaks, and replace it with a reference to the interface passed to the function of the type the function is declared on. I am working on a project now where the tests run using a test DB. Tests are slow, considering how little they do. Slow tests really make the CI/CD process a pain. &gt; Services do not talk to each other directly at all they all query and poll the DB I am assume you poll the DB to look for some change, and then act on it? This is a great place to use events. Look at something like RabbitMQ or Apache Kafka. This can remove some load from the DB, because you you no longer need to poll it. It can also improve response times to changes, since you can start processing immediately and you don't have to wait for the next poll. I watched [this video](https://youtu.be/E8-e-3fRHBw?t=1596) a while back on data refactoring. I am not sure if this is the best way, but it is the only video I found that covered decoupling from a monolithic DB. But I think a refactor of this kind is going to take more than a week, but it can be done slowly. 
Hahaha, I saw that too, but wouldn't you say that his home experience would be a profit to the business he works for? (I always encourage my colleagues to try things at home, and to bring back the good stuff)
I skipped html templates, because I am used to twig, so I saw pongo2. Which is a clkean separating between the presentation layer and the application logic.
Note: it's not a pointer to the selection interface, but rather interface contains a pointer to the actual type. For more information that you'll ever need https://research.swtch.com/interfaces and https://github.com/teh-cmc/go-internals/blob/master/chapter2_interfaces/README.md. Similarly each slice and string has a pointer https://blog.golang.org/go-slices-usage-and-internals and https://blog.golang.org/slices
is python any good at stuff like this?? i would've assumed not given how slow it was tbh
If I understand the OP correctly, these solutions don't actually solve the problem at all. 1 is only necessary if postgres has trouble handling the connections. Go's DB object is already a connection pool, so you almost never need pgpool when using Go. 2. pgx is just a new driver; bad design remains bad design no matter what library you import. &amp;#x200B; OP made a classic problem and now has a load of technical debt. DI is the solution but requires a significant time investment to refactor these apps.
It would be much nicer not to use `exec` for whois binary, instead, open tcp connection to some whois server, write domain to conn and read response, it is a simple protocol. It also doesn't need much code and is still useful as en example of some service.
I don't really understand why some developers feel like it's a good idea to delegate simple tasks like SIGHUP reload or file watch reload to external packages, or even worse, a separate binary. In this day and age adding external dependencies for trivial functionality is bad because nobody really maintains those packages outside their immediate need. In a month or two, or maybe a year, you'll have to fork the repo and take upon yourself to update that old go 1.10 project to match the rest of your environment. 
In this case, reflex is used only for the purpose of local development. You wouldn't use it for deployments of the application (note that it is not added to the \`go.mod\` as dependency). If it'd be discontinued, you can simply swap it in the Dockerfile with another software that does the same thing. While I agree with your statement that simple tasks don't need external libraries, this is not a regular dependency.
Mostly VS Code but I have used vim on a couple of small utilities. 
While I can understand the reasoning behind this, I think it is for the most part unnecessary to add a layer just to cover up this minor detail. Document that the zero value is useless and people will know. "Factory" functions are listed next to the struct in go doc anyway and if you really paranoid about that you could check in method if the reciever is the zero value and panic at this point. 
Are those IE screenshots? 
So, let's write everything from scratch, because it will be "deprecated" anyway?
We are using it in production for some specific task and so far it's working very well. It's really easy to manage and to upgrade (Just replace the binary basically). The Web UI is also great to start and it includes a Prometheus compatibility for easy monitoring (With pre-made Grafana dashboards and alert/recording rules) &amp;#x200B; So far all good, but our dataset is very small. &amp;#x200B; The only cons I would say is that there's no equivalent to the write/read concerns of MongoDB or consistency levels of Cassandra for example ( [https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlConfigConsistency.html](https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlConfigConsistency.html) ), all read/write need to be consistent (It mean if the cluster has split brain or you lose the majority you have no way to read even the local potentially stale data (That could in some case better than failing))
Have you actually tried that? It gets messy defining constants for every little part of a route. Also there's the problem of which package owns the constant. And when you add the package in the constant name, it gets much more verbose.
There's only one thing able to properly review code - human inteligence. It's not perfect but any other solution compared to it is not worth using.
Thanks. Yeah the connections themselves aren't an issue - we have a pgbouncer setup in front of our (Aurora) postgres instance that multiplexes connections and works fine. Another developer used pgx for some of their code handling but this was for new code. I'm looking to test code in existing microservices that don't follow that pattern. I may as well point out that I did not design the db connection this way and am fairly new to the team. I'm just looking for the most painless way to add tests to our codebase 
Yes. Everything that will make you spend more time in the long run doing maintenance than it would by developing it yourself. A file watcher or a SIGHUP handler represent functionality that requires at most half a developer day to implement.
Thanks for the reply. We have a package called db that contains a global variable called PSdb of type db.connector. We then define an interface for this type with the typical methods like Scan(), Next(), etc. This variable is initialized with a connection string in each of the microservices. Functions that call the database do not take a database type receiver but just use it directly. I want to add a DB receiver as you said but it will be a complex refactor because the main loops that run do not take arguments in their current design... I will take a look at gomock since that will be part of the solution when running these tests. Essentially instead of running tests against a running test postgres instance we can mock the interactions of the interface in our code. We do want to add a message bus soon I think now that we have more engineers on board
Did you consider adding [gometalinter](https://github.com/alecthomas/gometalinter) and/or [statickcheck](https://github.com/dominikh/go-tools) to your CI pipeline instead?
These 'developers' don't seem to know how to write things though, they just string dependencies together. 
&gt;the main loops that run do not take arguments in their current design... Can you give an example of the main loops? A made up example is fine if you don't want to share actual code. The refactor might take some time, but you should be able to do it one microservice at a time. So maybe spend a day every week doing the refactor for one service at a time. That way it is not a 20 day 'down time' without new features (I know how project managers respond to that). 
&gt; reflex is used only for the purpose of local development I see that you forgot to include this information in the article and yet you downvote me for understanding differently. &gt; this is not a regular dependency. OK, you're using it for `go run` inside a docker container, which in my opinion is an even bigger waste of computer cycles and convoluted tooling. Do you have any concrete example where this would actually benefit anyone more than compiling and running everything locally ?
Your explanation sounds exactly right to me! It seems like r2URL is redundant though: if r.URL != nil { r2.URL = new(url.URL) *r2.URL = *r.URL }
Firefox (you can see from the second screenshot) :)
Ah, I see now there's already a whois client at https://github.com/domainr/whois That'll not only improve security but also simplify the code. Will definitely update that part!
The upside is you can add extra functionality and all projects that use it can make use of it. For example, we wrote a SIGHUP handler to kill a global context. All contexts inherit from that context so all requests can be canceled when the program is terminated. Later, the Go http module got a graceful shutdown feature and we added it to the library an all our services automatically benefitted. 
I'm not sure if you're disagreeing or agreeing with me. :D 
I find a docker compose clearer than instructions that say ‚Äúopen a separate terminal and run x‚Äù. Also a consistent build environment. Not worrying whether you have the correct version of Go installed to compile properly is nice too. 
I‚Äôm somewhere in the middle I think!
Linters are the way to go. You can write custom linters to enforce patterns and check for known security issues. 
maybe [https://fixmie.com/](https://fixmie.com/) can help.
I understand that it might have not been clear from the start, thanks for pointing that out. I'll skip the part about wasting computer cycles, as running a docker container has no significant overhead on any modern developer machine. I'll try to explain the second part though: 1. First of all, using docker-compose will let you set up all services living in the same network with a single command. The alternative would be to run all instances on your local machine, like NATS in the example I showed or a DB instance or whatever else. You probably don't want to work in such environment. 2. Other developers can set up the project by cloning the repository and running a command, instead of installing dependencies and reading a manual. 3. I find the code reloading very useful for quickly testing your changes. 4. You can easily delete the whole environment and start from scratch by running \`docker-compose down\`. 5. This example is trivial on purpose, but it will also work for bigger projects, where you need more attached services (a database, a mail server, block storage, mock of remote APIs, etc.). As for a concrete example I hoped that the one in the article would show the benefits above. How would you approach it? 
We wrap the main loop inside of a function that takes in a `func v` and `time.Second s` and runs `v` and then waits `s` before doing so again. This is done in a separate goroutine from main, which just waits indefinitely for them to return. we could add a DB argument to these loops but then we have to supply it everywhere which could get messy. It would not allow for the incremental changes you suggest, going one service at a time
I don't see fixmie can be installed on self-hosted instances. I'll contact them. Thanks!
It's still on the menu. I've been looking for something with less maintenance. But, seeing it could be my only choice ... I'll investigate it further. Thanks!
reviewdog is great and it can be run locally.
You make it sound like building your own router is hard. Split on `/` and you get a slice of components, then you can just use string comparisons (switch/case) to determine which pattern you're matching and call the appropriate method to handle it. If you have enough patterns you can even subdivide them into separate processing methods. See [the article about ShiftPath](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html) -- shiftpath the first element and if it's `groups`, you call a HandleGroups(w, r) handler instead, and so on.
Well, another option is to shift `/foo` off the front, as described in the blog post, and make the handler expect its arguments at root. I tend to put my router in the same package as the handlers, they're all part of the web rendering functionality and distinct from business logic or model.
For people who are interested in how Go works, I like this article because it's not too long and is quite informative. My feedback to improve on the blog would probably be to look into adding syntax highlighting for the code. Of course, take that with a grain of salt, either way, bravo =) 
I just thought it was odd that he was fine with blogging about coding non work related things but not actually coding them.
This is the bare minimum required without using sessions, and to a degree it's still the same steps with a session, except replace the cookie's key/values for the session's in some steps.
Because Go dev's just like every other dev on the face of the planet love to do things like, use different dependency versions or different version of the language... all that fun stuff. Then they dont update the build specs properly and next thing you know it fails going into the CI system or in QA and has to be traced down... Even better is when the developer wants to use an OS that is different than prod... different compilers, different linked libraries, etc.
Hey! I really appreciate the work you did on that. That is really helpful for me to have a program that I can compare to a shell script and start figuring out how it works. This is awesome!
GCC and Clang are not written in assembly. They may have some tiny amount of assembly just for some optimization, but they're written primarily in either C or C++. You seem surprised that a C compiler would be written in C rather than assembly... but I don't know why.
Sure, here you go ‚Äî https://golanglibs.com/search?q=go-jira&amp;sort=top
Sure ‚Äî https://golanglibs.com/search?q=jira&amp;sort=top
Thank you!
Writing a basic router is easy, writing a good one is harder. I don't get why you need to reinvent the wheel for every project though, there's already routers like Chi that works very well. I've written my own router as well out of curiosity and to be honest it was a bit of a waste of time (except for the learning experience). The existing routers make this whole thing so much easier, cleaner and more performant than the standard lib allows for.
When you are on the subscription/buy page make sure you pick personal license ("For Individual Use"). Personal license is only 89 USD for a year. Also JetBrains provides [perpetual fallback license](https://sales.jetbrains.com/hc/en-gb/articles/207240845-What-is-perpetual-fallback-license-) which means you can keep a version for a lifetime after your subscription ends. (Not a sales person, just a satisfied customer)
Without commenting on the intent of the code and the style, your explanation seems correct. To help understand and debug things like this in the future, it'd be useful to print out information about the values and data in memory. Use the `%p` format specifier to functions in the `fmt
Personal license has limitations, for example I cannot use it to write/modify scripts for work while at home. I would have to use two different IDEs and at that point it is better to stick to other solutions. But, for hobby use only, annual $90 doesn't look bad.
Without commenting on the intent of the code and the style, your explanation seems correct. To help understand and debug things like this in the future, it'd be useful to print out information about the values and data in memory. Use the `%p` format specifier to functions in the `fmt` package, ie. `fmt.Printf("The address of r2URL is %p", r2URL)`. Additionally, `%v` is used to represent any kind of data in the default format, ie. `fmt.Printf("The number %v is spelled %v", 9, "nine")` - note that the two arguments are of different types, yet `%v` works for both. Hopefully this helps! There are probably better ways to debug or track data, but `print` statements have never failed me when trying to quickly determine the state of data.
As far as I can tell you can use the same personal license [at work and at home](https://sales.jetbrains.com/hc/en-gb/articles/207240855-Can-I-use-my-personal-license-at-work-and-at-home-). `A personal license is only limited by ownership and transfer options` as stated [here](https://sales.jetbrains.com/hc/en-gb/articles/206544569-Does-a-personal-license-have-limited-features-compared-to-a-commercial-license-). Please correct me if I'm wrong, because I have been using IntelliJ and PhpStorm for work while I'm at home.
&gt; Then it sets r2.URL to be that newly allocated object. This phrasing implies pass-by-reference. Go is only pass-by-value, so everything is a copy. Our concern is always whether the value being copied is a data structure or an address (of course, some structures contain fields that are addresses - be careful when copying these complex types). If I was explaining this for full clarity, I'd use the following: "Then it copies the value of r2URL, which is an address, to r2.URL." Here are some additional examples which may help: https://play.golang.org/p/BgeSoy4Aeql
Hmmm... In that case they changed it. Last time I checked (right after GoLand - or what was its name - went out of free beta access), license was more restrictive. I might take a look at it again. Thanks! 