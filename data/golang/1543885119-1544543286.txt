Good catch! The README has been updated [1]. [1] https://github.com/Microsoft/Ethr/commit/485327e
The Go Slack group [1] may also want to read this. There’s plenty of people in the #jobs channel there. [1] https://invite.slack.golangbridge.org/
I have no idea what the JVM will do with it, I do with go.
I’ll be on it! Thanks for helping us connect with the gopher community! 
Have a look at perkeep (was camlistore). Quite a big project with more than a hundred contributors, it should check a few points of your list https://github.com/perkeep/perkeep
Any details on the job, however broad? Are you looking to be mostly web-based (or even building on webasm in the future), some kind of backend service, etc. Do you just need devs, or are you looking for Sr. Devs to run the team too?
Does "select" have any performance impact vs bare channels?
Took me a while to figure this out as well, considering every example did something different. I’ve got a project I’m working on that I can post on GitHub to show how I got things working, if that could be helpful. It’s a “RESTful” API that uses GORM to connect to a Postgres backend. I could use some code review from everyone here as well!
[removed]
"They can result in go routines being blocked when they are no longer being consumed properly." But that's the whole point...
I said nothing about your intelligence. I said if you can’t answer the question yourself then my effort in doing so would provide neither you nor me with any value. If that bothers you, I’m sorry. Life moves on. 
So don’t learn Go, read the numerous discussions and talks about how Go helped improve some aspect of a project. I’m not going to dump Google results here. Google “who is using Go Lang” and start there. None of that requires you to learn and write Go code. 
That's different from "can't be accomplished"
Why does it have to be about what it doesn’t have? This is such a repetitive statement. Yes. Your correct. Go is not Swift, Kotlin or Rust. And each of those languages strive to solve problems in their own space. Just like Go. Google had a problem and saw a solution and wrote Go. If you won’t use it because it doesn’t have your favorite features, don’t use it. But lacking some feature “everyone else has” doesn’t make you lackluster, worse, garbage or any other insult you want to put together. I don’t even write Go professionally. It’s a hobby language. It does concurrency and builds 100x better than the three you mentioned. So it lacks generics. I rarely miss them. If you can’t solve a problem without them, fine. Don’t. _There is nothing wrong with you_.
I don't miss requests at all, and net/http.Client is a wonderful refreshing does of excellence compared to urllib, urllib2, urllib3
Would you still go with NSQ today versus NATS, considering NATS how has persistence with NATS Streaming? More recently there is Liftbridge too https://github.com/liftbridge-io/liftbridge 
I've done 2 different ways, in the other languages. You can go the traditional route of loading dlls, although I'm not sure that's possible without a lot of headache. You can use Unix sockets, dbus, http API, etc and have extra functionality be services that when started register with you main application with information about the functionality. For example it can your functionality can register by calling to localhost/register and have in the body localhost:9090, functionality. 
So you want one server but multiple languages? If the other languages are not taking requests? Then what are they doing? Like have one language take in a request and have python do processing? They all have to have their own run time anyways. Is there a really low level reason for this? Or legacy? I'm not really grasping the advantage of all the languages fualts ending up crashing the system all at once. Like a nil in Java is not a nil in php or in js. You would have such a touchy system it would be really hard to not bring it down. Plus, a lot of languages have different stack heaps and take up more processes and virtual memory. I just can't see that working well. Why not just containers with their own server with grpc. This way if one goes down it not only gets refreshed but doesn't take down the system. Plus all the advantages I described with apis. It literally generates them for you. I'm really not seeing how having them all share everything and be coupled some how is going to gain over uncoupling them and having fault protection.
Never mind, I found something better. It's called [Hyper](http://hyper.is/), its pretty nice.
I agree that interfaces expanding to cover generic types is natural (and desirable, whether or not they're the basis for the type constraint system). My badly-conveyed point is that this makes interfaces as they stand merely the starting point for describing type constraints, not the actual implementation. Once interfaces are only the starting point, you naturally have the question of 'why start from interfaces instead of something else?', and you can no longer say 'because it's a feature Go already has' (although you can say 'because we're starting from a feature Go already has', although contracts sort of are too). The issue of sets not implemented with map is a tangled one that I don't have clear thoughts on. I think that Go's current approach (of requiring a method) is at least honest in terms of the costs, of what it requires, and what it can deliver. It might be nice to expose the runtime's ability to hash map keys, but at the same time there are clearly arguments for keeping that part of the implementation opaque. Hashing map/set/etc keys is a hard API problem in my opinion. (It is easy to design an API; it is harder to design an API that is safe, especially in the face of people being accidentally perverse.)
&gt;You can go the traditional route of loading dlls, although I'm not sure that's possible without a lot of headache. Go plugins should work? [https://golang.org/pkg/plugin/](https://golang.org/pkg/plugin/)
RemindMe!
Fair enough. My intent by the statement was Go's concurrency model. As a consumer of languages I have yet to find a language that truly competes with Go on the field of writing concurrent (and safe) code. Sure, channels aren't the most efficient approach to concurrent communication, even in Go, but they're language level and fast enough for most anything necessary. The fact that running a function asynchronously is as simple as calling it with `go` in front (`go doLotsOfWork()`). Sure, there are equivalents, Go didn't invent green threads -- processes are easy to manage and use in Elixir/Erlang, and arguable the supervisor model that comes built in is pretty damn awesome. But Erlang/Elixir don't compile down to a native binary you can just send someone. At least not in the same way as Go. The cross compilation features of the tool chain, again while not new, are extremely accessible. The tool chain that comes with the language is tremendously useful. Testing is a first class citizen, write your test code, run it with `go test`, you just need Go installed. Need documentation? `go doc`, and that works for core libraries or any lib you have installed or your current project -- whatever. Sure, the GOPATH system is obtuse and weird but if you give it a go it makes dealing with depending software tremendously easy. Thankfully they've seen the light on vendoring and dependency management, with an official Go tool for dependencies, `dep` and supporting a vendor directory for some time now, and then versioned Go (without the need for GOPATH) is currently in a testing period, so more improvements in the toolchain that comes with the language. The core library is pretty massive, in terms of offering. Depending on your needs, there is a lot there for you. You get an HTTP server up and running with "net/http" and there is a text and HTML templating language built in. Drawing output PNG images was ridiculously easy and required nothing more than Go itself. The flag core library makes writing CLIs super easy without any third party libraries. The language is built in as a core library so writing tools that parse and understand Go code is incredibly easy. It came with `gofmt`, a useful tool that stopped people from complaining about how to properly format Go, since a tool was made to format it for you. And as has been said about that, "Gofmt's style is no one's favorite, yet gofmt is everyone's favorite." Dead code (unused imports, statements after a return, unused variables) is a compile time error, keeping the code base clean. Sure sometimes it can be annoying if you haven't written code to use the variable yet, but knowing that it's analyzed and reported. And probably most controversially in this post is error handling. If you grew up with exceptions then error handling in Go just looks terrible, and since it's all a matter of opinion, that means it's probably true for you, but in Go the errors are data values. They don't mean the world has ended, sometimes they're not really errors. EOF is signaled as an error, but it's not an error, it's EOF. Exceptions can do the same thing but they are/were intended to mean something different, and also have different resource costs to consider. You can throw an exception in Go, `panic(myErr)`, but that's supposed to mean the world _is over_. I don't believe Go is the best thing since slice bread. I don't think it's the best language out there. Honestly, if you think a language is the best language out there then you just don't yet understand the vast array of options at your disposal. Maybe your language is the best language _in your daily work._ I like to see and toy with _a lot_ of languages. And almost none of them are completely garbage (except mine). A language is generally written to solve a problem, and it usually solves that problem very well. That's why a lot of developers for Windows Software use C#. I'm sure there's still a lot of Visual C++ and Visual Basic guys too, I know there are at least some. Java is a great entry into the world of "write once, run anywhere." C/C++ are powerhouses, they wouldn't still be alive and kicking if they were worthless, I don't think I have to name any uses for them. Rust is an extremely fast and safe systems language. One of my daily tools, `ripgrep`, owes (at least in part) it's speed gains to Rust. Ruby is almost unmatched in developer productivity.** I've never seen a new hire start working so quickly on a project as I have with Ruby. Of course it's not just Ruby, Rails being a huge library makes it a lot easier for people to dive into a project and start feeling things out quickly. I can't say Ruby has much else going for it, although they're working to speed things up. I've never used Python professionally, but I've never heard bad things and it seems to be just as good at Ruby for productivity speed, so no faults there. The point is, if every language was like every other language, then nobody would care about language and discussions and thoughts and implementations wouldn't matter. Languages are the way they are because of the circumstances that brought them into existence. So instead of being so obsessed with what a language can't do, why not try and figure out what it _can_ do. Chances are it can do at least one thing in a better way than your language can. Or maybe not, so then it's just terrible. Boo, garbage, trash it!
**Defaulted to one day.** I will be messaging you on [**2018-12-05 02:57:52 UTC**](http://www.wolframalpha.com/input/?i=2018-12-05 02:57:52 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/golang/comments/a2siv8/examples_of_well_architected_large_webapps/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/golang/comments/a2siv8/examples_of_well_architected_large_webapps/]%0A%0ARemindMe! ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Iris has a pretty big selection of [examples](https://github.com/kataras/iris/tree/master/_examples), different ones tick different boxes. But if you go over a few of them you should be get a general idea of how things should look, at least in that framework. As far as big go webapps that are used in production, one that comes to mind would be [Gitea](https://github.com/go-gitea/gitea).
Is it just the sessions support you miss from the Python requests package? I would say the Go stdlib http package is much better than the Python stdlib to begin with. Have you looked at 3rd party Go packages if you need more than the stdlib provides? ie this exists: [github.com/levigross/grequests](https://github.com/levigross/grequests)
I don't agree. If a go routine leaks because it's trying to write to a channel, this is a problem.
Not sure why is a third party Python library being compared to Go's standard library. Either way, that thread might have some signal amidst the noise. Perhaps some insight on what users expect from http client libraries. Almost a https://github.com/golang/go/wiki/ExperienceReports
go-github uses modules:[https://github.com/google/go-github/blob/master/go.mod#L1](https://github.com/google/go-github/blob/master/go.mod#L1) This works corectly: mkdir program &amp;&amp; cd program cat &lt;&lt; EOF &gt; main.go package main import ( _ "github.com/google/v19/go-github" ) func main() { } EOF go mod init program go build
If I may.. I have been thinking about an ideal "base" architecture to build upon for specific uses... would love to hear thoughts on it. Essentially everything would be docker containers, configured/deployed with Kubernetes... to get that out of the way up front. Hopefully with the right configuration, this would allow it to auto scale as needed. Their would be a few parts to this. The first is a stateless ReST API, public facing with authentication/etc. Typical fanfare. I am fairly new to Go, but it seems like Gorilla/MUX is the more common way to go here with routing and such, and a middleware that takes all incoming requests, passes through middleware for things like logging, authentication, etc before reaching the next layer, the actual API Gorilla/MUX endpoints. Anything to add/change here? Next up would be back end services. These would be akin to Java session beans. These would be micro services, such as a user service, small/fast in size to handle specific things. I am not entirely sure about them having their own DB per micro service though. I am still not quite sure how you handle relational DB schemas between services.. also coming from a Java ORM background, I am still having a bit of difficulty in truly understanding how to break down multiple DB tables with relational schemas in such a way that allows individual services to work correctly. How do you avoid the situation where user service with a 1 to many column has to do x number of calls to the many calls to the many side service... it seems unusually inefficient when a single query that can pull the data that would span multiple micro services could be much faster?? Love some info on this. Tying the services together would be done over a message bus, and using MQTT to communicate between services. The benefit here is it allows each and every service to scale as much as needed, without affecting the rest of the system. A user service may get used 100x more than a calendar service. So at least as I understand it, each of these services would be stateless and auto scale as needed. I am not quite sure yet how to work out when a service spins up many instances.. how only one of those takes on the specific pub/sub request, but I know its possible. Probably some configuration in the message bus itself. All of this has some DB in the back.. not sure what is best for this sort of architecture. MariaDB I hear is pretty good. I have used MySQL and PostgreSQL, but am told those are not as well suited for this. Redundancy, migrations, rollbacks, etc all need to be well handled in whatever is chosen here obviously. A central logging of some sort would also be useful. Have worked with ELK but not a big big fan of it. Might be easy enough to provide a simple logging service that has its own logging DB (separate from application DB). I personally dont see why this would be a bad thing, but no doubt with big bulky systems like ELK there must be a reason for all the extra stuff it adds. Top of my head I just want a way to manage logging by date, with metadata covering the service, timestamp, error/issue, and other pertinent info that can then be dissected as needed. As I see it, once the basic CI/CD is set up to build the variety of containers, and K8 configuration to deploy to the cloud, then you get busy building services and API end points. I am sure there is more to it.. but from my years of experience most of what I have been part of is more or less this sort of setup, though usually in SOA/monolithic style JEE applications, not smaller micro services. 
I haven't needed to revisit it, but thanks for the resources.
Channel are basically blocking queues, they are designed to block to allow threads to stay synced which is important with understanding the system as a whole. They are smart to also allow a buffer so that you can give a limit for how out of sync they can be, but in the end you don't want to be wasting memory consuming data that you can't process yet.
I think you and I are talking about different things. I'm discussing a use of a channel where one go routine is buffering data via a channel and a consumer is on a different go routine. When the user leaves, the producing go routine needs a way to safely stop writing to the channel. If done improperly, it will block forever. I think you're talking about orchestrating via channels. I agree that not blocking would be the wrong choice with that.
os x as well
I found this pretty quickly. Between gorilla and gorm, if I recall, but the same principles have held for others. 
Not sure if this fits the bill, but you can use an embedded language. The best options for Go are: - Lua (https://github.com/yuin/gopher-lua) - JavaScript (https://github.com/robertkrimen/otto) The built-in Go plugin system has some limitations, but there is a mature alternative (https://github.com/hashicorp/go-plugin).
This would be great. As for a message bus, you might want to see if Event Sourcing and CQRS might help there.
Look at buffalo
What do you consider missing from package path? It answers the absolute/relative question and can clean a path to its canonical form making equal paths equal strings. The only thing is the file/directory thing which I do not understand as you cannot tell from the path (and it might even change).
Package path is about actual paths on disk. The post I made is about logical path manipulation (strings) which all have a single type (string) whether they are abs, rel and file, or dir. Try reading through: https://github.com/commercialhaskell/path if you'd like to understand the concept more.
You said I wasn’t capable of understanding it so now you are back tracking. Your argument is if you don’t know X then I can’t explain X to you. Anyone can use that argument to assert anything to be true. If you can’t cite a single example of what Go can do trivially that other languages can’t then life will move on safe in the knowledge that you don’t know what you’re talking about.
Look into Buffalo. Lots of good resources for building larger webapps.
This is an effort for creating a sample project to address all the questions asked above: [https://github.com/spy16/droplets](https://github.com/spy16/droplets). Note: I am the author of the project. It is far from complete, but might give some ideas about structure etc. 
When I was new to Go I often typed range n in ... Took me some time to flip the mental switch :)
thanks for link!
[removed]
Or you can use GitLab!
Is there a good mqtt broker in go? Might want to check out Redis 5 streams.
Zsh also
RemindMe!
I am using Solace, which is MQTT in go, yes. Havent explored it too deeply yet, but Solace is a very powerful highly scalable and very performant message bus. 
With some of the perkeep contributors being core GO contributors, this is a good suggestion. Also it’s a really cool project and idea. 
I can't give a great examples of webapp, but have a few directions. For folder structure I recommend to have a look at [https://github.com/golang-standards/project-layout](https://github.com/golang-standards/project-layout). It's great compilation of common practice in go community of app structuring. Then take a look at [https://github.com/go-kit/kit](https://github.com/go-kit/kit). Use it or not it's up to you, but examples may gives you idea how you can separate your application layers. If you will need DI in your project, best way is write down constructors by yourself or use something with code generate and static, like [https://github.com/google/wire](https://github.com/google/wire). Rest of all is common practice in all languages. Read "Clean Architecture" by Robert C. Martin and all will take a place in your head. Don't google some go clean architecture example on internet, it's a mess. Do it by yourself using examples below.
&gt; If you’re not capable of understanding this is true without me hand holding you ... Here I'm saying that **IF** you can't understand it without my assistance -- &gt; ... then there is no value in me going into anymore detail. Then it's not worth my time to. I never said _you can't understand it_. I do my very best not to insult some random person I've never met, because I know nothing about you. It does me no good to call you stupid. My point was that if you aren't willing to do any work on your side, it's not worth my time continuing the discussion. I'm not winning, I'm saying "if that's how you want to be, I'm out." 
Wow..thanks for this. I spent the past hour+ watching the video, looking into it. Very very similar to something like JEE, but with generators. I do think, from my initial hour+ dive in to it, that it is a bit overkill for my micro services architecture. I could be wrong, but it looks like it puts a lot of stuff in the one app, and maybe there are ways to use it to specifically build tiny micro-service only endpoints, separate non-api endpoints (task runners?) that are responding to queue messages to do things? But very very cool. I will definitely be looking at this in more details soon. If only there was a RAML Golang tool to parse RAML 1 docs! 
Read a little bit on it.. not sure it is as desired as simple MQTT. Essentially as I see it, an API request comes in, which is then sent as MQTT over MB, and then handled by one (or more) interested services in some manner, possibly with an MQTT response back to the requester. 
I have to admit, I'm lost. Go's package path _is_ "about logical path manipulations (strings) which all have a single type string" and not about "actual paths on disk". And yes I understand the concept but I think the concept is broken because a path may point to a file _or_ a directory and directories are files anyway. But I'm sure you could model this nicely with a handful of homotopies, monic endofunctors and monads.
To answer your question: Yes, please build it. Maybe it is useful.
I was going to ask the same thing. I am curious, are you considering seasoned devs in languages like Java, that are looking to make the switch? Unfortunately I would also be looking at remote. Been doing remote work for years now usually using SCRUM with daily slack/hangout stand ups, etc it has worked amazingly well. Totally understand the desire to keep it local, but you could probably pull in a lot of great talent remotely if you ever decide to go that route. Lot of west coast go developers (of which I hope to be one sooner than later ;).
I'm not suggesting your proposal is in any way bad. It's not. Far from it. However, it's unworkable for a startup/toy project/etc. What you're talking about here is: * Kubernetes * Multiple containers * Database * Message Bus of some kind * Centralised logging Things that aren't mentioned but are also needed: * Centralised request tracing * Service Discovery * Configuration management * Auto-scaling management - so you don't start too many services * Auto-deployment That's a *lot* of things to get your head around just to launch a new product/project. Conversely, if you go the monolith route for version one you need: * A single container / server / whatever * A database You can also add things like auto-deployment and logging management, but in this case you don't *need* to do that. You can then split microservices off of this if/when you need to do so. Which, for a startup, will be after you're already live and are hopefully bringing in money to pay for it.
&gt; I have to admit, I'm lost. Suppose you have: x := "/var/foo/" # an abs dir and y := "rel/path/bar" # a rel file if you wanted to collect abs paths, then appending them to the same array would be a type error, which it isn't currently. Similarly, you might want a special join that takes an abs path and a rel path and joins the two into an abs path: z := absresjoin(x, y) # works if you got it backwards: z := absreljoin(y, x) # compile error none of these issues could get caught currently since the type is only string everywhere.
[RealWorld example app](https://github.com/xesina/golang-echo-realworld-example-app) built using Echo. You can use and switch any front end app listed [here](https://github.com/gothinkster/realworld).
All valid point. Thing is I have done the monolith route several times over the years for various projects. This time out I wanted to let the groundwork for a very clean fast developer friendly set up that also provided what you added. My understanding of K8 so far is that it handles discovery config management etc. Not entirely sure what centralized request tracing is?? But i think everything else is covered. I have a few of the pieces still to learn. Right now I am trying to set up the basic ci/cd... then the message bus and database. Then some simple services that can communicate over the bus to one another and build a simple api to back end service to db. Hopefully if it all works including the ci and CD bits it should be relatively painless to then focus on services and such. Or am I off on this ?
You shouldn’t really be accessing private stuff in your tests. If your code requires a lot of boilerplate then it’s not easy to test, you find by writing your tests first it helps drive a design that’s easier to test, if that makes sense. Look into Kent Becks book on TDD, it’s really informative. 
My two cents on this: Channels are a communication and synchronisation primitive and blocking is therefore an immanent property of their behaviour. How do you solve the issue of minimizing blocking time for the producer? I first of all spend my time optimizing the recieving end to have my code bundled in one place rather than have code scattered around whenever trying to send. What I say is that the reciever can do a much more educated decision on what to do in case of high load. Using an overflowing bucket approach feels to me like surrendering. 1. Speed up the consumer: This seems very obvious, but it is kind of hard to achieve in practice especially if you're like here simply limited by a shared resource, IO. I hope you do already buffer your writes, preferably to smth. like 4kB. This has the implication that you now have to communicate panics to the writer to flush. 2. Use a goroutine local buffer: This offloads pressure from the channel and you can possibly have an infinite buffer. Not to useful by itself. 3. Prioritize at recieving side: If your log messages have something like a severity associated with them you could discard lower priority messages. This imo is much better than making a decision on the sending end. If this is to time consuming by itself use another goroutine (the writing one will block most of the time). You can for example say if the channel is filled to 2/3 of its capacity start throwing away messages. Remember that you can get information about the buffer length with the `len` function. 4. Test with reduced buffer length: This reveals a possible bottleneck early. 5. Avoid expensive syscalls: Keep files open and don't use append-write on already huge files. This kills performance. Create new files if necessary. 6. Reduce loging, especially in production. 7. Get better hardware: An nvme ssd has a write speed of multiple GB per second and enormous high IOPS rating. Good luck stretching it out. An architectural pattern you might be interested in is the actor model which is similar to Gos CSP approach but has a purely non-blocking fire and forget philosophy. I hope at least on thing comes in useful to you.
I think this is going way too far in terms of tooling. I wouldn't recommend any technology or sw architecture as a standard without knowing the problem to solve. So a recommended architecture should probably be database agnostic and "container" agnostic. As for recommending microservices: they are an answer to scalability issue, but they add so much complexity that they should probably never be a target, just the best(only?) tool when scalability can't be achieved in any other way. To answer your points on microservices, you don't share your DB across services: each one has its own database covering its own business domain, sharing data with the outside world only via external APIs (be it REST, RPC, events, whatever). Ps: english is not my mother language, sorry if I look rude... 
&gt;Boulder [Boulder](https://github.com/letsencrypt/boulder) is an implementation of an Automatic Certificate Management Environment (ACME) based CA (certificate authority). .... Boulder is the software that runs [Let's Encrypt](https://letsencrypt.org/). # 
Well I understand what you are _trying_ to do, but I think you are wrong. "/var/foo/" is an absolute path (you are correct here) but it is not a "directory". /var/foo might be a file or a directory or not existing at all. Adding a trailing slash to a path doesn't make it a directory. This conceptual problem does not go away with more types. Same for rel/path/bar. Just because there is no empty path element like the trailing "" in /var/foo/ doesn't make this a file path. Add hard and soft links and boom it goes.
If you need to access private properties to properly test then there is likely something wrong with the architecture choices. Everything should be able to be run via public methods and accessors. If it feels wrong or especially hard it may be time to refactor. Make everything as simpler and possible
Clearstreet.io
&gt;buffalo Which [gobuffalo.io video](https://gobuffalo.io/en/docs/videos) did you watch?
 TBQH… This seems overengineered. Of the five problems mentioned * The first three are solved by `path/filepath`. * The fourth is mostly unsolvable. The filesystem is not part of your address space, so whether a path refers to a file or a directory can change at literally any moment and you need to be able to cope with the consequences anyway. * Which leaves the fifth. Which, to me, is a typical Haskeller-Problem :) "There's a thing we could say in types but we aren't, which is bad". If you truly feel you need this, sure, build it. But it doesn't seem very Go-like to me, to put this level of type-overhead on something, if it doesn't serve to actually prevent any practically significant bugs.
What you're doing is laudable. I've no complaints about it. I just think it's not feasible for a brand new project with no time/money behind them and who need to get going quickly to start at that level. It's a lot to get in place before even a single piece of functionality. The long term benefits of it are great. There's no doubt there. It's just that the short term is where that kind of setup falls down. If it's a startup, spending however many months getting that setup in place and working isn't feasible. If it's a personal/toy project then all of that groundwork will put people off. Plus theres the cost factor. To achieve that means you're running a large number of services. Each very small, admittedly, but you couldn't deploy it on - for example - the Heroku free tier. For businesses, that's not an issue at all. For startups and personal projects, it is. Regarding what I called "Centralised request tracing". When things go wrong in a multi-service system, it's very useful to be able to trace a single request all the way through the system to see where it's gone. Sometimes it's as simple as putting a common "Request ID" into the log messages of every service, but then you need to be able to propagate that from one service to another painlessly and flawlessly. Sometimes it's a much bigger job. It depends on the architecture and what you need. (In the Java world, something like dynaTrace or AppDynamics do a really good job here, but you pay a *lot* for it)
I tend to follow the TDD pattern, and use the [https://github.com/cweill/gotests](gotests) tool to generate the templated tests. Here's an example of how i build out my packages to fit it: - create package directory - write interfaces in interfaces.go - write implementations(structs) of the interfaces in their own files i.e. scanner.go - I then run `gotests -w` in the package directory. - I then fill in the test cases that gotests generated, and start to then implement the actual business logic of the struct's receiver functions. I have enjoyed this pattern the most lately as it forces me to to think interface first, and test first, which results in very clean code, and good code coverage from the start. 
If you like Go then good for you. There is nothing wrong with having few nice to have features. C is also a very simple language. The criticism around generics that many people have is more around generics being part of a minimal set of features for a modern programming language. As you say they wanted to implement it but couldn't agree. That says that they thought it was important but they are not cooperating good enough and the users pay. That's my experience with the go creators. We know what's best for you. Ex warnings as errors.. that's crazy and almost no other compiler in history has that. You get an error on unused variables. It makes it really hard to explore different solutions.
Where is the comparison with a simple for cycle?
Hey thanks for comment Sorry but probably I forgot many frameworks when I worked on benchmark comparison I just tried with 2 of them, it would be so hard writing test for all the frameworks... Anyway I will keep in mind this framework for future comparison Cheers 
I've run a Java web server in about 10mb of heap. Handled a good 100,000 requests per second on a not too beefy server. (Under artificial benchmarks) Off-heap memory usage pushed it up to about 30mb of memory usage total IIRC. Still not as lean as Go, but it is possible to run Java in a lot leaner footprint than people realise. Just run far far away from anything remotely related to Spring or JEE. That said, Java would still not be my first choice if lean memory usage was a priority. There's much better options. 
That's often the case with these types of comparisons. They're rarely a direct port so take it with a grain of salt. IIRC Go is optimised for latency over raw speed, so while it's still fast I'd usually give Java the benefit of the doubt over Go when it comes to raw number crunching. (Whereas Go's green threads are much better for IO bound code) I don't doubt the memory comparisons though. Even using Graal AOT compilation, Java is still a memory hog.
I simply have a library, written in Go, that needs to be usable from a multitude of languages. Target users have an application server in their desired language, and want to use my library.
Pulumi does this. It's a terraform-style tool written in Go, but uses an FFI and Codegen to provide bindings for Python and Typescript. It's quite well engineered and sounds like a good example of what you're asking. 
There's no burden on me to do any work, you asserted it, provide evidence. Feel free to put simple instead of trivial.
when will it be in beta?
Yes, exactly that. When a goroutine does `net.(*TCPConn).Read`, it eventually reaches the `recv(2)` syscall and it may have two outcomes (barring error conditions): some data received and `EWOULDBLOCK` / `EAGAIN`. In the former case the call just returns all the way back from `Read` and in the latter the socket is given to netpoller and the goroutine is parked. 
Sometimes it's useful to export private variables/functions in your tests. The go stdlib technique is to write an `export_test.go` which is only compiled when running tests. [See this for example.](https://github.com/golang/go/blob/master/src/math/export_test.go) While indeed a very useful technique you should use it sparingly. Try to approach testing from the public surface of your package.
Great post! The thing that I don't like at all is defining the handler.go inside the ticket, as you said for larger applications you will move outside, but maybe here could be great to defining inside an http or http/rest package too. I have a question regarding the model, in your case you just have one model, so it's ok defining there, but as you commented the Kat's talk, I don't like her approach because the models are duplicated or triplicated, depending on the case. On that case, what do you think should be better? In my case I defined a pkg/model folder but I don't like it at all, but more than duplicating the models inside each "domain"-package. Thanks
There's this https://link.medium.com/gnXT9BUenS But unless you are doing some kind of wrapping I prolly would just make it a server file in a docker container.
stiching would be good.
So the way I structured this application was giving the expectation that if you wished to split the application into a separate repo, the only thing you would need to do is rewrite the main function. Since [handler](https://golang.org/pkg/net/http/#Handler) is an interface I felt like this was okay. I've used it (and there is an example in the application) where that interface is used for the **http.serve** function as well as using it for compiling into an AWS lambda function. I think Kat's talk does a great job at outlining how to structure domains but I agree that it can seem tedious to have repeated entities. My example was entity focused but I'm not entirely certain that it's correct. I have found that organizing by entity (in her case beer, my case ticket) seems to work well if there aren't a ton of relationships between them. I have not personally scaled this out to see what more complicated domains look like but I think using sub packages may work well. So **beer/entities**, **beer/review**, etc. I don't know if that answers your question.
I needed this! a month ago... Anyway, +1 for code generation, not reflection.
Take a look at [Mercure](https://github.com/dunglas/mercure)
Context?
Not sure how I feel about the "genericism" in a "buffer". Expected bytes.
Really not sure what argument is being advanced here.
Bytes would require encoding / decoding, making the whole thing a lot less efficient. 
Agreed. Without the title, it would be kind of interesting, maybe informative to someone who had no experience with Go interfaces. But the title strongly implies that it is illustrating something "harmful". I still don't know what that is supposed to be. That none of the blind men know what the animal is? Yeah... that's kind of the point. Or rather that none of them \*need\* to know/care what the animal is. Encapsulation and information hiding are positive qualities.
for me on Ubuntu 18.04, right after the first test, the server will start hammering the CPU massively. After I do a single thread test "ethr -c [192.168.1.100](https://192.168.1.100)", 1 core will go to 100% until I kill the server. If I try with multiple threads, multiple cores will get hammered. I didn't check the code to figure out where the bug is, but this seems quite broken to me.
Thanks for answering! My comment about the Handler was more related in that for example exposing your service via RPC or REST, so in that case, the "handler" would need to be moved (RPC it's the use-case that I'm trying to solve now). Regarding the domain I think your both approach is good because are small, but as you said for bigger ones would be crazy. I'll try the approach of subpackages that you suggested. The problem that I have is that I have a lot of relations between my entities and my services are also linked between them, so idk if the HEX architecture will be nice to solve my problem or not.
[https://golang.org/pkg/sync/atomic/](https://golang.org/pkg/sync/atomic/) provides some wrappers around simple variable/field manipulation. Still -- more typing then you might do in other languages but it helps. &amp;#x200B;
OK, but in an actual real-world application your structs are often not aligned wit the database. Eg. In the application I'm currently building I have: type Document struct { ID uuid.UUID Name string LatestVersion uuid.UUID Key [32]byte } and also type DisplayDocument struct { ID uuid.UUID Name string LatestVersion *DocumentVersion Owner *User Permissions *[]DocumentPermissions } because the `Document` struct matches what's in the table, suitable for Creating and Updating documents, but `DisplayDocument` matches what's required by the UI. I could construct the `DisplayDocument` in code from three or four separate database queries, but it's actually waaaay more efficient to do all of that in the database, so I have a Postgres function that takes a Document ID and returns the data needed to create a complete `DisplayDocument` in one go. So how would I use this tool to generation the necessary boilerplate?
&gt; Proverb 1: Don't communicate by sharing memory, share memory by communicating. If you absutuely have to share a struct among goroutines use a mutex and provide access methods as you pointed out. The log library in an example for this. The best thing is to rethink your architecture to avoid a lock and to minimize communication across threads. You could tell us what you want to archive and then we can propose a solution that fits your needs.
Yea. Next thing the author is going to make a post on how Generics are bad because you don't know the type. That's.. the point. Yeesh.
RemindMe!
+1
+1
I agree that expanding to bringing in remote talent would increase the potential to find excellent engineers to work on the project, and it is a path that I think is not only possible, but likely in the future as the team grows. For now, we are committed to building a tight and cohesive team here in NYC. I'll dm you my contact info so we can stay in touch if that changes. &amp;#x200B; As for engineers looking to make the switch from other languages, we want to see activity in the Go community or project work, so we know there is a baseline of familiarity to hit the ground running. Make sense?
&gt; Ex warnings as errors.. that's crazy and almost no other compiler in history has that. You get an error on unused variables. It makes it really hard to explore different solutions. How does that prevent you from exploring other solutions?
Yes, I never said the onus was on you. I feel like you aren't reading my replies? _It's not worth my time._ And with that, I'm done with this line of discussion as well.
Here is the info I dm'd u/JamesIsSoPro &amp;#x200B; &gt;To answer your question, the problem is quite complex. There is a very necessary and specific set of offering that institutions that are actively involved in the markets have to rely on in their workflow, and they have long been neglected. These platforms are the backbone that allows the providers to offer services ranging from clearing and settling of transactions to margin lending and risk calculations. We are dead set on modernizing this and building a scalable platform that improves the way these clients do business. &gt; &gt;We have a small tech team building a platform from scratch using very modern web stack (Javascript, react/redux, Go, Kafka, Kubernetes, terraform, Docker, puppet, etc) &gt; &gt;You can find more at clearstreet.io if you are interested &amp;#x200B;
Thanks for the reply. Yup..makes sense. I asked that because I am always curious if companies looking to hire for one language would take engineers well versed in others and give them time to learn on the job while coming up to speed with the company, project, etc. I usually assume pretty much any company is going to want you to hit the ground running and not expect to pay for a few months of learning while coming up to speed. But I hear/read sometimes some companies are willing to take a more senior engineer in other languages for their experience and knowledge and ignore the "tool" ignorance as they can learn that on the job. 
Hey u/jkoudys, &amp;#x200B; We have a very talented foundational team in place, so we don't need someone to run the team right now, however we open to hiring collaborative minded sr engineers that can own projects. We believe that everyone on the team should be hands-on and writing code. &amp;#x200B; [More info on the company and role](https://www.reddit.com/r/golang/comments/a2sgda/well_funded_start_up_looking_for_go_engineers/eb2qx9h) &amp;#x200B; &amp;#x200B; &amp;#x200B;
I'd say minikube or some other local kubernetes solution. Then just copy the kubernetes configs, it's really easy if your devops team uses yamls.
It doesnt prevent but it makes it harder. When I write code I write-refactor-write in cycles and in that cycle some variables are there from a previous cycle that I want to come back to or delete but I want to decide when to act. The stupid compiler won't compile because I have an unused variable. That is crazy. No other compiler behaves that way ever except for Go since "big brother" knows what's best for you. There is a reason why compilers has warnings .
TBH at this point the title "X considered harmful" should be considered harmful
Alternately: &amp;#x200B; The blind man does not care what pulls his cart, only that it is pulled.
There is nothing preventing you from doing both. I typically use the _test package naming so I can get a feel for the API from another user’s point of view. However when I feel there is benefit for testing something that I don’t want exported I make a foo_internal_test.go file(s) and make that part of the public package. “go test “ will run both sets of tests fine. 
Awesome. As a network guy using go. I love this 
Cool, so zero credibility on that claim then.
If your willing to dismiss the entire discussion. 
https://github.com/fogleman/gg
Subscriptions are managed by your payment provider, i.e Stripe / Authorize / Paypal. They keep you updated via webhooks with events such as when a subscription has been renewed, canceled, etc. and you have to handle those events properly.
Considered harmful posts considered harmful.
I built one in my book, but I've still not decided when the accompanying source code will be released open source. The book is Build a SaaS app in Go by the way. Are you targeting other aspects of a SaaS not related to subscription, say cron job like for specific events like sign-up email sequences or trial end actions?
netstat works and this is not the js ecosystem. there's no need to switch to something just because it's new.
Comment? Assign to underscore? Build a Go compiler that handles dead code? Use source control so it’s snappy to rewind? I love that dead code isn’t compiled. It has never bother me. And tools like `goimports` (a `gofmt` replacement) handle imports for you. If you hate it, don’t use Go. It’s not like anyone is forcing you to use it. I’m sorry you feel the Go developers didn’t build the language for you. They built it for themselves, for their needs and gave everyone access to it. That must be the “big brother” your talking about. As I said before _every language exists to solve a problem the author had_. Even languages built for educational purposes. The author had the issue of not knowing how to build a language so they built one. I don’t know anyone who has built a language for _everyone else’s problems_.
The problem with internals is you are coupling tests to implementation detail. When it comes to refactoring (i.e changing implementation details) you will be impeded by your tests. 
[removed]
Well as long as they are all not global, who cares. The exact same argument can be said about any part of low level programming. Functions can end up with name collisions, objects, arrays...ect. that's why there is scope. I'm not really seeing the point. Unless you are making a point about people who don't know scope?
We have helm charts that will create mysql pod depending on flags set in repo. Production deploys are managed by a different values file. Our services have no dependencies on any other service (all have their own db if required) so Devs can either use docker compose. Or minikube using the "real" helm chart just with some "local Dev" flags turned on (which invokes the creation of the mysql pod mentioned before) You could create a local pod that acts as a mock endpoint of third party. This could be used for local development, but also used in the cicd pipine if you wanted to test against the mocks. But real test endpoints might be better at that stage. This all assumes services can be run in isolation without heavy dependencies on other services, if you need that, then it sounds like you have a distributed monolith.... Which is harder to work with. 
Yes, you [can run a Java web server in an amount of memory comparable to Go](https://www.jetdrone.xyz/2018/08/10/Vertx-native-image-10mb.html). However, if you're going to use standard Java web development APIs, you need a Jakarta EE server, and at that point you're looking at a lot more RAM.
I've added a PR ([https://github.com/wesovilabs/koazee-comparison/pull/1](https://github.com/wesovilabs/koazee-comparison/pull/1)) to show what I mean: a simple Go for cycle. &amp;#x200B; Fro my greate surprise, koazee is not much slower than the plain Go for cycle!
No caveats, same as the credibility. 
Thank you so much for your PR and apologize for my bad understanding. I am afraid I understood that cycle was another framework (Sorry for my English hahaha) &amp;#x200B; I really appreciate your collaboration! That's the real value of the opensource! &amp;#x200B;
[removed]
Structs of response and request are not aligned with database tables. It's about the contract. The tool helps in communications between application and database. Preparing the struct for UI is responsibility of service object. But you are talking about a receiving complex response with nested structs. Bad news: currently there is no support for fetching one-to-many relations. (will be available with AppendRow hook). Good news: there is exists the support of nested structs. You can define response like that: ``` type GetDocumentResp struct { Document User DocumentVersion } ``` and if the database response will be: ``` id | name | id | name | id | created_at ---+------+----+------+----+----------- 1 | n1 | 13 | n2 | 34 | 12:34 ``` then you will get response: ``` var out = GetDocumentResp{ Document: Document{ ID: 1, Name: "n1", }, User: User{ ID: 13, Name: "n2", }, DocumentVersion: DocumentVersion{ ID: 34, CreatedAt: "12:34", }, } ``` It is not a solution to process array of DocumentPermissions. If you don't want to use embed structs, you should redefine a mapping like: ``` func (r *GetDocumentResp) ProcessRow(rowMap sal.RowMap) { rowMap.Set("name", r.Owner.User.Name) } ``` but in your case it's not suitable.
 &gt;- Embed an RWMutex in the struct and let the reader/writer handle locking an unlocking. I'd rather make the struct handle that internally if possible. &gt; I would recommend not exposing the synchronisation details, like the mutex, to the callers. Creating private fields and public getters and setters seems the way to go if you want to share access to a pointer to a struct (mutable) 
So, in theory, you could use QtWebView to write a fully-functional browser in Go, compile it to WebAssembly, and load it in a browser windw for a fully-functional and native web browser running within a web browser?
&gt; Production is on the k8s. Then most of the work is done for you. Just create a second set of services that operate in a separate domain. That's how I've done it at every startup &amp; company I've worked for... either docker or k8s, but an entire stack for dev, one for test, and one for production, each a copy of the other.
Here's a complete example cribbed from a project I wrote recently. Both the layout and the pages can have their own variables. There are other ways to do it, but this is what I settled on. func mustParse(name, tmpl string) *template.Template { t, err := baseTemplate.Clone() if err != nil { panic(err) } p, err := t.New(name).Parse(tmpl) if err != nil { panic(err) } return p } type renderContext struct { Data interface{} } // render a HTML template func render(rw http.ResponseWriter, req *http.Request, tmpl *template.Template, data interface{}) error { rc := renderContext{Data: data} rw.Header().Set("Content-Type", "text/html; charset=utf-8") return tmpl.ExecuteTemplate(rw, "base", rc) } // base layout template var baseTemplate = template.Must(template.New("base.html").Parse(` {{ define "base" -}} &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;title&gt;{{ block "title" . }}&lt;/title&gt; &lt;body&gt; &lt;nav&gt;&lt;/nav&gt; {{- template "content" . -}} &lt;/body&gt; &lt;/html&gt; {{ end }} `)) func hello(rw http.ResponseWriter, req *http.Request) { render(rw, req, helloTemplate, "world") } var helloTemplate = mustParse("hello.html", ` {{ define "title" }}Hello{{ end }} {{ define "content" }} &lt;div&gt;hello {{ .Data }}&lt;/div&gt; {{ end }} `) 
thx what are the dashes for? in `{{- template "content" . -}}`
&gt; In trying to learn what makes good Go architecture Keep in mind that architecture can change based the intended audience of a given application / service. If you're only serving 1 request / sec., there's no need to build a lot of what one would build to serve 1k requests / sec., nor would there be reason to build so much. I know there's a lot of value in following best practices, encapsulating and/or abstracting away various network and database functions, yadda yadda, but keep in mind the YAGNI principle as you work through your design, and find that your life becomes much easier. Much less to debug, maintain, configure, etc. when you just don't write things to begin with. All being said, have you considered the audience of your application? That'd be a helpful input to give us...
My `hello.html` would be in a file. How would the code look like then?
What you actually want to use is text/template instead of html/template. html/template escapes any html looking characters, not to useful when you want to generate html. Otherwise can you elaborate on what is not clear? The documentation is quite exhaustive and multiple examples are given. For kind-of inheritance look into the nested template definitions section.
I've added examples of a couple of ways to go about this to the repo.
Schema stiching is something that we're unlikely to add to this library in the near future. Our primary use for this library is building an API gateway to backend services that primarily speak REST and/or databases, so we don't have much need for it. &amp;#x200B; I agree this would be good functionality, and PRs to add this would be welcome!
I almost never put my tests in a separate package. People have been solemnly threatening me with Dire Consequences (TM) if my test code can access private internals for longer than Go has existed, and I'm still yet to see those Dire Consequences manifest. By contrast, any time I've fiddled with making the tests be public-access only, I've had Dire Consequences manifest immediately, in the form of things I don't _want_ to expose to the public interface but do need to twiddle with to test. For instance, I'll often have clear submodules inside of the package interacting, and the test wants to use dependency injection or something to separate those modules for testing purposes, but there is less than no reason to expose these for public use because there is no conceivable non-mock/test second implementation possible. ("Less" than no reason because all you could do is create bugs.) I think expecting the public interface to both correctly match what the public should see, and what the test interfaces need, is an unreasonable ask. The one exception I've got at the moment is a test package where for testing purposes I had to import another local package that would have been a circular import. Fortunately I was able to write that component of the test in an external package. But that's an implementation detail of a specific test, not a reason to start doing it everywhere.
The audience is... Me. Seriously. I'm not doing anything special or fancy. I'm not trying to launch the next Facebook or anything like that. I'm just playing around and learning new things. And getting in a mess already :-) And whilst I agree that the exact requirements dictate a lot, there's also a lot that's just standard practice. For example, in Java I'd have a fairly standard, repetitive package structure. For example, a blog might have: * users * users.rest * users.dao * posts * posts.rest * posts.dao In Go, this doesn't work. If I do that, I can't (easily) use "users.dao" and "posts.dao" because they share a last package name.
https://medium.com/@copyconstruct/testing-microservices-the-sane-way-9bb31d158c16
So how does select resolve this? Sorry pretty new to go. Would love to learn.
The dangerous thing here is the type-dependent switch statement — which interfaces are designed to avoid by providing type-safe polymorphism. Tail wagging the dog...
Maybe Koazee could have come in handy two days ago when I spent all day writing quadruple nested for loops. Such a pain when coming over from C# where LINQ makes it a one-liner.
Agree 💯 I’ve never understood and often lamented HTTP clients that create an arbitrary schism between the header and the body. HTTP is mostly about the header. The body is just the payload...
Totally agree, when coming from other languages you usually missed this kind of things. That was the main reason I decided to bet for this project. Now I nee to ensure the performance is the best and then providing a richer set of operations. I Hope koazee can be helpful for you. &amp;#x200B;
&gt;This position is based out of Chicago, IL and we are not looking for remote candidates at this time. :( &amp;#x200B;
Some double braces have "-" attached, which tells Go to remove all spaces on the corresponding side.
Each service extensively tested against it’s interfaces plus several simple end to end tests on staging k8s cluster. 
Why? I started learning Go some days ago and wanted to build something useful to me (I'm learning Korean). Papago Translate works much better for Korean than other machine translating tools, and their voice synthesis is really good. Currenly, all of the features of the web are implemented, but I'm open to suggestions on how to improve my code :)
Question: Why is this better than a buffered channel with a non-blocking write?
That's answered at the very beginning of the README: &gt; Diodes are optimized for high throughput scenarios where losing data is acceptable. Unlike a channel, a diode will overwrite data on writes in lieu of blocking. A buffered channel will block all writers when it's full. This library is for cases where you *never* want to block, where even discarding the data is a better option. The obvious use case is metrics and traces. Missing a few data points is much better than blocking your request handlers.
That's why I said "a non-blocking write". Write like this and you can choose to drop the data point: select { case ch &lt;- point: default: // Buffer full, ignore }
You're overthinking things. It's going to take you a lot longer to get a working prototype if you spend all day building abstractions on top of abstractions... 
Junior Backend ? Bachelor’s degree or equivalent experience Proficiency in a systems langauge (C, C++, Java, Rust, etc.) Desire to learn new programming languages and frameworks Golang experience desired, but not required Interest in bitcoin, blockchain technology, and digital currencies Junior Frontend ? Bachelor’s degree or equivalent experience React or React Native experience is required iOS or mobile experience recommended Interest in bitcoin, blockchain technology, and digital currencies 
in the documentation there's no example of a master layout and its children
But I'm personally not concerned about getting a working prototype out the door in the least amount of time I'm interested in what it takes to write code the is clean, easy to understand, easy to maintain, easy to extend, easy to test, follows best practices, etc. And yes, it takes longer to write that up front. But in general it actually saves a lot of time down to line if you're able to do that. Having HTTP handlers talking directly to the database is by far the *quickest* way to deliver something. And it's a nightmare for many of the things I just listed...
u/unix15e8 we're now live in the jobs channel. Thank you kindly for the invite. 
:(
Thank you all for your inquisitiveness and for your hospitality here in the sub. We appreciate you allowing us the opportunity to connect with the community. &amp;#x200B; &amp;#x200B;
We don't require golang experience for the backend position because we're willing to support a candidate learning the language if we think it's a good fit. We also don't require college degrees, but we aren't looking for any joe on the street that read a tutorial. Thanks!
Nice job. But what if I told you, you can do pretty much all that, including all web frontend and 3D force-directed graphs visualization in a pure Go? (and it's much easier than it sounds) :)
Tell us more
No. Your packages should contain bounded contexts. E.g If you have a customer thing, you should have a customer package: /customer If you have a rest handler, or structure (model), stick it in there or a sub package. E.g /customer/http /customer/model Then everything pertaining to customer is self contained.
Thanks that is what I have been thinking as well. A "noun" like customer would be a package and then everything under it can be split using example you posted. Ok great. &amp;#x200B; What about some global things like Database connection etc ? Do we inject in every API call using request context concept (I am looking at chi and mux routers) or we do the "global" declaration thing. 
It's almost strange how code that does not use "go fmt" looks dirty :-)
A code snippet from my project. By the way, are you aware that there is an excellent static site generator written in Go - [Hugo](https://gohugo.io/). ``` var notFound = template.Must(template.ParseFiles( "./template/notfound.html", "./template/partial/head.html", )) func NotFound(w http.ResponseWriter, r *http.Request) { p := &amp;page{Title: "404 Not Found"} w.WriteHeader(http.StatusNotFound) notFound.Execute(w, p) } ```
Basically my app itself is a virtual machine that executes byte code, (making a programming language runtime in go)... so i can't really use an embedded language because then I'm basically running a language inside a language which means the performance will be garbage. And it will just be another layer that will be required to maintain. But ill definitely check this rpc thing, if i understand it correctly then i should basically be able to replicate it with sockets and make it much lighter and simpler not to mention that it will be more specific to the project and thus easier to understand and maintain.
Yeah that's the problem with plugins, only linux and mac...
I've seen 100 different opinions on this and they all have their place. [Here's my opinion](https://GitHub.com/snowzach/gorestapi)
This is a good walk through on how to make rest useful and readable. https://www.thoughtworks.com/insights/blog/rest-api-design-resource-modeling
Maybe check out [https://github.com/go-swagger/go-swagger](https://github.com/go-swagger/go-swagger) it will add some overhead but also enforces best practices and comes with auto documentation.
&gt; However, if you're going to use standard Java web development APIs, you need a Jakarta EE server Not really. I can't even remember the last project I worked on that used any parts of the JEE stack at all. There's dozens of very good frameworks and libraries to build on that are much, much leaner than anything JEE (or Spring) can give you. Undertow, Vert.x, and Http4s can all run comfortable at scale in less than 32mb of heap. In practice I'd allocate a lot more than that in production, but you can do it. Don't get me wrong, Java with Hotspot is never going to be as lean as Go. The memory model is simply more bloated by design and there's a lot of overheads added by JIT Compilation and dynamic class loading. 
[Here's my opinion](https://github.com/arkavo-com/secure-rest-server) config = security/configuration models = security/\*.pb.go controllers = security/\*/handler.go drivers = cmd/arkavo-server/main.go
&gt; Also please no object oriented code in go. I.e no controllers necessary. Why? Go is an object oriented language, just not in the "mainstream" sense. If you do this, the only way of doing proper dependency injection for handlers (in case you want to do TDD or unit testing in general) is to use builder functions which inject the the necessary objects into the closure's scope. But if you think about it, this is essentially a constructor for an "objectless" method. Kind of defeats the purpose.
Thanks [DoomFrog666](https://www.reddit.com/user/DoomFrog666) and [scaevolus](https://www.reddit.com/user/scaevolus) for the replies. Unfortunately they still dont answer the real question i posed about slices : why dont they have a uniform behaviour, and if they do, what is it? I may not have explained it well enough in the original post so i'll elaborate &amp;#x200B; I wrote a quick bit of code to go through the issue i have with slices and made separate cases for each problem. I'll address them individually as they create some real inconsistencies in slice behaviour. &amp;#x200B; package main import ( "fmt" ) func printfSlice(slc []int, itr int) { fmt.Printf("\ncount : %v", itr) fmt.Printf("\nslice01 val : %v"+ "\nslice01 addr : %p "+ "\nslice length : %v "+ "\nslice01 cap : %v ", slc, &amp;slc, len(slc), cap(slc)) fmt.Printf("\n") } func main() { fmt.Println("start") slice01 := []int{2, 3, 5, 7, 11, 23} count01 := 0 //count 1 count01++ printfSlice(slice01, count01) //count 2 count01++ slice01 = slice01[0:0] printfSlice(slice01, count01) //count 3 count01++ slice01 = slice01[1:5] printfSlice(slice01, count01) //count 4 count01++ slice01 = slice01[:3] printfSlice(slice01, count01) //count 5 count01++ slice01 = slice01[:] printfSlice(slice01, count01) //count 6 count01++ slice01 = slice01[0:cap(slice01)] printfSlice(slice01, count01) //count 7 count01++ slice01 = slice01[1:4] printfSlice(slice01, count01) &amp;#x200B; and the output &amp;#x200B; count : 1 slice01 val : [2 3 5 7 11 23] slice01 addr : 0xc000046420 slice length : 6 slice01 cap : 6 count : 2 slice01 val : [] slice01 addr : 0xc000046460 slice length : 0 slice01 cap : 6 count : 3 slice01 val : [3 5 7 11] slice01 addr : 0xc0000464a0 slice length : 4 slice01 cap : 5 count : 4 slice01 val : [3 5 7] slice01 addr : 0xc0000464e0 slice length : 3 slice01 cap : 5 count : 5 slice01 val : [3 5 7] slice01 addr : 0xc000046520 slice length : 3 slice01 cap : 5 count : 6 slice01 val : [3 5 7 11 23] slice01 addr : 0xc000046560 slice length : 5 slice01 cap : 5 count : 7 slice01 val : [5 7 11] slice01 addr : 0xc0000465a0 slice length : 3 slice01 cap : 4 delve closed with code 0 &amp;#x200B; a) pointers and addresses: i understand that slices are pointers, but all the values end up with different addresses. if theyre all pointing back to the same array, shouldnt they all have the same address? &amp;#x200B; b) what is the actual underlying object everything is pointing to? : in sect 2 of the output, i select the slice to length 0 by selecting nothing. then in sect 3, I select *slice01\[1:5\]* which gets me *\[3 5 7 11\]*, which makes no sense. I've defined slice01 as nothing in the previous section, so why wouldnt it return nothing or an error? It also now has reduced the capacity to 5. Why? it should just reduce the length not the capacity? why did making a specific selection in a slice reduce the capacity but selecting nothing didnt? Then in sect 4 i select *slice01 = slice01\[:3\]* (remember im reusing using the SAME variable every single time). But instead of *\[2 3 5\]* from the original slice i get *\[3 5 7\]* from the slice defined in sect 3. This is even more confusing. In sect 3 it selected from sect 1 even though i redefined the variable in sect 2! and now in section 4 when i make another slice selection, it selects from sect 3 not sect 1? wtf is this? sect 5, 6 and 7 continue to demonstrate the same problem. &amp;#x200B; what am i missing here? why do slices behave like this? is there some kind of pattern or rule that im missing? 
https://rakyll.org/style-packages/ https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#.ds38va3pp https://peter.bourgon.org/go-best-practices-2016/#repository-structure https://www.goinggo.net/2017/02/design-philosophy-on-packaging.html https://www.elliotdwright.com/2018/02/27/directory-structure-and-manual-wiring/amp/ https://talks.bjk.fyi/bketelsen/talks?p=gcru18-best#/1 
One big drawback with packages named after your Domain types (like having a Customer and an Order packages for a commerce website for example) is that they require careful planning (or ugly hacks) to avoid circular import cycles. &amp;#x200B; Ben Johnson suggested another approach: [https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1) &amp;#x200B; We apply it almost litterally on an API project that's getting quite big, and it actually scales pretty well. My organization is as follows: \`\`\` cmd/server/main.go // Entrypoint, just basic app initialization cmd/migrate //SQL Migrations CLI tool pkg/&lt;domain&gt; //My business domain: Value types and Services interfaces pkg/http/rest // HTTP handlers for REST apis pkg/http/rpc //RPC handlers (reset password, emails sending) pkg/http/web // HTTP handlers for a few html endpoints (think Oauth login form) pkg/mocks //Testing mocks pkg/mysql //Services working around the database pkg/redis // Thin cache layer that decorates pkg/postgres services pkg/sendgrid //Email service based on sendgrid pkg/server //Everything related to the API server : configuration, services initialization, etc. \`\`\` &amp;#x200B; It currently exposes about 60 routes, and is quite easy to maintain. The only thing we changed is the package naming for the http/subdir: we use subpackages to avoid having to name conflicts with the net/http package. &amp;#x200B; give it a try, it works suprisingly well even if it is completely counter-intuitive when you come from another language/framework (symfony veteran here)
&gt; in general it actually saves a lot of time Based on which industry studies, pray tell? More SLOC = more vectors for bugs. Your time savings just went _poof_...
Thats where you are wrong. Most languages are built trying to solve the problem that many users have. Not just the Author. Go was built to solve a problem that Goolge had. They wanted a simple language so that they could hire cheap engineers. They even said so themselves indirectly. Compare that with Kotlin, Swift or Rust. Languages created for the masses of programmers and not just for solving a Google problem or problems of one or two authors. That mindset is what makes Go lack features and have unconventional ways compared to the other languages. Go was created by Google for Google and secondary however wanted to use it. It's a completely different approach. I'm still not saying that Go is a bad language but it lacks the modern features that a modern language has. Being a language with a modern set of features was never a usecase for the Go authors. They wanted a simple language that would be easy to learn so people with lesser knowledge in software engineering could be productive faster. They did not have an experienced programmer in mind.
What happens if some other endpoint needs to use Customer model? I ask this because I am looking to put together a micro-services architecture that would allow, in this case, customer to be self contained docker container, BUT plan to use a message bus between services with MQTT. Thus, I was thinking things like models would go in a re-usable "sdk" package, that each individual service, bet it an API facing endpoint, or a back end "agent" that does something like CRUD for a given type, or send out email, etc.. could ALL use this shared "sdk" package. I am also looking to take advantage of RAML 1.0 for defining my API which will then generate the server bit and the model bit of code, API first design with the RAML being single source of truth. &amp;#x200B;
I can't speak to idiomatic practices, and this is my first codebase with go, but I've been structuring my project the same way I'd structure my node projects. It's worked well so far: https://github.com/laaksomavrick/goals-api
1) master layout page 2) its child you don't have that
Object oriented? What?
How are controllers object oriented? Is it just in the sense of a controller class? I find putting my "controller" functions in a single package to be quite useful organizationally, even though there's not a controller class. MVC does not, as I understand it, require object oriented programming.
How does this lead to circular import cycles? Can't you just create a user model (struct and associated methods) in a package and import it in controllers that use the user model?
I mean, people were asking for it in the Go slack, so I wrote it. If it adds no value to you, that's fine.
Interesting, thanks. Most of my communication between application and database turns out to be fetching data for the UI lol 
[Microk8s](https://microk8s.io/) is a *much* better local/single-node kubernetes distribution than Minikube. Only downside is you have to disable the docker daemon if you already have it installed.
recently created a sample project to address the questions asked above: [https://github.com/spy16/droplets](https://github.com/spy16/droplets). This project: - Follows **Clean Architecture** for the core parts (domain entities and logic, stores, presentation layer etc.) - Strictly follows go conventions from **Effective Go** and **CodeReviewComments**. - Uses only single-purpose well designed libraries like viper, cobra, gorilla/mux and logrus and mgo. - Follows 12-Factor manifest for config management (all configs are overridable through environment variables) While enough unit tests are not present yet, there some basic table driven tests for domain entities. The directory structure is an opinionated one laid out by looking at popular open source projects. Note: It is far from complete. But still posting here hoping it will help you in someway.
Context should only hold values relating to that request. You can create your own handler struct which takes the DB connection so once you are in your handler, it can be used. e.g. type CustomerHandler struct { DB *sql.DB OtherThingYouNeed int } func (ch CustomerHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) { } 
You have coupling if they share libraries or structures. If you have another service which needs a customer you can either couple them by using a wire protocol like protobufs, or your own shared lib, or you can create a new struct specific to your needs in the service which needs to call the customer service. Don't be afraid of repeating code, especially when you have quality tests and coverage. 
No it's not. There is nothing stopping you from crafting requests with appropriate payloads and using the http ResponseRecorder to determine the outcome. https://golang.org/pkg/net/http/httptest/ There is no need for a "controller" in a web service. If you are doing a web site, just do an SPA which hits services on the back end for the data it needs. It's far simpler and way less code.
This app has been suggested multiple times in the past. Honestly, it does not fit the list that OP compiled. It's a bloated app with no clear direction of technology use. A look at the client side code shows thy used Closure Library, Gopherjs, and now added React to that mix. Also, it's an app designed to run mostly on localhost, OP asked for a more standard web app, like this app that we are using right now called Reddit.
Agree 💯 
I am using a message bus for inter service communications. Basically fire and forget. All API endpoints get a request, send the json payload via MQTT on a topic/queue, and done. I havent got quite that far yet, but my "sdk" was basically to share the generated models (from RAML, assuming I can eventually get it to generate models in Go), and some utility functions, like the ability to send MQTT messages over the bus, and/or configure a listener for messages from MQTT/bus. Can you elaborate on "you have coupling if they share..". I get the gist of it.. but given that each of these that use the shared lib would be in separate processes and connected via message bus, I am not sure I have the same idea as what you are conveying. 
This 100% this. Stop writing useless code that only adds ceremony.
^^^^ this. Also you don't need controllers.
Any time you have more than one service reference the same shared library, you have coupling. The more you can reduce that coupling, the faster you can iterate and release. Coupling microservices eventually leads to a distributed monolith which is significantly harder to debug than a normal monolith since everything is running in separate processes. If you updated that shared lib and only released one of your services, the other service wont have the updated code. This could cause unforeseen issues. There are ways to mitigate this but ultimately the less shared libs the services jointly reference, the better.
There is https://golang.org/pkg/html/template/#example_Template_block but unfortunately you have to be a programmer to read it. 
reallly??? that's why you're not able to read it?
What about something like this? internal/ ├── httptransport │ ├── httptransport.go │ └── utl.go ├── service │ ├── service.go │ └── utl.go └── service.go main.go In `internal/service.go` you put a service interface with all the methods Ex: package internal type Service interface { CreateUser(context.Context, CreateUserIn) (CreateUserOut, error) Users(context.Context, UsersIn) ([]User, error) User(context.Context, UserIn) (User, error) UpdateUser(context.Context, UpdateUserIn) error DeleteUser(context.Context, DeleteUserIn) error } You also define you types and models structs there, also any custom errors. Then, in `internal/service/service.go` you create the implementation for that interface. package service type service struct { db *sql.DB } func New(db *sql.DB) internal.Service { return &amp;service{db: db} } func (s *service) CreateUser(ctx context.Context, in internal.CreateUserIn) (internal.CreateUserOut, error) { return service.CreateUserOutput{}, errors.New("unimplemented") } // And so on... In `internal/httptransport/httptransport.go` you export an HTTP handler for the service with all the routing ready. package httptransport type handler struct { internal.Service } func Handler(s internal.Service) http.Handler { h := &amp;handler{s} r := way.NewRouter() r.HandleFunc("POST", "/api/users", h.createUser) r.HandleFunc("GET", "/api/users", h.users) r.HandleFunc("GET", "/api/users/:username", h.user) r.HandleFunc("PATCH", "/api/users/:username", h.updateUser) r.HandleFunc("DELETE", "/api/users/:username", h.deleteUser) return r } func (h *handler) createUser(w http.ResponseWriter, r *http.Request) { var in internal.CreateUserIn defer r.Body.Close() if err := json.NewDecoder(r.Body).Decode(&amp;in); err != nil { http.Error(w, err.Error(), http.StatusBadRequest) return } ctx := r.Context() out, err := h.CreateUser(ctx, in) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } b, err := json.Marshal(out) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } w.Header().Set("Content-Type", "application/json; charset=utf-8") w.Write(b) } // And so on... Those `utl.go` files you see in both packages is where you put utility functions. So, finally, in `main.go` you start the server. func main() { db, err := sql.Open("pgx", "...") if err != nil { log.Fatalln(err) return } defer db.Close() s := service.New(db) h := httptransport.Handler(s) err = http.ListenAndServe(":3000", h) log.Fatalln(err) } This structure allows you to separate the transport layer; whether you user HTTP, GRPC or whatever mechanism you want. Some people will create a third package under internal `postgres` with a postgres repository and pass it to the service package, but I think that is too much abstraction. It just creates more boilerplate. [Remoto](https://github.com/machinebox/remoto) is a tool that follows this structure in which you define your service interface, then your implementation and a transport layer to wrap that. As you see, the transport layer is very much boilerplate since it's just a wraper around your service, Remoto generates that for you in a JSON RPC fashion. I hope this help 😊
&gt; Usually, open source projects are not webapps due to the usecase specific nature of webapps. I disagree, there are _many_ large open source eb apps out there. It's just that they are mainly built on top of framework like Rails and Django. Discourse is a good example of this. The problem with Go is that it's not really used to built full stack web apps with. While a big group of Go programmers suggest that all you need is the standard library, almost none of them have built a full stack web app following their own advice.
You can use [getqor.com](https://getqor.com) for building admin area.
I can find 100 popular non-web apps in any language before you can find 10 popular web apps! I'm not saying there are no open source webapps. They are comparatively less (may be because non-webapp is very broad category including CLIs, API services, libraries, frameworks, databases, caches etc.). Maybe be you are right about Go being used less for full stack web apps. While I have written webapps, most of my Go usage has been API services and CLIs. But the point is, above said project was built to showcase design which works irrespective of presentation layer (rest API or webapp or CLI). 
Gofmt's style is no one's favorite, yet gofmt is everyone's favorite. — Rob Pike
master.html {{define "master"}} &lt;!DOCTYPE HTML&gt; &lt;html&gt; &lt;head&gt;{{ template "child" . }}&lt;/head&gt; &lt;/html&gt; {{end}} child.html {{define "child"}} &lt;title&gt;{{ .Title }}&lt;/title&gt; {{end}} main.go package main import ( "html/template" "os" ) var hello = template.Must(template.ParseFiles( "master.html", "child.html", )) func main() { i := &amp;struct{ Title string }{Title: "Example"} hello.ExecuteTemplate(os.Stdout, "master", i) } 
I had the same problems early on, and using an IDE like Goland ( I’m a fan of JetBrains ) with live templating helped to train my fingers and mind. And I’m lazy, so it means less typing ;)
thx, I'll try that
&gt; Most refactoring that I've done of their projects entailed stripping away 85% of their code as it was completely superfluous to the function of the services. I'm working on a codebase right now that has a serious premature generalization problem. Any tips or resources you can provide me on this type of refactoring would be extremely helpful. I'm finding the task a bit overwhelming. I end up getting lost in a sea of code that doesn't actually do anything.
This seems to be a problem that keeps coming up around me. If you have separate models, that still happens, right? You need to update the other model and deploy. Still, that's better than unexpected results! What I'm not so sure how to deal with is something like Service A creates Model 1, and Service B consumes Model 1, and both run Model 1 through some lib that acts on Model 1. So yeah, shared lib is the problem there but if this lib is very complicated it isn't feasible to copy paste it.
presumably, in your second example, the compiler/runtime "know" a 10GB slice is really huge for the stack and allocate it on the heap: https://golang.org/doc/faq#stack_or_heap as for why the stack isn't infinite, originally it was ([Dave Cheney blog post](https://dave.cheney.net/2013/06/02/why-is-a-goroutines-stack-infinite)) - but that was changed (see the [GitHub issue](https://github.com/golang/go/issues/4692)), mostly because "my program crashed" is generally considered less bad than "my machine is swapping horribly".
Thanks for the thoughtful approach, yet keeping it simple. I hope that adding support for more DB implementations doesn't compromise the simplicity.
infinite recursion is never possible... it would take infinite time, which would take infinite energy. For practical purposes, I think a 1 gigabyte stack allows for "infinite" recursion, with proper TCO (tail call optimization) being the only thing more infinitely recursive. If you need more than a gig to store your entire recursive stack, you should either stop using recursion or start using a language that supports TCO. If 1 gig isn't enough, the 16 gigs your laptop has probably isn't enough either.
What about the notion of dynamic stack? If my function needs 2 Gigs of stack for legit use, the runtime provides it gladly by increasing the stack size. But for uncontrolled recursion, the limit is only 1G. Is the runtime aware that an uncontrolled recursion is underway?
For fun, you can see the code [here](https://golang.org/src/runtime/stack.go#L1003), which actually throws the (air quotes) "stack overflow" when it decides the stack is too big (not because there's an *actual* stack overflow), and you can see [here in the runtime main function](https://golang.org/src/runtime/proc.go?s=5036:5047#L117) where the limit is actually set.
&gt; If my function needs 2 Gigs of stack for legit use, the runtime provides it gladly by increasing the stack size. The runtime will do no such thing, as seen in the code I linked elsewhere. /u/jpco linked to a FAQ where it discusses that large allocations *may* be moved to the heap at the compiler's discretion. If you're explicitly asking for lots of memory, it's not going to be on the stack.
Based on my own 15+ years of industry experience. I've witnessed first hand the effect that good, testable design and an increased effort on automated testing can have on your product. On my current team, we currently spend well over half our development effort on writing automated tests. Be it unit tests, full service integration tests (this service in its entirety, real in-memory database, everything else mocked out) or live acceptance tests (the entire set of services live and tests against it, e.g. in a browser) And, you know what the outcome is? QA time has gone down dramatically, time from code to prod has gone down, number of customer bugs has gone down, time spent supporting people has gone down. And as a side effect, delivery rate of features has gone *up*. I'm not talking about super complicated, multiple level abstraction layers. I'm talking about clean, easy to understand code that gets into model objects as soon as possible (so a `user.User` for example), works in terms of business language concepts (`user.Dao.FindByEmail` for example), where code is done once and shared (everything that wants to load users does so with a `user.Dao`, not by any other means) and where testing is a first class concern, so *everything* that is written is done so with an eye to how you will sanely test it (so things like no global state, everything is always given all it's dependencies, everything can be replaced with a mock object, etc). And it works. It sounds like a lot of effort, but *not* doing it is more effort in the long run.
&gt; OP asked for a more standard web app Where ? Anyway, I can't wait to read your great contributions on this topic.
I see. So beyond 1GB, no more growing of stack, just allocate stuff on heap. Does that mean that the runtime **is** aware whether the request for more memory is coming from a recursive call or some legit memory requirement and if it's the former case, throw stack overflow and if latter, allocate space on heap?
No, the decision is made at compile time. It looks at the size of each allocation and decides whether it would be better to keep it on the stack or allocate it on the heap. Run `go build -gcflags '-m -l'` (that's a lowercase L at the end, not a 1) to see the "escape analysis", where the compiler decides whether to keep things on the stack or move them to the heap.
Take a look at: https://github.com/ribice/gorsk
Thanks a lot. That really helps!
&gt; html/template escapes any html looking characters You got it all wrong. Package [html/template](https://gowebexamples.com/templates/) only escapes the values of the struct, it doesn’t touch the template that you are parsing. I suggest you to read more about it, because if you are using “text/template” for all your web projects, you must definitely have a bunch of vulnerabilities in them. Here is the [official documentation](https://golang.org/pkg/html/template/) for the “html/template” package so you can learn how to use it correctly.
I'm not sure how your examples prove anything, you've found that goroutines can only yield at function call points yet you put your scheduler call right before a function call to `fmt.Println` that is present in both examples. Here is an example of the problem: https://play.golang.org/p/T1SEdECbe6z If you run it on the playground or with 1 process using `GOMAXPROCS` it will never finish, whereas with 2 processes it quits. So no, it is not safe to trust that goroutines are guaranteed to be cooperative in all situations. Realistically goroutines are cooperative unless you're writing some seriously tight algorithmic code that is only composed of primitive functions like arithmetic and branching. Do note that Go also has function inlining, and the goroutine yield may **not** be present when functions are inlined. An example I've actually had an issue with goroutine cooperation is with a toy cryptocurrency miner I wrote for fun and when I accidentally had an infinite loop for something that should have exited.
I think the fastest way is to copy the directory structure from a Docker image. I'm not a linux expert, but my understanding is, a rootfs is not a single file, but the directory layout typical for a linux or unix root (`/`) without the logical dirs like `/proc`.
&gt; copy the directory structure from a Docker image Thanks for this tip.
You can see at 13:04 when she \`ls /home/rootfs\` there is structure, its whole ubuntu filesystem. What you can do is to copy/paste your filesystem to directory and you will have filesystem to use for your container.
You're quite right regarding the function calls to Println, I hadn't thought of that. Oddly though my first example outputs a sequence of 5 b's followed by 5 a's on the playground, whereas with GOMAXPROCS=1 on my system they are interleaved. Don't know why this would be but again you're right that it doesn't demonstrate anything relevant here. It's interesting to me coming from asynchronous programming where yields have to be explicit. I guess since there are no guarantees about (lack of) preemption points in Go, the compiler can be as aggressive as it wants in putting them in, prioritizing locations in the natural program flow where they won't incur additional context-saving work. Async programming is quite different in that implicitly all your code is blocking unless you explicitly yield, so you don't have to do any synchronization when meddling with shared memory. I guess my question about latency is just not interesting in real-world Go programs. Theoretically you end up with somewhat arbitrary yield points based on program flow. That is-- the compiler is not guaranteeing that a goroutine will cooperate say every N instructions, or every 100 microseconds. So some contending operation may be stalled for a theoretically arbitrary length of time. I suppose that #10958 will pretty much solve that, and I guess they will just choose a "reasonable" frequency for preemption points in tight loops, that will probably make everyone happy and the problem go away.
&gt; Is it safe to assume that the compiler will make goroutines cooperative regardless of the code? No. Not with present day compilers.
Im just wondering why author of this is getting downvoted for everything he says?
It was my fault... My unlocked mobile... And I clicked the voted buttons... and reddit down voted.... 
Why is there an src folder? Why are there scripts in the bin folder Why do you use glide instead of go modules (if your Docker container is based on go1.11)? Also, maybe add a sample Travis ci or gitlab ci script. For structure, I highly recommend https://github.com/golang-standards/project-layout
In a few days, in Go Advent 2018 series \^\_\^
\&gt; distributed monolith &amp;#x200B; trying to fight against it.. still in the war state with the monolithic mind :) 
/u/TimWasTakenWasTaken has hit the nail on the head really. Instead of Glide, use either Dep or Go Modules. Go Modules are new and experimental in Go 1.11 (but quite stable really). Dep is a bit more mature, but will likely see far less adoption when Go 1.12 hits and the ecosystem has matured around it a bit more. I also agree about putting scripts elsewhere, perhaps just a folder called "scripts". I'd save bin for binaries, like built Go software for example (but that's what the bin folder in your $GOPATH is for). Take a look around some other Go projects and look at their structure. You'll find some very common folder names, e.g. `cmd` where application entrypoints are usually found, some projects choose to use `internal`, which is a handy package that can't be imported by other projects (well, by anything other than sibling folders and their children). Looking at a lot of other projects is a really great way to learn how to structure Go code. That also includes the standard library too! This is neat though, you've made something that will help kickstart your own work, and really the suggestions being made here are tweaks - your overall process is sound.
What is a DB migration, it has been mentioned 2 times in this thread. I come from frontend so totally clueless about this.
A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works and cannot be patched up to make it work. You have to start over with a working simple system. – John Gall (1975, p.71)
"If I have seen further it is only by standing on the shoulders of giants." - Isaac Newton, 1676. Whilst I'm not disputing what you say, I'm suggesting that looking into the work that others have already done in discovering what does and doesn't work well can only have benefits.
Does 300ms seem really slow to anyone else? Like 100x slower than i would have thought. Perhaps locking the world while it iterates the pool is a bad idea. 
Have you tried looking at Linkerd?
&gt;If my function needs 2 Gigs of stack for legit use I'm curious about what you're doing that makes you think you require a 2GB stack? For comparison, in Java you'd set in anywhere between 256k and 2mb. 2GB stack is just ridiculous. I'd strongly recommend avoiding unconstrained recursion unless you're using a language with tail call optimisation (Which essentially means the compiler is rewriting it as an iterative loop for you). If you really do need do use deep recursion, then you could use trampolining to keep your stack size down (Along with performance)
Well, a use case could be to read a 2 GB file into memory.
That's what the heap is for. 
Why aren't you checking for errors from ExecuteTemplate to see if the call is successful? Where is "base" defined?
updated
https://github.com/x899/go_twitter/blob/master/account.go &gt; GetAccountVerifyCredentials - missing error check at first line Will try to have another look soon, I've seen only this file for now.
can you give us a few links/pointers?... you know, for those of us who can't wait
&gt; There is nothing stopping you from crafting requests with appropriate payloads and using the http ResponseRecorder to determine the outcome. https://golang.org/pkg/net/http/httptest/ Which you need to do for any type of testing. But how do you inject a fake database into your http.HandlerFunc implementation so you can change the database output at will and easily test for all the success and failure scenarios, without using global variables, a closure wrapper or attaching the HandlerFunc to a receiver that can hold the dependencies? I was talking about unit tests, not integration tests. 
See also [`http://golang.org/x/tools/cmd/gomvpkg`](https://github.com/golang/tools/blob/master/cmd/gomvpkg/main.go#L32-L74).
Putting those three files (main.go, base.tmpl, index.tmpl) in the same directory, running `go run main.go` and browsing to `http://localhost:4001` returns &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;title&gt; Main &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div class="contant"&gt; test index 123 &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; So it looks like it's working? This is with Go 1.11.2 on linux/amd64.
yes, I've found an error
The author didn't post specs of the machine doing benchmarks so obviously it is tough to tell. He did compare to traefik though, which gives some context. Traefik has some benchmarks against nginx [here](https://docs.traefik.io/v1.5/benchmarks/)
In my opinion it will remove the overhead writing all these models manually, so go-swagger is the thing to go.
the 2 backends were spin up in docker, i would say that's the bottleneck, setup was from here [https://docs.traefik.io/v1.5/benchmarks/](https://docs.traefik.io/v1.5/benchmarks/) but i left the limits out
You may be best off reading some tutorials, rather than adopting someone else's boilerplate. https://www.calhoun.io/intro-to-templates/ That's a start.
/u/TimWasTakenWasTaken /u/SeerUD Thank you so much for the feedback and suggestions. Appreciated. I am just getting started with Golang and haven't explored all the options yet. I wanted a way to kickstart a project quickly and I think it serves the purpose to some extent. I will improve it further along the way. Cheers!
Are you closing the HTTP responses after you read them? Not doing that leaks.
I'm doing a ioutil.ReadAll which I've read closes it
migrations are just sql queries, but the mecanism makes the changes reversible and testable. I see 2 huge improvements over executing requests directly on the server: - error prevention: you can test your requests before executing them on your production - rollback management : if one of your software versions fails, you can revert your DB model modifications in sync with the software rollback itself. 
Nope
really? resp.Body.Close = true will do the trick?
Hmm
Try logging meminfo every 10 seconds with the runtime package and show us the log
Hard to give advice without seeing any code, but pprof should be able to point out where your problem is.
Which parts of the MemStats do you want to see?
Everything from a meminfo struct. Create one and then pass it as a pointer to runtime.Memstats and serialize it to json and write it to a file in append mode. Do this every 10 seconds. Basic mem logging essentially. This helps identify leaks
You almost always want to read a huge file in chunks of a few kilobytes at a time.
ReadAll buffers everything in memory, I’d stream the download directly to files using 8k buffer.
the response is a short json response, typically &lt; 500 chars though
Oh, small payload. OK, then this is weird. You should then import runtime and dump number of goroutines as well as mstats. See what could possibly leak. Import pprof as well.
My sloppily coded crawler has been running nonstop for a week and is using 19mb. It's hard to help without seeing your code.
[https://pastebin.com/hgE9Tfqd](https://pastebin.com/hgE9Tfqd)
Thx a lot, I did not know, i did it super quickly as needed, now i know there is a more « official » way :)
interesting - are you using concurrent go routines?
&gt;&gt;if you're going to use standard Java web development APIs &gt;I can't even remember the last project I worked on that used any parts of the JEE stack at all. That's because you're not using the standard Java web development APIs.
I knew I forgot something! &amp;#x200B; I use go fmt at work I promise
yes, fan-in/out. * 1 goroutine reads URLs from SQLite and inserts them into `jobQueue` channel * 10 worker goroutines, each with their own http client, read from `jobQueue` channel, fetch content from internet, store result into `results` channel * 1 goroutine * reads from `results` channel * failed results (404, timeout, any erorr): logs error and reschedule with exponential backoff * successful results: stores in SQLite
Is Twilio not the real answer here?
[removed]
Probably, the article says exactly that in the very first paragraph &gt; When developers add an SMS component in their app either for verification or notification purposes, they usually do it via RESTful API like the ones provided by Twilio. But what really happens behind the scenes?
The point of rolling things manually over using existing libraries is for learning and self-improvement. What's the incentive to know how this functionality works and why it's doing what it's doing if somebody else abstracted the details away?
I suggest you use pprof to figure out where all the memory goes. See https://blog.golang.org/profiling-go-programs and https://golang.org/pkg/net/http/pprof/ That way you can easily get a diagram showing the memory on your heap and where it was allocated.
apparently one client is safe across go routines.
You are welcome! The link I posted earlier (Golang project standard layouts) provides great project examples that show how exactly to use it. You should really check it out!
it should be, yes
I really liked the article until this 3rd part. The benchmarks for the add missed a major thing for me. The problem he described feel into a 3rd category, memory bound. I believe the reason he saw performance falloff was he confused the prefer her. He then went on to draw some spurious conclusions from this. Well witht the read though.
Ill get my log analyzer dig though it as soon as I get home
I've added a link to the code in the original question
so why does each goroutine have its own client?
&gt; My sloppily coded crawler coded it in an afternoon
Not really. An abundance of curiosity is what kicked off the entire industry, so i'm glad to see the spirit still remains.
I'm about to implement graph visualization in a go project, but didn't find anything native to go, so I'm quite curious.
Don't read everything into memory, and don't convert it to string unnecessarily. json.NewDecoder(resp.Body)
&gt; I’d stream the download directly to files using 8k buffer. Just use io.Copy. It already takes care of the buffering and has various bypasses for high performance when available.
It is safe in general to assume your Go code will be cooperative in the _practical_ sense of the term. In general, you'll do something that introduces a yield point. In all my years working with this sort of language (including some other runtimes that work similarly before Go even existed), I've literally _never_ encountered this as a real problem in real code. So if you're asking about it from that perspective, the answer is basically, yes, you can assume code will be cooperative. However, from a mathematical perspective, it is absolutely true that there are sequences of code that you can write that will result in no yield points in the current implementation. It is something every serious Go programmer should be aware of as a possible problem. But if you're doing something like analyzing several languages for some task and you're wondering whether to put "could freeze the Go runtime with non-pre-emptable code" in the "cons" column, the answer is basically no. In the highly unlikely event that you encounter this as a problem, it's not hard to hack in a fix, and you are _very_ unlikely to encounter it as a problem. It is an insignificant issue.
If you're playing with modifying Go code, take a look at https://github.com/dave/dst
That's my point. 
From this I would assume a plain old memory leak somewhere. Pprof is useful
Curious, what dialect of English is this?
Looking at their post history they are most likely a bot
I kinda like my compression to happen at the LB to ensure I get raw output when directly connecting to my nodes for troubleshooting. Just a thought. 
Heh, no
That's good to hear that you have never encountered this and I agree it's looking like it should not be a practical concern. I am just evaluating my level of interest in a job that has a codebase written in Go, and trying to get a feel for working in this kind of runtime. But also digging deeper out of curiosity. I found this today-- it looks like my original question about latency is not totally off the mark. There are some issues referenced in this design proposal which sound like for high-end production systems the latency introduced by waiting for function prologues to preempt was actually an observable hindrance, and so they are looking to redesign this significantly for Go1.12. https://github.com/golang/proposal/blob/master/design/24543-non-cooperative-preemption.md I actually find this reassuring to have better guarantees around this aspect of the runtime. Though I think you're right that in practice I would probably never run into it in the current runtime implementation.
Sounds cool, but part of the reason I started this project was to learn by building my own shit, so I probably wouldn't use it in this case. Look forward to playing around with it though!
hi, author here. I work for a telco and we have partnerships with other telcos as well thats why we have a direct access to an SMSC.
Yeah, it should be possible once someone gets QtWebView/QWebEngine working, but it's built on Chromium and so it's probably not doable that easily.
You can use a repository interface. That interface can be implemented with a Postgres version. Having that interface means you can test the grpc with a mock. Also we run « unit test » for our Postgres implementation.
My guess is that &amp;#x200B; echo 'export GOPATH=#{consul\_path}/go' &gt;&gt; /etc/profile &amp;#x200B; \`/etc/profile\` never got sourced? &amp;#x200B; Also try updating Go. Setting \`GOPATH\` should be optional.
Why does your env say go 1.6 when your script says you were downloading 1.11? Are you sure you are testing the environment that you expected? Seems like if you set GOPATH properly, then the Go tool wouldn't present that error. Also you wouldnt have to set the gopath at all if you were using Go 1.11 since after 1.6 they defaulted it to the home dir
I honestly have no clue why it is there. I am using a clear install of Ubuntu 16.04 LTS with the only changes being hostname and adding my SSH key. Once I do that then I configure with chef but I do not install go 1.6 at all or any go but the most recent.
Don't think I sourced it no, thought you didn't need to with chef. I just gave it a try and no that doesn't change anything sadly
Hmm that's a pretty nifty method I guess. Is there a package that can easily mock a Postgres test DB for Golang?
I would recommend not setting GOPATH. Does that help at all?
Were you at the Berlin go meetup today? 
You can write integration tests with Postgres running inside docker. If you want less manual configuration try https://github.com/ory/dockertest
In perfect scenario, you would to mock out database layer to test function in isolation. If you dealing with monolith Go app where database interface doesn’t exist (welcome to my world) and happens your FUNCTIONS accepts db transaction then I suggest start database transaction and rollback on each unit test (last resort) or rely integration with Postgres docker image http://go-database-sql.org/modifying.html 
Run gofmt and golint on this - it will make code more consistent and readable. 
Yes, this was one of my first thoughts. Although, my function for each package don't necessarily take in a DB connection they do use a DB connection from the database package which acts as a singleton. I think I will just end up using the Dockertest so that I could leverage CI/CD.
thanks...guess I miss that.
[removed]
The Go version used is ancient, 1.6, so setting GOPATH is a must, unfortunately.
Industry is moving away from ucp in favor of smpp 
UCP, CIMD, SMPP are all roughly the same sematically. It's just that UCP and CIMD are text-based while SMPP is binary and supports TLS(however most telcos don't implement this). The protocol operations are all equivalent. - Establish TCP connection and send login credentials - Send pings periodically - Send packets synchronously - Receive packets asynchronously and handle it. - Encode messages in gsm 7-bit or ucs2 
I didn’t describe the difference just stated that after 10 years working in telecoms in Europe now only few operators support ucp and even with this few like three in uk it is called legacy with Smpp favored. 
Atomic values, mutexes and getter/setters, passing info via channels.
It looks like the value you're setting GOPATH to is also the installation's GOROOT and it doesn't like that. Try setting it to a different directory?
I agree with u/Timemc2, that it would help to [go fmt your code](https://blog.golang.org/go-fmt-your-code). In your Dockerfile, I'd suggest using a specific golang version, ie `golang:1.11.2-alpine3.8` instead of just `golang:alpine`. This ensures builds made from any specific revision of your source are consistent, and puts you in control of when you want to try a new minor (or major!) revision of Go (and alpine). Also, I'd suggest switching to [go modules](https://github.com/golang/go/wiki/Modules), which has the nice side effect of being able to put your code in any folder in your Docker image, making your Dockerfile just a tiny bit cleaner. As to the code itself, your use of a package for interfaces and a package for models reminds me of some of the Go anti-patterns covered by William Kennedy's "Package Oriented Design", which I definitely suggest checking out, either as a [video of a talk](https://www.youtube.com/watch?v=spKM5CyBwJA), or as a [blog post](https://www.ardanlabs.com/blog/2017/02/package-oriented-design.html). 
I don't know the "right" or "wrong" Go way to do this, as I am sure there are those two do that approach and some don't. But, I have seen it suggested that it can be a good practice to instead organise the packages by type instead of by models and controlled. That is, a "user" package would contain a data.go and a handlers.go (or whatever naming you want). And there could be a "post" and etc packages. 
There were already many debates about the controller in the MVC user (the perimeter of the controllers for example) and as far as I can see in Go community choosed another path: The controller is (often) split in multiple part, one for the routing and one for the business logic (and the business logic also tend to be splitted) That doesn't look like MVC pattern anymore, even if you still have models/routing/view separation. Golang project layout is still a topic being debated, but I'd would advise to use more idiomatic ways. Some insights could be found there: [https://www.ardanlabs.com/blog/2017/02/package-oriented-design.html](https://www.ardanlabs.com/blog/2017/02/package-oriented-design.html) [https://github.com/golang-standards/project-layout](https://github.com/golang-standards/project-layout) [https://www.youtube.com/watch?v=B5oQnECDJ8g](https://www.youtube.com/watch?v=B5oQnECDJ8g) &amp;#x200B;
Definitely makes sense to separate concerns. MVC is probably not an accurate description, even if you have things you call models, views, and controllers. MVC is generally used for dynamic applications, where things are changing and reacting over time. Your "view" is a single value returned once per request so it doesn't really fit that mold. That's OK - the problems an app and a server face are totally different. Consider things like Rx, which is a godsend for apps but almost useless on a stateless server. There is no one best architecture that covers all needs.
I was, although I'm not the speaker.
Not sure your full use case but a general DSL and Engine/Linrary to explore is NetFlix’s OPA which is a general purpose way to create rules to enforce. https://www.openpolicyagent.org We leverage it for making security decisions that go beyond “can Bob use X” questions. 
I learned it this way...fat model, slim controllers. Controller is for routing, and in the model you put the business logic.
Shameless plug: some years ago I put some effort into making a decent smpp package for Go, which at the time was part of my company’s products. I haven’t been very active maintaining it but there’s been many contributions. https://github.com/fiorix/go-smpp
I started a small project awhile back that I'm not really working on (and doesn't do what it supposed to do but sort of works for playing with live terminal updates) where I tried a somewhat rigorous attempt at MVC here: &amp;#x200B; [https://github.com/ewohltman/iClient](https://github.com/ewohltman/iClient) &amp;#x200B; I found it was a bit harder to do than I thought, and required using empty interfaces a bit more often that I was comfortable with to maintain clean lines of dependencies, but it could be possible. It's also entirely possible that I'm simply not doing MVC right :)
actually i started playing around with golang after i watched your [lightning talk](https://www.youtube.com/watch?v=oM-MfeflUZ8) in which you implemented diameter. i've also used go-smpp as a guide for idiomatic golang client for telco protocols :)
go is very model oriented. structs in go are your model. go annotation support, within structs directly, demonstrates a model-first approach. maybe look to [gin](https://github.com/gin-gonic/gin) to see HTTP patterns match well with templates. frankly: MVC is a "full stack" paradigm. go is not "full stack". go resembles a systems language, so I'd recommend you use go to solve systems problems. perhaps design an API in go, then go and [eat your own dog food](https://en.wikipedia.org/wiki/Eating_your_own_dog_food) with a front-end using an applicable framework. my 2c
No.
Repeat after me, Go is not OOP. Go is not OOP. Seriously, try to find popular go projects on github to see how the code is structured an learn from that. MVC was and is a bad pattern for PHP and it is horrible for Go. I believe underneath you felt that MVC was bad even when you coded in PHP... 
Why would you say it's archived?
Haha that’s amazing! :) Going again in 2019, if you’re around, see you at the Go dev room.
It's [not archived](https://arslan.io/2018/10/09/taking-an-indefinite-sabbatical-from-my-projects/), but thanks for the morning panic: &gt; this doesn’t mean that vim-go itself will be unmaintained. It’s not! For the past 1-2 years, there were people who were contributing to vim-go and eventually became full-time contributors. These are: &gt; &gt; - Martin Tournoij &gt; - Billie Cleek &gt; &gt;I had a chance to speak with Billie about my intentions and the direction of vim-go. Having said that, from now on Billie will be the lead of the vim-go project. Latest release is from [November 4](https://github.com/fatih/vim-go/releases/tag/v1.19).
That's what he calls it. Abandoned seems harsh. He's on a well earned indefinite sabbatical 
you might have confized with the tutorial [https://github.com/fatih/vim-go-tutorial](https://github.com/fatih/vim-go-tutorial) 
I the idea behind this approach is still right (though I'd still argue again using a controller for routing in any language as it's violating SRP). In Go I'd maybe define it as like slim handlers, fat domain, router is separate and deals with routing, and your domain code has the business logic in, and you probably shouldn't have a folder called `controllers`, or `models` or `router`, etc. 
Yeah, the Go language does actually have an impact on how you can write code (i.e. the possibility of circular dependencies), and this domain-driven approach does help avoid issues with that a lot. Having larger packages that pull lots of other packages in (e.g. if you were to have a `controllers` package for example) is how you end up running into issues more easily.
Take a look at https://goa.design
My 2 cents, based on once having shifting from PHP to Go, and having mentored engineers that were solely using Symfony/Laravel: Get comfortable not thinking about MVC as a pattern you have to implement, and don't structure/name your Go projects with this terminology. Spend your time on modelling the business domain first, don't focus on (opinionated) frameworks and libraries that sometimes nudge you towards naming things based on a pattern (like MVC). So, focus on modeling your business domain around the *behavior* and the problems of the business domain that your program is trying to solve, and structure/name your packages accordingly. For most web applications I tend to have one or more packages with transport logic (e.g. \`handler/http\`, \`handler/grpc\`) that get imported from a \`main\` pkg. You could say that these handlers packages are the "V" and "C" in MVC. Bundle logic with shared behavior into packages. If your app just does CRUD stuff, these pkgs will likely contain some struct definitions and work with a repository. Let's say you have a cargo management service, something like \`parcel\`, \`shipping\` and \`billing\` pkgs make sense. Your transport/handler package(s) will remain quite thin and import these "behavior" packages. In practice, most of my projects have thin transport logic with light integration tests, and heavy "behavior" packages (with focus on unit tests, not integration tests). Having read about Domain Driven Design paid off for me in the long run. For me, having readable code that closely resembles the reality of the business domain and its terminology is a first priority. I really enjoyed this talk, which also covers project design/structure a bit: [https://www.youtube.com/watch?v=PTE4VJIdHPg](https://www.youtube.com/watch?v=PTE4VJIdHPg)
I think you might want to see how gobuffalo pop orm does it
No, MVC is the wrong way. Too bloated. Static &amp; microservices.
Great. Go Advent 2018, December 10 then.
Not always, but a separation of concerns definitely is - whatever that can look like for your specific use case.
Thank you for your input. At first, I thought this is an improvement because I don't have to handle \`.env\` loading inside my code. But I'll take your advice into consideration.
Has anybody built a Kannel replacement using this yet? That's on my TODO list but other things keep coming up. Kannel is mostly great but really falls flat when you want more visibility into the state of your connections programmatically among others. Your lib looks like it has most everything needed save for myltipart messages. Kind of surprised nobody has written a good server yet, golang seems like the perfect language for it.
[removed]
hmm that sounds interesting. ive built fake smsc servers for testing purposes but not as full featured as Kannel.
I second this. I wonder why OP does this line (somewhere under the consul path): ``` echo 'export GOPATH=#{consul_path}/go' &gt;&gt; /etc/profile ``` Usually the GOPATH is `$HOME/go` on Unix, like `go help gopath` says.
I did an very powerful rules engine based on JSON Logic: http://jsonlogic.com My implementation to Go Lang of the spec is here: https://github.com/diegoholiveira/jsonlogic
Woah… except there's no space between minutes and `PM`
Problems I can see with your approach: - circular dependencies. You'll need to be careful that your "main" package doesn't export anything, or contain any globals that anything else needs, or that your model packages don't import anything. It could get awkward in places. I'd be tempted to shove all the models into one package, and all the handlers into the same package as the main and router (since they're all serving the same web front end and won't be re-used for a mobile app or anything - split out any API methods you need for that). - you'll probably need ViewModels to supply data to the UI in the format it needs, and DataModels (naming?) to supply data to the database in the format it needs. You might want to implement these as an intermediate layer between the handlers and the "real" models. - your models will almost certainly be where all your complexity ends up in your architecture. This might be perfectly acceptable. - if you're supplying the same data to HTML templates with every page refresh, you might want to implement caching on the session to reduce demand on the database connection That's about it. It might work. Give it a try :) 
lua (shopify and microsoft implementations) or javascript (otto) helps with testing and documentation as users can lookup language examples online. if a full language is not needed, json/yml is fine
That looks very useful for a project I'm working on. Gotta comment to remember the post
Btw, this uses code generation. Fun stuff... That's why I like Go: simple yet powerful. 
Makes no difference in what error I get
I now have the below: export GOROOT=/usr/local/go export GOPATH=$HOME/go export PATH=$GOPATH/bin:$GOROOT/bin:$PATH
&gt; waiting for function prologues to preempt was actually an observable hindrance Yes, it certainly _can_ happen. I want to make sure I make it clear I'm not saying it _can't happen_. But I'm pretty sure it happens less than once per Go dev on average, or, put another way, the average Go dev will literally never encounter this problem. In fact I suspect the average Go _team_ will never encounter this problem. But it is nice that they're looking to make it happen even less than that.
&gt; what constitutes MVC Over 95% of the "debate" I see on the matter completely fails right here. The "original" definition of MVC as given in the Design Pattern book observably fails to correspond to what most people actually implement when they claim they're using an MVC design. (For one thing, the original MVC has no network communication in it, and whether people like it or not, network communication is such a fundamental change that it _must_ be a major design consideration. Anyone who says otherwise is just deluded as to how difficult it is.) So, err... what exactly _is_ MVC? Nobody knows. But they're pretty sure it's good. Sometimes they're so sure it's good that they very completely know that MVC is the _only_ good design, and if it isn't MVC, it isn't good. But... errr... what is MVC again? You can get a dozen conflicting answers to that. Which means there literally _isn't_ an answer. The solution, in my considered-for-several-years-now opinion, is to just ignore "MVC" entirely. You can't design your code in accordance with "something. I'm not sure what exactly, but something. Models. It definitely has models. Although their exact responsibility and nature I'm not too clear on either. But definitely models. And definitely put the words 'view' and 'controller' in your code, too." Just because you have a name doesn't mean you have a thing that corresponds to that name. What you need is to separate your concerns, and to Don't Repeat Yourself. The rest will fall out naturally. I will also say that actually creating directories that are called "model", "view", and "controller" will drive you absolutely batty in Go, because of the way packages drive visibility. In conventional OO languages it would not be too surprising to see some "friend" relations between the bits and pieces. In Go, you'll be forced to have things public that really shouldn't be public. It's not how Go code "wants" to be split up. Go code "wants" to be split up by concern, so, for instance, all the "user" stuff goes in one package. If you _insist_ on MVC, the user's model and core view and controller should probably go in one "user" package. Although, honestly, you're just not going to see much benefit from that vs. simply separating responsibilities manually. __MVC was made for a problem that the vast majority of web apps simply do not have__. MVC was made for when you need a lot of mixing and matching between multiple views at a time, so you _have_ to abstract at that level. Think a 3D CAD program with multiple views on the same model, all of which can interact with it in realtime. Your web app does not look like that, so spending design budget on a design pattern for a problem you don't have is just cargo cult programming... and not even very good cargo cult programming.
With all due respect, you don't really have a _question_ there. All are solid and bullet-tested in production environments, so nobody here can really tell you anything more without some hint as to what your intended use is.
I don't get it, is it a joke? 
There is a port on the docker-machine VM for this. You’re docker.exe client uses this. Check either your environment variables or the ~/.docker/config file, but I think it’s either 6443 or 8443. You’ll need the client certificates from ~/.docker/ or you can restart the daemon with your own options/certificates. And don’t forget to forward the api port to your host network to make it accessible. 
Coming from PHP/Symfony myself. Not sure if it helps, but always test your approaches against the typical "User got registered, now I need to send a templated HTML mail (with username, address and dynamic blocks) through an SMTP service asynchronously without any further client interaction" flow. If it does not fit, you will run into serious problems later on. In a framework like symfony or laravel its easy, because you have this common logic of services, a single template engine and several finish implementations of core services.
sorry I have updated it to try and be a bit more clear of my use case
&gt; ECTD had no api for leader election Whoever holds a lock is the leader.
Wrong subreddit?
time.Kitchen
MVC in Go as I would do it.. would be a front end UI library like React, the VIEW, making API calls to a back end Go API the controller, and using Models as the request/response payloads, implemented in GO on the API side to convert JSON to/from the Go model classes.
100% of backend is written in golang. This month we will release it
MVC is just a way of doing Separation Of Concerns. SOC is always appropriate for every project of more than 100 lines of code. Is MVC the best way to acheive SOC? Not necessarily. You could do something more like Ben Johnson's standard package layout, for example. A lot of things like MVVC or [MVP](https://redditblog.com/2018/09/12/evolving-mobile-architecture-at-reddit/) whatever are just "MVC but we moved things around a little to have better separation of concerns". OTOH, sticking to MVC gives you a well known pattern that should be easy for your team to follow. It all just depends on the context.
haha yup ;)
but changing that would be a breaking change.. maybe open a proposal for go 2.0? 🧐
I don't have this problem because my 10 workers have been using the same 10 http clients. Looks roughly like this: func startWorker(jobs chan *Job, results chan *Result) { client := &amp;http.Client{/*timeout &amp; other settings*/} for job := range jobChannel { res, err := client.Get(job.URL) // ... handle response //res.Body.Close() //insert Result into results channel } } jobs := make(chan *Job, 100) results := make(chan *Result, 100) go fetchJobsFromSQLite(jobs) for i := 0; i &lt; 10; i++ { go startWorker(jobs, results) } go saveResultsToSQLite(results) // (also reschedules failed jobs with exponential backoff) Maybe this piece helps /u/sc3nner
Breaking? It's a constant. You refer to the constant, you don't hard-code the value behind the constant.
This is the holy grail for me.
What's the error? You probably shouldn't be setting GOROOT since that's typically defined by the location of the go binary.
For truly end-to-end, rigorous integration testing, I second royge's suggestion to run Postgres in a Docker container, and test against that. You can test against the actual version of the database you will be deploying with. If you depend upon particular unique-to-Postgres features, this is very helpful.
Cool, but why not wait and post a link to that repo instead of this one? It feels a bit malplaced here.
15:04PM -&gt; 03:04PM
[removed]
Take a peek at this (older) analysis of etcd: https://aphyr.com/posts/316-jepsen-etcd-and-consul It talks about linearizability, reliability of etcd at the time (it's much better now), and has timing diagrams to show how operations work and their ordering. 
&gt; Breaking? It's a constant. You refer to the constant, you don't hard-code the value behind the constant. Yes, breaking. It may not cause compile errors, but it would suddenly cause runtime errors when you try to `time.Parse(...)` a string with it.
Thanks, I updated the original question because I finally solved the problem - I had fired off lots of concurrent go routines but had the buffered concurrency chan inside the go routine instead of outside of it, hence loads of memory and cpu being eaten up and everything going to hell! once I sorted this out, not even a dent on cpu or memory now! thanks
&gt; Unless it can be used to detect that format in the wild? In that case, it'd be breaking. Hm. 🤔 
Not just detecting in the wild, but a text file you may have which has time formatted in the old `time.Kitchen` format
So you edited the core API and then got mad cause it's not as reusable? How about just create a new function that takes in a reader and writer.... And make your own copy? This oop thing I'm starting to think is like alcoholism. 
that's great to hear! GL
We have go types generation from graphql schema and skeleton creator. I thing visual tool is for user of every lang so thats why I posted 'frontend' editor here.
Generally I stick to the standard http mux, but I have a couple of things using chi, and must admit it is quite nice. Easy pattern matching for getting args, and it sticks to standard library based middleware approaches. Perf is fine, your mux is rarely the bottleneck.
Do you know of a project on github that demonstrates this well (sorry if it’s included in the talk, I’m not able to watch it yet)?
https://grpc.io
That is good to know. Can it handle multiple paths that typically match or are ambiguous? /user/names, /user/test, /user/:id, /user/:number things like that? I dont think I actually would need that, but sometimes I have come across APIs that do that, and it would be good if it could do exact match to /user/test, and /user/names, but then if /user/:number were a number it would call that, otherwise rest would go to /user/:id (being a string). 
&gt; https://grpc.io Looked into that a bit. Not sure I like it, but it may be an option. Thank you for sharing this.
httprouter is fast. gorilla mux is slower. But then again we are talking about routing, and unless all your microservice does is routing then it won't be the bottleneck. Database access or whatever other processing is likely to take longer. So it is also a matter of what extra features you need when choosing a plain router vs a framework vs the stdlib. Are you planning on an http based microservice? Gin will work fine, just like a number of others. I've used gin for a while and I use the middleware features. If I started a new project I might look at chi or echo just to see what they are like. 
Yup, HTTP based API, UI consumer (and possibly/hopefully 3rd party API consumers). My concern with Gin is each and every service would have a complete copy of it, so it seemed heavy weight for just routing 1, 2, 3 or so requests to handlers for each separate service, right? I havent taken a deep dive though, so will look at it more. Echo, oddly I recall reading that that one was no longer being worked on.. but just looked and it looks like it is. It looks comparable to Chi, in that it looks small, built on httprouter, adds some stuff. Good info that performance may not be an issue. If I deploy to GKE or EKS, their front facing routers would be more of a bottleneck than individual "tiny" routers like chi, echo or httprouter. Assuming I understand how scaling will work within Kubernetes, and that the API would be stateless (with Oauth tokens or something for authentication) I should be able to scale as much as needed to handle any number of simultaneous requests. Something I left out in my OP... the use of authentication... I read somewhere that some of these routers might "chain" (via middleware) so that you could say, first chain to an authentication handler to ensure the access to the API is allowed (e.g. RBAC), then, if good, chains on to the actual API handler. If that is the case, which seems like it is a good way to go, would it make sense to bundle up this first handler (for oauth/filter/etc) in the same micro service container as the specific API implementation? So that if I had 10 different API endpoints, thus 10 different "containers", each of those would handle the OAUTH/filter/etc bits... or would it make more sense to have the first layer in a separate container, maybe with SSL acceleration (if possible), then it would make a back end call to another container/service to handle the API endpoint? I am leaning towards the first idea.. where each and every micro-service would have the 2 layers in one container. 
As an extension of the ideas proposed in the above comment, an interesting read is Paul M. Jones' Action-Domain-Responder proposal, which claims to be a more adequate architectural model for web apps than the MVC pattern. It has the benefit of mapping neatly to net/http's concepts: - Action -&gt; a Handler or HandlerFunc - Responder -&gt; a simple component which takes Action outputs and operates on ResponseWriter accordingly - Domain -&gt; just a bunch of packages under domain/ or so. Your models, or entity-repository pairs would be a part of this, as well as authorizatio/authentication logic, utilities, caches, etc. 
I don't really understand the point of "a complete copy" being included with each one and it being heavy weight. Its statically compiled into a binary, so there is no real difference if you choose httprouter or gin. Are you concerned about vendoring into multiple repos? Once its compiled its all the same. Frameworks that have middleware would make authentication handlers easier.
Take also a look at Starlark https://github.com/google/starlark-go which is a Python-ish language used in Bazel
[removed]
I today saw a framework named _aah_ and I suggest you to check it out.
https://play.golang.org/p/tTmA43fexMq
Your print function prints the address of the slice (the 3-element structure with pointer, len and cap). Since the slice is a local variable of the print function its address doesn't tell you much. &amp;#x200B; You probably wanted the address of the 1st element of the underlying array. That's \`&amp;slice\[0\]\`. However beware that if len(slice) is 0 then this will (and should) panic, since it would be indexing out of bounds. &amp;#x200B;
You can simplify `hash[0:]` to just `hash[:]`.
Cool, I didn't know that.
thx
Just write your own router, every gopher must do it, at least once 
That's the Format call. It doesn't mean it literally comes out as 15:04; it specifies how to format the time. /u/SteinsGate, try printing out what you do have to see what is going on. There is not enough information for anyone else to guess from this. You may want to consider `fmt.Printf("Have: %q, expected: %q\n", Atime, "03:32:PM")`, to ensure there are any spaces creeping in or something.
There pretty clearly is a standard, but there are also single-vendor/single-implementation alternatives. That's true of every standard.
What the heck is NoPlan?
 I think you have to change the magic date / time format to `"03:04PM"` because that's the correct way if you want to have AM/PM. Testing against a fixed string works only for a minute each day, I'm not sure if you really want to do this. Often it's easier to calculate a time difference and test if it is small enough. https://play.golang.org/p/LRlNzwZu1Gz 
What's the rationale for prioritizing config file over environment variables? I would have thought the other way around was more typical.
At that point you might need to route all of /user/ to the same handler and write a switch statement.
Done routers elsewhere.. ready to just get stuff going and not waste time. :D I know.. wrong attitude.. but I have very little time these days to work on my own stuff, so want to focus as much as possible on specifics. That said, its not a bad idea. 
I assumed from the little bit I read, that that is handled by the router? You define /user/:id and a function and it handles routing correctly?
Yes, and then you could just pick out the values of :id you want to treat specially and reroute them to other handlers.
This is just a test what I'm doing is, I'm getting dates from a json external file and checking time match 
Reroute them.. isnt each one its own handler already? Not sure why you would reroute them again if they were routed to the func you provided for the match?
Here's my take: https://github.com/zamicol/jsonflag This is how I set the order of precedence for set config values: 1. Command line flags. (cli Example: `--flag1=flag1Value`) 2. JSON config values. (json Example: `{"flag2": "flag2Value"}`) 3. Environmental Variables (env Example: FLAG3=flag3value) 4. Default values set on flag. (go Example: `flag.StringVar(&amp;config.Flag4, "flag4Name", "
&gt; /user/names, /user/test, /user/:id, /user/:number What I mean is, you could have a main function `HandleUser` called with `/user/:pathelem` as path, which fetched the path element after `/user/` from the URL, examined it, and then called one of `HandleNames`, `HandleTest`, `HandleNumber` or `HandleUserID` depending on the syntax of that path element. That way you could keep the functionality in different handlers.
You don't. Specifically, you dont sha512 a password. You use bcrypt or argon2 (pref argon2). [https://godoc.org/golang.org/x/crypto/bcrypt](https://godoc.org/golang.org/x/crypto/bcrypt) [https://godoc.org/golang.org/x/crypto/argon2](https://godoc.org/golang.org/x/crypto/argon2)
Ooooh.. got it. Yah.. that is a possibility as well. Though if it is that dynamic.. it should be one function that handles all that. Otherwise the path should be exact matching. But thats more API design rather than how to handle the path like this.. good stuff. 
I will
There are arguments in both directions, but IMO config file is more explicit.
Chi is a fantastic router, extremely fast, but with as many features as gorilla's mux practically speaking. If you can have the speed, and the features, why choose something with only one of those things?
Does someone mind sharing a working example with argon2?
Any thoughts on the Go 2 proposals?
Config -&gt; env -&gt; cli rules all
probably as costly as serverless
Go helped you learn about FP? How is that possible?
There literally is an example in the docs. It also explains the difference between IDKey and Key at the top.
No question, just as sincere thank you for the just for func series!
Just ran `go fmt ./...`. Thanks for the feedback.
Honestly, with a Microservice architecture I might stick with the http mux in standard library until I need better. Yes, it can lead to more work routing, but before you go and grab a router I think it's a great idea to first consider how many unique routes you'll actually have? Microservices tend to be, well, micro, and thus have very few routes. If you've only got 3-5 (which is objectively a number range I pulled out of my ass) routes to match, I think idiomatic Go suggests you probably don't need a router. At the cost of only a little bit more code, this is far easier to read and understand. Each Microservice can be considered independently for the use case of a router. When using one I prefer chi because it is completely compatible with the standard library, but i think it's best to only reach for one when you need it. Just one fairly new Gophers opinion on the matter :)
I just updated my code to specify `golang:1.11.2-alpine3.8`. I'll have to look into `go modules`, that sounds pretty neat. As for the anti-pattern, I wasn't aware of it. I'll look into this as well. Thanks a lot for the feedback.
You are spot on.. in fact I was trying to figure out if I needed it or not. The only thing I am not entirely sure should factor in or not is middleware.. and by that I mean, I want to do a couple of things to incoming requests BEFORE my APIs are ever called. Namely, first, authenticate. Second, log them. Third, if possibly, ensure not a DDOS.. via some sort of white list, rate limit, etc. Possibly a few other things. With those in mind, I was trying to avoid having to figure out how to do all that myself if something like Chi, G/mux, etc already handles that for me. If I can configure the token engine, the log engine, and potentially some sort of configuration as to how many requests per second per "authenticated user" before my API is ever reached, from something like Chi, etc..then I would much rather take advantage of that. With that said.. do you (or anyone else reading this reply) know.. how to do those things.. e.g. does Chi, Ecco, Gin, etc have some form of way to configure/handle those 3 (or so) items on my list? I am hoping that the ability to scale the API in the cloud, e.g. GKE Ingress smart routing, handles the part of routing based on cpu/memory/etc load for me. Which leads me to ask.. if the 3 or so items are possible via one of the router options, I assume then that I would still wrap up the library/framework in my individual micro-service containers.. or would those sorts of things (e.g. auth, rate limit, log, etc) be a separate "tier" micro-service in front of the APIs, and the APIs would then be behind yet another Ingress router? Sorry, trying to wrap my head around not only how to best build/containerize these micro-services.. but also how they would deploy in the cloud in terms of what GKE, etc offer with routing, auto scaling, etc. 
Yah..this is part of what I am getting at. Seems Ecco and Chi are the way forward.. just not sure which would be the better way to go. Both seem to be small/lightweight, very fast, similar features, and both active in development. Thoughts?
is there anyone like it?
GoByExample has a [rate limiter](https://gobyexample.com/rate-limiting) example which may prove useful. As for middleware, Chi (and most other middleware supporting routers) use a composition-style \`http.HandlerFunc\` wrapper. GoWebByExample shows it well in their [basic middleware example](https://gowebexamples.com/basic-middleware/). You can see that a middleware accepts an http.HandlerFunc (the next handler) and returns an http.HandlerFunc. This pattern makes it incredibly easy to wrap requests in middleware that can perform tasks both before and after the next handler fires. The [advanced middleware example](https://gowebexamples.com/advanced-middleware/) from the same site gives a better demo. No matter what route you go, this is the pattern that seems the most widespread. &amp;#x200B; As for your third question, I'll be honest in that I don't think I'm the best resource for info on that. My gut tells me that rate limiting, logging and things of that nature probably don't need to belong in their own microservice unless you're a Google or Facebook. Authentication, I would personally put into a Users microservice. &amp;#x200B; To handle deployment, Docker is your best friend.
Wow..thank you so much..that helped a lot! Definitely reading up on those links. It makes perfect sense too. My whole architecture is centered around micro services communicating via MQTT over message bus, so I could see, for example a simple bit of middleware that every API endpoint uses to send a logging message to the bus that then gets logged separately, most likely asynchronously. Authentication, e.g. looking up the token and getting back an ACL as to what API/method/etc can be accessed by the requester of the token, I think generally is done via a /token endpoint. I saw there was a very good Go Oauth implementation, but have yet to explore it. I would assume that too would be its own micro-service. My only dilemma there is I dont want every API request to send messages via bus to authenticate... so I suspect a middleware bit would do the http call via /token to find out if the API endpoint that is handling the request can be accessed by the token. Thus, each and every micro-service would have to "reuse" the same sort of code for auth, logging, rate limiting and more, right? I had suggested perhaps I build a utility "sdk" bit of code that I then import in each of the micro service API endpoints so as not to have to copy/paste. Someone mentioned if I did this that my services would be tightly coupled.. but I didnt think that would be the case, would it? I would be using my own internal sdk bit to reuse the same code for the common/shared bits like auth, logging, etc. It may be coupled to that sdk, but that wouldnt make the services tightly coupled to one another since the sdk binary bits would be in every service, right? 
“for free”?!? doesn’t sit well with personally. I’m all about giving back to go community. They helped me when I need to help for FREE! Ps English my 4th language I apologize in advance, I’m furious now
What’s something you learned making videos that you didn’t expect to learn?
`HttpRouter` and anything built on it does not handle that (/user/add and /user/:id). `gin`, `echo` do. I believe, `chi` does not. Anything that, does not could not be used for OpenAPI, for instance. At least, not directly.
I believe it was a change in an early version of Go, maybe 1.4 or so. 
Those who are posting question here, the AMA is happening in Hashnode not in in /r/golang. The link is in the title itself. :)
We used it for a while in one of my projects but ultimately decided that for very small datasets (configuration tables) it had no benefit. Really it's architecture seems ideal for large datasets IMO. Though, if I had a very large dataset, I would probably just choose a columnar database. So we switched to postgresql, which was very easy since cockroachdb is protocol compatible. TLDR; I love it but not for my use case.
I'm using OpenAPI v3.0 because it's simpler and has more functionality than v2.0. It sucks that tooling isn't as robust as the previous version since it's new-ish but I'm hoping that eventually the community will catch up and I will have saved myself the pain of upgrading later on.
Have experience. It's pretty great. Deploy it with kubernetes. It doesn't work with istio. (or didn't when I tried). Use pod affinity to schedule 1 pod per node. It's easy to scale up but harder to scale down. Upgrading is easy, just follow the upgrade path. migration libraries for postgres work really well on crdb. So do postgres client libraries / drivers. Performance is pretty good too. Use it! It's awesome. :)
Caddy Telemetry now uses it, and we also use it at [Relica](https://relicabackup.com). Cockroach's documentation is *excellent*. Follow their guides under "Deploy" and you'll be fine: [https://www.cockroachlabs.com/docs/stable/manual-deployment.html](https://www.cockroachlabs.com/docs/stable/manual-deployment.html)
Also it ended quite a while ago...
You can try this - [https://github.com/bxcodec/go-clean-arch](https://github.com/bxcodec/go-clean-arch)
They sponsored a Jepsen analysis of the beta, and I believe they have Jepsen runs as part of their integration testing. https://jepsen.io/analyses/cockroachdb-beta-20160829 I've been considering CockroachDB for a project of my own. First thing I always check with a distributed database is whether it's had Jepsen run against it.
just use a big switch statement for routing, it's faster than anything else
Never had heard of this DB.. been trying to figure out as I get ready to build some applications from ground up, deployed with Kubernetes to google, amazon, as well as in local minikube, what DB to use for well pretty much everything. More so, would it be easy enough to scale as needed up and down, migrate db changes over releases, handle transactions, and rollback... MariaDB was one that came up, as was using googles Spanner. I didnt realize Spanner is an offshoot of cockroach DB (or is it the other way around). Would it be feasible to use cockroach DB in my build out of micro-services instead of mysql, postgresql, mariadb, etc? Something I can spin up locally for dev, but also see it deployed (as a container/pod) in the cloud as part of my architecture? I mean I assume it can, but what would be any of the drawbacks/issues to be concerned with vs something like mysql, postgresql, etc? &amp;#x200B;
\&gt; I think that this isn't an ordinary sha512 of 1234 - it also contains salt. &amp;#x200B; It's not salted: &amp;#x200B; `$ echo -n 1234 | shasum -a 512 | awk '{print $1}' | tr '[:lower:]' '[:upper:]' | xxd -r -p | base64` `1ARVn2Auq2/WAqx2gNrL+q3RNjAzXpUfCXrzkA6d4Xa22yhRLy4AC50E+6UTPoscbo31nbOoq51gvkuXzJ6B2w==`
I would say cli is the most explicit. Env could be either, but I would think an application would want to have a unique prefix to avoid naming conflicts. With a unique prefix, it is definitively more explicit. Then config files, and finally defaults. 
Very good read for humans :)
Superb!
Is it actually? Does this handle concurrency as other routers would? Thanks for the tip!
well, yeah, a single switch statement is going to be faster than an entire engine ;) The concurrency is handled by net/http anyway - if your big switch statement is a simple net/http Handler then it's called as a goroutine, and as long as you don't modify any external state (which you shouldn't need to) then it's all good. I'll keep saying this: all a router needs to do is decide which handler to call for a given request. It's a really simple decision 99% of the time, based on the path of the request. Using a library to do this is waaay overkill. Removing an external dependency is a huge win anyway... dependencies are bad. 
How are you solving automatic HA with postgresql?
Agreed. This is the hierarchy my [start](https://github.com/christophberger/start) package uses. Flags override env vars, env vars (with app name as prefix) override config files, config files override defaults.
Never heard of this butt his database seams to be really interesting
try [https://github.com/OhBonsai/croner](https://github.com/OhBonsai/croner)
We used it for a few months but never put it fully into production. The CPU demands are higher than other databases but it was very nice from an administrative view. The team was also super helpful and quick to resolve the issues we found. I can go into more detail if necessary. We were also doing thousands of queries a second so might not be applicable.
I've only used Chi out of those two personally, so can only recommend that. I'm using it in many production applications.
You're code is pretty readable, but perhaps you'd be better served using [ioutil.ReadDir](https://golang.org/pkg/io/ioutil/#ReadDir) instead of exec'ing ls.
A few suggestions: The `n` function gets declared and potentially created each time through the loop, but will be the exact same function each time through. You should consider moving it to being a top level function that will only be instantiated once, and also giving it a name that indicates what it does to make it more readable You use `n(is)` twice, but it looks like n is an involved function. You should call n(is) once, store the result in a variable (a variable whose name indicates what this value represents), and then use that value in place of each of those instances It doesn’t look like you’re using the cobra command or the rags that it sends. You should rename these variables to `_` to help readers know to not look for how you’re using these variables Those are probably the biggest refactoring that would help clean things up some
Oh thanks, I see. It already returns `Size()` in bytes - so I would decrease my code by like more than 20 lines. The anonymous function assigned to `n` would not even be needed then. I will try it out
Why did you set a variable to a function? The function could just be declared normally? You could also give that new function a descriptive name. n is not particularly descriptive. &amp;#x200B; Overall I think the variable names are not descriptive and make the code more cryptic than it needs to be.
`n` is not declared in a loop though. Did I get your point correctly? Well I used `n(is)` pretty much once - where I use it with `fmt` is simply for checking if it returns what I expect. I read a lot about keeping Go code short and readable so that is why I refrained from lengthy names of variables, especially ones that have small scope - correct?
I actually declared `n` inside the `Run` because I was not getting the proper output. Maybe I missed something...not sure. I will try again. Do you think that anonymous function in this case just does not make sense?
Here are some tips. You can move the function to run inside cobra to reduce the code indentation. The n function too. That regexp is being compiled every time, tho it's the same. You can extract that out of the n function.
Finally we can use channels and goroutines to lose all our data!
What do you mean by "run inside cobra"?
That anonymous function you are passing to cobra.Command Run. 
Ah, not a loop, but in the middle of the function. Generally, though, when a function is declared in the middle of a block, there is an assumption that it depends on variables from within the block. This function would be better off declared as a private package level function Readable is a good thing, but descriptiveness is part of readability. The name `n` isn’t very descriptive, and, when reading it in later parts of the code, it’s easy to forget what it is, which means you have to scan through the code above to find it, which breaks the reading of the code you were just doing
Another one. Inside n, you can invert this if `if len(s) &lt;= 8` to early return 0 and write the rest of the code below and reduce the indentation more. Reducing the indentation always help to make it more readable 😊
Mongo is utter garbage. 
Sorry, still not getting it...Can you please edit the code so I can see what you mean?
&amp;cobra.Command{ Run: run, } func run(cmd *cobra.Command, args []string) { // ... }
&gt; unless all your microservice does is routing then it won't be the bottleneck. Even *if* all your microservice does is routing, it won't be the bottleneck. Routing with `net/http` is fast enough that it will never ever matter (yes, that includes running at Google-scale).
I'm wondering why is everyone using an external library for this. I'm a go beginner and an attempt to find some good examples or posts about creating web apps with standard library only are really hard to find. Also, no one says really why they choose to make this big step and use some custom library. What is so difficult with std that you would risk a part of your program is abandoned, passed to some third party that either breaks it, doesn't care or distributes malware with it. Most of the time the advantages they name are like "it's compatible with the standard library". Yeah, that is not really an advantage over THE standard library though, is it. So what is so great about all those routers then? Can I not just use std lib and achieve the same thing?
It's certainly not the first
It's the first *official* driver, but yeah, definitely not *the* first
It's the first beta.
You may also want to try [OpenAPI Generator](https://github.com/OpenAPITools/openapi-generator/) (free, open-source) as well to generate Go API client and server stubs (e.g. [Go Gin framework](https://gin-gonic.github.io/gin/)) and it supports both OpenAPI spec v2 and v3. &amp;#x200B; Disclosure: I'm the top contributor to OpenAPI Generator, which is a community-driven fork of Swagger Codegen. Please refer to the [Q&amp;A](https://github.com/OpenAPITools/openapi-generator/blob/master/docs/qna.md) for more information about the fork.
What about github.com/go-mgo/mgo?
What do you mean?
What is it about?
It's a go mongo driver (released before this one). One that's been sitting at version 2 for a while now.
Okay, I guess.
I'd love to hear from someone who has migrated a relatively large project from mgo to the the official driver. Things like performance impact, memory consumption, open fds, etc. I'm preparing to do the switch on the projects I maintain but I'm not sure if the time is right yet.
Because on certain architectures, like amd64, it is implemented in assembly: https://github.com/golang/go/blob/master/src/internal/bytealg/count_amd64.s Vs a backup generic implementation : https://github.com/golang/go/blob/master/src/internal/bytealg/count_native.go There is a fast path for when you are counting a single byte: https://github.com/golang/go/blob/master/src/bytes/bytes.go#L72
 For one, it’s implemented in highly optimized assembly: https://github.com/golang/go/blob/master/src/internal/bytealg/count_amd64.s
I think, given the beta status of the official driver, you're probably best sticking with mgo in production for now. As of right now, there are 159 open issues in their JIRA board. For anyone interested: https://jira.mongodb.org/projects/GODRIVER 
thanks, i got it 
thanks, is there any way to optimize the origin loop for some boost
the old "mongodb is only good for data you can affort to loose" adage
Could you explain that? 
If you're going to roll your own DSL, there will probably be lots of boilerplate generated code... Take a look at my Jennifer project to make this simple: https://github.com/dave/jennifer ... also you might want to take a look at Jennifer itself as an example of a DSL. The https://github.com/dave/jennifer/tree/master/genjen package does all the code generation to create the Jennifer DSL (using Jennifer for the code generation naturally). Meta huh?
Following a couple links after the github issue you provided led me to this: https://github.com/etcd-io/etcd/issues/6829 &gt; (Quorum style reads) It's enabled by default. To get stale reads use clientv3.WithSerializable()
[This](http://cryto.net/~joepie91/blog/2015/07/19/why-you-should-never-ever-ever-use-mongodb/) and [this](https://i.redd.it/06k0c1v0yroy.jpg) are two of the most famous "Mongo loses data" stuff out there. That said, there have been quite significant [improvements](https://www.mongodb.com/jepsen).
you might look into whether go ever does array bounds check elision, and if so, see if your code is arranged to make sure it does it. otherwise, array bounds checks are going to make your for loop a bit slower. &amp;#x200B; you could unroll your loop a bit, if the compiler isn't already. &amp;#x200B; you could use go assembly to implement this with SIMD instructions (likely this is what bytes.count does, uses SSE2, that would explain most of the 5x increase) &amp;#x200B;
[removed]
Thanks for sharing. Honest question: how do avoid circular dependencies say `model/author` has a field `model/article`?
[Pions](https://github.com/pions) is a webRTC project, any help is very welcome there. It is not too big and there are small components that are easy to implement and maintain.
https://github.com/dejavuzhou/ginbro
With a managed service of postgresql - but in that with a fully replicated hot standby peer. 
haha, just made it up. But I should be careful because otherwise Agile adopts it as a new methodology...
FP in Go helps me reduce complexity in several parts of my codebase. E.g, routing system for HTTP server.
not going to bother sorry, it's something they fixed since (just tell mongodb about your data requirements), it's just an in-joke even if a bit dated 
We set up cockroach to run as our backend for [Drone.io](https://Drone.io) CI/CD tool. Cockroach was very easy to set up (deployed in Kube), and very slick, but we found a couple of things that Drone was trying to do in the DB weren't supported - something to do with Drone running a (rather unexpected, if I'm honest) correlated subquery, which isn't/wasn't supported. [https://forum.cockroachlabs.com/t/no-data-source-matches-prefix-error/1835](https://forum.cockroachlabs.com/t/no-data-source-matches-prefix-error/1835) &amp;#x200B; I really enjoyed using the DB, and the GUI that sits on top of it is \*excellent\* - I've wanted something like that in postGres for ages (without having to install third party stuff). Would use it again, with just that word of caution to test it thoroughly. Persistance was well handled in kube, and their helm chart was well formed and laid out. Really good project. 
This is exactly how I've handled my rest APIs as a learning developer. I'm curious about your comment about modifying an external state. Are you saying I shouldn't be writing to a mongodb in my handlers?
Yes, the `net/url` package of stdlib is what you'll want to explore. https://godoc.org/net/url 
hmm gorilla mux
Stdlib has tools for parsing URL, path composition and encoding. Wrap it in your own type if you need something like that. 
This blog post appears to explain it well. http://polyglot.ninja/golang-making-http-requests/
I love how Go is still getting momentum, but things like js.Global().Get("document"). Call("getElementById", "myBtn"). Call("addEventListener", "click", cb) Makes me feel weird and a little uncomfortable. Maybe with Go 2 the language can advance to ways more friendly and generic.
Typically, you'll create commands under the path `test-go-project/cmd/commandname/`, where you'll create a new `main` package. Running `go build` or `go install` from that path will build an executable with the name `commandname` (or whatever you've called that directory).
You can for sure. But part of the open source option is you have the source. If whoever is maintaining it stops you can continue yourself if need be. You are not stuck. The benefit is you dont have to reinvent the wheel like handling different paths with params. Or some other thing they do. You can go look at chi and ecco... there isnt a lot of code there. They have developed building and maintaining it that are far above my knowledge and I want to get started on my business more so than rewrite what is already written. 
Can you be more specific about the boost you are looking for? Details about the question and the input it is running over matter a lot in this sort of question. There are also algorithms based around some sort of pre-computation that may take some time, but allow you to answer subsequent questions quickly, so you should also specify whether you're going to run multiple queries over the same byte string.
Specifically, it uses SSE or AVX2 to test 16 or 32 bytes of the input string per loop iteration, instead of 1.
That doesn't have anything that answers my question. I've read it, hence my question being about the URL type. My question is why is the URL type not used for URLs in net/http and other stdlib packages. When using gorrila/websocket I happen to notice the deprecated `Conn.NewClient()` method *did* use url.URL for the server address but the `Dialer.Dial()` method which replaced it uses strings. net/http has a couple proxy related methods that work with URL types. If every Go installation has access to a URL type, why are strings almost universally used for functions which accept URLs? There's got to be some rational design convention in place here since gorilla changed their library to accept strings instead of URLs.
I wish we could get a `fmt.Stringer` implementation on the default `string` type. There's a _lot_ of places I'd like to take a "`fmt.Stringer` or a string", but I can't. (Maybe the new generics support will help with that....)
Need something like what? What are you talking about?
&gt; a url type that's super handy for constructing API paths instead of concatenating strings constantly 
https://www.reddit.com/r/golang/comments/a3rtta/learning_go_and_theres_one_thing_bugging_me_that/eballxg/
I've asked about this on Reddit few months ago. WebAssembly doesn't support the DOM modification currently, so basically what you can do is calling the JavaScript API to interact with the DOM. 
i think it depends on the struct as a struct can contain pointers too. Imo all non-pointer parameters will get copied but there might be a clever algorithm doing the cleanup for you
[removed]
Ah, that's your problem. My suspicion is they could accept URL type, but then they would impose a requirement, forcing you to convert string to that type, just so Dial() method could convert it back to string. Instead you have a choice: if you have a string, you can pass it, but if you choose to use url.URL, all is needed is a call to url.URL.String(). But don't quote me on that. Go is more low level than Python or Ruby and you have to do some things yourself.
I don't understand what your code measures. r will be 4 in both scenarios right ? I don't see how this measures by copy vs by value.
&gt; So go is pass-by-value which means when you call a function it should copy the passed values and pass those to the function being called Yes. &gt; This should mean that passing (non pointer) structs that contain a lot of data (or non pointer receivers for that matter) would be [relatively] costly Yes. For _large_ structs, like really large! Note that slices are very small (just a few words) and so are maps. It is _very_ _unlikely_ that you will be able to speed up you application by going "pointers only". &gt; I actually created a tiny benchmark to compare the difference Your sample struct is super small, just 10 words from continuous memory. Modern CPUs are very good at a lot of things and performance is often degraded by non-obvious stuff. Direct work like copying a few words (in your case literally just two hand full) is not important in most of the cases. Hidden, non obvious stuff like cache misses or context switches degrade the performance much more. There is nothing to worry about here. Unless your struct contains large array (array, not slice!): Move on.
Well, there's your explanation. If nothing potentially takes the address of something, then it doesn't have to go on the heap, and it doesn't count as an "allocation" (we mostly count allocs because we're interested in how much work the GC has to do; stuff on the stack doesn't need to be managed by the GC). So yeah, there's a copy, and it has a cost (and your benchmark does show that, on my system: 17.6 ns/op vs. 7.9 ns/op), but it's not a very big one
Just a thought. Most of the stuff on the internet is broken a bit. `net/url` deals with malformed (i.e. non RFC conforming) but this is ugly. Now suppose you need to make a request to some HTTP endpoint with a non-RFC compliant URL (wrong escaping, order of parameters matters, whatnot). Forcing net/url to produce such an URL is possible, but awkward. But it is simple with a string. And if you have a proper URL, encoded as a net/url/URL: Calling String on it is trivial. 
Oops.
&gt; So go is pass-by-value which means when you call a function it should copy the passed values and pass those to the function being called if I understand correctly. Yes. A bit more correct is that the caller copies the data which represents the arguments of the function to call, and then calls the function. As to benchmarks, the reason you don't see allocs is simple: the parameters to call a function (in the current reference Go implementation) are allocated on the stack, and these allocations do not count—simply because when the called function returns, the stack "backs out" by exactly the amount it was expanded to call the function. Now consider that in the "copying" case you're merely calling the same function lots of times in a row _but from the same call frame_ — the one running the loop. So you basically repeatedly push the data to the stack, call the function, move the the stack's head pointer back again; rinse, repeat. The final piece of this "puzzle" is that Go's goroutine have growable stacks—they are born with the stack of 2k in size (IIRC, 4k on Windows) and then the stack grows (by being reallocated) when needed, but—I _think—_never shrinks back. So even if the first call of your function in the first round of the benchmark run would grow the stack, the rest of the calls would merely reuse the available stack space. 
Well someone would have to sit down and write bindings for the Dom in golang, its a terribly boring job 
Maybe this could be generated somehow? Not sure
We've got a couple open issues on archiver, which is a pretty small and simple project: [https://github.com/mholt/archiver](https://github.com/mholt/archiver)
The benchmark in the answer is more than three years old. Run it again before drawing any conclusions.
Yeah, I've been using dockerhub/golang/1.11-stretch and it works fine.
It uses the POPCOUNT instruction on amd64 processors. In my benchmarking, github.com/tmthrgd/go-popcount is twice as fast, possibly because it has no fallback for processors that don’t implement POPCOUNT
Wasm will support DOM mutations natively Soon™. I'm betting everyone is just waiting for that.
Wasm will support DOM mutations natively Soon™. I'm betting everyone is just waiting for that.
On my development server it seems like type assertion is actually a bit faster now in more modern Go versions. ``` $ go version go version go1.11.2 linux/amd64 $ go test -bench=. goos: linux goarch: amd64 BenchmarkIntmethod-24 1000000000 2.44 ns/op BenchmarkInterface-24 1000000000 2.27 ns/op BenchmarkTypeSwitch-24 1000000000 2.14 ns/op BenchmarkTypeAssertion-24 1000000000 2.13 ns/op PASS ok \_/home/bbennett/bench 9.918s ```
It absolutely can. It's been [done elsewhere](https://rustwasm.github.io/wasm-bindgen/api/web_sys/). You just have to read and gen code from WebIDL [like they did](https://rustwasm.github.io/2018/09/26/announcing-web-sys.html).
(where natively means no external dependencies outside your go application)
Thanks all for the responses. It seems like adoption is still small. I am looking at this database to store large amount of data, closer to the several hundreds of terabytes. Need the database that is scalable, easy to zero effort to maintain that's why I am looking at CockroachDB.
It's unfortunate that the entire runtime is still required, which I feel makes Go a poor choice for WASM compile targets, at least for websites on the internet. I really hope this can be improved upon as I really like Go and would be delighted if I could do away with languages for some basic web apps. 
Thanks for the links and the detailed explanation! &amp;#x200B; &amp;#x200B;
Ye, I realized that slices (and thus also strings) and maps don't actually cost much to copy and that most of this is hypothetical or for when the struct actually contains A LOT of properties or arrays, but I wanted to know for sure. &amp;#x200B; thx for the answer!
not trying to optimize anything here, I was expecting the assignment of s to cause an alloc but as others explained here it's not being reporting in the benchmark because it only reports allocs to heap, not stack)
Maybe I dont See how this would be ressolved but Go still needs to be statically typed right? So there would still be a need for wrapper? 
So it's like running Python in pure go 🤔
Neat! Thanks for the info.
This is a really good point I haven't thought of. Just going to chalk it up to this I guess unless there's some official word floating around.
&gt;Since Go is a garbage collected language, the entire runtime is shipped inside the wasm binary. Hence it is common for binaries to have large sizes in the order of MBs. This is still a sore point compared to other languages like C/Rust; because shipping MBs of data to the browser is not ideal. However, if the wasm spec supports GC by itself, then this can change. How would this even work?? Is that much of the runtime just GC? How do you take out just the GC from the runtime and ship "only the essentials" in that case?
&gt; Modern CPUs are very good at a lot of things Sounds like OP skipped his computer architecture class! The cost of a copy depends on the location of said copy. Is it in L1 cache? L2? System RAM? Paged in / paged out? Stored on disk? Are the bytes consecutive or scattered about? Cost is much, much different for each operation. As in, fractions of a nanosecond (writing through the L1 cache) to tens of milliseconds (pulling a page up from a spinning disk). That's a difference of approx 1,000,000x. So, OP, do you know *where* your data is being copied? If not, of course you'll be surprised by the results. You can rewrite your benchmark to force the *where* if you're a bit more clever... 
Yes, even pointers ate passed by value.
I think the bindings will look terrible for Go since it can't handle generics :\\ 
Do you have a link to this thing you are referring to? Lua thingy?
Those predefined layouts are totally useless for me and the numbers are random. Something like 2001-02-03 04:05:06 would have been easier to remember. Otherwise it's a great package.
Yeah, you'd still need one, but the implementations would differ drastically, I imagine. I don't think Go will be attractive for wasm development at all until wasm supports linking up with the js vm's GC. Running a second vm inside js (along with the resultant wasm executable bloat) isn't so hot. I know that's in the works, but it might take a couple years.
This is great -- I love the idea of smart conversions / deep reflection through Go types. Though note that Starlark is a pretty restricted subset of Python (restricted for good reason given its goals). From the [Starlark Language](https://docs.bazel.build/versions/master/skylark/language.html) page, "Although it is inspired from Python, it is not a general-purpose language and most Python features are not included." As you can see [here](https://docs.bazel.build/versions/master/skylark/language.html#differences-with-python), it doesn't support `class`, `import`, float, set, ...
[https://github.com/Shopify/go-lua](https://github.com/Shopify/go-lua) [https://github.com/Azure/golua](https://github.com/Azure/golua) &amp;#x200B; and a sample use case [https://engineering.shopify.com/blogs/engineering/announcing-go-lua](https://engineering.shopify.com/blogs/engineering/announcing-go-lua) &amp;#x200B;
Am I wrong in passing by reference everything except ints? I pass strings, structs and arrays all by reference (unless I'm feeling lazy) assuming it'd help with speed.
&gt; Hidden, non obvious stuff like cache misses or context switches degrade the performance much more. 
&gt; Is that much of the runtime just GC? How do you take out just the GC from the runtime and ship "only the essentials" in that case? Good point actually. That point was all in theory. Practically, I think it is going to be very hard, if not impossible at this stage to strip out the GC and ship only the essentials. Wasm doesn't seem to be implementing GC any time soon anyways. So we will just have to wait and see.
Yes, this is wrong.
Surprised it took them so long, considering they use quite a bit of Go at golang and the previous unofficial Go driver which went without a maintainer .. 2 years ago?
Note that the link you have is to Bazel's implementation of Starlark... the go version's implementation is here: [https://github.com/google/starlark-go/blob/master/doc/spec.md](https://github.com/google/starlark-go/blob/master/doc/spec.md) \- it does have floats and sets, for example, and its arithmetic has infinite precision. It still doesn't have classes, though. Starlight is not something you'd use to implement your entire server's logic in. That's not its purpose (you could just write python in that case). Its purpose is to give users of your product the ability to extend its feature set. It can also be a way to modularize parts of your code, like you could write a game's monster behavior scripts in starlark. Starlark-go and starlight let you `load()` other scripts, so you can have reusable functions etc. Plus with starlight, you can easily give your scripts access to powerful Go functions and types. 
Yup.
why?
Do you have a point to make, or just looking for an excuse to post a comment?
A compile time check is faster than a runtime one.
Cache efficiency, for one
The person you were responding to had already addressed everything you laid out in your comment by stating the portion that I quoted. The piece you quoted, combined with your subsequent comment, makes it seem like you're chiding the parent commenter for not knowing about these things. If that was not your intention, perhaps you should attempt to reword your comment. If this doesn't clarify things for you, perhaps /explainlikeimfive can help you out further. 
Their point is that your point is based on a misreading of their comment; thus your comment adds nothing to the discussion except salt
Barring extraordinarily exceptional circumstances, it does not help with speed.
&gt; already addressed everything I didn't read a thing about which cache OP's data is bouncing through. Care to quote that bit for me?
Treat it like a learning experience and see if you can figure it out yourself. Here's a final hint: &gt;The person you were responding to 
Check your ego. You've got everything wrong so far.
Good one! 
* What projects do you use? * What kind of projects do you like? CLI? HTTP? Distributed systems? * What operating system? * What is your level of programing ability? go ability? Really these kind of posts are understandable, and common, but you've made so little effort it is hard to know how to help you. 
It takes time to dereference pointers. A slice is already just a couple integers and a pointer so it's probably faster to copy it than to dereference a second pointer.
The title is misleading. It's not Python per se.
Ah. Awesome. Like I said, I am a bit out of date on etcd stuff, but this makes me feel a bit better about consistency in all the K8S clusters I depend on!
To elaborate, arrays and strings are only size of 3 ints, the cache miss plus potential heap allocation are far more costly than just copying 3 words. Structs are more of a mixed bag but the vast majority of structs can likely be passed by value. Microoptimizations that complicate the code, like passing by pointer, should *always* be validated by benchmarks for the actual code in hand and not by gut feelings. Go's built in bencher makes this really easy to drop into your code. And of course all of this is likely totally irrelevant in many popular go domains (web servers) which are totally io bound and copying bits vs passing by pointer won't even rise to a single percent of your execution profile.
What would be considered a large struct?
well the rfc layouts are definitely handy.. and if you think of the crappy javascript / java date standard library the go time package is a godsend. 
That's true that it's not full python, but I didn't want to assume people knew what starlark was (especially since it was just renamed from skylark). 
Ooh, this looks like exactly what I want, right down to using TOML and putting the config files in the proper XDG location of `~/.config/appname`
[removed]
Sorry, poor wording. I meant shared state between the handlers. Writing to Mongodb is fine, but (for instance) writing to a global map without a mutex will bomb. One of the many reasons to avoid globals.
the thing to grok is stack and heap. function params passed by value are put on the stack by default, unless they're too big. Stuff on the stack is fast, until you start cracking stack boundaries. So at the moment, anything approaching 2Kb can be considered "big" (I'd actually draw the line around 1Kb because packing). Anything with a pointer is put on the heap. Heap allocation is slower than stack allocation, generally. So the standard approach is to only use pointers where needed, basically for large data objects. For smaller objects, the object may well have been created on the stack, and turning it into a pointer to save copying it to a new function will actually involve a lot of work copying it to the heap and creating a new pointer. 
Oh yes, I've been through that :/ did end up making it work but I got a lot of optimizing to do because I am actually double locking atm.
I’m getting “File not in classpath roots: /#!topic/golang-dev/Yk09_1ktph8 Error 404” Any ideas? 
From the post at golang-dev: &gt; Hello gophers, We plan to issue Go 1.11.3 and Go 1.10.6 on Wednesday, December 12 at approximately 8 pm UTC (12 pm PST, 3 pm EST). These are minor releases to fix a security issue. Following our policy at https://golang.org/security, this is the pre-announcement of those releases. Thanks, Dmitri on behalf of the Go team
I got that error in Apollo, but it worked in the browser.
Thanks for the shoutout /u/truefalse01 &amp;#x200B; /u/jaswdr we would love to have you! If you join the Slack channel feel free to mention me (Sean-Der on there also) and I would love to help you land something. We also have lots of cool project ideas if you would rather build a self contained project then contribute to the library.
As a general rule of thumb: If you code something in a way that _feels_ like it should be faster, it very rarely actually will be. Compilers are (A) ridiculously smart, and (B) designed to optimize the "lowest common denominator" of code. Trying to optimize code on your own, generally speaking, is synonymous with "trying to outsmart the compiler optimizer", which rarely works if you go in blind. 
&gt; Will adding generics to Go have any performance benefit? For the most part, no. There is no reason why generics would add any performance improvement in the general case. The hypothesis is, that the compiler could emit specialized implementations of generic functions for some types - but that hypothesis overlooks the fact that the compiler could do the same thing today with interfaces but doesn't. However, the most likely implementation of generics from what we can say right now, would use de-facto interfaces for generic functions (so that part wouldn't speed up), but use instantiations for generic types, which *would* speed up some things. For example, a generic list implementation would probably be slightly faster than [container/list](https://godoc.org/container/list), because it can save a pointer indirection and omit type-assertions. Personally, I kind of doubt that effect will matter a lot in practice though. We'll see.
No. Many libs are at GitHub, and even if you see some links like gopkg.in, they are still mainly just redirection to GitHub. Probably there are also some at Bitbucket, but I don't know such libs. AFAIK, theoretically you can use any version control system to use it with go get and go modules: git, subversion, mercury.
Maybe you want https://go-search.org?
I want whatever is considered standard among Go developers
Why would an assembly language standard support features like DOM modification natively?
[removed]
Because Web Assembly is not machine assembly, it's a sort of JS VM bytecode inside a separate sort-of-sandbox that is bolted on to the existing VM. There is a membrane between the JS-proper-VM and the wasm area. Holes need to be poked in it for direct DOM manipulation via WASM intructions, instead of trampolining off the JS-proper-VM and executing the DOM mutations via actual JS calls.
Replace the Go-provided bits of the runtime with the wasm-provided bits at compile time. If you chuck the GC and preemptive M-N thread model and replace them, respectively, with the JS gc and async/await functionality, then I assume there's not much left to emit besides the actual code you wrote. I guess I'm also assuming that the compiler could dead-code-eliminate any sort of language features that a particular wasm binary would not need. No need to process POSIX signals in a wasm bin, I'd guess. Not using channels? Don't compile them in. Stuff like that.
http://godoc.org/ is pretty standard. What you have to understand, is that the Go ecosystem is intentionally decentralized. In particular, literally anyone can put any package of any developer (as long as it's go-gettable) on godoc.org, just by virtue of looking it up. As a result, there are ~800K packages on there (though this also includes forks). There's also a [minimal REST API](https://github.com/golang/gddo/wiki/API).
You would also need reflect info and Unicode tables I think.
Doesn't answer the question, but here is a project who's architect and approach I find interesting, and which is polyglot: https://github.com/jruizgit/rules The language implementations use the underlying C library, which may not help you, but the devision been alpha and beta nodes and the use of Lua on redis is pretty cool for scalability. I'm not sure what it would take to implement the rules in Go.
There isn't a official registry of Packages, but I find this helpful: https://golanglibs.com/
[removed]
[removed]
[Start here](https://plus.google.com/+JeanBaptisteQueru/posts/dfydM2Cnepe). Then resign yourself to reading more broadly if you truly want the answer. If you decide there is a level of abstraction in there you can accept, then start there. That might be X86 assembly, or [syscalls](http://man7.org/linux/man-pages/man2/syscalls.2.html) and your kernel.
[removed]
1. Nobody on a unix will agree with you on calling that "screen", you're about three decades late. https://en.wikipedia.org/wiki/GNU_Screen 2. The way it's written, the name of the command is `cmd`.
Thanks!
Well ya. Ideally a full computer science education would be nice. I don't really feel like spending thousands of dollars and 4 years on this question though. I was thinking more along the lines of maybe a few hundred dollars max (for books maybe?) and a few months. Thanks for sharing the github repo. Ya, that's exactly what I want to do, but for a basic go program.
often? by whom? All GCs involve some STW, but Go's is highly concurrent, so the STW pauses are tiny. Go's GC is actually latency-optimized, with most pauses being well below a millisecond. C# is heavily used for game development and GC pauses are far bigger of an issue there since C#'s GC is throughput-optimized, prioritizing the amount of garbage that can be collected at the expense of higher latency pauses. I don't know who is even stating this, so I can't say if they're overstating it.
&gt; Is this just how it is or is the issue overstated? The issue of pauses definitely is. There are other issues with the GC and a heavy runtime, that IMO weigh a lot heavier. For example, the GC makes it harder to control peak memory usage. It also (because it needs precise information about what is and isn't a pointer) making some memory-tricks impossible and it makes it a bit harder to implement VMs and the like. Greenthreading makes process related things (basically anything going on between fork and exec) a lot more complicated. But honestly, all these problems only affect you in very specific and rare circumstances and can be worked around. Pauses, however, aren't really an issue in Go.
Select scales o(n), but your time is going to be dominated by the channels themselves. So in practice, no.
This sounds like an education problem. Select is the right tool for the job.
I don't know and I'm interested in this too, but have you tried skimming Gitea's code? 
how do I submit my package to it?
Do they typically include the security vulnerability details in the release notes?
[removed]
Put everything in main.go ^^^^^^/^^^^^^s
"often" might be unfair, but it is a thing I trip over every now and again. Here are some examples: [This](https://www.reddit.com/r/golang/comments/7fnaw2/game_development_in_go_book/dqec3fr/) reddit post [Comments](https://www.quora.com/Is-Go-a-systems-programming-language) here. [This](https://blog.plan99.net/modern-garbage-collection-911ef4f8bd8e) blog post Truthfully, these probably aren't the best examples. I just usually trip over it when poking around the internet. There always seems to be someone in the comments sniping at Go for either its lack of generics or GC.
A common standard for games today, at least competitive shooters, is 144fps, to match up with 144hz monitors. That means you have 7 milliseconds each from to get everything drawn. That is a lot of data the cpu has to get to the cpu, input has to be collected from controllers, networking work has to happen, physics and AI are all happening at the same time, and on and on and on. So most languages that have a GC can have pause times in the 1-1000ms range, and this can obviously be unworkable, and people who make games using languages like C# either put up with frame hitches, or do a lot of work to avoid putting any pressure on the GC in a per frame basis. Go's GC tends to have sub millisecond latency, so that isn't going to be a problem very often. But Go also has a higher than normal overhead when calling into C libraries, which is a problem with games. When a language has a GC there are often some indirect things that can cause slowdown, tricks you could do with memory in a non GC language that you can't with a GC language, or the tendency of GC languages to have other safety features like array bounds checks that also cause some slowdown. But *in principle* there is no reason a GC can't work even with AAA 3D shooters. However none currently are suited for that kind of game. But one should remember the best selling game of all time was done in Java. Most games can run fine today on suboptimal lang choices. 
you dont. just push your code to a public git hosting repo like github, gitlab or bitbucket and godoc will find it.
Most of the go ecosystem is built around github and similar platforms. To 'submit' a package to godoc.org you visit `godoc.org/github.com/myuser/mypackage`, and it automatically gets queued / uploaded. It will only generate documentation though, your package still lives on github.
[removed]
Is it web scale?
&gt; godoc will find it. how?
I'm not using Gin, but I personally like the structure of this project... [https://github.com/vsouza/go-gin-boilerplate](https://github.com/vsouza/go-gin-boilerplate). Not sure if it follows best practices, but it's been serving me well so far.
Yes when it's released. It'll also have a CVE number.
The problem is that a "*complete* top-down step by step understanding" of your question is a *huge* undertaking that does take literal years of study and work. That doesn't make it impossible at all (for a reasonable definition of "complete"), but you should know it's not a simple thing. My university's compilers course was only something you could practically take as a senior, and it had a reputation as a very hard course with a high fail/drop rate; even taking it (and loving it!) there was a lot of material uncovered with references to grad-level courses and research papers to read for more info. The way I would describe it is that the table stakes for really understanding a lot of CS stuff is an imposing order -- you need to know a lot just to learn more about certain fields sometimes. I say all this not to discourage you but to encourage you to think about following through on what could be a calling. It is only a tiny tiny fraction of people in the world who would ever want to know what you're asking here, and an even smaller fraction that would actually do *anything* -- even ask Reddit -- to pursue it. It'll also be very very very hard and so if you just work at this for a few months I would hate if you felt like you weren't getting the results you wanted and gave up. That said, OpenCourseWare helps, meeting people who work with compilers/programming languages can help, and even just reading the Go documentation can be a good starting point -- try to dig up *why* particular things (like string literal declarations, maybe) work the way they do. (A fun one that I understand but still annoys me: Why can't you declare a const string that's the interpolation of two const strings? e.g. `const foobar := fmt.Sprintf("foo%s", "bar")` )
Which CS concepts do you think I should focus on? I'm thinking right now: operating systems, compilers/languages, computer architecture. Surely there has to be some areas of computer science that aren't so relevant (like network stuff, and databases for example).
Ya, you're right of course. I guess I'd be satisfied with even just a sketchy understanding of the story. And maybe I could start a github project along the lines of: [https://github.com/alex/what-happens-when](https://github.com/alex/what-happens-when) where other people could contribute to the goal of telling a more complete story than I could reasonably expect to do on my own.
As an alternative to the apis used by the code in this post, there is still a xmpp gateway to hangouts chat. I used [this library](https://github.com/mattn/go-xmpp) to write a hangouts bot. 
I break circular dependencies by designing them out, or if I must, interfaces. Go's duck typing makes it simple.
In case others haven't made it clear, even pointers are copied by value. That means the receiver gets a copy of the pointer address, but not a copy of the value pointed to
Everyday we stray further from god.
Go doesn't have a central registry. You reference/import packages based off of URL (so e.g. `import "github.com/foo/bar"`. The go toolchain pulls the package directly from this URL and doesn't ask a central server where the package "bar" can be found.
If it doesn’t support class there is no resin to use it over lua, and I bet lua embedded will be faster.
I think the awesome-go list on github has a large collection of nice stuff. It's not all libraries, but to me it always kind of feels like the standard third party library. 
Hmm, maybe I should have called it "cursor", idk.
TIL about Sscanf, thank you.
Using it as: `screen.Clear()` is good GoStyle.
like `gpython`: https://github.com/go-python/gpython :)
Use 1.11, they removed gopath in this version
Yes, c++ dependencies are really easy and simple to include. 
go version go1.11.1 darwin/amd64
If I know what my dependencies are, I can compile in any folder I please. I don't get fucked around by GOPATH. 
This doesn't seem like an experience report from a recent version of Go. I have been using Go since its release candidate era and I have to say that with the module support in 1.11, the whole GOPATH argument can't possibly be any issue anymore. Technically it already got better from 1.7 when GOPATH gained a default location/value. I can't say I can relate to this problem, as someone that codes in Python, Go, and C++ on a regular basis. 
Go puts convention over configuration. It’s one thing I like about it. I understand other projects easily, because they’re doing it the same way. This negates any hassle to first get the build set up. If you don’t like it, that’s fine. Stick to other languages then. Don’t blame Go for its opinionated way of doing things. 
Google "golang modules 1.11".
I don't think so? Gpython is a python implementation that happens to be in go. .I don't believe it lets you mix go and python... But I might be wrong
Same, I was using a regexp and \`FindAllSubmatches\` for pretty much every input in the advent of code, which took considerably longer
hi there, the thing is that i receive a response that cannot be printed into a readable string ( which it should be), most of the tutorial online they make simple requests that could be printed into string not like mine (which is supposed to be a json), which, in this case also make the byte i receive not able to be parsed into Go data struct ( I use the check function of json lib to make sure the data is json but it said it is not). Does it have to do with anything about x-www-form-*urlencoded* ? this is the thing in the header the post request i tried to mimic.
 ╚5�A �0 ����كgo�!���C�a+��H����ݦ�K�%y�A��@╗u���\]�&amp;╝�,�:�y��Y���ou0(��-u������4�/O�═����� ��5n a͘�/�║�q����Ȯȱ�� x����(�3tY"|╔-)��߇g�o�?\_ ��� &amp;#x200B; this is what my response look like and this is how it should look like &amp;#x200B; {"data": \[\], "header": \["AlphaClientId", "Code", "IsInOS", "Hidden", "IsTeamAlpha", "Favorite", "AlphaName", "CodeType", "DateCreated", "Color", "Region", "Universe", "Sharpe", "Returns", "TurnOver", "Margin"\], "numRows": 0}
If you think it's the worst, it's probably because you haven't try many others and went though \_ dependencies hell \_ complex setup/tooling needed \_ complex cross compilation &amp;#x200B; Setting ONE env variable (in most of the cases) to have a one command build process can't be describe as an horrible experience. (and settings 2 mores to be able to get cross compilation to other architecture is simply awesome) And now with 1.11 it's getting even simpler... I regret you had such a bad feeling, but feel free to describe your problems, and I'm sure we could help you and maybe change your opinion...
Did exactly the same, I like my regexes. 
A decent compiler-course would get you writing an interpreter - if that were to evaluate that's a good start. If it were to emit assembly-language even better. You'd learn about low-level syscalls/traps/interrupts depending on the environment. 
https://github.com/spf13/viper
A lot more people are familiar with Python than are familiar with Lua, but use whatever you like. 
I consider myself a good programmer ... I never ended up finishing the project ... abandoned Haskell. May it be the case that you could consider yourself a good Go programmer but not terribly productive Haskell programmer? It seems to be quite a jump to go from your personal experience to general statements about "advanced features". And, btw, generics as they have been proposed for Golang are NOWHERE as advanced as Haskell type system which makes your argument event more bogus and biased.
Totally. I'm too afraid of a too complex type system which make our lives miserable. Even though I appreciate my experience programming in Haskell, Golang is what it is because it's super simple. &amp;#x200B; But type system, if designed correctly, can also be very, very simple and intuitive. I've already given an example of Elm which has an excellent, simplistic type system which is especially telling considering it's written in Haskell and some 30% of its users are Haskell developers constantly but ineffectually nagging Elm's creator to add more advanced features (e.g. typeclasses).
&gt; I consider myself a good programmer ... I never ended up finishing the project ... abandoned Haskell. May it be the case that you could consider yourself a good Go programmer but not terribly productive Haskell programmer? It seems to be quite a jump to go from your personal experience to general statements about "advanced features". You got me! I certainly wasn't very good back then and a huge part in my failure to complete the project was my own lack of experience back then. The point I am trying to make is that in a situation where you don't exactly know what kind of abstraction and design is suitable for the task at hand, the presence of complicated language features that cover rare use cases makes you consider them for your problem and thus lead you to a needlessly complicated design. To make an analogy, that's a bit like trying to solve a jigsaw puzzle where someone helpfully threw in a bunch of extra puzzle pieces that do seem to fit here and there but don't really help you complete the whole puzzle. Go is a language meant for this kind of programmer. It's a language that tries very hard to guide you towards a certain style of programming that has proven itself worthy. Taking extra features onto the language that do not support this style will only distract programmers, taking their effort and time away from building idiomatic code towards building needlessly complicated solutions that use generics where no generics would have done the trick in a much more straightforward manner. I do think I am a good programmer these days and looking back to when I tried to write this project, I am pretty sure that not having the ability to write complicated monad transformers would have led me to consider a simpler design in the first place. This sort of stuff is a huge part of the reason why I like to program in C so much: there is often only one intuitive way to implement a certain design and there are very few corners you can get hung up on. This allows me to focus my energy on solving my problems instead of picking features to use.
At first glance I thought this was a post for a charity that converts node code to go. 😂
At first glance I thought this was a post for a charity that converts node code to go. 😂
Viper is great. I've switched to toml for all my project configs and it's very human friendly. +1 for toml
Yes, I wholeheartedly agree that too much rope to hang oneself is not a good direction for Golang to go into. I also agree that not having generics isn't a BIG pain but they would be useful in library code. 
Give Consul.io a try
&gt; that can be proved to not "escape" the stack, are not heap allocated. Also, the compiler can potentially inline the function call if it can prove that you don't mutate the copy. Indeed, `go test -c -gcflags -m` gives: ./bench_test.go:21:6: can inline structP ./bench_test.go:29:6: can inline structV ./bench_test.go:52:14: inlining call to structP ./bench_test.go:73:14: inlining call to structV ./bench_test.go:21:14: structP s does not escape ./bench_test.go:55:13: r escapes to heap ./bench_test.go:37:37: BenchmarkStructPointerReceiver b does not escape ./bench_test.go:50:4: BenchmarkStructPointerReceiver &amp;SampleStruct literal does not escape ./bench_test.go:55:12: BenchmarkStructPointerReceiver ... argument does not escape ./bench_test.go:76:13: r escapes to heap ./bench_test.go:58:35: BenchmarkStructValueReceiver b does not escape ./bench_test.go:76:12: BenchmarkStructValueReceiver ... argument does not escape So both functions are indeed inlined in this case.
In general it's extremely unethical to share solutions to exercises like this. You can share advises, but not final implementation..
With due respect, those links are worthless. I wouldn't waste a second reading anecdata that's between 1 and 4 years old to educate myself about current technology. Specially because Go's GC (and technology in general) has evolved quite a bit since then. At the very least read recent technical posts like this: [Go vs C#, part 2: Garbage Collection](https://medium.com/servicetitan-engineering/go-vs-c-part-2-garbage-collection-9384677f86f1). Even better if you run benchmarks yourself to determine if a technology fits within your requirements. &gt; The Go programming language was conceived in late 2007 as an answer to some of the problems we were seeing developing software infrastructure at Google. - [Rob Pike 2012](https://talks.golang.org/2012/splash.article) It's fast enough to get people to write kernels ([1](https://github.com/mit-pdos/biscuit) [2](https://github.com/achilleasa/gopher-os) [3](https://github.com/jjyr/bootgo) [4](http://gofy.cat-v.org/)), [filesystems](https://bazil.org/), [network drivers](https://www.net.in.tum.de/fileadmin/bibtex/publications/theses/2018-ixy-go.pdf), [Docker](https://www.docker.com/), etc.
Presumably this is using AWS KMS? I was about to start but then I found this nice gist: [https://gist.github.com/fuzzyami/f3a7231037166117a6fef9607960aee7](https://gist.github.com/fuzzyami/f3a7231037166117a6fef9607960aee7)
Can you post the Go code you are using to make the request and parse the response? Do you get the same response when you try the request with Python or with Curl?
Extremely.
[removed]
Have a look at /r/adventofocode. It is full of it. Everywhere you look for advent of code, it is either the site itself, or solutions to it. People love sharing it. And while it is unethical for academia, why would it be unethical for a competition with no prize? Especially if a lot of people use it to try an learn new languages? Looking at the code of a senior can really help you learn idiomatic code.
What or why a bumpy ride?
I'd run something like that in AWS/GCP as a managed instance rather than running my own, I think. Is it all relational, or something that could be done in a big data store like Parquet format? We parse 500gb of data through our system daily while we're scaling, it'll be terabytes a day once everything's online, but we keep it in parquet in S3. 
These aren't interview questions. It's not at all unethical. It's encouraged. It's how we all learn, new approaches or new languages, nest tricks, etc.
I've been working on the puzzles in golang as well. My solutions are on my GitHub. Since I'm juggling a newborn, most solutions aren't very elegant. They work, but may be rough looking code. This is my first year doing it all in golang.
Look at 12 factor approach. I typically use viper to use env or json/yml
Thank you. Just as a note of caution, this package is still pre-1.0 and things may change (including the import path which I plan to turn into a vanity import path such as "appliedgo.net/start" when approaching 1.0).
I prefer flags instead of config files. For this I'm using https://github.com/alecthomas/kingpin which is very flexible. One of my favorite feature is that I can prefill flag from environment variables which is very helpful when run app from Docker.
Nonsense. My solutions are released under the Apache 2 license. I think it is unethical to *not* open source your code. Closed source software is a cancer on society. 
You should give tips when the assignment is very difficult design wise (for example, last year had one where it was a twist on the 'sheep+wolf cross the river' problem, but a very significant one on which research papers were written. It was very unlikely to be solved on your own within a reasonable timeframe without a hint of previous research ... ) but for the others, I like comparing my code afterwards with other implementations to see which features I've missed
I am a fan of Go, but if you compare the amount of code you had to write for 1.1 to what I had to with Ruby I worry it's just too verbose: [https://github.com/IdrisTheDragon/AdventOfCode2018/blob/master/Day%201%20Chronal%20Calibration/Part%201/main.go](https://github.com/IdrisTheDragon/AdventOfCode2018/blob/master/Day%201%20Chronal%20Calibration/Part%201/main.go) [https://github.com/drum445/adventofcode2018/blob/master/day1/part1/main.rb](https://github.com/drum445/adventofcode2018/blob/master/day1/part1/main.rb)
I am also learning Go as I go, so mine aren't perfect solutions either.
There are pros and cons to both languages and solutions, Mine is almost definitely long winded, there's almost definitely an easier way of doing it in Go. Your Ruby solution is very concise, but at the same time, as someone who's not used Ruby before, I find your solution difficult to understand what's its doing, and how it's doing it.
Nice. I've been coding in Go as well, but I only have days 1-5 so far. I hope to tackle day 6 this weekend.
Once the leaderboard is full, on r/adventofcode a solutions mega thread is unlocked by the creator for the day for all to share and compare their solutions in any and all languages, so if anyone copied a solution and submit a solution without understanding the code, the only person they are cheating are themselves. Although advent of code does have a competitive side to it, getting on the leaderboard, it's also a Christmas event about sharing, learning and improving and having fun. I have shared my solutions so other people can take inspiration from it or suggest improvements that I could make.
Have fun they are starting to get interesting :)
Yes, perfect, I was able to significantly decrease the number of lines. This is my function right now - much more readable and concise: Run: func(cmd *cobra.Command, args []string) { 17 files, err := ioutil.ReadDir(".") 18 var t int64 19 20 if err != nil { 21 log.Fatal(err) 22 } 23 24 for _, file := range files { 25 t += file.Size() 26 } 27 28 fmt.Printf("Total size of the files in current directory is %d bytes\n", t) 29 }, Thanks.
By the way, did I declare a variable on line 18 correctly (I mean idiomatically)? Or should I do a short variable declaration and then explicitly convert it to type `int64`?
Agreed, easy to understand code is often more important than syntax sugar. It's hitting that middle ground that is the key.
Stallman is that you?
If I were RMS, it would be GPL not Apache. 
Env vars work well, and are compatible with docker and k8s based deployments. Could use flags, and default to env vars. 
Wait what?
Like... erm. Everything? Unit tests, integration tests, acceptance tests, linters like gometalinter or golangci-lint, race detectors, deadlock detectors, coverage... 
Dereferencing a pointer into a value is relatively expensive. A slice is a length int, a capacity int, and a pointer to an array. By passing a slice as a pointer all you're really doing is replacing copying 2 integers with copying and dereferencing a pointer.
There was a related post two days ago: https://old.reddit.com/r/golang/comments/a3pitv/flagsfirst_package_for_configuration
Okay I write about it but onky id the Go community wants it 
Was referring to the cancer comment 
Yeah I am not a proponent of the GPL as I think it limits developer freedom. I prefer Apache 2 as I’m fine with my code going into closed source projects. But I do not think it is ethical or wise to use a closed license. There is an ethical way to do it (Canonical, Docker, Puppet, etc) and there is an evil way to do it (Oracle). 
Short version: Have been developing it as part of my master thesis, did not really finish though. Continued development parallel due to job during commuting and was always unsure since it was worth continuing since it drained a lot of time and energy - and because I did not receive a lot of feedback on the direction.
This doesn’t sound like a Go-specific post, more like a general /r/webdev question, but anyway… &gt; The general pattern is on my webapp, you hit a login button that redirects you to the authentication site. After successfully logging in, you are then directed back to my webapp. On my end, when a user logs in, all the authentication service returns is "yes" if the login is successful with their username or "no" if it isn't This sounds like JWT to me — https://jwt.io/introduction/ However, it depends on how the auth system is designed, can you give us more details? If they support JWT, you can check if the token is valid, if yes, create a session with the username. &gt; Also, after some time period, I would want my users to have to relogin for security reasons. Store the initial time of the login in the session as well, then check it on every page and clear the entire thing if it reached or exceeded the expiration time. The only problem with JWT is that you cannot force a re-login the same way you do with a session, but as long as you don’t store the token in the session or the cookie, everything will be okay. I do this in one of my projects, I allow people to authenticate using two different 3rd-party services. They both have different authentication methods: OAuth and OpenID respectively. I created a separate service to offer the JWT-based login, this service processes the response of the external services according to their corresponding APIs, when they return a successful response the middleware login system sends a JWT to my web application and then it creates the session and stores the username with it. &gt; I am very new to this… JWT specification is very straightforward, you’ll surely be able to follow it without problems. There are plenty of open-source libraries to add JWT support for your Go projects _(if that’s the programming language that you want to use)_. Of course, I’m assuming that the authentication system that your web application is going to interact with supports JWT, you didn’t give much details about that so I can only speculate ¯\\\_(ツ)_/¯
How to do CI effectively in a monorepo?
Hi there, when I use python i get the response in the like this ''' type(response.content) --&gt; bytes ''' therefore in order to make it become string again i need to do response.content.decode('utf-8') to decode it into normal string after that i get. """ {"data": \[\], "header": \["AlphaClientId", "Code", "IsInOS", "Hidden", "IsTeamAlpha", "Favorite", "AlphaName", "CodeType", "DateCreated", "Color", "Region", "Universe", "Sharpe", "Returns", "TurnOver", "Margin"\], "numRows": 0} """ When i make the request in Go i receive a resp.Body = \[\]byte -&gt; string(\[\]byte) I receive the unreadable respon below: &amp;#x200B; """ ╚5�A �0 ����كgo�!���C�a+��H����ݦ�K�%y�A��@╗u���\]�&amp;╝�,�:�y��Y���ou0(��-u������4�/O�═����� ��5n a͘�/�║�q����Ȯȱ�� x����(�3tY"|╔-)��߇g�o�?\_ ��� """
If you have free time could we talk a bit, I feel like this is a serious threshold i need to pass in order to go far with golang, thank you very much.
I don't know that I can recall doing that, and I'm not at a computer tonight, but did you try the prefix search?
&gt; This sounds like JWT to me — https://jwt.io/introduction/ &gt; &gt; has nothing to do with JWT, this is purely Oauth 3 legged authentication.
I don't have much Bleve experience, but if this were elasticsearch then I might try a pattern tokenizer to split on "/" or whitespace. https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern-tokenizer.html Then your search string and document field should get analyzed the same way and match on either of those inputs. I see Bleve has a regex tokenizer. Beyond that, have you tried the Bleve gitter chat to get a more focused answer? 
[removed]
Has anyone tried [https://github.com/mongodb/mongo-go-driver](https://github.com/mongodb/mongo-go-driver) ?
Hahahaha Not sure if you deserve a downvote for being silly, or an upvote for being funny XD
&gt;https://github.com/drum445/adventofcode2018/blob/master/day1/part1/main.rb Maybe a few lines less (didn't bother with error handling for file read) but here's mine: [https://github.com/arehmandev/adventofcode-2018-go/blob/master/day-1/part1/main.go](https://github.com/arehmandev/adventofcode-2018-go/blob/master/day-1/part1/main.go)
It would be a good way of learning more about it
Username checks out
Go uses UTF-8 by default, so string([]byte) should produce the same string as Python. Is there any difference in how you are getting the response in Go and Python? Can you post the code you use to get your response?
Having been a full time rubyist and now gopher, Go strikes almost a perfect middle ground in my opinion. &amp;#x200B; There's a lot of magic that happens with that ruby code, and there are certainly comparable higher level libraries that would let you write equally concise code in Go (one that comes to mind is [https://golang.org/pkg/io/ioutil/#ReadFile](https://golang.org/pkg/io/ioutil/#ReadFile)) but the reason I prefer the go code in this case over the ruby code: &amp;#x200B; 1. It is immediately obvious where things can go wrong and we have options for pivoting (rather than just logging + exiting). 2. It is immediately obvious that we are being good citizens and cleaning up our resources 3. It is immediately obvious the time complexity of the main loop of the program. Where as in the ruby code, you actually have two 2 iterations of an array needlessly, you could have been summing as you iterate through, but instead, you first collect everything into an array, then you iterate over the array again with sum. Case and point it is easier to write inefficient code and hide dangerous corner cases when you have nice and convenient methods that hide complexity. It's a double edged sword. 
Exactly. Type assertion in modern Go is **very** fast. I posted this 22 days ago: https://old.reddit.com/r/golang/comments/9xs0r2/why_is_type_assertion_so_fast/
Exactly. Type assertion in Go 1.11 is roughly 5x faster than in Go 1.4 on my benchmarks. Things change, we should be careful with outdated information. I posted this 22 days ago: https://old.reddit.com/r/golang/comments/9xs0r2/why_is_type_assertion_so_fast/
Hello there! Welcome to the world of pokemon! :-)
I understand where you're coming from, but it really, really bothered me that the article kept calling it Python when it's not Python. Upfront, the article could say that Starlark is a Python-like language, but it is a different language, and it's a disservice to Starlark to not use its name, it's a disservice to Python by weakening the meaning of its name, and a disservice to readers who will be confused. Just lots of downsides... It's an incredibly cool project, and it should be respected for what it is, rather than what it's not-but-almost.
Yes, I've asked this there too, it's very quiet these days... My question is basically how to setup the mapping properly. Here's my failing test cases: [https://github.com/herval/bleve-samples](https://github.com/herval/bleve-samples)
Prefix vs Match search will only define whether the search will look for a full match on content or prefix of tokens (based on fuzziness, tokenization, char filtering, etc). I've added my cases here - trying to make the tests pass: [https://github.com/herval/bleve-samples](https://github.com/herval/bleve-samples)
 And I see where you're coming from. I did link to the starlark go repo which describes exactly what starlark is in the first sentence. The main reason I said python and not starlark all the way through was in an attempt to avoid confusion between star*light* and star*lark*.... assuming I was introducing starlark as well as starlight to people, I didn't want to confuse people by using two names that were so similar for new things. I'll go back and add a blurb explaining that and linking to the differences between python and starlark.
here ya go: https://npf.io/2018/12/starlight/#what-is-starlark
Alternatively, do my work for $20. If no one responds I’ll donate $40 to the EFF.
Are you a Boy or a Girl?
I responded, and just donated $20 to the EFF. This is a personal project and I actually already figured it out. 
Crystal is another static labguage and has similar syntax like Ruby.
See https://honnef.co/go/js/dom.
My apologies, I was referring to a more full working example of it in use. I’m a new programmer, would just help a little I suppose. 
Just used named config files and supply some defaults. myapp --config asia.conf --country japan Loads of cli tools just do this with no special mechanism and it works really well. It also has the benefit of not really complicating your application while allowing the user to organise the configs how ever they like such as grouping them in subdirectories or inside different projects or what ever they feel is required. 
I‘m sure you will find something helpful over here: https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1 Check out his other articles regarding the WTF Dial. Another good resource: https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831
Hello Arnaud, You are talking about many things, where can I found a description of the podcast to get all the links you are sharing for example? &amp;#x200B; Thank you &amp;#x200B;
As a funny side-note; Skit == Shit in Swedish. Let's hope it's not ;-)
Hard to answer without knowing how things are changing, and also sounds like less of a go thing and more of a general programming/databases thing. Anyways, seems like you’re looking for hooks of some sort.
Ah, sure, I misunderstood the original comment.
Look in the podcast description there's a select button 'display more', if you click on it the description expand and you'll see all the links listed...
Yeah, I believe so.
\- added support for gobuffalo/packr \- templates now get minified using tdewolff/minify
Well I can think of many answers, but as I don't even know what you are trying to do, or what your categories represent, I can't think of anything that would help... Please help us with more contextual information, maybe paste bins of your code, a clear description of what you want to achieve :/
Fuck mate beautiful work on the docs!
Yeah Crystal is my main language these days
Thank you for your quick answer. I've listened to your 4 episodes. I really appreciate. You do a great work.
What is the value of this tool? Are there any examples when it is useful?
Did you consider to use the "flag" package? It has some ways to create groups of options. 
The name will make some DBA's nervous !
/u/JakubOboza I did some heavy refactoring and found ways to test most of the code. Can you please check it out and tell me if there is any improvement?
I'm going to use this tool to create a decentralized Virtual Identity Document, this tool helps to create and index the different Documents. Obviously this project is work in progress, and the next step is create an ORM like for upload structs or objects to IPFS.
&gt;Hard to answer without knowing how things are changing, and also sounds like less of a go thing and more of a general programming/databases thing. Anyways, seems like you’re looking for hooks of some sort. Yeah, it's not a go thing, but i'm writing in go
Pretty bad file names imo. If I were to contribute to this, I would have a hard time .
Think about discourse [https://github.com/discourse/discourse](https://github.com/discourse/discourse), i'm learning from it, it's easy to update last\_topic\_id, when a new topic is created, but it's difficult to update a category's last\_topic\_id, when delete a topic.
What are you trying to accomplish ? Is this question really Golang related ? (If it is not I will still help you but I need to understand what you want to do) I will read and document my self about discourse, but I am not really experienced with ruby and js so I am not sure that this will help me to help you. Can we please have little samples of your code ? Tell us all about the initial situation, your current algorithm/strategy/technique. It is really hard to understand what you need.
I wanna participate too :) Will you find some tasks for me?
That was the ide behind it 
LOL. It works like charm for me and so the meaning of `skit` is definitely not relevant to its meaning in sweden. I needed something quick to build a slack bot and didn't think about the name much. (just abbreviated slack-kit to skit)
Is this a SQLite like version for nosql databases?
I run a React-based Stripe payments dashboard with a Go backend. The Go backend is simply a JSON REST API that authenticates users and serves as a proxy to access their account info. I don't use (or like to use) server-side rendering if that's what you were implying. Searching GitHub though, there's this project if you wanted to see some direction on doing that: https://github.com/stephanos/go-reactjs though it's abandoned and I haven't tried it.
im not using react server side rendering. opting to use gin. practically just trying to deploy an app like this one: https://github.com/codehakase/golang-gin (but using create-react-app which comes with a node server?)
Name suggests that any data you put into it is lost forever
Error handling is intentionally omitted from all of the examples while it would be trivial to explicitly document that or at least introduce a simple panicking helper and use it everywhere. Hence that post should be classified as crap, so be it. 
Maybe differences in setup when using `dep` vs modules too?
As a side note, JSON unmarshaling in case-insensitive. You don't always need to use field tags. var structData struct{ Quantity int } var jsonData = []byte("{\"quantity\":1234}") if err := json.Unmarshal(jsonData, &amp;structData); err != nil { log.Fatal(err) } fmt.Println(structData.Quantity) Output: 1234
A. single deployment: build the react app, copy the files, and serve them as static content from go app B. have two deployments separately: 1) go api hosted say on heroku 2) react app say hosted on firebase. react app would be your entry point
Let me see if I understand correctly. When you write a key/value; the encrypted value is written to IPFS. Then the key and the IPFS address is written to a local BadgerDB instance. Then, the values could be recovered directly over IPFS, assuming one had a copy of the BadgerDB (or some subset of it).
Thank you. That'll work! I was sorta hoping to keep all the presets in a single file, using JSON for example. Here's a sample. Say I'm implementing uses of a pseudo random number generator. Preset "die" represents a 6-sided cube die, and presets "dice" and "yahtzee" are variants of that with different number of dice and arraying of the results. I include here a 6/49 lottery number picker as well. I was hoping to keep presets in a single config file... { presets: [ die: { min: 1 max: 6 }, dice: { preset: "die" num: 2, columns: 2 }, yahtzee: { preset: "die" num: 5, columns: 5, sorted: true }, Lotto649: { min: 1 max: 49 sorted: true unique: true columns: 6 } ] } 
I'm using the `flag` package now, yes. Do you mean, using the [`FlagSet type`](https://golang.org/pkg/flag/#FlagSet)? That's interesting. How did I miss that? I'll peek into that.
check these, - https://github.com/golang-standards/project-layout - https://github.com/google/go-cloud - https://github.com/google/wire/blob/master/_tutorial/README.md
A create-react-app is still just a set of compiled static files, no? The go backend serves these files and maybe more implied? So yes you can serve static files using http.ServeFile or http.ServeContent. 
Thank you very much. But don't hesitate to comment/correct/suggest to improve the podcast. And also don't forget to give your answer to the survey to get a chance to win the prize :-D
Bigpigfoot's solution is really good, but in addition you could use nginx to serve the static files, and then reverse proxy traffic to the running go api.
Legend has it, they asked the cockroach guys for DB naming advice
Did you read the response's body correctly ? Because actually, [http.Response](https://golang.org/pkg/net/http/#Response)'s body is of type [io.ReadCloser](https://golang.org/pkg/io/#ReadCloser), not []byte. There are many ways to read the body, but if you want the response to be stored in a Golang structure I would suggest that you look at the [encoding/json](https://golang.org/pkg/encoding/json/) library, particularly the [json.Decoder](https://golang.org/pkg/encoding/json/#Decoder) struct (but still look at all the librairie, everything will be useful here). Hope I could help.
[removed]
Thank you for this!! This appears to be something I definitely can use 
Close the Listener to make the Accept return early. https://golang.org/pkg/net/#Listener
If you're trying to stop the listener and make the goroutine return, have you tried just closing the listener? When closed, all blocking calls to it will return errors.
Did you know the term 'blackhole' is frequently used to describe a mock/test db that accepts writes but fails reads?
Something like this would connect the listener to the stop channel state: listener, err := net.Listen("tcp", "127.0.0.1:8080") if err != nil { panic(err) } go func() { &lt;-stopchannel listener.Close() }() 
If you read something from your stopchannel, close the listener before you return: [https://golang.org/src/net/net.go?s=12307:12609#L355](https://golang.org/src/net/net.go?s=12307:12609#L355) &amp;#x200B; Another note, your read from stopchannel is a blocking read; add a default case to make it non-blocking: &amp;#x200B; `select {` `case &lt;-stopchannel:` `listener.Close()` `return` `default:` `}`
I wouldn't recommend building a slackbot with Go unless that's the only language you know well. Too much boilerplate for something that is essentially throw away code. I'd recommend something like NodeJS for slackbots.
Ugh I hate it went people put being cute or funny above being practical when it comes to code. If it's not a serious project then whatever but of you expect other people to use the code then it damn well should be organized logically and not around your internal mental memes. 
You need to make sure you use the same analyzer/tokenizer for both indexing and query parsing (i.e. if you split on "/" for indexing, you also need to split on "/" when parsing the query). 
As bigpigfoot has already pointed out, create-react-app just creates a bunch of static files. If you type "npm run build" or "yarn build" you will get a folder called "build" containing all static assets. You can either embed those files in your go binary by using go-bindata or just serve them from the filesystem directly. Go's built-in http.FileServer can serve those files. &amp;#x200B; I usually use "npm/yarn start" during UI development (because of hot code reloading). You can tell the development server to forward "/api/" to your Go backend and handle everything else (e.g. the UI at "/") by itself. The release build however, embeds the static files as described above and you will end up with a single Go binary (without any dependencies) that can be started anywhere and handles both, UI requests at "/" and API calls at "/api/". &amp;#x200B; If you want to add server side rendering on top of that, you can do that too. There is a JS interpreter in pure Go available that works well with React. Alternatively, you can use a v8 binding in Go if performance matters. If you want to do that, you would have to write your own handler for the index page that imports your bundel.js and calls the React's server-side rendering function before serving the content.
But what analyzer/tokenizer? No combination I tried seems to work...
This looks like something I was looking for. Thank you!
Or a squid?
Hi 1. Some thoughts. argumentCheck should return os.Exit(1) or some other non-zero value 0 means success. 2. Appending file paths should use https://golang.org/pkg/path/filepath/#Join so it is crossplatform safe. 3. I would wait to calculate the md5 checksum until the later. It is the most computally expensive operation so you could do it after two files have the same size and then cache the results so you don't need to do it again. Just my thoughts 
If you are comfortable in Python and are wanting to gain an understanding of networking, then I'd say yes. That minimises the variables and allows you to work on the concepts, before then also learning an additional language for that. &amp;#x200B; If however you aren't more comfortable in one language or the other, then I'd recommend no. Better to go straight to Go and learn both the semantics and concepts at the same time.
[removed]
Cool thanks! I’ll update the code :) The exit code 0 was a debug I forgot to edit
I have used it at work before but unfortunately don't really have any examples/sample code available. I'd recommend you try out these libraries: * Goka [https://github.com/lovoo/goka](https://github.com/lovoo/goka) * Confluent Kafka Go [https://github.com/confluentinc/confluent-kafka-go](https://github.com/confluentinc/confluent-kafka-go) * Kafka-go [https://github.com/segmentio/kafka-go](https://github.com/segmentio/kafka-go) There's also Sarama [https://github.com/Shopify/sarama](https://github.com/Shopify/sarama) by Shopify but it's not that well documented and I prefer the other ones more .
Hey again, any update on when version 2 might be released? :)
I was just about to say the same. I wonder what my boss would say if I wanted to add a slack bot made with shit. :)
This is my preferred setup, but does require knowledge on nginx but that's not hard to pickup.
Calculating the hash is probably a waste of time. It doesn't permit you to short-circuit when a difference is found. I'd scoop in both files in fairly large chunks, like 16-64MB, and do a byte-wise compare on the chunks. The only thing that makes me say "probably" a waste of time is possible IO slowdowns from interleaved readings of two files. If both files could be accessed with 0 switching time between them, the MD5 sum would _certainly_ be a waste of time. It is possible that reading in one file, hashing it, then reading the other and hashing it will be faster, if the files are correctly optimized on disk.
Yes, I created [recursive.recipes](https://recursive.recipes) using the create-react-app and a Go backend. You can check out the source here: [https://github.com/schollz/recursive-recipes](https://github.com/schollz/recursive-recipes). Utilizing gin and gorilla/websockets will get you going really fast. &amp;#x200B;
cool &amp;#x200B; &amp;#x200B; &amp;#x200B;
Maybe you should use uint64?
updated, thanks for pointing it
I wouldn't recommend node.js for *anything*, even if it's the only language you know well. Go or Python would be effective substitutes ;-)
Is this really a serious project?
Silly question: Does it have IPFS daemon embedded or it has to be installed?
I mean I thought so. An ipfs DB lib seems like a legit use case. 
If you use a bufio.Reader, can you trust it to take a big enough block for you to make the interleaving non-problematic?
Source says that the default buffer size is 4K, which I don't think would cut it for a spinning platter. It might be OK for SSDs.
In DB (easy, wrong in many ways): Set trigger on delete and update actions of posts and change corresponding value in category. In code (harder, better): Use event system. Register event `OnTopicDelete` and `OnTopicUpdate`, send topic ID with event to EventListener and change corresponding value in category.
Great notes man! I agree with the points you provided OP
i'd store the results in a map of type \`map\[string\]\[\]string\` where the index of the slice is a text representation of the hash and the slice at each index is a slice of files that have that hash. this way, printing the duplicate files would be a matter of simply iterating over your map and printing the slices that are longer than 1 entry. you might also be able to benefit from hashing the files concurrently.
One thing that slowed me down in the first day was that the examples were given as a comma-delimited list, but the actual frequency data was newline-delimited. (The other thing was that I’m using Windows, which uses `\r\n` for newlines, so getting my test data to work meant the actual data didn’t…)
It might turn out advantageous if you had a bunch of identically-sized files to compare. If you had, say, 100 files to compare, that's 4900 pair-wise comparisons. Better to do that with the hash than each chunk.
[removed]
You don't do 4900 comparisons, you just read 1k at a time or so and make a map of chunk to list of filenames with that chunk. The map does the hashing for you. Once you have the map you iterate through it and throw away all keys that only had one file.
I've done testing on parallel file reads and it performs really nicely up to 4x concurrency, at least on an ssd
+1 on this. The use case in the article makes some sense, but generally speaking the lifecycle of your goroutines and their accompanying channels should be explicit enough that you don’t need to “guess” about whether someone is waiting on the other side: you should just know. 
len(os.Args[1:]) == 0 Is it golang way? 😳
Good point. My pedantic brain was thinking that that's just hashing under the hood, but that doesn't actually matter.
iirc, the approach I've taken for Go backed `create-react-app`'s: 1. Place the `create-react-app` project into e.g. `mygoapp/frontend/` 2. Do `npm run build` to create the built web assets at `mygoapp/frontend/build/*` (contains `index.html`, so serve this dir!) 3. In `main.go`, specify serving of this `build` directory at root path `/`: ``` buildHandler := http.FileServer(http.Dir("&lt;path to build&gt;")) router.PathPrefix("/").Handler(buildHandler) ``` 4. Also specify serving of the web static asset paths: ``` staticHandler := http.StripPrefix("/static/", http.FileServer(http.Dir("&lt;path to build/static&gt;"))) router.PathPrefix("/static/").Handler(staticHandler) ``` 5. Begin serving via `http.ListenAndServe` as usual. 
In Go, you don't deal with sockets, you have the `net` package and the `net.Conn` interface. &amp;#x200B;
What analyzer you are using? Try to use an analyzer with PorterStemmer filter.
More readable in my opinion. os.Args includes both the executable path and arguments in a single slice. This might not be so obvious at a first glance.
I would not say it is a prerequisite. If you want to learn to deal with raw sockets in Python, then you should do it for the experience. 
I'd add that some lightweight scripting engines in Go (mattn/anko, gomacro, lua) are a good way to add functionality to a bot without necessarily recompiling it for every little thing. The pain point in development mode may be recompiling it or extending functionality given the compile-and-run cycle, and embedding a scripting VM is a good way to get around that.
If you would learn socket programming with Go first, then learning how to do that in Python will provoke in you a series of irresistible urges to wash your hands. ;-) The reason is than in Python, the approach to socket programming roghly falls into two broad categories: - The core lib has a very thin wrapping around what's called "BSD sockets" layer found in all commodity OSes (including Microsoft® Windows™). This means, you may just as well take C and make yourself accustomed with how the socket code works almost at the OS level without Python getting in your way. - The set of libraries which abstract away "contemporary" concepts of efficiently doing socket programming by using the so-called "polling" interfaces (`epoll` on Linux, `kqueue` on \*BSD, IOCP on Windows™ etc). The libs I'm talking about are things like Twisted and the recently matured enough in-core "asyncio" facility. The problem with all of these libs is that they have lots of complex concepts to deal with while Go—thanks to its I/O being intergated into the scheduler provided by its runtime—lets you merely write dumb beautiful straight serialized code without all those "awaitables", "asyncables", "futures", "promises" which are plain callbacks in disguise anyway. So, take your poison, but think wisely ;-)
This won't help you to learn Go coding, but might be a useful high-level overview of Go: [https://devopedia.org/go-language](https://devopedia.org/go-language)
Very nice! Thank you 😀 I'm pretty sure I'm going to use this in one project or another in the future!
that is way more difficult to read than: if len(os.Args) == 1 { // handle error } in both cases, you need the knowledge that the first entry is the executable name. in the original version, you have to mentally decode the re-slice of `[]os.Args`. if Go does actually bother to create a new slice for `os.Args[1:]`, those are just wasted instructions. i realize this isn't time critical but it is never a good idea to be wasteful.
Hey, I hope you find it useful. We use it for rendering Kubernetes yaml manifests. &gt;Universal data-driven template for generating textual output, as a static binary and a library [https://github.com/VirtusLab/render](https://github.com/VirtusLab/render) &gt;Universal cryptographic tool with AWS KMS, GCP KMS and Azure Key Vault support [https://github.com/VirtusLab/crypt](https://github.com/VirtusLab/crypt) (it will be soon part of render, really helpful for secrets management)
FileInfo size returns int64 I didn't saw the point in casting
I agree, refactor it to be more efficient 
I agree, fixed
There is a good pull request from someone.
The PR is nice, but check hash for every file. this is way I didn't merge and decided to refactor
Thank you all, but i am new to programming, and i may not understand all you said, I am searching for advice.
IMHO, you should: \+ rename \`argumentCheck\` into \`init\` \+ use a better non-crypto hash, like xxhash
i see. it looks like they updated it. 
it looks like there are still some logical issues with the code. not sure why you're worried about current/previous hashes. just store all of the files with the same hash in a slice assigned to a map entry.
I don’t hash all the files. Only the ones with the same size 
right -- the logic just seems strange. compare it with the pull request (which only compares same sized files). 
 The real key there is converting to bytes.
good and needed effort to move forward, thank you
The answer is in the linked post. Not sure why you need to make a guess.
[removed]
[removed]
I have a toy app I used to play around with the confluent Kafka go client. It doesn't use a web framework, just HandleFunc to handle requests, and gorilla/websockets to communicate with the browser. Should help with initial Kafka set up and communication at least! https://github.com/flabbergasted/kafka-go 
[removed]
[removed]
[removed]
You won't be able to do it entirely in Go with native UI. However, if it's a game or something where there is a C api to draw to the screen, you might. https://github.com/golang/go/wiki/Mobile#building-and-deploying-to-ios
Native UI isn’t a requirement, nor does the UI code necessarily have to be in Go. I’m particularly after writing the app extension in Go, which implements the tunnel code. I’ll take a look at the link though, thanks.
A nice trick for filtering in-place is: func filterIntsInPlace(xs []int, pred func(x int) bool) []int { filtered := xs[:0] for _, x := range xs { if pred(x) { filtered = append(filtered, x) } } return filtered } Caveat: The original slice memory won't be garbage-collected until the filtered slice is. So if you filter a 1000-element slice down to 10 elements, you're keep 990 unused elements alive.
avoiding merge conflicts is the wrong way to think about it you either know how you want your code to look after merging both branches together, or you do not in which case you shouldn't merge at all having superfluous merge conflicts just comes down to not actually knowing what you are doing when it comes to git and version control also, this is way off-topic here
We wrote this little thing because we have to deal with a few thousand domains, subdomains and custom redirects. And we blew up nginx with the load of domains and needed anyway a more friendly way to add new ones. Our setup is basically an AWS NLB + swerve in an autoscaling group and a DynamoDB as a DB. The UI will follow this week. So we can move the actual work directly to our customer. It is a tool that made my life much easier. 
The goal of the article is to show ways of preventing conflicts. And yes conflicts are bound to happen every now and then. Thanks for reading though.
[https://godoc.org/golang.org/x/crypto/acme/autocert](https://godoc.org/golang.org/x/crypto/acme/autocert)
Because when people post a link to something that answers a question, and the title is the question, it's confusing as hell.
Looks great actually. At first I was confused, but after digging into the readme it became clear why this isn't just a replacement for the autocert package...
that spelLing makes me sad.
I suppose it could be. I just look to see if the post is a self post. If it is, the question is being asked here. If it isn't, then the question is being asked at the link and I click through to see if it gets answered there as well.
&gt; and no other library will ever match CertMagic's maturity and reliability That's a very bold claim regarding reliability. How can you possibly know that no other package will match the reliability of your package? I am now skeptical of everything said in the readme. 
Thanks! CertMagic is one-of-a-kind, here's a few reasons why it's different than autocert: 1. CertMagic (as a Caddy library) existed long before autocert did and has been used in production much longer and I suspect much more widely (securing tens of billions of connections now). 2. Autocert can't obtain wildcard certificates because it doesn't support the DNS challenge. 3. CertMagic supports the full range of ACME features and makes them configurable if needed. 4. CertMagic is more robust to failures. When Let's Encrypt abruptly discontinued the TLS-SNI challenge earlier this year, [autocert broke](https://github.com/golang/go/issues/21890#issuecomment-356495071) because it used ONLY that challenge, but Caddy (and by extension, CertMagic) continued without downtime because it also supports other challenge types. 5. To my knowledge, autocert does not really work behind load balancers as it does not coordinate certificate management between instances. 6. Autocert does not staple OCSP responses to certificates, which makes revocation -- if needed -- less useful. &amp;#x200B;
Caddy (from which CertMagic is extracted) was the first integrated Let's Encrypt client. It's been around longer than any other ACME client and used in production for years to secure tens of billions of connections. Caddy has repeatedly survived CA server and OCSP responder outages when other clients -- even major ones like CertBot, autocert, and Traefik -- had trouble. For example, when gnu.org went down because an OCSP responder went down, Caddy sites relying on that same OCSP responder remained online due to Caddy's OCSP caching features. As another example, when Let's Encrypt ended the TLS-SNI challenge recently, other clients such , any Go programs using autocert, and even some CertBot scripts, all were unable to procure certificates because they relied on just the one challenge type; but Caddy continued without interruption. In other instances, the CA server has been offline but due to Caddy's certificate management policies, has never experienced downtime-inducing interruptions. So yes, it's a bold claim but I'm quite confident in defending it. It's quite simple, really --- CertMagic was the first of its kind, so it *is* the most mature, and that will always be the case unless other libraries can go back in time.
[removed]
My comment was about reliability, not maturity. In any case, longevity is not a measure of maturity. When the Iris developer clones your repo, there will be another package that matches the reliability of your package.
Oh -- thanks for the gold, whoever you are! 💛 I hope lots of people find this package useful. Even though I need it myself, I really think that good, robust HTTPS support is ever more important, and that every server should use HTTPS.
My 2 cents ## Allow Go1 error idiom to continue working if err != nil { ... } Some consider `if err != nil { ... }` a good trait of Go, me included. It's verbose but simple and explicit. ## Reusable error "handlers" within a function and/or package Why would I want to encapsulate error handling? Hiding a bunch of `if err != nil` under the carpet doesn't make them go away. Instead it forces me to jump around the function function/package to understand how an error is handled. It makes reading code less linear with little gain. ## Really weird syntax Not trying to be dismissive but stuff like this will never land on a language like Go: f := func(i int) (T, error) { ... } x(f op hname (a)) f op hname (a).x() handle hname error { ... } ## No mention of check? The most sane suggestions from all the ones I read recently is being able to replace this: db, err := sql.Open() if err != nil { return error } with something along the lines of: db check := sql.Open() Yet it isn't even mentioned in your document. ## Finally a tip In your gist code blocks, specify the language to enable syntax highlight. Like this: ```Go type key struct{} ctx = context.WithValue(ctx, key{}, "my value") // Set value myValue, ok := ctx.Value(key{}).(string) // Get value ```
Awesome and great job with the documentation. Thank you 🙏 
Sounds interesting, I have bookmark it and will check it later. Thanks. 
Great, i wanted to create similar thing for my lib, but i can use this now.
Thanks for your input! &gt;Why would I want to encapsulate error handling? It's common for multiple operations in a function (or package) to apply the same error response, e.g. `log.Fatal(err)` or `return fmt.Errorf(...)`. The Go team has heard many complaints about the boilerplate currently required for each such case. The name of the handler should make clear how an error is handled, as function names should do today :-) &gt;stuff like this will never land on a language like Go Well the Go team proposed `work(check giveError(a))` which is arguably worse than `work(giveError?fatal(a))`. It's possible that no expression-style handler invocation will be adopted, to leave the relatively familiar v, ?fatal := giveError(a) work(v) &gt;No mention of check? It doesn't work for named handlers, and has other problems; see [*Golang, how dare you handle my checks!*](https://medium.com/@mnmnotmail/golang-how-dare-you-handle-my-checks-d5485f991289) &gt;In your gist code blocks, specify the language Thanks for the tip. It doesn't work that well for code with new language constructs, however.
Interesting! I have a question, out of curiosity -- noting, however, my obvious bias here -- did Caddy not meet your needs? (Caddy can handle tens of thousands of sites/certificates, no problem.) What would be needed for you to use Caddy?
The gist has the same outline; several items have been added within it, and examples have been clarified or added. As far as I know one can't bump an old reddit post back to the top by updating it.
I already handle errors in a single place with \`goto\` to a label at the end of the functions. lol
This is very interesting it might even be something that I will use for my one of my own projects. Do you have any benchmarks on the performance hit for both users and crawlers? Like, how much system resources does it use and how much longer are there load times?
The lack of interest in my work among Redditeers mystifies me. Error handling isn't sexy, but is ubiquitous, and the Go 1 idiom has generated immense criticism, both among Go users, and folks considering the language for future projects. The Go team has decided it must address this, thank goodness. Many, probably most, of the counter-proposals on the feedback wiki are slap-dash efforts (with few revisions/updates) which apparently reject the check/handle concept, but make no attempt to explore the design-space of error handling. Even the Go team's "draft design" makes little attempt to explore that space. My document does explore the design-space, although granted it rules out some dimensions, e.g. C++ exceptions, as they're unlikely to get traction among the Go principals. And I've been working on it steadily for three months.
I do wish folks wouldn't down-vote rational comments simply because they don't share the view expressed, jeez.
Linux kernel style! Well done. But you still need `if err != nil { ... }` which is three lines if you *go fmt* the code. (I hate *go fmt* actually.)
Thank you! I actually developed it because I have developed a somewhat complex website using vue.js and it was too complex for my architecture to do the native Vue SSR using Node.js so I built rendora instead :D. I have some really complex pages that could be rendered below 150ms. I also tested it on some simple React pages and got as low as 70ms! so I now guess headless Chrome isn't as slow as you might think. Also some other optimizations are made to help lower latencies (skip fetching&amp;rendering CSS, images, fonts, etc..) so that the HTML initial load can be faster. &amp;#x200B; I also added Prometheus metrics and a rendering API endpoint so that you can get the SSR latency and see the avg latencies for your use case. &amp;#x200B; TLDR; headless Chrome is actually faster than you think. It might be 200-300ms at maximum to get the initial DOM load assuming that you have complex enough pages.
There was a project that created a Perl5 slang, and that used grammar engine. That project has stalled. The project that allows you to use Perl5 modules as if they were written in Perl6 is Inline::Perl5; which is implemented in terms of NativeCall. It makes use of features that allow modifying the AST, but it doesn't really use the grammar engine. (I think it was a mistake to call it Inline:: as writing Perl5 code inline is just a minor feature of the module.)
&gt; Well the Go team proposed work(check giveError(a)) which is arguably worse than work(giveError?fatal(a)). You are arguably wrong about that, and seem to consistently confuse your opinions with facts.
Nice, but do you have any benchmarks comparing load speeds with and without Rendora? To see how much it actually adds in latency. I guess I could make them myself if I decided to try it out. Also, it would be interesting to know the resource utilization for something like this. I guess it wouldn't add too much since it only shows rendered pages for crawlers. I also use Vue btw, and I have been thinking of moving to Nuxt for my next project that requires SSR. But Rendora might be an alternative.
Hey Matt! This looks nifty. Thanks again for another cool project, https://github.com/mholt/json-to-go. 
Ha, I'm glad you like that one too!
My understanding is that winning an etcd election lets the leader update a value _as the leader_, and if it no longer is the leader, etcd will automatically prevent future operations from such a stale leader. That is, updates by the leader on that one special value are transactionally conditional on it still being the leader. https://coreos.com/etcd/docs/latest/dev-guide/api_concurrency_reference_v3.html
\&gt;do you have any benchmarks comparing load speeds with and without Rendora? do you mean when Rendora works a transparent reverse HTTP proxy (e.g. for normal users)? I don't have numbers but believe me the overhead could be as low as tens of microseconds and if you have something like a Docker network, it could be 100s of microseconds; you can be assured that the overhead of Rendora's layer in front of your backend is always below 1ms and you can verify that on your use case using \`ab\` of Apache; you will see that if you blacklist all requests the avg will be almost the same; I urge you to have a look at my code, the \`IsWhitelisted()\` function in \`filter.go\` made on average 3-4 microsconds on my machine, I intentionally avoided the use of regex because it made it around 50 microseconds. I would also like to mention that performance is one of my main goals and that's why I made it in golang instead of using Puppeteer/Node in the first place :D
I don't get all this complaining about Go's error handling. It's verbose sure, but it's easy to read and reason about. IMO, Go2 should focus on adding whatever we need to e.g. get rid of empty interfaces in function signatures - stuff which makes the code harder to reason about (and also breaks in production).
I am not sure what your priorities are, but in general, Go is actually going to be easier to deal with the sockets themselves, in my opinion. Python ironically has too many things trying to jump in and be helpful, and it's not terribly consistent with them. Depending on what you want to do, Python may be easier to work with the data once you have it. But Go's not bad in that department either, really. Network programming is Go's wheelhouse. It's good at other things, but it is very good at network programming.
Great, thanks for the answers. I'll bookmark the repo so I don't forget about it. :)
I think that project will help you. To use any Go code as a static library called from C, etc. you have to pass `-buildmode=c-archive`. gomobile might do that for you. You will have to do some kind of reference to pointer thing so that Go doesn't garbage collect variables that you want to hold onto in C land, though. This is a good example: https://github.com/swig/swig/blob/master/Lib/go/goruntime.swg#L349
So I am not sure what this is. Does this make it so you can bundle SSL in to say an api service without needing a cert? Or does it provide an endpoint to generate SSL certs? 
Not a rational comment, seeing as it doesn't provide any *reasons*.
irc
Thank not. I greatly appreciate the lack of stuff-happening-silently in Go 1's error handling. It's so useful when reviewing code. So folks who never checked for errors before (and thus wrote programs which paniced when there was a problem, like so many python programs I've used) can't get used to checking? I can't really sympathise. You can, even in Go 1, ignore errors like a junior pythonista. Just put a '\_' and your program will be just as fragile. Possibly what prevents you from doing that in Go is that it is so obvious and in your face that you aren't handling the error, that in good conscience you can't bring yourself to do it. Which is a great feature.
The Go team has heard a ton of complaints about all the boilerplate; otherwise they would have left it alone. Re empty interfaces, you've heard about the Go 2 draft design for generics, right?
Sweet, does this have zero-hit setup similar to https://github.com/cloudflare/certinel ?
yeah, ought to get a USB pedal to add the boilerplate quickly lol this is another idiom I use: ``` func (App *app) CustomerGet(ctx context.Context, w rest.ResponseWriter, r *rest.Request) error { logger := app.WithFields(logrus.Fields{"cid": ctx.Get("cid")}) onError := func (statusCode int, message string, err error) { logger.Errorf("CustomerGet: %s", message) w.WriteHeader(statusCode) w.WriteJson(&amp;reply{Status: 0, Message: message}) return err } onSuccess := func (message string, customers []App.Customer) { logger.Debugf("CustomerGet: Success: %s", message) w.WriteJson(&amp;reply{Status: 1, Message: message, Customers: customers}) return nil } var req Request var err error err = parseRequest(r, &amp;req) if err != nil { return onError(http.StatusBadRequest, "invalid request", ErrInvalidRequest) } var customers []App.Customer customers err = App.Customers.Get(req) if err != nil { return onError(http.StatusNotFound, "no customers found", ErrNotFound) } return onSuccess(fmt.Sprintf("found %d customers.", len(customers)), customers) } ``` 
&gt; interface{} says nothing https://go-proverbs.github.io
Awesome job on this library, especially the documentation ❤️! Any plans to add different storage backends (Redis, ETCD, etc)?
It abstracts the obtaining and management of certificates away from you. So, your API served over HTTPS (or anything requiring a TLS connection) still needs a certificate, but that's what CertMagic takes care of for you. You can use the high-level convenience functions to run the server or start the listener for you, or you can use its lower-level features to integrate it easily into your existing server/listener/middleware with just a line or two of code.
Yes, certificates managed by CertMagic are reloaded when they are renewed. (If you provide your own certificates, though, it's your job to update them.)
Not at this time, but pull requests welcome! Storage implementations don't even have to belong in CertMagic, and maybe they shouldn't -- they just have to satisfy the Storage interface. Note that it's a good idea to satisfy the Locker (and Waiter) interface, too, if your cluster synchronization relies on the same storage facilities as your certificate cache (which is usually the case, but may not always be).
You may be interested in the excellent [myrepos](https://myrepos.branchable.com/) (mr) which has been around for more than a decade to perform this task with any VCS. Or maybe not since you already went to the trouble of writing your own tool.
I think the examples are good examples regardless of skill level in Go. It shows exactly what I would want to know for doing each operation and I can copy paste it for the most part and test drive it. Anyone complaining that it doesn't show how to handle errors obviously haven't taught programming before. 
I opt for json tags in my structures to ensure I can Marshal them to lowercase. I hate seeing uppercase and camel case in my json. Only snake case belongs there. Lol
Sorry I didn't investigate much yet but can this work if you serve multiple apis from a host with a load balancer (nginx, traefik, etc) above them? Or could we write our own load balancer with this...? 
We are using this right now for storing some application data. Is there any examples on how to mock the db for unit testing? The official unit tests expect a running mongodb instance.
Yessss, HTTPS everything!
Yes, it works behind load balancers. You just need to make sure all the instances share Storage (and Sync). This section of the readme describes it a little more: [https://github.com/mholt/certmagic#behind-a-load-balancer-or-in-a-cluster](https://github.com/mholt/certmagic#behind-a-load-balancer-or-in-a-cluster)
Oh shit that's you? I feel like I owe you a beer. I'm learning Go by making an API client library and dealing with the JSON responses was a huge pain in my ass. I found your tool in the answer to an unrelated question two days ago and all of a sudden my structs for JSON data started coming together much faster.
For *NIX systems, print ‘\033]0;Title goes here\007’ to stdout For Windows, there’s an API for doing that, you can try dig up in MSDN, and should be able to call via syscall package. 
I use it all the time as well. Thank you.
AFAIK, distributed locks are a way to control access to a resource in a distributed fashion (so only one process has access to the resource at any given time). Elections are an easy way to determine a "master" between a group of nodes (like Raft's leader election). Imagine you have a distributed system running on 5 nodes; you want to make it so that all servers are equal, there's no single point of failure to your service - if any single one of them dies, your service goes on. Now imagine that this service consists of of pulling a list of URLs from a database, and having all nodes check those URLs for liveliness. You want your service to work just the same with 1, 5 or 10 servers, for scalability. One way to do it is to use Etcd's "leader election" to elect a leader out of those 5 nodes; this leader is responsible for pulling URLs from the database and tasking the other nodes with checking them. If this leader dies, another election is held between the 4 nodes that are still alive, a new leader is elected, and it begins pulling URLs from the database and tasking the other nodes with jobs to do.
[removed]
Ok, if that does what it says on the tin then thanks *you* for that comment pointing me to it! 
You don't need to vendor the dependencies. That was just backfilled as a crutch on those who already depend on vendoring. If you are using modules from scratch, just go with the plain go.mod and go.sum and let them resolve the dependencies for you.
I didn't write this, but personally I LIKE to vendor them. I like knowing that the code is there and I can always compile after that first git clone.
[removed]
To whomever wrote this: bless you laddie. Been trying to find a quick little tutorial on modules. 🙏
In some cases vendpring makes a lot of sense.... It allows a few of the CI / CD tool chains I use work soo much better
Sure, that is fine. But then you are just using vendoring using go modules. And not using the core features of go modules; in which case, you might as well just use plain vendoring.
At this point I only do vendoring of modules if I want a lazy way to drop a printf or two into the dependancies for debugging.
It's not crypto because the modules aren't signed anyway. As advanced CRC, SHA1 is still fine. I can think only of speed as the reason for using SHA1 instead the newer versions, which once again confirms that this is not not intended to be a crypto system.
Really the two commands I use with modules is "go mod tidy" and "go mod vendor". Seems "tidy" is a replacement for the "go get ./..."
I don't see how that is true. It is still using the module system to track the versions and dictate what goes into the vendor folder. All you are doing is skipping the shared module cache. 
Remember to add the flag: -mod=vendor To any relevant go commands (build), or probably even better add it to GOFLAGS env variable.
haven’t heard of it but still I needed some quick micro management such as stashing/view diffs while updating. aside from that, as a experienced java dev I found developing with golang is joyful. 
why parse grub config files instead of a much more comprehensive format like systemd-boot?
This. It would take a good minute for CI/CD upon every build to clone repositories, especially when you're using Docker and need to install the extra dependencies just for using Git.
Thanks, will try this out tonight
And god forbid if github goes down for a second or someone changes the public history of some 3rd level deep dependency and your builds start silently failing.
[Well that's totally unlikely](https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm)
Yeah you're right. [Github is a bastion of security and best practices these days.](https://github.com/dominictarr/event-stream/issues/116) What was I thinking?
And `tidy` removes unused dependencies, `go get ./...` does not
An encryption api over unencrypted network connection 
Thanks for the feedback mate. But what the service does is not actually the point of this article. It could simply be an echo service. But thanks a lot for the attention :)
Hi! Any chance you could chime in on questions frm a GCP-newbie? [https://www.reddit.com/r/googlecloud/comments/a54rw4/coming\_frm\_docker\_swarm\_on\_baremetal\_hardware/](https://www.reddit.com/r/googlecloud/comments/a54rw4/coming_frm_docker_swarm_on_baremetal_hardware/)
No config? So, it's a tool for generating invalid certificates?
It doesn't show how to update modules and focuses on vendoring, which is not the default workflow.
I've tried it but it doesn't work when 2 out of 3 nodes go down and also when there's only one node in the cluster :/ etcd is less and less suitable for my project the more I learn how it works. What a bummer.
Take a look at [https://github.com/gobuffalo/pop](https://github.com/gobuffalo/pop) &amp;#x200B;
It is a tool for generating valid local certificate. It may not be used for production but it is good for development and testing.
You can just use Snakeoil cert.
Many thanks for the great article! If you want to avoid to implement to encoding yourself, the [crypt](https://github.com/simia-tech/crypt) library can help you out.
The problem in that issue was not Github but npm's versioning system coupled by some developers not using package-lock.json. Go is not vulnerable to either of these things because of `go.sum`.
I don't know of any tutorial, but I am curious if you have tried it and are stuck? I'm only a recent Jetbrains user, but I found the debugger support in Goland quite straitforward. I was able to both attach to an existing process, and to start the debugger directly on my project. The breakpoints in the gutter seemed to work. 
I think Go modules are super straight-forward already. &amp;#x200B; Most of the article is not useful and can be trimmed down to just the following lines. &amp;#x200B; &amp;#x200B; \`go mod init\` - starter &amp;#x200B; \`go build/get/&lt;anything that interacts with dependencies&gt;\` will automatically download your golang dependencies. &amp;#x200B; \`go mod tidy\` is a must-have to reap unused dependencies.
I admit I did not taught programming but I taught rollerblade skating, and the skill of _properly failing_ is what is always taught first—unless you actively want your rookies to harm themsevles. (Well, it's actually taught second, but the first is the skill of properly staying fixed—as opposed to drifting haphazardly—but that's not important here) ;-) I see too much people posting questions on SO which were not posted in the first place if they had error handling in the first place. So no, I don't buy your argument, sorry. 
Why would you commit such an atrocity? One of the big benefits of Go is that it compiles to a single binary that's statically typed. It runs the same everywhere. There's nothing to containerized. Go also cross compiles; you can make a Linux build on your Mac laptop. Why would you want to run a build script (that *downloads* dependencies from the internet) when you deploy? And you dockerize your Go project for development too? Why? How do you drop into a debugger when your setup requires you to run the thing via docker? Remove all the benefits of Go and get all the downsides of docker, so that you can pad your resume with more buzzwords!!!!!!111
Good one mate. Thanks for the feedback. Super constructive!
I've never used `go get -u ./...` as a prep step. It seems inefficient. 
No mate, your blog is promoting bad ideas that are super destructive.
Good to know mate. Thanks
So being slightly less argumentative than the original poster, one reason you might want to stick a go binary in a docker container is because you're using Kubernetes or Mesos as a mechanism to deploy or scale your application. The price of entry to those orchestration systems is having your app in a container.
What's wrong with the ones on Youtube?
Hi. Can you please tell me what problems have you run into? We have our documentation available here https://www.jetbrains.com/help/go/debugging-code.html Have you seen this already? Is there anything missing or that we can improve? Feel free to reach out to me or open an issue on our tracker https://youtrack.jetbrains.com/issues/Go Thank you.
Just for the records. This might be interesting and looks like best practice to me: [https://docs.docker.com/develop/develop-images/multistage-build/#before-multi-stage-builds](https://docs.docker.com/develop/develop-images/multistage-build/#before-multi-stage-builds)
You are absolutely correct about one of Go's strength being able to compile down to a single binary. Everything else is just completely dismissive. Dockerise your dev environment. Why? Because you may have a Redis connection, AWS resources and other things that your app relies on and you can't expect every developer to dive in and configure that every time. You might also care about things like CI/CD where your pipelines are going to need to be able to run tests and deployments for you. How do you do that? You Dockerise it. You might also care about the scalability of your service so you dockerise it to spine instances up/down on demand. &amp;#x200B; &amp;#x200B;
Yes I am being dismissive. It's not a bad thing. &gt; Because you may have a Redis connection WHY do you have a Redis connection? Redis is needed for Python and Ruby projects because these languages suck. If you're using Go you don't need to have a central Redis server. Even if you have to spawn multiple servers and sync some data between them, you can do that in many other ways that don't complicate your development setup. &gt; other things that your app relies on and you can't expect every developer to dive in and configure that every time. So set it up so that it requires minimum to no configuration. Docker itself is a thing that needs configuration every time. It's one of those things where you _think_ it makes things easy for you, but every now and then something goes wrong and you have to waste your time figuring out how docker works and what it's doing. 
Great work! IMHO I suggest change title to dockerise a Go service along external resources as title. 
This article leaves out that `go get -u ./...` will upgrade your current dependency versions. Most of the information in this article is slightly off in some way. I would recommend people use this article instead https://github.com/golang/go/wiki/Modules as it's the article the author apparently couldn't find. 
Nice one, I've done the same. Makes it much easier to scale in a Kubernetes/ECS cluster.
Just guessing: main.Example was not inlined in 1.9 but is in 1.11.
Just as when dealing with ssh or git, _not_ relying on the canonical binary causes a lot of issues. Even when the alternate implementation is ok-ish as is the case with ssh, the user interface issues (your app now has to deal with user keys, passwords, kerberos, jump hosts, proxy config, host pattern based config, and so on ...) result in poor adoption, and eventually maintenance begins to suffer. Also consider how nobody's using rsync in server mode, for security reasons. 99% of the time people run it with the local rsync initiating a remote rsync command through ssh. So you have to implement not just a native rsync but a native ssh. You'd be better off finding a way to run and package rsync and ssh on Windows (I know it's possible, BackupPC does that iirc) and control that à la `expect` (is there a good golang lib for that?)
 Hashing is NOT encryption. I know this is just a very trivial example, but could we please not call hashing encryption? Seriously, it is not that hard to use the correct terms.
that solves it. thanks! 
Most CIs allow you to cache certain folders between builds.
If GitHub goes down you'll be thankful for that vendordir.
Was actually going to be looking for something like this next week, many thanks Matt. 
I keep checking, but I haven't seen it yet.
TIL attack vector: offer to maintain high-use but abandoned projects (facepalm)
Like all of us, you too must face the fact that the battle of "the language is called Go and golang is just a search term" is long lost.
My experiences with other package managers taught me to vendor by default. Internet unstable? GitHub [down](https://status.github.com/messages/2018-10-23)? Github [throttling](https://developer.github.com/v3/#rate-limiting)? Repository [deleted](http://left-pad.io/)? Sorry can't build. Not to mention that if [malicious code](https://news.ycombinator.com/item?id=18534392) is found on a dependency I'm using, I can just revert `/vendor/lib` to previous version without depending on GitHub. I know there's caching but that's ephemeral, unreliable, and a miss forces the build to hit GitHub anyway. Caching is QoL, nothing more. I just wish they change `-mod=vendor` flag [to be the default](https://github.com/golang/go/issues/27227) when `/vendor` folder exists.