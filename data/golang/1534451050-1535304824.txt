I've been looking into Kotlin a lot lately but hadn't seen that it has channels yet, neat. Though I definitely prefer the shorter operators go has over function calls for sending / receiving.
Not quite the same, but the stage-2 proposal for JavaScript pipelines is something of a "specialized syntax" that plays nicely with possibly async streams of data. They're alike enough that the arrow points in the direction the data flows, it's just left to right. The syntax is way more primitive than `&lt;-` in go, but combine with observables and you could eg ow a similar approach as a buffered channel: const manyClick$ = click$ |&gt; bufferCount(100);
[Cmd.start()](https://golang.org/pkg/os/exec/#Cmd.Start) will start a process but not block on it finishing. It will return a handle to the process which you can [Cmd.Wait()](https://golang.org/pkg/os/exec/#Cmd.Wait) to block the thread until that process exits. With this you can start the 20 processes, add their results to a slice then loop of the slice waiting on each process to exit.
Don‘t know why you’re being downvoted, it’s a 404 for me as well.
If GOCACHE=off is going away, what is the recommended way of re-running tests without using the cached results? This is especially useful when debugging flaky tests. 
Ponylang is another fun Actor-based language.
Why pass the context itself down to the internal package, when the purpose of the context is merely to identify what to pass into fsm.FSM? Shouldn't your calls to that function from Service simply pass the appropriate logger instead? That would eliminate your import cycle.
Something like that ? ` package main import ( "log" "os/exec" "strconv" "sync" ) func main() { wg := sync.WaitGroup{} for i := 0; i &lt; 20; i++ { wg.Add(1) go func(i int) { _, err := exec.Command("sleep", strconv.Itoa(i+2)).Output() if err != nil { log.Println(err) wg.Done() return } log.Printf("Done from routine %d\n", i) wg.Done() }(i) } wg.Wait() log.Println("Done") } `
Clojure/Clojurescript both have channel implementations in the core.async library, but they're usable exactly as it would look like in Go.
Looks like the idiomatic way is `-count=1` https://stackoverflow.com/a/48882892
Rust has channels. Actually concurrency in Rust is very similar to the way it's done in Go. The channels are almost the same, Rust threads=goroutines, handling mutexes is similar but is a bit more involved/robust (as with most resource management in Rust).
[Lines 45-46](https://github.com/valasek/rajce-get/blob/master/rajce-get.go#L45-L46), go slices contain the length of the array so there is no need to track this separatly just `downloaded := len(URLs)` after the loop or where you require the length (seems you only use it in one place so could just inline it. [Line 54](https://github.com/valasek/rajce-get/blob/master/rajce-get.go#L54) I am not sure why you need this sleep, seems it will just slow down the program for no real reason? [Line 73](https://github.com/valasek/rajce-get/blob/master/rajce-get.go#L73): You should not use [gos default http client](https://medium.com/@nate510/don-t-use-go-s-default-http-client-4804cb19f779) for production applications, by default it does not set a timeout so for some connections problems it can hang indefinitely which can lead to leaking resources in long-running programs - though it is not going to be as big a problem in this application it is worth pointing out. [Line 67](https://github.com/valasek/rajce-get/blob/master/rajce-get.go#L67) you name your return parameters but never use their names. [Lines 78-82](https://github.com/valasek/rajce-get/blob/master/rajce-get.go#L78-L82) can be collapsed into `return io.Copy(out, resp.Body)`.
The GetLogger function returns the Logger in the context, which is only accessible via the main package's contextKeyLogger - I need the Logger in the FSM for some debug statements.
The fact that your parent package and the sub package requires the same context key is a design mistake. The object within the context should be passed separately, or context key can be in another subpackage in the parent, named as constants or something else of your choice. I’d go with the first option.
He is saying, pass the logger explicitly, instead of inside context. Do not put things inside context.
Crystal. Ther shold be a list somewhere on wikipedia actually.
Thank you [mdaffin](https://www.reddit.com/user/mdaffin). All comments incorporated.
Yes, precisely. The signature on the FSM function shouldn't involve a type defined in what needs to import it.
Erlang uses communication based on the (actor-model)[https://en.wikipedia.org/wiki/Actor_model].
But doesn't python suffer from the global interpreter-lock and is therefore inherently sequential?
If you are looking at a C-style language you might like D. It has message passing between threads and also supports co-routines in D called fibers. https://tour.dlang.org/tour/en/multithreading/message-passing
[https://www.ardanlabs.com/blog/2017/10/the-behavior-of-channels.html](https://www.ardanlabs.com/blog/2017/10/the-behavior-of-channels.html) &lt;-- He explains this "delay guarantee" property.
You can use a log-interface instead of relying on a concrete type to decouple.
 defer wg.Done() 
Oh God no. LinkedIn is following me around.
Yes, but that's only for threads. 
I think it's funny how Erlang is always cited as a language heavily based on the actor model, yet there's a talk^(\[0\]) of Joe Armstrong where he says he didn't do it intentionally, wasn't aware of such concept, and was only aware of it after he looked it up after being told so much referencing Erlang. \[0\] I wish I can find that talk. I can't remember its title, and there are a ton of talks by him on YouTube.
Go is also single-process by default. You have to change compiler flags to make it use multiple processes, and the Go team warns that this may be unstable and should never be used unless you benchmark your application and know what you're doing.
Thanks for that , I'll try and see if it works
I'm pretty sure that's wrong. How do you make go multi-process?
C# has built in generic collections that approximate them pretty well.
[Here's the flag](https://golang.org/pkg/runtime/#GOMAXPROCS). Although it looks like the default [changed in go 1.5](https://golang.org/doc/go1.5) to match the number of CPU cores, so I'm out of date.
Not a premium member? here's a [friend link for /r/golang](https://medium.com/commitlog/hello-go-3e207da92da0?source=friends_link&amp;sk=0cc8a781ab09b5d8b174230f9bdd1d42)
Yeah that's true and I guess that's an important distinction.
In the context where we're talking about python's multiprocessing, which _does_ involve processes, yes. Otherwise maybe not so much.
&gt; Preferably this would include a blockchain and neural network on a serverless architecture for maximum hype factor You forgot big data. Always include big data for maximum hypeness. 
All true, and I appreciate the info as I'm still very much learning. No select in stable, but it is in nightly.
I just want typed enums. Not `const`s with iota. Seems like a simple ask. 
There was a similar article I read a few months ago during the craze of overly complicated hello worlds. The author benchmarked the optimal number of goroutines. I can't seem to find it. Are you the same author I'm speaking of? Also I read the article and appreciate the friend link!
Likely the same gag/article, moved my stuff from my @username to a publication this week.
I'll second that. Using the same for my project and don't feel that I need anything else
I’ll just echo what others have already said. You don’t really need to use a web framework for go. The standard library is enough, along with Gorilla mux.
Hi Todd, I am finishing your web development with Go course on Udemy, how different is it from your course on Greater Commons? 
Reading your code vs reading what you want is a little confusing, you say you don't want any directories in the archive, but you have code that specifically adds directories to the archive if info.IsDir() { header.Name += "/" } Directories are based on the '/' in the filename. If you don't want directories, you can do something like this: // We don't want any directories, so just don't process them if info.IsDir() { return nil } header, err := zip.FileInfoHeader(info) if err != nil { return err } header.Method = zip.Deflate ... This will result in a "flat" archive structure, all files from all folders will be put into the root of the archive, I'm not sure if this is what you want or not. This could also result in duplicate files, if there are multiple file with the same name in different directories. This isn't a problem in the zip file, but if you try to extract them all to the same folder you will get filename conflicts. If rather, you just don't want the "source" directory in the archive, you just have to strip the first directory off the path when adding it to the archive header: // We don't want the source directory in the archive, so we skip it if path == source { return nil } // We're splitting the path by the directory separator... d := strings.Split(path, string(os.PathSeparator)) // and setting the filename to everything after the first directory header.Name = filepath.Join(d[1:]...) header.Method = zip.Deflate ...
If you have any code already, I would probably recommend to paste the main chunk of code you're dealing with in the go playground and have permalink in description to see what you're working with. Regarding you're issue, have you looked into using the http module to download the json data?
And this too
Even better: use interfaces
Looks good but the trouble is that all of the articles I have read in the last week as they were posted to /r/golang
&gt; dynamically reading the contents of the plugin directory, parsing the source files using go/parser and go/ast packages and getting a map of the structs implementing Filehoster and loop over them until the hostname matches This feels like trying to hit a small nail with a very big hammer (a.k.a over-engineering). I don't understand the problem completely (especially, I am not sure if your question is in fact an [XY problem](http://xyproblem.info/); however, perhaps your approach could benefit of [Go plugins](https://golang.org/pkg/plugin/). Be sure to understand all limitations (esp. no unloading, only Linux &amp; macOS) before deciding. 
Yes you're right fixed.
'package main import ( "bufio" "fmt" "net" "os" ) func main() { clientCount := 0 allClients := make(map[net.Conn]int) newConnections := make(chan net.Conn) deadConnections := make(chan net.Conn) messages := make(chan string) server, err := net.Listen("tcp", ":6000") if err != nil { fmt.Println(err) os.Exit(1) } go func() { for { conn, err := server.Accept() if err != nil { fmt.Println(err) os.Exit(1) } newConnections &lt;- conn } }() for { select { case conn := &lt;-newConnections: allClients[conn] = clientCount clientCount += 1 go func(conn net.Conn, clientId int) { scanner := bufio.NewScanner(conn) for scanner.Scan() { if err := scanner.Err(); err != nil { break } messages &lt;- scanner.Text() } deadConnections &lt;- conn }(conn, allClients[conn]) case message := &lt;-messages: for conn, _ := range allClients { go func(conn net.Conn, message string) { _, err := conn.Write([]byte(message)) if err != nil { deadConnections &lt;- conn } }(conn, message) } case conn := &lt;-deadConnections: delete(allClients, conn) } } }' 
connect with a few clients ... I can type and it appears when I hit enter on all the connected clients. nc hostip 6000 echo "this is some text" | nc serverip 6000 But if I try to route pub-vrs to it nc pub-vrs.adsbexchange.com 30005 | nc serverip 6000 Nothing ... 
&gt; However, setting the logger is the job of the main package's consumers, and thus, those will also need to import the third package, which I find ugly. The main package can provide a function delegating the log-setting. e.g. package mainpkg import "example.com/foo/internal/logctx" func WithLogger(ctx context.Context, l *log.Logger) context.Context { return logctx.WithLogger(ctx, l) }
&gt; The fact that your parent package and the sub package requires the same context key is a design mistake. For the question, there isn't really a difference between providing the context key or providing a `WithLogger` function or the like. Both require imports.
I find it immoral to make examples for beginners using one letter variables. It teaches them a way to code that will make them cry for hours not finding bugs when they start making programs. I am not referring to i and j but the other ones.
Hmm, valid point I suppose.
Unless logger is a type from another package like logrus, which is probably the case
What ?
It is only funny because of your user name, but my surprise’s reason obvious, using interfaces has nothing to do with the problem in my opinion
From real world experience, I am a go Dev and would advocate it anywhere however bear in mind: Oracle databases being as proprietary as they are, work best with oracle java drivers. That will likely be a big pain for you, to maintain performance between the server and the database with go. Then there are more old guard politics with go. For example I have been asked for security and code scans which don't really exist in Go but do for Java C# and the like. While they add little value in the Go world, some large corporations can't deploy without a green ticks next to the code scans box. Java is supported by oracle if you pay enough. That brings comfort to some larger organisations logic. Go is developed by Google and the community but not supported in the way of support contracts, which some corporations may not like. I don't know anything about your companies internal processes but it's worth seeing how hard you have to fight infosec teams on these points.
Also don't hesitate to post it in the #reviews channels on the gopher slack :)
AI/machine learning. Never forget those. Also mention VR and watch the investment dollars flow
And also only when the thread is executing python code. If code is backed by C (such as stdlib) then it is free to multithread without the GIL
Are you referring to replicating the SQL command COPY blah TO table WITH FORMAT('csv')? Something like that off the top of my head anyway. Does that work in a sql.Exec(stmnt, filepath)
No, Logger is an interface defined in the main package.
I see, then as the other person suggest(i believe), among other 2 options, you can also define an interface in the sub-package that has the functions from the logger you’d like to use, and use that interface type as the function argument
That is a valid approach, but now if I have not only context but other data structures that are used by both main package and the subpackage, the amount of this poor-person's re-exporting code grows with the size of shared data structures. I think what would be useful here is Rust's approach of re pub-ing a used module...
No it does not. Different packages are to abstract logic between the pckages, if your subpackage needs a key from any other importing pckage, your argument is wrong from the beginning. Context is for cancellations. Most of the time putting values inside a context is not a good idea. Here I don’t think it is even an idea, no offence. Context values are just always a mistake when used inter-packages
We were trying to maintain `go doc` and `godoc` both. It involved duplicating effort across several tools. Please see - https://github.com/golang/go/issues/25443 for more info. For 1.12 - we will add all remaining features from `godoc` to `go doc` so that nothing gets missed out. And from then on, `godoc` will only be a web server.
It's a line mentioned in the docs https://golang.org/cmd/go/#hdr-Test_packages. &gt; The idiomatic way to disable test caching explicitly is to use -count=1. 
Agreed on normal inter-package use, but I do not think it applies to *internal* subpackages, since they are still part of the same abstraction exported by the main package.
&gt; but now if I have not only context but other data structures that are used by both main package and the subpackage, the amount of this poor-person's re-exporting code grows with the size of shared data structures. Well, if that code grows too much, you should just put it in a public package and import that. There are no significant negative consequences of explicitly (as opposed to indirectly) important a package. I can understand why you wouldn't want to necessitate that for small things, but for small things, the existing approaches work just fine. There's also a larger point here about *why* Go forbids import cycles. People tend to treat that as a technical restriction and are then trying to work around that technical restriction in ways like this. But it's meant as a technical *help* to encourage good, layered design and have that checked by the compiler. Which has advantages for correctness and maintainability. So if the import-cycle restriction gets into your way too much, that usually indicates that your layer boundaries are leaky and you should rethink them. Tricking the compiler to no longer recognize the cyclic dependency in your design does little to actually alleviate it. But as I said, I understand why it's still useful for small things. Just "this doesn't scale" isn't a good argument, because if it needs to, the problem is the design.
Hmm .. what has this to do with lynx ? 
So you would suggest having a 'loggercontextandotherstuffusedinthissubtree' package aside from the main package? I have trouble naming it, though... common, params, ..., All these names look ugly toward the consumers of the main package who will then need to call params.WithLogger(ctx, log) instead of mainpackage.WithLogger(ctx, log)
Unfortunately, golang style guide *recommends* doing this. https://github.com/golang/go/wiki/CodeReviewComments#variable-names I hate it.
So the lesson is that splitting up code into internal subpackages requires writing the same boilerplate code (e.g. context value extraction) for every subpackage. I guess what I was trying to solve is encapsulation of structs, and was using subpackages to achieve it.
I have done the same thing many times. And this is what I realised in time, that a sub-package really needs to be completely independent on its domain. You should be able to imagine it being used by any other software in the world in a fitting purpose. If you cant do that your code needs to be in the same package.
Interesting! I completely agree with you. &gt; &gt; Prefer c to lineCount. Prefer i to sliceIndex. For anyone not reading the link, this is a quote from the guide. In my personal opinion, this is stupid advice. Noone has trouble quickly reading "lineCount" so they have to have it shortened to "c".
&gt; So you would suggest having a 'loggercontextandotherstuffusedinthissubtree' package aside from the main package? No, I'm not suggesting anything specific at this point, as I'm unclear what you are trying to do. I'm suggesting that if you are having a serious cyclically dependent design, that's a problem of the design, not of the compiler. Where the borders should be drawn and how things should be named is a different question. The posed problem is this: &gt; I recently introduced package context to pass an instance of a logger from the main package to the internal subpackage. The subpackage thus needs to import the main package in order to get the context key of the logger, thereby creating an import cycle. &gt; My current solution is to move the context stuff into a separate package that is both imported by the main package and the internal package. However, setting the logger is the job of the main package's consumers, and thus, those will also need to import the third package, which I find ugly. And in this situation, IMO the best solution is a) have the context-key/context helpers for the loggers in an internal package that is used solely as a crutch to get on with your job and b) re-export the one (or *maybe* two?) necessary symbols from that internal package (`WithLogger(context.Context, Logger) context.Context` and *maybe* `GetLogger(context.Context)`) into the main package, as I've shown above. This is because the problem as stated is small, it's just two trivial helpers and a functional constant. It's more pragmatic to choose the hackish solution for a tiny problem and get on with your life. If the problem becomes larger, that tradeoff changes and doing the right™ thing (redrawing your abstraction levels) is more important - and requires more knowledge of the specifics.
I disagree. For example (where I used exactly this), if I want to set the log sink and verbosity on a per-request basis, it seems like a perfectly appropriate (and arguably the *only*) solution to have an HTTP middleware parse out the request headers and put an appropriate logger in the context. The call path from one part of the package to another part of the package is not always under your control and when it isn't, `context.Context` is exactly the tool designed to pass around stack-scoped values.
In my experience, in my projects and also in open source projects I had the chance to dive in, i have always observed code related to a single http api, was always in a single package. If you do what you say, you either have to get the value with a string literal or create a separate constants pckage for context keys, no ?
Haskell has [Chans](http://hackage.haskell.org/package/base-4.11.1.0/docs/Control-Concurrent-Chan.html) and [MVars](https://hackage.haskell.org/package/base-4.11.1.0/docs/Control-Concurrent-MVar.html).
A package with import path "a/b/c" may import a package with import path "a/b/c/d", but it may be the other way around with no trouble. (Of course they cannot import each other at the same time.) IOW: There's no such thing called 'subpackage' in Go and thinking in that term indicates there's probably some substantial confusion around.
&gt; In my experience, in my projects and also in open source projects I had the chance to dive in, i have always observed code related to a single http api, was always in a single package. Never observed any usage of third-party middleware? &gt; If you do what you say, you either have to get the value with a string literal or create a separate constants pckage for context keys, no ? See [this](https://www.reddit.com/r/golang/comments/97wcso/internal_packages_avoiding_import_cycles/e4cem2e/) subthread. Yes, if you have only one context-thingy that you need to break a cycle with, creating a separate, internal package for that is pragmatic. If the concern becomes larger, redraw your boundaries. I think "a separate constants package" is a bad pattern (though justifiable if small, internal and only to break cycles). Rather, in this case, have a log-package that is concerned with creating and wiring up loggers and owns the context key. That naturally breaks the cycle *and* draws a sensible line of abstraction between layers. &gt; I also did extend context type for this and passed that That's functionally equivalent though. If you pass a context through third party code, it may call `context.WithValue`, erasing your type. So you still have to make it accessible via `ctx.Value` anyway.
- some people don't like to participate in comments - some people like curated feeds skipping the "which framework" posts - some people read articles many times (esp. if written by Dave Cheney) - some people don't like caramel - I don't like caramel
Maybe it was a bad idea to dumb down the problem that much. The real problem is here: [https://github.com/zrepl/zrepl/tree/replication\_rewrite/cmd/replication](https://github.com/zrepl/zrepl/tree/replication_rewrite/cmd/replication) package `replication` is what is used by the rest of the app, and subpackage `replication/common` is the package where I moved the context key and some other data structures that are used by both consumers of the main package and the internal subpackages `internal/mainfsm` and `internal/fsfsm`.
This looks nice, but it looks like there's been some copy/paste from vim-go without attribution to Fatih. https://github.com/hexdigest/gounit-vim/blob/master/plugin/vim-gounit.vim#L64-L76 https://github.com/fatih/vim-go/blob/master/plugin/go.vim#L163-L175
The issue is not immediately obvious, but I do has some advice. Log errors. It might be that the scanner fails of the Write fails, and it would just quietly continue. having it continue after outputting errors might give you some insight into what is going on. The scanner by default gives messages after `\r?\n`, are you sure [pub-vrs.adsbexchange.com](https://pub-vrs.adsbexchange.com) emits new lines? It might be that there is only one really long message (so it never gets forwarded to clients).
[removed]
Yes indeed Go uses just a single process but GOMAXPRCS number of threads. Go was able of parallel execution since before version 1.
i, j, k is fine
Well I disagree with you both! :-) The golang style guide provides excellent advice in this regard.. &gt; the further from its declaration that a name is used, the more descriptive the name must be IMO overly verbose variable naming makes it difficult to skim a block of code and figure out what it's doing. This is not uncommon advice - see also the [Linux Kernel style guide](https://www.kernel.org/doc/html/latest/process/coding-style.html#naming), for example. 
&gt; A third-party middleware if uses a value within the context, by definition dictates the key itself. Yes. But the point is, that if you, say, do package my type Ctx struct { context.Context log.Logger } func A(ctx *Ctx) { ctx.Log(…) } (which is how I understood your "extending context type"), then once you pass that through a middleware, you can no longer rely on it being a `*my.Ctx`. i.e. this doesn't work package thirdparty func Wrap(f func(context.Context)) T { // ... } type T struct { f func(context.Context) } func (t T) Do(ctx context.Context) { // Potentially modifying ctx t.f(ctx) } func (t T) Wrap(f func(context.Context) T { // … } package main func main() { l := log.New() ctx := &amp;my.Ctx{context.Background(), l} t := thirdparty.Wrap(Foo) t = t.Wrap(Bar) // Nope, type error t.Do(ctx) } func Foo(ctx context.Context) { myctx := ctx.(*my.Ctx) // Nope, failed type-assertion } func Bar(ctx *my.Ctx) { } i.e. you can't get around, in some way, putting the stuff into the context as a Value, once it passes through some third party code. And that's *exactly* the reason it exists. &gt; I think golang is terrible for http apis anyway. I disagree.
Well how much reuse you get is entirely up to how you architecture, develop and test your product. This is the actual challenge.
For those not following the progress on Go modules recently, Paul has been very active in reporting bugs and contributing to their design. This talk gives a nice overview of their current state, prior to Go 1.11 itself being released.
It looks to me like the issue is with this line: `if baseDir != "" {` `header.Name = filepath.Join(baseDir, strings.TrimPrefix(path, source))` `}` What is baseDir? You define it here: `baseDir = filepath.Base(source)` So, baseDir is the "last element of path" source, where source is "output/" - so baseDir is "output"... [header.Name](https://header.Name) is : `type FileHeader struct {` `// Name is the name of the file.` `// It must be a relative path, not start with a drive letter (e.g. C:),` `// and must use forward slashes instead of back slashes.` `Name` [`string`](https://golang.org/pkg/builtin/#string) So, if in output/ there is a file test.dat, you are taking a full path of something like output/test.dat, stripping off the 'output/' part, then adding it right back on again, then finally writing its name in the FileHeader as 'output/test.dat'... and therefore all the files in the zip are under the output folder. Because you are adding "output/" to the front of them all! (After stripping it off, which in this example is a perfect undoing of the prior action, but if the example had been called as zipit("ABGStuff/test/output/","ABG\_Gather\_Data.zip"), then the original filename would have been "ABGStuff/test/output/test.dat", the TrimPrefixed result would be "test.dat", and the filepath.Join result would be "output/test.dat". Just replace that line with `header.Name = strings.TrimPrefix(path, source)` Then the name would be just "test.dat". Directories under output would be correctly added as subdirectories in the zip file, while the files in output would appear at the top level in the zip file.
[removed]
Overly descriptive variable names are also a code smell for too much happening in a single method
Whis you have more port like this. Thanks
wouldn't this be drastically faster using a []rune instead of string and performing a reflect.DeepEqual() to compare? This would remove the construction of a string in every loop at least. 
I don't know if Kubernetes is not real enough then what will be. 
In my opinion, the distinguishing characteristic of channels is not the pipeline aspect. That can be implemented in almost any language quite trivially. The distinguishing characteristic is the "select" functionality, where you can wait for "the first of these things to happen". This is extremely useful, but relatively rarer. Some of the mentioned things in this discussion don't have this characteristic. Whether that disqualifies them depends on your perspective. Erlang, as mentioned, does not have channels, but it does have something fairly similar in practice, where an Erlang process can select on which of several types of incoming messages it may have, which in practice is a lot like a select. Erlang is kind of like the dual of Go; in Erlang, the endpoints are first-class and the communication channel is implicit, in Go the communication channel is first-class and the endpoints are implicit. Go gets more flexibility and probably better performance in the local machine case, but it put semantics on the communication channel that makes it impossible to work over the network. Erlang, by contrast, works well over the network, but has some weaknesses in the local use case. (In particular, it's hard in Erlang to efficiently create a "pool" of processes. In Go, you just use multiple readers from one channel, and the readers automatically pick up tasks as they become free. In Erlang, you end up with a central job manager that tries to guess when the pool workers are available, or has a heavyweight coordination mechanism. In practice this isn't a big deal but it is something you have to know.) Haskell has the capability to do this, although it is somewhat less used. There's several libraries that can do this in various combinations. There are also some environments that naturally give you this capability, or perhaps rather, force you to use it whether you like it or not. GUIs are based on a message pump, so you're generally forced to deal with arbitrary incoming input orders whether you like it or not. One of Microsoft Window's legitimate structural advantages over UNIX is they have a much richer ability to put things into the event loop than UNIX does. In Windows, you can easily wait on semaphores and other things that are not files to do something; in Unix, the epoll/kqueue/etc. implementations generally can only wait on file handles. All in all, the ability to select is definitely up-and-coming, and has roots going back decades, but is still surprisingly uncommon in languages.
If it's not obvious that your code is counting lines, you have worse problems than variable naming.
yep
I feel pretty amused too by that (especially since it seems to be an account that only posts caps and also isn't a bot). Anyway... I think the comment to use interfaces might help sometimes. Sometimes it doesn't. I'm an experienced C# dev with only a little professional Go work and I'm currently hacking together a personal site in Go, which has some glaring issues (e.g. removing tests in a refactor and needing to add them back in--but I only get a little time each week to work on this). Enough apologizing though. I'll get to my point: For my project, I had a \`database\` package with all my models and with providers as well as the storage logic for my datastore (badgerdb, but now could be anything after this refactor). When I decided that the database project was getting too ugly (imagine it eventually being 90% of a project. Gross!) I decided I need to to split out the basic application types like \`User\` or \`Group\` into a package just for core types and the database imports only that! The providers are interfaces in the same database package so that the implementation of an interface can reference the database struct (thus accessing other providers to make relations). The providers are implemented in repos and the store it implemented in badgerstore but could be implemented by other types of stores as well. Now, even though the database has repos / providers and the providers can use the database to get stuff from other providers / repos, there isn't a circular reference. This allowed me to separate my database definition, my storage mechanism, core types, and search (UserProvider embeds UserSearcher) into different packages and allows me to add alternative implementations, which will make it much easier to add tests back. Github: [https://github.com/PaluMacil/dwn](https://github.com/PaluMacil/dwn) I'm not deploying it at the moment, so there is some mess, but perhaps my example can help the specific thing mentioned here. package database func New(store Storer) \*Database { return &amp;Database{store: store} } type Database struct { store Storer Sessions SessionProvider Users UserProvider Groups GroupProvider UserGroups UserGroupProvider SetupInfo SetupInfoProvider Util UtilityProvider } func (db Database) Close() error { return db.store.Close() } type Item interface { Key() \[\]byte Prefix() \[\]byte } type Storer interface { Get(obj Item) (Item, error) Set(obj Item) error Delete(obj Item) error All(pfx \[\]byte, out \*\[\]Item, preload bool) error Count(pfx \[\]byte) (int, error) Close() error } type UtilityProvider interface { IsKeyNotFoundErr(err error) bool } On the other hand, some refactorings don't benefit from interfaces. When I decided to have a webserver type that holds my APIs, it needed the Application package for database and config. So did the API! And the application needed to have the webserver itself (and the config and the database) as fields. The answer to that was a quick glance through what everything used. Some things needed a specific branch of configuration. Most needed the database. I changed my code to pass those things instead of the application struct itself and suddenly I didn't need to depend upon application from somewhere else. This paragraph probably explains the type of figuring you can figure yourself already, but I figured I'd make sure you don't take interface advice too seriously and waste time and brainpower adding interfaces where they aren't helping anything.
Oh interesting, I've never seen that before. [Stackless Python](https://github.com/stackless-dev/stackless/wiki) and its [channels](https://github.com/stackless-dev/stackless/wiki/Channels) for anyone else that hasn't seen it. 
Stackless python is very Go-like. I still find it unfortunate that it was not adopted as standard rather than the whole async mess in Python 3. CCP Games' stack was built on it, and they had a stackless IO module that made network calls compatible with it.
"Since every Gopher is using the same source, the chance of a Gopher getting the correct guess is drastically reduced because the “hint” that could have given that Gopher the correct answer is given to another Gopher who makes another wrong guess with it." Eh, that's not how randomness works ;) Identical draws from the source will produce an identical shuffle. Much more interesting than math is performance! So let's fix it! The default source is safe for concurrent use as is correctly pointed out, but that also means locking is done behind the scene, so give each goroutine their own source. Secondly, while it might look parallel, the shuffling is completely sequential. This is due to how unbuffered channels work. While main is printing to the screen only a single gopher can proceed to shuffle a new string. The others are still waiting for main to pick up their proposed shuffle. Only send on the channel when you have the answer, and you'll see a massive speedup.
You dont need any why GO, really. Standard library got everything covered and is awsome! Otherwize GIN or CHI
My bad I missed this in the PR now there is a reference to Fatih and link to the license.
&gt; Eh, that's not how randomness works ;) Identical draws from the source will produce an identical shuffle. It does produce non-deterministic results, but yeah actually due to the race and not the source. &gt; The default source is safe for concurrent use as is correctly pointed out, but that also means locking is done behind the scene, so give each goroutine their own source. Yup. &gt; Secondly, while it might look parallel, the shuffling is completely sequential. This is due to how unbuffered channels work. While main is printing to the screen only a single gopher can proceed to shuffle a new string. The others are still waiting for main to pick up their proposed shuffle. Only send on the channel when you have the answer, and you'll see a massive speedup. Yup everything is I/O bound.
downloadFile should receive an http client rather than create one every time. Should probably also check the statuscode of the resp, if resp.StatusCode != http.StatusOK or whatever return some error.
If your messages are to big then use binary messages, or make them smaller. &gt; It makes sense to me conceptually that there will be less bloat etc when connecting this way. how? the protocol websocket would still have to be the same, a browser doesn't understand raw TCP.
You mean AR, right? VR is so last year...
The idea is you can't keep track of many single letter variables over bigger methods, but you can do that with descriptive names.
There should be a flag for medium subscription articles.
You can read the first few bytes of the message and decide where is needs to go.
Technically I'd say Ada merges both the concept of Channel and Go-routine into something called Tasks. 
Make sure you don't exhaust the processes your machines has if you're planning on executing programs in parallel.
Thanks for the suggestion
[removed]
i was adamant about descriptive names till i read this. intriguing idea
That is the issue I think I am having. The source does not put out a new line, I need to look for '}]}' ... That tells me the blast of data is ended and the next one is coming. How can I do that in Go?
The web is the same
This was probably a bad idea to share. It violates their insane T's &amp; C's
Yeah but. Do the investor shits know that?
100ms for your happy path is quite high for websocket latency, I think. You're making sure each connection has two goroutines, right (a reader and a writer)? My feeling is that some other part is your bottleneck... Not the sending down the wire, but the de/serialization, function blocking your loops, etc. If it's static data I think there is something to preserialize a message too, might be useful.
It's possible you've had bad caramel. Caramel, like toffee, is really annoying in how it sticks to crevices in one's teeth and such. I always thought it was mostly about properties of those things we just wouldn't be able to circumvent. However, a friend of mine into making peanut brittle and toffee uses super cold slabs of marble to cool it super rapidly. The result is a candy that crunches in a similar fashion as the original but doesn't stick to the teeth at all! Also, it seems to improve flavor a bit by reducing sugar falling out of solution and making the granular bits noticeable. I talked to my wife, who works in plastic additives, and she explained how cooling rapidly has the effect on changing how substances crystalize. I guess the big question remains whether this would work for caramel. It isn't something that is supposed to stop being sticky entirely like peanut brittle and toffee, so it might be something that cannot be improved. I'm just not sure.
&gt; 100ms for your happy path is quite high for websocket latency, I think. Meaning it's unreasonable to ask websocket to do this? or do you mean it's quite easy? &gt; You're making sure each connection has two goroutines, right (a reader and a writer)? Yup, one go routine fetches data from a WSGI server, passes data along via channel, another go routine creates a queue of messages and writes a singular message every 100msec via websocket. And then a for loop at the bottom (not go routine) to read messages from the client and keep connection alive. &gt; Not the sending down the wire, but the de/serialization, function blocking your loops, etc. If it's static data I think there is something to preserialize a message too, might be useful. Hmm, okay I'll try to look for some other bottle neck 
Thank you u/gobdgodb. Comments reviewed and merged.
To clarify: they shuffle and wait to successfully handoff the string through the channel prior to looping due to the unbuffered channel? So you have concurrent goroutines but they may be bound by the main goroutine which is printing the string since it needs to finish that loop before another can be retrieved.. Is that correct?
&gt; Unless the gorilla package has been updated in the last couple of years (and I say that precisely because it may have been and I don't know, I haven't looked), it's good to migrate off of it anyhow. Why?
Yes, but to clarify even further - the issue is not the print (though it is arguable the slowest part of the programme) - the issue is that progress is determined by reads from the channel.
https://medium.com/golangspec/in-depth-introduction-to-bufio-scanner-in-golang-55483bb689b4 So this looks like scanner could do what I need it to?
I think this is awesome. To me, at least, it speaks of the design coming along organically rather than it being forced and playing the "How many patterns can I stuff into this project" game.
Yes. You can write a splitFunc to do what you need. I briefly considered using encoding/json to determine when a complete json object was sent. But it the decode functions do not like bytes after an object, so that would not work.
&gt;header.Name = strings.TrimPrefix(path, source) So, i think i might have done a poor job of explaining what i needed, i'm sorry for that. The code is something i found on google and modified it just a tad, i was stuck on this part. So the go app is in /root/, the files i need to zip will always be in the directory /root/output. I need to get the files inside of /root/output/ and put them in an archive that is completely flat. I tried the code you gave me `header.Name = strings.TrimPrefix(path, source)` and when i open the archive, it still has a folder inside named "ABG\_Data\_Gather". Any ideas now? I really appreciate your help!
&gt; IMO overly verbose variable naming makes it difficult to skim a block of code to figure out what it's doing. I feel this is a relatively minor issue compared to having code that is indecipherable without it's original author, accompanying comment (which may well be misleading/outdated), or hours of research. The examples of "lineCounters" and "sliceIndices" are fairly forgiveable - every programmer in the world likely knows the "i as array index" convention. "tmp" is completely understandable as well - in the same manner that I don't expect anybody to spell out what "HTTP" or "FTP" stands for when they're naming a variable. But if I was given the choice between naming a variable "FooBarServiceAPIKey" and "fbskey", I'd pick the former every time. Sure it might seem obvious what "fbskey" is today. But it may not be so obvious in a year's time, and it definitely won't be obvious to any newcomers to your code base. There is no major downside to having lengthy, descriptive variable names (unless they've functionally become a paragraph). Most developers are working on devices with high-res displays capable of displaying vast amounts of code at once (so reading isn't that big an issue), and are likely using editors that have auto-complete (so typing them out isn't an issue either). 
That’s a very detailed answer and I have mixed feelings. I like things sticking to my teeth. I just don’t particularly enjoy milky caramel and similar flavours or the texture of soft caramel. The germans made something called “Riesen”, which is somewhat chocolatey but most definitely still caramel and it’s awesome because it just doesn’t have that sugary creamy taste like toffee and many other forms of caramel. Another which I am fine with: creme bruleé (literally burned sugar on top of custard). Mostly I avoid dulce la leche, any kind of caramel coffee, caramel tiramisu, flan,... the russian “birds milk” cake...
Doesn't seem to work with a stream. I'll write this in nodejs, Golang is apparently for people who know Golang. If I wanted to fight with C++ lacking documentation and obscure type-casting I'd go write things in C++ Thanks for the help.
Cant edit now :/
As of a couple of years ago, the API was flawed in some fundamental way that I can't remember exactly, but that would have required a backwards-incompatible change to make work. It mostly worked, but broke down if you pushed it too hard. I am trying to be clear that this may well have been fixed, so I am not accusing anyone.
That's interesting. I assumed the was concern over some bug or it being unmaintained.
I think that the locked, shared source of randomness is likely to be the hangup here; it would be fun to see a repeat with that issue resolved.
We're not a cult? Damn... I'm out then. Lol
Correct me if I'm wrong but "httprouter" is just a router. That's all it does. /u/pookalatka httprouter does support params. I have an example [here](https://github.com/junland/sled).
Are there languages that use context like go in their channels and routines?
Is there a way to just pass a incoming data stream? That's really what I need - not quite a proxy server, which I made and tested for one to one data shuttling, but similar.
Sadly, that's what modern web development requires. Http have become more of a compile target than a source code viewer. Without the latest features I was going to accept node as a necessity. But performance is still an priority for hugo, and you don't have to use any features you don't need. If you go by the unix philosophy of combining simple tools, then all you need is a md render, hugo uses blackfriday, so you just need that and cat on your headers and footers.
&gt; you don't have to use any features you don't need. Yes, but I still have to go through them to figure out how to do what I want to do. Basically, I want to point an app to a folder of md files and have it generate a simple, minimalist blog with date based categories and post pages. My ideal app for this case would have only two inputs: path to markdown directory and path to generated HTML. I can't do that without getting bogged down with a dozen Hugo specific concepts. 
If you're at all familiar with JS/node you could use [mardown-js](https://github.com/evilstreak/markdown-js)
How would i merge what i have with what you're giving me? Sorry, really in experienced with go. Tried a few different ways, and it always comes up with unused variables, etc
slowly getting somewhere ... package main import ( "fmt" "net" "bufio" "log" // "os" "bytes" ) func main() { hostName := "pub-vrs.adsbexchange.com" portNum := "32005" conn, err := net.Dial("tcp", hostName + ":" + portNum) TCPoutput := make(chan string) go func() { if err != nil { fmt.Println(err) return } fmt.Printf("Connection established between %s and localhost.\n", hostName) fmt.Printf("Remote Address : %s \n", conn.RemoteAddr().String()) fmt.Printf("Local Address : %s \n", conn.LocalAddr().String()) var buffer bytes.Buffer for { status, err := bufio.NewReader(conn).ReadString(']') if err != nil { log.Fatal(err) } buffer.WriteString(status) buffer.WriteString("}") TCPoutput &lt;- buffer.String() buffer.Reset() } }() for { msg := &lt;-TCPoutput fmt.Printf(msg) } } 
I’ve been pretty happy with https://github.com/peterbourgon/grender when Hugo has felt like overkill
I'll check it out tomorrow! Cheers!
For rendering JS driven web pages we've switched from Splash to Headless Chrome at https://github.com/slotix/dataflowkit. From our experience Headless chrome shows much better results than Splash. 
My experience coming from Python was somewhat similar. My first real project was a rewrite of a Python server that would receive DNS Dynamic Updates and update corresponding records in Route53. While writing it, it felt like my code was significantly more verbose. But when I had finished the port it was roughly the same lines of code and much more readable. Part of that was most likely due to it being a second iteration on an existing project. I've never had any issues with the Go version but I did have the Python version blow up a few times, which is what spurred the rewrite.
Please get rid of src directory. Just put packages right into the project root – import paths with "src" are damn ugly.
I’ve done his course and it’s good for anyone newish to programming to get into go.
With the solution I gave, you don't need `baseDir` anymore, so you can remove this code: info, err := os.Stat(source) if err != nil { return nil } var baseDir string if info.IsDir() { baseDir = filepath.Base(source) } then replace everything between your error check in the filepath.Walk function and your writer with the code I posted. The final code would be this: package main import ( "archive/zip" "io" "os" "path/filepath" ) func zipit(source, target string) error { zipfile, err := os.Create(target) if err != nil { return err } defer zipfile.Close() archive := zip.NewWriter(zipfile) defer archive.Close() filepath.Walk(source, func(path string, info os.FileInfo, err error) error { if err != nil { return err } // We don't want any directories, so just don't process them if info.IsDir() { return nil } header, err := zip.FileInfoHeader(info) if err != nil { return err } header.Method = zip.Deflate writer, err := archive.CreateHeader(header) if err != nil { return err } if info.IsDir() { return nil } file, err := os.Open(path) if err != nil { return err } defer file.Close() _, err = io.Copy(writer, file) return err }) return err } func main() { zipit("output/", "ABG_Gather_Data.zip") } 
I disagree. I just launched a small personal project and it was easy to ignore all the new stuff I wasn’t using and just do the part I wanted. It’s great, and it’s not bloated at all yet. 
Very nice! A long time ago I wanted a portable version of awk but didn't dare to go that far. So I came out with this: https://github.com/raff/glin 
How is a program written in "Go assembly" any different from any "other" assembly? Do you just want to link against the stdlib for e.g. the fmt.Printf func? Also, LLVM IR is higher level than any assembly, as abstracts away concepts such as typing and function calling conventions, so your example isn't even relevant to the question being asked.
How would you say sqlboiler compares to gnorm?
Why did you choose Go and not something else?
Personally I use [https://github.com/alecthomas/kingpin](https://github.com/alecthomas/kingpin) these days. But I've wrote a minimal package which uses the standard library [https://github.com/dc0d/clarg](https://github.com/dc0d/clarg) (examples: [https://godoc.org/github.com/dc0d/clarg](https://godoc.org/github.com/dc0d/clarg)).
Awesome! Looking forward to *fix* (*automagically* fix issues) and *hierarchical configuration*!
I haven't really had a look. It was created after sqlboiler. Their versus page is also incorrect when it compares the two libraries, I've filed an issue for that here: https://github.com/gnormal/gnorm/issues/103 The quickest of peeks seems to show that sqlboiler really generates an orm out of the box and is ready to go as soon as you go install it, it has templates already put together for you. It seems like gnorm's expectation is that you build your own. We also support 2 more databases than they do (sqlite3 and mssql). Though mssql support is a bit iffy. Honestly, they really look extremely similar, and I don't know why sqlboiler wasn't good enough for them.
https://github.com/google/subcommands Does everything you said.
You can use the \`"%q"\` formatting directive to see any non-space white space characters. I've had an issue where there were \`\\0\`'s at the end that were causing invalid matches. 
Nice! The one thing your package doesn't do though is the `help` command, I'd have to manually write it.
I did go through the [hugo quickstart tutorial](https://gohugo.io/getting-started/quick-start/) but left the step 3 to copy the ananke-theme out because it want to understand how the pieces fit together and how themes work. The documentation / guidance to create a theme does not have a simple path to follow. So i am still stuck at [Why is Hugo serving blank pages?](https://stackoverflow.com/questions/43555696) Do you know if there is a tutorial that continues to explain how to create a theme instead of copying one?
Short answer - yes. Here's how we manage it: - No rendering for authenticated users - Cache HTML response for a few minutes - None of our marketing pages - We drop the path parameters for requests, so there are a finite number of pages - The requests have a timeout before serving unrendered content, but it will still finish the request to cache the rendering - Once the page is loaded, it's an SPA with no reloads - so max one render per client - We use Chrome for other things - like PDF printing, analyzing external sites, and screenshotting - Kubernetes works really well for this. It lets us make sure that chrome doesn't eat up resources for high-priority processes. 
Nice work! I love the idea of no Javascript and that the forum is fast and snappy and uncomplicated.
I want to understand what it takes to use hugo - eventually we will have to create a theme because the customer already has a corporate design. To evaluate hugo one important aspect for me is if new developers find documentation that guides them to get things done. 
Is subjective ugliness the only downside? I rather have weird import paths than files and folders scattered all over the root directory. I am a java dev, I guess it's just what I am used to.
Thanks both! 
Not found
Fixed can you check now ?
Ye, thanks
That's why you start with an existing theme then once your done the basics you get into creating your theme based on that. Your putting the cart before the horse. One step at a time
Another vote for kingpin.
You can print it a byte-slice. This is more easy to compare or write your own function that print the diff of two strings.
https://github.com/aykevl/tinygo/issues/1
Very well said. Thanks for the share.
Have you tried Ansible or Fabric? For more complicated tasks I would use a messaging bus architecture using nats-streaming.
You seem to be confusing next steps with first steps
Rest calls are not cached by default, HTTP GET request might be by your server or proxy. First step should usually be to analyse your requests and identify if and where it takes too much time. If that is within your go code and it does expensive operations, this might be the best place to introduce caching (which usually comes with the payoff of potentially stale data though). I'd be surprised if serving a gRPC request from memory is slower than your HTTP GET request cached on the proxy. But if in doubt just measure it, then you can make an informed decision.
If you have trouble reading code just because the variable names are clear, you really have a problem.
Overly verbose is not the same as clear though. using "c" instead of "lineCount" means you are using unclear names compared to a fairly clear name. Do you think "lineCount" qualifies as an overly verbose variable name?
It is so responsive, nice.
Sorry I must have misunderstood how REST caching works. I Just found this post in github. https://github.com/grpc/grpc/issues/7945 Do you happen to know if this has been implemented for golang? I guess that would solve my problem.
Thanks for the comparison. I agree, they do look very similar. Wasn't sure what to use. Another similar option is xo/xo. How do you think xo/xo compares to sqlboiler?
It compares the same as gnorm does. They're all database first template generators. Just with different levels of out of the box templating vs how much you write yourself as well as the templating options/functions etc.
I'm not a core Go developer, so you should try submitting it to them. Can't help you, sorry.
Yep, gRPC or RPC even net/http library would help.
[I feel the same way](https://xkcd.com/927/) ;)
Fixed it. It's now a BSD 3-clause license, like the rest of Go.
[removed]
What do you mean by that? What could be unsafe about looking at the code?
[removed]
It's the other way around, Go is slower than C when calling a C function. And it's ~40x slower. It's mostly down to needing to switch stacks. https://dave.cheney.net/tag/cgo contains this. &gt; C doesn’t know anything about Go’s calling convention or growable stacks, so a call down to C code must record all the details of the goroutine stack, switch to the C stack, and run C code which has no knowledge of how it was invoked, or the larger Go runtime in charge of the program.
So, is this a fixed point number type with eight digits after period? Can this type display 0.1 without issues?
Why not just ssh? You can execute any ssh client in your go application then run the desired commands capture their output and print it out.
I was looking at this and realized I use your irc package in a project.
This looks like cancer
Looks pretty cool - congrats. 
Yeah, but what if you wrote it in Arc?
Welcome and congrats.
Looks gross. Gonna keep using dep until they figure this out.
I have ran into the same issue with [gocui](https://github.com/jroimartin/gocui). May be worth it to open an issue (if possible) to see if the package author could tag a new version. Just like PyPi or Crates package authors/maintainers are now responsible for releases.
&gt; Fortunately, fixing this is easy Nope, that's just the master branch of those projects, not what you happen to have in your GOPATH and what you were previously building against.
Your question isn't terribly specific. Which part of the project are you unsure about approaching in Go?
The article in OP only tells half of the story. The issue, #25860, actually propose that an interface literal can have a method being `nil`, and, the propasal auctually encorage such usage. That being said, the following is valid: type I interface{ Foo() Bar() } var x:=I{Foo:f} This can compule but calling `x.Bar``()` will panic. I would say this is terrible and almost against the principle of interfaces. And on the other hand, the inlining to `struct` literal is actually subtle. A struct literal asks for members but an interface literals takes methods, and methods in Go is not assignable. Feels strange to me.
If you have an existing project, run go mod init That will do the conversation from the existing lock file for you.
You're right, lesson learned: not posting stuff anymore while half asleep before going to bed. The links are fixed, but I don't know why Reddit doesn't accept ``` for code blocks on mobile.
Thank you! Are there any features you would like to see?
It is not implemented yet. Use an application-level caching, and save the call, too! Useing groupcache, you need to implement your own invalidation scheme, but you gain singleflight (only one request is sent to the vackebd, all client-side requests wait for that one and get the same response). gRPC caching would be nice, but it's not a show stopper: app-level caching is a little more work, but waay more efficient.
Support for Go 1.11 RC1 should be out for GoLand next week, if all goes well. Also, "You also still need GOROOT to be set" it's actually GOPATH that still has to be set. GOROOT is where Go is installed.
Thanks
Too many nested statements, eg: [main.go#L49](https://github.com/MichaelMeir/Go-Web/blob/53d1409b818acba99c44a0d6514e5f3f20a698f9/main.go#L49) [model/placeholder.go#L25](https://github.com/MichaelMeir/Go-Web/blob/53d1409b818acba99c44a0d6514e5f3f20a698f9/model/placeholder.go#L25) Checkout Golang [project layout](https://github.com/golang-standards/project-layout) rather than using the MVC structure from other languages. Your better off returning `(string, error)` on functions like [controller/cmd.go#L61](https://github.com/MichaelMeir/Go-Web/blob/53d1409b818acba99c44a0d6514e5f3f20a698f9/controller/cmd.go#L61) so you can just `return nil, err` instead of `return "LUA ERROR:" + err.Error()`. When you return a value do `return "your string value", nil`. Those are the three things that stood out most to me, I am sure others will offer further advice. Keep at it, as the more you write the better it will get.
Wow this is great , +1 for strings Builder package main import ( "fmt" "time" "os" "strconv" "strings" ) func main() { n,_ := strconv.Atoi(os.Args[1]) s :=time.Now() var b strings.Builder b.Grow(n) for i :=0;i&lt; n;i++ { b.WriteString("hello world") } fmt.Println("string builder time taken:",time.Since(s)) s = time.Now() var a string for i :=0;i&lt; n;i++ { a+="hello world" } fmt.Println("normal time taken:",time.Since(s)) } string builder time taken: 4.790328ms ( 2k times faster than normal , crazy) normal time taken: 10.938608145s
thank you, i will try to understand the golang project layout as i've never seen that before, but everything else ill try to fix right now!
It would be great to write some tests, if I am looking at using a new project lack of any testing is a big red flag for me. 
There were some problems with initial rendering of downloaded page. Sometimes there is no way to select needed elements in DOM. That can be fixed by entering selectors' values manually. But then scraping itself goes smoothly. We've tried to parse 10 pages in our tests both for Amazon and Yelp.
Why is it undesirable that you can rely on tests passing for your dependencies?
For the HPC or 'performance oriented' file, gollvm is probably a good bet. - https://go.googlesource.com/gollvm/
thanks, let me edit
Contention profiler couldn't profile RWMutex before 1.11. 
Interesting, this will replace then the fight for go dep and vgo?? 
My practical answer is that those tests have no chance of passing anyway. There's no C compiler and no databases involved. They are only usable in an integration test environment. This has more to do with sqlx than it does go modules, I suppose. My reasoned answer is more of a question - why does it not mirror the behavior of `go get`? That brings (and always has) only the runtime dependencies and fails to run its tests due to missing packages (which I'm totally OK with). I'm not sure what the big picture is here.
Godep and dep are two separate projects. Go modules and vgo are the same project. 
Why does it have to work like `go get`? Go modules already does many things that `go get` does not, this is just one of those things. The big picture is that when you download a dependency, the idea is that you'll be able to test that dependency as well. As you correctly noted, the fact that the tests won't pass on the average user's machine is due to what the sqlx team has done, not go modules. There's nothing go modules can do about that.
You probably want something like this: * [https://github.com/vadas-daniel/devTrack](https://github.com/vadas-daniel/devTrack) * [https://github.com/alanbaumgartner/Aurora](https://github.com/alanbaumgartner/Aurora) * [https://github.com/alepacheco/Client](https://github.com/alepacheco/Client) * [https://github.com/gavt45/GolangRAT](https://github.com/gavt45/GolangRAT) A handy way to find those is Github search: [https://github.com/search?q=Remote+Administration+Toolkit+language%3AGo&amp;type=Repositories](https://github.com/search?q=Remote+Administration+Toolkit+language%3AGo&amp;type=Repositories)
&gt; Why does it have to work like go get? it's called the principle of the least surprise. Most package managers out there make a distinction between dependencies and dev dependencies.
Just tried it out and seems to work fine on macOS. Nice work!
Thank you.
It seems like they rebranded vgo as go modules, which I think is very clever marketing. Not that I mind, since I really love the changes.
Most package managers don't use MVS. Most package managers use lock files. Ad populum arguments don't really matter to the Go team. You asked for an explanation. That's what it is. The Go team decided that pulling test dependencies, thus allowing you to (in theory) test your dependencies, was worth the time. And since it's globally cached, you're not really paying much for that extra download (in theory). This isn't like pulling NPM dev dependencies, for example.
Nice, reminds me of https://github.com/zxh0/jvm.go, and at one time I also wrote a JVM byte code to Go transpiled at https://github.com/cretz/goahead.
vgo was the name of the prototype that eventually turned into the formalized "go modules".
Good point! Is there an easy way to address this? I suppose you could use `replace` directives, but those require (IIRC) that the replaced module have a `go.mod`, which isn't the case for most projects yet.
I’m confused. What exactly is the input for this compiler? Many languages can be compiled to WebAssembly. Does this compile JavaScript to WebAssembly? Go? Rust? C? The fact that code can start execution while data is still being downloaded is very neat. 
Lindsay, you really created an alt to flame someone? Not very professional. 
It compiles wasm -&gt; native code from what it looks like
Forget python and embrace Go ,C , Java , C++ . No offense to pythonistas , I am just trying to promote C 
If not already, there should probably be something like `go mod -require [import path]@GOPATH` where it checks for a local version of the dep and uses it's current commit if found.
They won't list the client because if you ended up applying directly they would not get the commission.
Yes it's unrelated. I used the name already when I discovered it had been used before, but both projects seem to be dead so I don't think it's a big issue.
Honestly `go mod init` on an existing project should use the existing branch and commit for all dependancies currently used by the project. Looks like I'm playing around with this this weekend. 
Yes it would be nice to have the same experience, and maybe I'll get to that point. But remember that there still need to be a few more options than with regular cross compiling to select the chip vendor/type/version or subarch/memorymap. There is a *lot* more variation in microcontrollers than there is in regular desktop/mobile chips. In my experience, high performance and reduced binary size are often different sides of the same coin, as less instructions executed are good for both code size and performance. Only some more aggressive optimizations like you'd find in -O3 actually increase code size due to aggressive inlining, autovectorization etc. (counter-intuitively, some inlining can even reduce code size).
I'm curious what Russ thinks. /u/rsc
It seems https://github.com/mafredri/cdp/ works smoother with Chrome in Headless mode than Chromedp.
So cool, this could be super useful, looks like quite advanced.
[removed]
[removed]
thank you
vgo was (and still is) the prototype. Go modules is the feature. Vgo demonstrated what is now called Go modules, but they're separate things.
&gt; Ad populum arguments don't really matter to the Go team. but hubris does apparently.
It turns out `go mod vendor` only vendors the runtime dependencies, so I'm *still* not clear on what the big picture is. `go help mod vendor` produces this help text: &gt; Vendor resets the main module's vendor directory to include all packages needed to build and test all the main module's packages. &gt; It does not include test code for vendored packages. So what it seems to be is: 1. Download all runtime dependencies 2. Download test dependencies for all dependencies 3. Vendor runtime dependencies I guess that's okay? I don't mind the messy `go.mod`, but it is pretty unclear when scanning it visually. Do I *really* depend on `github.com/docker/docker`? All I see is `// indirect`, which *could* be a runtime dependency, or maybe not. The `go mod why` tool tells me that my main module does not depend on it, so I guess from that I can infer that it's a transitive test dependency? I think it's working okay for me now, but all in all, this has been overall confusing/negative experience. 
So as library authors, we ought to add a go.mod file to the repository that lists the module name and its dependencies? What if the library is already at version 2 and version 1 is not used/supported anymore? Can I keep the import path without the \`v2\` suffix?
Personally, I'd like the default init behavior to remain along with the added ability to manually/simply pin according to the current version found in GOPATH.
&gt; A major goal of modules is to reduce or eliminate the need for vendoring Is it? Seems assumptive of online packages being reliable. Recently the owner of go-bindata deleted their GitHub account and the account and package were re-created by somebody else with "same" code and different release tags. Digests will protect integrity but not e.g. the availability of your CI process. &gt; I think you and the tooling have differing expectations I guess! No biggie though, turns out there's other ways to understand the dependency profile (`go list` one liners are handy).
&gt; So as library authors, we ought to add a go.mod file to the repository that lists the module name and its dependencies? Yes, that's the idea. &gt; What if the library is already at version 2 and version 1 is not used/supported anymore? Can I keep the import path without the `v2` suffix? The suffix is not strictly mandatory. You could have a module version 42 without a suffix if you really want it. The suffix is more like a naming convention (but a *strong* suggestion.) The idea behind the suffix is to make it super clear that v2 and v3 are *incompatible* (as they should be according to semantic versioning) and allow both to be used simultaneously, if needed. This solves a huge problem with dependency management: the one where you have multiple dependencies that themselves depend on different, incompatible versions of a common package. So the Go project made a decision to *strongly* suggest a naming convention that will make it very clear. Still, no one is forced to use it (they should though.)
The initDatabase() function could use some love. The visual “haduken” should give it a way. You could definitely combine most of that logic rather than nesting if’s that deeply. 
Surely that can be distilled as: func (e *exchange) ListSessions() string { var sessions []string e.sessions.Range(func(key, _ interface{}) bool { sessions = append(sessions, k.(string)) }) return strings.Join(sessions, ",") } I'm also not convinced you should be using `sync.Map`, a regular map with a `RWMutex` seems fine to me. Sessions always require some level of locking, right?
You might use ffmpeg via the `exec` package, [this stackoverflow](https://askubuntu.com/questions/999271/ffmpeg-command-for-mpeg-ts-encoding) might be helpful. It also looks like there are a few existing ffmpeg wrapper libraries that might be useful.
Not really, other than the printing inside the function. Here's a better way: [https://play.golang.org/p/OV8LZ\_KfFyg](https://play.golang.org/p/OV8LZ_KfFyg)
So basically it sorta _decompiles_ wasm into go?
I'll suggest: https://github.com/emersion/go-imap
There is a request to fix this: https://github.com/golang/go/issues/24250 I think it will be addressed in Go 1.12. 
Why are you storing stuff in a `map` and then iterating? Why not concat within the `sync.Map` iteration? That would clean up the code a bit. As for generics, yeah, I wish Go had them too. However, I find that I don't need them too much if I rethink what I'm trying to accomplish and come up with an alternate approach (e.g. judicious use of interfaces). And yes, an RWMutex is your best bet for anything channels and `sync.Map` don't cover. I like to break up my code and use goroutines and channels for synchronization instead of maps (or other non-threadsafe structures) where possible. Also, I'm glad you're noticing that Go maps aren't threadsafe. I assumed they were back in Go &lt;1.5 (before they turned on multiple threads and the race detector) and had to fix a ton of broken code. My code is still littered with mutexes that I can probably eliminate through careful restructuring.
Maybe someday this will be supported directly by go modules. Maybe not. In general, it sounds like you're looking for a way to version control a build environment. A package manager can only do so much here. If it's a trivial env, a simple "env-init" script with a few "go get" commands will do the trick. For a non-trivial env, a docker image is a much better way to have a reproducable build or test environment.
I would love some contributors. https://github.com/jivesearch/jivesearch. It's a search engine so there are tons of instant answers that need to be added (ranging from easy to more difficult). Most of the code to-date has been written by me with only limited feedback so would love some code review even if you don't plan on contributing. Bonus points if you are even average at css/styling as that seems to be my weak point that I'm trying to improve. I am not a developer by nature so I am still learning and totally understand the learning curve to Go. Some of the instant answers: https://www.jivesearch.com/?q=jimi+hendrix https://www.jivesearch.com/?q=btc
No. Looking at the readme, it effectively "translates" one ISA (wasm) into another (x86-64). Thus, it turns wasm binaries into a native executable. 
Oh I see, that's what he meant with _'native code'_. I was a bit unsure.
My bad for the wording, I always think of executables as assembly instead of binary 😅
I'll suggest: [https://github.com/arkavo-com/cv-gui-automation](https://github.com/arkavo-com/cv-gui-automation)
Look into an in memory [approach](https://godoc.org/golang.org/x/time/rate#Limiter) or something like redis (tons of available go solutions) if you're scaling beyond a single server.
That's nice! I was toying with using something like that but didn't consider assigning the a and b vars like that. Cool!
Depends on your overall app architecture. As another commenter said, you could cache the counts in memory in your Go service. However, this would fail if you're using a distributed methodology. Each service instance would have its own cache and you don't want that. Also, the counts would be lost upon restart/redeploy. You could use a second, smaller and faster DB for those counts. Like a basic redis or memcached instance. Sounds like it would be a simple key-value store: APIKey -&gt; QueryCount. This would work in a distributed model and it would be fast without putting load on the actual DB where the core data lives.
Well, because Map.Range uses a closure, you need a way to receive it - to I could could this which is slightly, cleaner and more efficient if I just need the keys, but in many cases I need to build a structure containing details from the contained elements, not just a string. func (e *exchange) ListSessions() string { _s := "" var s = &amp;_s e.sessions.Range(func(key, value interface{}) bool { if len(*s)&gt;0 { *s += "," } *s += key.(string) return false }) return *s } I've never been a fan of using an interface when there is only a single implementation, except when defining a service. A lot of data structures don't fall into this category. It's more than just the generics - it would probably be fine if there was a way to have create thread safe maps and slices, probably with something like Java's ConcurrentHashMap semantics. I think the real problem is the Go memory model not having a concept like Java's volatile - it makes it very hard to create CopyOnWrite type structures, at least as far as I can see, and these are very important in a lot of cases.
This is more of an answer i was looking fore. Specifically Sync every x minutes. Any references i could use/guides? Thanks!
&gt; What exactly is the threshold for breaking IP law when it comes to software? Ask a lawyer. Just [running a program makes copies](http://digital-law-online.info/lpdi1.0/treatise20.html), and if you don't have permission to make copies, you might be breaking the law. 
&gt;Seems assumptive of online packages being reliable. Definitely agreed. The Go team made noises about possibly building a public mirror repository for that very reason. Another mitigation people use is to set up mirror repositories on internal git servers instead of depending on the public source repository directly. Or, of course, there's vendor- it just seems to me that vendor is kind of an afterthought for go modules. 
I’d recommend looking at using gstreamer. It looks like there’s [Go bindings](https://godoc.org/github.com/spreadspace/go-gstreamer). You should be able to use a pipeline such as filesrc location=&lt;your file&gt; ! qtdemux name=demux ! h264parse ! mpegtsmux name=mux ! filesink location=&lt;output&gt; demux. ! opusparse ! mux. Substitute opusparse for the appropriate audio codec parser that you’re using. Basically it’s just a pipeline of blocks, read from a file, demux the audio and video streams from mp4, demux them to TS and then write to a file. If you need to generate playlists and such for hls it looks like you can use [hlssink](https://stackoverflow.com/questions/34975851/i-want-to-perform-hls-http-live-streaming-using-gstreamer)
Any ideas how to acomplish any of that? i want a reference/documentation, anything i can read in depth. I'm a noobie, just started go 5 days ago, i have a handle on the basics. 
&gt; 100,000 UPDATE requests are sent to the PostgreSQL database, this would surely have a huge load/crash/or even miss some requests. What do you base that on ? That strikes me as very very very VERY incorrect. For example "On smaller AWS instances (say r4.xlarge / r4.2xlarge), this number could be in single-digit thousands and can increase to several 10s of thousands on larger instances. " Thats per second. 
That's something different, it fixes go install. OP wants to keep list of installed development tools as dependencies. 
occam
yup, to second this we use redis rate limiting, worst case scenario some of your customers may get to go over their limit for free.. oh well
1. Why you always return false, this will stop Range after the very first element (\`(...) If f returns false, range stops the iteration. \` &lt;- Godoc) 2. Use string slice instead of appending directly to string as in Go strings are immutable. Alternatively use Strings.Builder (yet better go with slices and return strings.Join(my-slice, ",") &lt;- which will handle your comma issues. 3. if you have to do type assertion on types, use "comma, ok" idiom to prevent against panic -&gt; [https://tour.golang.org/methods/15](https://tour.golang.org/methods/15) 
I don't think you need a pointer there. [Example](https://play.golang.org/p/9GpgTVMrWWT). For copy on write, you'd probably need to implement it yourself: type CowMap { orig map[string]interface{} copy map[string]interface{} } func (cow *CowMap) Get(k string) interface{} { if v, ok := cow.copy[k]; ok { return val } return s.orig[k] } // other methods Dup for any other types you want. If you only have a few, it's really not a big deal. And that's really the difference between Go and Java. Java is very much a "batteries included, plus the whole kitchen sync" language/platform, whereas Go instead goes with simplicity in the language and popular building blocks in the standard library. With that simplicity, you get goroutines and a pretty fast language without too much complexity. However, you obviously pay for it in lack of features and you end up writing some small structures yourself instead of relying on generics or the standard library to do it for you. Think of Go as C, but with a garbage collector, far fewer footguns, nice concurrency model (goroutines, channels, select), and some syntax sugar. It's not batteries included, but it's not completely bare either. There's talk about generics for Go 2, but I don't know if that's going to make it in our if Go 2 will even happen anytime soon. If you want a fancy, safe language with more language features but without green threads, check out Rust. It has syntax like `let x = Mutex&lt;YourType&gt;::new(); let data = x.lock()` (x gets auto unlocked when it leaves scope). However, it's far more complex than Go, and therefore isn't ideal for many of the types of services you'd write in Go.
Domink's megacheck.
There are valid reasons to implement limits, such as a for-pay API charged by request.
 zero false positives I don't think any tool could achieve this feature.
[removed]
That's what I was thinking, especially since it is 100k *per month* op is worried about.
proof of concept: https://play.golang.org/p/1o1yfGBbqSk
Look at https://github.com/golangci/golangci-lint It can run multiple linters, including go vet
how about this: https://play.golang.org/p/BHbtPGzr_N6 (proof-of-concept only)
Why not? You can access the AST in Go, so it should be possible.
https://github.com/golang/go/issues/26913#issuecomment-411976222
Is this what npm is all about in the js world? If so i want no part of it in Go! What a nightmare
Please use (and tell others to use) "go get" instead of "go mod edit -require", since it evaluates @master immediately and also makes sure to make other necessary changes. ('go help mod edit' says the same.) 
1. That was just an error - hadn't tested with more than one connection yet so did not see it. 2. The previous commenter showed a solution. I tried with the slice, but you still need a pointer to the slice due to the closure, but then yes you can use strings.Join to return it more simply. 3. just an internal routine that is working on known types - the only reason the casting is required is due to lack of generics. For reference, the simplest code appears to be: func (e *exchange) ListSessions() string { var s []string e.sessions.Range(func(key, value interface{}) bool { s = append(s,key.(string)) return true }) return strings.Join(s,",") } which works, but interestingly, if you change the code to: but interestingly, if you change the code to: func (e *exchange) ListSessions() string { var s string var count = 0 e.sessions.Range(func(key, value interface{}) bool { s += key.(string) + " " count++ return true }) fmt.Println("count is ",count) return s } it also works - which I don't see how. Even the count is printed as 1. These should be captured in the closure by value, but that does not seem to be the case ??? Like I said, Go newbie...
&gt; that makes use of the stdlib flag When I wrote https://github.com/christophberger/start (still pre-1.0 BTW, API can change), I deliberately opted for POSIX flag instead of Go-style flags. Why? Because they are a standard since a long time, and while Go-style flags (full words with single dash) are nice, they unfortunately add confusion. The point is that users do not know whether a given cli tool accepts POSIX flag (the norm outside Go) or Go-style flags. Should I type `-help`, `--help`, or `-h`? Will the tool understand `-help` as a word, or will it interpret this as `-h -e -l -p`? I see the point for Go-style flags but IMO they have not helped making using cli tools easier.
Pretty sure I figured it out, and that the closures work very differently than Java... duh. The local variables are captured as a reference, where as Java captures by value. It would seem they would need to be allocated on the heap always then??? If someone could point me to the technical impl details for Go closures I would appreciate it...
Reddit does not know the ``` syntax at all. You need to indent by four spaces to get code blocks.
Where is the article?
Good to know!
[removed]
You've basically identified the technical details already :) [Spec on function literals](https://golang.org/ref/spec#Function_literals)
Don't try to prematurely optimise unless you know you've got an issue, or it's easy to perform the optimisation. As NimChimspky points out, your usage doesn't actually sound like it's very much. If you're not confident, then write a simple test case. Create a table, and create a program that performs the updates you're considering doing, and see how well it performs. If it turns out that you do have a problem, then you can potentially batch these updates as hackop points out. You may also lose some data, but perhaps it won't matter. If you're syncing every couple of seconds, then it probably won't undermine your business model to give some people a few 'free' updates (if the service that is storing the counter in memory dies). But again, don't prematurely optimise. You can try and do clever things like this to reduce the number of updates once you've verified you actually have a performance issue. You may also want to be aware that not all SQL queries are born equal. If you're limiting customers by queries, some of the queries they initiate may take up considerably more resources than others. Tying it to API calls as you also hint at probably makes more sense, as you can then get a good idea of the resource consumption of each type of API call as people start to use your system.
You'd be surprised how performant Postgres would be in this scenario - If your worry in on the region of "100,000 UPDATE requests" per month, you'll be fine. Postgres (and most relational solutions) can handle A LOT. Just make sure you're indexing correctly.
&gt; What if the library is already at version 2 and version 1 is not used/supported anymore? Can I keep the import path without the `v2` suffix? As long as you're creating semver tags (e.g. `v2.1.0` or such), you'll be fine to not change your import path. Modules that use semver tags are handled automatically. If you really don't think anyone currently depends, or ever wants to depend, on v1, you can ignore it entirely and just tag `v2.x.x` that has a go.mod and be done. If someone is using v1, or you're not sure, you should also tag a `v1.x.x` that has a go mod. I recommend creating a branch (`release-v1` or whatever) where you backport any additional patches beyond the go.mod and tag v1 versions off of.
We use `gometalinter` with the following enabled linters: `golint`, `vet`, `lll`, `deadcode`, `staticcheck`, `ineffassign`. We explicitly exclude source files generated by codegen tools (`gomock, `easyjson` etc).
Oh man, this is what I wanted. Though I figured out myself. Thanks a lot
Hello, Welcome to Go. You do not want to ignore the errors returned. Check them and handle them in your code.
You can completely reject OOP and still have some kind of generic like feature. I mentioned generics since Go likes to play in the kiddy pool. If Go developers are willing to introduce concepts like Type Classes and Higher Kinded Types then all the power to them.
&gt; If say 10 Applications/Users have an API Query/Usage limit of 10,000; that means 100,000 UPDATE requests are sent to the PostgreSQL database, this would surely have a huge load/crash/or even miss some requests. (...) trigger 2,000 UPDATE commands to the database, putting a huge load It sounds like you're worrying about things before you've identified them as problems. Do some benchmarks and trials with your Postgres setup, and you'll find that burdening it with 100,000 updates a month is like burdening an elephant with a bag of M&amp;Ms. Even on a cheap $5/month VPS you'll likely find that you can swing 1,000 updates per second per core easily; my $8 Ramnode VPS just updated 100,000 user columns in 7.1 seconds when I tested it. Over the course of a month, 100,000 queries is nothing at all. Even made all at once, this isn't going to make Postgres crash or miss requests.
Use pgx's CipyFromReader, and keep it simple.
I'll grant that, but OP is asking about implementing limits as a form of defensive design which I think is the wrong approach, especially for a self described "noob". This is not a common use case which is why OP is having trouble finding any implementation examples. 
I think they should. I think these tools carry the same risks as actual dependencies. If we don't trust actual dependencies to auto update them and to verify them, I think we shouldn't trust such tools either. After all they run in CI with every build and carry the same risks. Other languages like Python, Ruby or Node have a notion of build dependencies so CI can install an additional set of deps compared to production. Go being statically typed, doesn't need any production dependencies so in a way all dependencies are always build dependencies. So we don't really need distinction between dev vs prod deps but I think we should have a way to specify additional deps not consumed directly by the resultant binary. Installing metalinter tool might be simple enough but complex projects might needs tons of such go dependencies/tools resulting in complex bash scripts or makefiles (which I've been doing so far). IMO such tools need similar guarantees as go modules provide. I don't want one of my team's devs to use a different build from CI. I want all tools to be verified, etc etc. I believe a tool is needed to handle these cases. Whether it's go modules or something else isn't that important to me but I'd like it if we had a canonical way of doing this and docker is not it. /u/rsc recommended such tools should be imported in a tools.go file that is not actually imported by the code. This is good enough for now as it makes go modules handle such cases. If go modules doesn't add additional support, I'd really like to see tools.go (or some other name) treated as a special case by the compiler just like `internal` or `vendor`. It would help create a standard for handling this case in the community. 
One way to do it is to follow DDD principles and split out by Domain, then follow SOLID principles and extract all your models and interfaces to api package which are then implemented in the domain layers. * api - provides your rest/grpc/sockets access * http * handler1 - calls services * handler2 * ... * grpc * ... * cmd * myapi * main.go - wire up all dependencies here * repo - implements repo interfaces from myapi per domain * sql * user - provides data from the store * ... * redis * ... * service - implements service interfaces from myapi per domain * myservice - calls repos * user * myapi - all shared models and interfaces live here split by domain type * user * ... What this will do is provide clean layers of abstraction wherein you can add/remove implementations of repos, services and api layers easily and wire everything up in your cmd main.go file. By coding to interfaces in myapi (some people put these models and interfaces in the root of the application) you remove all cross dependencies between downstream consumers of the application giving you a a very flat rather than deep dependency tree (this is a good thing!). Also by coding to interfaces and using DI you can easily switch your implementations for mock objects, enabling easier testing. This is just one way i've done it and it's worked very well for me. Some sources: [Golang Clean Architecutre](https://hackernoon.com/golang-clean-archithecture-efd6d7c43047) [SOLID go design](https://dave.cheney.net/2016/08/20/solid-go-design) [Hexagonal Architecutre](https://apiumhub.com/tech-blog-barcelona/hexagonal-architecture/)
\&gt; a simple shell command and/or script would do this easier I know, I'm doing this for my own benefit of learning Go, plus having a binary to just upload and run can be useful. I'm not sure what you mean by comparing the lowercase terms?
Don’t over engineer this. Postgres can easily easily easily handle that many updates. No need to build some hybrid and occasionally synchronized system.
This is great, a lot for me to work with, I'll give it a go.
You have a `v = true` where you meant `found = true` :)
On top of the other things pointed out, you could use a string array and append values to it instead of writing to a file. Assuming you don’t have hundreds of millions of files to scan, it should be more performant and portable
Thanks, corrected :)
&gt; but OP is asking about implementing limits as a form of defensive design which I think is the wrong approach And I'll happily grant that. :) You can't prevent a DOS in the system that is being DOS'd; if you need to prevent a DOS you need a dedicated system for that.
Go is designed to let you break up your solution into thousands of goroutines without worrying as much about the performance hit. Java still uses traditional threads (unless that's changed?), so you have to be careful with how you use threads. They're different models entirely, and I personally prefer Go's model to Java's. It does require a different approach in many cases to get the same effect, but I think it leads to simpler, more maintainable code, even if there's a little more of it. I'm really not familiar enough with financial exchanges, so I'm not sure what types of structures you're dealing with or what the requirements are. In my naive opinion, isn't it essentially a CRUD app with a solid database doing most of the synchronization? If so, it's a perfect candidate for Go IMO since you can have lots of independent pieces running in goroutines (user sessions, transactions in limbo, etc) and rely on optimizing the database to scale out performance.
Goroutines are fast, and channels are basically just a mutex and an array. I would benchmark two competing solutions and see which ends up being faster. If you post some code comparing solutions to the types of problems you run into, I'm sure I or someone else can give some insight. For example, if you just want to see a list of active sessions, would querying a database like Redis be simpler and fast enough? That's typically the use case for Redis (caching, sessions, etc). And I'm not really sure what you mean by "trading exchange". Is it like a bank backend? Stock brokerage? Video game trading system? All of these have different tradeoffs in terms of vertical and horizontal scaling, correctness proofs, etc.
&gt; what I consider ugly code Eye of the behold I suppose. &gt; table this for now and revisit after I post the code Sounds good. I'm sure there's a way to get a reasonably elegant design for whatever problem you're trying to solve.
there are some tools: like : * https://github.com/lukasmartinelli/pgfutter * https://github.com/prest/prest * https://github.com/dhax/go-base * ...
If you lowercase `value` on line 46 and `scan.Text()` on line 48/49, you can remove the need to iterate over every possible capitalization permutation of the term. Unless you specifically want to avoid caseings like `pAssWord`. It would be slightly faster, though not significantly so. 
I think I could just write 100k rows per month with a pen and paper myself, no need for a computer. 
&gt;I get you, I'll try it, thanks.
1. Why you use space instead unicode.IsSpace? 2. Why is it have a left trim but it's not have a right trim? (strBuffer) 3. Why is it not handle "\\r\\n"? 4. Substring is not efficient. 5. I think, Slugify must transliterate, normalize (nfkd) and remove not safe for urls symbols (e.g. Привет, как дела? =&gt; privet-kak-dela). Now it only removes not safe symbols (Привет, как дела? =&gt; ) It is made without love to unicode and efficiency. Sorry for criticism.
Non go code answer related. You should try to share your code on [github.com](https://github.com) (or any repository like in that manor) , that would allowed you many thinks * it let you have a control version of your code * it would let any here update your code at your approval * jump on the wagon of open source * add integration to keep your code running whit automation testing(ish)
&gt;https://github.com/lukasmartinelli/pgfutterhttps://github.com/prest/presthttps://github.com/dhax/go-base Thanks, will take a look at all of these
I think there should be a separation between source code and tooling. Yes you should document your tools somewhere, but having it be required increases technical debt of all your users unnecessarily. If you are releasing a library or a product, the tools you use is irrelevant to them. The only time it matters is when you are working in the same team or accepting contributions.
I can't contribute sockets being spelled wrong because I don't have write access to the repo, but it is and it drives me nuts looking at it 
You can fork and do a PR fixing the issue
If you don't mind paying a little, you could take a look at AWS Elastic Transcoder - check the go sdk
yeah, it was my first project with golang :)
&gt; The only issue I thought of, is that this is unpractical in Real-World usage. If say 10 Applications/Users have an API Query/Usage limit of 10,000; that means 100,000 UPDATE requests are sent to the PostgreSQL database, this would surely have a huge load/crash/or even miss some requests. Read these comments * Look into in-memory in-app or as a service like redis [comment1](https://www.reddit.com/r/golang/comments/98pkr1/go_postgresql_best_method_to_handle_query_limits/e4huj6r/) [comment2](https://www.reddit.com/r/golang/comments/98pkr1/go_postgresql_best_method_to_handle_query_limits/e4hu6xr/) * [Don't prematurely optimize](https://www.reddit.com/r/golang/comments/98pkr1/go_postgresql_best_method_to_handle_query_limits/e4imcg5/) * [100k is not a lot of requests](https://www.reddit.com/r/golang/comments/98pkr1/go_postgresql_best_method_to_handle_query_limits/e4ic6x5/) Essentially right now, you're not in a place to worry. You will have enough to handle in tangible requests so avoid decisions around intangibles as much as possible.
Thanks, spotted the issue and fixed it
[removed]
I had no idea they were different. That makes total sense.
 I agree, this would be a good middle ground.
Unfortunately httprouter doesn't support the standard Context API in its stable version yet, a patch was pulled in [February of this year](https://github.com/julienschmidt/httprouter/pull/147) but it's flagged as planned for httprouter version 2.x.
That is a good point, this really only works transitionally. I feel like it's a very natural build process for some, or at least just myself, right now to get a functioning MVP of sorts with out version control and then lock things down once it either gets complex enough during alpha stages or once you start transitioning towards locking down core APIs. It would be convenient, but by no means a requirement, for this dev process to be supported. But hey, maybe I just need to change my dev process for early project stages!
thank you :) 
Use of &lt;pre&gt;&lt;code&gt; Followed by *unformatted* code quite ruins the readers experience :-( 
My point is you ought to be able to pipe `go doc` HTML output through lynx to get something that can be displayed in a terminal, if you need Go documentation in a terminal.
Applied Craptography. If you're going to post stuff like this, OP, please put a big notice on the code saying that it is totally insecure.
In Japanese Yen, 99999999999 is less than a billion dollars. That's a bit of a tight range restriction, don't you think?
Sorry, maybe there is some misunderstanding. `go doc` does not generate HTML output. It just outputs text in the terminal. If you need Go documentation in the terminal, just use `go doc`.
And, yes, the repeated `if (err != nil)` after every function call may feel awkward at first... but it works well. And don't panic. Literally. Don't use it.
Any contribution is welcome. 
Thanks, I was totally confused (again).
It takes a bit of a jump with embedding context.Context - I'm not at all clear on why you need that to manage sessions.
Ah okay, didn't even know about that patch. Looks like Chi is the only router I've found that's still actively maintained and has Context support. Do you have any recommendations on other routers?
No, Chi's the one I use.
&gt;HashMap, TList and Set does not need to be a pointer I made them pointers to stop copying values back to caller(a whole struct) I've not used RWMutexes, will look on to it, thanks for tip. &gt;util.ToString foes not convert the interface to stribg, just returns it if it happens to be an interface. Either change the comment, or return fmt.Sprintf("%v", i) That utility function will be removed in future, TList will be re written only to hold strings so it will no longer need. **Thank you for feedback**
Yes RWMutex can help in here a lot, i opened an issue in [here](https://github.com/kasvith/kache/issues/17)
Well, sure, but how does that tie into sessions? I suppose you could be using an http request to get the session store, but a database or cache would be more likely and if you have really slow requests there it's unusual in itself. I would expect that it's more usual that fetching or updating the request would complete before the cancellation got through anyway?
[removed]
Never apologize for valid criticism. If you stay quite and others stay quite, how would a novice programmer know what's good from what's bad
I understand it now, thanks. This seems overly complex compared to Java's "everything is a reference" just to avoid some indirection, and it seems that in complex code, there is going to be lots of copying going on... or you have to pass everything with a pointer, including pointers to slices, etc. Gets pretty ugly IMO. I'm learning...
Awesome resources! Thank you very much! 
I see [go-socket.io](https://github.com/googollee/go-socket.io) is no longuer mantained.Besides using the Golang's net library like in [astaxie's](https://astaxie.gitbooks.io/build-web-application-with-golang/en/08.1.html) example, what other socket libraries are currently actively being supported?
&gt; just to avoid some indirection, This isn't really the sole reason. I tend to use value-types whenever that's the semantic I want (e.g. in immutable data structures or with vectors). I don't think "avoiding indirection" really is the sole reason Go uses value types. They are just easier to reason about sometimes. &gt; including pointers to slices You'll find that those are incredibly rare. Most functions that need to modify slices (e.g. `append`) instead return the modified slice.
Postgres has the ability to import to a table from a csv. https://www.postgresql.org/docs/current/static/sql-copy.html I usually just load the csv using psql, but you should be able to do it programmatically as well. From psql, something like `\copy table_name from 'some_csv.csv' with csv header`
The example for SplitCamelCase doesn't list the actual output of the function with that input.
Agreed. Frameworks are over-rated. Especially since you said that it’s a “small” project. Try it without a framework!
[Obligatory plug](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html) :)
Anything but iris: https://www.reddit.com/r/golang/comments/57w79c/why_you_really_should_stop_using_iris/
I haven't implemented it yet, but the calls to remote caches (redis, memcache) will likely look something like this: ``` var bs []byte errc := make(chan error) go func() { bs, err := redis.Bytes(conn.Do("GET", key)) errc &lt;- err } select { case &lt;-ctx.Done(): return nil, ctx.Err() case err := &lt;-errc: return bs, err } ``` Any network call should be cancelable, in case they timeout. &gt; if you have really slow requests there it's unusual in itself Exactly why you want context here. I'm with you in that the context API isn't the cleanest, but it's what we've got.
Are you sure you do not mix up things? Storing static files and compile (bind) them to the resulting binary is okayish. Storing dynamic files into a compiled binaries space is a very bad idea. Always split up the executing code and the source of truth. You want your software as a binary, maybe combine it with some kind of migrations or fixtures to restore a common "base" state that your application can work with and even compile those with packr into the binary, so a first startup loads all countries and stuff. But the DB must and should be a dynamic file that can be easily backuped, restored and modified by official tools for that given storage engine.
[removed]
A while back I posted here in relation to how I might approach a self modifying simulation in Go. I've hacked around a bit this summer to come up with a super rudimentary implementation of that, ending up with a basic simulation that recognises certain kinds of aggregates in the world and creates new types for them, then recompiles and restarts itself. The whole project is a bit (ok a lot) of a mess, but it was a fun learning experience and I wrote up a summary. Linked here is part one, and part two is here: [http://liza.io/roee-self-modifying-go-simulation-experiment---part-2/](http://liza.io/roee-self-modifying-go-simulation-experiment---part-2/) The code is here: [https://gitlab.com/drakonka/roee/](https://gitlab.com/drakonka/roee/)
In Go most methods take pointer receivers but you can assign pointers to variables so no ugliness at all. Most 'constructors' (NewXXX-function) in Go return pointers anyway. Use pointer receivers if you want to modify an object or if its larger than about 32 Byte (the copy becomes more expensive than the pointer-dereference, this varies between architectures and maybe even between processors). A cache miss is ofc still more expensive. buf := &amp;bytes.Buffer{} buf.WriteRune('µ') return buf.String() In this made up example the difference is just one character. One nice thing about Go is that it does escape analysis. So even when you create a literal with '&amp;' or even with 'new' it can figure out that it will not escape the function and places it on the stack so no allocation there. In this example however it either creates a copy on the heap when returning or it creates it directly on the heap then 'transforming' it to a string.
[removed]
What if i went with graphql only? That would reduce the complicity, later I can implement grpc between servers only, or even through it all together.
Sure, but why throw a new unknown into it again? Where do you see graphql, what does it solve in your small project, why do you need to couple it later with grpc? Graphql would just replace the REST layer, not solve anything on the grpc front. If you work with protobuf and grpc your target would be specific requests and responses, nothing you can mimic with a graph request, which is about limiting the response. How about you do a small prototype to do the internal traffic with grpc and then try to, at least, do a simple REST layer on top of that infrastructure?
I like Macaron, but it doesn't really fit it you want grpc I think.
Yep. It was just an example, but you get the idea.
I think it's a good thing. The core design and development should be done by a dedicated group. Then it can be open to public for subsequent tweaks, fixes, and improvements. It is possible to build a good compiler with "designed by a committee" approach but it's much, much harder to get it right.
Sorry, let me clarify the end result I would like to have a web interface for my project. This web interface can either use REST, or GraphQL. As you might know, grpc isn't really mature when it comes to having a react web interface. It is however very suitable and flexible when it comes to federating servers, (communication between servers). What I have been thinking of, is either to throw away grpc completely, and use GraphQL, since I see that it provides a better architecture for a react based web apps, compared with REST. Or have grpc for server to server communication, while having on the side, not as a layer, a GraphQL interface for the web app. the end result would be one binary, containing the server and my react/web interface files, which could be accessed when the server is running. I would appreciate some input on this if you don't mind Maybe calling it a simple project was an underestimate, and I'm sorry for the lack of information in the first place. 
A couple of points here. First, you are right. A Central Registry is not a panacea. You need what you call "vendoring", but also referred to as "proxy" or cache" on multiple levels. The most local one is keeping the dependencies on the local machine (i.e. vendoring) speeds up local builds and allow offline builds. An organziational-level registry is extremely important as well. There are a bunch of reasons for that: * It speeds up the resolution for the entire organization (except the poor first developer) and protects against the central registry (or GitHub if you use it directly) outages and degradation of service * It provides you the control of what the organization uses and why allowing a true RBAC of the dependencies * It serves as a target for deployment of your internal modules (the ones that you created and you don't want or can't share on GitHub) * It gives you an integration pipeline platform. The binaries that you built are published to the same registry as the modules, clearly creating the artifact-dependency relationships between the built binaries themselves and the modules which were used. The quality gates are established in the registry and the artifacts are promoted between them as the quality is assured for each step of the pipeline. * Deepening on your stack, you might need support for different technologies in your registry to establish the metadata (this docker image contains this go binary, uses that docker image as the base image and it is a part of that helm chart, this kind of things) Back to the question of the necessity for the central registry. There are different ways to implement central registries, which you can put on a scale: * On the bazaar side of it you'll find npm Registry (circa #unpublishgate) and what you use today: GitHub of individual contributors with personal repositories with modules. It's freedom and liberty for all, you decide if you can trust a certain module, you decide if you can trust the contributor, and the contributor decides when they want to take their stuff and leave, breaking the whole internet, or when they want to impersonate someone you trust and feed you with a malicious dependency. * One the cathedral side of it you'll find Maven Central, which will protect you from #unpublish gate, (probably) protect you from dependency spoofing and will give you a curated choice of dependencies. But it will also prevent you as a contributor to publish any type of experiments, unfinished work, or "not so ready for prime time" modules. * The golden middle is something any community, including Go, can truly benefit. Preserving the liberty of experimentation in people's personal spaces, but then cherry-picking what to be included in the curated space, guaranteeing the authenticity and immutability is a real win-win. ---------------- ^(Disclamer: I am with JFrog, the creator of Artifactory, a universal artifact repository which also supports Go modules.)
There are different ways to implement central registries, which you can put on a scale: * On the bazaar side of it you'll find npm Registry (circa #unpublishgate) and what you use today: GitHub of individual contributors with personal repositories with modules. It's freedom and liberty for all, you decide if you can trust a certain module, you decide if you can trust the contributor, and the contributor decides when they want to take their stuff and leave, breaking the whole internet, or when they want to impersonate someone you trust and feed you with a malicious dependency. * One the cathedral side of it you'll find Maven Central, which will protect you from #unpublish gate, (probably) protect you from dependency spoofing and will give you a curated choice of dependencies. But it will also prevent you as a contributor to publish any type of experiments, unfinished work, or "not so ready for prime time" modules. * The golden middle is something any community, including Go, can truly benefit. Preserving the liberty of experimentation in people's personal spaces, but then cherry-picking what to be included in the curated space, guaranteeing the authenticity and immutability is a real win-win.
Sounds cool, just make sure that you do not overdesign stuff. What services do require or would really benefit from grpc? You mention "one binary" as if this is the thing of everything. Do you just want to run different microservices developed into the same binary; and if so, why not just load balance them from the outside to do everything in the first place? Where are the bottlenecks, where is the data store and what kind of microservices do need access to it; because 20 microservices accessing the same postgres instance are 20x the connections and 20x more network traffic. You could always try to do a simple KISS approach: - Go binary containing REST facade and static packed web files, offering auth towards web and connecting everything inside. - Put a reverse proxy like varnish, traefik or envoy in front of it (depending on the requirement) to handle SSL termination, letsencrypt renews, balancing, optional maintanence routing and health checking into that. There is no need for your server to do load balancing or even content compression itself, your server should handle REST over HTTP and serve static files over HTTP. There are much more dynamic and production ready solutions for that (most even written in go). - Whatever grpc services you have connect in the lan, as strong types and binary protocol is much easier to handle the mess and muddy water that arrives at public REST apis. Maybe use something like quicktype.io if you want best of types and json results to integrate with typescript or such. The problem with grpc and web is multi-facetted. Unary calls do not offer much, binary protocols can break easily, protoc support for dynamic typed languages is still weak and breaks much more. Server streaming is nice, but where grpc shines is in bidirectional stuff. What use it grpc if you cant hold a connection to the server (with resume support) to stop reauthenticating every call. Maybe just skip it and use websockets with some kind of stack like centrifugo. So what is grpc good for right now, I'm unsure, you need to decide. You do not want to facade a DB, nor a simple HTTP service that can live with a POST request, returning simple texts (like mailtemplating). Do you want to use it for redis, if you could use any other good libary that speaks to it directly? So it would be your own services and there we are again: Is the cost to split your code into microservices worth the effort if you could just loadbalance whole facades that can live on their own and do most caches, calls, queries and queues in memory? Good thing for grpc would be something like billing, that must should be isolated from the web facing implementation. As to graphql: Its nice. Its also a huge timewaste if the only consumer is your own webapp. It gets nicer the larger the app and corporate environment around the whole app, but in the beginning I find it a total overkill, to document, maintain and to write. Maybe this helps, maybe not, just some of my experiences in a mid-tier env.
As other people mentioned, you can't have a database embedded in the binary that you modify, but you could embed a database that has been initialized. However, the first thing your application would do would be to use this static file to create a database somewhere. For example, the user's application data folder would be a good place for applications specific to a user. 
Updating major versions seems like it will be more cumbersome. I suppose that is part of the point.
Sorry, I didn't had time Yesterday to give you feedback on that, but you made it :). As bonus, some good article about interesting gotcha for slice: [https://www.calhoun.io/why-are-slices-sometimes-altered-when-passed-by-value-in-go/](https://www.calhoun.io/why-are-slices-sometimes-altered-when-passed-by-value-in-go/)
I should have clarified that I'm using the database as read-only, I'm just going to display quotes in a terminal, not modify the file in any way. My quotes.db was seeded by a program completely unrelated to the CLI app described in my post, that's why I thought embedding it was maybe a good way to have it available to my app.
&gt; Jeff I see what you did there. 
&gt;but you could embed a database that has been initialized. How can I do that? In my other comment I clarify that I only need to read from my database file, not write to it, so this seems helpful.
Copying isn't as inefficient as you seem to think it is, especially since here you're just copying an integer, which is the same size as a pointer. If your type were more complex, you'd probably have a `NewA` function returning a pointer, so you'd never be handling it directly. In that case, you could just put the `String` method on the pointer without issue.
You recommend working with an in-memory db instead of Bolt? Seems like string constant could work, but how do make so that Go compiles them to my binary, I'm working with around 400 quotes, should I just put them all in a *.go and read from there?
Only if you really need to have *one* file. Obviously you can ship your application together with a second file (your db, JSON, XML or custom format). Either hard-code it in or use a flag or env-variable to get its location. There is also a package to read in files at compile-time. But ofc you don't have read access then. https://github.com/jteeuwen/go-bindata This might be your best option but I don't know if it works with Bolt at all.
Yep, been every year. Should be a ton of fun
It's pretty fun, I attended Bill Kennedy's workshop last year and it was great.
You should definitely join the Slack channel, room #gophercon-denver, and find out. Everyone's talking about it there and you can get feedback on past events/attendee experience.
For 400 strings (or even 4000 or 40000) where you only need sequential or random access, I would just put them in []string array in a go file. If you have them in a different format you can use "go generate" or a script in any language to generate your "database" go file. Trying to use a database for this seems an overkill, especially if you want to be able to ship a single file executable. If you want your "users" to be able to modify/add to your "database" then you can read the list from a JSON or YAML file (but again, you could have your "default" list embedded in the executable). Question: since you said you built something using BoltDB, how are you getting random quotes out of the database ? 
Issue was fixed by this PR from an user [PR 17](https://github.com/kasvith/kache/pull/19)
You would do it with the same methods you've seen to embed html. They will probably expand the contents to a temp folder while they are being used. You will want to make sure you find one doing something like that since the database will probably need to create some sort of lock file even if only reading it.
I've been to all the previous ones except the first one (sadly). I was afraid I might end up missing this one, but luckily I will be going after all! :D
Looks like the simplest way is to put all my data hard-coded into an array, definitely going to solve all the headache I'm getting, but its going to require a lot of copy paste. \&gt;Question: since you said you built something using BoltDB, how are you getting random quotes out of the database ? Since I'm dealing with a very low amount of data, I just go trough all the key/value pairs in run-time and put every value in a string slice, after that I use the rand package to get a random index from the slice, something like this: quoteSlice := make(\[\]*string*, 0, 0) db.View(func(tx \*bolt.*Tx*) error { b := tx.Bucket(\[\]*byte*("Quotes")) c := b.Cursor() for k, v := c.First(); k != nil; k, v = c.Next() { quoteSlice = append(quoteSlice, string(v)) } return nil }) func RandomQuote(slice \[\]string) string { return slice\[rand.Intn(len(slice))\] }
Yes! It'll be my first one. First ever conference, for that matter. 
That "whole struct" is just two pointers (for each of them)! Copying two pointers vs. copying one pointer AND dereference one pointer - the latter is slower, I bet. 
Yeah it makes sense. It could be a Value
 ͡º ͜ʖ ͡º
Yes i noticed that too, could be a performance issue, can you open an issue so it can be fixed
Sure! I’ll try to free some time for this today
I really liked gosimple. Thanks.
Thanks for contribution 
(I've also added it to https://github.com/golang/go/wiki/ResearchPapers)
&gt; its going to require a lot of copy paste Not if you write a program to write the go code...
I was waiting for this comment.
&gt; Then it can be open to public for subsequent tweaks, fixes, and improvements. But they won't.
&gt; This seems overly complex compared to Java's "everything is a reference" lol, why do you think Java is getting value types soon? Are you going to claim Java is overly complex once that language gets value types as well? which language do you think was ill conceived here since Java is about to copy go?
Træfik seems to be a popular choice as a reverse proxy around here, and is written in go. My setup was not affected, but if anyone has a public dashboard for their services, they might want to consider reconfiguring it.
&gt; Is this what npm is all about in the js world? If so i want no part of it in Go! What a nightmare I didn't know the Go community was full of ignorant people.
I think `golang-ci-lint` wasn't around the time we've adopted `gotemalinter`. Another point is that we have a makefile which has the `check` target which is run by both our CI _and_ the devs locally—when they work on the project. 
From the idea it should work then, but it will most likely fail. Assuming you used the bolt db flag ReadOnly and packr for the embedding, you still have the problem that you do not have a "path" and bolt only sports the Open function which requires a filepath that will go through a [simple filesystem setup](https://github.com/boltdb/bolt/blob/9da31745363232bc1e27dbab3569e77383a51585/db.go#L174). So this will fail in production, when the files are packed and work in dev where a simple passthrough will happen. As raff99 said, if its a key value store, choose a simple text/json file, pack that and load it into memory on startup. Other approach would be to extract the boltdb to a ioutil.TempDir() path and work with it there.
A more interesting question is what prevents newcomers, like you, from searching the place before posting a question which has already been asked and answered gazillion of times.
Both the server side and client side code are not better, they are just simpler to use. See in the post the code before and after using h2conn.
How about this (T is your struct type): func wrap(s T[]) T[][] { return append([][]T{}, s) }
There's also https://godoc.org/github.com/uniplaces/carbon
Great work... thanks for sharing the link...
It gets really hard to coordinate with the public. There is a lot less churn in a small group.
There's something wrong with your link. I get a browser security warning. Here's [nist.gov CVE-2018-15598](https://nvd.nist.gov/vuln/detail/CVE-2018-15598). It looks like more of a documentatin/warning. If you enable the API without setting up authentication, you can expose your configuration to the public. 
You weren't really specific about the constraints, but [this is how I'd solve this](https://play.golang.org/p/B0dBRbpwkig). That's assuming: * The order should be preserved as much as possible. If that's not necessary, you can leave out the code concerned with `outs` and only use a map * The json objects all have the same structure. If they don't and you still want to bucket them by a field, the problem is - to the best of my knowledge - not really solvable with the stdlib json package. You'd have to resolve to manually parsing at least some of it yourself.
Carbon seems to be a full feature time toolkit. Thanks for sharing.
I think the main difference is function chain.
Thanks. Yeah, Order need not be preserved. [ { "class": "1", "name": "sam" }, { "class": "2", "name": "frodo" }, { "class": "1", "name": "oliver" } ]. gives different result. And yes, Json objects all have same structure. 
“It sounds like” — are you just making things up? There are over seven pages of Go 2 proposals and discussions on the public issue tracker: [https://github.com/golang/go/issues?q=is%3Aissue+is%3Aopen+label%3AGo2](https://github.com/golang/go/issues?q=is%3Aissue+is%3Aopen+label%3AGo2)
I think the first thing to know going in is you won't get everything in every talk. Some of it will just be over your head (unless you really proficient at Go, I suppose). This is typically even more true at an academic conference (which this isn't). Second, if you're not shy, talk to people during meals. It's interesting to see their background, etc. 
Done. Thanks for reminding.
Ouch. No need to be bitey about it. Time marches onwards, and frameworks fall in and out of favour. There's no harm in allowing people to ask familiar questions every so often - there may even be surprising new answers for the rest of us to look at. I feel like the majority of this thread is antsy about this, not because OP is is "posting a question which has already been asked and answered gazillion of times", but because OP wants to use a framework (likely imagining a RoR-style framework), and the majority of this community just outright hates the notion of such frameworks. 
Yeah, i've plans to implement snapshots to persist data to disk too
[removed]
[removed]
Scrapinghub's splash was a good option before Headless Chrome. We use in our Datаflow kit CDP bindings from https://github.com/mafredri/cdp It works perfectly with Headless Chrome Docker image.
I know, but shouldn't Go change the A to &amp;A automatically in the first case? It seems backwards. If I put the String() on A then it works whether I pass an A or \*A, if I put the method on \*A, then it only works when I pass an \*A. If the method takes an \*A, and I pass an A, why doesn't go just make a copy (to protect), and pass a pointer to the copy? That enforces the safety that @TheMerovius says is required.
"Constants can be character, string, boolean, or numeric values." I know nothing, but suspect it's limited to values that don't require any allocations/startup computation.
Wow. You know your product has made it when it gets CVEs. 
hey thanks for showing your repo! Looks like I'm going with this route then :)
The previous question about which web framework to pick [was asked five days ago](https://www.reddit.com/r/golang/comments/98wii9/what_web_framework_would_you_suggest/). You could easily scroll the list of posts of this subreddit down to search for more, and I assure you, the distance between any two adjacent questions about which web framework to pick won't be larger than a dozen days. I mean, with all due respect to your point of view, I think your argument about re-asking in a refreshed context does not hold water. Still, you're correct in that my phrasing could indeed have been less toxic.
just a general note on the 'time' package which all these libs import: time: LoadLocation doesn't work on windows if Go is not installed [https://github.com/golang/go/issues/21881](https://github.com/golang/go/issues/21881)
The thing with constant values in go and many other languages is likely that they can be inlined where they are used, so there is no actual variable look-up at runtime, which performance slightly better than finding a variable somewhere else on the stack. This is at least the speculation on my part, I have no idea if that is actually the reason.
`const` doesn't just mean read-only. There is no equivalent in Go to the `final` keyword of other languages, you may confuse both concepts. `const` means the memory is allocated in the text segment of the binary. There was a link here recently on Go's memory management: https://www.reddit.com/r/golang/comments/98qz4y/go_memory_management/ that explains the works of this. Having understood binary file format and memory layout it makes sense which types can be constants and which can not. 
Because it's not useful enough to add to the language. You can just use a regular map and never modify it, or use enums and switch statements. 
Looks like there are ~3,000 of these dashboards exposed on the Internet: https://www.shodan.io/report/waW9qNoX https://www.shodan.io/search?query=http.title%3Atraefik
However, you might be ready for [Nailed It](https://www.netflix.com/title/80179138) !!
Very useful, thanks!
Cool thanks. We've been experimenting with commit hooks and have found that 2 seconds is about the maximum amount of time a developer is willing to wait for a hook to execute. I'm going to be investigating the speed of golang-ci-lint, especially with the option of checking only what's changed since the last commit, as a commit hook. I looked at gometalinter as well, but like you said, I did find it to be slow.
Thanks for sharing. I now realize I need gofillstruct in vscode. 
I think this is a cool idea for a learning exercise. First of all if you want to try this in Go, I think you should try using channels first. I don't think it is a good idea to ignore the core concurrency primitive in Go (sync.Map wasn't even introduced until go 1.9!) on the grounds it might not be useful/fast enough right of the bat (especially as a learning exercise!). So lets look at how we might do this with channels first. First lets sketch out some core structures for an exchange. For now the exchange will have one stock. type Trade struct { User *User Price float32 } type Exchange struct { Bids, Asks []Trade } type User struct{} func (u *User) Respond(s string) { fmt.Println("user response:", s) } The idea with channels is to have one channel own the mutable state, and have actions that need it run on that channel. For now we'll have the actions just be functions, and set up a loop to process them: var TradeChan = make(chan func(*Exchange)) func StartExchange() { e := Exchange{} for { f := &lt;-TradeChan f(&amp;e) } } Now we can implement an AddBuy() function: func AddBuy(user *User, price float32) { TradeChan &lt;- func(e *Exchange) { e.Bids = append(e.Bids, Trade{user, price}) go user.Respond("bid added") } } Let's test it: func main() { go StartExchange() u := &amp;User{} AddBuy(u, 100) } // output: "user response: bid added" Link to try it out: https://play.golang.org/p/qdztJR3oxtx Hopefully that's enough to get you started! There's a lot of things missing, like the StartExchange() function needs to see where the bids and asks overlap in order to execute transactions. But hopefully you can see the general way you might use channels to do this sort of problem. If you are worried about performance, channels actually have some nice properties compared to using locks, since sending on a channel doesn't (necessarily) block the sending goroutine (and I think you will otherwise end up using at least some locks, at least for parts like finding the Bid/Ask overlap). 
This is very interesting!
With give this a crack on windows tomorrow if you still need?
I'd like to add that for your example specifically about active sessions, I'd try putting them in a goroutine too. The function could be something like: // called in SessionManager goroutine func (sm *SessionManager) printSessions () { sliceCopy := make([]*Session, len(sm.ActiveSessions)) copy(sliceCopy, sm.ActiveSessions) go func() { // print out slices here using sliceCopy }() } The disadvantage is that you couldn't run the slice copy in parallel (although string processing can be). But the advantage is that, if you restrict access to one goroutine, you might be able to just copy a []*Session instead of using sync.Map.Range(). I bet the former operation might be an order of magnitude faster (no hash table overhead, atomic operation overhead, callback overhead (I think currently all registers are spilled to the stack, although I don't know if the compiler would inline there...)). So I think doing a performance comparison between the different approaches is not straightforward... sure, there is some overhead to using channels so one goroutine is dealing with the mutable state. But if the state is local to the goroutine, the code running in it can use the most efficient (non-thread safe) data structure and algorithms, doesn't have to add synchronization etc. You mentioned elsewhere using channels as iterators being relatively slow (to be fair, I also wouldn't use them as iterators). But just looping over a slice normally is insanely fast, it's only a few CPU instructions. I think what really matters is if channels are slow relative to the actual bottlenecks in your program. For example, if using a channel is 1/100th the overhead of receiving the data from the network you are acting on, then that overhead probably doesn't matter much. Part of the issue with channels is that the receiving goroutine may be running in a separate thread (I think some of the small benchmarks are faster if you limit Go to one OS thread). They aren't like iterators, since the other side of the channel can be running asynchronously. But in a network program, you actually may be benefiting from that and it may make your program faster. Like the stock exchange example, if you just use locks you may be blocking code receiving trades from the network, where with channels some of that code can be running in parallel to the code actually computing the trades.
If you can't be bothered to write a little code to try out your own idea, why should we be bothered to help you design your program?
My understanding is that the best practice is to generate your own name. Otherwise, you risk playing whack-a-mole every time you learn of a new nefarious filename trick.
Rename to guid, store original name in db
Could you use this to generate UUIDs? [https://github.com/kubernetes/apimachinery/tree/master/pkg/util/uuid](https://github.com/kubernetes/apimachinery/tree/master/pkg/util/uuid)
So Rust?
my advice is to use a fork of satori's, https://github.com/gofrs/uuid, it's under heavy development by a gopher community and has critical bug fixes that were taking too long to be made in satori's...
I was happy when they gave me netfilter in go, now you're givng me tun/tap in go... I'm going to need a tissue.
Why not the sha- 256? 
I would save the files named as the sha256 hash of their content and store any metadata in a database along with the hash for lookup.
It honestly looks less like a Go issue and more like an issue on your producer. What's on the other end of the websocket? What you're demonstrating looks exactly like what happens with floating point numbers where they begin to lose precision. Moving from an odd number to an even number would be the first loss of precision as a floating point number grows large. These numbers are not large enough for precision errors to be occurring with 64-bit floats, but it's possible that you're doing more math on the other end of the websocket and you're brushing against rounding errors.
The values on the other end are just a map[string]json.RawMessage (basically a series of JSONs). There's no math going on as these values are archival data just meant for development purposes. The values pasted above are just the timestamp values used to fetch the next payload (v["timestamp"]). As for printing the values, Ive printed the entirety of the queue's values and all it does is show me that it will randomly begin skipping values. One caveat is that most of the values come in from the server are simple JSON files with 200 bytes of data... but when the skip begins happening, it's a 4KB json file with an extra slice inside (think of a hash table with another hash table as one of the values) 
Yeah, could even avoid duplicates that way
You could pull out [WireShark](https://www.wireshark.org/) and look at the raw network traffic, but I find it hard to believe that Go's channels are the problem here. &gt; As for printing the values, Ive printed the entirety of the queue's values and all it does is show me that it will randomly begin skipping values. This isn't quite what I was asking about. You seem to think the channels are broken, so I was saying you should print the values out before they get pushed into the channel, and before they get pushed into your queue. *If* we assume the channels are working correctly (as they have been for many years and many thousands of other developers), then the problem has to be somewhere else in the code, or on the other end of that network connection. As the Sherlock Holmes quote says, "when you have eliminated the impossible, whatever remains, however improbable, must be the truth." So, the first step in debugging is to eliminate the impossible. For our purposes, it's far more likely that whatever is broken is something other than Go's built-in channels.
Ah, yeah I see. I've also verified these values are correct and follow the proper, expected order: ChanV: 1533709258576 queue has finished loading up: 100 ChanV: 1533709258676 ChanV: 1533709258776 ChanV: 1533709258876 ChanV: 1533709258976 ChanV: 1533709259076 ChanV: 1533709259176 ChanV: 1533709259276 ChanV: 1533709259376 ChanV: 1533709259476 ChanV: 1533709259576 ChanV: 1533709259676 
satori/go.uuid should no longer be used.
Interesting. How is the second `go func()` actually looping? It looks like it would load the queue once, do a single `select`, and then exit? I would also recommend avoiding the intermediate queue altogether. I would just build a [buffered channel](https://tour.golang.org/concurrency/3) and let that handle the queuing. Then I would have the second `go func()` just process values off of that directly.
Awesome! I've been thinking about building something like this. Look forward to reading through it.
it's hard to see how all the pieces fit together from the code you posted. It seems like the entire queue would get filled and then dropped with each tick, and only a single item would get sent. Maybe someone else will be able to see what's going on better than I can.
Yeah, thanks for the help. I did omit that the data coming in from wsgi() gets unmarshaled into the map[string]json.RawMessage, though I'm not sure this is important. As for the queue getting emptied, I've thought of that as well, so I print out the len(queue) for each tick and it stays consistent, even with the skipping data. Very confusing...
1. GUID should be globally unique already 2. What happens when the file is updated? Re-hash? Now there's a new filename, has to be updated in db, any existing links have to be updated
How come?
I suppose it depends on whether you're trying to represent a versioned history of an individual file, as opposed to distinct entries per each file uploaded.
It's a community effort to keep critical packages maintained, starting with satori's uuid package (which was beginning to fall into disrepair). You can read the announcement here: [https://medium.com/@theckman/keeping-important-go-packages-alive-5242917f83e8](https://medium.com/@theckman/keeping-important-go-packages-alive-5242917f83e8)
Forgive my ignorance, but what's the use case for something like this?
xattr?
A map in Go is a runtime initialized value. Creating a map involves a lot os operations like creating space on the heap, creating a salt, hashing the keys and finally adding the key-value pairs to the buckets. Even simpler values like byte-slices can't be const in Go as you are not allowed to take pointers to the '.text' section of the binary. This is technically possible (like in C) but writing to them would be undefined behaviour. Go is explicit here if you want them to be embedded in your binary or initialized at runtime which avoids any ambiguity for compiler optimizations.
here's the full post about the fork: https://medium.com/@theckman/keeping-important-go-packages-alive-5242917f83e8 tldr: satori's go.uuid was not generating unique IDs
Thanks for the link!
That seems pretty critical
The `case v := valuesChan:` part doesn't make any sense to me. First it should be `case v := &lt;-valuesChan:`, secondly even that doesn't make any sense because you already read stuff from `valuesChan` to `queue` above and didn't read them from `queue`, why do you read stuff from `valuesChan` again and appending to the `queue` and read from `queue`? That way the `queue` can never be read fully.
That's just a typo from the semi-psuedo code.. As for the second bit, I'm not sure what you mean. The channel puts 100 values onto the queue, and then that loop ends and then it begins pulling off the channel whenever a new value comes in. Not sure your question is 
Thanks, the more eyes, the better. &amp;#x200B;
Store it in non public location renamed into user-guid or something and in dB record of its original name and disk location. Your app should have like a “system” or “priv” directory that is separate to “public” you can write to. Storing files in dB will bite your ass sooner than you think. If you have more than one box make this as a start an nfs mount and later on you can move to s3 if you will have to.
If the user has the file, and the goal is to prevent then knowing the filename: wouldn't tgey just be able to generate the sha256 hash themselves? 
&gt; I am creating a copy of the struct in the common case when I want to just use the String() method??? Seems very inefficient - so I'm sure I am not understanding something correctly. No, you understand correctly. Values are passed by copy to functions (and methods), so calling one on a struct will copy the struct. This is barely ever a problem in practice. The overhead of copying the data in a struct is insignificant, unless it's being done in a very tight loop. In that case, profiling will point that out, and you can decide whether to pass data differently around your program. Until then, just pass the struct along. (Note that the same applies to passing slices around, as the backing array of a slice is not copied.) The main benefit of passing things around by value instead of passing pointers are that you get a guarantee that different functions and methods will not get in each other's way by modifying data in mysterious ways, or introduce data races to each other. It also becomes easier to reason about the behaviour of your program. Any time not spent debugging issues this prevents is time that can be spent on new features, correctness, performance, documentation, or just on another project entirely.
I would follow the git model. if you're emailing a snapshot at a particular point in time, use a hash. SHA256 would work. if you're emailing a link to the most up-to-date version, a guid that always points to the real file via a database would work - the equivalent of an auto updating branch. you can use this approach not just for a file, but for a folder.
I don't think your code will work - if another thread is modifying the 'active sessions' while this method is called - Boom! You would need to add a mutex to ave it work this way... This is why Java has defined semantics of how for/each works, and since everything is a reference, you can use a copy/swap and have success... I haven't been able to find anything that says Go slices are thread-safe to iterate while being mutated in the standard fashion. The sync.Map gets around this because it is essentially doing copy on write behind the scenes. Anyway, the session printing was just a test, and there is no concurrent iteration in the critical path. btw, code is getting close to being posted.
Do you have any test coverage?
Save metadata and filename in a db and name the file like the primary key of the db table. Easy to find and always unique.
just "proxy" from goth's user struct to your own yourUser.Email = gothUser.Email
I just sha256 file contents (poor man's deduplication), then save as eg. 8/8c/**8c**5c04391361cbf4afd74c5ed8101ea4af881c4ee3b3df1d5b3716a19b1a834d and in database I just save original filename, size, content type etc. 
**Thank you!** 
Usually using some optimized library to efficiently sha256 file, not doing buffer reads etc myself . I'm sure there is some lib in go for that. Also if you expect huge files you can use faster algorithm, it's security isn't important here . And for really huge you could hash only first X megabytes or just original filename plus size.
If it's read-only then generate the data structures you need using a tool/script you invoke via \`//go:generate\`
yes, it's cool. &amp;#x200B; Yet another mark: client library should not PANIC. It must return an error.
[https://play.golang.org/p/gX4lcve9yNb](https://play.golang.org/p/gX4lcve9yNb) &amp;#x200B; i hope this satisfies your need. its independent of the structure inside (see input2) &amp;#x200B;
https://github.com/suyashmohan/rest_api_golang_psql/blob/master/src/controller/request/user.go - i think splitting types from methods is messy and can lead to unreadable code https://github.com/suyashmohan/rest_api_golang_psql/blob/master/src/controller/response/common.go#L10 - ignoring error can lead to hard time when debugging, maybe it's better to return error/log it/panic https://github.com/suyashmohan/rest_api_golang_psql/blob/master/src/controller/user.go#L19 - this type should be an interface, to allow testing handlers https://github.com/suyashmohan/rest_api_golang_psql/blob/master/src/repository/user.go#L25 - i think instead of this method, it's better to create function which accepts *sql.Row and returns *entity.User https://github.com/suyashmohan/rest_api_golang_psql/blob/master/src/repository/user.go#L28 - logging in models isn't good idea, it's better to just return error or custom error https://github.com/suyashmohan/rest_api_golang_psql/blob/master/src/repository/user.go#L17 - what? what throw, what fatal error? https://github.com/suyashmohan/rest_api_golang_psql/blob/master/src/repository/user.go#L32 - returning pointer to User suggest's it's an active record, which i guess it isn't there's more, but i've only pointed the ones i've saw
[removed]
Easy for other users to find too. Just try all the numbers around yours and see if you get any good downloads. 
[removed]
godoc.org
thank you, google wasn't helping me at all trying to find something like this
https://github.com/avelino/awesome-go
I wasn't suggesting using the slice from multiple threads. I said "you couldn't run the slice copy in parallel" and "if you restrict access to one goroutine, you might be able to just copy a []*Session". To be fair, I didn't code up a whole example like my earlier comment and I was kind of assuming you would see that first - I think if you understand how that one works it'll be clear the sort of architecture I'm also proposing here. The rest of my comment is just going in to the performance (of doing it that way vs a more Java-like way) since you seem interested in that. I don't think that either way is an obvious performance win. I'm not saying the Java way is bad! I think there are a wide variety of problems that can be solved fine in both Java and Go. But channels are the core tool that Go gives you to solve this sort of problem, so if you're doing it as a learning exercise, I'd suggest trying out different architectures that use them instead of shared mutable state (hopefully my other comment with the example can help you get started). If you are set on not using channels and want to primarily use something else like concurrent collections, Java is probably better for that than Go. I don't think you will find an answer here that will make Go better than Java for that - Java is probably better for doing it that way. I'm not sure even the Go authors would dispute that. sync.Map didn't even exist until years and years after Go came out. You're right that Java is more reference-type oriented than Go. That allows some operations to be thread safe that are not thread safe in Go. But as a trade-off, having everything be reference types leads to more pointer-chasing, less efficient cache use etc. I think Go is just making a different set of trade-offs than Java there.
Does this mean that Go compiled to LLVM IR and Bash compiled to LLVM IR can finally be combined to a single executable? :D
[removed]
Should the creator of the channel be responsible for closing? For example should each of the go routines send a “done” message so the parent knows to stop?
I've typically found a Google search to be better at finding packages I need than nuget or npmjs. If I know of a specific library and want to know if it's being actively maintained, github works just as well as something like npmjs. Is there something I'm missing? I'm not sure what need you're trying to fill here.
Usually you do the opposite: you have a for loop in the goroutines `for v := range myChan` which exits when channel is closed (and in case of a buffered channel when all elements are read from channel)
I am sorry that i cant answer your questions directly. But most people that write go Apps do not care too much about GUI stuff. Mostly they write Apps that Serve a Web interface of some sort or just directly controlled by a commandline. This is not to say that what you are doing isnt going to work, both of these libraries should be fine to work with for the most parts. Your project will still compile to one single executable, but it May depend on the gtk shared libraries. That depends on how gotk and go-gtk handle the bindings 
Duckduckgo and reddit
No problem. I'm glad about any input I receive :-) I am of course fully aware that Go is mostly used for server/web/http stuff, but Go is so simple and yet so fast that I'd really like to use it for more of my projects even though they aren't typical Go projects. However I also have to add that I don't see any reason/restriction to NOT use Go for my project. I was thinking about Rust as well and while Rust is certainly an interesting language it is significantly harder, while only offering a relatively small increase in performance compared to Go. I'm just a hobbyist so I only have a very limited amount of time I can spend on my side/fun projects. Last but not least: Of course the system needs GTK installed, but I'm glad to hear that I still will end up with a single binary!
Don't bother Go, it takes around 40 times more time interfacing with C. https://github.com/dyu/ffi-overhead
Creator should be responsible for closing the channel. Consumers of the channel should just loop over the channel (loop will break when the channel is closed). This is often referred to as a worker pool and looks like this: https://gobyexample.com/worker-pools
Oh i would really like more people to use the gtk libraries. Only if there are users there will be progress. Just because it isnt what most people use it is a very valid use of the language. There really is no reason not to use go. Have a good time with it :) 
Glad to hear you're enjoying Go. 1. gotk3 is a GTK+3 binding, go-gtk is a GTK+2 binding. PyGObject is also GTK+3, so if you're wanting to port you're code, you'll probably want to use gotk3. For more details on the different backends, [there's a good ELI5](https://www.reddit.com/r/linux/comments/1x6lce/eli5_what_are_the_prime_differences_between_gtk2/). 2. I wouldn't worry about this much. They're both just bindings and so there shouldn't be any "new" features in the projects themselves, only the libraries they wrap. 3. I haven't used these libraries in Go, but after a quick glance at the docs I'm the gotk3 binding meets all of the needs you mentioned. 4. Yes, but like /u/Killing_Spark mentioned, the shared libraries (GTK3, Glib, Cairo) must also be installed on the target system. There's an [install guide](https://github.com/gotk3/gotk3/wiki#installation) on gotk3's wiki. Good luck!
&gt; If you're using the satori/go.uuid package, I can confidently say we've reached a stability point that should make it a good investment for you to migrate. If anyone is interested in migrating, use v2 of gofrs/uuid for a drop-in replacement for satori/go.uuid at tip, with critical bugs fixed. v3 removes the `Equal` function and adds some new features. Enjoy the release!
I know y'all probably get this all the time, but why use this over https://github.com/google/uuid? I can't find anything in the README, so if there is a reason beyond it just being an alternative and/or it predates it and/or a lot of people are just using it instead, you might want to update the README.
[go.libhunt.com](https://go.libhunt.com) [awesome-go.com](https://awesome-go.com) But frankly, searching on GitHub with search attribs \`language:go sort:stars\` is my first step. 
I don't think anybody can really answer this question for you. We don't know how your app works or how it will interact with the GTK libraries. Python may have faster ffi, but it has a ton of it's own performance considerations that don't map 1:1 with Go. We can't really compare them without an actual working product to measure.
http.ListenAndServe handles the multiple requests for you. go ahead and try it.
Unless you're spending your time switching between C and go, it's not noticeable. I only started to see it this when I made direct drawing with cairo and jumped over 500 C calls per second. At 1000 context switch per sec, with graph drawings and other things to do, my program is using less than 1% proc.
Thank-you I will!
Your software can handle lots of requests. ListenAndServe spins off a goroutine for each request. Write another go program to spam it and see how many it can handle. 
Maybe this is a case of "woosh", but this project appears to **output** bash from IR, so you could theoretically compile any program with an LLVM frontend to a bash script.
As others mentioned, it's going to depend on your application. With that disclaimer, I'd be *very* surprised if your python application outperformed your go application, given a 1:1 port.
https://www.gophercon.com/agenda You might want to check the agenda. Day 1 looks like workshops and isn't really the actual Go conference (usually, they hold tutorials just before the conference starts). Then, it's common to have a greeting and some keynote speakers that everyone sits for. Once you see three speakers slotted for the same time, then you pick the one you want to attend (some conferences can have 5-6 talks simultaneously) and sit in that room. Some people who don't find any talk they like might take a break and talk to others or get on their computers. Talks typically end around 5, but it looks like they have stuff afterwards aimed at specific audiences. You'll also seem some sponsors that set up booths to talk about their products. They are usually out in the hallways. Usually, there are small breaks where you can get coffee, soda, water, and maybe some snacks. There is usually a breakfast and lunch served, but not usually a dinner. Also, there's usually a registration period either early the first day or possibly the day before if you're there early for some reason.
click on title/link for more info I taught this should be more publicly made. Not generating unique ids is pretty bad for a library that is supposed to do that.
Drop a line on go-nuts. It is frequented much more then that forum. I'm sure it isn't personal or political.
&gt; This package is currently in development and the API may not be stable. Although no changes is 9 months ¯\\_(ツ)_/¯ 
That's ok, it works. For most larger libs, looking at something like that is ok, but for something like UUID, unless there are outstanding bugs, it's not "stale" as much as "completed"
I wasn't suggesting using them for iteration, but using them (along with goroutines) instead of locks or sync.Map like in your original post. For the example code you originally posted about, you can achieve the same thing in a thread-safe way just with just channels, goroutines, and a normal map or slice. If I was writing an exchange as a Go exercise, first I'd try to write a high-performance one without using any mutexes or concurrent collections at all. I'm pretty sure it is possible (for a fairly high level of performance). Anyway it sounds like you've made progress on it, so maybe your original post isn't relevant anymore. BTW, I assume you might already know this but just in case: you can change the channel buffer size to reduce the blocking, by default it's 0 and will block constantly. If the producer is spending a lot of time blocked you could try tweaking it (if you haven't already).
Why don't you just post it instead of asking? 
Ah, you are right, thanks.
How do I generate the entire documentation for a go lang project? 
Is it hosted on GitHub? Then you can use the godoc.org website to view your docs online 
No it's a private bitbucket repo
I understand that, but I think you're too hung up on maintainership of a tiny UUID lib w/ tests. Just vendor and move on I'd say. Or just fork and reference. I'm not saying UUID is left-pad, but I wouldn't avoid the library for the issues with the maintainer. If, back to my original question, what this other lib improves on is only stability guarantees then say so. It won't make me choose one over the other in this case though.
Need more code, but `s.StorageClient` is probably the culprit. Make sure you're calling a object, not a type. This is how it should look https://play.golang.org/p/iXtNoNoELc3
Very interesting read. Not sure about this sentence though: &gt;Given a floating point value `x` in the unit interval `[0, 1]`, consider the representation of the value `y = 1+x`. Since `y` is in the range `[1,2]`, the **largest** power of two less than or equal to `y` is `1.0` Shouldn't `y` be \`2.0\` here? Not sure what that would mean for the correctness of the 'Unit Interval Trick', if it changes anything at all.
If you need server rendering, your web layer should probably be Node.js, because you get great support for being able to use universal validation and serverside rendering your JS. The bulk of your work should be in the APIs written in Go. It feels a lot like JS or TS, supports concurrency, and is magnitudes more efficient.
This might be an interesting interview for you to read. [https://mappingthejourney.com/single-post/2017/08/31/episode-8-interview-with-ryan-dahl-creator-of-nodejs/](https://mappingthejourney.com/single-post/2017/08/31/episode-8-interview-with-ryan-dahl-creator-of-nodejs/)
Pros: Go is faster, like way faster. Go comes with some great tooling from the get go. Go has a lot more in the standard library than what you're used to with node/js. Go has no framework bloat. Cons: Go has fewer tutorials (btw does anyone know of a go tutorial on skillshare ?) Go is pretty opinionated, which combined with the point above means that you might do stuff the js/java/c# way because it feels natural and logical and it just won't work due to a small peculiarity you missed out in your tutorial.
Ah-ha, I misunderstood. Ok, it is a simple utility, so vendoring and moving on might be perfectly valid. For me, I write a lot of very small tools, so vendoring doesn't really apply to that use case. However, a breaking change in a previous example is also pretty painless in those smaller applications. If memory serves me, there are a number of marshalling conveniences in gofrs/uuid that I don't remember being in google/uuid. I would look for sure, but I've already wasted a bit of time today.
Yes there is a slight error here. It should use the half-open interval `[0, 1)` instead, since it's not true when `x=1` and `y=2`. For all other values of `x` in `[0, 1)`, the largest power of 2 less than `y` will be 1.0.
The net packages server will handle that for you.
&gt; btw does anyone know of a go tutorial on skillshare ? I don't know about skillshare but udemy has a good [Go Web Dev Course](https://www.udemy.com/go-programming-language/)
Because constants have to be evaluated at compile time.
Solid course, and it’s 9.99USD right now. 
Go might be faster, but Node has a lot of battle tested packages that will get you started with your app real quick. The only downside of Go I see is the lack of packages and smaller community. 
Sure. It's a dotfile based IMAP client. So far the GUI as well as very very basic IMAP functionality works. But it's still a looooong way to go. :-)
^The linked tweet was tweeted by [@njcw](https://twitter.com/njcw) on Aug 22, 2018 19:57:36 UTC (2 Retweets | 1 Favorites) ------------------------------------------------- I have moved gpython (a python interpreter written in go "batteries not included") to the go-python organisation to be with other go and python programs. Here is its new home :-) \#golang [https://github.com/go-python/gpython](https://github.com/go-python/gpython) ------------------------------------------------- ^^• Beep boop I'm a bot • Find out more about me at /r/tweettranscriberbot/ •
Thank you
ie: https://github.com/go-python/gpython Now with test coverage, ci Travis+AppVeyor. Join us and help us implement more of the python VM+modules :)
(https://github.com/satori/go.uuid/issues/73)[https://github.com/satori/go.uuid/issues/73] link to actual issue
"Ryan: Yeah, I think it’s… for a particular class of application, which is like, if you’re building a server, I can’t imagine using anything other than Go." ...
Pretty UI. I'll give it a shot as I'm rebuilding my home network and need automation with PXE Xen images (lots of UP Board and UP Squared devices along with several RPis). Need something to kick off the packer builds on near-daily updates.
It would be helpful to have actual full code. From the snippets you posted, the best guess I have is that you edited the wrong file or something. BTW, what's your Go version? Because it might also be related to different Go versions (e.g. a Go 1.11 with modules enables might use different files in the compilation than a Go 1.10).
I used node extensively for previous startup and use Go for current startup. We use Go for our backend API and React for front end Go pros: * Less resource usage * Easier deployment * Can handle more connections * Robust in production Node pros: * One language for front end and back end (don't underestimate this, our front end guys can look at backend code and understand it) * Easier to hire engineers * Better package management * More packages in the huge ecosystem (many are lower quality but the most used are good quality and better than Go counterparts like OAuth2 providers, GraphQL) I don't regret choosing Go at all but I have started to using node again for personal projects when I just need to get stuff done.
Maybe it is not an option..but just buy the Ultimate version and you get Goland. If this is your livelihood.. you make a living with it..the IDE is one of the most important tools. Worth $150 a year for the ultimate. I used to use community for years too.. finally sprang for ultimate (more so because I code in java, go and node/js and it includes all of those) and it is well worth the tiny fraction of a cost to make my life faster and easier on a day to day basis. 
Sorry for the silly question, but so there is a way to use a RAD like Glade to have the XML of my application and then use Go to interact with it? Something like HTML + JS?
The original repo has the fix sitting in a PR for more than 4 months ago. Dunno if people have tried to contact him, but currently the repo is fundamentally broken so people should use another uuid library.
Not a silly question :). GTK's glade can be used: https://glade.gnome.org/ The API for loading those xml files is GtkBuilder: https://developer.gnome.org/gtk3/stable/GtkBuilder.html And the Go bindings for that are here: https://godoc.org/github.com/gotk3/gotk3/gtk#Builder. 
They are always like that. That "discount" is always there.
They act as part of your documentation. So if it's not immediately obvious what the function returns or in which order use them.
Reason for the fork was that the author of satori/go.uuid was MIA, and there were bugs causing UUIDs to not be unique. Bit of a showstopper for it a UUID generator. ;) I also considered the amount of effort for consumers to migrate, and it seemed like it would be easier to have people migrate to a fork committed to minimizing breaking changes. I remember looking at the Google library awhile back, and feeling that the API surface area provided by go.uuid fit my needs without extra bells and whistles. The warning that things may break, in the context of the surface area for the package, had me lean toward the "simpler" API of go.uuid. &amp;#x200B;
I hate throwing this out there, but contributions from outside of the Gofrs organization are welcome.
It looks like you put a lot of effort into build this, which is pretty cool, but I don't see what I would use this for. Also, this is pretty much a less shitty version of vRealize Orchestrator (though open source, so there's that). This doesn't replace Terraform or Packer for my workflows. Sure, I could replace individual Terraform documents with a pipeline, but then I'm writing code for each of my Terraform documents, and then having to debug that code. The logical answer is then to put some kind of a templating engine over top of that code so I don't have to write code, and then you're basically just re-writing Terraform. This strikes me more as a serverless platform/framework than any kind of automation tool.
A few things made me choose satori instead of google/uuid. google/uuid haven't been updated in a long time and the last release isn't the last commit. This tells me that this is unstable and unmaintained. I am unsatisfied with the documentation of google/uuid, I can't tell what it supports from a glance. I even have a hard time knowing what it supports while looking at the godoc. When I needed a UUID package, I needed to generate UUID v5. Search for v5 on google/uuid, you find nothing. Search "version" and then you will find a function called "NewSHA1" to generate a UUID v5. Search v5 in satori, you immediately find a function called "NewV5", bingo. Then, the last criteria was the number of package that import the library. 461 by google/uuid, 2709 for satori. I believe that this is an important metric to determine which package is the most mature and to sort of crowd source your confidence to determine which one is probably better than the other.
Awesome! That's good to know ✌️
I don't understand the threat model `mprotect` is supposed to safeguard against. It only seems to matter for attacker-controlled code running in the same process. And in that case, I'd assume you're screwed anyway. Like, why wouldn't the attacker just call whatever API you provide? I think concern 1 isn't really a problem (can just happen as part of the API). 2 should probably be fine too - if RSA operations can get away with syscalls to get entropy from the operating system, then you can get away with a couple syscalls too. 3 is very valid. You would at least have to do rigorous testing against the compiler escape analysis. Probably just make sure to shove pointers around and not export anything giving access to the actual data. Which might preclude a lot of usecases. Overall, it seems far easier to have a separate process do the crypto-operations and communicate with that over RPC. You get all the same protections but its far easier to implement.
Your link doesn't provide any info on why satori doesn't generate unique ID. It just links to a comment on reddit linking back to the fork. This is the issue: https://github.com/satori/go.uuid/issues/73 And this is more info about the fork: https://medium.com/@theckman/keeping-important-go-packages-alive-5242917f83e8
&gt; I don't understand the threat model Yeah, this makes sense and I suppose I got lost in the weeds. Ultimately the environment (e.g. OS) needs to be secure also when the keys are in an unsealed state - no way to cheat that. I appreciate using KMS/an HSM but I'm trying to prioritize operational simplicity as well (and to some extent it's just shifting the problem around). One question - with Go would I just be best off using mlockall rather than trying to mlock the sensitive pages? I assume the problem with escape analysis also affects the use of mlock.
I actually would not suggest switching languages mid-project. This is not because of any language considerations but it is just wasted time. Python should be absolutely fine especially for a one-man project. For learning I'd more recommend writing CLI-applications or working on a http-server-project. Definitively read trough the standard library on golang.org.
Great article!
&gt; One question - with Go would I just be best off using mlockall rather than trying to mlock the sensitive pages? I assume the problem with escape analysis also affects the use of mlock. I honestly don't know. `mlockall` is at least a convenient and reliable way around any problems. But there might be an argument that `mlock` is less of a problem than `mprotect` overall - arguably, if a key would land on the stack, that would defeat `mprotect` (as it becomes readable to the attacker at that point) but not necessarily `mlock` (maybe, arguably, stack space is less likely to be swapped out? Though we still copy stacks around when they grow, so it might still matter). Either way, by only making pointers available and keeping the data unexported would make sure it doesn't get copied (though technically, I'm not sure you can even protect against copying in general, because of `reflect` which has limited ways to read unexported fields). TBH I wouldn't trust me on any of this though. I haven't spent a lot of time thinking about these questions because the threat model of either isn't that relevant to me (my machines are all either in the cloud and thus untrusted or FDE, no swap, single user desktops that I have to trust pretty much implicitly anyway).
I always check this website, it shows all the repositories created in the last days ordered by starts, it's pretty already discovered a lot on it. http://gitlogs.com/most_popular?from=last-week&amp;language=go
There hasn't been any response. There are many other PRs that had no response either. I thought this was more widely known because I often look at latest issues of packages I use and I've been seeing concern in other repos too.
SeerUD ++
Best answer!
Don't have much time to dig into your profile, but take a look at the upstream [pprof](https://github.com/google/pprof) if you're not using it already. They added a bunch of nice things like flamegraphs, goroutine tracing compared to the version that's shipped with the go toolchain (`go tool pprof`). Also look into `/debug/pprof/goroutine` profiling mode.
Is `s.StorageClient` an interface? check the return value at the interface definition if so
Umm no. I get you want to really define something and have it all in one interface and there prolly is a use case for that specifically. I don't know the use case for it. So all I have is the go way in the general use case. If you look at the go docs you will see types being made. You then see methods made with those types on a new type. Go tends to make you build a package with a type this way. For example the Reader interface in the io package. https://golang.org/pkg/io/#Reader Then there is the writer interface. https://golang.org/pkg/io/#Writer Then there is io copy that takes in both as params. https://golang.org/pkg/io/#Copy The point is that when you take in string.NewReader as a param you get a string but also all those io methods to use in that copy function or a custom one. The os.Stdout does the same but you get different io methods. You now have pieces to play with that get methods you may need or not but the point is that god interface in go wouldn't always make sense because in go you "can" build pieces, reuse types, mix and match, make your own, throw a type in a type to take from the source...ect. Instead of just one interface that kinda says something has to have all those methods. And yes you have to add those methods to get the interface. It's so that if you make a package people like me can read it. I'm sorry if that isn't specific enough for your use case or is simply out of scope but as you can tell it has the benefit of being uncoupled, reusable, easily read, extended easily, used to abstract away different parts (kinda really benefit of being uncoupled) and just plain easy to keep a mental model instead of that giant god interface, that might be really strict but no one can do any of those benefits I described with it.
I later wrote that I need to have many of the objects so it may be a bit confusing. sorry. Let me try to fix it up
It also has to reflect the json. Easy mnemonic is square brackets in the json, slice in the struct.
I added some pastebins to make it easier to read. It's just too hard formatting on reddit. 
Also looks like you’re passing in a naked var, try instantiating it. `x := S{}`
I will try now
*Copying my comment from Discuss:* I noticed you created two methods to process the JSON body. Because you are using Gin, have a look at: - Unmarshal: `c.BindJSON(&amp;todo)` - Marshal: `c.JSON(http.StatusOK, todo)` Bind does include some validations too. ;)
Definitely agree. I actually bought `geohash.io` once with the intention of publishing a spec, some test vectors and a reference implementation. Unfortunately that was one of many side projects ideas that never quite materialized.
I modified your example slightly: https://play.golang.org/p/ydJ3A-13fUR As you can see, it’s decoding the structure correctly, but your “Options” struct has a nested key called “Name” while you’re passing in JSON where the keys there are called things like “Dell”. If you’re looking to dynamically get those property names, make “Options” a map, not a struct. As far as I’m aware you can’t make dynamically keyed structures. 
I'm super fascinated by this, but I installed it and tried using the sample code in a repo and there were just tons of bugs. I'd love to check this out again when it's a bit more mature. Love the concept, though, and it _looks_ beautiful.
The input json’s options field and the structure’s options fields have different type signatures. Just oversight. 
Comparison of both releases: https://github.com/golang/go/compare/go1.11rc1...go1.11rc2 
Meh I did the framework thing and I don't like it. Gonna stick to building it out with custom types to actually have one line of code that is reusable. As for angular....I got burned in 2 so I'm done with that. I just use jQuery. But I just cannot wait for go webassembly and hopefully they'll be working on those Dom types so I have to use less js. Cannot wait for the end of npm!
\&gt; Currently they are down to only 3 release blocker issues &amp;#x200B; Quick, let's file some more. Better now than after the release.
Wow! Thanks a lot for looking at my code. I have just started with Go. These comments will help me improve my understanding :)
The most bloated front-end framework on the surface of the planet AKA JEE for the web, a good match with Go on the server? 
You can also use trace (the best introduction I found https://making.pusher.com/go-tool-trace/). It shows things that are time related. `pprof` only shows CPU usage (and memory), so things like time.Sleep , disk/network io or channel blocks is really hard to debug using pprof, because those operations don't use cpu or memory. 
It is OKAY to not import a package for things like left-pad.
You should go back to Angular. You don't need the DOM to do things and you should avoid trying to manipulate it. 
Thanks a lot, eduncan911. Let me know if I can help or improve certain things. I'm also really thankful for every feedback I can get! :-)
Hello Shammyhealz. Thanks a lot :-) Gaia was not developed to replace Terraform nor Packer. It was actually developed to provide a better fit for Spinnaker, Jenkins, Gitlab CI and many more tools when you have complex workflows. Let me provide you an real world example which happened to me: We got the task to provide our development team a small service which allows every developer to provision a test instance of our monolith "on-demand". So the developer could just provide the git repo location and branch where the source-code is located and the service does the rest. We had to automate therefore the following tasks: * Create a new schema in our central test-database. * Import the test dump into this schema. * Generate multiple YAML-files for kubernetes (namespace, ingress, service, deployment, etc.). * Store and get credentials (kubeconfig e.g.) from vault. * Apply generated YAML-files via kubectl. We used bash scripts, ansible and jenkins to solve this job which was literally pain. Gaia shines exactly here. One pipeline written in Go makes this super easy because you have available and stable APIs which you can use to connect to Kubernetes and Vault. There is no need to generate one YAML-file. Even creating and importing a SQL-Dump is easy because you can use existing libraries. I also wrote a tutorial about this: https://docs.gaia-pipeline.io/tutorials/kube-vault-deploy/ This is a bit outdated but gives you a good impression about what actually is possible with Gaia. :-)
So searching for `mach_semaphore_signal` I found the following thread https://groups.google.com/forum/#!msg/Golang-Nuts/9zqvdcfVzCA/4rvWkIQeAgAJ . The last response was by Dave Cheney and he suggests ``` 1. are you doing a LOT of channel sends and receives ? Perhaps the amount of work you are doing vs the amount you are handing off between goroutines is relatively small 2. are you generating a lot of garbage ? I recommend running your program with GODEBUG=gctrace=1 and looking at the frequency of the gc trace output, if it is continuous, that could be a sign you are generating too much garbage. ``` There is also apparently an issue with profiling on OS X less than el captain. Maybe that applies to you? I am honestly struggling to recreate this profile using a simple scenario on linux. I write a million messages from a million goroutines all to the same channel and that takes 2 seconds (starting up of the goroutines are included in this time, and I suspect that takes about a second on its own). So you should be able to get a throughput of about a million messages per second. Can you explain what is included in the `4k round-trip requests`? How many goroutine sends are you doing? From how many goroutines? And how big is the object you are sending? 
Considering your JSON, the \`Options\` field makes me think more of a map, so here's a map version: [https://play.golang.org/p/rhXOUxE4nYN](https://play.golang.org/p/rhXOUxE4nYN)
That's why https://github.com/awnumar/memguard allocates the memory for what you want to protect *outside of the Go heap* (i.e. in `mmap()`ed memory)
&gt; __func (*Decoder) Decode__ &gt; &gt; `func (d *Decoder) Decode(v interface{}) error` &gt; &gt; Decode works like Unmarshal, __except it reads the decoder stream to find the start element.__ https://golang.org/pkg/encoding/xml/#Decoder.Decode ---- Use `xml.Unmarshal()` instead.
I've already tried `xml.Unmarshal()` and the behaviour was still the same https://play.golang.org/p/zwfW1KhiA0t (and I'm not sure how to define a custom decoder withouht using `xml.Decoder`)
Sure thing. This library was written to fit decimal numbers into uint64 and meant to be used in matching engine concept where numbers are typically lower.
May I ask: Why are you even abstracting this? Are there multiple implementation of that interface? If there aren't, definitely don't abstract. Just have a concrete type implementing all the methods you need and pass a pointer to that around. For testing, make that implementation's API able to be used in tests (for example, make it take a directory for where to store data and then point that to a tempdir in tests). Premature abstraction is the root of all evil. If you do have multiple implementation, I'd go with interfaces. Reason being, that a) you still have concrete implementations with all the methods (making it easier to understand and encouraging coherency in what implementation is chosen) and b) it's easier to extend later - i.e. if a more efficient implementation of one of your functions might want to use different methods, it's easier to add them to an interface than to add a different function arg. If you go with interfaces, it's idiomatic to define those at the consumer site. i.e. the concrete implementation has all the methods and if a function only uses `RemoveEdge` it would define a `type EdgeRemover interface { RemoveEdge(…) }`. &gt; If I have a use case with two repositories in it, I either have to stub out the whole interface, which I find annoying, or use a mock library, which I also find annoying. Mocking a function is much more reasonable. I can implement a function right in the specific test. So, a) you are saying "if", which suggests that this is premature abstraction :) But b) it's not really hard to mock out a single method of an interface. i.e. (assuming you have a `ConceptRepository` interface): type testRepository struct { ConceptRepository } func (r *testRepository) RemoveEdge(…) { } func TestFoobar(t *testing.T) { r := &amp;testRepository{} RemoveSomeEdges(r) // Or whatevs } all the other methods then get promoted. If they get called by `RemoveSomeEdges` that would produce a nil-pointer panic, causing the test to fail. You can then add that method to the mock. But, not to be a stickler, IMO mocking is again a pattern that is more common in Java than it probably should be. You should just use the actual implementation of your `ConceptRepository` and make it useful in tests. Because when you use mocks, you tend to test implementation, not behavior. That is, if you change your implementation, your code might be correct but still fail, because you are calling different methods in a different order. Or just because the code you used to mock behaves differently from the real implementation. If you instead use the actual code as much as possible, you can't get any of these behavioral differences and you have to maintain less code. win-win. The rule of thumb (IMO) should be "use the real implementation with real dependencies, until you hit I/O (network, disk…). At that point, use fakes (e.g. ramfs, localhost…), not mocks". It's different to common practice in Java, but IMO… better :)
Got any source for build size? Also, I use Vue for extremely large projects for big companies. I don't see why it's for small tasks only. It has a nice learning curve and a rich community/ecosystem.
Well someone already purposed it kinda. https://github.com/WebAssembly/gc/blob/master/proposals/gc/Overview.md I personally want the Dom to be abstracted away so that I can simply make a custom type that it is named after. This way you can just have it in your code. 
Repositories are all I/O. For example, the concretions are all PG calls. The use cases are essentially transaction scripts that produce an end. Use Cases encapsulate the domain layer to prevent it from leaking to the controllers. A use case needs to get data by way of repositories. I want to be able to insert into the use case repositories at test that do not requiring invoking a database.
This IS a contribution :) Don't hate to say and repeat it. When it's a so easy change we don't know if it's a decision or just a lack.
So code in file which fails declares struct: type SQLAdminService struct { service *sqladmin.Service StorageClient *storageclient.StorageClient Logger *log.Logger } Having read your comment, I've renamed StorageClient field to just Storage to avoid confusion and possible mistakes, and updated all occurrences to use new name. Now interesting part is that my build fails: ./gcloud-dump.go:44:3: s.Storage undefined (type *sql.SQLAdminService has no field or method Storage) It's as if build somehow grabbed obsolete code couple of commits back. I've re-checked my commit - StorageClient -&gt; Storage change is there. Also my initial problem now makes sense - that method indeed didn't return errors until the commit that started failing. This is not a master branch. Maybe dep is trying to grab my master branch code instead of using local one for some reason? Local packages are not listed in lockfile, only remote ones.
are chi / sqlx better than httprouter?
&gt; For example, the concretions are all PG calls. A PG (postgres?) call is not I/O. You are calling into a library (presumably `database/sql/driver` via `database/sql`) which then does I/O on your behalf. When I say "I/O" I mean things like `os.Open`, `(*os.File).Write`, `net.Dial`…. &gt; I want to be able to insert into the use case repositories at test that do not requiring invoking a database. You should be able to start up a postgres instance on a tempdir. It is functionally the same thing, but it reuses the real implementation (and is thus bug-compatible). I know that this seems like overkill, and it might be. IMO it's the clean way, but how clean you want to be, you have to decide for yourself :)
&gt; its opinonated but has all the batteries included The browser API and the DOM already has all battery included.
A little circuitous but it does handle your BOM data - https://github.com/clbanning/mxj/blob/master/examples/bom.go
Chi is compatible with Go handlers while httprouter is not. Httprouter is faster in benchmarks but because of API I find chi better.
pkg/encoding/xml does not require it's input being a valid xml-document. You can easily test this however when checking for the magic-bits 3C 3F 78 6D 6C (&lt;?xml) at the beginning. I'm not to sure what the specs says about the end of the file but I'd say you can safely ignore that.
"lack of packages"
I know I know...
Really like your blog's design. Are you using a static site generator like Hugo with a custom theme?
I suspect it's tons of trivial messages that could be replaced by fewer substantial messages. Without seeing code, it's really hard to know what the problem might be.
Using higher-order functions is absolutely common in Go. Do note that variables of closures might get placed on the heap. And you can even define methods on function-types. As always documentation is king especially when things get more complicated.
Some other things I remember. They often have a lightning talk session. This is often held rather late, but the idea is for speakers to talk 5 minutes. Most talks have to be selected, and speakers get, say, 45 minutes to present. Lightning talks are impromptu, and lets anyone who has a 5 minute presentation to talk. They might have 10-20 such talks. Also, you tend to see lots of people with their laptops on tables typing away in the hallways. Guess they can't keep away from work or something. There's often some conference swag which might be part of the cost of registration, such as a t-shirt (they often ask for your size as part of applying for a conference) or some other things (a tote bag, etc). Some bigger events might have some night get-together paid by a sponsor which may be on-site, or possibly somewhere nearby.
what about center-string.js, return-true.js and steam-locomotive.js though?
If you add vue-router and vuex to your vue project you are essentially on par with Angular. There's no reason to categorize Angular for "large business" projects and Vue for smaller ones. A small API surface area doesn't automatically mean "only suited for small projects"
btw, the channels themselves are still backed by locks in the implementation - it is just that the CSP is easier for people to understand/use rather than using the locks directly. The channel is a shared queue with syntactic support in the language - nothing more (unless you consider the multi select, but even this is a feature of some shared queue systems, and can trivially be implemented with a round robin poll)
Honestly, I think it's at least as easy to hire Go devs. All of the Go dev's my previous team hired were only C# devs till the moment they were hired. The learning curve with Go is short, and I think that frontend devs looking at server code would be a similar experience.
Myself, I avoid editing code in the vendor directory. What you do from here depends on how much you will be using this package from here. If this is a one-off thing that you'll never use again, you could consider putting it into `internal`, but if you can even remotely conceive of ever using the improvements you're making again, then you need to fork. If you don't feel like contributing to open source, hard fork the project internally. If you do, fork the project on github, add your own repo as an alternate remote (so you don't have to muck with import paths), and then make changes on a dedicated branch, ideally on a featurewise basis. When you've finished your changes, you can issue a PR. If there's no response within a reasonable amount of time, you can consider a hard public fork or just fork internally and move on.
good point, I think the fork works best
https://golang.org/doc/faq#nil_error
So...final during GopherCon I think?
Wrong reddit to ask. There will still be users who'll recommand Go even though they haven't used NodeJS so far. For such a project, I'll write the API with Go and let Node handles stuffs like authentication, sockets etc. 
&gt; An interface value is nil only if the inner value and type are both unset, (nil, nil). In particular, a nil interface will always hold a nil type. If we store a nil pointer of type *int inside an interface value, the inner type will be *int regardless of the value of the pointer: (*int, nil). Such an interface value will therefore be non-nil even when the pointer inside is nil. 
Two things: 1. A lot more of Go comes from Oberon than C. The keywords are familiarly C-like, but beyond that it’s largely Oberon. 2. I want my programming language to be boring. It’s the problems I’m solving that should be interesting 😀
Per The Go Programming Language by Donovan and Kernighan : "Go is sometimes described as a "C-like language," or as "C for the 21st century." From C, Go inherited its expression syntax, control-flow statements, basic data types, call-by-value parameter passing, pointers, and above all, C’s emphasis on programs that compile to efficient machine code and cooperate naturally with the abstractions of current operating systems. But there are other ancestors in Go’s family tree. One major stream of influence comes from languages by Niklaus Wirth, beginning with Pascal. Modula-2 inspired the package concept. Oberon eliminated the distinction between module interface files and module implementation files. Oberon-2 influenced the syntax for packages, imports, and declarations, particularly method declarations. Notice that Go was initially developed mostly by Pike and Thompson, both with great roots on C and Unix. But anyways, that wasn't the question!
&gt; Any recommendations? I'd recommend not learning Go, probably. I'd find it incredibly frustrating to learn something I consider boring. And your assessment is IMO unlikely to change, it's pretty much correct.
While I can definitely appreciate the ability to get stuff done with Go, if your interests lie in creatively solving problems using your tools (ie programming language), Go is pretty boring. At work, this is great. You reduce completely horrible code from most people in an organization a lot of silly decisions are skipped altogether. From a personal perspective though, if you like being creative with how you use the language, it is a far cry from Ruby or Python and lacks interesting functional constructs like a lisp or haskell. That said, if you interest is in doing fun things with the language, there is certainly room to be creative if you look at things like code generation or development tools as you get an opportunity to capitalize on the simplicity of the language and scratch a creative itch. In either case, if you program professionally, Go is a really great language for scaling projects that balances performance, language features and opinions really well. Good luck!
uhm, boring is not necessarily bad. I like it when a tech solution is labelled boring; it is sometimes a synonym for stable. BradFitz did a talk about it; "ntroducing Go 1.6: asymptotically approaching boring" - [https://www.youtube.com/watch?v=4Dr8FXs9aJM](https://www.youtube.com/watch?v=4Dr8FXs9aJM) 
For me, the fact it is boring is one its major selling points. But I'd then note that it's boring _in the way I think a programming language must be:_ it's boring in that it's tailored to get your shit done with as little fuss and ceremony as possible. For me, this differentiates it from Java, which is, IMO, _plain_ boring. I mean, needlessly boring by having stupid design decisions. 
Oh, nice to see that Go is expected to be "boring". I can understand that!
Depends on the project. If I'm building it at work and it's going to be user-facing, I do every validation I think our QA engineers are going to test. Even the most arduous of validations are still likely going to be faster than the JSON marshaling/unmarshaling, so performance shouldn't really be a concern. If it's a personal project, I'll usually only do basic sanity checks and assume the small set of users aren't attempting to break things, but tread carefully if it's exposed to the open internet.
user input shouldnt be trusted so I validate everything possible
I mean, that's kind of the idea. The language isn't designed around being as exciting as possible, it's designed to be collaborated on, and some of the attributes that make something easy to work on by lots of people include familiarity and simplicity. Go explicitly has both. If you already know a C-like language, once you've finished the [tour](https://tour.golang.org/), you know enough about Go to start doing some work. &amp;#x200B; That said, Go's first-class interfaces and functions allow you a surprising amount of flexibility and expression, if you design the right way, and to do that the best way is to read [Effective Go](https://golang.org/doc/effective_go.html) and the [code review comments](https://github.com/golang/go/wiki/CodeReviewComments), maybe read some blogs (Dave Cheney's stuff is a good start) and then just dig in and build some stuff. Eventually idioms will start to be second nature and you'll stop being a C++ programmer writing Go and just be a Go programmer.
Well, of course it depends on you application, but for me, often the ideal balance is doing nothing but perhaps limiting the input size. JSON is nice in that it doesn't include declarations and stuff that can blow up like e.g., XML has. If I just decode using `encoding/json` then the types and structure will already be checked. Then of course take care to always correctly escape strings if storing/displaying as in using parametrized SQL queries and proper string escaping in HTML/javascript/whatever. I don't remember ever taking HTML as input from the user.
Oh no, that's not my goal! I'm pretty much love C++ :)
That's odd, a very good book according to reviews.
* If you have constraints on the data, you should validate those constraints after or during deserialization. * If you must know whether something was explicit or simply missing, your zero value can't be meaningful, or you need to use pointers. * Cap the input size
Well, I mean, it's just your (valid in its own right), opinion. This book was very much intended to join the legacy of **The C Programming Language**, which is renowned for its completeness and brevity. Some people like that stuff. 
I'm implying the context of \[while writing Go\]. I'm not suggesting you abandon C++, I'm just saying that when you're writing Go, you eventually want to be someone who's wielding the language most effectively. I'm not saying you're a swordsman who wants to switch to the spear, I'm suggesting you want to *also* learn the spear, but want to learn to not use it like a sword.
Yes Go is simple.
Did they fix go modules not working with private repos?
You want Elixir.
I haven't tried private module repos but I thought the module download protocol and goproxy (go help goproxy) where designed to accommodate private repos. Is there an open github issue for private repos? I found this one, looks like it is marked for 1.12 [https://github.com/golang/go/issues/25982](https://github.com/golang/go/issues/25982) I wonder if this problem can be solved by the Athens project. Something like you run Athens locally and have it configured to auth into your private repo. That way \`go get\` doesn't need to know, its a nice separation of concerns. &amp;#x200B;
Consider trying this lightweight JSON RPC 2.0 package. It lets you use whatever server framework you want as it just provides an HTTPHandler function. You can register your method functions and launch your server and you're off. It also recovers from panics if your member function panics and returns an error json response. Github.com/AdamSLevy jsonrpc2
If you're going to be at GopherCon next week, I'm covering the reasons for this in my "Go says WAT?" talk.
This is phenomenal work! Where does one learn to maths like this ;)
Man .. center-align has 3,934,447 weekly downloads. Do people seriously not want to write 2 lines extra ?
Perhaps you shouldn't create a HTTP client each time hitting request fn. Just create a Client in package scope and us it there.
It would be super cool if Russ sends out the release mail live right from GopherCon ! /u/rsc - can we make this happen ?
Not at all, I'm probably want Rust. First. I'm coming (and staying) from C++. Second. I'm not interested in doing web stuff at all. Third. Some of the worst developers I know like Elixir, by only implementing a couple of simple web stuff, of course. :)
Yes, I was recommending it even knowing that they use a lock under the hood. I think that it's much more interesting as a Go exercise to do it in CSP style (which can most conveniently be done using channels). I think a good way to think about Go is that it isn't about zero-cost abstractions, it provides a few low-cost general purpose abstractions, and then in performance bottlenecks you can write them in a non-abstract way. For networking, it has goroutines/channels as the convenient built-in abstraction, and in performance bottlenecks you can use atomics/mutexes/sync.Map etc (although there's no big advantage over other languages, in fact it might be less convenient). For data structures, it has slices/maps as the convenient built-in abstraction, and in performance bottlenecks you can write your own custom one (although there's no big advantage over other languages, in fact it might be less convenient). This probably works great for many programs. But if you just want to just focus on the low level part I don't think that is *interesting* to do in Go. I think you might end up frustrated with it since it's not as convenient for building your own abstractions and doesn't have lots of features. Since you seem to have a Java background, what are you looking for in Go that Java doesn't provide? I like Go but that doesn't mean it's the best fit for every problem.
Ah so they moved it out to 1.12
Yes, you can read from stdin while writing to stdout. Simultaneously in different goroutines, even.
If you love C++ and are familiar with more than one language there is no possibility you will like Go. 
Well I guess I mean that any form can take HTML as user input, right? &amp;#x200B; So do HTML sanitization for everything, or do RegEx filtering to only allow alphas or alphanumerics (first name, street address, etc.), or..?
If you don't mind answering, how are you handling things specifically? &amp;#x200B; That's what I'm wondering about--RegEx filtering for every field and its associated type, or some other approach? (First name only alpha, street address alpha and numeric, that kind of thing?) &amp;#x200B; I guess I'm most concerned about XSS, or any other HTML-related content (the user can enter whatever they like in web forms). I think one approach is to allow any sort of input, but be sure to escape all output, so bad stuff could be entered but wouldn't be effective when rendered...
&gt; in creatively solving problems Go gets the creativity out of language so you can take a step back and creatively solve the problem, rather than twiddle with the language. &gt; using your tools (ie programming language), Go is pretty boring Spend some time with goroutines and channels. ✅
Validate at the inception point so you don’t have to validate everywhere.
ChatMode(index)
Ahhh... Thank you!! I was trying index.(ChatMode) and was pretty lost. Thanks! 
It wasn't an actual mistake though. Finding a way to optimize code further isn't exactly the same. Still, it's a nice introduction to pprof.
Hi justinisrael, thanks for your feedback. Yes you are correct about the difference between the two declarations. I will update my post. Actually I wanted to explain that they are functionally equivalent as their **len** and **cap** are both zero. So when we do not want to initialise a value, **nil** slice must be the preferred way.
For what it's worth, I recommend also validating expectations for any external APIs that you call. They also constitute what should generally be untrusted content, and their owners will not always return what you expect. Better to error on a long string at the call site, than inserting it into a DB field that won't fit it, etc.
&gt; Premature abstraction is the root of all evil. This is directed at interfaces far too liberally. Interfaces are not abnormal in complexity or cost. It is often cleaner and more reasonable for wiring to disconnect at the contract level rather than the implementation level even when there is only one implementation. I would recommend against an interface for one implementation when: 1. The calling code requires complex and "intimate" access to the internals of the abstracted type. 2. The abstracted type is in the same library as (read: is conceptually related to) the calling code. (This might be remedied if it is reasonable to place the abstracted type into another lib.) &gt; In a long-lived project, you cannot assume that maintenance developers will grok abstractions that are much higher level than normally offered by the language and existing standards. This applies far more squarely to things like HTTP frameworks that offer high-level abstractions where the bulk of the benefit is shallow convenience (obfuscating underlying costs/behavior to a fault) and/or the coddling of habituated programmer style brought in from other communities (providing crutches for what should call for a small amount of retraining). That's not to say that all frameworks are a bad idea, but it is to say that when the language/stdlib provides abstractions we should be using those vastly more often than higher-level abstractions.
&gt; This is directed at interfaces far too liberally. Interfaces are not abnormal in complexity or cost. Agree to disagree then. I am constantly annoyed by interfaces thwarting static analysis tools and obscuring control flow.
I think you may be conflating separate issues: 1) Backend Data validation - like 'is this string field allowed to contains certain characters'. I'd implement that at the model layer and/or with constraints in the database. Also where you should use the features of your ORM / DB driver to avoid things like SQL injection. 2) Validate the inputs needed are there and the proper type - 'I received a `date` param, is this thing actually parsable as a date?' or 'did I get the params that are required for this endpoint to function?'. That I'll put somewhere around the controller layer, generally not in the controller itself, but it depends on the complexity of the endpoint. At the this level, you can use something like https://github.com/nicolasblanco/rails_param if it's just a couple params for create a PORO with ActiveModel::Validation or your validator of choice for more complex endpoints. 3) Security constraints. e.g. checking a CSRF token. You should usually do this in a middleware or prior to your actual controller code. I'm not sure what you mean by XSS in terms of an API - generally the protection against XSS would live where strings are rendered into HTML, in the case of an API used by a browser this is probably in the javascript, though you can do some sanitization on the backend as well if there is some field in the DB that is allowed to contain HTML. 
Thanks, would you have an example on how to do this?
You're thinking there of type assertions, which are different. [https://golang.org/ref/spec#Type\_assertions](https://golang.org/ref/spec#Type_assertions) See [https://golang.org/ref/spec#Conversions](https://golang.org/ref/spec#Conversions).
I definitely agree. My point is more for those folks that enjoy diving into the minutiae of a language might be disappointed. For example, folks that enjoy a lot of meta programming in Python or writing DSLs in Ruby might get bored with Go as a language. Clearly, that is a feature! But some folks really enjoy the ability to create magic in a language, in which case, Go might be a little lacking in that department. That said, if you've ever been frustrated by clever code and want to focus on solving problems, Go is as good as it gets IMO. 
I’d be interested to see how returning a C++ struct compares. 
Hi pookalatka, No there is no benefit as such. YAML files are just a way of storing our translations, other ways can be JSON, toml etc. You can refer these examples if you prefer to store the translations as a map: [https://github.com/nicksnyder/go-i18n/blob/master/v2/i18n/example\_test.go](https://github.com/nicksnyder/go-i18n/blob/master/v2/i18n/example_test.go) I completely agree that deployments will be easier according to your approach. I copied the YAML translation files to server via deployment script. Thanks for the feedback.
The distinction of type-casts and type-assertions is very important. A type-cast is a compile time construct that is very cheap and always succeeds. A type-assertion on the other hand happens at runtime and might even fail causing a panic. Always prefer casts. And one other thing. When you cast from type `int` to `ChatMode` the value itself does not become constant.
Stdin and Stdout are just ordinary files. Whatever you can do with a file you can do with them too.
The [repository](https://github.com/buzzfeed/sso/blob/master/docs/diagrams/sso_request_flow.png) contains a more detailed [request flow diagram](https://raw.githubusercontent.com/buzzfeed/sso/master/docs/diagrams/sso_request_flow.png) for anyone that wants jump straight to the design.
Hmm. This wasn’t a mistake. And this service was already quite fast. Good intro to pprof, but premature optimization, maybe. 
I would think it would be the same, since tuples essentially *are* structs.
You forgot the /s somewhere.
Myself being a long time C++ programmer, and will never give the language up, but I will write new services/server code in golang, I just find it really easy to get alot of things done, and the cross compilation is just so incredibly simple. I have made the decision about 1 year ago to know, and use C++ and golang as the two primary languages of choice, based on what I am developing. C++ will always be a goto language for many many tasks, and like yourself, I really really like C++. You are correct though, it is a boring language, but it is something you actually end up liking (a real lot) about the language when you get competent with it. Anyway, my 2 cents worth ¯\\\_(ツ)\_/¯
Depends on a lot of things, however if you have to ask I would say that you probably are not up for the task. Again, this depends on your goals but this requires a lot of knowledge of both. 
First class functions and interfaces rock for creative problem solving!
If he got a c compiler working he could just compile the goc compiler then compile the official go one
[removed]
[removed]
[removed]
What's wrong with a boring programming language?
Maybe start with writing smaller programs in ASM then move on to such a difficult task as writing a compiler in ASM.
I am also learning about compilers; the advice I received from experienced compiler programmers was to start with extremely small languages first. A toy language, basically. 
Hi! You are totally correct, I completely overlooked this one. Thank you so much for the feedback. Totally appreciate it
Yes, readme is coming. I'm sorry that I totally forgot the most important thing in an open-source project.
&gt; those folks that enjoy diving into the minutiae of a language might be disappointed Agreed. I remember people not liking source control, too, so there’s no doubt some people will not like anything. :-)
I would not call it premature optimization if it's that big of a speed step and the code is already out and public. 
but if the entire deployment of said code is doing less than 10000 RPS (probably is), then it is pretty premature. 
Port Monkey to RiscV. https://compilerbook.com/
Generally in Go, what I do is the following: Define a struct that very narrowly defines the data I want. Unmarshal the data into that struct, often just manually, but there are packages that can help you (check godoc.org search). Generally, if you build that up granularly, with individual types defining marshaling from text as needed, you'll find that the type system will generally guide you towards making is so that no bad data can survive the process of being unmarshaled into the struct. The only exception is when you are taking in arbitrary rich text, in which case you need a dedicated HTML sanitizer. Once you've converted it into that type, you basically know that you have safe data. The int you want to be an int can't help but be an int. To the extent that your struct can't represent bad data at all, bad data can not make it any farther into the system. Use the type system to your advantage. You're paying for it, reap the benefits.
&gt;BuzzFeed’s software ecosystem is. comprised of hundreds of microservices For a "news" website? Seems like a lot.
Do you ever plan of changing the constructor names for the next major release? I mean, I like to follow Effective Go guidelines and also implicit best practices from the standard lib, and I don't remember seeing a constructor prefixed with \`New\` ever returning an error... they usually only return the value itself, and I say usually because I have never seen one that returns an error, but they may exist... for when a function also returns an error, it usually receives an imperative name, like, for example, \`Generate()\` or \`Create()\`. I was about to open an issue to suggest exactly this, maybe change \`uuid.NewV4()\` (and similars) to simply \`uuid.V4()\` or \`uuid.Generate(uuid.V4)\` (this one using an enum) for the next major version. Sorry if that sounds silly, maybe I'm overexaggerating, but that's because I like the initiative of you Gofrs to rescue this lib and I really want to care about its quality. Thanks anyway!
It is very difficult. And modern compiler is not built from ASM any more, once we had a C compiler.
I guess because it is not so complicated like C++, so you feel boring. That simpleness is a blessing to me, because I can focus on the problems I am solving, not the language itself. &amp;#x200B;
I think you're drastically underestimating everything that BuzzFeed does. 
Thats what I want to do. I am just wondering how difficult this task would be. Would it be easier to do a c compiler in ASM, then use C to create a go compiler? 
That’s a concern for the output layer, not input. PHP was a bad templating language. Any good templating language (including Go’s) should escape HTML on output so that the angle brackets are turned into HTML entities etc. 
Why the part about trimming spaces to compare empty strings? And empty string is definitely not the same as `” “`, so why would you want them to show as equal?
On the topic of unique id's: I recently started using this ksuid package instead of a RFC-4122 UUID package: https://github.com/segmentio/ksuid I was inspired by reading &amp; using the Stripe API: all of their identifiers have a short prefix that describes what they are: evt_1CiPtv2eZvKYlo2CcUZsDcO6 - an event ch_1D2WUx2eZvKYlo2CtOha79tm - a charge Unlike RFC2122 UUID's, they are a little easier to copy &amp; paste, which is a small but handy detail. There's this blog from Segment that has a fascinating history of uuid's, leading up to why they created the ksuid package. https://segment.com/blog/a-brief-history-of-the-uuid/ 
Hey Alex :)
Hi jediorange, Good point. What I mean is that suppose you are getting JSON response from an API. In the response there is a field **address.** Now consider that there is a bug in API and in address field they start sending `" "`. In your code suppose you perform some actions if the address is empty. So if you will compare: if resp.Address == "" { // preform some actions } In this case the above scenario will fail as **response.Address** is `" "` and not `""`. So to get away with these kind of errors we can use the below method: if strings.TrimSpace(resp.Address) == "" { // preform some actions } &amp;#x200B;
You're waay out of your league here. Look here: https://github.com/search?l=Assembly&amp;o=desc&amp;q=c+compiler&amp;s=stars&amp;type=Repositories Notice anything? There aren't any results that match the search string. The reason for this is that *nobody writes compilers in assembly*. *Maybe* you can write a Forth or BASIC compiler in assembly, but there's no way you can write a full C compiler, let alone a Go compiler.
If I remember right, I thought with chromedp, you could actually have multiple tabs open just like you’d use it on your desktop... I may be wrong though...
You can write for loop a little bit simpler: for scanner.Scan() { os.Stdout.Write(scanner.Byres()) }
Youu mean .Bytes()? Thanks!
If you're looking to make a fancy terminal gui, you might want to consider using a library that's designed for that kind of interaction. I don't know if it's any good, but this one came up on Google and looks interesting: https://github.com/nsf/termbox-go/blob/master/README.md
It was before we had a C compiler... C isn't *that* old
&gt;I do consider this a mistake on my part. I'm a bit of a perfectionist, and I think I should have spotted it without the need for pprof :) I'll agree on the premature optimization part. My commenting server is getting more hits from my monitoring tools than actual users, so I'm nowhere near the 10000RPS mark :)
Kick ass work homie
So why not try D instead?
Okay, I have to say it - this looks like a reinvention of LDAP with VPN combo. And honestly I don't see any benefits beside that they outsourced the whole authentication part to 3rd party provider. 
You don't have to use LDAP?
I don't know what I expected from a BuzzFeed blog post, but it delivered, seizure inducing gifs and all. This actually looks really good. We're using CloudFlare access to try and provide something similar. If it wasn't for the requirement to support SAML i'd jump all over this solution.
Username checks out.
Couple of tips Your upstreams are pointers. Do you expect this value to be optional? To me there doesn't seem to be a reason to make them pointers as it's a basic struct. In your routing you are using regex must compile. One this means your program will panic ungracefully if the user provides invalid patterns and two on every request the pattern is recompiled. You should consider pre-compiling the pattern during setup and then catching the error using regexp.Compile 
I didn't check the exact code bc I'm on mobile atm but I believe go prefers to return copies (e.g. append()) 
Did you conciser using a tunnel like this https://github.com/mmatczuk/go-http-tunnel or ngrok
Just bought the book! That'll be this weekend's occupation ;)
So ``` if x+natTwo &lt; y { } ``` is equals to the `math/big` version ``` if x.add(x, natTwo).Cmp(y) &lt; 0 { } ``` If `x.add` modified `x` then the behavior would not be similar to the simple `int` type. Not sure if that is the only reason for that behavior, but it is the more intuitive one in my opinion. 
Just noticed that you're using an unmaintained mgo package: github.com/go-mgo/mgo You may want to switch to globalsign/mgo ;)
It might be better to introduce a separate function run, that returns an error. Let main to call the run and defer close checkAndClose in the run. Defer statement has access to return parameters, and thus may set the eeturn value to non-nil error, if close fails. Be careful with defers though, if the function has multiple defers, they will be called in reverse order, and each may change the return error value.
Thanks, I have update the example code. &gt; Be careful with defers though, if the function has multiple defers, they will be called in reverse order, and each may change the return error value. This is something I had not considered, I will need to check my code for functions with multiple deferred closes now, thanks for the tip.
Why did you write your own `println`, and not simply use `fmt.Println` or `log.Println`?
Meh. I'm underwhelmed. Should be more like \`9 basic tips for beginners\`.
&gt;Now consider that there is a bug in API and in address field they start sending &gt; &gt;" " Sure, but that's a special case. 
Hi rosacanina, thanks for the feedback. I completely admit that these might be basic tips for people who already knew Golang. When I started learning Go these are somethings which amazed/surprised me. So I thought of this title. But yes you are correct, the word \`beginner\` needs to be in the title. 
Hi tv64738, Thanks for your suggestion. I am a beginner in Golang and was struggling to implement localisation in my application. I tried to look for some libraries and found [https://github.com/nicksnyder/go-i18n](https://github.com/nicksnyder/go-i18n). I looked at the standard library package suggested by you. Seems quite good. I will try to check if its a better fit for my application. Thanks.
Optimization does happen because your software is in the Wild. It happens because it’s necessary. 
But how long did it take to compile the book? Everyone knows compilation is faster with go.
I'm very interested in this, but I'm also a bit hesitant. I found several grammatical errors on the website. Has the book been proofread by a native English speaker, or professional proofreader? Also, is the book geared towards newbies to Go, or do you need prior knowledge before picking up this book?
It is: func (z *Int) Abs(x *Int) *Int Add sets z to the sum x+y and returns z. https://golang.org/pkg/math/big/#Int.Add
Yikes! I think there are going to be some upset readers if the code is not free or at least free once you purchase the book--but over time credentials might get lost, and protecting examples can begin to get problematic as well. It's just the norm to not have people pay to get code examples. That also allows you to correct errata where it matters MOST--in the code that someone is compiling.
This will not work if you return different err variable (for example you want to directly return errors.New("everything went wrong")). You could use named returns for that tho, but I'm unsure about resulting code clarity. 
Congrats on publishing your ebook! 
[removed]
[This](https://gobyexample.com/line-filters) might be helpful. Basically, when you open a file Go gives you an `os.File` object which implements the `io.Reader` and `io.Writer` interfaces. You then use `ioutil` or other methods which operate on readers and writers to read and write the files. `os.Stdin` and `os.Stdout` also implement the Reader and Writer interfaces (respectively). So anywhere you would use the results of `os.Open()` to read a file, you can use `os.Stdin` instead to read from stdin, and similarly with stdout.
The reason for checking the results of Close() is to report on what you find. The reason for that, is to catch errors sooner rather than later. For example, if you wrote data to the file, it might have been cached in memory and not flushed to disk until you called `Close`. In that case, you'd probably want to know if it didn't get written, yes?
Thank you so much, that makes perfect sense. I think I need to learn more about the OS and what is actually happening during HTTP calls and file system interaction- so that I have a better idea of what might be occurring. &gt; In that case, you'd probably want to know if it didn't get written, yes? Ignorance is bliss, but...yes, yes I would.
Ok. Going to give it a whirl
There's a native English from UK that will do a proofread before the launch. I totally admit that this is a weakness, I'm a programmer and non-native English so yes if you're distracted by bad grammar and such, you might be disturbed. I would say the basics of Go would be better, looking at 1 or 2 getting started tutorial and on the Go website doing the initial guide would be a good starting point. I will definitely offer to purchase the source code for those that purchased the book only, it's just not available at this moment.
I totally think that the source code is worth something, since the goal of the book is to build a reusable web engine and basis for other projects. I will just remove the book only option than, maybe it will just be simpler like that.
Having the basics first would be better, but you don't really need to have completed a full project. Just being comfortable with Go syntax and concepts should be enough.
Thank you very much, please let me know if you have any question and comment :)
Always have two or three price points for ebooks/info products. A much better option would be to do a book+code for $29 and book+code+screencasts for $99 or similar higher price point. 
Yes, this chapter was written long ago, I have lots of cleanup to do before the release and after for that matter. People pre-ordered this book since Feb 2018 and I'm sending update about each month. Now the book is completed, but I still have some aspect to fix, there's no introduction and there's some modules that needs update. Thanks for the heads-up.
Thank you, please let me know if you have any questions.
Thank you very much :) Please let me know if you have questions/comments.
haha yes, I will probably have a blog post on my setup to build the PDF and ePUB. I'm using markdown and pandoc to render the book, pretty nice. I have some contributors that are on the GitHub repo that can push fixes and what not. It was kind of long to setup everything, but I think overall the flow is working fine to "compile" new version of the book :).
The question is somewhat confusing because x is used three times, which is probably what confused /u/NeoinKarasuYuu, see: https://play.golang.org/p/mOfEkMuQE6M ...as you can see r and z are the same, so it is enough to write just the later. The reason z returns itself is because of the .Cmp() usage, working with math/big is already convoluted enough.
Check out this article. [https://www.joeshaw.org/dont-defer-close-on-writable-files/](https://www.joeshaw.org/dont-defer-close-on-writable-files/) I think the interesting part is calling Close() twice doesn't blow up so you can check for errors when you are in the normal path, but if you hit an error then you can clean up your fds.
Just to clarify why Unmarshal is more situable is because Decode is used for decoding json streams and Unmarshal to decode json
1: You could specifically assign the fields you want by using "max: value". The current field would be assigned 0 as it's always initialized to the nil value (for an int this means 0). I'd also use the := assignment operator which declares the variable while also assigning it. `t := Test{min: 123, max:321}` 2: If you're just passing in ints to a Print function or something, then you generally can just pass in the value and it will output the correct number. If you have a more complicated output you need to create, you could implement the stringer interface which works well for this idiom. As an example, see: `type Min int type Max int func (m Min) String() string { return fmt.Sprintf("The min is %d.", m) } func (m Max) String() string { return fmt.Sprintf("The max is %d.", m) } type Test struct { min Min max Max` `current int` `}` `t := Test{min: 128, max: 321}` `fmt.Println(t.min)` `fmt.Println(t.max)` &amp;#x200B; &amp;#x200B;
[https://www.reddit.com/r/golang/comments/94vijj/measuring\_multiple\_return\_values\_in\_go\_and\_c/](https://www.reddit.com/r/golang/comments/94vijj/measuring_multiple_return_values_in_go_and_c/)
really well written, please bring more GoLang articles :) &amp;#x200B; Part1: [https://auth0.com/blog/developing-golang-and-angular-apps-part-1-backend-api/](https://auth0.com/blog/developing-golang-and-angular-apps-part-1-backend-api/)
This is exactly what I was looking for, thank you so much nemith. The article does an excellent job of explaining the issue, especially related to the filesystem. It also provides excellent ideas for handling functions with multiple defer's.
Finally a new book on #GoLang worth reading :) But the pricing though 
That is how you would initialize a variable in that type of data structure. But I would caution you to carefully examine why you're using that pattern. Coming from oop, people often use embedding too much in cases that it's not required. Do you really need an embedded type for just two ints? Likely not. Don't forget, there's a cost (in terms of readability and maintainability) to this pattern. I'd point you more towards using interfaces. Though even there, try to follow best practices. Look at how the std library uses interfaces and try to follow those examples. It really depends on what you're trying to do more than on the syntax considerations. Even with interfaces, I find it's easier to write something that works then you'll find where you have interfaces that can work best for your use case.
Were I going to build a SaaS (the topic of this book), I don't think I would be complaining about a cost of $20 (nor threatening to post copyrighted content?). People expect the world, in exchange for nothing.
People take offense now at everything. Even $2 for an app, is too much. (Then they waste many thousands on luxury products like electronics and automobiles.)
Please provide at least an example of code that you tried. 
I am wondering if ``` func helloNotes() error { f, err := os.Create("/home/joeshaw/notes.txt") if err != nil { return err } defer f.Close() if err = io.WriteString(f, "hello world"); err != nil { return err } return f.Sync() } ``` is in fact a solid idea?
You are right. I guess I should have read the docs more thoroughly ;)
I can see your thought process but calling something like a financial product anything like GOX is probably not a good idea. ;) &amp;#x200B; [https://en.wikipedia.org/wiki/Mt.\_Gox](https://en.wikipedia.org/wiki/Mt._Gox)
Thanks for the answers. I will complete the Go course I'm currently on, and then come back here to check out the book further in about a month or so. :)
That is a very good point... I'll change it to go-trader... with the exchange code of GOT
Hmmm... doesn't seem to be a way to edit the title...
On your second and third point: People use strconv.(Itoa, Atoi, ParseInt) very rarely. It is almost always nicer to use an fmt-function like Println, Printf, Sprint, Sprintf, Fprintf. They are much more versatile and easy to use. They do use reflection though and might not be ideal to use in hot-codepaths. 
Thank you!
Oh yeah that's a good point. I hadn't really considered the semantics. 
The thing to understand about `math/big` is that it was designed for efficiency first, usability second, and aesthetics third. The three-argument syntax of `x.Add(y, z)` is pretty ugly, but it gives you flexibility in terms of how many `big.Int`s you want to allocate. For example, if we're okay with allocating a new `big.Int` to hold the result, we can write `z := new(big.Int).Add(x, y)`. But if we want to reuse `x`'s memory, we could write `x = x.Add(x, y)`. This means that if you structure things carefully, you can write a huge function of `big.Int` math that only allocates a handful of `big.Int`s, and just religiously reuses them wherever possible. The downside of this efficiency is that it makes the API a little uglier/more confusing, but the Go authors did their best to make it usable. That's why functions like `Add` return a value instead of just setting their receiver: if a function returns a value, it can be used as an expression, whereas if it does not, it can only be used as a statement.
And the blog post: - https://blog.golang.org/go1.11 Packages are dead, long live the Go modules! :)
I am sure more than 5 people were waiting for these big news
Paying separately for code examples makes no sense whatsoever. If the code examples could be reproduced just by working through the material in the book, why should the author demand more money for them? On the other hand, if the code examples are markedly different from what readers can create from working through the book, that indicates the book itself may not be enough to fully understand the material. I buy technical books often and this is the first time I encountered such a pricing model. 
If that is the case, what is the point of using the former over the later?
I read about the allocation also, but if \`x.Add(x, y)\` re-uses the memory, why write \`x = x.Add(x, y)\` instead?
Link to the modules documentation: https://golang.org/cmd/go/#hdr-Preliminary_module_support 
Little page on WebASM [https://github.com/golang/go/wiki/WebAssembly](https://github.com/golang/go/wiki/WebAssembly)
Amazing! Lemme at them gomodules!
I wonder who's sponsoring it :)
I'm a bit disappointed by the need for a large JavaScript wrapper in the form of `wasm_exec.js`. I'm hoping that eventually that won't be necessary anymore and exporting functions to be used from JavaScript will be as simple as just building a package with those functions in them, [possibly marked with `//export` comments](https://github.com/golang/go/issues/25612). That being said, I'm quite ecstatic that this exists at all. I've already thrown together [a little test interface for Conway's Game of Life](https://deedlefake.github.io/conway) using this as well as moved over [the playground for my scripting language](https://deedlefake.github.io/wdte) to it from GopherJS.
You can't edit titles on Reddit. Even mods can't. You can stick a flair on it, though.
Time to convert projects to gomodules! ╭( ͡° ͜ʖ ͡°)╯
On linux-amd64 things are look good. But on linux-armv6l I am getting "plugin was built with a different version of package errors". What could this mean?
I am in violent agreement :) This would allow to use 'wagon' and drop some amount of JavaScript from the Go tree. - https://github.com/go-interpreter/wagon (But to be fair, wagon needs some more love to reach a point where it can be usable like so...)
Time to update my project that's been using `dep`
Whoever it is seems to not be in as much gold mood as usual.
Must've be the dep team.
I personally hope Elixir adopts this new system, but I'm afraid too many people are too locked in to the lockfile approach.
Nah, the Go community has a lot of hype and euphoria about itself and the project, therefore it could definitely be a community dude too.
For example, regex prefix routing, extracting parameters from urls eg, /users/:id/details), simple middleware use/reuse for groups of routes. Chi comes in at under 1000 loc, and makes use of standard lib handlers. It should be a useful lesson to go through it’s code and see what’s going on.
The glorious web-assembly era is upon us, prepare your compilers gentlemen (and ladies)! 
Finally, I can stop refreshing the downloads page! It was really pissing off my wife, especially as we’re on a family holiday.
Oh, nice! I’ve been wanting to do Game of Life as an exercise for myself in Go, but doing it in wasm kills two birds with one stone. So naturally I haven’t clicked on your link, sorry! Just have an upvote instead!
&gt; Who says releasing on Friday is a bad idea? Not people with a decent CI pipeline, test coverage and good QA process 
And using Gitlab for CI, it likes to stick you in a random folder anyway, which is outside goroot, so you can skip the bit creating the random folder at /app. Such a smooth process now!
Looking forward to no more `rm Gopkg.* &amp;&amp; dep init`
I would like some recommendations on this. Something that's not GORM. I kinda like how sqlx can use structures, I kinda want something that meets in the middle. 
[removed]
Ok. I wouldn’t call that go specific. I would do that in any language when dealing with user/external input. 
You should split that up even further for better caching. Build all your deps first as its own step so you don't need to do it each time. 
Google for "clean architecture in golang" and you will find several blog posts advocating for the controller/service/repo pattern that you're used to. That's more or less what I use and I think it works well.
The code is now available at [GOT](https://github.com/robaho/go-trader) Attached is an updated pprof graph, so you can see the code references. The interesting thing is that the flow is : quickfixgo reads socket and message -&gt; send update to channel -&gt; got processes the message -&gt; send update to market data channel so the number of channel messages processed by quickfix should be the same as GOT, but in reviewing the graph the quickfix causes a 10th of the time in mach\_semaphore\_signal... ??? &amp;#x200B; &amp;#x200B;
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/robaho/go-trader) - Previous text "GOT" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20e4sdto5) 
That doesn't explain why they would stop with the 1.11 release. Hence the joke.
Looks like we are on the GOPATH to victory \\( ͡° ͜ʖ ͡°)/
I'm not sure that GORM and sqlx and really fit into the discussion of design patterns. They are simply tools that may fit into a particular design pattern (like in the repository layer if we stick with the pattern described above). But to more directly answer your question, I've come to the conclusion that there isn't a great answer to your question. [Kallax](https://github.com/src-d/go-kallax) looks the most promising to me, but still falls short in a number of ways.
&gt; define a wrapper type for each implementation Yes, that's the best way. It's not great, but it's the best :-|
^^ yup. That's it. 
And see that is what I thought as well. I might need to figure out a way of opening multiple tabs in one session. Thanks for your help!
Hi thanks so much for responding! Sadly I do need to evaluate JavaScript as I wait for a webpage to load and then I use Chromedp to do clicks for me. There might be a better of doing this though. Do you by chance have any ideas? Thank you so much!
The fact that you don't need GOPATH to run builds changes *everything* from a devops perspective. It's always a nightmare setting up builds on a new tool. Most of them are just plain not designed to run builds in a custom directory. Add dep's poor performance and hardcoded cache on top of it, and it was not fun. Just this one change makes go into a devops dream.
I'm looking forward to removing the heap size limits! 
but do go modules support pinning Go developer tools per-project AKA per-module root, or nah?
WORKDIR creates a directory automatically. 
Hugo uses Mage, and I use Hugo, so by the transitive property, at least 6 people. 
&gt; Go will influence other languages to adopt saner version management Is this different from npm install ??
Yes, it uses a completely different version selection algorithm.
This has nothing to do with your workflow it's about something happen during the week end and no one is at work.
Quite soon after rc2. Not that I'm complaining
Thank you so much for this wonderful clarification. I'm also confused when to use `Decode` and `Unmarshal`. Now it is clear to me :) 👍
Yep. Completely forgotten that function, that is to be removed. Thanks!
Is the GC bundled as a runtime dependency when building for WASM? Since WASM has no GC yet. 
Seriously, this is huge. The GOPATH nonsense was a huge barrier to entry for a lot of people using Go more casually or fixing bugs just because of what a mess it made trying to work on multiple projects and how alien it is compared to most other languages/ecosystems.
Go has version management? lol
What do you think about Java's CLASSPATH nonsense?
Runtime not compile time, and generally already managed by every JVM-related tool/IDE/etc out there automatically. And most of the build tooling allows you to build a bundled jar in any case. Apples to oranges.
Make that 7, I use both to do tests with GoLand releases...
Here's the official documentation: https://tip.golang.org/cmd/go/#hdr-Preliminary_module_support
Once had a similar idea. I use [https://github.com/ipcjk/fifolog/blob/master/main.go](https://github.com/ipcjk/fifolog/blob/master/main.go) to capture and write log files with time stamps for some old daemon programs. Maybe helpful, so I will drop it here.
What about PYTHONPATH then? :)
&gt; I'm not sure that GORM and sqlx and really fit into the discussion of design patterns. ORM is a design pattern actually.
It depends. Routers may reduce some boilerplate code at a cost of increased complexity and introducing a global dependency through the whole app. IMO it's totally ok to use a router for a small server or inside a small component. But of you have multiple teams working on different parts of a big server, you probably don't want all of them to depend on a single lib. 
The (Bitcoin) economy is in the gutter...
That's terrible as well, and why tools like `pipenv` became so popular.
Using this type of architecture I immediately run into another problem; SQL transition across repositories. Go any experience with that?
There isn't one. The popular libraries for building web apps (Gin, Echo, Gorilla) are much smaller and not equivalent to an MVC framework like Rails/Django. I've gone back and forth between using those packages and using standard library only, and there the difference isn't *huge*. If you're looking for one, check out Buffalo. I haven't used it, but it looks like a big fully featured framework.
There is a difference. Java projects are responsible for assembling compiled classes and dependencies into a class path to run the project. There's no requirement that the source of the project and the source of its dependencies are stored and structured in any particular way.
I don't have experience with that but your solution sounds pretty reasonable.
Me too
what is provided in the source code? im confused
The source code is basically a starting point for any kind of side project you might want to start involving using a REST API as your backend. Things like user authentication/authorization, caching, throttling and rate limiting, billing using Stripe. The book start from zero and explains common web application concepts. Hopefully the source code can be seen as a starter kit for your next project that uses pieces of code that actually already run in production.
I'm really looking forward to someone doing a complete abstraction on the standard lib `js` package. It's a real pain to work with the DOM right now. Someone just needs to implement a proper API on top of the generic one in the standard lib e.g. `document.Call("getElementById", "foo")` becomes `document.GetElementByID("foo")` and so on. I've been playing about with this one a bit but it's still incomplete: https://github.com/dennwc/dom 
https://groups.google.com/forum/#!msg/golang-announce/O7POXMK3xbM/Ia8ObPyWDgAJ
Source code vs compiled code is irelevant when thinking about GOPATH. Go supports binary-only packages, which are quite like Java's `.class` files, for a long time and those are, of course, looked up also using GOPATH. Source form or the compiled one, in both the case of Go and the case of Jave, there must be a way how to translate an import path to a location where a compiled or source for of the class/package is located at either compile or run time, depending when that resolution is performed. And for the sake of completeness, AFAIK, GOPATH is actually going nowhere with the latest release. It just takes a default value when not set explicitly. And again, it's just like for Java: without the crucial piece of information provided by CLASSPATH/GOPATH, certain steps cannot be performed. Anyway, CLASSPATH/GOPATH is not that different compared to PATH. Yes, one can always use full, absolute paths to run commands. As it would be possible to interpret import paths that way. It's just non-practical to do so and makes projects dependent on things that may not translate well between different platforms or even between different machines even on the same platform. tl;dr: I have no idea why is GOPATH called a nonsense when it's actually a very essential thing upon which the whole build system is built. So far I'm ignoring modules, but IINM, this applies to using them as well, just in a more hidden way.
Because people value convenience and they tend to stick to what they already know. Nobody cares if they have to import 1000 loc of a dependency, just as long as they don't have to manually write 10 lines of code themselves to extract keys from the path. 
Why were you doing that in the first place?
At chapter 3.2 You created type User struct{} and added **func'**s but you didn't share the entire code. **u.Profile** was missing I found it from source code though. I feel you just share the code and jump without explanations. Pasting big lines of code in book and just going ahead without explaining, even the code has many lines. &amp;#x200B; So far the book feels like just a code review...
Classic friday release. Brave souls
Looking forward to seeing if the WebASM stuff will produce enough community interest to create something that can compete with the NodeJS community in the front end department. I know we have a couple projects still in the early stages, but I would love to get to a point where we can develop a complex web application quickly, easily, and efficiently without needing NodeJS or Java/TypeScript. 
 !reddit coal
Cached modules go in $GOPATH/pkg/mod, binaries go in $GOPATH/bin or $GOBIN.
If your url paths contain parameters, using a 3rd party route package will get a better readability.
This article claims strings are passed by values and functions are passed by references? I'm just curious that how could you prove these claims? Strings and functions are all immutable internally. 
The big difference is that PYTHONPATH is not meant to be a workspace, and module resolution is not limited to it.
There's a difference between "pass by reference" and "being a reference type". Slices, pointers, maps, channels… are all *reference types*, in that a value contains a reference to some other data. But they are not "passed by reference", because that usually means C++ references - which isn't in the "type" domain, but an alternative term to "variable", i.e. designating the storage location. So, a) in Go everything is pass by value - when you call a function, you always copy a value. But b) that value can be a reference type and that reference usually still allows modifications.
RTFM https://golang.org/doc/go1.10#test Use -count=1
Question on that. I'm reading through now and will think about this some more, but in the meantime was wondering how middleware-type functionality--such as authentication, logging, etc.--would be handled with this scheme? (Thanks.)
Because it's faster and less frustrating to just go nuclear than manually troubleshoot dependency problems. 
Also pick up your damn kids from school for once, I’ve had to give them rides every day for the past month!
Did you mean to reply to someone else? I don't see how your response is relevant to my question. 
Hurray!
Not an application design pattern being discussed by the original comment though. Although neither gorm or sqlx are ORMs.
No easy to read way to get path segments for IDs. No easy way to get query param values. No easy way to express verb/path routing combos. All of these can be done with a bit of extra code, but I prefer httprouter’s functionality for these reasons.
&gt; Java is an interpreted language, so classes are loaded at run time. Other than that, there's no substantial difference between a Java class and a Go package, neither there's any substantial difference between CLASSPATH and GOPATH. By this logic, everything that isn't statically compiled is interpreted. Java is *compiled* to a bytecode. Classes are loaded at run time yes, but it's not that different from dynamic linking. More importantly, GOPATH is clearly intended to be set globally, while CLASSPATH is virtually always set per-project, and behind the scenes. &gt; IMO, people thinking that they need a GOPATH per project are making trouble for themselves and that it's not the GOPATH which is to blame for that. This is the bit I very, very strongly disagree with. Being able to isolate dependencies across unrelated projects is an essential feature and exists in virtually every language and ecosystem out there. Golang is one of the only modern exceptions, and they've been forced to backfill with workarounds like vendoring since the beginning. &gt; So you're claiming the very existence of GOPATH actively discourages properly isolating projects from each other? How can poor GOPATH achieve that? The GOPATH forces you to turn project org paths inside out, so that your code lives at the bottom of a system-wide global tree instead of having dependencies mapped in the project's own context. Tools like dep are effectively workarounds to subvert the problems GOPATH causes.
I use standard library for routing both for work and personal. I wouldn't be opposed to gorilla with how long it has been a leader, but I prefer to limit dependencies to database drivers / badger, gonum, search (bleve), or maybe one specialized tool for ntlm or uuid gen or something.
Is there an easy command for building all dependencies after doing go mod download?
I agree that Dep has pretty nightmarish performance. I don't quite understand how modules make GOPATH unnecessary, though. Won't your modules still have to be parked in your GOPATH to be found during compile time? I'm not too familiar with Go modules myself (having yet to experiment with them) - from what I can understand from quick article reads about `vgo`, it's basically what's going to replace Dep as the official "answer" to package management, right? 
&gt; asymptotically approaching boring _Yesssssssssssss._
Go modules can resolve their dependencies on their own, with no need for an external tool. This was called `vgo` in the prototype phase, but it is now built into the main go binary. If you type `git clone github.com/my/awsome-module /foo` and then `cd /foo &amp;&amp; go build ./...` it will automatically resolve dependencies in the go.mod file and run your build. No need to think about GOPATH.
Ah! I get it now - code that you want to build no longer need to be in GOPATH! That is pretty handy, I must admit. I might think of converting my existing apps to this. Thanks for the explanation! But if `my/awsome-module` itself required, say, a module from `github.com/your/other-great-module`, then `your/other-great-module` would still be saved into `GOPATH`, no? They wouldn't be saved to a `vendor` subdirectory like it was for Dep?
There was an issue for supporting smth like that. Not sure if it got resolve in this release, but it seemed the team is commited to having a solution for this.
The vendor subdirectory is also deprecated, however your dependency would be downloaded to the module cache at `GOPATH/pkg/mod`
Thank you very much. I could find info [here](https://golang.org/doc/go1.10#build) in the go 1.10 release notes. But where are they stored ? What happens with the binary ? Before I defined GOBIN and added the dire tory to the PATH environment variable. What do I have to do know ? Things changed so fast that I'm lost. 
Congrats on your first package! My main comment is that a logging package (or really anyone outside the program author's control) shouldn't be using panic/log.Fatal/\*Must functions that will kill the calling program. If you can refactor those parts to return an error instead of killing the program I think that would be a big improvement. Cheers! &amp;#x200B; [https://github.com/omrikiei/go-logging/blob/master/formatter/formatter.go#L71](https://github.com/omrikiei/go-logging/blob/master/formatter/formatter.go#L71) Using template.Must will cause the program to panic if the template fails. I think it would be better to return (\*LogFormatter,error) and not use a Must\* func. [https://github.com/omrikiei/go-logging/blob/master/formatter/formatter.go#L79](https://github.com/omrikiei/go-logging/blob/master/formatter/formatter.go#L79) don't panic in a library See [https://github.com/golang/go/wiki/PanicAndRecover#usage-in-a-package](https://github.com/golang/go/wiki/PanicAndRecover#usage-in-a-package) &amp;#x200B; [https://github.com/omrikiei/go-logging/blob/master/formatter/formatter.go#L69](https://github.com/omrikiei/go-logging/blob/master/formatter/formatter.go#L69) NewFormatter should be renamed New() since it is already in a package called formatter. See [https://blog.golang.org/package-names](https://blog.golang.org/package-names) &amp;#x200B; [https://github.com/omrikiei/go-logging/blob/master/formatter/formatter.go#L84](https://github.com/omrikiei/go-logging/blob/master/formatter/formatter.go#L84) this should be a const &amp;#x200B; [https://github.com/omrikiei/go-logging/blob/master/logging.go#L95](https://github.com/omrikiei/go-logging/blob/master/logging.go#L95) log.Fatal kills calling program &amp;#x200B; [https://github.com/omrikiei/go-logging/blob/master/logging.go#L45](https://github.com/omrikiei/go-logging/blob/master/logging.go#L45) typo in comment &amp;#x200B; &amp;#x200B;
&gt; Street, for example, isn't labelled as 'rich text,' but malicious or mistaken users don't care what it's supposed to be. In this case, I still often try to harness the type system where I can to make it so the code has to be escaped. However, I am often fought by the template authors who want to make things too convenient, rather than safe. So it depends on the template language you use. Go templates are actually one of the better ones I've seen, at least from a safety perspective. If you dump an address out in the natural way, it'll be safely encoded. You don't have to ask for safe encoding, you have to ask for unsafe encoding. If you use another template language your mileage may vary.
Boring is good in this case. Code you'll be able to maintain in 10 years. Compilers which will still be relevant in 15 or 20. All of this is a welcome change to the mess we have now.
Some choice quotes from speaker notes: &gt; I'm pretty sure Go 2 will have generics. &gt; No "Go 2" named release without generics. It would just be too much marketing for too little excitement. Also some other "probable" changes: - improved error handling, maybe with actual types (slide 99) - arbitrary precision `int` (slide 103) - modularized stdlib, with packages being updated outside of the Go release cycle (slide 88)
I _love_ the Go community embrace of mature stability. Landing a plane and getting a colonoscopy are other similar activities which I do not want to provide me with exciting surprises.
The term "reference type" has no meaning in Go as the language specification never mentions nor defines it nor it is a well defined thing per se, like eg. prime number etc.
&gt; The term "reference type" has no meaning in Go as the language specification never mentions nor defines it nor it is a well defined thing per se, like eg. prime number etc. It is a pretty well defined term though, as "types, whose values are references to other values". Go also doesn't have subtyping and the FAQ still refers to [covariance](https://golang.org/doc/faq#covariant_types) - it turns out, that [assignability](https://golang.org/ref/spec#Assignability) provides a good enough approximation to still talk about the concept. The spec might not use the term "reference type", but Go still has reference types as a CS concept. It makes sense to use Go-specific parlance when talking about Go problems. But when explaining concepts to someone coming from a different language (as is usually the case when you try to explain the "everything is a value" adage), using commonly known terms is a good way of making yourself understood - the ultimate goal of language. Even if they are only approximately well-defined and only approximately correspond to the corresponding Go concept.
I spent much of the beta benchmarking go WebAssembly. For anyone interested in writing anything serious the go to js touch points are very expensive. https://github.com/golang/go/issues/26277 Tricks to get around it. 1. Use invoke instead of call. This removed the overhead of serializing strings out but buffers. 2. Combine multiple call outs in to just into a single helper function. You can do this either by creating a new functions at runtime or write helpers in js and reach out to them using syscall/js
it's honestly such a circlejerky statement. *No* language seeks to bring chaos into developers' lives, which is the opposite of the definition of "boring" being used here.
The question of which debugger would influence the method to do it quite a lot. In CLI debuggers for example you just execute: (gdb) run import --src_type=redis --src_uri="redis://localhost:6379/0" redis-test
My job is to deliver features that the business asks for. Nobody who counts in the organization is going to give me extra credit if I write a clever regex or have 10 lines of string splitting code to parse an ID out of a URL. I would love to see a web app that is so performance critical that the extra handful of lines of code from a small routing library was a measurable drawback in production. In Ruby or Python communities most companies use enormous web frameworks without thinking twice. On the other hand in Go, a macho attitude creeps up if you don't roll your own database driver. There's plenty of room between the extremes of having 4TB of transitive dependencies in the node_modules folder of your hello world app, and insisting that your kernel and compiler must be written in-house. For me personally the sweet spot is somewhere in the middle.
No language seeks to bring chaos, but some _do_, and the Go language and the Go community incorporate lessons learned from those languages. I would point to Go's intentionally limited scope as the primary example of this "boring" outlook. Java has feature creep. PHP has godawful inconsistencies. Javascript has type thunderdome. C has pointer arithmetic. That's okay. Go isn't trying to compete with JBoss, Wordpress, React.js, or Linux.
Go has many inconsistencies and surprising behaviors too. The more advanced Gophers brush these problems away because they have memorized them, just like advanced users of other languages. That's why this is circlejerky. Advanced users of any language would tell you the same thing, it's an echo chamber effect. "append" has *very* surprising behavior. Zero values are rarely desirable and often surprising, the compiler should instead statically check that a value has been assigned before it is read. Types are allowed to have methods, but the "primitives" (including strings and arrays) are apparently unable to have methods, so they have to use free functions, which is completely different from how everything else is typically written, and it's annoying because there's no way an IDE can help you by showing the methods like "find" or "sort" that would normally be defined on such types. Generics exist, but only as special cases. Enums don't exist, so this magic keyword "iota" magically does things?! There's nothing intuitive about that. The net/http ServeMux has often been quoted as confusing beyond the most basic routes. This list could go on. Go is not some specially boring language. Go *is* effective and useful. But it would take a concerted ergonomics initiative to fix all of its non-boring parts, and that's obviously not going to be boring for advanced Gophers, and it's obviously not something that could keep compatibility with existing code.
I really like where this project is headed so far. Enough that I added it to the tools supported by my \[automated dev environment setup for Windows\]([https://github.com/paltry/paltry](https://github.com/paltry/paltry)).
I really like where this project is headed so far. Enough that I added it to the tools supported by my [automated dev environment setup for Windows](https://github.com/paltry/paltry).
Totally didn't come here for gold
I think he's trying to imply that circuitously is a noob or something. The text itself is copypasta.
I’m with you on Enums. Why do we still not have them???!!! But what do you find surprising about append? The behavior seems straightforward enough to me.
This lazygit project really blew up. So much activity with it now it's crazy. 
You can have compiler directives without resorting to magic comments. Go's approach is particularly unorthodox and results in really weird stuff like the compiler depending on the runtime. 
Go's approach here is particularly weird since there are semi-documented not-in-spec magic comments that the gc compiler only supports if the comment is in the runtime package. I'd say a compiler depending on the runtime is *very* surprising behaviour and it suggests the devs were trying to work around deficiencies caused by earlier design decisions that they got stuck with. 
Compiler directives are not usually comments, they're a special syntax that stands out. As for what's wrong with append, [this was a great, succinct blog post](https://www.jjinux.com/2015/05/go-surprising-edge-case-concerning.html) on it. [This one](https://allegro.tech/2017/07/golang-slices-gotcha.html) also does an adequate job of describing some of the issues in greater detail. Essentially, `append` simultaneously mutates the slice that is passed into it, and returns a slice. In my opinion, the only sane choice would be one or the other. If `append` returns a new slice, it should not mutate the argument at all. If `append` mutates the argument, it should not return anything at all. When I was a newcomer to the language, I incorrectly assumed I could just `append(a, whatever)` and that it would work. It turns out that the only thing you should ever do is `a = append(a, whatever)`, to keep from having aliased slices.
No. To illustrate the difference, let's say you write some code that imports Library A and Library B. It turns out that deep down, they both use library C, but A wants version 1.3.4 and B wants 1.4.9. In NPM, [it will run two copies of library C](https://npm.github.io/how-npm-works-docs/npm3/how-npm3-works.html). This extra code takes longer to compile, takes more memory (ever wonder why your browser takes GBs of RAM?), etc. A single web page can load dozens of copies of the same library because nobody is paying attention. It might even cause odd problems because they can't share state. (Say the library exports metrics: if you have two copies, each will have to send their own metrics packets, which could confuse things.) The previous solution was thought to be 'dep' for Go. It tries to guess what versions might work, based on hints from the programmer. The programmer might assume that 1.3.x should be fine for A, and 1.4.x should be fine for B. Even with hints, dep may not be able to find a solution. (And when you have dozens of libraries, the math is extremely complicated. It can even downgrade versions to try and find the 'best' solution.) All this complexity is comes from the statement "we can't assume A will work with 1.4.9 because something important might have been removed from 1.3.x to 1.4.x." Go says "that shouldn't happen", and libraries must follow [semver](https://semver.org). This makes the solution trivial: use library C 1.4.9, which is the highest version we need. If that breaks A, it's a *bug in library C* and should be fixed. (If they fix it in 1.4.10, then A can say "I require 1.4.10" and everything will start using that version.) If A starts using C version 2.0, all bets are off. So Go will have a 1.x version of C and a 2.x version of C. This is similar to npm, but we won't have multiple copies of 1.x or 2.x like npm will. So the new module system of Go is a much simpler system to understand, debug, change, upgrade, etc. If you are using version 1.4.9 today, you will be using it tomorrow unless you install something that needs a newer version. That version will be the max version of all your libraries. Super simple to understand, no unnecessary extra copies. 
append can't mutate the slice because Go is pass by value. You would have to pass the input slice by pointer, but that would be forcing everyone to pass slices by pointer which is inefficient and increases GC load.
An optimization is not the same as twisting the semantics of the language. Optimizing map clearing does not change the semantics of the language. The implementation still produces the same results that the language specifies, just faster. Making append magically pass by reference violates the language spec.
&gt; prevents you from keeping two copies of the slice In my mind, that's what the `copy` function should be for. That kind of shared, mutable aliasing just leads to pain and confusion in order to save a trivial amount of copying. Modern computers are _very good_ at `memcpy`-ing things.
Thank you. To be honest I really struggled with it - and it seems it should be a simple thing. I found the basis here [https://golang.org/doc/code.html](https://golang.org/doc/code.html) which I think is the real reference document, but it appears I might have miss intepreted it.. but then again, the Go standard of having everything in a repo is a bit disturbing. The document you cite is a "community effort", and with the Java digs included, it is hard to take seriously. If I change things as described in your document, are the go build tools still going to work correctly? They work fine now with the current structure. Meaning, from anywhere I can type go install packagename and have it auto place the binary in bin? That's the way it works now. Essentially mine requires a local GOPATH - it is a top-level project. Can you offer a specific suggestion given that the project produces a reusable library, and multiple standalone applications ? I really would like to do this "right". &amp;#x200B; &amp;#x200B; &amp;#x200B;
what do you mean? :S
Go was built by Google and for [Google's monorepo](https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext) way of doing things. They are only now monkey-patching Go with experiments to solve these issues after years of community outcry. Trampling over its very community efforts in the process. You'd think that having the luxury of observing a rich history of trade-offs and errors from other languages would make them threat versioning and build reproducibility as a first class citizen.
Go was built by Google and for Google's monorepo way of doing things. They are only now monkey-patching Go with experiments to solve these issues after years of community outcry. Trampling over its very community efforts in the process. You'd think that having the luxury of observing a rich history of trade-offs and errors from other languages would make them treat versioning and build reproducibility as a first class citizen.
and Go has some obnoxious runtime reflection, string tags, and other horrors and is trying to reinvent the wheel with Go 2, because of course its creators didn't get it right on the first try. No language does. 
&gt; arbitrary precision int That's my fetish
You might feel badly about dep not being chosen, but it had severe issues that prevented many people from using in a professional environment and it didn't seem like they were being fixed.
There are more open source Java projects than any other language, and it didn't need to resort to the current Go scheme. Open source java is trivial to use with systems like maven, and even barebones, dropping a jar in a directly is pretty brainless.
People tend to vendor dependencies if they might be unstable, minimize third party dependencies, and a single gopath does not mean a single repository. I think modules will make it much simpler, and I look forward to that, but major Go packages tend to work extremely hard to not break APIs. For personal stuff I don't even vendor and stuff still almost never breaks. I'd vendor if necessary.
I fully understand about maintaining APIs. Probably the King of that is Java, as java 1.0 code will run in Java 10 today unchanged in almost every case. Although the world of Java libraries are far different, most major systems make API breaking changes on every major release, thus the need for proper version management. Java is as great out of the box as something like Node and NPM, Node handles different versions of different libraries pretty seamlessly - with Java you need a container and specialized class loaders. With Go, I don't think it is possible due to the static compilation, and name collisions between versions.
The site could be refusing to answer requests it thinks look like a bot. Some sort of rate limit might return an error or it might just hang up.
&gt;hatenocattle Hey /r/hatenocattle, great feedback and insights, thank you so much! committed my fixes following up with these comments..
Grpc is great when you control both ends of the conversation, and need a streaming protocol. But protobuf plus mqtt is a great combination too. Http for anything web based obviously.
I found GRPC confusing and ended up using gob over HTTP, which was sufficient for my needs. (I controlled both ends of the conversation.)
It's interesting seeing how the community consensus about `vendor` has evolved. When Dep was the hottest new tool, many insisted that "checking in your `vendor` subdirectory was best practice" because "it makes your build completely reproducible" and "you're not at the mercy of GitHub/someone else taking packages down". Now, `vendor` has been deprecated and we're once more "at the mercy of someone else" when we try to build. Since I'm mostly a node.js dev as my day job, I don't really have a big issue with this (I've long since accepted that if NPM went down for a day, a quarter of the world would break). But I'm curious what the community that *did* support Dep for that reason feel about it. Personally, I kind of liked the `vendor` subdirectory because it made builds semi-portable. I could chuck the root directory of my app to you, you could put it in your GOPATH, and you could rebuild the entire thing without having to `go get`/`dep ensure` anything. But Go modules method of caching modules in a globally accessible directory will undoubtedly save a lot of disk space and cut down on build times. One of the major downsides of `npm install` is that a fresh install always takes an eternity even if you've already previously installed the same packages for other projects hundreds of times. 
[grpc-gateway](https://github.com/grpc-ecosystem/grpc-gateway) addresses the first item (lack of HTTP1.1). I use it at my company (for a minority of services), and I appreciate having a well-defined data model, but it requires several extra steps when you want to make changes. Every time I do this, I always feel a little bit of a regret in not sticking with the standard library and plain JSON. As for organization, I tend to keep the proto files (and generated Go files) in a standalone project, so that any client that needs them can vendor them. I ran into one issue a while ago where it wasn't handling context timeouts correctly, and ended up crashing the service I was working on (I think that was when Go 1.7 was released, along with the standard context package). They have fixed it since, but debugging that was not fun. I had to hack and patch the source code until there was an official fix.
Finally! Congratulations and thank you for this awesome release.
Tried that too. go build updates the go.mod with a new line like: \`\`\` require path/to/pkg v0.0.0-20180826051727-469687506a43 \`\`\` Somehow, I'm not able to make it pick up the uncomitted changes.
&gt;OK, first I am new to Go... I have a lot of experience with other languages, especially Java. ... &gt;SO, I'm sure I'm not understanding this correctly, but can someone with more knowledge explain the flaws in my reasoning? I'd love to answer address and specific problems or questions you have about GOPATH and/or go modules… but honestly, after reading your post, all it sounds like you're asking is "why doesn't Go do everything like Java?" The only response to such a broad question is simply "because Go isn't Java, and it made different technical decisions with different tradeoffs." The official FAQ [also answers this general question](https://golang.org/doc/faq#Why_doesnt_Go_have_feature_X). The GOPATH worked well enough for a few years, but turned out to be a bit too simplistic in the long run, which is why we're moving to go modules now. Go modules probably address most of the root problems you have with GOPATH, as long as you can accept that that they still aren't Java classpaths. To be honest, you picked a slightly awkward time to pick up the language due to this transition. Your options are to learn and use the battle tested GOPATH today and then learn and switch to go modules in the relatively near future, OR just jump straight to go modules even thought they are very new and technically experimental. I'd recommend the using go modules if you can, because they are a clear improvement and also because learning a system that is about to become outdated is a waste of your time. OK! With all that out of the way, let's get back to your actual questions. &gt;From the Go docs "A typical workspace contains many source repositories containing many packages and commands. Most Go programmers keep *all* their Go source code and dependencies in a single workspace." &gt; &gt;This is just not feasible for most professional organizations, especially consulting type groups. Can you elaborate on this? If everything has a unique name/namespace, why can't they all live in a single workspace? That's the whole point of having namespaces. &gt;In the Java world, you create packages like, com.company.product to avoid name collision when sharing code. This works really well, and allows flexibility as to where the code resides... you just need to set a classpath for both compiling and possibly for running that includes the directories (and/or jars) of the dependent code. This is pretty much exactly how we do it in go too, except instead of `com.company.product`, we happen to use the format `somedomain.com/company/product` instead and we put the code in the path on disk that matches its name. This is a mostly a cosmetic difference and I'm not exactly sure what you find so confusing or problematic about it. &gt;In the Go world there seems to be a push that everything is shared, all is accessible, and I don't think that matches reality. I know that in 1.11 there is modules, which appears to be an attempt to resolve version conflicts, but it seems to me that the problem with GOPATH is deeper than that. IMO, this very much "matches reality". Packages (and modules) are precisely for sharing bundles of code to the world. Any package can import any other package (baring import cycles and "internal" packages). In that sense, "everything is shared" is the only reality. For example, every package published on NPM is shared with and accessible to all other packages. Go packages are no different. I'm honestlt not sure what reality are you living in, but if you could elaborate here it might help. &gt;The GOPATH supports multiple entries, e.g. GOPATH=/home/go:/home/myhobbies:/home/mywork and "go get" installs into the first. &gt; &gt;So, why is it not accepted practice to when creating go projects to install them however the developer wishes, and as long as the GOPATH is set properly, the build tool should find them ? &gt; &gt;It works for me, but in my project [GOT](https://github.com/robaho/go-trader) I've already been chastised for using a "incorrect directory structure". Honestly, if it works for you, and you will always be the only developer for that project, then you do you. That said, it's generally bad form to ignore the best practices and widely accepted idioms for any languages community when writing code in that language. If I were to write Java as if it were Go, I'm sure my colleagues would chastise my directory structure for being "incorrect" and they'd be right to, especially if my choices didn't play well with Java's tooling &gt;There seems to be a problem between how "go get" works, and how an import statement is resolved. I should be able to use "go get" to retrieve a public package from anywhere, and install it anywhere, and as long as my GOPATH (like a Java classpath) is set correctly, it should find it during the build process. This is more or less exactly how Go works. You can put your GOPATH wherever you want and as long as you install your packages in the correct subdirectory within your GOPATH (e.g. the one matching it's import path) then the go tooling will find it during the build process. &gt; This even solves the versioning problem without modules, just go get xxx v2 into a local directory that is earlier on the GOPATH... This is where you totally lose me. If you think that "the versioning problem" has a well defined meaning, and that the solution is simple enough to be conveyed in one sentence, then you have not fully explored the problem space.
Please find the documentation here - https://golang.org/cmd/go/#hdr-Preliminary_module_support. Last para answers your questions.
To me, Go is boring not because it doesn't have surprises and inconsistencies. It's more about that the programs written in Go tend to adhere to a plain and straightforward style. There is a programming culture in certain languages like C++ that tolerates or even encourages clever abstractions/indirections. So we have frameworks creating their own walled kingdoms, which have branded naming convention, string classes and even special syntaxes. This line of thinking explicitly wants to give the the ultimate power and flexibility to the library vendors. On the other hand, the culture of Go likes minimal number of layers. Uniformity is often valued more than customizability. Instead of letting the framework vendors invent everything you need in their super powerful frameworks, the Go culture keeps composability in mind and do not require a library to be versatile. When writing code in C++, many people would be stuck in the mentality of finding the optimal abstraction and trying to squeezing the last bit of the \*advanced\* language feature set that could make the code shorter and DRY, which makes the language exciting. In a more boring language like Go, there is little advanced features prepared for mainly library authors to make the magical things happen. &amp;#x200B; P.S. \`reflect\` probably belongs to the \*magical\* category that is mainly for library authors. But I think the point still stands in terms of the culture difference among languages.
The terminology "reference type" is very misleading. One misleading is that many Go programmers think array and struct types are never reference types. However, by its definition, a "reference type" is a type whose value may reference other values. By this definition, an array type with a pointer element type is also a reference type, and a struct type with pointer fields is a reference type too. The explanation conveniences brought by the terminology "reference type" are more than the confusions it brought. 
That's clear now. I was confused by the claim that GOPATH is dead or the off flag. It is thus still used and needed, unless we use $HOME/go. 
Yeah we do it as well. All proto files life within a api folder. Since all of our mircoservices are written in go we don’t have any “language clutter”. How is it for you? Do you use multiple languages?
Majority of them are go, small percentage is python and node at backend. Java and Swift gRPC client on mobile. GRPC gateway with typescript definitions on browser. 
Ok i see what you did there. The GOPATH is usually meant to contain all your go projects. So when you use *go get* it will be download within GOPATH/src/&lt;repo url&gt;/&lt;your project root&gt;. If you do *go install * within a folder with a main.go in it, then it will be installed (compiled into) GOPATH/bin with the binary be named as the folder your main.go lifes in. So move your main.go files to &lt;project root&gt;/cmd/&lt;binary name you wish&gt;/main.go. All common code to /pkg/ or /internal/pkg or /internal/app/&lt;binary name&gt;/ (if you have app specific code). Those changes will break your config approach, but i would suggest moving the files into /configs and use GOPATH/src/&lt;project url&gt;/configs/ as the default include path. Otherwise the defaults could simply life within the binaries. I am not sure which restriction you may face with Intellij. I am currently just on mobile and my workstation isn’t in reach. So i still didn’t dig deeper into your code. I hope i was able to explain it well enough. 
We've used gRPC heavily and our experiences with it have generally been good, especially grpc-go (grpc-python has been a little more frustrating). To some of those concerns, we did early on pipe gRPC through ELBs and did rapidly find out that was a bad idea. Once those were out of the way (which was beneficial for many reasons) we have no requirement for HTTP1.1. We typically upgrade the codegen (for all languages) and runtime simultaneously. That really requires something more powerful than `go build`; our generated proto code is never checked in and gets regenerated on the fly, and we pin particular versions of the gRPC and protobuf libraries (modules and vgo will probably help with that at least). On the bright side the compatibility of the wire protocol is good - running services do not have to be upgraded in lockstep, which would obviously be unacceptable.
You don't need to bother about it anymore. No need to set any env vars, or cloning a repo in some exact path. GOPATH is essentially an internal detail now. Only if you need to access installed commands from command line, you need to add $GOPATH/bin to your $PATH. I don't see a way around it. The packages and installed commands still need to exist _somewhere_.
Aside from the advantage of being able to program in Go, is there any reason one would use it over the existing (and popular) discord.py and discord.js libraries?
I like to understand how it works in case something is broken. What if there is no GOPATH and no $HOME/go directory ? Is a $HOME/.go directory created ? I used to run $ goinstall &amp;&amp; myApp
This will become less useful now wasm can be compiled to, right?
Prometheus (https://github.com/prometheus/prometheus) might be a good source for inspiration. Other tools I have used in the past are: - munin (back in the day...; http://munin-monitoring.org) - LibreNMS (https://www.librenms.org, https://github.com/librenms/librenms) - the TICK stack (https://www.influxdata.com, https://github.com/influxdata)
Yes, the book describe each implementation in fact, starting from the table of content the book start from scratch and talk about how one would build an API with Go. I think Go will improves any developer skills, cutting multiple level of abstractions that other languages/stacks tend to offer while keeping time to market very short. Also the end results is a more robust code base after 2-3 years in my opinion.
I found channels were the right abstraction for making the discord bot communicate with other independently running components.
Yeah grpc seems the safest route to go for a new project. I'm still going to take a few days to decide. I do like Twirp however.
I'm just sketching out a new project and this seems to be the best way to do it, you're right.
Maybe you can draw some inspiration from a post i wrote some time ago on how we handle a monorepo at our company - https://filipnikolovski.com/managing-go-monorepo-with-bazel
What do you consider “real time”? If it’s being requested by an API it’s probably already at least a second old depending on the network. Do you want to only display current metrics or a history up to the latest? If it’s the latter then you’ll probably want to look into a time series database. Otherwise just retrieve the metrics and return them when you get a request.
`vendor` is not dead ! we can still use it (`go mod vendor &amp; go build -mod=vendor` We'll have a lot of others possibilities with goproxy (`go help goproxy`). Basically it's `GOPATH/pkg/mod` but it can be a local webserver or a community server like https://docs.gomods.io/
You still need main packages for each service. Probably something like: bin pkg logging errors foo service auth main.go analytics main.go Then just use a makefile or script to build and package everything.
Footprint will be nice. As docker container built on scratch you would have a \~20mb footprint with minimal cpu/ram usage. So why not.
truly awesome, thanks for sharing
I didn't know about `go mod vendor` - that's awesome! Now I can use the global cache for regular builds, and still have the option to create a "portable build" whenever I want. I take it the comments about `vendor` being deprecated are premature, then? Or has the Go team expressed interest in removing support for it? About goproxy ... `go help goproxy` returns this for me: ``` Unknown help topic `goproxy`. Run 'go help'. ``` Is it because I'm not on 1.11 yet? Is it this (https://golang.org/cmd/go/#hdr-Module_proxy_protocol) feature? As I understand the doc, this would mostly be useful for consuming "mirrors" for libraries, right? Like, if I used `github.com/your/useful-golang-library` in all of my company's projects, but wanted every build to use my onsite NAS for quicker downloads instead of having to fetch it from GitHub? 
Could you give me some of the real world benefits you've found with go? I'm 2/3 through my first mid sized project with go and I want to know if I'm missing out on anything. All the blogs I've read reiterate the same high level points and am interested to hear something from 'on the ground'.
Hi. Thanks for taking the time to reply in-depth. Let me see if I can summarize as I think the gist of issue is being lost. I can see how putting everything in a repo of some sort is workable, especially when using private repos. The problem occurs when you 'pull from the repo' to use. A common issue I've needed to address is that I need to pull version 1 and version 1.x of a project and run them side by side - comparing differences. Because the Go system restricts where I can pull the package to, this seems difficult if not impossible, It is more difficult when two different "packages" (lets says different clients of the same software), build - they all get installed into the same top-level... Ideally, I should be able to install where-ever. I want this project segregated on the file systems for easier zipping of log files, easier pointing of 3rd party tools to the outputs, etc. It's almost as bad as saying, everything must be installed in root/C: just barely better. I THINK the proper way to solve this, is that I need to "open terminal, set GOPATH, pull code for version 1, open another terminal, set different GOPATH, pull version 1,1"... but it doesn't appear 'go get' understands version tags (thus modules?). So without the version tags, I can't use 'go get' and must manually clone the projects and do similar work to set the GOPATH). The latter is how I set up my code base for GOT - it is designed to be pullled/cloned and have its top-level install directory added to the current GOPATH - works fine in Intellij as well. But I've been informed this is not the proper way... thus my confusion. &amp;#x200B;
This is basically what I use with a top level docker compose file that will take care of building and running everything. Just be careful not to let your common package get too big, and keep it specific to go. 
If you want to provide a project closer to real life how about a RESTful endpoint using TLS? This project includes that with the simple goal of allowing clients to add ids and then validate they exist. Therefore they will learn how to setup a web server, routes, and share data structures. https://github.com/leonj1/go-tls
with gdb you can do: gdb --args ./abc import --src_type=redis ...
You might want to check this out. [https://github.com/flowerinthenight/golang-monorepo](https://github.com/flowerinthenight/golang-monorepo) This repo is actually a stripped down version of what we are using at our company. Right now, our company's monorepo has gone from go-only to multi-language but the underlying build system is still the same.
Got two minutes into the readme, then played the 2048 clone from the example for 10 minutes. 
We do it in our company the way you seek. I am on mobile, so wont be giving all the detail, if you have more questions ask through private Here is the structure: Scripts Makefile compose-file Jenkinsfile Services Service-1 Cmd Main.go Protofile Kubefile (we use kubernetes, this defines deployment + service) Service-2 Cmd Main.go Protofile Kubefile Scripts folder has some scripts like generating protobuf files Jenkinsfile defined the pipelines to build and deploy Compose file defines test images and actual run images to use on deployment Basically for the deployment of every service you run main.go of that specific service in the container, but every service’s container is identical
https://peter.bourgon.org/go-best-practices-2016/#repository-structure
At the moment, we are already checking out go modules. So far, we're not seeing any significant changes. The structure also will remain the same. We've already upgraded to 1.11 but everyone is still using GOPATH so no changes for now. Everything still works. I'll probably upgrade this monorepo to go modules as well when we are done upgrading the company's monorepo.
I modeled my monorepo on [cthulhu| https://blog.digitalocean.com/cthulhu-organizing-go-code-in-a-scalable-repo/], but had to write a custom build system to be able to build things the way I wanted.
Might take a peek at https://github.com/karrick/godirwalk. I can do up some sample code as a suggestion later, but take a peek at it and it’s examples for now.
I am noticing odd behaviors as well. I hope it is just due to tooling lagging behind the release. Outside of the tooling everything seems to be working. One thing I saw, was without specifically turning module support on, my go.mod file picked up all of the tooling add ons in the default GOPATH(~/home/go). Once I turned module support on go mod cleared out all extraneous packages in my GOPATH.
I installed it from the website. PPAs aren't necessarily updated that quickly, are they?
No, thanks. Let's write for platforms that don't harm their users' privacy instead.
From https://github.com/golang/go/wiki/Modules *"Typically the go.sum file should be checked in along with the go.mod file. go.sum contains the expected cryptographic checksums of the content of specific module versions. If someone clones your repository and downloads your dependencies using the go command, they will receive an error if there is any mismatch between their downloaded copies of your dependencies and the corresponding entries in your go.sum. In addition, go mod verify checks that the on-disk cached copies of module downloads still match the entries in go.sum. Note that go.sum is not a traditional lock file as used in some alternative dependency management systems."* 
I’ve wrapped a few ruby apps in Go using the stdlib net/http reverse proxy. The main goal was providing a grpc interface around a legacy system. It works really really well. 
where did you run the go get command? if you're going to force that flag to be on, instead of auto, then you have to be in a project directory with a go.mod file. Forcing it on almost means there is no $GOPATH anymore.
You can always download and untar the package from the website.
That sounds like it might be what I’m looking for. Do you know of any good tutorials/examples to learn from?
Have you tried gvm https://github.com/moovweb/gvm
Thanks! Is it possible to return a value from go functions?
Sources?
Loving these Go+WASM tutorials. Thanks.