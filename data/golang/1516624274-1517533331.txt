I think you can expand your benchmark. Do it on two axis, the one axis is the ratio of read/writes (100%,50%,0% writes). The other axis is the data-set size (small set, large set, large set with small percentage accessed). The small data-set can fit in memory, where the large cannot. Then one where the data cannot fit in memory, but the subset being access can fit in memory. I think grpc can give you even more through-put as the connections are recycled and should use less cpu to serialize the data. If you are unhappy with the performance of your application, use pprof for bench-marking. 
&gt; https://www.reddit.com/r/golang/comments/57w79c/why_you_really_should_stop_using_iris/ Good to always check Reddit first... I'd missed the whole story. Surely not going to use project that alienates community members &amp; and disrespects other FOSS projects &amp; their licensing. That always means the project is heading to an early grave...
That depends on different aspects. Attempt at starting with no framework and include libraries you need as oppose to loading full on framework.
You could do all that if you wanted to solve it in the same way, but I don't think that's necessary. I think all you need is a tagged union type and a special case in the compiler to require (I'd prefer a warning, but Go doesn't seem to do warnings) doing something with the return value. Go has all sorts of special cases (map and channel optional dual return), and if that doesn't fly, then solve it with a linter. You could strengthen this with adding tuples (which I also want), which allow eliminating the multiple return so you couldn't do things the old way. If you wanted all of the features from Rust, yes, you'd have to implement quite a bit, but a partway solution with a shift in the documentation could be enough to get the majority of people on board.
I have a Discord bot on Github written in Go with some open issues I marked as good for new comers. You're welcome to check it out! https://github.com/ewohltman/ephemeral-roles
My coworkers (new gophers) write buggy code (panics) because they ignore errors (e.g. don't look up function signature and thus don't know there's an error to handle). Forcing them to at least acknowledge errors would help. I use a lint to catch used return variables and put `_ = fn()` everywhere to show I'm ignoring the return on purpose instead of silently ignoring them. I'm trying to roll this out to my team with CI, but that hasn't happened yet. It *can* be solved today with tooling, though I think some support at the language level would help. Just turning on compile warnings or errors for unhandled return values could solve it.
Dear lord... those paid/bot acquired stars really work. Stop checking the GitHub stars people. They lie to you! You need to investigate your dependencies much more thoroughly. I know we lack the tools but not all is bleak. We have *some* tools! For example: https://godoc.org/github.com/kataras/iris?importers As you can see, the majority of the importers are either the author or forks or small incomplete projects. Compare that with a package that is *actually* used by people: https://godoc.org/github.com/gorilla/mux?importers P.S. I am speaking in general. Checking here, as the OP did, is part of the investigation. üëç
I think you were correct with this option, although I might still invert it to be user/userdb, etc: &gt;I thought about using a prefix like I often see with util, eg ioutil and so forth This confused me early on, but stutter deals with how a function is called from a package. &gt;but isn't dbusers clientusers stutter naming the packages? So, if you went with (not stutter): user/userdb If you used a constructor like this, then it would be stutter: func NewUserDB() Because usage would stutter like this: udb := userdb.NewUserDB() So, instead your constructor could/should be: udb := userdb.New() 
chi is amazing, don' t know why isn' t more used.
I'm afraid you're conflating several related but ultimately independent features. Rust has *affine* types these give you *at most once* semantics for your variables. *Exactly once* semantics are called linear types and are generally [regarded unusable with RAII](https://gankro.github.io/blah/linear-rust/). With that background let's look at the features of `Result`. &gt; First you need Attributes so you can implement the #[must_use] attribute for Result The `must_use` attribute is an attribute for the linter and is little more powerful than go's built in no unused variable lint. The one case that the built in go lint does not cover is something like: val := ReturnValAndError() The `must_use` lint would force you to write val, err := ReturnValAndError() Then the normal unused variable lint would kick in and make you use `err`. The `errcheck` linter already implements this lint. Aside from backwards compatibility concerns this doesn't seem unreasonable to move into the compiler or tool chain (`go vet` or `go lint`). Moreover, go already has annotations whether we like them or not in the form of struct tags or [regular function annotations](https://www.bigmarker.com/remote-meetup-go/The-hidden-pragmas-of-Go-by-Dave-Cheney). &gt; Now that we have our warning when we don't use it, how do we even know when it was never used? We need static guarantees about the lifetime of values, time to implement RAII. As mentioned above the must use property is unrelated to Rust's affine type-system. You don't necessarily need to implement RAII to get linear (Idris and Haskell do it with a GC) or affine semantics (swift varaibles will soon be able to opt into this behavior). But I ultimately agree that they shouldn't mix in go. &gt; Pull in those features dependencies. Now lets give them behavior with Traits, which we sort of have in Go with interfaces, except we don't. While its still an open question about how go would implement generics if it did. There's no reason to assume that traits are necessary at all. C#, OCaml and C++ all implement generic sum types without traits. However, even if the standard lib needs to be changed drastically to accommodate generics I think its worth it because of the type safety and performance benefits.
What a *darn* shame.. *** ^^Darn ^^Counter: ^^11796
Oh, fuck off you stupid bots.
Nice insight! Never thought of it that way! While it definitely deals with some of my concerns, it struggles with some others. Eg, if I were to nest packages because of large code, it might look like: `user/userdb/profiledb/blahdb` - that's a terrible example, a better one might be `handlers/userhandlers/profilehandlers` because I often store handlers in a similar structure to their url route. With that said, isn't the endless suffix of `db` or `handlers` quite.. gross? What are your thoughts on handling sub packages under that style?
Postgres had decent full text search, I I would start there
If I don't want to use std lib I mostly use echo (https://echo.labstack.com). It's not too bloated, easy and has everything I need.
I'm not sure about specifics but don't whole heartedly trust sites that say they use multiple job search sources. It might turn up that they are not using sources important to your search. Like the following example. https://whoishiring.io/search/41.8781/-87.6298/4?distance=50km&amp;location=Chicago&amp;search=Golang And compared to this one. https://www.simplyhired.com/search?q=golang+&amp;l=+il And yes one is searching a city and the other is searching a state but the one searching the city is doing a +50km and doesn't have any search results for golang + illinois. https://whoishiring.io/search/40.6331/-89.3985/4?distance=50km&amp;location=Illinois&amp;search=Golang 
I am not sure how exception handling would help. If I need to catch a specific status in the packet, I am looking for it in packet parser code. If any other error happens - wrong structure, unexpected end of packet, wrong protocol version, etc. - it's a bad packet, period. I split packet/message parsing and building into a separate layer and operate byte slices on the lowest layer. It's especially useful if you have stateful protocols with sessions and sequential fragments. Anyway, I have not found any need for exceptions yet when working with protocol handlers.
&gt; Rust has affine types these give you at most once semantics for your variables. Exactly once semantics are called linear types and are generally regarded unusable with RAII. With that background let's look at the features of Result. You're taking this a bit deeper than I wanted to go, but you and the article you linked to are both talking about the Rust **type** system in the *abstract*. My post and the OPS response are about forced error checking which requires diving into variables and scoping. Which from the RUST documentation specifically states rust [enforces RAII](https://rustbyexample.com/scope/raii.html). The variable scoping data is formed for both the Go and Rust linters from their associated tool chain support libraries, go/&lt;parser,ast...&gt; and libsyntax. Their is so much more information contained within the Rust AST to support compilation than Go. I find it _unreasonable_ to make a wide sweeping statement that must_use is "already implemented" in the errcheck linter, considering the vastly different semantics of variables in each language. I feel like your post is essentially separating the implementations of each individual feature in each language without going through gluing them all back together and painting the new picture which is where all the nuances of engineering happens- which continues to be my entire point. The only way I can see having the same Rust end user experience around errors in Go is by using Rust instead. If your pitch here is for a better end user experience around errors in Go using the experience in Rust as a point of inspiration cool, I'm sure Go could make improvements. But I'll continue to find the drive by statements of "Leave lang Y for X because it didn't drop in feature Shiny from X" silly. Until someone puts the arduous engineering effort into determining the implementation of Shiny in Y, evaluating the user experience after the compromises have been made I find it pointless to debate.
&gt; You're missing one of the semantics of the try operator ? in Rust: that it converts the error by calling into() on the error before returning it. That's an interesting point, but to actually be useful, it should probably be `from()` (i.e. call a method of the Error I want to return, not a method of the Error I have. LMK if I misunderstand the `into` mechanism). But even then, that seems to be, at best, another take at creating non-local error handling, with all the downsides it implies. I.e. that would make `Foo()?` semantically equivalent to if err := Foo(); err != nil { return convertErr(err) } func convertErr(err error) myErrorType { switch err := err.(type) { // ‚Ä¶ } } which I'd still consider bad form. It still pretends that error handling code is in some way special - and given that the error messages produced by `convertErr` will have lost most of the context of where the error occurred, you still end up with meaningless and unhelpful errors. That's the basic criticism: Underlying the discussion is always the assumption, that error handling *is* repetitive, that is, you can reuse the same error handling code in different locations. I don't really think that's the case, though - at least not more than with any other kind of code. A good, actionable error message, in my opinion, is specific to the exact operation and context the error happened in.
&gt; https://godoc.org/github.com/gorilla/mux?importers I did look at Buffalo as well, but for me its too much like Rails and while some projects that's a good thing, here the end results might not look much like traditional MVC app so I fear it gets in the way at some point
&gt; MK if I misunderstand the into mechanism). You've got it. &gt; It still pretends that error handling code is in some way special - and given that the error messages produced by `convertErr` will have lost most of the context of where the error occurred, you still end up with meaningless and unhelpful errors. This is also true. However, because you have a hook for conversions libraries like `error-chain` and `failure` are able to insert useful information like a stack trace or additional context. [`pkg/errors.Wrap`](https://godoc.org/github.com/pkg/errors#Wrap) provides basically the same primitive for go and works quiet well. &gt; That's the basic criticism: Underlying the discussion is always the assumption, that error handling is repetitive, that is, you can reuse the same error handling code in different locations. I don't really think that's the case, though - at least not more than with any other kind of code. A good, actionable error message, in my opinion, is specific to the exact operation and context the error happened in. That's definitely the issue to debate here. But I want to reframe it a bit, there's a difference between error propagation (returning an error with some context) and error-handling (retry, turning the error into an exit code, logging, etc.). Using `?` is inappropriate for error handling in most cases (some-times simple conversion is the only right answer, but not often). Most of the time we handle errors we handle a few specific errors locally then propagate the rest with some contextual information. The fact that `Result` is a sum-type helps with the first problem and `?` helps with the rest. The issue of context information is a weakness of the `error` interface not with the proposed `try` sugar in my opinion (though they are related). There certainly is an argument to be made that `?` encourages propagation over handling, which can be a problem. In my opinion, particularly in application code vs library code propagation is far and away the common case and sugar would be nice for it, in the same way go has `range` for iterating over collections (or channels).
&gt; I generally recommend starting your project with the standard library Why? These people want to develop a web app, a web app is a known creature that has known requirements and known frequently used components. Why start with a point and 'see what happens next'? They are not off to discovering a new drug. Their development path is mostly deterministic. Why wasting time and resources to start with something and see what happens later? Why cannot we have a solution that works for most cases when it comes to web dev in Go? 
You raise an interesting example: user/userdb/profiledb/blahdb - that does make me feel like curling up in a ball in the shower. Plus, I found something that contradicts my understanding of "stutter" as only being the relationship between the package name and the code inside the package - [repo path/package name stutter](https://talks.golang.org/2014/names.slide#16). Which as you pointed out, is just gross looking. Although, the stdlib prefers that type of stutter over ambiguous names that can easily collide (as you pointed out with io/ioutil). After all that, I don't think I have any satisfying answers either:) 
Agree w prev poster on using postgres, for the record if you want an all go embedded solution you could try `bleve`: http://www.blevesearch.com
&gt; P.S. I am speaking in general. Checking here, as the OP did, is part of the investigation. üëç I am really surprised someone from github hasnt banned him and his repo. If that author was in the US, he would have been sued a few hundred times. 
I'm not confused about what is useful about result, you are confused about my argument, which is: &gt; That all said I like Rust a lot and have played with it a good bit now but I'm sure I may be off in a few places. The general take away here is that Go and Rust are so different comparing individual idioms or features just seems unreasonable, since it's the entire design of the languages that allow the features to have a cohesive feel. You are picking apart the "off in a few places" to "prove" implementation details of _some_ of the individual features that form error handling in Rust. But you have yet to make a single argument against my actual position by proving it *is reasonable* to take any of these individual features that support error handling by themselves and drop them into Go to for a similar user experience. The closest you came to even comparing a Rust vs Go feature one to one was a converse error- you form your premise that errcheck is not particularly more complicated than the libsyntax rust based linter, based on an assertion that must_use lacks sophistication. I have nothing to concede or contest because nothing forms a concrete argument against my position. If your main concern is I listed a few of the feature dependencies incorrectly, I apologize- I tried to make it clear I may be off a bit. Maybe it would have been better to place the obligation to provide logical proofs to substantiate claims of value in feature proposals in Go to the individuals who make them. At the end of the day- regardless if the relationship between a dependency or two was jumbled up or not, you can't have the user experience of error handling in Rust without Rust. This is a simple fact that may not be contested, because Rust is what provides the experience. You may only borrow ideas and measure new experiences in Go, which no one ever does yet they claim they should exist. This is what I have a problem with and you won't change my view here if that's your aim, sorry.
That's honestly kind of amazing that such a sizeable community of developers sprung up without access to the official site. 
&gt; You are picking apart the "off in a few places" to "prove" implementation details of some of the individual features that form error handling in Rust. I am arguing the the "Rust" specific features (aside from the `?` operator) are not critical to the story here. Languages across the paradigm spectrum have been able to implement these features and integrate them nicely into their language without anything to do with Affine types, RAII, mutability or the like. Just a brief accounting Haskell (immutable, pure, gc), C# (mutable, gc, oop), Swift (mutable, ARC, oop-ish), OCaml (functional with mutability, gc), and C++ (multiple, manual memory, oopish). &gt; The closest you came to even comparing a Rust vs Go feature one to one was a converse error My goal was not to promote Rust vs Go. My goal was to educate about which features are required for Rust style error handling. As a result, I believe that Go can adopt some of these patterns idiomatically and cheaply. But my aim is more education to make when we debate stuff like `Result` we're not including a bunch of unrelated baggage which seems to have been happening a lot in this thread. &gt; you form your premise that errcheck is not particularly more complicated than the libsyntax rust based linter, based on an assertion that must_use lacks sophistication The argument I'm making is that you're evaluating features that are outside of Rust's error feature set. `must_use` is a red-herring in these discussions. The two features that go lacks to implement `Result` are generics and sum types. I think I've made a decent claim that sum types are a natural fit for go (assuming generics get implemented -- which is certainly up for debate). Quoting my previous post for context: &gt; believe Sum types are among them have small surface areas and would be a natural extension to the go type system. Go's type switches basically implement the necessary mechanics already. It would likely require some way to say that type can only be cast to a certain set of types statically and possibly a stack based representation for a tag + union representation (but this isn't necessary -- I believe scala's sum type representation is quiet similar to go's interface representation). Finally its also possible to implement the `try` operator without sum types or generics (`Result`) by make it work over function that return `val, error` and possibly `val, bool`. The go team is certainly not afraid to add magic keywords to help special cases (range for collections/channels, close for channels, etc.). &gt; At the end of the day- regardless if the relationship between a dependency or two was jumbled up or not, you can't have the user experience of error handling in Rust without Rust. I don't think we should steal features from Rust we should steal them from the other languages that have used `Result` like types over the last two decades. Go and Rust are two different languages that I enjoy greatly because they operate differently -- an affine type system would go against the fundamental tenants of go and that's ok! However, handling errors as values is a well understood problem in multiple mature-languages, and go should be taking notes. The only minor thing Rust adds to the state of the art is the `?` operator for early return. It seems that the go community is deliberately burying its head in the sand and declaring itself special before hearing out how the features work or are implemented. I'd love to debate you on the merits of the required functionality to support this error handling model, but we have to agree what features are required!
they can‚Äôt access golang.org before?
I'm a big fan of [Negroni](https://github.com/urfave/negroni). Who originally authored then [ditched](https://web.archive.org/web/20140521180901/http://codegangsta.io:80/blog/2014/05/19/my-thoughts-on-martini/) Martini.
was this a problem lol?
That importers URL parameter trick is awesome. Is there any docs to find any other similar things I can do with godocs 
cmd.Stdout is just an io.Writer. bytes.Buffer [implements Write](https://golang.org/pkg/bytes/#Buffer.Write). If the command (e.g. **tr**) is executed the result from normal Stdout has to be written somewhere. echo "some input" | tr "a-z", "A-Z" &gt; /dev/null but in the case of cmd.Run(), the data will be written to the given io.Writer. This could be just play os.Stdout out again, or here a bytes.Buffer. After the result was written to the bytes.Buffer you can just read it out with String(), Bytes(), or copy it to Stdout again with out.WriteTo(os.Stdout) 
I'm not the person you asked this question, but as someone who has helped many people learn to build web apps in Go I'm going to try to answer it. Long term I definitely recommend checking out frameworks/ecosystems like [buffalo](https://github.com/gobuffalo/buffalo), [gin](https://github.com/gin-gonic/gin), etc. They are super useful tools and you will probably end up using them in your apps. But for your first web app in Go, I highly recommend using the standard library as much as possible. Why? Why should a dev put themselves through that much work when frameworks make web dev faster? To make sure the developer actually understands what they are doing. To make sure they understand the `http.Handler` interface that nearly all web apps are built on top of (in one way or another). To make sure they understand that nearly all frameworks implement that interface, which means you can use multiple packages/libraries that support that interface. To illustrate how you can use the simple `http.ServeMux`to apply handlers to subsets of code, or to route your application based on simple things like subdomain and spin up several different apps in the same `main()` function. The list of things you will learn by exploring the `net/http` package goes on and on, and nearly everything you learn will be applicable even if you use a framework later on. Before jumping into Go I worked mostly in the Ruby on Rails ecosystem, and in that ecosystem they have the opposite mindset - don't use the standard libraries or any lower level packages - just learn to use Rails. It does everything magically for you and has sane defaults, so just use them. And those work well for a while, until they don't. Then you have a team of developers who don't really understand how to make the proper changes to support some app-specific feature they need, or they make bad decisions because they don't understand how they affect the underlying Rails architecture, or they do things that compromise security b/c they just didn't know they were doing it. I don't like telling people, "Don't use a framework, Go's standard library provides everything you need!" That is bad advice. You don't give someone a hammer, nails, and an axe and say "You have everything you need to build a house!" But we should encourage developers to learn about the base tools those frameworks are built from so that they can make educated decisions as they build out their application.
They had VPNs. And Programmers are the type of people that would have them.
probably because it was hosted on google servers, and google is banned by the government. Good though, because from what I hear the Go community in China is enormous
it's actually better to start with bloat, code fast, then remove the bloat when the requirements are well understood. The people who keep on praising the "std lib only" must not ship that much code with tight deadlines... now Go hardly have full stack frameworks to begin with. A http router isn't a framework it's a http router.
Even now.
Off-topic, but this is the ideal website to me. Clean, pretty, no ads and not bloated with JavaScript widgets.
Seconded. Use Postgres FTS, or even just ILIKE if your needs are simple (matching terms in blog post title and keywords fields or something like that).
&gt; These people want to develop a web app, a web app is a known creature that has known requirements and known frequently used components. Because it's multiple known creatures with known requirements and known frequently used components. There's CRUD apps. There's SPA apps. There's apps that need websockets. There's apps that are basically just glorified static websites. There's CMS apps. You can't have one framework to rule them all. And despite what you may think when you first start, you may not have the type of app you think you do at the beginning. Ruby on Rails is the closest thing the web community has ever had to a "default framework" for a given language, and note even that couldn't hang on; it is no longer the only framework for Ruby, or even (last I heard) the preferred one. When new to _both_ the language and your project, I recommend staying lean for a bit to scope out the real problem before running for a framework. Choosing the wrong framework is a catastrophic error for a project; it is worth it to take a moment to do some research first.
&gt; remove the bloat when the requirements are well understood Ah, yes, I believe that's in the backlog, right after "refactoring" and "technical debt".
nah, move fast, break things. 
Apparently not: https://github.com/golang/go/issues/8870
https://github.com/golang/go/issues/8870
Good news, but they should have included play as well. Right now it's just a [redirect](https://golang.google.cn/play).
Oh for sure. I'm not so much surprised but more in awe about the tenacity of developers around the world that just want to work on cool tech. 
I suspect the OP's confusion is because cmd.Stdout an interface, and an interface must be filled by a pointer, not a value - hence the: cmd.Stdout = &amp;out
&gt; You can't have one framework to rule them all. You completely missed my point. I never said we need a framework in Go to rule them all. I said this 'all you need is standard library' nonsense does not answer how to fill in all those nonexisting parts in the standard library which are essential for building any web applications. Ok, I can start with the standard library, then I realize that it does not come with routers advanced enough for my case, wha do I do? Go search for a router library, based on the misleading metric of github stars. Then I find out that I need sessions, what do I do? Go find another library for sessions. And so on. This way I'll end up with a bag of 3rd party libraries, some of them being maintained by a single developer. There is a very good risk that many of them will not be maintained at some point. &gt; Choosing the wrong framework is a catastrophic error for a project According the average mentality in Go community, _all_ frameworks are wrong frameworks for your Go web app projects.
Or, you wind up with a router that's well-suited to your needs, a session manager that's well-suited to your needs, and so on, instead of being stuck with whatever came with the framework you chose. I prefer a library that does one thing and does it well to a framework that limits my choices in the name of being a "one-stop shop" that only really works for their hello world tutorial.
&gt; According the average mentality in Go community, all frameworks are wrong frameworks for your Go web app projects. For what it's worth, I don't actually believe this is the average belief. I just think it feels that way because those people are more vocal, especially in this subreddit. I also think people like myself - people who think the std lib is a great learning tool *before* moving on to frameworks - can be accidentally lumped into the "never use a framework" group even though that isn't what we believe. I have no hard evidence for this aside from the fact that many popular "frameworks" have quite a bit of users and stars on github, suggesting that *someone* is using them in their projects. 
 package main import ( "fmt" ) type T struct{} func (t T) Yes() { fmt.Println("yes") } func main() { m := map[int]T{42: T{}} m[42].Yes() } https://play.golang.org/p/cQr4Dz0-Y_N
I am currently working on a largish Rails codebase to address performance and quality issues. I have been rewriting parts of the Rails app using the [StranglerApplication](http://martinfowler.com/bliki/StranglerApplication.html) approach. We identified parts that we can safely and easily move over to a new language for performance while keeping the API contracts the same. In some cases where ERB was used, we turned those parts into a partial SPA (business term for using React) and rendered JSON from the golang based services. These services currently share the same database with the Rails app. While the initial approach was to use something like [gorm](https://github.com/jinzhu/gorm), I have since settled on using [gorilla](http://www.gorillatoolkit.org/) for mux, sessions and websockets while using [sqlx](http://jmoiron.github.io/sqlx/) for database access. I have also started embracing the [CQRS](https://martinfowler.com/bliki/CQRS.html) pattern for having different structs for updates and deep updates and relying on materialized views and corresponding read related structs. This closes off a whole class of problems with the ActiveRecord pattern such as mass assignment and model validation. However, as with anything in a largish codebase, there are tradeoffs. This means that there is an explosion of structs but I keep them close to the service layer. Most of my structs are named XXXCommandRequest and the response as XXXCommandResponse and XXXQueryRequest and XXXQueryResponse. I also felt its easier to write tests with this approach. Golang's tooling and integration with VSCode and vim makes it really easy to navigate the complex codebase for the entire team. Golang's standard library is quite awesome. It gives a lot to start with however, I would recommend that you give a once over on some starter kits like [golang-restful-starter-kit](https://github.com/qiangxue/golang-restful-starter-kit) to organize your codebase.
very entertaining, I hope the python fancys do not eat you
&gt; Top notch Go libraries like mux usually depend only on the standard library I feel like that's the same for Python... django only relies on two libraries AFAIK... What's with Go being so lean? Compared to, say, js.
&gt; What's with Go being so lean? Compared to, say, js. I would say because it is part of the Go culture. In fact we have a [Go proverb](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s) for that.
From the analytics on my website, I have noticed that Go is very popular among Chinese visitors.
This is not a systemd issue or even an issue at all I don't believe. Go spawns [multiple threads to "balance"](https://rakyll.org/scheduler/) work across multiple cores. When you do `systemctl status odc.service` you should see one parent process (bottom) and 5 children (above). Even if you didn't stop your main() from exiting the Restart=on-abort shouldn't spawn perpetually. on-failure is typically the desired setting.
Incredible work by neelance, was not expecting GC to already be functional
Go has a standard library, JS has a few random functions. Most oft them from a time when JS was considered a toy language used to validate forms.
It's a good news for Gophers in China. 
And you've completely missed mine, since I outline a recipe for a project that ends up selecting a framework. It's just that instead of doing it when you don't know the language you're working in, or much about the project you're working in, you do it _after_ you know those things. You're so sure you know what I'm going to say that you aren't reading what I say.
Non-pointer values can implement interfaces. The popular Context object works that way. Since you can't modify them via the interface methods, it makes them the closest things to immutable values there are in Go.
Is this a library to be used by other Go programs? Or a library to be used by your customers via some socket/RPC/HTTP interface? Or something else entirely?
I considered that but I need much higher write throughput. 
https://blog.golang.org/hello-china here
Another Go program but I can't compile in any of the libraries, I just know they'll implement a common interface.
How fast does it need to be and how approx. how many records do you expect to search through?
My confusion comes from the fact that to me this says cmd.Stdout takes the value of out, when the description you're all putting forth is that you're dumping the value of stdout onto outs memory location 
Direct link: https://golang.org/doc/devel/release.html#go1.9.minor
[removed]
I think having each goroutine write to a *bytes.Buffer and then logging at the end would be the best way to group the lines together. One downside is that if a routine is stuck in the middle of something you wouldn't see any output to help debug it.
I just copied it from the sort package :)
Write in haste, repent at leisure :) If your type implements all the interface methods with value receivers, you can indeed assign a value directly to an interface type variable, eg. type ValueWriter struct{} func (n ValueWriter) Write([]byte) (int, error) { return 0, nil } var w io.Writer = ValueWriter{} This is not the case for most (all?) io.Writer's I've seen though, which use a pointer receiver, eg. bytes.Buffer's write method: func (b *Buffer) Write(p []byte) (n int, err error) { ... } FYI all the standard context.Context types use pointer receivers.
I like this, but still seems like it would still be random/interwoven output. Would I have to add some sort of "flush" method/action through the channel to inform the logger that it can now print all of that particular 'name's buffered up contents?
Thanks. This was my original thought as well. Just wondering if there was "a better way." Have you seen any existing libraries/code that does this so I could take a look?
No need to use a mutex. Send the log lines over a channel and start appending them to a `map[prefix][]string`. Have a ticker running, which at certain intervals flush the map by writing the values to stdout/file. ticker := time.NewTicker(flushIntervalSecs * time.Second) for { select { case &lt;-ticker.C: // flush the map, write to target case logLine := &lt;-logChan: // add to map } } The writes and reads on the map are automatically serialized because of the `for-select` ! You can make the channel buffered if you don't want your application to block during the flush is going on. But then while reading from the map, you have to do some juggling around.
The 'Unknown' case escapes because Go thinks the argument to `bytes.Buffer.Write()` escapes. If you run escape analysis on the source to the buffer package, it reports (for `Write()`): ./buffer.go:170:46: leaking param content: p ./buffer.go:170:46: from *p (indirection) at ./buffer.go:170:46 ./buffer.go:170:46: from copy(b.buf[m:], p) (copied slice) at ./buffer.go:176:13 (The line numbers are for the current git tip; they may be slightly off in other copies.) Given that `copy()` is a language builtin, it seems like the compiler should know that the source argument doesn't escape here. Or possibly the compiler is doing something sufficiently interesting with the actual implementation of copy() such that the source might escape under some circumstances.
cmd.Stdout is just a Field in [type Cmd struct](https://golang.org/pkg/os/exec/#Cmd). And cmd.Stdout doesn't take the value of out, it takes the pointer to out. This is necessary because Write() is defined on (*Buffer). Later down in the execution of cmd.Run() the io.Writers in `type Cmd struct` are handed off to [StartProcess](https://golang.org/pkg/os/#StartProcess) in the [ProcAttr](https://golang.org/pkg/os/#ProcAttr). cmd.Stdin cmd.Stdout cmd.Stderr will be the *Files* Field in Attr (they are wrapped a bit, to satisfy the interface). StartProcess doesn't know it is just a *bytes.Buffer, it only knows it can Write to the *\*File* in **ProcAttr**. &gt; you're all putting forth is that you're dumping the value of stdout onto outs memory location No, we are saying that bytes.Buffer implements the interface io.Writer and every the underlaying functions can call *cmd.Stdout.Write([]byte("YOUR DATA HERE))* and the data will be written to whatever implementation of io.Writer cmd.Stdout currently has.
Excellent article, I learned a lot. Looking forward to the next batch of compiler optimizations.
[removed]
I've had very good luck so far with gRPC. I think I would mock up a common rpc interface and implement it with each plugin being a stand alone binary. I would configure the listening port on each plugin via command line parameter, and have my main binary launch the plugins while keeping a map of plugin name to launched port. That would also let me gracefully stop a plugin if that feature was needed.
This is an assembly file (".s") with assembly for the amd64 architecture. That's all I can say, and my question is, why do you need to know? For me, in most cases a stack trace is useful down to the last source code file I have control over, or maybe the last file that is a .go file (in the cases where I fail to understand why my code fails), but everything below that has never been very usefulfor me.
I really like https://github.com/labstack/echo
The stdlib can get you _really_ far. The only major thing its internal muxing library is missing most routers might offer is clearer routing on HTTP methods, but there's some decent arguments against even using them in your API anyway (primarily of the variety "you think you're writing a RESTful API but you're really not, so stop trying and embrace RPC"). Generally my opinion is; use the stdlib. If you need more power, don't half ass it; look at gRPC, GraphQL, or maybe even the new twitch lib Twirp. If you think those libraries are too powerful, you might be right, but you might also be underestimating how far the stdlib + some abstracted logic in your app can get you. 
I am also using chi and I am very happy with it.
Take the Tour of Go. Once more if you did already solving all problems. Then read Effective Go. Then The Go Programming Language (Donovan, Thompson).
Go plugin support is indeed still incomplete. It works for Linux and afaik, support for macOS is around the corner (Go 1.10?), but maybe there are alternatives for you. * Go compiles really fast, so recompiling the binary in order to add new code may be feasible in your scenario. The pure-Go Web server [Caddy](caddyserver.com) does it this way (check out their download section - you can select the desired plugins there and get a custom build after a few seconds). * Make your plugins separate executables and use some communication mechanism, like gRPC (as /u/ericzhill suggested), or some message queue (nanomsg/Mangos, NATS,...) or just plain simple pipelines from stdout to stdin. (I describe these options in more detail in [this blog post](https://appliedgo.net/plugins).)
Maybe the dy comes when I don‚Äòt have to write javascript anymore.
See https://goreportcard.com/report/github.com/tomplex/wktfile.
os.Open returns nil file on error. If you defer closing the file, the code will be panicking.
Go In Action is quite an easy-to-read introduction to Go. The standard Go book certainly is The Go Programming Language by Donovan&amp;Kernighan, but IMHO it is not as easy to digest as Go In Actiopn. It is, however, quite complete and goes quite into the details. An excellent book especially about concurrency is "Concurrency in Go" by Katherine Cox-Buday (O'Reilly). The online Go documentation is quite extensive and worth a closer look, but in my opinion it does not form a cohesive whole. The Go Tour only covers the basics, while Effective Go strictly focuses on the specialties of Go, targeting experienced devs. There is quite a gap between the two. And both together are still not complete; you would have to refer to the language spec for learning all the details, but then a spec is a spec and not a tutorial. (Albeit an excellent spec, so if you are an experienced developer, you might find yourself looking more into the spec than to some Go book.) 
Oh, that makes perfect sense then. Thanks for the response!
Do you mind if I ask a question? I'd like to make this package a bit more helpful when used for geometry processing and allow the caller to specify a handler function that will convert a specified geometry column to the geometry implementation of their choice. The "functional parameters" pattern that I've used has been really helpful to specify attributes of my `WKTFile` type, but I'm not sure if I could use it to inform this behavior as well, or if there's a more idiomatic way to do that. For a more specific example, I was thinking the caller would specify a handler function like: func convertWKT(wkt string) (geometry interface{}) { geometry, err := geometrypackage.FromWKT(wkt) if err != nil { // handle } return } But I'm unsure how I could pass that function to Read() or otherwise allow the package to use it to process the data from the file. Does this make sense? Or is it likely more trouble than it's worth?
That's what I was thinking, but they each have their own PID. However, if I use htop and group them, they all fall under what looks like a master process, so I think they are go concurrency at work. Like you said, I didn't think they'd have separate PID's.
Who the hell coined the "serverless" term... There's no such thing as internet without a server, it is just someone elses computer
It's Go, not Golang
Whoops, my bad
Piggybacking off of this discussion, do you think *Go in Action* and *The Go Programming Language* cover the same ground or would both be useful as learning materials? I have TGPL as a reference at work and I was wondering if Go in Action would be any help.
[removed]
I think Go in Action would mainly appeal to those who find TGPL too dry. In my opinion, TGPL targets experienced developers and might be a bit tough for people who are quite new to programming in general. But that's just my own point of view.
https://github.com/apex/gateway
Then The Go Programming Language (Donovan, Thompson) https://www.amazon.com/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440
The question is very vague about your requirements. Please elaborate on your definition of "core system modules" and overall architecture requirements - such as CPU and RAM usage, latency, which of the web protocols you need, tooling, etc. If you asking from terms of language expressiveness - Rust is more expressive. Is it better or not? You decide. 
And the download link: https://golang.org/dl/#stable
thanks 
If the main driver is what you want (e.g. what you want to learn): Just do whatever you want in whatever language you want. Your question seems to indicate that you do neither of the two languages which makes the question a bit strange because both options might be a way to disaster. What other requirements than being inclined to write a certain part in one special language are there?
I'm working on something similar https://github.com/lileio/pubsub but it has some reflection. I'm reworking that a bit in the v1 branch though
[removed]
Thank you @dericofilho for detailed answers.
Sorry for not being clear in question? My main question was to check the experience of people having written microservices in Go and/or Rust I've written a prototype microservice in Rust and it doesn't disappoint, however, people generally recommend Go for microservice. Intention was to check peoples opinion before making a Go / No-Go decision 
Hello I've started using/learning Rust for a couple of months for my project as many of the modules I need to use is already written in Rust. Intention was to check if there is any specific reason why I shouldn't use Rust for my microservices and instead choose Golang
[io.TeeReader](https://godoc.org/io#TeeReader) might help. So, e.g.: f, err := os.Open("logfile.txt") if err != nil { panic("err") } defer f.Close() r := io.TeeReader(conn, f) s := bufio.NewScanner(r) for s.Scan() { log.Println("Got line:", s.Text()) } return s.Err() This 1. Opens a log file 2. Wraps the conn in a TeeReader. This is an io.Reader that, when you `Read` from it, will call `conn.Read` and then write the returned data to `f`. 3. Reads lines from the TeeReader with a `bufio.Scanner`.
What were the fixes to the http package?
Only this afaik: https://github.com/golang/go/issues/23066
Few things: - Rust does not have as many backend libraries as Go for talking to various services ect ... ( think cloud, gRPC and the like ) - Same for frameworks - Rust needs nightly to build on a lot of recents projects - Go is better suited for micro service, the standard lib has more packages to do anything backend related ( serialization, http, db ) - Concurrency is honestly better on Go for now, Tokio is not stable and there is no concensus on what to use and it's fairly complicated overall On the end if it's just a pet project to learn you should pickup anything you want. tbh I don't think Rust is well suited for micro service project where Go is really good at it.
Check out this article from someone at MalwareBytes http://marcio.io/2015/07/handling-1-million-requests-per-minute-with-golang/
Do you need any kind of persistence in case the server crashes? RabbitMQ is easy to use and quick to have a prototype working. If not, goroutines and channels would be the simplest solution. 
Sure, thanks for commenting. When I was writing the `Read` function, the constructor for a `WKTFile`, I wanted to be able to pass it optional parameters, like in Python how you can do `def somefunction(a, optional=None):`. Obviously, this isn't a thing in Go, but I found this [blog post](https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis) by Dave Cheney who uses this Functional Options idiom to provide default options for his constructors, as well as make his API easy to add features to without breaking, something that I hope to do with this package. There's another example in [this Gist](https://github.com/tmrts/go-patterns/blob/master/idiom/functional-options.md). Finally, defining these options as methods of the `WKTFile` object itself was inferior in my opinion, as it required another step before the data was usable in the form I wanted. For example, if these were methods, the workflow would go from: func main() { wkt, err := wktfile.Read("some_file.wkt", wktfile.CommaDelimited) if err != nil { // handle err } for i, row := range wkt.Rows() { // Do stuff with data } to... func main() { wkt, err := wktfile.WKTFile{FilePath:"file.wkt"} // handle err wkt.CommaDelimited() wkt.Parse() for i, row := range wkt.Rows() { // Do stuff with data } I believe the first option has a cleaner API and is easier to read and use, though some may disagree with me. Finally, you are right; these functions definitely don't need to be returning errors, as they will never cause one. I should change that, as it will remove some unnecessary error handling on my part. 
&gt; As the query pattern is only stable within a single user ie user 1 wants stuff sorted by x while user 2 wants things sorted by y, creating large number of secondary index keys seems like a road to hell. Should your dataset have a user column so you can sort by name? Or leave the existing columns as is and add an additional column for sorting and set it to the user if need be?
I've come to terms with people using 'serverless' this way. Hey what server do you run this on? -- Do I have any requests at the moment? No, not right now. -- Then none.
If you just want to take a peek how this looks like in action, [Here is the source for a basic app](https://github.com/IsomorphicGo/isogoapp). All related sources for the used libraries can be found [here](https://github.com/isomorphicgo).
While there are differences in a web application because code can be updated inline, I've worked on an application that shared client and server code and it can be a nightmare from the point of view that you can abuse the convenience and totally ignore the idea of versioning, dependencies and end up with a totally coupled mess. Even web client applications potentially have to deal with caching, so even with the case where all your logic is in a single javascript file so that it updates atomically, you still can't get the best performance without caching that on a CDN and potentially have temporary version differences between client and server code versions.
[removed]
http://contribsys.com/faktory/ is a relatively new job queue server written in Go by the author of Sidekiq, one of the most popular Ruby options. Looks very promising: http://contribsys.com/faktory/
https://pocketgophers.com/concurrency-slower/ is an example of using concurrency for parallelism that shows how to use Go's tooling (testing, benchmarking, profiling).
Just a heads up, that person is no longer with the company.
I've coded in Go for a few months and wrote a bytecode parser and a graph database driver. Also experimented with some of the REST frameworks out there. There's a lot of hype about Go and I think it's mostly down to the fact that a) Google own and use it, b) it's really easy to learn &amp; c) it makes concurrency seem easy. Things I don't like about Go. The core Go team have struggled to get it to perform at the speed of Java, and it'll never be anywhere near as fast as Rust, because of the GC. If all you're trying to do is get rid of the JVM memory overhead (useful for microservices) then perhaps you're better off with Go, but then you lose inheritance. Something I love. I digress. Rust benchmarks at anywhere between 2 to 10 times faster than Go, and in some cases it's even faster than C. Error handling is a pain. Write some networking code, and you'll soon see 75% of your code is just spent handling errors. I heard quite a lot of experienced Go Developers complain about error handling. I prefer Rust's Result type that forces you to deal with errors, and the ? operator that you can use to "throw" and error up the stack. Implied interface contracts. I just prefer seeing contracts stated upfront. Also, in Go, you don't have to group the method definitions of a type. You can define them all over the place spread across multiple files in a package (And people do it! I've seen this in code on GitHub.), which I dislike. Tryna figure out if a type implements an interface can turn into a hunt. I prefer Rust's Impl way of doing it. Also, there are no generics in Go. You'll soon find yourself having to write what essentially feels like boilerplate code, just to get around this, as you slowly feel your life ebb away. Go interfaces are just weird. There's no handy 'conformsTo' or 'instanceOf' keywords so you have to assign to the empty interface and then start your checking. Rust has better support for enumerated types, where each variant can store it's own custom set of value types. It may not seem useful at first, but it's a really cool way to create types. Imports in Go are simply defaulted to the head of the master branch of a repo. I'd seen people use vanity URLs (versioned URLS) in their source code(!??!) to get around this, but I never really explored this aspect of code integration, I just thought the idiomatic way of doing it was naive and ridiculous. And the amount of times I heard a Gopher claim that something was done a certain way because it was 'idiomatic' made me wonder if any of them could think for themselves. Rust uses Cargo and it works as anyone with a bit of open source coding under their belt, would expect. Concurrency. I haven't delved into this much in Rust yet, but from what I have read and seen, I prefer Rust's way of making sure nothing can go wrong when you use channels. Go on the other hand, is a different story. You'll get told to use channels and go routines in Go because they're idiomatic. But the fact is that they are slow. Much slower than ditching green threads. And if you push a value into a channel in Go once the channel has closed at the other end, your app will crash. And guess what? There is no way to tell if the channel was closed at the other end. Good luck with that! I got tired of hearing something was idiomatic every time you questioned a feature or such like. For example, you are encouraged to use single character variable names in Go because.... ta da! It's idiomatic. FML. Someone pointed out an opensource piece of code that was literally a call x.y.z(). And it wasn't code to handle 3D space coordinates. You are just supposed to know, and follow like an obedient dog. And one thing that I never hear anyone else mention, but was honestly one of the things that use to grind on my nerves the most was the use of upper and lowercase to denote public/private scope. At first I thought "oh how minimalist of them! Someone finally saw what had been right in front of us for decades and managed to ditch explicit scope specifiers for a cool reinterpretation of size with regard to scope'. Except it catches you up all the time. How? Well look at this: nb.Debug() - package level function call on a package called nb. nb.Debug() - public method call on an instance variable called nb. When you've spent decades writing in other langauges that have the convention of capitalizing type names, it gets super confusing when you see resultType and you automatically keep thinking it's a variable name and not a type like ResultType. Read "Programming Rust" by Blandy et al.. I've been a software engineer since the mid 90s and it's one of the best books on a language I've ever read. The amount of thought that has gone into the language has me convinced that it is future of systems programming and a very welcomed replacement for C/C++. There may be less library and tool choices out there for Rust, but I would guess most people give up on Rust because of it's ownership rules, which, if you've spent as much time as I have coding, simple enforce what you probably already know about best practices in coding. You'll be a better engineer for it. Also, Visual Source Code has support for Rust which includes the Rust Language Server and a step-debugger. Best light weight editor I've used in years. I've been wanting to get this off my chest for months :-) 
So just to ensure I'm understanding here, the field is taking the pointer to the bytes.Buffer, and upon executing run, stdout is being written to that memory location, which (in the example case) is what out is also accessing as a bytes.Buffer?
Thanks for your reply
Thanks a lot @rayascott .. made my choice easy.. will definitely read that book and will share my experience of development using Rust
Just keep in mind that on the front-end, gopherjs can be 60 times slower than server-side Go: https://github.com/gopherjs/gopherjs/issues/192 As long that the performance is adequate for the intended purpose, then all is OK. 
Isn't integrating all those js libraries and gopherjs a mess?
That comment comes across to me as mostly emotional opinion (except the performance part) because I like Go for the same reasons you dislike it. - I'm not a fan of inheritance - Although Go's convention is to err on the side of brevity, I was never told to or called out for using variables longer than one character - I don't get the vibe that you must follow convention like an obedient dog - There is a [blog post](https://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/) written from a notorious Rust developer that praises Go's concurrency, goroutines, and channels implementation while explaining the details of Tokio (one Rust's concurrency library) &amp;nbsp; That being sad, I love both languages, but whether I pick one over the other is a matter of how much control I want over memory and how performant I need it to be. But for most of my projects Go is good enough. Plus I'm more productive in Go than I Rust, but that's subjective.
version v0.5.0 released: https://github.com/nadoo/glider/releases
Yes, obviously the file is part of the Go runtime. I thought you were looking for help with interpreting a stack, that's why I replied, but I am afraid I cannot help with Go internals at assembly level. I would guess that the people who know more about this file can be found in the [golang-nuts](https://groups.google.com/forum/#!forum/golang-nuts) discussion list.
A circuit simulator for logic gates.
This is awesome! Thanks!
gRPC might be the way to go. Started really reading up on it and if I understand it right we might be able to modify the single Java application to use gRPC so our legacy Java and new Go libraries can exist side by side.
**This is an advert.** Please take this link down.
https://github.com/optiopay/klar is pretty simple and there are different potential tasks- from big refactoring to new features to small fixes. I‚Äôm a maintainer of the project. 
Use the downvote button if that isn't the kind of content that you want to see on the sub.
We're literally using gRPC as a common middle ground between Java and Go. There are some use cases that Java made better sense, and others where Go was the clear choice. We wound up deploying onto a [Nomad](https://www.nomadproject.io/) cluster and [Fabio](https://fabiolb.net/) (I hate the name) for service location. Each service deployed has consistent DNS entries pointing to the Fabio instance running on each cluster node, so it doesn't matter where the service runs or if a node is offline; the service is always available.
&gt; The core Go team have struggled to get it to perform at the speed of Java, and it'll never be anywhere near as fast as Rust, because of the GC. GC can be faster than "semi-manual" allocation. Please look into "pointer bump allocations" and local allocations. GC doesn't directly affect speed, it affects latency. From totally unpredictable to hardly predictable ways. If you have hard real-time requirements, aka you work in finance or avionics for example - GC will be in your way. Game devs tend to develop a customized version of GC because of their requirements. &gt; I digress. Rust benchmarks at anywhere between 2 to 10 times faster than Go, and in some cases, it's even faster than C. They used typed arenas - which is actually very cool. But you'll rarely see this in real life projects because this requires some serious forward thinking because it's essentially a static vector. Haven't seen this anywhere, aside from embedded. Also - it's not faster than C. Its LLVM doing some optimizations better than GCC. &gt; Error handling is a pain. Write some networking code, and you'll soon see 75% of your code is just spent handling errors. I heard quite a lot of experienced Go Developers complain about error handling. I prefer Rust's Result type that forces you to deal with errors, and the ? operator that you can use to "throw" and error up the stack. It's better to annotate error, rather than simply propagate it. Your colleagues will thank you. &gt; Tryna figure out if a type implements an interface can turn into a hunt. Ehh, both VSCode and IDEA can do it. Pretty sure VIM can too. &gt; Also, there are no generics in Go. You'll soon find yourself having to write what essentially feels like boilerplate code, just to get around this, as you slowly feel your life ebb away. I write network and system specific code. I miss generics sometimes. I do not feel "my life ebb away". &gt; There's no handy 'conformsTo' or 'instanceOf' keywords so you have to assign to the empty interface and then start your checking. WHAT? &gt; Imports in Go are simply defaulted to the head of the master branch of a repo. Please repeat with me: imports != package management. &gt; Concurrency. I haven't delved into this much in Rust yet, but from what I have read and seen, I prefer Rust's way of making sure nothing can go wrong when you use channels. Which one? std or crossbeam? BTW Rust still doesn't have an MPMC queue. &gt; But the fact is that they are slow. Much slower than ditching green threads. Slow is about 50-100ns btw. Which is faster than what Rust has in std, actually. &gt; And guess what? There is no way to tell if the channel was closed at the other end. Good luck with that! Don't close channel on the receiver side. You can check that channel is closed during receive operation: Like `val, ok := &lt;-myChan` and then check ok. &gt; I got tired of hearing something was idiomatic every time you questioned a feature or such like. At this point, I quite sure you never interacted with experienced Go developers, and just spill out your frustration with some quirks you encountered along the way. But again, beating zealotry with zealotry is not a good tactic. &gt; For example, you are encouraged to use single character variable names in Go because.... ta da! It's idiomatic. FML. Only if it make sense. &gt; Someone pointed out an opensource piece of code that was literally a call x.y.z(). And it wasn't code to handle 3D space coordinates. I saw that in Java codebase, so I should start bashing Java now? &gt; You are just supposed to know, and follow like an obedient dog. Ehh, no? &gt; When you've spent decades writing in other langauges that have the convention of capitalizing type names Personal taste. I spent time writing code in camelCase, snake_case, PascalCase. Don't care, as long as it fits the existing codebase. &gt; There may be less library and tool choices out there for Rust, but I would guess most people give up on Rust because of it's ownership rules, which, if you've spent as much time as I have coding, simple enforce what you probably already know about best practices in coding. You'll be a better engineer for it. Because implementing acyclic graph without pain is not "cool enough". Rust deals badly when application memory ownership is unexplicit by design - you can read about the struggles of those how to try to make good Qt or GTK bindings. Most of the time it ends up in wrapping stuff into `Arc&lt;&gt;`. This is not good. &gt; I've been wanting to get this off my chest for months :-) I'm glad you did - I hope that it helped you. Yet it was nowhere useful - it vaguely contained the words like "CPU\RAM usage" and "latency". It didn't contain anything about ecosystem (libs\tooling - btw arewewebyet?), "stackfull vs stackless model" of green threads with pro and cons of having the scheduler. It didn't had any insight about memory model, and perf implications of jemmaloc. So - instead of giving engineering response, you ranted. But I suppose it's okay.
Good point. That's probably worth filing an issue about.
I agree that this site is advertising the book of the author, but it also shows whats possible. The used frameworks and libraries are [open sourced on github](https://github.com/isomorphicgo), so the book is not required to try any of this. I thought about linking to the github page instead, but decided the website does a better job in conveying the ideas.
I prefer the following style for functional options: type Option struct { fn func(wkt *WKTFile) error } func CommentDelimiated() Option { return Option{func(wkt *WKTFile) error { wkt.delimiter = ',' return nil }} }} ... and so on func Read(filepath string, options ...Option) (*WKTFile, error) { } The reason that I like this is that application cannot call the functions outside of the factory function and it clumps the options together in godoc. 
https://github.com/mtojek/aws-lambda-go-proxy if you need this to run AWS lambda locally, you can also try new proxy application.
So, what is it really? A "modern, elegant, artisanal" framework on top of GopherJS, or what?
I'd design the API more like this: func Read(r io.Reader, rows interface{}, options ...Options) (*WKTFile, error) { } where the caller must pass pointer to slice of struct as argument. The function uses the header row to map values to struct fields. If field value supports [TextMarshaler](https://godoc.org/encoding#TextUnmarshaler) interface, then use that decode the string to the value. There's probably an existing CSV package that does this. I'd also add func ReadFile(filename string, rows interface{}, options ...Options) (*WKTFile, error) { } as a helper function. The function taking an io.Reader is easier to test and can be used in scenarios you have not thought of. 
&gt; BTW Rust still doesn't have an MPMC queue. Is there something wrong with [chan](https://github.com/BurntSushi/chan) and [multiqueue](https://github.com/schets/multiqueue)?
Just like with all multithread queues there are questions about fairness\distribution\speed. If you read the source of chan, you will see that Andrew Gallant admitted himself that he is not pro in this stuff(he is brilliant with DFA tho). Crossbeam is cool because it has papers and guarantees under. If you want to know more, both Jeff Preshing and Cameron have very good articles about implementing fast and scalable queues. Also 1024cores.net
What about the performance between Gopherjs and vanilla Javascript? Wouldn't that be the better metric?
I‚Äôm sorry, when I read that I some how interpreted it by sorting by user in the sql light cache, not sorting by a arbitrary column a user may prefer in Bigtable. Will your daily data sets fit in memory? If so you got a lot of flexibility and I would break it into two parts. First the portion that syncs all the missing chunks of data into a local google/btree (this data may be better suited for a prefix tree, but google btree is the only data structure I import because I‚Äôve used and tested it so much.) with a item that has all the fields normalized into a structure the way you want. I would then use that to make inserts into one or more completely separate btrees that share the same free list (assuming you occasionally flush data out if not doesn‚Äôt really help much accept to preallocate) with an Item that implements your key sorting you want. You may be able to get by with a single tree if your sorting permits it, but I always just make a second tree if I end up starting to type assert multiple structures in my range queries items to differentiate sorting schemes, in my experience it‚Äôs asking for bugs. Maybe this doesn‚Äôt help (again) but might get you thinking some. Good luck.
&gt; JS was considered a toy language used to validate forms. It's not?
Yes. But sadly I didn't find that metric. Still, javascript (under the V8 engine) isn't as slow as Go; it should be about 3.5X slower than Go, if we believe the "benchmarks game" on the internet (very good website.) 
I'm looking for people to help with Ponzu or the Ponzu go-client. Testing, features, docs all need work :) https://ponzu-cms.org The Go client (found in the ponzu-cms org) might be a better place to start contributing since the footprint is way smaller. 
I didn't insult you - you are more than welcome to invite mods to this discussion if you see it otherwise and see how it goes. And no - it wasn't rant - most of your points was incorrect or subjective - so I tried to make some corrections to wrong assumptions. Your post is a good rant, there is nothing wrong with that, but it doesn't help when one need to chose between one tool and another, like original poster requested. I stand by this. I also don't know everything. To be honest with each new knowledge I understand that I know even less. This is why when I debate something with someone I don't use my personal taste and use facts. I also try to investigate things before I make any sort of claims. This is why I think that hype driven development is not helpful. Also - if you want to play benchmarks game while comparing Rust vs Go you could as well use - https://www.techempower.com/benchmarks/
I don't understand why you think this is a problem. It's Go-related, it's novel, it's on-topic.
This is for a personal helper service so while I kinda do need persistence I'm guessing that all the jobs will be executed quickly enough. I'm going to go with the goroutines approach explained above, thanks
cirello.io/gochatbot could use some love as I am no longer actively maintaining it.
Are you specifically choosing the outdated (even within the issue you linked), worst-case comparison for some particular reason?
There are many non-technical requirements not specified. For example, at work I rewrote our Python code base to Java and then rearchitected the product. This wasn't due to the language, but to match the strengths of the team as the founder's choices were excellent to bootstrap, but didn't match the strength of the team. Similarly the web/mobile frontends were rewritten. It is important to fit the technology to the team, as well as the strengths of the ecosystem, when choosing the technology stack.
Could do that. It feels a bit more over-engineered than just having buffers in each goroutine. But, yeah, you could have the struct passed on the channel have a flush bool attribute. 
Is there any go package that has all those common cases for channels ? I find myself writing fan-in, fan-out patterns for almost every project. It‚Äôs weird that stdlib doesn‚Äôt have those high level utilities.
I'd be interested to see a demo of the form functionality described on the web site.
It's not obvious why you comment here at all, you seem to not like Go and aren't willing to talk to anyone who disagrees with you.
I'm working on Nakama (https://github.com/heroiclabs/nakama) - it's an open source server for real-time, social games and apps. Would really appreciate some community contribution and love as I know this is something a lot of people will find useful. 
Ponzu appears to be very thoughtfully written, and his comments like the one I'm replying to seem to follow a pattern of engaging the community. I think this is a great suggestion.
Thank you!
Storm is now based upon [coreos/bbolt](https://github.com/coreos/bbolt) since that is the most maintained fork of bolt.
What am I missing here. Everything in your sample input is in your output.
&gt; I'm guessing that all the jobs will be executed quickly enough. Then we can guess that all your users will experience errors soon enough. Unless you give us a few more details about your requirements (scale, uptime, available resources, environment, etc.) you're going to get answers all over the map...
That i need the "GE" "MS" and all the other relevant tickers to be the value of a key value pair in the struct like {"MarketName" : "GE" } show in the example in post... the name of the Ticker is obviously important and it is also not feasible to use map and have to do x.["GE"].LAST to retrieve it. New markets will be created all the time with out me knowing, and the purpose is to consolidate and organize the data from all the sources, I need to be able to store and use this data like i can the other 20 sources I am pulling from :-) 
It really depends on how durable and scalable you want your solution to be. The simplest solution is seriously just a buffered channel with a separate goroutine reading from the channel. You can set a buffer high so that it can handle some burst without blocking writes. That being said: - If you exceed the buffer, callers will be blocked, slowing your client API requests down. - You can't distribute work over multiple servers; the server that handled the request will always also do the work. - If the server dies, all the jobs are lost. And this might be expected to happen if your usage is especially bursty. But while these are bad, its actually pretty decent for simple projects. Beyond that, I'd highly suggest using SQS (if you're on AWS) or GCPS (if you're on GCloud). These are high scale queueing solutions that solve all of these problems. They're also practically free at low usage. They don't come without downsides, though: - More infra to support, though its **significantly** easier than running a turn key queue system like redis. - You can enqueue messages asynchronously from the request, but then you can't guarantee to callers that the request was actually enqueued. So its best to do the enqueue inside the thread that handled the request, which might add a few milliseconds to the request time. - Reading the queues isn't instant; it requires network calls. But its so fast this shouldn't mattered. - Neither of these products can guarantee exactly once delivery. They only do "at least once" delivery. So its possible your messages might rarely be delivered twice. To get exactly once, you can deduplicate incoming messages with the unique identifier of the message, either in-memory if you run one server or in a database like redis if you run multiple servers. Or, preferably, you can architect your system to be tolerant against receiving the same message twice by being idempotent. I'd stay away from redis, celery, etc unless you know why you need it. SQS/GCPS are great and basically free. Azure probably has a similar solution, I just haven't looked into it. Use 'em. 
This is a really good point, and it did slightly bother me while looking at the godoc that those helper functions were all at the top, sort of distracting from the main point of the package. Thanks for this, I think I like this pattern better, too.
I will need to take a little bit to consider and decide how I want to implement what you've suggested, but I definitely think this is the right way forward. Also, I want to say thanks a lot for all your thoughtful feedback. I really appreciate the time you've taken to help me.
GOPL is definitely one of my favourite books on Go. It helped me get a handle on Go Routines and Channels.
 &gt; Your example is misleading It is only misleading because you made it so from the start. It is quite obvious that you are storing a value in the map and not a pointer. The topic of discussion (pointer vs value receiver) and the final decision (pointer receiver because of modification) work as expected. The `n` changes from 0 to 1 just fine. Of course then you grab a new copy from the map and that new copy has 0 again. To my experience, in practice such stuff do not happen often. Maybe it's something that will bite a new gopher once or twice but that's about it. In conclusion, I can agree that if someone is not careful with pointer and value types it can lead to tricky situations. But my point still stands. As far as the pointer vs value receiver dilemma is concerned, you do not make decisions about that by thinking about addressability. A good rule is to ask if the method needs to modify the struct or not and use a pointer receiver if it does. This makes the code more readable. Readability and semantics go first. Efficiency second.
Sorry to be that guy that says the dumb thing here: but -- is it just me or does Rust have the most awful name conceivable for a language? I can't take myself seriously programming in a language called Rust. Sorry. I know, it's stupid. I essentially see Rust as a more intricate Go, but with a dumber name. 
Even if your queue client code isn't on AWS, I would recommend giving SQS a shot due to it being fast and reliable. With SQS a message will keep coming back to you until you ACK (in SQS you delete) the message. This requires your code to be idempotent in the context of the message, but that isn't a bad thing when you consider messages aren't just getting dropped on the floor if they fail to be processed by your handler. I know some people say just put it back on the Queue (if you're using Redis), but now what happens when Redis is unavailable temporarily? Your message will be lost. I definitely prefer the more reliable option for critical messages. Given that it is so cheap as to be almost free, and you don't need to manage the queue itself it is a great option. Having a reliable queue also means you need to think about what to do with messages that can never be processed. Instead of just erroring out for whatever reason and forgetting about the message you'll still need to remove the message form the queue. You can leave it there but that seems pointless and can create a lot of thrashing for your handler. Just my thoughts. There are other options but SQS has worked everytime, for little effort on my side.
I have a Discord bot on Github written in Go with some open issues I marked as good for new comers. You're welcome to check it out! https://github.com/ewohltman/ephemeral-roles 
&gt; Have you even programmed in Rust Not much, but I'd assume more than you've programmed in Go. &gt; I was called a liar, for no reason at all No, you weren't. &gt; and now I‚Äôm replying to someone who is confused about the thread. No, I'm not. Here's a free clue though, not everybody who disagrees with you is a "troll" or "confused". You should work a lot on how you (don't) take criticism. &gt; Life is too short for this. https://twitter.com/tomgreenlive/status/463016192274202624?lang=en
Threads also have a pid. Htop will show threads in green. If that is hard to see, enable the TGID column, which should be the PID of the process that owns the thread.
So I tweaked your original Go snippet: https://play.golang.org/p/xQFIcQU7ume * Added a `MarketName` attribute on the `Market` type. This doesn't get un-marshalled from the JSON so it gets a default blank string zero-value. * Made the map into `f := map[string]*Market` so that the Market structs could be modified after the fact. * After JSON unmarshalling, I loop over the key/value pairs in `f` and assign `Market.MarketName = key` so I copy those key names _into_ the struct. In the end I have an object that I can do this to: // Pretty print them or whatever for _, market := range f { fmt.Printf("MarketName: %s Last: %s HighestBid: %s\n", market.MarketName, market.Last, market.HighestBid, ) } Output: MarketName: MS Last: 25 HighestBid: 20 MarketName: GE Last: 24 HighestBid: 22
There's an example in the docs that does that! https://golang.org/pkg/crypto/cipher/#example_StreamWriter
I recently finished a major refactor and cleanup in which I made error handling simpler/more idiomatic, added a cancel button (using the context package), added support for multi-file transfers, and consolidated two struct types into one (which needs further work). Thinking about using more common interfaces like Reader and Writer. Also almost done with a CLI version.
Beside being able to search for articles by keywords, what other kind of features would be nice to have on a blog which requires a backend? If you can spare the backend, a static website is easier to maintain, cost exactly nothing, and can handle all sort of traffic by just popping up a CDN and let it tank the traffic with caching enabled. ie: Github pages + CloudFlare.
You can absolutely make a blog with those tools, I am doing this because I am interested in it not because it's the best course of action. One of the main reasons which got me thinking about doing this is to create a list of most popular posts overall and within tags. But I'm sure I could do that with some plugin if I dug around for it.
There's also [Gorgonia](https://github.com/gorgonia/gorgonia) and [Gonum](https://github.com/gonum/gonum). We don't bite and we welcome newbies
I'm not saying that you can't do it or that you shouldn't. I'm not a blogger, so was just asking what kind of cool features would require a backend like AWS Lambda. You absolutely should experiment with tech. Technically you could track your hits with Google analytics but if you're running a tech blog your target audience will probably have an adblock that will prevents tracking those hits anyways. I can see how having your own backend that tracks it being more useful.
Thanks, that is a great resource.
Assuming 1) variable reads are atomic, 2) noise and j are local to the routine, and 3) the updates are governed only by the inner if conditionals, the race seems benign.
Any time you have a data race your program will sometimes fail. Sometimes more often than others, but do you want to ever let your program fail when you could do something about it? The speed of hardware can definitely affect your result. This is especially true if you try to hack around it with timeout statements. Ex. ```setTimeout(function(){ alert("Hello"); }, 3000);```
I think the downvotes are because there is an additional assumption we need, which is that the compiler doesn't optimize something away. 
&gt; but I think this code will always be correct. Don't think. Read the spec and know - https://golang.org/doc/faq#What_operations_are_atomic_What_about_mutexes &gt; What operations are atomic? &gt; We haven't fully defined it all yet, There you go. It is undefined behavior. Fix the race and move on. :)
&gt; Assuming 1) variable reads are atomic, They are not. Please read the memory model.
&gt; Thanks everyone. I've fixed it with channels. Don't be so quick to say "I've fixed it". If you're using channels, you could well be substituting one problem for another.
Unfortunately it seems like in that specific community, not worship Go and its design choices as "the second coming" makes you a blasphemer.. I just wanted to say i agree with all the points you made and many many people that work with Go daily do, despite the echo chamber that is this sub.
You are on a Go forum, what do you think the majority of the opinions will be? favorable to rust?
Sounds almost like the use case for https://golang.org/pkg/sync/#Map
Overall, pretty good. One small nit, in your README, when finding an error, you should return or exit if err != nil { fmt.Println("error reading file") // return or exit here }
Sure, good point. Thanks for mentioning it. Even if it's sample code, no reason to give it a way to potentially fail! Thanks, I modified it.
I was about to post essentially this comment. Even if the reads are atomic -- the entire logic of that whole section needs to be atomic. This is why we call it a "critical section". Yes. This 100%. Even if it appears correct -- it won't always be. 99% of the time, you will get correct behavior. 1% of the time you won't. Put a lock around the whole bloody thing. If you think a mutex is overkill (say, because you will read 99% of the time and only write 1% of the time) do something else in your design. Read/Write Locks also are a thing for such a situation. 
&gt; The Gitaly service spawns Git child processes for many of its endpoints. Why ? Why not use something like https://github.com/src-d/go-git ?
If it did, everyone would be inclined to use the same implementation even if it wasn't the most effective one for their use case, I suppose.
Not really a *job* queue, but have tried a message service like NATS or, if you need Kafka-like persistence, NATS Streaming? You can write your messages as structs representing commands or events, send them through the message service and let another service react to it. It is extremely easy to setup, does fan-out by default (all subscribed services get the message), but competing consumers (messages are delivered in a round robin fashion) can be implemented using a queue group id.
I agree with this. There are even services simpler than RabbitMQ or ZeroMQ. If you don't need persistence, you could even use Redis.
https://github.com/fsnotify/fsnotify Needs reviewers. Would love to have more people help out :)
I strongly recommend using `bufio.Scanner`, instead of `(bufio.Reader).ReadLine`. It is a much less subtle API (case in point: Your code is broken) and reads easier. Using a Scanner has no downsides. Note, that even the [documentation of ReadLine](https://godoc.org/bufio#Reader.ReadLine) says that you probably don't want to use it.
goroutine 4 checks min again before setting it. the problem is more subtle than that. 
That's not a PSA.
&gt;So yes. Get rid of the outer if and just keep the inner if with locks. That fix is no good either, as it makes the performance the same as if there was only one thread. You need to keep track of per-thread mins and maxes, then after all threads are done, get the final mins and maxes. 
Is `defer wg.Wait()` correct? Shouldn't it wait just after calling `go consume(r)`?
I've been working in an alternative for Gorilla mux, with middleware support, just like Node's Express. New ideas and bug fixes are very welcome, it started as a pet project but I feel it can be useful for other folks who need a simple HTTP multiplexer... And, well, it is faster than Gorilla, I still need to do some more benchmarking, but the expected result is it to be really faster. I also take into account Go best practices, so for learning some patterns (and for teaching me too) it can be of great use... enjoy: https://github.com/gbrlsnchs/httpmux
The process hasn't started at that point, so that would be a deadlock (as no text would be produced, leaving `consume` eternally blocking, so `Wait` would never return). It is correct to defer the Wait.
Oh, ok, I get it now. Had to read the post again, thanks for your patience to answer!
Assuming the map is read-only almost all the time, with very rare updates, then [atomic.Value](https://golang.org/pkg/sync/atomic/#Value) might be what you want. For reads, use Load to get a pointer to your map. For writes, lock a mutex, create a new copy of your map and add the new value, Store it, release the mutex.
You'd be surprised at how much faster just execing git can be over a native implementation or pulling in libgit2, depending on what you're doing. Git is pretty well optimized for the things it does.
My fix is "good" in that at least it produces a correct program. However, yes, as you point out -- it could strangle performance. Without seeing the rest of the program it's hard to say whether it would be a bottleneck. I can picture scenarios where it is and where it isn't. But yes, generally computing per-thread min/maxes and then broadcasting them out (say, using a channel) is the way to go. 
No, if you are comfortable coding in Rust, there is no particular reason to use Go for portions of your project, and indeed, there is a good reason not to - technical debt and cognitive load. First, technical debt: Normally this is about the cost of using an 'easy' solution now only to have to reimplement it later in something that can handle a more complicated situation; but in this case, it is not about easy/hard that I am referencing it, just the potential cost of later reimplementation, specifically from the perspective of refactoring. If part of your project is in Go (or any other language) and part in Rust, then this creates a sharper boundary, where you will be reluctant to move code across it than you would if both were in the same language. So, for example, if later on, you realize that part of your main project could be moved into a microservice, and all your microservices are in Go, you may skip over that opportunity due to the implicitly felt need to rewrite in Go; or vice-versa if it turns out that some portion would work better within the monolithic portion. If both elements are in the same language, you can more easily shatter or compose during refactoring. Second: cognitive load. I program regularly professionally in vb.net, java, and go; at prior jobs I have had to juggle coding in vb.net and two forms of C, and at other times Perl, Python, PHP, and Javascript. Each time I have to switch frames to a different language, I notice an increased cognitive load - I have to remind myself what patterns apply here, what rules of formatting, do type definitions go before or after parameters, return values before or after parameter definitions, etc. Likewise within a single language, switching between projects that have different sets of frameworks, libraries, or just environments (like C on desktop vs. C on handheld device, or different GUI environments), it takes a little time to get back up to full speed. It is not a huge thing, certainly not enough to by itself determine that you should never include multiple languages - but it is something to consider, and when it is possible to do the entire project in one language comfortably, it speaks against multiplying languages/environments unnecessarily. It is the same sort of impulse that might push one to use GopherJS to write Go code on the front-end, or Node-JS on the backend. 
That's how my editors does it aswell. Just executing the git binary. Works perfect
From the Glide readme: &gt; The Go community now has the dep project to manage dependencies. Please consider trying to migrate from Glide to dep. If there is an issue preventing you from migrating please file an issue with dep so the problem can be corrected. Glide will continue to be supported for some time but is considered to be in a state of support rather than active feature development. So it seems like while development hasn't stopped officially, it might be a good idea to migrate to `dep`. At least for projects that are supposed to live longer.
This seems to have done the trick, it's doing exactly what I want now. Many thanks! :)
Getting approval for allowing user-generated content in China is a gigantic hurdle. That's why play.golang.org blocks the Share button from Chinese IPs. You can spend tons of effort getting your IP ranges whitelisted and then have one Chinese user generate some content that violates some unwritten rules Chinese rules somewhere and then you get your whole site blocked. It's sad either way: sad restricting users from using play to share code snippets, and sad blocking them from reading documentation. So we picked the least sad option. :(
&gt;the command names make more sense IMO The reason it's `dep ensure` is [explained in the FAQ](https://golang.github.io/dep/docs/FAQ.html#why-is-it-dep-ensure-instead-of-dep-install). &gt;The idea of "ensure" is roughly, "ensure that all my local states - code tree, manifest, lock, and vendor - are in sync with each other." `dep`'s commands may be a little awkward to learn, but as a dependency tool it is _enormously_ better than Glide. 1) It's the only tool that flattens the dependency tree, which is critical because nested `vendor/` directories cause insidious bugs. Basically, every tool before `dep` was potentially introducing bugs that were so subtle, the community was largely unaware they existed. 2) It's much easier to update dependencies, because `dep` is really smart about finding versions of deps that satisfy both _your code_ and _your dependencies' code_. For the sake of correctness, please everyone get on the `dep` train. It will solve problems with your Go projects you didn't know existed.
That's really interesting. Do you have numbers to show ? Also, I have heard people at conferences advising not to exec git and rather use an API. And at the same time, there are lots of people execing and just calling it a day. So I guess there's no consensus on this.
Thanks, those are all good questions! But I am familiar with those issues. This is a simplex noise function, so it does quite a bit of work per unit of memory used. the speedup is approximately linear with # of cores. ~60ms -&gt; ~13ms on my machine The whole thing was part of a teaching exercise, and everyone got to learn, including me :) 
For a beginner, I think you need to know atleast the basics before reading concurrency in go, empty interfaces everywhere, used as a shortcut for book examples I guess. She does say something about the matter but I can't remember exactly what it was and it's fairly understated.
TGPL is go's counterpart to the c programming language, also written by kernighan (and Richie, rip). Considered by most C programmers as the bible on the topic. I think TGPL will also be considered as such for go so It's worth picking it up even to use as a reference, although go has something C never had; amazing documentation.
I've used all three as queues before, and ZeroMQ wins on simplicity. Redis is likely the most complicated. This is all as a single-node, single-client install...
It's true that the patching tools are one of the basic functionalities that are missing at go-git, as is described on the README, git is huge and we just got focused on what the people were demanding. Also, git is super efficient, hundreds of developers are contributing since many years ago. Said this... spawning git process with Go, has two problems: - Go exec is not an easy task at large scales, we found similar problems at source{d} in the past. - You can't optimize your processes or do memory operations with the repository since at the end is a binary created for the users with very different goals. (That's why libgit was created). So, yes go-git is not there yet but is not too far, to be more optimal than using git through an exec call and spawning another fork. Happy to discuss the missing functionality, to understand more the needs of the people. 
I was struggling to implement some weird data structures and in the end had to write this to be able to see what I was doing wrong. The graphviz output starts to get pretty messy if you have too many nodes but for small examples I find it really useful.
That sounds very similar to how sync.Map is implemented under the hood.
I have compared the clone operation for a 150MB repo with exec‚Äôed git, libgit2(git2go wrapper) with go-git and found go-git very slow. The times are approx 20s, 24s and 41s respectively. 
The DNSControl project is very proud of how many new-to-Go contributions we get. Some examples here: https://everythingsysadmin.com/2017/08/go-get-up-to-speed.html Project page: https://stackexchange.github.io/dnscontrol/
I still have an open problem with dep when using it on projects behind a proxy and on a mixture of local gitlab and public projects https://github.com/golang/dep/issues/860 This isn't a problem with glide, so I have to keep using glide for now. 
Thanks that does work!
IIRC, for the Node server, you're basically running through almost 100% C code for the server. It's not a test of "Node" but a test of their C-based webserver code. Go being ~2x slower than C is about right. As is often the case, it's difficult to write a simple benchmark that means anything, because anything simple enough for you to write as a benchmarking case is simple enough to have been heavily optimized and not a valid benchmark of the speed you can expect in your code. In this case, while Go is broadly speaking substantially faster than Node on real code, it is very likely that you're going to have that time dominated by the work the respective webservers are going to do, as you receive substantial requests and likely do just a smidge of work to figure out what to do with them, then the webservers take over again. I wouldn't pick Go over Node for "performance" in this case. I would be looking at which work better. In Go's case, as soon as you do anything that involves some sort of operation that in the node world would be considered "blocking", you start to see significant code simplicity advantages for Go because in Go, you just write the code. I myself have a relatively thin Go-based webserver that mostly proxies stuff through, but first has to hit a couple of APIs on other webservers to decide what to do. The Go code that does that is simpler than anything Node could do, because even simply having to slather your code with `async` and `await` is already more complicated than Go. I just have handlers that run a request out to those other servers and write straightforward code to handle it. In practice, dozens or even hundreds of these requests may be pipelined up at a time, and I'm not sitting here directing them around, it just works.
Look at the different implementations here: https://github.com/golang/oauth2 It shouldn't be very hard to add a new one. 
I didn't get why you couldn't use reverseproxy because you had to make multiple calls based on config. Perhaps you can clarify ?
Honestly I can't remember that well, I made the PoC a few months ago but I remember not being able to get it to work. Maybe it was because of the regex requirement in the URL parsing? It meant I couldn't use the standard http/server
Since I had not read the model, I used "assuming" :) Since the advice from the spec is "Programs that modify data being simultaneously accessed by multiple goroutines must serialize such access.", I'd remove the outer check as the check is being repeated inside the critical region.
That's a good point, might be what you mentioned in your first paragraph. I like what you said about what work it has to do.. maybe Node would work better due to the lack of work it really needs to do.
Nice! I wrote something similar for Perl way back when: http://search.cpan.org/~mcmahon/GraphViz-Data-Structure-0.19/lib/GraphViz/Data/Structure.pm This was written before graphviz supported tables, so it does some pretty obscene gyrations to handle the layout of typed arrays and maps so that all the boxes line up properly (and explains it in nit-picky detail; the graphviz docs weren't very precise about it).
I think a lot of apps are being re-written with parts of it in Go, rather than the full stack. It's inexpensive to take your bottleneck, rewrite it in Go, deploy it in the original's stead, and see increased throughput and decreased bandwidth costs. Gradually refactor your app in to Go rather than all at once. At Etherparty, we're re-writing our Node app in Go. It's about one third the lines the code, much faster, and works directly with Ethereum Go bindings for Solidity contracts. This is about as good as it gets right now for blockchain programming, so it makes sense for us.
&gt; What am I missing? Most popular languages are 20+ years old and Go is 8 years old?
I should've made it more clear but the program won't be leaving my tiny VPS and I'm going to be the only user. But I think I'll end up using something like rabbitMQ even just as a learning experience. 
why are so many in Java? who knows why trends happen. 
Yeah, I'm going to the next. Was too late to get a spot at the last... :(
Probably because it was available like 20+ years ago. As for modern apps, because there is a broad community for it now. Still baffles me that few companies I meet mention Go. 
Well there are lots of fascinating things to choose from now. Why should Go be a favorite for companies? The things I like about Go would have no relevance for most business purposes. But Go has been growing very fast according to some measure so maybe in 5 more years you will see it more often. 
That still doesn't explain why so few companies seem to skip the language now. The startup scene is huge here, and even when startup companies show up they are all coding in Node or Python.
Why do you care how often people talk about it? Go *is* used extensively, at small companies and large ones. I use Go at work at a tiny company in a small town in the US. It has succeeded in becoming an established part of the web backend tech stacks, although there are probably more companies that don't use it than companies that do... just like any other single piece of technology. Skills are largely transferable, and even if a company you get a job with doesn't use Go, they might be willing to consider it if they hire someone (like you) that might know it. I'm a heavy Rust user, and I can tell you that Rust is far, _far_ less common than Go at this moment in time. It is also a lot younger. That doesn't mean I'm going to stop enjoying and learning Rust. Don't use technology just because it's popular. Riding the hype train is a quick way to find yourself all alone. Use a technology because you have found it to be useful in solving problems. Technology for the sake of technology is useless.
Would you mind elaborating? I'm genuinely curious, as I mentioned I'm still new to the language and I don't understand why, for instance, a startup doing something like a chat application (or something similar) would go for Node instead of Go.
Ah, you missunderstand me. I'm not riding the hype train, as there is no hype surrounding Go here. I'm more curious as to why there is no hype. I love the language and want to understand why so few people seem to opt out of using it...
f the keys are static a mph can be constructed to avoid having the string pointers; if they're dynamic a strong hash function (uint64, uint128) can again be used to transform the strings into pointer-free data.
Well I know why people go for Node: because there are tons of javascript developers to hire , and because everything is all in one language if the client is in javascript, which can be convenient, and since Electron is perceived to be the easiest way to develop cross platform desktop apps, we get node. I think this situation is sub-optimal but I understand why it is happening. 
Yeah. I get that. I suppose I could have said Python instead. :p But you do understand what I mean? :/
For practical purposes, yeah, ditch everything, go single threaded. For learning purposes, ditch everything, go 2x single threaded (producer and comsumer), and use a message queue. I can't say this enough: YAGNI, YAGNI, YAGNI. Even if you're building a service to run at scale, build it simply and test it thoroughly before deciding how to "fix" the design for better throughput. More often than not, a simple design on modern hardware is sufficient to handle scale.
If you think few people are using it or hyped about it, you haven't opened your eyes, in my considered opinion, because that's just wrong. Maybe all the stodgy old financial institutions in London couldn't give a care in the world for something other than Java, and that's fine for them. But, Go is one of the most [loved and wanted](https://insights.stackoverflow.com/survey/2017#most-loved-dreaded-and-wanted) languages. It is absolutely hyped in tech circles. It is also *used* in the industry, as that survey shows. It's not *javascript* or anything, but it's one of the top languages, easily, and it's relatively young. Go is *not* my favorite pick of tech, yet here I am defending it. I think you should really accept that the fundamental principle of your argument is off-base.
Python people just LIKE it, I don't know why. =) 
 &gt;Which languages are developers planning to learn next? #1. GO - 37.8% it is interesting GO is prefered "45 to 54 year old". from https://research.hackerrank.com/developer-skills/2018/#insight4 
I'm sorry, but the fact that they didn't actually benchmark and try to troubleshoot the problem makes this article‚Ä¶ not particularly worthwhile. I'm not denying that they had issues with GC - after all, they have pretty clear measurements and their issues went away after not using it. But we run plenty of servers with such large heaps and all of them have sub-ms pause times (mostly in the tens of Œºs), so clearly their troubles don't generalize as easily. But without more investigation or at least knowing their actual usage patterns, it is impossible to learn anything from what they did. A priori, I wouldn't be surprised if the winnings came from other changes in memory layout that came with the rewrite. They might've been able to get just as small pause times without going through the motions of implementing their own hashmap (FWIW, Go's hashmap is *really good*). Or not. We'll never know.
This looks nice. But if you don't mind I'd suggest considering another name. "memmap" typically refers to memory mapping, as in memory-mapped files, shared regions, etc. 
 for i := 0; i &lt; len(x)/2; i++ { x[i], x[len(x)-i-1] = x[len(x)-i-1], x[i] } https://play.golang.org/p/Gd9d3R6ZhcR
Yeah, agreed, it's definitely more ambiguous than I'd like. I guess memory visualisation (memvis?) would be a better analogy than mapping?
Type "http://godoc.org?q=" in front of the "https://github.com..." in the address bar and press enter to view the doc. Install the [bookmarklet](https://godoc.org/-/about#bookmarklet) to automate this.
**Developers are learning the languages employers are looking for most** **Go 6.9%** https://research.hackerrank.com/developer-skills/2018/#insight2 
Everything goes through an S-Curve and go hasn‚Äôt hit its exponential growth part of the curve yet, but it‚Äôs certainly feeling a lot closer than a couple of years ago. Another 3-4 years and I think the use of Go in professional development (as opposed to professional curiosity) will be exploding.
Python is 26 years old, so I'm not sure what you are trying to argue.
God. Why are so many of you so hostile?! What can I possibly have said that makes you believe I'm trying to argue something...? I'm not trying to *argue* anything. I'm trying to *understand* something that genuinely confuses me.
You seem to think that Go is obviously better than Python/Node/Java/F#/C3/Ruby et all Can you explain why you think that? 
I think the fact that it's built around concurrency makes it a more obvious candidate than say Node. The fact that you dont need licenses make it stronger than the .net stack for instance. Not sure if I think it's necessarily stronger on all fronts. But that's why I'm reaching out to the community..
I'm a project in graphql at the moment. I'll give this a shot later today and see what it thinks of the schema. Nice job!
Go is a language designed to be pleasing for developers (at least the ones working at Google). Employers tend to stick to industry standards in order to minimize risk and to be able to easier acquire external projects from bigger companies. Also generally, employers don't care about what developers find pleasing. They just want the job done with a press of a button if possible. The only way to convince them is by offering them the promise of that magic button. Thus success stories and articles like [How We Went from 30 Servers to 2: Go](https://blog.iron.io/how-we-went-from-30-servers-to-2-go/) are important.
Well everything is better than node if you ignore the ubiquity, but ubiquity is important and real and has feedback loops. You can build things in .NET without paying for any licenses. C# and F# are both free and open source. I have an F# web app in production, zero things had to be paid for. A lot of companies focus on what tech will let them get a product to market quickest as the first order parameter to optimize. Go being about as low level as GC languages go, may seem suboptimal to many. That may not be accurate but that will be the perception sometimes. The concurrency features are nice but it isn't totally unique in that way. The things *I* like about Go are the self contained, aot compiled, native executables, low latency GC, and that pointers are not hidden from you. But for code that is going to run on a server those things offer no substantial advantage usually.
&gt; Go's hashmap is really good I'm googling atm, but can't find anything related. Might care to explain? Do you have any code-examples? I'm currently using Go's sync.Map for caching and I'm still looking for "better"/faster options. Regards
The standard Go `map` that's in the runtime. I've had a hard time beating it in my own benchmarks with maps tune for my particular use case. Here's a talk about it: https://www.youtube.com/watch?v=Tl7mi9QmLns Here's the code: https://golang.org/src/runtime/hashmap.go
Keith Randall gave a [pretty good talk at GopherCon 2016](https://www.youtube.com/watch?v=Tl7mi9QmLns). At 24:35 he shows some benchmark stats and though, of course, they should be taken with a grain of salt, they are a pretty good indication of the quality of Go's builtin map implementation. &gt; I'm currently using Go's sync.Map for caching That doesn't seem like a usecase sync.Map was [designed to solve](https://www.youtube.com/watch?v=C1EtfDnsdDs) (really, watch that talk. It is a pretty conclusive debunking of most of the hype around sync.Map - from the person who wrote it).
&gt; Type Woah woah woah!!!! Let's not get crazy! :) Thank you for the bookmarklet. It embarrassingly didn't occur to me that such a thing might exist, even though I've been using the Kick-Ass bookmarklet to destroy web pages for years. Usually I only end up at godoc.org after being frustrated with a non-intuitive behaviour, so I'm all tunnel-visiony and frothy about the collar...
Yeah I think something like memvis would work well. If I'm going to change it I only want to do it once though so I've created an issue to get a larger sample size: https://github.com/bradleyjkemp/memmap/issues/17
Looking for help with https://github.com/zricethezav/gronit
Thankfully this is a common practice on most good Go packages on GitHub.
Even if the naming is weird, the learning curve is basically these four commands. dep init dep ensure -add dep ensure -update dep prune (going away) `dep prune` will soon be merged into `dep ensure`, and you can avoid using `dep ensure -add` by just importing the new package and running `dep ensure`. So you basically have to know two commands. I'm not sure what your objection is to `dep ensure -add`. It temporarily relaxes the requirement that every vendored package must be imported somewhere. The manifest, lock file, and vendor are never out of sync.
A lot of times it's about what is already well-established in your company or industry. For example, if your company is doing data science and machine learning, there's a good chance that everyone is already familiar with the Python data science stack. Also, many people have a "get off my lawn!" attitude toward new languages in general. I haven't been able to get anyone in our company to *look* at Go over Python, despite Python failing us miserably (performance, deployment complexity) and Go being ideal for our use case (fast, compiled, simple deployment, easy to use, easy to learn). No one has given any remotely compelling reasons not to switch; I think mostly no one takes it seriously, probably assuming that any new language must take months to learn.
&gt; I was about to post essentially this comment....EDIT: I just noticed he's checking the min/max values a second time within the critical section. So the situation you described can't happen. Well don't I have egg on my face
Oh yeah, this looks awesome! I agree, though, that memmap is not a very good name.
&gt; The idea of "ensure" is roughly, "ensure that all my local states - code tree, manifest, lock, and vendor - are in sync with each other." This is why I have a problem with the naming. This is the reasoning, but then they don't follow their own reasoning. That's all. The commands are easy, they're just unnecessary compared to what they could be. It's not a big deal by any means, like I said, I have set up some abbreviations anyway so I just end up typing `depea` which expands to `dep ensure -add` instead. Naming of commands and flags aside, they also have neglected a different convenience feature; being able to update to a new version of a library that has been refactored to the point where old sub-packages no longer exist. This is a pretty big problem IMO, because if you want to upgrade code, you want to have the new code installed so you can see what you need to do to update it. Right now, it has to be something along the lines of: * Remove folder from vendor folder. * Clone repo into vendor folder, or put it on your GOPATH at the right version. * Make your code changes. * Update dep (and you can't do this inbetween either). I'd rather sometimes the tool just trusted me and was like "okay, I know your code won't compile now because that package you're currently using isn't there in the new version, but I trust you know that and I will get out of your way, since you've passed some flag to tell me to do that".
&gt; Seriously, folks, this needs to happen more often. What, vague thread titles or memes? Frankly, I don't think either do much for the quality of this sub.
The divide between young and old people on Go is interesting. I would think Go would appeal to younger people over C/C++.
Most company backen infrastructure, especially financial sector, is going to be 15-30 years old. Stuff you'll see in similar presentations 20 years from now might have started development two years ago, but its going to be a long time before you start seeing components written originally in Go in stacks like that. In 5-10 year timeframe, you might start seeing replacement components that were rewritten in Go to replace technologies that are no longer supported today, such as .NET. 20 years ago, I was in your shoes with python- why don't I see it everywhere, its great! Then I started working, and business stacks in 2001 looked something like... a screen scraping Delphi GUI talking to some weird billing/shipping/business process backend written in Clipper over a virtual serial port.
I wish that were true. 
What are you trying to imply here?
Not only is this just an advertising link. It is advertising a horrible design practice of tightly coupling client/server code. Wish I had more than 1 downvote to give.
&gt; It is fully configurable through the GUI A screenshot would be nice.
I'll have you know that your comment isn't idiomatic... j/k great comment!
Got any examples of good Go packages that have no godoc link?
Sorry I wasn‚Äôt aware we were in court. I contacted my lawyer and he said this: &gt; gorilla/mux and julienschmidt/httprouter both do not have their godoc URL in the readme.md, it is buried in the GitHub description line. 
&gt; Sorry I wasn‚Äôt aware we were in court. I contacted my lawyer and he said this: &gt; &gt; gorilla/mux and julienschmidt/httprouter both do not have their godoc URL in the readme.md, it is buried in the GitHub description line. Your lawyer needs new glasses. https://imgur.com/a/c0XmS 
tl;dr &gt; The Go GC isn‚Äôt bad. It‚Äôs actually very good. But if you have large multi-GB data structures involving pointers (and in particular string map keys contain pointers!) then you‚Äôre probably paying a hefty penalty as Go periodically goes to check that every single one of those strings is still in use. And if this is happening to you now and you don‚Äôt think it is a problem, it may suddenly become a problem one grey and wet January morning. that's true, but I think the point was the "oh, we're hiring", if you follow it &gt; At Ravelin, you will be invited to have opinions about strategy, direction and product. **Your background is unimportant**; we care about where you want to go, not where you've been. I wonder if I can be a bad guy, at ravelin, under their noses, that dicks with their ML algos \^\^
I was not initially aware that you could add an import line then run `dep ensure` instead of using `-add`. I think more people should be aware of this feature. For example, to add multiple things at once, just list them all as `_` imports, run ensure, then use them in your real code. 
I believe you can do what you want by specifying a version override in Gopkg.toml temporarily, but it‚Äôs less clearly documented than it could be. 
‚ÄúLast resort‚Äù is maybe not how I‚Äôd phrase it, but certainly use channels sparingly since they are slower than locks. The point of a channel is to write *clear* code, not fast code. If you‚Äôre using a channel for speed, you‚Äôre probably doing something inefficiently. 
&gt; &gt; from someone at MalwareBytes &gt; Just a heads up, that person is no longer with the company. absolutely nothing except what was explicitly stated. the author of that blog post is a great dev, but to say that he is still at malwarebytes is incorrect. he left to do other (awesome) things. 
To do blockchain stuff you should start learning Haskell :) Plutus is going to almost certainly replace Solidity and Plutus is basically a form of Haskell
I would love to! I've seen Cardano's docs on Plutus and it seems great, and a much better language than Solidity for contracts.
FWIW, now that we've got a new release out, this is one of the main things i plan to turn my attention to.
The valuation makes sense when you see some of the more out of the limelight stuff they've put out :) They're going to be backwards compatible with ERC20 tokens and Ethereum contracts, you'll be able to run your Ethereum stuff on the Cardano network. Ethereum just has absolutely horrible software engineering principles if its trying to build infrastructure to build trillions of dollars of financial systems on. In fact the Ethereum foundation never Formally Verified the EVM, IOHK, the company making Cardano had to pay for https://www.coinspeaker.com/2017/08/01/iohk-funded-uiuc-project-produces-first-complete-formal-semantics-ethereum-virtual-machine/ Also you're going to love this, Cardano created it's own Virtual Machine, IELE, that is objectively way better than Ethereums :D https://runtimeverification.com/blog/?p=498 
yeah, the "in-between" time, when you're refactoring to work with a new, significantly changed version of a dependency can definitely be an awkward period. this has come up in the issue queue before, and there are some other approaches you can consider taking while in the transitional phase: https://github.com/golang/dep/issues/1265#issuecomment-336486323. that issue also includes some discussion of possible future plans.
tons more, better docs now, too üòÑ https://golang.github.io/dep/docs/introduction.html
Yeah I've seen a bunch of that stuff. The valuation still doesn't make sense. Cardano sold a gigantic percentage of their tokens to private presale investors for $0.0024 per token. If Cardano releases a popular, great product - I would love to make contracts for it as well. But it is all very far away, and I work professionaly with blockchain NOW. So I have very little focus on Cardano at the moment. It seems to be more of interest for traders rather than programmers. 
Doesn‚Äôt look like a readme to me, but I‚Äôll have to check with my lawyer and get back to you. 
&gt; Doesn‚Äôt look like a readme to me, but I‚Äôll have to check with my lawyer and get back to you. The evidence is undeniable though: https://i.imgur.com/r1cgNQX.png
Please. That could be any repository.
[]byte is a slice rather than an array. As a slice, it acts as a "pointer". https://blog.golang.org/go-slices-usage-and-internals
Even better, generate your `README.md` directly from code, that also links to the godoc. Helps those that are too lazy/dont know to go to godoc, and deep links to examples. I do it for all my repos. Case in point: https://github.com/eduncan911/podcast 
You need to post the code for a helpful response, I‚Äôll say that I‚Äôve never seen a correct benchmark between node and Go that Go doesn‚Äôt come out ahead on by a large margin. 
What licenses do you need for the .net stack? I don't know about Node, but you can do concurrency in .net pretty easy. Python is also capable of async. Go being so much younger than Python/.NET/Java make it less desirable for companies because its hard to find devs that have experience with it.
[removed]
I'm working on yet another medium-interaction SSH Honeypot in Go: https://github.com/mkishere/sshsyrup . Am still learningwith the language, so I'm struggling with design/coding etc. Would appreciate someone who can give insights and also implement the coreutil command set
I like defer. for _, element := range x { defer fmt.Printf("%#+v\n", element) } 
I think this whole framework thing is playing a big role in why go is not as popular for younger people. First by defualt it isn't a front-end. A ton of people start the web with front-end. Plus, it sounds exciting to learn new frameworks until the fatigue sets in. From doing js line by line console.logs to matching scope with a function that takes a function, that runs a 2 nested function with of course "this" that then returns a functions. To memorizing all those jQuery methods that when there is an error it returns the jquery lib. To realizing you made absolutely no reusable code with all those nice jQuery methods. To that wonderful, wonderful pre-flight error that you first learn about. To angular 1 using a scope object you have to wrap every time you call it. To forcing yourself to learn angular 2 and then they replace routing all of a sudden with a console link to some page. To now hey angular4? But then why not vue.js and react too! Oh how those days were... Coming out of learning c# and php to this.... Mess https://hackernoon.com/how-it-feels-to-learn-javascript-in-2016-d3a717dd577f Then came go! What? Anti framework? Doesn't change? Not many methods? Easy to read? Tells you what wrong out of the box? ....... Wait for it.... Wait for it... No npm!????? Yeah you know what I chose. 
You might also like https://mholt.github.io/curl-to-go/ for converting cURL commands to Go code. (I need to get on some PRs/issues for that, but it still works pretty well as-is.)
&gt; And no, I couldn‚Äôt ‚Äújust use postgres‚Äù for this How about rocksDB ? Genuinely curious.
Look at the noCopy struct https://github.com/valyala/fasthttp/blob/master/nocopy.go#L7:6 which points to https://github.com/golang/go/issues/8005#issuecomment-190753527
Perfect solution. But I want to know why we use the sort.Reverse() 2 times?
This is a good point, and I failed to mention that the concurrency book is not for beginners. I only included the book as the OP specifically asked for ressources about goroutines and channels.
True. I would defer to the open source community for that. I tried to separate out the colors to make such a thing easy to modify. Hopefully someone can add a flag for light background themes and PR it in!
Typically, I agree with you. The fragmentation in the Node.js space has led to utter anomie. Despite this, I think the tools you use very heavily, like every hour, should be as tailored to your tastes as possible. I think it's good to have tons of options for `ls`. I'm not trying to replace `ls`, just put something out there with a little personal flare üéá
Love your work man, I used to work for a company that connected to several different social media apis and json-to-go saved me so much time when I was transforming json payloads . üôè
It only excels at a handful of things that aren't the core product for the majority of startups. In particular things it's crap at are: scientific computation, analytics, front end web, gluing together off the shelf solutions, scripting, for example. Most startups shit out a website, Go's too low level to be quick at that. Source: me, trying to do all of the above.
Go isn't popular among some people because it's a boring, verbose and inelegant language. For some all these are a plus, but I don't think it is. Go has a great std lib when it comes to networking though, it's really easy to write servers with it. But the error handling is a joke, the absence of generics a pain in the ass and if you look carefully at its open source echo system, it's not that good. I have no doubt developer sweatshops will adopt it though, just like Java, because again, it's good at writing servers.
&gt; Which languages are developers planning to learn next? Is the question asked.
Good idea! I have added some screenshots.
it's 1.76x faster than Nginx now!
[removed]
&gt; Go being so much younger than Python/.NET/Java make it less desirable for companies because its hard to find devs that have experience with it. That's a vicious circle, though. Having that said I am seeing some major companies starting to ask for Go in job ads in my country. It's mostly for DevOps/SRE positions, though. 
and here are a few pointers to the sources: - http://mrg.doc.ic.ac.uk/tools/#godel-checker - https://bitbucket.org/MobilityReadingGroup/godel-checker - https://github.com/nickng/gospal and the link to the paper (draft): - http://mrg.doc.ic.ac.uk/publications/a-static-verification-framework-for-message-passing-in-go-using-behavioural-types/draft.pdf
When starting a startup your goal isn't to write insanely scalable code or to write the best version of your app - you get to that later. Your goal is to iterate quickly and prove that your business model works. As a result, most founders use a language they are already familiar with - this is faster than learning a new language - and most founders won't already know Go because it is still fairly new. Old companies don't use go for new projects often for simply reasons - why learn something new and retrain your team when they know how to build stuff in another language and have been doing it successfully for a while? Why bother with the risk? For it to make sense you need a big reward. As Go grows that reward will grow. It will be easier to hire devs who want to work with Go, and the number of devs in that category is rising. As more projects in Go succeed it may become clear that the initial cost of learning the language is outweighed but reduced maintenance or something else. Go also has less resources online than say python, making training harder. All if these get fixed in time, which is why age matters.
Awesome! If there is a newer and more specific issue that covers this problem, please link me so I can track it! 
I use the [Go2Doc](https://chrome.google.com/webstore/detail/go2doc/mnpdpppgidppdhingkmlcmmgdjknecif) chrome extension to go to godoc fast.
&gt;faster than nginx &gt;micro-benchmarks bet you it isn't
Look into LMAX architecture. I would use C++ or Rust for that kind of stuff.
Could someone just create the golang version of composer? (https://getcomposer.org/) I have tried all go package managers and none of them came near, every one of them had a blocker issue for me, like not supporting versioning, suggesting to commit the vendor folder into the app (due to the missing versioning support), terrible or non-existent private repository support or lack of authentication support for that matter etc.
The first time I write on reddit... To counteract the original reply: I'm happy to report that your slightly clickbaity post gave me a chuckle and made me realize I didn't add the godoc badge to one of the repos I own. If you want more joy, another option is to write more Go code :)
TL;DR: GitHub Enterprise support still broken (unlike v0.2.1)
Both Glide and Dep do handle all of the things you've mentioned there. Even if sometimes a little counter-intuitively (e.g. having to edit a file to add a private repo instead of just being able to run a command for it). Composer is excellent, and I do wish there was a direct 1-1 equivalent in Go. Pretty much the only issue I have left with Go package managers is when you want to update a dependency that has been refactored. The tools that are here now just get in your way, and you have to do really weird stuff to make it work. I've mentioned it in more detail elsewhere in this post.
in this case the channels are pushed to once per goroutine (order of 4) vs the lock which would need to be used order of a million times per goroutine. the overhead of the channels is not even measurable, but yes I could easily not use channels and achieve the same thing. 
If you use VSCode this is pretty cool: https://marketplace.visualstudio.com/items?itemName=quicktype.quicktype
I'll make a benchmark after release v0.1. for now it's just a simple test. I've read discuss by your link, what you say is truth :( but I think it's enough for most case. by the way, this package is designed just for `circuit breaker`, it should run behind Nginx(I don't want it to seize the power of Nginx, not handle lot's of details of HTTP RFC).
Ah well, you don't have to. I'm just an idiot who coded at midnight. I've corrected the Less function and adjusted the call. As you found out, things are a lot simpler if you use a StringSlice, a Float64Slice, or an IntSlice since the package already implements the Sort interface for them.
https://github.com/golang/dep/issues/860 is near the top of my priority list, now that this release is done. i'm also getting together a group of companies to try to pressure GitHub to fix the problem. i realize it's small consolation, but the GHE working under v0.2.1 is kind of a weird accident. i'm honestly not even sure how it did work; GHE's implementation of [`go-get` metadata in response to HTTP requests](https://golang.org/cmd/go/#hdr-Remote_import_paths) has _always_ been broken. 
nope, that's the one to watch :D
I am looking forward to a proper solution to private repos.
What exactly do you mean by "private" - like, GHE? If you just mean interacting with e.g. a private GitHub repo, that's been supported for some time - it's a question of [setting credentials in the background](https://golang.github.io/dep/docs/FAQ.html#how-do-i-get-dep-to-authenticate-to-a-git-repo).
Thank you!!! Sounds perfect :D
We use self-hosted GitLab and I was having trouble getting dep to work for our internal packages. But perhaps I was doing it wrong. I'll be trying again soon.
If you're already familiar with Node, I would consider it the best choice locally.
Awesome, love hearing that! Glad you find them useful!
the list of frameworks isn't even coherent. node and angular? those are categorically different things. why not put opengl and SDL on there too? 
Same, trying to make it works with private stash repo + SSH key was impossible, had to make the repo public.
The major question here is always whether the hosting service reports the go-get metadata responses correctly. i don't know if stash does; i do know that gitlab usually does, though it's broken for subgroups: https://github.com/golang/dep/issues/1371
&gt; I'm left wondering, shouldn't the Go runtime then not do it for me/you by default? It can't. In your specific case (or in the case of a minimum perfect hash) there is a bijective mapping from "hashes" to keys. But for that, you need to know the set of possible keys in advance (which the runtime can't). Given that the keys-&gt;hash mapping isn't injective, you thus need to store a set of key-value-pairs (say, as a linked list) to find the value of your actual key. And yes, *that* should be done for you, and it is. But it doesn't end up removing the problem of having to store the hash. I'd be interested to know whether the problem also happens if you store the strings in a slice, instead of a map; that is, is the problem the number of pointers, or is the problem the fact they are in a map? Because the latter should probably be addressed in some way.
Yeh, this looks like a GC/map bug more than anything else. On my machine with the code posted I get: * With a map of strings, GC took: 2.53878s * With map of strings(that are hashed to ints), GC took:: 12.802ms ...and if I convert everything from maps to slices and use append, I get: * With a []strings, GC took: 206¬µs * With []strings(that are hashed to ints), GC took:: 148¬µs 
I like Go (although it is missing immutable function parameters in my opinion), but I believe it is missing a driver or a unique selling point to help it become mainstream. C had UNIX. JavaScript had the Internet. C# had Microsoft. Turbo Pascal and Delphi had RAD. Go has... ?
That was all with 1.8.3, just tried 1.9.3 and it's ~20% faster. Also preallocating the map size at make time is about 20% faster. One major difference is that in the case of the [int]int map where both those changes make it ~90% better (new GC time: 1.431745ms).
&gt; wouldn't a downvote be sufficient? Votes are largely meaningless. I can't tell you anything by clicking an arrow. Words carry meaning. &gt; It isn't up to you It's up to all of us to maintain a continuous dialog on what the community should look like. That's what I'm doing here. Apathy only leads to decay. &gt; the evidence seems to support that our community... doesn't seem too think to badly of it. However you want to interpret that data, it's no reason to suppress "dissenting" ideas. You might even find said "dissent" is actually a popular opinion that's rarely expressed. You might consider that reacting so strongly to others' opinions... leads to a situation where folks begin to avoid expressing an opinion for fear of said reaction. Tribalism ensues. Discussions lose color, echo-chambers form in their stead. This happens everywhere: many subreddits, local communities, even our lovely Congress. This really what you want? Because this is the direction you're leading us... that is, if anyone's following you.
And https://www.youtube.com/watch?v=SzgRMrrbTnM
this is discussed in the new [Daily Dep](https://golang.github.io/dep/docs/daily-dep.html#adding-a-new-dependency) guide :D
type assert the error and inspect its fields items, err := ioutil.ReadDir(pathStr) if err != nil { if pathErr, ok := err.(*os.PathError); ok { if syscallErr, ok := pathErr.Err.(syscall.Errno); ok { switch syscallErr { case syscall.ENOENT, syscall.EACCES: log.Print("special handling for ", err) } } } return err } This article has some good tips for handling errors https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully. &gt; The Error method on the error interface exists for humans, not code. IMO that applies to every language. Error messages should only be inspected if there is truly no other option. In this go example the code for handling the error without inspecting the string is a little more verbose but that won't always be the case. Here's a little python example to show the equivalent options for error handling in another language. The option to handle the error based on its string message is less safe and correct and more work. class MyException(Exception): foo = 42 def __str__(self): return "foo: %d" % self.foo try: raise MyException except MyException as e: print e.foo try: raise MyException except Exception as e: s = str(e) if "foo:" in s: print int(s.split(" ")[1]) else: raise e
Any update on the symlink troubles and blues?
&gt;I think the fact that it's built around concurrency Erlang Elixir Lisp-Flavored Erlang even java had concurrency considerations from the start
I've used your 2 tools an absurd amount of times. I do a lot of work with communicating to apis and this has saved me so much time.
&gt;I have a random question that I've been thinking about during my time learning Golang: &gt;Why do I see so *few** companies using Golang?* If the company has already codebase in Java/C#, there is no real advantage in going to Golang. If the codebase is in Cobol, it will stay in cobol until 2199 approximately. Golang is a very niche product: not so fast (compared to other statically-typed languages and compared to some languages with GC), type system is limited and unflexible (compared to many mainstream languages), lacks some things considered essential to business system development (elegant error management, for example), and there are many concurrent models available for other languages. It's more of a niche player for concurrent programming, but even there, Erlang and family (Elixir/LFE) arrived first to the party.
This. In many cases you can get your webserver to respond with the correct command that go get should run: if ( $query_string = "go-get=1" ) { rewrite ^(/[a-z]+).*$ $1; # Rewrites /some/project?go-get=1 to /some return 200 '&lt;html&gt;&lt;head&gt;&lt;meta name="go-import" content="$http_host$1 git ssh://$http_host$1.git" /&gt;&lt;/head&gt;&lt;/html&gt;'; } Above would vary of course depending on your web server, repo etc but it does allow you to work around issues with `go get` in a lot of cases so long as you control the webserver.
&gt;The only way to convince them is by offering them the promise of that magic button. Thus success stories and articles like How We Went from 30 Servers to 2: Go are important. That story is about how a backend in Ruby went faster with Go. Ruby is the slowest of the mainstream languages (with the MRI implementation), even JRuby is still slow to many other dynamically typed languages. Rewriting it in almost any language would give a speed improvement. 
&gt; Do that many people really use VIM over commericial IDE's like IntelliJ? Yes. Yes we do.
The current two best vendoring tools are govendor and this one. /u/sdboyer Is there a recent benchmark for vendoring large dependencies? Thanks!
Since I'm not seeing it mentioned in the article or the comments, the CL that resolved that issue was implemented by Richard Musiol (https://github.com/neelance). Thank you Richard!
&gt; or is the problem the fact they are in a map? I could've sworn the GC didn't walk maps. Or at least I remember an issue about it a while back.
That‚Äôs precisely the point...
it works if there is an injective mapping into the key-space. i have no idea what happened with ravelin. FWIW, you can also use solutions like use a significantly large and strong hash function that it becomes *effectively* injective, but there would still be a chance for collisions. Or, if your strings are bounded in length, use a `[N]byte`, which would also be pointerless. I don't know, though, it really depends on the specifics.
It has to. GC generally works by exclusion. That is to say, you go through, mark what is live, and anything else that remains is assumed dead and can be collected. If you don't traverse the elements of the map, you can't know whether or not those elements are alive. I guess it could be avoided if for every map you could promote all entries into old gen, but that would be not great as it would require a full GC to clean up any map... Though, if your map gets big enough, that may happen anyways.
Consider switching to `dep`. Never had any issues whatsoever.
Get testing on this, run it from in container, in your CI, on your tests to see if they work (run twice, to get the spectacular cache feature and see how much quicker things are). Help the Go team make the best release they can.
I apologize if it sounded like I was attacking you. That was not my intent. I think a lot of us feel that Go has a very healthy base right now for its age, and it will just get better with time. This is from experience. (I went to college in the '80s, well before C++ was mainstream). JetBrains recently released its GoLand editor. AWS recently announced Go support in Lambda. This will result in more programmers seeing Go as a viable option for their projects, which will in turn lead to more tools being built for Go. It's a cycle. I assume that there were enough programmers asking for these products from JetBrains and AWS to make it worth their investments. The Go language is being used, maybe just not in your circles. This has been going on with Python for 26 years. And with JavaScript for 22 years. (Node.js is not a language, it's just part of the cycle for JavaScript that I'm describing). Eventually, Go will be a language that has just always existed in the minds of young programmers (and a much better language than it is now), with a strong infrastructure supporting it. Finally, to answer your question, the companies that you have been looking at probably feel that they can get the project completed WITH THE LEAST RISK in Python or Node.js because that is what they are most comfortable with at this time. As an experience to counter yours, I've been to meetups at Uber where they talked about their systems developed in Go. Companies that use Go are out there. 
You've gone off the philosophical deep end on this one, and I'm not sure if it's because you truly believe what you're saying, or if you're simply just trying to craft a credible sounding defence for your poor behaviour.
Neat! That's a good optimization.
Check out github.com/skelterjohn/go.wde - it can help with platform issues, depending on what layer you want to work on.
Philosophy? Sorry, not following you. You're more than welcome to respond to what I post, no need to get personal.
how about sgraph?
I did respond to what you posted. Perhaps my dismissive tone and unwillingness to play along with your ridiculous game is what confused you. Not philosophical? I'll break it down for you. &gt; However you want to interpret that data, it's no reason to suppress "dissenting" ideas. You might even find said "dissent" is actually a popular opinion that's rarely expressed. You're asking questions that neither you or I could obtain sufficient evidence to answer with any kind of authority. How is this not philosophical? &gt; You might consider that reacting so strongly to others' opinions... leads to a situation where folks begin to avoid expressing an opinion for fear of said reaction... [blah blah blah] ...even our lovely Congress. You're right, totally not waxing philosophical. You somehow brought up a foreign country's political system in a transient shitpost about godoc. &gt; This really what you want? Because this is the direction you're leading us... that is, if anyone's following you. Nobody is following anyone. I don't stay awake at night worrying about the reddit Go community. I don't think many folks do. 
&gt; Theoretically, I don't see what would prevent them from marking pointers allocated inside the map as "in map," other than a bunch of extra complexity. data := data.New(...) m1["foo"] = data m2["bar"] = data m1["foo"] = nil 
I really want to use grpc, but the lack of support for http 1.1 prevents me. I wish there was a way for limited support, even if it didn't allow streaming api.
[removed]
Finally generics! Do you know where is the document with valid syntax?
Obviously poor taste in trolling.
xD nice try.
Very generic troll. Did you use a template?
In that instance it might not work for the values, but it still holds true for keys.
There are a few changes that I'm excited for in 1.11, but none of them at the language level. What were you expecting to see and it didn't happend? Links to issues would be nice, create by you would be a bonus.
One note little addendum note - dep goes a step further than the toolchain and pretty much just disallows relative imports entirely.
üòïemojis.
Really nice, I was looking for something like this recently. Really glad that you've started this. I'm going to install it and play around with it now. ------ From your're readme cd $GOPATH/github.com/Ennovar/gPanel Do you have a weird gopath? or are you missing a `src` in there?
HTTP1.1 support; A simple RPC framework with protobuf service definitionshttps://github.com/twitchtv/twirp
Two things I'm really happy for with this release. Much faster build times for coverage tests. I tested out 1.10beta1 and our builds went from 14 to 7 minutes. And finally a the sanity change to bytes.Split and friends that makes appending to the resulting slices not cause behaviour that made me crazy. 
FTR, the issue with sending a file over RPC isn't, that it has no exported fields, but that you simply can't do that. Behind the scenes a file is in essence just an integer index into a datastructure in the kernel, associated with your process. That is, it is only helpful to your process on your machine. You have to do what you did - send the bytes, in some way or another (or a way to *find* the bytes, e.g. via a networked file system).
I agree this looks a little bit greedy on resources. We use a single transaction with multi-line inserts batched into groups. We do something similar to this but with batching (mysql has limits for the number of parameters allowed in parameterized queries): https://stackoverflow.com/a/21112176/303698 Make sure to write some db-enabled tests so you can optimise batch sizes for performance.
you should use for file management this package, https://github.com/hacdias/filemanager
It's quite a big project with an embedded CGO database (Rocksdb). Just to be clear the timings include running the tests. And no I haven't filed an issue. 
In Go &lt; 1.10 if you move the packages that import C into packages that rarely, if ever, change, then those will still be cached when using ` go build -i `. I would expect this behavior to be maintained with the new caching system. Same for tests,where 1.10 should massively speed this up.
I will think about how to hide the mouse and Multi monitor support.
I am thinking of using v2 in a new project. Is it stable enough now ? Or are there still changes happening ?
for postgres &amp; mssql, there are CopyIn api for do database specific bulk insert: https://godoc.org/github.com/lib/pq#hdr-Bulk_imports https://godoc.org/github.com/denisenkom/go-mssqldb#CopyIn https://github.com/denisenkom/go-mssqldb/blob/master/examples/bulk/bulk.go
The issue is (probably), that `ReadBytes` returns everything up to *and including* the delimiter, so `line` will include the newline (and comparison fails, as your string doesn't). Which causes me to re-emphasize that you should almost always, when reading line-wise input, just use `bufio.Scanner`. It takes care of all of that for you and should work as expected. I.e. func main() { resp, err := http.Get("the_url_of_the_file.m3u8") if err != nil { log.Fatal(err) } defer body.Close() s := bufio.NewScanner(resp.Body) for s.Scan() { line := s.Text() if line == "#EXT-X-ENDLIST" { //trigger } } if err := s.Err(); err != nil { log.Fatal(err) } }
Thanks for your thoughts @HowardTheGrum
Hmm, maybe map traversal takes a lot of time?
Thank you very much for this quick and clear explication worked perfectly 
You should add "...in London". I guess. At the same time financial comoopanies, banks etc will have lot's of java etc already. Nobody will jump onto the Go just because it is "built for stable, distributed systems". I see many job's posted for go developers all the time all over the world though. 
Another idea is: Create a CSV file on the HDD or in memory. Read that CSV file into MySQL. That is the fastest way to insert data. You can create a "shadow table" to read the data in and then via a rename table query to replace the old table with the new one. Rename queries are atomic.
Well, from something that doesn't even work with vendoring, it's about to be on the way out. I guess they haven't fully removed it only because some compatibility promises.
Thanks, I had trouble finding this with Google :) I will give the Windows SignTool a try.
You will need an actual Authenticode code-signing certificate to suppress the warning for end users, by the way. Test signing and self signing can be set up to bypass smartscreen on your local machine but you will need an actual cert for end users
Users could put in a duplicate entry. Duplicate of something already in the database. 
yeah, i have to imagine it's compatibility reasons. dep disallows it for safety reasons. i've only one or two cases over the last year where it's actually caused an issue (somebody had relative imports in their project, and someone else tried to use that project as a dependency). so i'd guess it's pretty narrow in the wild.
&gt;I've also got a Node.js PoC which does the exact same thing Doubt it.
Hi there, I'm actually not the author, George can be found on his github linked in the post, where it lists him as the author. I simply run the website :)
Something else to keep in mind is that Go does a copy when you convert from byte slice to string and vice versa as a way of guaranteeing string immutability, which means that calling `Scanner.Text()` does an allocation and a copy on every loop. If you don't need to actually use the string that you're checking there, you could alternatively use `Scanner.Bytes()` and then use [`bytes.Equal()`](https://godoc.org/bytes#Equal) to check for the equality. Probably a bit of a premature optimization in this case, but just something that's good to keep in mind.
If that's your concern, then instead of trying to handle this in Go, you should check and see if your database has a standard for performing an action when there's a duplicate key, for [example in PostgreSQL](https://www.postgresql.org/docs/9.5/static/sql-insert.html), `ON CONFLICT DO [ACTION] ....` where action can be an update of the row in question, or do nothing. [MySQL also has an implementation](https://dev.mysql.com/doc/refman/5.7/en/insert-on-duplicate.html) of this. Your Go code shouldn't need to care about the data that the database takes care of; that's what databases are good for. Your Go code should just say "I need this data in the database" and then your database can take care of duplicates and conflicts. Unless, of course, you need to give the user immediate feedback about the data they're trying to input, but since you're trying to process many rows at once, it doesn't seem like this is the case.
I have to say that I love this project &amp; find it cool but I don't have a practical use case yet :'(
I'm using aws. I need alb or elb, the nlb won't work for internal reasons. They require http 1.1. Part of the reason I picked twirp over grpc.
It sure feels like there's a buffer somewhere. I'd bet the output arrives in some nice 2^N size, probably 4kB. The first step I'd do is to narrow down where the buffer(s) is(are): the C program or the Go side. Try using /usr/bin/strace and attach to the C program and see how it calls the write syscall. If you see it writing buffers out then the buffering is in the C program. If you see it writing a line at a time then that isn't the source. Keep in mind that it is common in C code to use a FILE* (what fopen returns) for IO, and a FILE* will buffer by default unless it's connected to a tty-type device. So your C program can act one way when writing to a terminal (which is tty) and another when writing to a pipe or redirected to a file. Once you find the buffer, remove or disable it, and lather, rinse, repeat.
Oh, and if you can't change the C program and the buffer is isatty() dependent then you're in for the additional pain of constructing a pseudo-tty and setting the slave side as the stdout of the C program, and driving it from master side. At least you (hopefully) won't have to emulate a terminal's escape sequences.
The playground doesn't like to run it, but it can share it: https://play.golang.org/p/48Y2Pz8XKwi Just run as: * ./gc "map[string]string" * ./gc "map[int]int" * ./gc "map[int]string" * ./gc --capacity=30000000 "map[string]int" * ./gc "[]int" * ./gc "[]string" 
Looks like it is doing a bunch of write(1) calls. Looks a little weird though, most of them are of the form write(1, "Standard output"..., and the rest of the text output is outside quotes) = int Not sure if that formatting is messed up from strace, or a bug. 
ü§ù
I have been frustrated before at the expense of it, but after thinking about how they really are verifying that you are a company you say you are, it probably can't be cheap or free. In the case of letsencrypt, the main objective is encryption / proving that you're talking to the same server you asked to talk to. Software is a bit different, more comparable to extended validation.
I didn't see this warning in Syncthing last time I used it on Windows7
It shouldn't matter. The compilation speed depends on packages being compiled and cached or not. Use go test -i for coverage runs on Go 1.9 or less and this should speed up the compilation step. And, as I said, try moving the C dependencies into their own package which stays unmodified for as long as possible and your tests should compile in no time. 
Yeah they redid how Config/sess works, I've never used the thing and had no problem putting together a basic bin to make some queries on assets
Not a go problem. Your C program is not flushing stdout. You need to call fflush in C, or run it using `stdbuf -oL`.
You didn't demonstrate that understanding in your previous post. You did demonstrate that you cared enough to respond. This "snotty teenager" act you're giving us here.... doesn't look good for you.
The "snotty teenager" is the only response I feel is appropriate for your non-stop bombardment of /r/iamverysmart-isms. I understand what you wrote, I don't agree with you, but you've made it very clear that you're convinced you have everything figured out in life, so it's not worth taking the time to reply. Please, go on being miserable, don't let me hold you up.
Are there free cert providers, or is it just Verisign basically?
Definitely not premature. This is a good example of a simple, obvious optimization.
Because syncthing bought the certificate and signs the binary.
I'm glad someone is admitting this shit is hard to use. I've never managed to get much value from the go trace tools, they've been broken from 1.5 to 1.7 and now they just have dreadful discoverability.
&gt; The "snotty teenager" is the only response I feel is appropriate Once again, I implore you to read the sidebar, seems you're trying to run quite the opposite direction: * Treat everyone with respect and kindness. * Be thoughtful in how you communicate. * Don‚Äôt be destructive or inflammatory.
[removed]
First of all, thanks a ton for the reply! Tons of useful info! What exactly do you mean by splitting it into a library and command package? Which parts of my code would go into those packages respectively? I did not know about defers but after looking them up that definitely seems like the way to do it. Flags are an option but my plans were to just launch an .exe by double clicking, not using the command line at all, so flags wouldn't be correct choice right? I will look into statik and go-bindata. If I can get it to work I think that is a great solution. I don't exactly know how I would recover the app if the user gave an invalid address, my thoughts were to shut down the app, fix the invalid address, and relaunch. Thanks again for the help. I just started learning go and have only spent a few hours with it, but I think it is really great!
strace elides strings longer than 32 bytes. Use the -s flag to override this by setting it to a much larger value. The 131, however, is the length of the write and the return value. 131 would be a strange amount to buffer. Were you running the C program in a terminal, or attaching to the C program started by your Go program?
Changes are still happening, but I still use it. Changes are manageable with dep.
The v2 way of how the cfg is done is like the #1 reason I use it.
Now if only somehow Go could help with the database queries that dominate my performance problems. 
App Engine as well. 
!redditgarlic
!redditgarlic
!redditgarlic
!redditgarlic
[**Here's your Reddit Garlic, cep221!**](https://i.imgur.com/B7tVoVt.jpg "Reddit Garlic") /u/cep221 has received garlic 1 time. (given by /u/pythonETH) ^I'm ^^a ^^^bot ^^^^for ^^^^questions ^^^^^contact ^^^^^/u/flying_wotsit
[**Here's your Reddit Garlic, eltontay11!**](https://i.redd.it/0cy3nmwrucwz.jpg "Reddit Garlic") /u/eltontay11 has received garlic 1 time. (given by /u/pythonETH) ^I'm ^^a ^^^bot ^^^^for ^^^^questions ^^^^^contact ^^^^^/u/flying_wotsit
re: library and package see this post by Dave; https://dave.cheney.net/2014/12/01/five-suggestions-for-setting-up-a-go-project re: flags; I would probably create a config file so users wouldn't need to recompile the app when changing the address. If it's personal use only and you don't plan to distribute it to others then I'd leave it as is. re: statik; if you're not targeting general distribution it's fine without but it's generally good practise to not use hardcoded paths that are username/os specific. re: recovery; in that scenario you could do a couple of things; 1 tell the user they've entered an invalid address and prompt them to enter a new one. 2. tell the user they've entered an invalid address as you've suggested. For both you would only do that for the first request prior to entering the loop. If it fails exit/prompt. If it fails inside the loop you could add a counter that is reset with every success and increments for each failure. After a certain threshold you could either exit or exponentially back off/jitter trying less frequently with each failure thereby allowing the upstream system some breathing room to recover. https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/ Cheers!
I have one suggestion I can make. In Go, it‚Äôs common to order code from higher level functions first to lower level helpers second. That way, when reading code, you first encounter higher level, easier to understand code that helps provide context for the helpers. Then, once you're familiar with how a helper is being used and why it‚Äôs needed, reading its code is easier. So, I‚Äôd suggest putting main on top, and the two helpers, not the order they‚Äôre used, below.
I really appreciate all the help it man
ah okay. I am used to having main at the bottom of the file, just habits! Thanks for the info.
!redditgarlic
!redditgarlic
!redditgarlic
&gt; In Go, it‚Äôs common to order code from higher level functions first to lower level helpers second. Is this really the case? Are there any good examples from the standard library or maybe a code review guide on this subject?
It's using a lot of JS though https://i.imgur.com/NZXPgYi.png
Just a little bit offtopic, what is the advantage of using xgo instead of the official way of cross compiling? i.e. GOOG=windows go build ?
We have self-hosted Gitlab at work, if you add an alias to ~/.gitconfig... [url "git@gitlab.yourdomain.com:"] insteadOf = https://gitlab.yourdomain.com/
I believe that it's possible to compile with the right steps to get the same speedy result, but I tried quite a bit and in the end couldn't get it much faster. All I'm trying to say is that it's really nice that Go1.10 does it correctly without any trial and error from me and that it improves the CI timings a lot for me. PS. I'm using https://github.com/haya14busa/goverage to run the tests in the end to get correct coverage for the whole project, so maybe that has some impact as well. 
I think part of the issue is documentation. It took me a while to find out what all of the things meant in the pprof CPU profile web view, but once you know it is super helpful.
Golang have user space scheduler and performance aware GC. 
It builds for all platforms in parallel. 
Compared to what?
Oh sorry I didn‚Äôt realize this was an article link. I‚Äôm new to Reddit.
Really sweet. Of course for some reason it won't run on my Mac El Capitan. It complains my OpenGL version is 4.1 and it wants 4.3. Curse you Apple! Does it really need 4.3? 
Comparing channels with mutex is't fair because channels are essentially queues - you use them when you need to know, that one of the readers will handle the state you sent with value at some point. Mutexes, on the other hand, are useful when you care only about the last state or for mutual execution exclusion. You can emulate mutexes with channels, but it will be quite ineffective. You can implement channels with mutexes, slices and condition variables, but it's not as simple as it sounds.
&gt; Error 522 Not fast enough apparently. :)
At least for the compute shader, it is in the OpenGL core since 4.3... (https://www.khronos.org/opengl/wiki/Compute_Shader) But the good news is: Tessellation is in core since 4.0 and as far as I can see, I am not using any other 4.3 relevant features. The compute shader is a bonus now, currently not relevant to the application. So, if you need some help porting to 4.1, let me know, I'll try to help :)
I ran the channel one against [Loggregator's](https://github.com/cloudfoundry/loggregator) [Diode](https://github.com/cloudfoundry/go-diodes) to see how they compare: go test -bench=. goos: darwin goarch: amd64 pkg: test/diodes BenchmarkDiodes-8 20000000 55.4 ns/op 17 B/op 2 allocs/op BenchmarkChannelOneByte-8 20000000 72.0 ns/op 13.89 MB/s 0 B/op 0 allocs/op PASS ok test/diodes 2.714s Looks like Diodes are a little faster.
Go has Plan 9.
The mutex example also doesn't move memory around...
Don't worry about it; redditors don't read the articles before commenting either.
Can you post the code?
 func BenchmarkDiodes(b *testing.B) { d := diodes.NewOneToOne(4096, nil) wg := sync.WaitGroup{} wg.Add(1) defer wg.Wait() done := int64(0) defer atomic.AddInt64(&amp;done, 1) go func() { defer wg.Done() for { _, ok := d.TryNext() if !ok { if atomic.LoadInt64(&amp;done) != 0 { return } time.Sleep(time.Millisecond) continue } } }() b.ReportAllocs() for i := 0; i &lt; b.N; i++ { bb := byte(i) d.Set(diodes.GenericDataType(&amp;bb)) } } 
But your ^account ^is 9 years old ^with like a ^hundred comments...
It‚Äôs safe in that nothing will break, but it‚Äôs pointless, because nothing can import package main and make use of those exported identifiers; and nonidiomatic for that reason. Best not to do it. 
These numbers match what I‚Äôve seen. As a ballpark rule of thumb, you can remember that a normal op takes about 1ns, a mutex takes about 25ns, and a channel takes about 100ns.
In my case I'm using it to cross-compile something that uses a lot of CGO libraries (e.g. [go-sqlite3](https://github.com/mattn/go-sqlite3)). Since I'm using linux as a host, building a OS X app that uses `go-sqlite3` requires me to get an Apple Developer account, get the right version of Xtools, and then build the OS X SDK to build the sqlite3-compatible o64-clang compiler with `osxcross`. Windows is a similar headache. `xgo` is really cool in this respect because it leverages a docker container which already has all these compilers bulit-in and uses them automatically.
Also, golint will complain, if they are not documented (AFAIK), even if they're not importable.
Alb supports http2
So now the question is, which tool is Vscode using that generates the green underlines?
Had a similar experience while implementing a pubsub server.
You might want to extract most of what's in your `package main` into its own separate library package later on, leaving only `func main()` in there. Using uppercase while developing the code makes that easier. Alternatively, you could change the name of `package main` to something else, and change the main function to `func init()`. 
For next release I will try to also pass sound somehow. I can capture audio from camera/system microphone with https://github.com/gen2brain/malgo library, just not sure yet how to send that to html handler, maybe in chunks or something like that.
Your code might be easier to review if you can upload to a github repo ? Also, adding unit tests are always an added bonus. :)
Only incommming, not on the backend servers.
Because all of your CPUs get stuck on executing the infinite loop in those goroutines you spawned. Go's goroutine scheduler is very efficient, but can be fooled. It only switches between goroutines on special events or occasions, and an infinite loop can, clearly, make it never switch.
Your loop never yields to the scheduler.
They just added Go support to SAM Local this pst week. https://github.com/awslabs/aws-sam-local/releases/tag/v0.2.6
Makes sense to use that if you're using SAM as a scaffold for your app. The post was born out of curiosity really, and hopefully helps people understand what might be happening under the hood, but any officially supported solution is probably better. 
Not really. From [the spec](https://golang.org/ref/spec#Package_initialization) &gt; The declaration order of variables declared in multiple files is determined by &gt; the order in which the files are presented to the compiler: Variables declared &gt; in the first file are declared before any of the variables declared in the &gt; second file, and so on. In general, you should consider the order in which files are presented to the compiler to be unspecified. There are, theoretically, ways to do that, but you really shouldn't, because you will rely on users or developers of your package to do special tricks, instead of just having a regular old `go test` work as expected. Might I ask what problem you are trying to solve? In general, you should try as hard as you can to isolate your test-cases from each other and in that case it shouldn't matter which order they are executed in.
I'm trying to break down a big test file into multiple organised test files.. but some tests depend on others. And some must be tested before others
But why? Like, why would the tests not be isolated? It's bad form for one test to depend on state from another test. You are likely fitting square peg of a testing pattern from another language into the round hole of Go testing. If failure of one test implies failure of another, it's fine to run both and have both fail - in fact, that gives far more information. If you need to check that a sequence of action gives the intended result, then put them in one test function; it is one test. I would even go so far as to argue that your tests should, as far as possible, start with a call to `t.Parallel`, so you don't even get into these bad habits in the first place‚Ä¶ In any case, you can use [subtests](https://godoc.org/testing#hdr-Subtests_and_Sub_benchmarks) to induce an order on tests, if need be. I.e. don't export the test functions and call them manually via `t.Run` from a master-test. But, again, it's bad form.
I believe that if you are creating a c-archive or c-shared library from a Go main package that all exported symbols must not just have the //export directive but also be exposed by Go's naming rules.
&gt; but some tests depend on others That's generally considered a poor design to be honest (regardless of language). That means you can't run individual tests by themselves which means you must run the whole test suite or build that knowledge into the testing framework which means you can introduce bugs. This also makes it harder to write new tests. I don't know what you're working on but I'd highly suggest creating structs or functions that encapsulate enough of the setup that you can run a test by itself. Even if it makes the tests slower or requires some copy/pasting in a couple of cases it's better than having the inter-dependency IMHO.
hmm.. I see.. then I should rethink and restructure the whole tests and reuse what i can.. Thanks for taking the time to answer :3
Yeah that's what I would do and thank for taking the time to listen. I know it probably seems counter-intuitive but I've always considered writing tests to be fundamentally different than normal coding in that I try to forget what the internals do and write tests from the perspective of a user of my code. I also try and write test cases so they only test one thing that way when something breaks there's specific test cases to look at instead of wading through a test case with dozens of checks. Here's some example code: package main const DefaultValue = 42 type Config struct { setup bool Default int } func (c *Config) GetDefault() int { if !c.setup { panic("not setup") } if c.Default != 0 { return c.Default } return DefaultValue } I'd write two test cases: func TestConfig_GetDefaultNotSet(t *testing.T) { cfg := &amp;Config{} if cfg.GetDefault() != DefaultValue { t.Fatal() } } func TestConfig_GetDefault(t *testing.T) { cfg := &amp;Config{Default: 2} if cfg.GetDefault() != 2 { t.Fatal() } } Note however the above will panic because I didn't set `*Config.setup` to `true` anywhere. From a user's perspective, that's exactly what would happen because `setup` is private and cannot be modified outside of my package. So, because I'm not testing from my own perspective I realize I need to write a function and call that instead in a test: func NewConfig() *Config { return &amp;Config{setup: true} } func TestConfig_GetDefaultNotSet(t *testing.T) { cfg := NewConfig() if cfg.GetDefault() != DefaultValue { t.Fatal() } } On a somewhat related note, gocheck is a really nice library to improve on testing flow you might consider looking at: https://labix.org/gocheck 
I don't know much about the Slack Channel, but I haven't really seen StackExchange used as a place to request code reviews. I've seen people ask for code reviews here on the /r/golang subreddit, so this seems like a good place. I reviewed your code, (and [refactored it here](https://gist.github.com/anonymous/1d4e67db9b91394b7e04498cb74e48ca))my thoughts: * The main should have as little logic as possible, mostly just set up and clean up. I moved all of the quiz functionality into a separate quiz package. The main just handles flags, loading files, and checking the results of the quiz. * Dependencies should be made explicit whenever possible. I added a `FromCSV` function that takes an `io.Reader`, so that it's clear we're loading a CSV, and it can come from a file, or the body of an HTTP response, and the `quiz` package doesn't need to know. I also added `Input` and `Output` fields to the `Quiz`, so that you could write to places other than a terminal if you wanted to. This way, if you wanted to test it, you could make the input with `strings.NewReader` and the output could be stored in a `bytes.Buffer`
&gt; Where can I find code reviews for GoLang code? Beyond the ones you tried, you can also try to ask for code reviews at: * [golang-nuts](https://groups.google.com/forum/#!forum/golang-nuts) * [Gobridge forum](https://forum.golangbridge.org) According to the requirements: &gt; 1. Read a csv file, each line consisting of a question and an answer: 2. Print the question to the user 3. Validate if the supplied answer is correct. 4. Print the correct answers. It doesn't seem like you are asked to handle levels of verbosity. Sometimes it is better to follow the requirements strictly so that you have to write less code. The verbosity feature complicates the code a tiny bit: &gt; if q.ask() { if verbose { // extra if fmt.Println("Correct") } correct++ } else if verbose { // extra else if fmt.Println("Incorrect") } This is okay for such a small program but on a complex application, you might end up making your life harder by adding features you have not been asked to. To address some of your questions: &gt; * Best Practices &gt; * How to use more advanced functionality to solve it (ie. go routines or interfaces) You shouldn't be concerned so much about using goroutines everywhere. As the Go proverb says, [Clear is better than clever](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=14m35s). You should be thinking about writing simple, clear code and in this case you've already done that. Sometimes there's no reason to add additional complexity. Nevertheless using interfaces can make your code more general and testable which is useful even on small programs. &gt; * Refactoring * Overall design * Adding unit tests to it. What can be tested? I have purposely kept these together because writing tests, can lead to refactoring which sometimes improves the overall design. Let's look at the current code and try to write some tests. First let's look at: type q struct { question, answer string } func (q q) ask() bool { fmt.Println(q.question, " equals: ") scanner := bufio.NewScanner(os.Stdin) scanner.Scan() if scanner.Err() != nil { log.Fatal(scanner.Err()) } if scanner.Text() == q.answer { return true } return false } The method `ask` is not easily testable because it depends on `os.Stdin`. Moreover functionality such as scanning, is not a very good fit for a method. It is usually recommended to keep structs lean and not attach much logic to them if any. Also it seems like the scanning functionality could be done by `quizLoop` directly and reduce the coupling. func quizLoop(path string, verbose bool) { // Loop should: // 1. Read records line by line // 2. Ask the question (i/o) // 3. Keep score. file, err := os.Open(path) correct, lines := 0, 0 if err != nil { log.Fatal(err) } defer file.Close() reader := csv.NewReader(file) for { record, err := reader.Read() if err != nil { if err == io.EOF { break } log.Fatal(err) } q := q{question: record[0], answer: record[1]} if q.ask() { if verbose { fmt.Println("Correct") } correct++ } else if verbose { fmt.Println("Incorrect") } lines++ } fmt.Printf("You had %d/%d correct answers!\n", correct, lines) } The function `quizLoop` is not easily testable because it depends on opening a file, which needs to have a specific format. It also seems like it tries to do too many things (opens a file, reads questions, plays the quiz). In order to be able to write good tests we will remove some responsibility from this function and let it just play the quiz. Thus we need a new function that reads using the required format and returns a slice of questions. Let's call it `importQuizCSV` to signify that it depends on the CSV format. func importQuizCSV(r io.Reader) ([]q, error) { var quiz = make([]q, 0) csvr := csv.NewReader(r) for { record, err := csvr.Read() if err != nil { if err == io.EOF { break } return nil, err } qq := q{question: record[0], answer: record[1]} quiz = append(quiz, qq) } return quiz, nil } Notice that the function does not open a file. Writing tests for functions that open files is problematic. A better practice is to abstract away the source of reading by using the common `io.Reader` interface. The input can be a simple in memory string instead of a file which is ideal for testing. Here's an example of a [table driven test](https://github.com/golang/go/wiki/TableDrivenTests) for `importQuizCSV`: // in main_test.go func Test_importQuizCSV(t *testing.T) { tests := []struct { input string quiz []q }{ { "", []q{}, }, { "2+2,4", []q{ {question: "2+2", answer: "4"}, }, }, { "2+2,4\n1+2,3", []q{ {question: "2+2", answer: "4"}, {question: "1+2", answer: "3"}, }, }, } for _, tt := range tests { r := strings.NewReader(tt.input) quiz, err := importQuizCSV(r) if err != nil { t.Errorf("importQuizCSV(%q) returned error: %v", tt.input, err) } if got, want := quiz, tt.quiz; !reflect.DeepEqual(got, want) { t.Errorf("importQuizCSV(%q) = %v, want %v", tt.input, got, want) } } } So now all that remains for `quizLoop` is to play the quiz. That means that in needs to receive the quiz (slice of questions), print each question, scan the answer, compare and keep track of the correct answers. If we scan the answers from `os.Stdin` we will have the same problem which makes testing difficult. Instead we can use the same technique and read from an `io.Reader`. We can extend this technique and instead of printing the answers to `os.Stdout` we can write them to an `io.Writer`. Let's rename the function to `playQuiz`. // playQuiz will: // // 1. Write questions to w // // 2. Read answers from r // // 3. Write score to w at the end of the quiz func playQuiz(w io.Writer, r io.Reader, quiz []q) error { correct := 0 for _, q := range quiz { fmt.Printf("%s equals? ", q.question) scanner := bufio.NewScanner(r) scanner.Scan() if scanner.Err() != nil { return fmt.Errorf("scanning: %v", scanner.Err()) } input := scanner.Text() if input != q.answer { fmt.Fprintln(w, "&gt; Incorrect") continue } fmt.Fprintln(w, "&gt; Correct!") correct++ } fmt.Fprintf(w, "You had %d/%d correct answers!\n", correct, len(quiz)) return nil } A noteworthy detail is that it is common in Go to [omit unnecessary elses](https://golang.org/doc/effective_go.html#if) and [align the "happy path" to the left](https://medium.com/@matryer/line-of-sight-in-code-186dd7cdea88). Of course in this case it could be argued that using an else, like in the original function, improves readability but I wanted to showcase the idiom. Using the power of `io.Reader` and `io.Writer` now it is very easy to test the function: // in main_test.go func Test_startQuiz(t *testing.T) { quiz := []q{ {question: "2+2", answer: "4"}, {question: "1+2", answer: "3"}, } input := "4\n2" output := "&gt; Correct!\n&gt; Incorrect\nYou had 1/2 correct answers!\n" r := strings.NewReader(input) var buf bytes.Buffer err := playQuiz(&amp;buf, r, quiz) if err != nil { t.Errorf("play quiz %v with input %q returned error: %v", quiz, input, err) } if got, want := buf.String(), output; got != want { t.Errorf("play quiz %v with input %q\nhave: %q\nwant: %q", quiz, input, got, want) } } So now all we need is someone to open the file, call `importQuizCSV` and `playQuiz`. And of course there is no better candidate for that than `main`. Nevertheless, it is a good practice to use a function like `run() error` so that we can easily return errors with context and allow the caller to do centralized logging of the errors. As an added bonus, if we later want to move the function `run` to another package, the procedure becomes trivial. func main() { if err := run(); err != nil { fmt.Fprintln(os.Stderr, "Error:", err) os.Exit(1) } } func run() error { var ( csvFile = flag.String("csv", "problems.csv", "Specify the path to the quiz questions.") ) flag.Parse() file, err := os.Open(*csvFile) if err != nil { return fmt.Errorf("opening CSV: %v", err) } defer file.Close() quiz, err := importQuizCSV(file) if err != nil { return fmt.Errorf("importing quiz: %v", err) } return playQuiz(os.Stdout, os.Stdin, quiz) } In conclusion, thinking about testing, lead to refactoring which made the functions more flexible and testable. The responsibility of each function has been reduced and so did the coupling. For example it would be trivial to move these functions into a new package `quiz`, improve the naming (e.g. `quiz.Play`) and share the code if that is desirable. Last but not least, the quiz game is no longer concerned about its actual input and output. It could be reading and writing to a network connection for all it knows! Playground links of the full code: * [main.go](https://play.golang.org/p/OpSpkdWptQk) * [main_test.go](https://play.golang.org/p/4QN5wamCbjW) * [problems.csv](https://play.golang.org/p/eikk5oe7DEZ)
As with any microbenchmark, it's all in the fine details. Not saying your benchmark is wrong per-se (although I don't agree with it). Here are a few things that can be tweaked to improve go's channel throughput. * the channel buffer size forces a goroutine context switch at every 4096 entries. to avoid measuring that goroutine switch we can make the channel with room for b.N elements. then context switches will be guided by the runtime * benchmark is measuring more than two goroutines: one is the benchmark, at least one more handles the unnecessary WorkGroup synchronization. the producer, can just close the channel once it's done. that requires that you switch between producer and consumer and have the consumer be the benchmark gorotine * to measure _pure_ channel throughput goroutine switches can be eliminated entirely, having send and receives happen in the same function * to avoid cross-cpu synchronization one can measure with GOMAXPROCS=1 which will avoid a lot of unnecessary locking (or, rather, make it very fast) Code for modified benchmarks is here: https://play.golang.org/p/CpG1g69KpTr Here are the results with the benchmarks modified thusly, on my macbook pro 2015: $ go test -test.bench=. goos: darwin goarch: amd64 BenchmarkChannelOneByte-4 20000000 74.5 ns/op 13.42 MB/s 0 B/op 0 allocs/op BenchmarkChannelOneByteSizeN-4 20000000 71.9 ns/op 13.91 MB/s 0 B/op 0 allocs/op BenchmarkChannelOneByteSizeNNoWorkGroup-4 20000000 71.4 ns/op 14.00 MB/s 0 B/op 0 allocs/op BenchmarkChannelOneByteSizeNNoWorkGroupNoGoroutine-4 30000000 55.0 ns/op 18.17 MB/s 0 B/op 0 allocs/op PASS ok _/tmp 6.326s $ GOMAXPROCS=1 go test -test.bench=. goos: darwin goarch: amd64 BenchmarkChannelOneByte 20000000 59.8 ns/op 16.73 MB/s 0 B/op 0 allocs/op BenchmarkChannelOneByteSizeN 20000000 58.6 ns/op 17.07 MB/s 0 B/op 0 allocs/op BenchmarkChannelOneByteSizeNNoWorkGroup 20000000 58.9 ns/op 16.97 MB/s 0 B/op 0 allocs/op BenchmarkChannelOneByteSizeNNoWorkGroupNoGoroutine 30000000 53.9 ns/op 18.55 MB/s 0 B/op 0 allocs/op PASS ok _/tmp 5.453s
The real issue with reflect is not in these sorts of channel operations which are already expensive, but rather struct and map operations that change from a few processor instructions into an expensive function call.
For your every day use-case. Reflect won't cause much issue. When you get into performance critical low-level code, it's a big problem
Why are using a pointer to your mutex?
If you really wish to do it, there is a way: https://golang.org/pkg/testing/#hdr-Main But as others have pointed out you should try to write tests that can run in isolation.
FastHTTP is slower than stdlib for real world use-cases. We've benchmarked and profiled this quite extensively at work. Any time your request takes longer than a simple instant response (e.g. disk access, mutex contention, etc), your performance goes to shit
First off, thanks a lot for taking so much time to write this up for me! I'll have to properly go through this review. As mentioned in my question on CodeReview I've got really limited experience with GoLang, and some of the things that you are mentioning are things that I've never heard of, or used during the book that I read through (An into to programming in Go). That being said, the things that you are mentioning are absolutely amazing! I can't believe the time you must have spent on writing this up. For instance I love how you work with buffers to make the logic more extendable, something I had no clue you could do! Obviously (as you mention) it makes it a lot easier to test the underlying code. Having got experience with more object oriented programming, this is a rather well-known pattern to me. I just had no clue how I could do it in i GoLang. I suppose I need to go back to the documentation and just go through each package at a time. :) I also think you are right about the added complexity of adding verbosity to the code. But it's just something I make an effort to do when I program in Python, so that I have a way of debugging the code. :)
FWIW moreutils has been around a long time now with "ts" as the name. https://joeyh.name/code/moreutils/
[removed]
Since this was just a thought exercise, ill share how I performed [unsafe channel sends](https://gist.github.com/cstockton/2c7e9346af7b7daad11bf9a754a3716e#file-chansendn-go-L7) so I could test the potential value of a bulk chan send function before I wrote an [SSA pass](https://gist.github.com/cstockton/5f2fea4ace0f099b4908a115409f2da3). Maybe you could benchmark it too for fun if you wanted, iirc they are about the same speed.
I've found that [SOLID Go Design](https://dave.cheney.net/2016/08/20/solid-go-design) helps a lot with getting that "aha" moment when thinking about interfaces in Go. I wanted to mention it before but I ran out of words. :) There's also "the bible": [Effective Go](https://golang.org/doc/effective_go.html) And if you want something concise: [CodeReviewComments](https://github.com/golang/go/wiki/CodeReviewComments)
&gt; some tests depend on others If you need to establish some state before running a test, consider writing a fixture, and include a test whose sole purpose is to ensure the fixture is correct. The simplest of fixtures can be built on `testing.Main`: https://golang.org/pkg/testing/#hdr-Main 
I believe that it's from Clean Code by "Uncle" Bob Martin.
The only reason I'm suggesting `ReadAll` is that it's less code you have to write. Since this is for a quiz program, I'm not expecting the CSV to contain thousands or tens of thousands of rows, which might be the scale at which it's worth it to stream the records from the reader instead of loading them all at once. If you think the quiz files will be megabytes in size, definitely use `Read` and stream records individually. As for using goroutines and interfaces, they aren't really necessary for a project like this. There aren't a lot of opportunities for concurrency, unless you needed to do some heavyweight (file or network I/O) operations for each row in the CSV to process it, so you don't really need goroutines. If the `quiz` package were part of a larger system, you might want to create a `Quizzer` or an `Asker` interface, depending on the requirements. For this program though, we don't need that extra layer of abstraction. Things I would unit test: * `FromCSV` - Use `strings.NewReader` to create a reader with an in-memory CSV file, confirm that processing occurs as expected and the `Quiz` contains the right number of questions * `Run` - Make sure the output and results are correct. I wrote [some quick tests here](https://gist.github.com/anonymous/a3b6cdc71fcc0b78882005960de6b42d), but I had to change the way scanning works to get it to work correctly in the test, so these tests will fail with the above code.
Why do you defer in that for loop? Isn't it equal to just printing on each iteration without the defer? Or does defer print only on the last iteration of the loop
Very useful links. Thanks!!
[removed]
https://play.golang.org/p/P-dToED2Pv5 Defer makes it so that the function call is not executed until the surrounding function returns. Once the loop finish, it will start unstacking these calls.
My recommendations would be: 1. On line 23 of main.go, if you are not going to check the error then just assign it to _ instead of err. Not a big deal but IMO this is a little cleaner. 2. Check the response code of the http request for getting balance, and handle errors accordingly. You may not necessarily want to always exit the program if an http request fails. 3. You might want to retrieve the relative path for the icon rather than absolute, that way it works on any computer and not only yours. It also would be good practice to store the hard coded strings as constants declared at the top of the file. That's just a stylistic issue though. 4. "difference" doesn't need to be declared on line 45 of main.go Other than that it looks pretty good. Nice job!
Welcome to Go :) Please check out the sidebar for more info. You might want to start with https://tour.golang.org/ to get a quick taste of the features.
Off the top of my head there's Weave Works, Ravelin, and Monzo to name a few. For various reasons I think these are the broad stroke reasons why companies might not chose Go; 1. Conservatism (e.g. talent pool, unknown quantity, etc). 2. Legacy (full rewrites are a good way to tank a company). 3. Competition (e.g. Python, Ruby, Node.js, Clojure, Scala, Kotlin, Rust, etc). 4. Investment (e.g. tools, tech, and training). 5. Perception (e.g. it's missing X, I don't need X but I **might** someday). For existing codebases I think most companies would move to Scala/Clojure/Kotlin before Go if their platform is in the Java ecosystem. The labour market is substantially larger and it's viewed as Java++. From an operations/tooling perspective the existing monitoring and tuning is often still applicable. From a tools perspective you don't throw everything out the window. From a legacy perspective interop is stable and understood so you can be selective as to when and where you use it. When dealing with new code bases I think you'll find a lot of companies are taking up Go where it's purely service or command-line based. Fewer are likely to chose Go for web apps where other languages have real/perceived benefits over Go. In general I'd liken it to two restaurants side-by-side. People will use occupancy as a heuristic for quality.
I know nothing about VS Code, but: - It is impossible to listen for `os.Kill` (SIGKILL); SIGKILL isn't ever delivered to the process; it tells the operating system to simply end the process 
I just started a month or so ago and I have already written two new projects and rewrote something I wrote in Python. I would say the best way I learned as by rewriting something I was already familiar with, so I wasn‚Äôt struggling with the problem, just with the language. Good luck, so far I love it. 
check the https://github.com/tidwall/gjson library. 
Yeah, I think it's Kernel only? I should probably clean that bit then.
Requiring "graceful shutdown" may be a potential indication of a design problem elsewhere, maybe you could be performing recovery at startup instead of cleanup at shutdown.
&gt; Or perhaps I could create a struct for my input JSONs and unmarshal them, then pluck different struct fields into the output? This is the right idea, it's simple to understand and introduces no extra complexity. It is very unlikely the standard json library is not efficient enough for your use case; avoid solving problems that do not actually exist. https://play.golang.org/p/WAf8nZc8eR-
I'm just closing off a [websocket and one httpServer](https://i.imgur.com/TqZCqrf.png) when the app is rebooted or is shutdown. This isn't error recovery. I can always make another topic to ask for comments on my code but right now I'm interesting in getting the vscode debugger to behave :/
exercism has a bunch of exercises for go.
Oh man I really appreciate your enthusiasm in helping me to run it on my Mac. Apple is notoriously bad at supporting OpenGL. Don't worry too much about it -- I'll just install golang on my windows box and take your code for a spin. I'm more interested in teaching myself shader programming, which is why your project appeals to me. If I learn shader programming makes sense to just learn the latest versions. No worries! If I manage to like your codebase enough that i absolutely want to work on it on my mac (my preferred dev env is my mac), I'll take a stab at porting it. Thanks a lot for the support! 
Yes, try to stick to the newer OpenGL versions, if you get into shader programming. But anything higher than 3.3 is fine (no changes really for GLSL - OpenGL shader language). The codebase is probably not the very best (I use Go only on private projects, so I might be missing some Go conventions...). But let me know, porting it should not be a big deal. And if I am missing any Go conventions, feel free to point that out to me, I'd like to improve on that!
There are cases where you want to export identifiers, like types, if you have a simple app that reads a json and does things to it. Also for methods on types in order to satisfy interfaces. Functions alone probably not necessary, unless you want to document them in godoc.
No, Gosched is not needed. All you need is a function call, which is in this case should come naturally given that the variable is shared across goroutines thus unsafe to use without a mutex as it will lead to data races. Fixing the code rather than the symptoms will correctly solve this problem. 
&gt; unsafe channel sends Could you elaborate? What's the strategy here?
Might be worthwhile to add some kind kind of ws authentication (even just a token configured in cli options), so people can't just connect to the `/socket` endpoint and read frames. The `websocket` package will verify the Origin header by default, but that's easy enough to spoof. You'd have to switch to using a full `websocket.Server` instead of `websocket.Handler` and do something like send the token from the js side on connect and then read it from the Go side and verify it matches.
This list is pretty good: https://www.calhoun.io/beginners/. It covers everything from first steps, to semi advanced scenarios. 
The book "The Go Programming Language" is really neat. Lots of good examples in there. I've used it as a reference while learning.
&gt; The real answer is that you basically never need the same container to hold two different, completely incompatible types (like strings and ints). Yeah, reusable stacks, queues, binary heaps, linked lists are for pussies!
Define error types. Have an error for `RecordNotFound`, have another error for other errors. Check the error type in the response of `enterprises.FindByApiKey` and return 500 or whatever you want to return. Another major point - **Always, always** check for returned errors. Never do things like - jsonData, _ := json.Marshal(resp) jsonData, _ := json.Marshal(ErrorResponse{...}) Enjoy Go :)
Thank you! I know Gorm has a built in RecordNotFound error. Perhaps I just need to Google how to check the type. I was using [http://jinzhu.me/gorm/advanced.html#error\-handling](http://jinzhu.me/gorm/advanced.html#error-handling) as a reference for this implementation! Again thanks for your feedback and I will fix that JSON marshalling error handling 
Looks good, but I think you may want to handle your database connection errors in a different manner, and consider distinguishing between database-query errors and API keys not found: Instead of using `log.Fatal` in `FindByApiKey`, you should just return the error as you do elsewhere. Otherwise an intermittent connection error will kill the entire process (which I think is undesirable, but not sure whether AWS lambda is a single-invocation per message). Note, however, that if you remove the `log.Fatal` you will uncover a panic in `defer db.Close()` when `db` is nil. This would further cause issues in `HandleLambdaEvent` because you don't distinguish between a "API key not found" and "something else went wrong" (e.g. gorm table didn't exist). In `FindByApiKey` you should check if gorm is returning a [`ErrRecordNotFound`](https://github.com/jinzhu/gorm/blob/0a51f6cdc55d1650d9ed3b4c13026cfa9133b01e/errors.go#L10) (I think) and then return some package-level `var ErrAPIKeyNotFound = errors.New("api key not found")` which `HandleLambdaEvent` can check for explicitly: ``` if err == ErrAPIKeyNotFound { // 401 Unauthorized } else if err != nil { // 500 Internal Server Error } ``` Your call to`ec.NewEnterpriseCustomer`assumes no errors, which you should probably also add. Hope that's helpful üëç How are you finding AWS Lamba/Go to work with?
`database/sql` returns [`ErrNoRows`](https://golang.org/pkg/database/sql/#pkg-variables) when there are no results. I haven't used GORM before but it seems that it returns `ErrRecordNotFound` for this case. So what you can do is check for this error and return it. Then on your handler you can check again for that error and return 500 if it is something else. Here's an example: err := db.Where... switch err { case gorm.ErrRecordNotFound: return gorm.ErrRecordNotFound // or return your own custom error case nil: default: return err } enterprise, err := enterprises.FindByApiKey... switch err { case gorm.ErrRecordNotFound: // return 404 case nil: default: // return 500 } You could also define a new custom error, specific to your application and "translate" `ErrRecordNotFound` to your new error in order to avoid having database specific imports to your handlers. I highly recommend [this article](http://www.alexedwards.net/blog/organising-database-access) for a better way to organize your database code.
Perhaps reading through this - https://blog.golang.org/error-handling-and-go might help.
Yes it's needed if you don't add something, OP asked why I gave the answer.
Thank you for your thorough response I will make the changes as you suggested. I actually really enjoy using Lambda with Go thusfar. The cold start times are relatively instant and my functions for generating jpeg images are performing at around 80ms using only 27 mb of memory... I don't have any well researched performance statistics yet but based on my research I have found that the 1024mb instances are the sweet spot. I will however want to do some more thorough experiments on the performance of various lambda memory settings. I am using Python in our payment lambda service at work and Go handles dependencies much more intuitively. Unlike Python which requires me to pip install \-t everything. The provided API Gateway handlers developed by AWS are excellent as well and seem to be easy to work with. I am using the Servereless framework to build my API Gateway and they make use of Makefiles as part of the deployment process which is really cool. If you more interested in the details you can find it here [https://serverless.com/blog/framework\-example\-golang\-lambda\-support/](https://serverless.com/blog/framework-example-golang-lambda-support/)
I should have known better regarding the log.Fatal thig. It looks like I need to work on making that database connection stay open during the life the of lambda container as well. Thank you!
Just did a quick try on my CI and the test run went from 88s to 24s! Before: https://travis-ci.org/getfider/fider/builds/333917231#L663 After: https://travis-ci.org/getfider/fider/builds/334382095#L671 
Is that Groo?
5-6k? Why are you trying to hire junior developers? Try 5k per week.
Array's size are static while a slice's size can be dynamic
There is no need to export a type name to deserialize JSON into it; only the fields need to be exported. Similarly, an unexported type can satisfy any interface.
Slices are more flexible: you don't need to know the size upfront nor manually manage the resizing of the backing array. 
Yes true. but how is it better than Reference?
C++ has the concept of dynamic array decades ago. What matters?
https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
On phone so code was too hard to digest, But for maintaining a db connection, the following might help with a basic implementation. If db connection is nil, Create new connection If db ping fails Create new connection If final ping fails. Error out. Ping is pretty useful to make sure a connection is still valid. It's possible a long hanging connection fails or times out between requests. So just recreating it than doing another check seems to cover all problems for me currently. 
To explain: in Go, everything is pass-by-value. So, when you pass an array to a function, it copies the whole thing. When you pass a slice, it copies the slice *but not its backing array*. The slice is a pointer to the array plus length and capacity, so only those three words are copied when you pass a slice. You could also just pass a pointer to an array, which is only one word (no length or capacity), but the downside is array length has to be known at compile time. That‚Äôs how it gets away with not storing its length. 99% of the time in Go, you only use slices and you can ignore arrays. 
Yes, slices are dynamic arrays, case closed. No, it is not any more exciting than that, but no one ever claimed, so that seems fine.
Yes, Groo finally on the throne :)
Is simple Basic auth for websocket enough? Program already supports -htpasswd-file so I can use same username/password for the client I guess.
Lets say that the last time the GC ran, there was 100 MB of data remaining *after* the GC finished. The Go GC remembers this number. The Go GC will then run again once 100 MB * (100% + GOGC%) memory is allocated. With GOGC = 100, this is 100 MB * (100% + 100%) = 200 MB. Therefore, the Go GC will run again once 200 MB of data total has been allocated. With GOGC = 50, it would run again at 150 MB. If the previous GC ended with 80 MB of memory remaining, then with GOGC=100 it would GC again when the heap memory used reaches 160 MB.
This isn't solving the same problem at all. A UUID is a 128 bit, universally unique identifier, meaning there's effectively no possibility of a collision. If you want locally unique identifiers, that's a completely different problem and must databases already support it (e.g. incrementing IDs). Looks interesting I suppose, but it doesn't solve the problems I use UUIDs for, and honestly, ID generation is not my bottleneck. I suppose there's a use case for it though.
It's different, instead of forking PHP processes on each request it bootloads multiple processes in memory and communicate with them over std-pipes or sockets. Most of PHP frameworks have massive footprint which has to be loaded on each request, this approach allows you to skip bootloading and gain massive performance boost over singular request. We extracted this library from queue manager which feeds events to PHP code. Thought, it shows very good performance as http server.
Neat. Thanks for the explanation. I wonder if this would be usable or preferable for use in Caddy instead of calling out to php-fpm. Do you think it would/could be?
It should, library specifically designed to work as embeddable PHP server for Golang apps.
Ah yes, I was just noticing that. Guess we could still consider it as a feature. Thanks again.
[removed]
This can't be more clear . Thanks a lot ! 
Correct, but it is faster, smaller and more universal.
It's clear, but also wrong. The go gc is concurrent, and it starts collecting before it hits the threshold, based on current usage rate and some heuristics, to avoid stopping the world when it hits a given target overhead. 
To be fair though, that *used to be* how it worked for older versions of Go.
This was the only project in the wild that I've seen it with: https://github.com/robertkrimen/otto/pull/238 While I did want to use it at first, that initial tendency didn't last long. I was just used to 'include' from php and it really isn't the same thing :)
Does it mean the GC now run continuously in the background using some metrics averaged over time ?
Why?
Wouldn't mind seeing some benchmarks comparing them at some point (e.g. for Laravel and such)
Right, that much I got, but why is this more efficient?
Also, on line 53, it would be more readable like time.Sleep(10 * time.Second) 
FWIW, I think the key insight for slices (as opposed to most vector-types in languages) is, that they make referencing sub-arrays non-copying by default. E.g. if you write python code like a = [1,2,3,4] b = a[:2] a = 23 then `b` will remain `[1,2]`. In Go, however, `a` and `b` share an underlying array and thus the write to `a` will be visible to `b`. That is a caveat and it does lead to bugs, if you don't pay attention - but it makes it simple and idiomatic for packages like [strings](https://godoc.org/strings) or [bytes](https://godoc.org/bytes) to only copy memory, where it's needed. For example, all the `Trim*` functions won't allocate and neither will the `Split` functions or any of the matchers in [regexp](https://godoc.org/regexp). More to the point, [path.Clean](https://godoc.org/path#Clean) will allocate *iff* the path wasn't already clean (and similar for other `path` functions) - which is something that would be harder to build/express without slices and GC. But yes, it's not a dramatic innovation. I would be very surprised, if Go was even the first language to do this. I know that both C++ and Java have similar concepts. No one ever claimed that Go would be hugely innovative, language-wise.
It is more efficient because unsafe.Pointer is essentially free, while the Send method of reflect.Value is not. Anytime you see a reflect.Value there is an immediate cost of 1 allocation due to forcing all Value's to escape to the heap. For Send we require two allocations since it has a param as well the cost of ensuring type safety at runtime. The overhead avoided is the time to Send via reflect minus the time to send via unsafe. You would never do this, but it was relevant to the ops experiment so I shared.
If anyone is following this conversation, I implemented the suggestions made by /u/pkoniarski and /u/zanven42. I opted for the global variable to store my DB connection and added some logic to reuse existing connections during the lifetime of an AWS Lambda function container... ``` package models import ( "fmt" "github.com/jinzhu/gorm" _ "github.com/jinzhu/gorm/dialects/postgres" "os" ) var db *gorm.DB func InitDBConnection() (*gorm.DB, error) { host := os.Getenv("RDS_HOSTNAME") user := os.Getenv("RDS_USERNAME") password := os.Getenv("RDS_PASSWORD") dbName := os.Getenv("RDS_DATABASE") dbArgs := fmt.Sprintf("host=%s user=%s dbname=%s sslmode=disable password=%s", host, user, dbName, password) var err error if db == nil { db, err = gorm.Open("postgres", dbArgs) } if err = db.DB().Ping(); err != nil { db, err = gorm.Open("postgres", dbArgs) } if err != nil { return db, err } return db, nil } ```
[removed]
[removed]
It's a good thing you asked! The answer is a definite **no**! Never kill a program in a non-"main" package. The "main" package should always handle exiting a process. This protects everyone on your gopath from importing a function whose side effect is self destruction.
Oh wow, lots of reading lol. Thanks guys. +1
Nowhere in your post or your github page did you mention the intended use case except "unique within a data center". Personally, if I wanted that, I'd use an auto incrementing ID and a static "data center" or whatever ID and have them together make up the primary key. I guess that's essentially what you're doing, but the cases where you may or may not want that were not clear especially in comparison to other solutions to the problem (e.g. two column primary keys). As such, I'm not that motivated to look further. However, good on you for building a thing and sharing it!
Thank you, that makes more sense than I could reason at that moment.
Go, Typescript: rising PHP, Javascript: falling maybe the world will be okay after all surprises: C++ rising, Swift falling
Why is C++ rising a surprise to you? It's really only beginning to get a foothold in the embedded space (displacing C) these last few years.
You are right. I should not completely ignore the 'data center' ID in the design. Therefore, I just added the section ID support. It has 4 bits and occupies the highest 4 bits of the generated numbers. In addition, it is optional. Thank you.
Actually, WUID is not that fast but is still 20 times faster than Snowflake.
General rule of thumb - do not obuse global state and do not relay on global variables. Basically, any modern framework should work out from the box. 
Performance improvement on framework level will be identical for both solutions, however communication speed and HTTP stack performance will be different. Simple tests with empty project: PHP-PM: https://prnt.sc/hcyju4 (8K requests per second) RR (fasthttp): https://prnt.sc/hcyk9j (21K requests per second) RR (fasthttp + keep alive): https://prnt.sc/hrp4k8 (80K requests per second)
Neat. Is that a laravel project?
Ah okay. I don't have that good of an idea yet as to how it would be configured to work with other frameworks, based on the existing docs/tests. More examples would definitely be welcome!
We are planning to release PSR-7 server based on RR later, you will be able to plug it into any compatible framework without extra pain.
[removed]
How's the embedded space even relevant on github? Surely most projects there are from other domains. 
It's an insanely robust/redundant form of distributed storage that *may or may not* have applications in some very specific domains. Everything else is a combination of greed, scams, fomo, etc.
Problem spaces that benefit from decentralised trust. Smart contracts, cryptocurrencies etc
Woah Typescript 4%, I didn't expect that.
This is what I had in mind when I started this project: https://static.tumblr.com/0ef159a7f8106dcb8d9ee96fd1ce2447/ykhncuc/6REnkf6kg/tumblr_static_by67vkzvn7s440k0g44osogg8_640_v2.gif :D
Thanks for the explanation :)
Great README! Would it also be possible to cut images based on the energy map?
This is cool, nice job!
Very interesting, not as complicated as I originally thought.
I take it you're too young to remember this: https://www.google.com/search?q=microsoft+bob&amp;ie=utf-8&amp;oe=utf-8&amp;client=firefox-b-1 
Do you mean to cut some parts from the image or to crop the image based on the energy map? If you think about the first option, then my answer is no, but if we know the coordinate position of the image part we want to eliminate we can increase the sobel threshold (energy map) and the algorithm is clever enough to avoid them. If you think about the second option then you can use this library https://github.com/muesli/smartcrop which is doing this specifically. 
Hmm, I wasn't aware that cutting and cropping could be different things. Apparently I meant cropping. But I don't understand yet, what you mean by cutting.
I'm curious if someone has compared Go interfaces to abstract base classes / virtual function tables in terms of performance delta. They are significantly better in semantic form for allowing the interface to live with the code that requires it, rather than the code that implements it (See Uncle Bob's writing on the Interface Segregation Principle).
Thanks :)
There‚Äôs an interesting project using it for Internet tech like DNS and certificates: https://namecoin.org/
By cutting i mean, the algorithm permits to cut some parts from the image, for ex. to cut a person from the image, this does not change the size of the resulting image. Cropping on the other hand does alter the size of the resulting image.
Sure, once i will have PSR-7 support ready it will be able to work out of the box with most of the frameworks on a market.
The craze comes from how many people are making tons amounts of money trading tokens and currencies. Of course this is going to end at some point, but for now it's still possible. But below the craze there is ingenious software being written with some pretty exciting applications. Certain industries, like finance, are in the process of undergoing a major change. The innovation behind all of this is the distributed ledger. What it comes down to is people have figured out how to create a source of truth. This enables trust-less interactions; users of the ledger can trust the data without having to trust each other. The first and most obvious application is value exchange, i.e. cryptocurrencies like Bitcoin. This has the potential to disrupt some of our geo-political and economic norms like keeping populations separated through relative values of local currencies, giving governments over population through currency control, and the normal expectation that every transfer of value must be facilitated by one or more financial institutions (all of whom take a cut). But some very smart people have, in recent years, learned to extend the ledger beyond just a record of value distribution. Some platforms, like Ethereum, enable "smart contracts", which are really just snippets of software run on what some call a "world computer". Now not just the data is trustless, but also a set of functions. The implications are far-reaching and an imaginative person could think of dozens of applications in a short time. A simple idea is that a company could use a public smart contract for distributing shares of stock. With functions in place that allow investors to buy, sell, and transfer shares on their own and a public record of shares, the Enron scam becomes impossible. Other applications like universal ID for refugees, banking for the "unbanked", registration of luxury goods, and immutable public records are all being developed by some of the smartest people on the planet. It really is a very exciting space to be in. So, if you get past the hype around how much money certain nerds are making and warnings about a bubble from doubters, you'll find that there are some truly impressive innovations being made that will definitely change our world.
https://linux.die.net/man/1/yes
tthought it was the guy
Each of spawned php-fpm process is started with bootloading of your application (parsing php, connecting to db, etc). In other words in PHP request is state of environment, not package of data. Once processing of request is done, worker will be destroyed. This approach use slower protocol (you are correct about this part), but it is over-compensated by keeping PHP application pre-bootloaded in memory and calling it with request data only (no need to bootload and init framework on every request).
I don't think you should call [atomic.AddUint64](https://github.com/edwingeng/wuid/blob/master/internal/wuid.go#L31) a unique number generator in a general sense. Essentially all you're doing is seeding an integer per process with a base, which does not qualify as unique beyond a per-process space. Random UUID v4 generation is only two logical ands with an inclusive or each, it's getting quality entropy from the system that takes all the time. Point here is your approach of requiring central infrastructure to seed your upper bits provides no real advantage. You should consider just obtaining them from crypto/rand to simplify your library, the guarantees around collision remain the same. If possible you could namespace by machine-id or some similar application specific concept. 
No i am running ubuntu (linux x64). I have tried everything on the installation guides. I even tried cloning the repo and running make install. This is the response i get: make install go install -ldflags="-X main.Build=74d330a013a5412649aaa069d932b93889c2dbd2" github.com/derekparker/delve/cmd/dlv # github.com/derekparker/delve/pkg/dwarf/reader pkg/dwarf/reader/variables.go:81: vrdr.dwarf.Ranges undefined (type *dwarf.Data has no field or method Ranges, but does have dwarf.ranges) Makefile:52: recipe for target 'install' failed make: *** [install] Error 2 Which leads me to believe there is a bug relating public / private variables in the package. I tried looking at the source code but didn't have much time. At this point I may just give up having a debugger in vsCode. 
Use a yaml file to stitch together commands and bash snippits and run them with a bit of style. Allows you to easily run scripts/commands in parallel, reference scripts from a URL, bundle everything into a executable, show multi-task progress bar (vertical), still print stdout/stderr for all tasks in realtime, and a few other things. Please just keep in mind that it's in beta.
I've gone through it. I followed the examples directly and used the file structure that was recommended in the book.
Nice, what did you think of it?
It was _excellent_. I came away with a much deeper understanding of how interpreters work (and some better Go skills as well - this was my first Go learning project).
I'm currently doing a live stream series that teachings programming via small game-related projects in Go, you may enjoy it, and tt's free! http://gameswithgo.org/
These tools have saved me sooooo much time! Thank you!
&gt; This is not correct - php-fpm master will keep at least min_spare_servers number of children running, interpreted PHP code is available as bytecode in the opcache so that files are not parsed from disk. Correct, but you still have to load all of your codebase, initiate framework and ensure needed connections. OPcache only makes it faster, but initiation is still the bottleneck. &gt; Are you saying that each php process spawned by os.Exec does not die at the end of execution? Correct. &gt; How do you manage the PHP object graph lifecycle and memory usage? Maybe i'm not getting this question correctly, but i would do it exactly same way as i would do it in Go or any other language: do not abuse global state, make sure that all descriptors are closed and etc. We have also created PHP framework specifically designed to work in such mode. Also, library does have fail-switch for legacy codebases which MIGHT have memory leaks, it allows worker to notify parent process that rebuild is required (before request is being handled) and pass job to another worker. &gt; How can this be safe for use through multiple incoming requests? Because requests on PHP end are synchronous and worker only handles one job at the time. You do need to worry about memory leaks and state pollution, but that should be obvious.
Thanks for this; given what I know of the blockchain that really makes sense. And it explains why all these decentralized cryptocurrencies are hot for blockchain - they fit those criteria exactly.
Well, except that they're not generally useful as currencies because of the performance issues, as well as economic issues.
Side question: are there any other interesting books like this for Go?
Very cool tutorial - there's another, more complicated Golang Blockchain one here - https://jeiwan.cc/posts/building-blockchain-in-go-part-1/ - and it covers some indepth topics. I found it invaluable. It looks like you guys are in Vancouver as well? I'm Jeff, Solidity / Golang lead over at Etherparty here in Van as well, we should have a beer sometime and talk blockchain : )
The code you have in main (apart from the first line for repo setup) is what you need to do in the second part of Crawl(). As it is now as soon as the first Crawl() gets data it'll return and main() will end (even though a bunch of goroutines are doing something).
Hm, alos without setting up the waitgroup in main? Could you write a bit code to demo what you mean? Thanks.
I've been trying to workthrough "the way to go" I seems like is a nice structure for learning in depth on the language. There is a pdf floating around on the internet.
Not really sure what is unclear - Use the std lib to set up a little http api that accepts file uploads &amp; returns results instantly or returns some kind of id so the front end can wait for the process to finish - Design the Front End with HTML / CSS like normally and let it fetch everything via Ajax requests from js - Use OAuth for Google Login (https://skarlso.github.io/2016/06/12/google-signin-with-go/)
Yea...I think my problem was that I was trying to do things in Revel....perhaps I should have organized my question better.
I was looking more for something where it guides you through building a complicated application versus just showing off each language feature one by one
Another ugly solution, but more safe. Pool of channels. It will limit number of channels, but you will need to measure this number.
The last line of stdout from the process is shown to the right and there is a config flag to enable a log all output in all processes.
Ah gotcha, didn't catch that. I would totally try to get my boss to use this for random scripts but he loathes yaml and would probably dock my pay for mentioning it.
It's a mixture of causes. If you're using proof of work to add a block to the blockchain, then you basically have to make the work tough -- but not too tough or you'll cause massive fees and cripple performance. But the problem is, with no central authority it's very difficult to adjust the required amount of work later, whether it's by adjusting the block size or via some other mechanism. (There's also the problem that right now, anyone who has hardware capable of mining Bitcoin via proof of work is using it to do that and get rich, so you need a pretty big bribe to get them to do boring stuff like confirm transactions -- but that's more of an economic issue.) Bitcoin's theoretical maximum capacity is somewhere around 7 transactions per second. Visa alone hits peaks of 50,000 transactions per second, so Bitcoin is 4 orders of magnitude away from being able to handle transactions comparable to even one of the credit card networks, let alone replacing cash. The most popular "solution" to the capacity problem in the blockchain world is to [move most transactions off of the blockchain](https://coincentral.com/lightning-network-beginners-guide/), and use the main protocol only for resolving aggregated transactions. To me, though, that seems like an admission of failure, even assuming you can get it to work without having to trust anyone. I'm hoping we'll see a move towards proof of stake systems such as [iota](http://www.zdnet.com/article/a-better-blockchain-bitcoin-for-nothing-and-transactions-for-free/) where you don't need a GPU rig to take part and don't need to burn a day's worth of electricity per transaction.
The corresponding blog post is out! https://medium.com/justforfunc/two-ways-of-merging-n-channels-in-go-43c0b57cd1de
Ah, okay, like removing something, got it.
How did you make the loading screen (the gif in README.md)? 
One thing that really bothers me and I am surprised that nobody has pointed this out yet, it's the file structure, I don't think this project would be `go get`able, nor easy to work with, the package naming doesn't follow the standards either, please, for sake of all things good, look at other popular projects and how they structure their code.
This is seriously awesome work. Well done
I used peek (https://github.com/phw/peek) to capture the gif, I committed it to the repo and referenced it in the README.md (open up the raw readme to see how). The specific demo used was this file: https://github.com/wagoodman/bashful/blob/master/example/00-demo.yml invoked by running "bashful run example/00-demo.yml"
This is cool stuff. I really wish my photo editor of choice (Affinity Photo) would implement this (obv. not in Go, but oh well). https://forum.affinity.serif.com/index.php?/topic/31228-aph-content-aware-crop/&amp;do=findComment&amp;comment=275352
Neat. I am going to use this to provision my dev environments. Thank you for sharing!
Performance issues are basically solved with the very newest generation. RaiBlocks *should* be able to compete with the likes of VISA in terms of performance, but tests haven't reached into the thousands of TPS yet.
Not too long ago I tried myself at implementing a blockchain: https://github.com/tehcyx/gochain Probably similar to what your article ends up building in the end. But I can just recommend this for the curious out there. For me it clicked way better, after I implemented it myself.
I'm very impressed so far! I'm only on page 25 and I'm just trying to wrap my head around the functions. There are a few points where I have questions, but I think I can figure it once I get further along.
Oh I'm still really new, but I hope that someone can help you with that soon!
Source is here: https://github.com/hunterloftis/pbr I'd appreciate any technical feedback more experienced Gophers have. It's gone through several iterations as I learned the language and patterns (and got help / suggestions from folks here).
This is really neat! I don‚Äôt think the description does it justice.
[removed]
Hm. Can it execute ansible playbooks?
much appreciated! I'm not quite a wordsmith, so I made a gif instead :)
[relevant read on generating unique IDs in Go.](https://blog.kowalczyk.info/article/JyRZ/generating-good-unique-ids-in-go.html)
This is some really minor stuff, but https://godoc.org/github.com/hunterloftis/pbr#Scene.ReadHdr should probably be ReadHDR. See https://github.com/golang/go/wiki/CodeReviewComments#initialisms. Its documentation also mentions `SetEnv()`, but I'm not finding that available (perhaps it was renamed or removed).
Great to hear! It may be a bit rough around the edges since it's still in beta, but I'd be willing to work through any issues you find. Just submit an issue for anything that seems amiss.
Who cares 
Of course you're right, but blockchain acts as a generic term for DLT. And, technically, a blockchain is a DAG.
Omg what have you done cynic 
Nobody cares.
Thanks! I started - and stopped - several times as I ran into concepts, math, or code that I wasn't sure about. If you pick up your project again, feel free to reach out with questions and I'll help if I can, one amateur to another.
Thanks for the feedback! I'll go over all the docs and examples this week to be sure it's actually all current. Lots has been in flux as I've figured things out / realized I was doing something in a terrible way.
Nobody cares. 
I think you are confusing channels with goroutines. Goroutines are cheap. Channel is just like another variable. Will you be worried of declaring an integer for every single request ? I wouldn't be. So why bother about creating a channel for every request. It's perfectly fine to create a channel for every request. Of course, if you have a very high traffic server, you can go with a buffer pool of channels to reduce gc overhead. But up to you and your needs.
Nobody cares. 
I'm impressed so far. I'm still in creating a lexer part though.
The book "Web Development With Go" walks you through building a complete Web application - available on [usegolang.com](https://usegolang.com). (Also available as a video course)
Nice. Are there any comparisons which benchmarks the dev branch vs gogoproto ?
Speak for yourself. I think this is bloody amazing. &gt; Oh no bringing the bots in to downvote my comment. I‚Äôll just post another and another. And people will downvote again and again because this is not a sane behavior. Really.
Thanks man.
Thank you.
Great one, the next Go project in my todo list hopefully will be raytracing engine.
Because of type aliasining in Go1.9 there's no difference between the types in `x/context` and `context` anymore. So I don't really see the big issue with some packages using still using `x/context`.
Not really talking about your Go code which I think is fine (probably not better than you in Go anyways). But I think your commit messages could use some work. I tried to retrace how your project developed but had a hard time following the commit messages. You might to more and smaller commits with more explicit messages. Probably the best post I read on commit messages and how to write them was done by a guy called [Chris Beams] (https://chris.beams.io/posts/git-commit/). Otherwise, very lovely project. I am super impressed
It's one less thing to have in our Gopkg.lock :)
Hi, I figured it was time to finish up version 3.0 of my [decimal library](https://github.com/ericlagergren/decimal). This is probably the largest release yet, mostly because I kept kicking the date down the road. :-) New in this version: - a working `math` sub-package complete with elementary (`exp`, `log`, etc.) and trigonometric (`sin`, `cos`, etc.) functions. Much thanks to Nathan Hack for his help there. It also boasts multiple continued fraction and binary splitting algorithms. - performance improvements. I went through the code trying to remove as many allocations as possible, since they're easy to incur in an arbitrary-precision library. The general-case performance isn't _too_ much better, but overall it should perform better than before. - methods on `Context`. Before, it was annoying to do an operation with an explicit precision, rounding mode, etc. This made writing some mathematical functions difficult (since they rely on always using `decimal.ToNearestEven`, for example). So, for all the relevant arithmetic operations I've added methods on `Context`. The original methods still exist, of course. This new method is the "blessed" way as it's more explicit and not too much more verbose. - new test suite. Python's decimal package (which uses libmpdec) is robust and perhaps the standard-bearer for the GDA spec, so I've migrated my test suite to match it. This has helped me find a bunch of subtle bugs and adhere to the spec better. - a nearly-completed implementation. There are [only a couple](https://github.com/ericlagergren/decimal/blob/c9c954bc20d124776e6064553349d754bfeb5084/parity.md) (rarely-used) parts of the spec left to complete.
Great post. It showcased the main idea behind blockchains in a simple way. Very helpful. It would be pretty cool if the article showed how to do a some stuff like the routing using the standard library. One less thing to do for the reader is always good.
sorry, seen my mistake. one is a timer the other is a ticker. damn
Just wow...
&gt; Any changes for code generation which respect Go's idioms (e.g. fooID over fooId)? Consideration of such features will occur in the future, but there are several other Go protobuf issues we want to address first. &gt; Will x/context be replaced with std lib context? Unfortunately not yet. There are still major users of Go protobufs that are still on pre-Go1.9. I want to remove that dependency myself, but it is beyond my control.
 type Inter interface { Int() int } The way Go interfaces work mean, that if you observe a pattern, you can just declare that interface and use it. FWIW, there are two subtly distinct concepts that the term "interface" is used in: a) provided interfaces, that is the set of methods a type gives you and b) required interfaces, that is the set of methods you need from a type to be able to use it. Go interfaces are about b), not about a), so they should be consumer-defined. I.e. `fmt.Stringer()` is an interface created by `fmt`, so that you can tell it how to format a type. If you have a package and give people the ability to specify how to create an integer out of a thing, you can have it define above interface. It seems non-obvious to me, however, why you'd *want* that. Your example is weird to me; it would make much more sense to me to call that method `Mileage` (actually, you just shouldn't make it a method but an exported field, but that's beside the point).
Unfortunately I don't have any. We are unable to run gogo/proto internally at Google because some usages rely on esoteric, legacy, internal-only features of protobufs that aren't implemented by gogo/protobuf. If anyone has measurements of the performance differences on a real production workload, that would be great. I caution against micro-benchmarks as we have found them to fairly non-representative. As an aside, gogo/protobuf has more knobs to control how performant the serialization should be. In the extreme case, it performs full code-generation, which will almost always out-perform the table-driven approach we took. However, full code-generation drastically bloats the binary size when you have many proto messages linked in. Keeping the binary size smaller was an important design decision for us.
I'm *really* curious what the deleted comment contained...
Also, check out [RaiBlocks](https://raiblocks.net/).
I'll look into that. Hopefully it'll be easier than trying to dig into some of the other frameworks. 
&gt; is an interface created by `fmt` Oh, that I didn't know. I assumed that `Stringer()` this was somehow a global thing; Now it makes more sense. (And it explains why `println()` works differently in that regard then `fmt.Println()`. Thanks for pointing that out. &gt; why you'd want that I had the impression that implementing a `String()` method would somehow work on a global scope, and was used to get a *defined* string out of a type. Like "if you want to convert this type to a string, I'd call this `.String()` method of that type (if it has one) and that's it". I found the idea nifty and assumed it would be nice to have something similar with integers. Simply using `c.Mileage` makes sense, now. 
Whoa I had no idea this was a thing: type GoStringer interface { GoString() string } Which means that we can do: https://play.golang.org/p/3qH_l87W1qj
This is so cool! great work man!
Wow... I feel inadequate all of a sudden
Why doesn't Go have native support for decimal arithmetic?
Did you read the insulation guy that someone else linked you to here? The root directory of the git repo isn't compilable so your go get command is flawed. If you add /dlv to the and it will work because that is where the command resides. Go get is not exactly like git clone. But don't take my word for it because this is from a cell phone and from memory of last time I installed it. Take a look at the install guide linked in the other comment.
I'll have a look at the official docs soon and will either rework some of that or keep it in mind for my next Go-projects :) I only use Go for private projects, but I will improve on general structure! (Was hoping someone points it out, if there is something really wrong)
https://github.com/JubbeArt/removeddit/issues/1 It apparently hasn't worked for new threads since December... :( Thanks though.
It said ‚Äúwho cares‚Äù
Better question would be to ask, which languages do? Floating point is good enough for almost anybody.
How much time did you spend on this project? Your master branch's history goes back 2 weeks but I felt like it's not all the effort you put in this project
Thanks!
You should have given the Lambo a "Hello World" decal. (On the note of the Lambo, that front left brake disk is making me twitch... It seems to lack its hub mount.) What's next? Ray bundling like Hyperion does? A noise-free render? Or do you feel like your for-fun project reached its end?
Huh. I get the 401 error, even for the example thread on removeddit's frontpage...
I only have experience with Apache ActiveMQ but as far as I heard about NATS (and probably NSQ and Google PubSub work similar), there's no library to built them directly into your go application. And I think a user-to-user communication is also not possible with a classic message broker (except NATS, NSQ or PubSub explicitly offer these features). If a messaging service is able to efficiently serve as a social posting AND private communication service depends on the messaging service you use. I think the client has to fit into the servers architecture, for example knows AciveMQ only topics and no user-to-user communication. A client that wants a private communication with another client has to use this concept to achieve this (maybe not the smartest idea). To learn go, messaging and to create a minimalistic messaging service, I wrote goms (https://github.com/go-messaging-service/goms-server). It also can't do user-to-user communication (so far). What's possible is to change the code slightly and use goms as a library. Also user-to-user communication could be implemented (I think this is not so complicated). Maybe this helps. It would be interesting to hear if there's a go library for user-to-user communication.
Ha - it [did start with Hello, World](https://github.com/hunterloftis/pbr/commit/f9245fa4ade113d0a4b66da365bfc2dcede09875)
There have been quite a few of these before like ceddit. Most were shut down. Maybe this one have share the same fate. But anytime I have tried it on this subreddit it has worked. For example when I wanted to see the deleted comments of this thread, I took the URL: https://www.reddit.com/r/golang/comments/7twwhu/i_wrote_a_physicallybased_3d_renderer_to_learn_go/ and simply added 'emov' between r and e: https://www.removeddit.com/r/golang/comments/7twwhu/i_wrote_a_physicallybased_3d_renderer_to_learn_go/
Thanks! And agreed. If you'd like to retrace the beginning, check this out (off master): - [the first page of commits](https://github.com/hunterloftis/pbr/commits/actually-collada?after=ae2a1cc3ea6a6792380eeaf72d04ce6f1f6b2d1f+139) At some point, I checked in a massive 3d file and absolutely could not get rid of it. Everything I tried had issues with the git-lfs extension I have installed which was modifying every commit in the project's history for large binary blobs. So after a couple of hours I just blew away master and stopped trying with git.
Awesome! It was really a fun way to learn (the basics of) a language.
&gt; You should have given the Lambo a "Hello World" decal. I'm sadly not a 3D artist, so I've been cobbling together models and environments from whatever I can find online. I would happily accept a "Hello, World" texture! The problem with a hobby renderer is that [you can work on it infinitely](https://github.com/hunterloftis/pbr/blob/master/NOTES.md#features-to-try). Given how long a 1080p image like this takes to resolve (this one took more than half a day, basically just left my computer on overnight), and that I work at Heroku, I'd next like to make it network-distributed so I can scale it up and render something similar in a few minutes.
I hacked on it months ago to the point where I knew enough Go to be useful at work, then put it away. Then over Christmas break I took it out again. I've spent too many nights and weekends on it; my fiancee no longer endorses this project :) The git history sucks; I chose to blow it away on master instead of continuing to fight with an accidentally-checked-in 3D blob under LFS that I couldn't, for the life of me, remove from the history. Once I realized Go uses github repos for dependency management, I didn't want to have megabytes of fixtures in what's essentially a released package. [Here is the actual first commit (Hello, World)](https://github.com/hunterloftis/pbr/commit/f9245fa4ade113d0a4b66da365bfc2dcede09875) from over six months ago.
&gt; so I've been cobbling together models and environments from whatever I can find online That explains why the lambo is parked on a skateboard ramp. :) I'm glad you have something realistic to go forward on. Nothing is more annoying when you reach the end of a project and go "now what?". Network distribution is a great goal. How would one go about doing that? Restrict each node to a subset of the rays from the light source, merging the result? How many bounces did you trace in the example photo, btw?
As a developer I often struggle with spending too much time on things I find interesting and not enough on those that I find boring. I was recently reminded of the Pomodoro technique and wrote this little CLI tool to practice it. The creator of the technique advocated a low-tech approach but as someone who spends most of their day in front of a terminal this made sense for me. Wrote it with [termui](https://github.com/gizak/termui) and [sqlite3](github.com/mattn/go-sqlite3) I will try to add some more features in the coming weeks. Anyone's feedback is appreciated!
&gt; That explains why the lambo is parked on a skateboard ramp. :) Yep! :) &gt; Network distribution is a great goal. How would one go about doing that? Restrict each node to a subset of the rays from the camera, merging the result? That's one way you could do it. I would probably try to minimize orchestration - as long as you pair the number of samples taken (per pixel) with the resultant light energy, you can just sum all of the results without distorting the value. So my plan is to have workers render one full frame at a time and then send back the frame as an rgbe image (with values &gt; 255 and an alpha channel devoted to the number of samples taken). Then the collector can just sum everything together and act just as if it had taken all the samples itself! &gt; How many bounces did you trace in the example photo, btw? Just the default (8). iirc, Pixar used 9 for Big Hero Six.
Orchestration is the root of all suboptimal parallelism... That's a much simpler construct. I had forgotten the "monte carlo" part of "monte carlo path tracer", and thought for a moment that the slaves would have to be constrained in their tracing to avoid just creating the same output N times.
For what it's worth you did awesome!
yup basic auth on https is better than nothing. Digest is better if possible. Basic Auth sends the username/password across the wire encoded (not encrypted), so anyone listening in can get the credentials.
I believe you should use a custom [http.Client](https://golang.org/pkg/net/http/#Client) instead of a direct http.Get, so you can set a meaningful timeout. And maybe you want to handle redirects in a custom way too. [This](https://medium.com/@nate510/don-t-use-go-s-default-http-client-4804cb19f779) is a nice article about that stuff.
I'm glad that Go is getting used for graphics related projects too and not only for infrastructure and server side.
What is a 3d physically based renderer It sounds really cool, and complicated, gonna look it up
SQL, Haskell, Mathematica (&amp; Wolfram), Scala, Ruby...
Thanks man
Hdr isn't an initialisms or acronym, so that rule doesn't apply here.
hdr stands for high dynamic range, so i would think otherwise.
Oh, I assumed it meant header.
No problem! You can dynamically retrieve the absolute path using the ‚Äúpath/filepath‚Äù package.
Thanks for this article, I thought all the time that there's a default timeout like 30 seconds. But now I'm using the http.Client and http.Server (as mentioned in the comments, the default server has timeout issues too).
Maybe I'm missing something, but I can't see the advantage in that approach. I'd rather stick to: sort.Slice(emps, func(i, j int) bool { return jobsMap[emps[i].jobid].desc &lt; jobsMap[emps[j].jobid].desc })
Currently using this library for https://blockexplorer.com/market. I'm mainly just using Add/Mul/Div, so my use of it isn't complicated. Your decimal library was the most performant decimal library in my benchmarks, and it's easy enough to use. I really appreciate the hard work!
Seems like the cache is not thread safe...
The browser loads files linked by the html. If you want to download those files linked in the html, you need to parse the html for links and perform GET requests on the links. That is, if I understand you correctly. 
golang devs actively resist putting arbitrary decimal or 128-bit decimals into the native spec. go read the closed issues with very reasonable arguments, shot down by developers. some devs think only they know what's good for everyone. nevermind what the masses want, or the plethora of daily use-cases.
Go has a Big int library as well. Most people don't write finance code.
golang devs are stubbornly arrogant in their refusal to support probably the most requested feature (that I've seen) for their language. thanks for providing the support that the maintainers refuse.
That is not a bad idea at all. I have used BoltDB in the past and I think it could simplify the code quite a bit. I will open up an issue later to investigate implementing this. Thank you for the feedback!
It's very nice. I'm using it now. I think that the install from source instruction has a typo: go get github.com/kevinschoon/pomo cd $GOPATH/github.com/kevinschoon/pomo make ./bin/pomo line 2 should be ```cd $GOPATH/src/github.com/kevinschoon/pomo``` For me, I just ran ```go get``` and it worked (I guess I had sqlite already installed). 
Well this project taught me that I know dick about go... Incoming stupid questions: In main.go What does `Loop:` do? It looks like a goto label, but nothing seems to go to it. Where is `options()` coming from? It seems like it is the function from options.go, but options.go isn't imported anywhere into main.go.
Thank you for the correction! I can update shortly.
A function that returns multiple values needs to have those values assigned to variables (or thrown away with underscore). You can't use a function call that returns 2 arguments as a parameter to a function that takes 2 arguments; you need to use intermediary variables.
Agreed, the resources you provided are great if you'd like to skip the introduction that part 1 provides. The next parts in the series will have more depth in manipulating IP and ICMP packets and also injecting packets on the wire. My goal here is to deliver the content in a digestible format without providing too much content to the reader at once.
Scheme, Lisp, COBOL, Objective-C...
Looks like we might get [unlimited integers](https://github.com/golang/go/issues/19623), so maybe we can have accurate currency calculations in Go 3.
I will try to focus my comment on idiomatic go style and not about the algorithm/logic (code complexity is O(n^2) and could be O(n) using map). change your function to return tuple of result &amp; error func IsBlacklistedDNS(addr string) (string, error) then in main: if err == nil { fmt.Println(result) }
OP's code [does work](https://play.golang.org/p/fgtGvCQiFaH)...
A license would be appreciated, ideally a permissive open source one. :) I [opened an issue](https://github.com/hunterloftis/pbr/issues/24) to help track it.
I do like that idea. Three basic types: - `int`, an arbitrary-precision integer. - `float` an arbitrary-precision float. - `decimal` an arbitrary-precision decimal. Plus `int32`, `float64`, `decimal128`, etc. sized types for each of them.
I'd go with "float" as decimal, since it's what n00bs reach for when they don't know any better, and have something like `ieee854` or `binfloat` for your IEEE radix-2 float.
You just made my day.
You're welcome. I have more ;) Pomo would be great with OS notifications to let you know when the timer is done. At the moment, when the pomodoro is done it's really easy to not even notice, especially when it's minimised or on a different virtual desktop. You could use a lib like https://github.com/0xAX/notificator to implement such a feature in a cross platform way.
I had looked at a few of the cross platform notifier libs but I must have missed this one. If you are on Linux you should indeed get a notification bubble. These are great suggestions, feel free to open up some [issues](https://github.com/kevinschoon/pomo/issues) as well.
Ragel is great and I'm glad to see that Go support won't be removed from the upcoming version.
This is cool! I've written a proxy as well, unfortunately not something I can share but so far it's worked out pretty well. I'm storing the data in a DB instead of file system since I'm running the app on heroku, I need it to not rely on the filesystem (s3 may be an option but would need to look into latency) I'm wondering though, when you save the information to the filesystem, does that retain headers?
That's amazing! I tried using Go to get some experience writing low-level GL but the furthest I got was some [basic lighting and mesh loading](https://scontent-syd2-1.xx.fbcdn.net/v/t34.0-12/22901307_10156294673597080_404434226_n.png?oh=648c685dddd563f11d6d5b14771f6db1&amp;oe=5A7340FB). This blows it right out of the water!
CoreOS will soon die. 
You're a recruiter (I found your mobile number [here](https://www.seek.com.au/job/35194303)). If this isn't against the Rules it should be.
I dunno, that actually looks pretty nice to me, just low-res. Is it OpenGL or a software rasterizer?
You could put the transaction hash and balance into the blockchain without exposing the transactions. Unfortunately this means there has to be trust in whomever placed the link in the chain. You can't have perfect secrecy without trust between the participants.
It's OpenGL, and it was for a game jam called lowresjam, so yep that was kind of the goal! But still, thinking of how much effort it took to get it even to that stage... the mind boggles haha.
There should be a weekly recruiters thread, but that's it. Ping /u/natefinch or /u/dgryski 
This is cool! I came up with a text format for Pomodoros, so that you could switch tools and keep your history/settings: https://github.com/open-pomodoro/open-pomodoro-format I'd love to know what you think. Seeing you post this encouraged me to finally push up the client I wrote for this almost 2 (!!) years ago: https://godoc.org/github.com/open-pomodoro/go-openpomodoro I don't know why I waited so long to publish it. I guess I felt like it wasn't really done yet. Still needs better docs. I also have a CLI using the library with just start/status subcommands and a custom formatter for the status. I'll push that up soon. termui seems really neat, I want to play with it sometime soon.
Pushed the CLI for it with a WIP commit: https://github.com/open-pomodoro/openpomodoro-cli There are docs though in the README which explain for custom formatter. I use it in my tmux status bar.
I don't see any reason why this should be against the rules, unless and until it starts materially affecting the ratio of posts on the forum.
Whoops! You're right, it's special cased, as /u/anossov points out above. Mea culpa.
Weekly seems a bit too frequent -- I don't think there are really that many job posts that would come here. I'm happy to do once a month or so. As it's almost the start of February, I'll make a reminder to myself to post one.
I'd prefer a regular cadence of recruiter threads, not individual requests like this, to ensure they don't overwhelm the sub
Thank you! Can you please show how to do it with a map?
We get no more than one recruitment post per week, on average. Let's implement process when we actually have a problem.
/cc @purpleidea
Right on. Rules for their own sake are just overhead.
I don't think it is fair to label the code O(n^2). It is O(len(addr)*len(blacklist)), but len(addr) &lt;&lt;&lt; len(blacklist). The current code also uses strings.Contains, and doing that with a map is not possible. But your comment on the return types is accurate. 
Loop through channels' slice and test them with "select" statement.
So returning a bool hides some problems (and is nicely visible in the go playground). Your function returns false for an address that should be blacklisted due to an error in looking up the address. The caller (in this case main) has no idea that the result is wrong. Your function is perhaps mislabeled, the name indicates some Boolean value, but returns a string. I small name change + refactor could benefit your program. // Get a list of reasons it is blacklisted. If it is an empty list then it is not blacklisted func GetBlacklisted(string addr) ([]string,error) // Returns if blacklisted, or an error if a lookup failed. func IsBlacklisted(string addr) (bool,error) This is mostly nitpicking though. 
I think multiple channels would be good here too. You could make-use of non-blocking receives if you need to poll them without blocking: https://gobyexample.com/non-blocking-channel-operations
If you'd still like to use multiple senders, it looks like you can! https://stackoverflow.com/questions/29342701/write-to-same-channel-with-multiple-goroutines Though make sure not to close it too early: ``` C3. If a channel has multiple senders, do not close the channel from a sender goroutine. Closing the channel from a sender could make future sender goroutine to panic. ``` https://udhos.github.io/golang-concurrency-tricks/
Very helpful! Thank you.
net.Resolver#LookupAddr can be used with a context.
Instead of net.LookupAddr, you'll need to use the more flexible [LookupAddr method](https://golang.org/pkg/net/#Resolver.LookupAddr) of the net.Resolver type. That accepts a context which can have a timeout: func main() { const timeout = 10 * time.Millisecond ctx, cancel := context.WithTimeout(context.TODO(), timeout) defer cancel() // important to avoid a resource leak var r net.Resolver names, err := r.LookupAddr(ctx, "127.0.0.1") if err == nil &amp;&amp; len(names) &gt; 0 { fmt.Println(names[0]) // "localhost" } } https://play.golang.org/p/TuNZ6FABr3e 
From what I can recognize on the screenshot you posted, why not just GET the "playlist" file?
My favourite feature from this release: &gt; Performance &gt; Speaking of performance, the update makes it possible to limit indexing of the local project and avoid indexing an entire GOPATH. &gt; This new option makes sense when you vendor all your dependencies with dep or glide tools and don‚Äôt use libraries from global GOPATH. &gt; The option is available in both File | Settings | Go | GOPATH | Index entire GOPATH and the Project Wizard. When you have a very crowded GOPATH but you also vendor everything on a per-project basis, this makes a *huge* difference. No more multi-minute 100% CPU while the index is regenerated.
* In case you cannot tell by the funny english in the comments, Gerasimos is kataras, the author of iris. * Check the [comments](https://hackernoon.com/go-vs-net-core-in-terms-of-http-performance-7535a61b67b8) for a good laugh. Again gerasimos is kataras. * If these are not enough warning signs for you then check [this](https://github.com/avelino/awesome-go/pull/1137) out. If you couldn't guess, ghost is kataras. * And if you want to know the [original story of kataras](http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html).
Iris framework is like nuclear waste in the Go ecosystem. We shouldn't even touch it...
not an expert (these points may be wrong) but: 1) read channel aka `&lt;-` is blocking ... it will sit there until .C writes something... so this func runs until &lt;- and waits, it doesnt keep running like you would think channels do. (so you would have to do recursion pt3) 2) select is a weird construct; its not a loop, you could wrap the whole thing in `for`, ex `for { select { v &lt;- ch } }`... ive not seen this documented well anywhere but ive had to use it twice to make it work 3) give that fn a name ex `go func myfunc(username string)`, it may help b/c point 1 4) that function should only run once unless its on a timer. if you add recursion at the end it will probably work as you expect. after reset() call the func again (or wrap the whole thing in a for loop): `myfunc()`. `
Thank you! I will try your tips and report back
When is this function called? On every user event?
I wonder what are the consequences for etcd... 
Hey /u/shovelpost ! "have fan"! 
Prefer Solution #1. Your method does not modify the struct so a value receiver is preferred.
Okay, so here's my new code func (w *WebsocketManager) staffTimer(username string) { w.UsersMutex.Lock() w.StaffActivityTimers[username] = time.NewTimer(time.Minute * staffActivityMaxIdleTime) w.UsersMutex.Unlock() for { select { case &lt;-w.StaffActivityTimers[username].C: w.MongoManager.StaffIsInactive(username) case i := &lt;-w.StaffTimerChannels[username]: switch i { case 0: // active w.MongoManager.StaffIsActive(username) w.UsersMutex.Lock() if !w.StaffActivityTimers[username].Stop() { &lt;-w.StaffActivityTimers[username].C } w.StaffActivityTimers[username].Reset(time.Minute * staffActivityMaxIdleTime) w.UsersMutex.Unlock() case 1: // left w.MongoManager.StaffIsInactive(username) return } } } } I run this as a goroutine when a staff member logs in.. then I send to `w.StaffTimerChannels[username]` and every time the staff member's writes a message (resetting the timer), but it doesn't work, it seems like the channel blocks, and stops receiving (only `w.StaffActivityTimers[username].C` receives). I don't understand what's the problem and why these two channels are different
Thanks for explaining! First time I am hearing about CGO. Makes sense now.
I looked into it a bit more and I think this might be the exception to the rule. From https://golang.org/cmd/cgo/: &gt; When the Go tool sees that one or more Go files use the special import "C", it will look for other non-Go files in the directory and compile them as part of the Go package. Any .c, .s, or .S files will be compiled with the C compiler. Any .cc, .cpp, or .cxx files will be compiled with the C++ compiler. Any .f, .F, .for or .f90 files will be compiled with the fortran compiler. Any .h, .hh, .hpp, or .hxx files will not be compiled separately, but, if these header files are changed, the C and C++ files will be recompiled. The default C and C++ compilers may be changed by the CC and CXX environment variables, respectively; those environment variables may include command line options. 
https://blog.golang.org/c-go-cgo
First I run this function in a goroutine, then immediatly send w.StaffTimerChannels[username] &lt;- 0 
Shame it's not free anymore
Seems like the question lies in your JavaScript code rather than the Go code. I admit I'm not well versed in Javascript myself but maybe the cookie needs some attention there before the GET it performs?
As a trend, how much does Google rely on internal use only software vs publicly available FOSS? For example, do they still use borg or did they fully switch over to k8s?
In that case you would have to tunnel the requests through a proxy (like https://github.com/elazarl/goproxy) and match the path with regexes or string comparisons. Then you could get the file as soon as the name is transfered. if the target website uses HTTPS it would still be doable, but a bit more complicated. 
I would love to see your solution! I am having the same problem. 
you are looking for an university maybe ?
Noted
Quite disappointed about this. I'm also wondering what will happen to some other things like BoltDB even.
Been to University, got a BS, pretty sure I can learn/teach myself with the experience I mentioned previously, the education, and some self guided resources/materials.
[The Go Tour](https://tour.golang.org/welcome/1)
Very helpful thanks
Thanks will give this a try
Awesome!
You will probably have many holes in the knowledge and will suffer a lot from the impostor syndrome.. You should try to attend some serious classes instead of just playing this imitation game.. your future team mates, bosses and clients will thank you.
What I tell everyone with this question is to start solving a problem they find interesting. Since your a sysadmin you already know how to google effectively so this applies more so to you. Reading is nice and some people truly do great like that, but nothing comes close to actual practice you get when solving a problem you find interesting with a real program.
This is more red hat further cementing their dominion over linux for the next decade at least
Agreed - I stopped using it because it's too expensive; they need a community edition.
FYI, it is $89 / year, or $8.9 / month, or free for open-source developers, teachers, and students. If you already own the JetBrains Toolbox, it's also automatically added at no cost. I'm not saying it's really cheap, but maybe you can help me understand why do you think it's "too expensive"?
I think at the moment the plugin is the closest they can get to a community edition. I don't know that there is enough to the commercial edition yet to be able to sell it with a community edition.
Don't listen to that guy. You'll do fine.
Go is not my favorite language, but it's a fantastic choice of first programming language. Good luck!
The rule isn't really that simple, though. In this case, passing the two strings by value is probably just as fast as using indirection anyhow, so a value receiver can be fine, but if you care about performance you can end up with methods or relatively large structs that you use a pointer just to avoid the copy. And on the flip side, using [a value receiver doesn't guarantee that you won't mutate something anyhow](https://play.golang.org/p/Dct3PhwTTYW), so it's not like being a value receiver means that someone reading the docs can assume that is a proof that calling that method won't mutate the object. Since value vs. pointer carries so little semantic value, the "under-the-hood" behavior is the primary consideration. If you have a value object that is deliberately trying to be "const" with respect to its methods, you need to document that special fact in the methods because there is no way to indicate it with the type system.
I go back and forth on using JSON. Two of the goals are for the format to be human-editable and append-only (at least in the normal case). Using JSON would either require one line per JSON blob, which is not a valid JSON file in itself but only each line is valid JSON. I don't think would be a big deal, because splitting by lines is pretty trivial in any language, and `jq` supports this via its streaming mode. With the format as-is, each line begins with a timestamp and is followed by logfmt keys/values. I've been able to find a logfmt reader/writer in most languages I looked at. So i agree that the format is not as trivial as JSON, but I think I still prefer it for the semantics noted above. One thing that I haven't solved for is pausing. Any client could technically pause their timer, but I haven't figured out a good way to represent this appended to the existing data format.
thank you for the direction to take in my researchs ! I'm going to investigate your link right now
I stopped using it right after they announced it will be paid version. I use Go only for weekend projects.
Most universities are very poor at teaching modern programming. A lot of them teach you semantics and logic flow structure, and algorithms - but the actual language, probably not. 
&gt;if you care about performance you can end up with methods or relatively large structs that you use a pointer just to avoid the copy I thought pointers are "bad" for the GC? So you'd rather NOT use a pointer if you care about performance. Correct me if I'm wrong, which wouldn't exactly surprise me :D.
Thanks for explaining! That's why executable is over 100M+ :)
I would say the built in sort.Slice is more flexible for dealing with various types of sorting, but my code has 2 advantages: 1. For large slices, you are not actually sorting the data (you could also pass slice of indexes to sort.Slice) 2. If the code that returns the sort key value is more complex, probably have less coding 
This code seems suspicious to me: if !w.StaffActivityTimers[username].Stop() { &lt;-w.StaffActivityTimers[username].C } since it won't be able to go past the channel send until it is read (assuming non-buffered channel) and the read won't happen until another for loop iteration
Those three lines are according to godoc, do you know any other way to reset a timer? https://golang.org/pkg/time/#Timer.Reset
I'm learning Go and Vim. Playing arround command line feels awesome but sometimes i need to check my tasks and i wouldnt wanna go to another app and leave the cli. I made the td for myself, I'm using it with tmux and right now seems okey to me. I know there is lots of todo tools for cli but like i said. I'm just learning.
What's your favorite language?
About gocn.io: I found a link in its source, looks like a service http://www.wecenter.com/
Gorilla's [sessions](http://www.gorillatoolkit.org/pkg/sessions) package should be a good fit. It defines a `Store` interface and comes with implementations for cookies and local filesystem, but you can plug in any store you like such as [redis](https://github.com/boj/redistore).
Not 89$ if I use it for non opensource software. The license is 199$ per year for commercial use - which might be OK for people who use all the features but I just need the code navigation and inspection occasionally. There should be a community edition just like their Python IDE does, otherwise Goland is going to lose fringe users like me. 
As others have said, find a problem you want to solve, or something you want to do and use Go to do it. You've been a systems administrator so you're familiar with the design of UNIX, scripting and time zone problems. You're also familiar with config files and automating stuff. Go is really good language for system administration. In fact, of late, I've been writing t scripts in Go because they're so easy to write and use. Here's why you need a problem to solve: While a tour or tutorial will help you dip your toes in it, to truly get an appreciation for the thought that has gone into the language, you need to write something and then change it several times. Go is a language designed in the service of software engineering. The language designers really have thought about dependencies, compilation time, distribution, cross platform support, networking standards, concurrency, etc. Yeah it's fun writing code in Go, because they've done the hard yards for you. But that's just the beginning. It is actually a productive language with beautifully thought out interfaces and respect for the existing standards. You are right though. Most resources are directed at experienced programmers getting started with Go. Even more reason to solve a problem - you get to break the problem down into pieces and finally Google how to implement each step in Go. It's during the implementation and tying everything together that you will begin to also learn about good design and clean interfaces, because Go will push you in that direction. And all learning is part of the fun. I know it's probably not the answer you want, but it's worth the effort and it's actually a really enjoyable experience. Personally, after programming in Go for a few years I've started thinking about problems differently and I've found it has helped me come up with solutions faster.
It's impossible to say whether you're doing "it" right because "it" is insufficiently specified. This appears to be password related, which puts us in the secure code domain, but you don't specify what your passwords are going to be used for, what they are protecting, and what your threat model is. That said, I doubt this is right for a couple of reasons. First, you appear to be confused about why one would iterate a lot on a hashing function. This is usually done by an authentication server to store a user's password hashed with an expensive function, meaning that even if someone gets a hold of the hash and the exact algorithm used to compute it, it will be expensive to throw millions or billions of password crack attempts at the hash. I see no compelling reason to iterate on the _password_ side for so many iterations; if someone gets the seed values, the passwords will get cranked out very quickly. Secondly, the most likely reason to be writing code like this would be to be writing a deterministic password manager, which is a [bad idea on its own merits](https://tonyarcieri.com/4-fatal-flaws-in-deterministic-password-managers), regardless of how you choose passwords. If you want to generate secure passwords, I'd recommend code [like this](https://play.golang.org/p/wwNynpz4L_V), which I actually use to generate passwords. I was very aggressive in cutting out visually confusing characters because people overestimate how much entropy that removes from the passwords; that code generates 5.5 bits per character. Note the Playground will show you the same passwords every time due to various oddities of the Playground itself, however, this uses the cryptographically-strong random number generator on your PC. If you run that program on your own system it'll generate different passwords.
hum... digging through the forum a bit (and using google translate), I grabbed: - https://github.com/shen100/golang123 - https://github.com/huacnlee/mediom 
This section doesn't make sense: if !w.StaffActivityTimers[username].Stop() { &lt;-w.StaffActivityTimers[username].C } Per the documentation on `Stop()`: &gt; It returns true if the call stops the timer, false if the timer has already expired or been stopped. So your code is saying: stop the timer; if the timer was already stopped or expired, then wait for the timer to fire - which will never happen, by definition, causing it to block indefinitely.
&gt; Is it possible to have multiple senders into a single channel? Yes. There is nothing about a channel that binds it to a "sender" because there is no real notion of a "sender". Anything with a reference to the channel (other than a receive-only directional reference) can send on it.
It's fun playing around with this kind of stuff, isn't it? :D Currently there aren't any header information stored. If the file in the cache is an image, you are even able to open it with an image viewer. But that might be a feature which can be useful, that's right. I don't need it so far, but maybe someday someone will implement this ;)
&gt; use a pointer just to avoid the copy This seems like low-hanging-fruit for a compiler. Have you measured a difference and has it remained the same over time? I did a small test just see if they compile to equivalent code -- they don't. Sticking a * in the receiver led to significantly larger asm output, but I didn't spend any time into understanding what the actual difference was. i.e., I couldn't judge whether it was better or worse, just not the same. This is a little surprising, though. Given no field mutation, there's no reason to treat the two paths differently.
You know him as much as I do (I don't know his abilities and you don't either) and you give him an baseless assurance while I baselessly doubt his abilities. But you call me an idiot. Aren't you indirectly calling yourself an idiot too ?
per the faq, you can use the personal license for commercial use. But if you buy a personal license, a company isn't allowed to finance/refund/whatever it for you. [link1](https://sales.jetbrains.com/hc/en-gb/articles/207240855-Can-I-use-my-personal-license-at-work-and-at-home-) [link2](https://sales.jetbrains.com/hc/en-gb/articles/207240855-Can-I-use-my-personal-license-at-work-and-at-home-)
I mean not already implemented package. I look https://github.com/boj/redistore for backend store, it saves sessionid and json data. But also I need to implement link between sid and user_id to track active sessions in order to deactivate previous logged user sessions. I thought maybe there is package with similar mechanism or close
&gt; Go is a language designed in the service of software engineering. Exactly.. You don't become an engineer by learning Go.. you become an engineer and then you learn Go.. But God forbid to tell this to the script kiddies &amp; javascript brogrammers.. 
I recommend starting with [this](https://www.schneier.com/books/applied_cryptography/) instead.
Cool I'll go through that
There's a level of background knowledge I think helped from my time in college doing basic computational fundamentals, so I could really connect the dots between what the computer did, what my code did, and the various iff/and/nand/nor etc gates and active memory and all that stuff. I think a good cheat to get you up and running would be to go audit a DSA class (Data Structures and Algorithms), which is/was kind of the shit test of 'can you be a real programmer' and introduced all the different things you need to use- since C-like languages are so big, a lot of these have just become object oriented programming classes (there's other paradigms, eg, functional programming, and go is a non-objective language that's kind of a bit more bare-bones than objective languages like python or java), so this can be a mixed bag, but if you can understand objects, functions, data, conditional statements, loops, and in Go things like concurrency and channel controls and synchronized data writing and reading, and for bonus points pointers (which call by value, or call by reference- the way I keep it straight in my head is by imagining them as post-boxes at an apartment complex, and you either reference whatever is in the post box, or you reference the message that's in it, but the two are separate because the message can have an address of a different post box on it, pointing you to a different box with different letters in it), you should be fairly well set to do whatever you want with the language.
If I had to guess because a majority of their (CoreOS) products are written in Go, like rkt and etcd. 
I'm not sure what this is likely to mean, any insight why you are disappointed?
Fun wouldn't be the word I'd describe, but it's definitely been a learning experience! I'll need to play around with S3 to see how that performs, if it can save some metadata information like content-type then that may put me in a good spot. For the life of me I can't figure out how to correctly get byte range videos to be processed correctly through the application in Chrome. In Firefox it works fine, but Chrome doesn't know how to read the information correctly or something.
The key thing is start small. Get a very simple program working. Add a feature that uses a new concept. Add another feature .... When you run into a concept that is confusing, research it and get it working. 
People have already mentioned GoByExample and the tour, which are great resources. I also agree with finding a problem and solving it to practice. Once you've got to grips with the language basics* though, definitely check out [JustForFunc](http://justforfunc.com) - brilliant code reviews and projects-from-scratch that help intuitively explain certain patterns and concepts. *not necessarily interfaces and channels/concurrency, I believe you can pick these up via the justforfunc videos without needing much precursor knowledge. And of course this subreddit is a great place to ask questions and ask people to explain certain patterns and concepts! There's also the Gopher slack, GolangBridge forum and the Google newsgroups page.
That's my issue with anything and everything subscription based. Different projects often require different languages. I might not touch Go (or whatever language) for months. Photoshop is the same. I used to be a full time designer, but these days I only use it once a month, if that. I realize piracy was a massive problem for them, but still. Luckily my old license from pre-subscription days still works.
If you read that, make sure you follow it up with Secrets &amp; Lies, also by Schneier. It‚Äôs sort of a sequel where he talks about what happened when his ideas met the real world. tl;dr; no matter how good the crypto is, there are many more systems and human problems that undermine the theoretical security. 
This does not apply directly to your case, but many times I've gotten a "wow! you must be really smart to be able to do software development. that's so hard." And what I'm generally thinking is: I read a lot. It doesn't really take too much smarts, it just takes time to learn stuff, and if you're not willing to put in the time, you'll never learn anything. IMHO, *reading* is the key. Having said that, I actually would recommend _The Go Programming Language_ by Donovan and Kernighan. Yes, it's kinda geared towards experienced programmers, but the thing is, if you take the time and work through everything in that book, you'll be a go programmer. By doing this, you'll really absorb _the go way_, rather than just doing the same old programming with go syntax. I'm going to second the suggestion to pick up a data structures and algorithms book. If you want to be _a real programmer_, that's the ticket. Once you've mastered go syntax and stuff by doing the D&amp;K book, you should be able to pick up almost any data structures and algorithms book, regardless of what language it's targeting, and get through it. You'll have the choice of doing the exercises in that book's language, or continuing to learn go even better by implementing stuff in go. (For a real beginner, I would not suggest this route. Since you already work with computers, and given that you're familiar with scripting, you already have enough fundamentals for what I've laid out here.)
I'm not @SeerUD but for my little servers I'm using CoreOS's Container Linux on Digital Ocean and this announcement suggests that Container Linux will be abandoned. So that's disappointing as Container Linux is good for my use cases.
Honestly, Go is not the best language to start from. Go is cool and all and solves a lot of the issues people have with C++/C#...compiled languages in general. Plus it's fun to write but does have a STEEP learning curve unless coming from a low level language already. I would focus on Ruby or Python but being very proficient in BASH is another must have. 
So, are you saying I don't need those three lines? How else do I reset an expired timer? I just deleted them, the result is the same, something blocks right of the bat ...
&gt; The code is‚Äîlet us say‚Äînot yet production ready. &gt; &gt; Please start with studying this. I already tested on several os and it can write and rewrite. &gt; Then I would recommend thinking about what happens if I do &gt; $ td Foo^v^jBar^v^jBaz &gt; (where ^v and ^j denote Ctrl-v and Ctrl-j inputs). You're right about that. I will check it out. 
Nah he‚Äôs just a troll that lacks talent. Nbd
If you want to learn as you go, try out the (cryptopals challenge)[https://cryptopals.com] in your language of choice. You don't need to know a lot of math to complete it. &gt; I'm really into cryptography and maybe finding a job involving that. You DO need to know a lot of math to do this. Crypto courses are often taught at graduate level. Check out [some of Stanford's current crypto projects](https://crypto.stanford.edu) to get an idea of where you'll need to be.
There is one major distinction here, with any JetBrains license you pay for more than 12 months (so a year), you get to keep the IDE after you stop paying for as long as you want, it's yours. If you only need an IDE for a month, you can only pay for a month, if you plan to use it for longer, getting a 12 months subscription, gets you a 2 months discount as well. And as I've mentioned earlier, you can also get a free license in some cases as well as get discounts for various others. And on a different note, if you need an IDE that covers most of the languages, IntelliJ Idea is a the right choice. However, the downside is that it will be a bit slower, have more Java related menus, and overall less focused on only a certain language features, like GoLand or PyCharm are. That being said, I can totally understand you on this. I hope this helps you or someone else reading this.
This: https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1 is a good read for package layout tips. The TLDR is break up your subpackages by dependency and keep the main structures and interfaces for whatever you're doing at the top level. main.go almost always goes in a subpackage under a cmd/ directory. I like to develop everything as a library and have my main.go be about 4 lines just calling into it.
&gt; You should use a pointer when a pointer is appropriate. The reasoning involves semantics first and efficiency second. Big things are slower than small things. Indirection has a cost. Tradeoffs exist. &gt; Rob Pike ([source](https://groups.google.com/d/msg/golang-nuts/INedfATw74A/gmba8leWCeEJ))
This. The streams have been phenomenal so far.
&gt; I can only afford a timeout value of 10ms. I've got a fiber connection to the Internet, and I can't get a reply back from my nearest nameserver any faster than 13ms... and that's in near-ideal conditions. How do you expect this to work?
I am not a coder by any means but I have enough to get by. Working on my bot has gotten me further along. With the 2 responses I have gotten so far the other one is what I was looking at. Yes I get that I am asking on reddit. I was also hoping for a bit more formative help here. Not a snarky response. I have been reading all I could online to try to figure it out. You have no idea how long I have actually spent on this.
It's something that I've considered in the past too - I haven't been particularly impressed with some technical aspects of Discourse (iirc, how they deal with containers and db updates at the time). A forums-as-microservice application that can scale, run on kubernetes and perhaps be globally distributed (cassandra/dynamodb?) would be cool, as well as decoupling the presentation from the API and using some stuff like webcomponents (to throw out a laundry list of things that don't necessarily have end-user value).
Actually as European it its 89‚Ç¨ which is 110$ + 20$ tax. ;)
I‚Äôm on mobile, but wasn‚Äôt there a sysadmin guy who was a big fan of Go for systems administration? His stuff might help you get familiar with the language solving problems you‚Äôre already familiar with, and from there you can transfer into a more straight-code role. 
I consider myself to be fairly proficient with BASH and have tinkered with Python now and again, but never seriously. My 9 year old has Coding for Beginners Using Python and we've been doing it together.
‚Ç¨89 eur = $110, not $130. If you think they should pay the VAT, not you, then I guess they disagree with that. And in Europe you are paid in Euro not in USD, which I think it's fair. If you are not happy about this, please write to their sales department ask why this is happening.
You're asking something so fundamental, I get the impression you haven't spent any time with the materials that so many have worked to help people like you. &gt; I have been reading all I could online to try to figure it out. "trying to figure something out" means you're experimenting with your own code, or with someone else's code, or reading the source, scouring the language and library documentation, doing a heck of a lot more than tooling around with google. Poking around online is only going to lead you down rabbit holes, and you won't even know if you're solving the right problem. And here you are. I'm pretty sure you're in the wrong rabbit hole. And unless you share your problem with us, we'll never be able to help you. You might get unstuck here, but that's no guarantee you're headed somewhere that won't get you even more stuck.
SDL2 - yes we use it in stream a lot. Vulkan - no experience, I've only used opengl 
I am talking about the point, that the pricing from USD to EUR is just 1:1 nominal copied, which makes no sense at all. You can consider currency fluctuations but 20 bucks more? Vendors have a MSRP, which is USD. No vendor would "charge" us the same nominal value for a product.
&gt; I am talking about the point, that the pricing from USD to EUR is just 1:1 nominal copied, which makes no sense at all. You can consider currency fluctuations but 20 bucks more? &gt; &gt; Vendors have a MSRP, which is USD. No vendor would "charge" us the same nominal value for a product. It's not just JetBrains, almost everyone else that I can think of does this, see https://i.imgur.com/9g3IYhj.png for example :)
Awesome, I'll check out your stream! Have you noticed any overhead using the SDL2 bindings?
Yes, almost a century ago (god i am old) this was pretty exploitable, too. You could order electronic downloads from US websites, pay per credit card for cheap USD and without ever seeing the word "VAT". Even Lufthansa.com had cheaper flights than Lufthansa.de, till they closed this loophole ;) To come back to the topic, Golang is a nice product, go buy it! And to tell a funny story about Jetbrains. We once colocated a private server of a Jetbrains employee from St Petersburg in our datacenter. This guy was being relocated to Munich and because he was afraid of flying, he drove the whole way from Petersburg to Munich including fairy over Denmark or something with his car, so funny! Thats 2200 km + :D When I hear Jetbrains, I always need to think about that one guy on the road. 
Is there any particular reason you need it to be Golang based? Elasticsearch is pretty wonderful at what it does already. Elasticsearch is more of a clustered solution - intended to be run across multiple nodes, and agnostic of whatever language your primary application uses. Elastic does have [an official Golang API as well](https://github.com/elastic/go-elasticsearch). I know nothing about Bleve, but at first glance it does not appear to be quite the same thing.
Wow! You've really got me there.
Surely superficial attributes are the worst proxy for perspective diversity. If you want different perspectives, consider geography, income, religion, political beliefs, etc. Whenever people focus on superficial traits, they end up with a group of people who look different but think the same, and they pat themselves on the back for their "diversity".
You should clarify your README. You readme says that it uses the Aho‚ÄìCorasick algorithm. However, you also say that it's an reimplementation of the FlashText python module. That module uses the FlashText algorithm which is based on Aho-Corasick but it's not the same. If I can cite the research paper itself: &gt;This algorithm is much faster than Regex (see Figure 1 &amp; 2), because regex time complexity is O(M * N). It is also different from Aho Corasick Algorithm as it doesn‚Äôt match sub-strings. https://arxiv.org/pdf/1711.00046.pdf
Pretty much in the same boat. I'm personally trying out VSCode. Already ran in a few problems but in a few months I will have made my mind whether or not to fend the price for GoLand.
Damn. I haven't watched that episode yet. Will do so tonight! Thanks
Visual studio code is an awesome replacement for free. I‚Äôve been using it since jetbrains kicked us off and I haven‚Äôt looked back. 
Must eventChan be a single channel? Why not use a chan per behavior? https://play.golang.org/p/GWNOhA80hdg It seems that if one would need to create a different type at the time the logic is kicked off, it wouldn't be much more to send it down a particular pipe and avoid a bunch of complexity that can still panic if "a pattern is missed" (https://play.golang.org/p/sbD-rlQv6sL). Though, I am still all for union types with pattern matching. Apologies if I've misunderstood anything.
I keep hearing about how Go is big in China, but I almost never see any speakers from the PRC at the conferences I pay attention to. I wonder if their problems and problem-solving approaches are similar to ours in the West, or if they have interesting differences from our usual approaches.
There are only like 4 calls per frame into SDL2 in our game loops at the moment. You have to start approaching 1000 before C call overhead is much of an issue. 
That won't work if you need strictly serialised events. [Select will chose an available `chan` at random](https://tour.golang.org/concurrency/5) to consume from. The alternative would be to "fan-in" from your typed channels. I think you may need to use unbuffered channels (for the typed channels) and sacrifice performance. Additionally you can keep the channel private and write a dedicated function receiver for each type - but then your API could grow pretty large. Polymorphism could help, but that's pretty much a the same thing as sum types - arguably not as flexible. As the author notes at the end: &gt; Fortunately, with a slight change in the way of thinking, we can find decent alternatives. Unfortunately there isn‚Äôt one technique that is objectively better than the others. It‚Äôs a tradeoff between type-safety, complexity, and verbosity, and the ‚Äúbest‚Äù approach will depend on your use case and personal preferences.
I thought that was a given with "a company I am working with". Let's let the mods decide :) 
Ask yourself then why C++ has std::array in addition to std::vector 
I don't plan on this being a regular thing - just reaching outside the box for this particular one! Glad to be here. 
Nice. I'm thinking about doing it at school when I get to graduate school 
Man, what a smug, arrogant, and tactless set of remarks. There was no need at all for you to be an asshole, yet you were anyway. Good job. 
&gt; If you want different perspectives, consider *geography, income, religion, political beliefs, etc.* It is so refreshing to hear someone else say this.
Good article. I'm not happy with any of the approaches, to be honest; they obfuscate more than they provide utility. I'm in a situation right now where sum types would have been extremely useful. We have a project that operates on structured, schemaless JSON data -- where all the data is provided by the caller of the API, the app doesn't know about its contents -- where there's tons of code to work *with* the data. Since JSON only supports a handful of data types natively, it means that every method that works on the data really only needs to care about strings, floats, etc. But it's impossible to *guarantee* that they're covering all the cases, and doing it correctly. Since the data is just `map[string]interface{}` at the root, it means every function that works with data needs to work with `interface{}`. I'm hoping to improve this with a sum-type-like approach, either by declaring a type such as `type Value struct { value interface{} }` and then forcing everything to operate on that, or creating an interface similar to the one in the article. It's possible that visitors will work here, though I don't love the idea.
I'm interested in this as well. Mainly, I'm trying to purge the fat off my machines, and getting rid of Java follows closely after eliminating Mono.
OP compared it to UUIDs, yet didn't explain how it's a replacement for them. OP's solution and UUIDs solve different problems. I felt that, given the similarity between the two terms and since they're being compared, it would help others visiting the thread to understand the difference. I didn't intend to be a jerk, I merely expressed what I hoped would be taken as a mix of constructive criticism (i.e. explain the use case over UUIDs) as well as a warning to others. I didn't intend to detract from OP's work. The fact that my comment is somewhat highly upvoted tells me that others thought the same way. I suppose I could've sugar-coated it somewhat, but I honestly meant nothing negative at all.
He only mentioned one specific attribute (being a woman), and non-exclusively. If you think that's "superficial" then you're relegating all the other things you mention down to a vanishingly small significance.
This is what I've decided to start with. I've tried to slog through the Go Tour before, but I have enough background that the basic basics become very boring. I know what variables and for loops are, so its very dry. Go by Example so far is very efficient at progressing me through what I already know, hope to get to new stuff soon, but I want to start at the beginning and make sure I know what I think I know.
I have gone about 50% through Todd's class on StackSkills, but I find his mannerisms a bit distracting. He's giggles frequently and goes off on a lot of tangents. I should go back to it, though I'd probably have to rewatch some stuff since there's been a few month gap.
Watched this, didn't help with my skills any, but it was very engaging and gave me hope! 
"especially more women and others underrepresented in the Go community" "others underrepresented" covers everything you've mentioned. I get that with articles people sometimes read the headline, make an opinion about what it says and then skip the actual content. But this is a god damn tweet. Was it really so taxing to read the part after "women". 
It would not be the first time I disagree with Rob Pike and I doubt it will be the last. That does not scare me. Further, I'd point out that he just alludes to semantics without specifying what they are in that quote, but when you said "does not modify the struct", that's an oversimplification that does not match Go's semantics. Structs "passed by value" can end up modified, and if you code as if that can't happen you're in for some very hair-pulling bugs, especially if you think that you "passed by value" across a goroutine boundary and concurrency gets involved. I'd be interested in hearing what Rob Pike is thinking of when he says "semantics" here, because to my eye, Go's semantics aren't clean enough in this area for there to be a great difference between the two. It's not like Haskell where mutability is very strictly controlled, or Rust where it is strictly controlled and labelled; in Go it's a rather complicated mess of having to discuss what exactly is in the struct, how exactly structs are embedded if they are (pointer vs. not, and the problem recurses down as you do more embedding), and you also have to bring in what a "change" is under Go's semantics, all of which is a very pragmatic and not terribly clean set of rules that felt pretty good to a very experienced and senior engineer at the time, but don't have any sort of terribly precise driving logic behind them.
I don't strive for 100% coverage, but at least glancing at the coverage graphs when I think I'm "done" with a module has become routine for me, because I find they almost always have three or four useful things to tell me about my tests per module. (And I tend towards small, contained modules, so that's a pretty good hit rate!) These useful things include things like "Gee, I thought I covered that bit of functionality but that entire chunk of the module is red", "Huh, I guess no matter what I can't cover this 'else' clause, so I can delete it", "I was really sure I tested that error case but it's still showing uncovered", and rarely "Wait, what, that was covered in this test? What's it doing in _that_ bit of the code?" I don't have a recipe for what you do when you learn these things per se, for instance, sometimes I discover a big thing I thought would be covered isn't and it turns out that's just the way it's going to be, but I always learn _something_ about my code I didn't expect.
I'm getting mixed messages...gender doesn't matter, people are all individuals with different ideas and backgrounds...but gender does matter for diversity (because everyone of the same gender shares the same ideas and backgrounds that people of other genders do not?)
Yes, I do. It should restart whether it's still ticking or not
I think that is a fair comment. But at the same time, I have been in training with really robotic trainers that create 30 minute videos, that make you wanna fall asleep. I accept a real person with mannerisms over a robot. Just sayin....
&gt; Do you use full coverage unit tests Full coverage is an ideal situation that is hard to achieve. Your tests may bloat in the attempt to cover each and every branch in your functions. Also, covering all *execution paths* does not guarantee that the tests cover all *test cases*. (Read: Any given execution path can be covered with a lousy test just to shout "full coverage!") Having an eye on the actual coverage of one's tests, however, is always a good thing. &gt; Do you guys include benchmark tests for every function? Absolutely not. Writing performance tests without having a performance problem is a waste of time IMHO.
What I think Rob is saying (but I could be wrong) is that we should try to write simple, clear, predictable code first (optimize second) in which case the semantics start carrying much more value. It would certainly be nice if the language enforced those semantics somehow but at the moment it doesn't. &gt; Solution #2 is specially recommended if copying your value is too costly. What is problematic about the above sentence is that we are notoriously bad at judging if copying our values is too costly. So what I am suggesting is that on the choice between a value and pointer receiver, optimization should be our secondary thought, not the first.
If it helps you be productive, great. But don't forget to donate to all those people that wrote the tools on which it relies on, as they've put countless hours of hard work into them and I'm fairly sure they would appreciate it.
&gt; We have a project that operates on structured, schemaless JSON data -- where all the data is provided by the caller of the API, the app doesn't know about its contents -- where there's tons of code to work with the data. Can you give a few examples? Maybe there is a solution that does not include `map[string]interface{}`.
https://media.giphy.com/media/bWMnFC6BvMj5K/giphy.gif SRSLY though, this is gross.
You can take a look at - https://github.com/icza/session for a simple package. the in-mem store is included. You just have to implement your own store.
[Clean architecture in the context of Go.](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1)
SRSLY, why?
The correct reaction to an "unused variable" error is to either use it, or remove it. Not to make up crude hacks to circumvent it.
SRSLY, have you bothered to read the thread?
An interesting article about [cleanarchitecture on Golang](http://manuel.kiessling.net/2012/09/28/applying-the-clean-architecture-to-go-applications/)
Yes. Please don't assume ignorance just because I happen to disagree with you. It is perfectly possible and reasonable for two parties to come to different opinions, when presented with the same information. For example: I don't believe I could add any information here that you are missing, but apparently we still arrived at different opinions. I thus conclude that we simply disagree and will move on.
It was reasonable to assume you haven't read the thread, because you're complaining like this &gt; The correct reaction to an "unused variable" error is to either use it, or remove it. Not to make up crude hacks to circumvent it. which is in no way happening. The thread clearly says that &gt; You cannot forget the use invocation in production code as it is defined only when `go test` is building the program. The OP wanted tips how to solve this problem &gt; If I'm trying to debug something by commenting out lines, or if I'm hacking up an experimental script (meant to run with `go run`), I find this checking is very unwanted. For example, if I comment out one variable, it may lead to a new set of variables being unused, which sometimes leads back to a package being unused. It's not uncommon for this cycle to take 3-5 iterations, in my experience. The hint solves in a more easy way what the OP currently is doing *while not* doing what you complain about. The hack cannot be left accidentally in the code, the code does not build at all outside `go test`. 
There are too many architecture. So which one I must follow ?? 
&gt;&gt; Please start with studying this. &gt; I already tested on several os and it can write and rewrite. I had no doubts you tested it and it worked. What you did not test is what happens if your process managed to write the first half of the data into the file and then the power cut off. The way you rewriting a file displays the lack of basic understanding of how this stuff works (OS-wide that is), but I doubt you even bothered to explore the provided pointers. Still, I mildly insist on you doing that‚Äîof course, if you ever intend to do programming for a living, not just toying around.
Such a large number of stars, this is a big responsibility. It seems to me, it's not easy.
at the risk of sounding rude. ``` // file: /u/TheMerovius.go use(SRSLY, click, eyes) ```
 _ = holdon // TODO What am I missing? https://play.golang.org/p/zyVANRQ3AYJ
Your proposed solution would solve the unused variable part of the problem; however, the snippet in the OP has the nice additional benefit of also breaking non test builds. This forces/encourages you to remove the use blocks when you're done debugging. The reason for this is that `use` is defined in a `_test.go` file, so the function call (and therefore the temporary usage)like willy work when building tests.
They're good points, but I don't think they're not heard about much. If you're looking into Go, you will hear a lot about it's learning curve, tooling, performance, and amazing standard library.
Welcome to Go! I hope you enjoy the language as much as I do! While this subreddit is pretty active, you do not need to worry about posting your learning questions in a learning go subreddit because we don't have quite the mass traffic of the Python subreddit.
Then yeah, this code doesn't really make sense. A select with only one case and no default is pointless - either add a default if you want it to be non blocking, or get rid of the select if not. The stop-then-receive also doesn't work - if you want to reset it whether it's fired or not, just use Reset without the call to Stop.
I wrote a simple forum web app in go. It's nowhere near discourse though... https://github.com/disintegration/bebop
Thanks for your response! I think you are right. But, as you said, people usually hear about those abstract things like "tooling" or "performance." I just wanted to be a bit more specific on some of them because I *felt* people overlook a lot of quite essential details.
Fair enough. He was vague, so I welcome clarification. In any case, my criticism of the prevalent cultural tendency stands whether or not it actually applies to Russ.
&gt; "others underrepresented" covers everything you've mentioned. In America this is a popular euphemism for specific groups defined by superficial traits. If Russ meant something else, then my criticism doesn't apply to him, but it stands for the broader cultural tendency.
Yeah, it is important to remember that the domains that programmers work in is a huge space, and the types of workflows are thus also a huge space. It is always presumptuous to assert "the correct reaction to X is to Y" because you may be speaking to someone working in an entirely different universe than you, where Y could have downsides you aren't imagining. Even if you have 50 years of experience, none of it may overlap with the domain of another person. 
Previous post was false - I forgot that each sprite drawn calls renderer.Copy. So at 10,000 sprites I'm still getting ~400fps so overhead isn't that bad. If it became a problem you could write a short C function to accept an array of sprites, so that you could batch those calls. That is generally the solution to GC languages calling into C -&gt; batch the work up as much as possible. 
It clearly took some time to build it since the API is so extensive, but the [GoDoc](https://godoc.org/github.com/rivo/tview) page is still easily followed with each T having a clear purpose. I'm glad the author is dedicated enough to the project to adapt how they maintain it for the greater community, good stuff.
cgo would be the way. I think at some point in the stream we will make our own C function and call it from go. I want to teach simd intrinsics and C is the only way to do that well still. The function to batch up a bunch of calls to sdl's renderCopy is really simple, *but* if you are drawing tons of sprites you probably want to use opengl anyway, as SDL doesn't internally batch things to the GPU, so opengl would still let you do it more efficiently. Which would eliminate the need to do this at all. 
&gt; And that‚Äôs it! All in all, including comments, the code is less than 300 lines. If it seems pretty short, you should remember the original entire compiled binary ROM for the game is less than 110kb in size, including images and music! 110kb in 1978? I'm pretty sure Space Invaders was more like 8k.
I found the culprit. It blocked because I didn't `make` the channel. Thank you for your help
I was going to let it go, as promised, but apparently the reddit mob doesn't like civil disagreement, so let me illustrate with a perhaps more relatable example: If A asks for parametric types in Go and B responds, that by using sed at compile time and unsafe at runtime they can produce any flavor of generics they want, then a) this would be 100% correct and solve A's stated problem and b) it would not be unreasonable or wrong to hold the opinion that it is a gross solution. It would also not be unreasonable to tell A, that instead they should try to come up with a solution to the problem that does not require parametric types, to help them through a design that is more Go-like or to suggest that they might be happier using a different tool for this job. I was expressing an opinion about the proposed solution; solving the stated problem doesn't make it non-gross. Again: You don't have to agree with that solution being gross, but I will not accept that it's an unreasonable opinion to hold or to express, or that it implies that I didn't read the problem (in fact, it's a valid opinion even if I had *not* read the original problem statement, as it's an opinion about the solution). These insults are completely unwarranted.
(author here) I guess the "forbid methods" thing would work. Though really I was thinking of making the methods only work on interface objects. Yes, writing it as enum makes more sense, then, but I was hoping to make it seem natural. The intent was not to push for anything, more to just pen down some thoughts I've had from prior discussion. One of the main complaints I've seen in discussions I've and about this is that it's a rather foreign-sounding feature that changes how Go types work. This proposal attempts to work with that by extending the existing interface functionality (especially type switches) a bit. And yes, there are still arguments against that, which is why I'm not actually pushing for this. Just putting my thoughts out there in a slightly more structured form, partly for my own convenience.
The culture seems to have been tainted by Google's overt racism and sexism.
&gt; One of the main complaints I've seen in discussions I've and about this is that it's a rather foreign-sounding feature that changes how Go types work. That is not really my perception. I believe basically everyone in that github issue you linked to understands the feature and its uses just fine - calling it foreign, I think, doesn't do them justice. On the contrary, one of the main arguments from my reading is, that it is *not* foreign, but indeed seems to be mostly a subset of (or at least have very large overlap with) interfaces as they are. &gt; This proposal attempts to work with that by extending the existing interface functionality (especially type switches) a bit. The problem though, is that you are only doing that on the surface. You are overloading the existing syntax, but if you peek behind that, the semantics are not really an extension of interfaces at all. The inability of attaching methods to foreign types is very fundamentally linked to the design of interfaces, so if that'd be possible, it would go squarely *against* the interface design. But if we leave that out, there isn't really a lot left. Like, tell me how that isn't just *exactly* what was proposed in the [first message](https://github.com/golang/go/issues/19412#issue-211995124) of that thread.
I'm not talking about the folks in the GitHub issue, I'm talking about folks who I've spoken to. And I wasn't saying that they don't understand it -- everyone understands it fine -- I'm saying that folks find it rather "un-Go-y" if that makes sense. As in that it would be an additional hurdle for learners and didn't really fit in to go. Sure, it's close to what's proposed in that first message, but more fleshed out. I should edit my post to address the methods thing, I hadn't thought about that much. I personally don't find this to be too against the interface design. I find the method limitation to be an effect of the design, not a goal of it (I feel similarly about Rust's orphan rules). Again, the intent of my post was not to push this; more of to just get something that I've often explained to people written down so I can refer to it and others can build on it. I get that it's similar to stuff that's come up before.
mac iTerm only
I think if they really want more diversity they should stop being so 'opinionated'. You know who you are.
Also, just came across this on the gopher slack this morning: These articles will explain how to organize your Go packages: - https://rakyll.org/style-packages/ - https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#.ds38va3pp - https://peter.bourgon.org/go-best-practices-2016/#repository-structure This article will help you understand the design philosophy for packages: https://www.goinggo.net/2017/02/design-philosophy-on-packaging.html
No reason to wait... everything you need is available online!
True, I'm just trying to get really good at python and get a linux certification atm while balancing school and work. I've been going through Cracking ciphers with python and that's been lots of fun
&gt; To me, the most difficult of such rejections is for pull requests. This is maybe the hardest skill for OSS maintainers, trying to walk the line between inviting contributions without bloating the library. It's hard but totally worth it. Best of luck!
&gt; new perspectives I'd like to see speakers with headlines that make me think "You could use Go for that? I mean, sure, technically you could, but is that _really_ better than the alternatives?" Some ideas, however long: - I Write 200-Line XML-Munging Scripts. Here's Why I Ran Screaming from Python's eTree and lxml2 and into the Loving Embrace of encoding/xml - Gone In 16 Milliseconds: Yes, You Can Write Programs That Maintain 60 Frames Per Second
http://www.computerarcheology.com/Arcade/SpaceInvaders/Hardware.html Memory Map 0000-1FFF 8K ROM 2000-23FF 1K RAM . 2400-3FFF 7K Video RAM 4000- RAM mirror
The biggest proponents of sum types seem to be people who want to use them for error handling. How would this proposal help with that?
[removed]
You were even more vague. You haven't mentioned a single "superficial trait" that you're concerned about stealing the show.
&gt; It's a document store. API receives JSON documents for indexing, but they don't have a schema. So the store has to be able to deal with any JSON. It might be because I do not understand the problem domain very well but from what you said, it doesn't sound like you need `interface{}`. Check out how [boltdb](https://github.com/boltdb/bolt) does it.
BoltDB only deals with `[]byte`, doesn't it?
If you go through the first few SDL videos here: https://www.twitch.tv/jackmott42/videos/all You could easily adapt his space invaders and make it cross platform, use the GPU etc. 
Interesting. Writing a space invaders clone was one of my first Go projects too. Writing a game is a great way of learning a new language. I added the twist that I used my wife's little sisters school photo as the alien (she hates that photo and we do tons of little projects with it to annoy her). I didn't go for minimal footprint and implemented the game with SDL, sound and some flashy start and end screens. All in all 1k lines of code. The compiled binary comes in at 2.5M, nowhere near the footprint of the original. https://github.com/MichaelThessel/lileinvaders
I did no such thing. I mentioned superficial traits generally, and my concern wasn't about "stealing the show", it was that superficial traits are (by definition) bad proxies for perspectives. I was very clear about this. I'm perfectly capable of making my own bad arguments, please don't make your own and attribute them to me.
So you're just stating a tautology that superficial traits exist and are poor proxies for diversity? If so that seems to me like a strange thing to dedicate so many words to on reddit (unless you're trying to derail), and that's why I'm curious what kinds of specific diversity focus on superficial traits you're concerned about.
&gt; BoltDB only deals with []byte, doesn't it? Yes but you are free to store any document, for example you could use `json.Marshal` to store JSON or you could use `gob.Marshal` to store gobs.
Relax man. People do things differently. Drop the gopher juice.
dupe: https://www.reddit.com/r/golang/comments/7ulivf/security_go_187_and_go_194_preannouncement/
Beat me by seconds :D
Try to just import `sync` and add the two following lines at the end of `main`: var wg sync.WorkGroup wg.Add(1) wg.Wait() 
[This article series might be of interest](https://www.ibm.com/developerworks/cloud/library/cl-ibm-blockchain-chaincode-development-using-golang/index.html).
So where is your "experience report"? hum /s Like one can write an experience report about a feature that doesn't exist at first place ... "you don't need that with Go, see you're doing just fine without it right now..."
Awesome sauce 
Come on man, did you even read your own article? :P The second word is a typo! Fuzzing is great to know about though!
I think you may benefit from a simple change in the way that you represent your opinion: &gt;The correct reaction to an "unused variable" error is to either use it, or remove it. Not to make up crude hacks to circumvent it. If you're making the argument that you're putting forth a contrary opinion, you might benefit from prefixing a statement like that with something along the lines of "I believe the correct...". By simply stating "The correct ...", you're putting the issue in the realm of objectivity rather than subjectivity - at which point, it ceases to be communicated as an opinion, but rather a statement of fact. I think it's a very common issue in the go community, which I think generally takes subjective opinions to the realm of dogma. I think it's had a net-negative impact on the community, hurting peoples ability to have civil disagreement. One side comes across as believing something as an absolute truth -- which makes it very difficult to have rational discourse with.
What typo? :)
&gt; That doesn't address the type-safety problem, though. My issue is that if you unmarshal JSON into a map[string]interface{} Well, why are you decoding the JSON into a `map[string]interface{}`? What are you trying to achieve?
I like to model it so the long running process is a struct with `Start() error` and `Stop() error` methods. In cmd/main.go you call them with a `signal.Notify` in between: c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt, syscall.SIGTERM) &lt;-c
I've thought about sum types in Go quite a bit. Besides dynamic dispatch, the other performance penalty to interfaces (and typically quite a lot more significant) is the allocation that is incurred for value types. If they're implemented under the covers as a tagged union, then there is no dynamic dispatch or allocation cost (or at least you can choose between fat/fast and skinny/slow). However, I think tagged unions would require some modification to the GC, which would need to check the tag for sum types whose members could be pointers during some operations (although there might be a way to work around this?). Another interesting problem is zero value types. With tagged union types, you could just say that the zero value type is the zero value of the first struct variant (this means the memory for the type is all zeros, like other zero types in Go afaik), but the fact that there is an "uninitialized" state in the first place seems error prone (perhaps no more so than any other zero value?). And you can't well require explicit initialization, or everything that embeds one of these will also require some explicit initialization (e.g., you can't do `var mystruct MyStruct` if `MyStruct` contains an enum type anywhere, no matter how deep in the structure). It's probably worse with interface-based sum types, because the zero-value is nil. Finally, sum types are much more useful if you have generics. You can have nice types like Option/Maybe and Result. TL;DR: The best you can probably do in Go is tagged-union-based sum types whose zero values are the zero value of the first variant. Also generics + sum types are better than the sum of their parts.
&gt; The problem is, that once the initial sync of data is completed, main closes, and application quits. Generally, that's the expected behavior of anything you're going to control with `cron`. If your application never quit, why would you need to schedule jobs? If you really, absolutely, truly must keep your application up at all times: 1) put an endless event loop in main(), or have it wait at some sort of barrier (such as a Group) 2) launch your application with runit or some other service manager
One of the things that stands out to me is how readable the code base is. Just go check out other C based open source projects and the code is nearly incomprehensible. Full of callbacks and obscure macros. It looks like code written by an alien. The Golang code projects I have looked ad are much more understandable. 
FWIW, I don't believe "SRSLY, why?" is a comment that has a reasonable claim to try to start a constructive conversation.
Do you have a better suggestion? We need to be able to process the actual data. We don't know what the data *is*, so we can't unmarshal it into a struct. It can be anything. The scheme currently under consideration is one where we unmarshal into a sort of union supertype, similar to `reflect.Value`, but which supports only the strict subset of types we can handle, and where the data is hidden behind getter/setter methods. 
`Gin` uses v8 of https://github.com/go-playground/validator while the actual library is at v9 now. Check it out directly.
Yay, thanks!
Do your fixes for crashes need to be pushed upstream?
&gt; Do you have a better suggestion? We need to be able to process the actual data. We don't know what the data is, so we can't unmarshal it into a struct. It can be anything. I thought you were writing a document store. What kind of process are we talking about? Why exactly do you need to process the document? What is the goal? 
An excellent analysis. This is the proposal in that thread for a tagged union version https://github.com/golang/go/issues/19412#issuecomment-323208336 The workaround in the issue queue for the tagged union style is to not allow overlaps of pointers and non-pointers in the union rather than change the GC, so the size would be bounded between 1 + max(elementSizes) and 1 + sum(elementSizes). See https://github.com/golang/go/issues/19412#issuecomment-323397774 Not always optimal but even with the zero value constraint you deduced there's still a bit of leeway for the compiler to get a decent space savings and the absolute worst case is essentially the same as the best case for the equivalent struct. 
If it is at all possible to get a shell in the container the Go executable is in, what happens if you use telnet to try to get to the MySQL server? If you can't do that, use the net package to just try opening a socket to the MySQL server and see what happens. I'd guess you'll get a "socket not open" or "connection refused" message, which means that the mapping is not correctly done through Docker. Be sure the ports are indeed flowing correctly before adding the complication of the sql library, which tries to do some pooling and such that can complicate handling the simpler problems. Plus, given that you logged the error, you really should paste it in here. If it is "connection refused" or something similar it is almost certainly a docker configuration issue.
:)
This is slightly off-topic, but is there any way to stop Google Groups [asking me to authenticate to view the mailing list](https://groups.google.com/forum/#!topic/golang-announce/lGkem2e5WyQ) for announcements/go-nuts when I don't have a Google account? Currently it's a bit of a song dance to open up private browsing or view via grokbase or something.
I can't believe I not only hadn't heard of it until now but haven't been writing all my terminal tools with it.
[removed]
Try using explicit IP address as the host name.
I guess we're talking past each other. I'm asking, why does it matter that you can conceive of ineffective directions to diversify in? Are you sharing this thought out of concern that something of this nature is happening here? In other words, *do you have a point*? Since you haven't clarified after several opportunities, it appears not, so the next most likely scenario to me is that you like to derail diversity efforts. 