The web API that you are consuming already has hundreds of attributes to be able to respond to your HTTP requests with the data that you are expecting. Considering this, and knowing that you only have to build the static struct once, I don't see why you wouldn't want to do that, no matter who many attributes are there. If you don't want to write the struct by hand, you can use this service [1] which will convert a JSON object into a valid Go struct. There is also this one [2] which I have never tried but seems to offer the same functionality. [1] https://mholt.github.io/json-to-go/ [2] https://transform.now.sh/json-to-go/
LOL of course it's not 😄
another option along the same line as /u/unix15e8's suggestions: use vs code and this extension: https://marketplace.visualstudio.com/items?itemName=quicktype.quicktype
_"Marry them"_ would have been enough, but who am I to talk about English ¯\\\_(ツ)_/¯
Were you able to reuse any of the parser/compiler from the standard library to augment the language with a superset, or did you have to write a parser/build an AST from scratch before using code generation to compile to Go? (I'm assuming you're compiling to Go..)
How would I deal with JSON arrays that contain a variable number of attributes?
wherever i go, I see a fellow brazilian....
So, not saying you're wrong, but instead wanting to learn more about inclusive programming. Isn't it better to switch to the proper UI controls in that situation? For instance, if there's something you cannot change, yeah sure ARIA is probably the better idea. And maybe adding ARIA anyway is a good idea. But, generally, isn't the motto "use the right elements" a better idea? Or no? (I really don't know as much as many in this area)
You only need your struct to contain the fields your code cares about. Often that's just 10 out of the 100. The rest will be skipped over by the decoder (saving you CPU and gc time too) If you need to preserve and return a field without caring what it is inside, json.RawMessage is the easiest and most efficient way to do that. If you need to preserve those 100 fields, and return them with a few edits, unmarshal into a map\[string\]json.RawMessage and \*also\* unmarshal into your struct with the 10 fields you needed to look at in detail. Then marshal your response struct, and unmarshal it on top of your existing map\[string\]json.RawMessage (thus overwriting the fields you changed), marshal up the map\[string\]json.RawMessage and send it back.
Do do it. This is one of the cases where compiler optimizes the string(msg) away.
&gt; How would I deal with JSON arrays that contain a variable number of attributes? If it is an array, the number of attributes is irrelevant. However, if your question is _"How to deal with an array of attributes with different types?"_ then you will have to leverage the, slow but necessary, [reflect](https://www.google.com/search?q=golang+json+array+mixed+types) package to unmarshal the JSON object _(or at least this non-homogeneous array)_ one attribute at a time. People have done it before, it's a necessary evil, there is no other choice if you want to deal with an web API that doesn't follows a standard.
You can often use maps as a general purpose JSON value holder. Would that work for you?
Eiffel uses [] and Julia uses {}. In my opinion, they both are aesthetically and pragmatically better than &lt;&gt;. Besides what the link in the other comment has mentioned, see also https://stackoverflow.com/questions/29331315/double-closing-angle-brackets-generate-syntax-error-in-specific-case I think it's bad to inherit the redundant complexities from other languages just for the sake of being *visually* backward-compatible with them. 
How would it be able to reference the type to satisfy the requirements of the Go language? Go does not support generics at this point. If in our contrived example we say there is a type defined as: package list type Node[T] struct { Value T Next *Node[T] } and it compiles to package list import "project/customer" type NodeCustomer struct { Value customer.Customer Next *NodeCustomer } and package customer import "project/list" type Customer struct{} func List() list.Node[Customer] becomes package customer import "project/list" func List() *list.NodeCustomer It is, indeed, going to create the circular reference the parent refers to. Obvoiusly that is not going to work. The parent is asking for what alternative solutions Fo may use to deal with this case.
because build\-in generic uses \[\] too.
Append is free of panicking, but is always not free of data integrity.
I like D's `!T`/`!(T1, T2)`: auto list = new List!int;
It's not immediately obvious though. `append` returns the expanded slice, so it's easy to think it won't modify the original. Looking into the spec would clarify of course, but for a beginner it's not a hard mistake to make.
That's not true. The first example is thread safe.
No, it’s a data race. 
Why does it not fail with the -race flag?
Congratulations, "eye cancer" is the definition of bike shedding. It's something that doesn't matter *at all* until the functionality is settled, especially for a project that has been around for only a few months.
Because -race has false negatives. 
It *is* bikeshedding if the implementation works well enough to decide on the features. Once the features settle, things like syntax can be decided. Yes, `[T]` can be ambiguous and isn't a particularly good choice for Go IMO, but that's quite immaterial until the featureset settles enough that the syntax is the most relevant choice left to make. I'm guessing that this project isn't intended to be "production ready" yet, so it's just a plaything until things stabilize.
No, it doesn't. It relies on defined behavior in the spec, namely, that the underlying array will need to be re-allocated if there is insufficient capacity - avoiding a data race from writes to the same region of memory. https://golang.org/pkg/builtin/#append &gt; If it has sufficient capacity, the destination is resliced to accommodate the new elements. If it does not, a new underlying array will be allocated.
There's no race
In this case, i dont believe that is true. The first example will have guaranteed, deterministic, and consistent behavior if it is under the 1.0 promise. It's unclear how that is a data race.
[removed]
I see now that you are using new variables for y and z. But then it’s just that you are doing a read of the backing memory with no write. So there’s no data race but it’s just pointless. The rules are pretty simple. Reads and writes can’t interleave without a sync via channel or mutex. 
Does wasm give us native gRPC in the browser? 
TIL Google gives a shit about accessibility and proved it. 
The race detector cannot find all data races but is guaranteed to never report a false positive.
I'd love to know how you are benchmarking this... When you're doing IO, there's a lot of ways to skew or misread the benchmark.
Oops I broke it. ;) package main import ( "github.com/cjrd/allocate" ) type rec struct { Rec *rec } func main() { allocate.Zero(&amp;rec{}) } 
&gt; But then it’s just that you are doing a read of the backing memory with no write. So there’s no data race but it’s just pointless. It's not pointless, because `append` returns the new slice.
[removed]
[removed]
That was the plan. Maybe still is. Remember these are draft notes. 
I second this approach, I just recently used it for an API client and it worked wonderfully.
I do find it really hard to fully understand, to some degree. For example, why does this work: https://play.folang.org/p/KTHZYA_290W But this doesn't: https://play.folang.org/p/LHiwUE97VMB After all I only added 1 more argument to it, nothing else changed? Also, moving main() to the bottom can make it not compile, too... I must be missing something.
You said you want to acquire the JSON data, store it, and send it back to the user? It sounds like you don't even need to parse the data? If so, just read it into a buffer, save the buffer, and write it back out.
According to https://github.com/golang/go/wiki/Go-Release-Cycle#june-1--december-1-beta-1-issued, the beta is 2 weeks late
It depends on the load that you are expecting to handle. For small projects, I serve everything _(API endpoints + static files)_ via net/http and put Nginx in front. For larger projects, I server everything via net/http and put [ELB](https://aws.amazon.com/elasticloadbalancing/) in front, no Nginx or anything in the middle.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://aws.amazon.com/elasticloadbalancing/) - Previous text "ELB" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
It depends on the load that you are expecting to handle. For small projects, I serve everything _(API endpoints + static files)_ via net/http nothing in front. For medium projects, I serve everything _(API endpoints + static files)_ via net/http and put Nginx in front. For larger projects, I server everything via net/http and put [ELB](https://aws.amazon.com/elasticloadbalancing/) in front, no Nginx or anything in the middle.
In terms of performance Go is good enough for quite some time. I'd not bother managing another web server. https://blog.cloudflare.com/exposing-go-on-the-internet/ is worth a read. If you need better performance I'd look at a CDN (Cloudfront or equivalent), they are not hard to set up and will give you a much bigger performance gain due to edge caching. It's a bit more management though so may not be worth it at first.
Darn you, I immediately checked todays date.
Thanks for the article I’ve been looking to read something about this for a while 
the package based on go generate for basic types. 
…with the part participle of that being "awifen" :-)
Ahh man, maybe, maybe. I can't write as much as I'd like. Thanks for the encouragement tho :)
If you don't need much and just want to display rather static information, check out [hugo](http://gohugo.io/), which is written in Go. It can create HTML files with links and menus which you can host with NGINX, Apache, or S3. If you need session handling (login/logout), forms, dynamic content, etc. you need to use net/http or something that builds upon that. 
I really like D generics when I programmed in D. It gave the impression it was easy and lightweight. See by yourself https://dlang.org/spec/template.html. But, I don't think we can use () for generic definition. Using ! for generic instantiation, is more concise than &lt;&gt; when there is only one generic parameter which is mostly the case. 
The problem is CORS. CORS classifies the same hostname (localhost) as a different server because it’s running on a different port. If you notice the browser is making an OPTIONS request. This type of request is made to check that this resource can be accessed in a cross-origin manner. To make this work you need to support the OPTIONS HTTP method call in addition to the GET you already support in your application, and return appropriate CORS headers in the response to allow the other origin to access the resources on that host. 
\`OPTIONS\` looks like a pre\-flight request to check for CORS Headers. That makes sense since your frontend and backend are served from different ports, which is recognised as different hosts by your browser. You can try either enabling CORS headers using \[this\]([https://github.com/gin\-contrib/cors](https://github.com/gin-contrib/cors)) or serving front\- and backend from the same port.
Simple fact : a test can reveal a data race (and not in a deterministic way), but not prove there is none. And race detector isn't perfect. It's a tool, not a medium or some sort of oracle seeing hidden things in the space of your code and time. Appending to slice IS NOT thread safe. And according to the way append does its job y and z could refer to totally different memory spaces (depending on when the slice increase its capacity). Not just y and z, but also the underlying memory used to store data. 
You could use something like [https://github.com/buger/jsonparser](https://github.com/buger/jsonparser) , which is also pretty fast.
Depends on the definition. If you mean `append` as in the Go builtin, not always, as per the first example. If append grows the slice beyond its current capacity, `append` will allocate a new array and have the slice it returns refer to that piece of memory, leaving the original memory untouched. So it's perfectly safe to take a slice that's at its full capacity and start calling append on it from multiple threads as long as you don't touch the original reference In terms of semantics, though, that's not really just "append", it's "copy-and-append".
Can I buy dis plz
You are right, native controls usually give you far better accessibility than custom ones written by people who do not know anything about accessibility. MacOS is a good example, as Apple provides screen reader accessibility out of the box for all their existing UI controls. I think the problem is that the built in controls usually do not provide enough customisation and visually, a custom control looks better, can react to more things (For example Facebook's expanding Like button), even though this means reinventing the wheel. Although we tend to be open to new things, a lot of people do not expect blind people to be able to live a mostly independent life, to be able to use a computer and the same mainstream technologies as anyone else (a touch screen, for example). As a result, they are very surprised when a blind person asks for accessibility and when developers look into it, they realise that it is actually very easy to implement, in most cases. The other scenario is when developers do not want to try and do something about accessibility, because it would take too much energy and resources, which is often a misconception. It is not by accident that just in the US alone, more than three quarters of the blind population use iPhones, Apple Watches, etc. I realise I'm deviating from the topic, but I thought this would be a good insight for those interested.
&gt; But then it’s just that you are doing a read of the backing memory with no write. So there’s no data race but it’s just pointless. No, it's making a copy of the backing memory with some additional capacity and then writing to that. There's a very clear side effect. It's obviously a simplified example made for demonstration, but for a more realistic example let's say that you simultaneously want to build and send n &gt; 1 messages of some line oriented network protocol. You have a general implementation for line oriented protocols that you can pass slices of strings which the implementation will automatically write and terminate with the appropriate line ending convention and send as a single message. All packets share a common header. So you create a slice at full capacity containing the common header and launch n goroutines that each start by calling `append` on the common header. None of the goroutines actually modify the reference to the original slice, so no synchronization is needed. It's also not pointless because they all derive their headers from the original slice and are able to use that data meaningfully. There's a clear and deterministic effect of calling append on a slice at full capacity and assigning the new slice to a new variable, and in this case it is useful. Instead of backpedaling from "append is not ever thread safe" to "it's pointless" you can waste much less time by simply thinking it over and conceding.
Do you serve HTTPS? You may want to do a benchmark if you does that. Based on my observation, I found that Go [`tls.Server`](https://golang.org/pkg/crypto/tls/#Server) uses greater amount of memory compare to directly serving raw TCP streams. In that case, I guess it could be better to let Nginx to off load some of those TLS traffic and relay the decrypted request to the actual Go server. But of course, it's all depends on your load. Don't make your server too complex and hard to maintain if you don't have that amount of traffic needs to handle.
yeah sorry. **How do you design a project?** any project can be considered but I can give a sample [https://github.com/michenriksen/gitrob](https://github.com/michenriksen/gitrob) I'm doing a project, but I can not imagine how we would design the program. so it would be great if you share relevant resources with it!
That's huge, I thought I had a lot of stuff in $GOPATH/src but just looked and it's only 389mb, how can you have that much source it takes up 100gb?
In your interfaces section the feed_animal() function can be confusing for people trying to learn Go when it is an extra unnecessary step. See [this](https://play.golang.org/p/TALOQ6lGxf5) 
There is a [golang container](https://hub.docker.com/_/golang/) (which is pretty large, not best for end-user distribution) that is good for building go programs. To make the binary fully standalone, you want to pass in `CGO_ENABLED=0` and then your target os (`GOOS=linux`). What I do is use the golang container to build a binary. I then usually publish the binary in either a scratch or alpine image. Here's an example from where I build the vault-exporter. I have a Makefile with a line like so: `docker run --rm -v $(WORKDIR):/build golang /build/vault-exporter-build.sh` Then the script file is below. I will say that my forcing an explicit GOPATH shouldn't be needed, in the golang image, I believe it defaults to /usr/src. I did `go get` because it was a shortcut to fetching the various dependencies. #!/bin/bash export GOPATH=/go export BUILD=/build export PATH=$PATH:$GOPATH/bin if [ ! -d $GOPATH ] then mkdir $GOPATH fi go get github.com/mh-cbon/go-bin-deb go get github.com/grapeshot/vault_exporter cd $GOPATH/src/github.com/grapeshot/vault_exporter/ CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o /build/main . VERSION=`git tag | sed 's/v//'` echo "Determined version $VERSION from git" echo $VERSION &gt; /build/VERSION 
One thing you can do is use `disasm` to get a more detailed look at the generated assembly and where that spends its time. Random guesses: * This might indicate poor cache-performance: Line 110 dereferences `pos`, `t` and (if that's a pointer too) `t.Position`. It might be, that when that function gets called a subset of those isn't cached and needs to be fetched. Lines 111 to 113 then can work directly on the cache. * This might be due to an optimization that uses a SIMD-instruction for a copy, potentially needing to work around alignment issues? * Maybe the compiler inlined `PositionPool.Get` and now the accounting gets confused? TBH, I agree that it seems weird. I'd probably suggest asking on the gopher-slack in the performance channel :)
Do you plan to rewrite it in Fo?
I really like the idea of GOPATH. You don't need to think about how you organize things because everything's already organized based on the git repo path. And you can't lose anything because you can always open up Github/GitLab and find out what the repo path is. So as a result, I store absolutely EVERYTHING in there, not just Go stuff. The only downside is that goimports takes an eon to sort through all the garbage and find the Go packages.
I have attached \`disasm\` output. I hope it would help to understand what going on.
Sorry, I'm not sure myself, really. I'd probably try and use `new(position.Position)` instead of `b.PositionPool.Get()`, just to see if it's due to cache misses (which seems like the most likely explanation to me). You could also try using `perf`, which can help you find cache-related issues - though I'm not sure how in detail either.
What makes you put Nginx in front of the medium-sized projects? Surely to the Go application you won't be seeing any performance difference, and when compared to the small projects you surely still want both to be secure (which you can achieve with Go, but Nginx may be better configured out of the box for protecting your Go services).
data races not only depend on whether or not a new underlying memory block will be allocated, they also depend on whether or not the first argument is being modified by other goroutines. For example: var a []T go func() { append(a[:len(a):len(a)], x, y) }() go func() { a = make(T, n) }()
Honestly if you’re going to inject type dependent import dependencies your generated class needs the same type. That is, if you’re generating typed list code to satisfy the compiler, your list should adopt the types package e.g. customer.ListNode rather than list.CustomerNode to avoid collisions 
How does this contradict anything that I said? &gt; So it's perfectly safe to *take a slice that's at its full capacity* and start *calling append on it from multiple threads* as long as you *don't touch the original reference* Emphasis added. I never said that it's safe to do anything other than `append` to the original slice, and I explicitly said that you can't change the original reference. Your example does a great job at illustrating exactly *not* that.
And `!` is unambiguous since it never follows an identifier (AFAIK). `&lt;&gt;` is slightly ambiguous (not LL1 or whatever) since `&lt;` and `&lt;&lt;` is used for other things (C++ is particularly bad with this). However, `&lt;&gt;` is common and the ambiguity problems aren't that bad, so I'm not that invested in the argument.
quick bit of pseudo docker file code so excuse any mistakes... we use the multistage docker builds a lot in my work. (the builds happen i a k8s cluster so its nice to know nothing is being saved out to disk and picked up again etc. but basically copy your code in (using the GOPATH expected layout), pull the dependencies, build the code, take ONLY the compiled binary out of that container and into a nice new very small new one... leaving behind all the build dependencies and go runtime stuff etc ``` FROM golang:1.10 as builder COPY . /go/src/yourname.github.com #or whatever name you're using WORKDIR /go/src/yourname.github.com RUN dep ensure OR RUN go get -d -v ./... RUN go build -o /yourbinary main.go FROM alpine COPY --from=builder /yourbinary / CMD /yourbinary ```
You are adding a method to the type hotdog. 
I would also be interested in the answer. For a project I'm working on I ended up rolling out my own scheduler that has some of these features, though not as advanced as Quartz. https://github.com/michaelbironneau/analyst/tree/master/http. 
You aren't attaching it to an int, you're attaching it to a `hotdog`. You can implement methods on any type. The only reason you can't implement methods on `int` directly is that you can't implement methods on types that don't belong to your package. If it seems strange, don't think about it from an "object oriented" point of view; think about it from the memory perspective. When you use an object in another language, somewhere there's a pointer or something to the struct that is the members of the object. Well, who says that has to be a struct on the other end? Why not an int or a `chan string` or anything else? Ultimately, Go-style methods are just a fancy way of calling methods where the first parameter happens to be picked up from the thing in front of the dot. There are other languages where that is not an adequate summary, but it is in Go.
Here's an article which might be very useful to you: [On Yılda Programlama Öğrenin](https://web.archive.org/web/20121009080905/http://ileriseviye.org/arasayfa.php?inode=programmingtenyears.html) Don't worry about the title, haha. For me, when designing a project, I think about: * What are the most high-level, abstract goals of the project * What kind of data is involved - how is the data structured? * How will the program run? Is it a command-line tool? Is it a GUI? Is it a video game? Is it a web server? Is it a system daemon? * Can I break up the large program into multiple modules that communicate or work together? * What languages do I know, and for each language, what features in the language correspond to the structure of the program I want to build? I would start by making a diagram, or many diagrams, which show the connections between different parts of the program, the kind of data they transform / store, how they transform / store it, etc.
In Go, any (defined) type can have methods, no matter what it's underlying type is. So, `type hotdog int` declares a new type with underlying type `int` and then you define a `ServeHTTP` method on it. From then on, you can call `ServeHTTP` on any value of type `hotdog`. Other language might have classes to define method, but Go doesn't make that distinction. &gt; More concisely, what is the difference between implementing it on an int versus another type (i.e. string)? There is none, from Go's perspective. `int`, `string`, `struct`s, pointers, `chan`s, `func`s, all can have methods declared on them. It's useful for example for [http.HandlerFunc](https://godoc.org/net/http#HandlerFunc). So, if your handler for some reason can be represented as an `int`, you can use this. If it can't use something else. :)
I believe you mean "a fancy way of calling functions" :)
The main reason I have deployed Apache or Nginx in front of my go http(s) service is because I wanted a plug-in, module or service they provide out of the box, and those usually end up being things I’m getting from my infrastructure that are standardized or security related items that I don’t maintain as part of my business logic.
As I understand it, there's practically no difference. If 'hotdog' is 'type hotdog int' then the ServeHTTP function you have defined is basically handed an extra parameter 'm hotdog'. This language feature is helpful for at least two reasons. Firstly, it enables you to implement interfaces on all sorts of data types, such as the http.Handler interface on 'type hotdog int'. Secondly, as in the example, it enables you to use the most efficient data type necessary for the job. So, implementing this function on a string would work the same way, but perhaps the underlying data type may be able to be used by different functions or interfaces than an integer. Hope that helps.
I believe I do. (Fixed.) You know what they say... tautologies are tautological.
And go yell at the producer of this JSON. It isn't just Go that doesn't love heterogenous arrays of JSON, it's pretty much all the statically typed languages, and honestly even in a dynamically-typed language, you're just _begging_ for bugs related to misidentifying what type of thing you have. I know the serialization format permits it, but it's a bad idea.
Not OP, but this is sort of following `map`'s lead, except putting the value type outside of the braces is frankly insane.
As DoomFrog666 said, the Reader / Writer interfaces are very simple, but it's how they're used that makes powerful and an interesting case study. In my opinion, what you're really asking is, "what does it really mean to use Go interfaces?". I found this video to be very helpful as an introduction: https://youtu.be/F4wUrj6pmSI
Go has a bunch of different generic syntaxes: []T map[K]V chan T
Moved to gitlab. Get latest binary version from automated build jobs: [https://gitlab.com/bestmethod/go\-acp/\-/jobs](https://gitlab.com/bestmethod/go-acp/-/jobs)
I've been playing with the tello + go a little bit and am surprised how stable the drone is in flight. It by far is one of the most stable indoor drones I've come across so far. Just don't take it outside when it's windy. It doesn't compensate well for that. I've not worked with gobot much before and it was initially a challenge get get my head around the event/delay programming model. You can also stream video from the drone to your go application to air with something like OpenCV (GoCV) pretty easily. 
Ah, gotcha - okay. I've never seen that site before, and it seemed to throw red flags in my mind _(not sure why)_. I also didn't understand that you were posting a question, usually when people link like that they're linking content - where as you linked an absence of content *(a question)* further leading to confusion. No worries mate, I'd recommend posting the post again as a text post on reddit with your full question in the body :)
Okay. I was thinking of append+assign and not plain append without assign. I still think that’s a weird case and the examples for when you’d use it are pretty contrived. The protocol thing for example seems like it would more likely just be a constant string than a slice. 
I've published a blog post on how to write a multistage Dockerfile. Your code will be built inside a container with Dep (so that you have full replicability) and then transferred into a minimal image. [The Go Dockerfile: Build With Dep, Ship From Scratch](https://medium.com/@pierreprinetti/the-go-dockerfile-d5d43af9ee3c) You might find the enclosed example useful.
Thou it's not on this draft release notes (at the time of writing) I'm really looking forward to compressed binaries (Compressed DWARF / debug sections). Huge win in my book. This is the issue that is being tacked ([https://github.com/golang/go/issues/11799](https://github.com/golang/go/issues/11799)).
I'd recommend mounting in your repo as a volume instead of copying it. While copying it is not a big deal when your repo is small, when it starts to grow this will make the docker build command take forever. When you do docker build on this repo you have to zip up that directory and all subdirectories, send it across a linux socket and then the server needs to unzip it. For this to work you will need to do it in two steps: docker run -it --rm -w /go/src/&lt;package path&gt; -v `pwd`:/go/src/&lt;package path&gt; golang:1.10 bash -c "dep ensure &amp;&amp; go get &amp;&amp; mkdir bin &amp;&amp; go build -o bin/yourbinary docker build -f Dockerfile ./bin With the following dockerfile: FROM alpine COPY yourbinary / CMD /yourbinary
You need to allow OPTION request in your header: [https://developer.mozilla.org/en\-US/docs/Glossary/Preflight\_request](https://developer.mozilla.org/en-US/docs/Glossary/Preflight_request) In another word, you need to put this somewhere in your header: `Set("Access-Control-Allow-Methods", "POST, GET, OPTIONS, PUT, DELETE")` 
[https://play.golang.org/p/SDNoJTT2tsS](https://play.golang.org/p/SDNoJTT2tsS)
If you're only rounding on output, you can use `fmt.Printf` or `fmt.Sprintf`: https://play.golang.org/p/6QRvTG5k7VG
The other comments have great solutions I use in production as well. But just to throw another idea out there... Run your CI within Docket itself. You can install Go in the same container as your Jenkins workers. This is what I'm setting up on my new homelab actually. Very minimal OS packages and that OS only has docker. Everything else must run within Docker containers. 
Finally? Don't we have many logging libraries that are used in production systems? What makes them not production "grade"? In general to me, show me benchmarks and adoption - what more do we need? Personally, I've been loving zerolog lately.
Thank you for your replies, but I'm not only looking to round the output but the big.Float itself. Also the rounding mode (ceil / floor) is important. I could just convert big.Float back to float64 and use this: [https://yourbasic.org/golang/round\-float\-2\-decimal\-places](https://yourbasic.org/golang/round-float-2-decimal-places/), but I'm worried that this introduces the precision problem again. The article states and I quote "Due to the quirks of floating point representation, these rounded values may be slightly off." I would rather prefer to round / ceil / floor the big.Float itself. I understand that I can set mantissa bits and rounding mode, but I'm not sure how to calculate the correct mantissa to accurately achieve n decimal places when doing arbitrary calculations.
To those too lazy to use Google Translate: I just looked at the OP's other posts around Reddit, observed that he posts in Turkish, and used Google Translate to try and communicate that we need more information in his native tongue. I'm not sure why I got downvoted for that.
&gt; I'd recommend mounting in your repo as a volume instead of copying it. This is not great advice. Use [a `.dockerignore` file](https://docs.docker.com/engine/reference/builder/#dockerignore-file) to exclude things you don't need (like the `.git` directory, other large blobs, etc). Even your dependency folders, let Glide (or NPM or whatever) install dependencies during the build process -- that's what the various lock files are for with dependency management tools. You do want to reduce context that has to be sent to the docker server, but not to the point of having to abandon multi-stage builds. I've done this stuff both ways -- external build step + docker build and multi-stage builds -- multi-stage builds with correctly setup `.dockerignore` files tend to be a lot more snappy and easy to manage.
Why is the package declaration capitalized?
Oh shit! So I imagine this post but I all forget! Thx man!
good!
It's always a matter of time.. an engagement in Brazil seems to last 1..15 years
Its very serious...
And to top it off, it's GPLv3...
that is hardly an issue compared to the fact that they imply zap/logrus etc. are not production grade
I'd guess for caching of the static assets by the proxy, unless I've misunderstood.
at least for us, the "barrier" is financial, be able to keep an apartment by ourselves. 
Looking through the git logs, nothing substantial has changed.
Most applications log far too much. We put in lots of logs during development, and leave them in when deploying to production "just in case". This produces an enormous amount of logs that no\-one reads. \- If the log is just a record of something happening, if it could be aggregated, it's probably a metric (Prometheus). It's surprising how much falls into this category. \- If the log is something important, then it's not a log it's an alert. Send it by email, pagerduty, chat\-ops, etc. \- If the log is not something important then remove it. I'll go so far as to say that needing anything beyond the stdlib's \`log\` package is a code smell.
*And* that they imply that *this* is "production grade" *and* that the code isn't `gofmt`ed *and* that the tests (which they brag about) don't test much of anything *and* that they explicitly compare to `false` in if statements *and* everything else that's probably wrong with it. The license is just the icing on the cake.
I think wasm is the future. However, given that wasm is still in its early stage, I would still use a front\-end framework (like React or Angular) for the front\-end part, and Go for API only for now. Current front\-end frameworks are not likely to be deprecated in a couple of years, so it will give you enough time to develop your project/product and make transitions to wasm.
The little bit of Tello+Gobot I did hit me the same way with the delays. I plan to do more with it, but haven't had time yet.
We will stay with the DOM. The web won out as a UI platform for a reason and it isn't that we didn't have OpenGL available natively. It's that as much as there is a culture of contempt for it, it just is a good platform to build UIs.
The tool only picks up checked in CLs with RELNOTE=yes. The CL for compression of binaries hasn't gone in yet. But I'm sure it will be included in release notes.
+1 for multistage!
It's only being blocked by the fact that I have limited time and can't work on everything at once. Definitely something I plan to add soon. If you're asking why doesn't it just work already since Fo supports generic type declarations for any other type, the answer is that Go has special semantics for interfaces and they don't work the same as other types. Specifically, there's code in the type-checker that checks if a certain type implements a given interface, and that is the code I need to work on (and haven't yet). I'm also still thinking about how generic interfaces should work. Should `type A[T] interface{ f() T }` match on concrete methods like `func (B) f() string` or should it only match on generic methods like `func (B) f[T]() T`?
hmm maybe I should improve my CI. I currently just have a script that pulls from git, rebuilds, kills the app, and relaunches via nohup.
I remember a few work queues that have been posted about, but you'll have to check if they satisfy your needs: https://github.com/RichardKnop/machinery https://eng.uber.com/cherami/ https://github.com/contribsys/faktory
For context, right now Fo only works on a single file at a time, so I haven't run into this issue yet. It's certainly going to be a challenge to overcome when I work on support for imports and multiple packages in the near future. The good news is that Fo already more or less knows how to parse and type-check this scenario correctly. It boils down to a code-generation problem. One idea would be stop outputting Go source code and instead hook directly into the Go backend. This would be a significant amount of work and reduce interop (at least from the direction of using Fo code inside Go) to basically zero. It would come with the upside of improved compiler performance. The other idea I have is to change the code-generation strategy and use `interface{}` boxing/unboxing instead of generating concrete types for each usage. This also happens to solve some other issues I've run into. The downside is that it decreases runtime performance. I'll have to spend some more time thinking about this as any solution will involve some trade-offs, but it doesn't strike me as impossible to solve.
Yes, I started by copying the existing Go parser, type-checker, etc. and made changes on top of them.
Saw a post earlier about building Go projects with Docker, and thought this was a great approach using a "2-step" Docker file without having to install Go.
This is definitely a bug. I'll look into it.
I explained my reasoning here: https://www.reddit.com/r/programming/comments/8qk6w4/fo_an_experimental_language_which_adds_generics/e0jv553/
&gt; does it just treat the initial definition like a template, and generate an appropriate type at compile time? Yes, that's more or less how it works. &gt; Is type inference possible in the future? Yes, there's already an issue for it: https://github.com/albrow/fo/issues/1
I haven't tried but at first glance it should be possible to convert all of those to Fo.
I don't think big.Float will do precise division. It isn't meant to replace a decimal type like in other languages. If you don't want to use a library, it honestly might be easier to just implement the division algorithm yourself.
If you want to be taken seriously, either implement a library doing something nobody has tried before, or be at least a little humble.
Thanks for the help. How would I deal with the response if it contains several nested JSON objects?
 "Certifications": [ { "Id": "512", "Name": "Engineer certification", "Authority": "The Great Engineer Association", "Number": "1", "StartDate": "2006-02-07T19:02:55.803Z", "EndDate": "2007-02-07T19:02:55.803Z" } ], "Courses": [ { "Id": "888", "Name": "Advanced Algorithm", "Number": "1" } ], "Volunteer": [ { "Id": "456", "Role": "Teacher", "Organization": "The Great Wall", "Cause": "Teach people to defend the Wall" } ] Are three attributes in the JSON response body. There are over a hundred of these within the body.
Link to existing req? 
Just curious, why not LinkedIn, Indeed, Stack, Glassdoor, Angel.co, or Dice? Very high signal to noise ratio? The platforms always try to suck you in, nickle and diming you every step of the way?
WASM isn't designed to replace JavaScript as a way to modify DOM. That's why it currently can't even talk to DOM directly. To access DOM from WASM, you have to build a shim in JavaScript and call it out from WASM. WASM isn't designed to be used as a whole-sale replacement of JavaScript in a typical web app (games being a notable exception). The purpose of WASM is to allow you to write perf-critical parts of your code in a language faster than JavaScript and easily access this functionality from JavaScript. For example, if you were to write a converter of .rar archives into .zip archives on a web page, it would be very slow when implemented in JavaScript. With WASM you would still write almost the whole app in JavaScript but the time-critical parts of compressing/decompressing rar/zip would be implemented in C (or Go) and compiled to WASM and considerably speeding it up. 
Okay, so the big.Float is out, but does anyone know, is there anything else in the Go standard library that *does* precise arithmetic?
Yeh, FWIW I think it'd help a lot and be a great example to take just one of them (like say the AVL tree) and see what it looks like with generics.
[removed]
Sorry, I don't know why I didn't mention this in the other comment. For your use case where you know the exact precision needed, you can convert your numbers to big.Ints and use big.Rat to divide them. If you can't convert them (eg. maybe you don't know the precision required ahead of time) then you have to use a library like https://github.com/shopspring/decimal. The go team said they might be interested in adding a Decimal type to the stdlib, but I don't think anyone has worked on it since usually it isn't necessary.
Having `.Fatal` exit the program via the logging api seems like an overreach of what a logging framework should be doing.
[removed]
it would also be nice to be able to use a type alias, `type BoxedInt Box[Int]` would clean up the code further down...
OP probably already has those bases covered. 
It could have something to do with reddit, and the social class most programmers are in, especially in north america (and north america for that matter), all being skewed statistically toward the xenophobic. "Not English??? What the hell is this? Downvote."
Even if you don't don't copy it, the contents of the directory your in get copied into the "docker context" anyway by that point
bazil.org/fuse.
https://news.ycombinator.com/jobs
What about traefik or caddy? Both are go based
For go specific jobs I would post https://www.golangprojects.com/ and the official mailing list https://groups.google.com/forum/#!forum/golang-nuts
I did some side work on a Go project a while ago and the main dev claimed that using reverse proxies wasn't a "thing that Go developers often needed to worry about". I wasn't sure if that's actually true or that perhaps for a lot of the common Go use cases e.g. backend microservices, reverse proxies weren't really used a whole lot. When I first started doing web development, I remember thinking it was a bit weird with languages like Ruby, Python, PHP, etc that you usually have a reverse proxy, a middleware server and then your web framework (Rails, Flask, whatever) sitting on top of that. By weird I mean that it felt more complicated than it should be or than I wanted it to be. :) 
https://golang.org/pkg/text/template/: {{template "name"}} The template with the specified name is executed with nil data. {{template "name" pipeline}} The template with the specified name is executed with dot set to the value of the pipeline. You should be using the second form, and likely pass dot as the pipeline.
https://golang.org/pkg/text/template/: {{template "name"}} The template with the specified name is executed with nil data. {{template "name" pipeline}} The template with the specified name is executed with dot set to the value of the pipeline. You should be using the second form, and likely pass dot as the pipeline.
[Here is a real world example]( https://github.com/baltimore-sun-data/voter-guide-2018/blob/master/Dockerfile) of a Dockerfile for Go+dep. 
Are you using the [template](https://golang.org/pkg/html/template/) package? If so you probably have to pass the data to the sidebar template with '.' : Quick and dirty example: package main import ( "html/template" "os" ) // Notice the '.' being passed after the template name. This passes all the curently scoped data to the template const index = `{{ .hello }} {{template "sidebar" .}}` const sidebar = `{{ .bye }}` func main() { data := map[string]string{"hello": "hello", "bye": "goodbye!"} template.ParseFiles() sideBarTemplate, err := template.New("sidebar").Parse(sidebar) if err != nil { panic(err) } t, err := sideBarTemplate.New("index").Parse(index) if err != nil { panic(err) } t.Execute(os.Stdout, data) } 
Dice is terrible, btw, they are just an aggregator. No reason to use them, nothing they have his proprietary or unique.
I believe much of it was rewritten by Giovanni, and that it's those changes they pulled into 1.10.3.
Alright so this might be slightly ignorant, but what people say "reverse proxy" what do they mean? Also in that case...where can I learn more about web servers and such? 
Thanks a lot for the article - I'm pretty much just learning and trying to build a bot that logs information into a .db file and serve the daily files via a web server. For the structure of a Go program such as this - can you suggest a sane way to do this?
The packages in the standard library do binary arithmetic. If you want decimal math, you need to use something outside the stdlib. I believe https://github.com/cockroachdb/apd is the most tested decimal package in Go.
It looks like Golang allocates memory when we use the object for the first time instead of when we are creating it. I have created `positionBuffer` slice, see [@commit](https://github.com/z7zmey/php-parser/commit/93bc62f52d037f54040f79a85d9febf47072e1a6). After that, the function `New` in `PositionPool` spends about 6.5s. It is like a sum of `createToken` and `NewTokenPosition` functions that most actively created the positions. And now profiler shows that the time spends to growing slice
Also the #jobs channel on [Gophers Slack](https://gophers.slack.com) 
I’m not well versed in zmq but saw inproc wasn’t implemented. Is that something that could be implemented with a channel that satisfied the net interfaces your lib expects?
Gogs and Gitea both seem to go down the route of favouring a familiar UI - in which case, why not go down the route of primer? May even need less changes to get things to look right.
Currently, we are using Go back\-end with REST services with Electron front\-end (React/Redux). Works fairly well. I will be building a prototype with webview/GopherJS/ReactiveX with simple React components with the goal of reducing the JS application code. [https://github.com/zserge/webview](https://github.com/zserge/webview) [https://github.com/gopherjs/gopherjs](https://github.com/gopherjs/gopherjs) [https://github.com/ReactiveX/rxjs](https://github.com/ReactiveX/rxjs) [https://github.com/ReactiveX/RxGo](https://github.com/ReactiveX/RxGo)
I think wasm -&gt; DOM instead of wasm -&gt; JS -&gt; DOM is planned. 
If you're just trying to force it to allocate memory beforehand, this might be a neater way to do it. How does the performance compare? pos := new(position.Position) return &amp;Lexer{ Lexer: lx, StateStack: []int{0}, PhpDocComment: "", Comments: nil, heredocLabel: "", tokenBytesBuf: &amp;bytes.Buffer{}, TokenPool: sync.Pool{ New: func() interface{} { return &amp;Token{} }, }, PositionPool: sync.Pool{ New: func() interface{} { return pos }, //&amp;position.Position{} }, }
[removed]
Perhaps, but I don't want to speculate.
Thank you. Here is my code, still not work. ``` import { "github.com/gin-contrib/cors" "github.com/gin-gonic/gin" // ... } func main() { // DB connection r := gin.Default() r.Use(cors.New(cors.Config{ AllowOrigins: []string{"*"}, AllowMethods: []string{"PUT", "PATCH", "GET", "POST", "DELETE"}, AllowHeaders: []string{"content-type"}, ExposeHeaders: []string{"X-Total-Count"}, })) r.GET("/posts", GetPosts) r.GET("/posts/:id", GetPost) r.POST("/posts", CreatePost) r.PUT("/posts/:id", UpdatePost) r.DELETE("/posts/:id", DeletePost) r.Run() } ```
``` &lt;html&gt; &lt;body&gt;{{ .class.member }}&lt;/body&gt; &lt;/html&gt; ```
Thank you. I have did it using `github.com/gin-contrib/cors`. Pasted source at previous comment. Still not work.
nginx can cache and loadbalance to multiple backend instances.
Disclaimer: I maintain bazil.org/fuse. I'm trying to be polite so this is all I will say publicly about hanwen's library: if it had worked, or if it had seemed fixable, I would not have picked up rsc's fuse library and started working on it for Bazil. But at this point in time I am, naturally, biased. jacobsa's thing builds on top of bazil.org/fuse and as far as I can understand is primarily aimed at really enforcing the programmer to deal with all the nitty gritty, as means of making the eventual filesystem less bug-prone. I actually laud that goal and one of my forever-in-the-works API refactoring is changing bazil.org/fuse to share more of that mentality. bazil.org/fuse has very few bugs I would be aware of, and bugs get fixed quick (imho), but it is absolutely not stable in the specific meaning of completed and stopped evolving. The API will still have to change, even quite radically.
[removed]
We definitely won't be replacing the DOM with WebGL. That would be terribly inefficient. Web assembly might eventually be used to let you control the DOM. It would be lovely to be able to write an entire app in Go, sharing the same data structures on the client and server.
I would highly recommend going one further; use FROM scratch rather than alpine. It removes all effective surface area for attacks and keeps your container even smaller. 
I just realized this now after reading your comment this morning. This entire time I thought it was a variable declaration. Makes a bit more sense now that it's a hotdog type with underlying/base type int.
Glad it helped. Good luck on your tutorial and have fun learning!
While I'm not sure I prefer it, you can already do this: https://play.folang.org/p/P1OGtIswRyI
Contribution guide for 99.999% of other open source projects: * fork * branch * create PR 
for big corps you typically also have to sign away your rights (some more than the others)
Law of diminishing returns. `FROM scratch` containers can have some surprising gotchas, even with a compiled language like Go. `FROM alpine` gets you most of the way there and provides a relatively sane build/runtime environment. I agree that `FROM scratch` is better, but I think that it's an answer to which you need to know the question first.
First thing I've noticed on type Positions map\[node.Node\]\*position.Position is that you are using pointer. Try without pointer, should be faster. Also, I see that Node is an interface \- also might slow you down.
[removed]
[removed]
It works like a charm!
A http proxy will take an outbound request from a browser and redirect them to a server. It is a way to avoid having a computer on the wider internet. Extensively used in corporate networks. A reverse proxy will take an inbound request to a website and redirect it to the appropriate server. https://www.jscape.com/blog/bid/87783/Forward-Proxy-vs-Reverse-Proxy
I would suggest looking at https://github.com/vcr/vcr and https://github.com/kevin1024/vcrpy which are very similar ideas implemented in other languages. Apparently there is also a go implementation (https://github.com/dnaeon/go-vcr). Writing the JSON files out by hand works at the start when APIs are small, but it becomes very error prone as things change and APIs grow. Being able to automate it makes it a lot easier to use. You might also want to consider making it a test library that users can integrate into a `go test` suite. That way you don't have to implement all the parts that are already handled by `go test` and `testing`. Just my 2 cents, hope it helps!
Thanks for the feedback. Integrating it into go test is something I would like to do. I agree writing it out the tests for the entire api by hand would be a bit of a drag. I am considering maybe doing something with swagger docs, where I would automatically generate the test files by reading in the swagger file. I like this idea as it would keep testing consistent with your documentation (and maybe force you to write documentation). Thanks for the links as well, I haven't seen those before when.
[removed]
&gt; Readibility &gt; Portibility I sinse a theme. A recurring tipo, if you will.
[removed]
Totally understood. I have the same problem currently...
I've tested Caddy a while ago. In my result, it did uses a bit more memory to serve HTTPS compare to HTTP (reasonably). But I didn't do more research on it. So if you want to know more, then you need to benchmark it by yourself with the newest version. Here is the tool I've used to do the benchmark: https://github.com/wg/wrk
restic, appears to use bazil: https://github.com/restic/restic/tree/master/vendor/bazil.org/fuse I don't have any experience with the library but I've never had any issue using it's functionality in restic.
I had to LOL because it's true, the umbilical cord is strong with Brazilians!
I know about that bottleneck, I am going to move `position` and `comments` into node instead of using map.
I’ve used this before: https://github.com/tidwall/gjson Might be worth a look. 
&gt; It looks like Golang allocates memory when we use the object for the first time instead of when we are creating it. No, that is definitely incorrect. Otherwise the assembly would contain a call to the runtime to allocate (and that's where the time is spent), but that's not the case. This is still *far* more likely a simple cache-miss.
Now `PositionPool.Get()` always returns the same pointer for every call, but I need to create new objects.
Don't give up. ;)
I have found that this behavior is documented [allocation\_new](https://golang.org/doc/effective_go.html#allocation_new) &gt;new(T) does not *initialize* the memory, it only *zeros* it
You forgot the most important last bullet: - messy git history and bad review process
Android apps are Java, unfortunately. You can have natively compiled binaries, though, but those are usually C/C++ and a highly discouraged as they only run on the one processor architecture you compiled them for, and on Android you can have ARM or X86. If you want to do a project like you say there, I'd go with Unity for the game engine and then Go for the server. Mulitplayer games are not an easy feat, you'll encounter a lot of problems that already have solutions in Unity/UE4 or at least someone else solved already. Oh, and have fun countering cheating, even big AAA haven't mastered that part, yet.
I don't know why you are quoting that. Because it doesn't say anything about *allocation* (the distinction it makes is a distinction without a difference for Go. It is there for the benefit of people coming from C++ or Java and being used to the existence of non-zero-initialized values, i.e. constructors). And in the assembly you have posted, AFAICT, there is no zeroing happening either. AIUI, what is happening there is a) you get a pointer from `PositionPool.Get()` and b) the memory that is pointing to is then overwritten with the values from `t.Position`. It does exactly what you would expect. BTW, one thing you might be trying is to do `t.Position = *pos`, as that might emit fewer instructions than the four separate assignments.
Try FROM distroless/base
yes, definitely. IIRC, that's what github.com/go-mangos/mangos (a pure Go implementation of `nanomsg`) is doing. alternatively, and as a short gap solution, one could use either `os.Pipe` or `net.Pipe`. `net.Pipe` already uses a couple of `chan`s already: - https://golang.org/src/net/pipe.go#L118 
Dude, you linked one of the best packages with a great API which I've seen lately, at least what you could do is plug your twitter/blog page so I can read more when I do get the time :D
You create another struct for the nested objects. Someone already gave you an example [here](https://app.quicktype.io/?share=7hDyZ6PnuKvo1ezVLZPK).
[removed]
If you are allowing all domains in "AllowOrigins", why don't you use `cors.Default()` instead? [1] func main() { router := gin.Default() router.Use(cors.Default()) … router.Run() } [1] https://github.com/gin-contrib/cors/blob/6f0a820f/cors.go#L77-L85
&gt; Did I something wrong? Yes, most definitely. &gt; Or is there best way? Show us the code so we can tell you how to solve the problems. My guess is that you are using something like `template.ParseFiles(pages...)` and passing all the HTML files as _"pages"_ rather than passing only the base template and the child page that you want to render for a specific request. However, without having access to the code, we can simply guess at the reasons of why your implementation is failing.
I'm using Iris framework to render templates, only passing what files are necessary. For index view handler: ctx.View("index.html")
//This is the base.html {{define "base"}} &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="/static/css/style.css"&gt; &lt;link rel="stylesheet" href="/static/css/normalize.css"&gt; &lt;title&gt;{{template "title" .}}&lt;/title&gt; &lt;/head&gt; &lt;body&gt; {{template "sidebar" .}} {{template "header" .}} {{block "content" .}} {{end}} &lt;/body&gt; &lt;/html&gt; {{end}}
This is base.html ```HTML, tabs=4 {{define "base"}} &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="/static/css/style.css"&gt; &lt;link rel="stylesheet" href="/static/css/normalize.css"&gt; &lt;title&gt;{{template "title" .}}&lt;/title&gt; &lt;/head&gt; &lt;body&gt; {{template "sidebar" .}} {{template "header" .}} {{block "content" .}} {{end}} &lt;/body&gt; &lt;/html&gt; {{end}} ```
base.html ``` {{define "base"}} &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="/static/css/style.css"&gt; &lt;link rel="stylesheet" href="/static/css/normalize.css"&gt; &lt;title&gt;{{template "title" .}}&lt;/title&gt; &lt;/head&gt; &lt;body&gt; {{template "sidebar" .}} {{template "header" .}} {{block "content" .}} {{end}} &lt;/body&gt; &lt;/html&gt; {{end}} ```
base.html `` {{define "base"}} &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="/static/css/style.css"&gt; &lt;link rel="stylesheet" href="/static/css/normalize.css"&gt; &lt;title&gt;{{template "title" .}}&lt;/title&gt; &lt;/head&gt; &lt;body&gt; {{template "sidebar" .}} {{template "header" .}} {{block "content" .}} {{end}} &lt;/body&gt; &lt;/html&gt; {{end}} ``
` {{define "base"}} &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;link rel="stylesheet" href="/static/css/style.css"&gt; &lt;link rel="stylesheet" href="/static/css/normalize.css"&gt; &lt;title&gt;{{template "title" .}}&lt;/title&gt; &lt;/head&gt; &lt;body&gt; {{template "sidebar" .}} {{template "header" .}} {{block "content" .}} {{end}} &lt;/body&gt; &lt;/html&gt; {{end}} `
This is base.html: https://gist.github.com/cyantarek/a9308d4d970ae59c91e1cc7d85263438 This is index.html: https://gist.github.com/cyantarek/ca2636b79083b9b33b1fd26e55099893 This is new_post.html: https://gist.github.com/cyantarek/a9ecd31428b0fecd096d3c74b43fe638
Right now the best way to write android apps is kotlin. If you want you could use flutter
Thank you. This time, the backend works well! But if access frontend uri from browser, still got this error: ``` Warning: Missing translation for key: "The X-Total-Count header is missing in the HTTP Response. The jsonServer Data Provider expects responses for lists of resources to contain this header with the total number of results to build the pagination. If you are using CORS, did you declare X-Total-Count in the Access-Control-Expose-Headers header?" ``` Maybe it's a `react-admin` issue!
Thanks guys. I'll look into those packages.
Hi! Please check out https://g3n.rocks and #g3n channel in Gophers slack. 
Anyone knows how to signup for gophers slack?
I think aiming for Go on mobile is going to take much, much more time than you expect. Unity means coding in C#, but it handles making the Android/iOS build for you. I've worked on a (canceled) real-time multiplayer game with a Go server, and we went with Unity on the client, and protobuf for sending messages; it worked well. You could also try a browser game - phaser is a good 2D library, and protobuf over web sockets works just fine. That would involve even less set up than an app build.
Are you using GitLab and their CI system? If you are, [take a look at this](https://docs.gitlab.com/ee/ci/docker/using_docker_images.html); You can declare multiple jobs, and run some of them **inside** containers. Here is a sample project: ## .gitlab-ci.yml variables: DOCKER_IMAGE: $CI_REGISTRY_IMAGE/mycontainer stages: - build:gobinary - build:docker - deploy:docker build:gobinary: stage: build:gobinary image: 'golang:1.9' tags: [docker-runner] script: - CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o output . artifacts: paths: - ./output build:docker: stage: build:docker tags: [docker-builder] script: - echo docker build -t $DOCKER_IMAGE . - docker build -t $DOCKER_IMAGE . deploy:docker: stage: deploy:docker tags: [docker-builder] script: - docker login -u $CI_REGISTRY_USER -p $CI_BUILD_TOKEN $CI_REGISTRY - docker push $DOCKER_IMAGE ### Dockerfile FROM scratch ADD output /output ENTRYPOINT ["/output"] ### main.go package main import ( "fmt" ) func main() { fmt.Println("Hello world!") } ### Explanations The CI procedure will follow three stages: - `build:gobinary`: the GitLab Runner will download the `golang:1.9` container, run `go build` in it, and then extract the content of the `output` directory. - `build:docker`: the GitLab Runner will place the previous `output` directory next to the dockerfile, and then execute `docker build` - `deploy:docker` : the GitLab runner will run `docker push`. Please note that this last step works because, luckily, I have a single runner. If I were to have two, I'd encounter some issues; I'd have no guarantee that the `build:docker` and `deploy:docker` stages are run on the same machine. The `deploy:docker` stage would fail and say that the container I was trying to push did not exist. If you have multiple runners, you'd need to execute a `docker save` just after the `docker build` command, declare the save path as an artifact, and then run a `docker load` just before the `docker push`. (https://www.jamescoyle.net/how-to/1512-export-and-import-a-docker-image-between-nodes)
The Iris framework has been a reason for many [controversies](https://www.reddit.com/r/golang/search?q=Iris&amp;restrict_sr=on), so I would recommend against using it. * * * IIRC, each template with a given name can only be defined once. So you will probably need to `Clone()` your root template for every page. Alternatively, I would suggest to just make `title` a piece of your data and simply render it as `{{.title}}`. Defining templates within templates is, IMO, a road to trouble.
After running this ``` set GOGC=off go test -cpuprofile cpu.prof -bench=. -benchtime=20s ./php7 go tool pprof ./php7.test.exe cpu.prof ``` on windows I am getting ``` hp-parser\parser\position_builder.go 270ms 2.34s (flat, cum) 5.72% of Total . . 103: . . 104: return pos . . 105:} . . 106: . . 107:// NewTokenPosition returns new Position 50ms 50ms 108:func (b *PositionBuilder) NewTokenPosition(t *scanner.Token) *position.Position { 40ms 2.11s 109: pos := b.PositionPool.Get().(*position.Position) 180ms 180ms 110: pos.StartLine = t.Position.StartLine . . 111: pos.EndLine = t.Position.EndLine . . 112: pos.StartPos = t.Position.StartPos . . 113: pos.EndPos = t.Position.EndPos . . 114: . . 115: return pos ``` And this makes more sense. I have no idea why you are getting that. But I thought having some more data would help.
10 year here. Regret waiting so long.
For resources http://www.golangbootcamp.com/book/interfaces does not look too bad an intro to interfaces (and if you are struggling with ```io.Reader```/```io.Writer``` then you might be missing something about interfaces). For command line advice, I suggest using https://golang.org/pkg/bufio/#Scanner for reading. And writing ```fmt.FPrint``` will do just fine. There are examples in the docs that might make some things clearer. 
Nice \- love the last section. My handler is ugly because I want to pass configs: type HandlerConfig struct { PrintRequestsOnError bool PrintRequestsFile *os.File } type Handler struct { *HandlerConfig H func(w http.ResponseWriter, r *http.Request) error } 
Sorry, I cannot discuss assembler commands, I am new in it. I thought that `memory initialize` = `allocation`, also, I thought that memory allocation is slower rather memory operations. The article above explains to me why profiler shows so weird timing. At `scanner/lexer.go:488` we creating a new `zeroed storage` for `position.Position` and returns its address, it is quick. After that at `scanner/lexer.go:538` and `parser/position_builder.go:110` we assign data to zeroed object and Go starts memory initialization, it is slow. I have tried to change `scanner/lexer.go:488` to force initialize memory, see [gist](https://gist.github.com/z7zmey/10ac5ea8a766815ced968646f9888108)
https://github.com/xlab/android-go https://github.com/xlab/android-go/tree/master/example-egl
Cool, it works on Windows) I have not tested it on Windows yet. See [allocation\_new](https://golang.org/doc/effective_go.html#allocation_new), I think it is compiler optimization that works differently depending on the OS. Also, you can see my [gist](https://gist.github.com/z7zmey/10ac5ea8a766815ced968646f9888108), I tried explaining how it works, but it can be wrong.
Not going to be a popular opinion but... Tiny images are also non-debuggable images. The amount of time (and thus employer's money) I've lost trying to debug weird behavior of containers without so much as 'cat' or 'less' installed far exceeds the amount of money saved in smaller storage and transfer costs. Please stay away from 'from scratch' or ultra-tiny images as a base. Not even a huge fan of Alpine (mostly due to libmusl causing a lot of problems with the resolver) but at least in that situation one can ```apk add``` some tools in an emergency. Every time I have to debug a container with no support tooling in place the phrase "Do you hate your Operators?" pops into my head even though its not 100% fair. 
it should be an open slack group that you can just sign up with as usual. I just had to pick a username and a password and I was in. do you not get the option to join?
[removed]
Are you by any chance dealing with money, where you want two digits of precision because you need precise cents? The traditional answer in this case is to use integers to represent the number of cents you have. If you _always_ need things rounded to 2 decimal places, this may also work if you don't have money. It isn't necessarily the best choice in every way, and personally I'd implement every operation through methods, so I can do things like check for overflow or underflow. Floats can not be precisely rounded to two decimal points, because [the only precisely-representable two-decimal numbers are .00, .25, .50, and .75](https://stackoverflow.com/questions/3730019/why-not-use-double-or-float-to-represent-currency/3730040#3730040). If that is not an answer, this gets into some unavoidable, irreducible studying you're going to have to do on how to use floating point numbers correctly, which you're not going to be able to pick up from asking questions in online forums. It's an entire topic of study. I don't have a good suggestion, either, as I've never had to learn it ("just use ints" has always been good enough for me in my career). I'd recommend checking with a scientific-computing type forum, even if this isn't a scientific computing task. They should have resources for correct float usage.
well, you can always *choose* to use it simply as a design model - in a web service, you might have spawn a goroutine for each session, for example - but like any form of parallelism, it's only strictly *necessary* when performance becomes an issue and you need to leverage multiple processors.
Every http Handler request is called in separate goroutine.
Sometimes designs can be easier to understand when concurrent. The famous talk of rob pike goes into detail about this https://www.youtube.com/watch?v=cN_DpYBzKso
If you follow a microservices model, you'll find you're sometimes calling several other services to get data to fulfill your web request. In that case it can be quite handy to parallelize the outbound calls so they execute concurrently. Another use case is fire-and-forget calls, like analytics or notifications. Just a couple of examples, there are plenty of others.
Most commonly for simply running multiple blocking things at once. E.g. you might expose two web servers; one for normal HTTP on a public address and one for pprof or metrics exposition on an internal interface. Or you might have a GRPC server + a HTTP server. Only one can live in the main routine. There are also some instances where you want to have some kind of cache cleaning/flushing data/maintenance task running outside of the "hot path" of a request.
Every call to an HTTP handler in a web service uses a separate goroutine anyway. You might want to have some concurrency within that request though, for example, maybe you want to call multiple APIs at once and aggregate the results, that'd be an ideal case for using goroutines.
In terms of web services, there's still plenty of use-cases for goroutines, after bearing in mind that each request is processed in it's own goroutine too: * Making multiple blocking calls at once; for example, if you need to call multiple APIs in one request. Or maybe you want to execute multiple database queries at once, etc. * Running background operations; for example, maybe you want to keep something running after the request has ended and you've sent a response and the handler has finished. Or perhaps you have something else not even linked to the HTTP portion of your app, like some kind of process that periodically runs alongside your HTTP server. * Making blocking calls that can't be cancelled ordinarily able to be cancelled; for example, maybe you're dealing with something that may take 5 seconds, maybe it'll take 30 seconds, and the API exposed doesn't allow you to supply a timeout. You can choose to run that operation in a goroutine so that you can skip past the blocking call after a timeout that you want. The blocking call will still continue, but it's result would be ignored, and your other code can continue at least (this is handy in HTTP requests especially to ensure you don't have calls hijacked by rogue blocking calls). * For work that you can split into chunks to process faster over multiple CPU cores; for example, some algorithms for things like sorting, or calculating things can be made concurrent; these are operations generally bottlenecked by the CPU, so spreading them across more CPU cores can help dramatically speed things up.
[removed]
When you want concurrency. Let’s say your web server gets a request and has to itself make 5 separate requests to various data sources before responding. Instead of making those requests sequentially you can create a channel and pass it into 5 goroutines. They will send the requests and return the data over the channel concurrently. Instant performance increase. I’m on mobile so I can’t give an example but you’ll probably want to account for errors and timeouts as well as limiting concurrency. For instance if you need to make 1000 requests you might only want to send 10 at a time. For that I commonly use a buffered channel and sync.WaitGroup. 
so there is a distro called distroless?
I kind of agree, but ultimately, I don't. Good logging is important, that usually prevents me from running a debugger. I've learned to ls /proc to see which processes are running instead of using ps. I've learned to cat /proc/1/net/tcp to find the open ports on my running Go binary in a container. That lets me find the port that is listening on localhost which exposes pprof. `kubectl port-forward` lets me remote to that port.
This is an article that enjoyed a while ago: [https://rsmitty.github.io/Slack\-Bot/](https://rsmitty.github.io/Slack-Bot/)
[removed]
I see a lot of activity on the Gopher Slack #golang\-jobs channel. [https://invite.slack.golangbridge.org/](https://invite.slack.golangbridge.org/)
This is the most important response here probably. The reason you don't use it is because go routines are so fundamental with web services that it is handled in the standard library code or whichever multiplexer you are using. Within each request you probably want to keep your logic fairly simple, so it makes sense that you might not ever personally use go routines as a web developer.
nope, it's not.
While every language has high quality wrappers to interface with the operating system's scheduling, I have not seen an equivalent to Quartz outside C#, but so far I have not missed it.
I've been using pebbe/zmq4 for some time now, I greatly appreciate a pure Go version, Thx! I will be watching your repo closely, cheers!
https://github.com/GoogleContainerTools/distroless/tree/master/base
Great question. Have a look at the compulsory - https://www.youtube.com/watch?v=cN_DpYBzKso. (Concurrency is not parallelism) And also https://www.youtube.com/watch?v=rFejpH_tAHM (Simplicity is complicated) to get an overall feel of Go.
Quartz in C# is based on one from java... I think I'm going to write this project in java as this kind of scheduling is crucial
I’ve yet to run into any gotchas in 4 years of using them. If you have more info I would love to read it. Ultimately if someone is expecting to need to log into a container which is to be orchestrated, they are most likely using it incorrectly.
Not crazy about the "FROM scratch" on the final image, but otherwise really like it. Main complaint being, its not possible to troubleshoot a running app. Would need to perform a container rebuild, or copy out the binary to some other OS to troubleshoot. FROM a debian slim image or alpine linux doesn't add more than a few megs and allows for some troubleshooting if need be. 
Yes, that warning comes from React-Admin, and more specifically from [here](https://github.com/marmelab/react-admin/blob/55be22c/packages/ra-data-json-server/src/index.js#L95-L111). I guess you can simply add that HTTP header to the router, not a big deal.
react-admin required the header `X-Total-Count` when it is querying a a list (GET_LIST). You should add this header when returning a list and allow/expose it in the CORS. [react-admin doc on X-Total-Count](https://marmelab.com/admin-on-rest/RestClients.html#json-server-rest), admin-on-rest is the name of the v1, I don't know if it the new doc has this piece of information.
&gt; I thought that memory initialize = allocation No, it's not. Allocation refers to finding an unused block of memory, initialization means writing an initial value into it and zeroing means writing zeros into int. The quote clarifies that, as opposed to other languages, Go can only zero-initialize memory (as opposed to using a constructor to initialize it), AIUI. Allocation happens nevertheless at the same time. &gt; At scanner/lexer.go:488 we creating a new zeroed storage for position.Position and returns its address, it is quick. After that at scanner/lexer.go:538 and parser/position_builder.go:110 we assign data to zeroed object and Go starts memory initialization, it is slow. Again, I'm pretty sure you are seeing the effects of poor cache behavior. My assumption is, that when you are calling `(*sync.Pool).Get` it often returns a pointer to you that was previously `Put`, not one that was freshly allocated. If that memory area was purged from the cache, the first indirection accessing it (the first write in your code, currently `position_builder.go:109`) then has to fetch it from RAM, including doing some coordination with the other cores to invalidate the data. The following writes are then fast, because a whole cache-line was loaded, which also covers the other writes. In effect, I am hypothesizing that the issue is poor data-locality, thrashing the cache and leading to increased contention on the bus - all of which is what causes the slow down. By moving that first write into `PositionPool.New` instead, you are not actually speeding anything up, but you are instead simply moving that cache miss to a different function. --- To test my hypothesis, I decided to download your code and run the experiment I suggested [here](https://www.reddit.com/r/golang/comments/8qrq5b/need_help_with_profiling_pprof/e0livce/), removing all references to `sync.Pool` and instead using `new(position.Position)` and `new(Token)` directly. I saw a total speedup of 18% with `GOGC=off` and 11% without (in each case removing the `-benchtime` parameter and running the benchmark three times). And once you remove `sync.Pool`, the `NewTokenPosition` method no longer appears in the profile. Really, this is a cache-issue and your usage of `sync.Pool` is very likely counterproductive.
Is your username an email address?
no
Does your password contain an @? Might need to change that or escape it
Nope
Places where I've implemented a use of goroutines in backend web dev: - Running an HTTP and HTTPS server at the same time. - Fire-and-forget calls for logging or doing a big db operation where the consumer doesn't expect the operation to necessarily be done when the server responds (documented). - Doing API polling every n minutes
&gt; Doing API polling every n minutes What means polling in this context?
Just pulling data from an API and putting it into our database every 5 minutes.
This is painfully obvious when you're writing an ajax call and you've messed up both the frontend *and* the backend, so you end up with the repeated stacktraces of 20 threads filling up your terminal and your browser locking up.
What about this? . 450ms 537: pos := new(position.Position) . . 538: 6.77s 7.08s 539: pos.StartLine = l.File.Line(firstChar.Pos()) . 290ms 540: pos.EndLine = l.File.Line(lastChar.Pos()) . . 541: pos.StartPos = int(firstChar.Pos()) . . 542: pos.EndPos = int(lastChar.Pos()) In this case, the script assigns data to the position immediately after `new(position.Position)`. I deliberately added `-benchtime`, to stabilize profiling result.
Shouldn't APIRequest and APIResponse's JSON fields be interface{} rather than map[string]interface{}? For example if an API endpoint just responds with `false`.
In what way? Rust borrows ideas from C as well as functional ideas from Haskell, and I think it's valid to say it's closer to C than Haskell. I don't know what metric we're using for C-like, but [this Wikipedia article](https://en.wikipedia.org/wiki/List_of_C-family_programming_languages) doesn't include Rust, but it *does* include R, and calling R C-like is a *huge* stretch since it's more functional than procedural. I go about solving problems in Rust similar to how I'd solve them in any other C-like language, just with more attention paid to object lifetimes and far more immutable variables. In fact, I feel like I solve things more similar to how I'd solve them in Go or C than with Java or C# (higher quantity of smaller objects vs inheritance tree).
Do you have the same proxy setting for your SCM? Example if you are using git: git config \-\-global http.proxy http://USER:PASSWORD@PROXY\_ADDRESS:PORT
This is not an experience report. 
Yes
It's documented here: https://golang.org/ref/spec#Composite_literals &gt; A slice literal describes the entire underlying array literal. Thus the length and capacity of a slice literal are the maximum element index plus one. A slice literal has the form 
Much as I like Go, I wish it had algebraic datatypes. The Maybe pattern is so darn nice. (Algebraic datatypes would also help with error handling, at that.)
Hmm... everything should be working fine then. Have you checked whether the proxy works properly with your credentials? You can verify it by accessing an external site (like google) though it: http_proxy=http://USER:PASSWORD@PROXY_ADDRESS:PORT wget www.google.com
&gt; ...we have realized that Go is not JavaScript and that it is extremely difficult to master two technologies equally well. I bet that most developers know many languages at a good-enough-to-hack-some-code level, and exactly one language at expert level. The decision to go back to the language they know best is thus perfectly reasonable.
Maybe is dope. We need not just algebraic types for Maybe but also generics, though.
I m on windows is it an important information ?
lsof is more convenient than finding stuff for hours in /proc. For instance once I didn't not understand why some networking was not working, 2sec lsof command and I saw some SYN_SENT TCP connection blocked.
I think the takeaway here is that if you don't understand your problem domain, you're better off using a language you're proficient with.
t;dr Some way to protect against nil being passed as a pointer or interface. Doesn't look much like an experience report either. I'm skeptical if it's that big a problem, I've accidentally done it a few times in Go but they were always the easiest bugs to find/fix.
It is. Your command shell is probably PowerShell now by default. It tries to interpret special characters. Make sure to enclose the entire proxy address in double quotes (") on the command line.
You of all people should know: if you’re making http calls, use a cancelable context 😉
Agreed, and in our microservices-based distributed systems _Tracing_ (eg. opentracing with eg. Jaeger or what-have-you) has taken over the previous predominance/purposes of structured logging really. Mostly for the UX and especially the _underlying cross-service-capture-by-design principles_. Old-school logging is still technically in place as functionality, but mainly used for "only errors" mostly right now. (Lets us grasp bad stuff happening before we can get to tracing or that prevents completion of traces.) All still in flux anyway. &gt; I'll go so far as to say that needing anything beyond the stdlib's `log` package is a code smell. Not sure about that, fewer-allocs-and-ops/ns are always nice to have (even if the feature is used sparingly) if someone out there did feel motivated enough for obsess for weeks or months over achieving this cleanly. =)
Definitely, https://golang.org/pkg/net/http/#TimeoutHandler is a must-have!
Hi everyone! I'm very much a beginner to Go and this is my first public project. Any feedback would be highly appreciated. Thanks!
You can try making your username and password percent url encoded and see if that makes a difference
That's why the directory I passed to `docker build` was `./bin`, that only zips up the `bin/` directory.
Oh cool I didn't know about the `.dockerignore` file. I'll check that out!
Yeah, I was (and sorta still am) working on a functional language that compiles to Go and adds support for sum types and generics. It won't go anywhere because I know fuck-all about compiling, but it's a great learning experience for me, and the more I work on it, the more I become convinced of the feasibility of the approach.
Yeah, I'm less interested in the nil problem and more interested in generally representing "this thing can have form X or Y or Z" in a sane, ergonomic, performant way.
Aha :) I'll post a few histograms comparing latency between cgo-based transport and pure-Go based transport in my favorite application. Nothing earth shattering, between the pure-Go transport has a better figure of merit.
Goroutines are a tool for doing things concurrently. Concurrency is not parallelism. It's important to understand the distinction. Parallelism, often a represented as threads, is a tool you use when two tasks can happen entirely independent of each other. Think of the various departments in a company. They work together but they have very isolated domains. For example finance, marketing, R&amp;D. Each of these can work in parallel to achieve a goal. Concurrency is similar, but different. In concurrency imagine a kitchen in a large restaurant. Here I'm going to use the line cook analogy. When an order comes in, let's say for an entree. The tasks are handed out to the specialist who prepares their part and passes it along to the next chef/cook in line. At the end all of their work comes together to complete the goal. So, when should you use concurrency? When a goal has two or more tasks that can work independent of each other towards the same goal. Let's say you needed to write an application that transcoded a media file from one format to another from an incoming stream and write the conversion out to another stream. \`\`\` func Recv(conn net.Conn, out chan \[\]byte) {} func Transcode(in chan \[\]byte, out chan \[\]byte) {} func Send(conn net.Conn, chan \[\]byte) {} trans := make(chan \[\]byte) send := make(chan \[\]byte) go Recv(.., trans) go Transcode(trans, send) go Send(..., send) \`\`\`
This perspective has always confused me. I disagree that nil bugs are not a big deal, but let’s set that aside as opinion and just consider that introducing Maybe would not only make code more secure (whether by a little or a lot as we would differently say) but also easier to read, write, and organize. I don’t understand why this is something someone wouldn’t want. That said I only disagree with your route to the conclusion; I personally think the conclusion is fine. Nil bugs and lack of generics have to be weighed against the compile time cost of losing incremental compilation. I think inside of Google the solution is obviously to forgo generics but I have never succeeded in understanding why someone with a dependency tree any smaller would opt out of generics, and the language is in theory for not just Google.
Meh, static analysis based on conditionals ala Kotlin (or @Nullable in Java w/ modern analyzers) would be cleaner. All you need is a way to say pointers and interfaces can be nil (and not with syntax change).
Does your use name or password contain any special characters, and if so, have you tried url encoding each of them? Also have you tried putting quotes around the entire url to prevent the shell from interpreting any special characters? 
Or improve kotlin's performance?
No idea why you're getting downvoted for this. It sounds like a great project to learn with.
On the web app context: processing email/alarms and long running calculations (that go over the whole database, say).
[removed]
[removed]
and kill off the jvm 
I wonder if the author (and everyone else) is aware of SGo, a dialect of Go that attempts to tackle this very problem: https://github.com/tcard/sgo
Works for me - though it bothers me that the binary needs to be in that folder for the icon to work.
Oh! Hahaha... I didn't realize the first Quartz was Java. 😇
[removed]
That's more like making your own alpine than not using alpine.
I'm thinking of when you run across a website you've never heard of an import path. I guess my statement was too broad. 🙄
This is weird. I feel like, in practice, a \`nil\` would rarely be passed to a function unintentionally. Such a variable being \`nil\` seems like an error that should have been caught further up the call chain.
And how is that different from running across a github user you've never heard of?
You're making a sliding scale problem into a binary problem. It's not "are nil bugs big deal or not" or "it's easier to read and write". It's "how much easier it's to read and write" and "how frequent is this bug we're trying to prevent, how well can we prevent it and is the cost of preventing it acceptable". This proposal fails on all three counts. From experience, the 'nil' problem is infrequent and easily fixable. The proposal only shows the most trivial use cases. In real programs the number of scenarios where compiler can prove "this value is definitely nil" property is small. For example, imagine this: type Foo struct { Number *myNumber } func inBetweenFunction(f *Foo) { plusOne(f.Number) } Good luck writing a compiler that can detect that f.Number is certainly nil, especially when crossing package boundaries. You just can't prove this in general case and doing anything that is non-local explodes into exponential running time (you have to trace the flow of each value across functions, taking into account conditional branches i.e. if myCondition { f.myNumber = &amp;myNumber{5} } And given how rare this issue is, how the proposed solution doesn't solve it 100% and how adding such checks by default would unacceptably slow down the compiler, sullying the language with this ugly (and confusing, if you come from C++) syntax makes no sense. Go is about saying yes to a small number of really good ideas. If you want a language that spares no effort to provide nullability checks and more, you already have Swift and Rust. 
That looks really cool! I hadn't seen that before. Once it goes out of alpha I might try it out. Would especially be nice if it would merge with Fo: https://github.com/albrow/fo
&gt; Go is about saying yes to a small number of really good ideas. The party line is symmetrical. I can say it about your ideas and you can say it about my ideas without either of us meaning anything at all. &gt; Good luck writing a compiler that can detect that f.Number is certainly nil To be clear, no one (in this comment chain) wants to do this. We were discussing Maybe, which is a generic sum type, and the compiler tech for that has existed since the 60s. In addition, a nonnillable pointer type which is closer to your hypothetical exists at present in Rust (there may be earlier precedent I’m not aware of). &gt; This proposal fails on all three counts. I don’t know how to respond to this assertion. I think clearly there is some hard-to-quantify aspect of what we’re discussing that maybe has to do with personal disposition or something, because having used proper sum types I just can’t empathize with proudly omitting them and instead embracing the nasty makeshift solutions Go offers like iota declarations and runtime typecasting switch statements with their unintuitive holes (e.g. an interface being a subset of another interface means the switch cast order matters).
It is. And not just to learn with. I think the Go runtime is perfect for writing DSLs on top of. The two just seem to fit really well together. Here's one for lisp that's fairly well used: [https://github.com/glycerine/zygomys](https://github.com/glycerine/zygomys).
[removed]
I agree. Very rarely do I declare an empty pointer before I need to use it (`ptr := &amp;SomeType{}`). And if I'm getting the pointer from a map I generally check that it is usable before passing it on...
Wut? Kotlin already has good performance in all of platforms (including native where it's likely better than Go due to LLVM optimizations). Channels like [this](https://github.com/Kotlin/kotlinx.coroutines/blob/master/coroutines-guide.md#channels)?
There are many uses for goroutines, like Futures or scatter/gather processing as mentioned in Peter Bourgons article https://peter.bourgon.org/go-for-industrial-programming/. Or for handling operations internally like Dave Cheney demonstrates in his 2015 talk “Do not fear first class functions“: https://m.youtube.com/watch?v=5buaPyJ0XeQ The nice thing about an operations channel in your struct is that it enforces sequential processing, so you can mutate state without having to deal with locking (explicitly - the goroutine implementation uses locks internally of course) Being able to cancel your operation using contexts also requires channels. So there are a lot of cases where channels make sense and make your code easier to understand. 
That's exactly the problem. It happens rarely so rarely that you forget to create a check for the nil case in places where it's actually allowed to happen. Because you're used to stuff never actually being nil. 
Yes they're easy to fix, but never having the bug is obviously better. 
Keep in mind this only applies to pointers and interfaces. If you’re not checking for nil at the beginning of a function that accepts those, it’s programmer error. It’s the same argument for always checking the returned error value from a function call. Defensive programming has been a thing for a long time, I’m not sure why we need to change the language to accommodate a programmer that is too lazy to perform input validation. 
I can't discuss things on the "just use generic sum type" abstraction level. There are many possible implementations of that idea, none that I consider good as someone who cares more about writing fast, reliable code quickly than fixating on some supposedly great idea, like "sum types", that for (not really) inexplicable reason is not used by top 5 programming languages used to actually write 99% of the code out there. If you think a language X has it solved, that tell us what that language is, how much code you wrote in that language and use at least a few personal anecdotes how you suffered terribly from nil problem in language Y and language X totally solved it for you. I did program in Swift a little bit which has stellar compiler support for nullability that is supposed to fix the "I dereferenced nil accidentally". Swift doesn't actually prevent accidental nil access. It allows you to declare "this variable or struct member can be nil" and then the compiler will complain if you're accessing it without first checking if its nil or not. And that's not much of a solution because you end writing a lot of annoying "is this nil" checks in cases where you know that the value can't possibly be nil (as a side effect you bloat your code with unnecessary checks). And because writing those "is this nil" checks annoys so many people, Swift had to concede to reality and added a forced dereference in which case you're where you didn't want to be as in "trust me, compiler, I know what I'm doing, this pointer can't possibly be nil". Unfortunately bugs don't care about your confidence level. So that's my opinion on solving "nil pointer" by using sum types and having compiler enforce writing boilerplate "if v != nil" checks. I would rather not have that and I'm happy to fix the occasional nil pointer dereference. 
I completely agree that that's a better solution. But I didn't want to go into the different options for solutions a lot. The main reason I chose to write about the one in the article was to show that this problem can also be solved without them. So that even in case we don't get algebraic types and generics in Go2 we could still solve this problem. 
So the problem is solely on the programmer. If you accept a pointer or interface the value _can_ be `nil` regardless of what you think and needs to be tested. Period. There are no surprises, no excuse to forget. This is not a problem with `nil` it’s a problem with programmers. Removing this feature from the language is addressing a symptom, not the problem, and therefore won’t fix anything. 
I don’t believe Swift solves the problem and no one in this comment chain represented Swift as having solved this problem. Some languages I think _do_ solve this particular problem (nil) well are Rust and Idris. Your bit about the compiler generating boilerplate checks seems intentionally unimaginative. A tagged union was the low hanging hypothetical implementation, not that the implementation could possibly approach the complexity of the workarounds Go programmers are forced to amass in large code bases, and for bonus points it’s different in every code base since there is no built in standard approach.
I disagree and I think your argument is quite weak. You could make that same argument against the need for static type checking. Why would you need it, if you can check at the start of each function if the arguments are the right type. If it's the wrong type you can simply return an error. Why would you solve this problems that only programmers have that can't be bothered to add these critical checks everywhere? I hope you see my point. A programming language is there to make the programmers life easier. If it can help the programmer find bugs, why shouldn't it do so? 
All programming language features are there to help "lazy" programmers. Static type checking is there to help "lazy" programmers. Why don't you just write all your code in C? It's a programmer error not to free your memory or to free it twice. What is your actual issue with the compiler helping a programmer not to make mistakes. We're all human and humans make mistakes. If our computer can help detect those then that's a good thing right? (same holds for checking the returned error value, I definitely use a linter to help me find the place where I forget) 
What Go version are you using? FWIW, that's a completely different function, doing something completely different. When I disassemble that, it becomes obvious that most of the time is spent in calls to `File.Line`, which makes complete sense, given how that's implemented. The original "problem" pointed out, disappears on my machine, under go1.10.3 - i.e. NewTokenPosition just does not appear in the profile *at all* and similar functions have predictable and reasonable runtime behaviors.
I’m responding to your comment not the article. If you want non-nillable types then more power to you, I suppose. So long as it doesn’t cost in performance. &gt; It happens rarely so rarely that you forget to create a check for the nil case in places where it's actually allowed to happen. I forget a lot of things sometimes. That doesn’t mean the language needs to be compensating for my own mistakes. I pick up and move on. The “places where it’s allowed to happen” are clearly defined and easy to distinguish and the documentation support in Go is pretty great (I use `go doc` a lot) so there are plenty of ways to compensate for the issues and find success. Like I said, I’m not trying to say “don’t add things to Go,” but this trend of “X language supports Y feature I want but I want/have to use A language that doesn’t. A language should support it” isn’t going to make the world a better place. Languages exist with strengths and weaknesses and trade offs to accomplish different things. If we homogenize them all were going to lose a whole lot. Rust is great and boasts pretty solid protections, but it comes at the cost of compile times and simplicity to introduce new programmers. Go is designed _for_ new programmers. And has striven to keep compile times as low as they can (which Rust has worked towards too, not discrediting them). So in the long run I don’t think it’s worth adding to Go, and as a Go programmer that means being diligent or building your own solution. 
Note that they [changed the code](https://github.com/z7zmey/php-parser/commit/93bc62f52d037f54040f79a85d9febf47072e1a6) since originally posting this thread, with the specific result to get what you are seeing (and I just realized that in the process they made it incorrect…). I tried to explain the results [here](https://www.reddit.com/r/golang/comments/8qrq5b/need_help_with_profiling_pprof/e0o1q9c/).
Oh wow, really? It's already so far, damn that's cool and good to know!
I also tend to think nil errors are not frequent enough in go for me to care about it. I would rather have a const keyword à la c++. Because I spent much more time chasing mutability bugs than nil dereferences (and AFAIK it is trivial to implement). This billion dollar mistake thing is a bit overrated IMO.
How is Rust solving it any differently than what I described? Show me the actual snipped of code where you're defining maybe-nil type, pass it to a function and how do you avoid dereferencing nil without writing "if !nil" boilerplate. Also, at the risk of letting you ignore answering the above: how much code did you write in Idris? How much code did you write in Rust? What was the largest code-base in any of those languages that you wrote personally? The largest code based your worked on as part of the team? I ask for that because practice of programming is, in the end, about writing code that works, not worshipping features of programming languages. I don't consider nil to be a program because I worked on a million lines of code C++ programs and of all the things that were difficult about that, nil-dereferencing wasn't on the list. 
From what I've seen/heard Rust makes a lot of bugs non-existant, but I'm not using Rust and have no plans to do so ... because there are costs associated with not having those bugs anymore. Having two different kinds of pointer is not a trivial thing to just flip on.
&gt; just consider that introducing Maybe would not only make code more secure (whether by a little or a lot as we would differently say) but also easier to read, write, and organize. I don’t understand why this is something someone wouldn’t want. I'm not saying I don't want Maybe, that depends on a lot of things. I'm saying that there are costs as well as benefits with everything and introducing a new kind of pointer that just says "not nil" seems like a pretty big cost for a small benefit. There other things I'd rather the language change to accommodate and there are a lot of things I'd rather the code team's energy be occupied by.
&gt; The main use case for nil is indicating that a value is “missing”. I’m mostly against this. I think in most cases, you’re better served with a boolean that marks whether the value is present or absent. In the usual case (value is present), it takes up the same amount of memory but with better locality and less fragmentation etc. 
Thes a new project called fo which is “functional” go
This is absurd mate. We can discuss the ideas in front of us without vetting each other’s CV. The answer to your question is: pattern match. For example: mapMaybe : Maybe a -&gt; (a -&gt; b) -&gt; Maybe b mapMaybe (Just v) g = Just $ g v mapMaybe Nothing _ = Nothing
Is it that hard to check for nil? I mean plenty of other languages, especially dynamic ones (and don’t get me started on JacaScript) always need this kind of consideration. If you’re used to it, it’s not that bad. Though I completely understand if the compiler helps you in so many cases, why does it not help you here? I mean, I get that. But habits are important in programming. Plus the error is indeed super common and I encounter it here and there. When I do, I immediately know what it’s about. So is it a huge issue? I don’t know. I think it could be better sure, but I’m also not real concerned about it either.
Sounds like JavaScript has institutionalized you man 😂
??? JavaScript has null, so not seeing any relevance at all. 
https://invite.slack.golangbridge.org/
Which you can if() in a truthy Boolean kinda way. It also has undefined too. Maybe Go should introduce another type? I think nil is fine as is. I dunno.
Do you have a GitHub link? I’d love to contribute. A lot of people start this kind of project but then end up abandoning it. This was pretty promising the but the dev gave up. I wasn’t a huge fan of the syntax. http://oden-lang.github.io/ This one is a beginning of an Elm to Go transpiler but dev stopped about a year ago. https://github.com/elm-tangram/tangram This one is a new language but it’s interpreted rather than compiled right now. https://github.com/faiface/funky This one is OCaml to Go https://github.com/rhysd/gocaml
&gt;Having two different kinds of pointer is not a trivial thing to just flip on. I've been using rust for a few months now (and it's definitely not the right hammer for every nail). But I'm not sure what you mean by this.
This is not Rust, which you claimed was the language that solves the nil problem. I specifically asked for Rust example because I know it'll show the "if nil" boilerplate problem I mention and I have a reasonable chance of mapping it into an understandable syntax. So of course you respond with some obscure Haskell (?) snippet. Which, btw, has the same boilerplate problem. Assuming we're still talking about nil handling, 66% of this program is boilerplate to define a Maybe type and then handle the nil case. 
&gt; We were discussing Maybe, which is a generic sum type, and the compiler tech for that has existed since the 60s. Let's have a look at how we would implement sum types. But first it's important to look at prior art. An implementation in C/C++ looks like this: (spoiler alert: UBs abound) 1. We start with `union`. Members of a `union` in C/C++ share the same location. This means if there are two members that are different sized, the larger will be chosen. If you have this: union Maybe { int value; int err; }; if you have a `Maybe` with `value` filled, reading a `M-&gt;err` will either be a undefined behaviour or if you use modern C++, it'll be aliased to the `M-&gt;value`. It can best be emulated in Go as thus: type Maybe struct { valOrErr interface{} } 2. So we come to the tagged union, which is a struct that can be best emulated in Go as thus: type Maybe struct { isVal bool; valOrErr interface{} } 3. All C-style languages that provide Maybe handles Maybe in the above way. Cleverer languages store the tags using a form of [pointer tagging](https://blog.chewxy.com/2013/12/10/pointer-tagging-in-go/). Now let's look at how sum types are implemented in ML class languages: data Maybe a = Value a | None This is represented internally as a graph. Graph reduction machines that read the rules of something like this: f : Int -&gt; Maybe Int f x = case x of Int -&gt; Value x None -&gt; None And then applies the rules on other parts of the graph while reducing it. After a number of reductions, in the code generation phase, the compiler produces code that looks like the above scenario with C. GHC even does the pointer tagging trick in Haskell. Again, you can emulate this process in Go by doing something like this: func lift(a interface{}) interface{} { switch a.(type) { } } This can obviously be translated into internals as well. But the key thing to note is this: all these do not come for free - it touches a large surface area with additional considerations on these fronts: 1. Code bloat 2. Compiler analysis time increments 3. Runtime support bloat. 4. User friendliness (do users have to learn a borrow checker?) I've implemented generics in Go a number of times and still am, but rest assured that there is nothing simple about the simple Maybe. There's always a cost somewhere. And the surface area touched is huge.
I have a struct that contains a `time.Ticker`. When I call `.Start()` on that struct, it sets an interval on the Ticker, and runs a goroutine that listens on `Ticker.C`. Then the Ticker fires, the goroutine performs an action. It's a super simple, very cheap scheduler in my case, basically. I also have a `.Stop()` on the struct that stops the Ticker and sets a semaphore to tell the goroutine to return.
It’s Idris, which is the other language I said solved it well. It’s not Haskell or obscure; it would be hard to write much Idris without pattern matching. Here is the analog syntax in Rust: match maybe { Some(v) =&gt; Some(g(v)), None =&gt; None }
You don’t need a substructural type system for sum types. There’s no need for a borrow checker. My point isn’t about what you _can_ do with sum types, it’s about what you _can’t_, which is easily write incorrect code. You can “emulate” it in Go but it makes you the human do a compiler’s work and check the union tag, which in a huge code base someone will forget to do eventually (ime, frequently), considering they last many years. Algebraic types don’t need to bloat a binary. The most it absolutely needs to add to the binary is the union guards, which is what Go expects humans to add themselves.
You do need an increased analysis time, which increases compile time. 
[removed]
Sure, maybe, though to be clear compilation time doesn’t predict binary size. And anyway, yes, obviously, implementing them properly would change the way the compiler works. Whether it requires increased time in some areas or allows some assumptions that reduce time in areas and how the analysis will work out in typical and edge use cases of the compiler would be worthwhile to look at, but I can’t imagine that if the community decides on it as a direction that data could show a high enough cost to change our minds.
I concede you have a point. I'm personally in favour of increasing analysis time, and instantiation of abstract types into concrete types which would lead to codebloat and compile time increments for faster performance. But my main point above remains: 40 years of compiler tech has not reduced the available options for us - there isn't a "good" choice, more of a "here are 3 options pick 2". 
I think he meant to check the value's existence with assertion or just checking "!= nil" ratherthan truthy check
``` docker run -it --pid=container:mygobinary \ --net=container:mygobinary \ --cap-add sys_admin \ alpine sh ```
&gt; This perspective has always confused me. I disagree that nil bugs are not a big deal [...] In my experiences, the nasty bugs in unsafe languages are not about null pointers most of the times but rather the absence of bounds checking and automatic memory management. However, runtime bounds checking seems to be dispensable even in languages without null like Haskell, Rust, and Swift. Even if we have sum types and pattern matching in Go, if we write match v { case Some(x) =&gt; /* use x */ case Null =&gt; printStackTrace(); } What is the difference than the compiler inserting it for us as it already does? Except that we can do something other than printStackTrace? To me, pattern matching and ADT are more about the elegance and convenience instead of safety. 
possibly mutable vs. immutable borrows?
At which point we'll have to agree to disagree that this is acceptable cost to pay to avoid exceedingly rare nil dereferences. If I expect the value might be nil, then I can do: if v != nil { // do something } But in practice, in real code that passes around pointers, the pointer is "known" (to the programmer but not the compiler) to be non-nil so all this boilerplate is unnecessary. It's code you don't need. Which was my point from the beginning: that this boilerplate and code bloat is not worth it. 
use goroutine to handle seperate reqeust 
Go does have a Maybe pattern, though: if foo, err := someFunction(); if err != nil { // } else { // } You can't just "accidentally" use a nil value: foo := someFunction() // compile error
Thank you very much. That's the key problem. The second version document should be here: https://marmelab.com/react-admin/DataProviders.html But there isn't exist any `X-Total-Count` content. I have added it to the source as: ``` r := gin.Default() r.Use(cors.New(cors.Config{ AllowOrigins: []string{"http://localhost:3000"}, AllowMethods: []string{"GET", "POST", "PUT", "PATCH", "DELETE", "HEAD"}, AllowHeaders: []string{"Origin", "Content-Length", "Content-Type"}, ExposeHeaders: []string{"X-Total-Count"}, })) r.Run() ``` It doesn't work. Still has the same error.
I have added `X-Total-Count` to the `ExposeHeaders` of `gin` framework, still not work.
I also read the default config [here](https://github.com/gin-gonic/contrib/blob/master/cors/cors.go#L79), don't know why can't add that header.
I don't think we need that for the following reasons - keep the language simple. Coding and validity checking will remain easy. - nil is just a particular value like any other. Make sure you don't pass invalid values, or check input if you can't exclude the possibility the get an invalid value. - use panic recovery in critical tasks to mitigate runtime errors like this one that can cost millions of dollars. - references have constrains like not be reassignable to preserve the non-nil invariant, and which limit it's usefulness. - a nil dereferencing panic is equivalent to a division by zero error. You prevent nil errors the same way you prevent division by zero errors. No language defined a non-zero floating point type. - increasing the complexity of the language increase the probability of bugs. 
Actually theres been a few bug checkers in the past 5-10 years that have each caught hundreds of bugs in linux due to programmers mistakenly thinking pointers **cant** be null or are not network packets or not unsafe user level pointers when they actually are. So this is a real issue that affects real developers at scale. 
Scratch docker containers are the best thing ever, as a security engineer. 
You can build one for Go too! It's not that difficult to write an alias analysis program. It's just undecideable :P
The x in your logo is very unfortunate looking.
Hi I'm looking for some directions too but more for the game mechanics / engine of mmo. How do you manage the multiple events from actions, quests, xp , achievement, rewards etc and the snow ball effects with multiple players. And how to store those informations in a efficient way. This blog resume the kind of problem I'm trying to solve : [https://theburningmonk.com/2014/07/here-be-monsters-message-broker-that-links-all-things/](https://theburningmonk.com/2014/07/here-be-monsters-message-broker-that-links-all-things/) If you have any links, experiences on that subject : you are welcome.
here is the initial preliminary little study: - https://gist.github.com/sbinet/07b5fa628b5278498eea612a0c4b65c3 - `nanomsg`: [go-mangos/mangos](https://github.com/go-mangos/mangos) - `zeromq`: [go-zeromq/zmq4](https://github.com/go-zeromq/zmq4) - `czmq`: [pebble/zmq4](https://github.com/pebble/zmq4) and my favorite application: - https://github.com/sbinet-alice/fer/tree/master/_example/cmd/fer-ex-web-ctl
Hell yeah. PM me
Valid point - but I think the op is suggesting something like kotlins 'int?' The SQL package has a few optionals/maybe in it
https://tour.golang.org/moretypes/1 https://dave.cheney.net/2017/04/26/understand-go-pointers-in-less-than-800-words-or-your-money-back
Golang allows pointers to the underlying memory of a value. This is useful because when you pass a non-pointer to a function it is copied. Here’s an in depth guide on the subject: http://www.golang-book.com/books/intro/8 I recommend reading this book in addition to the official Golang tour because it has additional information and is easy to understand for new programmers. 
I'm aware that I can convert currency into cents yes, but at the moment this was not the case. I was a little bit surprised actually that big decimal is not built into the language and thought that big.Float could substitute big decimal. I couldn't find much information about this from Google so I made this post. I think for now I won't go deeper into the topic and will use the libraries suggested in the other answers.
Ampersand-&gt;Address Shit I guess Asterisk starts with A too
Take the Tour, especially from here on: https://tour.golang.org/moretypes/6 
Actually even pointer are passed by copy, it is just the copy points to the same underlying address. Commenting just to avoid confusion in newbie.
It's a star.
I took it man , thank you for the tip
That is to say; everything is passed by value, pointers are values too, they just refer to the location of another value.
For me I can't get git to work with a proxy with authentication. That is why I locally have a Cntlm running. Afterwards you just need to set the http_proxy, https_proxy and no proxy env, configure your git and you are good to go. 
look : players := []string{useraddr} I made this slice but it show an error : Cannot use useraddr (type *net.UDPAddr) as type string in array or slice literal
look : players := []string{useraddr} I made this slice but it show an error : Cannot use useraddr (type *net.UDPAddr) as type string in array or slice literal
&gt; The solution used by Go is: do nothing. But Go has annotations already, you have this boxing overhead java has but without type safety.
`players := []*net.UDPAddr{useraddr}`
Thank you man 
thanks dave cheney provided a brilliant primer to get me started!
&gt; Good luck writing a compiler that can detect that f.Number is certainly nil, especially when crossing package boundaries. You just can't prove this in general case and doing anything that is non-local explodes into exponential running time What are types?
What about the generics attack on the type systems?
I am using go1.10.1 darwin/amd64. There no so big problem with `File.Line` but probably I will replace by my own realization later. If switch lines there is still problem with first assertion ([pprof output](https://gist.github.com/z7zmey/39d2841cd256d2d217c453a6b310992b)) . 630ms 537: pos := new(position.Position) . . 538: 9.55s 9.55s 539: pos.StartPos = int(firstChar.Pos()) . . 540: pos.EndPos = int(lastChar.Pos()) 50ms 470ms 541: pos.StartLine = l.File.Line(firstChar.Pos()) 20ms 360ms 542: pos.EndLine = l.File.Line(lastChar.Pos()) And now I cannot understand why when I replaced sync.Pool.Get() by creating new object, `Lexer.createToken()` spend more time but `PositionBuilder.NewTokenPosition()` on the contrary less. I use profiling with to find bottlenecks, it's just easier to run it with a benchmark
great. I completely forgot about using .dockerignore . I don't ever want to trust writing a binary out to disk then pulling it back into another image. Not had anything bad happen, but just doesn't feel right as all my builds are happening in short lived docker containers on k8s. plus our code bases are in KBs and production docker images average about 10meg
Also look at: https://www.reddit.com/r/golang/comments/8fjpjh/why_mutating_a_value_receiver_accepted_by_a/
“If at first the compiler complains try the other your memory’s lame.”
 var err = new(C.GError) C.notify_notification_show(n, &amp;err)
`new` already returns a pointer. Try just removing the `&amp;`.
He needs a pointer to a pointer. At the same time, using any form of `new` in that function call defeats the point of the second argument, which is basically the equivalent to an `error` return in Go.
You're right. I didn't notice the double pointer. I haven't had my morning coffee yet :)
1. int
Need a one liner.
Well I did this and it worked: new(*C.GError)
I really enjoyed this post, I definitely agree with your points near the end about the alternative solutions. I actually stumbled across this post on Google and was hoping to find more discussion about this over here on Reddit. I've been looking into all of this error wrapping stuff recently and trying to decide the best way to tackle it. One way I've approached it before is very similar to pkg/errors, and is sort of similar in a way to this approach in that it used a linked-list to build a stack of errors. One problem I encountered was the fact that this information was captured in another type (`Wrapper`) that contains a field for the error it's wrapping, and a pointer to the previous wrapper. The problem with this is, the wrapper is also an error, so you can wrap a wrapper, at which point you can have a chain of errors that branches into 2... it makes absolutely no sense in reality, and should never happen, but it's been bugging the hell outta me because I know that it _could_ happen - as in the API permits it to happen. This post has shown me a way that I can possibly get around that issue, which is great. This approach is simple, and quite elegant. Like the upspin errors, it can also be extended quite easily to fit the needs of your application (for example, including information about the user for which an error occurred, etc.)
I strongly suggest that you are trying to read up on assembly and how modern CPUs (in particular caching) works, if you want to micro optimize like this. I don't really have the time to go through all of your code and its bottlenecks myself, TBH. IMO that large number you are seeing is likely caused by stalls in the CPU, which is usually caused by cache-misses or branch mispredictions or the like. All you can really do is trace the slow instructions in the assembly and see where its arg is coming from and how you might be able to make it more cache-efficient. Or use (on linux, don't know the darwin equivalent) perf, which can give you more insights into how the CPU is behaving. Sorry, but I can't be of more help at this point :) Your problem is almost certainly not allocation-overhead though.
Thank you. Anyway, I have gotten a lot of information and things that I need to learn.
I had the same question when i started with go and here is my way to understanding it: It helped me to spell out what happens very precisely, so here is the code and than how i read it in my head: package main import "fmt" func main() { a := 10 fmt.Printf("The value of a: %v\n", a) fmt.Printf("The type of a: %T\n\n", a) b := &amp;a fmt.Printf("The value of b: %v\n", b) fmt.Printf("The type of b: %T\n\n", b) var c *int c = b fmt.Printf("The value of c: %v\n", c) fmt.Printf("The type of b: %T\n\n", c) *c++ fmt.Println(a) } a := 10 I declare a variable named "a" and assign it the value "10". Because i didn't declare a type the compiler assigns it a type based on the value i assigned. The type is "int" b := &amp;a I declare a variable named "b" and assign it the value of the "the memory address of a". Because i didn't declare the type of "c" the compiler assigns it a type based on the value i assigned, in this case its of type "pointer to and int". The value it holds is a memory address. var c \*int: I declare a variable that is named "c" and of type "pointer to an int". Because i didn't assign it a value it will be set to its "Zero value [https://tour.golang.org/basics/12](https://tour.golang.org/basics/12)" by the compiler. The value its holds is 0. c = b I assign the value of "b" to a variable called "c". Because i didn't declare the type of "c" the compiler assigns it a type based on the value i assigned, in this case its of type "pointer to and int". The value it holds is a memory address. \*c++ Look at the memory address stored in "c", retrieve the value stored under that address and increment it by one. Write the result value back into the location the memory address points to. How this helps in some way =)
Add a semicolon after the variable
Yeah, I've seen that as well. I wish that project the best.
&gt; And that's not much of a solution because you end writing a lot of annoying "is this nil" checks in cases where you know that the value can't possibly be nil (as a side effect you bloat your code with unnecessary checks). If you know it can't be nil at certain points, why would you use an optional type to represent that value? I don't program in Swift, but Optional Binding seems to give you a nice way to create a scope where you know the value is not nil and you can pass the non-nil variable in to other functions ([blog1](https://drewag.me/posts/2014/07/05/what-is-an-optional-in-swift#optional-binding), [blog2](https://dev.iachieved.it/iachievedit/a-morning-with-swift-optionals/)). So you need to check for nil once at some kind of boundary and then use the non-nil variable and type internally.
That's not really a question of go but of your application. In memory if you don't want to persist between runs, on disk if you do. Serialize a map as json or some other format to disk if you don't need any of the features of a database. If you do, select the database that makes sense.
It depends on when you discover things. If you're debugging locally, sure, a nil error is easily discovered and fixed. However, if you're using an API that, for example, returns nil on timeout, or nil for not found, then you could discover issues like that only in production. Some production software only gets patched bi-weekly, or monthly. The earlier you can detect a mistake, the cheaper it is to fix. I imagine calling it a billion dollar mistake might actually be underselling it.
try with bolt may be ? It's plain go ! https://github.com/boltdb/bolt
I see.
When you need to be an octopus.
This is too true, and its not the norm. The lesson I take away from this is not to always have the tools available in any container. It is to always be able to build and target a larger than usual container which has the tools available.
&gt;it makes you the human do a compiler’s work Golang philosophy summed in only one sentence.
That API doesn't look carefully designed, though. Timeout looks like an error to me, and "not found" should be signalled accordingly. So, rather than returning a `*Foo`, those two functions should return, respectively, `(f *Foo, err error)` and `(f *Foo, ok bool)`. So, sure, not having nils at all is better, but it's not the end all be all of software robustness. That hypothetical API probably has other design flaws, so you're probably better off avoiding it anyway, no matter the language it is written into. I mean, although it's becoming a little harder, it's possible to have shitty design that leads to hard-to-find bugs even in languages without null. In rust for instance, it's easy to abuse things like `unwrap` or `try!`, for instance, and defeat the purpose of "maybe" types. I ran into lots of bugs in production code, but except in dynamic languages(*), I can't remember a single instance of null dereferencing. Lots of invalid results, lots of unexpected empty strings, lots of invalid types (in dynamic languages again, and sometimes in go because of the lack of generics), lots of concurrency-related bugs, but no null pointer exception. (*) In dynamic languages though, they tend to happen a lot more, because it's easy to try to call a method that doesn't exist because the value you get is of the wrong type ("undefined is not a function" and friends), but by definition these problems can't be solved with stricter type systems in these languages.
As a developer, you're often interfacing with badly designed third party stuff. I agree that, if your library is well designed, these things should happen less often. Open source stuff is often well designed, but interfacing with private interfaces or FFI though is often a less pleasant experience. You can't always avoid it. I've run in quite a number of unexpected nil/null errors that way, often at a time where these errors where very inconvenient. I don't think anyone claimed nil-safety is the end all be all of software robustness, it's a good step forward though. Also, I think in rust "try!" passes the error up a layer, it doesn't suppress it, "unwrap" just errors and exists, so that's something to avoid unless it's a fatal error.
I don’t know, you can master a frontend and backend language at the same time. It’s how we used to do it all the time. PHP and JavaScript or python and js, etc. it’s certainly faster to learn just JavaScript of course because it can serve both needs. So it’s far cheaper to train a team. It also allows team members to be more flexible. It’s a good business decision. However, if Node.js isn’t cutting it, one can be in a position of increased costs elsewhere. This may negate their savings in engineering. Or perhaps engineering costs could become greater as well - in maintenance and tracking down bugs. I find that the JavaScript ecosystem moves much faster. This is good sure, but also bad. It necessitates a perpetuity in engineering that amounts to a hidden cost over time. It’s not at all uncommon that people can’t see the forest for the trees here though. I would not force the issue or limit yourself for these more instant gratifications and perceptions of a “good” solution when the reality is, with perhaps hindsight, you end up realizing you made a mistake. 
I was just making a "no one competes with Google like Google competes with Google" joke
Is wolkenkit or buntsift the product here? And how many CLI modules (or Go packages) do we need like that? Did the Go version also require you to build a similar package? Was that open sourced as well? Or was such a package not needed when using Go because someone else’s was used? I see a lot of consideration and time and nice documentation on a side project here after switching back, retracing steps and I imagine duplicating work effort. Is this a business? Or a fun side project? Also, I don’t know if I would say using node for CLI is great, because you need to get node and npm. With Go, you just get a single binary. So there’s pros and cons here to think about as well. I guess what I’m thinking here is: There’s so many operational and business considerations here that seem to be ignored all for programmer comfort. Is there any sort of insight as to how this helped from a business perspective? Did the open source CLI package help in any way? Did it bring some sort of good will or clout or marketing to the other business efforts in a meaningful way? Was there some sort of time savings we aren’t reading about here? From the sounds of it, it seems like the cost to develop the product just shot through the roof.
Is this a second post? So close to another... Spam?
Awesome, thanks!
Awesome. Thank you. If I wanted to tie this in with charting (Grafana, for example) would you recommend MySQL, Postgres, or one of the google DBs? I am a Python guy so I don't know what Go Programmers prefer for databases or which ones they generally have good experiences with
I would think a time series database would be better for interfacing with Grafana.
[removed]
I think a rule of thumb that can help to think about it\[1\], is that: 1. &amp; is generally mostly used in assignment, to create and return a pointer for a new value 2. \* is mostly used for declaration of, and access to the values that pointers point to (like those created in 1) \[1\] might not hold in 100&amp;#37; of cases
Any you would recommend for Go?
[removed]
See OPs post. Go would have two kinds of pointers * and &amp;.
I don't know what library you are using but they can not deref the value with that, i.e. `**v` would panic. I really don't think you should do this, I would consider any code that did low quality: `(**int)(&amp;[]*int{new(int)}[0])`
An inexperienced Go programmer might still return a nil interface, that won't get caught by the if statement (the nil != nil problem).
Yikes. Changing ASAP. 
Changed.
Now it’s unfortunate in other ways, but it’s okay we’re programmers not designers ☺️
&gt; If I wanted to tie this in with charting Why would you want to tie it in so directly? This doesn't make for a very flexible architecture. You haven't specified your use case(s) so we can't really give you a good answer other than to say this isn't (nor should it be) a golang question. This is a timeseries DB question. That being said, Prometheus would be the first place to look. It integrates with Grafana very nicely. And it scales up very, very far... if that's something you need.
You are lucky! Not everyone is though. If you have to deal with CGO all bets are off. There's a good chance you won't be able to have static builds...
Very true; c go is one situation. I think the vast majority don’t need to interop with c when building a binary which will be hosted in an orchistrator.
You have a valid point. The pain is real. Sidecar containers loaded with the tools you need (and attached to the target container) can be a good solution though (and you can ensure you have everything you need in a constant way :-))
The zero value for an int pointer is nil, not zero. 
One can allocate memory and write the copy directly, the other one allocates, zeroes and then copies. Basically one more "write" pass, so factor two sounds okay. 
You can squeeze off a few more bytes by applying `-ldflags='-s'`
This is not an great tutorial since its just showing howto install Go but NOT howto setup an Go workplace. It would have been great if the blogpost would mention the official Go docs: [How to Write Go Code](https://golang.org/doc/code.html) 
You could do this instead: for { n, err := f.Read(data) if err != nil { fmt.Println("read.fail;", err) break } fullFile = append(fullFile, data...) count = count + n } A better way to solve this is to use the [bufio](https://golang.org/pkg/bufio/) package, [like this](https://play.golang.org/p/E9SGUYKtZNP).
Great post! Thank you! And there I thought that pointers were good for everything!
omg! I forgot about 'break'! Instead of packing everything into the loop argument lines I could've avoided that completely! Thank you! The reason I didn't want to use bufio's scanner was to just get more comfortable with the Read/Write functions. (I'm just starting on the Read() ). And also to get a better handle on slicing and appending and such. I'm still fairly new with the language. This is essentially the first programming language that I got to study on my own in the last two decades. Had some C++ back in college, but that was SO long ago!
Is this folder `{{cookiecutter.app_name}}` [1] supposed to be there? [1] https://github.com/lacion/cookiecutter-golang/tree/9c13663/%7B%7Bcookiecutter.app_name%7D%7D
You can also break if the reader has reached the end of the file: for { n, err := f.Read(data) if err == io.EOF { /* graceful stop */ break } if err != nil { /* unexpected reader failure */ fmt.Println("read.fail;", err) break } … }
 for { n, err := f.Read(data) if err == io.EOF { /* graceful stop */ break } if err != nil { /* unexpected reader failure */ fmt.Println("read.fail;", err) break } … }
You can also break if the reader has reached the end of the file: for { n, err := f.Read(data) if err == io.EOF { /* graceful stop */ break } if err != nil { /* unexpected reader failure */ fmt.Println("read.fail;", err) break } … }
yes, thats a template variable, when you run cookiecutter against this template that folder will get rename to whatever your project will be called. cookiecutter is a tool that allows you to kickstart a project structure from a template, so its not just clone a repo and rename stuff kind of deal, its all done for you either via a few questions, or a set config that will get read and autopopulate some data. there is also some logic when you create a project to generate things like adding and setting up logging or config, or adding CI, or if you want docker or not. i basically use this a lot as i create cli tools or micro services so having a quick start is great. having the option to dockerized and ci fast making me deploy to prod faster.
Hah! I was just implementing that!!! 
[removed]
I'm not sure your issue with var/const. The way variables are scoped in blocks remains the same. The only time you need to do that is if you are moving variables to a package level, in which case you should be very wary of doing it in the first place. Package variables that aren't consts are almost always a bad idea. As for redeclaration, the same is true, the rules don't change. You can happily shadow a const or var with the const or var syntax, the := makes no difference. Because neither of these things make any difference, you'll never see a linter that does what you are asking. It's not idiomatic, and fighting the Go idioms is usually a quick way to get into issues. Can you help me understand where these ideas you have came from?
I think idiomatic go allows for both, and that you should not try to enforce one or the other. When you get more familiar with go, they both come naturally.
Can you use the append() function to just make a new one?
Someone needs to write a VueJs port in go. We'd rule the internet.
I mean . . . ok . . . but that actually does seem like a pretty trivial thing to just flip on.
You have to supply a typed `nil` as the first argument.
Yeah the alloc &amp; copy method does indeed initialise all values to 0.
Repost from two days ago: https://www.reddit.com/r/golang/comments/8qk6xw/fo_an_experimental_language_which_adds_generics/
Is that more or less efficient than what you suggested? I don’t get to use go in a professional setting, so I’m really not up to snuff on optimization tricks in it. 
Bloody beginners could also download it from the official repositories. You may not get the very latest version but it's a bit easier. Should be something like: `# apt install go`. And note `apt-get` is deprecated.
I really dislike `text/template`, and I don't find that using it like the example you linked to ends up more readable than string concatenation. We've done a combination of `fmt.Sprintf`, `bytes.Buffer` and a custom sql builder similar to squirrel, depending on the complexity of the query. This is an example of our sql builder that uses functional options: b := mysql.NewBatchSelector(c, "db.Tags", []string{"WorkspaceID", "ID", "Name", "Description", "Config", "Created", "Modified", "Deleted"}, // field names []string{"WorkspaceID", "ID"}, // where fields mysql.BatchSelectorRequireOneRowAffectedPerAdd(), ) for _, tag := range tags { b.Add(tag.WorkspaceID, tag.ID) // params that have to match the where fields }
Static type checking is not a thing that was meant to help prevent errors. A type system in general was implemented to make it more convenient. Static typing is just the compromise between humans and the machine while dynamic typing is full convenience.
Quickly wanted to share a benchmark I did: ` BenchmarkStruct24 2000000000 1.66 ns/op BenchmarkStructP24 2000000000 1.64 ns/op BenchmarkStruct28 2000000000 1.65 ns/op BenchmarkStructP28 2000000000 1.65 ns/op BenchmarkStruct32 2000000000 1.96 ns/op BenchmarkStructP32 2000000000 1.65 ns/op BenchmarkStruct64 1000000000 2.59 ns/op BenchmarkStructP64 2000000000 1.65 ns/op PASS ` The number is the size of bytes of the structs, P means pointer receiver. It was done on an Intel i5 7th gen. If you are not sure about your struct sizes you can use `unsafe.Sizeof`.
Static types absolutely help prevent errors. Most large applications written in dynamically typed languages use unit tests to asymptotically approach the error checking provided automatically in statically typed languages.
I'm not familiar with VueJS, but there is http://github.com/gopherjs/vecty (but unfortunately it's not stable enough for production apps yet). disclaimer: author here
[removed]
Wow, all of the articles here are interesting: https://github.com/go101/go101/wiki Although I wouldn't call most of them go "101".
# Why I love functional programing, Rx-style coding, and Optional usages. However it's hard to implement them in Golang, and there're few libraries to achieve parts of them. Thus I implemented fpGo. I hope you would like it :) # Features * Optional * Monad * Publisher * Pattern matching * Fp functions * Java8Stream-like Collection * PythonicGenerator-like Coroutine(yield/yieldFrom)
I'm not a Go developer at all, but will be remaining vigilant regarding this project. Interested ...
That's good to know. Thank you!
Could this be used to run a Laravel app? What does the performance look like? This is perfect to run on Windows since php-fpm is unavailable there. 
The append use in the example code of OP is guaranteed to make a new slice if the lenght of the base slice is not zero.
As that article has mentioned, using `baseSlice[:0:0]` is better than `nil` as the first augment.
Yes, but only in a logical way. The performance is equal.
It can work with any framework, including Laraver. Up to 50 faster that php-fpm (bigger framework - bigger speed improvement).
This whole security thinking: Safe nulls, no race conditions, only valid arguments to functions is relatively new to the programming world. When Ritchie created C and added a typesystem to B it was not made which any security considerations. Strong typing on the other hand is entirely there to prevent human errors as weak typing adds convince. But strong-weak, static-dynamic are orthogonal concepts.
I disagree. People now add static typing on top of Javascript and Python: https://docs.python.org/3/library/typing.html, https://flow.org/en/ In these languages the only benefit it adds is reducing programmer errors. There's no speedup gained and it's stripped out before actually running the code, so there's no other benefit. I see in your other comment that you say strong-weak and static-dynamic are orthogonal concepts. In which you are definitely correct. When I say static typing, I mean strong static typing. Because when you have weak static typing it's not nearly as useful for handling errors indeed, so I don't really consider it.
I don't trust this benchmark. Allocation is not free, "yForMakeCopy = make([]T, N)" is placed in the benchmark loop, that is why it is slower. If you move it above the loop it shows that copy() is actually faster. Please note that this benchmarking is for "copying" data and data allocation should not be included.
yes
I did not say it does not prevent errors it was just not its intend the error prevention was a side effect. This whole typesafty and non-nulling is a very recent development.
need something like quartz in golang
I put the repository on the struct like your second example to keep method calls cleaner, it’s easier to read what arguments are actually necessary then 
Personally, I tend to do the latter. And I might understand your point poorly, but: Why would you need a bigger interface? ISTM that if you can pass smaller interfaces as arguments, you can also have smaller interfaces as struct fields.
The reason you have bigger interfaces is that the method that is being called does not know which specific functions it needs, so the receiver has to provide all of them to the method. In my example above `CourseRepository` is an interface that describes `FindMany`. If you add more methods, that one interface has to grow and contain all other repository functions as well. Other than that you could create smaller interfaces but you would then need to add each one to the receiver struct, right? Thinking about it, that might actually be a good tradeoff. Instead of adding smaller interfaces to the arguments, you add them to the struct. Nevertheless I can't help but feel that none of these seem to be very clean.
I dont mean to be a meany but... The usual problem with these kind of libraries is that they're usually not typesafe because Go does not offer generics. FP is a pretty subjective term for me but an important property of it for me is being able to easily compose functions in a type-safe manner. I can see there is a lot of \`interface\` going on, which will put off some people (such as me) off using it. Nonetheless nice one for releasing it out to the wild
This seemed to be a decent option: https://github.com/validator/validator
I would create a types that takes in strings cause I'm pretty sure that's gonna be the class data with strings.NewReader. Then create interfaces that grab each kinda of class method. Then create a type that takes in those other types that satisfy the interfaces. This way if you need to change one you can easily. If you need a type that takes in more then one class you just add a method to satisfy the interfaces. There won't be this giant struct or giant interface and it'll be completely uncoupled. 
Hey, sorry I think I don't entirely understand what you mean. Would you mind sharing some example code?
But it takes the same diligence to decorate a parameter with `&amp;` as it does to manually check for a `nil` value. The special syntax only adds more stuff to learn. I'm not saying this type of programming error is bad but I think better practices can fix it. I also feel like the whole article is kind of straw-man-y because, frankly, I don't think this is as big a problem in Go as the author suggests.
Ya -- maybe I'm wrong but the impression I get is that the author is somewhat new to programming? Maybe new to programming in Go? I'd like to see the code that has been causing him or her these problems and I bet there are major errors/omissions and poor practices at the root of it.
[removed]
OMG, that sounds awesome. Looking forward to taking a look at it. 
Yeah... I totally agree your point... without generic it's not possible to be type-safe In fact I have the same feeling too. However, whatever maybe we should still have a try anyway...:P At least in some cases it would works and has some benefits somehow Thanks for your comment :D Maybe we will have better ways in Golang 2.x (maybe?)
[removed]
I’m not sure it really matters but I would use your first example. Side note, it’s definitely best practice to return errors last. 
I prefer the latter form, because it let's me pass the service to other components, and those components don't need to know about the particular of the repository. Though you might have a use case where you want the client to know, in which case it's better to have it passed in as an argument. use the latter form if you're unsure which to use, once you have a strong reason to use the former, switch over. Also, if you're worried about creating 'big interfaces', write an adapter for the particular use cases that you need that builds on a more well defined interface. This let's you keep your core and use-case specific code separate.
Influx for Time series. It’s actually written in go. 
I think your first approach has the added benefit of making testing easier yeah? 
I'll have to write up something later cause I sadly work on weekends but in a sense how the standard library makes packages. Like you have the Reader type that is an interface that has one method Read(). Well you can generically say this is the class type that has an interface getclass(). Then if let's say you need to get idk certificate classes. You would create cert type that has cert interface with the method getcert(). Now if you want to use these both you then create a type with the method getClassCert(). Then the params are type class (core data for classes) and the type certclass (whatever makes it a cert class) you then can utilize that data in that function. And so on... You now have the starting of a class package separated by class types and their methods built upon these basic types as one big type class package that someone else can utilize or add to, or whatever. Point is"ALL" the code will be reusable. Big structs and interfaces will never allow that cause you are cutting corners (with yes less code) but completely not reusable code that will eventually lead to that the great phrases like "new file time!" Or the greatest eventual one "rewrite!!!". You get the idea.
Defining methods on an empty struct is a code smell. **Just use a function**. The interface example is just an obfuscated function call. func GetAllCourses(finder CourseManyFinder) ([]Course, error) When you remove the unnecessary type, there's no more mystery about what a `CourseService` is supposed to be or what's inside it. 1. Notice how the return type is `([]Course, error)`. Named returns should be used sparingly --mostly for documentation. It's clear that `[]Course` is a list of courses. We don't need to name that. If the func were returning `(string, float64, error)`, we might want to use named returns because it isn't obvious what those types are for. 2. `error` should always be the *last* return parameter. It's always `(Foo, error)`, not `(error, Foo)`. Now onto your question. IMHO it's best to use an interface for the db client, because you can mock it out during tests. It doesn't matter whether you pass it as an arg or put it in a struct. If you have lots of funcs that all need to use the db client interface, make a custom struct type with the interface inside. Otherwise, just use a function.
I'll check it out. Thanks
That's something i'll be trying soon. I'm going to be aiming for yet another binding for React though, not Vue. My goal for React is to allow React Native to work, which would be really cool to use with Go. Granted, it's probably a pipe dream, but worth trying. I doubt React would be the best fit for Go.
[removed]
I agree about var vs const on package level. The idea about inconsistency comes from that when `foo := 1` is moved to package level, it will result in error and needs to be rewritten to `var foo = 1` (could be also good to have linter rule to enforce `const` here). And the idea about human errors is: foo, qux := 1, 2 ... bar, qux := 3, 4 // not ok, I meant quux, but qux was redeclared without an error This sort of mistakes will probably be revealed on compilation with *undefined* or *declared but not used* error. Or probably not. It's implicit declaration that causes this issue, I just want to force it to be always explicit with var/const and eliminate such possibilities in the code base. There can be similar style problems in JS that lead to human errors: let foo = 1; // ok, redeclaration will cause an error bar = 4; // not ok, accidentally (re)declared a global var qux = 2; // not ok, redeclaration won't cause an error ... let foo = 3; // ok, causes an error var qux = 3; // not ok, I meant quux, but qux was redeclared without an error But in JS they can be sorted out with linters. Since JS is interperted and compiled, the probabilities of human errors are obviously higher, yet they are non-zero in Go.
not \_really\_, you could test the latter approach just by creating a mock for the repository, building the service and assigning it the created mock, and then calling the method and asserting.
Hey - you may have missed an 's' at the end of your URL that you posted here
Github expends considerable resources to detect malicious code, humans can flag things they find suspicious, and the star system looks can indicate that that a repo is popular. Activity and popularity area a weak indicator of safety, just just like the other two things I mentioned, but it can at least point you in the right direction for determining how much effort you want to spend reading the code you're importing.
Oh, I see. Yeah, the multiple assignment semantics are definitely a gotcha for new gophers. I made the mistake a great deal of times over 3-6 months (thanks code review!) before I got it into my muscle memory. The use of multiple assignment syntax reassigning in this way is now an idiomatic way of working (rightly or wrongly), and so again, you're unlikely to see a linter. Here's why: hero, err := newHero("Batman") if err != nil { return fmt.Errorf("Couldn't get hero") } ... badGuy, err := newBadGuy("Joker") if err != nil { return fmt.Errorf("Couldn't get bad guy") } Without the reassignment, you'd have to make a new `err` name each time. But it is strange to newcomers because if it was `hero, err :=` you'd get a complaint from the compiler that there were no new variables. I think it's one of those things where your POV means you can consider it a feature or a bug (or both), *but* if it does help, you do eventually get used to it and not notice it anymore. 
realize
So, the latter approach is what I am currently using. Continuing with the example above, `CourseRepository` is an interface like this (simplified): ``` type CourseRepository interface { Insert() FindOne() FindMany() Update() Delete() } ``` This is a very big interface IMO. In order to test CourseService methods, I have to mock all those functions to satisfy the interface and pass the mock. The only other way I see to do this is to have separate fields in the struct for each smaller interface like so: ``` type CourseService struct { CRi CourseInserter CRu CourseUpdater } ``` Is that what you mean by "adapter"? To be honest this does not look exactly clean to me either.
&gt; ### Golang Task Runner &gt; • **Live Reload** — The best performing Golang Live Reloading in the market &gt; • **Multiple Projects** — Manage easily multiple projects at the same time &gt; • **Custom Watchers** — Choose exactly what extensions and paths you want to watch &gt; • **Minimal GUI** — Minimal distraction-free GUI to enhance your workflow &gt; • **Full Support** — All the Go commands are supported &gt; • **Export Logs** — Export the logs and errors to an external file &gt; — https://gorealize.io
Thanks for sharing your experience, assigning an error to same variable is a good use case for := indeed. Yes, this requires some discipline to be performed properly.
Thanks for the suggestion. I can see realize watching the files, but I can't figure out how to get it to run/rerun the file. I copied the yaml from the server example, but it doesn't restart the server. When I run `realize start` All I see is that realize is watching files and makes note if a file is changed. What am I missing? 
I came here to say this. Its a darn shame, cuz I do find most of these features very useful.
I would argue that the type safe manner is not important for FP, see lisp and erlang. However it breaks the spirit of Go.
Can you mock out an example of your repo structure?
Yes, that's why it said it's subjective. For me I like the maths-y version, like Haskell, Scala et al as we use computers to prove things. 
lol....I assume you mean in terms of making sure you have lots of billable hours in the pipeline? Since, almost by design, there's no on-going maintenance for "My Custom Distro"?
I've been down the road of sidecarring in a debug container but, at least historically, that's been a problem in many environments. (I'm looking at you k8s! Which until only a few months ago did not support PID namespace sharing and thus a sidecar had very limited access to the main Pod container.)
It's just a one file app, so - project - main.go - docker-compose.yml - .realize.yaml - vendor/ To help figure things out I replaced .go code with a simple http hello world app, but the problem remains; if I change "Hello World" to something else the changes are not seen on page reloads.
well, no, that's not what I meant. But I'm beginning to see your point. I think \`CourseRepository\` is a big interface, but I find it a necessity. The other way would be to define an interface for every operation, which will probably get out of hand really quickly in a big application. I think from from idomatic POV, your former approach is better, but from a realistic view point, I think the secondary approach is better. I'm kind of confused about this now. I'll think more about it and get back to you.
There are two VueJS bindings on the GopherJS wiki page. Disclaimer: am author of one of them. https://github.com/gopherjs/gopherjs/wiki/Bindings
&gt;github.com/joseph... Thanks. Yeah, that's another good way to pass in the config. I would expect to see objects like a logger and a database connection in the struct as well.
[removed]
I think faktory is closest to his needs. It's the cross platform reboot of ruby sidekiq by the sidekiq developer. 
Strange, no one reported it before you. :( Thanks for the finding. I will delete this and repost it.
Yes that’s exactly what I mean. I am kind of stuck finding the right path between what is idiomatic and what is actually maintainable. Maybe I am missing the path where both are the same here though. Thanks a lot anyways, this is a great help.
[removed]
Why \*interface{} ?
I don't see any kind of replication mentioned..
Where in vecty is the vdom generated and updated to actual Dom? Vue is amazing because of the tight integration with Dev tools, vuex, router, etc. Kinda like all go code looks roughly the same, same with Vue. From my initial look vecty doesn't have that kinda workflow yet.
[removed]
Vecty's virtual DOM uses self-application, i.e. it does not have a separate vdom structure. Your code uses the vdom and it applies itself to the real browser DOM based on the previous render's vdom. You can look at the `(*HTML).restore`method for where this occurs: https://github.com/gopherjs/vecty/blob/master/dom.go#L200 --- And yes, there is no integration with dev tools, no official router, etc. yet. Vecty is not stable / ready for production apps yet for exactly this reason.
[removed]
I used the fswatch library in a magefile. You can check it out in this repository (disclaimer: it’s mine) [https://github.com/ravernkoh/jabba/blob/master/magefile.go](https://github.com/ravernkoh/jabba/blob/master/magefile.go)
[removed]
A for loop?
[removed]
[removed]
[removed]
There are a bunch of programs; my favourite is https://github.com/teamwork/reload. Mostly because that is what I wrote myself :-) I like it because it doesn't watch (potentially thousands) of `*.go` files for changes, but just the binary that's being run. It will *only* restart on a successful `go build or `install`.
That's cool, would be great if that was documented. Not down playing the work. Would love for vecty to more like Vue than react. 
Sometimes if just returning a `interface{}` might cause a lot of `copy` behaviors... Maybe returning a `pointer` would be better in general cases(in my imaginations).
Thanks, I'll keep your library in mind :)
I just saw one at DockerCon called skaffold. It's part of Google's container tools project and will auto reload your code for you
I love that people are putting their money where their mouth is by actually prototyping changes rather than debating online ad-nauseum. Cool project.
Do you need this? https://github.com/codegangsta/gin
interface{} is just a pair of type and pointer to the value, so it's only copying two pieces of data. by making it a pointer, you are adding an extra level of indirection for no gain.
Sounds like a neat idea, but you really should include some code examples in the README.
I got it. I saw the reflection implementations... Thanks for your suggestions :D I'll make a version of `interface{}`, thanks :)
With all due respect, searching [Differences Between Go and C](https://www.google.com/search?q=differences+between+go+and+c) on the Internet will give you much more relevant information than short messages from a Reddit user. There are great articles out there that explain with great details what are the good and bad things about the two languages and how do they compare to each other. I don't want to sound harsh, but please go there and read some articles and come back when you have more specific questions, I am sure you will learn much more that way.
This question is beyond golang, its about basic Computer Science itself on how computer allocate and store data in its memory. Other programming languages by-pass this so its easier to use, however that comes with a trade-off, most commonly in term of performance. Generally in Golang you can always just pass it straight via Value instead of using Pointers(* and &amp;). However when you want to optimize your app, or you start caring about which Object you are modifying after having copied it multiple times, you would want to start on pointer.
I use gin, it’s great 
Vecty isn't ready for production apps. It would be misleading to do that, I think.
Yeah! Gin is the best most straight forward reload tool I have tried.
Currently we've been doing a bit of both. Internally within a service we have larger interfaces that cover complete concepts, like the `CourseRepository` example above. Then externally, things that use the `CourseRepository` usually define subset interfaces like the `CourseUpdater` to only accept the methods they explicitly need. This means that within our service package we have the ease of use of the larger interface which is natural since the implementation needs to use the entire interface, and we would need to mock everything there anyway, and then external users of the service usually only need to do one or two things with the service and can limit their coupling and mock requirements to those specific things.
7 and foo.
[Reflex](https://github.com/cespare/reflex) and [realize](https://github.com/oxequa/realize) are good.
Here is a similar script in Ruby, with colorization/anybar/coverage report/etc [https://github.com/zhuochun/dotfiles/blob/master/scripts/go-test.rb](https://github.com/zhuochun/dotfiles/blob/master/scripts/go-test.rb) 
I'm not saying that u/gufranmirza exists solely to spam ednsquare.com links, but you'd be hard pushed to tell that from their post history.
I use it sometimes. But it's all I know. Don't have any problems with it
Good to know somebody does this as well.
This is because constants are untyped. Essentially, they are treated by the type system as whatever type you try to use them as. If you do something like `v := 3`, though, you're basically trying to do a two-way inference, which isn't going to work. Instead of just failing, Go defaults the constant to an `int` or a `float64`, depending on whether it's a floating point number or not. This could be solved by explicitly typing the constants in the `math` package, but you could also solve it on your end by explicitly typing them. For example, something like `t := int64(math.MaxInt64)`.
I kind of see what you are saying, but I think you are underestimating people if you think having an example in your README will lure people into deploying your code to production. On the other hand, code in a README will make the project a lot more "concrete", as the current description is extremely vague. For example, I find React extremely verbose, so is this better or worse? I don't know and can't tell. I even spent a few minutes trying to find an example, and started to poke at code of the users of your project. But couldn't find what I was looking for, so I "wandered off" (closed the tab). Even if the project isn't 'ready' now, getting people to understand the project is the first step to them bookmarking it, playing with it, and perhaps them sending you a pull request for a missing feature.
[This](https://github.com/golang/go/wiki/SliceTricks#delete) is what you're looking for. Also, please, don't forget to handle the error, don't just ignore it. 
with what I will replace a and i
a is the slice, i is the index of the elelemt you want to delete. 
Check my profile too..
So I gave it a go for my little open-source roguelike, and the [wasm version](https://download.tuxfamily.org/boohu/play-wasm/index.html) is way faster than the [gopherjs version](https://download.tuxfamily.org/boohu/play/index.html), in particular for computation heavy things such as auto-exploration. Maybe it's because performance is more limited by computations than graphics, or just gopherjs hits some performance pitfall in this particular case, dunno.
Any benchmarks?
From what I've been told, crossing the barrier between WASM and JS comes with some heavy overhead in all implementations. So while GopherJS allows you to "natively" interact with the DOM (as it's already all in JS), WASM requires that you cross this barrier (via "syscalls") every time you want to update something to the user, because browsers still don't have any way for WASM to directly interact with the DOM.
That’s not the idiomatic Go form because you’re not checking the error returned from open(). If you do, you wind up with something closer to the Rust form, and I’m pretty sure there is an ‘if let’ syntax form that is idiomatic and addresses your qualm.
`v := int64(math.MaxInt64)` also doesn't work. `v := uint64(math.MaxInt64)` should be used. `MaxInt64` is declared as an untyped `int` constant. Its default type is `int`, this may bring some conveniences, and sometimes, bring some inconveniences.
Some are better than math.Big, ssome are worse. $ go test -bench=. goos: linux goarch: amd64 pkg: github.com/ncw/gmp BenchmarkSwapO-4 1000000 1613 ns/op BenchmarkSwapX-4 3000000 546 ns/op BenchmarkAddUintO-4 1000000 1193 ns/op BenchmarkAddUintX-4 3000000 561 ns/op BenchmarkMulInt0-4 1000000 1169 ns/op BenchmarkMulIntX-4 3000000 559 ns/op BenchmarkAddMulO-4 1000000 1538 ns/op BenchmarkAddMulX-4 2000000 776 ns/op BenchmarkCmpIntO-4 2000000 942 ns/op BenchmarkCmpIntX-4 5000000 336 ns/op BenchmarkCmpAbsO-4 1000000 1704 ns/op BenchmarkCmpAbsX-4 3000000 542 ns/op BenchmarkGetIntO-4 2000000 768 ns/op BenchmarkGetIntX-4 5000000 340 ns/op BenchmarkGetUintO-4 2000000 742 ns/op BenchmarkGetUintX-4 5000000 355 ns/op BenchmarkGmpAdd1-4 2000000 1442 ns/op BenchmarkGmpAdd10-4 2000000 776 ns/op BenchmarkGmpAdd100-4 2000000 785 ns/op BenchmarkGmpAdd1000-4 2000000 835 ns/op BenchmarkGmpAdd10000-4 1000000 1171 ns/op BenchmarkGmpAdd100000-4 300000 10141 ns/op BenchmarkGmpAdd1000000-4 20000 94259 ns/op BenchmarkGmpMul1-4 1000000 1555 ns/op BenchmarkGmpMul10-4 2000000 793 ns/op BenchmarkGmpMul100-4 2000000 841 ns/op BenchmarkGmpMul1000-4 300000 4123 ns/op BenchmarkGmpMul10000-4 20000 170285 ns/op BenchmarkGmpMul100000-4 500 2350300 ns/op BenchmarkGmpMul1000000-4 50 49351883 ns/op BenchmarkBitset-4 5000000 328 ns/op BenchmarkBitsetNeg-4 5000000 331 ns/op BenchmarkBitsetOrig-4 500000 3314 ns/op BenchmarkBitsetNegOrig-4 200000 5727 ns/op BenchmarkMathBigAdd1-4 50000000 59.4 ns/op BenchmarkMathBigAdd10-4 50000000 29.9 ns/op BenchmarkMathBigAdd100-4 30000000 43.2 ns/op BenchmarkMathBigAdd1000-4 10000000 183 ns/op BenchmarkMathBigAdd10000-4 3000000 732 ns/op BenchmarkMathBigAdd100000-4 100000 11268 ns/op BenchmarkMathBigAdd1000000-4 20000 71029 ns/op BenchmarkMathBigMul1-4 50000000 34.9 ns/op BenchmarkMathBigMul10-4 30000000 35.0 ns/op BenchmarkMathBigMul100-4 10000000 289 ns/op BenchmarkMathBigMul1000-4 300000 5207 ns/op BenchmarkMathBigMul10000-4 2000 606713 ns/op BenchmarkMathBigMul100000-4 200 15555405 ns/op BenchmarkMathBigMul1000000-4 5 396024229 ns/op 
This seems sensible, yes. Another difference may be allocation: Go allocates a lot on the stack, and maybe this is efficiently translated into wasm, but it is probably not possible with gopherjs (this is just speculation based on the fact that my dijkstra pathfinding algorithm with no dynamic allocations runs much better with wasm).
You are implementing the cache as a list. Lists, unless they are skip lists are usually O(n) for operations. Consider using data structures that have log(n) look ups, specifically heaps, which can be implemented with arrays, sort of similar to what you have. Using a max heap could get you the top 20 items in log(n). 
https://play.golang.org/p/Ilddy1mOfI3
\&gt; Tbh i don't like this because it makes function arguments long and redundant, and i am too lazy to create the mock object. I dont really see how A(x somefunc) Is much more terse than A(x func() int) Or A(x MyDatabaseInterface)
Oh, hey, that sounds much more useful. I may have to try that one out n I've never used the watcher-based ones because I've already got processes invoking the compiler for correctness checking (flymake in emacs), I don't need another process doing a thundering herd on every save.
Using a global variable is not unheard of, but it can be very limiting - it means that there is another way to use it, but only one at a time. So, for example, if you made a library that used this pattern and two other libraries each changed the function for some reason, they could not be used together. I think that if you look at the http package, it shows some great patterns: 1) there's a way to use it without thinking about things (eg. http.Get) 2) you can create a client, and it uses a default transport (eg. &amp;http.Client{}) 3) you can override the default transport in a custom client too (eg. &amp;http.Client{Transport: tr}) I honestly think this is great design. It's easy to use, you don't have to add or override these things if you don't want to, but everything is there in case you do.
Looks like it was worth it... https://twitter.com/bradfitz/status/1007720291630379009
https://github.com/avelino/awesome-go#gui
Sorry but i think you misunderstand it. With my approach, i don't need to put every external object as arguments in my method (dependency injection). Let's say method A need to access method B from object X, method C from object Y, method D from object Z. I need to create interface for object X,Y,Z I need to put interface X,Y,Z as arguments. func A(X interfaceX, Y interfaceY, Z interfaceZ) I need to create mock object of X,Y,Z that implements every method of it. See, it's a really long process for unit test. With my approach, what i need to do is just simply change method B,C,D to variable and then reinitialize method B,C,D in the unit test.
I see. I would still favour DI, global variables are going to make things hard to follow for other people. If you are really adverse to declaring an interface you can just send in a function type e.g `func f(x func() int)` 
&gt;This could be solved by explicitly typing the constants in the math package... Any thoughts why it was not done?
For similar reasons, there is some undesired behavior in your maybe implementation: [https://play.golang.org/p/Om7kOYYyCjB](https://play.golang.org/p/Om7kOYYyCjB) The reason is that checking to see if an interface == nil returns false when the type in the interface is not nil (in my example, it's \*int), even though the value is nil. This example might illustrate it better: [https://play.golang.org/p/yaMKV9A7XT2](https://play.golang.org/p/yaMKV9A7XT2)
Owen here and I'm a designer building a community around an early stage cryptocurrency called U Network. If you're not familiar with projects like Steem, U Network is similar however has potentially to be a more fair system for valuing content creators work. We're now starting to look for dev's to join our Hive community, Go dev's in particular. The idea is that we would collaborate on some of the first dapps to hit the U Network ecosystem. It's still an early stage with little competition and I think there's lots of room to become leaders in this market if we can assemble a pro-active team. Regarding funding, the plan is to post project updates on U Network. As the platform works by users investing in content, there's a good chance people on the network will help to support our projects. The community I've created is called" UNetworkHive" and you can search it on Google, Twitter and Telegram. Also you'll find our project conceptss have been recieving lots of support from the official U Network team and so they seem to be excited about Hive. 
To OP, I don't know if you are the author or not, but if you are, the link to Github is broken.
I've always thought of heaps as working well with static objects. How would you use a heap in this case where the counter field of an lruItem is increasing over time?
[repost] OP's code should be changed to `v := uint64(math.MaxUInt64) ` MaxUInt64 is declared as an untyped int constant. Its default type is `int`, but it can be used as a value of any numeric type. This may bring some conveniences, but sometimes, this will also bring some inconveniences. An untyped constant might be not able to be represented by its default type at run time: [https://go101.org/article/constants-and-variables.html](https://go101.org/article/constants-and-variables.html)
This post is also a word for word ripoff of a medium post written last year 
I think, on each operation, you would restructure the heap so that the order of the heap gets maintained. The restructuring parameter would in this case be the counter. 
You could use a queue for the first 20 elements which include their value. When you get a miss pop one element of the queue and append the requested one. This of course only works well if you have up to 20 elements that are highly requested. This has horrible performance on random reads.
https://github.com/lxn/walk/ for Windows. Though 99% of Gophers would tell you to use a HTTP server + web UI.
I personally find "var v uint64 = ..." to be more readable here: https://play.golang.org/p/nz7PXYAgB7x 
&gt; Any thoughts why it was not done? You have to so you can support the non-int numbers. Eg.: https://play.golang.org/p/Ixp6oSf5hae
\&gt; Casts from max uint64 to float64 which just can't hold value losslessly \&gt; No warning from compiler
Indian SEO spammers ...
If you really want a native GUI you could use https://github.com/dontpanic92/wxGo, a wxWidgets wrapper. It would be easier however if the app was simply a webview (https://github.com/zserge/webview) and code the server in Go.
☝️
No such thing as compiler warnings in Go. You can `go vet` if you want, though
Ya look up heapify algorithms and restructure based on your needs. 
By "bubble" do you mean session? I'm not sure what you're trying to solve, this sounds like a game server with matchmaking maybe? I'm by no means educated in this subject but when I've done projects like yours in the past I've used RPC, try looking that up
that's exactly what I'm trying to do : a matchmaking system
I started working with webview and I like it so far: [https://github.com/zserge/webview](https://github.com/zserge/webview) There is also SDL, but I don't have experience. [https://github.com/veandco/go-sdl2](https://github.com/veandco/go-sdl2)
Be aware that [Apcera no longer exists](https://www.apcera.com/) and the package is unmaintained.
[removed]
I'm not so sure, but I hear you and will think about what you've said here. &gt; I even spent a few minutes trying to find an example, and started to poke at code of the users of your project. There are examples in the `example/` directory. I want to make sure we are not giving people a bad impression of the project by adding docs when it's not production ready. If you're willing to dig into the code and understand how it all works (and dig into the code and find the examples folder..), then I trust you can make the right choice about whether or not using it is right for you. But otherwise, I am afraid we would be misleading people into thinking it is production ready and/or that user's issues could be fixed promptly -- which just isn't the case right now.
[removed]
Not the author, I'm a noob (OK intermediate noob :) ) was wondering if I should use this library and thought that some people here might have some comments about it, good or bad. Here's the github link: https://github.com/jpillora/velox
Is there a reason there's no compiler warnings? Compiler warnings generally seem like a good thing. 
IIRC, it's because if a command is successful, it shouldn't have output
Thanks for your suggestions!! :D I've already made them in v1.1.0 It's hard work but worthy doing :D 
 I'm very confused about BenchmarkGmpAdd10 and BenchmarkGmpAdd10, dito. Mul variants and the MathBig versions. How aren't they identical?: https://github.com/ncw/gmp/blob/master/bench_gmp_test.go#L28
 BenchmarkGmpAdd1-4 2000000 1442 ns/op BenchmarkMathBigAdd1-4 50000000 59.4 ns/op BenchmarkGmpAdd10-4 2000000 776 ns/op BenchmarkMathBigAdd10-4 50000000 29.9 ns/op BenchmarkGmpAdd100-4 2000000 785 ns/op BenchmarkMathBigAdd100-4 30000000 43.2 ns/op BenchmarkGmpAdd1000-4 2000000 835 ns/op BenchmarkMathBigAdd1000-4 10000000 183 ns/op BenchmarkGmpAdd10000-4 1000000 1171 ns/op BenchmarkMathBigAdd10000-4 3000000 732 ns/op BenchmarkGmpAdd100000-4 300000 10141 ns/op BenchmarkMathBigAdd100000-4 100000 11268 ns/op BenchmarkGmpAdd1000000-4 20000 94259 ns/op BenchmarkMathBigAdd1000000-4 20000 71029 ns/op BenchmarkGmpMul1-4 1000000 1555 ns/op BenchmarkMathBigMul1-4 50000000 34.9 ns/op BenchmarkGmpMul10-4 2000000 793 ns/op BenchmarkMathBigMul10-4 30000000 35.0 ns/op BenchmarkGmpMul100-4 2000000 841 ns/op BenchmarkMathBigMul100-4 10000000 289 ns/op BenchmarkGmpMul1000-4 300000 4123 ns/op BenchmarkMathBigMul1000-4 300000 5207 ns/op BenchmarkGmpMul10000-4 20000 170285 ns/op BenchmarkMathBigMul10000-4 2000 606713 ns/op BenchmarkGmpMul100000-4 500 2350300 ns/op BenchmarkMathBigMul100000-4 200 15555405 ns/op BenchmarkGmpMul1000000-4 50 49351883 ns/op BenchmarkMathBigMul1000000-4 5 396024229 ns/op 
Work has started on a package loader that supports multiple build systems. Once that is initially released tools can be ported over to use it. Right now probably none. Soon all should support vgo and bazel.
You could simply do `fmt.Sprintf("%d", count)` 😄
 c.Header("X-Total-Count", strconv.Itoa(count))
&gt; Have tried strconv.Itoa(&amp;count), got another error: In this case, `count` has the type `int` so there's no need to make a reference to it when passing it to `Itoa`. `c.Header("X-Total-Count", strconv.Itoa(count))` will do what you want.
It works. Thanks!
It works. Thanks!
Not at a computer so didn't get a chance to run it, but did you try switching where you assign sum and where you assign sum.Next? It looks like you are assigning the sum next pointer and then overwriting sum immediately after that which undoes any chaining. It appears you want to set sum first then set sum.Next
tl;dr it's because math.MaxUint64 is a constant, and numeric constants are untyped.
My cat hides when I type this command
It should be as simple as: 1. Put connections into a list 1. Make matches 1. Fire off a goroutine to handle data transfer between them What exactly are you having trouble with?
That's kind of a lame reason, IMHO. That works great for most utilities but the go compiler is not a simple utility.
For anyone else: https://medium.com/learning-the-go-programming-language/streaming-io-in-go-d93507931185
Worth noting that the alpha reader has a bug where they copy NUL bytes and rely on something in the output chain not displaying them.
You are overwriting sum every time with next node: ``` sum.Next = &amp;nextNode sum = *sum.Next ``` Therefore `dummy.Next` is always pointing to the last sum ListNode 
I tend to use goroutines for their purpose - asyncrounous functionality - and generally that's for [firing cron-jobs](https://github.com/robfig/cron), or [collecting metrics](https://github.com/skx/golang-metrics). Otherwise I'm like you, I tend to write HTTP-servers, so there are goroutines behind the scenes but I'm not explicitly using them.
What I was doing now is quite similar. All services are completely isolated with their repositories in the respective structs. If a method needs to access another services repository, it accepts the specific function as an interface in the arguments. Thanks for your help!
I've switched permanently from Go to vgo. `gofmt` is fine, `vgo tool cover` is mostly fine (but if your package has a major version number above 1, you may need to change the paths in your coverage file, which is easily done). To be honest I mostly stick to the core tools and ones I write myself and haven't seen any issues. `vgo test all` and `vgo list all` are amazing as they only process the packages you actually depend on now.
Either an issue is severe enough to refuse compilation, or not worth bothering the user about. IMO this should be a compiler error anyway, not a warning.
literal constants are always untyped, but named constants can be typed.
The reason advanced was compiler warning, such as the one of gcc, end up being noise. Take Gucci with the pedantic warning, you can write valid code doing exactly what you want but have a bunch of unnecessary warning. For go they decided to have only error and use tool to produce warning, the go compiler will either compiler or produce the error.
Just stating the obvious - since this just compresses debug info, if you already use `-ldflags='-s -w'`, then there will be no difference to your binary size.
Even the Wikipedia page is abandoned. It's probably something that it's hard to be passionate about. Also not a fast-moving piece of tech. So long as the lib is valid, it may not need to be updated often. [https://en.wikipedia.org/wiki/ISO\_8583](https://en.wikipedia.org/wiki/ISO_8583)
&gt; Show me the actual snipped of code where you're defining maybe-nil type, pass it to a function and how do you avoid dereferencing nil without writing "if !nil" boilerplate. In Rust you do this all the time. `Option`s and `Result`s are `map`ped and converted using `into()` and whatnot, the same is true of iterators, in fact, the for loop is just syntax sugar for sequential checks of `Option` returned by an iterator. But that's not the point, I think you missed the point entirely. The point of the solution to the nil dereference problem in Rust and other languages is not so much a better usage of nullable types but rather not using them in the first place unless necessary, that is, having the possibility of _not_ using nullable types when you don't actually want to. A reference in Rust is guaranteed to not be null by the type system. In Go, Java, Python and others, references/pointers are all mandatory nullable. Many times one wants to write a function which takes a pointer/reference that is not supposed to be null, but the language (Go, Java, Python,...) forces you to write the function such that it also accepts null pointer even though you don't want that. That's the problem the languages like Swift, Rust,... solve - they don't force you to use nullable references when it better fits your usecase to use a non-nullable one. Many times I create an object or some data structure as a value and then pass a reference to it around without creating a nullable reference because it's simply not needed / doesn't make sense. In Go, Java, Python,... on the other hand, there's no middle ground, you can either use a nullable reference or cannot use a reference at all. &gt; I don't consider nil to be a program because I worked on a million lines of code C++ programs and of all the things that were difficult about that, nil-dereferencing wasn't on the list. Somehow I find that hard to believe. Professionaly I worked on projects in C, C++, Python, and Java, including very large ones. Those languages feature null in some fashion and each of them caused its fair share of runtime null-related bugs. 
Here's a wiki [comparing a few](https://github.com/tomarus/go-gui-libs/wiki) packages. [andlabs-ui](https://github.com/andlabs/ui) or [astilectron](https://github.com/asticode/go-astilectron/) are probably your best bets. There's also QML but the license is not commercially friendly.
Does chi handle sessions and auth?
This is a nice tip for me, so I don't hold myself back worrying about pointers. Not writing production code at this point
A consistent title of the article should read 'Golang vs Javalang'.
It depends on what you're trying to use it for. Data synchronization between a server and client is a very common task that can be implemented in a variety of different ways. This way uses websockets with a long polling fallback to sync a singular object between client and browser. Most of the time when you implement a form of websocket connection you don't want to limit yourself to syncronizing a singular object. If you did that for every object you want to syncronize, you would end up with a lot of open websockets to a singular client, which is a lot of wasted resources. You'll typically only ever need one websocket connection for each client consumer. That connection will typically implement a [message based communication](https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/architect-microservice-container-applications/asynchronous-message-based-communication). That basically means that many different data types are sent across the connection, but those pieces of data are labeled with event names so that the client and server know what data is being sent and how to handle that data. Message brokers like RabbitMQ and Kafka implement something like this. Although if you know that syncronizing one object is all you will ever do, than this library will help you. I wouldn't use it though simply because the last commit was 7 months ago, indicating that the project has most likely been abandoned.
You'd probably have to pass a `context.Context` around into each goroutine and occasionally check if it's been cancelled.
You could use a channel and close that channel if you want to exit go routines. In the go routines you use a loop with a select statement with a select on the channel and a default statement. The select on the channel will be selected if you close the channel. Check out this gist: [cancel.go](https://gist.github.com/iwittkau/f6c1a8dd2970e03fd5bee0a84645dd07).
I've used GTK3 with Go before via: https://github.com/gotk3/gotk3 It worked really well for what I needed (a workspace manager for i3 WM with a native GUI workspace grid overlay). I can imagine that building larger applications is pretty tricky though.
TL;DR: Java is old, Go is new, so ... &gt;Golang is a smarter choice than Java when developing enterprise applications.
A little simplistic approach would look like this package main import ( "fmt" "time" ) func task(done chan struct{}, output chan string, taskDone chan struct{}) { for { select { case &lt;-done: taskDone &lt;- struct{}{} return case output &lt;- time.Now().String(): time.Sleep(100 * time.Millisecond) } } } func main() { var done = make(chan struct{}) var output = make(chan string) var taskDone = make(chan struct{}) //Simulating sigterm with timeout timeout := time.After(1 * time.Second) go task(done, output, taskDone) go task(done, output, taskDone) go task(done, output, taskDone) for { select { case &lt;-timeout: done &lt;- struct{}{} // lets shutdown all goroutines // Now unmount //return case o, ok := &lt;-output: if ok { fmt.Println(o) } case &lt;-taskDone: fmt.Println("Unmounting") return } } } 
But in this code you do the task every second so that it will check whether the chan is closed after every second. In my case, goroutines are doing time consuming tasks that may take 10-15 mins.
Your task is short-lived here. It has free time to check whether we're done but in my case, they are long-running. It will never check if we're done before completing it's code block in select which may take 10-15 mins.
Like the other answers over here have said you can pass a parent context to all the goroutines you want to cancel . If you cancel on the context on any routine. They all will be aborted at that moment
Unfortunately, there's not really a way to forcibly kill a goroutine that's not the one currently executing (afaik). The generally accepted solution would be to use `context.Context` and periodically check if it is canceled, commonly that looks something like: select { case &lt;-ctx.Done(): // return the ctx cancellation error &amp; terminate default: } // continue doing things If you have expensive tasks that need the ability to be killed early, perhaps look into a way to segment them into multiple less expensive tasks. What are they be blocking on? If it is io read/writes it would be relatively simple to write a wrapper around any arbitrary `io.Reader` / `io.Writer` to do a context check between calls, as one example: type reader func([]byte) (int, error) func (read reader) Read(p []byte) (int, error) { return read(p) } func contextReader(ctx context.Context, r io.Reader) io.Reader { return reader(func(p []byte) (int, error) { select { case &lt;-ctx.Done(): return 0, ctx.Err() default: } return r.Read(p) }) }
You are either going to have to have the goroutines pause their work to check (I can't imagine you are writing something that isn't in a loop where you could check at the beginning) or you run them with a select as shown here, and if the select says to unblock the program just continues and doesn't wait for the goroutines to finish. This is a perfectly acceptable solution if your goroutines don't need to shut down cleanly and your program is heading to exit anyway. If it's not going to exit, the goroutine "leaks" and runs in the background, but you won't ever check the channel again, and it'll burn CPU til it's done. These are your only two options. There is no way to Ctrl-C a goroutine. 
Thanks for the correction. edited my post.
Yeah, I wouldn't worry about few updates to a library where most implementations target the 1993 publication of the standard.
yeah, my bad. but a lot of people using it right now, so would have to make another to change caps :/
[removed]
What about a large application, which utilizes microservices and therefore, in order to trace a message across 30 or so components, you need at least message IDs and what one application thought it did to it to merge with what another application thought it received as a message? What about enterprise code, where without logging you will never notice there was a network issue or that latency is happening because a disk or controller is failing? I agree for most small applications you don't need logs, but having recently used Caddy, I will say, there is such a thing as not enough logging. Didn't know what the heck it was doing, why it wasn't serving one of the files, etc. How about the current user-base, banking? Where it's more important to log than it is to not crash. Would be nice to know who stole your money and how much. For these, descriptive clear logs are more important than having an outage. There is also FCA rules, EU rules, etc which hold them accountable for having these logs.
make matches
Or do it in a better way(?) But if you insist: https://github.com/bestmethod/go-acp Yeah, I also do stuff no one did before. ;) The go-logger exists for where logging is dreadfully important (pretty much every banking, financial, government, nhs application out there) and must be syslog-way descriptive. Noted on the 'humble' part :)
You won't be able to stop if you don't check periodically if you have to stop. Same as with the context solution ...
If by "config" you're referring to settings/options for new instances in general then; I've always been weirded out by the date and odd things people come up with to convey config information to instantiate new instances. To me, a simple struct (FooConfig or FooOpts) is simple, toolchain/autocomplete friendly, can be serialized/marshalled, and just.. works. At the end of the day, some piece of code will always need to validate the config values regardless. /shrug, unpopular opinion I know.
The go-logger exists for where logging is dreadfully important (pretty much every banking, financial, government, nhs application out there) and must be syslog-way descriptive. Having said that, my application does not exit via fatal on error, it returns error… Did you misread the logger.Fatal() call that applications can call to log a fatal message and exit at the same time? It’s in line with log.Fatal() existing in the standard logging library as well, but provides exit code at the same time. 
[removed]
😲 sounds like a nice replacement for nginx proxy (and nginx-certbot). Wondering what the pros and cons are. 
`task` is not short lived. Its gonna wait until `done`. As I mentioned this is a simplified version
Pros: single binary, portable, works on all OS, lightweight, written in golang, so fast. Cons: not flexible like nginx/apache if you want to achieve something funky with your setup. It is designed for one job only (well 2): to serve proxy requests and to do redirects. Hopefully that means it can do the job better than others :) But since it's not super pluggable, it's fast. Less code, more stable, less bug possibilities. It's a tradeoff. I'm willing to add features as required, as long as it can remain nice and simple (and light).
[removed]
[removed]
Any differences of this versus traefik?
Well, it works in a number of banks for months now without dying once, so I think \*wrong\* isn't exacly the right wording. It's a small code base, I will not add 100s of interfaces to satisfy the test-crazed world we live in. Moved to Apache (GPL was an accidental mistake with clicking... the damn mouse). It's stable, it's fast, it doesn't break, it allows you to specify which levels go to stdout/stderr/devlog and it supports async. Bragging on tests removed. Didn't notice it. Someone else wrote the README at some point...
It sounds like the goroutine that does work once a disk is mounted should be the goroutine to unmount.
&gt;traefik Just that this one is light and simple, as opposed to heavy and feature-rich. It's more for those who just want as streamlined code as you can get while having configuration still present. Traefik is a brilliant project (no, really, it is), but requires a lot of configuration and time to get running (not sure about support). This just works with minimal config, which is what a lot of "let's just put a proxy in the front of multiple service endpoints and have the certs magically happen" people want (like me:D). Doesn't do load balancing (well, if you proxy to a dns name and make a DNS-balancer, it will, or if you use AWS ELB, but you know, it doesn't do load balancing on it's own).
Even with Apache, the license is still bigger than the source code. It's also interesting that one of the first things the README for a "production grade" logger is essentially "here be dragons" (about the async stuff).
&gt; There's also QML but the license is not commercially friendly. There have been untold thousands of QML (i.e., Qt) commercial apps developed under their free LGPL license, seemingly without serious issues. Sure, it's not as friendly as MIT, but I wouldn't call it *un*friendly.
There are multiple workers.
Yes, so does "here be dragons" exist in mysql config params and oracle DB as well as a multitude of Apache configs. Yes, code is small, but that's the idea. it's a light and fast logger while still providing configuration options most comonly searched for. It also means the 'dragons" are closer in the readme than in code that has a lot of functions/parameters. If it contained 1000s upon 1000s of lines, that is a bit of overkill for logging.
Took a quick look at the code and it looks like a simple to use front-end proxy. Looks like it's not yet using ACME v2; is that right? There's no end date for support of v1, but may be good to consider migrating to a library that supports v2 in the near future. My needs are a bit more complex so I've beeb using Caddy which is also a single binary with auto-cert. It also has plugins like rewrite, file manager, upload, hugo integration.
You are absolutely right. The Qt license in itself is not unfriendly. I was more referring to certain Qt/Go binding packages which have an unfriendly license.
Yup, for more complex needs there is caddy. I just found it a bit awkward to use and complete lack of reporting if I do something wrong with the config. I do love the filemanager plugin in caddy though. It's just brilliant. I'll have a look at ACMEv2 at some point soon, just busy with a multitude of migrations between amazon accounts and other CI/ID boredoms (the stuff they pay me for). Dully noted :)
It'll be very hard to convince people to use this when many other more production ready, better tested and well documented competing solutions already exist like Caddy. In fact there are a few other solutions that are also called goproxy https://godoc.org/?q=Goproxy 
ah, thank you!
&gt; just busy with a multitude of migrations between amazon accounts and other CI/ID boredoms (the stuff they pay me for) lol, the pain of us all. Great work with the project!
Yes. It's somewhat idiomatic to return the result of the computation as a value object, or a pointer a freshly allocated object. But any strategy that would effectively avoid allocation would increase perf, e.g. passing as argument a pointer to the object to be populated.
Agreed. Also precisely zero tests is a disappointing thing to see.
Anything your code depends on inherently becomes your responsibility. In Go when you require a library the code is necessarily pulled locally so you can compile. Even if an upstream repo vanishes, you will find your local copy in your `GOPATH`.
No GitHub doesn't prevent projects from being deleted. Depending on the license of the open source libraries you are using, in most cases [vendoring](https://golang.org/cmd/go/#hdr-Vendor_Directories) (and don't put `vendor` to your `.gitignore` file) is the way to protect against the concern you have here.
First of all, your concern is not with depending on open source. Both Go and (to some extent?) Java are open source. Your concern is with small projects. The short answer is: vendor. &gt; I assume Github dependencies are safe.. e.g. Github either prevents the removal of a project once created.. or keeps some sort of referenced link that always works? No. Vendor your dependencies and you'll be fine. &gt; In the case that it is possible a dependency disappears and your code no longer works/builds.. is the solution to clone/fork the repo so that you now manage the fork/clone, and dont worry about it disappearing? Vendor it. Then you'll always be able to build it. If you want to make changes to the project after it disappears you can create a new repo from your vendored copy. No need to preemptively fork every single package you use.
Nice looking project!
By "config" I really meant something that users can edit (i.e. a yaml file) and serve as general store for configuration options "outside of the application". For passing new instances I'd use a struct too or maybe a sub Section() of the config implementation above - if I'm in the need of reacting to changes. Regarding validation: True, it has to happen somewhere. But even if it's done later down the line again, it's often helpful to catch invalid options as early as possible.
Is there a plan to provide webassembly support for vecty?
Gotcha. I think in general I've still preferred to keep them in a plain struct, marshaling/unmarshaling it as needed. Being able to statically understand the config is just good. My 2c :)
\&gt; refuses to compile with unused variable \&gt; compiles fine with unused function return value
Using a struct might be a perfectly valid usecase, depending on the size of the application. Once it gets bigger though, there is often a lot of additional adhoc validation code. Also, in my application it's possible to do something like "app config set backend.workers 20". This would be a lot of boilerplate code with plain structs (validation/parsing/casting). &gt;Being able to statically understand the config is just good. My 2c :) Same opinion here. That's why I decided to define all keys in a \[static structure with go types\]([https://github.com/sahib/brig/blob/develop/config/example\_test.go#L17](https://github.com/sahib/brig/blob/develop/config/example_test.go#L17)).
That doesn’t matter, it just means the goroutine responsible for ensuring they all exit is the one that must unmount. If there is no synchronization for the exit of the workers then that is your problem.
Is this question different than the exact same title you posted a day ago? https://reddit.app.link/c1XLupXbRN
because I didn't get an answer last time
So what did you do differently this time to expect a different result?
&gt;I just found it a bit awkward to use and complete lack of reporting if I do something wrong with the config. The CLI for caddy has a `-validate` flag: &gt;\-validate &gt; &gt;Parse the Caddyfile and exit. If syntactically valid, a message will be printed to stdout and the process log (if any) and will exit with status 0. If not, an error will be returned with a non-zero exit status.
Here's some idea I would start with. If it's only 1vs1. When new player joins, search for all existing lobbies with one player and if none found create new lobby instance with this player. When next player joins it will find this lobby and join it then possibly let both confirm and start the game.
You need to find a way to split those tasks into smaller parts, between which you could check if it should exit if you need to stop work cleanly.
You could just memorize the number of operands at startup so that you don't have to use reflection for every call... Also you can avoid using interface{} by having all lambdas take two args and ignore the ones that are not needed...
&gt;handling anything in go beyond basic ints and goroutines is a fucking nightmare FTFY
&gt; There are examples in the example/ directory. Heh, I feel dumb. This should be in the README. &gt; I want to make sure we are not giving people a bad impression of the project by adding docs when it's not production ready. I still say you are conflating two things: 1) People who *might* be interested in the project. There are millions of projects out there, so they won't spend hours evaluating any one. You need to help them by giving them as much information upfront as you can. If you have a bad readme, they will just move on. Even if your project doesn't do much, you want to "pitch" it to the developer community so you can start getting as much feedback as possible. ("Have you considered.." "Do you know about.." "Here is a PR adding blah") If it doesn't look like **you** are investing time in your project, nobody else will. That is why people have nice READMEs, sometimes even nice logos for their projects (regardless if it's ready for production or not.) 2) People who *might* want to use this for production. A warning in the readme is all you need. You will not "trap" a developer into using it for production just because the README is nice, or just because you documented some examples. On the other hand, a bad README will lower the number of people giving you feedback, or giving you ideas, or trying out the project, etc.
It is a daemon program.
Go's philosophy is to keep things simple and do not implement a feature as a library if it is already standalone binary. So just use Docker with `--restart always`.
That doesn't work if the goroutine is hung in a system call. Contexts can only cancel things cooperatively, they are incapable of actively killing things, since nothing can actively kill goroutines.
It's up to you. Opinions vary. I'm on the "yes" side because I'm a fan of being able to build even if the network is down, or building from servers that are not connected to the internet at the time they are building, or being able to build even if a project is actively terminated by its creator, but it's an opinion. All the reasons I gave become more important progressively over time as you add dependencies, and Go programs tend to have many fewer dependencies than Node programs, so you can get away without committing for a lot longer.
Well, while an interesting example for reflection, it's still not what I would have done. For an RPN calculator, passing the stack to each operation would be correct. Addition should indeed be `func(s Stack) { s.Push(s.Pop() + s.Pop()) }` in the table. It gets less fun if your stack can hold values of different types, though. Then again, while Python may superficially look better than Go, both of them will be prone to errors in your own ways. You really need something like a Haskell GADT to make that use case slick.
Another cool thing that you can do is to let functions have methods. First define an interface: type Op interface { Do(operands ...int) int } then have `catalog := map[string]Op`. Furthermore, define 3 new types: type binaryOp func(a, b int) int type unaryOp func(a int) int type nullaryOp func() int Let each type have their methods that implements `Op`: func (o binaryOp) Do(operands ...int) int { return o(operands[0], operands[1]) } func (o unaryOP) Do(operands ...int) int { return o(operands[0]) } Then write the functions such that when you assign to `catalog`: catalog := map[string]Op { "+": binaryOp(add), "-": binaryOp(sub), }
I have seen a little bit of this.. still trying to understand why I have to go get a library if I can provide the import to it directly in my code.. why doesnt go just download it at compile time automatically? But besides that, once I go get a library that ends up in vendor/ do I commit that to my repo so a clone of my repo works without needing access to the vendor sites? Guess I need to read up more on how that works. I was always taught not to commit code like that.. e.g. let the build manager pull it down at build time, keep the repo clean as can be.
Got it.. so as I asked in the other reply.. once I go get a library that is now in the vendor/ path, I commit it with my code to my repo so that anyone cloning my project will get that too?
I found that it can't login to one of the servers I use (irc.chatrealm.net) I assume that it's because they use a self-signed certificate. I found in the code where you could set validate_certificates and set it to false in the config.toml, but that didn't seem to help and there doesn't appear to be a log of debug logging that I can turn on to find where it's having trouble.
That is correct, for any product/project, from a QA perspective, you should always commit everything required to rebuild your product again so it is identical to the last time it was built. The last thing you ever want, in any project, is some third party lib changes slightly and causes security issues/bugs in your product that you never had a chance to test the updates with.
I usually keep the folder in version control. Also nicer to see the changes if you update your dependencies and you always have a “working state” checked in. 
How does this differ from handling infra using the AWS API?
thank you man 
&gt; why doesnt go just download it at compile time automatically? Because you are concerned that you might not be able to download it in the future, and vendoring fixes exactly that. &gt; do I commit that to my repo so a clone of my repo works without needing access to the vendor sites yes, that's my "(and don't put `vendor` to your `.gitignore` file)" part. &gt; I was always taught not to commit code like that.. e.g. let the build manager pull it down at build time, keep the repo clean as can be. Google "reproducible builds"
That depends on what you want. In general, I would: - make a big slice of waiting connections, sorted by connection time - have each connection not be considered for match making for a random time (e.g. between 5 and 15 seconds) - pair connections randomly once they become "available" This *should* prevent the same people from playing each other back to back. If you want additional metrics involved (e.g. skill level based on win/loss record, geographic proximity, etc), add those in.
thank you man a lot
What happened to the CLI tool? Repo seems to have been removed?
Sounds like you are saying 'no' to adding it to .gitignore then? :)
&gt; can I freely copy/paste code into my own project so as not to have to depend on it? IANAL, however... Whether you can do this or not depends entirely on the license the code is released under. You need to take the license into account even if you don't copy code, if you will distribute binaries containing that code, you must honour the license conditions. Also, the original author typically retains copyright (varies by region).
Something similar to this? https://github.com/spf13/viper
Reproducible build. So "no" for me
Yes, at some point I'd like to investigate this. It should be relatively straightforward to do.
Thanks for the advice! About this library I like that you can use Server Sent Events with JS' EventSource instead of WebSockets, so lighter at times on people batteries for example. The idea of syncing a JS object sounded cool because I'm using React, so the synced object could be used as state for a major component or even an entire app potentially, for multiuser / multiplayer apps that can tolerate a few more ms of latency. The lack of recent commits is a bit worrying, yeah. Anyway after figuring out how to do SSE in Go, my next step will be WebSockets and I've been reading the article you linked with a lot of interest, so thanks. I suppose I could just use the Gin-Gonic framework and save some trouble... 
Yes, I think jerf meant “yes add; no ignore”. 
Fwiw, I mostly ignore it so I don’t have to check in big diffs when my dependencies change, but this is probably not a best practice. 
The popular opinion in the go community still seems to be to commit vendor to git. In many cases I'm not convinced it's worth it. Even when the network is down, or when a dependency is removed you can most likely still build. You have a local copy of all the files in `vendor`, and you have a `dep` cache of all the git checkouts. If the project is a library (no main package, or primarily used by being imported by other projects) then committing vendor is actually hurting more than helping. Anyone who uses the library is going to have all of `vendor` removed by `dep` so including it in git is just increasing the time it takes it takes to download. The size of the `vendor` directory can sometimes be an order of magnitude larger than the project itself. `dep ensure` gives you the same reproducible builds as committing vendor to git.
why are you here if you have nothing constructive to add? I see you frequent programmer circle jerk. Is this a weak attempt at trolling?
Now just write `if err != nil` across the rubber band and you get the *real* Gopher safety belt.
This seems really useful. Has anyone tried using this yet?
Of course you add all dependencies to your own repository if you want to keep sanity. As soon as team size is &gt; 1, you will inevitably get into trouble, if you don’t have 100% reproducible builds. The only reason you should not check in node_modules is that NPM is build in a way, that the contents of that dir are architecture dependent. You have to work around this limitation using yarn offline mirroring in the JS world. It works wonders in our ~2000 dependencies project. 
Yeah, will have to bake tests in. It's on the long list of todo.
I don't mind whether it's used or not. Just shared for whoever wants it :)
Thanks :)
I was wondering the same and that is why I posted it ;-)
This isn't readable - can you put it on Github?
Yes, viper does something similar, but in a different way. Viper supports many different input formats and some other features my implementation does not. Instead it supports migration/versioning, static validation and reacting on changed keys. So in short: Same purpose mostly, but pretty different API with somewhat different features.
I'm opting for NOT ignoring for sanity and compatibility reason. Suppose you include a project which does not have versioning. In this case the master branch is included into the project. If someone make some changes in the project without to be dev complete it might happen to broke. So in my opinion is better to include it.
Instead of \`app/\*.js\`, I think you want \`app/\*\*/\*.js\` to recursively search subdirectories of app, rather than looking for JS files in only the app directory
&gt;app/\*\*/\*.js The error still persists Error loading templates:html/template: pattern matches no files: \`app/\*\*/\*.js\`
My mistake, looks like that isn't supported in the standard library. See here for your answer: [https://stackoverflow.com/questions/38686583/golang-parse-all-templates-in-directory-and-subdirectories/38688083](https://stackoverflow.com/questions/38686583/golang-parse-all-templates-in-directory-and-subdirectories/38688083)
New companies like this that abstract away cloud api's because the product lines have become so complex. Developer tools for developer tools. Lol. I need a new startup like this.
[https://github.com/srikanth32/go](https://github.com/srikanth32/go)
Cant find any answer
For libraries I never commit vendor; for runnable projects (e.g. something with `package main`) I do. If a dependency disappears for a library then it's usually not a big deal as such, since all the stuff you actually want to run will still run (as the runnable projects have vendor in `git`).
We ignore it in all of our projects where I work. The only time I've committed it is when I've been making an open source project that I want to be `go get`-able.
[removed]
It is not trolling, it is true.
https://github.com/spiral/roadrunner/issues/11 you can find the solution here.
Sorry. Wee double negatives. I prefer to commit my vendor.
The purpose of a repository is to build a project, years later you will thanks the guy that commited vendor because libs / repo are not available anymore.
what about getting the User slice from your json, appending the new user, and converting it back to json?
Videos are the least effective form of documentation. They are difficult to refer to sections. They aren’t easily skim-able or scrub-able. Prefer simple text documents for everything, video for training style material.
JSON is relatively hostile to just "appending stuff on the end". Loading and marshaling the full file, making the change to the internal data structure, and marshaling it back out is going to be idiomatic in most languages. If you have super high performance needs, like you need to append something that _absolutely must_ be JSON to the end of a gigabyte file, there are ways to use the standard library to do that, but I'd avoid code this complicated unless you really, really know you need it. Step one would be, as I hinted at, seeing if you really _need_ JSON, or can go with something that can be simply appended to. In that case, given what you seem to be talking about here, a "format that can be simply appended to" can be as easy as "a file that contains a series of JSON objects representing users", such as: {"username": "blah", "password": "blah"} {"username": "meh", "password": "meh"} I mean that file, literally. No enclosing object, no commas between objects. You _technically_ don't need newlines between the objects, but I recommend it for human readability. For this, you'd open the file, create a new Decoder with json.Decoder, and then keep unmarshaling things into a User object until the decoder yields either `io.EOF` or another error. The JSON decoder can be re-used on the same stream just fine. The JSON decoder is also conservative, in that it won't read any more than it needs to, since all JSON values are cleanly delimited at the end, so you don't have to worry that the JSON decoder will read too far into the stream and leave the Reader pointed at the middle of the next object.
Both of your functions are already returning io.Writers. The minimal set of changes you need to make is... nothing. var logWriter io.Writer if (*cmdLineUseSyslog) { logWriter, _ = logInits(*cmdLineFile) } else { logWriter, _ = logInitf(*cmdLineFile) } Assuming cmdLineUseSyslog is a boolean flag from the flag package, and cmdLineFile is a string, just by way of example. In many cases, I would simply leave that code inline in the main function, but if you want to wrap it into one function something like func GetLog(filename string, isSyslog bool) (io.Writer, error) { if isSyslog { return logInits(filename) } return logInitf(filename) }
Thank you for your answer. I’m not in front of the computer right now but I will do it that way, it seems like the best! Have a nice day
That's exactly what these are, just additional training. If you check out our documentation you'll see it's very thorough! The videos are just supplemental and also timestamped in the descriptions to make it easier to navigate.
Thanks : )
Is this project basically the same idea as jOOQ? Is Oracle support planned?
Never heard of JOOQ before. It seems similar from the blurb on the main page of their website. Oracle support is not planned, although the out of band driver support in v3 makes it fairly easy to create one yourself.
i've been liking this library but i have 2 issues with it: 1) The API is not the best if you don't have structs to map the parquet schema too. Would like to see a way to read parquet easier without knowing all the type info upfront 2) No semver releases. This is pretty important for tools like dep On the other hand, I really like how a lot of the "internal" fields and methods are public so you can really get down into some lower level parquet concepts. For example, I was able to write a tool that retrieves the last few KBs of a parquet file from S3 and simply parse it as the footer of a parquet file. In this way we can look at column stats, row/null/distinct counts, etc. without downloading the entire file
**Thank you so much!** *I'd really faced with the situation with a re-declaration!!! You're a guru of Golang!* Can I ask another newbie's question by the subj? :) May I do the next trick? `func initLog(cnf *Settings) (io.Writer, error) {` `switch cnf.Log {` `case "file":` `w, err := os.OpenFile(cnf.Acc_log, os.O_APPEND|os.O_CREATE|os.O_RDWR, 0775)` `if err != nil {` `return nil, err` `}` `return w, nil` `case "journald":` `w, err := syslog.New(syslog.LOG_ERR|syslog.LOG_WARNING|syslog.LOG_DAEMON|syslog.LOG_NOTICE|syslog.LOG_DEBUG, cnf.Channame)` `if err != nil {` `return nil, err` `}` `return w, nil` `default:` `return nil, genError("Wrong value of the variable")` `}` `}` **cnf** is the structure containts of settings, and **genError** is an mine function for transform of the string to the error.
That should work. Though it's probably safe to just return the results of os.OpenFile and syslog.New as I did in my code; I don't think they will give both errors and values at the same time. Still, I have to admit I've got some places where I make extra-sure to return zero values when I'm not sure myself what the underlying code will do, so _shrug_ :)
&gt; Both of your functions are already returning io.Writers. I'd return a io.WriteCloser (both types satisfy this interface), so that the caller has the possibility to close it after use.
It is inspirational to see what can be done with the new web assembly support landing in 1.11 .
[removed]
[removed]
I thought this might be helpful for hobby projects as Heroku and GitLab both have free plans. This example shows a simple way to get started right away.
Indeed :)
I looked at this project when I was choosing how to access the DB in a small webapp. I gave up because how it expected the tables to be set up was poorly documented. It just said "ActiveRecord", which I am unfamiliar with.
Yes!!! Was looking to use this for a project, but the lack of sqlite support hurt. Excited to try this out!
Super confused about this comment. The Readme mentions active record three times and nowhere past the initial "why we made this" paragraph. Furthermore the requirements are here: https://github.com/volatiletech/sqlboiler/blob/master/README.md#requirements Contrary to every thing you said it is well documented and says nothing about Active Record. Instead of giving up if you were unable to grok the docs that are there, maybe you should have reached out and we could have fixed them up if they're not up to other people's standards!
Here's code for what you were asking for in case you don't want to go the [json lines](http://jsonlines.org/) route, which you may want to especially if you are dealing with a very large amount of users. The benefit here is a json array has much wider support than newline separated json objects. The downside is you're reading the entire file into memory. https://gist.github.com/montanaflynn/244e45f2ae597c5ac909712d8c8ec5da
It's always nice to see modern compiler/interpreter books. Looks promising thanks!
The first example is a fake, not a mock.
OP gave you a valuable experience report, and your response is very defensive and argumentative. Instead of arguing why their feedback is wrong, try to learn why they might have had that experience and improve your product.
But if you use this streaming approach, are you concerned about wanting to change the password of an existing user entry? In that case, you would already have appended a user, and you would need to append another entry for the same user. When you read the file back, you would need to keep updating existing user objects as you read them from json. Are you looking for an append-only solution (a file that only ever gets new data appended)? 
Not all feedback is valuable. The word "ActiveRecord" is mentioned three times, two of which are in the first two sentences. The third mention of the word table (first being the "Table of Contents") in the readme describe how it expects the tables to be set up. It's the first section after the first code example. I don't really see how you can measurably improve your docs based on a feedback that indicates the person did no read past the first paragraph to find a very specific information before giving up.
&gt; The Readme mentions active record three times Yes. Apparently in lieu of its own documentation on how the library infers relationships. &gt; it is well documented Not really. Where's the *explanation* of how tables should be named? There's one simple example. Examples should supplement explanations, not replace them. What happens if my table is named `video_users` instead of `user_videos`? Does that affect the generated code? What about `users_videos` or `videos_users`? Before deciding your library is well documented, please find someone unfamiliar with the code and see how far they get with only the docs (i.e. don't help them). It's extremely difficult to judge the quality of your own documentation because it's almost impossible to put yourself in the position of somebody who knows nothing about the library. 
use a RWMutex workers will get a read lock when working. When you want to unmount, get a write lock, and the workers won't be able to obtain new read locks until the write lock is released. Obtaining a write lock won't return until the last read lock is released also [https://golang.org/pkg/sync/#RWMutex](https://golang.org/pkg/sync/#RWMutex)
You might also use JSON Sequences, since it's [an actual RFC standard](https://tools.ietf.org/html/rfc7464) and has a defined MIME type distinct from JSON. There's [a Go implementation](https://github.com/jmank88/jsonseq).
Good post but please reconsider your font color choices (assuming OP is the author). Even someone with good eyesight and no color blindness may find it difficult to read in its current state (especially if they don't have a lot of constrast in their monitor)
I haven't used this package yet (but I do intend to do so, in combination with `arrow/go`). I must say I was a bit put off by the non completely idiomatic package names (_e.g.:_ `ParquetFile`, `ParquetReader`, ...) but hey! it's there :)
Function `template.ParseGlob()` is essentially `filepath.Glob()` [1][2] What I would do is to call `filepath.Glob()` with the same pattern and print the list of files to see if they match the list that you are expecting to get. Just be aware that this method will not run recursively, it will only return the files that you are directly matching with the pattern, but it will not go through the subfolders. If you want to get all the JavaScript files, you will need to either expand the pattern or write a custom file loader by yourself. [1] https://github.com/golang/go/blob/707ca18/src/html/template/template.go#L455-L482 [2] https://play.golang.org/p/GbVqA0iu1aF
&gt; Yes. Apparently in lieu of its own documentation on how the library infers relationships. More than be familiar with the library, I think this is a case of you maybe not being familiar with relational databases. It's not my job to teach those through our documentation. But I can try to help you out: When a table has a foreign key that references another table in a relational database, that forms a relationship (hence the name relational database). SQLBoiler being something that deals with relationships reasonably well obviously will honor the relationships that exist in the database. There's no need for inference here since this is a very well defined construct inside the relational database and the generated code simply reflects those. I feel the burning need to point out **again** that ActiveRecord is not mentioned in the documentation that covers this subject. The horse is dead, stop beating it. The documentation on this subject admittedly is brief because it assumes your comfort level with relational databases is very high. If it could stand to be improved I again welcome you to contribute where in the past you have not done so. Link to docs without the word ActiveRecord anywhere near it: https://github.com/volatiletech/sqlboiler#relationships &gt; Not really. Where's the explanation of how tables should be named? There's one simple example. &gt; Examples should supplement explanations, not replace them. The naming requirement is CLEARLY spelled out in the documentation I linked earlier. Past that it doesn't matter. The docs don't mention any extra requirements because there aren't any. It simply shows that if you name your foreign keys in a particular way that involve the table name you'll get nicer generated names for your relationships in the end. You've imagined a requirement and are somehow blaming us for not documenting the lack of it. Name your tables whatever you want, being careful to follow requirements where a requirement exists (snake case + pluralized, as documented). Before deciding the library is not well documented and posting zero-effort dismissals of all the effort that's gone into it, I again suggest that maybe you should have reached out for help if you couldn't figure it out so that we could have worked together to make it better. You seem extremely entitled. Remember this is open source, and all this work has gone on so you can use this for free if you so choose. Maybe expending a little bit of effort on your part to ask the questions before trashing the project would have garnered a little bit less of a passive aggressive dialogue between us.
Sorry about this! I've been meaning to redo the design for a while and I think I'll start tackling that this evening.
Great news! The previous book is super helpful as it is, going to a full compiler will be even better.
There's a few things to keep in mind if using a JSON file as a database - namely, dealing with ACID (Atomicity, Consistency, Isolation, Durability). Basically, adding the user should either work perfectly, or not work at all. * Atomicity: By using Rename, we ensure that no process can see the file in a non-valid state (such as invalid JSON). * Consistency: By Renaming at the end, we ensure that we will only present the new version of the file if it's valid (IE, represents a valid database). * Isolation: By using a Lock file, we guarantee that no User will be missed. It is easy to see that if 2 goroutines (http handlers for example) both add a user concurrently, they would both succeed, but only the latter user would actually end up in the file and the other user would be permanently lost. * Durability: We already get this by virtue of writing to, and closing, the file. https://gist.github.com/daniel-toye-vt/a1fd5917b9bef542e2a272f0293081a7
Saved for future study
No need to apologize, glad to hear it's being worked on :)
Neat!
just out of curiosity (not trying to be a complete dick), but how does this differ from something like: echo hello world | ssh user@host tee ~/myproc.stdout or something to that effect (with any credentials configured in a ~/.ssh/config). especially since ssh already allows for something like: tar czf - ~/ | ssh user@host tar xzf - for picking up your entire homedir, pushing it through ssh, and untarring it on the remote side.
It's a fantastic practical guide for Go once you've already grasped the fundamentals such as syntax.
&gt; I think this is a case of you maybe not being familiar with relational databases. No, I'm perfectly familiar with them. &gt; I feel the burning need to point out again that ActiveRecord is not mentioned in the documentation that covers this subject. I know. I took an earlier version of the library for a spin, when the ActiveRecord thing was front and centre. With its name popping up again, I made the not unreasonable assumption that that is still the case. &gt; The naming requirement is CLEARLY spelled out in the documentation I linked earlier. No, it isn't. You give a few examples. Like I said, examples are to supplement explanations, not replace them. &gt; I again suggest that maybe you should have reached out for help There was no point at the time I tried it: it was clearly explained in one of the GH issues that the library wasn't compatible with the schema in the database I was running it against. And I spent several hours adding all the FOREIGN KEYs to the schema that the original developer (yay PHP!) hadn't bothered to and renaming columns just so I could try sqlboiler. So stick your "zero effort" right up your arse. &gt; You seem extremely entitled. And you seem like a dick. You could have just said, "Oh, that ActiveRecord business has gone. The new version is way smarter." And I'd have said, "Awesome! Off to try it now!" But you got all defensive instead and started insulting me. Way to "advertise" for your community, don't you think?
nobody can look at your code unless it has an open source license associated with it.
Do those books can help writing an emulator in Go?
Without comments you are gonna have trouble getting anyone to review that. 
No prob - curiosity appreciated! The main reason I did it this way was to be able to use a config file to save defaults (possibly in future storing servers by name) without having to rely on a shell. For my use cases it was fairly important that I could execute from code if necessary rather than manually and rely on all those processes having one common source for the configuration. But I take your point - given the state of the repo now most people would probably be better served by piping the process :)
&gt; I know. I took an earlier version of the library for a spin, when the ActiveRecord thing was front and centre. I don't know how to tell you this, but even git pickaxe disagrees with you that that word was ever in our repository more than it is now, so no, you're still very wrong and I wish you'd stop insisting. Stop pretending like we campaigned "just look at ActiveRecord, that'll tell you everything you need to know!" instead of having documentation, this was NEVER the case and still isn't. So I can't say "Oh that ActiveRecord business has gone" because it's never been there! &gt; No, it isn't. You give a few examples. Like I said, examples are to supplement explanations, not replace them. Yes, it is. It says very clearly: "Table names and column names should use snake_case format." This is the only requirement. I'm not sure why you still think there's undocumented requirements? Or that ActiveRecord has some bearing here? Also there's no example here, it literally says exactly how you should name your table. How does this require more explanation than there is here? &gt; There was no point at the time I tried it: it was clearly explained in one of the GH issues that the library wasn't compatible with the schema in the database I was running it against due to its ActiveRecord-based expectations. We don't have any of these and never have. The requirements as documented have not changed since the the sections first inception of that section. I looked in the git history just now to check. If anything we have more strict requirements than they do. &gt; And you seem like a dick. I think we're done here. Have a nice day crackers.
If I lived in Oregon,and didn't had a job already... Sounds good
If you guys are ever looking for an intern let me know please! I'm a high school student in Portland and would have no problem commuting to Lake Oswego. I can PM you my details and resume if you're at all looking for an intern.
Wow! Great news!
`database/sql` plus `SQL` queries as abstraction on top of your database :)
Been using https://upper.io/db.v3/ for the past few months, great middleground for ORM/raw query patterns.
The `database/sql` access library is absolutely fantastic. I'm looking for a little bit of abstraction for my team though :)
This looks neat - a very tidy API. If you don't mind, why are you using this rather than `jinzhu/gorm`?
It isn't open source yet, once it is reviewed, I am gonna upload it to github. You saying I should add a license just for you guys to help review it?
Shouldn't be to hard to read but I will add some comments, thanks!
Yeah, to *you* it’s not because *you* wrote it. I’m sure someone could figure it out if they spent the time studying it, but you didn’t even tell us what this is supposed to do, or what it’s purpose is.
Gotcha, the licensing system licences software by handling get requests. It has capabilities to register with a key or login with a username and password. The Instagram Turbo constantly checks a Instagram username for change and when it does, it changes your username to the designated one. Thanks!
Why?
yes. without knowing what the license is i can not look at the code.
We have a small client base so aren't optimising for milliseconds of performance just yet, and would prefer the speed of development that an ORM would afford us. We also have a lot of data models (i should have explained this in my initial post) so an ORM would simplify access to relations, as well as the readability of our code.
Why should it cause a warning? It's not overflowing. Quite a lot of numbers that you might want to work with can not be perfectly represented as floats. You should only use floats when this is not a problem. For example, 6.125 and 2^64 can be represented exactly. 2^63 and 6.1 can not. Should the compiler also bitch if you happen to use `6.1` because a float can't hold the value losslessly? Because what, let's ignore the IEEE-754 semantics and have the compiler whine about shit the FPU couldn't give two fucks about? There's a lot of low hanging fruit to complain about, no need to grasp for straws.
I'm doing exactly this!! So i just bought your interpreter book :)
I'm very excited to see this. The first book was really good and kickstarted my learning about how languages worked. The language I made based off the first book already has a compiler and virtual machine but I'm looking forward to see how he handles these topics. Hopefully I'll learn something to improve my existing project.
I think some of the confusion people have is caused by popular web frameworks in other languages making it seem like there's only one right way to do things. Obviously, that's not correct. Here are a few very different approaches I've seen people use: 1. Just use database/sql and run SQL queries directly in your HTTP handlers. This works for very small apps or if you aren't writing very detailed tests. It doesn't scale as well as some other solutions. If you go this route, check out `sqlx` for a lot of great, simple helper functions. 2. Use one of the "magic" reflection based ORMs, like GORM. Many of these are very polished and have lots of pretty documentation. They are not the worst thing in the world, but, still, I strongly recommend you stay away from them, because they tend to be complicated and inefficient, and they tend to sort of take over your whole app, making it difficult to change your mind later if you want to use something else. 3. Use one of the statically generated ORMs, like sqlboiler. These are much more efficient and "go-like", and they work well as long as you are following the same patterns as they are. It can be more difficult to mock ORMs of this type out in tests, though. If you don't like one of the existing libraries, it's easy to make your own using Go templates. 4. Implement a DB or Model struct, with methods for all the different sorts of calls you need to do. For example, if you need to load all of the rows in table A, add a `SelectAllFromA` method. This still requires you to write SQL, and it might be higher maintenance, but it is lightweight, it's easy to mock out in tests, and you have a lot of control over optimizations and other things like that. You'll probably find that, in practice, you usually only use each table in a few specific ways, so there aren't actually that many methods that you need to implement.
Excellent, thoroughly enjoyed the last book. I've been following crafting interpreters since. Pet peeve, when is this summer?
Are these models strongly related or not? Do you anticipate to use a lot of complex join statements sometime in the future? For simple relationships that does not join more than 2 tables, I think an ORM would probably fits your needs better since writing data access code is a bit tedious. For queries that need to join more than 2 tables, I would suggest writing your own query code and use `database/sql`.
I think a combination of context.Context as other people have mentioned but you also need a sync.WaitGroup to tell when the other goroutines have finished. See [https://play.golang.org/p/9ZXsQtzrhB1](https://play.golang.org/p/9ZXsQtzrhB1)
I am curious about it. Is there any law specifically saying that one cannot inspect another's code unless the code has a license with it?
Exactly my thoughts haha.
I plan on using the GNU GPLv3 licence.
Well, you got me -- summer is already here. My plan is to release it at the end of July, beginning of August. So, still _this_ summer :)
Since writing a virtual machine and writing an emulator is not completely different from each other, I'd say, yes, it can help. But I also have to say, that emulators are not explicitly mentioned or that it's my goal to teach something about emulators.
no. it's common sense. if i find a bug in your code and then you sue me because "i wasn't supposed to be looking at your code, just see the goddamn license ffs" then i lose. nobody volunteering their time on the internet wants to deal with that. 
&gt;end of July, beginning of August That's winter for me ;) Excellent! I'll buy it soon as it's released Thanks for the top notch work :)
&gt; That's winter for me ;) Ohhh, now I get it! Sorry about that. Now that you mentioned it I think I'll have to change it... And, thanks for giving me a new pet peeve ;) &gt; Thanks for the top notch work :) Thanks! Glad to hear you enjoyed it! 
Very inspiring for use in translation tools. 
Looks awesome, I'm excited
Hmm...I am not sure how likely you will lose that kind of case. To me, it sounds like an author sues you for browsing a few pages of his book at a bookstore (assume the book is not packaged). 
&gt; would prefer the speed of development that an ORM would afford us Perhaps that's true due to your second point, but I've never found that to be the case in general.
Thanks! After your response and the other replies in this post i've decided that we will just go about implementing `database/sql`. 
I've gotten into the habit of doing two commits (one for vendor, one for my changes) to make diffs easier to grok
&gt;We do not see the version 1.2 as well as 1.1, 1.0 or 0.6. It seems this is happening because of the semantic import versioning paradigm of vgo. It is ignoring any versions that is not in the vn.n.n form. Let’s hope this issue is temporary as well. Man this is definitely not a small issue. Dep seems to me like a much more matured solution, at least with current stage.
I've gotten into the habit of doing two commits for that reason
It's a little bit outdated, there is a new command `vgo mod` which replace `vgo vendor` and add other possibilities. The cache path `v` is replaced by `mod`. And so on, vgo is growing fast these days, we should `go get -u golang.org/x/vgo` regularly ! 
It was built on a Windows machine and cannot be run on anything else. You'll need to get the source code, install Go, and build a version on your platform.
So there isn't a way it can be run using Docker and it was a binary of a filename_test.go file. Okay thank you!!
Thank you! This excess code is the serious mistake? 
Thank you! I'll fix that.
I love it. Please do the following: 1.) Finish writing the book 2.) take my money 3.) maybe write a chapter about the forgotten part, whatever it is :D 4.) go to 1.) Thank you, Sir!
somebody committed a binary they shouldn't have. `git add -a` sucks.
Southern Hemisphere people: many other people in the world experience cold “summers” and hot “winters” (eg. Hawaii, India, and San Francisco all have seasons that don’t correspond to the standard summer = hot and winter = cold paradigm). Why are you special so that you get to call Q2 “winter” instead of just “cold summer”? I think it’s nuts. Just say you have hot winters and stop all the confusion. 
&gt;No support, no warranty Well this brings me lots of confident
I know for sure you don't want to "redirect" the user anywhere. You want to serve that file directly. If your file is members.html, then requests to /members.html would run through your Go server, which would stream the contents of the file back out as a response (if the JWT allows it).
can u help me out with the code according to my application mentioned above
`dep` matured? `dep` is defective by design because vendoring is defective by design.
I've found the sqlx package to provide the perfect amount of abstraction for the job.
It'd certainly be nice for vgo to support branches by name, and arbitrary tags. Then again, if we can consistently use semver, I personally wouldn't complain about it. It'll be those cases where library authors don't want to do that and we're left with that v0.0.0-SHA business dotted all-over that make it nasty.
This comment made my day. Thank you!
Whatever starts with https://ghostbin.com/paste/gbeec#L178 is wrong on so many layers I don't know where to start, sorry. You should really get the basics of how HTTP and HTML forms work before embarking on using them.
You might need to set the content type for the request. 
A couple of assorted points re https://ghostbin.com/paste/kdsqr * There's no need to initialize a mutex. Just do `var mu sync.Mutex` and use it; it will be initialized on its first use (when `Lock` is called on it, that is). In either case, initalization of global state somewhere deep in some event handler is a no-no. It's okay to initialize there something which requires accessing data which is not available in the program itself (like reading a file). "Static" global state should be initlaized "statically"—that is, in the `init` special functions of their respective packages and/or somewhere in the preamble of `main`. * Never overwrite a file the way you do it—it is wrong on multple levels: * You only protect it from multiple concurrent updates which could be attempted in a particular running process. But this does nothing to prevent concurrent updates from several processes executing the same program or several processes executing *different* programs (such as a user updating that file in a text editor). * If the process executing your program will be killed—for whatever reason inclusing the power loss of the host computer—at the point where `ioutil.WriteFile` opened *and truncated* the file but before the data to be written had been actually written to that file (and the OS synchronized its internal buffers and so on and so on) you will end up with an empty file—with all the data lost. The only "true" way to do in-place updates is to use the classic "write the updated data to a *new* file → flush it → close it → rename the new file *over* the original one"—this sequence ensures atomicity of the update because even Windows supports atomic renaming, and so if any of the steps fails, you'll end up with an old version of the file. For a start, you might look at [`github.com/dchest/safefile`](https://github.com/dchest/safefile) (I, for one, do not like its implementation, but it works). * Do not hard-code TCP port names—either make them configurable (look for the stock `flag` package for a start) and/or use the port "0", then—after creating a TCP listener for it—ask it what port the OS assigned to the listener, and print it so that the user knows where to connect to. (If you're doing web UI, it's also possible to just run a browser with the URL constructed to point at the correct port so the user does not have to think.) * Regarding the code organization—it's quite suboptimal at the moment. * Refrain from "inlining" everything. The fact in Go it's possible to make a lambda right out of function literal does not mean you *have* to do that—if the said lambda is over, say, 10 lines of code it hinders code comprehension. This approach also makes further updates to the code harder. That is, don't be afraid to create types with methods where applicable: types tie bits of data, and behaviour, together in more easily understandable chunks. * Use blank lines, really. A solid wall of text is not too great to look at.
I pretty much been using these resources. https://www.vividcortex.com/resources/the-ultimate-guide-to-building-database-driven-apps-with-go http://www.alexedwards.net/blog/organising-database-access Tutorials - http://go-database-sql.org/index.html https://github.com/golang/go/wiki/SQLInterface Structs to tables - https://github.com/samonzeweb/godb/blob/master/README.md
You’re right about it being overkill :) but even in a scaled out production environment I wouldn’t use Kafka like this as a message bus. I know a lot of microservice “frameworks” put some sort of message bus in between layers, but personally I wouldn’t. First, there’s no great way to give clients back-pressure if you’re under heavy load, except timeouts, which aren’t great. And in a related point, it lets the backlog of order requests grow without bound. Second, it doesn’t really do anything for you except serialize requests to your back end service, which you can do anyway by limiting the number of workers or DB connections or whatever. Third, if your client drops off due to timeout, you’ll still complete the order (this is a problem anyway, but it’ll be more common with a message bus) Also, if you do decide to do this in production, Kafka isn’t the best choice because it’s near real-time (typical latencies in the hundreds of ms to several seconds). But I wouldn’t worry about that for such a project.
My general advice for kafka is: Don't use it until you REALLY need it. Setting up and maintaining kafka is more complex then the rest of your setup. Your setup sounds like it is all synchronous, so I would go with grpc. grpc really is a great framework, if implemented well it is like just using local functions.
`curl -H "Content-Type: application/json" -X POST -d '{"foo":"bar"}' http://scooterlabs.com/echo` doesn't work either. Without the content type set, it returns ``` [request] =&gt; Array ( [{"foo":"bar"}] =&gt; ) ``` and interprets it as `[Content-Type] =&gt; application/x-www-form-urlencoded`.
Have you considered using a decorator for your HandlerFunc instead? [https://medium.com/@matryer/the-http-handler-wrapper-technique-in-golang-updated-bc7fbcffa702](https://medium.com/@matryer/the-http-handler-wrapper-technique-in-golang-updated-bc7fbcffa702) Basically, you can implement a HandlerFunc that serves the restricted contents, something like: `func serveContent (w http.ResponseWriter, r * http.Request) {` `fmt.Fprintln(w, "restricted contents") // or something similar` `}` Then you use another function to take the `serveContent` function as an argument, check the authorization, like the `MustAuth` function in that article, and return a new handler depending on the authorization. Then you need to implement the `validateAuth` function that checks if JWT is included in the request.
Awesome idea! In this case you have one service that needs to know about the order, so it might not make sense to use kafka. Instead I think you might want an RPC server (which can just be another restful http api). Let's say in the future you want to add a "warehouse" service that's responsible for boxing up the item and shipping it to the customer. At that point you might want to consider a message bus like rabbitmq or kafka for life cycle events. Things like "order.created", "order.updated", "order.deleted". Now the "warehouse" service can subscribe to "order.created" events to send the package, and when it receives updates from the courier, they can make RPC calls back to the order service. Also, if you want to add a "notifications" service, they can subscribe to "order.created" to send a "thanks for shopping with us" email, and "order.updated" to notify the customer when a package has been delivered. In summary: keep request/ reply messages (things that have to happen now) over RPC and use a message bus for life cycle events (things that have to happen eventually). This certainly isn't the only way to build a distributed system, but it's what we're currently using in production, and what I would reach for if I was starting over. Quick side note: We use nats in production for our request/ reply stuff, and we really like it. It's super fast, but it's also been a learning experience. Since the main intent is for learning purposes I would start with an http api for your backend services, and then try swapping out your RPC transport for nats or grpc. Try changing your message bus from kafka to rabbitmq, or reverse. Start with a simple working setup before adding complexity. And remember to branch often, haha! But really though, this is an awesome project! Have fun!
Hey, thanks alot for the very detailed reply (need to google some of the words mentioned though, and led me to discover new concepts)! What are your thoughts about other transport methods?
If I were to go with grpc, I think I would go for go-kit for each services, and implement the api gateway with an HTTP transport method. Is this the right way to go? Also how did you come up with the decision; "all synchronous, go with grpc"?
&gt; Southern Hemisphere people: many other people in the world experience cold “summers” and hot “winters” (eg. Hawaii, India, and San Francisco all have seasons that don’t correspond to the standard summer = hot and winter = cold paradigm). Why are you special so that you get to call Q3 “winter” instead of just “cold summer”? I think it’s nuts. Just say you have hot winters and stop all the confusion. OP didn’t say, I’ll release the book when it’s hot outside. He lives in Northern Europe; it’s not going to get hot outside for him! He said “summer” which means “between June and August”. Don’t confuse things by giving those months a different name just because it’s cold for you. Is this some elaborate joke I've missed?
I am not a go developer (yet) but I did read about vgo and it sounds like this is very deliberate. If newer versions exist then it will not use a later version, you do not want your build to suddenly break because a report had a bad commit added on top. It uses the latest, used version. A branch is by nature subject to change. Vgo looks awesome to me.
Yeah, that's fine, but I think /u/uw_NB and I are only saying it'd be nice if it were flexible enough to have both approaches. Then again, maybe that opinionated nature is the right move, much like how Go is quite opinionated and there aren't many ways to solve the same problem - it can be an advantage and disadvantage. In practice, I will be using semver as often as possible.
This does a real good job of explaining the reasons behind this choice https://youtu.be/F8nrpe0XWRg
Thank you. I had not heard of it. That does have some advantages. Kinda nice to see some of those obscure ASCII values get used correctly.
Blocking during an http request for a response over a message queue is generally a bad idea. You’ll want to use something synchronous, such as grpc or http. Otherwise the request can timeout if the backend is down, leading to hanging requests and bad user experience. 
Hi! If it's opensource, could you share a link?
It's called Nitrogen: https://github.com/nitrogen-lang/nitrogen. It's foundation is based on Bell's first book but I've since added several features such as constants, classes, imports, and plugins. The docs are still a work in progress so if you have questions feel free to ask.
I imagine that the service list is abbreviated for the sake of time with this project but I just want to mention that a bare minimum ecommerce project would have more services. Notably, you would need a product, user and a fulfillment service. The only non-obvious one being a fulfillment service. But fulfillment typically becomes very complex in ecommerce and understanding how you intend to ship, from where and how much it costs is a task that will have a different scaling profile than other services. Otherwise, I completely agree with others feedback about Kafka being a large point of weakness in your design.
Not sure I understand your logic there. This happens in http as well. 
Wow, thanks for sharing this!
When I first started Go, I ported ruslanspivak's "simple pascal interpreter" series to Go. Code here: https://github.com/thegtproject/spi Complete with an AST graph generator: https://github.com/thegtproject/spi/blob/master/images/sample1ast.png
https://12factor.net/logs
That's nice! I've never heard of ruslanspivak's series of articles before. I'll take a look now. Thanks!
This is quite an interesting one. The main thing I'd say is that I'd not normally use a queue like this, it doesn't seem to serve any benefit throwing a queue in here, other than to make it more complex. If nothing else, I'd use a queue if I were processing orders asychronously, i.e. if I responded from that order endpoint once the order was submitted to the queue, and not when it was actually processed. In this case though, that probably doesn't make too much sense.
Honestly I’d just do a straight pass through (synchronous API call) to the Orders service, just like you do with a sql database. If you need scale, then scale out the Orders service and put it behind a load balancer (if that’s where your bottleneck is). Use that until you run into a problem you can’t solve without a message bus.
Honestly, I've never felt slowed down by not using an ORM in Go. If anything, it's quite liberating, and easy to write.
My understanding of upper.io/db is that it's more of a DBAL than an ORM, meaning it's probably going to produce faster queries as a result. It's a bit less magical.
Where logs *should* go depends almost entirely on your platform of choice. Are you exclusively using containers? Probably want to log to stdout letting the container management system like k8s handle log redirection, or bypass that altogether and use a UDP log ingestion endpoint. Is there a file-based log ingestion agent that you're required to use? Your hands are tied, log to the expected file location and configure logrotate as needed. Write your app to assume write permissions or log to `/dev/null`/noop where permissions are not provided. Are you too lazy/inexperienced to set up centralized logging or configure your container management engine to handle log redirection? Log to a file with proper logrotate configuration and forget about it.
Where logs *should* go depends almost entirely on your platform of choice. Are you exclusively using containers? Probably want to log to stdout letting the container management system like k8s handle log redirection, or bypass that altogether and use a UDP log ingestion endpoint. Is there a file-based log ingestion agent that you're required to use? Your hands are tied, log to the expected file location and configure logrotate as needed. Write your app to assume write permissions or log to `/dev/null`/noop where permissions are not provided. Are you too lazy/inexperienced to set up centralized logging or configure your container management engine to handle log redirection? Log to a file with proper logrotate configuration and forget about it.
Considering the educational context of the issue. I'd pay more attention to the criteria you use to separate between services. Your teacher will surely ask. Why did you separate things like this. Are they at the same abstraction level, are you following open closed principles? Etc...
By merit of using a message queue, you are not guaranteed prompt response. You also don’t know when the task will be handled. The queue could be full or not enough workers. If you are calling an RPC server, synchronous response is expected. It’s like mailing a letter when you really need to just phone someone. 
Queues are good for background tasks that live longer than a short-lived request. Websockets may change this down the road. 
Mentioned in another comment, but this video drops a great job of explaining vgo's design decisions. https://youtu.be/F8nrpe0XWRg
Log to stdout or syslog and let your runtime handle the rest. 
There is nothing wrong with writing to log files. Sometimes stdout is useful, sometimes log files are useful. If you accept `-` as an argument then you can support both (which is easy thanks to the `io.Writer` interface).
[`true` is not necessary here](https://github.com/lane-c-wagner/spi/blob/master/spi.go)
Adding to that, you can use [https://github.com/agnivade/funnel](https://github.com/agnivade/funnel) for it.
In general I prefer to write to a local# facility of syslog and let the dev/prod system configuration determine how to handle the data. Write to a log file on my dev system, but do log shipping to a central syslog server for my production machines. Keep stdout nice and clean for when I'm doing dev work and want to dump something to read.
Why stdout? strictly speaking that's intended for consumable program output, and stderr is more for informational stuff, right? To note, if you write logs to disk you also need to worry about potentially filling your disk up if you have a massive number of errors. If you have to, I would recommend a specific limited partition for logging so that it can't affect other operational things.
Your hypothesis does not work for programs producing their results already to stdout.
Yeah, that was definitely a weak point in that code. I had to extract some JSON from within a whole HTML file and didn't know the best way, so I just trimmed everything left of my string and then everything right of my string and I was left with the JSON I wanted.
I don’t agree Kafka in Go is incredible easy to use and extremely powerful. Projects like confluent-kafka-go are very easy to use and set up. 
Will look into all of this, thanks so much for taking the time to look into this code. Will update you with the GitHub links shortly after I look into.
I’m new to this too, and wondering what to use for request/reply between my services, from my understanding I thought NATS is a messaging queue (That can replace Kafka and RabbitMQ). Am I wrong thinking that, and if you don’t mind can you tell me how you’d use it as a replacement for gRPC?
$0.02 Compiling different binaries for different environments is a terrible practice.
Use a redis pub sub mechanism as a message bus, much easier to configure than Kafka. Since this is not a real production service, red is would be a simpler and better choice.
Honestly, I hadn't thought about how this might prove useful from within a go process instead of a separate binary. Being able to do logging/output over ssh without relying on a shell would make for a nice option for use in a single-binary-container-service :D
If you write to log files you also need to support rotating them, and that's tedious to get right and to handle flexibly. Even if it's just something old-school like "reopen on SIGwhatever".
What I have done in a similar situation is to map the configuration to host name or some other environmental variable that is retrieved at run time. To have only a single executable file act differently on different machines without managing a configuration file separately. 
Thanks. I've never used it before, we actually we're working on an app that required a bitbanged solution because it didnt't adhere to all the spi standards (on a hardware level) so it needed a custom solution. I should probably include that in my article.
[removed]
Could you please explain why? I'm new in Go, so all the information, you can provide about the compilation, will be thrilling useful!
Yes, I've thought about environment variables, but I try to avoid them.
Why?
Maybe I'm missing something, but why not use docker swarm configs?
It's just a personal preference. I know the mentioned variables are useful and can be easily handled in the Makefile, but as a newbie, I don't have a standardized naming procedure for those variables.
I don't use Docker for my projects; I right now I prefer to run them on the VPS itself, without encapsulating them in a Docker image.
Even in non-containerized apps, it seems writing to stdout/stderr is the way to go these days. If it's something designed to be daemonized, letting whatever executes the process (systemd for example) can be told where to send the logs, defaulting to a common location like /var/log/syslog. If it's running inside a docker container or k8s, they have their own way to send logs. More and more, I think the only time you want your program dealing with log files directly is if you have a need for specific multiple logs. But even then, it seems like adding labels or tags to your log stream would be the better. 
That’s a really cool idea actually! I hadn’t thought of that one :)
You may set variable(s) during build with linker flag `-X`. See an example at https://www.atatus.com/blog/golang-auto-build-versioning/ One way is to pass multiple values. Strings only though. Another way is to set one variable that defines environment name. In the code select respective configuration based on that. I would also add output when application starts to indicate which environment it is configured for. However, I never embed configuration in my applications. First, you'd have to recompile when a setting changes. Second, you store important data in your code and it may leak (someone could look at all the strings in a binary executable). Pass configuration through configuration file (don't store it next to code), environment variables, or command line flags. Alternatively, for highly sensitive information use services like Azure Key Vault or HashiCorp Vault.
No, not handled in a Makefile ( you really shouldn't need one for Go anyways) The point is to differentiate your configuration at run time, not at build time. In general, you want to make your development environment to be as close as production as possible, compiling all your production only code during development will save you a lot of trouble. 
Hundreds of ms to seconds for Kafka latency? I do not envy whatever infrastructure you’re running on. 
you could say the same of redis, rabbitmq, zookeeper, certbot, ad infinitum. the point here is that dependencies are bad for simplicity - _especially_ external dependencies like kafka.
In that case log to stderr so that stdout can be safely captured down the pipe.
No need to repost after just 6 days [https://www.reddit.com/r/golang/comments/8r25ho/a\_modern\_messaging\_platform\_for\_message/](https://www.reddit.com/r/golang/comments/8r25ho/a_modern_messaging_platform_for_message/) 
Configuration shouldn't be hardcoded like this. Changing anything would require recompiling your binaries and a redeploy. Consider using config files / other options before baking in a config. Build flags and such are more commonly used for architecture dependent things (i.e., where you actually will need a different binary for a different arch).
The standard practice (search "12 Factor") is to load configuration at runtime via environment variables. You do this specifically so you can ship the same binary to every environment, and you do that so you can have testing/staging environments that actually represent production. (And a shameless plug, I've got a library that makes loading this kind of stuff into a struct pretty easy, check it out: https://github.com/mhoc/enveload) If you really wanted to move forward with compiling in your configuration, I'd suggest compiling in the configuration for every environment into the single binary, then doing a runtime switch on a single environment variable like `ENV=production`. If you _really_ wanted to move forward with generating different binaries for each environment, it would be irresponsible to help you because its a Bad Idea. But your best bet is build tags. 
Here's the [issue](https://github.com/bcantoni/echotest/issues/1) for what you're experiencing. You're doing it right, I'd go back to the standard library.
Logs should be written to a io.Writer. `main()` can then configure the io.Writer in any necessary manner, including setting it simply be os.Stdout, to be a rotated log file, to be a simple file, to be a pipe, to be a syslog output, to be anything else that you could use. Using simple command-line flags to deal with this is easy. io.TeeWriter can be used to even choose more than one (I often like to have a -debug flag that dumps all the logs to os.Stderr, just so I can run the program and not have to go chasing the file). Since only one part of your code should be dealing with the configuration of the io.Writer, making grand pronunciations about the "correct" way of doing this isn't particularly necessary. Such things are only necessary in situations where you have to grind the answer in all over your code; i.e., if you one day change your variable or function naming policy, you've got a lot of work to do. The only trick is to ensure that you write your code so that the configuration of the logging is indeed isolated to one place, and you don't have 20 places that are opening a file and dumping something out.
NATS is a message bus, but it has a built in request/ reply pattern. The publisher can specify a return inbox (which is a random topic you generate), so you don’t have to include that information in your request blob. Since NATS supports wildcard topics, the client creates one inbox to listen for messages (ex: “_INBOX.123.*). This means you don’t waste time making round trip subscribe commands, and since you’re not constantly mutating the gnatsd internal data structure, your routing is extremely quick and heavily cached. But why use a broker like NATS for RPC? It’s allowed us to rip out a toooon of service discovery code. Now apps subscribe to whatever routes they know how to fulfill, and clients tell NATS what they need. That’s it. It’s allowed us to prototype a single route for a single service in a different stack to see how much fast technology X can handle problem Y. It’s been a really powerful tool. PS: that’s not to say we couldn’t have done the same thing with grpc, but I’ve really enjoyed working with NATS and will absolutely reach for it again down the road. 
Configure via environment variables that choose dependencies to inject.
👍🏻
This is a great answer!
I generally agree with the people saying if at all possible, make it configuration, but there are cases where it is not possible. I encountered one myself, where I have a debug build that accepts several command-line arguments that I actively do not want the production version to have, for security reasons. Security guarantees are being enforced by ensuring the end-users can not mess with the parameters I need to mess with during development. Obviously you want to minimize how much is wrapped up like this, but it can be necessary. It mucks with the godoc a bit but what you can do is declare a `var GetConfig func() Config` in an unconditionally-included file, then the development and prod version can have func init() { GetConfig = func() Config { ... } } Another suggestion is to just have "prod" and "-prod", so by default you build a legal developer binary with "go build". Then make all production binaries be built with a script. Most of my projects have something that ensures I've got no untracked files and no current diffs in the repo, increments a raw version number (i.e., "version_56"; if you want semantic versions you add that later manually), pushes the new tag, and builds the various executables, each of which gets tagged with the current git head hash (`git rev-parse --short HEAD`) and any useful tags on the current branch via `git log --format=%d -1 | tr ' ' @`. I have a "version" command that will print all this out. For the useful tags, the Go code replaces `@` with space again; if there's a way to pass a space in the string with -X, I haven't figured it out yet. As a general rule, I try to keep it so that "go build" produces something useful, but for anything I'm really serious about, I always use a build script because of the way I want to tag _exactly_ where the binary came from, so "go build" never produces my _production_ binaries.
Live and learn! Docker is your friend.
Better to inject the individual environment variables than switch on a fleeting concept of specific environments within the code, IMHO. Did the export ENV things for decades, far prefer shell wrappers per-env to manage the config sets.
Can anyone explain why the standard library log package uses stderr by default?
This is crap code. 10 seconds of reading: `BenchmarkParameterSlicePassedByValue` is not about slices, it's about arrays.
&gt; but it presents a problem for my IDE (GoLand), making it complain about two identical functions in the same package. Use only one tag and negate it in the other file. e.g. `// +build development` in `development.go` and `// +build !development` in `production.go`. If GoLand still complains at that point, that would seem like a bug in GoLand.
&gt; the only goal for me is just for learning purposes You aren't going to learn much building a system for scale... that never sees any scale. The learning really happens when things start breaking. IMO you'd stand to learn a lot more by building the most basic website you can, then break it with too many requests, and find out what broke and why. If I were your professor, I'd say this is a much better final project.
Thanks for the responses. I also stumbled upon this article: http://cryto.net/~joepie91/blog/2016/06/13/stop-using-jwt-for-sessions/ Do you guys use sessions or JWT tokens for logging/out?
huh, but go doesnt have objects???
Oh man... Waterloo grad here. Not 4 me but wish you good luck.
The article is literally about creating objects.
It's the POSIX standard. See [http://pubs.opengroup.org/onlinepubs/9699919799/functions/stderr.html](http://pubs.opengroup.org/onlinepubs/9699919799/functions/stderr.html)
To contrast with the fmt package I would assume.
It's not creating an object, it's mocking one using structs. Go doesn't have an object type. You'd use a struct, which the author did. It's nothing more than that. 
https://twitter.com/rob_pike/status/942528032887029760
Thanks :-)
Your example really clears my confusion on when to use a queue. Thanks!
Your example really clears my confusion on when to use a message queue, thanks!
thank you so much for the insight, I felt that too about NATS, like services should not care who is doing the job as long as someone is doing it, with gRPC I have to tell it the specific address of the other service. But it seems like you lose the safety of protobuffer and gRPC if you go with NATS, or there are ways to go around that?
So you advocate that a developer should bind and limit a component to a platform. I suggest this should be avoided for flexibility purposes and the most generic mechanism should be used -&gt; the process output
Why do you prefer syslog over stdout or stderr? the later will work on all modern platforms, the former I suspect wont work on Lambda/k8s
In some cases, nats-streaming could also be a good alternative to Kafka. https://nats.io/documentation/streaming/nats-streaming-intro/
Depends on your definition of "object".
&gt; If GoLand still complains at that point, that would seem like a bug in GoLand. That's my suspicion as well. is /u/dlsniper around?
\&gt; What about a large application, which utilizes microservices and therefore, in order to trace a message across 30 or so components That's "distributed tracing", mentioned in meta\_leap's comment above. My understanding is you add an HTTP header with an id, and that allows you to track the request as it flows through the system. Instead of writing the id to a log file at various points, and then trying to aggregate that, you skip the log file. I think [http://opentracing.io/](http://opentracing.io/) is the standard tools are growing around. \&gt; What about enterprise code, where without logging you will never notice there was a network issue or that latency is happening Those are metrics. Individual network errors happen, what matters is their rate, spikes in the graph. Latency is also a metric, probably visualized as a graph and not numbers dumped to a log file. \&gt; Didn't know what the heck it was doing, why it wasn't serving one of the files, etc Yeah I'm with you on that one. I do appreciate a \`-verbose\` mode in my tools, especially if the setup is complex. An alternative is an external took or mode that checks your setup: \`nginx -t\`, \`packer validate\`, \`systemd-analyze verify\` and things like that. \&gt; Where it's more important to log than it is to not crash. Would be nice to know who stole your money and how much. For these, descriptive clear logs are more important than having an outage. There is also FCA rules, EU rules, etc which hold them accountable for having these logs. I think this is a really good example of examining why the log statement is being issued and how it would be used, and discovering that a general-purpose logger might not be the best fit. This sounds like an audit log. It probably has some special requirements, such as recording who authorized the event, being cryptographically signed, and being sent to a secure remote system. My broader point is I think we often use "logging" to mean a lot of different unexamined things, and a lot of junk. Once we separate out the valuable parts into tracing, metrics, alerts, auditing, and so on, there isn't much left in the log. And if it's not valuable (e.g. log levels "Info" and "Debug"), if the answer to "why do you need that log statement?" is "debugging" or "just in case", then remove it.
Also if you have a package called Client don't call your constructor NewClient() but just New().
How you will be scaling your system? How you will be shipping updates? How you will be managing replications of services? How you will be managing a distributed system? Do you really like setup each server manually right now when Docker exists from 2013? I really think you need to take a look to Swarm (stacks, configs, secrets) &amp; Portainer. Your life can be easier. :)
I'm writing a Go implementation of Telegram's MTProto Mobile Protocol which uses AES-IGE. I was surprised not to find a library for this. Hopefully this can be useful to someone else in my position.
Would say that Redundancy_'s comment is valid for all compiled languages. Two environments running two different binaries means you're actually managing two codebases, and potential bugs in one environment that you cannot reproduce/detect in the other. There are dozens of very well tested packages to help you manage config in Go programs using a env variables, CLI flags and json/yml/toml files.
The reason why software is considered "soft" (compared with "hardware") is that it is "soft": meaning that ideally it should be able to run in as many different machines and OS as possible, and that's pretty much what CS folks have been doing: we started off writing programs that only run on certain model of machines. Then we invented OS that allows us to run software on all machines that can run that OS. Recently, we invented containers so that we have one binary file that can run on any platform that supports the container. To put it simple, environment is a "detail" and is at "low level". Software is a "abstraction" and is "high level". High level should not have dependency on low level things. We want software to be able to run everywhere regardless of the CPU or OS. When you compile your source code for different environment, you are essentially doing what people were doing back in the 60s or even before that. Back then, whenever a program needs to be run on a different machine, the source code has to be modified, and this has always been an error-prone process. Switching environment in your case is essentially switching machine back in the 60s. If this does not make much sense to you, I suggest you reading Robert Martin's *Clean Architecture*. Uncle Bob basically talks about the same thing that I mentioned above, but probably much more articulate than my interpretation.
Thanks for the ping. /u/h4ckth1ssh1t sorry to hear you have issues with this in the IDE, I'll have look in a few hours as I'm not near my computer for a bit. Feel free to ping me here/twitter (@dlsniper) or open an issue on our tracker https://youtrack.jetbrains.com/issues/Go whenever something is not working in the IDE, it's likely going to be much faster to get help.
I thought this said Infinite Garfield Extension at first. Yours sounds okay too I guess. 
At least a decent readme would be handy before pushing it on Reddit... We have short attention spans...
Looks pretty neat, but based on the initial run, the first thing I want to do is be able to manage containers (delete, start, etc). I'd be curious what you're attempting to accomplish that Kitematic doesn't already give us, but if it's just "because", I dig it.
Author here. I spent a good hour debating &amp; researching what to actually call "memory allocated things". I went with "object" because it's used numerous times in [Effective Go](https://golang.org/doc/effective_go.html) and that seems to be the canonical reference in Go.
I think a better approach is to find a better package name than `client`. :)
I don't understand why people are getting so worked up about the term "object". What do you call an instantiated struct instead?
bcus objects implies things like classes, mixed data, inheritance and a whole paradigm that comes with them in C based languages
&gt;func initLog(cnf \*Settings) (io.Writer, error) { switch cnf.Log { case "file": return := os.OpenFile(cnf.Acc\_log, os.O\_APPEND|os.O\_CREATE|os.O\_RDWR, 0775) case "journald": return syslog.New(syslog.LOG\_ERR|syslog.LOG\_WARNING|syslog.LOG\_DAEMON|syslog.LOG\_NOTICE|syslog.LOG\_DEBUG, cnf.Channame) default: return nil, genError("Undefined value of variable") } } Can shorten this a bit 
This was a good read, thanks
how does it compare to portainer.io ?
I don't particularly care about the term object. Even the C standard calls object to any storage region. But I could argue that the key feature of an object in OOP is open recursion, which Go types lack. That's the feature that virtual/abstract methods enable in inheritance-based OOP (but there are other mechanisms to design an object system). So I can see why people can claim they're "not really objects". I still think it doesn't really matter though. Anyone who knows Go understands what it means in context. Again, even C calls object to any storage region.
"object" does not show up in this thread at all. OO (Object-Oriented) does come up, but it's a programming paradigm. I don't think using the "object" term does imply OO (although it seems natural why this could happen).
What is the intended use-case of this? Notably, this would require separate authentication, right? What is the motivation to use this over an AEAD mode of operation?
"object" just means a chunk of memory (and usually the "thing" living in that memory). For an example of prior use, you can take a look at the C standard. In c99 (http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf) they define "object" in Sec. 3.14 as a "region of data storage in the execution environment, the contents of which can represent values (NOTE When referenced, an object may be interpreted as having a particular type)". I'd bet this definition goes further back than c99, but I didn't bother to check.
Yeah, tend to agree. Go is not object-oriented, but I think calling a thing "object" gets the point across, and that's what is important.
Additionally, the "right" way to think about classes in OO languages is that you should think of them as a template of sorts for creating objects - a class of objects usually have same-ish layouts. This is similar to the notion of a prototype: you start with an object with the memory layout of the prototype and then it changes later on. Static methods of classes are essentially functions but the compiler may optionally limit operation to within the class.
To make sure someone is processing work we added a two message response: the first message is either an Ack or a Nack, the second contains the actual response. The first message has a very short timeout. The second is more forgiving, because we know a server is processing our request. This gets us closer to TCP semantics which we liked. It also let us retry faster when we know something is wrong. One other point: retries are also super fast because we maintain a persistent connection to NATS. No need for keep alive management on the client side. And we actually use protobuf to define service and message definitions, so really we’re swapping out grpc as transport for NATS and that’s about it. Btw, we open sourced a bunch of our ruby stuff (protobuf / protobuf-nats gems). The go stuff is relatively new and not public yet. I’ll post it here when we get it out though!
&gt; What is the intended use-case of this? For IGE in general, I'm only using this to implement Telegram's protocol. I'm not sure if anyone else is using IGE in the wild, as it seems like an odd choice for a block cipher mode. For this library specifically, it's meant to be used with Go's `crypto/cipher` package. It exposes a `cipher.BlockMode` for IGE. You can then use the `cipher.BlockMode` to encrypt/decrypt with a specific `cipher.Block` (most likely from `crypto/aes`).
There are a few reasons that quickly come to mind: * There are a lot of reasons you might need to change your config at sort notice. * The person who does this might not have access to source code or CI (sysadmin, NOC, live operations etc). * If your source control is unavailable for some reason, you're in trouble. (github does get DDOSed!) * If you can't do it without redeploying, you might be coupled to pushing other things that you didn't intend to * You might also be coupled to pushing code changes up your branches and environments for something that won't change them, incurring more testing (especially if it's not fully automated) * You cannot easily test and compare old / new versions if the required config changed * You cannot easy predict the configs you may want in the future Absolutely have sensible defaults and minimize the number of things you need to configure, but don't bake assumptions about your environments into your executable.
sorry for doing this, but we have just released verson 0.8 and added a chatting room example,maybe it's better to post now,not 6 days before, so sorry again for unrestricted posting 
Your a cuck buddy. This is a terrible idea Loser 
Dunno, then. Seems (disclaimer: from a first glance, as someone whose job is not cryptography) like no reason to prefer this over established AEAD patterns, in general.
i hope the sequel incorporates some of the techniques discussed [here](https://youtu.be/HxaD_trXwRE) by rob pike
Is this an intern's project?
[removed]
It is a decent summary of different options, however I think the arguments against the alternatives are pretty weak. Export fields instead of getter/settings, and use constructors, solid advice. For simple objects just use exported fields, sure. The argument against Functional Options is pretty weak. You can just as easily expose the fields on the struct they are modifying. Godoc does a great job of documenting these by grouping them all together under the type. Structuring code to make the intent obvious does a lot more to help developers use it correctly than writing long comments on every field. The only argument against a Config struct is that it only has a single advantage over not using one. That's not much of a disadvantage. You get to better communicate how the values are used by adding a couple extra lines of code, great!
You name a "critical" feature of OO, I will name an OO language that lacks it. I've pretty much settled on "a bundling together of a data type and it's associated methods". I also consider it a characteristic of _programs_, not _languages_, as there are object-oriented C codebases. Certainly many languages push you towards object orientation when you use them, but you can mostly avoid it in those languages, and you can use the technique even in languages that don't explicitly offer features to support it. (In Java, for instance, you may be forced to use "class" constructs to organize your code, but you can write an old-fashioned procedural program in it just by using "classes" that are all public with no methods, and have a whole bunch of static class methods with your code. Yeah, your code by necessity may have the words "class" and "public" in it and such, but it won't be an object oriented program if you do that.)